- en: What is a Feature?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是特征？
- en: In the previous chapter, our main focus was filtering an image and applying
    different transformations on it. These are good techniques to analyze images but
    are not sufficient for the majority of computer vision tasks. For example, if
    we were to make a product detector for a shopping store, computing only edges
    may not be enough to say whether the image is of an orange or an apple. On the
    other hand, if a person is given the same task, it is very intuitive to differentiate
    between an orange and an apple. This is because of the fact that human perception
    combines several features, such as texture, color, surface, shape, reflections,
    and so on,  to distinguish between one object with another. This motivates to
    look for more details that relates to complex features of objects. These complex
    features can then be used in high level image vision tasks like image recognition,
    search, and so on. There are, however, cases where someone just walks straight
    into a glass wall, which is due not being able to find enough features to say
    whether it is free space or glass.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们的主要关注点是过滤图像并在其上应用不同的变换。这些技术是分析图像的好方法，但对于大多数计算机视觉任务来说并不足够。例如，如果我们为一家商店制作一个产品检测器，仅计算边缘可能不足以判断图像是橙子还是苹果。另一方面，如果一个人被赋予同样的任务，区分橙子和苹果是非常直观的。这是因为人类感知结合了多个特征，例如纹理、颜色、表面、形状、反射等，以区分一个物体与另一个物体。这促使我们寻找与物体复杂特征相关的更多细节。这些复杂特征可以用于高级图像视觉任务，如图像识别、搜索等。然而，也有情况是有人直接撞上了玻璃墙，这是由于无法找到足够多的特征来判断是空旷空间还是玻璃。
- en: In this chapter, we will first begin with an explanation features and its importance
    in computer vision. Later in the chapter, we will different types of features
    extractors like Harris Corner Detector, FAST keypoint detectors, ORB features
    detectors. The visualization of the keypoints using each of them are also described
    using OpenCV. Lastly, the effectiveness of ORB features is shown with two similar
    applications. We will also see a brief discussion on black box features.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先将解释特征及其在计算机视觉中的重要性。在章节的后面部分，我们将介绍不同类型的特征提取器，如Harris角点检测器、FAST关键点检测器、ORB特征检测器。使用OpenCV描述了使用每个提取器可视化关键点的方法。最后，通过两个类似的应用展示了ORB特征的有效性。我们还将简要讨论黑盒特征。
- en: Features use cases
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征用例
- en: 'Following are some of the generic applications that are popular in computer
    vision:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些在计算机视觉中流行的通用应用：
- en: We have two images and we would like to quantify whether these images match
    each other. Assuming a comparison metric, we say that the image matches when our
    comparison metric value is greater than a threshold.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有两张图像，我们想要量化这两张图像是否匹配。假设一个比较度量，当我们的比较度量值大于阈值时，我们说图像匹配。
- en: In another example, we have a large database of images, and for a new image,
    we want to perform an operation similar to matching. Instead of recomputing everything
    for every image, we can store a smaller, easier to search and robust enough to
    match, representation of images. This is often referred to as a feature vector
    of the image. Once a new image comes, we extract similar representation for the
    new image and search for the nearest match among the previously generated database.
    This representation is usually formulated in terms of features.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在另一个例子中，我们有一个大型图像数据库，对于一张新图像，我们想要执行类似于匹配的操作。而不是为每张图像重新计算一切，我们可以存储一个更小、更容易搜索且足够鲁棒的图像表示。这通常被称为图像的特征向量。一旦有新图像到来，我们提取新图像的相似表示，并在先前生成的数据库中搜索最近的匹配。这种表示通常用特征来表述。
- en: Also, in the case of finding an object, we have a small image of an object or
    a region called a **template**. The goal is to check whether an image has this
    template. This would require matching key points from the template against the
    given sample image. If the match value is greater than a threshold, we can say
    the sample image has a region similar to the given template. To further enhance
    our finding, we can also show where in the sample image lies our template image.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，在寻找物体的案例中，我们有一个物体的或区域的较小图像，称为**模板**。目标是检查图像是否包含这个模板。这需要将模板中的关键点与给定的样本图像进行匹配。如果匹配值大于阈值，我们可以说样本图像有一个与给定模板相似的区域。为了进一步增强我们的发现，我们还可以显示模板图像在样本图像中的位置。
- en: Similarly, a computer vision system needs to learn several features that describes
    an object such that it is quite easy to distinguish from other objects.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，计算机视觉系统需要学习描述对象的几个特征，以便于与其他对象区分开来。
- en: When we design software to do image matching or object detection in images,
    the basic pipeline for detection is formulated from a machine learning perspective.
    This means that we take a set of images, extract significant information, learn
    our model and use the learned model on new images to detect similar objects. In
    this section, we will explore more on this.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们设计软件在图像中进行图像匹配或目标检测时，检测的基本流程是从机器学习角度制定的。这意味着我们取一组图像，提取显著信息，学习我们的模型，并在新图像上使用学习到的模型来检测相似对象。在本节中，我们将进一步探讨这一点。
- en: 'In general, an image matching procedure looks as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，图像匹配过程如下所示：
- en: The first step is to extract robust features from a given image. This involves
    searching through the whole image for possible features and then thresholding
    them. There are several techniques for the selection of features such as SIFT[3],
    SURF[4], FAST[5], BRIEF[6], ORB detectors[2], and so on. The feature extracted,
    in some cases, needs to be converted into a more descriptive form such that it
    is learnt by the model or can be stored for re-reading.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一步是从给定图像中提取鲁棒特征。这涉及到在整个图像中搜索可能的特征，然后对其进行阈值处理。有几种选择特征的技术，如SIFT[3]、SURF[4]、FAST[5]、BRIEF[6]、ORB检测器[2]等。在某些情况下，提取的特征需要转换为更描述性的形式，以便模型学习或可以存储以供重新读取。
- en: In the case of feature matching, we are given a sample image and we would like
    to see whether this matches a reference image. After feature detection and extraction,
    as shown previously, a distance metric is formed to compute the distance between
    features of a sample with respect to the features of reference. If this distance
    is less than the threshold, we can say the two images are similar.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在特征匹配的情况下，我们给定一个样本图像，并希望查看它是否与参考图像匹配。在特征检测和提取之后，如前所述，形成一个距离度量来计算样本特征与参考特征之间的距离。如果这个距离小于阈值，我们可以说这两张图像是相似的。
- en: For feature tracking, we omit previously explained feature matching steps. Instead
    of globally matching features, the focus is more on neighborhood matching. This
    is used in cases such as image stabilization, object tracking, or motion detection.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于特征跟踪，我们省略了之前解释过的特征匹配步骤。不是全局匹配特征，而是更关注邻域匹配。这在图像稳定、目标跟踪或运动检测等情况下使用。
- en: Datasets and libraries
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集和库
- en: In this chapter, we will use `OpenCV` library for performing feature detection
    and matching. The plots are generated using `matplotlib`. We will be using custom
    images to show the results of various algorithms. However, the code provided here
    should work on webcam or other custom images too.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用`OpenCV`库进行特征检测和匹配。图表使用`matplotlib`生成。我们将使用自定义图像来展示各种算法的结果。然而，这里提供的代码也应该适用于摄像头或其他自定义图像。
- en: Why are features important?
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征为什么重要？
- en: Features play a major role in creating good quality computer vision systems.
    One of the first features we can think of is **pixels**. In order to create a
    comparison tool, we use an average of squared distance between the pixel values
    of two images. These, however, are not robust because rarely will you see two
    images that are exactly the same. There is always some camera movement and illumination
    changes between images, and computing a difference between pixel values will be
    giving out large values even when the images are quite similar.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 特征在创建高质量计算机视觉系统中起着重要作用。我们可以想到的第一个特征是**像素**。为了创建一个比较工具，我们使用两个图像像素值之间平方距离的平均值。然而，这些并不稳健，因为很少会看到两张完全相同的图像。图像之间总是存在一些相机移动和光照变化，计算像素值之间的差异将会给出很大的值，即使图像非常相似。
- en: There are, however, other kinds of features that take into account local and
    global properties of an image. The local properties are referred to as image statistics
    around the neighborhood of the image, while global refers to considering overall
    image statistics. Since both local, and global properties of an image provide
    significant information about an image, computing features that can capture these
    will make them more robust and accurate in applications.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有其他类型的特征，它们考虑了图像的局部和全局属性。局部属性指的是图像周围邻域的图像统计信息，而全局属性是指考虑整体图像统计信息。由于图像的局部和全局属性都提供了关于图像的重要信息，因此计算能够捕捉这些信息的特征将使它们在应用中更加鲁棒和准确。
- en: The most basic form of feature detector is point features. In applications such
    as panorama creation on our smartphones, each image is stitched with the corresponding
    previous image. This stitching of image requires correct orientation of an image
    overlapped at pixel level accuracy. Computing corresponding pixels between two
    images requires pixel matching.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的特征检测形式是点特征。在我们的智能手机上创建全景图等应用中，每张图像都与对应的上一张图像拼接。这种图像拼接需要以像素级精度正确对齐重叠的图像。计算两张图像之间的对应像素需要像素匹配。
- en: Harris Corner Detection
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哈里斯角检测
- en: We start feature point detection using the Harris Corner Detection[1] technique.
    In this, we begin with choosing a matrix, termed a **window**, which is small
    in size as compared to the image size.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始使用哈里斯角检测[1]技术进行特征点检测。在这个过程中，我们首先选择一个矩阵，称为**窗口**，其大小与图像大小相比较小。
- en: 'The basic idea is to first overlay chosen window on the input image and observe
    only the overlayed region from the input image. This window is later shifted over
    the image and the new overlayed region is observed. In this process, there arise
    three different cases:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 基本思想是首先将选定的窗口叠加到输入图像上，并仅从输入图像中观察叠加区域。然后，将这个窗口在图像上移动，并观察新的叠加区域。在这个过程中，会出现三种不同的情况：
- en: If there is a flat surface, then we won't be able to see any change in the window
    region irrespective of the direction of movement of the window. This is because
    there is no edge or corner in the window region.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果存在一个平面表面，那么无论窗口移动的方向如何，我们都无法看到窗口区域中的任何变化。这是因为窗口区域中没有边缘或角落。
- en: In our second case, the window is overlayed on edge in the image and shifted.
    If the window moves along the direction of the edge, we will not be able to see
    any changes in the window. While, if the window is moved in any other direction,
    we can easily observe changes in the window region.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们的第二种情况下，窗口在图像的边缘上叠加并发生了偏移。如果窗口沿着边缘的方向移动，我们将无法看到窗口中的任何变化。然而，如果窗口向任何其他方向移动，我们可以很容易地观察到窗口区域中的变化。
- en: Lastly, if the window is overlayed on a corner in the image and is shifted,
    where the corner is an intersection of two edges, in most of the cases, we will
    be able to observe the changes in the window region.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，如果窗口叠加在图像的角落上并且发生了偏移，而角落是两条边缘的交汇处，在大多数情况下，我们将能够观察到窗口区域中的变化。
- en: 'Harris Corner Detection uses this property in terms of a score function. Mathematically,
    it is given as:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 哈里斯角检测（Harris Corner Detection）利用这个属性作为得分函数。从数学上讲，它表示为：
- en: '![](img/57db2e62-ffbc-41f7-8bc3-c5c706c99c02.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/57db2e62-ffbc-41f7-8bc3-c5c706c99c02.png)'
- en: Where *w* is a window, *u* and *v* are the shift and *I* is image pixel value.
    The output *E* is the objective function and maximizing this with respect to *u*
    and *v* results in corner pixels in the image *I*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *w* 是窗口，*u* 和 *v* 是偏移量，*I* 是图像像素值。输出 *E* 是目标函数，通过相对于 *u* 和 *v* 最大化这个函数，我们得到图像
    *I* 中的角落像素。
- en: 'The Harris Corner Detection score value will show whether there is an edge,
    corner, or flat surface. An example of Harris Corners of different kinds of images
    is shown in the following figure:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 哈里斯角检测的得分值将显示是否存在边缘、角落或平面表面。以下图中展示了不同类型图像的哈里斯角示例：
- en: '![](img/26e4734c-afa1-48e7-b2b6-afa9e56c4236.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/26e4734c-afa1-48e7-b2b6-afa9e56c4236.png)'
- en: 'In the previous figure, the upper row has input images, while the bottom row
    has detected corners. These corners are shown with small gray pixels values corresponding
    to the location in the input image.  In order to generate an image of corners
    for a given colored image, use the following code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，上面一行是输入图像，下面一行是检测到的角落。这些角落用对应于输入图像位置的灰色像素值表示。为了生成给定彩色图像的角落图像，请使用以下代码：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We can generate different number of corners for an image by changing the parameters
    such as covariance matrix block size, neighbourhood kernel size and Harris score
    parameter. In the next section, we will see more robust feature detectors.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过改变协方差矩阵块大小、邻域核大小和Harris分数参数等参数来为图像生成不同数量的角点。在下一节中，我们将看到更鲁棒的特征检测器。
- en: FAST features
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FAST特征
- en: Many features detectors are not useful for real-time applications such as  a
    robot with a camera is moving on the streets. Any delay caused may decrease the
    functionality of the robot or complete system failure. Features detection is not
    the only part of the robot system but if this effects the runtime, it can cause
    significant overhead on other tasks to make it work real time.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 许多特征检测器对于实时应用（如带有摄像头的机器人在街道上移动）没有用。任何延迟都可能导致机器人或整个系统的功能下降，甚至可能导致系统完全失效。特征检测不是机器人系统的唯一部分，但如果这影响了运行时间，它可能会对其他任务造成显著的开销，使其能够实时工作。
- en: '**FAST** (**Features from Accelerated Segment Test**)[5], was introduced by
    Edward Rosten and Tom Drummond in 2006. The algorithm uses pixel neighborhood
    to compute key points in an image. The algorithm for FAST feature detection is
    as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**FAST**（**加速段测试特征**）[5]，由Edward Rosten和Tom Drummond于2006年提出。该算法使用像素邻域来计算图像中的关键点。FAST特征检测的算法如下：'
- en: 'An interesting point candidate pixel **(i,j)** is selected with an intensity
    *I (i,j)*:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个有趣的点候选像素**（i,j）**，其强度为*I (i,j)*：
- en: '![](img/9d6d678d-ac93-4f05-a4ab-41e561fa4109.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d6d678d-ac93-4f05-a4ab-41e561fa4109.png)'
- en: In a circle of 16 pixels, given a threshold *t,* estimate *n* adjoining points
    which are brighter than pixel *(i,j)* intensity by a threshold *t* or darker than
    *(i,j)* pixel intensity by a threshold *t*. This will become *n* pixels which
    are either less than *(I(i,j) + t)* or greater than *(I(i,j) - t)*. This *n* was
    chosen as 12.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个16像素的圆内，给定一个阈值*t*，估计*n*个相邻点，这些点的亮度比像素*(i,j)*的强度高一个阈值*t*，或者比*(i,j)*像素的强度低一个阈值*t*。这将成为*n*个像素，这些像素的亮度要么小于*(I(i,j)
    + t)*，要么大于*(I(i,j) - t)*。这个*n*被选为12。
- en: In a high-speed test, only four pixels (as shown in the figure) at 1, 9, 5,
    and 13 are looked at. The intensity value of at least three pixels of these decides
    whether the center pixel *p* is a corner. If these values are either greater than
    the *(I(i,j) + t)* or less than *(I(i,j) - t)* then the center pixel is considered
    a corner.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在高速测试中，只查看四个像素（如图所示），位置为1、9、5和13。这些像素中的至少三个像素的强度值决定了中心像素*p*是否为角点。如果这些值要么大于*(I(i,j)
    + t)*，要么小于*(I(i,j) - t)*，则中心像素被认为是角点。
- en: 'In OpenCV , the steps to compute FAST features are as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，计算FAST特征的步骤如下：
- en: Initialize detector using `cv2.FastFeatureDetector_create()`
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cv2.FastFeatureDetector_create()`初始化检测器
- en: Setup threshold parameters for filtering detections
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置阈值参数以过滤检测
- en: Setup flag if non-maximal suppression to be used for clearing neighbourhood
    regions of repeated detections
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置标志，如果需要使用非最大抑制来清除重复检测的邻域区域
- en: Detect keypoints and plot them on the input image
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在输入图像上检测关键点并绘制它们
- en: 'In the following figure, there are plots of FAST corners (in small circles)
    on the input image with varying threshold values. Depending on the image, a different
    choice of thresholds produce different  number of key feature points:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图中，有不同阈值值的输入图像上的FAST角点（在小圆圈中）的图表。根据图像的不同，不同的阈值选择会产生不同数量的关键特征点：
- en: '![](img/a69b4bbf-cc5e-4cfd-b77f-18597c86bb15.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a69b4bbf-cc5e-4cfd-b77f-18597c86bb15.png)'
- en: 'To generate each image in the previous figure, use the following code by changing
    the threshold values:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成上一图中的每个图像，请使用以下代码并更改阈值值：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following figure shows variations of the same detector across different
    images with varying thresholds:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了在不同图像上具有不同阈值的同一检测器的变化：
- en: '![](img/56b8c648-f7fa-42ef-81b9-1966529dc528.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/56b8c648-f7fa-42ef-81b9-1966529dc528.png)'
- en: This shows that choice of parameters is quite crucial for different images.
    Though a common threshold value may not work for all image, a good approximation
    can be used depending on the similarity of images.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明参数的选择对于不同的图像至关重要。尽管一个常见的阈值值可能不适用于所有图像，但可以根据图像的相似性使用一个好的近似值。
- en: ORB features
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ORB特征
- en: Using previously described corner detectors are fast to compute, however in
    matching two images, it is difficult to select which two image corners are matched
    for corresponding pixels. An additional information that describes properties
    a corner is required. A combination of detected keypoints, such as corners, and
    corresponding descriptors makes comparing images more efficient and robust.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用先前描述的角点检测器计算速度快，然而在匹配两张图像时，很难选择哪两个图像角点对应于相应的像素。需要额外的信息来描述角点的属性。检测到的关键点（如角点）及其对应描述符的组合使得比较图像更加高效和鲁棒。
- en: 'ORB features detection[2] features were described by Ethan Rublee et al. in
    2011 and have since been one of the popular features in various applications.
    This combines two algorithms: FAST feature detector with an orientation component
    and BRIEF Descriptors, hence the name **Oriented FAST and Rotated BRIEF** (**ORB**). The
    major advantage of using ORB features is the speed of detections while maintaining
    robust detections. This makes them useful for several real-time applications like
    robotics vision system, smartphone apps, and so on.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ORB特征检测[2]由Ethan Rublee等人于2011年描述，并自那时起在各种应用中成为流行的特征之一。它结合了两个算法：具有方向组件的FAST特征检测器和BRIEF描述符，因此得名**Oriented
    FAST and Rotated BRIEF**（**ORB**）。使用ORB特征的主要优点是检测速度的快速性，同时保持鲁棒的检测。这使得它们在机器人视觉系统、智能手机应用等多种实时应用中非常有用。
- en: In this chapter we have already seen FAST feature detectors, we will further
    continue describing BRIEF descriptor and finally build on ORB detector.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经看到了FAST特征检测器，我们将进一步继续描述BRIEF描述符，并最终基于ORB检测器构建。
- en: FAST feature limitations
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FAST特征限制
- en: FAST Features as described in the previous section computes corner in the image
    using neighborhood pixels. By creating a comparison test along the circular region
    around a pixel, features are computed rapidly. FAST features are quite efficient
    for real-time applications; these do not produce rotation information of the features.
    This causes a limitation if we are looking for orientation invariant features.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述的FAST特征通过使用邻域像素计算图像中的角点。通过在像素周围的圆形区域内创建比较测试，特征可以快速计算。FAST特征对于实时应用非常高效；这些特征不产生特征旋转信息。如果我们寻找的是方向不变的特征，这会带来限制。
- en: 'In ORB,  FAST features are used with orientation information as well. Using
    a circular radius of 9 pixels, a vector between computed intensity centroid and
    center of the corner is used to describe orientation at the given corner. This
    intensity centroid for a given patch is computed as follows :'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在ORB中，FAST特征与方向信息一起使用。使用9像素的圆形半径，一个从计算出的强度质心到角点中心的向量用于描述给定角点的方向。给定补丁的强度质心按以下方式计算：
- en: 'For an image I and a patch window, compute moments using:'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于图像I和补丁窗口，使用以下方法计算矩：
- en: '![](img/14ad6e32-f91b-4e8d-8d22-676b7c221fe5.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/14ad6e32-f91b-4e8d-8d22-676b7c221fe5.png)'
- en: 'Using previous moments, intensity centroid of given patch is given as:'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用先前矩，给定补丁的强度质心给出如下：
- en: '![](img/ff053273-7b12-4d6f-ac57-9f88240e707d.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ff053273-7b12-4d6f-ac57-9f88240e707d.png)'
- en: Since, we already know the center *O* of the patch, a vector joining ![](img/29e62981-0826-45d3-8e36-d9b721011edb.png) is
    the orientation of the patch.  In further sections, we will see an overall implementation
    of ORB feature detectors which uses this method.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经知道了补丁的中心*O*，连接![](img/29e62981-0826-45d3-8e36-d9b721011edb.png)的向量是补丁的方向。在接下来的章节中，我们将看到ORB特征检测器的整体实现，它使用这种方法。
- en: BRIEF Descriptors and their limitations
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BRIEF描述符及其限制
- en: 'The popular feature descriptors like SIFT or SURF outputs large vectors of
    dimensions 128 and 64 respectively. In applications such as image search, it is
    quite likely that the features are stored and searched for features rather than
    the original image. This becomes computationally complex and memory may be inefficient
    if the number of images reaches a few hundred thousand. In such cases, simple
    dimensionality reduction is an added step and may reduce overall efficiency. The
    descriptor proposed by Michael Calonder and their co-authors. in *BRIEF: Binary
    Robust Independent Elementary Features*[6] resolves issues by consuming less memory.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '流行的特征描述符如SIFT或SURF分别输出128维和64维的大向量。在图像搜索等应用中，很可能会存储和搜索特征而不是原始图像。如果图像数量达到几百万，这会变得计算复杂，内存可能效率低下。在这种情况下，简单的降维是一个额外的步骤，可能会降低整体效率。由Michael
    Calonder及其合作者在*BRIEF: Binary Robust Independent Elementary Features*[6]中提出的描述符通过消耗更少的内存解决了这些问题。'
- en: BRIEF computes differences of intensities in a small patch of an image and represents
    it as a binary string. This not only makes it faster but also the descriptor preserves
    good accuracy. However, there is no feature detector in BRIEF but combining it
    with FAST detectors makes it efficient.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: BRIEF计算图像小补丁中强度的差异，并将其表示为二进制字符串。这不仅使其更快，而且描述符保持了良好的精度。然而，BRIEF中没有特征检测器，但与FAST检测器结合使其更有效。
- en: ORB features using OpenCV
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OpenCV的ORB特征
- en: The following code uses ORB features implementation in `OpenCV`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码使用了`OpenCV`中的ORB特征实现。
- en: 'It is a three-step process, which is described as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个三步过程，具体描述如下：
- en: 'First create an ORB object and update parameter values:'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先创建一个ORB对象并更新参数值：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Detect keypoints from previously created ORB object:'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从之前创建的ORB对象中检测关键点：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Lastly, compute descriptors for each keypoints detected:'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，计算每个检测到的关键点的描述符：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The overall code for  ORB keypoints detections and descriptor extractor is
    given as:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ORB关键点检测和描述符提取的整体代码如下：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'An example of generated keypoints is as shown in the following figure (in circles):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的关键点的示例如图所示（圆圈中）：
- en: '![](img/2acb8135-7ca7-4144-88d6-94cd87f58a27.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2acb8135-7ca7-4144-88d6-94cd87f58a27.png)'
- en: 'As you can see in the following figure, different images produce different
    feature points for various shapes of objects:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在以下图中所见，不同的图像为各种形状的物体产生了不同的特征点：
- en: '![](img/24e634de-267e-4f7f-b768-c79e2b5c4de7.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/24e634de-267e-4f7f-b768-c79e2b5c4de7.png)'
- en: 'In order to plot previous shown figures with different keypoints, we can use
    both `OpenCV` and `Matplotlib` as:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了绘制之前展示的图像并使用不同的关键点，我们可以同时使用`OpenCV`和`Matplotlib`如下：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this section, we saw formulation of ORB features that not only combines robust
    features, but also provides descriptors for easier comparison to other features.
    This is a strong formulation of feature detector, however explicitly designing
    a feature detector for different task will require efficient choice of parameters
    such as patch size for FAST detector, BRIEF descriptor parameters etc. For a non-expert,
    setting these parameters may be quite cumbersome task. In following section, we
    will begin with discussion on black box features and its importance in creating
    computer vision systems.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了ORB特征的公式化，它不仅结合了鲁棒特征，还为其他特征的比较提供了描述符。这是一个强大的特征检测器公式，然而，为不同的任务显式设计特征检测器将需要高效选择参数，例如FAST检测器的补丁大小、BRIEF描述符参数等。对于非专家来说，设置这些参数可能是一项相当繁琐的任务。在下一节中，我们将从讨论黑盒特征及其在创建计算机视觉系统中的重要性开始。
- en: The black box feature
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 黑盒特征
- en: 'The features we discussed previously are highly dependent on an image to image
    basis. Some of the challenges observed in detecting features are:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论的特征高度依赖于图像到图像的基础。在检测特征时观察到的挑战包括：
- en: In case of illumination changes, such as nighttime image or daylight images
    there would be a significant difference in pixel intensity values as well as neighborhood
    regions
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在光照变化的情况下，例如夜间图像或日光图像，像素强度值以及邻域区域会有显著差异
- en: As object orientation changes, keypoint descriptor changes significantly. In
    order to match corresponding features, a proper choice of descriptor parameters
    is required
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着物体方向的变化，关键点描述符会显著变化。为了匹配相应的特征，需要正确选择描述符参数
- en: Due to these challenges, several parameters used here need to be tuned by experts.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些挑战，这里使用的几个参数需要由专家进行调整。
- en: In recent years, a lot has been happening with neural networks in the field
    of computer vision. The popularity of them has risen due to higher accuracy and
    less hand-tuned parameters. We can call them black box features—though the term
    black refers only to the way they are designed. In a majority of these model deployments,
    the parameters are learned through training and require the least supervision
    of parameters setting. The black box modeling feature detection helps in getting
    better features by learning over a dataset of images. This dataset consists of
    possible different variations  of images, as a result the learnt detector can
    extract better features even in wide variation of image types. We will study these
    feature detectors in the next chapter as CNNs.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，在计算机视觉领域，神经网络发生了许多变化。它们的普及率因更高的准确性和更少的手动调整参数而上升。我们可以称它们为黑盒特征——尽管“黑”一词仅指它们的设计方式。在这些模型部署的大多数情况下，参数是通过训练学习的，并且需要参数设置的最小监督。黑盒建模特征检测有助于通过学习图像数据集来获得更好的特征。这个数据集包含图像的可能不同变体，因此，学习到的检测器甚至可以在图像类型广泛变化的情况下提取更好的特征。我们将在下一章中作为CNN研究这些特征检测器。
- en: Application – find your object in an image
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用 – 在图像中找到你的对象
- en: The most common application for using features is given an object, find the
    best possible match for it in the image. This is often referred to as **template
    matching**, where the object at hand is a usually small window called a **template**
    and goal is to compute the best-matched features from this template to a target
    image. There exist several solutions to this, but for the sake of understanding,
    we will use ORB features.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用特征的最常见应用是给定一个对象，在图像中找到其最佳匹配。这通常被称为**模板匹配**，其中当前对象通常是一个称为**模板**的小窗口，目标是计算从该模板到目标图像的最佳匹配特征。存在几种解决方案，但为了理解起见，我们将使用ORB特征。
- en: 'Using ORB features, we can do feature matching in a brute force way as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用ORB特征，我们可以以以下暴力方式执行特征匹配：
- en: Compute features in each image (template and target).
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算每个图像（模板和目标）中的特征。
- en: For each feature in a template, compare all the features in the target detected
    previously. The criterion is set using a matching score.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于模板中的每个特征，比较之前在目标中检测到的所有特征。标准是通过匹配分数设置的。
- en: If the feature pair passes the criterion, then they are considered a match.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果特征对通过了标准，则它们被认为是匹配的。
- en: Draw matches to visualize.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绘制匹配以可视化。
- en: 'As a pre-requisite, we will follow previously shown codes for extracting features
    as:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 作为先决条件，我们将遵循之前显示的代码来提取特征：
- en: '[PRE7]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Once we have keypoints and descriptors from each of the images, we can use them
    to compare and match.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们从每个图像中获得了关键点和描述符，我们就可以使用它们进行比较和匹配。
- en: 'Matching keypoints between two images is a two-step process:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 两个图像之间匹配关键点是一个两步过程：
- en: 'Create desired kind of matcher specifying the distance metric to be used. Here
    we will use Brute-Force Matching with Hamming distance:'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建所需的匹配器，指定要使用的距离度量。这里我们将使用汉明距离的暴力匹配：
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Using descriptors for keypoints from each image, perform matching as:'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用每个图像的关键点描述符进行匹配，执行如下：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the following code, we will show overall Brute-Force method of matching
    keypoints from one image to another using corresponding descriptors only:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将展示使用对应描述符从一幅图像到另一幅图像匹配关键点的整体暴力方法：
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the following figure, the features from the template are matched to the
    original image. To show the effectiveness of matching, only the best matches are
    shown:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图中，模板中的特征与原始图像进行了匹配。为了展示匹配的有效性，只显示了最佳匹配：
- en: '![](img/aeb9b00d-4645-4f3f-9f2c-0ebed4b2656a.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/aeb9b00d-4645-4f3f-9f2c-0ebed4b2656a.png)'
- en: 'The previous feature matching image is created using the following code, where
    we use a sample template image to match to a large image of the same object:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的特征匹配图像是通过以下代码创建的，其中我们使用一个样本模板图像与同一对象的较大图像进行匹配：
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Applications – is it similar?
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用 – 它们是否相似？
- en: In this application, we would like to see if they are similar using previously
    described feature detectors. For that, we use a similar approach as previously
    mentioned. The first step is computing feature keypoints and descriptors for each
    image. Using these performs matching between one image and another. If there are
    a sufficient number of matches, we can comfortably say that the two images are
    similar.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个应用中，我们想通过之前描述的特征检测器来查看它们是否相似。为此，我们采用与之前提到的类似方法。第一步是计算每个图像的特征关键点和描述符。使用这些信息在一张图像和另一张图像之间进行匹配。如果有足够多的匹配，我们就可以舒适地说这两张图像是相似的。
- en: 'For the prerequisites,  we use the same ORB keypoint and descriptor extractor
    but added downsampling of the image:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于先决条件，我们使用相同的 ORB 关键点和描述符提取器，但增加了图像的下采样：
- en: '[PRE12]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Using the previously computed keypoints and descriptors, the matching is done
    as:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前计算的关键点和描述符，匹配过程如下：
- en: '[PRE13]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The results of an example are as shown in the following figure, where inputs
    are same objects with different viewpoints. The correct matches are shown as with
    connecting lines:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图所示为示例结果，其中输入是具有不同视点的相同对象。正确的匹配用连接线表示：
- en: '![](img/3983685d-067f-473f-bf48-634dd55bc183.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3983685d-067f-473f-bf48-634dd55bc183.png)'
- en: In this section, we saw two similar approaches for image matching using ORB
    keypoints and a Brute-Force matcher. The matching can be further enhanced by using
    more faster algorithms like approximate neighborhood matches. The effect of faster
    matching is mostly seen in the cases where a large number of features keypoints
    are extracted.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了两种使用 ORB 关键点和暴力匹配器进行图像匹配的类似方法。通过使用更快的算法，如近似邻域匹配，可以进一步增强匹配效果。更快的匹配效果主要在提取了大量特征关键点的情况下才能看到。
- en: Summary
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we began discussion features and its importance in computer
    vision applications. Harris Corner Detector is used to detect corners where runtime
    is of utmost importance. These can run on embedded devices with high speeds. Extending
    over to more complex detectors, we saw FAST features and in combination with BRIEF
    descriptors, ORB features can be formed. These are robust for different scales
    as well as rotations. Finally, we saw the application of feature matching using
    ORB features and a use of pyramid downsampling.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们开始讨论特征及其在计算机视觉应用中的重要性。Harris 角点检测器用于检测运行时间至关重要的角点。这些可以在高速运行的嵌入式设备上运行。扩展到更复杂的检测器，我们看到了
    FAST 特征，以及与 BRIEF 描述符结合，可以形成 ORB 特征。这些特征对不同的尺度和旋转都具有鲁棒性。最后，我们看到了使用 ORB 特征进行特征匹配的应用，以及金字塔下采样的使用。
- en: The discussion on black box features will continue in the next chapter with
    the introduction of neural networks and especially CNNs.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 关于黑盒特征的讨论将在下一章继续，届时将介绍神经网络，特别是卷积神经网络 (CNN)。
- en: References
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Harris Chris, and Mike Stephens. *A combined corner and edge detector*. In Alvey
    vision conference, vol. 15, no. 50, pp. 10-5244\. 1988.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Harris Chris, 和 Mike Stephens. *一种结合角点和边缘检测器*. 在 Alvey 视觉会议，第 15 卷，第 50 期，第
    10-5244 页。1988 年。
- en: 'Rublee Ethan, Vincent Rabaud, Kurt Konolige, and Gary Bradski. *ORB: An efficient
    alternative to SIFT or SURF*. In Computer Vision (ICCV), 2011 IEEE international
    conference on, pp. 2564-2571\. IEEE, 2011.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rublee Ethan, Vincent Rabaud, Kurt Konolige, 和 Gary Bradski. *ORB：SIFT 或 SURF
    的有效替代方案*. 在 2011 年 IEEE 国际计算机视觉会议 (ICCV)，第 2564-2571 页。IEEE，2011 年。
- en: Lowe David G. *Object recognition from local scale-invariant features*. In Computer
    vision, 1999\. The proceedings of the seventh IEEE international conference on,
    vol. 2, pp. 1150-1157\. IEEE, 1999.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lowe David G. *从局部尺度不变特征进行物体识别*. 在 1999 年计算机视觉会议，第 7 届 IEEE 国际会议，第 2 卷，第 1150-1157
    页。IEEE，1999 年。
- en: 'Bay Herbert, Tinne Tuytelaars, and Luc Van Gool. *Surf: Speeded up robust features*. Computer
    vision–ECCV 2006(2006): 404-417.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bay Herbert, Tinne Tuytelaars, 和 Luc Van Gool. *Surf：加速的鲁棒特征*. 计算机视觉 – ECCV
    2006(2006): 404-417。'
- en: 'Rosten Edward, and Tom Drummond. *Machine learning for high-speed corner detection*. Computer
    Vision–ECCV 2006(2006): 430-443.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rosten Edward, 和 Tom Drummond. *高速角点检测的机器学习*. 计算机视觉 – ECCV 2006(2006): 430-443。'
- en: 'Calonder Michael, Vincent Lepetit, Christoph Strecha, and Pascal Fua. *Brief:
    Binary robust independent elementary features*. Computer Vision–ECCV 2010 (2010):
    778-792.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Calonder Michael, Vincent Lepetit, Christoph Strecha, 和 Pascal Fua. *Brief：二进制鲁棒独立基本特征*.
    计算机视觉 – ECCV 2010 (2010): 778-792。'
