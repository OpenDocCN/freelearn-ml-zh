- en: Chapter 5. Object Detection Using Ada Boost and Haar Cascades
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter shows a very interesting feature of OpenCV—detecting faces in an
    image or a video stream. In the latter case, we call it **face tracking**. In
    order to do so, this chapter dives into machine-learning algorithms, specifically
    supervised learning with boosting. We will cover the **Viola-Jones classifier**
    and its theory as well as the details on how to use the face-trained classifiers
    that are bundled with OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The boosting theory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viola-Jones classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting faces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning new objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to understand the theory behind
    face classifiers through boosting, and the Viola-Jones classifier. You will also
    know how to use straightforward face classifiers. Besides, you will be able to
    create your own object classifier for different objects.
  prefs: []
  type: TYPE_NORMAL
- en: The boosting theory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The problem of detecting a face in an image can be posed in a simpler way. We
    could iterate the whole image through several smaller windows and create a classifier
    that will tell whether a window is a face or not. The windows that correctly identify
    the face will be the coordinates of face detection.
  prefs: []
  type: TYPE_NORMAL
- en: Now, what exactly is a classifier and how can it be built? In machine learning,
    the problem of classification has been deeply explored and it is posed as the
    identification of which of the set of categories a given observation belongs to,
    based on a previously trained set of known category memberships. This could be
    something like if a given image belongs to the banana, apple, or grape category,
    for instance, in a fruit classification application. In the case of face detection,
    there are two categories—face and non-face.
  prefs: []
  type: TYPE_NORMAL
- en: This section describes a meta-algorithm, which is basically a templated algorithm
    to create a strong classifier using a set of weak learners. These weak learners
    are classifiers based on some features that although not able to divide the whole
    set in the two categories, they do a good job for some of the sets. Let's say
    that a weak learner could be a classifier that looks for a mustache in order to
    tell whether a given face is of a man. Even if it might not find all men in the
    set, it will do a good job for the ones who have mustaches.
  prefs: []
  type: TYPE_NORMAL
- en: AdaBoost
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**AdaBoosting**, from Adaptive Boosting, is not actually an algorithm, but
    it''s a meta-algorithm that will help us with building a classifier. Its main
    mission is to build a great classifier out of weak classifiers, which are just
    better by chance. Its final form is a weighted combination of the given classifiers,
    as given in the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![AdaBoost](img/3972OS_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The sign operator will return `+1` when the expression in parenthesis is positive,
    and `-1` otherwise. Note that it is a binary classifier that yields *yes* or *no*,
    or it could be *does belong* or *does not belong*, or simply `+1` or `-1`. So,
    ![AdaBoost](img/3972OS_05_06.jpg) is the weight assigned to the given classifier
    ![AdaBoost](img/3972OS_05_07.jpg) for a given input *x* in a set of *T* classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, in a group of people, one wants to know whether any given person
    *p* is a man or woman. Let''s say we have some weak classifiers, which are good
    guesses, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![AdaBoost](img/3972OS_05_08.jpg): If the height is greater than 5 feet and
    9 inches (~175 cm), then the person is a male or else female. Of course, there
    are several women taller than men, but on an average, men are taller.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![AdaBoost](img/3972OS_05_09.jpg): If a person has long hair, then the person
    is a female or else male. Again, there are several long haired men, but, on an
    average, women usually have longer hair.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![AdaBoost](img/3972OS_05_10.jpg): If a person has a beard, then the person
    is a male or else female. Here, we can misclassify shaved men.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s say we have this random set of people:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name/Feature | Height (h1) | Hair (h2) | Beard (h3) | Gender (f(x)) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Katherine | 1.69 | Long | Absent | Female |'
  prefs: []
  type: TYPE_TB
- en: '| Dan | 1.76 | Short | Absent | Male |'
  prefs: []
  type: TYPE_TB
- en: '| Sam | 1.80 | Short | Absent | Male |'
  prefs: []
  type: TYPE_TB
- en: '| Laurent | 1.83 | Short | Present | Male |'
  prefs: []
  type: TYPE_TB
- en: '| Sara | 1.77 | Short | Absent | Female |'
  prefs: []
  type: TYPE_TB
- en: Classifier `h1` will correctly classify three people, while `h2` will get it
    right for four people, and `h3` will work for three people. We would then select
    `h2`, which was the best, for the one that minimizes the weighted error, and set
    its alpha. We would then increase weight for wrongly classified data (Sara) and
    decrease weight for all the others (Katherine, Dan, Sam, and Laurent). We would
    then look for the best classifier on the new distribution. Now that Sara is on
    the spot, either `h2` or `h3` would be selected, depending on the error, since
    `h1` gets Sara wrong with a higher weight. We would then continue for the `T`
    weak classifiers, in our case 3.
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm for AdaBoost goes like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![AdaBoost](img/3972OS_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Fortunately, OpenCV already implements boosting. The following example can be
    found in the `boost` project from `Chapter 5`, and it shows how to deal with the
    `Boost` class, with the preceding example. We first create a 5 x 3 matrix called
    `data`. This matrix stores our training dataset, and will be used by `Boost` to
    create a classifier. Then, we feed the matrix just like in the preceding table.
    The first column is the height. Hair and beard are given values one or zero. When
    the hair is short, we put `zero`, when it's long, we put `one`. In case the beard
    is present, its value is `one` or else `zero`. These values are set using the
    Mat's `put` function. Note that the fact of being a man or a woman does not go
    into the `data` matrix since it is actually the output we want for our classifier.
    This way, a 5 x 1 column matrix `responses` is created. It simply stores `zero`
    for female and `one` for male.
  prefs: []
  type: TYPE_NORMAL
- en: Then, a `Boost` class is instantiated, and we set parameters for the training
    through the `CvBoostParams` its setters. We have set the boost type to be **Discrete
    Adaboost** using the `setBoostType` method, passing `Boost.DISCRETE` as a parameter.
    Other variants of boosting are known as **Real AdaBoost**, **LogitBoost**, and
    **Gentle AdaBoost**. The setWeakCount method sets the number of weak classifiers
    used. In our case, it was `3`. The next setting tells that if the number of samples
    in a node is less than this parameter, then the node will not be split. Actually,
    the default value is `10`, and it won't work with such a small dataset, so it
    is set to `4` so that it will work with this dataset. It is important to note
    that Boost derives from DTrees, which is decision-trees related. That's why, it
    uses the node terminology.
  prefs: []
  type: TYPE_NORMAL
- en: 'After parameters are set, the boost classifier is trained using the `data`
    and `responses` matrices through the `train` method. Here follows this method
    signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This is the `trainData` training matrix with the features, and the `responses`
    matrix is the one with classification data. The `tflag` parameter will tell whether
    the features are put in rows or columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, predicting is a simple matter of creating a new row matrix with
    the input parameters for height, hair size, and beard presence, and passing it
    to the `Boost` `predict` function. Its output will classify the input as male
    or female:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Cascade classifier detection and training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One might be wondering how OpenCV could detect faces as this would be a very
    straightforward task for a couple-of-month old baby, and it looks quite complicated
    to tell a computer how to accomplish it. We will divide the problem in two parts—*object
    detection*, which is applying a classifier and retrieving the object position
    when the classifier says so, and *training* a new classifier to learn new objects
    that should be mostly rigid.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV Cascade Classifier initially implemented a face-detection technique known
    as the *Viola-Jones* detector, first developed by Paul Viola and Michael Jones,
    which uses the so-called Haar-like features, named after Alfréd Haar wavelets.
    These features are based on thresholds of sums and differences of rectangular
    regions of raw image values. Later, this classifier also enabled the use of **Local
    Binary Patterns** (**LBP**) features, which are integer values in contrast to
    Haar-like features; this results in faster training times, but similar quality.
  prefs: []
  type: TYPE_NORMAL
- en: Although using a cascade classifier in OpenCV is quite straightforward, it is
    important to know how it works to understand the usage boundaries. As a thumb
    rule, it should work fine on objects that are consistently textured and mostly
    rigid. The cascade classifier is presented with a set of size and histogram equalized
    images that are labeled as either containing or not containing an interest object.
    The classifier iterates through several smaller windows that cover the whole image,
    so it will tend to rarely find an object. For instance, group pictures will have
    faces in just a couple of coordinates, while the rest of the image should be labeled
    as not having a face. Since it should maximize rejection, the OpenCV cascade classifier
    uses a form of AdaBoost classifier organized as a rejection cascade, which means
    non-object patches should be dropped as early as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Features thresholds can be used as weak classifiers to build a strong classifier
    using AdaBoost, as we have learned in this chapter. After we calculate a feature,
    we can decide on this question: *Is this value above or below a given threshold?*
    If the answer is `true`, the object is a face, for instance, or else it is not.
    We generally use a single feature for this decision, but this number can be set
    in training. Using AdaBoost, we build the classifier as a weighted sum of the
    weak classifiers like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cascade classifier detection and training](img/3972OS_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![Cascade classifier detection and training](img/3972OS_05_13.jpg) is
    the function associated to each feature `i`, which returns `+1` in case the feature
    value is above some threshold and `-1` in case it is below. Boosting is used to
    correctly quantify each of the weights ![Cascade classifier detection and training](img/3972OS_05_14.jpg)
    related to the features. The Viola-Jones classifier builds each node of the tree
    as the signal of a weighted sum, like in the function `F`. Once this function
    is set, it yields a node for the Viola-Jones classifier, and all the surviving
    data from higher up in the cascade is then used to train the next node and so
    on. The final tree looks similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cascade classifier detection and training](img/3972OS_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenCV already comes with several previously-trained cascades that are ready
    to be used. Among them, we can find front and profile face detectors as well as
    eye, body, mouth, nose, lower-body, and upper-body detectors. In this section,
    we will cover how to use them. The complete source can be found in the project
    `cascade` in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how to load a trained cascade:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Most of the action happens in the class `CascadeClassifier`, from the `objdetect`
    package. This class wraps cascade loading and object detection. The constructor
    with strings already loads the cascade from the given path. In case you want to
    postpone the cascade name, you can use the empty constructor and the `load` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `runMainLoop` method, which is not shown here, will simply grab an image
    from the webcam and pass it to `detectAndDrawFace`, which will put the initialized
    classifier to work. The following is the `detectAndDrawFace` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Firstly, we instantiate the `faceDetections` object, which is a `MatOfRect`
    container (a special container for `Rect`). Then, we run the `detectMultiScale`
    method, passing the received image and the `MatOfRect` as parameters. This is
    where the cascade detector is run. The algorithm will scan the image using a sliding
    window, running the cascade classifier for each of the windows. It will also run
    this procedure with different scales of the image. By default, it will reduce
    the image scale by 1.1 for each attempt. In case at least three detections happen,
    also by default, in three different scales, the coordinate is considered a hit,
    and it will be a part of the `faceDetections` array, added to the width and height
    of the detected object.
  prefs: []
  type: TYPE_NORMAL
- en: The `for` loop simply iterates through the returned rectangles and draws them
    in green over the original image.
  prefs: []
  type: TYPE_NORMAL
- en: Training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although OpenCV is already packaged with several cascade classifiers, there
    might be a need for detecting some particular object, or class of object, of your
    choice. Creating a custom cascade classifier is not straightforward since it requires
    thousands of images from which all the variance should be removed. For instance,
    if a classifier for faces is being created, all the images should have their eyes
    aligned. In this section, we will describe the process of creating a cascade classifier
    using OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: In order to train a cascade, some tools have been provided in OpenCV. They can
    be found in the `opencv/build/x86/vc11/bin` directory. The `opencv_createsamples`
    and `opencv_traincascade` executables are used for preparing a training dataset
    of positive samples and for generating the cascade classifier, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: In order to give a good idea of the process, we have included files from UIUC
    Image Database for Car Detection, collected by Shivani Agarwal, Aatif Awan, and
    Dan Roth. These files are available in the `cardata` directory from `Chapter 5`.
    The following instructions rely on being at this folder to work.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Positive samples – pictures that contain the target image**'
  prefs: []
  type: TYPE_NORMAL
- en: Negative samples are the arbitrary images that must not contain the object that
    is intended to be detected.
  prefs: []
  type: TYPE_NORMAL
- en: To create your own cascade classifier, gather hundreds of pictures of the target,
    making sure that these pictures show enough variance to give a good idea of the
    class of the object being detected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, use the `opencv_createsamples` tool to prepare a training dataset of
    positive and test samples. This yields a binary file with the `.vec` extension,
    which contains positive samples generated from a given marked up dataset. No distortion
    is applied; they are only resized to target samples'' size and stored in the `vec-file`
    output. The reader should issue the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command will read file `cars.info`, which contains, in each line,
    the path to an image followed by a number *n*. This number is the quantity of
    object instances present in the image. Following this, there are *n* coordinates
    of the object bounding `rectangle (x, y, width, height)`. These are the examples
    of valid lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The parameters `-w` and `-h` give the width and height of the output samples
    that we want to be generated. This should be kept small enough so that in the
    image we are searching for object in the later object detection, the size of the
    object in the image will be greater than this size. The `-num` parameter tells
    the number of these samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to create a classifier for a given `.vec` file, use the `opencv_traincascade`
    tool. This application will read positive samples from the file given through
    the `-vec` parameter as well as some negative samples from a file given by the
    `-bg` parameter. The negative samples file simply points to an image in each of
    the lines, which are arbitrary ones and must not contain the object that is intended
    to be detected. In order to use this tool, issue the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The parameters `-numPos` and `-numNeg` are used to specify the number of positive
    and negative samples used in training for every classifier stage, while `-numStages`
    specifies the number of cascade stages to be trained. The last `-featureType`
    parameter sets which type of feature is to be used and can be selected from Haar-like
    features or LBP. As stated before, LBP features are integer values in contrast
    to Haar features, so detection and training will be much faster with LBP, but
    their quality can be the same, depending on the training. More parameters can
    be used to fine-tune the training, such as the false alarm rate, maximum tree
    depth, and minimal hit rate. The reader should refer to documentation for these
    settings. Now, regarding the training time, even on fast machines, it can take
    from a couple of hours to a few days. But, if you don''t want to wait for final
    results, and are impatient to check how the classifier would work, you can get
    the intermediate classifier XML file using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here `48` and `24` are the width and height for minimum possible detection and
    are similar to `–w` and `–h` in the `opencv_traincascade` command.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have issued the previous command, a file called `cascade.xml` is created
    in the folder passed as the `-data` parameter. Other files created in this folder
    can be safely deleted after training has been succeeded. Now, it can be loaded
    and used through the `CascadeClassifier` class, just as described in the preceding
    *Detection* section. Simply use this file instead of the `lbpcascade_frontalface.xml`
    file given in that example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows one correct detection of a toy car using the
    trained cascade as well as one wrong detection, which is a false positive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Training](img/3972OS_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the video, *OpenCV Tutorial: Training your own detector*, *Packt Publishing*,
    ([https://www.packtpub.com/application-development/opencv-computer-vision-application-programming-video](https://www.packtpub.com/application-development/opencv-computer-vision-application-programming-video))
    by Sebastian Montabone.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has provided the reader with several interesting concepts. We have
    covered a solid background on the boosting theory as well as working on a practical
    example. Then, we also covered OpenCV's Viola-Jones cascade classifier, and a
    hands-on approach was applied in order to use a classifier through the `CascadeClassifier`
    class. After that, we covered a complete, real-world example for creating a new
    car classifier, which can be adapted for any mostly rigid object of your preference.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will study and practice the field of background subtraction
    using pure image-processing methods through frame differencing and averaging background,
    and the interesting Kinect device for depth maps.
  prefs: []
  type: TYPE_NORMAL
