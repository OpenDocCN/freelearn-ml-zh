- en: Chapter 5. Object Detection Using Ada Boost and Haar Cascades
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。使用Ada Boost和Haar级联进行对象检测
- en: This chapter shows a very interesting feature of OpenCV—detecting faces in an
    image or a video stream. In the latter case, we call it **face tracking**. In
    order to do so, this chapter dives into machine-learning algorithms, specifically
    supervised learning with boosting. We will cover the **Viola-Jones classifier**
    and its theory as well as the details on how to use the face-trained classifiers
    that are bundled with OpenCV.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了OpenCV的一个非常有趣的功能——在图像或视频流中检测人脸。在后一种情况下，我们称之为**人脸跟踪**。为了做到这一点，本章深入探讨了机器学习算法，特别是带有提升的有监督学习。我们将涵盖**Viola-Jones分类器**及其理论，以及如何使用OpenCV附带的人脸训练分类器的详细说明。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The boosting theory
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升理论
- en: Viola-Jones classifier
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Viola-Jones分类器
- en: Detecting faces
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸检测
- en: Learning new objects
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习新对象
- en: By the end of this chapter, you will be able to understand the theory behind
    face classifiers through boosting, and the Viola-Jones classifier. You will also
    know how to use straightforward face classifiers. Besides, you will be able to
    create your own object classifier for different objects.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够通过提升和Viola-Jones分类器理解人脸分类器背后的理论。你还将了解如何使用简单的分类器。此外，你将能够为不同的对象创建自己的对象分类器。
- en: The boosting theory
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升理论
- en: The problem of detecting a face in an image can be posed in a simpler way. We
    could iterate the whole image through several smaller windows and create a classifier
    that will tell whether a window is a face or not. The windows that correctly identify
    the face will be the coordinates of face detection.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像中检测人脸的问题可以用更简单的方式提出。我们可以通过几个较小的窗口迭代整个图像，并创建一个分类器，该分类器将告诉我们一个窗口是否是人脸。正确识别人脸的窗口将是人脸检测的坐标。
- en: Now, what exactly is a classifier and how can it be built? In machine learning,
    the problem of classification has been deeply explored and it is posed as the
    identification of which of the set of categories a given observation belongs to,
    based on a previously trained set of known category memberships. This could be
    something like if a given image belongs to the banana, apple, or grape category,
    for instance, in a fruit classification application. In the case of face detection,
    there are two categories—face and non-face.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，究竟什么是分类器，以及它是如何构建的呢？在机器学习中，分类问题已经被深入探索，并被提出为基于先前训练的已知类别成员资格的集合，确定给定观察属于哪个类别。这可能是像在水果分类应用中，如果给定的图像属于香蕉、苹果或葡萄类别，例如。在人脸检测的情况下，有两个类别——人脸和非人脸。
- en: This section describes a meta-algorithm, which is basically a templated algorithm
    to create a strong classifier using a set of weak learners. These weak learners
    are classifiers based on some features that although not able to divide the whole
    set in the two categories, they do a good job for some of the sets. Let's say
    that a weak learner could be a classifier that looks for a mustache in order to
    tell whether a given face is of a man. Even if it might not find all men in the
    set, it will do a good job for the ones who have mustaches.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了一个元算法，它基本上是一个模板算法，用于使用一组弱学习器创建一个强大的分类器。这些弱学习器是基于某些特征的分类器，尽管它们不能将整个集合分为两类，但它们对某些集合做得很好。比如说，一个弱学习器可能是一个寻找胡子的分类器，以判断给定的人脸是否为男性。即使它可能不会在集合中找到所有男性，但它会对有胡子的那些人做得很好。
- en: AdaBoost
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AdaBoost
- en: '**AdaBoosting**, from Adaptive Boosting, is not actually an algorithm, but
    it''s a meta-algorithm that will help us with building a classifier. Its main
    mission is to build a great classifier out of weak classifiers, which are just
    better by chance. Its final form is a weighted combination of the given classifiers,
    as given in the following equation:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**AdaBoosting**，即自适应提升，实际上不是一个算法，而是一个元算法，它将帮助我们构建分类器。它的主要任务是构建一个由弱分类器组成的强大分类器，这些弱分类器只是偶然地更好。它的最终形式是给定分类器的加权组合，如下面的方程所示：'
- en: '![AdaBoost](img/3972OS_05_05.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![AdaBoost](img/3972OS_05_05.jpg)'
- en: The sign operator will return `+1` when the expression in parenthesis is positive,
    and `-1` otherwise. Note that it is a binary classifier that yields *yes* or *no*,
    or it could be *does belong* or *does not belong*, or simply `+1` or `-1`. So,
    ![AdaBoost](img/3972OS_05_06.jpg) is the weight assigned to the given classifier
    ![AdaBoost](img/3972OS_05_07.jpg) for a given input *x* in a set of *T* classifiers.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 符号运算符在括号内的表达式为正时将返回`+1`，否则返回`-1`。请注意，它是一个二元分类器，输出为*是*或*否*，或者可能是*属于*或*不属于*，或者简单地是`+1`或`-1`。因此，![AdaBoost](img/3972OS_05_06.jpg)是分配给给定分类器![AdaBoost](img/3972OS_05_07.jpg)在*T*个分类器集中对给定输入*x*的权重。
- en: 'For instance, in a group of people, one wants to know whether any given person
    *p* is a man or woman. Let''s say we have some weak classifiers, which are good
    guesses, such as:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一组人中，我们想知道任何给定的人*p*是男性还是女性。假设我们有一些弱分类器，它们是好的猜测，例如：
- en: '![AdaBoost](img/3972OS_05_08.jpg): If the height is greater than 5 feet and
    9 inches (~175 cm), then the person is a male or else female. Of course, there
    are several women taller than men, but on an average, men are taller.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![AdaBoost](img/3972OS_05_08.jpg)：如果身高超过5英尺9英寸（约175厘米），那么这个人就是男性或女性。当然，有些女性的身高超过男性，但平均来看，男性通常更高。'
- en: '![AdaBoost](img/3972OS_05_09.jpg): If a person has long hair, then the person
    is a female or else male. Again, there are several long haired men, but, on an
    average, women usually have longer hair.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![AdaBoost](img/3972OS_05_09.jpg)：如果一个人有长发，那么这个人就是女性或男性。同样，有几个长头发的男性，但平均来看，女性通常有更长的头发。'
- en: '![AdaBoost](img/3972OS_05_10.jpg): If a person has a beard, then the person
    is a male or else female. Here, we can misclassify shaved men.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![AdaBoost](img/3972OS_05_10.jpg)：如果一个人有胡须，那么这个人就是男性或女性。在这里，我们可能会错误地将刮胡子的男性分类。'
- en: 'Let''s say we have this random set of people:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组随机的人群：
- en: '| Name/Feature | Height (h1) | Hair (h2) | Beard (h3) | Gender (f(x)) |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| Name/Feature | Height (h1) | Hair (h2) | Beard (h3) | Gender (f(x)) |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Katherine | 1.69 | Long | Absent | Female |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| Katherine | 1.69 | Long | Absent | Female |'
- en: '| Dan | 1.76 | Short | Absent | Male |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| Dan | 1.76 | Short | Absent | Male |'
- en: '| Sam | 1.80 | Short | Absent | Male |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| Sam | 1.80 | Short | Absent | Male |'
- en: '| Laurent | 1.83 | Short | Present | Male |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| Laurent | 1.83 | Short | Present | Male |'
- en: '| Sara | 1.77 | Short | Absent | Female |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| Sara | 1.77 | Short | Absent | Female |'
- en: Classifier `h1` will correctly classify three people, while `h2` will get it
    right for four people, and `h3` will work for three people. We would then select
    `h2`, which was the best, for the one that minimizes the weighted error, and set
    its alpha. We would then increase weight for wrongly classified data (Sara) and
    decrease weight for all the others (Katherine, Dan, Sam, and Laurent). We would
    then look for the best classifier on the new distribution. Now that Sara is on
    the spot, either `h2` or `h3` would be selected, depending on the error, since
    `h1` gets Sara wrong with a higher weight. We would then continue for the `T`
    weak classifiers, in our case 3.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器`h1`将正确分类三个人，而`h2`将正确分类四个人，`h3`将正确分类三个人。然后我们会选择`h2`，这是最好的，因为它最小化了加权错误，并设置其alpha值。然后我们会增加错误分类数据（Sara）的权重，并减少其他所有数据（Katherine、Dan、Sam和Laurent）的权重。然后我们会在新的分布上寻找最好的分类器。现在Sara处于关键位置，要么选择`h2`或`h3`，这取决于错误，因为`h1`以更高的权重错误地将Sara分类。然后我们会继续对`T`个弱分类器进行操作，在我们的例子中是3个。
- en: 'The algorithm for AdaBoost goes like this:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: AdaBoost的算法如下：
- en: '![AdaBoost](img/3972OS_05_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![AdaBoost](img/3972OS_05_02.jpg)'
- en: Fortunately, OpenCV already implements boosting. The following example can be
    found in the `boost` project from `Chapter 5`, and it shows how to deal with the
    `Boost` class, with the preceding example. We first create a 5 x 3 matrix called
    `data`. This matrix stores our training dataset, and will be used by `Boost` to
    create a classifier. Then, we feed the matrix just like in the preceding table.
    The first column is the height. Hair and beard are given values one or zero. When
    the hair is short, we put `zero`, when it's long, we put `one`. In case the beard
    is present, its value is `one` or else `zero`. These values are set using the
    Mat's `put` function. Note that the fact of being a man or a woman does not go
    into the `data` matrix since it is actually the output we want for our classifier.
    This way, a 5 x 1 column matrix `responses` is created. It simply stores `zero`
    for female and `one` for male.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，OpenCV已经实现了boosting。以下示例可以在第5章的`boost`项目中找到，它展示了如何处理`Boost`类，以及前面的示例。我们首先创建一个名为`data`的5
    x 3矩阵。这个矩阵存储我们的训练数据集，将被`Boost`用于创建分类器。然后，我们像前面的表格一样输入矩阵。第一列是高度。头发和胡须被赋予值一或零。当头发短时，我们将其设置为`zero`，当头发长时，我们将其设置为`one`。如果胡须存在，其值为`one`否则为`zero`。这些值使用Mat的`put`函数设置。请注意，男性或女性的事实并没有进入`data`矩阵，因为这是我们想要的分类器的输出。这样，就创建了一个5
    x 1列矩阵`responses`。它简单地存储`zero`表示女性和`one`表示男性。
- en: Then, a `Boost` class is instantiated, and we set parameters for the training
    through the `CvBoostParams` its setters. We have set the boost type to be **Discrete
    Adaboost** using the `setBoostType` method, passing `Boost.DISCRETE` as a parameter.
    Other variants of boosting are known as **Real AdaBoost**, **LogitBoost**, and
    **Gentle AdaBoost**. The setWeakCount method sets the number of weak classifiers
    used. In our case, it was `3`. The next setting tells that if the number of samples
    in a node is less than this parameter, then the node will not be split. Actually,
    the default value is `10`, and it won't work with such a small dataset, so it
    is set to `4` so that it will work with this dataset. It is important to note
    that Boost derives from DTrees, which is decision-trees related. That's why, it
    uses the node terminology.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，实例化一个`Boost`类，并通过`CvBoostParams`的setter设置训练参数。我们使用`setBoostType`方法将boost类型设置为**离散Adaboost**，传递`Boost.DISCRETE`作为参数。其他boosting的变体被称为**实Adaboost**、**LogitBoost**和**温和Adaboost**。`setWeakCount`方法设置使用的弱分类器的数量。在我们的案例中，它是`3`。下一个设置告诉如果节点中的样本数量小于此参数，则节点将不会分裂。实际上，默认值是`10`，它不会与如此小的数据集一起工作，因此将其设置为`4`以便它能够与这个数据集一起工作。重要的是要注意，Boost是从DTrees派生的，它与决策树相关。这就是为什么它使用节点术语。
- en: 'After parameters are set, the boost classifier is trained using the `data`
    and `responses` matrices through the `train` method. Here follows this method
    signature:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置参数之后，通过`train`方法使用`data`和`responses`矩阵来训练boost分类器。以下是此方法签名：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is the `trainData` training matrix with the features, and the `responses`
    matrix is the one with classification data. The `tflag` parameter will tell whether
    the features are put in rows or columns.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是具有特征的`trainData`训练矩阵，而`responses`矩阵是包含分类数据的矩阵。`tflag`参数将告诉特征是放在行还是列中。
- en: 'After that, predicting is a simple matter of creating a new row matrix with
    the input parameters for height, hair size, and beard presence, and passing it
    to the `Boost` `predict` function. Its output will classify the input as male
    or female:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，预测是一个简单的问题，就是创建一个新的行矩阵，包含输入参数高度、头发大小和胡须存在，并将其传递给`Boost`的`predict`函数。它的输出将把输入分类为男性或女性：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Cascade classifier detection and training
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 然后是级联分类器的检测和训练
- en: One might be wondering how OpenCV could detect faces as this would be a very
    straightforward task for a couple-of-month old baby, and it looks quite complicated
    to tell a computer how to accomplish it. We will divide the problem in two parts—*object
    detection*, which is applying a classifier and retrieving the object position
    when the classifier says so, and *training* a new classifier to learn new objects
    that should be mostly rigid.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人可能会想知道OpenCV是如何检测人脸的，因为这对于几个月大的婴儿来说是一个非常简单的任务，而对于告诉计算机如何完成这项任务来说则看起来相当复杂。我们将问题分为两部分——*目标检测*，即在分类器说的时候应用分类器并检索对象位置，以及*训练*一个新的分类器来学习新的、应该主要是刚性的对象。
- en: OpenCV Cascade Classifier initially implemented a face-detection technique known
    as the *Viola-Jones* detector, first developed by Paul Viola and Michael Jones,
    which uses the so-called Haar-like features, named after Alfréd Haar wavelets.
    These features are based on thresholds of sums and differences of rectangular
    regions of raw image values. Later, this classifier also enabled the use of **Local
    Binary Patterns** (**LBP**) features, which are integer values in contrast to
    Haar-like features; this results in faster training times, but similar quality.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV级联分类器最初实现了一种称为*Viola-Jones*检测器的面部检测技术，最初由Paul Viola和Michael Jones开发，它使用所谓的Haar-like特征，以Alfréd
    Haar小波命名。这些特征基于原始图像值矩形区域的和与差的阈值。后来，这个分类器也允许使用**局部二值模式**（**LBP**）特征，与Haar-like特征相比是整数值；这导致训练时间更快，但质量相似。
- en: Although using a cascade classifier in OpenCV is quite straightforward, it is
    important to know how it works to understand the usage boundaries. As a thumb
    rule, it should work fine on objects that are consistently textured and mostly
    rigid. The cascade classifier is presented with a set of size and histogram equalized
    images that are labeled as either containing or not containing an interest object.
    The classifier iterates through several smaller windows that cover the whole image,
    so it will tend to rarely find an object. For instance, group pictures will have
    faces in just a couple of coordinates, while the rest of the image should be labeled
    as not having a face. Since it should maximize rejection, the OpenCV cascade classifier
    uses a form of AdaBoost classifier organized as a rejection cascade, which means
    non-object patches should be dropped as early as possible.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在OpenCV中使用级联分类器相当直接，但了解它是如何工作的对于理解使用边界很重要。作为一个经验法则，它应该能够在纹理一致且大部分刚性的物体上工作得很好。级联分类器被提供了一组大小和直方图均衡化的图像，这些图像被标记为包含或不包含感兴趣的对象。分类器通过几个较小的窗口迭代，这些窗口覆盖整个图像，因此它很少会找到一个对象。例如，团体照片中只有几个坐标有面部，而图像的其余部分应该被标记为没有面部。由于它应该最大化拒绝，OpenCV级联分类器使用一种AdaBoost分类器形式的拒绝级联，这意味着非对象补丁应该尽可能早地被丢弃。
- en: 'Features thresholds can be used as weak classifiers to build a strong classifier
    using AdaBoost, as we have learned in this chapter. After we calculate a feature,
    we can decide on this question: *Is this value above or below a given threshold?*
    If the answer is `true`, the object is a face, for instance, or else it is not.
    We generally use a single feature for this decision, but this number can be set
    in training. Using AdaBoost, we build the classifier as a weighted sum of the
    weak classifiers like this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 特征阈值可以用作弱分类器，通过AdaBoost构建强分类器，正如我们在本章所学。在计算一个特征之后，我们可以决定这个问题：*这个值是否高于或低于给定的阈值？*
    如果答案是`true`，那么对象是一个面部，例如，否则它就不是。我们通常使用单个特征来做这个决定，但这个数字可以在训练中设置。使用AdaBoost，我们构建分类器作为弱分类器的加权求和，如下所示：
- en: '![Cascade classifier detection and training](img/3972OS_05_03.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![级联分类器检测和训练](img/3972OS_05_03.jpg)'
- en: 'Here, ![Cascade classifier detection and training](img/3972OS_05_13.jpg) is
    the function associated to each feature `i`, which returns `+1` in case the feature
    value is above some threshold and `-1` in case it is below. Boosting is used to
    correctly quantify each of the weights ![Cascade classifier detection and training](img/3972OS_05_14.jpg)
    related to the features. The Viola-Jones classifier builds each node of the tree
    as the signal of a weighted sum, like in the function `F`. Once this function
    is set, it yields a node for the Viola-Jones classifier, and all the surviving
    data from higher up in the cascade is then used to train the next node and so
    on. The final tree looks similar to this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![级联分类器检测和训练](img/3972OS_05_13.jpg)是与每个特征`i`相关联的函数，如果特征值高于某个阈值，则返回`+1`，如果低于阈值，则返回`-1`。提升用于正确量化与特征相关的每个权重![级联分类器检测和训练](img/3972OS_05_14.jpg)。Viola-Jones分类器将树的每个节点构建为加权求和的信号，就像在函数`F`中一样。一旦这个函数被设置，它就会为Viola-Jones分类器提供一个节点，然后使用级联中更高层次的所有存活数据来训练下一个节点，依此类推。最终的树看起来类似于这个：
- en: '![Cascade classifier detection and training](img/3972OS_05_04.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![级联分类器检测和训练](img/3972OS_05_04.jpg)'
- en: Detection
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测
- en: OpenCV already comes with several previously-trained cascades that are ready
    to be used. Among them, we can find front and profile face detectors as well as
    eye, body, mouth, nose, lower-body, and upper-body detectors. In this section,
    we will cover how to use them. The complete source can be found in the project
    `cascade` in this chapter.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV已经包含了一些预训练的级联分类器，可以直接使用。其中，我们可以找到正面和侧面面部检测器，以及眼睛、身体、嘴巴、鼻子、下半身和上半身检测器。在本节中，我们将介绍如何使用它们。完整的源代码可以在本章的`cascade`项目中找到。
- en: 'The following code shows how to load a trained cascade:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何加载一个训练好的级联：
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Most of the action happens in the class `CascadeClassifier`, from the `objdetect`
    package. This class wraps cascade loading and object detection. The constructor
    with strings already loads the cascade from the given path. In case you want to
    postpone the cascade name, you can use the empty constructor and the `load` method.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分操作发生在`objdetect`包中的`CascadeClassifier`类中。这个类封装了级联加载和对象检测。具有字符串的构造函数已经从给定路径加载了级联。如果您想推迟级联名称，可以使用空构造函数和`load`方法。
- en: 'The `runMainLoop` method, which is not shown here, will simply grab an image
    from the webcam and pass it to `detectAndDrawFace`, which will put the initialized
    classifier to work. The following is the `detectAndDrawFace` method:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`runMainLoop`方法，此处未展示，它将简单地从网络摄像头中抓取一张图片并将其传递给`detectAndDrawFace`方法，该方法将初始化的分类器投入使用。以下为`detectAndDrawFace`方法：'
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Firstly, we instantiate the `faceDetections` object, which is a `MatOfRect`
    container (a special container for `Rect`). Then, we run the `detectMultiScale`
    method, passing the received image and the `MatOfRect` as parameters. This is
    where the cascade detector is run. The algorithm will scan the image using a sliding
    window, running the cascade classifier for each of the windows. It will also run
    this procedure with different scales of the image. By default, it will reduce
    the image scale by 1.1 for each attempt. In case at least three detections happen,
    also by default, in three different scales, the coordinate is considered a hit,
    and it will be a part of the `faceDetections` array, added to the width and height
    of the detected object.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们实例化`faceDetections`对象，它是一个`MatOfRect`容器（一个用于`Rect`的特殊容器）。然后，我们运行`detectMultiScale`方法，将接收到的图像和`MatOfRect`作为参数传递。这就是运行级联检测器的地方。算法将使用滑动窗口扫描图像，为每个窗口运行级联分类器。它还会以不同的图像比例运行此过程。默认情况下，它将每次尝试将图像比例减少1.1。如果至少有三个检测发生，默认情况下，在三个不同的比例下，坐标被认为是命中，它将成为`faceDetections`数组的一部分，并添加到检测对象的宽度和高度中。
- en: The `for` loop simply iterates through the returned rectangles and draws them
    in green over the original image.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`for`循环简单地遍历返回的矩形，并在原始图像上用绿色绘制它们。'
- en: Training
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练
- en: Although OpenCV is already packaged with several cascade classifiers, there
    might be a need for detecting some particular object, or class of object, of your
    choice. Creating a custom cascade classifier is not straightforward since it requires
    thousands of images from which all the variance should be removed. For instance,
    if a classifier for faces is being created, all the images should have their eyes
    aligned. In this section, we will describe the process of creating a cascade classifier
    using OpenCV.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然OpenCV已经打包了几个级联分类器，但可能需要检测一些特定对象或对象类别。创建自定义级联分类器并不简单，因为它需要成千上万张图像，其中应该去除所有差异。例如，如果正在创建面部分类器，所有图像的眼睛都应该对齐。在本节中，我们将描述使用OpenCV创建级联分类器的过程。
- en: In order to train a cascade, some tools have been provided in OpenCV. They can
    be found in the `opencv/build/x86/vc11/bin` directory. The `opencv_createsamples`
    and `opencv_traincascade` executables are used for preparing a training dataset
    of positive samples and for generating the cascade classifier, respectively.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练级联，OpenCV提供了一些工具。它们可以在`opencv/build/x86/vc11/bin`目录中找到。`opencv_createsamples`和`opencv_traincascade`可执行文件用于准备正样本的训练数据集以及生成级联分类器。
- en: In order to give a good idea of the process, we have included files from UIUC
    Image Database for Car Detection, collected by Shivani Agarwal, Aatif Awan, and
    Dan Roth. These files are available in the `cardata` directory from `Chapter 5`.
    The following instructions rely on being at this folder to work.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地展示这个过程，我们包括了来自UIUC图像数据库中用于车辆检测的文件，这些文件由Shivani Agarwal、Aatif Awan和Dan Roth收集。这些文件可以在“第5章”的`cardata`目录中找到。以下说明依赖于位于此文件夹中才能工作。
- en: Note
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Positive samples – pictures that contain the target image**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**正样本 – 包含目标图像的图片**'
- en: Negative samples are the arbitrary images that must not contain the object that
    is intended to be detected.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 负样本是任意图像，不得包含旨在检测的对象。
- en: To create your own cascade classifier, gather hundreds of pictures of the target,
    making sure that these pictures show enough variance to give a good idea of the
    class of the object being detected.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建自己的级联分类器，收集目标对象的数百张图片，确保这些图片展示了足够的变化，以便给出被检测对象类别的良好概念。
- en: 'Then, use the `opencv_createsamples` tool to prepare a training dataset of
    positive and test samples. This yields a binary file with the `.vec` extension,
    which contains positive samples generated from a given marked up dataset. No distortion
    is applied; they are only resized to target samples'' size and stored in the `vec-file`
    output. The reader should issue the following command:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用 `opencv_createsamples` 工具准备正样本和测试样本的训练数据集。这将生成一个具有 `.vec` 扩展名的二进制文件，其中包含从给定标记数据集中生成的正样本。没有应用扭曲；它们仅被调整到目标样本的大小并存储在
    `vec-file` 输出中。读者应发出以下命令：
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding command will read file `cars.info`, which contains, in each line,
    the path to an image followed by a number *n*. This number is the quantity of
    object instances present in the image. Following this, there are *n* coordinates
    of the object bounding `rectangle (x, y, width, height)`. These are the examples
    of valid lines:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令将读取 `cars.info` 文件，该文件中的每一行包含一个图像的路径，后面跟着一个数字 *n*。这个数字是图像中存在的对象实例的数量。随后是
    *n* 个对象的边界 `矩形 (x, y, width, height)` 坐标。以下是有效行的示例：
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The parameters `-w` and `-h` give the width and height of the output samples
    that we want to be generated. This should be kept small enough so that in the
    image we are searching for object in the later object detection, the size of the
    object in the image will be greater than this size. The `-num` parameter tells
    the number of these samples.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 参数 `-w` 和 `-h` 指定要生成的输出样本的宽度和高度。这应该足够小，以便在后续目标检测中搜索图像中的对象时，图像中对象的大小将大于这个大小。`-num`
    参数告诉这些样本的数量。
- en: 'In order to create a classifier for a given `.vec` file, use the `opencv_traincascade`
    tool. This application will read positive samples from the file given through
    the `-vec` parameter as well as some negative samples from a file given by the
    `-bg` parameter. The negative samples file simply points to an image in each of
    the lines, which are arbitrary ones and must not contain the object that is intended
    to be detected. In order to use this tool, issue the following command:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为给定的 `.vec` 文件创建分类器，使用 `opencv_traincascade` 工具。此应用程序将读取通过 `-vec` 参数提供的文件中的正样本以及通过
    `-bg` 参数提供的文件中的某些负样本。负样本文件简单地指向每行中的一个图像，这些图像是任意的，并且不得包含旨在检测的对象。为了使用此工具，发出以下命令：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The parameters `-numPos` and `-numNeg` are used to specify the number of positive
    and negative samples used in training for every classifier stage, while `-numStages`
    specifies the number of cascade stages to be trained. The last `-featureType`
    parameter sets which type of feature is to be used and can be selected from Haar-like
    features or LBP. As stated before, LBP features are integer values in contrast
    to Haar features, so detection and training will be much faster with LBP, but
    their quality can be the same, depending on the training. More parameters can
    be used to fine-tune the training, such as the false alarm rate, maximum tree
    depth, and minimal hit rate. The reader should refer to documentation for these
    settings. Now, regarding the training time, even on fast machines, it can take
    from a couple of hours to a few days. But, if you don''t want to wait for final
    results, and are impatient to check how the classifier would work, you can get
    the intermediate classifier XML file using the following command:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 参数 `-numPos` 和 `-numNeg` 用于指定每个分类器阶段训练中使用的正样本和负样本的数量，而 `-numStages` 指定要训练的级联阶段数量。最后的
    `-featureType` 参数设置要使用哪种类型的特征，可以选择 Haar 类特征或 LBP。正如之前所述，LBP 特征是整数值，与 Haar 特征不同，因此使用
    LBP 将会使得检测和训练更快，但它们的品质可以相同，这取决于训练。还可以使用更多参数来微调训练，例如误报率、最大树深度和最小命中率。读者应参考文档了解这些设置。现在，关于训练时间，即使在快速机器上，也可能需要从几小时到几天。但是，如果您不想等待最终结果，并且急于检查分类器的工作情况，可以使用以下命令获取中间分类器
    XML 文件：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here `48` and `24` are the width and height for minimum possible detection and
    are similar to `–w` and `–h` in the `opencv_traincascade` command.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`48`和`24`分别是可能检测到的最小宽度和高度，类似于`opencv_traincascade`命令中的`–w`和`–h`。
- en: Once you have issued the previous command, a file called `cascade.xml` is created
    in the folder passed as the `-data` parameter. Other files created in this folder
    can be safely deleted after training has been succeeded. Now, it can be loaded
    and used through the `CascadeClassifier` class, just as described in the preceding
    *Detection* section. Simply use this file instead of the `lbpcascade_frontalface.xml`
    file given in that example.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦发出前面的命令，就会在作为`-data`参数传递的文件夹中创建一个名为`cascade.xml`的文件。在训练成功后，可以安全地删除此文件夹中创建的其他文件。现在，可以通过`CascadeClassifier`类加载并使用它，正如前面*检测*部分所描述的那样。只需使用此文件代替示例中给出的`lbpcascade_frontalface.xml`文件即可。
- en: 'The following screenshot shows one correct detection of a toy car using the
    trained cascade as well as one wrong detection, which is a false positive:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示了使用训练好的级联分类器正确检测到的玩具汽车以及一个错误检测，这是一个假阳性：
- en: '![Training](img/3972OS_05_01.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![训练](img/3972OS_05_01.jpg)'
- en: References
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Refer to the video, *OpenCV Tutorial: Training your own detector*, *Packt Publishing*,
    ([https://www.packtpub.com/application-development/opencv-computer-vision-application-programming-video](https://www.packtpub.com/application-development/opencv-computer-vision-application-programming-video))
    by Sebastian Montabone.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考视频，*OpenCV教程：训练自己的检测器*，*Packt Publishing*，([https://www.packtpub.com/application-development/opencv-computer-vision-application-programming-video](https://www.packtpub.com/application-development/opencv-computer-vision-application-programming-video))，由Sebastian
    Montabone编写。
- en: Summary
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter has provided the reader with several interesting concepts. We have
    covered a solid background on the boosting theory as well as working on a practical
    example. Then, we also covered OpenCV's Viola-Jones cascade classifier, and a
    hands-on approach was applied in order to use a classifier through the `CascadeClassifier`
    class. After that, we covered a complete, real-world example for creating a new
    car classifier, which can be adapted for any mostly rigid object of your preference.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向读者提供了几个有趣的概念。我们不仅介绍了提升理论的坚实基础，还通过一个实际例子进行了实践。接着，我们还涵盖了OpenCV的Viola-Jones级联分类器，并应用了实际操作方法，通过`CascadeClassifier`类使用分类器。之后，我们提供了一个完整的、真实世界的例子，用于创建一个新的汽车分类器，它可以适应你偏好的任何主要刚性的物体。
- en: In the next chapter, we will study and practice the field of background subtraction
    using pure image-processing methods through frame differencing and averaging background,
    and the interesting Kinect device for depth maps.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过帧差分和背景平均等纯图像处理方法研究并实践背景减法领域，以及有趣的Kinect设备用于深度图。
