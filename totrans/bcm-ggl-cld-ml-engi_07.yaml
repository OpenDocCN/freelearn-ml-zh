- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploring Google Cloud Vertex AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we discussed Google Cloud BQML, which is used to develop
    ML models from structured data, and Google’s TensorFlow and Keras frameworks,
    which provide a high-level API interface for ML model development. In this chapter,
    we will discuss Cloud Vertex AI, which is Google’s integrated cloud service suite
    for ML model development. We will examine the Vertex AI suite and all its products
    and services.
  prefs: []
  type: TYPE_NORMAL
- en: '**Google Vertex AI** is an integrated set of Google Cloud products, features,
    and a management interface that simplifies the management of ML services. It offers
    users a complete platform to build, train, and deploy ML applications in Google
    Cloud, from end to end. Vertex AI provides a single stop for data scientists to
    build machine learning applications.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following Vertex AI products and services:'
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI data labeling and datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI Feature Store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI Workbench and notebooks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI models and predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI Pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI metadata
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI experiments and TensorBoard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start with data labeling and datasets in the Vertex AI suite.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI data labeling and datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Datasets play such a significant role in the machine learning process that the
    quality of datasets has a huge impact on the ML model performance. As we discussed
    in [*Chapter 4*](B18333_04.xhtml#_idTextAnchor094), *Developing and Deploying
    ML Models*, data preparation is the first and most important step in any machine
    learning process.
  prefs: []
  type: TYPE_NORMAL
- en: '**Vertex AI Data labeling** is a Google Cloud service that lets end users work
    with human workers to review and label datasets uploaded by users. After the datasets
    are labeled, they can be used to train machine learning models. The human workers
    are employed by Google, and the users will need to provide the dataset, the labels,
    and instructions to the human workers for labeling.'
  prefs: []
  type: TYPE_NORMAL
- en: 'End users can also upload labeled datasets directly. **Vertex AI datasets**
    are part of a Google Cloud service that provides users with the ability to upload
    data of varying types for the purpose of building, training, and validating machine
    learning models. Currently, Vertex AI supports four types of datasets (image,
    tabular, text, and videos):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image datasets**: You can create image datasets within Vertex AI, and use
    them to train models for image classification, image segmentation, and object
    detection. With Vertex AI, you can either upload the image datasets directly or
    use the images stored in Google Cloud Storage buckets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tabular datasets**: You can directly upload a CSV file from your local computer,
    use one from Google Cloud Storage, or select a table from the BigQuery service.
    Once the tabular dataset is generated, the data is available in Vertex AI datasets
    for model training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Video datasets**: Vertex AI allows you to directly upload videos from your
    local computers or use videos from Google Cloud buckets. Once you have the video
    datasets, you can use them for video classifications or action recognitions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text datasets**: In Vertex AI, you create a text dataset, and import the
    CSVs from a Google Cloud Storage bucket into the dataset. Then, you can use the
    dataset for text document classification, custom text entity identification, sentiment
    analysis, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI datasets allow you to create and manage datasets directly within the
    Vertex AI suite, and the datasets uploaded through Vertex AI are automatically
    stored in the Cloud Storage bucket, which is created and managed by Vertex AI.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Feature Store
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In ML/DL model training, features are the attributes to build a model and make
    future inferences. Google Vertex AI Feature Store is a fully managed cloud service
    that provides a centralized repository to store, organize, and serve ML features.
    You can create and manage a **Vertex AI Feature Store** that contains all the
    model features and their values. With a central feature store, users in a Google
    Cloud organization can share and reuse these features for model training or serving
    tasks in different ML/DL projects to speed up machine learning application development
    and model deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Feature Store enables users to manage features in ML models. A feature
    store can serve real-time, online predictions, or batch predictions for the new
    data. For example, after loading information about movie-watching habits, the
    Feature Store can serve to predict what movie a new user may watch based on their
    characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: In traditional ML frameworks, you may have computed feature values and saved
    them in various locations including Cloud Storage buckets or BQ tables, and you
    may have separate solutions for storing and managing the feature values. With
    Vertex AI Feature Store, you are provided with a unified solution, consistent
    across the organization, to store and serve features that can be shared among
    different teams for different projects or use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Workbench and notebooks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Vertex AI Workbench** service provides a single development platform for
    the entire data science workflow; you can use it to launch Cloud VM instances/notebooks
    to query and explore data and to develop and train a model for deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we explained earlier in the *Preparing the platform* section, Jupyter Notebook
    is a widely used platform for ML model development. Vertex AI Workbench provides
    two Jupyter-Notebook-based options for your data scientists, managed notebooks
    and user-managed notebooks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Managed notebooks** are Google-managed, Jupyter-based, scalable, enterprise-ready
    compute instances that help you set up and work in an end-to-end ML production
    environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-managed notebooks** are heavily customizable instances and are thus
    fitting for users who need a lot of control over their environment. With a user-managed
    notebook instance, you have a suite of deep learning packages pre-installed, including
    TensorFlow and PyTorch frameworks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI Workbench provides flexible notebook options. It offers a great ML
    model training platform for data scientists to train and develop models.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In an ML model development process, training jobs are discrete tasks that generate
    ML models. In Vertex AI, you can choose different training methods based on the
    source of model and data; **Vertex AI AutoML**, which is managed by Google, uses
    Google’s model and your data to train, and the **Vertex AI platform**, with user-defined
    code or custom containers, utilizes your model and your data to perform model
    training.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI AutoML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Vertex AI AutoML** is a managed Google Cloud service that enables users to
    build models across a wide variety of use cases without writing any code. The
    objective is to enable ML model development for various levels of AI expertise.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The types of models supported by Vertex AutoML are shown in *Table 7.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 7.1 – Vertex AI AutoML models ](img/Figure_7.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 7.1 – Vertex AI AutoML models
  prefs: []
  type: TYPE_NORMAL
- en: 'When creating an AutoML training pipeline job, you have the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dataset**: Managed by Vertex AI and uploaded by a user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model type**: Selected from the supported models (as described above)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data split** (Optional): Split dataset between training, validation, and
    testing data using custom parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Encryption** (Optional): Option to select a **customer-managed encryption
    key** (**CMEK**) for in-process encryption'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI AutoML helps you to build a code-free model based on your training
    data. With Vertex AI AutoML, you customize Google’s models using your own data.
  prefs: []
  type: TYPE_NORMAL
- en: The Vertex AI platform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **Vertex AI platform**, with custom containers, enables you to build your
    own models from scratch, with your own data. **Custom containers** are user-created
    Docker images that are selected while creating a pipeline. A typical workflow
    for a custom container environment is shown in *Figure 7.2*, and it has the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code development**: You can build an application in the programming language
    of your choice, locally or within a notebook, and dependencies can be sourced
    from any internet location by default.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Build**: You can build code into a packaged artifact or write a configuration
    to automatically package code and various dependencies into a container runtime
    artifact.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Artifact storage**: You can push newly built customized artifacts into Cloud
    Storage or a container registry.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Start training pipeline**: You can select a *custom container* when creating
    a training pipeline to build an ML model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Vertex AI platform custom container ](img/Figure_7.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Vertex AI platform custom container
  prefs: []
  type: TYPE_NORMAL
- en: After the models are trained in Vertex AI, you can use either AutoML or custom
    containers, accessed/managed in Vertex AI Models, and be deployed in Vertex AI
    Endpoints for individual predictions or batch predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Models and Predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Vertex AI Models** provides a platform for managing ML models. With Vertex
    AI Models, you can develop and manage ML models in many ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Create model**: Users can choose to create a new model and be redirected
    to the **training Pipelines** screen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Upload model**: Users can upload a model that’s been trained elsewhere for
    use within their Vertex AI project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deploy model**: Users can deploy a selected model to an endpoint, making
    it available through a REST API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Export model**: Users can export a trained model to a GCS bucket, where it
    can be stored or used in another project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the models are trained, they can be exported or deployed publicly or privately
    to predict production cases. When you deploy a model to an endpoint resource for
    online predictions, or when you request batch predictions, you can always customize
    the VM types that the prediction service uses, and you can also configure prediction
    nodes to use GPUs. We will discuss model deployment in the next sections.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI endpoint prediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Vertex AI Endpoints** allow users to create REST API endpoints based on Vertex
    AI models, to predict results for new data. With Vertex AI, a model can be deployed
    into either public endpoints or private endpoints:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Public endpoints**: The model is deployed to an internet-routable, Google-managed
    endpoint hosted in a selected region.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Private endpoints**: The model is deployed to a Google-managed endpoint hosted
    in a selected region on a private IP address in a selected VPC.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vertex AI Endpoints are used to deploy trained models for online prediction.
    When creating a new endpoint, users can configure the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Endpoint Name**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GCP Region**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Private or Public Access**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Encryption (Optional)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model(s)**: One or more models to be served by the new endpoint.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating with Vertex AI training and Vertex AI Models, Vertex AI Endpoints
    allow users to predict individual results interactively.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI batch prediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Different from Vertex AI Endpoints, **Vertex AI batch prediction** jobs are
    discrete tasks that run batch sets of input data against a prediction model. As
    shown in *Figure 7.3*, it can input files in Google Cloud Storage, and outputs
    the results to a specified GCS location.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Vertex AI batch prediction ](img/Figure_7.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Vertex AI batch prediction
  prefs: []
  type: TYPE_NORMAL
- en: 'When creating a batch prediction job, you have the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Region**: Where the model is stored'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model**: Points to the ML model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Input data**: Cloud Storage bucket where input data is stored'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output directory**: Cloud Storage bucket to store predictions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute-related information including machine type and number of nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As we can see from the preceding services, Vertex AI provides an ML development
    and management suite for you to create and manage datasets, create and manage
    notebooks to conduct model training, and develop and manage models for the endpoint
    of batch prediction. With Vertex AI, you can perform all the tasks in an ML workflow,
    from end to end. And that leads us to the Vertex AI Pipelines discussion: automating
    the ML workflow.'
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Vertex AI Pipelines** allow you to automatically orchestrate your ML workflow
    in a serverless manner using **TensorFlow Extended** (**TFX**) or **Kubeflow**.
    Each Vertex AI pipeline job is generated from a configuration file that outlines
    a list of steps. A typical Vertex AI pipeline imports data into a dataset, trains
    a model using a **training pipeline**, and deploys the model to a new endpoint
    for prediction. Pipeline jobs are run using compute resources, with the following
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: You can write custom configurations for pipeline jobs using the **Kubeflow DSL**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can create, run, and schedule pipeline jobs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can specify **Service Account** or use **Compute Default Service Account**
    if not specified.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Vertex AI Pipelines orchestrates your ML workflow, based on your descriptions
    of the workflow as a pipeline. ML pipelines are portable and scalable ML workflows
    that are based on containers. ML pipelines are composed of a set of input parameters
    and a list of steps – each step is an instance of the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Metadata
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Vertex AI Metadata** is a repository of metadata that is generated across
    a variety of Vertex AI components. When models are developed in the ML workflow
    pipelines, metadata is generated and stored, and you can consolidate this metadata
    into a single metadata store, which allows users to query and answer questions
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Which version of a trained model has achieved a certain quality threshold?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which pipeline runs/uses a certain dataset?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Within a Vertex AI pipeline, users can also configure data objects that are
    written to the metadata store. And from there, users can create *Context* objects
    that organize these data objects into logical groupings and obtain more insights.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Vertex AI metadata API, users can build schemas, organize data objects,
    or query data that’s been stored within Vertex AI metadata.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI experiments and TensorBoard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**TensorBoard** is a Google open source project for machine learning experiment
    visualization. Vertex AI experiments are an implementation of TensorBoard. With
    Vertex AI experiments, users can create TensorBoard instances and upload TensorBoard
    logs generated from Vertex AI Models to run experiments – visual representations
    of a variety of metrics, such as loss function and accuracy over different model
    parameters at different running times. *Figure 7.4* shows a sample workflow for
    Vertex AI experiments and TensorBoard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Vertex AI experiments and TensorBoard ](img/Figure_7.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Vertex AI experiments and TensorBoard
  prefs: []
  type: TYPE_NORMAL
- en: 'These TensorBoard visualizations are available via a web application that can
    be shared with other users by setting up GCP IAM permissions. With Vertex AI experiments,
    you can configure the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Manage TensorBoard Instances**: Users can create, update, or delete TensorBoard
    instances; instances are used for experiments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Create Experiments**: By uploading pipeline log data, users can generate
    experiments and visualizations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**View TensorBoard Web Application**: Users can view TensorBoard via a web
    application generated for each TensorBoard instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Export Data**: Users can export pipeline metadata and TensorBoard data points
    using the API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI experiments provide users with a platform to experiment and tune model
    parameters. With Vertex AI experiments, we can interact on the TensorBoard web
    and check the results. It is an important and integral part of the Google Vertex
    AI suite.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have introduced the Google Vertex AI suite, including its
    services, platforms, and tools for ML model development and deployment. With Vertex
    AI, you can manage the datasets, models, and pipelines easily and flexibly. Without
    a doubt, mastering Vertex AI needs hands-on practice for each service in the suite,
    and we have provided sample hands-on practice steps in [*Appendix 4*](B18333_14.xhtml#_idTextAnchor218),
    *Practicing with Google Vertex AI*. Please follow these practices and understand
    the steps in the appendix. In the next chapter, we will discuss another Google
    Cloud ML service: Google Cloud ML APIs.'
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For further insights on the learning of the chapter, you can refer to the following
    links:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Vertex AI documentation*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vertex-ai/docs](https://cloud.google.com/vertex-ai/docs)'
  prefs: []
  type: TYPE_NORMAL
- en: '*All dataset documentation | Vertex AI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vertex-ai/docs/datasets/datasets](https://cloud.google.com/vertex-ai/docs/datasets/datasets)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Introduction to Vertex AI Feature Store*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vertex-ai/docs/featurestore/overview](https://cloud.google.com/vertex-ai/docs/featurestore/overview)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Introduction to Vertex AI Workbench*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vertex-ai/docs/workbench/introduction](https://cloud.google.com/vertex-ai/docs/workbench/introduction)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Choose a notebook solution | Vertex AI Workbench*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vertex-ai/docs/workbench/notebook-solution](https://cloud.google.com/vertex-ai/docs/workbench/notebook-solution)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Introduction to Vertex AI Model Monitoring*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vertex-ai/docs/model-monitoring/overview](https://cloud.google.com/vertex-ai/docs/model-monitoring/overview)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Introduction to Vertex AI Pipelines*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vertex-ai/docs/pipelines/introduction](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Vertex Explainable AI | Vertex AI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vertex-ai/docs/explainable-ai](https://cloud.google.com/vertex-ai/docs/explainable-ai)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deploy a model using the Cloud console | Vertex AI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-console](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-console)'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Appendix 4*](B18333_14.xhtml#_idTextAnchor218), *Practicing with Google Vertex
    AI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
