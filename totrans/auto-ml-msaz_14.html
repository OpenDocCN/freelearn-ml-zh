<html><head></head><body>
		<div id="_idContainer124">
			<h1 id="_idParaDest-168"><em class="italic"><a id="_idTextAnchor172"/>Chapter 11</em>: Implementing a Real-Time Scoring Solution</h1>
			<p>While most <strong class="bold">machine learning (ML)</strong> projects involve <strong class="bold">batch scoring</strong>, the most complex ML projects use <strong class="bold">real-time solutions</strong>. Think about models that determine whether a credit card transaction is fraudulent, models that decide which ads to show online shoppers, and models that decide whether a customer at a car dealership is creditworthy or not. These situations all demand a real-time scoring solution and it's incredibly important that your model be both fast and accurate. </p>
			<p>Luckily, creating a fast, reliable real-time scoring solution in AutoML is easy whether you decide to code it with Python or use the <strong class="bold">Azure Machine Learning </strong>(<strong class="bold">AML</strong>)<strong class="bold"> </strong>Studio <strong class="bold">graphical user interface</strong> (<strong class="bold">GUI</strong>). </p>
			<p>You will begin this chapter by creating a real-time scoring endpoint through the AML studio GUI. <strong class="bold">Real-time scoring endpoints</strong> are web services through which you can pass data and quickly receive results. Continuing, you will then create real-time scoring endpoints through Python code using the AzureML SDK in a Jupyter notebook. Lastly, you will learn how to improve the performance of your real-time scoring endpoints to better serve your end users. </p>
			<p>By the end of this chapter, you will have a more complete data science skillset. Being able to train models, score models in batch, retrain models on a schedule, and score models in real time are all fundamental ML engineering skills that you will have in your repertoire. This skillset is in high demand. Moreover, you will be able to craft real-time scoring endpoints that you can embed in complex scenarios. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Creating real-time endpoints through the UI</li>
				<li>Creating real-time endpoints through the SDK</li>
				<li>Improving performance on your AKS cluster</li>
			</ul>
			<h1 id="_idParaDest-169"><a id="_idTextAnchor173"/>Technical requirements</h1>
			<p>In this chapter, you will be creating an <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>) instance through AML studio and creating real-time scoring endpoints using the <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong> that you created in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>. </p>
			<p>As such, you will need a working internet connection, an <strong class="bold">Azure Machine Learning Service </strong>(<strong class="bold">AMLS</strong>) workspace, and a compute instance. You will also need permission to create an AKS cluster. If you are using a personal account, this will not be an issue.</p>
			<p>The following are the prerequisites for the chapter:</p>
			<ul>
				<li>Have access to the internet</li>
				<li>Have a web browser, preferably Google Chrome or Microsoft Edge Chromium</li>
				<li>Have a Microsoft Azure account</li>
				<li>Have created an AMLS workspace</li>
				<li>Have created the <strong class="source-inline">compute-cluster</strong> compute cluster in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em></li>
				<li>Understand how to navigate to the Jupyter environment from an Azure compute instance as demonstrated in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em></li>
				<li>Have trained and registered the <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong> ML model in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em></li>
			</ul>
			<p>The code for this chapter is available here: <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter11">https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter11</a>.</p>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor174"/>Creating real-time endpoints through the UI</h1>
			<p>The crux of any<a id="_idIndexMarker710"/> real-time scoring solution is a<a id="_idIndexMarker711"/> real-time scoring endpoint, a web URL through which you can pass data and immediately retrieve ML<strong class="bold"> </strong>predictions. Endpoints<a id="_idIndexMarker712"/> are hosted on containerized services that are up and running 24 hours a day, 7 days a week, waiting for incoming requests. </p>
			<p><strong class="bold">Requests</strong> send<a id="_idIndexMarker713"/> data to the endpoint for scoring and can be written in any computer language including Python. As soon as a request comes through, your endpoint will automatically execute the underlying code and return results. </p>
			<p>You can use these endpoints anywhere; any coding language from C# to Python to Java can make use of real-time scoring endpoints. Thus, once you obtain the URL that hosts the endpoint, you are free to implement it in any other piece of code. Commonly, real-time scoring endpoints are incorporated in streaming jobs, web applications, and mobile apps. </p>
			<p>When using real-time<a id="_idIndexMarker714"/> scoring endpoints based on AutoML<a id="_idIndexMarker715"/> models, there are a few key points to keep in mind that make them quite different from the batch scoring pipelines you created in <a href="B16595_09_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 9</em></a>, <em class="italic">Implementing a Batch Scoring Solution</em>. They are as follows:</p>
			<ul>
				<li>First, when passing data into an endpoint that's scoring data using an AutoML-trained model, you must pass input data in a JSON format, the most common format for sending data through an endpoint. Pandas dataframes or any format other than JSON will fail. </li>
				<li>Second, you do not have to write a Python script for scoring AutoML-trained models. Azure AutoML automatically generates one for you. Because of this, the data you pass into the endpoint must be in the proper shape needed to score. You cannot do data preprocessing within your endpoint itself unless you want to alter the underlying scripts generated by AutoML.</li>
			</ul>
			<p>There are two main services that AMLS uses to host endpoints, <strong class="bold">Azure Container Instances</strong> (<strong class="bold">ACI</strong>) and <a id="_idIndexMarker716"/>AKS. Both are containerized and use Docker. Both can be created either using the GUI within AML studio or using the Python SDK through a Jupyter notebook. ACI is lightweight, cheap, and used largely for testing. AKS is powerful, expensive, and used for production.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">A key difference<a id="_idIndexMarker717"/> between ACI and AKS is authentication. ACI supports <strong class="bold">key-based authentication</strong> only whereas AKS supports both key-based<a id="_idIndexMarker718"/> and <strong class="bold">token-based authentication</strong>.</p>
			<p>In this section, you will use the AML studio GUI to create an endpoint using the <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong> ML model you built in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, hosted on ACI. Then, you will create an <strong class="bold">AKS cluster</strong> through <a id="_idIndexMarker719"/>the UI; an AKS cluster is a group of <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>) that run 24/7 to host your endpoints. You will wrap up this section by creating an endpoint hosted on your AKS cluster. </p>
			<p>Overall, the goal of <a id="_idIndexMarker720"/>this section is to introduce you to <a id="_idIndexMarker721"/>endpoints and show how you can easily create them with AutoML trained models in just a few clicks. </p>
			<h2 id="_idParaDest-171"><a id="_idTextAnchor175"/>Creating an ACI-hosted endpoint through the UI</h2>
			<p>First, create<a id="_idIndexMarker722"/> an Azure container instance <a id="_idIndexMarker723"/>using the AI using the following steps:</p>
			<ol>
				<li>Open up your AML studio by navigating to <a href="https://ml.azure.com/.">https://ml.azure.com/.</a></li>
				<li>Click on <strong class="bold">Models</strong> on the left-hand panel under <strong class="bold">Assets</strong>.</li>
				<li>You will see a list of all of the ML models you have trained on this AMLS workspace. Click the blue link to <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong>.</li>
				<li>Click the blue link under <strong class="bold">Run ID</strong> to take you to the experiment used to train your model. It should begin with <strong class="source-inline">AutoML_</strong> followed by a GUID, a unique string of characters.</li>
				<li>Click <strong class="bold">Deploy</strong> near the top of your screen. </li>
				<li>Give your endpoint the name <strong class="source-inline">diabetes-aci-gui</strong>. Endpoint names may only consist of lowercase letters, numbers, and dashes.</li>
				<li>Select <strong class="bold">Azure Container Instance</strong> for <strong class="bold">Compute type</strong>.</li>
				<li>After <a id="_idIndexMarker724"/>confirming that your settings <a id="_idIndexMarker725"/>match the following screenshot, click <strong class="bold">Deploy</strong>:<div id="_idContainer120" class="IMG---Figure"><img src="image/Figure_11.1_B16595.jpg" alt="Figure 11.1 – ACI settings "/></div><p class="figure-caption">Figure 11.1 – ACI settings</p></li>
				<li>Your model will take a few minutes to deploy. After waiting a sufficient amount of time, click <strong class="bold">Endpoints</strong> on the left-hand panel under <strong class="bold">Assets</strong>.<p class="callout-heading">Important note</p><p class="callout">The first time you create an endpoint in either ACI or AKS, AMLS will create a container registry to host them. Do not, under any circumstances, delete this registry as you will be unable to deploy endpoints from that point on.</p></li>
				<li>Click the blue link to <strong class="source-inline">diabetes-aci-gui</strong>.</li>
				<li>Click <strong class="bold">Consume</strong> near the top of your screen.</li>
				<li>Copy the <strong class="source-inline">REST</strong> endpoint URL into a text editor such as Notepad. Notice that there is also code to use the model in C#, Python, and R. You have now created a functioning scoring endpoint hosted on ACI.</li>
			</ol>
			<p>With an ACI<a id="_idIndexMarker726"/> built, you now have a working endpoint <a id="_idIndexMarker727"/>that you can use to score new data. ACI is great for testing purposes, but to create a production-ready solution, you need AKS.</p>
			<h2 id="_idParaDest-172"><a id="_idTextAnchor176"/>Creating an AKS cluster through the UI</h2>
			<p>Before you <a id="_idIndexMarker728"/>can host an endpoint on AKS, you first need<a id="_idIndexMarker729"/> to build an AKS cluster. Follow these steps to create one using the GUI: </p>
			<ol>
				<li value="1">Click <strong class="bold">Compute</strong> on the left-hand panel under <strong class="bold">Manage</strong>.</li>
				<li>Click <strong class="bold">Inference clusters</strong> near the top of your screen.</li>
				<li>Click <strong class="bold">Create</strong>.</li>
				<li>Select <strong class="bold">North Central US</strong> for <strong class="bold">Location</strong> or whatever Azure location your AMLS workspace is located in.</li>
				<li>Use the search box on the right-hand side to search for <strong class="source-inline">Standard_DS3_v2</strong>.</li>
				<li>Select <strong class="source-inline">Standard_DS3_v2</strong> for your VM and click <strong class="bold">Next</strong>.</li>
				<li>Give your AKS cluster a name. Call it <strong class="source-inline">aks-amls-cluster</strong>. It can only be 16 characters long.</li>
				<li>Select <strong class="bold">Dev/test</strong> for <strong class="bold">Cluster purpose</strong>. </li>
				<li>Set <strong class="bold">Number of nodes</strong> to <strong class="source-inline">3</strong>.<p class="callout-heading">Important note</p><p class="callout">When creating an AKS cluster, ensure that the number of cores on your VM type multiplied by the number of nodes is equal to or greater than 12. <strong class="source-inline">Standard_DS3_v2</strong> VMs have 4 cores each, thus we set the number of nodes to <strong class="source-inline">4</strong>. This is a minimum requirement.</p></li>
				<li>Once you <a id="_idIndexMarker730"/>compare your settings to the following <a id="_idIndexMarker731"/>screenshot and ensure they match, click <strong class="bold">Create</strong>:<div id="_idContainer121" class="IMG---Figure"><img src="image/Figure_11.2_B16595.jpg" alt="Figure 11.2 – AKS cluster settings "/></div></li>
			</ol>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 11.2 – AKS cluster settings</p>
			<p>You have now successfully created an AKS cluster. You can use this cluster to host a large number of ML models. While ACI is suitable only for running models up to 1 GB in size, you can use AKS clusters to host much larger models. Next, you will create an endpoint on<a id="_idIndexMarker732"/> this <a id="_idIndexMarker733"/>cluster.</p>
			<h2 id="_idParaDest-173"><a id="_idTextAnchor177"/>Creating an AKS-hosted endpoint through the UI</h2>
			<p>In order to <a id="_idIndexMarker734"/>create a real-time scoring endpoint hosted <a id="_idIndexMarker735"/>on AKS, you need to follow nearly the exact same steps that you used to create one hosted on ACI. Begin with the following:</p>
			<ol>
				<li value="1">Open up your AML studio by navigating to <a href="https://ml.azure.com/">https://ml.azure.com/</a>.</li>
				<li>Click on <strong class="bold">Models</strong> on the left-hand panel under <strong class="bold">Assets</strong>.</li>
				<li>You will see a list of all of the ML models you have trained on this AMLS workspace. Click the blue link to open <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong>.</li>
				<li>Click the blue link under <strong class="bold">Run ID</strong> to take you to the experiment used to train your model. The run ID of your experiment will begin with <strong class="source-inline">AutoML_</strong> followed by a GUID, a unique string of characters.</li>
				<li>Click <strong class="bold">Deploy</strong> near the top of your screen. </li>
				<li>Give your endpoint the name <strong class="source-inline">diabetes-aks-gui</strong>. Endpoint names may only consist of lowercase letters, numbers, and dashes.</li>
				<li>Select <strong class="bold">Azure Kubernetes Service</strong> for <strong class="bold">Compute type</strong>.</li>
				<li>Switch <strong class="bold">Enable Authentication</strong> on.</li>
				<li>Select <strong class="bold">Key-based authentication</strong> for <strong class="bold">Type</strong>.</li>
				<li>After confirming that your settings match with the following screenshot, click <strong class="bold">Deploy</strong>:<div id="_idContainer122" class="IMG---Figure"><img src="image/Figure_11.3_B16595.jpg" alt="Figure 11.3 – AKS settings "/></div><p class="figure-caption">Figure 11.3 – AKS settings</p></li>
				<li>Your<a id="_idIndexMarker736"/> model will take a few minutes to <a id="_idIndexMarker737"/>deploy, the same as your ACI-hosted model. Once it's ready, click <strong class="bold">Endpoints</strong> on the left-hand panel under <strong class="bold">Assets</strong>.</li>
				<li>Click the blue link to open <strong class="source-inline">diabetes-aks-gui</strong>.</li>
				<li>Click <strong class="bold">Consume</strong> near the top of your screen.</li>
				<li>Copy the <strong class="source-inline">REST</strong> endpoint URL into a text editor such as Notepad. Also, copy one of the keys. You can use either the primary key or the secondary key. Either will work for authentication.</li>
			</ol>
			<p>Via this section, you have now created two real-time scoring endpoints, one hosted in ACI and the other in AKS. You have also created an AKS cluster to host your endpoints and assigned key-based authentication to secure your AKS-hosted endpoint. Through AML studio, by <a id="_idIndexMarker738"/>clicking <strong class="bold">Consume</strong>, you can also <a id="_idIndexMarker739"/>easily find code to deploy your endpoint in C#, Python, and R. </p>
			<p>In the next section, you will do the same thing with code. Additionally, you will also test your endpoints to see how they work.</p>
			<h1 id="_idParaDest-174"><a id="_idTextAnchor178"/>Creating real-time endpoints through the SDK</h1>
			<p>One-click <a id="_idIndexMarker740"/>deployment through AML studio is <a id="_idIndexMarker741"/>really easy, but most organizations will require you to develop your solutions via code. Luckily, creating real-time scoring endpoints for AutoML models via the AzureML Python SDK is almost as easy as creating them through the UI. Furthermore, you'll gain a deeper understanding of how your endpoints work and how to format your JSON testing to pass data into the endpoint as a request.</p>
			<p>In this section, you'll begin by entering your Jupyter environment and creating a new notebook. First, you will deploy your <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong> model via ACI, test it, and, once you've confirmed that your test is a success, create a new AKS cluster via code and deploy it there. You will conclude this section by testing your AKS deployment and confirm that everything works as expected. </p>
			<p>The goal of this section is to further your understanding of real-time scoring endpoints, teach you how to create everything in code, and enable you to craft and test complex real-time solutions. </p>
			<h2 id="_idParaDest-175"><a id="_idTextAnchor179"/>Creating and testing a real-time endpoint with ACI through Python</h2>
			<p>Anytime<a id="_idIndexMarker742"/> you intend to deploy a<a id="_idIndexMarker743"/> ML model <a id="_idIndexMarker744"/>in<a id="_idIndexMarker745"/> real<a id="_idIndexMarker746"/> time, you should begin<a id="_idIndexMarker747"/> by deploying your model to ACI and testing it. This way, you can get an idea of how your data needs to be formatted, how long your endpoint will take to respond with a score, and whether your model works. Begin by creating an endpoint.</p>
			<h3>Creating a real-time scoring endpoint hosted on ACI</h3>
			<p>Much like <a id="_idIndexMarker748"/>previous chapters, you first <a id="_idIndexMarker749"/>need to open a Jupyter notebook on your compute instance. Then, build a real-time scoring endpoint with the following steps:</p>
			<ol>
				<li value="1">Open up your AML studio by navigating to <a href="https://ml.azure.com/">https://ml.azure.com/</a>.</li>
				<li>Click <strong class="bold">Compute</strong>, start up a compute instance, and open a Jupyter environment. </li>
				<li>Create a new Jupyter notebook and name it <strong class="source-inline">real-time-endpoints</strong>. If you need a refresher, please review <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>.</li>
				<li>Import your standard Azure libraries with the following code:<p class="source-code">from azureml.core import Workspace, Dataset, Datastore</p><p class="source-code">from azureml.core import Experiment, Environment, Model</p><p class="source-code">from azureml.core.compute import ComputeTarget, AksCompute</p><p>All of these packages should be familiar to you by now except <strong class="source-inline">AksCompute</strong>. If you need a refresher, consult <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, for <strong class="source-inline">Workspace</strong>, <strong class="source-inline">Dataset</strong>, <strong class="source-inline">Datastore</strong>, <strong class="source-inline">Experiment</strong>, and <strong class="source-inline">ComputeTarget</strong>, and <a href="B16595_09_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 9</em></a>, <em class="italic">Implementing a Batch Scoring Solution</em>, for <strong class="source-inline">Environment</strong> and <strong class="source-inline">Model</strong>. <strong class="source-inline">AksCompute</strong> allows you to create an AKS cluster via code.</p></li>
				<li>Import your Azure libraries specific to creating an endpoint with ACI with the following code:<p class="source-code">from azureml.core.model import InferenceConfig</p><p class="source-code">from azureml.core.webservice import AciWebservice</p><p class="source-code">from azureml.core.webservice import AksWebservice</p><p class="source-code">from azureml.train.automl.run import AutoMLRun</p><p><strong class="source-inline">InferenceConfig</strong> lets you specify the Python script and environment you will use to <a id="_idIndexMarker750"/>create your endpoint <a id="_idIndexMarker751"/>deployment. This package is used with both AKS and ACI-based deployments. </p><p><strong class="source-inline">AciWebservice</strong> is what you use to actually create endpoints deployed on ACI and <strong class="source-inline">AksWebservice</strong> is what you use to create endpoints deployed on AKS. <strong class="source-inline">AutoMLRun</strong> will let you access previous AutoML training runs. You will need to recover the Python script created when you trained your model.</p><p class="callout-heading">Important tip</p><p class="callout">If you are having trouble loading Azure libraries, update the AzureML SDK by running the <strong class="source-inline">Update AzureML SDK.ipynb</strong> notebook, found here: <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb">https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb</a>.</p></li>
				<li>Import the non-Azure libraries with the following code:<p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p><p class="source-code">import random as r</p><p class="source-code">import requests</p><p class="source-code">import json</p><p class="source-code">import os</p><p>You are already familiar with <strong class="source-inline">pandas</strong>, <strong class="source-inline">numpy</strong>, <strong class="source-inline">os</strong>, and <strong class="source-inline">random</strong>. If you need a refresher, please consult <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, or <a href="B16595_09_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 9</em></a>, <em class="italic">Implementing a Batch Scoring Solution</em>, for <strong class="source-inline">os</strong> and <strong class="source-inline">random</strong>. </p><p>Onto the <a id="_idIndexMarker752"/>new packages, <strong class="source-inline">requests</strong> lets <a id="_idIndexMarker753"/>you make web requests to your deployed endpoints. This package will let you test your deployment and score data using your endpoint, while <strong class="source-inline">json</strong> lets you transform your data into the JSON format used by web requests.</p></li>
				<li>Connect your Jupyter notebook to your AMLS workspace with the following code: <p class="source-code">ws = Workspace.from_config()</p><p>If you are prompted to log in, follow the instructions.</p></li>
				<li>Set your datastore to the default with the first line of code. If you want to use a different datastore, use the second and third lines of code instead, replacing <strong class="source-inline">workspaceblobstore</strong>: <p class="source-code">datastore = Datastore.get_default(ws)</p><p class="source-code">my_datastore_name = 'workspaceblobstore'</p><p class="source-code">my_datastore = Datastore.get(ws, my_datastore_name)</p></li>
				<li>Set your compute cluster to the one you created in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em>, with the following code:<p class="source-code">compute_name = 'compute-cluster'</p><p class="source-code">compute_target = ComputeTarget(ws, compute_name)</p></li>
				<li>Set your environment to <strong class="source-inline">AzureML-AutoML</strong> with the following code: <p class="source-code">environment = Environment.get(ws, 'AzureML-AutoML')</p><p><strong class="source-inline">AzureML-AutoML</strong> is a standard environment that comes with the AzureML SDK. You can <a id="_idIndexMarker754"/>use this environment<a id="_idIndexMarker755"/> for any real-time AutoML deployment.</p><p class="callout-heading">Tip</p><p class="callout">There are many different standard environments that come with the AzureML SDK. You can access a list of them by using the <strong class="source-inline">Environment.list</strong> function.</p></li>
				<li>Set your <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong> model with the following code:<p class="source-code">model = Model(ws, 'Diabetes-AllData-Regression-AutoML')</p><p>This is the model you will deploy to an endpoint to score diabetes data in real time.</p></li>
				<li>Navigate to your AML studio and click <strong class="bold">Models</strong> on the left-hand panel. You need to retrieve the experiment and run the ID associated with your model.</li>
				<li>Click the blue link to open <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong>.</li>
				<li>Copy <strong class="bold">Experiment name</strong> and <strong class="bold">Run ID</strong> to a text editor such as Notepad. The name of your experiment should be <strong class="source-inline">Diabetes-Sample-Regression</strong> if you followed the instructions word for word in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>.</li>
				<li>Set your experiment and run ID with the following code:<p class="source-code">experiment = Experiment(ws, 'Diabetes-Sample-Regression') </p><p class="source-code">runID = 'AutoML_your_run_ID' </p></li>
				<li>Retrieve your AutoML run with the following code:<p class="source-code">run = AutoMLRun(experiment, runID)</p><p>The reason you are retrieving your old run is so you can pull the Python script out of it<a id="_idIndexMarker756"/> that was used to deploy<a id="_idIndexMarker757"/> the models. This is the same script that was used to deploy your models using the GUI. </p><p class="callout-heading">Important tip</p><p class="callout">You can always retrieve old model runs using this code. This is important if you forgot to register models. You can similarly retrieve old ML pipeline runs.</p></li>
				<li>Extract the best model fitted by AutoML with the following code:<p class="source-code">best_run, fitted_model = run.get_output()</p><p>This code retrieves two objects, the best run as well as the model. You will only use the best run, but <strong class="source-inline">get_output()</strong> requires you to pass two objects or the function will return an error. </p></li>
				<li>Make a folder to hold all of your real-time scripts with the following code:<p class="source-code">os.makedirs('Real_Time_Scripts', exist_ok=True)</p></li>
				<li>Retrieve the Python script you will use for scoring data in real time with the following code:<p class="source-code">script_path =\</p><p class="source-code">'Real_Time_Scripts/Diabetes_Inference.py'</p><p class="source-code">best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_path)</p><p>When AutoML trains a model, it outputs a scoring file for real-time inferencing. This file is always called <strong class="source-inline">scoring_file_v_1_0_0.py</strong> and is located in the <strong class="source-inline">outputs</strong> folder. This code grabs that file and saves it as <strong class="source-inline">Diabetes_Inference.py</strong>.</p></li>
				<li>Set a variable to name your ACI deployment:<p class="source-code">aci_service_name = 'diabetes-scoring-aci'</p></li>
				<li>Configure <a id="_idIndexMarker758"/>your endpoint to<a id="_idIndexMarker759"/> use your Python script and <strong class="source-inline">Azure-AutoML</strong> environment with the following code:<p class="source-code">inference_config =\</p><p class="source-code">InferenceConfig(entry_script=script_path,\</p><p class="source-code">environment = environment)</p></li>
				<li>Configure your ACI deployment with the following code: <p class="source-code">aci_config =\</p><p class="source-code">AciWebservice.deploy_configuration(\</p><p class="source-code">cpu_cores = 1, memory_gb = 1,\</p><p class="source-code">tags = {'Project': 'Diabetes'},\</p><p class="source-code">description = 'Diabetes Real-Time ACI Deployment')</p><p>Notice you need to set the number of cores to use for the deployment as well as the amount of memory to reserve. You can also set tags and add a description.</p></li>
				<li>Create your ACI endpoint with the following code:<p class="source-code">aci_service =\</p><p class="source-code">Model.deploy(ws, aci_service_name,\</p><p class="source-code">[model], inference_config, aci_config,overwrite=True)\</p><p class="source-code">aci_service.wait_for_deployment(True)</p></li>
			</ol>
			<p>This code requires you to pass your AMLS workspace, the name of your ACI deployment, your ML model, your endpoint (inference) configuration, your ACI configuration, and to set an <strong class="source-inline">overwrite</strong> flag to <strong class="source-inline">True</strong> or <strong class="source-inline">False</strong>. Your endpoint should take<a id="_idIndexMarker760"/> between 5 and 10 minutes to <a id="_idIndexMarker761"/>deploy.</p>
			<h3>Testing your real-time scoring endpoint</h3>
			<p>Now that you<a id="_idIndexMarker762"/> have created a real-time scoring endpoint on ACI, it's time to test it. First, you'll need to create some data to test it with, then you need to convert it to JSON and pass it into the endpoint with the following steps:</p>
			<ol>
				<li value="1">To create some random <strong class="source-inline">Diabetes</strong> data, first, create a range of possible values for each variable using the minimum and maximum values from the <strong class="source-inline">Diabetes</strong> sample dataset you created in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em>, with the following code:<p class="source-code">AGE_range = np.arange(19,79,1)</p><p class="source-code">SEX_range = np.arange(1,2,1)</p><p class="source-code">BMI_range = np.arange(18.0,42.2,0.1)</p><p class="source-code">BP_range = np.arange(62, 133, 1)</p><p class="source-code">S1_range = np.arange(97, 301, 1)</p><p class="source-code">S2_range = np.arange(41.6, 242.4, 0.1)</p><p class="source-code">S3_range = np.arange(22, 99, 1)</p><p class="source-code">S4_range = np.arange(2, 9.09, 0.01)</p><p class="source-code">S5_range = np.arange(3.258, 6.107, 0.001)</p><p class="source-code">S6_range = np.arange(58, 124, 1)</p></li>
				<li>Create an empty list to help generate the sample data. This is similar to the method you used to create sample <strong class="source-inline">Iris</strong> data in <a href="B16595_09_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 9</em></a>, <em class="italic">Implementing a Batch Scoring Solution</em>. Also, create an empty pandas dataframe and assign columns to it with the following code:<p class="source-code">DiabetesList = []</p><p class="source-code">columns =\</p><p class="source-code">['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6']</p><p class="source-code">DiabetesDF = pd.DataFrame(columns=columns)</p></li>
				<li>Use the following <a id="_idIndexMarker763"/>code to create sample diabetes data using a <strong class="source-inline">for</strong> loop:<p class="source-code">for i in range(0,5):</p><p class="source-code">    values = [r.choice(AGE_range),\</p><p class="source-code">r.choice(SEX_range),r.choice(BMI_range),\</p><p class="source-code">r.choice(BP_range), r.choice(S1_range),\</p><p class="source-code">r.choice(S2_range), r.choice(S3_range),\</p><p class="source-code">r.choice(S4_range), r.choice(S5_range),\</p><p class="source-code">r.choice(S6_range)]</p><p class="source-code">    DiabetesDict = pd.DataFrame(dict(zip(columns, values)), index=[0])</p><p class="source-code">    DiabetesList.append(DiabetesDict)</p><p class="source-code">DiabetesDF = DiabetesDF.append(DiabetesList,True)</p><p>This code is identical to the code you used to create <strong class="source-inline">Iris</strong> data. Please refer to <a href="B16595_09_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 9</em></a>, <em class="italic">Implementing a Batch Scoring Solution</em>, for a detailed explanation.</p></li>
				<li>Register your sample data with the name <strong class="source-inline">Diabetes Scoring</strong> with the following code:<p class="source-code">Dataset.Tabular.register_pandas_dataframe(\</p><p class="source-code">DiabetesDF, datastore, 'Diabetes Scoring')</p><p>This will write the underlying data to your default datastore and register it as a dataset called <strong class="source-inline">Diabetes Scoring</strong>.</p></li>
				<li>Convert <strong class="source-inline">DiabetesDF</strong> into a JSON object beginning with <strong class="source-inline">{"data":</strong> and ending with <strong class="source-inline">}</strong>. Every AutoML real-time deployment requires data in this format:<p class="source-code">test = '{"data":' +\</p><p class="source-code">DiabetesDF.to_json(orient='records') + '}'</p><p class="callout-heading">Important tip</p><p class="callout">When creating a JSON file, always set <strong class="source-inline">orient</strong> to <strong class="source-inline">records</strong>. Any other JSON format risks errors. </p></li>
				<li>View your<a id="_idIndexMarker764"/> data to understand what your incoming data should look like: <p class="source-code">Test</p><p>Your data should resemble <em class="italic">Figure 11.4</em>, although the values will be different based on your data. The key point is that the JSON values need to be in a key-value pair to guarantee a correct prediction: </p><div id="_idContainer123" class="IMG---Figure"><img src="image/Figure_11.4_B16595.jpg" alt="Figure 11.4 – JSON format "/></div><p class="figure-caption">Figure 11.4 – JSON format</p></li>
				<li>Navigate to your AML studio front page and click <strong class="bold">Endpoints</strong>.</li>
				<li>Click the blue link to <strong class="source-inline">diabetes-scoring-aci</strong> and click <strong class="bold">Consume</strong>. Copy the URL that links to your endpoint and paste it in a text editor such as Notepad.</li>
				<li>Going back to your code, set the URL and headers as variables:<p class="source-code">aci_url = 'your-aci-endpoint-url'</p><p class="source-code">headers = {'Content-Type': 'application/json'}</p><p>While you need to enter your URL, the headers will be the same for every deployment.</p></li>
				<li>Test your <a id="_idIndexMarker765"/>ACI deployment with the following code:<p class="source-code">response =\</p><p class="source-code">requests.post(aci_url, test, headers=headers)</p><p class="source-code">print(resp.text)</p></li>
			</ol>
			<p>You have now coded a real-time scoring endpoint hosted on ACI and have successfully tested it. Additionally, you understand how your data needs to be shaped and formatted in JSON in order to be scored. Once you have confirmed that your real-time endpoint is working in ACI, the next step is to create an AKS cluster and deploy the production version there as you will do next.</p>
			<h2 id="_idParaDest-176"><a id="_idTextAnchor180"/>Creating an AKS cluster through Python</h2>
			<p>Creating an AKS <a id="_idIndexMarker766"/>cluster through code is just as easy and <a id="_idIndexMarker767"/>straightforward as creating it through the GUI. Many organizations require all infrastructure to be created as code, and you can use the following steps as a template: </p>
			<ol>
				<li value="1">Continuing in your Jupyter notebook, set variables for your VM size, the number of nodes required, your AKS cluster location, and your AKS cluster name:<p class="source-code">aks_cluster_name = 'aks-code-cluster'</p><p class="source-code">vm_type = 'Standard_DS3_v2'</p><p class="source-code">node_count = 3</p><p class="source-code">AKS_location = 'northcentralus'</p></li>
				<li>Set your AKS cluster configurations with the following code:<p class="source-code">prov_config =\</p><p class="source-code">AksCompute.provisioning_configuration(vm_size =\</p><p class="source-code">vm_type, agent_count = node_count, location =\</p><p class="source-code">AKS_location)</p><p>When setting your configurations, keep in mind that your node count multiplied by the number of cores on each VM must be greater than or equal to 12. Also, think about <a id="_idIndexMarker768"/>where the incoming data will be <a id="_idIndexMarker769"/>coming from when setting your Azure location.</p></li>
				<li>Create your AKS cluster with the following code:<p class="source-code">aks_target =\</p><p class="source-code">ComputeTarget.create(workspace = ws, name =\</p><p class="source-code">aks_cluster_name, provisioning_configuration =\</p><p class="source-code">prov_config)</p><p class="source-code">aks_target.wait_for_completion(show_output = True)</p><p>You have to pass in your AMLS workspace, AKS cluster name, and AKS cluster provisioning configurations. It should take about 5-10 minutes to spin up your cluster.</p></li>
			</ol>
			<p>You have just created an AKS cluster via code. Once it is up and running, you can deploy your scoring endpoint to your AKS cluster and test it using many of the same variables you have already created. For this reason, it's recommended that you create both the ACI and AKS endpoint in the same Jupyter notebook. It will save you a lot of work copying over code. </p>
			<h2 id="_idParaDest-177"><a id="_idTextAnchor181"/>Creating and testing a real-time endpoint with AKS through Python</h2>
			<p>Your<a id="_idIndexMarker770"/> last<a id="_idIndexMarker771"/> task <a id="_idIndexMarker772"/>in this section <a id="_idIndexMarker773"/>is to <a id="_idIndexMarker774"/>deploy your real-time <a id="_idIndexMarker775"/>scoring endpoint to your AKS cluster, grab the URL and access key, and test your deployment. There are only a few steps, as you have already created most of the code when deploying to ACI. </p>
			<p>At the end of this chapter, remember to delete your AKS endpoints and cluster as they can be quite expensive and rack up a bill. Within the same Jupyter notebook, continue with the following steps:</p>
			<ol>
				<li value="1">Set your target AKS cluster with the following code:<p class="source-code">aks_cluster = AksCompute(ws, 'aks-code-cluster')</p></li>
				<li>Set a variable for the name of your AKS deployment:<p class="source-code">aks_service_name = 'diabetes-scoring-aks' </p></li>
				<li>Configure your AKS deployment with the following code:<p class="source-code">aks_config =\</p><p class="source-code">AksWebservice.deploy_configuration(cpu_cores = 1,\</p><p class="source-code">                  memory_gb = 1, tags = {'Project':\</p><p class="source-code">                  'Diabetes'}, description =\</p><p class="source-code">                  'Diabetes Real-Time ACI Deployment')</p><p>Notice that these configurations are identical to those used for your ACI deployment.</p></li>
				<li>Create your AKS endpoint with the following code:<p class="source-code">aks_service =\</p><p class="source-code">Model.deploy(ws, aks_service_name, [model],\</p><p class="source-code">inference_config, aks_config, aks_cluster,\</p><p class="source-code">overwrite=True)</p><p class="source-code">aks_service.wait_for_deployment(show_output = True)</p><p>Notice that this code is nearly identical to the code you used to create the ACI deployment; the one difference is that you also must pass in the AKS cluster. This is because AKS is hosted on a cluster of VMs that you manage, whereas ACI is a serverless container service.</p></li>
				<li>Navigate to your AML studio front page and click <strong class="bold">Endpoints</strong>.</li>
				<li>Click the blue link to open <strong class="source-inline">diabetes-scoring-aks</strong> and click <strong class="bold">Consume</strong>. Copy the URL that links to your endpoint and paste it in a text editor such as Notepad. Do<a id="_idIndexMarker776"/> the same thing for <a id="_idIndexMarker777"/>your access<a id="_idIndexMarker778"/> key, using either the<a id="_idIndexMarker779"/> primary or secondary <a id="_idIndexMarker780"/>key. Either will work.</li>
				<li>Going back to your code, set your URL, key, and headers as variables:<p class="source-code">aks_url = 'your-aks-endpoint-url'</p><p class="source-code">key = 'your-aks-key'</p><p class="source-code">headers = {'Content-Type': 'application/json'}</p><p class="source-code">headers['Authorization'] = f'Bearer {key}'</p><p>Here, you need to add in one additional header for authorization. <strong class="bold">Bearer functions</strong> work by granting access to anyone who provides the correct key.</p><p class="callout-heading">Important tip</p><p class="callout">In a production setting, make sure you store all of your keys in <strong class="bold">Azure Key Vault</strong> and do not expose your passwords and keys in open code. This is a best practice that will protect you.</p></li>
				<li>Test your AKS deployment with the following code:<p class="source-code">resp = requests.post(aks_url, test, headers=headers)</p><p class="source-code">print(resp.text)</p><p>You should see the same results as your ACI test as they use the same input data. Make sure the output matches and you can call your test a success.</p></li>
			</ol>
			<p>You have now learned everything you need to learn in order to successfully create a real-time scoring endpoint in Azure. These endpoints can be used anywhere in any other piece of code. Make sure that any data that gets pushed into the endpoint is in the correct JSON format and your projects will be successful.</p>
			<p>The last part <a id="_idIndexMarker781"/>of this chapter deals<a id="_idIndexMarker782"/> with optimizing the performance of your <a id="_idIndexMarker783"/>AKS clusters. There is <a id="_idIndexMarker784"/>some fine-tuning involved<a id="_idIndexMarker785"/> that can greatly enhance the response time of your scoring solution.</p>
			<h1 id="_idParaDest-178"><a id="_idTextAnchor182"/>Improving performance on your AKS cluster</h1>
			<p>Sometimes you<a id="_idIndexMarker786"/> will deploy an endpoint on AKS and it doesn't perform how you'd like. Maybe it times out, maybe it's too slow, maybe an endpoint that was previously working fine suddenly gets a lot more traffic that it cannot handle. These situations happen, and you must be prepared to face them. </p>
			<p>Thankfully, AKS deployments have a lot of additional configurations that you can take advantage of to solve these problems. This section covers some of the more common situations as follows:</p>
			<ul>
				<li>Depending on how complex your model is, how many data points you are trying to score, and the size of your VMs, AKS models can sometimes take a while to score or even timeout. In this situation, there are many things you can do. <p>First, you can try increasing the size of your VM, selecting one with more RAM. Next, you can add an additional setting to your deployment configuration, <strong class="source-inline">scoring_timeout_ms</strong>. This setting defaults to <strong class="source-inline">60000</strong> milliseconds, or 1 minute. You can adjust it to a maximum of <strong class="source-inline">300000</strong> milliseconds, or 5 minutes. Sometimes, adjusting <strong class="source-inline">memory_gb</strong> or upping the number of <strong class="source-inline">cpu_cores</strong> can help too.</p></li>
				<li>Check the size of your model using AML studio. You can do this by clicking <strong class="bold">Models</strong>, selecting your model, and clicking <strong class="bold">Artifacts</strong>. There, you will find a pickle file containing your model. If it's quite large, try increasing the <strong class="source-inline">memory_gb</strong> setting on your deployment configurations. </li>
				<li>In the case where your endpoint is suddenly encountering surges in traffic that it cannot handle, try turning on autoscaling and increasing its ability to scale. <strong class="bold">AKS autoscaling</strong> creates <a id="_idIndexMarker787"/>replicas of your application, scaling out horizontally. Autoscale is on by default, but you can explicitly set <strong class="source-inline">autoscale_enabled</strong> to <strong class="source-inline">True</strong> in your <a id="_idIndexMarker788"/>deployment configurations. <p>You can also manually adjust the minimum and maximum number of replicas autoscaling will create using <strong class="source-inline">autoscale_min_replicas</strong> and <strong class="source-inline">autoscale_max_replicas</strong>. These default to <strong class="source-inline">1</strong> and <strong class="source-inline">10</strong>, respectively. Try upping both of these to increase performance in the case of heavy traffic.</p></li>
			</ul>
			<p>Armed with this information, you can easily create powerful AKS deployments that meet your business and performance requirements. When traffic is heavy, up the autoscaling. When your application times out, adjust the timeout setting. When your AKS endpoint runs slowly, try using a larger VM or adjusting the memory settings. Above all, always test your deployment in ACI before deploying it in AKS, and make sure that input data is coming in the correct JSON format in key-value pairs.</p>
			<h1 id="_idParaDest-179"><a id="_idTextAnchor183"/>Summary</h1>
			<p>You have now created and tested real-time scoring solutions using an AutoML trained model. Deploying first on ACI and then on AKS, you understand the full end-to-end process of creating a real-time scoring endpoint. </p>
			<p>Furthermore, you understand how data must be shaped and formatted in order to generate predictions using these endpoints, which can be incorporated into any piece of code using a wide variety of computer languages to create powerful, innovative solutions.</p>
			<p>In the next chapter, <a href="B16595_12_ePub.xhtml#_idTextAnchor184"><em class="italic">Chapter 12</em></a>, <em class="italic">Realizing Business Value with AutoML</em>, the final chapter of the book, you will learn how to present AutoML solutions in a way that will gain the trust of your non-technical business partners. Their trust and acceptance, after all, is the foundation to unlocking the power and value of ML and artificial intelligence in your organization.</p>
		</div>
</body></html>