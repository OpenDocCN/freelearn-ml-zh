<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">HDInsight</h1>
                </header>
            
            <article>
                
<p><span>HDInsight is a type of implementation of Hadoop that runs on the Microsoft Azure platform. HDInsight builds on the</span> <strong>Hortonworks Data Platform</strong> <span>(</span><strong>HDP</strong><span>), and is completely compatible with Apache Hadoop.</span></p>
<p class="mce-root">HDInsight can be perceived as Microsoft's <strong>Hadoop-as-a-Service</strong> (<strong>Haas</strong>). You can quickly deploy the system from a portal or through Windows PowerShell scripting, without having to create any physical or virtual machines.</p>
<p>The following are features of HDInsights:</p>
<ul>
<li class="mce-root">You can implement a small or large number of nodes in a cluster</li>
<li class="mce-root">You pay only for what you use</li>
<li class="mce-root">When your job is complete, you can deprovision the cluster and, of course, stop paying for it</li>
<li class="mce-root">You can use Microsoft Azure Storage so that even when the cluster is deprovisioned, you can retain the data</li>
<li class="mce-root"><span>The HDInsight service works with input-output technologies from Microsoft and other vendors</span></li>
</ul>
<p style="color: black">As mentioned, the HDInsight service runs on Microsoft Azure, and that requires a little explaining before we proceed further.</p>
<p style="color: black">Data is described as 'big data' to indicate that it is being collected in ever-escalating volumes, at increasingly high velocities, and for a widening variety of unstructured formats and variable semantic contexts. Big data collection does not provide value to an enterprise on its own. For big data to provide value in the form of actionable intelligence or insight, it must be accessible, cleaned, analyzed, and then presented in a useful way, often in combination with data from various other sources.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p style="color: black">Apache Hadoop is a software framework that facilitates big data management and analysis. The core of Apache Hadoop provides reliable data storage with the <strong>Hadoop Distributed File System</strong> (<strong>HDFS</strong>), and a simple MapReduce programming model to process and analyze the data stored in this distributed system <span>in parallel.</span> HDFS uses data replication to address hardware failure issues that arise when deploying such highly distributed systems.</p>
<p style="color: black">Windows Azure HDInsight makes Apache Hadoop available as a service in the cloud. It makes the HDFS or MapReduce software framework and related projects available in a simpler, more scalable, and cost-efficient environment. To simplify configuring and running Hadoop jobs, and managing the deployed clusters, Microsoft provides JavaScript, and Hive interactive consoles. This simplified JavaScript approach enables IT professionals and a wider group of developers to deal with big data management and analysis by providing a more accessible path into the Hadoop framework <span>for them</span>.</p>
<p style="color: black">For data scientists who already use R, HDInsight offers a route into the cloud to empower big data analytics. For IT professionals and system administrators, it allows the administration of big data with straightforward management.</p>
<p style="color: black">As in the previous chapters, we will use Microsoft's TDSP as a backdrop for producing machine learning models with HDInsight. <span><span>Now, </span></span>we will use R and HDInsight to analyze and model a sample dataset.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">R with HDInsight</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>What are the main features of HDInsight? It is a Microsoft proprietary solution, but it is a 100% Apache Hadoop solution in the Microsoft Azure cloud. Azure HDInsight is a service that deploys and provisions Apache Hadoop clusters in the cloud for big data analytics.</span></p>
<p class="mce-root">HDInsight provides a software framework designed to manage, analyze, and report on big data. You can use HDInsight to perform interactive queries at petabyte scales over structured or unstructured data in any format. You can also build models, connecting them to BI tools. HDInsight is aimed at providing big data analytics and insights through Excel and Power BI. Azure's HDInsight service makes Apache Hadoop available as a service in the cloud, providing a software ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting started with Azure HDInsight and ML services</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>HDInsight has a number of</span><span> cluster types, which include Hadoop (Hive), HBase, Storm, Spark, Kafka, Interactive Hive (LLAP), and</span> ML Services (R Server) (w<span>ith R Studio, R 9.1). Here is the ML <span class="packt_screen">Cluster configuration</span>, which is established during setup:</span></p>
<p class="mce-root CDPAlignCenter CDPAlign"><img src="Images/b8410df7-c2b0-4306-a016-a43783599a02.png" style="width:39.00em;height:23.33em;" width="690" height="413"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Setup and configuration of HDInsight</h1>
                </header>
            
            <article>
                
<p>In this section, we will set up and configure HDInsight. To set up and configure HDInsight, carry out the following steps:</p>
<ol>
<li>Ensure that you have an Azure account</li>
<li>Log into the Azure portal at <a href="https://portal.azure.com">portal.azure.com</a></li>
<li>When you are logged into the Azure portal, click on the button to add a new resource</li>
<li>In the search query box, type in<span> </span><kbd>HDInsight</kbd><span> </span>and you will be given a number of options</li>
<li>Select the option that simply says<span> </span><span class="packt_screen">HDInsight</span></li>
</ol>
<p>Next, we will set up a basic configuration of HDInsight.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Basic configuration of HDInsight</h1>
                </header>
            
            <article>
                
<p>On the basic configuration item, you will need to enter in the name you wish to use for your Azure HDInsight, along with the storage options. Here is an example configuration:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/891fe187-132f-42f1-a98e-3a4daff41bae.png" style="width:19.50em;height:53.83em;" width="304" height="839"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>For <span class="packt_screen">Cluster type</span>, ensure that you select the <span class="packt_screen">ML Services</span> option. Here is an example:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/9384125a-c80c-4ad7-9c2d-55c07740284c.png" style="width:40.42em;height:24.17em;" width="690" height="413"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Storage options for Azure HDInsight</h1>
                </header>
            
            <article>
                
<p>Once the cluster type has been selected, the next step is to consider the storage. At the time of writing, there are two types of storage: default Azure Storage, and Azure Data Lake Storage Generation 1. For this walk-through, the default <span class="packt_screen">Azure Storage</span> will be used:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/90e3ce6a-8f38-43ae-adfb-144cd84421c4.png" style="width:18.25em;height:53.00em;" width="289" height="839"/></p>
<p class="mce-root">To finalize the creation of the HDInsight cluster, click on<span> </span><span class="packt_screen">Next</span>. Then check through the settings and click<span> </span><span class="packt_screen">Create</span>.</p>
<p>The HDInsight cluster will take approximately twenty minutes to set up.</p>
<p>When setup is complete, click on the <span class="packt_screen">Azure HDInsight</span> cluster in the portal. Here is a screenshot of the portal:</p>

<p>Here is a screenshot of the Azure HDInsight ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Connect to the HDInsight cluster using SSH</h1>
                </header>
            
            <article>
                
<p>The Azure Cloud Shell permits data scientists to access the HDInsight clusters using SSH. The Azure Cloud Shell <span>can be found at the top navigation of the Azure portal, and it is denoted with an arrow sign. Here is a screenshot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/116610d9-6ffd-47a4-98ea-e09b9001b748.png" style="width:16.08em;height:3.25em;" width="208" height="42"/></p>
<ol>
<li>Click on the Azure Cloud Shell icon in the Azure portal.</li>
<li>Select a subscription to create a storage account and Microsoft Azure Files share.</li>
<li>Select<span> </span><span class="packt_screen">Create storage</span>.</li>
<li><span>Check that the environment dropdown on the left-hand side of the shell window says <span class="packt_screen">Bash</span>. Now, you can log in using the </span><kbd>ssh</kbd><span> command. Here is a screenshot:</span></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="Images/19ce155e-cb82-4eeb-8a1f-6eef84ba93c4.png" style="width:12.25em;height:2.58em;" width="180" height="37"/></p>
<p>Once you have logged in, you can then access Microsoft ML Services on the Azure HDInsight cluster.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Accessing Microsoft ML Services on Azure HDInsight</h1>
                </header>
            
            <article>
                
<p>In the bash prompt, simply type in R to access Microsoft ML Services. Here is a screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/9b2fe719-926b-41d7-abe4-96d361a48247.png" style="width:48.58em;height:42.17em;" width="687" height="595"/></p>
<p>To see the files on the HDInsight cluster, use the following RevoScaleR command:</p>
<pre><strong>rxHadoopListFiles</strong></pre>
<p>The files are then read into the DOS prompt box. Here is an example:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/9465d23a-0e91-4cb9-afcd-c07601cd2f4f.png" style="width:60.83em;height:22.92em;" width="876" height="328"/></p>
<p>Once the files are read out, we can start to work with some sample datasets in R. The Iris dataset will be used to explain the use of R in Microsoft ML Services in HDInsight.</p>
<p>Typing in the following command will reassure the data scientist ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">HDInsight and data analytics with R</h1>
                </header>
            
            <article>
                
<p class="mce-root">Firstly, we need to get our data into Azure so that HDInsight can see it. We can upload data directly to Azure Storage, or we can use functionality in <strong>SQL Server Integration Services</strong> (<strong>SSIS</strong>). SSIS has the capability of connecting to Azure Blob Storage and Azure HDInsight. It enables you to create integration service packages that transfer data between an Azure Blob Storage and the on-premise data source. Then, the Azure HDInsight process can conduct processing on the data.</p>
<p class="mce-root">In order to get the data into HDInsight using SSIS, it's necessary to install the Azure Feature Pack. The Microsoft SSIS Feature Pack for Azure provides SQL Server Integration Services with the capability to connect to many Azure services, such as Azure Blob Storage, Azure Data Lake Store, Azure SQL Data Warehouse, and <span>Azure HDInsight. It is a separate install, and you will need to e</span><span>nsure that the SQL server is installed before installing the Azure Feature Pack on a server. Otherwise, the components in the Feature Pack may not be available when you deploy packages to the SSIS catalog database. </span></p>
<p class="mce-root">To install the Microsoft SQL Server 2017 Integration Services Feature Pack for Azure, search for the Microsoft download page by using the term <kbd>Microsoft SQL Server 2017 Integration Services Feature Pack for Azure</kbd>. Then, download the file and run through the wizard.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How do Azure Data Factory and HDInsight interact?</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">It is possible to move files or read and write data to Azure Blob storage. The benefit of using Azure Data Factory means that it is possible to extend existing ETL pipelines with cloud storage, or cloud-based SSIS execution through Azure VMs. It is possible to deploy SSIS packages in Azure Data Factory Version 2, which went to general availability release in July 2018. It provides powerful functionality that facilitates data preparation for cloud compute services such as HDInsight and Microsoft ML Server. It can do a range of tasks, including data archival to cloud storage, and straightforward enumeration of files in blob storage.</p>
<p class="mce-root CDPAlignLeft CDPAlign">There are specific HDInsight processing tasks in the Azure ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Running queries on Azure HDInsight with ML Services</h1>
                </header>
            
            <article>
                
<p class="mce-root">In ML Services on HDInsight, the compute context specifies the physical location of the computational engine handling a given workload. The default is local, which means that it is running on your local machine. In order to make the most of running in the cloud, you will need to switch from local to remote.</p>
<p class="mce-root">R script runs within the R interpreter on that node, if it is<span> run in the ML Services cluster on the edge node</span>. If it calls a RevoScaleR function, then it is executed in a compute environment that is determined by how you set the RevoScaleR compute context. In this case, when you run your R script from an edge node, the possible values of the compute context are as follows:</p>
<ul>
<li>local sequential (<em>local</em>)</li>
<li>local parallel (<em>localpar</em>)</li>
<li>MapReduce</li>
<li>Spark</li>
</ul>
<p>Parallel offers the best performance. The<span> </span>local<span> </span>and<span> </span>localpar<span> </span>options both execute other <kbd>rx</kbd> function calls in a parallel manner across all available cores unless specified otherwise. To do this, the <kbd>rxOptions numCoresToUse</kbd> setting is used, and here is an example:</p>
<pre><strong>rxOptions(numCoresToUse=6)</strong></pre>
<p>If the amount of data to analyze is small, and is a one-off or infrequent analysis, then it is recommended that you stream it directly into the analysis routine using local or localpar. If the amount of data to analyze is on a small or medium scale, and requires repeated or iterative analysis, then copy it to the local filesystem, import it to XDF, and analyze it via local or localpar.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">RevoScaleR in Azure</h1>
                </header>
            
            <article>
                
<p class="">RevoScaleR is a set of powerful Microsoft proprietary functions that are used for practicing data science at scale. RevoScaleR gives extra power when conducting big data analyzes using R, such as data-related functions for import, transformation, manipulation, summarization, visualization, and analysis. Using R and HDInsight provides you with the capability to perform these tasks against very large datasets, in parallel and on distributed file systems. <span>RevoScaleR uses external memory algorithms that allow it to work on one chunk of data at a time, updating results, and proceeding through all available data.</span></p>
<p class="">RevoScaleR functions are provided through the RevoScaleR package, which is available in Azure HDInsight ML Services.  ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">How can we read data into HDInsight using ML Services?</h1>
                </header>
            
            <article>
                
<p class="mce-root">Using RevoScaleR R default commands, we can read data with ML Services on HDInsight. These data types include the following:</p>
<ul>
<li class="mce-root"><span>Reading</span><span> data through <strong>Open Database Connectivity</strong></span> (<strong>ODBC</strong>) <span>data sources</span></li>
<li class="mce-root">Reading in files from other file systems, such as <span>SAS, SPSS, ODBC, Teradata, delimited, and fixed format text</span></li>
<li class="mce-root">Using an internal dataframe as a data source</li>
<li class="mce-root">Processing data from sources that cannot be read natively by R Server</li>
</ul>
<p><span>RevoScaleR is also embedded in Azure HDInsight, Azure DSVMs, and SQL Server. </span>RevoScaleR also includes an extensible framework for writing your own analyzes for big datasets.</p>
<p class="mce-root">The preferred data format is an XDF format. From there, we can do a number of analyzes with HDInsight and ML Services, using R. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">What kind of analyzes can we do with R in ML Services on HDinsight?</h1>
                </header>
            
            <article>
                
<p class="mce-root">We can do summaries, cross-tabs, and create cubes, and conduct modelling such as decision trees and forests, as well as standard R work. To execute code, we will execute the Microsoft R server commands using RStudio. RStudio makes R easier to use. It includes a code editor, as well as debugging and visualization tools. In the following examples, the code exercises and images will be executed using RStudio. We will also use R Notebooks as a tidy way to execute code. An R Notebook is a document with code chunks that can be executed independently and interactively. As we will see throughout the exercises, the output is visible immediately beneath the input. We can visualize ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Reading data from files into Azure HDInsight ML Services</h1>
                </header>
            
            <article>
                
<p class="mce-root">ML Services can read almost all flat text files, such as SPSS, CSV, and TXT files.<br/>
Here is an example where we provide the path direction and read file directory from the given path to R:</p>
<pre class="mce-root">filename &lt;- read.csv ( file = "Filename.csv" )</pre>
<p class="mce-root">We can also import the text file into R and then view the file to read it:</p>
<pre class="mce-root">filename &lt;- rxImport ( "full file path")</pre>
<p class="mce-root">It is crucial to start by checking the location of the working directory in R. It is good practice to confirm your path. The command is executed using the following command:<br/>
<kbd>getwd()</kbd></p>
<p class="mce-root">In our example, the working directory is on the <kbd>D</kbd> drive, and it is the <kbd>Demo</kbd> folder.</p>
<p class="mce-root">To read in a CSV file, we provide the path, and then we read the file path, which is directed toward a variable name. In this example here, the file will be stored in the variable called <kbd>SalesRecordsFile</kbd>:</p>
<pre class="mce-root"> SalesRecordsFile &lt;- read.csv ( "D:/Demo/SalesRecordsFile.csv" , header = TRUE )</pre>
<p class="mce-root">Next, we will take the <kbd>SalesRecordsFile</kbd><span>variable </span>and we will set it to a command to read in a CSV file.</p>
<p class="mce-root">Once we execute the <kbd>SalesRecordsFile</kbd> <span>command,</span> then Microsoft ML Server will read in the <kbd>SalesRecordsFile.csv</kbd> file. </p>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Converting text and CSV files to the preferred XDF format</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">An XDF file is small in size and is compressed, as compared to CSV files. This means that an XDF file can be read and processed much faster than a CSV file. The flat file contains records that have no structured inter-relationship. XDF file formats can only be read by Microsoft ML Server. It is a very efficient way of storing, and querying data stored in flat files. These files are very small in size compared to other files, so they are analyzed quickly, and easily. RStudio can easily handle the task of converting our source text or CSV files into XDF format.</p>
<p class="mce-root CDPAlignLeft CDPAlign">To convert the file, we can use the<span> </span><kbd>rxImport</kbd><span> </span>function, which loads data held in a flat file, such as a text file, to the preferred ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using the new XDF file in Microsoft ML Services</h1>
                </header>
            
            <article>
                
<p class="mce-root">We set the <kbd>SalesRecordsXDF</kbd> variable to hold the path of the inbound data, and to specify where the XDF file has to be written.</p>
<p class="mce-root"/>
<p class="mce-root">We can use the<span> </span><kbd>print</kbd><span> </span>command to find out more about the contents in the variable called <kbd>SalesRecordsXDF</kbd>. When we run the code, we can see the output, which details the number of rows processed and the location. If we want to see the content of the file, we can use the <kbd>rxGetInfo</kbd> command to provide us with some information. In this example, we are going to obtain the first five rows of data.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">XDF versus flat text files</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now that we have looked at a CSV file and an XDF file, which one is better? XDF files can be read and processed so they are stored on the local disk. Microsoft R Server, with a call to <kbd>rxImport()</kbd>, will read an XDF file and decompress it, and then insert it into memory as a dataframe.</p>
<p class="mce-root">The XDF file format is a Microsoft file format. This means it is important to check output and export functionality, because other programs will not be able to read it. The XDF file is aimed at supporting the set of analytical and data processing functions in the RevoScaleR package.</p>
<p class="mce-root">What is the advantage of the file size? For big data, this means the data can be as large as the available disk on the machine without putting any strains ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Reading data from SQL Server</h1>
                </header>
            
            <article>
                
<p class="mce-root">To connect to SQL Server, there is a sequence of events that should be followed:</p>
<ol>
<li class="mce-root">Connect to Microsoft SQL Server</li>
<li class="mce-root">Retrieve data from Microsoft SQL Server</li>
</ol>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Connecting to a SQL Server database</h1>
                </header>
            
            <article>
                
<p class="mce-root">Microsoft ML Services can also read data through <strong>Open Database Connectivity (ODBC)</strong>, which is a well-known and commonly accepted database access method. Initially, the connection string is set up, and it is assigned to a variable. In this example, the variable name holds the connection string. Here is the example code:</p>
<pre class="mce-root">sqlServerConnectionString &lt;- "SERVER=&lt;IP Address goes here&gt;;DATABASE=&lt;database name goes here&gt;;UID=&lt;User Name goes here&gt;; PWD=&lt;Your Password Goes Here&gt;”</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Extracting data from a table retrieving data from Microsoft SQL Server</h1>
                </header>
            
            <article>
                
<p class="mce-root">Once we have set up the connection string information, the next step is to set up a variable to hold the SQL command to retrieve the data. Here is an example piece of code:</p>
<pre class="mce-root">sqlServerDataSource &lt;- RxSqlServerData(sqlQuery = "SELECT * FROM &lt;view name goes here&gt;",connectionString = sqlServerConnectionString)</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Installing R packages on Microsoft ML Services</h1>
                </header>
            
            <article>
                
<p class="mce-root">It is possible to use the same R code in Azure ML Studio, Microsoft ML Server, and in SQL Server machine learning services.</p>
<p class="mce-root">In this example, the<span> </span><kbd>rjson</kbd><span> </span>package allows users to import the data using the <kbd>fromJSON()</kbd> function. If the<span> </span><kbd>rjson</kbd><span> package </span>is not installed on Microsoft ML Server, then you will need to install it. The instructions are as follows:</p>
<ol>
<li class="mce-root">Navigate to the folder where the R tools are installed.</li>
<li class="mce-root">Right-click <kbd>RGui.exe</kbd>, and select <span class="packt_screen">Run as administrator</span>. If you do not have the required permissions, contact the database administrator and provide a list of the packages you need.</li>
<li class="mce-root">From the command line, if you know the package name, type: <kbd>install.packages("rjson")</kbd>.</li>
<li class="mce-root">Note that double quotation ...</li></ol></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Analyzing and summarizing data in Microsoft ML Services</h1>
                </header>
            
            <article>
                
<p class="mce-root">We can analyze and summarize our data using different types of statistics. Some statistics are more basic, and we start from using simple crosstabs. Then, we can move onto more complex statistics.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Cross tabs and univariate statistics</h1>
                </header>
            
            <article>
                
<p class="mce-root">Cross tabs offer a function that aids the exploration of survey data through simple tabulations of respondent counts and proportions, including the ability to specify the following:</p>
<ul>
<li class="mce-root">A frequency count or a row/column/joint/total table proportion</li>
<li class="mce-root">Multiple row and column variables</li>
<li class="mce-root">All margins, only grand margins, or no margins</li>
</ul>


<p class="mce-root">To create crosstabs, the <kbd>rxCrossTabs()</kbd> <span>function </span>is used.<span> </span><kbd>rxCrossTabs()</kbd> is also used to compute sums according to combinations of different variables:</p>
<pre class="mce-root">rxCrossTabs(formula, data, …)</pre>
<p class="mce-root">The <kbd>rxCrossTabs</kbd> function uses a formula containing the variables that you want to cross tabulate. It also has a reference to the data, which refers to the dataset in which you want to look for variables ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Working with cubes of data</h1>
                </header>
            
            <article>
                
<p class="mce-root">One important feature of analysis is the aggregation of data. In Microsoft ML Server, the <kbd>rxCube()</kbd> <span>function </span>is used when we want to aggregate data for further analysis within R.<br/>
<br/>
<kbd>rxCube()</kbd> performs a very similar function to <kbd>rxCrossTabs()</kbd>. <kbd>rxCube()</kbd> helps with the analysis by computing metrics such as tabulated sums or means. <kbd>rxCube()</kbd> produces the sums or means in long format rather than a table. Example syntax for <kbd>rxCube</kbd> is as follows:</p>
<pre class="mce-root">rxCube(formula, data, …)</pre>
<p class="mce-root">The code shows that <kbd>rxCube</kbd> requires a formula containing the variables to cross-tabulate. It differs from <kbd>rxCrossTabs()</kbd> in the default value of the means argument (true for <kbd>rxCube()</kbd>; false for <kbd>rxCrossTabs()</kbd>). As with <kbd>rxCrossTabs</kbd>, the data item refers to the dataset in which you want to look for variables specified in the formula. Here is an example piece of code, using the Iris dataset, as before:</p>
<pre>IrisDataCube &lt;- rxCube(Petal.Width ~ Species, data = iris)</pre>
<p class="mce-root">In order to clarify its use, the following demonstrates a sample output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/54569ef2-d1fb-410e-8809-8db46d43934c.png" style="width:32.83em;height:23.25em;" width="492" height="347"/></p>
<p class="mce-root">Now that we have seen how to do some preliminary analysis, we can further investigate the data by doing some grouping. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Grouping data using Microsoft ML Server and R</h1>
                </header>
            
            <article>
                
<p class="mce-root">In Business Intelligence and analytics, many data operations are completed on grouped data, defined by variables. In Microsoft ML Services, there is an additional enhanced R formula, called <kbd>rxSummary</kbd>, which summarizes data, which is a good starting point when investigating data.<span> </span><kbd>rxSummary</kbd> works by computing summary statistics that include a variable mean.</p>
<p class="mce-root">Here is an example of the output using <kbd>rxSummary</kbd> and the Iris dataset:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img src="Images/85e658c8-f540-4daa-b5d9-17f951e0e43c.png" style="width:35.58em;height:14.25em;" width="527" height="211"/></p>
<p class="mce-root">The summary focuses on one of the columns, <kbd>Petal.Length</kbd>. It produces the same information that we expect from the <kbd>summary</kbd> command in R.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Computing quantiles with R in Microsoft ML Server</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">In Microsoft ML Server, the <kbd>rxQuantile</kbd> <span>function </span>is used to quickly compute approximate quantiles. Note that this computation doesn't include any type of sorting. The following piece of code uses <kbd>rxQuantile</kbd> on the petal length of the Iris dataset:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><br/>
<img src="Images/9d9ad502-4eba-4dfd-a55f-fcaea487385a.png" style="width:20.42em;height:3.83em;" width="320" height="60"/></p>
<p class="mce-root CDPAlignLeft CDPAlign">The quantile calculation provides the quantiles for the data and prints it out.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Logistic regression in Microsoft ML Services</h1>
                </header>
            
            <article>
                
<p class="mce-root">Logistic regression is a standard tool for modeling data with a binary response variable. In R, you fit a logistic regression using the <kbd>glm</kbd> function, specifying a binomial family and the logit link function. In Microsoft ML Services, <kbd>rxGlm</kbd> is used for the same purpose, and in the same way:</p>
<pre class="mce-root">irisGLM &lt;- rxGlm(Petal.Width~ Species,family = Gamma,dropFirst = TRUE,data = iris)</pre>
<p>Then, we can type in the variable name in order to see the result. Here is a screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/8c64dfca-cb72-4451-aa87-5dcf602aec68.png" style="width:32.83em;height:19.42em;" width="572" height="338"/></p>
<p>To interpret the coefficients better, we can transform them back to the original scale of the dependent variable. To do this, we execute the ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Predicting values with the model</h1>
                </header>
            
            <article>
                
<p class="mce-root">If the input dataset is the same as the dataset used to fit the <kbd>rxLinMod</kbd> object, the resulting predictions are the fitted values for the model. If the input dataset is a different dataset, the resulting predictions are true predictions of the response for the new data from the original model. As you can see from the following example, the residuals for the predicted values can be obtained by setting the <kbd>computeResiduals</kbd> flag to <kbd>TRUE</kbd>:</p>
<pre class="mce-root">rxPredict(irisGLM,data = iris,writeModelVars = TRUE,<span>computeResiduals  = TRUE,</span>overwrite = TRUE)</pre>
<p>Next, we use <kbd>rxPredict</kbd> to obtain the fitted values, prediction standard errors, and confidence intervals. By setting <kbd>writeModelVars</kbd> to <kbd>TRUE</kbd>, the variables used in the model will also be included in the output dataset. Sample output is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/aa69a101-6000-4b50-95dc-db782aa60805.png" width="910" height="380"/></p>
<p>We can view the summary of the <kbd>irisGLM</kbd> model here:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/4e45b9e4-085e-40ee-9ce1-34038a19ebec.png" style="width:45.50em;height:42.50em;" width="670" height="625"/></p>
<p>The output shows that these are highly significant p-values, which means that the model looks like a good fit.</p>
<p>However, we can check that the model is sound by looking at the ratio between the residual deviance and the residual degrees of freedom, which is 10.2/147, giving us a result of 0.06. This means that the model is quite under-dispersed. Another option is to redo the <kbd>irisGLM</kbd> model <span>using a binomial instead of a gamma family</span>.</p>
<p>In order to understand the data better, it is possible to visualize it using default R and custom functionality in Microsoft ML Services.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Visualizing data</h1>
                </header>
            
            <article>
                
<p class="mce-root">Microsoft ML Services has facilities for producing graphs using R as the visualization engine. It is possible for you to provide a variety of charts and dashboards that represent both univariate and multivariate numerical and categorical data in a straightforward manner. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating histograms</h1>
                </header>
            
            <article>
                
<p class="mce-root"><br/>
<kbd>rxHistogram()</kbd> is used to create a histogram for the data. Here is an example of the syntax for the Iris dataset:</p>
<pre class="mce-root">rxHistogram(~Petal.Width, data = iris)</pre>
<p class="mce-root">You can see in the formula that the simplest case is a formula with only a single variable to the right-hand side of the <kbd>~</kbd>.</p>
<p class="mce-root">As before, the Iris dataset is the data used here, and this is the part of the formula in which you want to specify the dataset you are using. Here is an example of the output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/527c2aa1-837e-4677-a1fe-88899ee27a45.png" style="width:24.00em;height:22.33em;" width="485" height="450"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>It is very simple to create a histogram with a single line of code.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating line plots</h1>
                </header>
            
            <article>
                
<p>A histogram is only one way of visualizing the data. Another example is the <kbd>rxLinePlot</kbd> example, which creates the line of a scatter plot using data. <span>For this function, this formula should have one variable on the left-hand side of the <kbd>~</kbd> that reflects the <em>y</em> axis, and one variable on the right-hand side of the <kbd>~</kbd> that reflects the <em>x</em> axis. Here is an example of the line plot:</span></p>
<p class="mce-root CDPAlignCenter CDPAlign"><img src="Images/1118ee8a-a9d4-4256-83db-d9f138264321.png" style="width:22.83em;height:20.58em;" width="490" height="445"/></p>
<p class="mce-root CDPAlignLeft CDPAlign">We can also transform subsets of data using other features and functionality in Microsoft ML Services, and then revisualize the data.</p>
<p>Once we can see and understand our data, we can enrich it further by using additional Microsoft ML Services functionalities. ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Enriching data for analysis</h1>
                </header>
            
            <article>
                
<p class="mce-root">With big data solutions, sometimes the data needs to be transformed and processed into smaller chunks due to its sheer size. In order to deal with this problem, Microsoft have introduced some functionality to help. This section will cover the features that are designed to assist with big data issues.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">rxDataSteps</h1>
                </header>
            
            <article>
                
<p class="mce-root">The <kbd>rxDataStep</kbd> function can be used to process data in chunks. It is one of the important data transformation functions in Microsoft ML Services.</p>
<p class="mce-root">The <kbd>rxDataStep</kbd> function can be used to create and transform subsets of data. The <kbd>rxDataStep</kbd> function processes data one chunk at a time, reading from one data source and writing to another. <kbd>rxDataStep</kbd> allows you to modify existing columns or add new columns to the data. It can also enrich analysis by working with your columns and rows, and by filtering and excluding them before working with the data further.</p>
<p class="mce-root">A common use of <kbd>rxDataStep</kbd> is to create a new dataset with a subset of rows and variables, as follows:</p>
<pre>rxDataStep(<span class="pl-v">inData</span> <span class="pl-k">=</span> <span class="pl-smi">iris</span>, <span class="pl-v">outFile</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>myIrisXDF.xdf<span class="pl-pds">"</span></span>)</pre>
<p class="mce-root">In the previous piece ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have examined the machine learning process for Microsoft ML Services on HDInsight. We have reviewed how to ingest data, how to clean it, how to model it, and how to visualize it.</p>
<p>The final step is to ensure that HDInsight is torn down when you have stopped using it. HDInsight is charged by the minute and it will cost you money to leave it running. It is recommended that you save code and tear everything down when you no longer need it.</p>
<p>If you are simply wanting to run code and learn how to use Microsoft ML Services, the previous code samples will also work on Microsoft ML Server in Visual Studio on the DSVM.</p>


            </article>

            
        </section>
    </div>



  </body></html>