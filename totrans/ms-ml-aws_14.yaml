- en: Working with AWS Comprehend
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 AWS Comprehend
- en: As a data scientist, knowing how machine learning algorithms work is very important.
    However, it may not be efficient to build your own machine learning models to
    perform certain tasks, as it takes a lot of effort and time to design an optimal
    algorithm. In [Chapter 10](b83ce0ca-e2d7-43f5-9e82-21edb54250c9.xhtml), *Working
    with AWS Comprehend*, [Chapter 11](b6601397-10a0-4a94-ba9f-32b5bfcdbb06.xhtml), *Using
    AWS Rekognition* and [Chapter 12](f9e097f0-ee26-456d-9360-7d0d3743e3a6.xhtml), *Building
    Conversational Interfaces Using AWS Lex*, we will look at the **machine learning
    as a s****ervice** (**MLaaS**) product that you can access in AWS. These products
    allow you to use models that are pre-trained in AWS using either the AWS dashboard
    or API calls.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，了解机器学习算法的工作原理非常重要。然而，构建自己的机器学习模型来执行某些任务可能并不高效，因为这需要大量的努力和时间来设计一个最优算法。在第
    10 章 [使用 AWS Comprehend](b83ce0ca-e2d7-43f5-9e82-21edb54250c9.xhtml)、第 11 章 [使用
    AWS Rekognition](b6601397-10a0-4a94-ba9f-32b5bfcdbb06.xhtml) 和第 12 章 [使用 AWS Lex
    构建对话界面](f9e097f0-ee26-456d-9360-7d0d3743e3a6.xhtml) 中，我们将探讨您可以在 AWS 中访问的 **机器学习即服务（MLaaS**）产品。这些产品允许您使用在
    AWS 中预先训练的模型，无论是通过 AWS 仪表板还是 API 调用。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introducing Amazon Comprehend
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 Amazon Comprehend
- en: Accessing Amazon Comprehend
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问 Amazon Comprehend
- en: Testing entity recognition using Comprehend
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Comprehend 测试实体识别
- en: Testing sentiment analysis using Comprehend
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Comprehend 测试情感分析
- en: Implementing text classification using Comprehend APIs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Comprehend API 实现文本分类
- en: Introducing Amazon Comprehend
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Amazon Comprehend
- en: Amazon Comprehend is a service available in AWS that offers **natural language
    processing** (**NLP**) algorithms. NLP is a field in machine learning that analyzes
    human (natural) languages and can identify various attributes of these languages.
    In most of our previous chapters, we looked at examples of structured data. The
    data had predefined features and was organized as rows of observations. However,
    a natural language dataset is more complicated to process. Such datasets are called
    **unstructured datasets**, as the structure of the features is not well-defined.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Comprehend 是 AWS 上提供的一项服务，它提供了自然语言处理（**NLP**）算法。NLP 是机器学习中的一个领域，它分析人类（自然）语言，并可以识别这些语言的多种属性。在我们之前的多数章节中，我们查看了一些结构化数据的示例。这些数据具有预定义的特征，并按观察值的行组织。然而，自然语言数据集更难以处理。这样的数据集被称为
    **非结构化数据集**，因为特征的结构没有很好地定义。
- en: Hence, algorithms are needed to extract structure and information from a text
    document. For example, a natural language has words that are arranged using a
    grammatical structure. Natural-language sentences also have keywords, which contain
    more information regarding places, people, and other details. They also have a
    context, which is very hard to learn, and the same words may convey different
    meanings based on how they are arranged.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，需要算法从文本文档中提取结构和信息。例如，自然语言中的单词是按照语法结构排列的。自然语言句子也有关键词，它们包含有关地点、人物和其他细节的更多信息。它们还有一个上下文，这非常难以学习，并且相同的单词根据它们的排列方式可能传达不同的含义。
- en: The field of NLP studies how to process these text documents and extract information
    from them. NLP not only involves clustering and classifying the documents, but
    also preprocessing the data to extract important keywords and entity information
    from the text. Based on the domain of the text documents, different preprocessing
    is required, as the styles of written documents change. For example, medical and
    legal texts are written with a lot of jargon and are well-structured. However,
    if you are using an NLP algorithm to process Twitter data, the text may be composed
    of poor grammar and hashtags. Hence, based on the domain of the data, you need
    a separate process to preprocess the data and how the models should be trained.
    Domain expertise is generally required when training NLP models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: NLP 领域研究如何处理这些文本文档并从中提取信息。NLP 不仅涉及对文档进行聚类和分类，还包括对数据进行预处理，以从文本中提取重要的关键词和实体信息。根据文本文档的领域，需要不同的预处理，因为书面文档的风格会变化。例如，医学和法律文本包含大量术语，并且结构良好。然而，如果您使用
    NLP 算法处理 Twitter 数据，文本可能由语法较差的句子和标签组成。因此，根据数据的领域，您需要单独的过程来预处理数据以及如何训练模型。在训练 NLP
    模型时通常需要领域专业知识。
- en: AWS Comprehend provides tools to both train machine learning models and use
    pre-trained models to perform NLP tasks. It provides real-time dashboards to analyze
    text data and also provides tools to train machine learning algorithms using their
    UI.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Comprehend 提供了训练机器学习模型和使用预训练模型执行自然语言处理任务的工具。它提供了实时仪表板来分析文本数据，同时也提供了使用其用户界面训练机器学习算法的工具。
- en: In this chapter, we will explore four NLP tasks that can be accomplished using
    AWS Comprehend. We will also suggest when a data scientist should employ ready-to-use
    tools and when they should invest time in building their own machine learning
    algorithms.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨可以使用 AWS Comprehend 完成的四个自然语言处理任务。我们还将建议数据科学家何时应使用现成的工具，何时应投入时间构建自己的机器学习算法。
- en: Accessing AmazonComprehend
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问 AmazonComprehend
- en: '[Amazon Comprehend](https://aws.amazon.com/comprehend/) is available to use
    on the AWS Console. When you log into the AWS Management Console, search for Amazon
    Comprehend in the AWS Services box. Selecting Amazon Comprehend will take you
    to the AWS Comprehend start screen, as shown in the following screenshot:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[Amazon Comprehend](https://aws.amazon.com/comprehend/) 可在 AWS 控制台中使用。当您登录
    AWS 管理控制台时，在 AWS 服务框中搜索 Amazon Comprehend。选择 Amazon Comprehend 将带您进入 AWS Comprehend
    启动屏幕，如下面的截图所示：'
- en: '![](img/f00d8f41-3c7c-4046-bfed-4f8cf06da30d.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f00d8f41-3c7c-4046-bfed-4f8cf06da30d.png)'
- en: Click on Launch Comprehend when you get to this screen, which will take you
    to the AWS Comprehend dashboard. You should be able to access the algorithms used
    in the following sections from this page.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当您到达此屏幕时，请单击“启动 Comprehend”，这将带您进入 AWS Comprehend 仪表板。您应该能够从该页面访问以下部分使用的算法。
- en: Named-entity recognition using Comprehend
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Comprehend 进行命名实体识别
- en: '**Named-entity recognition** (**NER**) is a field in NLP that tags mentions
    of named entities in unstructured text. Named entities are names of people, places,
    organizations, and so on. For example, consider the following sentence:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**命名实体识别**（**NER**）是自然语言处理中的一个领域，它对非结构化文本中提到的命名实体进行标记。命名实体包括人名、地名、组织等名称。例如，考虑以下句子：'
- en: Tim Cook traveled to New York for an Apple store opening.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Tim Cook 前往纽约参加苹果商店的开业。
- en: In this sentence, there are three named entities. Tim Cook is the name of a
    person, New York is the name of a city (location), and Apple is the name of an
    organization. Hence, we need an NER model that can detect these entities. Note
    that Apple is an ambiguous noun, as it can be the name of a company or a fruit.
    The NER algorithm should understand the context in which the term is used and
    identify it accordingly.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个句子中，有三个命名实体。Tim Cook 是一个人的名字，New York 是一个城市的名称（位置），Apple 是一个组织的名称。因此，我们需要一个能够检测这些实体的
    NER 模型。请注意，Apple 是一个歧义名词，因为它可以是公司或水果的名称。NER 算法应理解术语使用的上下文，并据此识别。
- en: 'AWS Comprehend offers a good NER tool that can be used to identify entities.
    This tool can be used in real-time via their dashboard or using their APIs. AWS
    Comprehend detects the following entities:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Comprehend 提供了一个很好的 NER 工具，可以用来识别实体。此工具可以通过他们的仪表板或使用他们的 API 在实时中使用。AWS Comprehend
    检测以下实体：
- en: '**Commercial Item**: Brand names'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**商品**：品牌名称'
- en: '**Date**: Dates in different formats'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日期**：不同格式的日期'
- en: '**Event**: Names of concerts, festivals, elections, and so on'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件**：音乐会、节日、选举等的名称'
- en: '**Location**: Names of cities, countries, and so on'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**位置**：城市、国家等的名称'
- en: '**Organization**: Names of companies and governmental organizations'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组织**：公司和国有组织的名称'
- en: '**Person**: Names of people'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人物**：人名'
- en: '**Quantity**: Commonly used units used to quantify a number'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数量**：用于量化数字的常用单位'
- en: '**Title**: Names of movies, books, and so on'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标题**：电影、书籍等的名称'
- en: 'To access the AWS dashboard for NER, go to the Real-time Analysis tab in the
    menu. You can then add input text in the text box provided on the page. The following
    screenshot demonstrated how Amazon Comprehend performs the NER task:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问 AWS 仪表板中的 NER，请转到菜单中的实时分析选项卡。然后您可以在页面提供的文本框中添加输入文本。以下截图展示了 Amazon Comprehend
    如何执行 NER 任务：
- en: '![](img/b9c4ab81-b32e-4ca8-be65-168e7402f1b9.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b9c4ab81-b32e-4ca8-be65-168e7402f1b9.png)'
- en: You can see that the NER tool in Amazon Comprehend automatically labels the
    entities in the sentence. Along with labeling the categories of the entities,
    it also gives us a confidence score. This score can be used to determine whether
    we trust the results from the tool.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，Amazon Comprehend 中的 NER 工具会自动标记句子中的实体。除了标记实体的类别外，它还给出了一个置信度分数。这个分数可以用来确定我们是否信任工具的结果。
- en: The NER tool in Amazon Comprehend can also be accessed using the API provided
    by AWS.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊Comprehend中的NER工具也可以通过AWS提供的API进行访问。
- en: 'The following code shows how you can call the Comprehend tool to get the entity
    scores:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何调用Comprehend工具来获取实体分数：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You use the `boto3` package, which is an AWS tool package for Python. We first
    initialize the Comprehend client and then pass our text to the client to get a
    JSON response with information about the named entities. In the following code
    block we can see the response we receive from the client:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用的是`boto3`包，这是一个Python的AWS工具包。我们首先初始化Comprehend客户端，然后将我们的文本传递给客户端以获取包含有关命名实体信息的JSON响应。在以下代码块中，我们可以看到我们从客户端收到的响应：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Thus, parsing the JSON can get us information regarding the entities in the
    text.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，解析JSON可以让我们了解文本中的实体信息。
- en: You can also train a custom NER algorithm in AWS Comprehend using the Customization
    | Custom entity recognition option in the left-hand side menu. You can add training
    sample documents and a list of annotations for entities. The algorithm automatically
    learns how to label these entities in the correct context and updates the existing
    models.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在AWS Comprehend中使用自定义NER算法，通过左侧菜单中的自定义实体识别选项进行训练。你可以添加训练样本文档和实体标注列表。算法会自动学习如何在正确的上下文中标记这些实体，并更新现有模型。
- en: NER algorithms are applied in various applications. One of their important applications
    is in the field of News Aggregation. You can automatically generate tags for a
    document so that users can search for documents based on the entities in them.
    NER is also useful in the field of recommendation algorithms, where NER is used
    to detect keywords and we can create a news-recommendation algorithm. We can build
    a collaborative filtering model that can recommend articles about entities that
    readers of a current article may also be interested in.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: NER算法在各种应用中被应用。它们的一个重要应用领域是新闻聚合。你可以自动为文档生成标签，以便用户可以根据文档中的实体进行搜索。NER在推荐算法领域也非常有用，其中NER用于检测关键词，我们可以创建一个新闻推荐算法。我们可以构建一个协同过滤模型，推荐关于当前文章读者可能感兴趣的实体的文章。
- en: Sentiment analysis using Comprehend
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Comprehend进行情感分析
- en: Sentiment analysis algorithms analyze text and categorize it based on the sentiments
    or opinions in the text. Sentiment analysis detects subjective opinions that are
    expressed in text. For example, reviews on Amazon Marketplace give a good or a
    bad review of a product. Using sentiment analysis, we can detect whether a review
    is positive or negative. We can also recognize emotional nuances in a review,
    such as whether the reviewer was angry, excited, or neutral about a given product.
    In this age of social media, we have a large number of avenues to voice our opinions
    on products, movies, politics, and so on. Data scientists use sentiment analysis
    algorithms to analyze a large amount of data and extract opinions regarding a
    certain entity based on unstructured text data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析算法分析文本并根据文本中的情感或观点对其进行分类。情感分析检测文本中表达的主观观点。例如，亚马逊市场中的评论给出了对产品的良好或不良评价。使用情感分析，我们可以检测评论是正面还是负面。我们还可以识别评论中的情感细微差别，例如评论者对特定产品是愤怒、兴奋还是中立。在这个社交媒体时代，我们有大量途径来表达我们对产品、电影、政治等的观点。数据科学家使用情感分析算法分析大量数据，并根据非结构化文本数据提取关于某个实体的观点。
- en: 'Amazon Comprehend makes the task of sentiment analysis easy by providing a
    real-time dashboard to analyze the sentiment in text. You can access the Sentiment
    Analysis dashboard the same way you did for the NER algorithm. We''ll provide
    two examples of how Comprehend can perform sentiment analysis on our data. I looked
    at two reviews on Amazon that were positive and negative and used Comprehend to
    perform sentiment analysis on them. Consider the first example, as seen in the
    following screenshot:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊Comprehend通过提供实时仪表板来分析文本中的情感，使得情感分析任务变得简单。你可以像访问NER算法一样访问情感分析仪表板。我们将提供两个示例，说明Comprehend如何对我们的数据进行情感分析。我查看了两篇亚马逊的评论，一篇是正面的，另一篇是负面的，并使用Comprehend对它们进行了情感分析。考虑以下截图中的第一个示例：
- en: '![](img/a7961739-0c56-4aee-ac29-d97eff366f0d.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a7961739-0c56-4aee-ac29-d97eff366f0d.png)'
- en: 'In this example, the reviewer has used words such as disappointed. These terms
    have negative connotations. However, sentiment analysis algorithms can detect
    that the user also used a negative before this word and correctly predict that
    this text has a positive sentiment. Similarly, consider the following example:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，评论者使用了诸如失望之类的词语。这些术语具有负面含义。然而，情感分析算法可以检测到用户在这个词之前也使用了负面词汇，并正确预测这段文本具有积极的情感。同样，考虑以下例子：
- en: '![](img/fc145b08-2999-4f2d-b8d4-4a8c31ac9089.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fc145b08-2999-4f2d-b8d4-4a8c31ac9089.png)'
- en: You can see that the reviewer was initially happy regarding the product, but
    then had issues. Hence, the reviewer was not happy with the product. Hence, the
    sentiment analysis algorithm correctly predicts that the confidence of the review
    being negative is 70%. However, it also predicts that there are some mixed sentiments
    in this review and provides confidence of 22%. We use the soft-max methodology
    to pixel the sentiment with the highest confidence.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，评论者最初对产品感到满意，但后来出现了问题。因此，评论者对产品不满意。因此，情感分析算法正确预测评论为负面的置信度为 70%。然而，它还预测在这篇评论中存在一些混合情感，并提供了
    22% 的置信度。我们使用 softmax 方法对具有最高置信度的情感进行像素化。
- en: 'Sentiment analysis can also be accessed using the Amazon API. Here, we provide
    example code that shows how we can call the sentiment analysis API using the `boto3`
    Python package:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析也可以通过 Amazon API 获取。在这里，我们提供了示例代码，展示了如何使用 `boto3` Python 包调用情感分析 API：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This API call returns the following JSON with the data regarding the sentiment
    of the text:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此 API 调用返回以下 JSON，其中包含有关文本情感的资料：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can use the API to classify a large number of reviews to detect what the
    overall sentiment is for a given product.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 API 对大量评论进行分类，以检测给定产品的整体情感。
- en: Sentiment analysis is a very powerful tool that companies use to analyze social
    media data to detect the overall sentiment regarding their products and also to
    determine why users are unhappy with their products. Movie review aggregators,
    such as Rotten Tomatoes, also use them to detect whether reviews are positive
    or negative so that they can classify them and generate aggregated scores.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析是一个非常强大的工具，公司用它来分析社交媒体数据，以检测对其产品的整体情感，并确定用户为何对其产品不满意。电影评论聚合器，如烂番茄，也使用它来检测评论是正面还是负面，以便它们可以对它们进行分类并生成汇总评分。
- en: Text classification using Comprehend
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Comprehend 进行文本分类
- en: Text classification is the process of classifying text documents into categories.
    Similar to the classification algorithms that we studied in [Chapter 2](9163133d-07bc-43a6-88e6-c79b2187e257.xhtml), *Classifying
    Twitter Feeds with Naive Bayes* to [Chapter 6](c940bfe6-b849-4179-b8f8-65e5d44652d6.xhtml),
    *Analyzing Visitor Patterns to Make Recommendations*, text classification algorithms
    also generate models based on labeled training observations. The classification
    model can then be applied to any observation to predict its class. Moreover, the
    same algorithms that we studied in the previous chapters, such as [Chapter 2](9163133d-07bc-43a6-88e6-c79b2187e257.xhtml), *Classifying
    Twitter Feeds with Naive Bayes*, [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml), *Predicting
    House Value with Regression Algorithms*, and [Chapter 4](af506fc8-f482-453e-8162-93a676b2e737.xhtml), *Predicting
    User Behavior with Tree-Based Methods,* can also be used for text classification.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类是将文本文档分类到类别中的过程。与我们在第 2 章[使用朴素贝叶斯分类 Twitter 流](9163133d-07bc-43a6-88e6-c79b2187e257.xhtml)和第
    6 章[分析访问模式以提供建议](c940bfe6-b849-4179-b8f8-65e5d44652d6.xhtml)中研究的分类算法类似，文本分类算法也基于标记的训练观察结果生成模型。然后，分类模型可以应用于任何观察结果以预测其类别。此外，我们在前几章中研究的相同算法，如第
    2 章[使用朴素贝叶斯分类 Twitter 流](9163133d-07bc-43a6-88e6-c79b2187e257.xhtml)、第 3 章[使用回归算法预测房屋价值](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml)和第
    4 章[使用基于树的预测用户行为](af506fc8-f482-453e-8162-93a676b2e737.xhtml)，也可以用于文本分类。
- en: 'Text data is unstructured data. Hence, we need to generate features from text
    documents so that those features can be used as input for our classification model.
    For text datasets, features are generally terms in the document. For example,
    consider the following sentence:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据是无结构数据。因此，我们需要从文本文档中生成特征，以便这些特征可以作为我们分类模型的输入。对于文本数据集，特征通常是文档中的术语。例如，考虑以下句子：
- en: Tim Cook traveled to New York for an Apple store opening.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 蒂姆·库克前往纽约参加苹果商店的开业。
- en: 'Let''s consider the class of this document as `Technology`. This sentence will
    be translated into structured data, as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑该文档的类别为`Technology`。此句子将被翻译成以下结构化数据：
- en: '| `Tim Cook` | `traveled` | `to` | `New York` | `Apple` | `Store` | `Opening`
    | `Microsoft` | `Google` | `Class` |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| `Tim Cook` | `traveled` | `to` | `New York` | `Apple` | `Store` | `Opening`
    | `Microsoft` | `Google` | `Class` |'
- en: '| `1` | `1` | `1` | `1` | `1` | `1` | `1` | `0` | `0` | `Technology` |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| `1` | `1` | `1` | `1` | `1` | `1` | `1` | `0` | `0` | `Technology` |'
- en: Each term will be considered a feature in the dataset. Hence, for a large dataset
    with many documents, the feature set can be as large as the lexicon of that language.
    The value of the features is set to `0` or `1` based on whether that term exists
    in that document. As our example contains words such as `Tim Cook` and `New York`,
    the value of those features for this observation is set to `1`. As the terms Microsoft
    and Google are not present in the sentence, the value of those features is set
    to `0`. The `Class` variable is set to `Technology`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 每个术语都将被视为数据集中的特征。因此，对于包含许多文档的大型数据集，特征集可以与该语言的词汇表一样大。特征值根据该术语是否存在于该文档中设置为`0`或`1`。由于我们的示例包含诸如`Tim
    Cook`和`New York`之类的单词，这些特征的观察值设置为`1`。由于Microsoft和Google这两个术语在句子中不存在，这些特征的值设置为`0`。`Class`变量设置为`Technology`。
- en: In this section, we will show a step-by-step methodology on how to train custom
    classifiers on Comprehend. We'll use a popular text classification dataset called
    **20 Newsgroups** to generate a machine learning model that can mark a review
    as positive or negative. The dataset can be downloaded from [https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups](https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示如何在Comprehend上逐步训练自定义分类器的方法。我们将使用一个流行的文本分类数据集**20 Newsgroups**来生成一个机器学习模型，该模型可以标记评论为正面或负面。数据集可以从[https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups](https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups)下载。
- en: 'The dataset can be downloaded as separate text files that are organized into
    20 folders. Each folder name represents the category of documents in the folder. The
    dataset is a publicly available dataset. It contains news articles that are categorized
    into the following categories:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以下载为单独的文本文件，这些文件组织在20个文件夹中。每个文件夹的名称代表文件夹中文档的类别。该数据集是一个公开可用的数据集，它包含被分类到以下类别的新闻文章：
- en: '`alt.atheism`'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alt.atheism`'
- en: '`comp.graphics`'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comp.graphics`'
- en: '`comp.os.ms-windows.misc`'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comp.os.ms-windows.misc`'
- en: '`comp.sys.ibm.pc.hardware`'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comp.sys.ibm.pc.hardware`'
- en: '`comp.sys.mac.hardware`'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comp.sys.mac.hardware`'
- en: '`comp.windows.x`'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comp.windows.x`'
- en: '`misc.forsale`'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`misc.forsale`'
- en: '`rec.autos`'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rec.autos`'
- en: '`rec.motorcycles`'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rec.motorcycles`'
- en: '`rec.sport.baseball`'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rec.sport.baseball`'
- en: '`rec.sport.hockey`'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rec.sport.hockey`'
- en: '`sci.crypt`'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sci.crypt`'
- en: '`sci.electronics`'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sci.electronics`'
- en: '`sci.med`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sci.med`'
- en: '`sci.space`'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sci.space`'
- en: '`soc.religion.christian`'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`soc.religion.christian`'
- en: '`talk.politics.guns`'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`talk.politics.guns`'
- en: '`talk.politics.mideast`'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`talk.politics.mideast`'
- en: '`talk.politics.misc`'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`talk.politics.misc`'
- en: '`talk.religion.misc`'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`talk.religion.misc`'
- en: 'You can use the following steps to train the classifier:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下步骤来训练分类器：
- en: 'The first step is to download and preprocess the data into a format that is
    readable by the Comprehend tools. Comprehend requires the training data to be
    in the following format in CSV (comma-separated values):'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是将数据下载并预处理成Comprehend工具可读的格式。Comprehend要求训练数据以以下CSV（逗号分隔值）格式：
- en: '| **Category** | **Document** |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| **类别** | **文档** |'
- en: Hence, once you download the dataset, convert the data into the preceding format
    and upload it to your S3 bucket.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一旦您下载了数据集，将其转换为上述格式并上传到您的S3存储桶。
- en: You can access the Custom Classification tool on the Comprehend dashboard, on
    the left-hand side under the Customization tab. To train the model, you have to
    click on the Train Classifier option. Note that Comprehend allows you to train
    your machine learning models and store them on this dashboard so that you can
    use them in the future.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以在Comprehend仪表板的左侧自定义标签页下访问自定义分类工具。要训练模型，您必须点击“训练分类器”选项。请注意，Comprehend允许您在此仪表板上训练您的机器学习模型并将它们存储起来，以便您将来使用。
- en: 'When you click on the Train Classifier option, you will see the following screenshot:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当您点击“训练分类器”选项时，您将看到以下截图：
- en: '![](img/787277e7-a142-425a-8ee4-0d946a21b8ab.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/787277e7-a142-425a-8ee4-0d946a21b8ab.png)'
- en: 'Name the classifier and select the language of the documents. Add your S3 location,
    where the training CSV document is stored. After you select the correct role,
    you can tag the classifier with relevant values, which can help you to search
    them in the future. Once you have added all the information, click on Train classifier:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为分类器命名并选择文档的语言。添加存储训练CSV文档的S3位置。选择正确的角色后，您可以给分类器添加相关标签，这有助于您在将来搜索它们。一旦您添加了所有信息，请点击训练分类器：
- en: '![](img/4d8e2c52-835f-4526-a351-5064fe5b913f.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d8e2c52-835f-4526-a351-5064fe5b913f.png)'
- en: 'You will be taken back to the dashboard screen where you will see that the
    classifier training is in progress. Once the training is done, the status of the
    classifier will be marked as Trained:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将被带回到仪表板屏幕，您将看到分类器训练正在进行。一旦训练完成，分类器的状态将被标记为已训练：
- en: '![](img/d08fd414-7ac7-4685-97a9-1479bba25557.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d08fd414-7ac7-4685-97a9-1479bba25557.png)'
- en: 'You can then click on the classifier to see the evaluation metrics of the model.
    As you can see, our classification model has an accuracy of 90%:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以点击分类器查看模型的评估指标。如您所见，我们的分类模型准确率为90%：
- en: '![](img/cc1fe664-413f-46be-af89-870f0a42ce6a.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc1fe664-413f-46be-af89-870f0a42ce6a.png)'
- en: As we now have a classifier that is trained, you can get predictions for any
    document using this model. We create a `test.csv` file that contains 100 documents
    to get predictions from this model. We preprocess the data to create a CSV file
    with one document per line. To start the prediction process, click on the Create
    Job option shown on the preceding screen.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们现在有一个经过训练的分类器，您可以使用此模型对任何文档进行预测。我们创建一个包含100个文档的`test.csv`文件，以从该模型获取预测。为了开始预测过程，请点击前一个屏幕上显示的“创建作业”选项。
- en: 'This will take you to another screen, where you can add details on which file
    you want to use for testing and where the output should be stored:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这将带您进入另一个屏幕，您可以在其中添加有关您想要用于测试的文件以及输出应存储位置的详细信息：
- en: '![](img/5b2840cf-efee-495c-8a5b-e612436a9d68.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b2840cf-efee-495c-8a5b-e612436a9d68.png)'
- en: 'On the Create analysis job screen, add the details about the classifier to
    be used: where the input data is stored (on S3) and an S3 location where the output
    is stored. You can either specify the input data as one document per line or one
    document per file and point the input data to the directory that contains all
    the files. In our example, since the `test.csv` file contains one document on
    each line, we use that format.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建分析作业的屏幕上，添加有关要使用的分类器的详细信息：输入数据存储的位置（在S3上）以及输出存储的S3位置。您可以指定每行一个文档或每个文件一个文档的输入数据，并将输入数据指向包含所有文件的目录。在我们的示例中，由于`test.csv`文件每行包含一个文档，我们使用该格式。
- en: Once you click on Create Job, it will automatically classify the documents and
    store the output in the output location. The output is stored in JSON format,
    where each line of the `output` file contains JSON that gives the analysis of
    that line.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您点击创建作业，它将自动对文档进行分类并将输出存储在输出位置。输出以JSON格式存储，其中`output`文件的每一行都包含对该行的分析。
- en: 'The following is an example of the output that was generated:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个生成的输出示例：
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Thus, you can see that our model labeled the first line in our input file as
    `"alt.atheism"` with a confidence score of 86.42%.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您可以看到我们的模型将输入文件的第一行标记为`"alt.atheism"`，置信度为86.42%。
- en: 'You can also create a document classifier and prediction jobs using the Amazon
    Comprehend APIs:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用Amazon Comprehend API创建文档分类器和预测作业：
- en: '[PRE5]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Running this function will automatically generate the same classifier that
    we created in the previous steps. You can access your ARN value from the Roles
    tab on the My Security Credentials page. This is the ARN value of the same IAM
    role we created in step 3\. The output data config location will automatically
    get a confusion metric of the evaluation of the classifier and the response string
    will be returned as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此函数将自动生成我们在前一步骤中创建的相同分类器。您可以从“我的安全凭证”页面上的角色选项卡访问您的ARN值。这是我们在第3步中创建的相同IAM角色的ARN值。输出数据配置位置将自动获取分类器评估的混淆度量，响应字符串将返回如下：
- en: '[PRE6]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The string will be the Amazon resource name that identifies the classifier.
    You can also run prediction jobs using the API. The following code can be used
    to generate the predictions for your input files:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串将是标识分类器的Amazon资源名称。您还可以使用API运行预测作业。以下代码可以用于生成输入文件的预测：
- en: '[PRE7]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The preceding code will start the exact same classification job that we created
    on the dashboard. Thus, you can control when you want to use a certain classifier
    and generate predictions on different datasets as required. The response of the
    function will be the status of the job. The job will also generate a job ID, that
    you can ping to check the status of the job using the `describe_document_classification_job()` function.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将启动与我们在仪表板上创建的完全相同的分类作业。因此，您可以控制何时使用某个分类器，并根据需要在不同数据集上生成预测。函数的响应将是作业的状态。作业还将生成一个作业ID，您可以使用`describe_document_classification_job()`函数ping该ID来检查作业的状态。
- en: Thus, we have generated a custom document classifier using Comprehend tools
    on AWS. These tools will help you to create these classifiers quickly without
    having to worry about what classification algorithms to select, how to tune the
    parameters, and so on. Amazon automatically updates the algorithms used by Comprehend
    based on the expertise of their research teams. However, the main disadvantage
    is that Comprehend tools can be costly if you are running operations on large
    datasets, as they charge you per prediction. You can access the pricing information
    for AWS Comprehend at [https://aws.amazon.com/comprehend/pricing/](https://aws.amazon.com/comprehend/pricing/).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经在AWS上使用Comprehend工具生成了一个自定义文档分类器。这些工具将帮助您快速创建这些分类器，无需担心选择哪些分类算法、如何调整参数等问题。亚马逊会根据其研究团队的专长自动更新Comprehend使用的算法。然而，主要缺点是如果您在大数据集上运行操作，Comprehend工具可能会很昂贵，因为它们按预测收费。您可以在[https://aws.amazon.com/comprehend/pricing/](https://aws.amazon.com/comprehend/pricing/)访问AWS
    Comprehend的定价信息。
- en: Summary
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we studied how to use a built-in machine learning tool called
    Comprehend in AWS. We briefly discussed the field of NLP and provided an introduction
    to its sub-fields, such as NER and sentiment analysis. We also studied how to
    create a custom document classifier in Comprehend using the dashboard it provides.
    Moreover, we studied how to access Comprehend's APIs using the `boto3` package
    in Python.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了如何在AWS中使用内置的机器学习工具Comprehend。我们简要讨论了自然语言处理（NLP）领域，并介绍了其子领域，如命名实体识别（NER）和情感分析。我们还研究了如何使用Comprehend提供的仪表板创建自定义文档分类器。此外，我们还研究了如何使用Python中的`boto3`包访问Comprehend的API。
- en: These tools are fascinating as they will help you to create complex machine
    learning models quickly and start applying them in your applications. A data scientist
    who has cursory knowledge in the field of NLP can now train sophisticated machine
    learning models and use them to make optimal decisions. However, the question
    most data scientists face is whether the pricing provided by such tools is more
    economical than building algorithms in-house using Python packages. Note that
    Comprehend adds a layer of abstraction between data scientists and the machine
    learning models by making them worry about the underlying cluster configurations.
    In our experience, we use these tools during the rapid prototyping phases of our
    projects to evaluate a product. If we decide to move to production, it is easy
    to calculate the cost differences between using the AWS tools versus building
    algorithms in-house and maintaining them on our clusters.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具非常吸引人，因为它们将帮助您快速创建复杂的机器学习模型，并开始将它们应用于您的应用程序中。现在，对NLP领域只有初步了解的数据科学家现在可以训练复杂的机器学习模型，并使用它们做出最优决策。然而，大多数数据科学家面临的问题是，这些工具提供的定价是否比使用Python包自行构建算法更经济。请注意，Comprehend通过让数据科学家关注底层集群配置，在数据科学家和机器学习模型之间添加了一层抽象。根据我们的经验，我们在项目的快速原型阶段使用这些工具来评估产品。如果我们决定投入生产，很容易计算出使用AWS工具与自行构建算法并在我们的集群上维护它们之间的成本差异。
- en: We will introduce the Amazon Rekognition in the next chapter. This service is
    used for image recognition and is an out of the box solution for Object detection
    and similar applications
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章介绍亚马逊Rekognition。这项服务用于图像识别，是对象检测和类似应用的即用型解决方案。
- en: Exercise
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Your task is to perform NER on a large dataset using APIs provided by Amazon
    Comprehend. Use the annotated NER dataset provided in the Kaggle competition to
    create a custom entity recognition in Comprehend ([https://www.kaggle.com/abhinavwalia95/chemdner-iob-annotated-chemical-named-etities](https://www.kaggle.com/abhinavwalia95/chemdner-iob-annotated-chemical-named-etities)).
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的任务是使用亚马逊Comprehend提供的API在大型数据集上执行命名实体识别（NER）。使用Kaggle竞赛中提供的标注NER数据集在Comprehend中创建自定义实体识别（[https://www.kaggle.com/abhinavwalia95/chemdner-iob-annotated-chemical-named-etities](https://www.kaggle.com/abhinavwalia95/chemdner-iob-annotated-chemical-named-etities)）。
- en: Apply sentiment analysis on the Yelp dataset in Kaggle and then evaluate whether
    your predictions match the review score ([https://www.kaggle.com/yelp-dataset/yelp-dataset](https://www.kaggle.com/yelp-dataset/yelp-dataset)).
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Kaggle的Yelp数据集上应用情感分析，然后评估您的预测是否与评论评分相匹配（[https://www.kaggle.com/yelp-dataset/yelp-dataset](https://www.kaggle.com/yelp-dataset/yelp-dataset)）。
