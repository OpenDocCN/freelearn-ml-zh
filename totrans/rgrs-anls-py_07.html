<html><head></head><body>
<div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07" class="calibre1"/>Chapter 7. Online and Batch Learning</h1></div></div></div><p class="calibre8">In this chapter, you will be presented with best practices when it comes to training classifiers on big data. The new approach, exposed in the following pages, is both scalable and generic, making it perfect for datasets with a huge number of observations. Moreover, this approach can allow you to cope with streaming datasets—that is, datasets with observations transmitted on-the-fly and not all available at the same time. Furthermore, such an approach enhances precision, as more data is fed in during the training process.</p><p class="calibre8">With respect to the classic approach seen so far in the book, batch learning, this new approach is, not surprisingly, called online learning. The core of online learning is the <em class="calibre9">divide et impera</em> (divide and conquer) principle whereby each step of a mini-batch of the data serves as input to train and improve the classifier.</p><p class="calibre8">In this chapter, we will first focus on batch learning and its limitations, and then introduce online learning. Finally, we will supply an example of big data, showing the benefits of combining online learning and hashing tricks.</p></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_1"><a id="ch07lvl1sec40" class="calibre1"/>Batch learning</h1></div></div></div><p class="calibre8">When the dataset is fully available at the beginning of a supervised task, and doesn't exceed the quantity of RAM on your machine, you can train the classifier or the regression using batch learning. As seen in previous chapters, during training the learner scans the<a id="id541" class="calibre1"/> full dataset. This also happens when <strong class="calibre2">stochastic gradient descent</strong> (SGD)-based methods are used (see <a class="calibre1" title="Chapter 2. Approaching Simple Linear Regression" href="part0018_split_000.html#H5A42-a2faae6898414df7b4ff4c9a487a20c6">Chapter 2</a>, <em class="calibre9">Approaching Simple Linear Regression</em> and <a class="calibre1" title="Chapter 3. Multiple Regression in Action" href="part0023_split_000.html#LTSU2-a2faae6898414df7b4ff4c9a487a20c6">Chapter 3</a>, <em class="calibre9">Multiple Regression in Action</em>). Let's now<a id="id542" class="calibre1"/> compare how much time is needed to train a linear regressor and relate its performance with the number of observations in the dataset (that is, the number of rows of the feature matrix <em class="calibre9">X</em>) and the number of features (that is, the number of columns of <em class="calibre9">X</em>). In this first experiment, we will use the plain vanilla <code class="email">LinearRegression()</code> and <code class="email">SGDRegressor()</code> classes provided by Scikit-learn, and we will store the actual time taken to fit a classifier, without any parallelization.</p><p class="calibre8">Let's first create a function to create fake datasets: it takes as parameters the number of training points and the number of features (plus, optionally, the noise variance), and returns normalized training and testing feature matrixes and labels. Note that all the features<a id="id543" class="calibre1"/> in the <em class="calibre9">X</em> matrix are numerical:</p><div><pre class="programlisting">In:
import matplotlib.pyplot as plt
import matplotlib.pylab as pylab
%matplotlib inline

In:
from sklearn.preprocessing import StandardScaler
from sklearn.datasets.samples_generator import make_regression
import numpy as np

def generate_dataset(n_train, n_test, n_features, noise=0.1):
    X, y = make_regression(n_samples=int(n_train + n_test),
                           n_features=int(n_features), noise=noise, 
                           random_state=101)
    
    X_train = X[:n_train]
    X_test = X[n_train:]
    
    y_train = y[:n_train]
    y_test = y[n_train:]
    
    
    X_scaler = StandardScaler()
    X_train = X_scaler.fit_transform(X_train)
    X_test = X_scaler.transform(X_test)
    
    y_scaler = StandardScaler()
    y_train = y_scaler.fit_transform(y_train)
    y_test = y_scaler.transform(y_test)
    
    return X_train, X_test, y_train, y_test</pre></div><p class="calibre8">Let's now store the time needed to train and test the learner in all the combinations of these configurations:</p><div><ul class="itemizedlist"><li class="listitem">Two classifiers: <code class="email">LinearRegression()</code> and <code class="email">SGDRegressor()</code></li><li class="listitem">Number of observations: <code class="email">1000</code>, <code class="email">10000</code>, and <code class="email">100000</code></li><li class="listitem">Number of features: <code class="email">10</code>, <code class="email">50</code>, <code class="email">100</code>, <code class="email">500</code>, and <code class="email">1000</code></li></ul></div><p class="calibre8">To average the results, each training operation is performed five times. The testing dataset always <a id="id544" class="calibre1"/>comprises <code class="email">1000</code> observations:</p><div><pre class="programlisting">In:
from sklearn.linear_model import LinearRegression, SGDRegressor
import time

In:

n_test = 1000

n_train_v = (1000, 10000, 100000)
n_features_v = (10, 50, 100, 500, 1000)
regr_v = {'LR': LinearRegression(), 'SGD': SGDRegressor(random_state=101)}
results = {}

for regr_name, regr in regr_v.items():
    
    results[regr_name] = {}
    
    for n_train in n_train_v:
        for n_features in n_features_v:

            results[regr_name][(n_train, n_features)] = {'train': [], 'pred': []}

            for n_repetition in range(5):

                X_train, X_test, y_train, y_test = \
                generate_dataset(n_train, n_test, n_features)

                tick = time.time()
                regr.fit(X_train, y_train)
                train_time = time.time() - tick

                pred = regr.predict(X_test)
                predict_time = time.time() - tick - train_time


                results[regr_name][(n_train, n_features)]['train'].append(train_time)
                results[regr_name][(n_train, n_features)]['pred'].append(predict_time)</pre></div><p class="calibre8">Let's finally plot the results. In the following screenshot, the chart on the left shows the training time of the <code class="email">LogisticRegressor</code> algorithm against the number of features, whereas the chart <a id="id545" class="calibre1"/>on the right displays the time against the number of observations:</p><div><pre class="programlisting">In:
pylab.rcParams['figure.figsize'] = 12, 6
plt.subplot(1, 2, 1)

for n_train in n_train_v:
    X = n_features_v
    y = [np.mean(results['LR'][(n_train, n_features)]['train']) 
         for n_features in n_features_v]
    plt.plot(X, y, label=str(n_train) + " train points")

plt.title('Training time VS num. features')
plt.xlabel('Num features')
plt.ylabel('Training time [s]')
plt.legend(loc=0)


plt.subplot(1, 2, 2)

for n_features in n_features_v:
    X = np.log10(n_train_v)
    y = [np.mean(results['LR'][(n_train, n_features)]['train']) 
         for n_train in n_train_v]
    plt.plot(X, y, label=str(n_features) + " features")

plt.title('Training time VS num. training points')
plt.xlabel('Num training points [log10]')
plt.ylabel('Training time [s]')
plt.legend(loc=0)
plt.show()

Out:</pre></div><div><img src="img/00113.jpeg" alt="Batch learning" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">In the plots, you <a id="id546" class="calibre1"/>can see that the classifier is pretty good on small datasets, with a small number of features and observations. While dealing with the largest <em class="calibre9">X</em> matrix, 1,000 features and 100,000 observations (containing 100 million entries), the training time is just above <code class="email">30</code> seconds: that's also the limit above which the regressor no longer scales.</p><p class="calibre8">Let's now see what happens with the testing time:</p><div><pre class="programlisting">In:
plt.subplot(1, 2, 1)

for n_train in n_train_v:
    X = n_features_v
    y = [np.mean(results['LR'][(n_train, n_features)]['pred']) 
         for n_features in n_features_v]

    plt.plot(X, y, label=str(n_train) + " train points")

plt.title('Prediction time VS num. features')
plt.xlabel('Num features')
plt.ylabel('Prediction time [s]')
plt.legend(loc=0)


plt.subplot(1, 2, 2)

for n_features in n_features_v:
    X = np.log10(n_train_v)
    y = [np.mean(results['LR'][(n_train, n_features)]['pred']) 
         for n_train in n_train_v]

    plt.plot(X, y, label=str(n_features) + " features")

plt.title('Prediction time VS num. training points')
plt.xlabel('Num training points [log10]')
plt.ylabel('Prediction time [s]')
plt.legend(loc=0)
plt.show()
Out:</pre></div><div><img src="img/00114.jpeg" alt="Batch learning" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The testing time<a id="id547" class="calibre1"/> does scale as a linear function of the number of features, and it's independent of it. It seems that applying the linear approach is not very much of a problem on big data, fortunately.</p><p class="calibre8">Let's now see what happens with the SGD implementation of linear regression:</p><div><pre class="programlisting">In:
plt.subplot(1, 2, 1)

for n_train in n_train_v:
    X = n_features_v
    y = [np.mean(results['SGD'][(n_train, n_features)]['train']) 
         for n_features in n_features_v]
    plt.plot(X, y, label=str(n_train) + " train points")

plt.title('Training time VS num. features')
plt.xlabel('Num features')
plt.ylabel('Training time [s]')
plt.legend(loc=0)


plt.subplot(1, 2, 2)

for n_features in n_features_v:
    X = np.log10(n_train_v)
    y = [np.mean(results['SGD'][(n_train, n_features)]['train']) 
         for n_train in n_train_v]
    plt.plot(X, y, label=str(n_features) + " features")

plt.title('Training time VS num. training points')
plt.xlabel('Num training points [log10]')
plt.ylabel('Training time [s]')
plt.legend(loc=0)
plt.show()
Out:</pre></div><div><img src="img/00115.jpeg" alt="Batch learning" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The results have drastically changed in comparison with the previous regressor: on the biggest matrix, this learner takes around 1.5 seconds. It also seems that the time needed to train an SGD regressor is linear with respect to the number of features and the number of training points. Let's <a id="id548" class="calibre1"/>now verify how it works in testing:</p><div><pre class="programlisting">In:
plt.subplot(1, 2, 1)

for n_train in n_train_v:
    X = n_features_v
    y = [np.mean(results['SGD'][(n_train, n_features)]['pred']) 
         for n_features in n_features_v]

    plt.plot(X, y, label=str(n_train) + " train points")

plt.title('Prediction time VS num. features')
plt.xlabel('Num features')
plt.ylabel('Prediction time [s]')
plt.legend(loc=0)


plt.subplot(1, 2, 2)

for n_features in n_features_v:
    X = np.log10(n_train_v)
    y = [np.mean(results['SGD'][(n_train, n_features)]['pred']) 
         for n_train in n_train_v]

    plt.plot(X, y, label=str(n_features) + " features")

plt.title('Prediction time VS num. training points')
plt.xlabel('Num training points [log10]')
plt.ylabel('Prediction time [s]')
plt.legend(loc=0)
plt.show()
Out:</pre></div><div><img src="img/00116.jpeg" alt="Batch learning" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Applying the <a id="id549" class="calibre1"/>SGD-based learner on a test dataset takes about the same time as the other implementation. Here, again, there is really no problem when scaling the solution on big datasets.</p></div></div>

<div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07lvl1sec41" class="calibre1"/>Online mini-batch learning</h1></div></div></div><p class="calibre8">From the<a id="id550" class="calibre1"/> previous section, we've <a id="id551" class="calibre1"/>learned an interesting lesson: for big data, always use SGD-based learners <a id="id552" class="calibre1"/>because they are faster, and they do scale.</p><p class="calibre8">Now, in this section, let's consider this regression dataset:</p><div><ul class="itemizedlist"><li class="listitem">Massive number of observations: 2M</li><li class="listitem">Large number of features: 100</li><li class="listitem">Noisy dataset</li></ul></div><p class="calibre8">The <code class="email">X_train</code> matrix is composed of 200 million elements, and may not completely fit in memory (on a machine with 4 GB RAM); the testing set is composed of 10,000 observations.</p><p class="calibre8">Let's first create the datasets, and print the memory footprint of the biggest one:</p><div><pre class="programlisting">In:
# Let's generate a 1M dataset
X_train, X_test, y_train, y_test = generate_dataset(2000000, 10000, 100, 10.0)
print("Size of X_train is [GB]:", X_train.size * X_train[0,0].itemsize/1E9)

Out:
Size of X_train is [GB]: 1.6</pre></div><p class="calibre8">The <code class="email">X_train</code> matrix is itself <code class="email">1.6</code> GB of data; we can consider it as a starting point for big data. Let's<a id="id553" class="calibre1"/> now try to classify it using the best model we got from the previous section, <code class="email">SGDRegressor()</code>. To access its performance, we use MAE, the Mean Absolute Error (as for error evaluation, the lower the better).</p><div><pre class="programlisting">In:
from sklearn.metrics import mean_absolute_error

regr = SGDRegressor(random_state=101)
tick = time.time()
regr.fit(X_train, y_train)
print("With SGD, after", time.time() - tick ,"seconds")
pred = regr.predict(X_test)
print("the MAE is [log10]:", np.log10(mean_absolute_error(y_test, pred)))

Out:
With SGD, after 5.958770098299116 seconds
the MAE is [log10]: -1.2422451189257</pre></div><p class="calibre8">On our computer (equipped with Mac OS and 4 GB of RAM), this operation takes around 6 seconds, and the final MAE is 10<sup class="calibre21">-1.24</sup>.</p><p class="calibre8">Can we do better? Yes, with mini-batches and online learning. Before we see these in action, let's introduce how SGD works with mini-batches.</p><div><ol class="orderedlist"><li class="listitem" value="1">Split the <code class="email">X_train</code> matrix in batches of <em class="calibre9">N</em> observations. Since we're using SGD, if possible it's better to shuffle the observations, as the method is strongly driven by the order of the input vectors. At this point, every mini-batch has <em class="calibre9">N</em> lines and <em class="calibre9">M</em> columns (where <em class="calibre9">M</em> is the number of features).</li><li class="listitem" value="2">We train the learner using a mini-batch. SGD coefficients are initialized randomly, as shown previously.</li><li class="listitem" value="3">We train the learner using another mini-batch. SGD coefficients are initialized as the output of the previous step (using the <code class="email">partial_fit</code> method).</li><li class="listitem" value="4">Repeat step 3 until you've used all the mini-batches. In each step, the coefficients of the SGD model are refined and modified according to the input.</li></ol><div></div><p class="calibre8">This is clearly a smart approach, and it doesn't take too long to implement. You just need to set the initial values of each coefficient for every new batch and train the learner on the mini-batch.</p><p class="calibre8">Now, in terms <a id="id554" class="calibre1"/>of performance, what do we get using online learning?</p><div><ul class="itemizedlist"><li class="listitem">We have an incremental way to train the model. Since, at every step, we can test the model, we can stop at any point we think is good enough.</li><li class="listitem">We don't need to keep the whole <code class="email">X_train</code> matrix in memory; we just need to keep the mini-batch in RAM. That also means that the consumed RAM is constant.</li><li class="listitem">We have a way to control the learning: we can have small mini-batches or big ones.</li></ul></div><p class="calibre8">Let's see now how it performs, by changing the batch size (that is, the number of observations for each observation):</p><div><pre class="programlisting">In:
def get_minibatch(X, y, batch_size):
    # We will shuffle consistently the training observations
    from sklearn.utils import resample
    X, y = resample(X, y, replace=False, random_state=101)
    n_cols = y.shape[0]
    for i in range(int(n_cols/batch_size)):
        yield (X[i*batch_size:(i+1)*batch_size, :], y[i*batch_size:(i+1)*batch_size])
    
    if n_cols % batch_size &gt; 0:
        res_rows = n_cols % batch_size
        yield (X[-res_rows:, :], y[-res_rows:])


plot_x = []
plot_y = []
plot_labels = []

for batch_size in (1000, 10000, 100000):
    regr = SGDRegressor(random_state=101)
    training_time = 0.0
    
    X = []
    y = []
    
    for dataset in get_minibatch(X_train, y_train, batch_size):
        tick = time.time()
        regr.partial_fit(dataset[0], dataset[1])
        training_time += (time.time() - tick)
        pred = regr.predict(X_test)
        X.append(training_time)
        y.append(np.log10(mean_absolute_error(y_test, pred)))
    
    print("Report: Mini-batch size", batch_size)
    print("First output after [s]:", X[0])
    print("First model MAE [log10]:", y[0])
    print("Total training time [s]:", X[-1])
    print("Final MAE [log10]: ", y[-1])
    print()
    
    plot_x.append(X)
    plot_y.append(y)
    plot_labels.append("Batch size: "+str(batch_size))

Out:</pre></div><div><img src="img/00117.jpeg" alt="Online mini-batch learning" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">In the end, the<a id="id555" class="calibre1"/> final MAE is always the same; that is, batch learning and online learning eventually provide the same results when both are trained on the whole training set.</p><p class="calibre8">We also see that, by using a small mini-batch (1,000 observations), we have a working model after just 1 millisecond. Of course, it's not a perfect solution since its MAE is just 10<sup class="calibre21">-0.94</sup>, but still we now have a reasonable working model.</p><p class="calibre8">Now, let's compare timings to fully train the model. Using mini-batches, the total time is around 1.2 seconds; using the batch it was greater than 5 seconds. The MAEs are more or less equal—why such a difference in timings? Because the dataset didn't all fit in RAM and the system kept on swapping data with storage memory.</p><p class="calibre8">Let's now focus<a id="id556" class="calibre1"/> on mini-batch size: is smaller really always better? Actually, it will produce an output earlier, but it will take more time in total.</p><p class="calibre8">Here's a plot of the training time and the MAE of the learner, when trained with different mini-batch sizes:</p><div><pre class="programlisting">In:
plt.subplot(1,2,1)
for i in range(len(plot_x)):
    plt.plot(plot_x[i], plot_y[i], label=plot_labels[i])
plt.title('Mini-batch learning')
plt.xlabel('Training time [s]')
plt.ylabel('MAE')
plt.legend(loc=0)

plt.subplot(1,2,2)
for i in range(len(plot_x)):
    plt.plot(plot_x[i], plot_y[i], label=plot_labels[i])
plt.title('Mini-batch learning: ZOOM 0-0.15s')
plt.xlabel('Training time [s]')
plt.ylabel('MAE')
plt.xlim([0, 0.15])
plt.legend(loc=0)

plt.show()
Out:</pre></div><div><img src="img/00118.jpeg" alt="Online mini-batch learning" class="calibre10"/></div><p class="calibre11"> </p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch07lvl2sec78" class="calibre1"/>A real example</h2></div></div></div><p class="calibre8">Let's now <a id="id557" class="calibre1"/>combine feature hashing (seen in <a class="calibre1" title="Chapter 5. Data Preparation" href="part0035_split_000.html#11C3M2-a2faae6898414df7b4ff4c9a487a20c6">Chapter 5</a>, <em class="calibre9">Data Preparation</em>), batch-learning, and SGD. From what we've seen so far, this should be the best way to deal with big data because:</p><div><ol class="orderedlist"><li class="listitem" value="1">The number of features is constant (feature hashing).</li><li class="listitem" value="2">The number of observations per batch is constant (batch learning).</li><li class="listitem" value="3">It allows streaming datasets.</li><li class="listitem" value="4">The algorithm is stochastic (SGD).</li></ol><div></div><p class="calibre8">All these points together will ensure a few consequences:</p><div><ol class="orderedlist"><li class="listitem" value="1">We can very quickly have a model (after the first mini-batch) that is refined with time.</li><li class="listitem" value="2">RAM consumption is constant (since every mini-batch has exactly the same size).</li><li class="listitem" value="3">Ideally, we can deal with as many observation as we want. </li></ol><div></div><p class="calibre8">In the real-world example, let's use a textual input: the Twenty Newsgroups dataset. This dataset contains 20,000 messages (textual content) extracted from 20 different newsgroups, each of them on a different topic. The webpage of the project is: <a class="calibre1" href="https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups">https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups</a>.</p><p class="calibre8">The goal is to classify each document in one of the possible labels (it's a classification task). Let's<a id="id558" class="calibre1"/> first load it, and split it into train and test. To make it more real, we're going to remove headers, footers, and quoted e-mail from the dataset:</p><div><pre class="programlisting">In:
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import HashingVectorizer

to_remove = ('headers', 'footers', 'quotes')

data_train = fetch_20newsgroups(subset='train', random_state=101,
                                remove=to_remove)

data_test = fetch_20newsgroups(subset='test', random_state=101,
                                remove=to_remove)


labels = data_train.target_names
targets = np.unique(data_train.target)</pre></div><p class="calibre8">Let's now create a function that yields mini-batches of the dataset:</p><div><pre class="programlisting">In:
def get_minibatch_docs(docs, targets, batch_size):
    n_docs = len(docs)
    for i in range(int(n_docs/batch_size)):
       yield (docs[i*batch_size:(i+1)*batch_size], 
              targets[i*batch_size:(i+1)*batch_size])
    
    if n_docs % batch_size &gt; 0:
        res_rows = n_docs % batch_size
        yield (docs[-res_rows:], targets[-res_rows:])</pre></div><p class="calibre8">Now, the core task is simply to classify the document. We first apply feature hashing via the <code class="email">HashingVectorizer</code> class, whose output feeds a <code class="email">SGDClassifier</code> (another class with the <code class="email">partial_fit</code> method). This fact will ensure an additional advantage: since the output of the <code class="email">HashingVectorizer</code> is very sparse, a sparse representation is used, making the mini-batch size even more compact in memory</p><p class="calibre8">To understand what the best hash size is, we may try a full search with sizes of <code class="email">1000</code>, <code class="email">5000</code>, <code class="email">10000</code>, <code class="email">50000</code>, and <code class="email">100000</code> and then measure the accuracy for each learner:</p><div><pre class="programlisting">In: 
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score
import sys

minibatch_size = 1000
values_to_plot = {}

for hash_table_size in (1000, 5000, 10000, 50000, 100000):
    
    values_to_plot[hash_table_size] = {'time': [], 'score': []}

    vectorizer = HashingVectorizer(stop_words='english',
   non_negative=True, n_features=hash_table_size,
   ngram_range=(1, 1))

    X_test = vectorizer.transform(data_test.data)
    y_test = data_test.target

    clf = SGDClassifier(loss='log')
    timings = []

    for minibatch in get_minibatch_docs(data_train.data, data_train.target, minibatch_size):
        y_train = minibatch[1]

        tick = time.time()
        X_train = vectorizer.transform(minibatch[0])
        clf.partial_fit(X_train, y_train, targets)
        
        timings.append(time.time() - tick)
        
        pred = clf.predict(X_test)
        
        values_to_plot[hash_table_size]['score'].append(accuracy_score(y_test, pred))
    
    values_to_plot[hash_table_size]['time'] = np.cumsum(timings)</pre></div><p class="calibre8">Finally, we<a id="id559" class="calibre1"/> plot our results on a graph representing time and accuracy for each size of the hash size. The <em class="calibre9">X</em> signs on the graph are the instances (and related accuracy) when the classifier outputs a model:</p><div><pre class="programlisting">In:
for k,v in sorted(values_to_plot.items()):
    plt.plot(v['time'], v['score'], 'x-', label='Hashsize size '+str(k))
plt.title('Mini-batch learning: 20newsgroups')
plt.xlabel('Training time [s]')
plt.ylabel('Accuracy')
plt.legend(loc=0)

plt.show()
Out:</pre></div><div><img src="img/00119.jpeg" alt="A real example" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">It appears<a id="id560" class="calibre1"/> from the obtained results that using a hash table bigger than 10,000 elements can allow us to achieve the best performance. In this exercise, the mini-batch size was fixed to 1,000 observations; this means that every mini-batch was a matrix of 10 M elements, represented in sparse way. It also means that, for every mini-batch, the memory used is up to 80 MB of RAM.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch07lvl2sec79" class="calibre1"/>Streaming scenario without a test set</h2></div></div></div><p class="calibre8">In many real cases, the test dataset is not available. What can we do? The best practice would be to:</p><div><ol class="orderedlist"><li class="listitem" value="1">Fetch the<a id="id561" class="calibre1"/> data <a id="id562" class="calibre1"/>until you reach a specific mini-batch size; let's say 10 observations.</li><li class="listitem" value="2">Shuffle the observations, and store eight of them within the train set, and two in the test set (for an 80/20 validation).</li><li class="listitem" value="3">Train the classifier on the train set and test on the test set.</li><li class="listitem" value="4">Go back to step 1. With each mini-batch, the train set will increase by 10 observations and the test set by 2.</li></ol><div></div><p class="calibre8">We have just described the classic method, used when data is consistent and the dataset is not very large. If the features change throughout the streaming, and you need to build a learner that has to adapt to rapid changes of feature statistics. then simply don't use a test set and follow<a id="id563" class="calibre1"/> this algorithm. In addition, this is the preferred way to learn from big data:</p><div><ol class="orderedlist"><li class="listitem" value="1">Fetch the data till you reach a mini-batch size; let's say 10 observations. Don't shuffle and train the learner with all the observations.</li><li class="listitem" value="2">Wait till you fetch another mini-batch. Test the classifier on those observations.</li><li class="listitem" value="3">Update the classifier with the mini-batch you received in the previous step.</li><li class="listitem" value="4">Go back to step 2.</li></ol><div></div><p class="calibre8">The good thing about this algorithm is that you don't have to keep anything but the model and the current mini-batch in memory; these are used first to test the learner, and then to update it.</p></div></div>
<div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07lvl1sec42" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">In this chapter, we've introduced the concepts of batch and online learning, which are necessary to be able to process big datasets (big data) in a quick and scalable way.</p><p class="calibre8">In the next chapter, we will explore some advanced techniques of machine learning that will produce great results for some classes of well-known problems.</p></div></body></html>