["```py\ns3://project1/<date>/<unique version id 1>/train_1.txt\ns3://project1/<date>/<unique version id 1>/train_2.txt\ns3://project1/<date>/<unique version id 2>/train_1.txt\ns3://project1/<date>/<unique version id 2>/train_2.txt \n```", "```py\n        import json\n        import boto3\n        def lambda_handler(event, context):\n             s3 = boto3.resource('s3')\n             for record in event['Records']:\n                   srcBucket = record['s3']['bucket']['name']\n                   srckey = record['s3']['object']['key']\n                   desBucket = \"MLSA-DataLake-<your initials>\"\n                   desFolder = srckey[0:srckey.find('.')]\n                   desKey = \"bank_customer_db/\" + desFolder + \"/\" + srckey\n                   source= { 'Bucket' : srcBucket,'Key':srckey}\n                   dest ={ 'Bucket' : desBucket,'Key':desKey}\n                   s3.meta.client.copy(source, desBucket, desKey)\n             return {\n                   'statusCode': 200,\n                   'body': json.dumps('files ingested')\n             } \n        ```", "```py\n    description: credit score is the FICO score for each customer \n    ```", "```py\n    description: churn flag \n    ```", "```py\nSELECT * FROM \"bank_customer_db\".\"customer_data\", \" bank_customer_db\".\"churn_list\" where \"bank_customer_db\".\"customer_data\".\"customerid\" = \"bank_customer_db\".\"churn_list\".\"customerid\" ; \n```", "```py\n    import sys\n    from awsglue.utils import getResolvedOptions\n    from awsglue.transforms import Join\n    from pyspark.context import SparkContext\n    from awsglue.context import GlueContext\n    from awsglue.job import Job\n    import pandas as pd\n    from datetime import datetime\n    import uuid\n    from pyspark.ml.feature import StringIndexer\n    glueContext = GlueContext(SparkContext.getOrCreate())\n    logger = glueContext.get_logger()\n    current_date = datetime.now()\n    default_date_partition = f\"{current_date.year}-{current_date.month}-{current_date.day}\"   \n    default_version_id = str(uuid.uuid4())\n    default_bucket = \"<your default bucket name>\"\n    default_prefix = \"ml-customer-churn\"\n    target_bucket = \"\"\n    prefix = \"\"\n    day_partition =\"\"\n    version_id = \"\"\n    try:\n         args = getResolvedOptions(sys.argv,['JOB_NAME','target_bucket','prefix','day_partition','version_id'])\n         target_bucket = args['target_bucket']\n         prefix = args['prefix']\n         day_partition = args['day_partition']\n         version_id = args['version_id']\n    except:\n         logger.error(\"error occured with getting arguments\")\n    if target_bucket == \"\":\n         target_bucket = default_bucket\n    if prefix == \"\":\n         prefix = default_prefix\n    if day_partition == \"\":\n         day_partition = default_date_partition\n    if version_id == \"\":\n         version_id = default_version_id \n    ```", "```py\n    # catalog: database and table names\n    db_name = \"bank_customer_db\"\n    tbl_customer = \"customer_data\"\n    tbl_churn_list = \"churn_list\"\n    # Create dynamic frames from the source tables\n    customer = glueContext.create_dynamic_frame.from_catalog(database=db_name, table_name=tbl_customer)\n    churn = glueContext.create_dynamic_frame.from_catalog(database=db_name, table_name=tbl_churn_list)\n    # Join the frames to create customer churn dataframe\n    customer_churn = Join.apply(customer, churn, 'customerid', 'customerid')\n    customer_churn.printSchema() \n    ```", "```py\n    # ---- Write out the combined file ----\n    current_date = datetime.now()\n    str_current_date = f\"{current_date.year}-{current_date.month}-{current_date.day}\"   \n    random_version_id = str(uuid.uuid4())\n    output_dir = f\"s3://{target_bucket}/{prefix}/{day_partition}/{version_id}\"\n    s_customer_churn = customer_churn.toDF()\n    gender_indexer = StringIndexer(inputCol=\"gender\", outputCol=\"genderindex\")\n    s_customer_churn = gender_indexer.fit(s_customer_churn).transform(s_customer_churn)\n    geo_indexer = StringIndexer(inputCol=\"geography\", outputCol=\"geographyindex\")\n    s_customer_churn = geo_indexer.fit(s_customer_churn).transform(s_customer_churn)\n    s_customer_churn = s_customer_churn.select('geographyindex', 'estimatedsalary','hascrcard','numofproducts', 'balance', 'age', 'genderindex', 'isactivemember', 'creditscore', 'tenure', 'exited')\n    s_customer_churn = s_customer_churn.coalesce(1)\n    s_customer_churn.write.option(\"header\",\"true\").format(\"csv\").mode('Overwrite').save(output_dir)\n    logger.info(\"output_dir:\" + output_dir) \n    ```"]