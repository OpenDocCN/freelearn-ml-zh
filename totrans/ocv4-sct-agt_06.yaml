- en: Controlling a Phone App with Your Suave Gestures
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用你的优雅手势控制手机应用程序
- en: '"You''ve got all the moves."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “你所有的动作都做得很好。”
- en: '- Lani Hall, Never Say Never Again (1983)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- Lani Hall，《永不言弃》（1983）'
- en: He raises an eyebrow; he lowers his chin; he twists the corners of his mouth;
    he folds one arm into the crook of the other as he points his pistol at the ceiling.
    It all looks very impressive, but is he simply wasting time while trying to remember
    people's names?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 他扬起眉毛；他低下下巴；他扭曲嘴角的轮廓；当他指向天花板时，他把一只手臂折进另一只手臂的弯里。这一切看起来都很令人印象深刻，但他在尝试记住别人的名字时，是不是只是在浪费时间？
- en: Agent 007 has a few old friends with normal names, such as Bill Tanner and Felix
    Leiter. Almost every other name is a number, a single letter, a mash-up of multiple
    languages, or a blindingly obvious double entendre. After a few vodka martinis
    and tranquilizer darts, any man would start to wonder whether his memory for names
    was playing tricks on him.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 007特工有几个老朋友，名字很普通，比如Bill Tanner和Felix Leiter。几乎所有其他名字都是一个数字、一个字母、多种语言的混合体，或者是一个明显的双关语。喝了几杯伏特加马提尼酒和镇静剂飞镖后，任何人都可能会开始怀疑自己的名字记忆是否在捉弄他。
- en: To put such doubts to rest, we will develop an Android app that determines a
    person's name based on a series of yes/no questions. To allow a secret agent to
    use it discretely, the app will rely on gesture controls and audio output, which
    can go to a Bluetooth headset so that others cannot hear.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了消除这些疑虑，我们将开发一个基于一系列是/否问题的Android应用程序，以确定一个人的名字。为了让秘密特工能够隐秘地使用它，该应用程序将依赖于手势控制和音频输出，这些输出可以连接到蓝牙耳机，这样其他人就听不到。
- en: The app's logic is like the game Twenty Questions. First, the app asks a question
    by playing an audio clip. Then, the user responds with a nod or a shake of the
    head. Each question is more specific than the last, until the app is ready to
    guess a name or give up. Recognizing the two possible head gestures—a nod or a
    shake—is our computer vision task for this chapter.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序的逻辑类似于二十个问题的游戏。首先，应用程序通过播放音频剪辑来提出一个问题。然后，用户通过点头或摇头来回答。每个问题都比上一个更具体，直到应用程序准备好猜测一个名字或放弃。识别两种可能的头部手势——点头或摇头——是我们本章的计算机视觉任务。
- en: 'Specifically, this chapter covers the following programming topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，本章涵盖了以下编程主题：
- en: Using Android Studio and the Android SDK to build an Android app in Java
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Android Studio和Android SDK用Java构建Android应用程序
- en: Using OpenCV's Android camera functions to capture, process, and display images
    from the Android device's camera
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用OpenCV的Android相机功能来捕获、处理和显示来自Android设备相机的图像
- en: Tracking head gestures using OpenCV's functions for face detection, feature
    detection, and optical flow
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用OpenCV的面部检测、特征检测和光流功能跟踪头部手势
- en: The app's codename is `Goldgesture`.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序的代号是`Goldgesture`。
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter’s project has the following software dependencies:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的项目有以下软件依赖项：
- en: Android Studio
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Android Studio
- en: OpenCV Android pack
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV Android包
- en: Setup instructions are covered in [Chapter 1](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml),
    *Preparing for the Mission*. Refer to the setup instructions for any version requirements.
    Instructions for building and running Android projects are covered in the current
    chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 设置说明在[第1章](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml) *准备任务* 中介绍。有关任何版本要求的说明，请参阅设置说明。构建和运行Android项目的说明在本章中介绍。
- en: The completed project for this chapter can be found in the book's GitHub repository, [https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition),
    in the `Chapter004` folder. If you want to open the completed project, just launch
    Android Studio, select Open an existing Android Studio project, and then select
    the `Chapter004/Goldgesture` folder.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的完成项目可以在本书的GitHub仓库中找到，[https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition)，在`Chapter004`文件夹中。如果您想打开完成的项目，只需启动Android
    Studio，选择打开现有的Android Studio项目，然后选择`Chapter004/Goldgesture`文件夹。
- en: Planning the Goldgesture app
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规划Goldgesture应用程序
- en: '`Goldgesture` is a GUI app built with the Android SDK and OpenCV''s Java bindings
    for Android. It has just a single view, seen in the screenshot on the next page.
    The app has the following flow of execution:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`Goldgesture`是一个使用Android SDK和OpenCV的Android Java绑定的GUI应用程序。它只有一个视图，如下一页的截图所示。该应用程序具有以下执行流程：'
- en: Constantly display a live video feed from the front-facing (self-portrait) camera.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 持续显示前置（自拍照）摄像头的实时视频流。
- en: Perform human face detection using OpenCV's `CascadeClassifier` class.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用OpenCV的`CascadeClassifier`类进行人脸检测。
- en: 'When a human face is detected:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当检测到人脸时：
- en: Draw a blue rectangle around the face.
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在脸部周围画一个蓝色矩形。
- en: Detect features of the face (points that should be easy to track in subsequent
    frames despite movement) using OpenCV's `goodFeaturesToTrack` function. Draw green
    circles around these features.
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用OpenCV的`goodFeaturesToTrack`函数检测人脸特征（在后续帧中尽管有运动但应该容易跟踪的点），在这些特征周围画绿色圆圈。
- en: As the face moves, track the features in every frame using OpenCV's `calcOpticalFlowPyrLK`
    function. This function can continuously track the features even though `CascadeClassifier`
    is unlikely to continuously detect a face.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当人脸移动时，使用OpenCV的`calcOpticalFlowPyrLK`函数在每一帧中跟踪特征。尽管`CascadeClassifier`不太可能连续检测到人脸，但此函数可以连续跟踪特征。
- en: When the features' center point moves up and down by a certain amount and a
    certain number of times, deem that a nod has occurred.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当特征的中心点上下移动一定量并移动一定次数时，认为发生了点头。
- en: When the features' center point moves left and right by a certain amount and
    a certain number of times, deem that a shake of the head has occurred.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当特征的中心点左右移动一定量并移动一定次数时，认为发生了摇头。
- en: Play a sequence of audio clips. At each juncture, choose the next clip depending
    (in part) on whether a nod or shake of the head has occurred.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 播放一系列音频剪辑。在每个转折点，根据头部是否点头或摇头来选择下一个剪辑。
- en: 'Reset the tracking if its reliability deteriorates to a certain extent or if
    the user''s head appears to be nodding and shaking at the same time:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果跟踪的可靠性下降到一定程度，或者用户的头部看起来同时点头和摇头，请重置跟踪：
- en: '![](img/9eba51d6-30cc-4e7e-a933-3a732aacd28f.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9eba51d6-30cc-4e7e-a933-3a732aacd28f.png)'
- en: The face-detection functionality in `Goldgesture` should already be familiar
    from the Angora Blue project in [Chapter 3](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml)*,
    Training a Smart Alarm to Recognize the Villain and His Cat*. However, feature
    tracking, and specifically optical flow, is a new topic for us. Let's talk about
    the concepts a little before proceeding to set up our project.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`Goldgesture`中的面部检测功能应该已经从[第3章](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml)*，训练一个智能闹钟来识别恶人和他的猫*中的Angora
    Blue项目熟悉。然而，特征跟踪，特别是光流，对我们来说是一个新话题。在继续设置我们的项目之前，让我们先谈谈这些概念。'
- en: Understanding optical flow
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解光流
- en: '**Optical flow** is the pattern of apparent motion between two consecutive
    frames of video. We select feature points in the first frame and try to determine
    where those features have gone in the second frame. This search is subject to
    a few caveats:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**光流**是视频连续两帧之间的明显运动模式。我们在第一帧中选择特征点，并试图确定这些特征在第二帧中的位置。这个搜索受到一些限制：'
- en: We make no attempt to distinguish between camera motion and subject motion.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不尝试区分相机运动和主体运动。
- en: We assume that a feature's color or brightness remains similar between frames.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们假设特征的颜色或亮度在帧之间保持相似。
- en: We assume that neighboring pixels have similar motions.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们假设相邻像素具有相似的运动。
- en: 'OpenCV''s `calcOpticalFlowPyrLK` function implements the Lucas-Kanade method
    of computing optical flow. Lucas-Kanade relies on a *3 x 3* neighborhood (that
    is, 9 pixels) around each feature. Taking each feature''s neighborhood from the
    first frame, we try to find the best matching neighborhood in the second frame,
    based on least squares error. OpenCV''s implementation of Lucas-Kanade uses an
    image pyramid, meaning it performs the search at various scales. Thus, it supports
    both large and small motions (`PyrLK` in the function name stands for *pyramidal
    Lucas-Kanade*). The following diagram is a visualization of a pyramid—a progression
    from low-resolution (or low-magnification) images to high-resolution (or high-magnification)
    images:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV的`calcOpticalFlowPyrLK`函数实现了计算光流的Lucas-Kanade方法。Lucas-Kanade依赖于每个特征周围的*3
    x 3*邻域（即9个像素）。从第一帧中取每个特征的邻域，我们尝试在第二帧中找到最佳匹配的邻域，基于最小二乘误差。OpenCV对Lucas-Kanade的实现使用图像金字塔，这意味着它在不同的尺度上进行搜索。因此，它支持大范围和小范围的运动（函数名中的`PyrLK`代表*pyramidal
    Lucas-Kanade*）。以下图表是金字塔的可视化——从低分辨率（或低放大）图像到高分辨率（或高放大）图像的进展：
- en: '![](img/e38cd409-3f9b-4e21-b0fd-28516c6f15be.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e38cd409-3f9b-4e21-b0fd-28516c6f15be.png)'
- en: For more details on optical flow and the Lucas-Kanade method, see the official
    OpenCV documentation at [http://docs.opencv.org/master/d7/d8b/tutorial_py_lucas_kanade.html](http://docs.opencv.org/master/d7/d8b/tutorial_py_lucas_kanade.html).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 关于光流和 Lucas-Kanade 方法的更多详细信息，请参阅官方 OpenCV 文档 [http://docs.opencv.org/master/d7/d8b/tutorial_py_lucas_kanade.html](http://docs.opencv.org/master/d7/d8b/tutorial_py_lucas_kanade.html)。
- en: OpenCV offers implementations of other optical flow algorithms as well. For
    example, the `calcOpticalFlowSF` function implements the SimpleFlow algorithm,
    which makes optimizations for high-resolution video by assuming that smooth (uniform)
    image regions move in unison. The `calcOpticalFlowFarneback` function implements
    Gunnar Farneback's algorithm, which posits that a neighborhood remains identifiable,
    even during motion, by the coefficients of a polynomial relationship among its
    pixel values. Both of these algorithms are forms of *dense* optical flow, meaning
    that they analyze every pixel in the image instead of just selected (*sparse*)
    features. More of OpenCV's optical flow functions are documented at [https://docs.opencv.org/master/dc/d6b/group__video__track.html](https://docs.opencv.org/master/dc/d6b/group__video__track.html)
    and [https://docs.opencv.org/master/d2/d84/group__optflow.html](https://docs.opencv.org/master/d2/d84/group__optflow.html).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 还提供了其他光流算法的实现。例如，`calcOpticalFlowSF` 函数实现了 SimpleFlow 算法，该算法通过假设平滑（均匀）图像区域一起移动来为高分辨率视频进行优化。`calcOpticalFlowFarneback`
    函数实现了 Gunnar Farneback 的算法，该算法认为一个邻域即使在运动过程中，也可以通过其像素值之间的多项式关系的系数来识别。这两种算法都是 *密集*
    光流的形式，这意味着它们分析图像中的每个像素，而不仅仅是选定的（*稀疏*）特征。更多 OpenCV 的光流函数文档可以在 [https://docs.opencv.org/master/dc/d6b/group__video__track.html](https://docs.opencv.org/master/dc/d6b/group__video__track.html)
    和 [https://docs.opencv.org/master/d2/d84/group__optflow.html](https://docs.opencv.org/master/d2/d84/group__optflow.html)
    找到。
- en: Of the several options, why choose `calcOpticalFlowPyrLK`? *You see, it is a
    pyramid,* as Imhotep said to the Pharaoh Djoser, *and it has open spaces inside
    it.* A pyramidal, sparse technique is a good way for us to cheaply and robustly
    track a few features in a face, which may change scale as it moves nearer to or
    farther from the camera.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在几个选项中，为什么选择 `calcOpticalFlowPyrLK`？*你看，它是一个金字塔，*正如伊姆霍特普对法老德杰瑟所说，*它内部有开阔的空间。*金字塔式、稀疏的技术是我们以低成本和鲁棒性跟踪面部几个特征的好方法，这些特征在接近或远离相机时可能会改变尺度。
- en: For our purposes, it is useful to select features inside a detected object,
    specifically a detected face. We choose an inner portion of the face (to avoid
    background regions) and then use an OpenCV function called `goodFeaturesToTrack`,
    which selects features based on the algorithm described in Jianbo Shi and Carlo
    Tomasi's paper, "Good Features to Track", *Proc. of IEEE Conf. on Computer Vision
    and Pattern Recognition*, pp. 593-600, June 1994.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的来说，选择检测到的对象内部的特征是有用的，特别是检测到的面部特征。我们选择面部的一个内部区域（以避免背景区域），然后使用一个名为 `goodFeaturesToTrack`
    的 OpenCV 函数，该函数根据 Jianbo Shi 和 Carlo Tomasi 的论文 "Good Features to Track"，*Proc.
    of IEEE Conf. on Computer Vision and Pattern Recognition*，第 593-600 页，1994 年 6
    月中描述的算法来选择特征。
- en: As the name suggests, the **Good Features to Track** (**GFTT**) algorithm (also
    known as the **Shi-Tomasi algorithm**) takes into account the requirements of
    tracking algorithms and tracking use cases, and attempts to select features that
    work well with these algorithms and use cases. As described in detail in the paper,
    good features to track must have a stable appearance with respect to small changes
    in the camera's perspective. Examples of poor features to track are reflections
    (such as sunlight on a car's hood) and lines that cross at different depths (such
    as a tree's branches), since these features move quickly as the viewer or camera
    moves. The effects of a change in perspective can be simulated (albeit imperfectly)
    by warping a given image and moving its contents linearly. Based on such a simulation,
    the most stable features can be selected.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，**Good Features to Track**（**GFTT**）算法（也称为 **Shi-Tomasi 算法**）考虑了跟踪算法和跟踪用例的要求，并试图选择与这些算法和用例配合得好的特征。正如论文中详细描述的那样，要跟踪的良好特征必须相对于相机视角的小变化具有稳定的外观。要跟踪的不良特征示例包括反射（如汽车引擎盖上的阳光）和在不同深度交叉的线条（如树木的树枝），因为这些特征在观察者或相机移动时会快速移动。可以通过扭曲给定图像并线性移动其内容来模拟视角变化的效果（尽管并不完美）。基于这样的模拟，可以选择最稳定的特征。
- en: OpenCV offers implementations of several feature-detection algorithms, besides
    Good Features to Track. For references to information about these other algorithms,
    please refer to [Appendix B](01685b22-2dcc-4d5b-ac19-0b8a15e0e3b1.xhtml),* Learning
    More about Feature Detection in OpenCV*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 除了 Good Features to Track 之外，还提供了几个特征检测算法的实现。有关这些其他算法的信息，请参阅[附录 B](01685b22-2dcc-4d5b-ac19-0b8a15e0e3b1.xhtml)，*在
    OpenCV 中学习更多关于特征检测的内容*。
- en: Setting up the project in Android Studio
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Android Studio 中设置项目
- en: For a refresher on setting up Android Studio and the OpenCV Android pack, refer
    to the *Setting up Android Studio and OpenCV* section in [Chapter 1](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml),
    *Preparing for the Mission*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 若要复习设置 Android Studio 和 OpenCV Android 包的步骤，请参阅[第 1 章](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml)中的*设置
    Android Studio 和 OpenCV*部分，*准备任务*。
- en: 'We will organize all the source code and resources for our Android app in an
    Android Studio project, as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下方式在 Android Studio 项目中组织所有源代码和资源：
- en: 'Open Android Studio and select File | New | New Project... from the menu. The
    Create New Project window should appear, and it should show the **Choose your
    project** form. Select Empty Activity, as shown in the following screenshot, and
    click Next:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Android Studio，从菜单中选择 File | New | New Project...。应该会出现创建新项目窗口，并显示**选择您的项目**表单。选择
    Empty Activity，如以下截图所示，然后点击 Next：
- en: '![](img/efe6e451-a22b-40a6-9dcf-34c017da0e1d.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/efe6e451-a22b-40a6-9dcf-34c017da0e1d.png)'
- en: 'The Create New Project window should show the Configure your project form. We
    want to specify that our app name is `Goldgesture`, its package name is `com.nummist.goldgesture`,
    it is a Java project, and its minimum Android SDK version is API level 21, which
    is Android 5.0\. You may choose any new folder as the project''s location. Fill
    out the form as shown in the following screenshot, and click Finish:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建新项目窗口应该显示配置您的项目表单。我们希望指定应用程序名称为`Goldgesture`，包名为`com.nummist.goldgesture`，它是一个
    Java 项目，其最小 Android SDK 版本是 API 级别 21，即 Android 5.0。您可以选择任何新的文件夹作为项目位置。按照以下截图所示填写表单，然后点击
    Finish：
- en: '![](img/aabdd9d9-f12d-467e-bb92-15548b922d21.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/aabdd9d9-f12d-467e-bb92-15548b922d21.png)'
- en: 'By default, Android Studio creates a main class, called MainActivity. Let''s
    rename this to give it a more descriptive name, CameraActivity. Right-click on
    `app/src/main/java/com.nummist.goldgesture/MainActivity` (in the Project pane)
    and select Refactor | Rename... from the context menu. The Rename dialog should
    appear. Fill it out as shown in the following screenshot, and click Refactor:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，Android Studio 创建一个主类，称为 MainActivity。让我们将其重命名为更具有描述性的名称，CameraActivity。在项目面板中右键单击`app/src/main/java/com.nummist.goldgesture/MainActivity`，从上下文菜单中选择
    Refactor | Rename...。应该会出现重命名对话框。按照以下截图所示填写，然后点击 Refactor：
- en: '![](img/4288f5da-a3f8-4c83-8314-72ff2b958849.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4288f5da-a3f8-4c83-8314-72ff2b958849.png)'
- en: 'Let''s rename the XML file that defines the GUI layout associated with the
    `main` class. Right-click on `app/src/main/res/layout/activity_main.xml` (in the
    Project pane) and select Refactor | Rename... from the context menu. The Rename
    dialog should appear again. Fill it out as shown in the following screenshot,
    and click Refactor:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们重命名与`main`类关联的 GUI 布局定义的 XML 文件。在项目面板中右键单击`app/src/main/res/layout/activity_main.xml`，从上下文菜单中选择
    Refactor | Rename...。应该再次出现重命名对话框。按照以下截图所示填写，然后点击 Refactor：
- en: '![](img/2ef64a54-3085-439e-a2fc-f6f7989c3cb0.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2ef64a54-3085-439e-a2fc-f6f7989c3cb0.png)'
- en: 'Since our app will depend on OpenCV, we need to import the OpenCV library module
    that we obtained as part of the OpenCV Android pack in [Chapter 1](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml)*,
    Preparing for the Mission*. From Android Studio''s menu, select File | New | New
    Module.... The Create New Module dialog should appear, and it should show the
    New Module form. Select Import Gradle Project, as shown in the following screenshot,
    and click Next:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们的应用程序将依赖于 OpenCV，我们需要导入在[第 1 章](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml)*，准备任务*中作为
    OpenCV Android 包的一部分获得的 OpenCV 库模块。从 Android Studio 的菜单中选择 File | New | New Module....
    应该会出现创建新模块对话框，并显示新模块表单。选择 Import Gradle Project，如以下截图所示，然后点击 Next：
- en: '![](img/700b1b37-8bae-46d9-b0d1-06ff77964796.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/700b1b37-8bae-46d9-b0d1-06ff77964796.png)'
- en: 'A file picker dialog should appear. Select the `sdk` subfolder of the OpenCV
    Android pack, as shown in the following screenshot, and confirm the choice by
    clicking the Open or OK button (whose name varies depending on the operating system):'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应该会出现一个文件选择对话框。选择 OpenCV Android 包的`sdk`子文件夹，如以下截图所示，然后通过点击 Open 或 OK 按钮（其名称取决于操作系统）确认选择：
- en: '![](img/bcf30f4e-c994-4972-b99b-67638aba9efc.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bcf30f4e-c994-4972-b99b-67638aba9efc.png)'
- en: 'The Create New Module dialog should show the Import Module from Source form.
    Enter `:OpenCV` in the Module name field, as shown in the following screenshot,
    and click Finish:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建新模块对话框应显示从源导入模块表单。在模块名称字段中输入`:OpenCV`，如图所示，然后点击完成：
- en: '![](img/fb464e3a-333e-4357-9cf3-cba7092b9e15.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fb464e3a-333e-4357-9cf3-cba7092b9e15.png)'
- en: At this point, Android Studio might prompt you to perform updates and accept
    license agreements so that you have all of OpenCV's dependencies. If you are prompted,
    agree.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在此阶段，Android Studio可能会提示您执行更新并接受许可协议，以便您拥有OpenCV的所有依赖项。如果您被提示，请同意。
- en: 'We need to specify that the `Goldgesture` app module depends on the OpenCV
    library module. From Android Studio''s menus, select File | Project Structure....
    The Project Structure dialog should appear. Under Modules, select app. Then, select
    the Dependencies tab, as shown in the following screenshot:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要指定`Goldgesture`应用程序模块依赖于OpenCV库模块。从Android Studio的菜单中选择文件 | 项目结构... 项目结构对话框应该出现。在模块下选择app。然后，选择依赖项选项卡，如图所示：
- en: '![](img/7a3f0eff-604e-496c-86ce-684cc3665d45.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7a3f0eff-604e-496c-86ce-684cc3665d45.png)'
- en: 'Hit the + button to add a dependency. A menu should appear. Select Module dependency.
    The Choose Modules dialog should appear. Select :OpenCV, as shown in the following
    screenshot, and click OK:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击+按钮添加依赖项。应该会出现一个菜单。选择模块依赖项。选择模块对话框应该出现。选择：OpenCV，如图所示，然后点击确定：
- en: '![](img/fd64d877-3ee5-491c-8201-5bee23d6207d.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fd64d877-3ee5-491c-8201-5bee23d6207d.png)'
- en: The OpenCV library is now linked into `Goldgesture`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV库现在已链接到`Goldgesture`。
- en: Getting a cascade file and audio files
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取级联文件和音频文件
- en: Like parts of [Chapter 3](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml), *Training
    a Smart Alarm to Recognize the Villain and His Cat,* *Angora Blue project*, `Goldgesture`
    performs human face detection and requires one of the cascade files that comes
    with OpenCV. Also, `Goldgesture` uses audio clips. The cascade file and audio
    clips are located in the book's GitHub repository in the `Chapter004/Goldgesture/app/src/main/res/raw` subfolder.
    If you are recreating the project from scratch, you should copy these files to
    your own `app/src/main/res/raw` folder. This folder is a standard location for
    files that we want bundled with the Android app in raw (unmodified) form. By default,
    this folder does not exist in new Android Studio projects.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如同[第3章](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml)的部分内容，*训练智能闹钟识别恶棍和他的猫*，*安哥拉蓝项目*，`Goldgesture`执行人脸检测并需要OpenCV附带的一个级联文件。此外，`Goldgesture`使用音频剪辑。级联文件和音频剪辑位于书籍的GitHub仓库中的`Chapter004/Goldgesture/app/src/main/res/raw`子文件夹中。如果您是从头开始重新创建项目，您应该将这些文件复制到自己的`app/src/main/res/raw`文件夹中。此文件夹是我们希望与Android应用程序捆绑的文件的标准位置，以原始（未修改）形式。默认情况下，新Android
    Studio项目中不存在此文件夹。
- en: 'To create it in Android Studio, right-click on the `app/src/main/res` folder
    (in the Project pane) and select New | Android Resource Directory from the context
    menu. The New Resource Directory window should appear. Fill it out as shown in
    the following screenshot, and click OK:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Android Studio中创建它，请右键单击`app/src/main/res`文件夹（在项目窗格中），然后从上下文菜单中选择新建 | Android资源目录。新资源目录窗口应该出现。填写它，如图所示，然后点击确定：
- en: '![](img/0fe45012-dc95-4f81-b826-c525c91ae4f9.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0fe45012-dc95-4f81-b826-c525c91ae4f9.png)'
- en: After you create the `app/src/main/res/raw` folder, you can drag and drop files
    into it in Android Studio.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建`app/src/main/res/raw`文件夹后，您可以在Android Studio中将文件拖放到其中。
- en: 'The audio clips are generated using the Vicki voice of the standard text-to-speech
    synthesizer on Mac. For example, one of the clips is created by running the following
    command in Terminal:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 音频剪辑是使用Mac标准文本到语音合成器的Vicki语音生成的。例如，一个剪辑是通过在终端中运行以下命令创建的：
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Speech synthesis is hours of fun for the whole family.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 语音合成对全家人来说都是一项充满乐趣的活动。
- en: The Mac speech synthesizer pronounces `007` as double-O seven. This is an anomaly.
    For example, *008* is pronounced as *zero, zero, eight*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Mac语音合成器将`007`读作双-O七。这是一个异常。例如，*008*被读作*零，零，八*。
- en: Specifying the app's requirements
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定应用程序的要求
- en: '`AndroidManifest.xml` (the Android Manifest) is the place where an app announces
    information that the system, Google Play, and other apps might need to know. For
    example, `Goldgesture` requires a front-facing camera and permission to use it
    (a license to shoot, one might say). `Goldgesture` also expects to run in landscape
    mode, regardless of the physical orientation of the phone, because OpenCV''s camera
    preview always uses the camera''s landscape dimensions (OpenCV''s Android documentation
    does not indicate whether this behavior is intended. Perhaps future versions will
    provide better support for portrait orientation). To specify these requirements,
    edit `app/src/main/AndroidManifest.xml` to match the following sample:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`AndroidManifest.xml`（AndroidManifest文件）是应用宣布系统、Google Play和其他应用可能需要知道的信息的地方。例如，`Goldgesture`需要前置摄像头并允许使用它（可以说是一种拍摄许可）。`Goldgesture`还期望在横屏模式下运行，无论手机的物理方向如何，因为OpenCV的摄像头预览始终使用摄像头的横屏尺寸（OpenCV的Android文档没有表明这种行为是否是预期的。也许未来的版本将提供更好的对竖屏方向的支持）。为了指定这些要求，编辑`app/src/main/AndroidManifest.xml`以匹配以下示例：'
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: When you open `AndroidManifest.xml` in Android Studio, you might see two tabs,
    one labeled Text and another labeled Merged Manifest. Select the Text tab, which
    allows us to directly edit the source code of `AndroidManifest.xml` (by contrast,
    the Merged Manifest tab is not directly editable, and it shows a combination of
    settings from `AndroidManifest.xml` and the project properties).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在Android Studio中打开`AndroidManifest.xml`时，你可能会看到两个标签页，一个标有“Text”，另一个标有“Merged
    Manifest”。选择“Text”标签页，它允许我们直接编辑`AndroidManifest.xml`的源代码（相比之下，“Merged Manifest”标签页不可直接编辑，它显示了`AndroidManifest.xml`和项目属性的设置组合）。
- en: Now, our app can use a camera and will remain in landscape mode. Also, if we
    publish it on Google Play, it will only be available to devices with a front-facing
    camera.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的应用可以使用摄像头，并且将保持在横屏模式。此外，如果我们将其发布在Google Play上，它将仅适用于具有前置摄像头的设备。
- en: Laying out a camera preview as the main view
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将摄像头预览作为主视图布局
- en: Android, like many systems, enables the programmer to specify GUI layouts in
    XML files. Our Java code can load an entire view, or pieces of it, from these
    XML files.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Android，像许多系统一样，允许程序员在XML文件中指定GUI布局。我们的Java代码可以从这些XML文件中加载整个视图或其部分。
- en: '`Goldgesture` has a simple layout that contains only a camera preview, on which
    we draw some additional graphics using OpenCV. The camera preview is represented
    by an OpenCV class called `JavaCameraView`. Let''s edit `app/src/main/res/layout/activity_camera.xml`
    to fill the layout with a `JavaCameraView`, using the front-facing camera, as
    follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`Goldgesture`有一个简单的布局，其中只包含一个摄像头预览，我们使用OpenCV在上面绘制一些额外的图形。摄像头预览由一个名为`JavaCameraView`的OpenCV类表示。让我们编辑`app/src/main/res/layout/activity_camera.xml`，使用前置摄像头填充布局，如下所示：'
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Alternatively, OpenCV also provides a class called `JavaCamera2View`. Both `JavaCameraView`
    and `JavaCamera2View` are implementations of an interface called `CameraBridgeViewBase`.
    The difference is that `JavaCamera2View` builds atop a more recent version of
    Android's camera APIs, but currently it yields a lower frame rate on many devices.
    The performance of `JavaCamera2View` could improve in future versions of OpenCV
    or on future Android devices, so you might want to run your own performance tests
    on the particular Android devices you are targeting.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，OpenCV还提供了一个名为`JavaCamera2View`的类。`JavaCameraView`和`JavaCamera2View`都是名为`CameraBridgeViewBase`的接口的实现。区别在于`JavaCamera2View`基于Android摄像头API的较新版本，但目前在许多设备上帧率较低。`JavaCamera2View`的性能可能在OpenCV的未来版本或未来的Android设备上得到改善，因此您可能需要在您针对的特定Android设备上运行自己的性能测试。
- en: Tracking back-and-forth gestures
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪来回手势
- en: 'Several common gestures consist of a repetitive, back-and-forth movement. Consider
    the following examples of this type of gesture:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的手势由重复的、来回移动组成。考虑以下此类手势的例子：
- en: Nodding (yes or I'm listening)
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点头（是或我在听）
- en: Shaking one's head (no or dismay)
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摇头（不或失望）
- en: Waving (a greeting)
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挥手（问候）
- en: Shaking hands (a greeting)
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 握手（问候）
- en: Shaking one's fist (a threat or a protest)
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挥拳头（威胁或抗议）
- en: Wagging a finger (scolding)
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挥手指（责备）
- en: Wiggling a finger or fingers (beckoning)
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挥动手指或手指（召唤）
- en: Tapping one's foot against the ground (impatience)
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用脚跟敲击地面（不耐烦）
- en: Tapping four fingers against a table (impatience)
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用四个手指敲击桌子（不耐烦）
- en: Tapping two fingers against a table (Thanks for the green tea)
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用两个手指敲击桌子（谢谢绿茶）
- en: Pacing (anxiety)
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 踱步（焦虑）
- en: Jumping up and down (excitement, joy)
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跳上跳下（兴奋，快乐）
- en: To help us recognize such gestures, let's write a class, `BackAndForthGesture`,
    which keeps track of the number of times that a value (such as an *x* coordinate
    or *y* coordinate) has oscillated between a low threshold and a high threshold.
    A certain number of oscillations can be considered a complete gesture.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们识别此类手势，让我们编写一个名为 `BackAndForthGesture` 的类，该类跟踪一个值（如 *x* 坐标或 *y* 坐标）在低阈值和高阈值之间振荡的次数。一定次数的振荡可以被认为是一个完整的手势。
- en: 'Create a file, `app/src/main/java/com/nummist/goldgesture/BackAndForthGesture.java`.
    To do this in Android Studio, right-click on the `app/src/main/java/com.nummist.goldgesture` folder
    (in the Project pane) and select New | Java Class from the context menu. The Create
    New Class window should appear. Fill it out as shown in the following screenshot,
    and click OK:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个文件，`app/src/main/java/com/nummist/goldgesture/BackAndForthGesture.java`。在
    Android Studio 中，右键点击 `app/src/main/java/com.nummist.goldgesture` 文件夹（在项目面板中），然后在上下文菜单中选择
    New | Java Class。创建新类窗口应该会出现。按照以下截图所示填写，然后点击 OK：
- en: '![](img/82d88afa-76ae-48f5-9b0d-2df8a34a379e.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82d88afa-76ae-48f5-9b0d-2df8a34a379e.png)'
- en: 'As member variables, `BackAndForthGesture` will store the minimum distance
    or threshold that defines a back or forth motion, an initial position, the latest
    delta from this position, and the number of back movements and forth movements.
    Here is the first part of the class''s code:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 作为成员变量，`BackAndForthGesture` 将存储定义反向或正向运动的最低距离或阈值、初始位置、从这个位置的最新 delta 以及反向运动和正向运动的次数。以下是类代码的第一部分：
- en: '[PRE3]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The back-and-forth count (or number of oscillations) is the lesser of the back
    count and the forth count. Let''s implement this rule in the following getter
    method:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 反向和正向计数（或振荡次数）是反向计数和正向计数的较小值。让我们在以下获取器方法中实现此规则：
- en: '[PRE4]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The constructor takes one argument, the minimum distance or threshold of movement:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数接受一个参数，即运动的最低距离或阈值：
- en: '[PRE5]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To begin tracking movement, we call a `start` method with an initial position
    as an argument. This method records the initial position and resets the delta
    and counts:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始跟踪运动，我们使用初始位置作为参数调用一个 `start` 方法。此方法记录初始位置并重置 delta 和计数：
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We are considering position as a one-dimensional value because a head nodding
    (up and down) or shaking (left and right) is a linear gesture. For an upright
    head, only one of the image's two dimensions is relevant to a nod or shake gesture.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将位置视为一维值，因为点头（上下）或摇头（左右）是一种线性手势。对于直立的头，图像的两个维度中只有一个与点头或摇头手势相关。
- en: 'To continue tracking movement, we call an `update` method with the new position
    as an argument. This method recalculates the delta and if a threshold has just
    been passed, the back count or forth count is incremented:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 要继续跟踪运动，我们使用新的位置作为参数调用一个 `update` 方法。此方法重新计算 delta，如果刚刚超过了阈值，则反向计数或正向计数会增加：
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If we consider the gesture complete, or for some other reason we believe the
    counts to be invalid, we call a `resetCounts` method:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们认为手势已完成，或者出于其他原因我们认为计数无效，我们将调用一个 `resetCounts` 方法：
- en: '[PRE8]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that `BackAndForthGesture` contains no computer vision functionality of
    its own, but the position values we pass to it will be derived from computer vision.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`BackAndForthGesture` 本身不包含计算机视觉功能，但我们传递给它的位置值将来自计算机视觉。
- en: Playing audio clips as questions and answers
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将音频剪辑作为问题和答案播放
- en: The logic of the question-and-answer sequence is another component that has
    no computer vision functionality. We encapsulate it in a class called `YesNoAudioTree`,
    which is responsible for playing the next audio clip whenever the app's computer
    vision component notifies it of a yes or no answer.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 问题-答案序列的逻辑是另一个没有计算机视觉功能的组件。我们将其封装在一个名为 `YesNoAudioTree` 的类中，该类负责在应用程序的计算机视觉组件通知它有是或否答案时播放下一个音频剪辑。
- en: Remember that the audio clips are part of the book's GitHub repository, and
    they belong in the project's `app/src/main/res/raw` folder. However, note that
    the audio clips in the repository are by no means an exhaustive set of questions
    and guesses about characters in the Bond franchise. Feel free to add your own
    clips and your own logic to play them.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，音频剪辑是本书的 GitHub 仓库的一部分，它们属于项目的 `app/src/main/res/raw` 文件夹。然而，请注意，仓库中的音频剪辑绝不是关于邦德系列中角色的问题和猜测的完整集合。请随意添加您自己的剪辑和您自己的逻辑来播放它们。
- en: 'Create a file, `app/src/main/java/com/nummist/goldgesture/YesNoAudioTree.java`.
    Our `YesNoAudioTree` class needs member variables to store a media player and
    a related context, an ID for the most-recently-played audio clip, and information
    gathered from the answers to previous questions. Specifically, the next question
    depends on whether the unknown person is already identified as a member of MI6,
    the CIA, the KGB, or a criminal organization. This information, along with the
    answer to the most recent question, will be enough for us to build a simple tree
    of questions to identify several characters from the Bond franchise. The class''s
    implementation begins as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个文件，`app/src/main/java/com/nummist/goldgesture/YesNoAudioTree.java`。我们的`YesNoAudioTree`类需要成员变量来存储一个媒体播放器和相关上下文，最近播放的音频剪辑的ID，以及从之前问题的答案中收集的信息。具体来说，下一个问题取决于未知的人是否已经被识别为MI6、CIA、KGB或犯罪组织的成员。这些信息，加上最近问题的答案，将足以让我们构建一个简单的问题树，以识别来自邦德系列的多个人物。类的实现开始如下：
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The class is instantiated with a `Context` object, which is a standard abstraction
    of the app''s Android environment:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 该类使用`Context`对象实例化，这是应用Android环境的标准抽象：
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `Context` object is needed to create a media player, as we will see later
    in this section of the chapter.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`Context`对象是创建媒体播放器所必需的，正如我们将在本章的这一节中看到的那样。'
- en: For more information about the Android SDK's `MediaPlayer` class, see the official
    documentation at [http://developer.android.com/reference/android/media/MediaPlayer.html](http://developer.android.com/reference/android/media/MediaPlayer.html).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Android SDK的`MediaPlayer`类的更多信息，请参阅官方文档[http://developer.android.com/reference/android/media/MediaPlayer.html](http://developer.android.com/reference/android/media/MediaPlayer.html)。
- en: 'To (re)start from the first question, we call a `start` method. It resets the
    data about the person and plays the first audio clip using a private helper method,
    `play`:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要（重新）从第一个问题开始，我们调用一个`start`方法。它重置有关个人的数据，并使用一个私有的辅助方法`play`播放第一个音频剪辑：
- en: '[PRE11]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To stop any current clip and clean up the audio player (for example, when the
    app pauses or finishes), we call a `stop` method:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 要停止任何当前剪辑并清理音频播放器（例如，当应用暂停或结束时），我们调用一个`stop`方法：
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'When the user has answered Yes to a question, we call the `takeYesBranch` method.
    It uses nested `switch` statements to pick the next audio clip based on previous
    answers and the most recent question:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户对一个问题的回答是肯定时，我们调用`takeYesBranch`方法。它使用嵌套的`switch`语句根据之前的答案和最近的问题选择下一个音频剪辑：
- en: '[PRE13]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Similarly, when the user has answered No to a question, we call the `takeNoBranch`
    method, which also contains big, nested `switch` statements:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，当用户对一个问题的回答是否定时，我们调用`takeNoBranch`方法，该方法也包含大的嵌套`switch`语句：
- en: '[PRE14]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'When certain clips finish, we want to automatically advance to another clip
    without requiring a Yes or No from the user. A private helper method, `takeAutoBranch`,
    implements the relevant logic in a `switch` statement:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 当某些剪辑结束时，我们希望自动跳转到另一个剪辑，而无需用户输入是或否。一个私有的辅助方法`takeAutoBranch`在`switch`语句中实现了相关逻辑：
- en: '[PRE15]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Whenever we need to play an audio clip, we call the `play` private helper method.
    It creates an instance of `MediaPlayer` using the context and an audio clip''s
    ID, which is given to `play` as an argument. The audio is played and a callback
    is set so that the media player will be cleaned up and `takeAutoBranch` will be
    called when the clip is done:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们需要播放一个音频剪辑时，我们调用`play`私有的辅助方法。它使用上下文和一个音频剪辑的ID创建一个`MediaPlayer`实例，该ID作为参数传递给`play`。音频播放，并设置一个回调，以便在剪辑完成后清理媒体播放器并调用`takeAutoBranch`：
- en: '[PRE16]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now that we have written our supporting classes, we are ready to tackle the
    app's main class, including the computer vision functionality.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经编写了我们的支持类，我们准备处理应用的主类，包括计算机视觉功能。
- en: Capturing images and tracking faces in an activity
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在活动中捕获图像和跟踪面部
- en: An Android app is a state machine in which each state is called an **activity**.
    An activity has a life cycle. For example, it can be created, paused, resumed,
    and finished. During a transition between activities, the paused or finished activity
    can send data to the created or resumed activity. An app can define many activities
    and transition between them in any order. It can even transition between activities
    defined by the Android SDK or by other apps.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 安卓应用是一个状态机，其中每个状态被称为**活动**。活动有一个生命周期。例如，它可以被创建、暂停、恢复和完成。在活动之间的转换过程中，暂停或完成的活动可以向创建或恢复的活动发送数据。一个应用可以定义许多活动，并以任何顺序在它们之间转换。它甚至可以在由Android
    SDK或其他应用定义的活动之间进行转换。
- en: For more information about Android activities and their life cycles, see the
    official documentation at [http://developer.android.com/guide/components/activities.html](http://developer.android.com/guide/components/activities.html). For
    more information about OpenCV's Android and Java APIs (used throughout our activity
    class), see the official Javadocs at [https://docs.opencv.org/master/javadoc/index.html](https://docs.opencv.org/master/javadoc/index.html).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Android活动和它们的生命周期的更多信息，请参阅官方文档[http://developer.android.com/guide/components/activities.html](http://developer.android.com/guide/components/activities.html)。有关OpenCV的Android和Java
    API（在我们的活动类中广泛使用）的更多信息，请参阅官方Javadocs[https://docs.opencv.org/master/javadoc/index.html](https://docs.opencv.org/master/javadoc/index.html)。
- en: 'OpenCV provides classes and interfaces that can be considered add-ons to an
    activity''s life cycle. Specifically, we can use OpenCV callback methods to handle
    the following events:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV提供了类和接口，可以将它们视为活动生命周期的附加组件。具体来说，我们可以使用OpenCV回调方法来处理以下事件：
- en: The camera preview starts
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摄像头预览开始
- en: The camera preview stops
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摄像头预览停止
- en: The camera preview captures a new frame
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摄像头预览捕获了一个新的帧
- en: '`Goldgesture` uses just one activity, called `CameraActivity`. `CameraActivity`
    uses a `CameraBridgeViewBase` object (more specifically, a `JavaCameraView` object)
    as its camera preview. (Recall that we saw this earlier, in the *Laying out a
    camera preview as the main view* section of this chapter, when we implemented
    `CameraActivity`''s layout in XML.) `CameraActivity` implements an interface called
    `CvCameraViewListener2`, which provides callbacks for this camera preview. (Alternatively,
    an interface called `CvCameraViewListener` can serve this purpose. The difference
    between the two interfaces is that `CvCameraViewListener2` allows us to specify
    a format for the captured image, whereas `CvCameraViewListener` does not.) The
    implementation of our class begins as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`Goldgesture`只使用一个活动，称为`CameraActivity`。`CameraActivity`使用一个`CameraBridgeViewBase`对象（更具体地说，是一个`JavaCameraView`对象）作为其摄像头预览。（回想一下，我们之前在本章的*将摄像头预览作为主视图布局*部分中看到了这个，当时我们实现了`CameraActivity`的XML布局。）`CameraActivity`实现了一个名为`CvCameraViewListener2`的接口，它为此摄像头预览提供回调。（或者，一个名为`CvCameraViewListener`的接口也可以起到这个作用。两个接口之间的区别在于，`CvCameraViewListener2`允许我们指定捕获图像的格式，而`CvCameraViewListener`则不提供这种功能。）我们类的实现如下：'
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For readability and easy editing, we use static final variables to store many
    parameters in our computer vision functions. You might wish to adjust these values
    based on experimentation. First, we have face-detection parameters that should
    be familiar to you from the Angora Blue project in [Chapter 3](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml)*,* *Training
    a Smart Alarm to R**ecognize the Villain and His Cat*:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高可读性和便于编辑，我们在计算机视觉函数中使用静态最终变量来存储许多参数。您可能希望根据实验调整这些值。首先，我们有面部检测参数，这些参数您可能从[第3章](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml)*,*
    *训练一个智能闹钟来识别恶棍和他的猫*中已经熟悉：
- en: '[PRE18]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'For the purpose of selecting features, we do not use the entire detected face.
    Rather, we use an inner portion that is less likely to contain any non-face background.
    Thus, we define a proportion of the face that should be excluded from feature
    selection on each side:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择特征，我们不使用整个检测到的面部。相反，我们使用一个内部区域，这个区域不太可能包含任何非面部背景。因此，我们定义了面部两侧应该排除在特征选择之外的面积比例：
- en: '[PRE19]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'For face tracking using optical flow, we define a minimum and maximum number
    of features. If we fail to track at least the minimum number of features, we deem
    that the face has been lost. We also define a minimum feature quality (relative
    to the quality of the best feature found), a minimum pixel distance between features,
    and a maximum acceptable error value when trying to match a new feature to an
    old feature. As we will see later in this section of the chapter, these parameters
    pertain to OpenCV''s `calcOpticalFlowPyrLK` function and its return values. Here
    are the declarations:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用光流进行人脸追踪，我们定义了一个最小和最大特征数。如果我们无法追踪至少最小数量的特征，我们认为人脸已经丢失。我们还定义了一个最小特征质量（相对于找到的最佳特征的质量），特征之间的最小像素距离，以及尝试将新特征与旧特征匹配时的最大可接受误差值。正如我们将在本章的后续部分看到，这些参数与OpenCV的`calcOpticalFlowPyrLK`函数及其返回值相关。以下是声明：
- en: '[PRE20]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We also define how much movement (as a proportion of the image size) and how
    many back-and-forth cycles are required before we deem that a nod or shake has
    occurred:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了在认为点头或摇头发生之前所需的移动量（作为图像大小的比例）和往返周期数：
- en: '[PRE21]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Our member variables include the camera view, the dimensions of captured images,
    and the images at various stages of processing. The images are stored in OpenCV
    `Mat` objects, which are analogous to the NumPy arrays that we saw in the Python
    bindings. OpenCV always captures the images in landscape format, but we reorient
    them to portrait format, which is a more common orientation for a picture of one''s
    own face on a smartphone. Here are the relevant variable declarations:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的成员变量包括摄像头视图、捕获图像的尺寸以及处理各个阶段的图像。这些图像存储在OpenCV `Mat`对象中，类似于我们在Python绑定中看到的NumPy数组。OpenCV始终以横幅格式捕获图像，但我们将其重新定向为竖幅格式，这是智能手机上自己人脸图片更常见的方向。以下是相关的变量声明：
- en: '[PRE22]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As seen in the following code and comments, we also declare several member
    variables related to face detection and tracking:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下代码和注释所示，我们还声明了与人脸检测和追踪相关的几个成员变量：
- en: '[PRE23]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we store instances of the classes that we defined earlier, namely
    `BackAndForthGesture` (in the *Tracking back-and-forth gestures* section of this
    chapter) and `YesNoAudioTree` (in the *Playing audio clips as questions and answers*
    section of this chapter):'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们存储了我们之前定义的类的实例，即`BackAndForthGesture`（在本章的*追踪往返手势*部分）和`YesNoAudioTree`（在本章的*播放音频剪辑作为问题和答案*部分）：
- en: '[PRE24]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, let''s implement the standard life cycle callbacks of an Android activity.
    First, when the activity is created, we try to load the OpenCV library (if for
    some reason this fails, we log an error message and exit). If OpenCV loads successfully,
    we specify that we want to keep the screen on even when there is no touch interaction
    (since all interaction is through the camera). Moreover, we need to load the layout
    from the XML file, get a reference to the camera preview, and set this activity
    as the handler for the camera preview''s events. Here is the implementation:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们实现一个Android活动的标准生命周期回调。首先，当活动被创建时，我们尝试加载OpenCV库（如果由于某些原因失败，我们将记录错误信息并退出）。如果OpenCV成功加载，我们指定即使在没有触摸交互的情况下也要保持屏幕开启（因为所有交互都是通过摄像头进行的）。此外，我们需要从XML文件中加载布局，获取摄像头预览的引用，并将此活动设置为摄像头预览事件的处理程序。以下是实现代码：
- en: '[PRE25]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Note that we have not yet initialized most of our member variables. Instead,
    we do so once the camera preview has started. When the activity is paused, we
    disable the camera preview, stop the audio, and reset the gesture recognition
    data, as seen in the following code:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们尚未初始化大多数成员变量。相反，我们在摄像头预览开始后进行初始化。当活动暂停时，我们禁用摄像头预览，停止音频，并重置手势识别数据，如下面的代码所示：
- en: '[PRE26]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'When the activity resumes (including the first time it comes to the foreground,
    after being created), we check whether the user has granted permission for the
    app to use the camera. If permission has not yet been granted, we request it.
    (In some circumstances, Android requires us to display a rationale for the permission
    request. We do this through a private helper method called `showRequestPermissionRationale`.)
    If permission has already been granted, we enable the camera view. Here is the
    relevant code:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 当活动恢复（包括在创建后第一次进入前台时），我们检查用户是否已授予应用使用摄像头的权限。如果尚未授予权限，我们将请求权限。（在某些情况下，Android要求我们显示权限请求的理由。我们通过一个名为`showRequestPermissionRationale`的私有辅助方法来完成此操作。）如果权限已经授予，我们启用摄像头视图。以下是相关代码：
- en: '[PRE27]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'When the activity is destroyed, we clean things up in the same way as when
    the activity is paused:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当活动被销毁时，我们清理的方式与活动暂停时相同：
- en: '[PRE28]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Our `showRequestPermissionRationale` helper method shows a dialog that explains
    why `Goldgesture` needs to use the camera. When the user clicks this dialog''s
    `OK` button, we request permission to use the camera:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`showRequestPermissionRationale`辅助方法显示一个对话框，解释为什么`Goldgesture`需要使用摄像头。当用户点击此对话框的`OK`按钮时，我们请求使用摄像头的权限：
- en: '[PRE29]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We implement a callback to handle the result of the permission request. If
    the user granted permission to use the camera, we enable the camera view. Otherwise,
    we log an error and exit:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现一个回调来处理权限请求的结果。如果用户授予使用摄像头的权限，我们启用摄像头视图。否则，我们记录错误并退出：
- en: '[PRE30]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, let''s turn our attention to the camera callbacks. When the camera preview
    starts (after the OpenCV library is loaded and permission to use the camera is
    obtained), we initialize our remaining member variables. To begin, we store the
    pixel dimensions that the camera is using:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将注意力转向摄像头回调。当摄像头预览开始（在加载OpenCV库并获得使用摄像头的权限之后），我们初始化剩余的成员变量。首先，我们存储摄像头正在使用的像素尺寸：
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, we initialize our face-detection variables, mostly through a private
    helper method called `initFaceDetector`. The role of `initFaceDetector` includes
    loading the detector''s cascade file, `app/main/res/raw/lbpcascade_frontalface.xml`.
    A lot of boilerplate code for file handling and error handling is involved in
    this task, so separating it into another function improves readability. We will
    examine the helper function''s implementation later in this section of the chapter,
    but here is the call:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过一个名为`initFaceDetector`的私有辅助方法初始化我们的面部检测变量。`initFaceDetector`的作用包括加载检测器的级联文件，`app/main/res/raw/lbpcascade_frontalface.xml`。在这个任务中涉及大量的样板代码用于文件处理和错误处理，因此将其分离到另一个函数中可以提高可读性。我们将在本章的这一节稍后检查辅助函数的实现，但这里是如何调用的：
- en: '[PRE32]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As we did in [Chapter 3](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml)*, Training
    a Smart Alarm to Recognize the Villain and His Cat*, we determine the smaller
    of the two image dimensions and use it in proportional size calculations:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第3章](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml)*，训练智能闹钟以识别恶棍和他的猫*中所做的那样，我们确定两个图像尺寸中的较小者，并在成比例的大小计算中使用它：
- en: '[PRE33]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We initialize matrices relating to the features:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化与特征相关的矩阵：
- en: '[PRE34]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We specify colors (in **RGB** (**red, green, and blue**) format, not **BGR**
    (**blue, green, and red**)) for drawing a rectangle around the face and circles
    around the features:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定用于在脸部周围绘制矩形和在特征周围绘制圆圈的**颜色**（以**RGB**（**红色、绿色和蓝色**）格式，而不是**BGR**（**蓝色、绿色和红色**））：
- en: '[PRE35]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We initialize variables relating to nod and shake recognition:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化与点头和摇头识别相关的变量：
- en: '[PRE36]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We initialize and start the audio sequence:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化并开始音频序列：
- en: '[PRE37]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Finally, we initialize the image matrices, most of which are transposed to
    be in portrait format:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们初始化图像矩阵，其中大部分都是转置以适应肖像格式：
- en: '[PRE38]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'When the camera view stops, we do not do anything. Here is the empty callback
    method:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 当摄像头视图停止时，我们不进行任何操作。以下是空的回调方法：
- en: '[PRE39]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'When the camera captures a frame, we do all the real work, the computer vision.
    We start by getting the color image (in **red, green, blue, and alpha** (**RGBA**)
    format, not BGR), convert it to grayscale, and reorient it to portrait format.
    The reorientation from landscape to portrait format is equivalent to rotating
    the image''s *content* 90 degrees *counterclockwise*, or rotating the image''s
    *X and Y **coordinate axes* 90 degrees *clockwise.* To accomplish this, we apply
    a transpose operation followed by a vertical flip. After reorienting the grayscale
    image to portrait format, we equalize it. Thus, the callback''s implementation
    begins as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 当摄像头捕获一帧时，我们进行所有真正的操作，即计算机视觉。我们首先获取彩色图像（以**红色、绿色、蓝色和透明度**（**RGBA**）格式，而不是BGR），将其转换为灰度，并将其重新调整为肖像格式。从横向到肖像格式的重新调整相当于将图像的 *内容* 逆时针旋转90度，或者将图像的
    *X和Y坐标轴* 顺时针旋转90度。为了实现这一点，我们应用转置操作后进行垂直翻转。在将灰度图像重新调整为肖像格式后，我们对其进行均衡。因此，回调的实现开始如下：
- en: '[PRE40]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We get the RGBA image by calling `inputFrame.rgba()` and then we convert it
    to grayscale. Alternatively, we could get the grayscale image directly by calling
    `inputFrame.gray()`. In our case, we want both the RGBA and grayscale images because
    we use the RGBA image for display and the grayscale image for detection and tracking.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用`inputFrame.rgba()`来获取RGBA图像，然后将其转换为灰度图。或者，我们可以直接通过调用`inputFrame.gray()`来获取灰度图像。在我们的情况下，我们想要RGBA和灰度图像，因为我们使用RGBA图像进行显示，而使用灰度图像进行检测和跟踪。
- en: 'Next, we declare a list of features. A standard Java `List` allows for fast
    insertion and removal of elements, whereas an OpenCV `Mat` does not, so we are
    going to need a `List` when we filter out features that did not track well. Here
    is the declaration:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们声明一个特征列表。标准的Java `List`允许快速插入和删除元素，而OpenCV的`Mat`则不允许，因此当我们过滤掉跟踪不佳的特征时，我们需要一个`List`。以下是声明：
- en: '[PRE41]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We detect faces—a familiar task from the Angora Blue project in [Chapter 3](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml)*,
    Training a Smart Alarm to Recognize the Villain and His Cat*. Unlike in OpenCV''s
    Python bindings, the structure to store the face rectangles is provided as an
    argument:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检测面部——这是来自[第3章](49c9a5fb-89a3-4c0d-bbee-021d2618168c.xhtml)*，训练一个智能闹钟来识别恶棍和他的猫*的Angora
    Blue项目的熟悉任务。与OpenCV的Python绑定不同，存储面部矩形的结构作为参数提供：
- en: '[PRE42]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'If at least one face is detected, we take the first detected face and draw
    a rectangle around it. We are performing face detection on an image in portrait
    orientation, but we are drawing the original image in landscape orientation, so
    some conversion of coordinates is necessary. Note that the origin (the upper-left
    corner) of the portrait image corresponds to the upper-right corner of the landscape
    image.  Here is the code:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果至少检测到一个面部，我们取第一个检测到的面部并围绕它画一个矩形。我们正在对纵向图像执行面部检测，但我们以横向图像绘制原始图像，因此需要进行一些坐标转换。注意，纵向图像的起点（左上角）对应于横向图像的右上角。以下是代码：
- en: '[PRE43]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Next, we select features within the inner part of the detected face. We specify
    the region of interest by passing a mask to OpenCV''s `goodFeaturesToTrack` function.
    A mask is an image that is white in the foreground (the inner part of the face)
    and black in the background. The following code finds the region of interest,
    creates the mask, and calls `goodFeaturesToTrack` with all relevant parameters:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在检测到的面部内部选择特征。我们通过传递一个掩码到OpenCV的`goodFeaturesToTrack`函数来指定感兴趣的区域。掩码是一个前景为白色（面部的内部部分）而背景为黑色的图像。以下代码找到感兴趣的区域，创建掩码，并使用所有相关参数调用`goodFeaturesToTrack`：
- en: '[PRE44]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Note that we copy the features into several variables: a matrix of initial
    features, a matrix of current features, and a mutable list of features that we
    will filter later.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们将特征复制到几个变量中：一个初始特征的矩阵，一个当前特征的矩阵，以及一个我们将稍后过滤的特征的可变列表。
- en: 'Depending on whether we were already tracking a face, we call a helper function
    to either initialize our data on gestures or update our data on gestures. We also
    record that we are now tracking a face:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们是否已经在跟踪面部，我们调用一个辅助函数来初始化我们的手势数据或更新我们的手势数据。我们还记录我们现在正在跟踪一个面部：
- en: '[PRE45]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Alternatively, we might not have detected any face in this frame. Then, we
    update any previously-selected features using OpenCV''s `calcOpticalFlowPyrLK`
    function to give us a matrix of new features, a matrix of error values, and a
    matrix of status values (`0` for an invalid feature, `1` for a valid feature).
    Being invalid typically means that the new feature is estimated to be outside
    the frame and thus it can no longer be tracked by optical flow. We convert the
    new features to a list and filter out the ones that are invalid or have a high
    error, as seen in the following code:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可能在这个帧中没有检测到任何面部。然后，我们使用OpenCV的`calcOpticalFlowPyrLK`函数更新任何先前选定的特征，以给我们一个新特征的矩阵，一个错误值的矩阵和一个状态值的矩阵（`0`表示无效特征，`1`表示有效特征）。无效通常意味着新特征估计在帧外，因此它不能再通过光流跟踪。我们将新特征转换为列表，并过滤掉无效或错误高的那些，如下面的代码所示：
- en: '[PRE46]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'If too few features remain after filtering, we deem that the face is no longer
    tracked and we discard all features. Otherwise, we put the accepted features back
    in the matrix of current features and we update our data on gestures:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果过滤后特征太少，我们认为面部不再被跟踪，并丢弃所有特征。否则，我们将接受的特征放回当前特征的矩阵中，并更新我们的手势数据：
- en: '[PRE47]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We draw green circles around the current features. Again, we must convert coordinates
    from portrait format back to landscape format in order to draw on the original
    image:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在当前特征周围画绿色圆圈。同样，我们必须将坐标从竖直格式转换回横幅格式，以便在原始图像上绘制：
- en: '[PRE48]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'At the end of the frame, the current equalized gray image and current features
    become the previous equalized gray image and previous features. Rather than copying
    these matrices, we swap references:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在帧的末尾，当前均衡的灰度图像和当前特征成为前一个均衡的灰度图像和前一个特征。我们不是复制这些矩阵，而是交换引用：
- en: '[PRE49]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We horizontally flip the preview image to make it look like a mirror. Then,
    we return it so that OpenCV can display it:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们水平翻转预览图像，使其看起来像镜子。然后，我们将其返回，以便OpenCV可以显示它：
- en: '[PRE50]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We have mentioned several helper functions, which we will examine now. When
    we start analyzing face motion, we find the geometric mean of the features and
    use the mean''s *x* and *y* coordinates, respectively, as the starting coordinates
    for shake and nod gestures:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到了几个辅助函数，我们现在将检查它们。当我们开始分析面部运动时，我们找到特征的几何平均值，并分别使用平均值*x*和*y*坐标作为摇头和点头手势的起始坐标：
- en: '[PRE51]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Recall that our `BackAndForthGesture` class uses one-dimensional positions.
    For an upright head, only the *x* coordinate is relevant to a shake gesture and
    only the *y* coordinate is relevant to a nod gesture.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，我们的`BackAndForthGesture`类使用一维位置。对于一个直立的头，只有*x*坐标与摇头手势相关，只有*y*坐标与点头手势相关。
- en: 'Similarly, as we continue to analyze face motion, we find the features'' new
    geometric mean and use the mean''s coordinates to update the shake and nod data.
    Based on the number of back-and-forth shaking or nodding motions, we may take
    a yes branch or a no branch in the question-and-answer tree. Alternatively, we
    may decide that the user''s current gesture is ambiguous (both a yes and a no),
    in which case we reset the data:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，当我们继续分析面部运动时，我们找到特征的新几何平均值，并使用平均值坐标来更新摇头和点头数据。根据前后摇动或点头的次数，我们可能在问答树中采取是分支或否分支。或者，我们可能决定用户的当前手势是模糊的（既是是又是否），在这种情况下，我们将重置数据：
- en: '[PRE52]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We always reset the nod gesture data and the shake gesture data at the same
    time:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们总是同时重置点头手势数据和摇头手势数据：
- en: '[PRE53]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Our helper method for initializing the face detector is very similar to the
    method found in an official OpenCV sample project that performs face detection
    on Android. We copy the cascade''s raw data from the app bundle to a new file
    that is more accessible. Then, we initialize a `CascadeClassifier` object using
    this file''s path. If an error is encountered at any point, we log it and close
    the app. Here is the method''s implementation:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化面部检测器的辅助方法与在官方OpenCV示例项目中找到的方法非常相似。我们将级联的原始数据从应用包复制到一个更易于访问的新文件。然后，我们使用此文件的路径初始化一个`CascadeClassifier`对象。如果在任何点上遇到错误，我们将记录它并关闭应用。以下是此方法的实现：
- en: '[PRE54]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'That''s all the code! We are ready to test. Make sure your Android device has
    its sound turned on. Plug the device into a USB port and press the run button
    (the play icon in green). The first time you run the project, you might see the
    Select Deployment Target window:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 那就是所有的代码！我们准备测试。确保你的Android设备已经打开声音。将设备插入USB端口并按下运行按钮（绿色中的播放图标）。第一次运行项目时，你可能会看到选择部署目标窗口：
- en: '![](img/9dfbc1fd-fc7d-49bd-a22c-2b229ea9e69b.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9dfbc1fd-fc7d-49bd-a22c-2b229ea9e69b.png)'
- en: If you see this window, select your Android device and hit the OK button.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看到这个窗口，请选择你的Android设备并点击OK按钮。
- en: 'Soon, you should see the app''s camera preview appear on your device. Nod or
    shake your head knowingly as the questions are asked:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 很快，你应该会在设备上看到应用的相机预览出现。当问题被提出时，有意识地点头或摇头：
- en: '![](img/0bc6829a-8706-47d7-b9c3-efce3bd336ad.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0bc6829a-8706-47d7-b9c3-efce3bd336ad.png)'
- en: You should see a blue rectangle around your face, and green dots that remain
    (more or less) anchored to some features of your face as you move. Refer to the
    previous screenshot as an example.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会看到围绕你脸部的蓝色矩形，以及随着你的移动而（或多或少）锚定在你脸部某些特征上的绿色点。参考之前的截图作为示例。
- en: To improve the gesture detection results for your particular camera and environment,
    you may want to experiment with adjusting the parameters that we defined as constants
    in the code. Moreover, try to keep the camera still. Camera motion will interfere
    with our gesture detection algorithm because we rely on optical flow, which does
    not differentiate between camera motion and subject motion.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改善特定摄像头和环境的手势检测结果，您可能想要尝试调整我们在代码中定义为常数的参数。此外，尽量保持摄像头静止。摄像头的运动将干扰我们的手势检测算法，因为我们依赖于光流，而光流无法区分摄像头运动和主体运动。
- en: Summary
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Silence is golden—or perhaps gestures are. At least, gestures can fill an awkward
    silence and control an app that whispers reminders in your earphones.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 沉默是金——或者也许手势才是。至少，手势可以填补尴尬的沉默，并控制耳机中低声提醒的应用。
- en: In this chapter, we built our first Android app with OpenCV's Java bindings.
    We also learned to use optical flow to track the movement of an object after detection.
    Thus, we are able to recognize a gesture, such as a head moving up and down in
    a nod.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用 OpenCV 的 Java 绑定构建了我们的第一个 Android 应用。我们还学习了如何使用光流来跟踪检测到的物体运动。因此，我们能够识别出像点头时头部上下移动这样的手势。
- en: In the next chapter, our project deals with motion in three dimensions. We will
    build a system that estimates changes in distance in order to alert a driver when
    the car is being followed.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们的项目将处理三维运动。我们将构建一个系统，该系统可以估算距离的变化，以便在汽车被跟踪时提醒驾驶员。
