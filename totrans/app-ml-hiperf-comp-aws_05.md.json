["```py\n...\nimport sys\n!{sys.executable} -m pip install \"sagemaker>=2.51.0\"\n!{sys.executable} -m pip install --upgrade -q \"scikit-learn\"\n!{sys.executable} -m pip install \"sdv\"\nimport sklearn\nsklearn.__version__\nimport sdv\nsdv.__version__\n...\n```", "```py\n...\nimport os\nfrom sklearn.datasets import fetch_california_housing\nimport time\nimport boto3\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport sagemaker\nfrom sagemaker import get_execution_role\nprefix = 'california_housing'\nrole = get_execution_role()\nbucket = sagemaker.Session(boto3.Session()).default_bucket()\n...\n```", "```py\n...\ndata_dir = os.path.join(os.getcwd(), \"data\")\nos.makedirs(data_dir, exist_ok=True)\nraw_dir = os.path.join(os.getcwd(), \"data/raw\")\nos.makedirs(raw_dir, exist_ok=True)\ndata = fetch_california_housing(data_home=raw_dir, download_if_missing=True, return_X_y=False, as_frame=True)\n...\ndf_data = data.data\n...\n```", "```py\n...\ndf_data.astype({'Population': 'int32'}).dtypes\n...\n```", "```py\n...\nimport matplotlib.pyplot as plt\ndef plot_boxplot(data, title):\n    plt.figure(figsize =(5, 4))\n    plt.boxplot(data)\n    plt.title(title)\n    plt.show()\n...\ndf_data.drop(df_data[df_data['avgNumRooms'] > 9].index, inplace = True)\ndf_data.drop(df_data[df_data['avgNumRooms'] <= 1].index, inplace = True)\nplot_boxplot(df_data.avgNumRooms, 'rooms')\n...\n```", "```py\n...\ndf_data.isna().sum()\n...\n```", "```py\n...\nfrom sdv.tabular import TVAE\nmodel = TVAE(rounding=2)\nmodel.fit(df_data)\nmodel_dir = os.path.join(os.getcwd(), \"model\")\nos.makedirs(model_dir, exist_ok=True)\nmodel.save(f'{model_dir}/tvae_model.pkl')\n...\n```", "```py\n...\nfrom sdv.tabular import TVAE\nmodel = TVAE.load(f'{model_dir}/tvae_model.pkl')\nsynthetic_data = model.sample(1000000)\n...\n```", "```py\n...\nsess = boto3.Session()\nsagemaker_session = sagemaker.Session(boto_session=sess)\nsynthetic_data.to_parquet('data/raw/data.parquet.gzip', compression='gzip')\nrawdata_s3_prefix = \"{}/data/raw\".format(prefix)\nraw_s3 = sagemaker_session.upload_data(path=\"./data/raw/data.parquet.gzip\", key_prefix=rawdata_s3_prefix)\n...\n```", "```py\n%load_ext sagemaker_studio_analytics_extension.magics\n%sm_analytics emr connect --cluster-id <EMR Cluster ID> --auth-type None\n```", "```py\nhousing_data=sqlContext.read.parquet('s3://<SageMaker Default Bucket>/california_housing/data/raw/data.parquet.gzip')\n```", "```py\nprint((housing_data.count(), len(housing_data.columns)))\nhousing_data.printSchema()\n```", "```py\n(1000000, 9)\nRoot\n|-- medianIncome: double (nullable = true)\n|-- medianHousingAge: double (nullable = true)\n|-- avgNumRooms: double (nullable = true)\n|-- avgNumBedrooms: double (nullable = true)\n|-- population: double (nullable = true)\n|-- avgHouseholdMembers: double (nullable = true)\n|-- latitude: double (nullable = true)\n|-- longitude: double (nullable = true)\n|-- medianHouseValue: double (nullable = true)\n```", "```py\nfrom pyspark.sql.functions import isnan, when, count, col\nhousing_data.select([count(when(isnan(c), c)).alias(c) for c in housing_data.columns]).show()\n```", "```py\nimport matplotlib.pyplot as plt\ndf = housing_data.select('avgNumRooms', 'avgNumBedrooms', 'population').toPandas()\ndf.hist(figsize=(10, 8), bins=20, edgecolor=\"black\")\nplt.subplots_adjust(hspace=0.3, wspace=0.5)\nplt.show()\n%matplot plt\n```", "```py\nplot_boxplot(df.avgNumBedrooms, 'Boxplot for Average Number of Bedrooms')\n%matplot plt\n```", "```py\nimport pyspark.sql.functions as f\ncolumns = ['avgNumRooms', 'avgNumBedrooms', 'population']\nhousing_df_with_no_outliers = housing_data.where(\n    (housing_data.avgNumRooms<= 8) &\n    (housing_data.avgNumRooms>=2) &\n    (housing_data.avgNumBedrooms<=1.12) &\n    (housing_data.population<=1500) &\n    (housing_data.population>=250))\n```", "```py\ndf = housing_df_with_no_outliers.select('avgNumRooms', 'avgNumBedrooms', 'population').toPandas()\nplot_boxplot(df.avgNumBedrooms, 'Boxplot for Average Number of Bedrooms')\n%matplot plt\n```", "```py\n%%writefile preprocess.py\n...\ndef main():\n    parser = argparse.ArgumentParser(description=\"app inputs and outputs\")\n    parser.add_argument(\"--bucket\", type=str, help=\"s3 input bucket\")\n    parser.add_argument(\"--s3_input_prefix\", type=str, help=\"s3 input key prefix\")\n    parser.add_argument(\"--s3_output_prefix\", type=str, help=\"s3 output key prefix\")\n    args = parser.parse_args()\n    spark = SparkSession.builder.appName(\"PySparkApp\").getOrCreate()\n    housing_data=spark.read.parquet(f's3://{args.bucket}/{args.s3_input_prefix}/data.parquet.gzip')\n    housing_df_with_no_outliers = housing_data.where((housing_data.avgNumRooms<= 8) &\n                   (housing_data.avgNumRooms>=2) &\n                   (housing_data.avgNumBedrooms<=1.12) &\n                    (housing_data.population<=1500) &\n                    (housing_data.population>=250))\n    (train_df, validation_df) = housing_df_with_no_outliers.randomSplit([0.8, 0.2])\n    train_df.write.parquet(\"s3://\" + os.path.join(args.bucket, args.s3_output_prefix, \"train/\"))\n    validation_df.write.parquet(\"s3://\" + os.path.join(args.bucket, args.s3_output_prefix, \"validation/\"))\nif __name__ == \"__main__\":\n    main()\n...\n```", "```py\n%local\nimport sagemaker\nfrom time import gmtime, strftime\nsagemaker_session = sagemaker.Session()\nrole = sagemaker.get_execution_role()\nbucket = sagemaker_session.default_bucket()\ntimestamp = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nprefix = \"california_housing/data_\" + timestamp\ns3_input_prefix = \"california_housing/data/raw\"\ns3_output_prefix = prefix + \"/data/spark/processed\"\n```", "```py\n%local\nfrom sagemaker.spark.processing import PySparkProcessor\nspark_processor = PySparkProcessor(\n    base_job_name=\"sm-spark\",\n    framework_version=\"2.4\",\n    role=role,\n    instance_count=2,\n    instance_type=\"ml.m5.xlarge\",\n    max_runtime_in_seconds=1200,\n)\n```", "```py\nspark_processor.run(\n    submit_app=\"preprocess.py\",\n    arguments=[\n        \"--bucket\",\n        bucket,\n        \"--s3_input_prefix\",\n        s3_input_prefix,\n        \"--s3_output_prefix\",\n        s3_output_prefix,\n    ],\n)\n```", "```py\n    from super_image import EdsrModel, ImageLoader\n    ```", "```py\n    from PIL import Image\n    ```", "```py\n    import requests\n    ```", "```py\n    model = EdsrModel.from_pretrained('eugenesiow/edsr-base', scale=4)\n    ```", "```py\n    import os\n    ```", "```py\n    from os import listdir\n    ```", "```py\n    folder_dir = \"horse-or-human/\"\n    ```", "```py\n    for folder in os.listdir(folder_dir):\n    ```", "```py\n        folder_path = f'{folder_dir}{folder}'\n    ```", "```py\n        for image_file in os.listdir(folder_path):\n    ```", "```py\n            path = f'{folder_path}/{image_file}'\n    ```", "```py\n            image = Image.open(path)\n    ```", "```py\n            inputs = ImageLoader.load_image(image)\n    ```", "```py\n            preds = model(inputs)\n    ```", "```py\n            ImageLoader.save_image(preds, path)\n    ```", "```py\nfrom sagemaker.pytorch import PyTorch\nestimator = PyTorch(entry_point='train.py',\n                    source_dir='src',\n                    role=role,\n                    instance_count=1,\n                    instance_type='ml.g4dn.8xlarge',\n                    framework_version='1.8.0',\n                    py_version='py3',\n                    sagemaker_session=sagemaker_session,\n                    hyperparameters={'epochs':5,\n                                     'subset':2100,\n                                     'num_workers':4,\n                                     'batch_size':500},\n                   )\n```", "```py\nfrom sagemaker.inputs import TrainingInput\ntrain = TrainingInput(s3_input_data,content_type='image/png',input_mode='File')\n```", "```py\nestimator.fit({'train':train})\n```"]