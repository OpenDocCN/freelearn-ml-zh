- en: Deep Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度神经网络
- en: 'In the previous chapter, we discussed neural networks and their basic operation.
    Specifically, we discussed the fully connected feedforward neural network, which
    is just one simple topology out of many possible ANN topologies. In this chapter,
    we''re going to focus on two advanced topologies: the **Convolutional Neural Network**
    (**CNN**) and one form of **recurrent neural network** (**RNN**), called the **Long
    Short-Term Memory** (**LSTM**) network. CNNs are used most often for image processing
    tasks, such as object detection and image classification. LSTM networks are often
    used in NLP or language-modeling problems.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了神经网络及其基本操作。具体来说，我们讨论了全连接前馈神经网络，这只是众多可能的ANN拓扑结构中的一种简单拓扑。在本章中，我们将重点关注两种高级拓扑：**卷积神经网络**（**CNN**）和一种称为**长短期记忆**（**LSTM**）网络的循环神经网络。CNNs通常用于图像处理任务，如目标检测和图像分类。LSTM网络常用于自然语言处理或语言建模问题。
- en: These exotic ANN topologies are considered to be **deep neural networks** (**DNNs**).
    While the term is not well-defined, DNNs are typically understood to be ANNs with
    multiple hidden layers between the input and output layers. Convolutional network
    architectures can become quite deep, with ten or more layers in the network. Recurrent
    architectures can be deep as well, however, much of their depth comes from the
    fact that information can flow either forward or backward through the network.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这些异构的ANN拓扑被认为是**深度神经网络**（**DNNs**）。虽然这个术语没有很好地定义，但DNNs通常被理解为在输入层和输出层之间有多个隐藏层的ANN。卷积网络架构可以非常深，网络中有十个或更多的层。循环架构也可以很深，然而，它们的大部分深度来自于信息可以通过网络向前或向后流动的事实。
- en: 'In this chapter, we''re going to take a look at TensorFlow''s capabilities
    in terms of CNN and RNN architectures. We will discuss TensorFlow''s own examples
    of these topologies and take a look at how they are used in practice. In particular,
    we will discuss the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨TensorFlow在CNN和RNN架构方面的能力。我们将讨论TensorFlow自己提供的这些拓扑示例，并查看它们在实际中的应用。特别是，我们将讨论以下主题：
- en: CNNs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNNs
- en: Simple RNNs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单RNN
- en: Gated recurrent unit networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 门控循环单元网络
- en: LSTM networks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LSTM网络
- en: CNN-LSTM networks for advanced applications
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于高级应用的CNN-LSTM网络
- en: 'Let''s get started by taking a look at a classic **machine learning** (**ML**)
    problem: identifying handwritten digits from images.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从查看一个经典的**机器学习**（**ML**）问题开始：从图像中识别手写数字。
- en: Convolutional Neural Networks
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: To make the case for CNNs, let's first imagine how we might approach an image
    classification task using a standard feedforward, fully connected ANN. We start
    with an image that's 600 x 600 pixels in size with three color channels. There
    are 1,080,000 pieces of information encoded in such an image (600 x 600 x 3),
    and therefore our input layer would require 1,080,000 neurons. If the next layer
    in the network contains 1,000 neurons, we'd need to maintain one billion weights
    between the first two layers alone. Clearly, the problem is already becoming untenable.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明CNNs，让我们首先想象一下我们如何使用标准的全连接前馈ANN来处理图像分类任务。我们从一个600 x 600像素大小、有三个颜色通道的图像开始。这样的图像中编码了1,080,000条信息（600
    x 600 x 3），因此我们的输入层需要1,080,000个神经元。如果网络中的下一层包含1,000个神经元，我们只需要在第一层和第二层之间维护十亿个权重。显然，问题已经变得难以承受。
- en: Assuming the ANN in this example can be trained, we'd also run into problems
    with scale and position invariance. If your task is to identify whether or not
    an image contains street signs, the network may have difficulty understanding
    that street signs can be located in any position in the image. The network may
    also have issues with color; if most street signs are green, it may have difficulty
    identifying a blue sign. Such a network would require many training examples to
    get around issues of scale, color, and position variance.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 假设本例中的ANN可以训练，我们还会遇到规模和位置不变性的问题。如果你的任务是识别图像中是否包含街道标志，网络可能难以理解街道标志可以位于图像的任何位置。网络在颜色上也可能有问题；如果大多数街道标志是绿色的，它可能难以识别蓝色标志。这样的网络需要许多训练示例来解决规模、颜色和位置变化的问题。
- en: In the past, before CNNs became popular, many researchers viewed this problem
    as a dimensionality reduction problem. One common tactic was to convert all images
    to grayscale, reducing the amount of data by a factor of three. Another tactic
    is to downscale images to something more manageable, such as 100 x 100 pixels,
    or even smaller, depending on the type of processing required. Converting our
    600 x 600 image to grayscale and to 100 x 100 would reduce the number of input
    neurons by a factor of 100, from one million to 10,000, and further reduce the
    number of weights between the input layer and a 1,000-neuron hidden layer down
    from 1 billion to only 10 million.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积神经网络（CNN）变得流行之前，许多研究人员将这个问题视为一个降维问题。一种常见的策略是将所有图像转换为灰度，通过三倍的比例减少数据量。另一种策略是将图像下采样到更易于管理的尺寸，例如100
    x 100像素，甚至更小，这取决于所需的处理类型。将我们的600 x 600像素图像转换为灰度并缩小到100 x 100像素将使输入神经元的数量减少100倍，从一百万减少到一万，并将输入层和包含1000个神经元的隐藏层之间的权重数量从十亿减少到只有一千万。
- en: Even after employing these dimensionality reduction techniques, we would still
    require a very large network with tens of millions of weights. Converting images
    to grayscale before processing avoids issues with color detection, but still does
    not solve scale and position variance problems. We are also still solving a very
    complex problem, since shadows, gradients, and the overall variance of images
    would require us to use a very large training set.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用了这些降维技术，我们仍然需要一个包含数千万个权重的非常大的网络。在处理之前将图像转换为灰度可以避免颜色检测问题，但仍然不能解决尺度和位置变化问题。我们仍然在解决一个非常复杂的问题，因为阴影、梯度以及图像的整体变化性需要我们使用一个非常大的训练集。
- en: Another common preprocessing tactic employed was to perform various operations
    on images, such as noise reduction, edge detection, and smoothing. By reducing
    shadows and emphasizing edges, the ANN gets clearer signals to learn from. The
    problem with this approach is that preprocessing tasks are typically unintelligent;
    the same edge detection algorithm gets applied to every image in the set, whether
    or not that specific edge detection algorithm is actually effective on a particular
    image.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的预处理策略是对图像执行各种操作，例如噪声减少、边缘检测和平滑处理。通过减少阴影并强调边缘，ANN可以得到更清晰的信号来学习。这种方法的缺点是预处理任务通常是低效的；相同的边缘检测算法被应用于集合中的每一张图像，无论该特定的边缘检测算法是否对特定图像有效。
- en: The challenge, then, is to incorporate the image-preprocessing tasks directly
    in the ANN. If the ANN itself manages the preprocessing tasks, the network can
    learn the best and most efficient ways to preprocess the images in order to optimize
    the network's accuracy. Recall from [Chapter 8](69151615-d71a-4e8f-86c5-90801ffa5393.xhtml), *Artificial
    Neural Network Algorithms* that we can use *any *activation function in a neuron,
    as long as we can differentiate the activation function and employ its gradient
    in the backpropagation algorithm.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，挑战在于将图像预处理任务直接集成到人工神经网络（ANN）中。如果ANN本身管理预处理任务，网络就可以学习最佳且最有效的方法来预处理图像，以优化网络的准确性。回想一下[第8章](69151615-d71a-4e8f-86c5-90801ffa5393.xhtml)，《人工神经网络算法》，我们可以在神经元中使用任何激活函数，只要我们能对激活函数进行微分并使用其在反向传播算法中的梯度。
- en: In short, a CNN is an ANN with multiple—perhaps many—preprocessing layers that
    perform transformations on the image before ultimately reaching a final fully
    connected layer or two that performs the actual classification. By incorporating
    the preprocessing tasks into the network, the backpropagation algorithm can tune
    the preprocessing tasks as part of the network training. The network will not
    only learn how to classify images, it will also learn how to preprocess the images
    for your task.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，CNN是一个包含多个——可能很多——预处理层的ANN，这些预处理层在最终到达一个或两个执行实际分类的完全连接层之前对图像进行转换。通过将预处理任务集成到网络中，反向传播算法可以将预处理任务作为网络训练的一部分进行调整。网络不仅会学习如何分类图像，还会学习如何为你的任务预处理图像。
- en: Convolutional networks contain several distinct layer types in addition to the
    standard ANN layer types. Both types of network contain an input layer, an output
    layer, and one or more fully connected layers. A CNN, however, also incorporates
    convolution layers, ReLU layers, and pooling layers. Let's take a look at each
    in turn.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标准的ANN层类型外，卷积网络还包含几种不同的层类型。这两种类型的网络都包含输入层、输出层和一个或多个完全连接层。然而，CNN还结合了卷积层、ReLU层和池化层。让我们逐一看看每个层。
- en: Convolutions and convolution layers
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积和卷积层
- en: Convolutions are a mathematical tool that combine two functions into a new function;
    specifically, the new function represents the area under the curve created by
    the pointwise multiplication of one function as another function is swept over
    it. If this is difficult to visualize, don't worry; it's easiest to visualize
    as an animation, which unfortunately we can't print in a book. The mathematical
    details of convolutions will not be important in this chapter, but I do encourage
    you to do some additional reading on the topic.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积是一种数学工具，它将两个函数组合成一个新的函数；具体来说，新函数表示当另一个函数在其上扫过时，一个函数点乘产生的曲线下的面积。如果这很难想象，不要担心；最简单的方法是将其想象成动画，不幸的是，我们无法在书中打印动画。本章中卷积的数学细节并不重要，但我确实鼓励你阅读有关该主题的额外资料。
- en: Most image filters—such as blur, sharpen, edge detect, and emboss—can be accomplished
    with convolution operations. In an image context, convolutions are represented
    by a *convolution matrix, *which is typically a small matrix (3 x 3, 5 x 5, or
    something similar). The convolution matrix is much smaller than the image to be
    processed, and the convolution matrix is swept across the image so the output
    of the convolution applied to the entire image builds a new image with the effect
    applied.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数图像过滤器——如模糊、锐化、边缘检测和浮雕——都可以通过卷积操作实现。在图像上下文中，卷积由一个*卷积矩阵*表示，这通常是一个小矩阵（3 x 3、5
    x 5或类似）。卷积矩阵比要处理的图像小得多，卷积矩阵在图像上扫过，因此卷积应用于整个图像的输出构建了一个应用了效果的新图像。
- en: 'Consider the following image of Van Gogh''s *Water Lilies*. Here is the original:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下梵高的*睡莲*图像。这是原始图像：
- en: '![](img/b5059b31-b768-4646-8435-813766e67f9e.jpeg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b5059b31-b768-4646-8435-813766e67f9e.jpeg)'
- en: 'I can use my image editor''s *convolution matrix *filter to create a sharpening
    effect. This has the same effect as the image editor''s *sharpen *filter, except
    that I''m writing the convolution matrix manually:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以使用我的图像编辑器的*卷积矩阵*过滤器来创建锐化效果。这与图像编辑器的*锐化*过滤器有相同的效果，只不过我是手动编写卷积矩阵的：
- en: '![](img/6ed62c7b-5cdd-480a-be07-16c049351766.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6ed62c7b-5cdd-480a-be07-16c049351766.png)'
- en: 'The result is a sharpened version of the original image:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是原始图像的锐化版本：
- en: '![](img/3b3c3dff-d96b-4f66-b78f-0fe9bf40be49.jpeg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3b3c3dff-d96b-4f66-b78f-0fe9bf40be49.jpeg)'
- en: 'I can also write a convolution matrix that blurs the image:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我也可以编写一个使图像模糊的卷积矩阵：
- en: '![](img/315d900d-e70a-4f56-ae1d-eefed0cd51ea.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/315d900d-e70a-4f56-ae1d-eefed0cd51ea.png)'
- en: 'It results in the following image. The effect is subtle, as the oil panting
    itself is a little blurry, but the effect is there:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下图像。效果微妙，因为油画本身有点模糊，但效果是有的：
- en: '![](img/fa8ff56a-c6cc-47f3-b4f6-d9d0d2f89376.jpeg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fa8ff56a-c6cc-47f3-b4f6-d9d0d2f89376.jpeg)'
- en: 'Convolutions can also be used to emboss or detect edges:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积也可以用来浮雕或检测边缘：
- en: '![](img/eb7c1e45-a7da-491f-84d1-9c7d4c000132.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/eb7c1e45-a7da-491f-84d1-9c7d4c000132.png)'
- en: 'The preceding matrix results in the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的矩阵会产生以下效果：
- en: '![](img/66dd6ff7-6701-4afd-a654-613af40cfb90.jpeg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/66dd6ff7-6701-4afd-a654-613af40cfb90.jpeg)'
- en: A CNN uses multiple convolving layers, each with multiple convolution filters,
    to build a model of the image. The convolving layers and the convolution filters
    themselves are trained by the backpropagation algorithm, and the network will
    eventually discover the correct filters to use in order to enhance the features
    that the network is trying to identify. As with all learning problems, the types
    of filters the CNN develops may not necessarily be readily understood or interpretable
    by a human, but in many cases, you will find that your network develops a number
    of convolution filters that perform blur, edge detection, color isolation, and
    gradient detection.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: CNN使用多个卷积层，每个层包含多个卷积过滤器，来构建图像模型。卷积层和卷积过滤器本身是通过反向传播算法进行训练的，网络最终会发现正确的过滤器来增强网络试图识别的特征。与所有学习问题一样，CNN开发的过滤器类型可能不一定能被人类轻易理解或解释，但在许多情况下，你会发现你的网络开发了许多执行模糊、边缘检测、颜色隔离和梯度检测的卷积过滤器。
- en: In addition to extracting useful features from images, the convolution operations
    in effect provide for spatial and positional independence of features. The convolving
    layers are not fully connected, and therefore are able to inspect specific areas
    of the image. This reduces the dimensionality required of the weights in between
    layers and also helps us avoid reliance on the spatial positioning of features.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 除了从图像中提取有用特征外，卷积操作实际上提供了特征的空间和位置独立性。卷积层不是完全连接的，因此能够检查图像的特定区域。这减少了层间权重的维度要求，并有助于我们避免对特征空间位置的依赖。
- en: There is still a lot of data involved in these operations, so convolving layers
    are typically immediately followed by pooling layers, which essentially downsample
    an image. Most often you will employ something such as *2 x 2 max pooling*, which
    means that for every 2 x 2 area of pixels in the source feature, the pooling layer
    will downsample the 2 x 2 area to a single pixel that has the value of the maximum
    pixel in the source 2 x 2 area. A 2 x 2 pooling layer therefore reduces the image
    size by a factor of four; because the convolution operation (which may also reduce
    dimensionality) has already occurred, this downsampling will typically reduce
    the computation required without the loss of too much information.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些操作中涉及的数据量仍然很大，因此卷积层通常紧接着是池化层，这本质上是对图像进行下采样。最常见的是使用 *2 x 2 最大池化*，这意味着对于源特征中的每个
    2 x 2 像素区域，池化层将下采样 2 x 2 区域到一个像素，该像素具有源 2 x 2 区域中最大像素的值。因此，2 x 2 池化层将图像大小减少到原来的四分之一；因为卷积操作（可能也会降低维度）已经发生，这种下采样通常可以减少计算需求而不会丢失太多信息。
- en: In some cases, a CNN will employ simple ReLU activation functions immediately
    following the convolution operations and immediately preceding pooling; these
    ReLU functions help avoid oversaturation of the image or the feature maps that
    result from the convolution operations.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，卷积神经网络将使用简单的 ReLU 激活函数直接跟随卷积操作并直接在池化之前；这些 ReLU 函数有助于避免图像或卷积操作产生的特征图过度饱和。
- en: 'A typical architecture for a simple CNN would look like this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 简单卷积神经网络的一个典型架构看起来可能是这样的：
- en: Input layer, with width x height x color depth neurons
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入层，具有宽度 x 高度 x 颜色深度神经元
- en: Convolving layer, with N convolution filters of an M x M size
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积层，具有 M x M 大小的 N 个卷积滤波器
- en: Max pooling layer
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大池化层
- en: Second convolving layer
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个卷积层
- en: Second max pooling layer
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个最大池化层
- en: Fully connected output layer
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全连接输出层
- en: More complex architectures for CNNs typically include several more groups of
    convolving and pooling layers, and may also involve two convolving layers in a
    row before reaching a pooling layer.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 的更复杂架构通常包括更多的卷积和池化层组合，并且可能在达到池化层之前涉及两个连续的卷积层。
- en: Each successive convolving layer in the network operates at a higher level than
    the convolving layers before it. The first convolving layer will only be able
    to perform simple convolutions, such as edge detection, smoothing, and blurring.
    The next convolving layer, however, is able to combine the results from previous
    convolutions into higher level features, such as basic shapes or color patterns.
    A third convolving layer can further combine information from previous layers
    to detect complex features, such as wheels, street signs, and handbags. The final
    fully connected layer, or layers, acts much like a standard feedforward ANN, and
    performs the actual classification of the image based on the high-level features
    that the convolving layers have isolated.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 网络中每个后续的卷积层在其之前的卷积层之上运行。第一个卷积层只能执行简单的卷积，例如边缘检测、平滑和模糊。然而，下一个卷积层能够将先前卷积的结果组合成更高层次的特征，例如基本形状或颜色模式。第三个卷积层可以进一步结合先前层的信息来检测复杂特征，例如轮子、路标和手提包。最后的全连接层或层则类似于标准的前馈人工神经网络，并根据卷积层所隔离的高层次特征对图像进行实际分类。
- en: Let's now attempt to employ this technique in practice using `TensorFlow.js`
    on the MNIST handwritten digit dataset.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试使用 `TensorFlow.js` 在 MNIST 手写数字数据集上实际应用这项技术。
- en: Example – MNIST handwritten digits
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 - MNIST 手写数字
- en: Rather than building an example from first principles, let's instead walk through
    an excellent `TensorFlow.js` MNIST example. The goal of this example is to train
    a CNN to classify images of handwritten digits. More specifically, the goal of
    this example is to achieve a high accuracy in classifications made against the
    MNIST handwritten digit dataset. In this section, we will aim to get an understanding
    of the code and the algorithm by performing experiments on the code and observing
    their results.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不如从构建一个从第一原理开始的示例，而是通过一个优秀的 `TensorFlow.js` MNIST 示例来逐步了解。此示例的目标是训练一个卷积神经网络（CNN）来对手写数字图像进行分类。更具体地说，此示例的目标是在
    MNIST 手写数字数据集上实现高准确率。在本节中，我们将通过在代码上执行实验并观察其结果来了解代码和算法。
- en: The current version of this example may be found on `TensorFlow.js`'s GitHub: [https://github.com/tensorflow/tfjs-examples/tree/master/mnist](https://github.com/tensorflow/tfjs-examples/tree/master/mnist).
    However, as the repository may be updated after this writing, I have also added
    the version that I am using as a Git submodule in this book's example repository.
    If you are using this book's repository and haven't already done so, please run `git
    submodule init`; `git submodule update` from the command line in the repository
    directory.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当前版本的此示例可以在 `TensorFlow.js` 的 GitHub 上找到：[https://github.com/tensorflow/tfjs-examples/tree/master/mnist](https://github.com/tensorflow/tfjs-examples/tree/master/mnist)。然而，由于在撰写本文后存储库可能已更新，我还在本书的示例存储库中添加了我使用的版本作为
    Git 子模块。如果您正在使用本书的存储库并且尚未这样做，请从存储库目录中的命令行运行 `git submodule init`；`git submodule
    update`。
- en: In the terminal, navigate to `Ch5-CNN`. This path is a symbolic link, so if
    it doesn't work on your system, you may alternately navigate to `tfjs-examples/mnist`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端中，导航到 `Ch5-CNN`。此路径是一个符号链接，因此如果您的系统上不起作用，您可以改用导航到 `tfjs-examples/mnist`。
- en: Next, issue `yarn` from the command line to build the code, and finally issue `yarn
    watch`, which will start a local server and launch your browser to `http://localhost:1234`.
    If you have any other programs using that port, you will have to terminate them
    first.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，从命令行运行 `yarn` 来构建代码，最后运行 `yarn watch`，这将启动一个本地服务器并将您的浏览器打开到 `http://localhost:1234`。如果您有使用该端口的任何其他程序，您必须首先终止它们。
- en: The page will start by downloading MNIST images from Google's servers. It will
    then train a CNN for 150 epochs, periodically updating two graphs that show the
    loss and the accuracy. Recall that the loss is typically a metric, such as **mean
    square error** (**MSE**), while accuracy is the percentage of correct predictions.
    Finally, the page will display a few example predictions, highlighting correct
    versus incorrect predictions.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 页面将首先从 Google 的服务器下载 MNIST 图像。然后，它将训练一个 CNN 进行 150 个周期，定期更新显示损失和准确性的两个图表。回想一下，损失通常是像均方误差（MSE）这样的指标，而准确率是正确预测的百分比。最后，页面将显示一些示例预测，突出显示正确与错误的预测。
- en: 'My test run of this page yielded a CNN with an accuracy of around 92%:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我对这个页面的测试运行产生了一个准确率约为 92% 的 CNN：
- en: '![](img/b8f0de54-12f5-4011-8352-151ec75d87d2.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b8f0de54-12f5-4011-8352-151ec75d87d2.png)'
- en: 'Often, the incorrect predictions are understandable. In this example, the digit
    1 does seem to be shaped a bit like a 2\. It is unlikely a human would have made
    this particular error, though I have encountered examples where I would have gotten
    the prediction wrong as well:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，错误的预测是可以理解的。在这个例子中，数字 1 看起来确实有点像数字 2。尽管我遇到过我也会预测错误的例子，但不太可能有人会犯这个特定的错误：
- en: '![](img/496b160d-dafe-439a-8353-aa708bcb7765.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/496b160d-dafe-439a-8353-aa708bcb7765.png)'
- en: 'Opening `index.js`, we can see the topology of the network toward the top of
    the file:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 `index.js`，我们可以在文件顶部看到网络的拓扑结构：
- en: '[PRE0]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This network has two convolving layers with a pooling layer after each, and
    then a single fully connected layer that makes a prediction. Both the convolving
    layers use a `kernelSize` of `5`, which means that the convolution filter is a
    5 x 5 matrix. The first convolving layer uses eight filters, while the second
    uses 16\. This means that the first layer will create and use eight different
    convolution filters, therefore identifying eight separate graphical features of
    the image. These features may be abstract, but in the first layer it is common
    to see features that represent edge detection, blurring or sharpening, or gradient
    identification.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这个网络有两个卷积层，每个卷积层后面跟着一个池化层，然后是一个单一的用于预测的全连接层。这两个卷积层都使用`kernelSize`为`5`，这意味着卷积滤波器是一个5
    x 5的矩阵。第一个卷积层使用八个过滤器，而第二个使用16个。这意味着第一层将创建并使用八个不同的卷积滤波器，因此识别图像的八个不同的图形特征。这些特征可能是抽象的，但在第一层中，常见的特征是表示边缘检测、模糊或锐化，或者梯度识别。
- en: The second convolving layer uses 16 features, which likely will be of a higher
    level than the first layer's features. This layer may try to identify straight
    lines, circles, curves, swoops, and so on. There are more high-level features
    than there are low-level features, so it makes sense that the first layer uses
    fewer filters than the second layer.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个卷积层使用16个特征，这些特征可能比第一层的特征更高级。这一层可能试图识别直线、圆形、曲线、波浪线等。高级特征比低级特征多，因此第一层使用比第二层少的过滤器是有意义的。
- en: The final dense layer is a fully connected layer of 10 neurons, each representing
    a digit. The softmax activation function ensures that the output is normalized
    to 1\. The input to this final layer is a flattened version of the second pooling
    layer. The data needs flattening because convolving and pooling layers are typically
    multidimensional. Convolving and pooling layers use matrices representing height,
    width, and color depth, which themselves are in turn stacked atop one another
    as the result of the convolution filters used. The output of the first convolving
    layer, for example, will be a volume that is [28 x 28 x 1] x 8 in size. The bracketed
    portion is the result of a single convolution operation (that is, a filtered image),
    and eight of them have been generated. When connecting this data to a vector layer,
    such as the standard dense or fully connected layer, it must also be flattened
    into a vector.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的密集层是一个包含10个神经元的全连接层，每个神经元代表一个数字。softmax激活函数确保输出被归一化到1。这个最终层的输入是第二个池化层的展平版本。数据需要展平，因为卷积和池化层通常是多维的。卷积和池化层使用代表高度、宽度和颜色深度的矩阵，这些矩阵本身又是通过卷积滤波器使用的结果堆叠在一起的。例如，第一个卷积层的输出将是一个体积为[28
    x 28 x 1] x 8大小的体积。括号内的部分是单个卷积操作（即滤波后的图像）的结果，并且已经生成了八个这样的操作。当将此数据连接到向量层，如标准的密集层或全连接层时，它也必须被展平成一个向量。
- en: The data entering the final dense layer is much smaller than the data coming
    out of the first layer. The max-pooling layers serve to downscale the image. The `poolSize `parameter
    of `[2, 2]` means that a 2 x 2 window of pixels will be reduced to a single value;
    since we are using max-pooling, this will be the largest value (the lightest pixel)
    in the set. The `strides` parameter means that the pooling window will move in
    steps of two pixels at a time. This pooling will reduce both the height and width
    of the image by half, meaning that the image and the data is reduced in area by
    a factor of four. After the first pooling operation, images are reduced to 14
    x 14, and after the second they are 7 x 7\. Because there are 16 filters in the
    second convolving layer, this means that the flattened layer will have *7 * 7
    * 16 = 784* neurons.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 进入最终密集层的数据比第一层输出的数据小得多。最大池化层的作用是降低图像的尺寸。`poolSize`参数为`[2, 2]`意味着一个2 x 2像素窗口将被减少到一个单一值；由于我们使用的是最大池化，这将是在该集合中最大的值（最亮的像素）。`strides`参数意味着池化窗口将以每次两个像素的步长移动。这种池化将图像的高度和宽度都减半，这意味着图像和数据在面积上减少了四倍。第一次池化操作后，图像被减少到14
    x 14，第二次后变为7 x 7。由于第二个卷积层有16个过滤器，这意味着展平层将有*7 * 7 * 16 = 784*个神经元。
- en: Let's see whether we can squeeze some more accuracy out of this model by adding
    another fully connected layer before the output. In the best case scenario, adding
    another layer will give us an improved ability to interpret the interplay of the
    16 features that the convolutions generate.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看通过在输出之前添加另一个全连接层，我们是否能从这个模型中挤出更多准确度。在最佳情况下，增加另一个层将使我们能够更好地解释卷积产生的16个特征的相互作用。
- en: However, adding another layer will increase the required training time, and
    it also may not improve results. It's perfectly possible that there is no more
    information to be discovered by adding another layer. Always remember that ANNs
    simply build and navigate a mathematical landscape, looking for shapes in the
    data. If the data isn't highly dimensional, adding another dimension to our capabilities
    may simply be unnecessary.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，增加另一个层会增加所需的训练时间，并且它也可能不会提高结果。完全有可能，通过增加另一个层，我们不再能发现更多信息。始终记住，人工神经网络只是构建和导航数学景观，寻找数据中的形状。如果数据不是高度多维的，增加我们能力的一个维度可能只是不必要的。
- en: 'Add the following line, before the final dense layer in the code:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码的最终密集层之前添加以下行：
- en: '[PRE1]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In context, the code should now look like this, with the new line highlighted:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在上下文中，代码现在应该看起来像这样，新行被突出显示：
- en: '[PRE2]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Since you have issued `yarn watch` from the command line, the code should automatically
    rebuild. Refresh the page and observe the results:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您已从命令行发出`yarn watch`，代码应自动重建。刷新页面并观察结果：
- en: '![](img/fd60951b-94b1-4cfc-bc02-298925b711f3.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fd60951b-94b1-4cfc-bc02-298925b711f3.png)'
- en: The algorithm is learning at a slower rate than the original version, which
    is expected because we have added a new layer and therefore more complexity to
    the model. Let's increase the training limit a little bit.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的学习速度比原始版本慢，这是预期的，因为我们增加了一个新层，因此增加了模型的复杂性。让我们稍微增加训练限制。
- en: 'Find the `TRAIN_BATCHES` variable and update it to `300`. The line should now
    look like this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 找到`TRAIN_BATCHES`变量并将其更新为`300`。该行现在应如下所示：
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Save the file to trigger the rebuild and reload the page. Let''s see whether
    we can beat the baseline:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 保存文件以触发重建并重新加载页面。让我们看看我们是否能打败基线：
- en: '![](img/8b9bdac3-9b99-4b7f-b002-059567d6e6d8.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b9bdac3-9b99-4b7f-b002-059567d6e6d8.png)'
- en: It does seem that we have indeed beaten the baseline score of 92%, however I
    would caution against too much optimism. It is possible we have overtrained and
    overfit the model, and there is a chance it will not perform so well in real life.
    Additionally, because training and validation are stochastic, it is possible that
    the true accuracy of this network is comparable to the baseline's. Indeed, 92%
    is already an excellent result and I would not expect much better from any model.
    However this is still an encouraging result, as the new layer was not too much
    of a burden to add.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们确实打败了92%的基线分数，然而我必须谨慎地提醒，不要过于乐观。有可能我们已经过度训练和过度拟合了模型，并且有可能它在现实生活中表现不佳。此外，由于训练和验证是随机的，这个网络的真正准确度可能与基线相当。确实，92%已经是一个非常好的结果，我不期望任何模型能做得更好。然而，这仍然是一个鼓舞人心的结果，因为新层增加的负担并不大。
- en: At this point, revert your changes so that you are working with the original
    copy of the file. Let's run a different experiment. It would be interesting to
    see how small we can make the network without losing too much accuracy.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，请撤销您的更改，以便您使用文件的原始副本进行工作。让我们进行一个不同的实验。看看我们能否在不损失太多准确度的情况下将网络规模缩小到多小，这将会很有趣。
- en: 'First, let''s reduce the number of convolution filters the second convolving
    layer uses. My reasoning is that numerals use pretty simple shapes: circles, lines,
    and curves. Perhaps we don''t need to capture 16 different features. Maybe eight
    will do. In the second convolving layer, change `filters: 8` to `filters: 2`.
    Your code should now read:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，让我们减少第二个卷积层使用的卷积滤波器数量。我的理由是数字使用相当简单的形状：圆形、线条和曲线。也许我们不需要捕捉16种不同的特征。也许8个就足够了。在第二个卷积层中，将`filters:
    8`更改为`filters: 2`。您的代码现在应该如下所示：'
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Rerunning the code, we see that we still get decent accuracy, though the variance
    is a little higher than the baseline:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 重新运行代码，我们看到我们仍然得到了相当准确的度，尽管方差略高于基线：
- en: '![](img/c9c3f174-2ebb-4800-9601-360c3e9e80c6.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9c3f174-2ebb-4800-9601-360c3e9e80c6.png)'
- en: 'This supports the overall idea that the shapes and features used are relatively
    few. However, when we look at the test examples, we also find that the mistakes
    are less *understandable* than before. Perhaps we have not lost much accuracy,
    but our model has become more abstract:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这支持了这样一个总体观点，即使用的形状和特征相对较少。然而，当我们查看测试示例时，我们也发现错误比以前更难以理解。也许我们没有损失很多准确率，但我们的模型变得更加抽象：
- en: '![](img/a085a4ec-111b-42ce-983d-fa02d3c053f0.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a085a4ec-111b-42ce-983d-fa02d3c053f0.png)'
- en: I encourage you to continue exploring and experimenting with this example, as
    there are many things you can learn by reading the code. One aspect of this example
    I would like to point out in particular is the `data.js` file, which manages the
    handling of the MNIST dataset. In your real-world applications, you will likely
    need to employ an approach similar to this, as your training data will not always
    be on the local machine. This file handles downloading data from a remote source,
    splitting it into testing and validation sets, and maintaining batches to be requested
    by the training algorithm. It is a good, lightweight approach to follow if you
    require training data from a remote source. We will discuss this topic in-depth
    in [Chapter 11](8bb0fe0d-84df-41b9-a955-69a84eb2d8ea.xhtml), *Using Machine Learning
    in Real-Time Applications*.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你继续探索和实验这个示例，因为通过阅读代码你可以学到很多东西。我想特别指出这个示例的一个方面，那就是`data.js`文件，它负责处理MNIST数据集。在你的实际应用中，你可能会需要采用类似的方法，因为你的训练数据不一定总是在本地机器上。这个文件处理从远程源下载数据，将其分为测试集和验证集，并为训练算法维护请求的批次。如果你需要从远程源获取训练数据，这是一个很好的、轻量级的方法。我们将在[第11章](8bb0fe0d-84df-41b9-a955-69a84eb2d8ea.xhtml)深入讨论这个主题，*在实时应用中使用机器学习*。
- en: 'Here are some ideas for experiments you can try:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些你可以尝试的实验想法：
- en: Make the network as small as possible while maintaining 90%+ accuracy.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在保持90%以上准确率的同时，尽可能使网络规模最小化。
- en: Make the network as small as possible while maintaining 85%+ accuracy.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在保持85%以上准确率的同时，使网络尽可能小。
- en: Train the model to 90%+ accuracy in fewer than 50 epochs.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在少于50个epoch中将模型训练到90%以上的准确率。
- en: Discover the fewest number of training examples required to achieve 90%+ accuracy
    (reduce the value of `NUM_TRAIN_ELEMENTS `in `data.js `to use fewer training examples)
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现实现90%以上准确率所需的最少训练示例数量（在`data.js`中将`NUM_TRAIN_ELEMENTS`的值减少以使用更少的训练示例）
- en: In the next section, we will explore series prediction with recurrent neural
    networks.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨使用循环神经网络进行序列预测。
- en: Recurrent neural networks
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: There are many cases where memory is required of neural networks. For instance,
    when modeling natural language context is important, that is, the meaning of a
    word late in a sentence is affected by the meaning of words earlier in the sentence.
    Compare this to the approach used by Naive Bayes classifiers, where only the bag
    of words is considered but not their order. Similarly, time series data may require
    some memory in order to make accurate predictions, as a future value may be related
    to current or past values.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，神经网络需要记忆。例如，当建模自然语言上下文很重要时，也就是说，句子中较晚出现的单词的意义受到句子中较早出现的单词的意义的影响。这与朴素贝叶斯分类器使用的做法形成对比，朴素贝叶斯分类器只考虑单词袋，不考虑它们的顺序。同样，时间序列数据可能需要一些记忆才能做出准确的预测，因为未来的值可能与当前或过去的值相关。
- en: RNN are a family of ANN topologies in which the information does not necessarily
    flow in only one direction. In contrast to feedforward neural networks, RNNs allow
    the output of neurons to be fed backward into their input, creating a feedback
    loop. Recurrent networks are almost always time-dependent. The concept of time
    is flexible, however; ordered words in a sentence can be considered time-dependent,
    as one word must follow another. It is not necessary for the time-dependence of
    RNNs to be related to the actual passage of time on a clock.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: RNN是一组ANN拓扑结构，其中信息不一定只在一个方向上流动。与前馈神经网络相比，RNN允许神经元的输出反向输入到它们的输入中，从而创建一个反馈循环。循环网络几乎总是时间相关的。然而，时间概念是灵活的；句子中的有序单词可以被认为是时间相关的，因为一个单词必须跟在另一个单词之后。RNN的时间相关性不一定与时钟上实际时间的流逝相关。
- en: In the simplest case, all that is required of an RNN is for the output value
    of a neuron to be connected - typically with a weight or decay factor—not just
    to neurons in the next layer, but also back to its own input. If you are familiar
    with **finite impulse response** (**FIR**) filters in digital signal processing,
    this style of neuron can be considered a variant of an FIR filter. This type of
    feedback results in a sort of memory, as the previous activation value is partially
    preserved and used as an input to the neuron's next cycle. You can visualize this
    as an echo created by the neuron, becoming more and more faint until the echo
    is no longer audible. Networks designed in this manner will therefore have a finite
    memory, as ultimately the echo will fade away to nothing.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在最简单的情况下，对RNN的要求仅仅是神经元的输出值需要连接——通常是通过权重或衰减因子——不仅连接到下一层的神经元，而且也连接回自己的输入。如果你熟悉数字信号处理中的**有限脉冲响应**（**FIR**）滤波器，这种类型的神经元可以被视为FIR滤波器的一种变体。这种类型的反馈会产生一种记忆，因为之前的激活值部分保留并用作神经元下一个周期的输入。你可以将这想象成神经元产生的回声，变得越来越微弱，直到回声不再可闻。因此，以这种方式设计的网络将具有有限的记忆，因为最终回声会消失得无影无踪。
- en: Another style of RNN is fully recurrent RNNs, in which every neuron is connected
    to every other neuron, whether in the forward or backward direction. In this case,
    it is not just a single neuron that can hear its own echo; every neuron can hear
    the echoes of every other neuron in the network.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种RNN的风格是全循环RNN，其中每个神经元都与网络中的每个其他神经元相连，无论是正向还是反向。在这种情况下，不仅仅是单个神经元可以听到自己的回声；网络中的每个神经元都可以听到其他每个神经元的回声。
- en: While these types of networks are powerful, in many cases a network will need
    memory that persists longer than an echo will last. A very powerful, exotic topology,
    called **LSTM**, was invented to solve the problem of long-term memory. The LSTM
    topology uses an exotic form of neuron called an LSTM unit, which is capable of
    storing all previous input and activation values and recalling them when calculating
    future activation values. When the LSTM network was first introduced, it broke
    an impressive number of records, particularly in speech recognition, language
    modeling, and video processing.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些类型的网络功能强大，但在许多情况下，网络需要比回声持续更长时间的内存。为了解决长期记忆的问题，发明了一种非常强大、异类的拓扑结构，称为**LSTM**。LSTM拓扑使用一种称为LSTM单元的异类神经元，能够存储所有之前的输入和激活值，并在计算未来激活值时回忆它们。当LSTM网络首次推出时，它打破了令人印象深刻的一系列记录，尤其是在语音识别、语言建模和视频处理方面。
- en: 'In the next section, we will briefly discuss three different types of RNN topologies
    provided by TensorFlow.js: the SimpleRNN (or fully recurrent RNN), the **gated
    recurrent unit** (**GRU**) network, and the LSTM network.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将简要讨论TensorFlow.js提供的三种不同类型的RNN拓扑：SimpleRNN（或全循环RNN）、**门控循环单元**（**GRU**）网络和LSTM网络。
- en: SimpleRNN
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SimpleRNN
- en: The first RNN layer provided out-of-the-box by `TensorFlow.js` is the SimpleRNN
    layer type, which is a layer composed of a SimpleRNNCell neuron. This is an exotic
    neuron that can feed its output back to its input. The input to such a neuron
    is a vector of time-dependent values; the activation output of each input value
    is fed back into the input of the next value, and so on. A *dropout *factor between
    0 and 1 may be specified; this value represents the strength of each echo. A neuron
    designed in this manner is similar in many ways to an FIR filter.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`TensorFlow.js`提供的第一个RNN层是SimpleRNN层类型，它由一个SimpleRNNCell神经元组成。这是一种异类的神经元，可以将自己的输出反馈到输入。这种神经元的输入是一个时间依赖值的向量；每个输入值的激活输出被反馈到下一个值的输入，依此类推。可以指定一个介于0和1之间的*dropout*因子；这个值代表每个回声的强度。以这种方式设计的神经元在许多方面类似于FIR滤波器。'
- en: In fact, this type of RNN architecture is made possible by earlier work in digital
    signal processing concerning FIR filters. The advantage of this architecture is
    that the mathematics are well-understood. It is possible to *unroll* an RNN, meaning
    that it is possible to create a feedforward ANN of many layers that generates
    the same results as an RNN with fewer layers. This is because the echoes of the
    neurons' feedback are finite. If a neuron is known to echo 20 times, then that
    neuron can be modeled as 21 feedforward neurons (including the source neuron).
    Initial efforts in training these networks were inspired by work on FIR filters,
    as the analysis is much the same.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这种RNN架构是由数字信号处理领域关于FIR滤波器的前期工作所实现的。这种架构的优势在于数学原理已被充分理解。可以**展开**一个RNN，这意味着可以创建一个多层前馈ANN，其结果与较少层的RNN相同。这是因为神经元反馈的回声是有限的。如果一个神经元已知回声20次，那么这个神经元可以被建模为21个前馈神经元（包括源神经元）。训练这些网络的初步努力受到了FIR滤波器工作的启发，因为分析非常相似。
- en: 'Consider the following image, created by François Deloche (own work, CC BY-SA
    4.0), which illustrates the unrolling of a recurrent neuron:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下由弗朗索瓦·德洛什（François Deloche）创作的图像（原创作品，CC BY-SA 4.0），它说明了循环神经元的展开：
- en: '![](img/89d834d6-7df8-407e-9ec9-cf2a41d56ce5.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89d834d6-7df8-407e-9ec9-cf2a41d56ce5.png)'
- en: The loop labeled **V** represents the feedback operation of the neuron. As future
    input values (**X**) are given to the neuron, the output from the previous activation
    reaches the input and becomes an input factor. As the graphic illustrates, this
    can be modeled as a linear series of simple neurons.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 标记为**V**的循环表示神经元的反馈操作。当给神经元提供未来输入值（**X**）时，前一次激活的输出达到输入并成为输入因子。如图所示，这可以建模为一系列简单的神经元的线性序列。
- en: From TensorFlow's perspective, the operation of recurrent layers are abstracted
    away by the TensorFlow layers API. Let's look at another of TensorFlow.js's examples
    that illustrates the interchangeability of various RNN architectures.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从TensorFlow的角度来看，循环层的操作被TensorFlow层API抽象化。让我们看看TensorFlow.js的另一个示例，该示例说明了各种RNN架构的可互换性。
- en: From this book's GitHub repository, navigate to the `Ch9-RNN` directory, which
    is once again a symbolic link to the `tfjs-examples/addition-rnn` directory. (If
    you still have the previous RNN example running, you will need to stop it by pressing
    *Ctrl *+ *C* in the terminal that is running the yarn watch command.) First, issue
    the `yarn` command to build the code, then run `yarn watch` to once again start
    a local server and navigate to `http://localhost:1234`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 从本书的GitHub仓库中，导航到`Ch9-RNN`目录，这再次是一个指向`tfjs-examples/addition-rnn`目录的符号链接。（如果你仍然在运行之前的RNN示例，你需要在运行yarn
    watch命令的终端中按*Ctrl + C*来停止它。）首先，运行`yarn`命令来构建代码，然后运行`yarn watch`再次启动本地服务器并导航到`http://localhost:1234`。
- en: This particular example is meant to teach an RNN integer addition by example.
    The training data will be a list of questions, such as `24 + 22` or `14 + 54`,
    represented in string form, and the network will need to be able to decode the
    string, represent it numerically, learn the answers, and be able to extend the
    knowledge to new examples.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的例子旨在通过示例教授RNN整数加法。训练数据将是一系列问题，如`24 + 22`或`14 + 54`，以字符串形式表示，网络需要能够解码字符串，将其数值化，学习答案，并将知识扩展到新的示例。
- en: 'When the page loads, you''ll see the following form. Keep the defaults and
    click the **Train Model **button:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当页面加载时，你会看到以下表单。保持默认设置并点击**Train Model**按钮：
- en: '![](img/df4355c3-4336-476c-beed-99d8bf83e2cb.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/df4355c3-4336-476c-beed-99d8bf83e2cb.png)'
- en: 'You''ll see loss and accuracy graphs similar to the following, which show that
    after 100 epochs of training, the accuracy for this model was 93.8%:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到类似于以下损失和准确度图，这表明在100个训练周期后，该模型的准确度为93.8%：
- en: '![](img/7970408c-f5d0-498f-80be-4a276443ff7d.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7970408c-f5d0-498f-80be-4a276443ff7d.png)'
- en: The loss and similarity graph
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 损失和相似度图
- en: 'You''ll also see test results from a random test input that the model validates
    against:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你还会看到模型针对随机测试输入的测试结果：
- en: '![](img/00c97fbd-a14a-4506-b313-66a262fc8e87.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00c97fbd-a14a-4506-b313-66a262fc8e87.png)'
- en: 'Let''s take a closer look at how this is working under the hood. Open the `index.js `file
    and find the `createAndCompileModel `function. I will assume that you selected
    the SimpleRNN network type for this example, and omit the switch/case statements
    that handle GRU and LSTM topologies:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看这是如何在底层工作的。打开 `index.js` 文件并找到 `createAndCompileModel` 函数。我将假设您为这个示例选择了
    SimpleRNN 网络类型，并省略了处理 GRU 和 LSTM 架构的 switch/case 语句：
- en: '[PRE5]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This code builds a model with two recurrent layers, a time-distributed, fully
    connected layer and an output layer. The `vocabularySize `parameter represents
    the total number of unique characters involved, which are the numerals 0-9, the
    plus sign, and the space character. The `maxLen` parameter represents the maximum
    length an input string could be; for two-digit addition problems, `maxLen `will
    be five characters, because the plus sign must be included.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码构建了一个包含两个循环层、一个时间分布的全连接层和输出层的模型。`vocabularySize` 参数表示涉及的总唯一字符数，这些字符是数字 0-9、加号和空格字符。`maxLen`
    参数表示输入字符串的最大长度；对于两位数加法问题，`maxLen` 将是五个字符，因为必须包括加号。
- en: Of particular note in this example is the `timeDistributed` layer type. This
    is a layer wrapper in TensorFlow's API, meant to create a volume of neurons in
    the layer where each slice represents one slice of time. This is similar in spirit
    to the volumes used by CNNs in the previous example, where the depth of the volume
    represented an individual convolution operation. In this example, however, the
    depth of the volume represents a time slice.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，特别值得注意的是 `timeDistributed` 层类型。这是 TensorFlow API 中的一个层包装器，旨在在层中创建一个神经元体积，其中每个切片代表一个时间切片。这与前一个例子中
    CNN 使用的体积在精神上相似，其中体积的深度代表一个单独的卷积操作。然而，在这个例子中，体积的深度代表一个时间切片。
- en: 'The `timeDistributed `wrapper allows each time slice to be handled by an individual
    dense or fully connected layer, rather than attempting to interpret the time-dependent
    data with only a single vector of neurons, in which case the temporal data may
    be lost. The `timeDistributed `wrapper is required because the previous *simpleRNN*
    layer uses the `returnSequences: true` parameter, which causes the layer to output
    not only the current time step, but all time steps encountered in the layer''s
    history.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`timeDistributed` 包装器允许每个时间切片由一个单独的密集层或全连接层处理，而不是仅用单个神经元向量来尝试解释时间依赖性数据，在这种情况下，时间数据可能会丢失。`timeDistributed`
    包装器是必需的，因为之前的 `simpleRNN` 层使用了 `returnSequences: true` 参数，这导致层不仅输出当前时间步，还输出层历史中遇到的所有时间步。'
- en: Next, let's take a look at the GRU topology.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看 GRU 架构。
- en: Gated recurrent units
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 门控循环单元
- en: The GRU topology comprises specialized, exotic neurons that use several internal
    mechanisms to control the memory and feedback of the neuron. The GRU is a recent
    invention, being developed only in 2014 as a simplified version of the LSTM neuron.
    While the GRU is newer than the LSTM, I present it first as it is slightly simpler.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: GRU 架构由特殊、异质的神经元组成，这些神经元使用几个内部机制来控制神经元的记忆和反馈。GRU 是一项较新的发明，仅在 2014 年作为 LSTM 神经元的简化版本被开发出来。虽然
    GRU 比 LSTM 更新，但我首先介绍它，因为它稍微简单一些。
- en: In both GRU and LSTM neurons, the input signal is sent to multiple activation
    functions. Each internal activation function can be considered a standard ANN
    neuron; these internal neurons are combined in order to give the overall neuron
    its memory capabilities. From the outside, GRU and LSTM neurons both look like
    neurons capable of receiving time-dependent inputs. On the inside, these exotic
    neurons use simpler neurons to control how much of the feedback from a previous
    activation is attenuated or amplified, as well as how much of the current signal
    is stored into memory.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GRU 和 LSTM 神经元中，输入信号被发送到多个激活函数。每个内部激活函数可以被认为是一个标准的 ANN 神经元；这些内部神经元被组合起来，以赋予整体神经元其记忆能力。从外部看，GRU
    和 LSTM 神经元都看起来像是能够接收时间依赖性输入的神经元。从内部看，这些异质神经元使用更简单的神经元来控制从前一个激活中衰减或增强多少反馈，以及将多少当前信号存储到内存中。
- en: GRU and LSTM neurons have two major advantages over simple RNN neurons. First,
    the memories of these neurons do not decay over time like the echoes of a simple
    RNN neuron do. Second, the memory is configurable and self-learning, in the sense
    that the neuron can learn through training how important specific memories are
    to the current activation.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: GRU和LSTM神经元相较于简单的RNN神经元有两个主要优势。首先，这些神经元的记忆不会像简单RNN神经元的回声那样随时间衰减。其次，记忆是可配置和自学习的，也就是说，神经元可以通过训练学习到特定记忆对当前激活的重要性。
- en: 'Consider the following illustration, also by François Deloche (own work, CC
    BY-SA 4.0):'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下插图，也是由François Deloche（本人作品，CC BY-SA 4.0）提供的：
- en: '![](img/733ab961-704c-4714-993f-eed6d557c398.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/733ab961-704c-4714-993f-eed6d557c398.png)'
- en: The flowchart may be a little difficult to interpret at first. The **Z[t]**
    signal is a vector that controls how much of the activation gets stored into memory
    and passed to future values, while the **R[t]** signal controls how much of the
    prior values should be forgotten from memory. Each of these signals are attached
    to standard activation functions, which in turn have their own weights. In a sense,
    the GRU is itself a tiny neural network.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 流程图一开始可能有点难以理解。**Z[t]**信号是一个向量，它控制了多少激活被存储到记忆中并传递给未来的值，而**R[t]**信号控制了应该从记忆中遗忘多少先前值。这些信号都连接到标准的激活函数，而这些激活函数又都有自己的权重。从某种意义上说，GRU本身就是一个微型的神经网络。
- en: At this point, it might be tempting to ask why the memory of neurons can't simply
    be programmed, for example, with a key/value store that the neuron can make lookups
    against. The reason these architectures are used is due to the fact that the backpropagation
    algorithm requires mathematical differentiability. Even exotic topologies like
    RNNs are still trained using mathematical methods such as gradient descent, so
    the entire system must be mathematically representable. For this reason, researchers
    need to use the preceding techniques in order to create a network whose every
    component is mathematically analyzable and differentiable.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，可能会有人好奇为什么神经元的记忆不能简单地通过编程来实现，例如，使用神经元可以查询的键/值存储。这些架构之所以被使用，是因为反向传播算法需要数学可微性。即使是像RNN这样的异构拓扑，也是通过数学方法如梯度下降进行训练的，因此整个系统必须是数学上可表示的。因此，研究人员需要使用前面的技术来创建一个网络，其中每个组件都是数学上可分析和可微的。
- en: 'On the test page at `http://localhost:1234`, change the *RNN Type *parameter
    to GRU while keeping all other parameters the same, and click **Train Model **again.
    The graphs will update and you should see something like the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在`http://localhost:1234`的测试页面上，将**RNN类型**参数更改为GRU，同时保持所有其他参数不变，然后再次点击**训练模型**。图表将更新，你应该会看到以下内容：
- en: '![](img/d85622d8-f6d0-4491-9cf4-a6cc44349762.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d85622d8-f6d0-4491-9cf4-a6cc44349762.png)'
- en: In this case, the training process has taken longer, but the accuracy has improved
    from 92% to 95% over the SimpleRNN type. The increased training time is not surprising,
    as the GRU architecture essentially triples the number of activation functions
    employed by the network.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，训练过程花费了更长的时间，但准确性从SimpleRNN类型的92%提高到了95%。增加的训练时间并不令人惊讶，因为GRU架构实际上将网络使用的激活函数数量增加了三倍。
- en: While many factors affect the accuracy of the network, two obvious ones stand
    out. First, the GRU topology has long-term memory, unlike the SimpleRNN that will
    eventually forget previous values as their echoes decay. Second, the GRU has more
    precise control over how much of an activation signal is fed into future activations
    as well as how much of the information is retained. These parameters of the network
    are trained by the backpropagation algorithm, so the forgetfulness of neurons
    itself is optimized by the training.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然许多因素会影响网络的准确性，但有两个明显的因素脱颖而出。首先，GRU拓扑具有长期记忆，而SimpleRNN最终会忘记先前值，因为它们的回声衰减。其次，GRU对激活信号输入未来激活以及保留信息的控制更加精确。这些网络的参数是通过反向传播算法训练的，因此神经元的遗忘性本身是通过训练进行优化的。
- en: 'Next, let''s take a look at the topology that inspired the GRU and opened up
    entire new fields of research: the LSTM.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看那个启发GRU并开辟了全新研究领域拓扑结构：LSTM。
- en: Long Short-Term Memory
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 长短期记忆
- en: The LSTM was introduced in 1997 and made waves throughout the academic ANN community
    due to its impressive accuracy at solving historically difficult problems. In
    particular, the LSTM excelled at many natural language-processing tasks, handwriting
    recognition, and speech recognition. In many cases, LSTM networks beat the previous
    accuracy records by a wide margin. Many systems at the forefront of speech recognition
    and language modeling use LSTM networks. Most likely, systems such as Apple's
    Siri and Google's Assistant, use LSTM networks both in their speech recognition
    and language- parsing models.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM在1997年被引入，由于其在解决历史难题方面的出色准确率，在学术人工神经网络社区中引起了轰动。特别是，LSTM在许多自然语言处理任务、手写识别和语音识别方面表现出色。在许多情况下，LSTM网络以很大的差距打破了之前的准确率记录。许多处于语音识别和语言建模前沿的系统都使用了LSTM网络。很可能是像苹果的Siri和谷歌的Assistant这样的系统，在它们的语音识别和语言解析模型中都使用了LSTM网络。
- en: The LSTM network gets its name due to the fact that it can retain short-term
    memory (for example, memory of a word used earlier in a sentence) for long periods
    of time. When training, this avoids a problem known as the **disappearing gradient**,
    which is what simple RNNs suffer from as the echoes of previous activations fade
    away.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM网络之所以得名，是因为它能够长时间保留短期记忆（例如，句子中较早使用过的单词的记忆）。在训练过程中，这避免了被称为“梯度消失”的问题，这是简单RNN在先前激活的回声逐渐消失时所遭受的问题。
- en: 'Like the GRU, an LSTM neuron is an exotic neuron cell with sophisticated inner
    workings. Specifically, the LSTM neuron has three *gates* it uses internally:
    an *input gate*, which controls how much of a value is allowed to enter the neuron,
    a *forget gate*, which manages the memory of the neuron, and an *output gate*,
    which controls how much of a signal is allowed in the output of the neuron. The
    combination of gates, along with the fact that the neurons are all connected to
    each other, gives the LSTM very fine-grained control over which signals a neuron
    remembers and how they are used. Like the gates in a GRU, the gates in an LSTM
    can also be thought of as individual standard neurons, each with their own weights.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 与GRU一样，LSTM神经元是一种具有复杂内部工作的异类神经元细胞。具体来说，LSTM神经元有三个内部使用的**门**：一个**输入门**，它控制允许进入神经元的值的量；一个**遗忘门**，它管理神经元的记忆；以及一个**输出门**，它控制允许进入神经元输出的信号的量。门的组合，加上神经元之间都是相互连接的，使得LSTM对神经元记住哪些信号以及如何使用这些信号具有非常精细的控制。与GRU中的门一样，LSTM中的门也可以被视为具有自己权重的独立标准神经元。
- en: 'Consider the following graphic by François Deloche (own work, CC BY-SA 4.0):'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下由弗朗索瓦·德洛什（François Deloche）制作的图形（本人作品，CC BY-SA 4.0）：
- en: '![](img/f2dd99f3-47e2-47ce-bbcc-b84d6de2b23a.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f2dd99f3-47e2-47ce-bbcc-b84d6de2b23a.png)'
- en: The **I[t ]**signal controls the proportion of the input signal that is allowed
    into the cell. The **O[t]** signal controls how much of the output is allowed
    out of the cell, and the **F[t ]**signal controls how much of the previous value
    is retained by the cell. Keep in mind that these are all vector quantities, so
    that the input, output, and memory can be controlled on a per-element basis.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**I[t]**信号控制允许进入细胞的输入信号的比例。**O[t]**信号控制允许从细胞中输出的输出量，而**F[t]**信号控制细胞保留先前值的量。记住，这些都是矢量量，因此输入、输出和记忆可以按元素进行控制。'
- en: The LSTM excels at tasks that require memory and knowledge of prior values,
    though the sophisticated inner workings of the cell (there are five distinct activation
    functions involved) lead to much longer training times. Returning to the test
    page in your browser, switch the **RNN Type **to LSTM and click **Train Model:**
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM在需要记忆和先前值知识的任务上表现出色，尽管细胞复杂的内部工作（涉及五个不同的激活函数）导致训练时间更长。回到你的浏览器中的测试页面，将**RNN类型**切换为LSTM，然后点击**训练模型**：
- en: '![](img/2791cf8b-a8b2-4d58-a58b-50e8cb9fa041.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2791cf8b-a8b2-4d58-a58b-50e8cb9fa041.png)'
- en: The LSTM has achieved an accuracy of nearly 98%, exceeding both the SimpleRNN
    and GRU RNN topologies. Of course, this network took longer to train than either
    of the others, due to the simple fact that there are more neurons (internal to
    the LSTM cells) that need to be trained.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM（长短期记忆网络）的准确率达到了近98%，超过了SimpleRNN和GRU RNN拓扑结构。当然，这个网络训练时间比其他两个都要长，因为简单的事实是，需要训练的神经元（在LSTM细胞内部）更多。
- en: There are many state-of-the-art uses for LSTM networks. They are very popular
    in audio analysis, such as speech recognition, as audio is heavily time-dependent.
    A single audio sample on its own is meaningless; it is only when many thousands
    of audio samples are taken together in context that an audio clip starts to make
    sense. An LSTM trained to recognize speech would first be trained to decode short
    audio clips (on the order of 0.1-0.25 seconds) into *phonemes*, or textual representations
    of phonetic sounds. Another LSTM layer would then be trained to connect sequences
    of phonemes together in order to determine the most likely phrase that was uttered.
    The first LSTM layer relies on time dependence in order to interpret the raw audio
    signal. The second LSTM layer relies on time dependence to bring context to natural
    language—for instance, using context and grammar to figure out whether the word
    *where* or *we're* was spoken.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM网络有许多最先进的用途。它们在音频分析中非常受欢迎，如语音识别，因为音频高度依赖于时间。单个音频样本本身是没有意义的；只有当数千个音频样本在上下文中一起取用时，音频剪辑才开始有意义。一个用于识别语音的LSTM首先会被训练来将短音频剪辑（大约0.1-0.25秒）解码成*音素*，即语音声音的文本表示。然后，另一个LSTM层会被训练来将音素序列连接起来，以确定最可能说出的短语。第一层LSTM依赖于时间依赖性来解释原始音频信号。第二层LSTM依赖于时间依赖性为自然语言提供上下文——例如，使用上下文和语法来确定是说了*在哪里*还是*我们在哪里*。
- en: Another state-of-the-art use case for LSTM is the CNN-LSTM. This network topology
    combines a CNN with an LSTM; a typical application would be action detection in
    a video clip. The CNN portion of the model analyzes individual video frames (as
    if they were independent images) to identify an object and its position or state.
    The LSTM portion of the model brings the individual frames together and generates
    a time-dependent context around them. Without an LSTM portion, a model would not
    be able to tell whether a baseball is stationary or in motion, for instance. It
    is the memory of the previous states of the object detected by the CNN that provides
    the context for determining the action occurring in the video. The CNN portion
    of the model identifies a baseball, and then the LSTM portion is what understands
    that the ball is moving and likely has been thrown or hit.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM的另一个最先进用例是CNN-LSTM。这种网络拓扑结合了CNN和LSTM；一个典型的应用将是视频剪辑中的动作检测。模型的CNN部分分析单个视频帧（就像它们是独立的图像一样），以识别对象及其位置或状态。模型的LSTM部分将单个帧组合在一起，并围绕它们生成一个时间依赖的上下文。如果没有LSTM部分，模型将无法判断棒球是静止的还是运动的，例如。是CNN检测到的对象先前状态的记忆为确定视频中发生的动作提供了上下文。模型的CNN部分识别出棒球，然后LSTM部分理解球是在移动的，可能被扔出或击中。
- en: Another variation of the CNN-LSTM is used for the automated description of images.
    One can present a CNN-LSTM with an image of a woman standing on a pier by a lake.
    The CNN portion of the model individually identifies the woman, the pier, and
    the lake as objects in the image. The LSTM portion can then generate a natural
    language description of the image based on the information gathered by the CNN;
    it is the LSTM portion that grammatically compiles the description, *woman on
    a pier by a lake*. Remember that natural language descriptions are time-dependent,
    as the order of words matters.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: CNN-LSTM的另一种变体用于自动描述图像。可以给CNN-LSTM展示一张站在湖边码头上的女人的图像。模型的CNN部分会单独识别图像中的女人、码头和湖作为对象。然后，LSTM部分可以根据CNN收集到的信息生成图像的自然语言描述；是LSTM部分在语法上编译了描述，“湖边的码头上的女人”。记住，自然语言描述是时间依赖的，因为单词的顺序很重要。
- en: One final note about LSTM networks relates to the *gates* used in the LSTM cell.
    While the input, forget, and output gates are usually standard activation neurons,
    it is also possible to use entire neural networks as gates themselves. In this
    manner, an LSTM can use *other* models as part of their knowledge and memory.
    A typical use case for this approach would be automated language translation.
    Individual LSTMs can be used to model the English and French languages, for instance,
    while an overall LSTM can manage translations between the two.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 关于LSTM网络的一个最后注意事项与LSTM单元中使用的*门*有关。虽然输入、遗忘和输出门通常使用标准的激活神经元，但也可以使用整个神经网络作为门本身。以这种方式，LSTM可以使用*其他*模型作为其知识和记忆的一部分。这种方法的典型用例将是自动语言翻译。例如，单个LSTM可以用来模拟英语和法语，而一个整体的LSTM可以管理两者之间的翻译。
- en: It is my personal belief that LSTM networks, or some variation thereof, such
    as the GRU topology, will be a key player in the road toward AGI. Having a robust
    memory is essentially a requirement when attempting to emulate general human intelligence,
    and LSTM fits the use case very nicely. These network topologies are at the forefront
    of ANN research, so expect to see major advances over the next couple of years.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人的信念是，LSTM网络，或其变体，如GRU拓扑结构，将在通往通用人工智能（AGI）的道路上扮演关键角色。在尝试模拟通用人类智能时，拥有强大的记忆能力是一个基本要求，而LSTM非常适合这种用例。这些网络拓扑结构是人工神经网络（ANN）研究的前沿，因此预计在未来几年内将看到重大进展。
- en: Summary
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we discussed two advanced neural network topologies: the CNN
    and the RNN. We discussed the CNN in the context of image recognition, specifically
    the problem of handwritten digit identification. While exploring the CNN, we also
    discussed the convolution operation itself in the context of image filtering.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了两种高级神经网络拓扑结构：卷积神经网络（CNN）和循环神经网络（RNN）。我们以图像识别的背景讨论了CNN，特别是手写数字识别的问题。在探索CNN的同时，我们还讨论了图像滤波背景下的卷积操作本身。
- en: We also discussed how neural networks can be made to retain memory through the
    RNN architecture. We learned that RNNs have many applications, ranging from time-series
    analysis to natural language modeling. We discussed several RNN architecture types,
    such as the simple fully recurrent network and the GRU network. Finally, we discussed
    the state-of-the-art LSTM topology, and how it can be used for language modeling
    and other advanced problems, such as image captioning or video annotation.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了如何通过RNN架构使神经网络保持记忆。我们了解到RNN有许多应用，从时间序列分析到自然语言建模。我们讨论了几种RNN架构类型，例如简单的全循环网络和GRU网络。最后，我们讨论了最先进的LSTM拓扑结构，以及它如何用于语言建模和其他高级问题，如图像标题或视频注释。
- en: In the next chapter, we'll take a look at some practical approaches to natural
    language processing, particularly the techniques that are most commonly used in
    conjunction with ML algorithms.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨一些自然语言处理的实际方法，特别是与机器学习算法最常结合使用的技术。
