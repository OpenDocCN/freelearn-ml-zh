<html><head></head><body>
		<div id="_idContainer227">
			<h1 id="_idParaDest-177" class="chapter-number"><a id="_idTextAnchor233"/>13</h1>
			<h1 id="_idParaDest-178"><a id="_idTextAnchor234"/><a id="_idTextAnchor235"/>Operationalizing and Optimizing Amazon Redshift ML Models</h1>
			<p>Now that you have learned how to create many different types of ML models, we will show you how you can operationalize your model training pipelines. Once you have moved your model to production, you want to refresh the model regularly and automate the process to do this. Additionally, it is important to periodically evaluate your models to maintain and improve <span class="No-Break">their accuracy.</span></p>
			<p>In this chapter, we will go through the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Operationalizing your <span class="No-Break">ML models</span></li>
				<li>Optimizing the Redshift model <span class="No-Break">for accuracy</span></li>
			</ul>
			<h1 id="_idParaDest-179"><a id="_idTextAnchor236"/>Technical requirements</h1>
			<p>This chapter requires a web browser and access to <span class="No-Break">the following:</span></p>
			<ul>
				<li>An <span class="No-Break">AWS account</span></li>
				<li>An Amazon Redshift <span class="No-Break">Serverless endpoint</span></li>
				<li>Amazon Redshift Query <span class="No-Break">Editor v2</span></li>
				<li>An Amazon EC2 Linux <span class="No-Break">instance (optional)</span></li>
			</ul>
			<p>You can find the code used in this chapter <span class="No-Break">here: </span><a href="https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/"><span class="No-Break">https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-180"><a id="_idTextAnchor237"/>Operationalizing your ML models</h1>
			<p>Once <a id="_idIndexMarker587"/>a model is validated and used on a regular basis for running predictions, it should be operationalized. The reasons for this are to remove the manual tasks of retraining your models and to ensure that your model still retains high accuracy <a id="_idIndexMarker588"/>after your data distribution has changed over time, also referred to as <strong class="bold">data drift</strong>. When<a id="_idIndexMarker589"/> data drift occurs, you need to retrain the model using an updated <span class="No-Break">training set.</span></p>
			<p>In the following sections, we will do a simple model retraining, then show you how you can create a version from an <span class="No-Break">existing model.</span></p>
			<h2 id="_idParaDest-181"><a id="_idTextAnchor238"/>Model retraining process without versioning</h2>
			<p>To walk <a id="_idIndexMarker590"/>through the retraining process, we will use one of our previously <span class="No-Break">used models.</span></p>
			<p>In <a href="B19071_07.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, we discussed different regression models, so let’s use the <strong class="source-inline">chapter7_regressionmodel.predict_ticket_price_auto</strong> model. This model solved a multi-input regression problem <a id="_idIndexMarker591"/>and <strong class="bold">SageMaker Autopilot</strong> chose<a id="_idIndexMarker592"/> the <span class="No-Break"><strong class="bold">XGBoost algorithm</strong></span><span class="No-Break">.</span></p>
			<p>Let’s assume this model is performing well and, based on our data loading processes, we want to retrain this <span class="No-Break">model weekly.</span></p>
			<p>To retrain this model, we must first remove the existing model and then re-execute the <strong class="source-inline">CREATE MODEL</strong> command <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
DROP MODEL chapter7_RegressionMOdel.predict_ticket_price_auto;
CREATE MODEL chapter7_RegressionMOdel.predict_ticket_price_auto from
chapter7_RegressionModel.sporting_event_ticket_info_training
TARGET final_ticket_price
FUNCTION predict_ticket_price_auto
IAM_ROLE default
PROBLEM_TYPE regression
OBJECTIVE 'mse'
SETTINGS (s3_bucket &lt;&lt;'your-S3-bucket&gt;&gt;',
s3_garbage_collect off,
max_runtime 9600);</pre>
			<p>You can<a id="_idIndexMarker593"/> set this up to run on a regular schedule using various techniques, which could include using the Query Editor v2 scheduling feature or running scripts. For more information on scheduling queries with Query Editor v2, refer<a id="_idIndexMarker594"/> to <span class="No-Break">the following:</span></p>
			<p><a href="https://docs.aws.amazon.com/redshift/latest/mgmt/query-editor-v2-schedule-query.html"><span class="No-Break">https://docs.aws.amazon.com/redshift/latest/mgmt/query-editor-v2-schedule-query.html</span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-182"><a id="_idTextAnchor239"/>The model retraining process with versioning</h2>
			<p>This <a id="_idIndexMarker595"/>approach of simply dropping and recreating the model might be fine in some cases, but there is no model history available since we are simply dropping and recreating the model. This makes comparing the newly trained model to previous versions very difficult, if <span class="No-Break">not impossible.</span></p>
			<p>At the time of writing, Redshift ML does not have native versioning capabilities. However, you can still do versioning by <a id="_idIndexMarker596"/>implementing a few simple SQL techniques and leveraging the <strong class="bold">bring our own model</strong> (<strong class="bold">BYOM</strong>) capability, which you learned about in <a href="B19071_11.xhtml#_idTextAnchor192"><span class="No-Break"><em class="italic">Chapter 11</em></span></a><span class="No-Break">.</span></p>
			<p>BYOM is <a id="_idIndexMarker597"/>great for leveraging pre-built Amazon SageMaker models in order to run your inference queries in Amazon Redshift and you can also use BYOM for models that were built using Redshift ML, which means we can create a <em class="italic">version</em> of an existing model that was previously created by <span class="No-Break">Redshift ML.</span></p>
			<p>Let’s take a quick refresher on the syntax of BYOM for <span class="No-Break">local inference:</span></p>
			<pre class="source-code">
CREATE MODEL model_name
    FROM ('job_name' | 's3_path' )
    FUNCTION function_name ( data_type [, ...] )
    RETURNS data_type
    IAM_ROLE { default }
    [ SETTINGS (
      S3_BUCKET 'bucket', | --required
      KMS_KEY_ID 'kms_string') --optional
    ];</pre>
			<p>We<a id="_idIndexMarker598"/> need the job name, the data types of the model inputs, and the output. We can get the information we need for the <strong class="source-inline">CREATE MODEL</strong> statement by running the <strong class="source-inline">SHOW MODEL</strong> statement on our existing model. Run the following command in Query <span class="No-Break">Editor v2:</span></p>
			<pre class="source-code">
SHOW MODEL chapter7_regressionmodel.predict_ticket_price_auto;</pre>
			<p>The result is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer209" class="IMG---Figure">
					<img src="image/B19071_13_01.jpg" alt="Figure 13.1 – ﻿The SHOW MODEL output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.1 – The SHOW MODEL output</p>
			<p>The following is the <strong class="source-inline">CREATE MODEL</strong> statement to create a version of the current model using the <strong class="bold">AutoML Job Name </strong>value from our <strong class="source-inline">SHOW MODEL</strong> command. You will also need to include the function parameter types from <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.1</em> in <strong class="source-inline">FUNCTION</strong> here and include the data type of <strong class="source-inline">Target Column</strong>(<strong class="source-inline">FINAL_TICKET_PRICE</strong>). Note that we append the date (<strong class="source-inline">YYYYMMDD</strong>) to the end of the model name and function name to create our version. You can run the following code in Query Editor v2 to create a version of <span class="No-Break">your model:</span></p>
			<pre class="source-code">
CREATE MODEL chapter7_regressionmodel.predict_ticket_price_auto_20230624
    FROM 'redshiftml-20221229211311236659'
    FUNCTION predict_ticket_price_auto_20230624 (float8,
        int8, varchar, timestamp, varchar, varchar,
        varchar, varchar, int8, int8, varchar, int8,
        float8, varchar)
    RETURNS float8
    IAM_ROLE default
    SETTINGS (
      S3_BUCKET '&lt;&lt;your S3 Bucket&gt;&gt;');</pre>
			<p>Run the <a id="_idIndexMarker599"/>following <strong class="source-inline">SHOW </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> command:</span></p>
			<pre class="source-code">
SHOW MODEL chapter7_regressionmodel.predict_ticket_price_auto_20230624;</pre>
			<p>In <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.2</em>, notice that <strong class="bold">Inference Type</strong> shows <strong class="bold">Local</strong>, which designates this as BYOM with <span class="No-Break">local inference:</span></p>
			<div>
				<div id="_idContainer210" class="IMG---Figure">
					<img src="image/B19071_13_02.jpg" alt="Figure 13.2 – ﻿The SHOW MODEL output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.2 – The SHOW MODEL output</p>
			<p>Now that you<a id="_idIndexMarker600"/> have learned how to create a version of a previously trained Redshift ML model, we will show you how you can automate <span class="No-Break">this process.</span></p>
			<h2 id="_idParaDest-183"><a id="_idTextAnchor240"/>Automating the CREATE MODEL statement for versioning</h2>
			<p>We<a id="_idIndexMarker601"/> have <a id="_idIndexMarker602"/>included the scripts <span class="No-Break">here: </span><a href="https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13. "><span class="No-Break">https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13.</span></a></p>
			<p>You can use these scripts and customize them as needed. These contain all the components needed to automate the process of performing model versioning. The example in this chapter uses Bash scripts with RSQL running on an EC2 instance. If you prefer, you can also install RSQL on Windows <span class="No-Break">or macOS.</span></p>
			<p>You may find more information on using <a id="_idIndexMarker603"/>RSQL to interact with Amazon Redshift <span class="No-Break">here: </span><a href="https://docs.aws.amazon.com/redshift/latest/mgmt/rsql-query-tool-getting-started.html"><span class="No-Break">https://docs.aws.amazon.com/redshift/latest/mgmt/rsql-query-tool-getting-started.html</span></a><span class="No-Break">.</span></p>
			<p>To download all the code for this book, you may run the commands given in the following link on an EC2 instance running on Linux or Windows or on your local Windows or <span class="No-Break">Mac machine:</span></p>
			<p><a href="https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift.git"><span class="No-Break">https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift.git</span></a><span class="No-Break">.</span></p>
			<p>Before <a id="_idIndexMarker604"/>running the scripts, we need to create the<a id="_idIndexMarker605"/> schema and the table needed to generate the <strong class="source-inline">CREATE MODEL</strong> command for the model version. You can run the following steps in Query <span class="No-Break">Editor v2:</span></p>
			<ol>
				<li>Create <span class="No-Break">the schema:</span><pre class="source-code">
Create schema chapter13;</pre></li>
				<li>Create the table to contain the metadata needed to auto-generate the <strong class="source-inline">CREATE </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> command:</span><pre class="source-code">
create table chapter13.local_inf_ml_model_components</pre><pre class="source-code">
(model_name varchar(500),</pre><pre class="source-code">
schema_name varchar(500),</pre><pre class="source-code">
automlJobName varchar(500),</pre><pre class="source-code">
functionName varchar(500),</pre><pre class="source-code">
inputs_data_type varchar(500),</pre><pre class="source-code">
target_column varchar(50),</pre><pre class="source-code">
returns_data_type varchar(50),</pre><pre class="source-code">
model_arn varchar (500),</pre><pre class="source-code">
S3_Bucket varchar (200) );</pre></li>
				<li>Initialize the <span class="No-Break"><strong class="source-inline">local_inf_ml_components</strong></span><span class="No-Break"> table.</span></li>
			</ol>
			<p>Note that you will just need to initialize this table once, with the model name, schema name, the data type of the target value we are predicting, the <strong class="bold">Amazon Resource Name</strong> (<strong class="bold">ARN</strong>) of the <a id="_idIndexMarker606"/>IAM role, and the S3 bucket to be used for the Redshift ML artifacts. The table will get updated with the additional data needed as part of the <span class="No-Break">automation script:</span></p>
			<pre class="source-code">
insert into chapter13.local_inf_ml_model_components
values
(
'predict_ticket_price_auto',
'chapter7_regressionmodel',
' ',' ',' ',' ','float8',
'&lt;arn of your IAM ROLE&gt;'
'&lt;your S3 Bucket&gt;)';</pre>
			<p>Now, we are <a id="_idIndexMarker607"/>ready to run the automation <a id="_idIndexMarker608"/>script. <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.3</em> illustrates this flow using our <strong class="source-inline">predict_ticket_price_auto</strong> model from <a href="B19071_07.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>. <strong class="bold">Step 1</strong> creates the model version by using BYOM and appending the timestamp and <strong class="bold">Step 2</strong> drops and creates the <span class="No-Break">new model:</span></p>
			<div>
				<div id="_idContainer211" class="IMG---Figure">
					<img src="image/B19071_13_03.jpg" alt="Figure 13.3 – Automation script steps 1 and 2"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.3 – Automation script steps 1 and 2</p>
			<p>Let’s walk through the steps in <span class="No-Break"><em class="italic">Figure 13</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">.</span></p>
			<h3>Step 1 – creating a version from the existing model</h3>
			<p>You may refer to the <strong class="source-inline">step1_create_model_version.sh</strong> script<a id="_idIndexMarker609"/> at <a href="https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13">https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13</a> or where you placed the file after running the <strong class="source-inline">git </strong><span class="No-Break"><strong class="source-inline">clone</strong></span><span class="No-Break"> command.</span></p>
			<p>The contents of the <strong class="source-inline">step1_create_model_version.sh</strong> script are also shown in the following code snippet. As you can see, it <a id="_idIndexMarker610"/>calls other scripts and commands <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
#! /bin/bash
# create SHOW MODEL sql command
./generate_show_model_sql.sh  'chapter7_regressionmodel.predict_ticket_price_auto'
#Read SHOW MODEL output and write to file
./show_model.sh
#copy SHOW MODEL output to the model info table
aws s3 cp create_model.txt s3://&lt;your-s3-bucket&gt;&gt;
#load SHOW MODEL output and prep table to generate create model
./prep_create_model.sh
#generate sql to create model version
./generate_create_model_version_sql.sh
#execute the sql to create model verson
./execute_create_model_version.sh</pre>
			<p>Before you execute this script, read through the following subsections as they contain instructions on some <span class="No-Break">setup steps.</span></p>
			<h4>Creating the show_model_sql command</h4>
			<p>We have a <a id="_idIndexMarker611"/>simple script <a id="_idIndexMarker612"/>called <strong class="source-inline">generate_show_model_sql.sh</strong> with code as <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
#!/bin/bash
modelname=$1
echo $1
echo SHOW MODEL $1 ';' &gt; show_model.sql</pre>
			<p>This script takes as input the model name. In the script provided, we have already supplied the model name in the <strong class="source-inline">step1_create_model_version.sh</strong> driver script. You can modify this as needed for <span class="No-Break">your models.</span></p>
			<p>The script <a id="_idIndexMarker613"/>creates a <strong class="source-inline">SHOW MODEL</strong> command that is written to a file called <strong class="source-inline">show_model.sql</strong> to be read in the <span class="No-Break"><strong class="source-inline">show_model.sh</strong></span><span class="No-Break"> script.</span></p>
			<h4>Reading the SHOW MODEL output and writing it to a file</h4>
			<p>This <a id="_idIndexMarker614"/>step executes an Amazon Redshift RSQL script called <strong class="source-inline">show_model.sh</strong>, which reads <a id="_idIndexMarker615"/>the <strong class="source-inline">show_model.sql</strong> file and<a id="_idIndexMarker616"/> writes the output to a<a id="_idIndexMarker617"/> file <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">create_model.txt</strong></span><span class="No-Break">.</span></p>
			<h4>Copying the SHOW MODEL output to the model info table</h4>
			<p>This <a id="_idIndexMarker618"/>copies the <strong class="source-inline">create_model.txt</strong> file into an <a id="_idIndexMarker619"/><span class="No-Break">S3 bucket.</span></p>
			<h4>Loading the SHOW MODEL output and prepping the table to generate <strong class="source-inline">CREATE MODEL</strong></h4>
			<p>This step <a id="_idIndexMarker620"/>executes <a id="_idIndexMarker621"/>another Amazon Redshift RSQL script called <strong class="source-inline">prep_create_model.sh</strong>, which <a id="_idIndexMarker622"/>performs <a id="_idIndexMarker623"/><span class="No-Break">the following:</span></p>
			<ul>
				<li>Creates and loads the <span class="No-Break"><strong class="source-inline">model_info</strong></span><span class="No-Break"> table</span></li>
				<li>Updates <strong class="source-inline">local_inf_ml_model_components</strong> from the <strong class="source-inline">model_info</strong> table so that the <strong class="source-inline">CREATE MODEL</strong> statement can be generated for the <span class="No-Break">model version</span></li>
				<li>Inserts the generated <strong class="source-inline">CREATE MODEL</strong> statement into the <span class="No-Break"><strong class="source-inline">create_model_sql</strong></span><span class="No-Break"> table</span></li>
			</ul>
			<h4>Generating the SQL to create the model version</h4>
			<p>This<a id="_idIndexMarker624"/> step calls an Amazon Redshift RSQL script called <strong class="source-inline">generate_create_model_version_sql.sh</strong>, which reads the <strong class="source-inline">create_model</strong> table and writes the SQL to a text file <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">model_version.txt</strong></span><span class="No-Break">.</span></p>
			<h4>Executing the SQL to create the model version</h4>
			<p>This step calls <a id="_idIndexMarker625"/>an Amazon Redshift RSQL script called <strong class="source-inline">execute_create_model_version.sh</strong>, which creates the version of our previously <span class="No-Break">created model.</span></p>
			<p>Now you can drop and create your model since we have the <span class="No-Break">model version.</span></p>
			<h3>Step 2 – retraining your Redshift ML model to create a version from the existing model</h3>
			<p>This step calls an<a id="_idIndexMarker626"/> Amazon Redshift RSQL script called <strong class="source-inline">retrain_model.sh</strong>, which drops and creates our model. It references <strong class="source-inline">retrain_model.sql</strong>, which you can modify for <span class="No-Break">your needs.</span></p>
			<p>Now that you have learned how to automate the process of retraining your Redshift ML models, let’s discuss how to optimize the accuracy of <span class="No-Break">your models.</span></p>
			<h1 id="_idParaDest-184"><a id="_idTextAnchor241"/>Optimizing the Redshift models’ accuracy</h1>
			<p>In this section, we will <a id="_idIndexMarker627"/>review best practices for maintaining the optimal accuracy of <span class="No-Break">your models.</span></p>
			<p>You will need to continually monitor your models over time to ensure the scores stay stable between model training runs. Consider the new version of the model we <span class="No-Break">created here:</span></p>
			<div>
				<div id="_idContainer212" class="IMG---Figure">
					<img src="image/B19071_13_04.jpg" alt="Figure 13.4 – New model output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.4 – New model output</p>
			<p>Create a table similar to this and track each week’s mean square error (MSE) score from the <strong class="source-inline">SHOW </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> output:</span></p>
			<pre class="source-code">
CREATE TABLE chapter13.model_score_history (
    model_name character varying(500),
    schema_name character varying(500),
    score integer,
    variance integer,
    training_date date
)
DISTSTYLE AUTO;</pre>
			<p>The variance will <a id="_idIndexMarker628"/>be the difference in the score of each successive version of <span class="No-Break">a model.</span></p>
			<p>Check how your models are trending by writing a query <span class="No-Break">like this:</span></p>
			<pre class="source-code">
Select model_name, score, variance, training_date
Order by model_name, training_date desc;</pre>
			<p>If variances are <a id="_idIndexMarker629"/>not within a reasonable amount, you will need to look at ways to improve the <span class="No-Break">model scores.</span></p>
			<p>Let’s explore how we can improve the model quality by using more data and experimenting with different model types <span class="No-Break">and algorithms.</span></p>
			<h2 id="_idParaDest-185"><a id="_idTextAnchor242"/>Model quality</h2>
			<p>The first <a id="_idIndexMarker630"/>best practice is to use more data to improve the model’s quality. Also, you can add more training time to your model by increasing the <span class="No-Break"><strong class="source-inline">MAX_RUNTIME</strong></span><span class="No-Break"> parameter.</span></p>
			<p>Ensure you are using a representative dataset for training and create at least a 10% sample <span class="No-Break">for validation.</span></p>
			<p>Experiment with different model types and algorithms to get the best model. For example, in <a href="B19071_07.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, we tried two different algorithms for the multi-input regression models. On the first one, we tried linear learning and we got an MSE score <span class="No-Break">of 701:</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer213" class="IMG---Figure">
					<img src="image/B19071_13_05.jpg" alt="Figure 13.5 – MSE score of ﻿the linear learner model type"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.5 – MSE score of the linear learner model type</p>
			<p>When we <a id="_idIndexMarker631"/>ran it again without specifying the model type, SageMaker Autopilot chose XGBoost as the model type and it gave a better MSE score <span class="No-Break">of </span><span class="No-Break"><strong class="bold">0.711260</strong></span><span class="No-Break">:</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer214" class="IMG---Figure">
					<img src="image/B19071_13_06.jpg" alt="Figure 13.6 – MSE score of XGBoost model type"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.6 – MSE score of XGBoost model type</p>
			<h2 id="_idParaDest-186"><a id="_idTextAnchor243"/>Model explainability</h2>
			<p>The second<a id="_idIndexMarker632"/> best practice is to use the explainability report to better understand which inputs to your model carried the <span class="No-Break">most weight.</span></p>
			<p>Run the following SQL command in Query <span class="No-Break">Editor v2:</span></p>
			<pre class="source-code">
select EXPLAIN_MODEL ('chapter7_regressionmodel.predict_ticket_price_auto')</pre>
			<p>This returns Shapley values for the inputs used to train <span class="No-Break">the model:</span></p>
			<pre class="source-code">
{"explanations":{"kernel_shap":{"label0":{"expected_value":23.878915786743165,"global_shap_values":
{"away_team":0.050692683450484,"city":0.004979335962039937,"event_date_time":0.05925819534780525,"event_id":0.31961543069587136,"home_team":0.04245607437910639,"list_ticket_price":36.364129559427869,"location":0.005178670063000977,"seat":0.011496876723927165,"seat_level":0.011342097571256795,"seat_row":0.011987498536296578,"seat_section":12.15498245617505,"sport":0.0029737602051575346,"ticket_id":0.3184045531012407,"ticketholder":0.005226471657467846}}}},
"version":"1.0"}</pre>
			<p>You will <a id="_idIndexMarker633"/>notice that <strong class="source-inline">list_ticket_price</strong> has the highest value of <strong class="source-inline">36.364</strong> – this means it was the highest weighted input. You can experiment by removing the input columns with very low weights as inputs to your model training. Check to see whether you still get the same approximate model score by removing unnecessary columns for the training input and helping improve <span class="No-Break">training times.</span></p>
			<h2 id="_idParaDest-187"><a id="_idTextAnchor244"/>Probabilities</h2>
			<p>For <a id="_idIndexMarker634"/>classification problems, leverage the built-in function that is generated so that you can see the probability of a given prediction. Refer to <a href="B19071_05.xhtml#_idTextAnchor068"><span class="No-Break"><em class="italic">Chapter 5</em></span></a> for detailed examples <span class="No-Break">of this.</span></p>
			<p>Let’s now take a look at some useful notebooks that are generated by Amazon <span class="No-Break">SageMaker Autopilot.</span></p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor245"/>Using SageMaker Autopilot notebooks</h2>
			<p>Your <a id="_idIndexMarker635"/>Autopilot job generates a data <a id="_idIndexMarker636"/>exploration notebook and a candidate definition notebook. To view these notebooks, follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li>In the AWS console, search for <strong class="source-inline">SageMaker</strong>, then choose <span class="No-Break"><strong class="bold">Amazon SageMaker</strong></span><span class="No-Break">:</span></li>
			</ol>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer215" class="IMG---Figure">
					<img src="image/B19071_13_07.jpg" alt="Figure 13.7 – Choosing Amazon SageMaker"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.7 – Choosing Amazon SageMaker</p>
			<ol>
				<li value="2">Then, <span class="No-Break">choose </span><span class="No-Break"><strong class="bold">Studio</strong></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer216" class="IMG---Figure">
					<img src="image/B19071_13_08.jpg" alt="Figure 13.8 – Choosing Studio"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.8 – Choosing Studio</p>
			<ol>
				<li value="3">Next, choose <span class="No-Break"><strong class="bold">Open Studio</strong></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer217" class="IMG---Figure">
					<img src="image/B19071_13_09.jpg" alt="Figure 13.9 – Choosing Open Studio"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.9 – Choosing Open Studio</p>
			<ol>
				<li value="4">Next, <span class="No-Break">choose </span><span class="No-Break"><strong class="bold">AutoML</strong></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer218" class="IMG---Figure">
					<img src="image/B19071_13_10.jpg" alt="Figure 13.10 – Choosing AutoML"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.10 – Choosing AutoML</p>
			<p>After you <a id="_idIndexMarker637"/>choose <strong class="bold">AutoML</strong>, the <a id="_idIndexMarker638"/>following screen will <span class="No-Break">show up:</span></p>
			<div>
				<div id="_idContainer219" class="IMG---Figure">
					<img src="image/B19071_13_11.jpg" alt="Figure 13.11 – List of model names"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.11 – List of model names</p>
			<ol>
				<li value="5">Choose the model name you want to evaluate. You can get this by using the AutoML job name from your <strong class="source-inline">SHOW MODEL</strong> output. In this example, I used <strong class="source-inline">SHOW MODEL</strong> on the <span class="No-Break"><strong class="source-inline">predict_ticket_price_auto</strong></span><span class="No-Break"> model:</span></li>
			</ol>
			<div>
				<div id="_idContainer220" class="IMG---Figure">
					<img src="image/B19071_13_12.jpg" alt="Figure 13.12 – ﻿The SHOW MODEL output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.12 – The SHOW MODEL output</p>
			<p>You will <a id="_idIndexMarker639"/>see output<a id="_idIndexMarker640"/> <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer221" class="IMG---Figure">
					<img src="image/B19071_13_13.jpg" alt="Figure 13.13 – AutoML best model"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.13 – AutoML best model</p>
			<p>In <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.13</em>, you <a id="_idIndexMarker641"/>can see a list of models that were trained, and the <em class="italic">best</em> model is highlighted. This also shows the objective of <strong class="bold">Mse</strong>, the values, and which algorithm was used, and<a id="_idIndexMarker642"/> there are links to view the model details, the candidate generation notebook, and the data <span class="No-Break">exploration notebook.</span></p>
			<ol>
				<li value="6">Click on <strong class="bold">View model details</strong> – this is another way you can see feature importance <span class="No-Break">or explainability:</span></li>
			</ol>
			<div>
				<div id="_idContainer222" class="IMG---Figure">
					<img src="image/B19071_13_14.jpg" alt="Figure 13.14 – Feature importance"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.14 – Feature importance</p>
			<p>You can also<a id="_idIndexMarker643"/> see the <a id="_idIndexMarker644"/>hyperparameters used by <span class="No-Break">SageMaker Autopilot:</span></p>
			<div>
				<div id="_idContainer223" class="IMG---Figure">
					<img src="image/B19071_13_15.jpg" alt="Figure 13.15 – Hyperparameters"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.15 – Hyperparameters</p>
			<ol>
				<li value="7">Now, try <a id="_idIndexMarker645"/>clicking <a id="_idIndexMarker646"/>on <strong class="bold">Open data </strong><span class="No-Break"><strong class="bold">exploration notebook</strong></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer224" class="IMG---Figure">
					<img src="image/B19071_13_16.jpg" alt="Figure 13.16 – Data exploration report"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.16 – Data exploration report</p>
			<p>This will<a id="_idIndexMarker647"/> show you the<a id="_idIndexMarker648"/> data exploration report and you can see things such as <strong class="bold">Target Analysis</strong>, <strong class="bold">Feature Summary</strong>, <strong class="bold">Duplicate Rows</strong>, and <span class="No-Break">other statistics.</span></p>
			<p>Here is what <strong class="bold">Target Analysis</strong> showed for our <span class="No-Break"><strong class="source-inline">predict_ticket_price_auto</strong></span><span class="No-Break"> model:</span></p>
			<div>
				<div id="_idContainer225" class="IMG---Figure">
					<img src="image/B19071_13_17.jpg" alt="Figure 13.17 – Target Analysis"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.17 – Target Analysis</p>
			<p>To <a id="_idIndexMarker649"/>learn more <a id="_idIndexMarker650"/>about the data exploration notebook, you may <a id="_idIndexMarker651"/>refer to this <span class="No-Break">link: </span><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-data-exploration-report.html"><span class="No-Break">https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-data-exploration-report.html</span></a><span class="No-Break">.</span></p>
			<ol>
				<li value="8">Now, click on <strong class="bold">Open candidate </strong><span class="No-Break"><strong class="bold">generation notebook</strong></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer226" class="IMG---Figure">
					<img src="image/B19071_13_18.jpg" alt="Figure 13.18 – Candidate definition notebook"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.18 – Candidate definition notebook</p>
			<p>This notebook contains information about the processing steps, algorithms, and hyperparameters. To learn more about using the<a id="_idIndexMarker652"/> candidate generation notebook, refer <span class="No-Break">to </span><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-candidate-generation-notebook.html"><span class="No-Break">https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-candidate-generation-notebook.html</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-189"><a id="_idTextAnchor246"/>Summary</h1>
			<p>In this chapter, you learned techniques to operationalize your models in Amazon <span class="No-Break">Redshift ML.</span></p>
			<p>We discussed how you can create a version of your model. This is important to track the quality of your model over time and to be able to run inferences with <span class="No-Break">different versions.</span></p>
			<p>We then showed you how to optimize your Redshift ML models for accuracy and how you can use the notebooks generated by Amazon SageMaker Autopilot to deepen your understanding of tasks that Autopilot <span class="No-Break">is performing.</span></p>
			<p>We hope you have found this book useful. Our goal when we set out to write this book was to help you gain confidence in these <span class="No-Break">main areas:</span></p>
			<ul>
				<li>Gaining a better understanding of machine learning and how to use it to solve everyday <span class="No-Break">business problems</span></li>
				<li>Implementing an end-to-end serverless architecture for ingestion, analytics, and machine learning using Redshift Serverless and <span class="No-Break">Redshift ML</span></li>
				<li>Creating supervised and unsupervised models, and various techniques to influence <span class="No-Break">your model</span></li>
				<li>Running inference queries at scale in Redshift to solve a variety of business problems using models created with Redshift ML or natively in <span class="No-Break">Amazon SageMaker</span></li>
			</ul>
			<p>We thank you very much for your time and investment in reading this book. We would welcome your feedback on how we can make Redshift and Redshift ML better. You can find us <span class="No-Break">on LinkedIn.</span></p>
		</div>
	</body></html>