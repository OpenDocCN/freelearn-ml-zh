["```py\nlibrary(recommenderlab)\nlibrary(ggplot2)\n```", "```py\ndata(MovieLense)\nratings_movies <- MovieLense[rowCounts(MovieLense) > 50, colCounts(MovieLense) > 100]ratings_movies\n## 560 x 332 rating matrix of class 'realRatingMatrix' with 55298 ratings.\n```", "```py\npercentage_training <- 0.8\n```", "```py\nmin(rowCounts(ratings_movies))\n## _18_\n```", "```py\nitems_to_keep <- 15\n```", "```py\nrating_threshold <- 3\n```", "```py\nn_eval <- 1\n```", "```py\neval_sets <- evaluationScheme(data = ratings_movies, method = \"split\", train = percentage_training, given = items_to_keep, goodRating = rating_threshold, k = n_eval) eval_sets\n## Evaluation scheme with 15 items given\n## Method: 'split' with 1 run(s).\n## Training set proportion: 0.800\n## Good ratings: >=3.000000\n## Data set: 560 x 332 rating matrix of class 'realRatingMatrix' with 55298 ratings.\n```", "```py\ngetData(eval_sets, \"train\")\n## 448 x 332 rating matrix of class 'realRatingMatrix' with 44472 ratings.\n```", "```py\nnrow(getData(eval_sets, \"train\")) / nrow(ratings_movies)\n## _0.8_\n```", "```py\ngetData(eval_sets, \"known\")\n## 112 x 332 rating matrix of class 'realRatingMatrix' with 1680 ratings.\ngetData(eval_sets, \"unknown\")\n## 112 x 332 rating matrix of class 'realRatingMatrix' with 9146 ratings.\n```", "```py\nnrow(getData(eval_sets, \"known\")) / nrow(ratings_movies)\n## _0.2_\n```", "```py\nunique(rowCounts(getData(eval_sets, \"known\")))\n## _15_\n```", "```py\nqplot(rowCounts(getData(eval_sets, \"unknown\"))) + geom_histogram(binwidth = 10) + ggtitle(\"unknown items by the users\")\n```", "```py\npercentage_training <- 0.8\nitems_to_keep <- 15\nrating_threshold <- 3\nn_eval <- 1\neval_sets <- evaluationScheme(data = ratings_movies, method = \"bootstrap\", train = percentage_training, given = items_to_keep, goodRating = rating_threshold, k = n_eval)\n```", "```py\nnrow(getData(eval_sets, \"train\")) / nrow(ratings_movies)\n## _0.8_\n```", "```py\nperc_test <- nrow(getData(eval_sets, \"known\")) / nrow(ratings_movies)\nperc_test\n## _0.4393_\n```", "```py\nlength(unique(eval_sets@runsTrain[[1]]))\n## _314_\n```", "```py\nperc_train <- length(unique(eval_sets@runsTrain[[1]])) / nrow(ratings_movies)\nperc_train + perc_test\n## _1_\n```", "```py\ntable_train <- table(eval_sets@runsTrain[[1]])\nn_repetitions <- factor(as.vector(table_train))\nqplot(n_repetitions) + ggtitle(\"Number of repetitions in the training set\")\n```", "```py\nn_fold <- 4\neval_sets <- evaluationScheme(data = ratings_movies, method = \"cross-validation\", k = n_fold, given = items_to_keep, goodRating = rating_threshold)\n```", "```py\nsize_sets <- sapply(eval_sets@runsTrain, length)\nsize_sets\n## _420_, _420_, _420_ and _420_\n```", "```py\nn_fold <- 4\nitems_to_keep <- 15\nrating_threshold <- 3\neval_sets <- evaluationScheme(data = ratings_movies, method = \"cross-validation\", k = n_fold, given = items_to_keep, goodRating = rating_threshold)\n```", "```py\nmodel_to_evaluate <- \"IBCF\"\nmodel_parameters <- NULL\n```", "```py\neval_recommender <- Recommender(data = getData(eval_sets, \"train\"), method = model_to_evaluate, parameter = model_parameters)\n```", "```py\nitems_to_recommend <- 10\n```", "```py\neval_prediction <- predict(object = eval_recommender, newdata = getData(eval_sets, \"known\"), n = items_to_recommend, type = \"ratings\") class(eval_prediction)\n## realRatingMatrix\n```", "```py\nqplot(rowCounts(eval_prediction)) + geom_histogram(binwidth = 10) + ggtitle(\"Distribution of movies per user\")\n```", "```py\neval_accuracy <- calcPredictionAccuracy(\n  x = eval_prediction, data = getData(eval_sets, \"unknown\"), byUser = TRUE)\nhead(eval_accuracy)\n```", "```py\nqplot(eval_accuracy[, \"RMSE\"]) + geom_histogram(binwidth = 0.1) + ggtitle(\"Distribution of the RMSE by user\")\n```", "```py\neval_accuracy <- calcPredictionAccuracy(x = eval_prediction, data = getData(eval_sets, \"unknown\"), byUser = FALSE) eval_accuracy\n## _1.101_, _1.211_ and _0.8124_\n```", "```py\nresults <- evaluate(x = eval_sets, method = model_to_evaluate, n = seq(10, 100, 10))\nclass(results)\n## evaluationResults\n```", "```py\nhead(getConfusionMatrix(results)[[1]])\n```", "```py\ncolumns_to_sum <- c(\"TP\", \"FP\", \"FN\", \"TN\")\nindices_summed <- Reduce(\"+\", getConfusionMatrix(results))[, columns_to_sum]\nhead(indices_summed)\n```", "```py\nplot(results, annotate = TRUE, main = \"ROC curve\")\n```", "```py\nplot(results, \"prec/rec\", annotate = TRUE, main = \"Precision-recall\")\n```", "```py\nlist(name = \"IBCF\", param = list(k = 20))\n```", "```py\nmodels_to_evaluate <- list(\n  IBCF_cos = list(name = \"IBCF\", param = list(method = \"cosine\")),IBCF_cor = list(name = \"IBCF\", param = list(method = \"pearson\")),UBCF_cos = list(name = \"UBCF\", param = list(method = \"cosine\")),UBCF_cor = list(name = \"UBCF\", param = list(method = \"pearson\")),random = list(name = \"RANDOM\", param=NULL)\n)\n```", "```py\nn_recommendations <- c(1, 5, seq(10, 100, 10))\n```", "```py\nlist_results <- evaluate(x = eval_sets, method = models_to_evaluate, n = n_recommendations)\nclass(list_results)\n## evaluationResultList\n```", "```py\nclass(list_results[[1]])\n## evaluationResults\n```", "```py\nsapply(list_results, class) == \"evaluationResults\"\n## TRUE TRUE TRUE TRUE TRUE\n```", "```py\navg_matrices <- lapply(list_results, avg)\n```", "```py\nhead(avg_matrices$IBCF_cos[, 5:8])\n```", "```py\nplot(list_results, annotate = 1, legend = \"topleft\") title(\"ROC curve\")\n```", "```py\nplot(list_results, \"prec/rec\", annotate = 1, legend = \"bottomright\") title(\"Precision-recall\")\n```", "```py\nvector_k <- c(5, 10, 20, 30, 40)\n```", "```py\nmodels_to_evaluate <- lapply(vector_k, function(k){\n  list(name = \"IBCF\", param = list(method = \"cosine\", k = k))})names(models_to_evaluate) <- paste0(\"IBCF_k_\", vector_k)\nUsing the same commands as we did earlier, let's build and evaluate the models:\nn_recommendations <- c(1, 5, seq(10, 100, 10))\nlist_results <- evaluate(x = eval_sets, method = models_to_evaluate, n = n_recommendations)\n```", "```py\nplot(list_results, annotate = 1,      legend = \"topleft\") title(\"ROC curve\")\n```", "```py\nplot(list_results, \"prec/rec\", annotate = 1, legend = \"bottomright\")\ntitle(\"Precision-recall\")\n```"]