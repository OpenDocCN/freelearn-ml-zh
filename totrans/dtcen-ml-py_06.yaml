- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Techniques for Programmatic Labeling in Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In machine learning, the accurate labeling of data is crucial for training
    effective models. Data labeling involves assigning meaningful categories or classes
    to data instances, and while traditionally a human-driven process, there are various
    programmatic approaches to dataset labeling. This chapter delves into the following
    methods of programmatic data labeling in machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Pattern matching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Database** (**DB**) lookup'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boolean flags
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weak supervision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-weak supervision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slicing functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Active learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To execute the code examples provided in this chapter on programmatic labeling
    techniques, ensure that you have the following technical prerequisites installed
    in your Python environment:'
  prefs: []
  type: TYPE_NORMAL
- en: Python version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The examples in this chapter require Python version 3.7 or higher. You can
    check your Python version by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We recommend using the Jupyter Notebook **integrated development environment**
    (**IDE**) for an interactive and organized coding experience. If you don’t have
    it installed, you can install it using this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Launch Jupyter Notebook with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Library requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Ensure that the following Python packages are installed in your environment.
    You can install them using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Additionally, for the TensorFlow and Keras components, you may need GPU support
    for optimal performance. Refer to the TensorFlow documentation for GPU installation
    instructions if you have a compatible GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Pattern matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In machine learning, one of the most important tasks is to label or classify
    data based on some criteria or patterns. However, labeling data manually can be
    time consuming and costly, especially when dealing with a large amount of data.
    By leveraging predefined patterns, this labeling approach enables the automatic
    assignment of meaningful categories or classes to data instances.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pattern matching** involves the identification of specific patterns or sequences
    within data that can be used as indicators for assigning labels. These patterns
    can be defined using regular expressions, rule-based systems, or other pattern
    recognition algorithms. The objective is to capture relevant information and characteristics
    from the data that can be matched against predefined patterns to infer labels
    accurately.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pattern matching can be applied to various domains and scenarios in machine
    learning. Some common applications include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Text classification**: In natural language processing, pattern matching can
    be utilized to label text data based on specific keywords, phrases, or syntactic
    patterns. This enables tasks such as sentiment analysis, spam detection, and topic
    categorization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image recognition**: Pattern matching can aid in labeling images by identifying
    distinctive visual patterns or features that correspond to specific classes. This
    technique can be valuable in tasks such as object recognition, facial detection,
    and image segmentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time series analysis**: When dealing with time-dependent data, pattern matching
    can be employed to label sequences of events or patterns that occur over time.
    This is particularly useful in financial analysis, anomaly detection, and predicting
    stock market trends.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fraud detection**: Pattern matching can play a crucial role in identifying
    fraudulent activities by matching suspicious patterns or anomalies against known
    fraud patterns. This technique can help in credit card fraud detection, network
    intrusion detection, and cybersecurity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pattern matching offers several advantages as a labeling technique in machine
    learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Automation and efficiency**: By automating the labeling process, pattern
    matching reduces the reliance on manual labeling, saving time and effort. It allows
    for large-scale dataset labeling with increased efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility and adaptability**: Patterns can be easily modified or extended
    to accommodate new data or evolving requirements. This provides flexibility in
    adapting to changing labeling criteria and ensures scalability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interpretability**: Pattern matching provides a transparent and interpretable
    approach to labeling, as the rules and patterns can be examined and understood.
    This aids in the transparency and explainability of the labeling process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complementing other techniques**: Pattern matching can be used in conjunction
    with other labeling techniques, such as weak supervision or transfer learning,
    to enhance the overall labeling accuracy and robustness of machine learning models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While pattern matching is a valuable labeling technique, it also presents certain
    challenges and considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Noise and ambiguity**: Data instances that do not perfectly match predefined
    patterns may introduce noise or ambiguity in the labeling process. Handling such
    cases requires careful design and consideration of pattern definitions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: As datasets grow larger, the scalability of pattern matching
    becomes crucial. Efficient algorithms and techniques must be employed to handle
    the increasing computational demands.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overfitting**: Overfitting can occur if patterns are too specific and fail
    to generalize well to unseen data instances. Regularization techniques and cross-validation
    can be used to mitigate this risk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section of the chapter, we will explore how to create pattern-matching
    labeling functions using Python and apply them to the `credit-g` dataset. The
    `credit-g` dataset, also known as the German Credit dataset, is a collection of
    data points used for risk analysis in the field of finance and machine learning.
    It’s used to classify people as good or bad credit risks based on a set of attributes.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset consists of 20 variables, including both numerical and categorical
    data. These variables provide information about each individual, such as their
    checking account status, credit history, purpose of the loan, credit amount, savings
    account/bonds, employment, installment rate in percentage of disposable income,
    personal status and gender, and other attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Each entry in the dataset represents an individual who has applied for a loan.
    The target variable indicates whether the individual is classified as a ‘good’
    or ‘bad’ credit risk. This makes the dataset particularly useful for supervised
    machine learning tasks, especially binary classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: The `credit-g` dataset is widely used in academia and industry for developing
    and testing machine learning models for credit risk assessment. It is available
    on several platforms, such as DataHub, Kaggle, OpenML, and UCI Machine Learning
    Repository.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the specifics of the variables might differ slightly depending
    on the source of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can start by loading the `credit-g` dataset into Python. The dataset contains
    information about loan applicants, including their demographic information, financial
    information, and loan approval status. We can use the `pandas` library to load
    the dataset and explore its structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the first five rows of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – The features (first column) and first five rows of the credit-g
    dataset](img/B19297_06_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – The features (first column) and first five rows of the credit-g
    dataset
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have loaded the dataset, we can create pattern-matching labeling
    functions. In this example, we will create two labeling functions that assign
    labels to loan applicants based on their income and credit history. `income_labeling_function`
    assigns a label of `1` to loan applicants with an income greater than 5,000 and
    a label of `0` to all others. `credit_history_labeling_function` assigns a label
    of `1` to loan applicants with a credit history of 1, and a label of `0` to all
    others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the features in the `credit-g` dataset, we can create two labeling functions
    based on `credit_amount` and `age`. `credit_amount_labeling_function` assigns
    a label of `1` to loan applicants with a credit amount greater than 5,000 and
    a label of `0` to all others. `age_labeling_function` assigns a label of `1` to
    loan applicants older than 30 and a label of `0` to all others:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating the labeling functions, we can apply them to the `credit-g`
    dataset. We can use the `apply` function in pandas to apply the labeling functions
    to each row of the dataset. The `apply` function applies the labeling functions
    to each row of the dataset and assigns the labels to new columns in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output DataFrame using these functions. The DataFrame now has two
    additional columns with newly created labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – The updated credit-g dataset with two new features, credit_amount_label
    and age_label](img/B19297_06_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – The updated credit-g dataset with two new features, credit_amount_label
    and age_label
  prefs: []
  type: TYPE_NORMAL
- en: Having explored pattern-matching functions, we now shift our focus to the simplicity
    and effectiveness of database lookup techniques. In this next section, we’ll harness
    structured databases to enhance labeling accuracy, making our approach even more
    robust.
  prefs: []
  type: TYPE_NORMAL
- en: Database lookup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **database lookup** (**DB lookup**) labeling technique provides a powerful
    means of assigning labels to data instances by leveraging information stored in
    databases. By querying relevant databases and retrieving labeled information,
    this approach enables automated and accurate labeling. This technique involves
    searching and retrieving labels from databases based on specific attributes or
    key-value pairs associated with data instances. It relies on the premise that
    databases contain valuable labeled information that can be utilized for data labeling
    purposes. By performing queries against databases, relevant labels are fetched
    and assigned to the corresponding data instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'The DB lookup technique finds application in various domains and scenarios
    within machine learning. Some common applications include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Entity recognition**: In natural language processing tasks, such as named
    entity recognition or entity classification, DB lookup can be used to retrieve
    labels for entities based on their attributes stored in databases. This aids in
    the accurate identification and categorization of entities in text data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Product categorization**: E-commerce platforms often maintain databases containing
    product information, including categories and attributes. DB lookup can be employed
    to fetch product labels based on their features, allowing for automated categorization
    and organization of products.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Geospatial analysis**: Databases containing geographical information, such
    as maps or geotagged data, can be queried using DB lookup to assign labels based
    on spatial attributes. This technique facilitates tasks such as location-based
    recommendations, geospatial clustering, and boundary identification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Medical diagnosis**: Medical databases store extensive information about
    diseases, symptoms, and patient records. DB lookup can be utilized to retrieve
    relevant labels for patient symptoms, aiding in automated medical diagnosis and
    decision support systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s talk about Boolean flag labeling. It’s a simple yet powerful method
    that helps us improve and automate labeling by using clear and logical conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Boolean flags
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `true`/`false` or `1`/`0`), are associated with specific characteristics
    or properties that help identify the desired label. By examining the presence
    or absence of these flags, data instances can be automatically labeled.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Boolean flags labeling technique finds applications across various domains
    in machine learning. Some common applications include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data filtering**: Boolean flags can be used to filter and label data instances
    based on specific criteria. For example, in sentiment analysis, a positive sentiment
    flag can be assigned to text instances that contain positive language or keywords,
    while a negative sentiment flag can be assigned to instances with negative language.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event detection**: Boolean flags can aid in labeling instances to detect
    specific events or conditions. For instance, in cybersecurity, a flag can be set
    to indicate instances with suspicious network activity, enabling the identification
    of potential security threats.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anomaly detection**: Boolean flags can be used to label instances as normal
    or anomalous. By defining flags that capture typical patterns or behaviors, instances
    that deviate from these patterns can be flagged as anomalies, facilitating anomaly
    detection tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quality control**: Boolean flags can assist in labeling instances for quality
    control purposes. For example, in manufacturing, flags can be set to label instances
    as defective or non-defective based on predefined quality criteria.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Boolean flags labeling technique offers several advantages in machine learning
    applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simplicity and efficiency**: Boolean flags provide a straightforward and
    efficient labeling mechanism. The labeling process involves checking the presence
    or absence of flags, which can be implemented using simple conditional statements
    or logical operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility and customization**: Boolean flags allow for customization and
    adaptability to different labeling scenarios. Flags can be defined based on specific
    criteria or requirements, providing flexibility in assigning labels according
    to the desired characteristics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interpretability**: The Boolean flags labeling technique offers interpretability,
    as the presence or absence of flags directly corresponds to the assigned labels.
    This transparency allows for better understanding and validation of the labeling
    process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: Boolean flags can be easily scaled to handle large datasets.
    Since the labeling decision is based on binary indicators, the computational overhead
    remains low, making it suitable for processing massive amounts of data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While the Boolean flags labeling technique provides simplicity and efficiency,
    certain challenges and considerations should be taken into account:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature engineering**: Designing effective Boolean flags requires careful
    feature engineering. The flags should be informative and relevant to the desired
    labels, necessitating a deep understanding of the problem domain and data characteristics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data imbalance**: In scenarios where the data is imbalanced, meaning one
    label dominates over others, the Boolean flags technique may face challenges.
    Proper handling techniques, such as oversampling or under-sampling, may be required
    to address the imbalance issue.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalization**: Boolean flags may not capture the full complexity of the
    underlying data distribution, potentially leading to overfitting or limited generalization.
    It is important to consider complementary techniques, such as feature extraction
    or more advanced machine learning algorithms, to enhance the performance and generalization
    capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flag interpretation**: While Boolean flags provide interpretability, it is
    crucial to carefully interpret the flags’ meanings in relation to the assigned
    labels. In some cases, the flags may capture correlations rather than causal relationships,
    requiring further investigation for a more accurate interpretation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may have already noticed some similarities between Boolean flags and one-hot
    encoding (covered in [*Chapter 5*](B19297_05.xhtml#_idTextAnchor070)*, Techniques
    for Data Cleaning*). Therefore, it’s important to understand when these techniques
    are appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: When choosing between Boolean flags and one-hot encoding, the specific use case
    is a crucial factor. If you’re working with a categorical variable that can be
    naturally divided into two categories or states (such as yes/no, true/false),
    using a Boolean flag might be the best option. It’s simpler, more memory-efficient,
    and can make the model easier to interpret.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you’re predicting whether an email is spam or not, a Boolean
    flag such as `contains_link` (`1` if the email contains a link, `0` otherwise)
    could be a very effective feature. This simplicity can lead to more interpretable
    models, as each feature directly corresponds to a condition or state.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, one-hot encoding is more suitable for categorical variables
    with multiple categories where no natural binary division exists. For instance,
    if you’re working with a feature such as `color` with values such as `red`, `blue`,
    `green`, etc., one-hot encoding would be a better choice. That’s because the numbers
    assigned to each category shouldn’t imply a mathematical relationship between
    the categories unless one exists. For example, encoding red as `1` and blue as
    `2` doesn’t mean blue is twice red.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid implying such unintended relationships, creating a separate feature
    for each possible color is preferred. This approach captures more information
    about the color feature and doesn’t impose an arbitrary order or importance on
    the different colors.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the type of machine learning model being used also influences the
    choice. Some models, such as decision trees and random forests, can handle categorical
    variables quite well, so one-hot encoding (which increases the dimensionality
    of the dataset) might not be necessary. However, others, such as linear regression,
    logistic regression, and support vector machines, require numerical input, necessitating
    some form of encoding for categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, it’s worth noting that these aren’t the only methods for handling categorical
    data. There are other techniques, such as ordinal encoding, target encoding, and
    bin counting, each with its own strengths and weaknesses. The key is to understand
    the nature of your data and the requirements of your specific use case to choose
    the most appropriate method.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore how to utilize Boolean flags in Python with the `credit-g` dataset.
    Imagine we want to create a function that applies Boolean flags to label data
    points according to basic rules or heuristics. For instance, we can write a function
    that evaluates whether a credit applicant’s credit amount is above a specific
    threshold, subsequently assigning a Boolean flag to the data point based on this
    assessment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following functions will check if the credit amount is below or above the
    median credit amount:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have defined our function, we can apply it to our `df` DataFrame
    to label the data points with Boolean flags:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 6**.3* is the output DataFrame after we have applied these functions.
    Notice that we have now created a new column giving us additional information
    on the applicant’s credit amount, which can be used as a feature in machine learning
    models.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – The credit-g dataset with the new Boolean flag LF_CreditAmountAboveMedian
    added](img/B19297_06_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – The credit-g dataset with the new Boolean flag LF_CreditAmountAboveMedian
    added
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, let’s explore weak supervision—a sophisticated labeling
    technique that adeptly integrates information from various sources, navigating
    the intricacies of real-world data to enhance precision and adaptability.
  prefs: []
  type: TYPE_NORMAL
- en: Weak supervision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Weak supervision is a labeling technique in machine learning that leverages
    imperfect or noisy sources of supervision to assign labels to data instances.
    Unlike traditional labeling methods that rely on manually annotated data, weak
    supervision allows for a more scalable and automated approach to labeling. It
    refers to the use of heuristics, rules, or probabilistic methods to generate approximate
    labels for data instances.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than relying on a single authoritative source of supervision, weak supervision
    harnesses multiple sources that may introduce noise or inconsistency. The objective
    is to generate labels that are “weakly” indicative of the true underlying labels,
    enabling model training in scenarios where obtaining fully labeled data is challenging
    or expensive.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, consider a task where we want to build a machine learning model
    to identify whether an email is spam or not. Ideally, we would have a large dataset
    of emails that are accurately labeled as “spam” or “not spam.” However, obtaining
    such a dataset could be challenging, time-consuming, and expensive.
  prefs: []
  type: TYPE_NORMAL
- en: 'With weak supervision, we can use alternative, less perfect ways to label our
    data. For instance, we could create some rules or heuristics based on common patterns
    in spam emails. Here are a few examples of such rules:'
  prefs: []
  type: TYPE_NORMAL
- en: If the email contains words such as “lottery”, “win”, or “prize”, it might be
    spam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the email is from an unknown sender and contains many links, it might be
    spam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the email contains phrases such as “urgent action required”, it might be
    spam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using these rules, we can automatically label our email dataset. These labels
    won’t be perfect— there will be false positives (non-spam emails incorrectly labeled
    as spam) and false negatives (spam emails incorrectly labeled as non-spam). But
    they give us a starting point for training our machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: The model can then learn from these “weak” labels and, with a sufficiently large
    and diverse dataset, should still be able to generalize well to new, unseen emails.
    This makes weak supervision a scalable and efficient approach to labeling, particularly
    useful when perfect labels are hard to come by.
  prefs: []
  type: TYPE_NORMAL
- en: 'Weak supervision can be derived from various sources, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rule-based systems**: Domain experts or heuristics-based approaches can define
    rules or guidelines for labeling data based on specific patterns, features, or
    conditions. These rules may be derived from knowledge bases, existing models,
    or expert opinions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Crowdsourcing**: Leveraging the power of human annotators through crowdsourcing
    platforms, weak supervision can be obtained by aggregating the annotations from
    multiple individuals. This approach introduces noise but can be cost-effective
    and scalable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distant supervision**: Distant supervision involves using existing labeled
    data that may not perfectly align with the target task but can serve as a proxy.
    An example is using existing data with auxiliary labels to train a model for a
    related but different task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data augmentation**: Weak supervision can be obtained through data augmentation
    techniques such as data synthesis, transformation, or perturbation. By generating
    new labeled instances based on existing labeled data, weak supervision can be
    expanded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Weak supervision offers several advantages in machine learning applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scalability**: Weak supervision allows for large-scale data labeling by leveraging
    automated or semi-automated techniques. It reduces the manual effort required
    for manual annotation, enabling the utilization of larger datasets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost-effectiveness**: By leveraging weakly supervised sources, the cost of
    obtaining labeled data can be significantly reduced compared to fully supervised
    approaches. This is particularly beneficial in scenarios where manual labeling
    is expensive or impractical.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility and adaptability**: Weak supervision techniques can be easily
    adapted and modified to incorporate new sources of supervision or update existing
    rules. This flexibility allows for iterative improvement and refinement of the
    labeling process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handling noisy labels**: Weak supervision techniques can handle noisy or
    inconsistent labels by aggregating multiple weak signals. This robustness to noise
    reduces the impact of individual labeling errors on the overall training process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are, however, certain challenges and considerations to be aware of:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Noise and label quality**: Weakly supervised labels may contain noise or
    errors due to the imperfect nature of the supervision sources. Careful evaluation
    and validation are necessary to ensure label quality and minimize the propagation
    of noisy labels during model training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trade-off between precision and recall**: Weak supervision techniques often
    prioritize scalability and coverage over precision. Balancing the trade-off between
    recall (coverage) and precision (accuracy) is essential in obtaining reliable
    weakly labeled data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Labeling confidence and model training**: Handling the uncertainty associated
    with weakly supervised labels is crucial. Techniques such as label calibration,
    data augmentation, or active learning can be employed to mitigate the impact of
    label uncertainty during model training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalization and model performance**: Weakly supervised models may struggle
    with generalizing to unseen or challenging instances due to the inherent noise
    in the labels. Strategies such as regularization, ensemble methods, or transfer
    learning can be employed to enhance model performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this section, we will explore how to use labeling functions in Python to
    train a machine learning model on the *Loan Prediction* dataset we introduced
    in [*Chapter 5*](B19297_05.xhtml#_idTextAnchor070)*, Techniques for Data Cleaning*.
    First, we need to prepare the data by importing the necessary libraries and loading
    the dataset, and we need to preprocess the data by handling missing values and
    encoding categorical variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the `LabelEncoder` function from scikit-learn’s `preprocessing`
    class to encode categorical columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can define our labeling functions. In this example, we will define
    three labeling functions based on some simple heuristics. These labeling functions
    take in a row of the dataset as input and return a label. The label is `1` if
    the row is likely to be in the positive class, `0` if it is likely to be in the
    negative class, and `-1` if it is uncertain. Functions such as these are commonly
    used in weak supervision approaches where you have a large amount of unlabeled
    data and you want to generate noisy labels for them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can apply the labeling functions to the dataset using the Snorkel library.
    Here, we create a list of the three labeling functions and use the `PandasLFApplier`
    to apply them to the dataset. The output is a `L_train` matrix where each row
    corresponds to a data point and each column corresponds to a labeling function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You’ll see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Progress bar showing the training progress](img/B19297_06_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – Progress bar showing the training progress
  prefs: []
  type: TYPE_NORMAL
- en: 'To improve the output of the labeling functions, we need to combine them to
    obtain a more accurate label for each data point. We can do this using the `LabelModel`
    class in the Snorkel library. The `LabelModel` class is a probabilistic model
    used for combining the outputs of multiple labeling functions to generate more
    accurate and reliable labeling for each data point. It plays a crucial role in
    addressing the noise and inaccuracies that may arise from individual labeling
    functions. We create a `LabelModel` object as `label_model` and fit it to the
    output of the labeling functions. The cardinality parameter specifies the number
    of classes, which is `2` in this case. We also specify the number of epochs to
    train for and a random seed for reproducibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'After executing the preceding code snippet utilizing Snorkel’s labeling model,
    a progress bar will display the incremental application of the labeling:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – The Snorkel progress bar showing the incremental progress of
    the labeling process](img/B19297_06_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – The Snorkel progress bar showing the incremental progress of the
    labeling process
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now use the `LabelModel` class to generate labels for the training data
    and evaluate its performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s learn how to use semi-weak supervision for labeling. It’s a smart
    technique that combines weak supervision with a bit of manual labeling to make
    our labels more accurate.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-weak supervision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Semi-weak supervision is a technique used in machine learning to improve the
    accuracy of a model by combining a small set of labeled data with a larger set
    of weakly labeled data. In this approach, the labeled data is used to guide the
    learning process, while the weakly labeled data provides additional information
    to improve the accuracy of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-weak supervision is particularly useful when labeled data is limited or
    expensive to obtain and can be applied to a wide range of machine learning tasks,
    such as text classification, image recognition, and object detection.
  prefs: []
  type: TYPE_NORMAL
- en: In the loan prediction dataset, we have a set of data points representing loan
    applications, each with a set of features such as income, credit history, and
    loan amount, and a label indicating whether the loan was approved or not. However,
    this labeled data may be incomplete or inaccurate, which can lead to poor model
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: To address this issue, we can use semi-weak supervision to generate additional
    labels for the loan prediction dataset. One approach is to use weak supervision
    techniques to generate labels automatically based on heuristics or rules. For
    example, we can use regular expressions to identify patterns in the loan application
    text data that are indicative of a high-risk loan. We can also use external data
    sources, such as credit reports or social media data, to generate additional weakly
    labeled data.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have a set of weakly labeled data, we can use it to train a model along
    with the small set of labeled data. The labeled data is used to guide the learning
    process, while the weakly labeled data provides additional information to improve
    the accuracy of the model. By using semi-weak supervision, we can effectively
    use all available data to improve model performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of how to implement semi-weak supervision for the loan prediction
    dataset using Snorkel and Python. We first import the necessary libraries and
    functions from those libraries. We then load the dataset using pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s define a function to preprocess the dataset. We will use similar preprocessing
    methods to the ones discussed earlier in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Now we create three labeling functions for `ApplicantIncome` and `LoanAmount`.
    The `lf1(x)` function takes a data instance `x` as input and performs a labeling
    operation based on the value of the `ApplicantIncome` feature. If the `ApplicantIncome`
    is less than 5,000, the function returns a label of `0`. Otherwise, if the `ApplicantIncome`
    is greater than or equal to 5,000, the function returns a label of `1`. Essentially,
    this function assigns a label of `0` to instances with low applicant income and
    a label of `1` to instances with higher applicant income.
  prefs: []
  type: TYPE_NORMAL
- en: The `lf2(x)` function also takes a data instance `x` as input and assigns a
    label based on the value of the `LoanAmount` feature. If the `LoanAmount` is greater
    than 200, the function returns a label of `0`. Conversely, if the `LoanAmount`
    is less than or equal to 200, the function returns a label of `1`. This function
    categorizes instances with large loan amounts as label `0` and instances with
    smaller loan amounts as label `1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Utilizing the `lf3(x)` function, we compute the ratio between the loan amount
    and the applicant’s income. This ratio serves as a crucial metric in determining
    the feasibility of the loan. Based on this calculated ratio, we categorize the
    data points into different labels. If the loan-to-income ratio falls below or
    equals 0.3, we assign a label of `1`, indicating approval of the loan request.
    In cases where the ratio exceeds 0.3 but remains less than or equal to 0.5, we
    designate the data point with a label of `0`, signifying uncertainty regarding
    loan approval. Conversely, if the ratio surpasses 0.5, we assign the label `-1`,
    indicating denial of the loan application. This approach enables us to incorporate
    the affordability aspect into our labeling process, enhancing the granularity
    of our weak supervision approach for loan approval prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We then apply the preprocessing techniques to the input data (`df`). The `preprocess_data`
    function is used to perform the necessary preprocessing steps. The resulting preprocessed
    data is stored in the variable `X`. Additionally, the target variable, `Loan_Status`,
    is transformed from categorical values (`N` and `Y`) to numerical values (`0`
    and `1`) and stored in the variable `y`. This step ensures that the data is ready
    for training and evaluation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step involves splitting the preprocessed data into training and testing
    sets. The `train_test_split` function from the scikit-learn library is used for
    this purpose. The data is divided into `X_train` and `X_test` for the features
    and `y_train` and `y_test` for the corresponding labels. This separation allows
    for training the model on the training set and evaluating its performance on the
    test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we apply the two labeling functions, `lf1` and `lf2`, to the training set
    (`X_train`) using the `PandasLFApplier` class. The resulting weakly labeled data
    is stored in `L_train_weak`. The LFs analyze the features of each instance and
    assign labels based on predefined rules or conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The label model is instantiated using the `LabelModel` class. It is configured
    with a cardinality of `2` (indicating binary classification) and set to run in
    verbose mode for progress updates. The label model is then trained on the training
    data (`L_train_weak`) using the `fit` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the label model is trained, it is evaluated on the test set (`X_test`)
    to assess its performance. The applier object is used again to apply the labeling
    functions to the test set, resulting in `L_test`, which contains the weakly labeled
    instances. The score method of the label model is then used to calculate the accuracy
    of the label predictions compared to the ground truth labels (`y_test`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the upcoming section, we explore slicing functions for labeling—an advanced
    technique that allows us to finely segment our data. These functions provide a
    tailored approach, enabling us to apply specific labeling strategies to distinct
    subsets of our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Slicing functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Slicing functions are functions that operate on data instances and produce binary
    labels based on specific conditions. Unlike traditional labeling functions that
    provide labels for the entire dataset, slicing functions are designed to focus
    on specific subsets of the data. These subsets, or slices, can be defined based
    on various features, patterns, or characteristics of the data. Slicing functions
    offer a fine-grained approach to labeling, enabling more targeted and precise
    labeling of data instances.
  prefs: []
  type: TYPE_NORMAL
- en: Slicing functions play a crucial role in weak supervision approaches, where
    multiple labeling sources are leveraged to assign approximate labels. Slicing
    functions complement other labeling techniques, such as rule-based systems or
    crowdsourcing, by capturing specific patterns or subsets of the data that may
    be challenging to label accurately using other methods. By applying slicing functions
    to the data, practitioners can exploit domain knowledge or specific data characteristics
    to improve the labeling process.
  prefs: []
  type: TYPE_NORMAL
- en: To fully understand the concept of slicing functions, let’s use an example of
    a dataset containing reviews for a range of products from an e-commerce website.
    Our goal is to label these reviews as either positive or negative.
  prefs: []
  type: TYPE_NORMAL
- en: 'For simplicity, let’s consider two slicing functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Slicing Function 1** (**SF1**): This function targets reviews that contain
    the word “refund”. It labels a review as negative if it includes the word “refund”
    and leaves it unlabeled otherwise. The intuition behind this slicing function
    is that customers asking for a refund are likely dissatisfied with their purchase,
    hence the negative sentiment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Slicing Function 2** (**SF2**): This function targets reviews from customers
    who purchased electronics. It labels a review as positive if it includes words
    such as “great”, “excellent”, or “love” and labels it as negative if it includes
    words such as “broken”, “defective”, or “useless”. It leaves the review unlabeled
    if it doesn’t meet any of these conditions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You will notice that these slicing functions operate on specific subsets of
    the data and enable us to incorporate domain knowledge into the labeling process.
    Therefore, designing effective slicing functions requires a combination of domain
    knowledge, feature engineering, and experimentation. Here are some key considerations
    for designing and implementing slicing functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identify relevant slices**: Determine the specific subsets or slices of the
    data that are relevant to the labeling task. This involves understanding the problem
    domain, analyzing the data, and identifying distinct patterns or characteristics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Define slicing conditions**: Specify the conditions or rules that capture
    the desired subsets of the data. These conditions can be based on feature thresholds,
    pattern matching, statistical properties, or any other relevant criteria.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evaluate and iterate**: Assess the performance of the slicing functions by
    comparing the assigned labels to ground truth labels or existing labeling sources.
    Iterate on the design of the slicing functions, refining the conditions and rules
    to improve the quality of the assigned labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Slicing functions offer several benefits in the labeling process:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fine-grained labeling**: Slicing functions allow for targeted labeling of
    specific subsets of the data, providing more detailed and granular labels that
    capture distinct patterns or characteristics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain knowledge incorporation**: Slicing functions enable the incorporation
    of domain expertise and specific domain knowledge into the labeling process. This
    allows for more informed and context-aware labeling decisions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complementarity with other techniques**: Slicing functions complement other
    labeling techniques by capturing slices of the data that may be challenging to
    label using traditional methods. They provide an additional source of weak supervision
    that enhances the overall labeling process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability and efficiency**: Slicing functions can be automated and applied
    programmatically, allowing for scalable and efficient labeling of large datasets.
    This reduces the dependency on manual annotation and enables the labeling of data
    at a larger scale.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s understand how we can implement slicing functions in Python using the
    loan prediction dataset. We first import the required libraries and load the dataset
    into a pandas DataFrame. We will use the same preprocessing step discussed in
    the previous sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'To create slicing functions, we utilize the `@labeling_function` decorator
    provided by Snorkel. These functions encapsulate the labeling logic based on specific
    conditions or rules. For example, we can define slicing functions based on the
    `ApplicantIncome`, `LoanAmount`, or `Self_Employed` features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'To apply the slicing functions to the training data, we use the `PandasLFApplier`
    class provided by Snorkel. This class takes the slicing functions as input and
    applies them to the training dataset, generating weak labels. The resulting weak
    labels will be used to train the label model later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the weak labels from the slicing functions, we can train a label
    model using the `LabelModel` class from Snorkel. The label model learns the correlation
    between the weak labels and the true labels and estimates the posterior probabilities
    for each data instance. In this step, we create a `LabelModel` object, specify
    the cardinality of the labels (e.g., binary classification), and fit it to the
    weakly labeled training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'After training the label model, we want to evaluate its performance on the
    test data. We use the `PandasLFApplier` to apply the slicing functions to the
    test dataset, obtaining the weak labels. Then, we calculate the accuracy of the
    label model’s predictions compared to the true labels of the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Snorkel provides the `LFAnalysis` module, which allows us to analyze the performance
    and characteristics of the labeling functions. We can compute various metrics
    such as coverage, conflicts, and accuracy for each labeling function to gain insights
    into their effectiveness and potential issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following summary table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Summary table showing statistics for each labeling function
    (LF)](img/B19297_06_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – Summary table showing statistics for each labeling function (LF)
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll explore active learning for labeling—a clever strategy
    that involves picking the right data to label, making our model smarter with each
    iteration.
  prefs: []
  type: TYPE_NORMAL
- en: Active learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore the concept of active learning and its application
    in data labeling. Active learning is a powerful technique that allows us to label
    data more efficiently by actively selecting the most informative samples for annotation.
    By strategically choosing which samples to label, we can achieve higher accuracy
    with a smaller dataset, all else being equal. On the following pages, we will
    discuss various active learning strategies and implement them using Python code
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: Active learning is a semi-supervised learning approach that involves iteratively
    selecting a subset of data points for manual annotation based on their informativeness.
    The key idea is to actively query the labels of the most uncertain or informative
    instances to improve the learning process. This iterative process of selecting
    and labeling samples can significantly reduce the amount of labeled data required
    to achieve the desired level of performance.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with a simple example of active learning to help you get the basic
    idea before going into detail on specific active learning strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we are building a machine learning model to classify emails into spam
    and not spam. We have a large dataset of unlabeled emails, but manually labeling
    all of them would be very time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is where active learning comes in:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Initial training**: We start by randomly selecting a small subset of emails
    and manually labeling them as spam or not spam. We then train our model on this
    small labeled dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Uncertainty sampling**: After training, we use the model to make predictions
    on the rest of the unlabeled emails. However, instead of labeling all the emails,
    we choose the ones where the model is most uncertain about its predictions. For
    example, if our model outputs a probability close to 0.5 (i.e., it’s unsure whether
    the email is spam or not), these emails are considered ‘informative’ or ‘uncertain’.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Label query**: We then manually label these uncertain emails, adding them
    to our training set.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Iterative learning**: *Step 2* and *step 3* are repeated in several iterations—
    retraining the model with the newly labeled data, using it to predict labels for
    the remaining unlabeled data, and choosing the most uncertain instances to label
    next.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This way, active learning allows us to strategically select the most informative
    examples to label, thereby potentially improving the model’s performance with
    fewer labeled instances.
  prefs: []
  type: TYPE_NORMAL
- en: There are several active learning strategies that can be employed based on different
    criteria for selecting informative samples. Let’s discuss a few commonly used
    strategies and their Python implementations.
  prefs: []
  type: TYPE_NORMAL
- en: Uncertainty sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Uncertainty sampling is based on the assumption that instances on which a model
    is uncertain are more informative and beneficial to label. The idea is to select
    instances that are close to the decision boundary or have conflicting predictions.
    By actively acquiring labels for these challenging instances, the model can refine
    its understanding of the data and improve its performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several common approaches to uncertainty sampling in active learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Least confidence**: This method selects instances for which the model has
    the lowest confidence in its predictions. It focuses on instances where the predicted
    class probability is closest to 0.5, indicating uncertainty. For instance, in
    our email example, if the model predicts a 0.52 probability of a particular email
    being spam and a 0.48 probability of it not being spam, this indicates that the
    model is uncertain about its prediction. This email would be a prime candidate
    for labeling under the least confidence method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Margin sampling**: Margin sampling aims to find instances where the model’s
    top two predicted class probabilities are close. It selects instances with the
    smallest difference between the highest and second-highest probabilities, as these
    are likely to be near the decision boundary. Let’s say we have a model that classifies
    images of animals. If it predicts an image with probabilities of 0.4 for cat,
    0.38 for dog, and 0.22 for bird, the small difference (0.02) between the top two
    probabilities suggests uncertainty. This image would be chosen for labeling in
    margin sampling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Entropy**: Entropy-based sampling considers the entropy of the predicted
    class probabilities. It selects instances with high entropy, indicating a high
    level of uncertainty in the model’s predictions. Using the same animal classification
    model, if an image gets equal 0.33 probabilities for each class (cat, dog, bird),
    it shows high uncertainty. This image would be selected for labeling by the entropy
    method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s implement uncertainty sampling in Python. For this example, we go back
    to the `credit-g` dataset introduced at the beginning of this chapter. Let’s have
    a look at the features in this dataset to refresh your memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – The features of the credit-g dataset](img/B19297_06_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – The features of the credit-g dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the assumption that the dataset has already been loaded into a `df` DataFrame,
    we start by preprocessing the dataset by standardizing the numerical features
    and one-hot encoding categorical features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'With our new `df_preprocessed` DataFrame in hand, we can perform uncertainty
    sampling. We start by importing the necessary libraries and modules, including
    pandas, NumPy and scikit-learn, for data manipulation and machine learning operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We split the `df_preprocessed` dataset into a small labeled dataset and the
    remaining unlabeled data. In this example, we randomly select a small portion
    of 10% as labeled data and leave the rest as unlabeled data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: We define the uncertainty sampling functions—`least_confidence`, `margin_sampling`,
    and `entropy_sampling`—as discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an explanation of each of these functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`least_confidence`: This function takes in a 2D array of probabilities with
    each row representing an instance and each column representing a class. For each
    instance, it calculates the confidence as 1 – `max_probability`, where `max_probability`
    is the largest predicted probability across all classes. It then sorts the instances
    by confidence in ascending order. The idea is that instances with lower confidence
    (i.e., higher uncertainty) are more informative and should be labeled first:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`margin_sampling`: This function also takes in a 2D array of probabilities.
    For each instance, it calculates the margin as the difference between the highest
    and second-highest predicted probabilities. It then sorts the instances by margin
    in ascending order. The idea is that instances with smaller margins (i.e., closer
    top-two class probabilities) are more informative and should be labeled first:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`entropy_sampling`: This function calculates the entropy of the predicted probabilities
    for each instance. Entropy is a measure of uncertainty or disorder, with higher
    values indicating greater uncertainty. It then sorts the instances by entropy
    in ascending order. The idea is that instances with higher entropy (i.e., more
    uncertainty in the class probabilities) are more informative and should be labeled
    first:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We enter the active learning loop, where we iteratively train a model, select
    instances for labeling using uncertainty sampling, obtain labels for those instances,
    and update the labeled dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, a list named `accuracies` is used to keep track of the accuracy of
    the model on the labeled data at each iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The active learning loop is then implemented over a specified number of iterations.
    In each iteration, a logistic regression model is trained on the labeled data,
    and its accuracy is calculated and stored. The model then makes predictions on
    the unlabeled data, and the instances about which it is least confident (as determined
    by the `least_confidence` function) are added to the labeled dataset. These instances
    are removed from the unlabeled dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The final output is an updated labeled dataset containing additional instances
    labeled during each iteration of active learning. The process aims to improve
    model performance by iteratively selecting and labeling the most informative instances
    from the unlabeled data. In the preceding code, the success and effectiveness
    of active learning depend on the `least_confidence` custom function and the characteristics
    of the dataset. The `least_confidence` function is assumed to return indices corresponding
    to the least confident predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this code uses the `least_confidence` function to perform active learning.
    To perform the same process using `margin_sampling` or `entropy_sampling` instead
    of `least_confidence`, you could replace `least_confidence(probabilities)[:batch_size]`
    with `margin_sampling(probabilities)[:batch_size]` or `entropy_sampling(probabilities)[:batch_size]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s compare the performance of each of the three active learning functions
    on the same sample from `credit-g`. We use matplotlib to produce visual representations
    of the accuracy for each of the three active learning functions. To replicate
    the output, apply the following code to the outputs of each function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The *least confidence* method achieved a model accuracy of 0.878 after five
    iterations, with the best performance observed after the first iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Accuracy of the least_confidence active learning function over
    five iterations when predicting the target variable on the credit-g dataset](img/B19297_06_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Accuracy of the least_confidence active learning function over
    five iterations when predicting the target variable on the credit-g dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Margin sampling achieved a slightly higher accuracy of 0.9 after two and three
    iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Accuracy of the margin_sampling active learning function over
    five iterations when predicting the target variable on the credit-g dataset](img/B19297_06_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – Accuracy of the margin_sampling active learning function over five
    iterations when predicting the target variable on the credit-g dataset
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, entropy sampling and least confidence achieved identical results. How
    come?
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Accuracy of the entropy_sampling active learning function over
    five iterations when predicting the target variable on the credit-g dataset](img/B19297_06_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – Accuracy of the entropy_sampling active learning function over
    five iterations when predicting the target variable on the credit-g dataset
  prefs: []
  type: TYPE_NORMAL
- en: These two methods may yield the same results in certain scenarios, especially
    when working with binary classification problems. Here’s why.
  prefs: []
  type: TYPE_NORMAL
- en: The least confidence method considers the class with the highest predicted probability.
    If the model is very confident about a particular class (i.e., the probability
    is close to 1), then it’s less likely that this instance will be selected for
    labeling.
  prefs: []
  type: TYPE_NORMAL
- en: Entropy sampling considers the entropy or “disorder” of the predicted probabilities.
    For binary classification problems, entropy is maximized when the probabilities
    are both equal (i.e., the model is completely unsure which class to predict).
    This could coincide with low-confidence predictions.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, both methods will often select the same instances for labeling
    in the context of binary classification. However, this might not always be the
    case, especially for multi-class problems.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, margin sampling focuses on the difference between the highest
    and second-highest predicted probabilities. Even slight differences in these probabilities
    can lead to different instances being selected compared to the other methods.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll explore **Query by Committee** (**QBC**) for labeling—a
    method that brings together a group of models to help decide which data points
    are most important for labeling.
  prefs: []
  type: TYPE_NORMAL
- en: Query by Committee (QBC)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: QBC is based on the idea that instances for which the committee of models disagrees
    or exhibits high uncertainty are the most informative and should be prioritized
    for labeling. Instead of relying on a single model’s prediction, QBC takes advantage
    of the diversity and collective decision-making of the committee to make informed
    labeling decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The QBC process typically involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Committee creation**: Create an initial committee of multiple models trained
    on the available labeled data. Models in a committee can be diverse in terms of
    their architectures, initializations, or training methodologies.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Instance selection**: Apply the committee of models to the unlabeled instances
    and obtain predictions. Choose the instances that elicit the most disagreement
    or uncertainty among the committee members for labeling.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Committee update**: Label the selected instances and add them to the labeled
    dataset. Re-train or update the committee of models using the expanded labeled
    dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Repeat**: Iterate the process by returning to *step 2* until a desired performance
    level is achieved or labeling resources are exhausted.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'QBC offers several advantages in active learning for labeling:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model diversity**: QBC utilizes a committee of models, allowing for diverse
    perspectives and capturing different aspects of the data distribution. This diversity
    helps identify instances that are challenging or ambiguous, leading to improved
    labeling decisions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model confidence estimation**: By observing the disagreement or uncertainty
    among the committee members, QBC provides an estimate of the models’ confidence
    in their predictions. Instances that lead to disagreement or uncertainty can be
    considered more informative and valuable for labeling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Labeling efficiency**: QBC aims to prioritize instances that have the greatest
    impact on the committee’s decision. This approach can save labeling efforts by
    focusing on instances that provide the most relevant information to improve the
    model’s performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s implement this approach using the `credit-g` dataset in Python. First,
    we define functions for creating the committee, obtaining committee predictions,
    and measuring disagreement or uncertainty among the committee members.
  prefs: []
  type: TYPE_NORMAL
- en: The `create_committee(num_models)` function creates a committee of logistic
    regression models. The number of models in the committee is specified by `num_models`.
  prefs: []
  type: TYPE_NORMAL
- en: The `get_committee_predictions(committee, data)` function gets predictions from
    each model in the committee for the provided data. It returns an array of prediction
    probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `measure_disagreement(predictions)` function measures the disagreement
    among the committee’s predictions. It calculates the variance of the predictions
    and returns the mean disagreement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We enter the active learning loop, where we iteratively train the committee,
    measure disagreement or uncertainty, select instances for labeling, obtain labels
    for those instances, and update the labeled dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Here’s an explanation of the code. `labeled_dataset = labeled_data.copy()` creates
    a copy of the initial labeled dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The loop over `num_iterations` represents the number of rounds of semi-supervised
    learning. In each round, the following steps occur:'
  prefs: []
  type: TYPE_NORMAL
- en: Each model in the committee is trained on the current labeled dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The committee makes predictions on the unlabeled data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The disagreement among the committee’s predictions is calculated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The indices of the instances with the highest disagreement are identified. The
    size of this batch is specified by `batch_size`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These instances are added to the labeled dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, these instances are removed from the unlabeled data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The idea behind this approach is that the instances the models disagree about
    the most are the ones where the models are most uncertain. By adding these instances
    to the labeled dataset, the models can learn more from them in the next round
    of training. This process continues for a specified number of iterations.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s discuss diversity sampling in labeling—a smart technique that focuses
    on selecting a varied set of data points to ensure a well-rounded and representative
    labeled dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Diversity sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Diversity sampling is based on the principle that selecting instances that cover
    diverse patterns or regions in the dataset can provide a more comprehensive understanding
    of the underlying data distribution. By actively seeking diverse instances for
    labeling, diversity sampling aims to improve model generalization and robustness.
  prefs: []
  type: TYPE_NORMAL
- en: 'The diversity sampling process typically involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Initial model training**: Train an initial machine learning model using a
    small, labeled dataset. This model will be used to guide the selection of diverse
    instances for labeling.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Instance selection**: Apply the trained model to the unlabeled instances
    and obtain predictions. Calculate a diversity metric to measure the dissimilarity
    or coverage of each instance with respect to the already labeled instances. Select
    instances with the highest diversity metric for labeling.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Labeling and model update**: Label the selected instances and add them to
    the labeled dataset. Retrain or update the machine learning model using the expanded
    labeled dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Repeat**: Iterate the process by returning to *step 2* until a desired performance
    level is achieved or labeling resources are exhausted.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Diversity sampling offers several advantages in active learning for labeling:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Comprehensive data coverage**: By selecting diverse instances, diversity
    sampling ensures that the labeled dataset covers a wide range of patterns or regions
    in the data. This approach helps the model generalize better to unseen instances
    and improves its ability to handle different scenarios.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exploration of data distribution**: Diversity sampling encourages the exploration
    of the underlying data distribution by actively seeking instances from different
    parts of the feature space. This exploration can reveal important insights about
    the data and improve the model’s understanding of complex relationships.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mitigation of bias and overfitting**: Diversity sampling can help mitigate
    biases and overfitting that may arise from selecting only easy or similar instances
    for labeling. By diversifying the labeled dataset, diversity sampling reduces
    the risk of model overconfidence and enhances its robustness.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s explore this approach on our preprocessed `credit-g` dataset, using pairwise
    distances from the `sklearn` library in Python. The `pairwise_distances` function
    from `sklearn` calculates the distance between each pair of instances in a dataset.
    In the context of diversity sampling, this function is used to find instances
    that are most different from each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the process:'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the pairwise distances between all pairs of instances in the unlabeled
    dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify the instances that have the greatest distances between them. These
    are the most diverse instances according to the distance metric used.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select these diverse instances for labeling and add them to the labeled dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The idea is that by actively seeking out diverse instances (those that are farthest
    apart in terms of the chosen distance metric), you can cover a wider range of
    patterns in the underlying data distribution. This helps to improve the model’s
    ability to generalize to new data and enhances its robustness.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the `pairwise_distances` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We define functions for calculating diversity and selecting instances with
    the highest diversity for labeling. We will use pairwise Euclidean distance as
    the diversity metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We enter the active learning loop, where we iteratively calculate diversity,
    select diverse instances for labeling, obtain labels for those instances, and
    update the labeled dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we’ll explore transfer learning in labeling—an advanced
    method that leverages knowledge gained from one task to improve performance on
    a different but related task.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Transfer learning involves using knowledge gained from a source task or domain
    to aid learning. Instead of starting from scratch, transfer learning leverages
    pre-existing information, such as labeled data or pre-trained models, to bootstrap
    the learning process and improve the performance of the target task. Transfer
    learning offers several advantages in the labeling process of machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reduced labeling effort**: By leveraging pre-existing labeled data, transfer
    learning reduces the need for the manual labeling of a large amount of data for
    the target task. It enables the reuse of knowledge from related tasks, domains,
    or datasets, saving time and effort in acquiring new labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved model performance**: Transfer learning allows the target model to
    benefit from the knowledge learned by a source model. The source model might have
    been trained on a large, labeled dataset or a different but related task, providing
    valuable insights and patterns that can enhance the target model’s performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adaptability to limited labeled data**: Transfer learning is particularly
    useful when the target task has limited labeled data. By leveraging labeled data
    from a source task or domain, transfer learning can help generalize the target
    model better and mitigate the risk of overfitting on a small, labeled dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Transfer learning can be applied in various ways for labeling in machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature extraction**: Utilize pre-trained models as feature extractors. Extract
    high-level features from pre-trained models and feed them as inputs to a new model
    that is trained on the target labeled dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fine-tuning pre-trained models**: Use pre-trained models that have been trained
    on large, labeled datasets, such as models from popular deep learning architectures
    such as VGG, ResNet, or BERT. Fine-tune these pre-trained models on a smaller
    labeled dataset specific to the target task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s discuss these in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Feature extraction involves using the representations learned by a pre-trained
    model as input features for a new model. This approach is particularly useful
    when the pre-trained model has been trained on a large, general-purpose dataset
    such as ImageNet. Here’s an example of using transfer learning for image labeling
    using the VGG16 model.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The data used in this example is available from [https://github.com/odegeasslbc/FastGAN-pytorch](https://github.com/odegeasslbc/FastGAN-pytorch).
  prefs: []
  type: TYPE_NORMAL
- en: 'We first import the necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use an image of a Golden Retriever for labeling. We can view this image
    using the `PIL` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'This will display the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.11 – The Golden Retriever: man’s best friend and our sample image](img/B19297_06_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.11 – The Golden Retriever: man’s best friend and our sample image'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s load the pre-trained VGG16 model from the TensorFlow library and predict
    the label for this sample image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12 – The VGG16 model’s prediction with confidence levels; the model
    has labeled the image as golden_retriever with a high level of confidence](img/B19297_06_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 – The VGG16 model’s prediction with confidence levels; the model
    has labeled the image as golden_retriever with a high level of confidence
  prefs: []
  type: TYPE_NORMAL
- en: The model has correctly predicted the image as `golden_retriever` with `0.92119014`
    confidence. We now understand how a pre-trained model can be used on a new dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning pre-trained models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fine-tuning in transfer learning refers to the process of adapting or updating
    the pre-trained model’s parameters to better fit a specific task or dataset of
    interest. When using transfer learning, the pre-trained model is initially trained
    on a large-scale dataset, typically from a different but related task or domain.
    Fine-tuning allows us to take advantage of the knowledge learned by the pre-trained
    model and customize it for a specific task or dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fine-tuning process typically involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-trained model initialization**: The pre-trained model, which has already
    learned useful representations from a source task or dataset, is loaded. The model’s
    parameters are frozen initially, meaning they are not updated during the initial
    training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Modification of the model**: Depending on the specific task or dataset, the
    last few layers or specific parts of the pre-trained model may be modified or
    replaced. The architecture of the model can be adjusted to match the desired output
    or accommodate the characteristics of the target task.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Unfreezing and training**: After modifying the model, the previously frozen
    parameters are unfrozen, allowing them to be updated during training. The model
    is then trained on the target task-specific dataset, often referred to as the
    fine-tuning dataset. The weights of the model are updated using backpropagation
    and gradient-based optimization algorithms to minimize the task-specific loss
    function.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Training with a lower learning rate**: During fine-tuning, a smaller learning
    rate is typically used compared to the initial training of the pre-trained model.
    This smaller learning rate helps to ensure that the previously learned representations
    are preserved to some extent while allowing the model to adapt to the target task
    or dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The process of fine-tuning strikes a balance between utilizing the knowledge
    captured by the pre-trained model and tailoring it to the specifics of the target
    task. By fine-tuning, the model can learn task-specific patterns and optimize
    its performance for the new task or dataset. The amount of fine-tuning required
    may vary depending on the similarity between the source and target tasks or domains.
    In some cases, only a few training iterations may be sufficient, while in others,
    more extensive training may be necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fine-tuning is a crucial step in transfer learning, as it enables the transfer
    of knowledge from a source task or dataset to a target task, resulting in improved
    performance and faster convergence on the target task. Here’s an example of using
    transfer learning for image labeling using the VGG16 model. We first import the
    necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'We have two classes of images – that of dogs and cats – and therefore we set
    the number of classes variable to `2`. We will also load a pre-trained VGG16 model
    without the top layers. The image sizes we have here are 256 x 256 x 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'We now freeze the pre-trained layers and create a new model for fine-tuning.
    We then compile the model using `''adam''` as the optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'To prepare for training, we are configuring data generators for both training
    and validation datasets. This crucial step involves rescaling pixel values to
    a range between 0 and 1 using `ImageDataGenerator`. By doing so, we ensure consistent
    and efficient processing of image data, enhancing the model’s ability to learn
    patterns and features during training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now fine-tune the model and save it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: With this saved model, we can deploy it for various applications, such as making
    predictions on new data, integrating it into larger systems, or further fine-tuning
    similar tasks. The saved model file encapsulates the learned patterns and features
    from the training process, providing a valuable resource for future use and analysis.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll delve into the concept of semi-supervised learning
    in labeling—a sophisticated yet approachable technique that combines the strengths
    of both labeled and unlabeled data.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditional supervised learning relies on a fully labeled dataset, which can
    be time-consuming and costly to obtain. Semi-supervised learning, on the other
    hand, allows us to leverage both labeled and unlabeled data to train models and
    make predictions. This approach offers a more efficient way to label data and
    improve model performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Semi-supervised learning is particularly useful when labeled data is scarce
    or expensive to obtain. It allows us to make use of the vast amounts of readily
    available unlabeled data, which is often abundant in real-world scenarios. By
    leveraging unlabeled data, semi-supervised learning offers several benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cost-effectiveness**: Semi-supervised learning reduces the reliance on expensive
    manual labeling efforts. By using unlabeled data, which can be collected at a
    lower cost, we can significantly reduce the expenses associated with acquiring
    labeled data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Utilization of large unlabeled datasets**: Unlabeled data is often abundant
    and easily accessible. Semi-supervised learning enables us to tap into this vast
    resource, allowing us to train models on much larger datasets compared to fully
    supervised learning. This can lead to better model generalization and performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved model performance**: By incorporating unlabeled data during training,
    semi-supervised learning can improve model performance. The unlabeled data provides
    additional information and helps the model capture the underlying data distribution
    more accurately. This can lead to better generalization and increased accuracy
    on unseen data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are different approaches within semi-supervised learning that leverage
    the unlabeled data in different ways. Some common methods include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Self-training**: Self-training involves training a model initially on the
    limited labeled data. Then, the model is used to make predictions on the unlabeled
    data, and the confident predictions are considered as pseudo-labels for the unlabeled
    instances. These pseudo-labeled instances are then combined with the labeled data
    to retrain the model iteratively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Co-training**: Co-training involves training multiple models on different
    subsets or views of the data. Each model learns from the labeled data and then
    predicts labels for the unlabeled data. The agreement or disagreement between
    the models’ predictions on the unlabeled data is used to select the most confident
    instances, which are then labeled and added to the training set for further iterations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generative models**: Generative models, such as **variational autoencoders**
    (**VAEs**) or **generative adversarial networks** (**GANs**), can be used in semi-supervised
    learning. These models learn the underlying data distribution and generate plausible
    instances. By incorporating the generated instances into the training process,
    the model can capture more diverse representations and improve its generalization
    performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s see a simple implementation in Python of this labeling approach. First,
    we import the necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We utilize the preprocessed `credit-g` dataset from previous examples and split
    it into labeled and unlabeled subsets. This example assumes that you are using
    the `df_preprocessed` DataFrame we created in the *Uncertainty* *sampling* section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we train a supervised machine learning model using the labeled data. In
    this example, we will use logistic regression as the supervised model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We then apply the trained supervised model to predict labels for the unlabeled
    data. The predicted labels are considered as pseudo-labels for the unlabeled instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Now concatenate the labeled data (`X_labeled`) with the pseudo-labeled data
    (`X_unlabeled`) to create the combined feature dataset (`X_combined`). Concatenate
    the corresponding labels (`y_labeled` and `pseudo_labels`) to create the combined
    label dataset (`y_combined`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, train a semi-supervised machine learning model using the combined feature
    dataset (`X_combined`) and label dataset (`y_combined`). In this example, we will
    use `LabelPropagation` as the semi-supervised model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the trained semi-supervised model to make predictions on the test set and
    calculate the accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The print statement outputs the resulting accuracy score, which, in this case,
    is 0.635.
  prefs: []
  type: TYPE_NORMAL
- en: After training our `semi_supervised_model` using `LabelPropagation`, the resulting
    model has effectively learned from both labeled and unlabeled data. The predictions
    on the test set (`y_pred`) showcase the model’s ability to generalize and infer
    labels for previously unseen instances. This output serves as a valuable demonstration
    of how semi-supervised learning techniques, leveraging both labeled and unlabeled
    data, can contribute to robust and accurate predictions in real-world scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored various programmatic labeling techniques in machine
    learning. Labeling data is essential for training effective models, and manual
    labeling can be time-consuming and expensive. Programmatic labeling offers automated
    ways to assign meaningful categories or classes to instances of data. We discussed
    a range of techniques, including pattern matching, DB lookup, Boolean flags, weak
    supervision, semi-weak supervision, slicing functions, active learning, transfer
    learning, and semi-supervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: Each technique offers unique benefits and considerations based on the nature
    of the data and the specific labeling requirements. By leveraging these techniques,
    practitioners can streamline the labeling process, reduce manual effort, and train
    effective models using large amounts of labeled or weakly labeled data. Understanding
    and utilizing programmatic labeling techniques are crucial for building robust
    and scalable machine learning systems.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll explore the role of synthetic data in data-centric
    machine learning.
  prefs: []
  type: TYPE_NORMAL
