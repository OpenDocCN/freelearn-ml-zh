<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Building Personalized Recommendation Engines" id="aid-1CQAE1"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Building Personalized Recommendation Engines</h1></div></div></div><p>Recommendation engines have been evolving very fast, with a lot of research also going into this field. Big multinational companies are investing huge amounts of money into this field. As mentioned earlier, right from the earlier models of recommendation engines such as collaborative filtering, these systems have been a huge success. With more and more revenues being generated through recommendation engines and more and more people using the Internet for their shopping needs, reading news, or for getting information related to health, business organizations have seen huge business in tapping this available user activities on the Internet. With the increase in the number of users of recommendation engines, and with more and more applications being powered by recommendation engines, users also started asking for personalized suggestions rather than community-based recommendations. This requirement of the user community was taken as the new challenge, and personalized recommendation engines have been built for providing suggestions at a personal level.</p><p>Almost all the industry domains are currently building recommendation engines that can recommend at personalized levels.</p><p>The following are a few personalized recommendations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Personalized news recommendations--Google News</li><li class="listitem">Personalized health-care systems</li><li class="listitem">Personalized travel recommendation systems</li><li class="listitem">Personalized recommendations on Amazon</li><li class="listitem">Personalized movie recommendations on YouTube</li></ul></div><p>The following is the screenshot of personalized recommendations:</p><div class="mediaobject"><img src="../Images/image00351.jpeg" alt="Building Personalized Recommendation Engines"/></div><p style="clear:both; height: 1em;"> </p><p>In the <a class="link" title="Chapter 3. Recommendation Engines Explained" href="part0022.xhtml#aid-KVCC1">Chapter 3</a>, <span class="emphasis"><em>Recommendation Engines Explained</em></span>, we learned in detail about content-based recommender systems and context-aware recommender systems. In this chapter, we will recall these topics in brief and then move ahead to build content-based and context-aware recommender systems.</p><div class="section" title="Personalized recommender systems"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec40"/>Personalized recommender systems</h1></div></div></div><p>In this chapter, we will learn about two flavours of personalized recommenders:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Content-based recommender systems</li><li class="listitem">Context-aware recommender systems</li></ul></div></div></div>
<div class="section" title="Content-based recommender systems"><div class="titlepage" id="aid-1DOR02"><div><div><h1 class="title"><a id="ch06lvl1sec41"/>Content-based recommender systems</h1></div></div></div><p>Building collaborative filtering is relatively easy. In the fifth chapter, we learned about building collaborative filtering recommender systems. While building those systems, we just considered the ratings given to a product and the information about whether a product is liked or not. With this minimal information, we built the systems. To many people's surprise, these systems performed very well. But these systems had their own limitations, such as the cold start problem explained in the previous chapters.</p><p>Assume a case of a user, Nick, giving five-star rating to a movie, say <span class="emphasis"><em>Titanic.</em></span> What could have made Nick give that rating? May be the story of the film, the actors in the movie, the background score, or the screenplay. These preferences for these features made Nick rate the movie. Wouldn't including this internal information of preferences for the product/features make more sense while building recommendations?</p><p>In collaborative filtering, the basic assumption is that people with similar taste in the past will have similar taste in the future. If we closely observe, this assumption may not apply in all cases. For example, if my neighbors have rated the thriller movie <span class="emphasis"><em>The Exorcist highly</em></span>, that movie should not be suggested to me since I have a preference for romantic movies. I should instead get <span class="emphasis"><em>Titanic,</em></span> which is of the romance genre, as a suggestion. I do not always have the same taste as my neighbors; I would be happy if I got suggestions solely based on my preferences and actions. Businesses have seen a lot of business opportunities in implementing these types of recommendations, known as personalized recommender systems, at an individual level.</p><div class="section" title="Building a content-based recommendation system"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec75"/>Building a content-based recommendation system</h2></div></div></div><p>In content-based recommender systems, we use the content information of both users and items while building recommendation engines. A typical content-based recommender system will perform the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Generate user profiles.</li><li class="listitem">Generate item profile.</li><li class="listitem">Generate the recommendation engine model.</li><li class="listitem">Suggest the top N recommendations.</li></ol><div style="height:10px; width: 1px"/></div><p>We first generate user and item profiles from the available information. A profile typically contains preferences for the features of items and users (refer to <a class="link" title="Chapter 3. Recommendation Engines Explained" href="part0022.xhtml#aid-KVCC1">Chapter 3</a>, <span class="emphasis"><em>Recommendation Engines Explained</em></span> for details). Once the profiles are created, we choose a method to build the recommendation engine model. Many data-mining techniques such as classification, text similarity approaches such as <span class="emphasis"><em>tf-idf</em></span> similarity, and Matrix factorization models can be applied for building content-based recommendation engines.</p><p>We can even employ multiple recommendation engine models and build hybrid recommendation engines to serve as content-based recommendations. A typical content recommender is depicted in the following figure:</p><div class="mediaobject"><img src="../Images/image00352.jpeg" alt="Building a content-based recommendation system"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Content-based recommendation using R"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec76"/>Content-based recommendation using R</h2></div></div></div><p>Let's start building a personalized recommendation engine in R. We choose the MovieLens dataset to build our system. In the previous section, we refreshed the concepts of content-based recommender systems. There are multiple ways we can build personalized recommenders; in this section, we will use the multiclass classification approach to build our basic content-based recommendation engine.</p><p>Using the classification approach, we are trying to build a model-based recommendation engine. Most recommender systems--either collaborative filtering or content-based--use neighbourhood methods to build the recommenders. Let's explore how we can use a supervised machine-learning approach to build the recommendation engines.</p><p>Before we start writing the code, let's discuss the steps for building the personalized recommender system. The following figure shows the order of steps we would be following to achieve our objective:</p><div class="mediaobject"><img src="../Images/image00353.jpeg" alt="Content-based recommendation using R"/></div><p style="clear:both; height: 1em;"> </p><p>The first step would always be to gather the data and pull it into the programming environment so that we may apply further steps. For our use case, we download the MovieLens dataset containing three sets of data, as defined next:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Ratings data containing userID, itemID, rating, timestamp</li><li class="listitem">User data containing the user information, such as userID, age, gender, occupation, ZIP code, and so on</li><li class="listitem">Movie data containing a certain movie's information, such as movieID, release date, URL, genre details, and so on</li></ul></div><p>The second step would be preparing the data required to build the classification models. In this step, we extract the required features of the users and class labels to build the classification model:</p><div class="mediaobject"><img src="../Images/image00354.jpeg" alt="Content-based recommendation using R"/></div><p style="clear:both; height: 1em;"> </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">For our example case, we define the ratings (1 to 5) given by the users as class labels, such as 1-3 rating as 0 and 4-5 rating as 1. Thus, we will build a two-class classification model. Our model will predict the class label, given the input features for a given user.<div class="note" title="Note"><h3 class="title"><a id="tip15"/>Tip</h3><p>You might be wondering why we are choosing binary classification instead of multiclass classification. The choice of model is left to the person building the recommender system; in our case, with the dataset we have chosen, binary class classification fits better than a multiclass classification. Readers are encouraged to try multiclass-classification for your understanding.</p></div></li><li class="listitem">We choose user demography and item features from user data and item data to form the features of our binary classification model. We extended the <code class="literal">User_item_rating</code> data by including features such as genre information for the movie rated by the user, user personal information such as age, gender, occupation, and so on. The final features and class labels can be seen in the preceding figure.</li></ul></div><p>The third step will be to build the binary classification model. We will choose the RandomForest algorithm to build the class.</p><p>The fourth and final step will be to generate the top-N recommendations for the users. For our example, we take a test user and predict the class labels for the movie that he has not rated earlier and send the top-N movies, which have higher probability ratings predicted by our classification model.</p><p>Please note that the choice of generating the top-N recommendations are left to the choice of the users.</p><p>Let's implement the aforementioned steps using R. In this section, we will go through a step-by-step implementation of content-based recommendation using R.</p><div class="section" title="Dataset description"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec13"/>Dataset description</h3></div></div></div><p>For this exercise, we use two MovieLens dataset files--one is a ratings file containing ratings given to 943 to 1682 movies on a scale of 1-5, and the second is an item dataset file containing content information, that is, information about the movie genre, movie name, movie ID, URLs, and so on.</p><div class="note" title="Note"><h3 class="title"><a id="tip16"/>Tip</h3><p>The MovieLens dataset can be downloaded from following URL:<a class="ulink" href="http://grouplens.org/datasets/movielens/">http://grouplens.org/datasets/movielens/</a></p></div><p>Loading ratings data into R environment using <code class="literal">read.csv()</code> function available in R:</p><pre class="programlisting">raw_data = read.csv("~/udata.csv",sep="\t",header=F) &#13;
Adding column names to the dataframe &#13;
colnames(raw_data) = c("UserId","MovieId","Rating","TimeStamp") &#13;
</pre><p>This code removes the last column from the DataFrame:</p><pre class="programlisting">ratings = raw_data[,1:3] &#13;
</pre><p>See the first five lines of the data, we use <code class="literal">head()</code> function as follows:</p><pre class="programlisting">head(ratings) &#13;
</pre><p>See the columns of the rating data frame using <code class="literal">names()</code> function.</p><p>See the descriptions of the ratings function using <code class="literal">str()</code> function. All the results of the three mentioned functions are shown as follows:</p><div class="mediaobject"><img src="../Images/image00355.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>The following code loads item data into the R environment using the <code class="literal">read.csv()</code> function available in R:</p><pre class="programlisting">movies = read.csv("C:/Suresh/R&amp;D/packtPublications/reco_engines/drafts/personalRecos/uitem.csv",sep="|",header=F) &#13;
</pre><p>Next, we add columns to the data frame:</p><pre class="programlisting">colnames(movies) = c("MovieId","MovieTitle","ReleaseDate","VideoReleaseDate","IMDbURL","Unknown","Action","Adventure","Animation","Children","Comedy","Crime","Documentary","Drama","Fantasy","FilmNoir","Horror","Musical","Mystery","Romance","SciFi","Thriller","War","Western") &#13;
</pre><p>Then we remove unwanted data; for this exercise we are keeping only the genre information only:</p><pre class="programlisting">movies = movies[,-c(2:5)] &#13;
View(movies) &#13;
</pre><div class="mediaobject"><img src="../Images/image00356.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>The description of movies is given by <code class="literal">str(movies)</code>.The column names can be seen using <code class="literal">names(movies)</code>:</p><div class="mediaobject"><img src="../Images/image00357.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>The next step is to create feature profiles of customers to build a classification model. We should extend the rating data frame containing userID, movieID, and rating with the movie properties, as shown next.</p><p>In the following code, we use <code class="literal">merge()</code> to perform a join function to merge ratings data with item data:</p><pre class="programlisting">ratings = merge(x = ratings, y = movies, by = "MovieId", all.x = TRUE) &#13;
 &#13;
View(ratings) &#13;
</pre><div class="mediaobject"><img src="../Images/image00358.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>Let's see the columns names using <code class="literal">names()</code> method:</p><div class="mediaobject"><img src="../Images/image00359.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>Now we create the class labels for each record of the profile we just created. We shall create a binary class label for each of the ratings so that 1-3 ratings will be labelled as 0 and 4-5 ratings as 1. The following code does this conversion for us. We use the <code class="literal">lapply()</code> function to reshape the ratings:</p><p>The following code manages the conversion of numerical ratings to binary categorical variable:</p><pre class="programlisting">nrat = unlist(lapply(ratings$Rating,function(x) &#13;
{ &#13;
  if(x&gt;3) {return(1)} &#13;
  else {return(0)} &#13;
})) &#13;
</pre><p>Next, we combine the newly created rating categorical rating variable - <code class="literal">nrat</code> - with the original rating data frame ratings using <code class="literal">cbind()</code>:</p><pre class="programlisting">ratings = cbind(ratings,nrat) &#13;
</pre><div class="mediaobject"><img src="../Images/image00360.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>In the preceding figure, we can observe the new rating binary class, <code class="literal">nrat</code>.</p><p>Now let's observe the variables that will be going into the model building stage using the <code class="literal">apply()</code> function by applying <code class="literal">table()</code> to each column, as shown next:</p><pre class="programlisting">apply(ratings[,-c(1:3,23)],2,function(x)table(x)) &#13;
</pre><div class="mediaobject"><img src="../Images/image00361.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>From the preceding results, we can observe that the number of zeroes is very high when compared to the number of 1s; so let's remove this variable from our feature list. Also, let's remove the rating variable, as we have created a new variable <code class="literal">nrat</code>:</p><pre class="programlisting">scaled_ratings = ratings[,-c(3,4)] &#13;
</pre><p>We shall now standardize or center the data by using the <code class="literal">scale()</code> function available in R before we build the model as shown in the following code snippet. Standardizing will adjust data in different scales to common a scale. The scale function will apply centering by removing column means on the each of corresponding column:</p><pre class="programlisting">scaled_ratings=scale(scaled_ratings[,-c(1,2,21)]) &#13;
scaled_ratings = cbind(scaled_ratings,ratings[,c(1,2,23)]) &#13;
</pre><div class="mediaobject"><img src="../Images/image00362.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>Now let's get into building the model using the <code class="literal">randomForest</code> algorithm for binary classification. Before that, let's divide the data into training and test sets with an 80:20 split.</p><p>The following code will first create a randomize index object of all the data. Then we use this indexes to divide the train and test sets.</p><pre class="programlisting">set.seed(7) &#13;
which_train &lt;- sample(x = c(TRUE, FALSE), size = nrow(scaled_ratings), &#13;
                      replace = TRUE, prob = c(0.8, 0.2)) &#13;
model_data_train &lt;- scaled_ratings[which_train, ] &#13;
model_data_test &lt;- scaled_ratings[!which_train, ] &#13;
</pre><div class="mediaobject"><img src="../Images/image00363.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>Now let's build the model using <code class="literal">randomForest</code> algorithm from the library <code class="literal">randomForest</code>:</p><div class="note" title="Note"><h3 class="title"><a id="note17"/>Note</h3><p>In the following code snippet, we are converting the integer <code class="literal">nrat</code> variable to factor format.</p></div><pre class="programlisting">library(randomForest) &#13;
fit = randomForest(as.factor(nrat)~., data = model_data_train[,-c(19,20)]) &#13;
</pre><p>We can see the details of the model build, fit, by just typing, <code class="literal">fit</code>:</p><div class="mediaobject"><img src="../Images/image00364.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>In the previous code snippet we have used the <code class="literal">randomforest()</code> method with default values. For random forests we have two parameters which can be tuned for optimal performance; <span class="strong"><strong>mtry</strong></span> is number of samples at each tree split, <span class="strong"><strong>ntree</strong></span> is number of decision trees to be grown. Using parameter tuning and cross-validation approaches, we should choose optimal parameters.</p><p>We can also see the summary of the model using <code class="literal">summary()</code>, as shown next:</p><div class="mediaobject"><img src="../Images/image00365.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>Now, let's see how the model performs on the test set:</p><pre class="programlisting">predictions &lt;- predict(fit, model_data_test[,-c(19,20,21)], type="class") &#13;
</pre><div class="mediaobject"><img src="../Images/image00366.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>Let's evaluate the model using the Precision-Recall method:</p><pre class="programlisting">#building confusion matrix &#13;
cm = table(predictions,model_data_test$nrat) &#13;
(accuracy &lt;- sum(diag(cm)) / sum(cm)) &#13;
(precision &lt;- diag(cm) / rowSums(cm)) &#13;
recall &lt;- (diag(cm) / colSums(cm)) &#13;
</pre><div class="mediaobject"><img src="../Images/image00367.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>With the preceding results, we are quite happy with a 60% precision rate and a 75% recall rate. Now we move ahead to generate the top-N recommendations to a user ID (943) by performing the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a DataFrame containing all the movies not rated by the active user (user id: 943 in our case).<pre class="programlisting">        #extract distinct movieids &#13;
        totalMovieIds = unique(movies$MovieId) &#13;
        #see the sample movieids using tail() and head() functions: &#13;
</pre><div class="mediaobject"><img src="../Images/image00368.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><pre class="programlisting">        #a function to generate dataframe which creates non-rated &#13;
          movies by active user and set rating to 0; &#13;
        nonratedmoviedf = function(userid){ &#13;
          ratedmovies = raw_data[raw_data$UserId==userid,]$MovieId &#13;
          non_ratedmovies = totalMovieIds[!totalMovieIds %in%  &#13;
            ratedmovies] &#13;
           df = data.frame(cbind(rep(userid),non_ratedmovies,0)) &#13;
           names(df) = c("UserId","MovieId","Rating") &#13;
           return(df) &#13;
        } &#13;
 &#13;
        #let's extract non-rated movies for active userid 943 &#13;
        activeusernonratedmoviedf = nonratedmoviedf(943) &#13;
</pre><div class="mediaobject"><img src="../Images/image00369.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">Build a profile for this active user DataFrame:<pre class="programlisting">        activeuserratings = merge(x = activeusernonratedmoviedf, y = &#13;
          movies, by = "MovieId", all.x = TRUE) &#13;
</pre><div class="mediaobject"><img src="../Images/image00370.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">Predict ratings, sort and generate 10 recommendations:<pre class="programlisting">        #use predict() method to generate predictions for movie ratings &#13;
          by the active user profile created in the previous step. &#13;
        predictions &lt;- predict(fit, activeuserratings[,-c(1:4)],  &#13;
          type="class") &#13;
        #creating a dataframe from the results &#13;
        recommend = data.frame(movieId = &#13;
          activeuserratings$MovieId,predictions) &#13;
        #remove all the movies which the model has predicted as 0 and  &#13;
          then we can use the remaining items as more probable movies   &#13;
            which might be liked by the active user. &#13;
        recommend = recommend[which(recommend$predictions == 1),] &#13;
</pre></li></ol><div style="height:10px; width: 1px"/></div><p>With this step, we have when extending or improving finished building the content-based recommendation engine using a classification model. Before we move into the next section, I would like to make a clear point that the choice of the model and class label features is up to the reader to extend or improve the model.</p><p>As mentioned earlier, we should use cross-validation approach to choose optimal parameters so as to improve the model accuracy.</p></div></div><div class="section" title="Content-based recommendation using Python"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec77"/>Content-based recommendation using Python</h2></div></div></div><p>In the previous section, we built a model-based content recommendation engine using R. In this section, we will build content recommendations using another approach, using the Python <code class="literal">sklearn</code>, <code class="literal">NumPy</code>, and <code class="literal">pandas</code> packages.</p><p>Let's recall the steps for building a content-based system discussed in the beginning of the chapter:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Item profile generation</li><li class="listitem">User profile generation</li><li class="listitem">Recommendation engine model generation</li><li class="listitem">Generation of the top-N recommendations</li></ol><div style="height:10px; width: 1px"/></div><p>In this section, we shall learn in detail how to build content following the aforementioned steps using Python:</p><p>The design of the approach is shown in the following figure:</p><div class="mediaobject"><img src="../Images/image00371.jpeg" alt="Content-based recommendation using Python"/></div><p style="clear:both; height: 1em;"> </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Item profile creation</strong></span>: In this step, we create a profile for each item using the content information we have about the items. The item profile is usually created using a widely-used information retrieval technique called tf-idf. In <a class="link" title="Chapter 4. Data Mining Techniques Used in Recommendation Engines" href="part0029.xhtml#aid-RL0A2">Chapter 4</a>, <span class="emphasis"><em>Data Mining Techniques for Recommendation Engines</em></span>, we explained <span class="emphasis"><em>tf-idf</em></span> in detail. To recap, the tf-idf value gives the relative importance of features with respect to all the items or documents.</li><li class="listitem"><span class="strong"><strong>User profile creation</strong></span>: In this step, we take the user activity dataset and preprocess the data into a proper format to create a user profile. We should remember that, in a content-based recommender system, the user profile is created with respect to the item content, that is, we have to extract or compute the preferences of the user for the item content or item features. Usually, a dot product between user activity and item profile gives us the user profile.</li><li class="listitem"><span class="strong"><strong>Recommendation engine model generation</strong></span>: Now that we have the user profile and item profile in hand, we will proceed to build a recommendation model. Computing a cosine similarity between the user profile and item profile gives us the affinity of the user to each of the items.</li><li class="listitem"><span class="strong"><strong>Generation of the top-N recommendations</strong></span>: In the final step, we shall sort the user-item preferences based on the values calculated in the previous step and then suggest the top-N recommendations.</li></ul></div><p>Now we will proceed toward the implementation of the aforementioned steps in Python.</p><div class="section" title="Dataset description"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec14"/>Dataset description</h3></div></div></div><p>In this section, we will use the Anonymous Microsoft Web Dataset to build a content-based recommendation system. The objective of this section is to recommend websites to an active user, based on his previous web browsing history.</p><p>MS Web Dataset refers to the web logs of the website <a class="ulink" href="http://www.microsoft.com">www.microsoft.com</a> accessed by 38,000 anonymous users. For each of the users, the dataset consists of lists about data of all the websites visited by the users in a time frame of one week.</p><p>The dataset can be downloaded from the following URL:</p><p><a class="ulink" href="https://archive.ics.uci.edu/ml/datasets/Anonymous+Microsoft+Web+Data">https://archive.ics.uci.edu/ml/datasets/Anonymous+Microsoft+Web+Data</a></p><p>For the sake of simplicity, from now on, we will refer to the website areas with the term <span class="emphasis"><em>items.</em></span> There are 5,000 users, and they are represented by sequential numbers between 10,001 and 15,000. Items are represented by numbers between 1,000 and 1,297, even if they are less than 298.</p><p>The dataset is an unstructured text file. Each record contains several fields between two and six. The first field is a letter defining what the record contains. There are three main types of records, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Attribute (A)</strong></span>: This is the description of the website area</li><li class="listitem"><span class="strong"><strong>Case (C)</strong></span>: This is the case for each user, containing its ID</li><li class="listitem"><span class="strong"><strong>Vote (V)</strong></span>: This is the vote lines for the case</li></ul></div><p>The first column case record is followed by the userID/caseID. The third column contains the user ID/vote given to the website area. The fourth column contains the description of the website area, and the fifth column consists of the URL of the website area.</p><p>The following image shows a small set of original data:</p><div class="mediaobject"><img src="../Images/image00372.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>Our target is to suggest that each user explores some areas of the website that they haven't explored yet.</p><p>The following is the list of packages we will be using for this exercise:</p><pre class="programlisting">import pandas as pd &#13;
import numpy as np &#13;
import scipy &#13;
import sklearn &#13;
</pre><p>Loading the data:</p><pre class="programlisting">path = "~/anonymous-msweb.test.txt" &#13;
import pandas as pd &#13;
</pre><p>Use <code class="literal">read.csv()</code> function available in pandas package to read the data:</p><pre class="programlisting">raw_data = pd.read_csv(path,header=None,skiprows=7) &#13;
raw_data.head() &#13;
</pre><div class="mediaobject"><img src="../Images/image00373.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>Let's see more sample data to have a much clearer idea:</p><div class="mediaobject"><img src="../Images/image00374.jpeg" alt="Dataset description"/></div><p style="clear:both; height: 1em;"> </p><p>We can observe the following from the preceding figure:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The first column contains three types of values: <span class="strong"><strong>A</strong></span>/<span class="strong"><strong>V</strong></span>/<span class="strong"><strong>C</strong></span>, where A represents case ID, <span class="strong"><strong>V</strong></span> represents the user, and <span class="strong"><strong>C</strong></span> represents the case IDs that the user has accessed</li><li class="listitem">The second column contains IDs to represent users and items</li><li class="listitem">The third column contains the description of website area</li><li class="listitem">The fourth contains the URL for the website area on the website</li></ul></div><p>To make an item profile, we use the rows containing <span class="strong"><strong>A</strong></span> in the first column, and to create a user activity or dataset, we use the rows which don't contain <span class="strong"><strong>A</strong></span> in the first column.</p><p>Let's get started with profile generation.</p><p>Before we proceed toward profile generation, we will have to format the user activity data; the following section explains how to create a user activity dataset.</p></div><div class="section" title="User activity"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec15"/>User activity</h3></div></div></div><p>In this section, we will create a user-item rating matrix containing users as rows, items as columns, and the value as the cells. Here, the value is either <code class="literal">0</code> or <code class="literal">1</code>, indicating <code class="literal">1</code> if the user has accessed the web page, else <code class="literal">0</code>:</p><p>First we filter only records that don't contain <code class="literal">"A"</code> in the first column:</p><pre class="programlisting">user_activity = raw_data.loc[raw_data[0] != "A"] &#13;
</pre><p>Next, we assign then we remove unwanted columns from the dataset:</p><pre class="programlisting">user_activity = user_activity.loc[:, :1] &#13;
</pre><p>Assigning names to the columns of <code class="literal">user_activity</code> DataFrame:</p><pre class="programlisting">user_activity.columns = ['category','value'] &#13;
</pre><p>The following code shows the sample <code class="literal">user_activity</code> data:</p><div class="mediaobject"><img src="../Images/image00375.jpeg" alt="User activity"/></div><p style="clear:both; height: 1em;"> </p><p>To get the total unique <code class="literal">webid</code> in the dataset, see as the following code:</p><pre class="programlisting">len(user_activity.loc[user_activity['category'] =="V"].value.unique()) &#13;
Out[73]: 236 &#13;
</pre><p>To get the unique users count, see following code:</p><pre class="programlisting">len(user_activity.loc[user_activity['category'] =="C"].value.unique()) &#13;
Out[74]: 5000 &#13;
</pre><p>Now let's run the following code to create a user-item-rating matrix, as follows:</p><p>First, we assign variables:</p><pre class="programlisting">tmp = 0 &#13;
nextrow = False &#13;
</pre><p>Then we get the last index of the dataset:</p><pre class="programlisting">lastindex = user_activity.index[len(user_activity)-1] &#13;
lastindex &#13;
Out[77]: 20484 &#13;
</pre><p>The for loop code loops through each record and adds new columns(<code class="literal">'userid'</code>, <code class="literal">'webid'</code>) to <code class="literal">user_activity</code> data frame which shows <code class="literal">userid</code> and corresponding web activity:</p><pre class="programlisting">for index,row in user_activity.iterrows(): &#13;
    if(index &lt;= lastindex ): &#13;
        if(user_activity.loc[index,'category'] == "C"): &#13;
            tmp = 0            &#13;
            userid = user_activity.loc[index,'value'] &#13;
            user_activity.loc[index,'userid'] = userid &#13;
            user_activity.loc[index,'webid'] = userid &#13;
            tmp = userid &#13;
            nextrow = True             &#13;
        elif(user_activity.loc[index,'category'] != "C" and nextrow == True): &#13;
                webid = user_activity.loc[index,'value'] &#13;
                user_activity.loc[index,'webid'] = webid &#13;
                user_activity.loc[index,'userid'] = tmp &#13;
                if(index != lastindex and user_activity.loc[index+1,'category'] == "C"): &#13;
                    nextrow = False &#13;
                    caseid = 0 &#13;
                    &#13;
</pre><div class="mediaobject"><img src="../Images/image00376.jpeg" alt="User activity"/></div><p style="clear:both; height: 1em;"> </p><p>Next, we remove the unwanted rows from the preceding data frame, that is, we will be removing the rows containing <code class="literal">"C"</code> in the category column:</p><pre class="programlisting">user_activity = user_activity[user_activity['category'] == "V" ] &#13;
</pre><div class="mediaobject"><img src="../Images/image00377.jpeg" alt="User activity"/></div><p style="clear:both; height: 1em;"> </p><p>We subset the columns, and remove the first two columns, which we no longer needed:</p><pre class="programlisting">user_activity = user_activity[['userid','webid']] &#13;
</pre><p>Next, we sort the data by <code class="literal">webid</code>; this is to make sure that the rating matrix generation is in good format:</p><pre class="programlisting">user_activity_sort = user_activity.sort('webid', ascending=True) &#13;
</pre><p>Now, let's create a dense binary rating matrix containing user_item_rating using the following code:</p><p>First, we get the size of <code class="literal">webid</code> column:</p><pre class="programlisting">sLength = len(user_activity_sort['webid']) &#13;
</pre><p>Then we add a new column, <code class="literal">'rating'</code> to the <code class="literal">user_activity</code> data frame which contains only 1:</p><pre class="programlisting">user_activity_sort['rating'] = pd.Series(np.ones((sLength,)), index=user_activity.index) &#13;
</pre><p>Next, we use pivot to create binary rating matrix:</p><pre class="programlisting">ratmat = user_activity_sort.pivot(index='userid', columns='webid', values='rating').fillna(0) &#13;
</pre><p>Finally, we create a dense matrix:</p><pre class="programlisting">ratmat = ratmat.to_dense().as_matrix() &#13;
</pre></div><div class="section" title="Item profile generation"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec16"/>Item profile generation</h3></div></div></div><p>In this section, we will be creating an item profile from the initial raw data (<code class="literal">raw_data</code>). To create item data, we will consider the data that contains <code class="literal">A</code> in the first column:</p><p>First, we filter all the records containing first column as <code class="literal">"A"</code></p><pre class="programlisting">items = raw_data.loc[raw_data[0] == "A"] &#13;
</pre><p>Then we name the columns as follows:</p><pre class="programlisting">items.columns = ['record','webid','vote','desc','url'] &#13;
</pre><p>To generate <code class="literal">item</code> profile we only needed two columns so we slice the dataframe as follows:</p><pre class="programlisting">items = items[['webid','desc']] &#13;
</pre><p>To see the dimensions of the items, the dataframe is given like:</p><pre class="programlisting">items.shape &#13;
Out[12]: (294, 2) &#13;
</pre><p>We observe that there are <code class="literal">294</code> unique <code class="literal">webid</code> in the dataset:</p><p>To check the sample of the data, we use the following code:</p><pre class="programlisting">Items.head() &#13;
</pre><div class="mediaobject"><img src="../Images/image00378.jpeg" alt="Item profile generation"/></div><p style="clear:both; height: 1em;"> </p><p>To check the count of unique <code class="literal">webid</code>, we use the following code:</p><pre class="programlisting">items['webid'].unique().shape[0] &#13;
Out[117]: 294 &#13;
</pre><p>We can also only those <code class="literal">webid</code> which are present in the <code class="literal">user_activity</code> data:</p><pre class="programlisting">items2 = items[items['webid'].isin(user_activity['webid'].tolist())] &#13;
</pre><p>We can use the following code check type of the object</p><pre class="programlisting">type(items2) &#13;
Out[123]: pandas.core.frame.DataFrame &#13;
</pre><p>We can also sort the data by <code class="literal">webid</code>:</p><pre class="programlisting">items_sort = items2.sort('webid', ascending=True) &#13;
</pre><p>Let'see what we have done till now, using the <code class="literal">head(5)</code> function:</p><div class="mediaobject"><img src="../Images/image00379.jpeg" alt="Item profile generation"/></div><p style="clear:both; height: 1em;"> </p><p>Now, we shall create the item profile using the <code class="literal">tf-idf</code> functions available in the sklearn package. To generate <code class="literal">tf-idf</code>, we use the <code class="literal">TfidfVectorizer()</code>. The <code class="literal">fit_transform()</code> methods are in the <code class="literal">sklearn</code> package. The following code shows how we can create <code class="literal">tf-idf</code>.</p><p>In the following code, the choice of the number of features to be included depends on the dataset, and the optimal number of features can be selected by the cross-validation approach:</p><pre class="programlisting">from sklearn.feature_extraction.text import TfidfVectorizer &#13;
v = TfidfVectorizer(stop_words ="english",max_features = 100,ngram_range= (0,3),sublinear_tf =True) &#13;
x = v.fit_transform(items_sort['desc']) &#13;
itemprof = x.todense() &#13;
</pre><div class="mediaobject"><img src="../Images/image00380.jpeg" alt="Item profile generation"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="User profile creation"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec17"/>User profile creation</h3></div></div></div><p>We now have item profile and user activity in hand; the dot product between these two matrices will create a new matrix with dimensions equal to <code class="literal">#</code> of users by <code class="literal">#</code> Item features.</p><p>To compute the dot product between user activity and item profile, we use the <code class="literal">scipy</code> package methods such as <code class="literal">linalg</code>, dot available.</p><p>Run the following code to compute the dot product:</p><pre class="programlisting">#user profile creation &#13;
from scipy import linalg, dot &#13;
userprof = dot(ratmat,itemprof)/linalg.norm(ratmat)/linalg.norm(itemprof) &#13;
 &#13;
userprof &#13;
</pre><div class="mediaobject"><img src="../Images/image00381.jpeg" alt="User profile creation"/></div><p style="clear:both; height: 1em;"> </p><p>The final step in a recommendation engine model would be to compute the active user preferences for the items. For this, we do a cosine similarity between user profile and item profile.</p><p>To compute the cosine calculations, we will be using the <code class="literal">sklearn</code> package. The following code will calculate the <code class="literal">cosine_similarity</code>:</p><p>We calculate the cosine similarity between <code class="literal">userprofile</code> an item profile:</p><pre class="programlisting">import sklearn.metrics &#13;
similarityCalc = sklearn.metrics.pairwise.cosine_similarity(userprof, itemprof, dense_output=True) &#13;
</pre><p>We can see the results of the preceding calculation as follows:</p><div class="mediaobject"><img src="../Images/image00382.jpeg" alt="User profile creation"/></div><p style="clear:both; height: 1em;"> </p><p>Now, let's format the preceding results calculated as binary data <code class="literal">(0,1)</code>, as follows:</p><p>First, we convert the rating to binary format:</p><pre class="programlisting">final_pred= np.where(similarityCalc&gt;0.6, 1, 0) &#13;
</pre><p>Then we examine the final predictions of first three users:</p><div class="mediaobject"><img src="../Images/image00383.jpeg" alt="User profile creation"/></div><p style="clear:both; height: 1em;"> </p><p>Removing the zero values from the preceding results gives us the list of the probable items that can be recommended to the users:</p><p>For user <code class="literal">213</code> the recommended items are generated as follows:</p><pre class="programlisting">indexes_of_user = np.where(final_pred[213] == 1) &#13;
</pre><p>In the preceding code, we are generating recommendations for the active user <code class="literal">213</code>:</p><div class="mediaobject"><img src="../Images/image00384.jpeg" alt="User profile creation"/></div><p style="clear:both; height: 1em;"> </p></div></div></div>
<div class="section" title="Context-aware recommender systems"><div class="titlepage" id="aid-1ENBI2"><div><div><h1 class="title"><a id="ch06lvl1sec42"/>Context-aware recommender systems</h1></div></div></div><p>The next type of personalized recommender system that we will be learning here is context-aware recommender system. These recommender systems are next generation recommendations systems, which fall into the hyper-personalization category. It's natural that there won't be an end to the needs of humans. The more we get, the more we want. Though content-based recommender systems are efficient, targeted at an individual level, and consider the user's personal preferences alone while building recommendation engines, people wanted recommendation engines to be more personalized. For example, a person going on a trip alone may need a book to read whereas the same person may need beer if he is travelling with friends. Similarly, the same person might require diapers, medicines, snacks, and so on if he is going with his own family. People at different places at different times with different company have different needs. Our recommender systems should be robust enough to handle such scenarios. Such hyper personalized recommender systems, which cater to different recommendations to the same person based on his current context, are known as context-aware recommender systems.</p><div class="section" title="Building a context-aware recommender systems"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec78"/>Building a context-aware recommender systems</h2></div></div></div><p>Building a context-aware recommender system is more like extending a content recommender system. Building a context-aware system typically involves adding the context dimension on top of content recommenders, as shown in the following figure:</p><div class="mediaobject"><img src="../Images/image00385.jpeg" alt="Building a context-aware recommender systems"/></div><p style="clear:both; height: 1em;"> </p><p>In the preceding figure, we can observe that context dimension is added on top of a content-based recommendation engine model, and then recommendations are generated. As we discussed in <a class="link" title="Chapter 3. Recommendation Engines Explained" href="part0022.xhtml#aid-KVCC1">Chapter 3</a>, <span class="emphasis"><em>Recommendation Engines Explained</em></span>, there are two popular types of approaches for building context-aware recommendations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Pre-filtering approaches</li><li class="listitem">Post-filtering approaches</li></ul></div><p>In this section, we will use post-filtering techniques to build context-aware recommender systems.</p></div><div class="section" title="Context-aware recommendations using R"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec79"/>Context-aware recommendations using R</h2></div></div></div><p>In the previous section, we built a content-based recommendation engine. In this section, we will extend the previous model to include context information and generate a context-aware recommendation engine.</p><p>The usual practice of building context-aware systems is to add a time dimension to the content-based recommendations.</p><p>The workflow is shown as follows:</p><div class="mediaobject"><img src="../Images/image00386.jpeg" alt="Context-aware recommendations using R"/></div><p style="clear:both; height: 1em;"> </p><p>Let's try building context aware systems using R. The steps for building context-aware systems in R are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Define context.</li><li class="listitem">Create a context profile with respect to a user for item content.</li><li class="listitem">Generate recommendations for a context.</li></ol><div style="height:10px; width: 1px"/></div><div class="section" title="Defining the context"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec18"/>Defining the context</h3></div></div></div><p>The first step is to define the context that we will be including in our recommendations. In the previous section, we used the MovieLens dataset to build content-based recommendation engines. In the dataset, we have a time component, timestamp, in the rating data. We shall use this variable for our context-aware recommendation systems.</p><p>We will extend the R code we used while building content-based recommendations.</p><p>We load the full MovieLens ratings dataset as follows:</p><pre class="programlisting">raw_data = read.csv("C:/Suresh/R&amp;D/packtPublications/reco_engines/drafts/personalRecos/udata.csv",sep="\t",header=F) &#13;
colnames(raw_data) = c("UserId","MovieId","Rating","TimeStamp") &#13;
</pre><p>See the sample data using <code class="literal">head()</code> function:</p><div class="mediaobject"><img src="../Images/image00387.jpeg" alt="Defining the context"/></div><p style="clear:both; height: 1em;"> </p><p>We load movies dataset:</p><pre class="programlisting">movies = read.csv("C:/Suresh/R&amp;D/packtPublications/reco_engines/drafts/personalRecos/uitem.csv",sep="|",header=F) &#13;
</pre><p>Then we add column names to the movies data frame:</p><pre class="programlisting">colnames(movies) = c("MovieId","MovieTitle","ReleaseDate","VideoReleaseDate","IMDbURL","Unknown","Action","Adventure","Animation","Children","Comedy","Crime","Documentary","Drama","Fantasy","FilmNoir","Horror","Musical","Mystery","Romance","SciFi","Thriller","War","Western") &#13;
</pre><p>Next, we remove unwanted columns from the data frame:</p><pre class="programlisting">movies = movies[,-c(2:5)] &#13;
</pre><div class="mediaobject"><img src="../Images/image00388.jpeg" alt="Defining the context"/></div><p style="clear:both; height: 1em;"> </p><p>We merge the Movies and Ratings datasets using <code class="literal">merge()</code> function</p><pre class="programlisting">ratings_ctx = merge(x = raw_data, y = movies, by = "MovieId", all.x = TRUE) &#13;
</pre><div class="mediaobject"><img src="../Images/image00389.jpeg" alt="Defining the context"/></div><p style="clear:both; height: 1em;"> </p><p>The context that we want to introduce to our previous content-based recommendation is the hour of the day, that is, our recommendations will be made as per the time of the day. The set of recommendations for an active user will be different for each hour of the day. Usually, these changes in recommendations are due to the ordering of the recommendations as per the hour. We will see next how we achieve this.</p></div><div class="section" title="Creating context profile"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec19"/>Creating context profile</h3></div></div></div><p>In the following section, we shall write code to create context profile of the user. We chose the timestamp information available in the dataset and calculate the preference value for movie genres for each user for each hour of the day. This context profile information is used for generating context aware recommendations.</p><p>We extract timestamp from the ratings dataset:</p><pre class="programlisting">ts = ratings_ctx$TimeStamp &#13;
</pre><p>Then, we convert it into a <code class="literal">POSIXlt</code> date object and using hour property to extract hour of the day:</p><pre class="programlisting">hours &lt;- as.POSIXlt(ts,origin="1960-10-01")$hour &#13;
</pre><p>See below for sample data:</p><div class="mediaobject"><img src="../Images/image00390.jpeg" alt="Creating context profile"/></div><p style="clear:both; height: 1em;"> </p><p>We can append the hours back on to the ratings dataset:</p><pre class="programlisting">ratings_ctx = data.frame(cbind(ratings_ctx,hours)) &#13;
</pre><div class="mediaobject"><img src="../Images/image00391.jpeg" alt="Creating context profile"/></div><p style="clear:both; height: 1em;"> </p><p>Now, let's start building a context profile for a user with the user ID 943:</p><p>Extract ratings information for the active user(943) and removing UserId, MovieId, Rating, Timestamp columns, as shown as follow:</p><pre class="programlisting">UCP = ratings_ctx[(ratings_ctx$UserId == 943),][,-c(2,3,4,5)] &#13;
</pre><div class="mediaobject"><img src="../Images/image00392.jpeg" alt="Creating context profile"/></div><p style="clear:both; height: 1em;"> </p><p>As a next step, we compute the columns of all the item features. This columnwise sum is used to compute the preferences for the item features for each hour of the day.</p><p>We compute the column wide sum of each column using <code class="literal">aggregate()</code> function:</p><pre class="programlisting">UCP_pref = aggregate(.~hours,UCP[,-1],sum) &#13;
</pre><div class="mediaobject"><img src="../Images/image00393.jpeg" alt="Creating context profile"/></div><p style="clear:both; height: 1em;"> </p><p>From the preceding figure, we can see the time preferences for each of the movie genres for the active user 943. We can observe that during the ninth hour of the day, the user watches more movies, especially action/drama/comedy movies:</p><p>We can normalize the preceding data between 0-1 using following function:</p><pre class="programlisting">UCP_pref_sc = cbind(context = UCP_pref[,1],t(apply(UCP_pref[,-1], 1, function(x)(x-min(x))/(max(x)-min(x))))) &#13;
</pre><div class="mediaobject"><img src="../Images/image00394.jpeg" alt="Creating context profile"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Generating context-aware recommendations"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec20"/>Generating context-aware recommendations</h3></div></div></div><p>Now that we have created the context profile for the active user, let's start generating context-aware recommendations for the user.</p><p>For this, we shall reuse the recommend object built using R, which contains content recommendations for all the users.</p><p>Let's see the recommendations made to the user 943 using the content-based system:</p><pre class="programlisting">recommend$MovieId &#13;
</pre><div class="mediaobject"><img src="../Images/image00395.jpeg" alt="Generating context-aware recommendations"/></div><p style="clear:both; height: 1em;"> </p><p>Now, to these content recommendations, we add our time or hour of the day dimension and then generate recommendations as per the current context.</p><p>We merge recommendations and movies dataset using <code class="literal">merge()</code> function:</p><pre class="programlisting">UCP_pref_content = merge(x = recommend, y = movies, by = "MovieId", all.x = TRUE) &#13;
</pre><div class="mediaobject"><img src="../Images/image00396.jpeg" alt="Generating context-aware recommendations"/></div><p style="clear:both; height: 1em;"> </p><p>With the preceding step, we have computed all the required matrices, user context profile (<code class="literal">UCP_Pref_SC</code>) and user content recommendations (<code class="literal">UCP_Pref_content</code>).</p><p>Suppose we want to generate recommendations for the user at the ninth hour; we just need to perform an element wise multiplication of user content recommendations and the context row for the ninth hour of the day from the <code class="literal">UCP_pref_SC</code> object. This is given as follows:</p><p>Performing element wise multiplication for the User content recommendations and the ninth hour context preferences for the user:</p><pre class="programlisting">active_user =cbind(UCP_pref_content$MovieId,(as.matrix(UCP_pref_content[,-c(1,2,3)]) %*% as.matrix(UCP_pref_sc[4,2:19]))) &#13;
</pre><p>The results can be seen as follows; we can observe that the preference for MovieId 3 is 0.5 where as for MovieId 4 the preference is 2.8</p><div class="mediaobject"><img src="../Images/image00397.jpeg" alt="Generating context-aware recommendations"/></div><p style="clear:both; height: 1em;"> </p><p>We can create a dataframe object of the prediction object:</p><pre class="programlisting">active_user_df = as.data.frame(active_user) &#13;
</pre><p>Next, we add column names to the predictions object:</p><pre class="programlisting">names(active_user_df) = c('MovieId','SimVal') &#13;
</pre><p>Then we sort the results:</p><pre class="programlisting">FinalPredicitons_943 = active_user_df[order(-active_user_df$SimVal),] &#13;
</pre></div></div></div>
<div class="section" title="Summary" id="aid-1FLS41"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec43"/>Summary</h1></div></div></div><p>In this chapter, we learned how to build content-based recommendation engines and context-aware recommendation engines using R and Python. We modelled content-based recommendation engines in two types--the classification model and the tf-idf model approaches using R and Python. To build context-aware recommendations, we simply did an element wise multiplication between content-based recommendations and context profile of the user.</p><p>In the next chapter, we will be exploring Apache Spark, to build scalable, real-time recommendation engines.</p></div></body></html>