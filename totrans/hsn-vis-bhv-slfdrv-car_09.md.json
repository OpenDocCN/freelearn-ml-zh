["```py\nCarlaUE4 -windowed -ResX=640 -ResY=480\n```", "```py\npython config.py -m=Town01\n```", "```py\npython spawn_npc.py  -w=100 -n=100\n```", "```py\n    python manual_control.py\n    ```", "```py\nhttp://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\n```", "```py\nssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.\n```", "```py\nurl = 'http://download.tensorflow.org/models/object_detection/'\n+ model_name + '.tar.gz'\nmodel_dir = tf.keras.utils.get_file(fname=model_name,\nuntar=True, origin=url)\n\nprint(\"Model path: \", model_dir)\nmodel_dir = pathlib.Path(model_dir) / \"saved_model\"\nmodel = tf.saved_model.load(str(model_dir))\nmodel = model.signatures['serving_default']\n```", "```py\nimg = cv2.imread(file_name)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\ninput_tensor = tf.convert_to_tensor(img)\ninput_tensor = input_tensor[tf.newaxis, ...]\n# Run inference\noutput = model(input_tensor)\n```", "```py\ntf.Tensor([1.], shape=(1,), dtype=float32)\n```", "```py\nnum_detections = int(output.pop('num_detections'))\noutput = {key: value[0, :num_detections].numpy()\n          for key, value in output.items()}\noutput['num_detections'] = num_detections\n```", "```py\noutput['detection_classes'] =    output['detection_classes'].astype(np.int64)\noutput['boxes'] = [\n    {\"y\": int(box[0] * img.shape[0]), \n     \"x\": int(box[1] * img.shape[1]), \n     \"y2\": int(box[2] * img.shape[0]),\n     \"x2\": int(box[3] * img.shape[1])} \n        for box in output['detection_boxes']]\n```", "```py\n{ 'detection_scores': array([0.4976843, 0.44799107, 0.36753723,      0.3548107 ], dtype=float32),    'detection_classes': array([ 8, 10,  6,  3], dtype=int64),  'detection_boxes': array([     [0.46678272, 0.2595877, 0.6488052, 0.40986294],     [0.3679817, 0.76321596, 0.45684734, 0.7875406],     [0.46517858, 0.26020002, 0.6488801, 0.41080648],     [0.46678272, 0.2595877, 0.6488052, 0.40986294]],      dtype=float32),  'num_detections': 4,  'boxes': [{'y': 220, 'x': 164, 'y2': 306, 'x2': 260},            {'y': 174, 'x': 484, 'y2': 216, 'x2': 500},            {'y': 220, 'x': 165, 'y2': 306, 'x2': 260},            {'y': 220, 'x': 164, 'y2': 306, 'x2': 260}]}\n```", "```py\nobj_class = out[\"detection_classes\"][idx]if obj_class == object_detection.LABEL_TRAFFIC_LIGHT:    box = out[\"boxes\"][idx]    traffic_light = img[box[\"y\"]:box[\"y2\"], box[\"x\"]:box[\"x2\"]]\n```", "```py\nMaxPooling2D(pool_size=(3, 3), padding='same', strides=(1, 1))\n```", "```py\nmodel = InceptionV3(weights='imagenet', input_shape=(299,299,3))\n```", "```py\nimg = cv2.resize(preprocess_input(cv2.imread(\"test.jpg\")),\n(299, 299))\nout_inception = model.predict(np.array([img]))\nout_inception = imagenet_utils.decode_predictions(out_inception)\nprint(out_inception[0][0][1], out_inception[0][0][2], \"%\")\n```", "```py\nsea_lion 0.99184495 %\n```", "```py\nbase_model = InceptionV3(include_top=False, input_shape=    (299,299,3))\n```", "```py\ntop_model = Sequential()top_model.add(base_model) # Join the networks\n```", "```py\ntop_model.add(GlobalAveragePooling2D())top_model.add(Dense(1024, activation='relu'))top_model.add(Dropout(0.5))top_model.add(Dense(512, activation='relu'))top_model.add(Dropout(0.5))top_model.add(Dense(n_classes, activation='softmax'))\n```", "```py\nfor layer in base_model.layers:\n    layer.trainable = False\n```", "```py\nTotal params: 21,802,784\nTrainable params: 21,768,352\nNon-trainable params: 34,432\n```", "```py\n____________________________________________________________\nLayer (type)                 Output Shape              Param # \n============================================================\ninception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n____________________________________________________________\nglobal_average_pooling2d_1 ( (None, 2048)              0 \n____________________________________________________________\ndense_1 (Dense)              (None, 1024)              2098176 \n____________________________________________________________\ndropout_1 (Dropout)          (None, 1024)              0 \n____________________________________________________________\ndense_2 (Dense)              (None, 512)               524800    \n____________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0 \n____________________________________________________________\ndense_3 (Dense)              (None, 4)                 2052      \n============================================================\nTotal params: 24,427,812\nTrainable params: 2,625,028\nNon-trainable params: 21,802,784\n____________________________________________________________\n```", "```py\ndatagen = ImageDataGenerator(rotation_range=5, width_shift_\nrange=[-5, -2, -1, 0, 1, 2, 5], horizontal_flip=True,\nheight_shift_range=[-30, -20, -10, -5, -2, 0, 2, 5, 10, 20,\n30])\n```", "```py\nfrom keras.applications.inception_v3 import preprocess_input\nimages = [preprocess_input(img) for img in images]\n```", "```py\nindexes = np.random.permutation(len(images))\n```", "```py\nimages = [images[idx] for idx in indexes]\nlabels = [labels[idx] for idx in indexes]\n```", "```py\nidx_split = int(len(labels_np) * 0.8)\nx_train = images[0:idx_split]\nx_valid = images[idx_split:]\ny_train = labels[0:idx_split]\ny_valid = labels[idx_split:]\n```", "```py\nMin Loss: 0.028652783162121116\nMin Validation Loss: 0.011525456588399612\nMax Accuracy: 1.0\nMax Validation Accuracy: 1.0\n```", "```py\n    datagen = ImageDataGenerator(rotation_range=5, width_\n    shift_range= [-10, -5, -2, 0, 2, 5, 10],\n    zoom_range=[0.7, 1.5],\n    height_shift_range=[-10, -5, -2, 0, 2, 5, 10],\n    horizontal_flip=True)\n    ```", "```py\n    top_model.add(GlobalAveragePooling2D())top_model.add(Dropout(0.5))top_model.add(Dense(1024, activation='relu'))top_model.add(BatchNormalization())top_model.add(Dropout(0.5))top_model.add(Dense(512, activation='relu'))top_model.add(Dropout(0.5))top_model.add(Dense(128, activation='relu'))top_model.add(Dense(n_classes, activation='softmax'))\n    ```", "```py\n    print('Labels:', collections.Counter(labels))\n    ```", "```py\n    Labels: Counter({0: 123, 2: 79, 1: 66, 3: 23})\n    ```", "```py\nn = len(labels)\nclass_weight = {0: n/cnt[0], 1: n/cnt[1], 2: n/cnt[2], 3: n/cnt[3]}\n```", "```py\nClass weight: {0: 2.365, 1: 4.409, 2: 3.683, 3: 12.652}\n```", "```py\nMin Loss: 0.10114006596268155\nMin Validation Loss: 0.012583946840742887\nMax Accuracy: 0.99568963\nMax Validation Accuracy: 1.0\n```", "```py\nimg_traffic_light = img[box[\"y\"]:box[\"y2\"], box[\"x\"]:box[\"x2\"]]img_inception = cv2.resize(img_traffic_light, (299, 299))img_inception = np.array([preprocess_input(img_inception)])prediction = model_traffic_lights.predict(img_inception)label = np.argmax(prediction)\n```"]