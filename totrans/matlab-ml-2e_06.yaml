- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep Learning and Convolutional Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Deep learning** (**DL**) is a **machine learning** (**ML**) technology based
    on multilayer **artificial neural networks** (**ANNs**) that has allowed many
    applications to reach a high degree of accuracy. **Deep NNs** (**DNNs**) are capable
    of modeling and have the ability to capture intricate connections between input
    and output information. Among the highly effective uses, **computer vision** (**CV**)
    stands out, encompassing activities such as categorization, image regression,
    and the identification of objects. As an illustration, an advanced NN can produce
    a stratified portrayal of entities, wherein each entity is recognized by a collection
    of features taking the shape of visual basics, such as specific contours, directed
    lines, surface details, and repetitive designs. **Convolutional** **networks**
    (**CNNs**) are characterized by convolutional layers, which use filters to analyze
    data in a local region and produce an activation map. These activation maps are
    then processed by pooling layers, which aggregate the low-resolution data to reduce
    the dimensionality of the representation and make processing more computationally
    efficient. The convolutional and pooling layers are then alternated several times
    until the image is represented by a low-resolution activation map. In this chapter,
    we will learn the basic concepts of DL and discover how to implement an algorithm
    based on CNNs in the MATLAB environment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding DL basic concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring DL models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaching CNNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a CNN in MATLAB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the model’s results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering DL architectures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As always, I thank the technical reviewers for their helpful advice on improving
    my chapter. I will try to apply them as they were proposed to me.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will introduce ML basic concepts. To understand these topics,
    a basic knowledge of algebra and mathematical modeling is needed. A working knowledge
    of the MATLAB environment is also required.
  prefs: []
  type: TYPE_NORMAL
- en: 'To work with the MATLAB code in this chapter, you need the following files
    (available on GitHub at [https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition](https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition)):'
  prefs: []
  type: TYPE_NORMAL
- en: '`CNNPistachioClassification.m`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PistachioShort.zip`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding DL basic concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**DL** is a branch of ML based on using algorithms to model high-level abstractions
    about data. This discipline is part of a range of approaches that aim to learn
    methods for representing data. For example, an observation such as an image can
    be described in different ways: as a vector of intensity values for each pixel,
    or more abstractly as a set of edges or regions that have shapes or significant
    features. Some of these possible representations may prove more effective than
    others in facilitating the process of training another ML system.'
  prefs: []
  type: TYPE_NORMAL
- en: For automatically identifying and extracting relevant features from raw data,
    we can use automated feature extraction to eliminate the need for manual **feature
    engineering** (**FE**). This process streamlines ML tasks and improves model performance.
  prefs: []
  type: TYPE_NORMAL
- en: Automated feature extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this context, one of the central aspects of DL is the development of learning
    algorithms that specialize in automatically extracting significant features from
    a dataset, which can then be used to train ML systems. This is a significant contribution,
    considering that without such techniques, these features would have to be manually
    generated and vetted prior to training. The basic concept of DL is to successively
    subject the input data to different levels of processing, the result of which
    is the emergence of features. Consider an image of a cat. Automated feature extraction
    can identify features such as the cat’s eyes, ears, and whiskers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the field of NNs, the concept of DL was introduced with the creation of
    so-called **DNNs**. The operating principle is like that of traditional NNs but
    with one obvious difference: the significant increase in the number of intermediate
    layers of hidden neurons. As with classical NNs, DNNs are capable of modeling
    complex relationships between input and output data.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the most successful areas of application is CV, which includes tasks
    such as classification, image regression, and object detection. In the latter
    task, a DNN can build a layered representation of objects, in which each object
    is identified by a set of features that appear in the form of primitive visual
    elements, such as specific edges, oriented lines, textures, and recurring patterns.
    This modeling ability is rooted in a large number of hidden layers of neurons.
  prefs: []
  type: TYPE_NORMAL
- en: Training a DNN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As far as the training phase is concerned, it is still possible to use the
    well-established backpropagation algorithm. As with traditional NNs, DNNs can
    suffer from the age-old problem of overfitting. To mitigate this situation, **regularization
    techniques** are usually employed, which intervene in the optimization process
    during the training phase. Among the most frequently employed methods are the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**L2 regularization** (**weight decay**), which influences the optimizer’s
    operation by adding the **L2 norm** of the network weights, multiplied by a specific
    constant, to the loss function. The L2 norm, also known as the Euclidean norm,
    is a mathematical function that measures the length of a vector. It is defined
    as the square root of the sum of the squares of the vector’s components. The L2
    norm is often used in ML and statistics to measure the distance between two vectors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The formula for the L2 norm of a vector *x* is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '||x||2 = sqrt(∑ (x _ i) ^ 2)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Please refer here as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*||x||_2* is the L2 norm of *x*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x_i* is the i-th component of *x*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L1 regularization** (**sparsity**), functioning similarly to the former but
    using the **L1 norm**. The L1 norm is often used in ML and statistics to measure
    the distance between two vectors. It is also known as the Manhattan norm or the
    Taxicab norm because it corresponds to the distance traveled by a taxicab moving
    along city streets. The formula for the L1 norm of a vector *x* is:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '||x||1 = ∑ |x _ i|'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*||x||_1* is the L1 norm of *x*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x_i* is the i-th component of *x*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dropout**, where, during each training step, a set number of randomly chosen
    neurons within the hidden layers are turned off, preventing their outputs from
    affecting subsequent neurons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these techniques serve to lessen the interdependencies between the network
    and the training data samples, effectively curbing overfitting. Although backpropagation
    training provides a solid solution due to its simplicity and tendency to converge
    toward better local minima compared to other methods, it can pose considerable
    challenges in deep networks concerning actual computation. Indeed, an array of
    **hyperparameters** must be considered in DNNs, encompassing factors such as dimensions
    (in terms of layer count and units per layer), learning rate, initial weights,
    and the optimization of these parameters—a process that can become unwieldy in
    terms of time and computational resources.
  prefs: []
  type: TYPE_NORMAL
- en: Various solutions have been suggested in this context, including the utilization
    of mini-batches of data to expedite training. However, a substantial breakthrough
    has been the advancement of GPUs with increasingly powerful computational capabilities
    in recent years. In network operations, the primary computational tasks involve
    matrix and vector operations, which align well with parallel implementation on
    GPU hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue stemming from gradient descent-based techniques, accentuated by
    the intricate structure of deep networks, is the **vanishing gradient problem**.
    This challenge originates from gradient computation within the chain and the network’s
    substantial number of layers. Typically used activation functions tend to generate
    gradients with minute values, typically within the range of [-1, 1]. Due to the
    chain computation, this results in the multiplication of many small values when
    calculating the gradient in the initial layers of an *n*-level network. Consequently,
    the gradient decreases exponentially with *n*, causing the initial layers to learn
    at a sluggish pace.
  prefs: []
  type: TYPE_NORMAL
- en: Another solution provides the preliminary training in an unsupervised way of
    one level of the network at a time, to then carry out a final complete training
    by means of backpropagation. Another way around the problem, encouraged by the
    development of GPUs in recent times, is the use of faster hardware to counteract
    what is the main symptom of the problem—namely, the slowness of the training process.
    Another point against DNNs, in the case of **supervised learning** (**SL**), is
    represented by the very large amount of sample data (including the desired output)
    necessary for the network to reach the required results at the end of the training.
    This represents a significant obstacle since, for certain tasks, the production
    of the expected outputs for each example is an operation that can take a very
    long time.
  prefs: []
  type: TYPE_NORMAL
- en: After introducing DL, let’s now see the different types of DL available.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring DL models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Various types of DL architectures and techniques have been developed to tackle
    different tasks and challenges. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CNNs**: Mainly used for image and video analysis, CNNs are designed to learn
    spatial hierarchies of features automatically and adaptively from input data.
    They have been highly successful in tasks such as image classification, object
    detection, and image segmentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recurrent NNs** (**RNNs**): RNNs are well suited for tasks involving sequences,
    such as **natural language processing** (**NLP**) and speech recognition. They
    have an internal memory that allows them to maintain information about previous
    inputs, making them effective for handling sequential data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Long short-term memory** (**LSTM**) **networks**: A type of RNN, LSTMs are
    designed to overcome the vanishing gradient problem in training deep networks.
    They are particularly useful for capturing long-range dependencies in sequential
    data, making them popular for tasks such as language modeling and machine translation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generative adversarial networks** (**GANs**): GANs consist of two NNs—the
    generator and the discriminator—engaged in a game-like setting. GANs are used
    for generating new data samples that are like a given dataset. They have been
    used for image generation, style transfer, and data augmentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Autoencoders** (**AEs**): AEs are used for **unsupervised learning** (**UL**)
    and data compression. They consist of an encoder that maps the input data to a
    latent space and a decoder that reconstructs the input from the latent representation.
    AEs find applications in dimensionality reduction, denoising, and anomaly detection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transformer networks**: Transformers have gained popularity in NLP tasks.
    They utilize self-attention mechanisms to process input data in parallel, making
    them efficient for handling long-range dependencies in sequences. The **Bidirectional
    Encoder Representations from Transformers** (**BERT**) model is a prominent example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Capsule networks**: Capsule networks aim to improve the robustness of NNs
    to variations in object poses and viewpoints. They use *capsules* to represent
    different aspects of an object, allowing them to capture hierarchical relationships
    between features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neural Turing machines** (**NTMs**): These architectures combine NNs with
    external memory, enabling them to perform algorithmic tasks. They are designed
    to learn algorithmic procedures and have been used for tasks such as sorting and
    associative recall.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph NNs** (**GNNs**): GNNs operate on graph-structured data, making them
    suitable for tasks such as node classification, link prediction, and graph-level
    classification. They have applications in social network analysis, molecular chemistry,
    and recommendation systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just a few examples of the diverse range of DL architectures and techniques
    available, each tailored to specific tasks and data types. For example, CNNs are
    designed for image and spatial data analysis using convolutional layers to automatically
    learn hierarchical features and patterns from images. Characteristic claims are
    image classification, object detection, and image segmentation. RNNs are suited
    for sequential and temporal data analysis, maintaining the memory of previous
    inputs through recurrent connections and enabling them to capture sequential patterns.
    Typical applications are NLP, speech recognition, and time-series prediction.
    LSTM networks are an improved version of RNNs to address the vanishing gradient
    problem, incorporating memory cells to selectively retain and update information
    over long sequences. Applications of these technologies provide language modeling,
    machine translation, and **sentiment analysis** (**SA**). GANs are used to generate
    new data samples that resemble a given dataset using a generator and a discriminator
    network that compete in a minimax game. This type of DL is particularly suitable
    for image generation, style transfer, and data augmentation. Finally, AEs as UL
    for data compression and feature extraction comprise an encoder to map input data
    to a lower-dimensional latent space and a decoder to reconstruct input data. Dimensionality
    reduction, denoising, and anomaly detection are representative applications for
    these algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The field of DL continues to evolve, with new architectures and approaches emerging
    to address various challenges across different domains.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we can delve into the main technology of DL—namely, CNNs.
  prefs: []
  type: TYPE_NORMAL
- en: Approaching CNNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As outlined in [*Chapter 5*](B21156_05.xhtml#_idTextAnchor105), *Introducing
    Artificial Neural Networks Modeling,* ANNs draw their inspiration from biological
    NNs. These ANNs aim to replicate human cognitive processes by emulating the mechanisms
    observed in natural NNs. They serve the purpose of estimating or approximating
    functions that might rely on numerous inputs, many of which could be unfamiliar.
    ANNs are typically conceptualized as networks of interconnected neurons, facilitating
    the exchange of messages. Each connection possesses an associated weight, the
    value of which can be adjusted through learning from experience. This adaptive
    characteristic empowers NNs to accommodate diverse input types and facilitates
    their capacity to learn (*Figure 6**.1*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – ANN architecture with hidden layers](img/B21156_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – ANN architecture with hidden layers
  prefs: []
  type: TYPE_NORMAL
- en: 'ANNs define a neuron as the **central processing unit** (**CPU**) that executes
    a mathematical operation to produce a single output from a set of input values.
    The neuron’s output is determined by the weighted sum of inputs and an added bias.
    Each neuron undertakes a straightforward task: activation occurs if the cumulative
    signal surpasses a specified activation threshold. The previous diagram illustrates
    a basic ANN structure, which essentially embodies CNNs. Indeed, like the latter,
    CNNs consist of interconnected neurons linked by weighted branches (weights);
    the networks’ training parameters remain the weights and biases.'
  prefs: []
  type: TYPE_NORMAL
- en: Within CNNs, the inter-neuron connectivity pattern takes inspiration from the
    arrangement observed in the animal world’s visual cortex. Neurons within this
    section of the brain (visual cortex) react to specific stimuli within limited
    observation zones referred to as receptive fields. These fields partially overlap
    to encompass the entire field of vision. The response of an individual neuron
    to stimuli within its receptive field can be approximated mathematically through
    a convolution operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'All aspects pertaining to NN training, encompassing forward/backward propagation
    and weight updates, hold true in this context. Additionally, an entire CNN utilizes
    a singular differentiable cost function. However, CNNs are based on a particular
    assumption: their input possesses a specific data structure, such as an image.
    This characteristic empowers them to incorporate tailored architectural elements
    for enhanced processing of such data.'
  prefs: []
  type: TYPE_NORMAL
- en: CNNs adopt a **fully connected** (**FC**) **architecture**, where each neuron
    in each layer connects to all neurons in the preceding layer (excluding bias neurons).
    Generally, these architectures do not scale effectively when confronted with expanding
    input data sizes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common layers in a CNN are:'
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pooling layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rectified linear** **units** (**ReLUs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FC layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The function of each layer is addressed in detail in the following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, a CNN is composed of multiple sequential levels of convolution and
    subsampling (pooling), which are subsequently succeeded by one or more FC final
    levels, especially in the context of classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: For addressing real-world challenges, these procedures can be merged and repeated
    as required. For instance, you can incorporate two, three, or even multiple layers
    of convolution. Additionally, you have the flexibility to apply pooling operations
    repeatedly to downsize the data dimensions. As mentioned earlier, a variety of
    levels are typically employed within a CNN. Certain layers encompass adjustable
    training parameters (weight and bias), whereas others are designed to execute
    predefined functions.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a CNN, the primary layer type is the **convolutional layer**, and including
    one or more of these layers within a CNN is indispensable. In practical terms,
    the parameters of a convolutional layer are tied to a collection of adaptable
    filters. In contrast to CNNs, convolutional layers are structured in three dimensions,
    encompassing width, height, and depth.
  prefs: []
  type: TYPE_NORMAL
- en: Every filter occupies a small spatial area (along width and height dimensions)
    while spanning the complete depth of the input volume it is applied to. In forward
    propagation, each filter is shifted—or, more precisely, convolved—across the input
    volume’s width and height, generating a two-dimensional activation map (also known
    as a feature map) specific to that filter. While the filter traverses the input
    region, a scalar product operation takes place between the filter values and those
    of the corresponding input section.
  prefs: []
  type: TYPE_NORMAL
- en: Conceptually, the network’s objective is to learn activated filters that detect
    specific functionalities within distinct spatial regions of the input. Combining
    all these feature maps (for every filter) along the depth dimension forms the
    output volume of a convolutional layer. Each element within this volume can be
    interpreted as the output of a neuron observing a confined input area, and it
    shares its parameters with other neurons within the same feature map. This sharing
    stems from their common origin—the application of the same filter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mathematical steps for filtering are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Align the filter and the image patch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiply each image pixel by the corresponding feature pixel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sum the products.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Divide each sum by the total number of pixels in the feature.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here is the formula for the output of a convolutional layer:'
  prefs: []
  type: TYPE_NORMAL
- en: Output = ∑ F(k, l) * I(i + k, j + l)) / S(k, l)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here:'
  prefs: []
  type: TYPE_NORMAL
- en: F(k, l) is the feature map element in (k, l)position
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I(i + k, j + l)) ) is the image element in(i + k, j + l)position
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S(k, l) is the sum of the feature pixel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In summary, key points to emphasize include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Local receptive field**: Neurons in a layer are connected to a small segment
    of the input, known as a local receptive field. Each connection learns a weight.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shared weights**: Since significant features (such as edges or blobs) can
    appear anywhere in an image, neurons within the same layer share weights. This
    implies that identical features are recognized by all neurons in the layer, even
    if they’re positioned at different input points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Convolution**: Identical weight patterns are employed at various positions.
    The outcome of convolution is termed a **feature map**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each filter captures a specific feature from the preceding layer. Therefore,
    training multiple convolutional filters is necessary to extract diverse features.
    Each filter produces a feature map highlighting distinct characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Pooling layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These layers are systematically integrated into a network to periodically diminish
    the spatial dimensions (width and height) of ongoing representations and volumes
    within a specific stage of the network. This serves a dual purpose of minimizing
    the number of parameters, reducing computational time, and keeping a check on
    overfitting. The role of a **pooling layer** is to operate on each depth slice
    of the input volume independently to resize it spatially.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each feature obtained during the convolutional process, a matrix is constructed,
    and the maximum value within each selected matrix is identified to compress the
    entire input. The steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Choose a window size (typically `2` or `3`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select a stride distance for pixel movement (usually 2). In a CNN, the stride
    distance in a pooling layer determines how much the pooling operation slides across
    the input feature map. A higher stride distance means that the pooling operation
    will skip over more pixels, resulting in a smaller output feature map. A lower
    stride distance means that the pooling operation will slide more carefully across
    the input feature map, resulting in a larger output feature map.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Slide the window across the filtered images.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each window, determine the maximum value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Illustratively, this method partitions an input image into groups of squares,
    and for each resulting segment, the highest value is extracted as the output.
    CNNs additionally incorporate pooling layers, strategically placed right after
    the convolutional layers. A pooling layer dissects the input into sections and
    chooses a representative value, employing methods such as max pooling or average
    pooling. The **max pooling** layer captures the highest features detected by preceding
    convolutional layers. The output layer assesses the presence of a potential feature
    within a region of the previous layers, albeit without exact spatial coordinates.
    The objective is to enable subsequent layers to process larger data sections.
    Max pooling expedites convergence rates, thereby enabling the selection of highly
    invariant features that enhance generalization performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The integration of a pooling layer offers the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Reduces subsequent layer computations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enhances feature robustness concerning spatial positioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operates under the premise that after identifying a particular feature, its
    precise location within the input becomes less significant than its general position
    relative to other features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Average pooling serves as a downsampling operation that consolidates the representation
    of features within patches of the feature map. Typically, it is implemented in
    2x2 patches of the feature map with a stride of (2, 2). The process entails computing
    the average for each patch of the feature map, indicating that every 2x2 square
    in the feature map is downsampled to its average value. To illustrate, consider
    the 6x6 feature map resulting from the line detector convolutional filter discussed
    in the preceding section. We can manually explore the application of the average
    pooling operation to the initial line of that feature map.
  prefs: []
  type: TYPE_NORMAL
- en: In a typical CNN architecture, convolution layers and pooling layers are interleaved
    in a recurring pattern.
  prefs: []
  type: TYPE_NORMAL
- en: ReLUs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**ReLUs** serve as crucial activation functions within NNs. Their frequent
    utilization occurs multiple times within a single network, often following each
    convolutional layer. A ReLU layer is composed of neurons that execute the function
    *f(x) = max(0, x)*. Incorporating these layers enhances the network’s non-linearity
    while maintaining the convolutional levels’ receptive fields unchanged.'
  prefs: []
  type: TYPE_NORMAL
- en: ReLUs are favored over alternative functions such as hyperbolic tangent or sigmoid,
    primarily due to their capacity to accelerate the training process significantly
    without substantially compromising generalization accuracy. By employing ReLU
    layers, network training becomes remarkably swifter, all while preserving comparable
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'These layer types lack adjustable parameters, thus executing a fixed function.
    Furthermore, they don’t possess any adaptable parameters either. Layers devoid
    of tunable parameters simplify the backward propagation process: errors computed
    up to that point, stemming from the subsequent layer, are propagated backward
    to the preceding layer.'
  prefs: []
  type: TYPE_NORMAL
- en: FC layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This layer type mirrors the structure of any layer found in a traditional ANN
    featuring an FC architecture. In an **FC layer**, each neuron establishes connections
    with all neurons from the preceding layer, specifically interacting with their
    activations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike what has been observed thus far in CNNs, this layer type does not adhere
    to the principle of local connectivity. An FC layer establishes connections spanning
    the entire input volume, which naturally results in a multitude of connections.
    The sole adjustable parameter in this layer type is the number of neurons, *K*,
    that constitute it. The fundamental characteristic of an FC layer can be summarized
    as follows: linking its K neurons with the entire input volume and calculating
    the activation for each of these K neurons.'
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the outcome will be a singular 1 x 1 x K vector, encapsulating
    the computed activations. The transition from an input volume, organized in three
    dimensions, to a singular output vector in one dimension (1 x 1 x K) after implementing
    an FC layer signifies that the utilization of additional convoluted layers becomes
    infeasible. In the realm of CNNs, FC layers primarily serve the purpose of consolidating
    information amassed up to that point, presenting it as a singular value (the activation
    of one of its neurons). This singular value subsequently forms the basis for subsequent
    computations in the final classification process.
  prefs: []
  type: TYPE_NORMAL
- en: Having thoroughly examined each element of a CNN, it is now fitting to delve
    into the overarching structure of a complete CNN.
  prefs: []
  type: TYPE_NORMAL
- en: Building a CNN in MATLAB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will see how to train a CNN for image classification, starting
    from the images as input layers. The overall architecture of a CNN typically comprises
    a sequence of convolutional layers, interspersed with ReLU layers and, when appropriate,
    standardization and pooling layers. Ultimately, the network concludes with a series
    of FC layers leading to the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'CNNs consist of two primary types of neurons:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Processing neurons**: These neurons undertake the responsibility of processing
    specific sections of the input image through convolution functions. Their primary
    role involves extracting distinctive features from the input data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Aggregation or pooling neurons**: These neurons aggregate the input data
    and reduce its dimensions through subsampling, enhancing efficiency for subsequent
    layers’ processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By assembling the output values from a given layer, it becomes possible to
    reconstruct an intermediate image that serves as a foundation for subsequent layers’
    operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – CNN architecture](img/B21156_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – CNN architecture
  prefs: []
  type: TYPE_NORMAL
- en: The fundamental concept involves commencing with a sizable image and progressively
    condensing the data through incremental steps until a singular outcome is achieved.
    As the number of convolutional passages increases, the NN’s capacity to comprehend
    and handle intricate functions amplifies.
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration of a basic CNN can be succinctly described through the following
    components:'
  prefs: []
  type: TYPE_NORMAL
- en: An input layer tasked with acquiring input elements, such as images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A sequence of convolutional layers, occasionally punctuated by a ReLU layer
    and, when deemed appropriate, pooling layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A series of FC layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An output layer that furnishes the final results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recent research has indicated that the significance of FC layers might be less
    substantial. Nevertheless, for the present context, the outlined structure represents
    the typical architecture of a CNN.
  prefs: []
  type: TYPE_NORMAL
- en: '**Object recognition** refers to the capacity to locate a specific object within
    a series of images or videos. Humans effortlessly identify diverse objects in
    images, even when those objects appear differently. Moreover, objects can be distinguished
    even when only parts of them are visible. However, this remains a challenging
    task for the broader field of CV.'
  prefs: []
  type: TYPE_NORMAL
- en: In each image, every object boasts numerous intriguing features that can be
    extracted to craft a depiction of it. This portrayal subsequently serves to distinguish
    the object when attempting to spot it amid multiple objects in a test image. Ensuring
    the features taken from the reference image are unaffected by differences in image
    scale, disturbances, lighting variations, and distortions is crucial for establishing
    dependable recognition.
  prefs: []
  type: TYPE_NORMAL
- en: CNNs are particularly well suited for this endeavor, providing algorithms that
    excel in the identification of objects with remarkable accuracy. This is because
    they are able to learn features from images that are invariant to translation,
    scale, and rotation. This is due to the use of convolutional layers, which apply
    a filter to a small region of the input image and then slide the filter across
    the image. This allows the network to learn features that are specific to different
    parts of the image, regardless of where they are located. Additionally, pooling
    layers are used to reduce the dimensionality of the feature maps, which makes
    the network more efficient to train and run.
  prefs: []
  type: TYPE_NORMAL
- en: For CNN training, we will use Pistachio image dataset. The dataset offers data
    for analyzing the species of pistachio using a large collection of photos.
  prefs: []
  type: TYPE_NORMAL
- en: 'It encompasses a total of 2,148 images categorized into 2 classes—`Kirmizi`
    and `Siirt`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, we must load the dataset in the MATLAB workspace. The dataset is
    available in ZIP format on the site linked in the *Technical requirements* section.
    To facilitate the reader’s work, the images have been divided according to class
    into folders named according to the category and resized to reduce the weight
    of the data. These folders are available for download on the book’s GitHub site.
    Once the file has been downloaded and the contents extracted, it will be enough
    to define the path of the root folder. At this point, it will be possible to upload
    the data to the MATLAB workspace as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To load the data, we used the `imageDatastore()` function, which employs an
    `ImageDatastore` entity to oversee a compilation of image files, with each singular
    image fitting within memory, although the complete image collection might not.
    Constructing an `ImageDatastore` entity involves utilizing the `imageDatastore`
    function, where you can define its attributes. Subsequently, you can import and
    manipulate the data using the functions associated with the entity. Three parameters
    were used, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`Location= ''C:\MatlabScript\PistachioShort''`: This is the location of the
    dataset. To replicate the example, the reader has to simply substitute the path
    of the folder in which the dataset was stored.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IncludeSubfolders`: The inclusion of subfolders can be controlled using the
    `IncludeSubfolders` name-value argument, which accepts either `true` or `false`.
    Opt for `true` to encompass all files and subfolders within each main folder,
    or select `false` to solely encompass files within each main folder. When `IncludeSubfolders`
    is not explicitly specified, the default value is `false`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LabelSource`: The origin of label data is determined through the `LabelSource`
    name-value argument, which accepts either `none` or `foldernames`. By specifying
    `none`, the `Labels` property remains devoid of labels. On the other hand, designating
    `foldernames` results in the assignment of labels based on the folder names, which
    are then stored within the `Labels` property. Subsequent adjustments to the labels
    can be made by directly accessing the `Labels` property. It’s important to note
    that the `LabelSource` name-value argument cannot be utilized when a `FileSet`
    object serves as the file or folder location.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can now view some of the images loaded through a random process:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this piece of code, we have used the `randperm()` function, which generates
    a row vector comprising `9` distinct random integers chosen from the range of
    `1` to `2148`. Each number generated was used as an index to identify an image
    file path stored in the `Data.Files` property.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following output was returned:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Image samples from PistachioShort dataset](img/B21156_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – Image samples from PistachioShort dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'We are now able to determine the image count in each category. The `ClassItemsNumber`
    variable represents a table containing the labels and the corresponding number
    of images associated with each of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We used the `countEachLabel()` function that produces a summary table indicating
    the labels within the `Data` dataset and the respective count of associated files
    for each label.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table was printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, there are two categories, and there are enough images in each
    category.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, it is necessary to divide the data at our disposal into two subsets;
    the first will be used for training, and the second for algorithm validation.
    Data splitting is a crucial step in ML and data analysis whereby a dataset is
    divided into two or more subsets for the purpose of training, validation, and
    testing of a model. We have `2148` samples divided into `1232` Kirmizi species
    and `916` Siirt species. Usually, the data would be split into 80% for the training
    and 20% for validation. For this purpose, we decide to use 700 samples for the
    training and the remainder for validation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To do this, the `splitEachLabel()` function was used: this function divides
    the image files in the Data dataset into two distinct datastores—namely, `DataTrain`
    and `DataValidation`. The freshly created `DataTrain` datastore encompasses the
    initial `TrainSamples` value from every category, while the `DataValidation` datastore
    holds the remaining files from each category. `TrainSamples` can either be a fractional
    value between `0` and `1`, denoting the proportion of files to allocate to `DataTrain`,
    or an integer representing the exact count of files to be placed in `DataTrain`
    for each category.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we can start building our CNN. As anticipated, a CNN is formed by a series
    of layers connected to each other. To get started, you need to use a layer to
    import your input data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `layers` variable is an array containing a list of layers of the CNN and
    defines the architecture of NNs for DL. As a first layer, we set the `imageInputLayer`
    layer: this layer serves as an image input, feeding 2D images into a NN while
    also implementing data normalization. This layer provides an image input layer
    and defines the unchangeable `InputSize` attribute.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `InputSize` attribute is a depiction of the input data’’ dimensions, represented
    as a 1D array of integers `[h w c]`, where `h`, `w`, and `c` denote the height,
    width, and number of channels respectively. In this case, we have an RGB image
    with height = 64 and width = 64.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After the input layer, we set the first block of three layers in sequence:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Downsampling at a 2:1 ratio and stride = 2 indicate a shift by 2 columns and
    2 rows in the pooling operation. A 2D max pooling layer conducts downsampling
    by partitioning the input into rectangular pooling regions and subsequently determining
    the maximum value within each region.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we will apply a second block of layers like the first, changing the parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After that, a new pooling layer is applied:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And finally, a third block of layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In an FC layer, the input is multiplied by a weight matrix and then augmented
    with a bias vector. A bias vector is a set of values added to the weighted input
    of a neuron before applying the activation function. It plays a crucial role in
    adjusting neuron activation thresholds and enabling the network to represent complex
    relationships in data. The `Size` parameter output specifies the output size;
    we are classifying a two-species pistachio, so the size is `2`. This layer category
    replicates the configuration of layers typically present in a conventional ANN
    that employs an FC design. Within an FC layer, each neuron establishes connections
    with every neuron from the previous layer, engaging directly with their respective
    activations. softmaxLayer
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`softmaxLayer` is a type of layer used in NNs, specifically designed to apply
    the `softmax` function to the input. The `softmax` function is often used in classification
    tasks to convert raw scores or logits into a probability distribution over multiple
    classes. This layer is commonly utilized as the final layer in a NN for multi-class
    classification, where the output values are transformed into probabilities that
    sum up to `1`, making it easier to interpret the model’s predictions. classificationLayer];'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The classification layer computes cross-entropy loss for both standard and weighted
    classification tasks involving mutually exclusive classes. The layer automatically
    determines the number of classes based on the dimension of the output from the
    preceding layer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Right now, we have to set the option of the CNN:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `trainingOptions()` function was used to set several options relevant to
    the training of the network. The following options were set:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`sdm`: Solver for training the NN; we have used the `InitialLearnRate`: The
    initial learning rate employed in training is a positive numerical value. When
    the learning rate is excessively low, the training process might become prolonged.
    Conversely, if the learning rate is excessively high, the training could yield
    suboptimal results or diverge.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MaxEpochs`: The maximum number of training epochs is defined as a positive
    integer. In the context of gradient descent optimization using mini-batches, an
    iteration signifies a single step aimed at minimizing the loss function. An epoch
    refers to the full iteration of the training algorithm across the entire training
    dataset.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Shuffle`: Option for data shuffling. For this, we employed the practice of
    shuffling the training data before every training epoch, and similarly, shuffling
    the validation data before each validation of the NN.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ValidationData`: The validation data to be utilized during training is defined
    as either a datastore, a table, or an array of cells containing the predictors
    and validation responses.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ValidationFrequency`: The NN’s validation rate is expressed as a positive
    integer, representing the count of interactions. `ValidationFrequency` signifies
    the interval, in terms of iterations, at which validation metrics are assessed.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Verbose`: For displaying training progress information.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Plots`: Upon configuring the `training-progress` training option in `trainingOptions`
    and initiating the network training using `trainNetwork()`, a plot is generated.
    This plot showcases training metrics for each iteration. Each iteration involves
    an estimation of the gradient and an adjustment of the network parameters. If
    you provide validation data within `trainingOptions`, the plot will additionally
    present validation metrics whenever the network undergoes validation by the `trainNetwork`
    process.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we have to train the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `trainNetwork()` function facilitates the training of DNNs. This training
    can be executed on either a CPU or a GPU. For tasks such as image classification
    and image regression, it’s possible to train a single NN concurrently using multiple
    GPUs or a local/remote parallel pool. However, the employment of GPUs or parallel
    processing necessitates the presence of Parallel Computing Toolbox. Additionally,
    utilizing a GPU for DL mandates the availability of a compatible GPU device.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following plot was returned to the `trainNetwork()` function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Training process](img/B21156_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – Training process
  prefs: []
  type: TYPE_NORMAL
- en: 'The plot in *Figure 6**.4* will be progressively updated throughout the training
    process. In this way, it will be possible to check how the algorithm manages to
    adjust the weights to reach convergence. The plot in *Figure 6**.4* consists of
    three curves:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Training error**: This curve shows the average error of the network on the
    training data as a function of the number of training epochs. Epochs are the number
    of times the network is trained on the entire training dataset. A low training
    error indicates that the network is learning well from the training data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Validation error**: This curve shows the average error of the network on
    the validation data as a function of the number of training epochs. Validation
    data is data that the network was not trained on, and it is used to evaluate how
    well the network generalizes to unseen data. A low validation error indicates
    that the network is learning to generalize well to new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network weights**: This curve shows the magnitude of the weights of the network
    as a function of the number of training epochs. The weights are the parameters
    that the network learns from the training data. A stable weight curve indicates
    that the network is not overfitting to the training data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After seeing how to train a CNN in MATLAB, we now need to learn how to interpret
    the results and use the validation metrics correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the model’s results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Evaluating results is an essential part of any CNN implementation process. This,
    of course, is true for any algorithm based on ML. Evaluation metrics are quantitative
    measures used to assess the performance and quality of a model, algorithm, or
    system in various tasks, such as ML, data analysis, and optimization. These metrics
    provide a way to objectively quantify how well a model is performing and to compare
    different models or approaches.
  prefs: []
  type: TYPE_NORMAL
- en: The type of metric to adopt obviously depends on the type of algorithm we are
    implementing; in the previous section, we implemented a CNN for the classification
    of the pistachio species. So, let’s take a look at the metrics available for this
    type of algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a classification task, we can use the following metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy**: The proportion of correctly classified instances out of the total
    instances'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Precision**: The ratio of true positive predictions to the total number of
    positive predictions, indicating the accuracy of positive predictions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recall (Sensitivity)**: The ratio of true positive predictions to the total
    number of actual positives, indicating the model’s ability to identify positive
    cases'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F1-score**: The harmonic mean of precision and recall, providing a balance
    between them'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Receiver Operating Characteristic (ROC) curve**: A graph showing the trade-off
    between true positive rate and false positive rate at various thresholds'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Area Under the ROC Curve (AUC-ROC)**: A metric that quantifies the overall
    performance of a binary classification model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let us try to deepen the concept of accuracy. Accuracy is a fundamental evaluation
    metric used in classification tasks to measure the proportion of correctly predicted
    instances out of the total instances in a dataset. It provides an overall view
    of how well a classification model is performing. The accuracy formula is:'
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy =  Number of Correct Predictions  ______________________  Total Number
    of Predictions
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if you have a binary classification problem with 100 instances,
    and your model correctly predicts 90 of them, the accuracy would be:'
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy =  90 _ 100  = 0.90, or 90%
  prefs: []
  type: TYPE_NORMAL
- en: While accuracy is a simple and intuitive metric, it might not be suitable in
    cases of imbalanced classes, where one class significantly outnumbers the other.
    In such situations, a high accuracy could be misleading if the model is performing
    well on the dominant class but poorly on the minority class. In these cases, precision,
    recall, F1-score, and other metrics might provide a more accurate representation
    of the model’s performance. Also, in this case, it is important to point out that
    when the dataset is not sufficiently balanced between the classes, the classification
    result may not be applied to all the classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let’s try to apply this metric to the case study analyzed in the previous
    section for the classification of the pistachio species. We have already trained
    the network, and at this point, we can use it to make classifications using data
    never seen before by the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To carry out the validation, we start by classifying the collected images in
    the `DataValidation` subset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This function employs a trained DNN to classify data. Predictions can be generated
    using the trained network on either a CPU or GPU. Utilizing a GPU necessitates
    both a *Parallel Computing Toolbox™ license* and a compatible GPU device. Two
    parameters are passed: the CNN trained (`CNnet`) and the input dataset (`DataValidation`).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After that, we must extract the label of the input data; this information is
    contained in the image datastore. We have only to use the `labels` parameter,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s calculate the accuracy using the formula previously introduced:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following result is returned:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: An accuracy of 86.95% was obtained; this tells us that the CNN-based algorithm
    can correctly classify 86.95% of the pistachio images we passed it. We also recall
    that these images had never been used by the network training algorithm.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To better understand the performance of the model, we can draw a confusion matrix.
    A confusion matrix is a tabular representation used in the field of ML and statistics
    to evaluate the performance of a classification model. It provides a comprehensive
    view of how well the model’s predictions align with the actual classes in a dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A confusion matrix is organized into four categories:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**True Positives** (**TP**): Instances that are correctly predicted as positive'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True Negatives** (**TN**): Instances that are correctly predicted as negative'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Positives** (**FP**): Instances that are incorrectly predicted as positive
    when they are actually negative (**Type** **I error**)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Negatives** (**FN**): Instances that are incorrectly predicted as negative
    when they are actually positive (**Type** **II error**)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The matrix format looks like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | **Predicted Positive** | **Predicted Negative** |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Actual Positive** | True Positives | False Negatives |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Actual Negative** | False Positives | True Negatives |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: Figure 6.5 – Confusion matrix terms’ meaning
  prefs: []
  type: TYPE_NORMAL
- en: 'In MATLAB, we can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This function generates a confusion matrix chart using true labels stored in
    `DataValLabel` and predicted labels stored in `CNNPredLabel`. It then returns
    a `ConfusionMatrixChart` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following results are printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output was returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Confusion matrix](img/B21156_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – Confusion matrix
  prefs: []
  type: TYPE_NORMAL
- en: In that matrix, rows correspond to the true classes, and columns correspond
    to the predicted classes. Cells along the diagonal represent correctly classified
    instances, while off-diagonal cells represent instances that were classified incorrectly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also show the accuracy calculation from the confusion matrix table as
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: (TP + TN) / (Totalvalidationdata) = (204 + 169) / 916 = 0.8695
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 6**.6*, we can notice that false negatives are greater than false
    positives. In some applications, false negatives are more serious than false positives.
    For example, in the context of medical diagnosis, it is generally more important
    to avoid missing a disease than to incorrectly flag a healthy person as having
    a disease. However, in other applications, false positives may be more serious.
    For example, in the context of fraud detection, it is generally more important
    to avoid incorrectly accusing an innocent person of fraud than to miss a fraudulent
    transaction.
  prefs: []
  type: TYPE_NORMAL
- en: After seeing how to implement a CNN and correctly interpret the results, we
    can now explore some of the many DL architectures available.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering DL architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DL models are essentially multi-layered NNs, which refers to NNs that comprise
    multiple hidden layers (at least two) structured hierarchically. This hierarchical
    arrangement facilitates the sharing and reuse of information. Across this hierarchy,
    one can pinpoint features while disregarding unnecessary intricacies, thereby
    enhancing invariance. Within the realm of multi-level ML, deeper tiers acquire
    inputs from the outputs of prior layers and execute more complex transformations
    and abstractions. This layering approach to learning draws inspiration from the
    information processing and learning methods of mammalian brains, enabling them
    to react to external stimuli.
  prefs: []
  type: TYPE_NORMAL
- en: DL architectures are the fundamental blueprints that underlie the construction
    of DNNs, enabling them to effectively learn and represent complex patterns and
    features from data. These architectures define the layout, connections, and flow
    of information within the network, determining how data is transformed and features
    are extracted at various layers. Several notable DL architectures have been developed
    over the years, each designed to tackle specific types of tasks and data. In the
    following sections, we will address the most used.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding RNNs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Feedforward NNs** (**FNNs**) operate by providing input data to the network
    that is then transformed into output. In SL scenarios, the output typically represents
    a label that corresponds to the input. These algorithms essentially link raw data
    with specific categories by recognizing underlying patterns. In contrast, recurrent
    networks incorporate not only the current input data being fed into the network
    but also information they have accumulated over time.'
  prefs: []
  type: TYPE_NORMAL
- en: An RNN embodies a neural model with bidirectional information flow. Unlike feedforward
    networks where signal propagation only moves unidirectionally from inputs to outputs,
    RNNs exhibit a different behavior. In RNNs, signal propagation can traverse between
    neural layers, from a prior layer to a subsequent one, among neurons within the
    same layer, or even from a neuron to itself. A decision made by an RNN at a given
    moment influences its subsequent decisions. Consequently, RNNs possess two sources
    of input—the present and the recent past—combining to determine responses to new
    data, mirroring how people make decisions in everyday life.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key distinction between recurrent and feedforward networks lies in the
    **feedback loop** that connects RNNs to their past decisions, momentarily utilizing
    their output as input. This aspect underscores the memory aspect of RNNs. The
    inclusion of memory in NNs serves a purpose: there is intrinsic information in
    the sequence itself, and RNNs leverage this information to perform tasks that
    feedforward networks are unable to accomplish.'
  prefs: []
  type: TYPE_NORMAL
- en: Access to this memory occurs based on content rather than specific addresses
    or locations. One approach entails considering memory content as the activation
    patterns on nodes within an RNN. The concept involves initiating the network with
    an activation pattern that partially or noisily represents the desired memory
    content, allowing the network to stabilize around the required content. An RNN
    belongs to the category of NNs where there exists at least one feedback connection
    between neurons, forming a directed cycle within the network’s structure.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6**.7* illustrates a standard RNN with connections linking the hidden
    layer to the output layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – RNN architecture](img/B21156_06_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – RNN architecture
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram depicting a recurrent network, the hidden layer’s weights
    are defined using both the input and output layers. Essentially, we can view RNNs
    as a variation of ANNs, with differences in the number of hidden layers and the
    flow of data patterns. RNNs exhibit distinct data flow patterns due to the cyclic
    connections between neurons. Unlike feedforward networks, RNNs can leverage internal
    memory during their computations. RNNs belong to the class of ANNs that incorporate
    connections between hidden layers, which are carried forward across time to facilitate
    the learning of sequences.
  prefs: []
  type: TYPE_NORMAL
- en: RNNs derive their strength and effectiveness from their unique mechanism of
    storing and flowing data across varying time intervals. These networks are adept
    at identifying patterns in data sequences, making them valuable tools for prediction
    and forecasting. Their versatility spans multiple domains, encompassing text,
    images, speech, and time series data. Positioned among the potent members of the
    ANN family, RNNs embody the intricacies of the biological brain, encompassing
    both memory and computational capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing LSTM networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A specific form of RNN is the LSTM network, originally conceptualized by Hochreiter
    and Schmidhuber in 1997\. This architecture has garnered renewed attention within
    the realm of DL due to its immunity to the vanishing gradient problem and its
    proven excellence in practical results and performance.
  prefs: []
  type: TYPE_NORMAL
- en: The vanishing gradient problem poses challenges in training ANNs through gradient-based
    learning techniques. Methods such as backpropagation adjust weights based on error
    gradients. However, these gradients can diminish exponentially as they propagate
    deeper into the network, sometimes rendering them exceedingly small and preventing
    weight adjustments. In extreme cases, this can halt network training altogether.
  prefs: []
  type: TYPE_NORMAL
- en: LSTM networks offer an ideal solution for predicting and classifying sequential
    data, outperforming numerous traditional ML methodologies. A significant example
    is Google’s transition in 2012 from **hidden Markov models** (**HMMs**) to DNNs
    for voice recognition. By 2015, Google had adopted LSTM-based RNNs combined with
    **Connectionist Temporal Classification** (**CTC**) for improved voice recognition.
  prefs: []
  type: TYPE_NORMAL
- en: CTC serves as an output and scoring function for training RNNs. An LSTM network’s
    strength lies in its ability to capture long-term dependencies among data, enhancing
    its utility in contexts such as speech recognition where understanding sentence
    context is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: An LSTM network comprises interconnected LSTM cells, each featuring input, output,
    and **forget gates**. These gates facilitate writing, reading, and resetting functions
    on the cell memory. Rather than binary, the gates are analogical, typically managed
    by sigmoid activation functions that map values to a range (0, 1). This multiplicative
    nature empowers the cells to retain information over extended periods. The input
    gate controls whether the current state is combined with incoming input, while
    the forget gate resets the cell’s state when its value drops to zero. The output
    gate determines whether the cell’s content is retrieved or not, influencing the
    network’s overall output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram explains an LSTM unit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – LSTM architecture](img/B21156_06_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – LSTM architecture
  prefs: []
  type: TYPE_NORMAL
- en: NN-based approaches possess significant potency, enabling the extraction of
    inherent data characteristics and relationships. Notably, LSTM networks have demonstrated
    impressive real-world efficacy, boasting remarkable recognition rates. However,
    one drawback is that NNs function as **black-box models**. This means their behavior
    lacks predictability, and it’s impossible to decipher the underlying logic by
    which they process data.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing transformer models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Transformer models** are a revolutionary architecture in the field of NLP
    and beyond. Introduced in 2017, transformers have since become a foundational
    framework for a wide range of tasks, from language translation to image generation.
    The key innovation in transformer models is the self-attention mechanism. Traditional
    models process sequences in a linear manner, which limits their ability to capture
    long-range dependencies. In contrast, transformers employ self-attention to weigh
    the importance of different words in a sequence with respect to each other, enabling
    them to consider global context and dependencies.'
  prefs: []
  type: TYPE_NORMAL
- en: The transformer architecture consists of an encoder and a decoder, each comprising
    multiple layers. The encoder processes the input data, while the decoder generates
    the output. **Attention mechanisms** within these layers allow the model to focus
    on relevant parts of the input or output sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Transformers can be applied with success in various applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine translation**: Models such as *transformers* and *BERT* have set
    new benchmarks in machine translation, allowing for more accurate and contextually
    meaningful translations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Language understanding**: BERT captures bidirectional context, significantly
    improving language understanding tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text generation**: **Generative Pre-trained Transformer** (**GPT**) models
    generate coherent and contextually relevant text, finding applications in chatbots,
    content generation, and more'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image generation**: **Vision Transformer** (**ViT**) extends transformers
    to images, achieving competitive performance in image classification and generation
    tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the reasons behind transformers’ success is their parallelizable structure,
    which speeds up training. Additionally, the attention mechanism enables capturing
    relationships without explicitly defining sequence lengths.
  prefs: []
  type: TYPE_NORMAL
- en: Despite their immense capabilities, transformers have their own challenges,
    such as a high computational cost for large models and the potential for generating
    biased or inappropriate content. Researchers continue to refine and adapt the
    transformer architecture to address these issues and push the boundaries of AI
    capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned the basic concepts of DL and discovered how to implement
    a CNN algorithm in the MATLAB environment. First, we looked at how DL enables
    automated feature extraction, then we looked at how to train a deep network, and
    then we got a taste of the most popular DL architectures.
  prefs: []
  type: TYPE_NORMAL
- en: We then focused on CNN to analyze it in detail. We learned about the different
    layers that make up this network and what functions these layers perform. We then
    saw in practice how to implement a CNN in the MATLAB environment for image classification
    of pistachio nuts. We learned how to correctly import the image database, how
    to draw the architecture of the network with the different layers one after the
    other, and how to set the network parameters. Finally, we saw how to use evaluation
    metrics for the correct interpretation of the results.
  prefs: []
  type: TYPE_NORMAL
- en: In the last section, we introduced some of the most used networks, which will
    be the subject of more detailed study and application in the following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will understand the basic concepts of NLP, how to use
    corpora and word and sentence tokenization, and how to build a model to label
    sentences, and finally, we will implement gradient boosting techniques using MATLAB.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 3: Machine Learning in Practice'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, we will take a journey into the specialized domains of MATLAB
    application, where we will reveal the immense potential of the software in various
    fields.
  prefs: []
  type: TYPE_NORMAL
- en: Explore the enchanting world of natural language processing using MATLAB, where
    language intricacies are deciphered, enabling machines to comprehend and respond
    to human communication. Transitioning into the visual realm, [*Chapter 8*](B21156_08.xhtml#_idTextAnchor167)
    opens doors to the manipulation and understanding of visual data, bringing pixels
    to life through sophisticated algorithms. Delve into the intricate patterns of
    [*Chapter 9*](B21156_09.xhtml#_idTextAnchor184), where historical data paves the
    way for informed predictions and strategic decision-making. Then, witness the
    power of [*Chapter 10*](B21156_10.xhtml#_idTextAnchor202), where personalized
    suggestions and recommendations emerge from intricate algorithms, enhancing user
    experiences. Concluding our exploration, immerse yourself in the realm of [*Chapter
    11*](B21156_11.xhtml#_idTextAnchor223), where subtle deviations in data patterns
    are unveiled, providing a critical edge in identifying outliers and potential
    threats. Join us as we navigate through these diverse applications, unlocking
    the capabilities of MATLAB in shaping the future of data analysis and decision
    support.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B21156_07.xhtml#_idTextAnchor145), *Natural Language Processing
    Using MATLAB*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B21156_08.xhtml#_idTextAnchor167), *MATLAB for Image Processing
    and Computer Vision*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B21156_09.xhtml#_idTextAnchor184), *Time Series Analysis and
    Forecasting with MATLAB*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B21156_10.xhtml#_idTextAnchor202), *MATLAB Tools for Recommender
    Systems*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B21156_11.xhtml#_idTextAnchor223), *Anomaly Detection in MATLAB*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
