<html><head></head><body>
  <div class="calibre1" id="_idContainer159">
    <h1 class="chapternumber">15</h1>
    <h1 class="chaptertitle" id="_idParaDest-319">Building a CNN Model for CIFAR-10 with ChatGPT</h1>
    <h1 class="heading" id="_idParaDest-320">Introduction</h1>
    <p class="normal">Having explored the depths of the <strong class="screentext">Multi-Layer Perceptron</strong> (<strong class="screentext">MLP</strong>) in our previous chapter with the Fashion-MNIST dataset, we now pivot to a more intricate and visually complex challenge. This chapter marks our transition from the primarily tabular, grayscale world of Fashion-MNIST to the colorful and diverse realm of the CIFAR-10 dataset. Here, we elevate our focus to <strong class="screentext">Convolutional Neural Networks</strong> (<strong class="screentext">CNNs</strong>), a class of deep neural networks that are revolutionizing the way we approach image classification tasks.</p>
    <p class="normal1">Our journey through the MLP chapter provided a strong foundation for understanding the basics of neural networks and their application in classifying simpler, grayscale images. Now, we step into a more advanced territory where CNNs reign supreme. The CIFAR-10 dataset, with its array of 32x32 color images across 10 different classes, presents a unique set of challenges that MLPs are not best suited to address. This is where CNNs, with their ability to capture spatial and textural patterns in images, come into play.</p>
    <p class="normal1">As we transition from MLPs to CNNs, we carry forward the insights and knowledge gained, applying them to a more complex dataset that closely mimics real-world scenarios. The CIFAR-10 dataset not only tests the limits of image classification models but also serves as an excellent platform for us to explore the advanced capabilities of CNNs.</p>
    <p class="normal1">This chapter aims to build upon what we learned about neural networks and guide you through the nuances of CNNs. We will delve into why CNNs are the preferred choice for image data, how they differ from MLPs in handling color and texture, and what makes them so effective in classifying images from the CIFAR-10 dataset. Prepare to embark on a journey that takes you from the fundamentals to the more sophisticated aspects of CNNs.</p>
    <h1 class="heading" id="_idParaDest-321">Business problem</h1>
    <p class="normal">The CIFAR-10 dataset<a id="_idIndexMarker627" class="calibre3"/> presents a business challenge to companies seeking to enhance image recognition capabilities for various objects and optimize decision-making processes based on visual data. A multitude of industries, such as e-commerce, autonomous driving, and surveillance, can benefit from accurate object classification and detection. By harnessing machine learning algorithms, businesses aim to improve efficiency, enhance their user experience, and streamline operations.</p>
    <h1 class="heading" id="_idParaDest-322">Problem and data domain</h1>
    <p class="normal">In this context, we will utilize CNNs to tackle the object recognition task using the CIFAR-10 dataset. CNNs are particularly effective for image-related problems due to their ability to automatically learn hierarchical features from raw pixel data. By training a CNN model on the CIFAR-10 dataset, we aim to develop a robust system capable of accurately classifying objects into one of the ten predefined categories. This model can be applied in various domains, such as image-based search engines, automated surveillance systems, and quality control in manufacturing.</p>
    <h2 class="heading1" id="_idParaDest-323">Dataset overview</h2>
    <p class="normal">The CIFAR-10 dataset <a id="_idIndexMarker628" class="calibre3"/>comprises 60,000 color images, divided into 10 classes, with 6,000 images per class. Each image has dimensions of 32x32 pixels and is represented in RGB format. The dataset is split into a training set of 50,000 images and a test set of 10,000 images.</p>
    <p class="normal1">Features in the dataset include:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Image data</strong>: Color images of various objects, each represented as a 3-dimensional array containing pixel intensities for red, green, and blue channels. These images serve as input data for training the CNN model.</li>
      <li class="bulletlist1"><strong class="screentext">Label</strong>: The class label assigned to each image, representing the category of the depicted object. The labels range from 0 to 9, corresponding to classes such as airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.</li>
    </ul>
    <p class="normal1">By analyzing the CIFAR-10 <a id="_idIndexMarker629" class="calibre3"/>dataset and its associated labels, our goal is to train a CNN model capable of accurately identifying objects depicted in images. This predictive model can then be deployed in real-world applications to automate object recognition tasks, improve decision-making processes, and enhance overall efficiency in diverse industries.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_15_01.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.1: CIFAR-10 dataset</p>
    <h1 class="heading" id="_idParaDest-324">Breaking the problem down into features</h1>
    <p class="normal">Given the CIFAR-10 dataset and the application of CNNs for image recognition, we outline the following features to guide users through building and optimizing CNN models:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Building the baseline CNN model with a single convolutional layer</strong>: Users will start by constructing a simple CNN model with a single convolutional layer for image classification. This feature focuses on defining the basic architecture, including convolutional filters, activation functions, and pooling layers, to establish a foundational understanding of CNNs.</li>
      <li class="bulletlist1"><strong class="screentext">Experimenting with the addition of convolutional layers</strong>: Users will explore the impact of adding additional convolutional layers to the baseline model architecture. By incrementally increasing the depth of the network, users can observe how the model’s capacity to capture hierarchical features evolves and its ability to learn complex patterns improves.</li>
      <li class="bulletlist1"><strong class="screentext">Incorporating dropout regularization</strong>: Users will learn how to integrate dropout regularization into the CNN model to mitigate overfitting and improve generalization performance. By randomly dropping units during training, dropout helps prevent the network from relying too heavily on specific features and encourages robust feature learning.</li>
      <li class="bulletlist1"><strong class="screentext">Implementing batch normalization</strong>: Users will explore the benefits of batch normalization in stabilizing training dynamics and accelerating convergence. This feature focuses on incorporating batch normalization layers into the CNN architecture to normalize activations and reduce internal covariate shift, leading to faster and more stable training.</li>
      <li class="bulletlist1"><strong class="screentext">Optimizing with different optimizers</strong>: This feature explores the effects of using various optimization algorithms, including SGD, Adam, and RMSprop, to train the CNN model. Users will compare the training dynamics, convergence speed, and final model performance achieved with different optimizers, allowing them to select the most suitable optimization strategy for their specific task.</li>
      <li class="bulletlist1"><strong class="screentext">Performing data augmentation</strong>: Users will experiment with data augmentation techniques such as rotation, flipping, zooming, and shifting to increase the diversity and size of the training dataset. By generating augmented samples on the fly during training, users can improve the model’s ability to generalize to unseen data and enhance robustness against variations in input images.</li>
    </ul>
    <p class="normal1">By following these features, users will gain practical insights into building, fine-tuning, and optimizing CNN models for image classification tasks using the CIFAR-10 dataset. They will learn how to systematically experiment with different architectural components, regularization techniques, and optimization strategies to achieve superior performance and accuracy in object recognition.</p>
    <h1 class="heading" id="_idParaDest-325">Prompting strategy</h1>
    <p class="normal">To leverage ChatGPT for machine learning, we need to have a clear understanding of how to implement prompting strategies specifically for code generation for machine learning.</p>
    <p class="normal1">Let’s brainstorm what we would like to achieve in this task to get a better understanding of what needs to go into the prompts.</p>
    <h2 class="heading1" id="_idParaDest-326">Strategy 1: Task-Actions-Guidelines (TAG) prompt strategy</h2>
    <p class="normal"><strong class="screentext">1.1 - Task</strong>: The<a id="_idIndexMarker630" class="calibre3"/> specific task or goal is to build and optimize a CNN model for the CIFAR-10 dataset.</p>
    <p class="normal1"><strong class="screentext">1.2 - Actions</strong>: The key steps involved in building and optimizing a CNN model for the CIFAR-10 dataset include:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Preprocessing the image data</strong>: Normalize the pixel values and resize the images to a standardized size.</li>
      <li class="bulletlist1"><strong class="screentext">Model construction</strong>: Define the baseline CNN model architecture with a single convolutional layer.</li>
    </ul>
    <p class="normal1"><strong class="screentext">1.3 - Guidelines</strong>: We will provide the following guidelines to ChatGPT in our prompt:</p>
    <ul class="calibre15">
      <li class="bulletlist">The code should be compatible with Jupyter Notebook.</li>
      <li class="bulletlist1">Ensure that there are detailed comments for each line of code. </li>
      <li class="bulletlist1">You have to explain each line of code in detail, covering each method used in the code.</li>
    </ul>
    <h2 class="heading1" id="_idParaDest-327">Strategy 2: Persona-Instructions-Context (PIC) prompt strategy</h2>
    <p class="normal"><strong class="screentext">2.1 - Persona</strong>: Adopt<a id="_idIndexMarker631" class="calibre3"/> the persona of a beginner who needs step-by-step guidance on building and optimizing CNN models for image classification tasks.</p>
    <p class="normal1"><strong class="screentext">2.2 - Instructions</strong>: Request ChatGPT to generate code for each feature one step at a time and wait for user feedback before proceeding to the next step.</p>
    <p class="normal1"><strong class="screentext">2.3 - Context</strong>: Given that the focus is on building CNN models for image classification tasks using the CIFAR-10 dataset, ChatGPT is already aware of the dataset and its characteristics, so additional context may not be necessary.</p>
    <h2 class="heading1" id="_idParaDest-328">Strategy 3: Learn-Improvise-Feedback-Evaluate (LIFE) prompt strategy</h2>
    <p class="normal"><strong class="screentext">3.1 - Learn</strong>: </p>
    <ul class="calibre15">
      <li class="bulletlist">Emphasize the<a id="_idIndexMarker632" class="calibre3"/> importance of learning about CNN models and their components, including convolutional layers, pooling layers, dropout regularization, batch normalization, data augmentation, and optimization algorithms.</li>
    </ul>
    <p class="normal1"><strong class="screentext">3.2 - Improvise</strong>: </p>
    <ul class="calibre15">
      <li class="bulletlist">We will improvise later by adding more layers, dropout layers, pooling, data augmentation, and so on.</li>
    </ul>
    <p class="normal1"><strong class="screentext">3.3 - Feedback</strong>: </p>
    <ul class="calibre15">
      <li class="bulletlist">Share code and model outputs for feedback to ensure effective learning and understanding.</li>
      <li class="bulletlist1">Incorporate suggestions and critiques to refine the model and the approach<strong class="screentext">.</strong></li>
      <li class="bulletlist1">Provide errors to troubleshoot and resolve the issues.</li>
    </ul>
    <p class="normal1"><strong class="screentext">3.4- Evaluate</strong>: </p>
    <p class="normal1">Execute the code provided by ChatGPT to ensure accuracy and validity. This is used throughout the chapter.</p>
    <h1 class="heading" id="_idParaDest-329">Building a CNN model to accurately classify the CIFAR-10 images using the free version of ChatGPT</h1>
    <p class="normal">The <a id="_idIndexMarker633" class="calibre3"/>premium version of ChatGPT has a code interpreter, but it doesn’t support deep learning libraries such as Keras and TensorFlow, which are required to build ML code. Hence, for this chapter, we will stick to the free version of ChatGPT. </p>
    <h2 class="heading1" id="_idParaDest-330">Feature 1: Building the baseline CNN model with a single convolutional layer</h2>
    <p class="normal">Let’s<a id="_idIndexMarker634" class="calibre3"/> craft our initial prompt for the baseline model.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">I want to create a simple classification model for CIFAR-10 dataset (TAG 1.1) that consists of a single-layer CNN model (PIC 2.2). It should consist of following steps (TAG 1.2) and provide one step at a time, waiting for user feedback (PIC 2.2):</p>
    <ul class="calibre15">
      <li class="bulletlist">Preprocessing the image data: Normalize the pixel values and resize the images to a standardized size.</li>
      <li class="bulletlist1">Model construction: Define the baseline CNN model architecture with a single convolutional layer.</li>
    </ul>
    <p class="normal1">I am a beginner user (PIC 2.1), so please provide step-by-step code and strictly follow the below instructions (TAG 1.3):</p>
    <ul class="calibre15">
      <li class="bulletlist">The code should be compatible with Jupyter Notebook.</li>
      <li class="bulletlist1">Ensure that there are detailed comments for each line of code. </li>
    </ul>
    <p class="normal1">You have to explain each line of code in detail, covering each method used in the code.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">You should receive a response similar to the following, where ChatGPT has provided us with the code for the data preprocessing step along with detailed comments and explanations.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure, let’s<a id="_idIndexMarker635" class="calibre3"/> start with the first step: preprocessing the image data. In this step, we will normalize the pixel values and resize the images to a standardized size.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Step 1: Preprocessing the image data</span>
<span class="hljs-comment"># Import necessary libraries</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow.keras.datasets <span class="hljs-keyword">import</span> cifar10
<span class="hljs-keyword">from</span> tensorflow.keras.utils <span class="hljs-keyword">import</span> to_categorical
<span class="hljs-keyword">from</span> skimage.transform <span class="hljs-keyword">import</span> resize
<span class="hljs-comment"># Load CIFAR-10 dataset</span>
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
<span class="hljs-comment"># Normalize pixel values to range [0, 1]</span>
x_train = x_train.astype(<span class="hljs-string">'</span><span class="hljs-string">float32'</span>) / <span class="hljs-attr">255.0</span>
x_test = x_test.astype(<span class="hljs-string">'float32'</span>) / <span class="hljs-attr">255.0</span>
<span class="hljs-comment"># Resize images to a standardized size (e.g., 32x32 pixels)</span>
standardized_size = (<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>)
x_train_resized = np.array([resize(image, standardized_size) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> x_train])
x_test_resized = np.array([resize(image, standardized_size) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> x_test])
<span class="hljs-comment"># Display shape of datasets after preprocessing</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Shape of x_train:"</span>, x_train_resized.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Shape of x_test:"</span>, x_test_resized.shape)
</code></pre>
    <p class="normal1">Now, let’s break down each line of code:</p>
    <p class="normal1">We import the necessary libraries:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">numpy</code> for numerical operations.</li>
      <li class="bulletlist1"><code class="inlinecode">tensorflow</code> for building and training the model.</li>
      <li class="bulletlist1">cifar10 dataset from <code class="inlinecode">tensorflow.keras.datasets</code> for loading CIFAR-10 data.</li>
      <li class="bulletlist1"><code class="inlinecode">to_categorical</code> function from <code class="inlinecode">tensorflow.keras.utils</code> for one-hot encoding labels.</li>
      <li class="bulletlist1">resize function from <code class="inlinecode">skimage.transform</code> for resizing images.</li>
      <li class="bulletlist1">We load the CIFAR-10 dataset using <code class="inlinecode">cifar10.load_data()</code> function, which returns training and testing data splits.</li>
      <li class="bulletlist1">We normalize pixel values of images to the range <code class="inlinecode">[0, 1]</code> by dividing by <code class="inlinecode">255.0</code>.</li>
      <li class="bulletlist1">We define the standardized size for resizing images (e.g., 32x32 pixels).</li>
      <li class="bulletlist1">We resize all images in the training and testing sets to the standardized size using list comprehension and the resize function.</li>
      <li class="bulletlist1">Finally, we print the shapes of the training and testing datasets after preprocessing to verify the changes.</li>
    </ul>
    <p class="normal1">Let me <a id="_idIndexMarker636" class="calibre3"/>know if you have any questions or if you’d like to proceed to the next step!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We will now apply the evaluate prompting strategy (LIFE 3.4) and validate the code by executing the code in Google Colab for every step. The code loads the model from Keras and normalizes the images. The code runs perfectly fine without requiring any modifications or returning any errors.</p>
    <p class="normal1">Please refer to the Building a CNN Model for CIFAR-10 with <code class="inlinecode">ChatGPT.ipynb</code> notebook for the executable code snippets or copy the code from the prompt response.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_15_02.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.2: Code execution – data preprocessing</p>
    <p class="normal1">We will now<a id="_idIndexMarker637" class="calibre3"/> instruct ChatGPT to proceed to the next step.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed to the next step.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following, where ChatGPT should provide the code for creating a baseline model.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Great! The next step is to construct the baseline CNN model architecture with a single convolutional layer.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Step 2: Model Construction</span>
<span class="hljs-comment"># Import necessary libraries</span>
<span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Conv2D, MaxPooling2D, Flatten, Dense
<span class="hljs-comment"># Define the baseline CNN model architecture</span>
model = Sequential([
    <span class="hljs-comment"># Add a convolutional layer with 32 filters, kernel size of (3, 3), and ReLU activation function</span>
    Conv2D(<span class="hljs-attr">32</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>, <span class="hljs-attr">3</span>)),
    <span class="hljs-comment"># Add a max pooling layer with pool size of (2, 2)</span>
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    <span class="hljs-comment"># Flatten the output of the convolutional layer</span>
    Flatten(),
    <span class="hljs-comment"># Add a fully connected layer with 64 neurons and ReLU activation function</span>
    Dense(<span class="hljs-attr">64</span>, activation=<span class="hljs-string">'relu'</span>),
    <span class="hljs-comment"># Add the output layer with 10 neurons (one for each class) and softmax activation function</span>
    Dense(<span class="hljs-attr">10</span>, activation=<span class="hljs-string">'softmax'</span>)
])
<span class="hljs-comment"># Compile the model</span>
model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">'adam'</span>,
              loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,
              metrics=[<span class="hljs-string">'accuracy'</span>])
<span class="hljs-comment"># Display model summary</span>
model.summary()
</code></pre>
    <p class="normal1">Now, let’s <a id="_idIndexMarker638" class="calibre3"/>explain each line of code:</p>
    <ul class="calibre15">
      <li class="bulletlist">We import the necessary libraries:</li>
      <li class="bulletlist1">Sequential from <code class="inlinecode">tensorflow.keras.models</code> to create a sequential model.</li>
      <li class="bulletlist1"><code class="inlinecode">Conv2D</code>, <code class="inlinecode">MaxPooling2D</code>, <code class="inlinecode">Flatten</code>, and <code class="inlinecode">Dense</code> layers from <code class="inlinecode">tensorflow.keras.layers</code> to define the different types of layers in the CNN model.</li>
      <li class="bulletlist1">We define the baseline CNN model architecture using the Sequential API, which allows us to create a linear stack of layers.</li>
    </ul>
    <p class="normal1">Within the <a id="_idIndexMarker639" class="calibre3"/>Sequential model:</p>
    <ul class="calibre15">
      <li class="bulletlist">We add a convolutional layer (<code class="inlinecode">Conv2D</code>) with 32 filters, a kernel size of <code class="inlinecode">(3, 3)</code>, and <code class="inlinecode">ReLU</code> activation function. The <code class="inlinecode">input_shape</code> parameter defines the shape of input images.</li>
      <li class="bulletlist1">We add a max pooling layer (<code class="inlinecode">MaxPooling2D</code>) with a pool size of <code class="inlinecode">(2, 2)</code> to downsample the feature maps.</li>
      <li class="bulletlist1">We flatten the output of the convolutional layer using the <code class="inlinecode">Flatten</code> layer to prepare it for the fully connected layers.</li>
      <li class="bulletlist1">We add a fully connected layer (<code class="inlinecode">Dense</code>) with 64 neurons and a <code class="inlinecode">ReLU</code> activation function.</li>
      <li class="bulletlist1">Finally, we add the output layer with 10 neurons (one for each class in CIFAR-10) and the <code class="inlinecode">softmax</code> activation function.</li>
    </ul>
    <p class="normal1">We compile the model using <code class="inlinecode">model.compile()</code> with the following:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">optimizer='adam'</code> to use the <code class="inlinecode">Adam</code> optimizer.</li>
      <li class="bulletlist1"><code class="inlinecode">loss='sparse_categorical_crossentropy'</code> as the loss function, suitable for classification tasks with integer labels.</li>
      <li class="bulletlist1"><code class="inlinecode">metrics=['accuracy']</code> to monitor the accuracy during training.</li>
      <li class="bulletlist1">We display the summary of the model architecture using <code class="inlinecode">model.summary()</code>.</li>
    </ul>
    <p class="normal1">Let me know if you have any questions or if you’d like to make any adjustments!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We execute the code in the notebook and it runs perfectly. A model summary is printed, which includes the <code class="inlinecode">Conv2d</code> layer with 32 filters and 896 params, followed by a <code class="inlinecode">MaxPooling2D</code> layer, a flatten layer, which doesn’t have any parameters, then a dense layer with 64 neurons and the ReLU activation function, and finally the dense layer with 10 neurons and the softmax activation function.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_15_03.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.3: Code execution – baseline model summary</p>
    <p class="normal1">We will now<a id="_idIndexMarker640" class="calibre3"/> instruct ChatGPT to proceed to the next step.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed to the next step.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should <a id="_idIndexMarker641" class="calibre3"/>receive a response like the following where ChatGPT should provide the code for training the model.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure! The next step is to train the model on the preprocessed CIFAR-10 dataset.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Step 3: Model Training</span>
<span class="hljs-comment"># Train the model</span>
history = model.fit(x_train_resized, y_train,
                    epochs=<span class="hljs-attr">10</span>, 
                    batch_size=<span class="hljs-attr">32</span>,
                    validation_data=(x_test_resized, y_test))
</code></pre>
    <p class="normal1">Here’s an explanation of the code:</p>
    <ul class="calibre15">
      <li class="bulletlist">We train the model using the fit method on the preprocessed training data <code class="inlinecode">(x_train_resized)</code> and corresponding labels <code class="inlinecode">(y_train)</code>.</li>
      <li class="bulletlist1">We specify the number of training epochs (<code class="inlinecode">epochs=10</code>) to train the model for 10 iterations over the entire dataset.</li>
      <li class="bulletlist1">We set the batch size (<code class="inlinecode">batch_size=32</code>) to specify the number of samples per gradient update. It is a hyperparameter that determines how many samples are processed before updating the model’s parameters.</li>
      <li class="bulletlist1">We provide the validation data (<code class="inlinecode">validation_data=(x_test_resized, y_test)</code>) to evaluate the model’s performance on the testing data after each epoch.</li>
      <li class="bulletlist1">The <code class="inlinecode">fit</code> method returns a history object containing training metrics (e.g., loss and accuracy) for each epoch, which can be used for analysis and visualization.</li>
    </ul>
    <p class="normal1">Let me know if you have any questions or if you’d like to proceed with evaluating the model or making any adjustments!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We execute<a id="_idIndexMarker642" class="calibre3"/> the code and it runs without any errors. The model is trained for 10 epochs, after which we receive a validation accuracy of 62.6%, which is not bad for a basic model.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_15_04.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.4: Code execution – model training</p>
    <p class="normal1">We will now instruct ChatGPT to proceed to the next step to evaluate the model performance.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed to the next step.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT should provide the code for model evaluation along with comments.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure! The next step is to evaluate the trained model on the testing dataset and visualize its performance.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Step 4: Model Evaluation and Visualization</span>
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-comment"># Evaluate the model on the testing dataset</span>
test_loss, test_accuracy = model.evaluate(x_test_resized, y_test, verbose=<span class="hljs-attr">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Loss:"</span>, test_loss)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Accuracy:"</span>, test_accuracy)
<span class="hljs-comment"># Plot training history</span>
plt.plot(history.history[<span class="hljs-string">'accuracy'</span>], label=<span class="hljs-string">'Training Accuracy'</span>)
plt.plot(history.history[<span class="hljs-string">'val_accuracy'</span>], label=<span class="hljs-string">'Validation Accuracy'</span>)
plt.title(<span class="hljs-string">'Training and Validation Accuracy'</span>)
plt.xlabel(<span class="hljs-string">'Epoch'</span>)
plt.ylabel(<span class="hljs-string">'Accuracy'</span>)
plt.legend()
plt.show()
</code></pre>
    <p class="normal1">Here’s <a id="_idIndexMarker643" class="calibre3"/>what this code does:</p>
    <ul class="calibre15">
      <li class="bulletlist">We import <code class="inlinecode">matplotlib.pyplot</code> to visualize the training history.</li>
      <li class="bulletlist1">We evaluate the trained model on the testing dataset using the evaluate method, which returns the test loss and accuracy.</li>
      <li class="bulletlist1">We print the test loss and test accuracy to assess the model’s performance on unseen data.</li>
      <li class="bulletlist1">We plot the training and validation accuracy over epochs using <code class="inlinecode">matplotlib.pyplot</code>. The history object returned by the <code class="inlinecode">fit</code> method contains accuracy values for both training and validation datasets across epochs.</li>
      <li class="bulletlist1">The <code class="inlinecode">history.history['accuracy']</code> contains training accuracy values.</li>
      <li class="bulletlist1">The <code class="inlinecode">history.history['val_accuracy']</code> contains validation accuracy values.</li>
      <li class="bulletlist1">The plot helps us visualize how well the model is learning over time and whether it is overfitting or underfitting.</li>
    </ul>
    <p class="normal1">Let me know if you have any questions or if you’d like to analyze the results further!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We <a id="_idIndexMarker644" class="calibre3"/>execute the code and it runs without any errors. It evaluates the test loss and test accuracy (62.5%) and also plots the graph of training accuracy vs. validation accuracy, showing that model is not performing well on the validation set.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_15_05.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.5: Code execution – model evaluation</p>
    <p class="normal1">This<a id="_idIndexMarker645" class="calibre3"/> completes feature 1, where we achieved an accuracy of 0.6259 (62.59%) with our baseline CNN model. (Please note that you may receive different accuracy scores even after running the exact same code.) Next, we will move to the second feature of adding more layers to the model and learn how ChatGPT can assist us in that. </p>
    <h2 class="heading1" id="_idParaDest-331">Feature 2: Experimenting with the addition of convolutional layers</h2>
    <p class="normal">Now <a id="_idIndexMarker646" class="calibre3"/>that we have a baseline model architecture, let us try adding layers to it. We will apply the prompting strategy to improvise the model (LIFE 3.4) and ask ChatGPT to provide us the code for it, also note the importance of providing specific instructions by using the phrase (on top of our baseline model) (PIC 2.2) and keyword incrementally (PIC 2.2); without these, the response wouldn’t be fully consistent with our expectations.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">We received an accuracy of 62.59 with the baseline model, so now I would like to experiment with the addition of two consecutive layers of 64 filters first and then two consecutive layers of 128 filters on top of our baseline model. Then, let’s compare the result of these two incremental changes with our baseline model.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with the code for a modified model with consecutive layers of 64 filters and another one with consecutive layers of 128 filters. </p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure! Let’s first add two consecutive layers of 64 filters to the baseline model and train it again. After that, we’ll add two consecutive layers of 128 filters and train the model once more. Finally, we’ll compare the results of these two changes with the baseline model.</p>
    <p class="normal1">Here’s how we can modify the baseline model to include additional layers:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Define the modified model with two consecutive layers of 64 filters</span>
modified_model_64 = Sequential([
    Conv2D(<span class="hljs-attr">32</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>, <span class="hljs-attr">3</span>)),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Flatten(),
    Dense(<span class="hljs-attr">64</span>, activation=<span class="hljs-string">'relu'</span>),
    Dense(<span class="hljs-attr">10</span>, activation=<span class="hljs-string">'softmax'</span>)
])
<span class="hljs-comment"># Compile the modified model</span>
modified_model_64.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">'adam'</span>,
                          loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,
                          metrics=[<span class="hljs-string">'accuracy'</span>])
<span class="hljs-comment"># Display model summary</span>
modified_model_64.summary()
<span class="hljs-comment"># Train the modified model with two consecutive layers of 64 filters</span>
history_64 = modified_model_64.fit(x_train_resized, y_train,
                                    epochs=<span class="hljs-attr">10</span>, 
                                    batch_size=<span class="hljs-attr">32</span>,
                                    validation_data=(x_test_resized, y_test))
<span class="hljs-comment"># Evaluate the modified model on the testing dataset</span>
test_loss_64, test_accuracy_64 = modified_model_64.evaluate(x_test_resized, y_test, verbose=<span class="hljs-attr">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Loss (Modified Model with 64 Filters):"</span>, test_loss_64)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Accuracy (Modified Model with 64 Filters):"</span>, test_accuracy_64)
</code></pre>
    <p class="normal1">Now, let’s <a id="_idIndexMarker647" class="calibre3"/>explain the modifications:</p>
    <ul class="calibre15">
      <li class="bulletlist">We define the modified model (<code class="inlinecode">modified_model_64</code>) by adding two consecutive convolutional layers with 64 filters each after the baseline model’s architecture.</li>
      <li class="bulletlist1">We compile the modified model with the same settings as the baseline model.</li>
      <li class="bulletlist1">We train the modified model (<code class="inlinecode">modified_model_64</code>) on the preprocessed training data (<code class="inlinecode">x_train_resized</code>).</li>
      <li class="bulletlist1">We evaluate the performance of the modified model on the testing dataset (<code class="inlinecode">x_test_resized</code>) and print the test loss and accuracy.</li>
    </ul>
    <p class="normal1">Next, we’ll <a id="_idIndexMarker648" class="calibre3"/>repeat the process for adding two consecutive layers of 128 filters:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Define the modified model with two consecutive layers of 128 filters</span>
modified_model_128 = Sequential([
    Conv2D(<span class="hljs-attr">32</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>, <span class="hljs-attr">3</span>)),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'</span><span class="hljs-string">relu'</span>),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Flatten(),
    Dense(<span class="hljs-attr">64</span>, activation=<span class="hljs-string">'relu'</span>),
    Dense(<span class="hljs-attr">10</span>, activation=<span class="hljs-string">'softmax'</span>)
])
<span class="hljs-comment"># Compile the modified model</span>
modified_model_128.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">'adam'</span>,
                           loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,
                           metrics=[<span class="hljs-string">'accuracy'</span>])
<span class="hljs-comment"># Display model summary</span>
modified_model_128.summary()
<span class="hljs-comment"># Train the modified model with two consecutive layers of 128 filters</span>
history_128 = modified_model_128.fit(x_train_resized, y_train,
                                     epochs=<span class="hljs-attr">10</span>, 
                                     batch_size=<span class="hljs-attr">32</span>,
                                     validation_data=(x_test_resized, y_test))
<span class="hljs-comment"># Evaluate the modified model on the testing dataset</span>
test_loss_128, test_accuracy_128 = modified_model_128.evaluate(x_test_resized, y_test, verbose=<span class="hljs-attr">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Loss (Modified Model with 128 Filters):"</span>, test_loss_128)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Accuracy (Modified Model with 128 Filters):"</span>, test_accuracy_128)
</code></pre>
    <p class="normal1">This code follows the same structure as the previous modification but adds two consecutive convolutional layers with 128 filters each. We train and evaluate the model accordingly.</p>
    <p class="normal1">Let me <a id="_idIndexMarker649" class="calibre3"/>know if you have any questions or if you’d like to proceed with the modifications!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We first execute the code that defines the two additional layers with 64 filters. It runs perfectly fine, training the model and achieving an improved accuracy of 71%.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_15_06.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.6: Adding two consecutive layers with 64 filters to the model</p>
    <p class="normal1">Next, we <a id="_idIndexMarker650" class="calibre3"/>execute the code to add further depth to the model by adding two more layers with 128 filters. In this case, the code results in an error, so we will use a prompting strategy and provide the error back to ChatGPT.</p>
    <p class="normal1">You should see a <code class="inlinecode">ValueError</code> from running the code.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">We received <a id="_idIndexMarker651" class="calibre3"/>the below error. Also, ensure that maxpooling doesn’t reduce the dimension too much for 128 filters. Error is below:</p>
    <pre class="programlisting"><code class="hljs-code">ValueError: Exception encountered when calling layer "conv2d_38" (type Conv2D).
Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_38/Conv2D}} = Conv2D[T=DT_FLOAT, data_format="NHWC", dilations=[1, 1, 1, 1], explicit_paddings=[], padding="VALID", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_38/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,128].
Call arguments received by layer "conv2d_38" (type Conv2D):
  inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32).
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with the modified code to resolve the issue. </p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">It seems we’re encountering an issue where the dimensions after the last max pooling layer are too small for the subsequent convolutional layer with 128 filters. To address this, we’ll adjust the architecture to ensure compatibility between layers.</p>
    <p class="normal1">Here’s <a id="_idIndexMarker652" class="calibre3"/>the corrected code:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Define the modified model with two consecutive layers of 128 filters added to the 64-layer model</span>
modified_model_64_to_128 = Sequential([
    Conv2D(<span class="hljs-attr">32</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>, <span class="hljs-attr">3</span>)),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>),  <span class="hljs-comment"># Add padding</span>
    Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>),  <span class="hljs-comment"># Add padding</span>
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Flatten(),
    Dense(<span class="hljs-attr">64</span>, activation=<span class="hljs-string">'relu'</span>),
    Dense(<span class="hljs-attr">10</span>, activation=<span class="hljs-string">'softmax'</span>)
])
<span class="hljs-comment"># Compile the modified model</span>
modified_model_64_to_128.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">'adam'</span>,
                                  loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,
                                  metrics=[<span class="hljs-string">'accuracy'</span>])
<span class="hljs-comment"># Display model summary</span>
modified_model_64_to_128.summary()
<span class="hljs-comment"># Train the modified model with two consecutive layers of 128 filters added to the 64-layer model</span>
history_64_to_128 = modified_model_64_to_128.fit(x_train_resized, y_train,
                                                 epochs=<span class="hljs-attr">10</span>, 
                                                 batch_size=<span class="hljs-attr">32</span>,
                                                 validation_data=(x_test_resized, y_test))
<span class="hljs-comment"># Evaluate the modified model on the testing dataset</span>
test_loss_64_to_128, test_accuracy_64_to_128 = modified_model_64_to_128.evaluate(x_test_resized, y_test, verbose=<span class="hljs-attr">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Loss (Modified Model with 64 to 128 Filters):"</span>, test_loss_64_to_128)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Accuracy (Modified Model with 64 to 128 Filters):"</span>, test_accuracy_64_to_128)
</code></pre>
    <p class="normal1">In this modification:</p>
    <ul class="calibre15">
      <li class="bulletlist">We’ve removed the max pooling layer after the last convolutional layer with 64 filters to ensure that the feature map dimensions are not reduced too much before applying the subsequent convolutional layers with 128 filters.</li>
      <li class="bulletlist1">We’ve added <code class="inlinecode">same</code> padding to the convolutional layers with 128 filters to ensure compatibility with the input dimensions.</li>
      <li class="bulletlist1">The rest of the architecture remains the same.</li>
    </ul>
    <p class="normal1">This<a id="_idIndexMarker653" class="calibre3"/> adjustment should resolve the issue, and the model should compile and train properly. Let me know if you have any questions or if you encounter any further issues!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">Let’s execute the code, which removes some max pooling layers and also has <code class="inlinecode">padding = 'same'</code> added to ensure the dimensions are compatible. It runs successfully, training the model but reducing the accuracy to 69%.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B21232_15_07.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.7: Added layers with 128 filters</p>
    <p class="normal1">Based on<a id="_idIndexMarker654" class="calibre3"/> these results, we can observe that the addition of more layers achieved a slightly higher accuracy compared to the baseline model. However, the differences in accuracy are relatively small, indicating that the addition of layers did not significantly improve the model’s performance and<a id="_idIndexMarker655" class="calibre3"/> the model is also still not regularized. Let’s move on to the next feature and experiment with dropout regularization. </p>
    <h2 class="heading1" id="_idParaDest-332">Feature 3: Incorporating dropout regularization</h2>
    <p class="normal">Now that <a id="_idIndexMarker656" class="calibre3"/>we have learned how to add more layers, we will now experiment with a dropout layer. We will apply the prompting strategy to improvise the model (LIFE 3.4) and ask ChatGPT to provide us the code for it. </p>
    <p class="normal1">Also note that we have applied the prompting strategy of using specific instructions (PIC 2.2) by asking it to add the dropout over the previously provided code.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">The model accuracy of the baseline model was 62.5%, with additional layers of 64 filters it was 71%, and the further addition of layers with 128 filters reduced it to 69%. Can we please apply dropout regularization to the model code given by you in your previous message?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with the code for the addition of a dropout layer.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure, let’s add dropout regularization to the modified model with two consecutive layers of 128 filters. Dropout regularization helps prevent overfitting by randomly dropping a fraction of the units (neurons) during training. Here’s how we can modify the model to include dropout layers:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dropout
<span class="hljs-comment"># Define the modified model with dropout regularization</span>
modified_model_64_to_128_with_dropout = Sequential([
    Conv2D(<span class="hljs-attr">32</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>, <span class="hljs-attr">3</span>)),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>),
    Dropout(<span class="hljs-attr">0.25</span>),  <span class="hljs-comment"># Add dropout regularization with a dropout rate of 25%</span>
    Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'</span><span class="hljs-string">relu'</span>, padding=<span class="hljs-string">'same'</span>),
    Dropout(<span class="hljs-attr">0.25</span>),  <span class="hljs-comment"># Add dropout regularization with a dropout rate of 25%</span>
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Flatten(),
    Dense(<span class="hljs-attr">64</span>, activation=<span class="hljs-string">'relu'</span>),
    Dropout(<span class="hljs-attr">0.5</span>),  <span class="hljs-comment"># Add dropout regularization with a dropout rate of 50%</span>
    Dense(<span class="hljs-attr">10</span>, activation=<span class="hljs-string">'softmax'</span>)
])
<span class="hljs-comment"># Compile the modified model with dropout regularization</span>
modified_model_64_to_128_with_dropout.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">'adam'</span>,
                                              loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,
                                              metrics=[<span class="hljs-string">'accuracy'</span>])
<span class="hljs-comment"># Display model summary</span>
modified_model_64_to_128_with_dropout.summary()
<span class="hljs-comment"># Train the modified model with dropout regularization</span>
history_64_to_128_with_dropout = modified_model_64_to_128_with_dropout.fit(x_train_resized, y_train,
                                                                           epochs=<span class="hljs-attr">10</span>,
                                                                           batch_size=<span class="hljs-attr">32</span>,
                                                                           validation_data=(x_test_resized, y_test))
<span class="hljs-comment"># Evaluate the modified model with dropout regularization on the testing dataset</span>
test_loss_64_to_128_with_dropout, test_accuracy_64_to_128_with_dropout = modified_model_64_to_128_with_dropout.evaluate(x_test_resized, y_test, verbose=<span class="hljs-attr">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Loss (Modified Model with Dropout):"</span>, test_loss_64_to_128_with_dropout)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Accuracy (Modified Model with Dropout):"</span>, test_accuracy_64_to_128_with_dropout)
</code></pre>
    <p class="normal1">In <a id="_idIndexMarker657" class="calibre3"/>this modification:</p>
    <ul class="calibre15">
      <li class="bulletlist">We add dropout layers after the convolutional layers with 128 filters. We set the dropout rates to 25% and 50% for the first and last dropout layers, respectively. These values can be adjusted based on experimentation and the level of regularization needed.</li>
      <li class="bulletlist1">We compile and train the modified model with dropout regularization using the same settings as before.</li>
      <li class="bulletlist1">We evaluate the performance of the modified model with dropout regularization on the testing dataset and print the test loss and accuracy.</li>
    </ul>
    <p class="normal1">Adding <a id="_idIndexMarker658" class="calibre3"/>dropout regularization may help improve the generalization performance of the model and reduce overfitting. Let me know if you have any questions or if you’d like to explore further!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We execute the code, which defines a model with a dropout layer. It also trains and evaluates the performance of the model and prints the model summary covering loss and accuracy. Note that the dropout layer does not add any parameters to the model.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_15_08.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.8: Code execution – dropout layer</p>
    <p class="normal1">We can <a id="_idIndexMarker659" class="calibre3"/>see that there is not much difference between the accuracies, so we will apply the Learn prompting strategy (LIFE 3.1) and ask ChatGPT to provide the plot of the loss and accuracy to see the impact of regularization.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <pre class="programlisting"><code class="hljs-code">Test Loss (Modified Model with Dropout): 0.876133382320404 
Test Accuracy (Modified Model with Dropout): 0.7014999985694885  
</code></pre>
    <p class="normal1">Can you<a id="_idIndexMarker660" class="calibre3"/> please provide the plots for loss and accuracy to see if there has been any regularization and also explain it?</p>
    <p class="normal1"><strong class="screentext">[End of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT provides the code and explains the significance of the plots.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Certainly! Let’s plot the training and validation loss and accuracy curves for the modified model with<a id="_idIndexMarker661" class="calibre3"/> dropout regularization. This will help us visualize how dropout regularization affects the training process and the model’s performance.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-comment"># Plot training history for loss</span>
plt.plot(history_64_to_128_with_dropout.history[<span class="hljs-string">'loss'</span>], label=<span class="hljs-string">'</span><span class="hljs-string">Training Loss'</span>)
plt.plot(history_64_to_128_with_dropout.history[<span class="hljs-string">'val_loss'</span>], label=<span class="hljs-string">'Validation Loss'</span>)
plt.title(<span class="hljs-string">'Training and Validation Loss'</span>)
plt.xlabel(<span class="hljs-string">'Epoch'</span>)
plt.ylabel(<span class="hljs-string">'Loss'</span>)
plt.legend()
plt.show()
<span class="hljs-comment"># Plot training history for accuracy</span>
plt.plot(history_64_to_128_with_dropout.history[<span class="hljs-string">'accuracy'</span>], label=<span class="hljs-string">'Training Accuracy'</span>)
plt.plot(history_64_to_128_with_dropout.history[<span class="hljs-string">'val_accuracy'</span>], label=<span class="hljs-string">'</span><span class="hljs-string">Validation Accuracy'</span>)
plt.title(<span class="hljs-string">'Training and Validation Accuracy'</span>)
plt.xlabel(<span class="hljs-string">'Epoch'</span>)
plt.ylabel(<span class="hljs-string">'Accuracy'</span>)
plt.legend()
plt.show()
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Training Loss vs. Validation Loss</strong>: This plot shows the trend of training and validation loss over epochs. If there is a large gap between training<a id="_idIndexMarker662" class="calibre3"/> and validation loss, it <a id="_idIndexMarker663" class="calibre3"/>indicates overfitting. Dropout regularization aims to reduce overfitting by preventing the model from becoming overly reliant on specific features, thereby reducing the gap between training and validation loss.</li>
      <li class="bulletlist1"><strong class="screentext">Training Accuracy vs. Validation Accuracy</strong>: This plot shows the trend of training<a id="_idIndexMarker664" class="calibre3"/> and validation accuracy<a id="_idIndexMarker665" class="calibre3"/> over epochs. Dropout regularization can also help improve generalization performance, leading to better validation accuracy, especially if overfitting was present in the model.</li>
    </ul>
    <p class="normal1">By <a id="_idIndexMarker666" class="calibre3"/>observing these plots, we can assess whether dropout regularization<a id="_idIndexMarker667" class="calibre3"/> effectively mitigated overfitting and improved the model’s generalization performance. Let me know if you have any questions or if you need further explanation!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We will execute the code and plot the graphs to understand the impact of dropout.</p>
    <figure class="mediaobject"><img alt="A graph of a training and vallation accuracy  Description automatically generated" src="../Images/B21232_15_09.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.9: Effect of the dropout layer</p>
    <p class="normal1">The output <a id="_idIndexMarker668" class="calibre3"/>graphs show the training and validation loss and accuracy for a model trained on the CIFAR-10 dataset with a dropout layer. Both losses decrease over epochs while the accuracy improves, indicating effective learning. The small gap between training and validation metrics suggests minimal overfitting, likely aided by the dropout layer. Overall, the model generalizes well to new data, demonstrating good performance. </p>
    <h2 class="heading1" id="_idParaDest-333">Feature 4: Implementing batch normalization</h2>
    <p class="normal">We will apply the <a id="_idIndexMarker669" class="calibre3"/>prompting strategy to improvise the model (LIFE 3.4) and ask ChatGPT to provide us the code for adding batch normalization to the previously provided code.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">I want to apply the <a id="_idIndexMarker670" class="calibre3"/>batch normalization on the previously provided code.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with the code for batch normalization on our existing model.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure! We can apply batch normalization to the convolutional layers of the model to improve training stability and convergence speed. Here’s how we can modify the model to include batch normalization layers:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> BatchNormalization
<span class="hljs-comment"># Define the modified model with batch normalization</span>
modified_model_64_to_128_with_batchnorm = Sequential([
    Conv2D(<span class="hljs-attr">32</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>, <span class="hljs-attr">3</span>)),
    BatchNormalization(),  <span class="hljs-comment"># Add batch normalization</span>
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    BatchNormalization(),  <span class="hljs-comment"># Add batch normalization</span>
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
    Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>),
    BatchNormalization(),  <span class="hljs-comment"># Add batch normalization</span>
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>),
    BatchNormalization(),  <span class="hljs-comment"># Add batch normalization</span>
    MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
    Flatten(),
    Dense(<span class="hljs-attr">64</span>, activation=<span class="hljs-string">'relu'</span>),
    BatchNormalization(),  <span class="hljs-comment"># Add batch normalization</span>
    Dense(<span class="hljs-attr">10</span>, activation=<span class="hljs-string">'softmax'</span>)
])
<span class="hljs-comment"># Compile the modified model with batch normalization</span>
modified_model_64_to_128_with_batchnorm.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">'adam'</span>,
                                                loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,
                                                metrics=[<span class="hljs-string">'accuracy'</span>])
<span class="hljs-comment"># Display model summary</span>
modified_model_64_to_128_with_batchnorm.summary()
<span class="hljs-comment"># Train the modified model with batch normalization</span>
history_64_to_128_with_batchnorm = modified_model_64_to_128_with_batchnorm.fit(x_train_resized, y_train,
                                                                               epochs=<span class="hljs-attr">10</span>,
                                                                               batch_size=<span class="hljs-attr">32</span>,
                                                                               validation_data=(x_test_resized, y_test))
<span class="hljs-comment"># Evaluate the modified model with batch normalization on the testing dataset</span>
test_loss_64_to_128_with_batchnorm, test_accuracy_64_to_128_with_batchnorm = modified_model_64_to_128_with_batchnorm.evaluate(x_test_resized, y_test, verbose=<span class="hljs-attr">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Loss (Modified Model with Batch Normalization):"</span>, test_loss_64_to_128_with_batchnorm)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Test Accuracy (Modified Model with Batch Normalization):"</span>, test_accuracy_64_to_128_with_batchnorm)
</code></pre>
    <p class="normal1">In this modification:</p>
    <ul class="calibre15">
      <li class="bulletlist">We add <code class="inlinecode">BatchNormalization</code> layers <a id="_idIndexMarker671" class="calibre3"/>after each convolutional layer. Batch normalization normalizes the activations of the previous layer at each batch, making training more stable and accelerating convergence.</li>
      <li class="bulletlist1">We compile and train the modified model with batch normalization using the same settings as before.</li>
      <li class="bulletlist1">We evaluate the performance of the modified model with batch normalization on the testing dataset and print the test loss and accuracy.</li>
    </ul>
    <p class="normal1">Adding <a id="_idIndexMarker672" class="calibre3"/>batch normalization can improve the performance and stability of the model during training. Let me know if you have any questions or if you’d like further explanation!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We will execute the code, evaluate the model’s performance, and print the results. Note that batch normalization adds a small number of parameters, unlike dropout or maxpooling.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_15_10.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.10: Batch normalization</p>
    <p class="normal1">We can<a id="_idIndexMarker673" class="calibre3"/> see that there are some non-trainable parameters. Let us make use of the Learn prompting strategy (LIFE 3.1) to understand the calculations of non-trainable parameters.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you please explain the calculation of 832 in the model summary?</p>
    <pre class="programlisting"><code class="hljs-code">"sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_5 (Conv2D)           (None, 30, 30, 32)        896       
                                                                 
 batch_normalization (Batch  (None, 30, 30, 32)        128       
 Normalization)                                                  
                                                                 
 max_pooling2d_3 (MaxPoolin  (None, 15, 15, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_6 (Conv2D)           (None, 13, 13, 64)        18496     
                                                                 
 batch_normalization_1 (Bat  (None, 13, 13, 64)        256       
 chNormalization)                                                
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 6, 6, 64)          0         
 g2D)                                                            
                                                                 
 conv2d_7 (Conv2D)           (None, 4, 4, 64)          36928     
                                                                 
 conv2d_8 (Conv2D)           (None, 4, 4, 128)         73856     
                                                                 
 batch_normalization_2 (Bat  (None, 4, 4, 128)         512       
 chNormalization)                                                
                                                                 
 max_pooling2d_5 (MaxPoolin  (None, 2, 2, 128)         0         
 g2D)                                                            
                                                                 
 conv2d_9 (Conv2D)           (None, 2, 2, 128)         147584    
                                                                 
 batch_normalization_3 (Bat  (None, 2, 2, 128)         512       
 chNormalization)                                                
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 1, 1, 128)         0         
 g2D)                                                            
                                                                 
 flatten_1 (Flatten)         (None, 128)               0         
                                                                 
 dense_2 (Dense)             (None, 64)                8256      
                                                                 
 batch_normalization_4 (Bat  (None, 64)                256       
 chNormalization)                                                
                                                                 
 dense_3 (Dense)             (None, 10)                650       
                                                                 
=================================================================
Total params: 288330 (1.10 MB)
Trainable params: 287498 (1.10 MB)
Non-trainable params: 832 (3.25 KB)
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with an explanation of the calculation of non-trainable parameters.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">In the <a id="_idIndexMarker674" class="calibre3"/>model you’ve described, the non-trainable parameters are 832, which specifically come from the batch normalization layers. Here’s how this number is calculated:</p>
    <p class="normal1">Components of <a id="_idIndexMarker675" class="calibre3"/>Batch Normalization</p>
    <p class="normal1">Each batch normalization layer introduces parameters that are used to normalize the outputs of the previous layer. Specifically, these parameters are:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Gamma (scale factor)</strong></li>
      <li class="bulletlist1"><strong class="screentext">Beta (shift factor)</strong></li>
      <li class="bulletlist1"><strong class="screentext">Moving average of means</strong></li>
      <li class="bulletlist1"><strong class="screentext">Moving average of variances</strong></li>
    </ul>
    <p class="normal1">The gamma and beta parameters are trainable, while the moving means and variances are non-trainable. Each of these groups (gamma/beta and moving mean/variance) has as many elements as there are channels in the input to the batch normalization layer.</p>
    <p class="normal1">Calculation</p>
    <p class="normal1">Based on your <a id="_idIndexMarker676" class="calibre3"/>model configuration:</p>
    <p class="normal1"><strong class="screentext">Batch Normalization after first Conv2D layer (32 channels):</strong></p>
    <ul class="calibre15">
      <li class="bulletlist">Moving means: 32</li>
      <li class="bulletlist1">Moving variances: 32</li>
    </ul>
    <p class="normal1"><strong class="screentext">Batch Normalization after second Conv2D layer (64 channels):</strong></p>
    <ul class="calibre15">
      <li class="bulletlist">Moving means: 64</li>
      <li class="bulletlist1">Moving variances: 64</li>
    </ul>
    <p class="normal1"><strong class="screentext">Batch Normalization after third Conv2D layer (128 channels):</strong></p>
    <ul class="calibre15">
      <li class="bulletlist">Moving means: 128</li>
      <li class="bulletlist1">Moving variances: 128</li>
    </ul>
    <p class="normal1"><strong class="screentext">Batch Normalization after fourth Conv2D layer (128 channels):</strong></p>
    <ul class="calibre15">
      <li class="bulletlist">Moving means: 128</li>
      <li class="bulletlist1">Moving variances: 128</li>
    </ul>
    <p class="normal1"><strong class="screentext">Batch Normalization after Dense layer (64 units):</strong></p>
    <ul class="calibre15">
      <li class="bulletlist">Moving means: 64</li>
      <li class="bulletlist1">Moving variances: 64</li>
    </ul>
    <p class="normal1">Total Non-Trainable Parameters</p>
    <p class="normal1">Summing these values gives the total number of non-trainable parameters: <code class="inlinecode">[ (32 + 32) + (64 + 64) + (128 + 128) + (128 + 128) + (64 + 64) = 832 ]</code></p>
    <p class="normal1">Each <a id="_idIndexMarker677" class="calibre3"/>batch normalization layer contributes twice the number of its input’s channels to the non-trainable parameter count (once for moving means and once for moving variances). This results in a total of 832 non-trainable parameters for your model.</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">Now that we have learned how to add batch normalization and also the calculation of non-trainable parameters, let us move to the next feature and try different optimizers.</p>
    <h2 class="heading1" id="_idParaDest-334">Feature 5: Optimizing with different optimizers</h2>
    <p class="normal">We will <a id="_idIndexMarker678" class="calibre3"/>apply the prompting strategy to improvise the model (LIFE 3.4) and ask ChatGPT to provide us the code for experimenting with different optimizers such as SGD, Adam, and RMSProp.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you please provide me with code for the SGD, Adam, and RMSprop optimizers, and compare the previously provided code for the model and its performance for various optimizer combinations?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with the code for different optimizers along with comparison results.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Certainly! We can compare the performance of the model with different optimizers such as SGD, Adam, and RMSprop. Here’s how we can modify the model and train it with different optimizers:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Import optimizers</span>
<span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> SGD, Adam, RMSprop
<span class="hljs-comment"># Define the optimizers</span>
optimizers = [SGD(), Adam(), RMSprop()]
<span class="hljs-comment"># Define lists to store test accuracies for each optimizer</span>
test_accuracies = []
<span class="hljs-comment"># Iterate over each optimizer</span>
<span class="hljs-keyword">for</span> optimizer <span class="hljs-keyword">in</span> optimizers:
    <span class="hljs-comment"># Define the modified model with batch normalization and the current optimizer</span>
    modified_model = Sequential([
        Conv2D(<span class="hljs-attr">32</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>, <span class="hljs-attr">3</span>)),
        BatchNormalization(),
        MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
        Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
        BatchNormalization(),
        MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
        Conv2D(<span class="hljs-attr">64</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>),
        Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>),
        BatchNormalization(),
        MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
        Conv2D(<span class="hljs-attr">128</span>, (<span class="hljs-attr">3</span>, <span class="hljs-attr">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>),
        BatchNormalization(),
        MaxPooling2D((<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>)),
        Flatten(),
        Dense(<span class="hljs-attr">64</span>, activation=<span class="hljs-string">'relu'</span>),
        BatchNormalization(),
        Dense(<span class="hljs-attr">10</span>, activation=<span class="hljs-string">'softmax'</span>)
    ])
    <span class="hljs-comment"># Compile the model with the current optimizer</span>
    modified_model.<span class="hljs-built_in">compile</span>(optimizer=optimizer,
                           loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,
                           metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-comment"># Train the model with the current optimizer</span>
    history = modified_model.fit(x_train_resized, y_train,
                                 epochs=<span class="hljs-attr">10</span>,
                                 batch_size=<span class="hljs-attr">32</span>,
                                 validation_data=(x_test_resized, y_test),
                                 verbose=<span class="hljs-attr">0</span>)
    <span class="hljs-comment"># Evaluate the model with the current optimizer on the testing dataset</span>
    test_loss, test_accuracy = modified_model.evaluate(x_test_resized, y_test, verbose=<span class="hljs-attr">0</span>)
    <span class="hljs-comment"># Append the test accuracy to the list</span>
    test_accuracies.append(test_accuracy)
    <span class="hljs-comment"># Print the test accuracy for the current optimizer</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Test Accuracy (Optimizer: </span><span class="hljs-name">{optimizer.__class__.__name__}</span><span class="hljs-string">): </span><span class="hljs-name">{test_accuracy}</span><span class="hljs-string">"</span>)
<span class="hljs-comment"># Plot the test accuracies for each optimizer</span>
plt.bar([<span class="hljs-string">'SGD'</span>, <span class="hljs-string">'Adam'</span>, <span class="hljs-string">'RMSprop'</span>], test_accuracies)
plt.title(<span class="hljs-string">'Test Accuracy Comparison for Different Optimizers'</span>)
plt.xlabel(<span class="hljs-string">'Optimizer'</span>)
plt.ylabel(<span class="hljs-string">'Test Accuracy'</span>)
plt.show()
</code></pre>
    <p class="normal1">In this code:</p>
    <ul class="calibre15">
      <li class="bulletlist">We<a id="_idIndexMarker679" class="calibre3"/> import the <code class="inlinecode">SGD</code>, <code class="inlinecode">Adam</code>, and <code class="inlinecode">RMSprop</code> optimizers from <code class="inlinecode">tensorflow.keras.optimizers</code>.</li>
      <li class="bulletlist1">We define a list of optimizers to iterate over.</li>
      <li class="bulletlist1">For each optimizer, we define the model with batch normalization and the current optimizer.</li>
      <li class="bulletlist1">We compile and train the model with the current optimizer.</li>
      <li class="bulletlist1">We evaluate the model’s performance on the testing dataset with the current optimizer.</li>
      <li class="bulletlist1">We print the test accuracy for each optimizer and store the test accuracies in a list.</li>
      <li class="bulletlist1">Finally, we plot the test accuracies for each optimizer to compare their performance.</li>
    </ul>
    <p class="normal1">This code allows us to compare the performance of the model trained with different optimizers. Let me know if you have any questions or if you’d like further explanation!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We execute the code, which defines the models with different optimizers. It also trains the models, evaluates their performance, and prints the results of the comparison of their performance.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_15_11.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 15.11: Code execution – different optimizers</p>
    <p class="normal1">Based on these <a id="_idIndexMarker680" class="calibre3"/>results, we can observe that the RMSprop optimizer achieved the highest accuracy, followed by Adam and SGD. This indicates that RMSprop performed better in optimizing the model’s parameters and improving its performance on the testing data.</p>
    <p class="normal1">Let us move on to our last feature and apply the DavidNet architecture.</p>
    <h2 class="heading1" id="_idParaDest-335">Feature 6: Applying the DavidNet architecture</h2>
    <p class="normal">We will apply <a id="_idIndexMarker681" class="calibre3"/>the prompting strategy to improvise the model (LIFE 3.4) and ask ChatGPT to provide us the code for DavidNet and also learn about it using the Learn prompting strategy (LIFE 3.1).</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Tell me what is so special about <a id="_idIndexMarker682" class="calibre3"/>DavidNet architecture?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT will provide us with an explanation of DavidNet.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">DavidNet architecture is<a id="_idIndexMarker683" class="calibre3"/> notable for its simplicity and effectiveness in achieving high accuracy on image classification tasks, particularly on the CIFAR-10 dataset. Here are some key aspects that make DavidNet special:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Residual Blocks</strong>: DavidNet utilizes<a id="_idIndexMarker684" class="calibre3"/> residual blocks, which allow for easier training of very deep neural networks. Residual connections enable the network to learn residual mappings, making it easier to train deeper networks without vanishing or exploding gradients.</li>
      <li class="bulletlist1"><strong class="screentext">Batch Normalization</strong>: Batch normalization<a id="_idIndexMarker685" class="calibre3"/> is applied after each convolutional layer, which helps stabilize and speed up the training process by normalizing the activations of each layer. This improves the convergence of the model during training and helps prevent overfitting.</li>
      <li class="bulletlist1"><strong class="screentext">Skip Connections</strong>: Skip connections (also known as identity shortcuts) are used within residual blocks. These <a id="_idIndexMarker686" class="calibre3"/>connections allow the gradient to flow directly through the network, mitigating the vanishing gradient problem and facilitating the training of very deep networks.</li>
      <li class="bulletlist1"><strong class="screentext">Max Pooling</strong>: Max pooling<a id="_idIndexMarker687" class="calibre3"/> layers are used to reduce the spatial dimensions of the feature maps, aiding in the extraction of important features while reducing computational complexity.</li>
      <li class="bulletlist1"><strong class="screentext">Dense Layers</strong>: Fully <a id="_idIndexMarker688" class="calibre3"/>connected (dense) layers are employed at the end of the network to perform classification based on the learned features from the convolutional layers.</li>
      <li class="bulletlist1"><strong class="screentext">Learning Rate Schedule</strong>: DavidNet uses a learning rate schedule<a id="_idIndexMarker689" class="calibre3"/> with warmup epochs and a decay factor to gradually adjust the learning rate during training. This helps to stabilize training and improve convergence.</li>
      <li class="bulletlist1"><strong class="screentext">Regularization</strong>: Although not explicitly mentioned in the architecture, regularization<a id="_idIndexMarker690" class="calibre3"/> techniques such as weight decay can be applied to prevent overfitting and improve generalization performance.</li>
    </ul>
    <p class="normal1">Overall, DavidNet <a id="_idIndexMarker691" class="calibre3"/>strikes a balance between model complexity and effectiveness, demonstrating that even relatively simple architectures can achieve impressive results with appropriate design choices and training strategies.</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We will try to learn about the residual blocks and ask a follow-up question to ChatGPT.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">What are residual blocks?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT provides us with an explanation about residual blocks.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Residual blocks are a fundamental component of deep neural networks, particularly in architectures like ResNet and its variants. They are designed to address the vanishing gradient problem that occurs during the training of very deep networks.</p>
    <p class="normal1">Residual blocks are composed of two main paths: the identity path and the shortcut path. The identity path is the main path through the block, while the shortcut path provides a direct connection for the input to skip one or more layers.</p>
    <p class="normal1">Here’s a basic overview of how residual blocks work:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Identity Path</strong>: The input to the <a id="_idIndexMarker692" class="calibre3"/>residual block is passed through a series of convolutional layers, batch normalization, and activation functions. This sequence of operations allows the network to learn a representation of the input data.</li>
      <li class="bulletlist1"><strong class="screentext">Shortcut Path</strong>: The<a id="_idIndexMarker693" class="calibre3"/> original input to the residual block (identity) is passed through a separate path, bypassing some of the convolutional layers. This path is known as the “shortcut” or “skip” connection.</li>
      <li class="bulletlist1"><strong class="screentext">Merge Operation</strong>: The outputs from the identity path and the shortcut path are combined using element-wise addition. This merge operation<a id="_idIndexMarker694" class="calibre3"/> adds the original input to the output of the convolutional layers.</li>
      <li class="bulletlist1"><strong class="screentext">Activation Function</strong>: Finally, the<a id="_idIndexMarker695" class="calibre3"/> combined output undergoes an activation <a id="_idIndexMarker696" class="calibre3"/>function, typically a <strong class="screentext">ReLU</strong> (<strong class="screentext">Rectified Linear Unit</strong>) activation, to introduce non-linearity.</li>
    </ul>
    <p class="normal1">The key idea<a id="_idIndexMarker697" class="calibre3"/> behind residual blocks is that the shortcut connection allows the gradient to flow more easily through the network during backpropagation. If the identity path (convolutional layers) learns to approximate the identity function, the residual block can learn to adjust the output by a small residual mapping, hence the name “residual block.”</p>
    <p class="normal1">By enabling the direct propagation of the input signal through the shortcut connection, residual blocks mitigate the vanishing gradient problem and facilitate the training of very deep neural networks. This architecture has been highly successful in various tasks, leading to the development of deeper and more accurate models.</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We will now ask ChatGPT to provide us the code for DavidNet and here we will give some information to ChatGPT that we obtained from an internet search to achieve better accuracy using CIFAR-10.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you give me the code for DavidNet which offers better accuracy? The hyperparameters used in DavidNet include:</p>
    <ul class="calibre15">
      <li class="bulletlist">Batch size: 512</li>
      <li class="bulletlist1">Momentum: 0.9</li>
      <li class="bulletlist1">Weight decay: 0.000125</li>
      <li class="bulletlist1">Learning rate: 0.4</li>
      <li class="bulletlist1">Number of epochs: 24</li>
      <li class="bulletlist1">Warmup epochs: 5</li>
    </ul>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response like the following where ChatGPT understands the request and provides us with the code for DavidNet.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Certainly! Here’s<a id="_idIndexMarker698" class="calibre3"/> an implementation of DavidNet with the specified hyperparameters:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Model
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Add
<span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> SGD
<span class="hljs-keyword">from</span> tensorflow.keras.callbacks <span class="hljs-keyword">import</span> LearningRateScheduler
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">def</span> <span class="hljs-meta">davidnet</span>():
    input_layer = Input(shape=(<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>, <span class="hljs-attr">3</span>))
    <span class="hljs-comment"># Initial convolutional layer</span>
    x = Conv2D(<span class="hljs-attr">64</span>, kernel_size=<span class="hljs-attr">3</span>, padding=<span class="hljs-string">'same'</span>)(input_layer)
    x = BatchNormalization()(x)
    x = Activation(<span class="hljs-string">'relu'</span>)(x)
    <span class="hljs-comment"># Stack of residual blocks</span>
    num_residual_blocks = <span class="hljs-attr">4</span>
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residual_blocks):
        y = x
        x = Conv2D(<span class="hljs-attr">64</span>, kernel_size=<span class="hljs-attr">3</span>, padding=<span class="hljs-string">'same'</span>)(x)
        x = BatchNormalization()(x)
        x = Activation(<span class="hljs-string">'relu'</span>)(x)
        x = Conv2D(<span class="hljs-attr">64</span>, kernel_size=<span class="hljs-attr">3</span>, padding=<span class="hljs-string">'same'</span>)(x)
        x = BatchNormalization()(x)
        x = Add()([x, y])  <span class="hljs-comment"># Skip connection</span>
        x = Activation(<span class="hljs-string">'relu'</span>)(x)
    <span class="hljs-comment"># Max pooling layer</span>
    x = MaxPooling2D(pool_size=(<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>))(x)
    <span class="hljs-comment"># Flatten layer</span>
    x = Flatten()(x)
    <span class="hljs-comment"># Dense layers</span>
    x = Dense(<span class="hljs-attr">512</span>)(x)
    x = BatchNormalization()(x)
    x = Activation(<span class="hljs-string">'relu'</span>)(x)
    x = Dense(<span class="hljs-attr">10</span>, activation=<span class="hljs-string">'softmax'</span>)(x)
    <span class="hljs-comment"># Create model</span>
    model = Model(inputs=input_layer, outputs=x)
    <span class="hljs-keyword">return</span> model
<span class="hljs-comment"># Learning rate scheduler with warmup</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">learning_rate_scheduler</span>(<span>epoch</span>):
    <span class="hljs-keyword">if</span> epoch &lt; <span class="hljs-attr">5</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-attr">0.4</span> * (epoch + <span class="hljs-attr">1</span>) / <span class="hljs-attr">5</span>
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-attr">0.4</span> * np.exp(<span class="hljs-attr">0.1</span> * (<span class="hljs-attr">5</span> - epoch))
<span class="hljs-comment"># Create DavidNet model</span>
model_davidnet = davidnet()
<span class="hljs-comment"># Compile the model</span>
optimizer = SGD(momentum=<span class="hljs-attr">0.9</span>, decay=<span class="hljs-attr">0.000125</span>)
model_davidnet.<span class="hljs-built_in">compile</span>(optimizer=optimizer,
                        loss=<span class="hljs-string">'</span><span class="hljs-string">sparse_categorical_crossentropy'</span>,
                        metrics=[<span class="hljs-string">'accuracy'</span>])
<span class="hljs-comment"># Print model summary</span>
model_davidnet.summary()
<span class="hljs-comment"># Load CIFAR-10 dataset and preprocess if necessary</span>
<span class="hljs-comment"># Assuming x_train, y_train, x_test, y_test are loaded and preprocessed</span>
<span class="hljs-comment"># Define batch size and number of epochs</span>
batch_size = <span class="hljs-attr">512</span>
num_epochs = <span class="hljs-attr">24</span>
<span class="hljs-comment"># Train the model with learning rate scheduler</span>
history_davidnet = model_davidnet.fit(x_train, y_train,
                                      batch_size=batch_size,
                                      epochs=num_epochs,
                                      validation_data=(x_test, y_test),
                                      callbacks=[LearningRateScheduler(learning_rate_scheduler)],
                                      verbose=<span class="hljs-attr">1</span>)
</code></pre>
    <p class="normal1">In this code:</p>
    <ul class="calibre15">
      <li class="bulletlist">We define the DavidNet architecture, which consists of convolutional layers, residual blocks, max pooling, and dense layers.</li>
      <li class="bulletlist1">We define a learning rate scheduler function to adjust the learning rate during training, implementing both warmup and exponential decay as specified.</li>
      <li class="bulletlist1">We compile the model with the <strong class="screentext">Stochastic Gradient Descent</strong> (<strong class="screentext">SGD</strong>) optimizer with the specified hyperparameters: <code class="inlinecode">momentum=0.9</code> and <code class="inlinecode">decay=0.000125</code>.</li>
      <li class="bulletlist1">We train the model using the CIFAR-10 dataset, with the specified batch size, number of epochs, and learning rate scheduler.</li>
    </ul>
    <p class="normal1">This <a id="_idIndexMarker699" class="calibre3"/>implementation follows the described architecture and hyperparameters of DavidNet. Let me know if you have any questions or if you need further assistance!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We execute the code provided by ChatGPT and it encounters an error, since ChatGPT is trained on older versions of machine learning code and hence provided us with a deprecated method for decay.</p>
    <p class="normal1">You should see a <code class="inlinecode">ValueError</code> from running the code.</p>
    <p class="normal1">We will provide the error to ChatGPT and see if the modified code provided by ChatGPT works.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <pre class="programlisting"><code class="hljs-code">ValueError: decay is deprecated in the new Keras optimizer. Please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.SGD.
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive<a id="_idIndexMarker700" class="calibre3"/> a response like the following where ChatGPT understands the request and provides us with the modified code with the decay issue addressed.</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Thank you for the update. It seems the decay parameter is deprecated in the new Keras optimizer. We can use a different method to implement weight decay, such as using a custom callback. Let’s modify the code accordingly:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Model
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Add
<span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> SGD
<span class="hljs-keyword">from</span> tensorflow.keras.callbacks <span class="hljs-keyword">import</span> LearningRateScheduler, Callback
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">class</span> <span class="hljs-meta">SGDLearningRateDecay</span>(<span class="hljs-meta">Callback</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-meta">__init__</span>(<span>self, initial_lr, warmup_epochs, decay_factor</span>):
        <span class="hljs-built_in">super</span>(SGDLearningRateDecay, <span class="hljs-attr">self</span>).__init__()
        <span class="hljs-attr">self</span>.initial_lr = initial_lr
        <span class="hljs-attr">self</span>.warmup_epochs = warmup_epochs
        <span class="hljs-attr">self</span>.decay_factor = decay_factor
    <span class="hljs-keyword">def</span> <span class="hljs-meta">on_epoch_begin</span>(<span>self, epoch, logs=</span><span class="hljs-literal">None</span>):
        <span class="hljs-keyword">if</span> epoch &lt; <span class="hljs-attr">self</span>.warmup_epochs:
            lr = (<span class="hljs-attr">self</span>.initial_lr * (epoch + <span class="hljs-attr">1</span>)) / <span class="hljs-attr">self</span>.warmup_epochs
        <span class="hljs-keyword">else</span>:
            lr = <span class="hljs-attr">self</span>.initial_lr * <span class="hljs-attr">self</span>.decay_factor**(epoch - <span class="hljs-attr">self</span>.warmup_epochs)
        <span class="hljs-attr">self</span>.model.optimizer.lr = lr
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f'Learning rate for epoch </span><span class="hljs-name">{epoch + </span><span class="hljs-attr">1</span><span class="hljs-name">}</span><span class="hljs-string"> is </span><span class="hljs-name">{lr}</span><span class="hljs-string">'</span>)
<span class="hljs-keyword">def</span> <span class="hljs-meta">davidnet</span>():
    input_layer = Input(shape=(<span class="hljs-attr">32</span>, <span class="hljs-attr">32</span>, <span class="hljs-attr">3</span>))
    <span class="hljs-comment"># Initial convolutional layer</span>
    x = Conv2D(<span class="hljs-attr">64</span>, kernel_size=<span class="hljs-attr">3</span>, padding=<span class="hljs-string">'same'</span>)(input_layer)
    x = BatchNormalization()(x)
    x = Activation(<span class="hljs-string">'relu'</span>)(x)
    <span class="hljs-comment"># Stack of residual blocks</span>
    num_residual_blocks = <span class="hljs-attr">4</span>
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residual_blocks):
        y = x
        x = Conv2D(<span class="hljs-attr">64</span>, kernel_size=<span class="hljs-attr">3</span>, padding=<span class="hljs-string">'same'</span>)(x)
        x = BatchNormalization()(x)
        x = Activation(<span class="hljs-string">'relu'</span>)(x)
        x = Conv2D(<span class="hljs-attr">64</span>, kernel_size=<span class="hljs-attr">3</span>, padding=<span class="hljs-string">'same'</span>)(x)
        x = BatchNormalization()(x)
        x = Add()([x, y])  <span class="hljs-comment"># Skip connection</span>
        x = Activation(<span class="hljs-string">'relu'</span>)(x)
    <span class="hljs-comment"># Max pooling layer</span>
    x = MaxPooling2D(pool_size=(<span class="hljs-attr">2</span>, <span class="hljs-attr">2</span>))(x)
    <span class="hljs-comment"># Flatten layer</span>
    x = Flatten()(x)
    <span class="hljs-comment"># Dense layers</span>
    x = Dense(<span class="hljs-attr">512</span>)(x)
    x = BatchNormalization()(x)
    x = Activation(<span class="hljs-string">'relu'</span>)(x)
    x = Dense(<span class="hljs-attr">10</span>, activation=<span class="hljs-string">'softmax'</span>)(x)
    <span class="hljs-comment"># Create model</span>
    model = Model(inputs=input_layer, outputs=x)
    <span class="hljs-keyword">return</span> model
<span class="hljs-comment"># Create DavidNet model</span>
model_davidnet = davidnet()
<span class="hljs-comment"># Define hyperparameters</span>
batch_size = <span class="hljs-attr">512</span>
initial_lr = <span class="hljs-attr">0.4</span>
num_epochs = <span class="hljs-attr">24</span>
warmup_epochs = <span class="hljs-attr">5</span>
decay_factor = <span class="hljs-attr">0.4</span>
<span class="hljs-comment"># Compile the model</span>
optimizer = SGD(momentum=<span class="hljs-attr">0.9</span>)
model_davidnet.<span class="hljs-built_in">compile</span>(optimizer=optimizer,
                        loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,
                        metrics=[<span class="hljs-string">'accuracy'</span>])
<span class="hljs-comment"># Print model summary</span>
model_davidnet.summary()
<span class="hljs-comment"># Define learning rate scheduler callback</span>
lr_decay_callback = SGDLearningRateDecay(initial_lr, warmup_epochs, decay_factor)
<span class="hljs-comment"># Load CIFAR-10 dataset and preprocess if necessary</span>
<span class="hljs-comment"># Assuming x_train, y_train, x_test, y_test are loaded and preprocessed</span>
<span class="hljs-comment"># Train the model with learning rate scheduler</span>
history_davidnet = model_davidnet.fit(x_train, y_train,
                                      batch_size=batch_size,
                                      epochs=num_epochs,
                                      validation_data=(x_test, y_test),
                                      callbacks=[lr_decay_callback],
                                      verbose=<span class="hljs-attr">1</span>)
</code></pre>
    <p class="normal1">In this <a id="_idIndexMarker701" class="calibre3"/>modified code:</p>
    <ul class="calibre15">
      <li class="bulletlist">We define a custom callback <code class="inlinecode">SGDLearningRateDecay</code> to implement the learning rate decay strategy. This callback adjusts the learning rate based on the current epoch and the specified warmup epochs and decay factor.</li>
      <li class="bulletlist1">We remove the decay parameter from the optimizer initialization and set it to the default value of 0.</li>
      <li class="bulletlist1">We use the custom learning rate decay callback during model training.</li>
    </ul>
    <p class="normal1">This approach allows us to implement the weight decay strategy without using the decay parameter in the optimizer. Let me know if you have any questions or if you need further assistance!</p>
    <p class="normal1"><strong class="screentext">[End of response]</strong></p>
    <p class="normal1">We <a id="_idIndexMarker702" class="calibre3"/>execute the code provided by ChatGPT and it runs perfectly fine. It provides a model summary and the accuracy score has improved to 77%.</p>
    <pre class="programlisting"><code class="hljs-code">Model Summary: 
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 32, 32, 3)]          0         []                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_20 (Ba  (None, 32, 32, 64)           256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 64)           0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_21 (Ba  (None, 32, 32, 64)           256       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 64)           0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_11[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 32, 32, 64)           256       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_4 (Add)                 (None, 32, 32, 64)           0         ['batch_normalization_22[0][0]
                                                                    ',                            
                                                                     'activation_10[0][0]']       
                                                                                                  
 activation_12 (Activation)  (None, 32, 32, 64)           0         ['add_4[0][0]']               
                                                                                                  
 conv2d_23 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_23 (Ba  (None, 32, 32, 64)           256       ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 32, 32, 64)           0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_13[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 32, 32, 64)           256       ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_5 (Add)                 (None, 32, 32, 64)           0         ['batch_normalization_24[0][0]
                                                                    ',                            
                                                                     'activation_12[0][0]']       
                                                                                                  
 activation_14 (Activation)  (None, 32, 32, 64)           0         ['add_5[0][0]']               
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 64)           256       ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 32, 32, 64)           0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_15[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 64)           256       ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_6 (Add)                 (None, 32, 32, 64)           0         ['batch_normalization_26[0][0]
                                                                    ',                            
                                                                     'activation_14[0][0]']       
                                                                                                  
 activation_16 (Activation)  (None, 32, 32, 64)           0         ['add_6[0][0]']               
                                                                                                  
 conv2d_27 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_27 (Ba  (None, 32, 32, 64)           256       ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 32, 32, 64)           0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 32, 32, 64)           256       ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_7 (Add)                 (None, 32, 32, 64)           0         ['batch_normalization_28[0][0]
                                                                    ',                            
                                                                     'activation_16[0][0]']       
                                                                                                  
 activation_18 (Activation)  (None, 32, 32, 64)           0         ['add_7[0][0]']               
                                                                                                  
 max_pooling2d_9 (MaxPoolin  (None, 16, 16, 64)           0         ['activation_18[0][0]']       
 g2D)                                                                                             
                                                                                                  
 flatten_3 (Flatten)         (None, 16384)                0         ['max_pooling2d_9[0][0]']     
                                                                                                  
 dense_6 (Dense)             (None, 512)                  8389120  
['flatten_3[0][0]']           
                                                                                                  
 batch_normalization_29 (Ba  (None, 512)                  2048      ['dense_6[0][0]']             
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 512)                  0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 dense_7 (Dense)             (None, 10)                   5130      ['activation_19[0][0]']       
                                                                                                  
==================================================================================================
Total params: 8695818 (33.17 MB)
Trainable params: 8693642 (33.16 MB)
Non-trainable params: 2176 (8.50 KB)
</code></pre>
    <p class="packt_figref"><img alt="" src="../Images/B21232_15_12.png" class="calibre4"/></p>
    <p class="packt_figref">Figure 15.12: DavidNet – improved accuracy</p>
    <h1 class="heading" id="_idParaDest-336">Assignment</h1>
    <p class="normal">Increase the number of epochs for feature 3 when the dropout layer is added.</p>
    <h1 class="heading" id="_idParaDest-337">Challenge</h1>
    <p class="normal">Try to improve the model performance to greater than 80%. Feel free to use any architecture.</p>
    <h1 class="heading" id="_idParaDest-338">Summary</h1>
    <p class="normal">In this chapter, we explored how to effectively use AI assistants like ChatGPT to learn and experiment with <strong class="screentext">convolutional neural network</strong> (<strong class="screentext">CNN</strong>) models. The strategies provided a clear step-by-step approach to experimenting with different techniques for building and training CNN models using the CIFAR-10 dataset. </p>
    <p class="normal1">Each step was accompanied by detailed instructions, code generation, and user validation, ensuring a structured learning experience. We started by building a baseline CNN model, where we learned the essential preprocessing steps, including normalizing pixel values and resizing images. It guided you through generating beginner-friendly code that is compatible with Jupyter notebooks, ensuring that even those new to the field could easily grasp the fundamentals of CNN construction. </p>
    <p class="normal1">As we progressed, our AI assistant became an integral part of the learning process, helping us delve into more complex areas such as adding layers, implementing dropout and batch normalization, and experimenting with different optimization algorithms. Each of these steps was accompanied by incremental code updates, and we paused regularly to review the feedback, making sure the learning was paced appropriately and responsive to your needs. Our journey culminated with the implementation of the DavidNet architecture, applying all the strategies and techniques we had learned. </p>
    <p class="normal1">In the next chapter, we will learn how to use ChatGPT to generate the code for clustering and PCA. </p>
    <h1 class="heading" id="_idParaDest-339">Join our community on Discord </h1>
    <p class="normal">Join our community’s Discord space for discussions with the author and other readers: </p>
    <p class="normal1"><a href="https://packt.link/aicode" class="calibre3"><span class="calibre3">https://packt.link/aicode</span></a></p>
    <p class="normal1"><span class="calibre3"><img alt="" src="../Images/QR_Code510410532445718281.png" class="calibre4"/></span></p>
  </div>
</body></html>