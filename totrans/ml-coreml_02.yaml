- en: Introduction to Apple Core ML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apple Core ML 简介
- en: In this chapter, we are going to briefly introduce the framework that we will
    be using throughout this book - Core ML. But before doing so, we will elaborate
    on what training and inference are, specifically how they differ; and then we'll
    look at the motivation for performing **machine learning** (**ML**) on the edge,
    that is, your iOS device.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将简要介绍我们将在这本书中使用的框架——Core ML。但在这样做之前，我们将详细阐述训练和推理是什么，特别是它们之间的区别；然后我们将探讨在边缘执行**机器学习**（**ML**）的动机，即在您的
    iOS 设备上。
- en: 'We will be covering the following topics in the chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Highlighting the difference between training a model and using the model for
    inference
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强调训练模型和使用模型进行推理之间的区别
- en: Motivation and opportunities for performing inference on the edge
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在边缘执行推理的动机和机会
- en: Introducing Core ML and the general workflow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 Core ML 和一般工作流程
- en: A brief introduction to some ML algorithms
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些机器学习算法的简要介绍
- en: Some considerations to keep in mind when developing ML-enabled applications
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在开发具有机器学习功能的应用程序时需要考虑的一些事项
- en: Difference between training and inference
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和推理的区别
- en: The difference between training and inference is similar to that of a student
    being taught something like algebra at school and then applying it in the real
    world. In school, the student is given numerous exercises; for each exercise,
    the student attempts the question and hands his/her answer over to the teacher,
    who provides feedback indicating whether it is correct or not. Initially, this
    feedback is likely to be skewed toward the student being wrong more often than
    right, but after many attempts, as the student starts building his/her understanding
    of the concepts, the feedback shifts towards mostly being right. At this point,
    the student is considered to have sufficiently learned algebra and is able to
    apply it to unseen problems in the real world, where he/she can be confident of
    the answer based on his/her exposure to the exercises provided during the lessons
    at school.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和推理之间的区别类似于学生在学校学习代数等知识后将其应用于现实世界的情况。在学校，学生会做大量的练习；对于每个练习，学生会尝试回答问题，并将答案交给教师，教师会提供反馈，指出答案是否正确。最初，这种反馈可能倾向于学生答错多于答对，但经过多次尝试，随着学生对概念的理解开始建立，反馈逐渐转向主要是正确的。此时，学生被认为已经足够了解代数，能够将其应用于现实世界中的未见问题，在那里他/她可以根据在学校课程中提供的练习来自信地回答问题。
- en: 'ML models are no different; the initial phase of building the model is through
    the process of **training,** where the model is provided with many examples. For
    each example, a **loss function** is used in place of the teacher to provide feedback,
    which, in turn, is used to make adjustments to the model to reduce the loss (the
    degree to which the model''s answer was incorrect). This process of training can
    take many iterations and is typically compute intensive, but it offers opportunities
    for being parallelized (especially for neural networks); that is, a lot of the
    calculations can run in parallel with one another. For this reason, it''s common
    to perform training in the cloud or some dedicated machines with enough memory
    and compute power. This process of training is illustrated in the following diagram:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型也没有不同；构建模型的初始阶段是通过**训练**过程完成的，在这个过程中，模型被提供了许多示例。对于每个示例，使用**损失函数**代替教师提供反馈，这反过来又用于调整模型以减少损失（模型答案错误的程度）。这个过程可能需要多次迭代，通常是计算密集型的，但它提供了并行化的机会（特别是对于神经网络）；也就是说，很多计算可以并行进行。因此，通常在云端或一些具有足够内存和计算能力的专用机器上执行训练。以下图表展示了这个过程：
- en: '![](img/526df58d-2638-4bfc-85d4-da47fc6dc5c4.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/526df58d-2638-4bfc-85d4-da47fc6dc5c4.png)'
- en: To better illustrate the compute power required, in the blog post *Cortana Intelligence
    and Machine Learning Blog*, Microsoft data scientist Miguel Fierro and others
    detail the infrastructure and time required for training on the ImageNet dataset (1,000
    classes with over 1.2 million photos) using an 18-layer ResNet architecture. It
    took approximately three days to train over 30 epochs on an Azure N-series NC-24
    virtual machine with 4 GPUs, 24 CPU cores, and 224 GB of memory. The full details
    are described here: [https://blogs.technet.microsoft.com/machinelearning/2016/11/15/imagenet-deep-neural-network-training-using-microsoft-r-server-and-azure-gpu-vms/](https://blogs.technet.microsoft.com/machinelearning/2016/11/15/imagenet-deep-neural-network-training-using-microsoft-r-server-and-azure-gpu-vms/).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地说明所需的计算能力，在博客文章《Cortana Intelligence and Machine Learning Blog》中，微软数据科学家Miguel
    Fierro和其他人详细介绍了在ImageNet数据集（1,000个类别，超过1.2百万张照片）上使用18层ResNet架构进行训练的基础设施和时间要求。在一个配备4个GPU、24个CPU核心和224
    GB内存的Azure N-series NC-24虚拟机上，大约需要三天时间训练超过30个epoch。详细内容描述在这里：[https://blogs.technet.microsoft.com/machinelearning/2016/11/15/imagenet-deep-neural-network-training-using-microsoft-r-server-and-azure-gpu-vms/](https://blogs.technet.microsoft.com/machinelearning/2016/11/15/imagenet-deep-neural-network-training-using-microsoft-r-server-and-azure-gpu-vms/)。
- en: 'After the training is complete, the model is now ready for the real world;
    like our student, we can now deploy and use our model to solve unseen problems.
    This is known as **inference**. Unlike training, inference only requires a single
    pass through the model using its gained understanding from training, that is,
    weights and coefficients. Additionally, there are some sections in our model that
    are no longer needed, so there is a degree of pruning (the reduction of less important
    aspects that do not affect accuracy) that can be performed to further optimize
    the model:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，模型现在可以用于现实世界；就像我们的学生一样，我们现在可以部署并使用我们的模型来解决未见过的难题。这被称为**推理**。与训练不同，推理只需要通过模型进行单次遍历，使用其在训练中获得的认知，即权重和系数。此外，我们的模型中还有一些部分不再需要，因此可以进行一定程度的剪枝（减少不影响准确性的不那么重要的方面），以进一步优化模型：
- en: '![](img/6821673b-b328-478f-bea7-4299b8635afe.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6821673b-b328-478f-bea7-4299b8635afe.png)'
- en: Because of these conditions, a single pass, and pruning, we can afford to perform
    inference on less performant machines, like our smartphone. But why would you
    want to do this? What are the advantages of performing inference on the edge?
    This is the topic of the next section.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些条件，单次遍历和剪枝，我们可以在性能较差的机器上执行推理，比如我们的智能手机。但为什么你想这样做呢？在边缘进行推理的优势是什么？这是下一节的主题。
- en: Inference on the edge
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘推理
- en: For those unfamiliar with the term **edge computing**, it simply refers to computation
    performed at the end, or edge, of a network as opposed to sending it to a central
    server for computation. Some examples of edge devices include cars, robots, **Internet
    of Things** (**IoT**), and, of course, smartphones.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些不熟悉“边缘计算”这个术语的人来说，它简单指的是在网络末端或边缘进行的计算，而不是将其发送到中央服务器进行计算。边缘设备的例子包括汽车、机器人、**物联网**（**IoT**）和当然，智能手机。
- en: The motivation for performing computation at the edge, where the data resides,
    is that sending data across the network is expensive and time-consuming; this
    incurred latency and cost restrict us with what experiences we can deliver to
    the user. Removing these barriers opens up new applications that would otherwise
    not be possible. Another benefit of performing inference at the edge is data privacy;
    removing the need of having to transmit personal data across the network reduces
    the opportunities that a malicious user has for obtaining it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据所在边缘进行计算的动力在于，将数据通过网络发送是昂贵且耗时的；这种产生的延迟和成本限制了我们可以提供给用户的体验。移除这些障碍将开启原本不可能的新应用。在边缘进行推理的另一个好处是数据隐私；无需通过网络传输个人数据，减少了恶意用户获取它的机会。
- en: Luckily, technology advances at an astonishing rate and improvements in hardware
    and software have now made it feasible to perform inference at the edge.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，技术以惊人的速度发展，硬件和软件的改进现在使得在边缘进行推理变得可行。
- en: As this book's focus is on applied ML on iOS; **detailed** model architectures
    and training have been intentionally omitted as training currently requires significant
    computational power that is still out of reach of most of today's edge devices
    - although this is likely to change in the near future as edge devices become
    increasingly powerful, with the most likely next advancement being around tuning
    and personalizing models using personal data that resides on the device.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书的重点是iOS上的应用机器学习；**详细**的模型架构和训练已被有意省略，因为当前的训练需要大量的计算能力，而这对于今天的大多数边缘设备来说仍然难以达到——尽管随着边缘设备的日益强大，这种情况可能会在不久的将来改变，最有可能的下一步进展将是使用设备上存储的个人数据调整和个性化模型。
- en: 'Some common use cases for ML on the device include:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 设备上机器学习的常见用例包括：
- en: '**Speech recognition**: It''s currently common to perform wake (or hot) word
    detection locally rather than continuously streaming data across the network.
    For example, **Hey Siri** is most likely performed locally on the device, and
    once detected, it streams the utterance to a server for further processing.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音识别**：目前通常在本地执行唤醒（或热）词检测，而不是在网络中持续传输数据。例如，“嘿，Siri”很可能是在本设备上本地执行的，一旦检测到，它将语音传输到服务器进行进一步处理。'
- en: '**Image recognition**: It can be useful for the device to be able to understand
    what it is seeing in order to assist the user in taking a photo, such as applying
    the appropriate filters, adding captions to the photos to make them easier to
    find and grouping similar images together. These enhancements may not be significant
    enough to justify opening a connection to a remote server, but because these can
    be performed locally, we can use them without worrying about cost, latency, or
    privacy issues.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像识别**：设备能够理解它所看到的内容，以便协助用户拍照，例如应用适当的滤镜、添加标题以便更容易找到照片以及将相似图像分组，这些功能可能不足以证明连接到远程服务器是合理的。但由于这些功能可以在本地执行，我们可以使用它们而无需担心成本、延迟或隐私问题。'
- en: '**Object localization**: Sometimes, it is useful to know not only what is present
    in view, but also where it is in the view. An example of this can be seen in **augmented
    reality** (**AR**) apps, where information is overlaid onto the scene. Having
    these experiences responsive is critical for their success, and therefore there
    is a need for extremely low latency in performing inference.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标定位**：有时，知道视图中的内容以及它们在视图中的位置是有用的。这种例子可以在**增强现实**（**AR**）应用中看到，其中信息被叠加到场景上。这些体验的响应性对于其成功至关重要，因此在进行推理时需要极低的延迟。'
- en: '**Optical character recognition**: One of the first commercial applications
    of neural networks is still just as useful as it was when it was used in American
    post offices in 1989\. Being able to read allows for applications such as digitizing
    a physical copy or performing computations on it; examples include language translation
    or solving a Sudoku puzzle.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**光学字符识别**：神经网络最早的商业应用之一，即使在1989年用于美国邮局时也依然有用。能够读取内容使得数字化物理副本或在其上进行计算成为可能；例如语言翻译或解决数独谜题。'
- en: '**Translation**: Translating from one language to another quickly and accurately,
    even if you don''t have a network connection, is an important use case and complements
    many of the visual-based scenarios we have discussed so far, such as AR and optical
    character recognition.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**翻译**：即使没有网络连接，也能快速准确地翻译一种语言到另一种语言，这是一个重要的用例，并且补充了我们之前讨论的许多基于视觉的场景，例如增强现实和光学字符识别。'
- en: '**Gesture recognition**: Gesture recognition provides us with a rich interaction
    mode, allowing quick shortcuts and intuitive user interactions that can improve
    and enhance user experience.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手势识别**：手势识别为我们提供了一种丰富的交互模式，允许快速捷径和直观的用户交互，这可以改善和增强用户体验。'
- en: '**Text prediction**: Being able to predict the next word the user is going
    to type, or even predicting the user''s response, has turned something fairly
    cumbersome and painful to use (the smartphone soft keyboard) into something that
    is just as quick or even quicker than its counterpart (the conventional keyboard).
    Being able to perform this prediction on the device increases your ability to
    protect the user''s privacy and offer a responsive solution. This is not feasible
    if the request has to be routed to a remote server.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本预测**：能够预测用户将要输入的下一个单词，甚至预测用户的响应，已经将一个相当繁琐且使用起来痛苦的东西（智能手机软键盘）变成了与它的对应物（传统键盘）一样快，甚至更快。能够在设备上执行这种预测提高了您保护用户隐私和提供响应式解决方案的能力。如果请求必须路由到远程服务器，这是不可行的。'
- en: '**Text classification**: This covers everything from sentiment analysis to
    topic discovery and facilitates many useful applications, such as providing means
    to recommend relevant content to the user or eliminate duplicates.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本分类**：这涵盖了从情感分析到主题发现的所有内容，并促进了许多有用的应用，例如为用户提供推荐相关内容或消除重复内容的方法。'
- en: These examples of use cases and applications hopefully show why we may want
    to perform inference on the edge; it means you can offer a higher level of interactivity
    than what could be possible with performing inference off the device. It allows
    you to deliver an experience even if the device has poor network connectivity
    or no network connectivity. And finally, it's scalable—an increase in demand doesn't
    directly correlate to the load on your server.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些用例和应用的示例可能展示了为什么我们可能想在边缘执行推理；这意味着您可以提供比在设备上执行推理更高的交互级别。它允许您在设备网络连接差或没有网络连接的情况下提供体验。最后，它是可扩展的——需求的增加并不直接与服务器负载相关。
- en: 'So far, we have introduced inference and the importance of being able to perform
    it on the edge. In the next section, we will introduce the framework that facilitates
    this on iOS devices: Core ML.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经介绍了推理及其在边缘执行的重要性。在下一节中，我们将介绍在iOS设备上促进这一功能的框架：Core ML。
- en: A brief introduction to Core ML
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Core ML简介
- en: 'With the release of iOS 11 and Core ML, performing inference is just a matter
    of a few lines of code. Prior to iOS 11, inference was possible, but it required
    some work to take a pre-trained model and port it across using an existing framework
    such as **Accelerate** or **metal performance shaders** (**MPSes**). **Accelerate**
    and MPSes are still used under the hood by Core ML, but Core ML takes care of
    deciding which underlying framework your model should use (**Accelerate** using
    the CPU for memory-heavy tasks and MPSes using the GPU for compute-heavy tasks).
    It also takes care of abstracting a lot of the details away; this layer of abstraction
    is shown in the following diagram:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随着iOS 11和Core ML的发布，执行推理只需几行代码。在iOS 11之前，推理是可能的，但需要一些工作来将预训练的模型通过现有的框架（如**Accelerate**或**metal性能着色器**（MPSes））迁移过来。**Accelerate**和MPSes仍然在Core
    ML的底层使用，但Core ML负责决定您的模型应该使用哪个底层框架（对于内存密集型任务使用CPU的**Accelerate**，对于计算密集型任务使用GPU的MPSes）。它还负责抽象掉很多细节；这一层抽象在以下图中展示：
- en: '![](img/fbdf956c-99c2-43fb-a357-834cf0ef66d7.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fbdf956c-99c2-43fb-a357-834cf0ef66d7.png)'
- en: 'There are additional layers too; iOS 11 has introduced and extended domain-specific
    layers that further abstract a lot of the common tasks you may use when working
    with image and text data, such as face detection, object tracking, language translation,
    and **named entity recognition** (**NER**). These domain-specific layers are encapsulated
    in the **Vision** and **natural language processing** (**NLP**) frameworks; we
    won''t be going into any details of these frameworks here, but you will get a
    chance to use them in later chapters:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些额外的层之外；iOS 11引入并扩展了特定领域的层，这些层进一步抽象了您在处理图像和文本数据时可能使用的许多常见任务，例如人脸检测、对象跟踪、语言翻译和**命名实体识别**（NER）。这些特定领域的层封装在**视觉**和**自然语言处理**（NLP）框架中；我们在这里不会深入探讨这些框架的细节，但在后面的章节中，您将有机会使用它们：
- en: '![](img/754528fc-4c89-42c7-8aa1-f3055e811d49.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/754528fc-4c89-42c7-8aa1-f3055e811d49.png)'
- en: It's worth noting that these layers are not mutually exclusive and it is common
    to find yourself using them together, especially the domain-specific frameworks
    that provide useful preprocessing methods we can use to prepare our data before
    sending to a Core ML model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: So what exactly is Core ML? You can think of Core ML as a suite of tools used
    to facilitate the process of bringing ML models to iOS and wrapping them in a
    standard interface so that you can easily access and make use of them in your
    code. Let's now take a closer look at the typical workflow when working with Core
    ML.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Workflow
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As described previously, the two main tasks of a ML workflow consist of **training**
    and **inference**. Training involves obtaining and preparing the data, defining
    the model, and then the real training. Once your model has achieved satisfactory results
    during training and is able to perform adequate predictions (including on data
    it hasn't seen before), your model can then be deployed and used for inference
    using data outside of the training set. Core ML provides a suite of tools to facilitate
    getting a trained model into iOS, one being the Python packaged released called **Core
    ML Tools**; it is used to take a model (consisting of the architecture and weights)
    from one of the many popular packages and exporting a `.mlmodel` file, which can
    then be imported into your Xcode project.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'Once imported, Xcode will generate an interface for the model, making it easily
    accessible via code you are familiar with. Finally, when you build your app, the
    model is further optimized and packaged up within your application. A summary
    of the process of generating the model is shown in the following diagram:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/870eb15e-d50e-45c2-a61c-ea386dd88d36.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: 'The previous diagram illustrates the process of creating the `.mlmodel;`, either
    using an existing model from one of the supported frameworks, or by training it
    from scratch. Core ML Tools supports most of the frameworks, either internal or
    as third party plug-ins, including  Keras, turi, Caffe, scikit-learn, LibSVN,
    and XGBoost frameworks. Apple has also made this package open source and modular
    for easy adaption for other frameworks or by yourself. The process of importing
    the model is illustrated in this diagram:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/39178104-5b20-473a-8327-dad08a10a23f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: In addition; there are frameworks with tighter integration with Core ML that
    handle generating the Core ML model such as **Turi Create**, **IBM Watson Services
    for Core ML**, and **Create ML**.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be introducing Create ML in chapter 10; for those interesting in learning
    more about Turi Create and IBM Watson Services for Core ML then please refer to
    the official webpages via the following links:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Turi Create; [https://github.com/apple/turicreate](https://github.com/apple/turicreate)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: IBM Watson Services for Core ML; [https://developer.apple.com/ibm/](https://developer.apple.com/ibm/)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Once the model is imported, as mentioned previously, Xcode generates an interface
    that wraps the **model**, model **inputs**, and **outputs**. You will get acquainted
    with these throughout the rest of this book, so we won't go into any further details
    here.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: In the previous diagrams we have seen the workflow of training and importing
    a **model** - let's now delve into the details of what this model is and what
    Core ML currently supports.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Learning algorithms
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 1](7d4f641f-7137-4a8a-ae6e-2bb0e2a6db5c.xhtml), *Introduction to
    Machine Learning*, we saw many different types of learning algorithms and learned
    that ML is really a process of automatically discovering rules given a set of
    examples. The main components required for this process, specifically for supervised
    learning, include:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '**Input data points**: For image classification, we would require images of
    the domain we want to classify, for example, animals.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The expected outputs for these inputs**: Continuing from our previous example
    of image classification of animals, the expected outputs could be labels associated
    with each of the images, for example, cat, dog, and many more.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A ML algorithm**: This is the algorithm used to automatically learn how to transform
    the input data points into a meaningful output. These derived sets of rules are
    what we call the model, derived through a process of learning called **training**.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's make these concepts more concrete by working through a simple example.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Auto insurance in Sweden
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you haven't done so already, navigate to the repository at [https://github.com/joshnewnham/MachineLearningWithCoreML](https://github.com/joshnewnham/MachineLearningWithCoreML)
    and download the latest code. Once downloaded, navigate to the directory `Chapter2/Start/`
    and open the playground `LinearRegression.playground`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be creating a model that will predict the total payments for all claims
    (y) given the number of claims (x); the dataset we will be working with is auto
    insurance claims in Sweden. It consists of 2 columns and 64 rows, the first column
    containing the number of claims, and the second containing the total payments
    for all claims. Here is an extract from the dataset:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '| **Number of claims** | **Total payments for all claims in thousands of Swedish
    Kronor** |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| 108 | 329.5 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| 19 | 46.2 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| 13 | 15.7 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| 124 | 422.2 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: '| ... | ... |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: For more details, visit the source website: [http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/slr06.html](http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/slr06.html).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'In the playground script, you will see that we are creating a view of the type
    `ScatterPlotView` and assigning it to the playground''s live view. We will use
    this view to visualize the data and the predictions from our model:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'By using this view, we can plot an array of data points using the `view.scatter(dataPoints:)`
    method and draw a line using the `view.line(pointA:,pointB)` method. Let''s load
    the raw data and visualize it:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用这种视图，我们可以使用 `view.scatter(dataPoints:)` 方法绘制一系列数据点，并使用 `view.line(pointA:,pointB)`
    方法绘制一条线。让我们加载数据并可视化它：
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the previous code snippet, we first load the data into the `csvData` variable
    and then cast it into a strongly typed array of `DataPoint` (a strongly typed
    data object, which our view is expecting). Once loaded, we pass our data to the
    view via the `scatter` method, which renders the following output:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们首先将数据加载到 `csvData` 变量中，然后将其转换为强类型数组 `DataPoint`（一个强类型数据对象，我们的视图所期望的）。一旦加载，我们就通过
    `scatter` 方法将我们的数据传递给视图，它渲染以下输出：
- en: '![](img/ac2f3a43-c656-4fdc-ba2b-e51ca485bafc.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ac2f3a43-c656-4fdc-ba2b-e51ca485bafc.png)'
- en: Each dot represents a single datapoint plotted against the number of claims
    (*x* axis) and total payments for all claims (*y* axis). From this visualization,
    we can infer some linear relationship between the **number of claims** and **total
    payments for all claims**; that is, an increase in **number of claims** increases
    the **total payments for all claims**. Using this intuition, we will attempt to
    model the data according to a linear model, one that, when given the **number
    of claims**, is able to predict the **total payments for all claims**. What we
    are describing here is a type of algorithm known as **simple linear regression**;
    in essence, this is just finding a straight line that best fits our data. It can
    be described with the function *y = w * x + b,* where *y* is the **total payments
    for all claims**, *x* is the **number of claims**, *w* is the relationship between
    *y* and *x,* and *b* is the intercept.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 每个点代表一个单独的数据点，它与索赔数量（*x*轴）和所有索赔的总支付额（*y*轴）相对应。从这种可视化中，我们可以推断出索赔数量和所有索赔的总支付额之间的一些线性关系；也就是说，索赔数量的增加会导致所有索赔的总支付额增加。利用这种直觉，我们将尝试根据线性模型建模数据，这种模型在给定索赔数量时能够预测所有索赔的总支付额。我们在这里描述的是一种称为**简单线性回归**的算法；本质上，这只是在寻找最适合我们数据的直线。它可以描述为函数
    *y = w * x + b*，其中 *y* 是所有索赔的总支付额，*x* 是索赔数量，*w* 是 *y* 和 *x* 之间的关系，而 *b* 是截距。
- en: Linear regression is a type of regression model that maps a linear function
    from a set of continuous inputs to a continuous output. For example, you may want
    to model and predict **house prices**; here, your inputs may be the **number of**
    **bedrooms** and the **number of bathrooms**. Using these two features, you'd
    want to find a function that can predict the house price, one that assumes there
    is a linear correlation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是一种回归模型，它将一组连续输入映射到一个连续输出上的线性函数。例如，你可能想要建模和预测**房价**；在这里，你的输入可能是**卧室数量**和**浴室数量**。使用这两个特征，你将想要找到一个可以预测房价的函数，它假设存在线性相关性。
- en: Simple enough! Our next problem is finding this line that best fits our data.
    For this, we are going to use an approach called **gradient descent**;there are
    plenty of books that go into the theoretical and technical details of gradient
    descent, so here we will just present some intuition behind it and leave it to
    you, the curious reader, to study the details.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 简单易懂！我们接下来的问题是找到最适合我们数据的这条线。为此，我们将使用一种称为**梯度下降**的方法；关于梯度下降的理论和技术细节有很多书籍进行深入探讨，所以在这里我们只介绍一些背后的直觉，并留给好奇的读者去研究细节。
- en: Gradient descent is a set of algorithms that minimize a function; in our case,
    they minimize the loss of our output with respect to the actual output. They achieve
    this by starting with an initial set of parameters (weights or coefficients) and
    iteratively adjusting these to minimize the calculated loss. The direction and
    magnitude of these adjustments are determined by how far off the predicted value
    is compared to the expected error and the parameters' contribution.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一组算法，用于最小化一个函数；在我们的情况下，它们最小化输出与实际输出之间的损失。它们通过从一个初始参数集（权重或系数）开始，并迭代调整这些参数以最小化计算出的损失来实现这一点。这些调整的方向和幅度由预测值与预期误差以及参数贡献之间的差异决定。
- en: 'You can think of gradient descent as a search for some minimum point; what
    determines this minimum point is something called a **loss function**. For us,
    it will be the absolute error between our prediction and actual number of claims.
    The algorithm is steered by calculating the relative contribution of each of our
    variables (here it is *w*and *b*). Let''s see how this looks in code by working
    through the `train` method:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Our `train` method takes in these arguments:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '`x`: An array of `DataPoint` containing the number of claims'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y`: An array of `DataPoint` containing the total number of payments'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b`: This is a random value used in our linear function to start our search'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`w`: Another random value used in our linear function to start our search'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learningRate`: How quickly we adjust the weights'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`epochs`: The number of times we iterate, that is, make a prediction, and adjust
    our coefficients based on the difference between the prediction and expected value'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trainingCallback`: This function is called after each epoch to report the
    progress'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We next create some variables that will be used throughout training and begin
    our search (`for epoch in 0...epochs`). Let's step through each `TODO` and replace
    them with their respective code.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we start by creating two variables to hold the gradients for our variables
    `b` and `w` (these are the adjustments we need to make to their respective coefficients
    to minimize the loss, also known as **absolute error**):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we iterate over each data point, and for each data point, make a prediction
    and calculate the absolute error:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now calculate the partial derivative with respect to the error. Think of this
    as a way to steer the search in the right direction, that is, calculating this
    gives us the **direction** and **magnitude** that we need to change `b` and `w`
    to minimize our error:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is done after iterating through all data points; that is, it
    is influenced by all data points. Alternatives are to perform this update per
    data point or over a subset, known as a **batch**.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After iterating over each data point, we adjust the coefficients `B` and `W`
    using their accumulated gradients.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'After each epoch, `trainingCallback` is called to draw a line using the current
    model''s coefficients (its current best fit line that fits the data); the progress
    of this is shown in the following diagram:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/92f56310-c232-481b-947c-6072e198f4f7.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: 'Admittedly, this is difficult to interpret without a key! But the pattern will
    hopefully be obvious; with each iteration, our line better fits the data. After
    100 epochs, we end up with this model:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ef20d7f-0f58-4561-b958-182ea6f17a50.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: The function describing this line is `y = 0.733505317339142 + 3.4474988368438
    * x`. Using this model, we can predict the **total payments for all claims** given
    the **number of claims** (by simply substituting *x* with the **number of claims**).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Supported learning algorithms
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous example, we used **l****inear regression** (algorithm) to build
    a model that predicts the total payments for all claims (output) given the number
    of claims (input). This is one of many algorithms available for ML; a few of them
    are plotted in the following diagram, grouped into **unsupervised** or **supervised**,
    and **continuous** or **categorical**:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a171496-cdec-4b72-a2d2-a09dbbdc50d3.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
- en: 'The process of creating Core ML models involves translating the model from
    the source framework into something that can be run on iOS. The following diagram
    shows which learning algorithms Core ML currently supports:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb816183-f6b1-4030-ac42-8bd66a56f8d0.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: The supported algorithms and neural networks should be versatile enough for
    most ML tasks but given how fast this field is moving, it's inevitable that you
    will encounter one that is not supported. Apple have anticipated this and provides
    two protocols for extending the framework; `MLCustomLayer` can be used to create
    custom layers (which we cover in later chapters) and `MLCustomModel` for creating
    custom models.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: This has hopefully given you some idea of where Core ML fits in the general
    ML workflow and why Apple has made the design decisions it has. We will finish
    this chapter by looking at a few high-level considerations when dealing with ML
    on an iOS device, or, more generally, the edge before wrapping up.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Considerations
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When performing ML on the edge, you lose some of the luxuries you tend to have
    when running on a more powerful device (albeit this is shifting all the time).
    Here is a list of considerations to keep in mind:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '**Model size**: Previously, we walked through building a simple linear regression
    model. The model itself consists of two floats (bias and weight coefficients),
    which of course are negligible in terms of memory requirements. But, as you dive
    into the world of deep learning, it''s common to find models hundreds of megabytes in
    size. For example, the VGG16 model is a 16-layer conventional neural network architecture
    trained on the ImageNet dataset used for image classification, available on Apple''s
    site. It is just over 500 megabytes. Currently, Apple allows apps 2 gigabytes in
    size, but asking your user to download such a large file may well put them off.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory**: It''s not just the executable size that you need to be mindful
    of, but also the amount of working memory available. It''s common for desktop
    machines to have memory in the range of 16-32 gigabytes, but the memory for the
    latest iPhone (iPhone 8) is just 2 gigabytes—impressive for a mobile device, but
    quite a difference from its counterpart. This constraint is likely to dictate
    what model you choose, more so than how much memory it takes on disk. It is also
    worth mentioning that it''s not just the model weights you''ll need to load into
    the memory; you will also need to load in any label data and, of course, the input
    data you are performing inference on.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speed**: This, of course, is correlated to the model size (in normal circumstances)
    and relevant to your specific use case. Just keep in mind that performing inference
    is only one part of the workflow. You have pre-processing and post-processing
    tasks that also need to be taken into account, such as loading and pre-processing
    the input data. In some cases, you may have to trade off accuracy with performance
    and size.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Supported algorithms and data types**: In the previous section, we presented
    the current algorithms that Core ML supports. Along with these, Core ML supports
    a subset of data types, summarized in the following table for convenience:'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| **Input type** | **Data type** |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: '| Numeric | `Double`, `Int64` |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '| Categories | `String`, `Int64` |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: '| Images | `CVPixelBuffer` |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
- en: '| Arrays | `MLMultiArray` |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
- en: '| Dictionaries  | `[String : Double]`, `[Int64, Double]` |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
- en: Here, we have presented just a few of the considerations at a high level when
    performing ML on a mobile device. The specifics will be dependent on your use
    case and models available, but it's worth keeping these in the back of your mind
    and reminding yourself that these, albeit very powerful devices, are still mobile
    devices. They run on a battery and are therefore subject to the typical considerations
    and optimizations normally required for a mobile project. These considerations
    are even more applicable to those who plan to create their own model, which should
    be most of you if you plan to take advantage of ML.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the difference between training and inference,
    along with the typical ML workflow and where Core ML fits in. We also saw how
    Core ML is not just a single framework, but rather a suite of tools that facilitate
    getting pretrained models into the iOS platform and making them available to your
    application via a familiar and simple interface. Thus, it democratizes ML and
    puts it into the hands of many iOS app developers.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'It has been suggested that the explosion in diverse apps contributed to the
    success of the adoption of smartphones; if this is true, then prepare yourself
    for the next explosion of AI-enhanced apps. And take comfort knowing that you
    are in the perfect place to begin and lead this journey, where we will explore
    many concepts and examples related to computer vision using Core ML, including
    these:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing objects through the video feed of your camera
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging object detection to build intelligent image search, allowing you
    to search for images with specific objects and their position relative to one
    another
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizing facial expressions and inferring the emotional state of a person
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizing hand-drawn sketches using convolutional neural networks and then
    with recurrent neural networks
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning the secrets behind Prisma's style transfer and implementing your own
    version
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, using image segmentation to create the action shot effect
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is plenty to get through, so let's get started!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
