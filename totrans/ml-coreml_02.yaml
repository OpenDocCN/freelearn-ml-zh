- en: Introduction to Apple Core ML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apple Core ML 简介
- en: In this chapter, we are going to briefly introduce the framework that we will
    be using throughout this book - Core ML. But before doing so, we will elaborate
    on what training and inference are, specifically how they differ; and then we'll
    look at the motivation for performing **machine learning** (**ML**) on the edge,
    that is, your iOS device.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将简要介绍我们将在这本书中使用的框架——Core ML。但在这样做之前，我们将详细阐述训练和推理是什么，特别是它们之间的区别；然后我们将探讨在边缘执行**机器学习**（**ML**）的动机，即在您的
    iOS 设备上。
- en: 'We will be covering the following topics in the chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Highlighting the difference between training a model and using the model for
    inference
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强调训练模型和使用模型进行推理之间的区别
- en: Motivation and opportunities for performing inference on the edge
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在边缘执行推理的动机和机会
- en: Introducing Core ML and the general workflow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 Core ML 和一般工作流程
- en: A brief introduction to some ML algorithms
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些机器学习算法的简要介绍
- en: Some considerations to keep in mind when developing ML-enabled applications
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在开发具有机器学习功能的应用程序时需要考虑的一些事项
- en: Difference between training and inference
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和推理的区别
- en: The difference between training and inference is similar to that of a student
    being taught something like algebra at school and then applying it in the real
    world. In school, the student is given numerous exercises; for each exercise,
    the student attempts the question and hands his/her answer over to the teacher,
    who provides feedback indicating whether it is correct or not. Initially, this
    feedback is likely to be skewed toward the student being wrong more often than
    right, but after many attempts, as the student starts building his/her understanding
    of the concepts, the feedback shifts towards mostly being right. At this point,
    the student is considered to have sufficiently learned algebra and is able to
    apply it to unseen problems in the real world, where he/she can be confident of
    the answer based on his/her exposure to the exercises provided during the lessons
    at school.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和推理之间的区别类似于学生在学校学习代数等知识后将其应用于现实世界的情况。在学校，学生会做大量的练习；对于每个练习，学生会尝试回答问题，并将答案交给教师，教师会提供反馈，指出答案是否正确。最初，这种反馈可能倾向于学生答错多于答对，但经过多次尝试，随着学生对概念的理解开始建立，反馈逐渐转向主要是正确的。此时，学生被认为已经足够了解代数，能够将其应用于现实世界中的未见问题，在那里他/她可以根据在学校课程中提供的练习来自信地回答问题。
- en: 'ML models are no different; the initial phase of building the model is through
    the process of **training,** where the model is provided with many examples. For
    each example, a **loss function** is used in place of the teacher to provide feedback,
    which, in turn, is used to make adjustments to the model to reduce the loss (the
    degree to which the model''s answer was incorrect). This process of training can
    take many iterations and is typically compute intensive, but it offers opportunities
    for being parallelized (especially for neural networks); that is, a lot of the
    calculations can run in parallel with one another. For this reason, it''s common
    to perform training in the cloud or some dedicated machines with enough memory
    and compute power. This process of training is illustrated in the following diagram:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型也没有不同；构建模型的初始阶段是通过**训练**过程完成的，在这个过程中，模型被提供了许多示例。对于每个示例，使用**损失函数**代替教师提供反馈，这反过来又用于调整模型以减少损失（模型答案错误的程度）。这个过程可能需要多次迭代，通常是计算密集型的，但它提供了并行化的机会（特别是对于神经网络）；也就是说，很多计算可以并行进行。因此，通常在云端或一些具有足够内存和计算能力的专用机器上执行训练。以下图表展示了这个过程：
- en: '![](img/526df58d-2638-4bfc-85d4-da47fc6dc5c4.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/526df58d-2638-4bfc-85d4-da47fc6dc5c4.png)'
- en: To better illustrate the compute power required, in the blog post *Cortana Intelligence
    and Machine Learning Blog*, Microsoft data scientist Miguel Fierro and others
    detail the infrastructure and time required for training on the ImageNet dataset (1,000
    classes with over 1.2 million photos) using an 18-layer ResNet architecture. It
    took approximately three days to train over 30 epochs on an Azure N-series NC-24
    virtual machine with 4 GPUs, 24 CPU cores, and 224 GB of memory. The full details
    are described here: [https://blogs.technet.microsoft.com/machinelearning/2016/11/15/imagenet-deep-neural-network-training-using-microsoft-r-server-and-azure-gpu-vms/](https://blogs.technet.microsoft.com/machinelearning/2016/11/15/imagenet-deep-neural-network-training-using-microsoft-r-server-and-azure-gpu-vms/).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地说明所需的计算能力，在博客文章《Cortana Intelligence and Machine Learning Blog》中，微软数据科学家Miguel
    Fierro和其他人详细介绍了在ImageNet数据集（1,000个类别，超过1.2百万张照片）上使用18层ResNet架构进行训练的基础设施和时间要求。在一个配备4个GPU、24个CPU核心和224
    GB内存的Azure N-series NC-24虚拟机上，大约需要三天时间训练超过30个epoch。详细内容描述在这里：[https://blogs.technet.microsoft.com/machinelearning/2016/11/15/imagenet-deep-neural-network-training-using-microsoft-r-server-and-azure-gpu-vms/](https://blogs.technet.microsoft.com/machinelearning/2016/11/15/imagenet-deep-neural-network-training-using-microsoft-r-server-and-azure-gpu-vms/)。
- en: 'After the training is complete, the model is now ready for the real world;
    like our student, we can now deploy and use our model to solve unseen problems.
    This is known as **inference**. Unlike training, inference only requires a single
    pass through the model using its gained understanding from training, that is,
    weights and coefficients. Additionally, there are some sections in our model that
    are no longer needed, so there is a degree of pruning (the reduction of less important
    aspects that do not affect accuracy) that can be performed to further optimize
    the model:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，模型现在可以用于现实世界；就像我们的学生一样，我们现在可以部署并使用我们的模型来解决未见过的难题。这被称为**推理**。与训练不同，推理只需要通过模型进行单次遍历，使用其在训练中获得的认知，即权重和系数。此外，我们的模型中还有一些部分不再需要，因此可以进行一定程度的剪枝（减少不影响准确性的不那么重要的方面），以进一步优化模型：
- en: '![](img/6821673b-b328-478f-bea7-4299b8635afe.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6821673b-b328-478f-bea7-4299b8635afe.png)'
- en: Because of these conditions, a single pass, and pruning, we can afford to perform
    inference on less performant machines, like our smartphone. But why would you
    want to do this? What are the advantages of performing inference on the edge?
    This is the topic of the next section.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些条件，单次遍历和剪枝，我们可以在性能较差的机器上执行推理，比如我们的智能手机。但为什么你想这样做呢？在边缘进行推理的优势是什么？这是下一节的主题。
- en: Inference on the edge
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘推理
- en: For those unfamiliar with the term **edge computing**, it simply refers to computation
    performed at the end, or edge, of a network as opposed to sending it to a central
    server for computation. Some examples of edge devices include cars, robots, **Internet
    of Things** (**IoT**), and, of course, smartphones.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些不熟悉“边缘计算”这个术语的人来说，它简单指的是在网络末端或边缘进行的计算，而不是将其发送到中央服务器进行计算。边缘设备的例子包括汽车、机器人、**物联网**（**IoT**）和当然，智能手机。
- en: The motivation for performing computation at the edge, where the data resides,
    is that sending data across the network is expensive and time-consuming; this
    incurred latency and cost restrict us with what experiences we can deliver to
    the user. Removing these barriers opens up new applications that would otherwise
    not be possible. Another benefit of performing inference at the edge is data privacy;
    removing the need of having to transmit personal data across the network reduces
    the opportunities that a malicious user has for obtaining it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据所在边缘进行计算的动力在于，将数据通过网络发送是昂贵且耗时的；这种产生的延迟和成本限制了我们可以提供给用户的体验。移除这些障碍将开启原本不可能的新应用。在边缘进行推理的另一个好处是数据隐私；无需通过网络传输个人数据，减少了恶意用户获取它的机会。
- en: Luckily, technology advances at an astonishing rate and improvements in hardware
    and software have now made it feasible to perform inference at the edge.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，技术以惊人的速度发展，硬件和软件的改进现在使得在边缘进行推理变得可行。
- en: As this book's focus is on applied ML on iOS; **detailed** model architectures
    and training have been intentionally omitted as training currently requires significant
    computational power that is still out of reach of most of today's edge devices
    - although this is likely to change in the near future as edge devices become
    increasingly powerful, with the most likely next advancement being around tuning
    and personalizing models using personal data that resides on the device.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书的重点是iOS上的应用机器学习；**详细**的模型架构和训练已被有意省略，因为当前的训练需要大量的计算能力，而这对于今天的大多数边缘设备来说仍然难以达到——尽管随着边缘设备的日益强大，这种情况可能会在不久的将来改变，最有可能的下一步进展将是使用设备上存储的个人数据调整和个性化模型。
- en: 'Some common use cases for ML on the device include:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 设备上机器学习的常见用例包括：
- en: '**Speech recognition**: It''s currently common to perform wake (or hot) word
    detection locally rather than continuously streaming data across the network.
    For example, **Hey Siri** is most likely performed locally on the device, and
    once detected, it streams the utterance to a server for further processing.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音识别**：目前通常在本地执行唤醒（或热）词检测，而不是在网络中持续传输数据。例如，“嘿，Siri”很可能是在本设备上本地执行的，一旦检测到，它将语音传输到服务器进行进一步处理。'
- en: '**Image recognition**: It can be useful for the device to be able to understand
    what it is seeing in order to assist the user in taking a photo, such as applying
    the appropriate filters, adding captions to the photos to make them easier to
    find and grouping similar images together. These enhancements may not be significant
    enough to justify opening a connection to a remote server, but because these can
    be performed locally, we can use them without worrying about cost, latency, or
    privacy issues.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像识别**：设备能够理解它所看到的内容，以便协助用户拍照，例如应用适当的滤镜、添加标题以便更容易找到照片以及将相似图像分组，这些功能可能不足以证明连接到远程服务器是合理的。但由于这些功能可以在本地执行，我们可以使用它们而无需担心成本、延迟或隐私问题。'
- en: '**Object localization**: Sometimes, it is useful to know not only what is present
    in view, but also where it is in the view. An example of this can be seen in **augmented
    reality** (**AR**) apps, where information is overlaid onto the scene. Having
    these experiences responsive is critical for their success, and therefore there
    is a need for extremely low latency in performing inference.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标定位**：有时，知道视图中的内容以及它们在视图中的位置是有用的。这种例子可以在**增强现实**（**AR**）应用中看到，其中信息被叠加到场景上。这些体验的响应性对于其成功至关重要，因此在进行推理时需要极低的延迟。'
- en: '**Optical character recognition**: One of the first commercial applications
    of neural networks is still just as useful as it was when it was used in American
    post offices in 1989\. Being able to read allows for applications such as digitizing
    a physical copy or performing computations on it; examples include language translation
    or solving a Sudoku puzzle.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**光学字符识别**：神经网络最早的商业应用之一，即使在1989年用于美国邮局时也依然有用。能够读取内容使得数字化物理副本或在其上进行计算成为可能；例如语言翻译或解决数独谜题。'
- en: '**Translation**: Translating from one language to another quickly and accurately,
    even if you don''t have a network connection, is an important use case and complements
    many of the visual-based scenarios we have discussed so far, such as AR and optical
    character recognition.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**翻译**：即使没有网络连接，也能快速准确地翻译一种语言到另一种语言，这是一个重要的用例，并且补充了我们之前讨论的许多基于视觉的场景，例如增强现实和光学字符识别。'
- en: '**Gesture recognition**: Gesture recognition provides us with a rich interaction
    mode, allowing quick shortcuts and intuitive user interactions that can improve
    and enhance user experience.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手势识别**：手势识别为我们提供了一种丰富的交互模式，允许快速捷径和直观的用户交互，这可以改善和增强用户体验。'
- en: '**Text prediction**: Being able to predict the next word the user is going
    to type, or even predicting the user''s response, has turned something fairly
    cumbersome and painful to use (the smartphone soft keyboard) into something that
    is just as quick or even quicker than its counterpart (the conventional keyboard).
    Being able to perform this prediction on the device increases your ability to
    protect the user''s privacy and offer a responsive solution. This is not feasible
    if the request has to be routed to a remote server.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本预测**：能够预测用户将要输入的下一个单词，甚至预测用户的响应，已经将一个相当繁琐且使用起来痛苦的东西（智能手机软键盘）变成了与它的对应物（传统键盘）一样快，甚至更快。能够在设备上执行这种预测提高了您保护用户隐私和提供响应式解决方案的能力。如果请求必须路由到远程服务器，这是不可行的。'
- en: '**Text classification**: This covers everything from sentiment analysis to
    topic discovery and facilitates many useful applications, such as providing means
    to recommend relevant content to the user or eliminate duplicates.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本分类**：这涵盖了从情感分析到主题发现的所有内容，并促进了许多有用的应用，例如为用户提供推荐相关内容或消除重复内容的方法。'
- en: These examples of use cases and applications hopefully show why we may want
    to perform inference on the edge; it means you can offer a higher level of interactivity
    than what could be possible with performing inference off the device. It allows
    you to deliver an experience even if the device has poor network connectivity
    or no network connectivity. And finally, it's scalable—an increase in demand doesn't
    directly correlate to the load on your server.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些用例和应用的示例可能展示了为什么我们可能想在边缘执行推理；这意味着您可以提供比在设备上执行推理更高的交互级别。它允许您在设备网络连接差或没有网络连接的情况下提供体验。最后，它是可扩展的——需求的增加并不直接与服务器负载相关。
- en: 'So far, we have introduced inference and the importance of being able to perform
    it on the edge. In the next section, we will introduce the framework that facilitates
    this on iOS devices: Core ML.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经介绍了推理及其在边缘执行的重要性。在下一节中，我们将介绍在iOS设备上促进这一功能的框架：Core ML。
- en: A brief introduction to Core ML
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Core ML简介
- en: 'With the release of iOS 11 and Core ML, performing inference is just a matter
    of a few lines of code. Prior to iOS 11, inference was possible, but it required
    some work to take a pre-trained model and port it across using an existing framework
    such as **Accelerate** or **metal performance shaders** (**MPSes**). **Accelerate**
    and MPSes are still used under the hood by Core ML, but Core ML takes care of
    deciding which underlying framework your model should use (**Accelerate** using
    the CPU for memory-heavy tasks and MPSes using the GPU for compute-heavy tasks).
    It also takes care of abstracting a lot of the details away; this layer of abstraction
    is shown in the following diagram:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随着iOS 11和Core ML的发布，执行推理只需几行代码。在iOS 11之前，推理是可能的，但需要一些工作来将预训练的模型通过现有的框架（如**Accelerate**或**metal性能着色器**（MPSes））迁移过来。**Accelerate**和MPSes仍然在Core
    ML的底层使用，但Core ML负责决定您的模型应该使用哪个底层框架（对于内存密集型任务使用CPU的**Accelerate**，对于计算密集型任务使用GPU的MPSes）。它还负责抽象掉很多细节；这一层抽象在以下图中展示：
- en: '![](img/fbdf956c-99c2-43fb-a357-834cf0ef66d7.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fbdf956c-99c2-43fb-a357-834cf0ef66d7.png)'
- en: 'There are additional layers too; iOS 11 has introduced and extended domain-specific
    layers that further abstract a lot of the common tasks you may use when working
    with image and text data, such as face detection, object tracking, language translation,
    and **named entity recognition** (**NER**). These domain-specific layers are encapsulated
    in the **Vision** and **natural language processing** (**NLP**) frameworks; we
    won''t be going into any details of these frameworks here, but you will get a
    chance to use them in later chapters:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些额外的层之外；iOS 11引入并扩展了特定领域的层，这些层进一步抽象了您在处理图像和文本数据时可能使用的许多常见任务，例如人脸检测、对象跟踪、语言翻译和**命名实体识别**（NER）。这些特定领域的层封装在**视觉**和**自然语言处理**（NLP）框架中；我们在这里不会深入探讨这些框架的细节，但在后面的章节中，您将有机会使用它们：
- en: '![](img/754528fc-4c89-42c7-8aa1-f3055e811d49.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/754528fc-4c89-42c7-8aa1-f3055e811d49.png)'
- en: It's worth noting that these layers are not mutually exclusive and it is common
    to find yourself using them together, especially the domain-specific frameworks
    that provide useful preprocessing methods we can use to prepare our data before
    sending to a Core ML model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，这些层并不是相互排斥的，你可能会发现自己同时使用它们，特别是那些提供有用的预处理方法的特定领域框架，我们可以在将数据发送到Core ML模型之前使用这些方法来准备数据。
- en: So what exactly is Core ML? You can think of Core ML as a suite of tools used
    to facilitate the process of bringing ML models to iOS and wrapping them in a
    standard interface so that you can easily access and make use of them in your
    code. Let's now take a closer look at the typical workflow when working with Core
    ML.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Core ML究竟是什么呢？你可以将Core ML视为一套工具，用于简化将机器学习模型带到iOS并封装在标准接口中的过程，这样你就可以轻松地在代码中访问和使用它们。现在让我们更详细地看看使用Core
    ML时的典型工作流程。
- en: Workflow
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作流程
- en: As described previously, the two main tasks of a ML workflow consist of **training**
    and **inference**. Training involves obtaining and preparing the data, defining
    the model, and then the real training. Once your model has achieved satisfactory results
    during training and is able to perform adequate predictions (including on data
    it hasn't seen before), your model can then be deployed and used for inference
    using data outside of the training set. Core ML provides a suite of tools to facilitate
    getting a trained model into iOS, one being the Python packaged released called **Core
    ML Tools**; it is used to take a model (consisting of the architecture and weights)
    from one of the many popular packages and exporting a `.mlmodel` file, which can
    then be imported into your Xcode project.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，机器学习工作流程的两个主要任务包括**训练**和**推理**。训练涉及获取和准备数据，定义模型，然后进行实际训练。一旦你的模型在训练期间达到了令人满意的结果，并且能够进行适当的预测（包括对之前未见过的数据），那么你的模型就可以部署并使用训练集之外的数据进行推理。Core
    ML提供了一套工具，以简化将训练好的模型导入iOS的过程，其中之一就是名为**Core ML Tools**的Python打包工具；它用于从一个众多流行的包中提取模型（包括架构和权重），并导出`.mlmodel`文件，然后可以将其导入你的Xcode项目中。
- en: 'Once imported, Xcode will generate an interface for the model, making it easily
    accessible via code you are familiar with. Finally, when you build your app, the
    model is further optimized and packaged up within your application. A summary
    of the process of generating the model is shown in the following diagram:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦导入，Xcode将为模型生成一个接口，使其通过你熟悉的代码轻松访问。最后，当你构建你的应用程序时，模型将得到进一步优化并打包到你的应用程序中。生成模型的流程总结如下图所示：
- en: '![](img/870eb15e-d50e-45c2-a61c-ea386dd88d36.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/870eb15e-d50e-45c2-a61c-ea386dd88d36.png)'
- en: 'The previous diagram illustrates the process of creating the `.mlmodel;`, either
    using an existing model from one of the supported frameworks, or by training it
    from scratch. Core ML Tools supports most of the frameworks, either internal or
    as third party plug-ins, including  Keras, turi, Caffe, scikit-learn, LibSVN,
    and XGBoost frameworks. Apple has also made this package open source and modular
    for easy adaption for other frameworks or by yourself. The process of importing
    the model is illustrated in this diagram:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张图展示了创建`.mlmodel`的过程，无论是使用支持框架中的一个现有模型，还是从头开始训练。Core ML Tools支持大多数框架，无论是内部还是第三方插件，包括Keras、turi、Caffe、scikit-learn、LibSVN和XGBoost框架。苹果公司还使这个包开源并模块化，以便于其他框架或你自己进行适配。导入模型的流程如下图所示：
- en: '![](img/39178104-5b20-473a-8327-dad08a10a23f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/39178104-5b20-473a-8327-dad08a10a23f.png)'
- en: In addition; there are frameworks with tighter integration with Core ML that
    handle generating the Core ML model such as **Turi Create**, **IBM Watson Services
    for Core ML**, and **Create ML**.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些与Core ML更紧密集成的框架，如**Turi Create**、**IBM Watson Services for Core ML**和**Create
    ML**，它们负责生成Core ML模型。
- en: 'We will be introducing Create ML in chapter 10; for those interesting in learning
    more about Turi Create and IBM Watson Services for Core ML then please refer to
    the official webpages via the following links:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第10章介绍Create ML；对于那些对Turi Create和IBM Watson Services for Core ML感兴趣并想了解更多信息的人，请通过以下链接访问官方网站：
- en: Turi Create; [https://github.com/apple/turicreate](https://github.com/apple/turicreate)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Turi Create; [https://github.com/apple/turicreate](https://github.com/apple/turicreate)
- en: IBM Watson Services for Core ML; [https://developer.apple.com/ibm/](https://developer.apple.com/ibm/)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: IBM Watson Services for Core ML; [https://developer.apple.com/ibm/](https://developer.apple.com/ibm/)
- en: Once the model is imported, as mentioned previously, Xcode generates an interface
    that wraps the **model**, model **inputs**, and **outputs**. You will get acquainted
    with these throughout the rest of this book, so we won't go into any further details
    here.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型被导入，如前所述，Xcode 会生成一个界面，该界面封装了 **模型**、模型 **输入** 和 **输出**。你将在本书的其余部分熟悉这些内容，所以我们不会在这里进一步详细介绍。
- en: In the previous diagrams we have seen the workflow of training and importing
    a **model** - let's now delve into the details of what this model is and what
    Core ML currently supports.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的图中，我们已经看到了训练和导入 **模型** 的工作流程——现在让我们深入了解这个模型是什么以及 Core ML 当前支持的内容。
- en: Learning algorithms
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习算法
- en: 'In [Chapter 1](7d4f641f-7137-4a8a-ae6e-2bb0e2a6db5c.xhtml), *Introduction to
    Machine Learning*, we saw many different types of learning algorithms and learned
    that ML is really a process of automatically discovering rules given a set of
    examples. The main components required for this process, specifically for supervised
    learning, include:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第1章](7d4f641f-7137-4a8a-ae6e-2bb0e2a6db5c.xhtml)，*机器学习简介*中，我们看到了许多不同类型的机器学习算法，并了解到机器学习实际上是一个在给定一组示例的情况下自动发现规则的过程。这个过程所需的主要组件，特别是对于监督学习，包括：
- en: '**Input data points**: For image classification, we would require images of
    the domain we want to classify, for example, animals.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入数据点**：对于图像分类，我们需要我们想要分类的领域的图像，例如，动物。'
- en: '**The expected outputs for these inputs**: Continuing from our previous example
    of image classification of animals, the expected outputs could be labels associated
    with each of the images, for example, cat, dog, and many more.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于这些输入的预期输出**：继续我们之前关于动物图像分类的例子，预期输出可以是与每张图像关联的标签，例如，猫、狗以及更多。'
- en: '**A ML algorithm**: This is the algorithm used to automatically learn how to transform
    the input data points into a meaningful output. These derived sets of rules are
    what we call the model, derived through a process of learning called **training**.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习算法**：这是用于自动学习如何将输入数据点转换为有意义输出的算法。这些通过学习过程（称为 **训练**）推导出的规则集就是我们所说的模型。'
- en: Let's make these concepts more concrete by working through a simple example.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一个简单的例子来具体化这些概念。
- en: Auto insurance in Sweden
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 瑞典汽车保险
- en: If you haven't done so already, navigate to the repository at [https://github.com/joshnewnham/MachineLearningWithCoreML](https://github.com/joshnewnham/MachineLearningWithCoreML)
    and download the latest code. Once downloaded, navigate to the directory `Chapter2/Start/`
    and open the playground `LinearRegression.playground`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有这样做，请导航到 [https://github.com/joshnewnham/MachineLearningWithCoreML](https://github.com/joshnewnham/MachineLearningWithCoreML)
    上的存储库并下载最新代码。下载完成后，导航到 `Chapter2/Start/` 目录并打开 playground `LinearRegression.playground`。
- en: 'We will be creating a model that will predict the total payments for all claims
    (y) given the number of claims (x); the dataset we will be working with is auto
    insurance claims in Sweden. It consists of 2 columns and 64 rows, the first column
    containing the number of claims, and the second containing the total payments
    for all claims. Here is an extract from the dataset:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个模型，该模型将根据索赔数量（x）预测所有索赔的总支付额（y）；我们将使用的数据集是瑞典的汽车保险索赔数据。它包含2列和64行，第一列包含索赔数量，第二列包含所有索赔的总支付额。以下是数据集的摘录：
- en: '| **Number of claims** | **Total payments for all claims in thousands of Swedish
    Kronor** |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| **索赔数量** | **所有索赔的总支付额（瑞典克朗千位）** |'
- en: '| --- | --- |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 108 | 329.5 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 108 | 329.5 |'
- en: '| 19 | 46.2 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 19 | 46.2 |'
- en: '| 13 | 15.7 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 15.7 |'
- en: '| 124 | 422.2 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 124 | 422.2 |'
- en: '| ... | ... |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... |'
- en: For more details, visit the source website: [http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/slr06.html](http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/slr06.html).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 更多详情，请访问源网站：[http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/slr06.html](http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/slr06.html)。
- en: 'In the playground script, you will see that we are creating a view of the type
    `ScatterPlotView` and assigning it to the playground''s live view. We will use
    this view to visualize the data and the predictions from our model:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在 playground 脚本中，你会看到我们正在创建一个 `ScatterPlotView` 类型的视图，并将其分配给 playground 的实时视图。我们将使用这个视图来可视化模型的数据和预测：
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'By using this view, we can plot an array of data points using the `view.scatter(dataPoints:)`
    method and draw a line using the `view.line(pointA:,pointB)` method. Let''s load
    the raw data and visualize it:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用这种视图，我们可以使用 `view.scatter(dataPoints:)` 方法绘制一系列数据点，并使用 `view.line(pointA:,pointB)`
    方法绘制一条线。让我们加载数据并可视化它：
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the previous code snippet, we first load the data into the `csvData` variable
    and then cast it into a strongly typed array of `DataPoint` (a strongly typed
    data object, which our view is expecting). Once loaded, we pass our data to the
    view via the `scatter` method, which renders the following output:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们首先将数据加载到 `csvData` 变量中，然后将其转换为强类型数组 `DataPoint`（一个强类型数据对象，我们的视图所期望的）。一旦加载，我们就通过
    `scatter` 方法将我们的数据传递给视图，它渲染以下输出：
- en: '![](img/ac2f3a43-c656-4fdc-ba2b-e51ca485bafc.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ac2f3a43-c656-4fdc-ba2b-e51ca485bafc.png)'
- en: Each dot represents a single datapoint plotted against the number of claims
    (*x* axis) and total payments for all claims (*y* axis). From this visualization,
    we can infer some linear relationship between the **number of claims** and **total
    payments for all claims**; that is, an increase in **number of claims** increases
    the **total payments for all claims**. Using this intuition, we will attempt to
    model the data according to a linear model, one that, when given the **number
    of claims**, is able to predict the **total payments for all claims**. What we
    are describing here is a type of algorithm known as **simple linear regression**;
    in essence, this is just finding a straight line that best fits our data. It can
    be described with the function *y = w * x + b,* where *y* is the **total payments
    for all claims**, *x* is the **number of claims**, *w* is the relationship between
    *y* and *x,* and *b* is the intercept.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 每个点代表一个单独的数据点，它与索赔数量（*x*轴）和所有索赔的总支付额（*y*轴）相对应。从这种可视化中，我们可以推断出索赔数量和所有索赔的总支付额之间的一些线性关系；也就是说，索赔数量的增加会导致所有索赔的总支付额增加。利用这种直觉，我们将尝试根据线性模型建模数据，这种模型在给定索赔数量时能够预测所有索赔的总支付额。我们在这里描述的是一种称为**简单线性回归**的算法；本质上，这只是在寻找最适合我们数据的直线。它可以描述为函数
    *y = w * x + b*，其中 *y* 是所有索赔的总支付额，*x* 是索赔数量，*w* 是 *y* 和 *x* 之间的关系，而 *b* 是截距。
- en: Linear regression is a type of regression model that maps a linear function
    from a set of continuous inputs to a continuous output. For example, you may want
    to model and predict **house prices**; here, your inputs may be the **number of**
    **bedrooms** and the **number of bathrooms**. Using these two features, you'd
    want to find a function that can predict the house price, one that assumes there
    is a linear correlation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是一种回归模型，它将一组连续输入映射到一个连续输出上的线性函数。例如，你可能想要建模和预测**房价**；在这里，你的输入可能是**卧室数量**和**浴室数量**。使用这两个特征，你将想要找到一个可以预测房价的函数，它假设存在线性相关性。
- en: Simple enough! Our next problem is finding this line that best fits our data.
    For this, we are going to use an approach called **gradient descent**;there are
    plenty of books that go into the theoretical and technical details of gradient
    descent, so here we will just present some intuition behind it and leave it to
    you, the curious reader, to study the details.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 简单易懂！我们接下来的问题是找到最适合我们数据的这条线。为此，我们将使用一种称为**梯度下降**的方法；关于梯度下降的理论和技术细节有很多书籍进行深入探讨，所以在这里我们只介绍一些背后的直觉，并留给好奇的读者去研究细节。
- en: Gradient descent is a set of algorithms that minimize a function; in our case,
    they minimize the loss of our output with respect to the actual output. They achieve
    this by starting with an initial set of parameters (weights or coefficients) and
    iteratively adjusting these to minimize the calculated loss. The direction and
    magnitude of these adjustments are determined by how far off the predicted value
    is compared to the expected error and the parameters' contribution.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一组算法，用于最小化一个函数；在我们的情况下，它们最小化输出与实际输出之间的损失。它们通过从一个初始参数集（权重或系数）开始，并迭代调整这些参数以最小化计算出的损失来实现这一点。这些调整的方向和幅度由预测值与预期误差以及参数贡献之间的差异决定。
- en: 'You can think of gradient descent as a search for some minimum point; what
    determines this minimum point is something called a **loss function**. For us,
    it will be the absolute error between our prediction and actual number of claims.
    The algorithm is steered by calculating the relative contribution of each of our
    variables (here it is *w*and *b*). Let''s see how this looks in code by working
    through the `train` method:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将梯度下降视为寻找某个最小点的搜索；决定这个最小点的东西被称为**损失函数**。对我们来说，它将是我们的预测与实际索赔数量之间的绝对误差。算法通过计算我们每个变量的相对贡献（这里是指*w*和*b*）来引导。让我们通过`train`方法来看看它在代码中的样子：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Our `train` method takes in these arguments:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`train`方法接受以下参数：
- en: '`x`: An array of `DataPoint` containing the number of claims'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：一个包含索赔数量的`DataPoint`数组'
- en: '`y`: An array of `DataPoint` containing the total number of payments'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`：一个包含总支付次数的`DataPoint`数组'
- en: '`b`: This is a random value used in our linear function to start our search'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b`：这是在我们的线性函数中用于开始搜索的随机值'
- en: '`w`: Another random value used in our linear function to start our search'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`w`：在我们的线性函数中用于开始搜索的另一个随机值'
- en: '`learningRate`: How quickly we adjust the weights'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learningRate`：我们调整权重的速度'
- en: '`epochs`: The number of times we iterate, that is, make a prediction, and adjust
    our coefficients based on the difference between the prediction and expected value'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epochs`：我们迭代的次数，也就是说，进行预测，并根据预测值和期望值之间的差异调整我们的系数'
- en: '`trainingCallback`: This function is called after each epoch to report the
    progress'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainingCallback`：这个函数在每个时代之后被调用以报告进度'
- en: We next create some variables that will be used throughout training and begin
    our search (`for epoch in 0...epochs`). Let's step through each `TODO` and replace
    them with their respective code.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一些将在整个训练过程中使用的变量，并开始搜索（`for epoch in 0...epochs`）。让我们逐步通过每个`TODO`并将它们替换为相应的代码。
- en: 'First, we start by creating two variables to hold the gradients for our variables
    `b` and `w` (these are the adjustments we need to make to their respective coefficients
    to minimize the loss, also known as **absolute error**):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建两个变量来保存变量`b`和`w`的梯度（这些是我们需要对其各自的系数进行调整以最小化损失，也称为**绝对误差**）：
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we iterate over each data point, and for each data point, make a prediction
    and calculate the absolute error:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们遍历每个数据点，并对每个数据点进行预测，然后计算绝对误差：
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now calculate the partial derivative with respect to the error. Think of this
    as a way to steer the search in the right direction, that is, calculating this
    gives us the **direction** and **magnitude** that we need to change `b` and `w`
    to minimize our error:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，计算关于误差的偏导数。将这视为引导搜索正确方向的方法，也就是说，计算这个值给我们提供了改变`b`和`w`以最小化我们的误差所需的**方向**和**大小**：
- en: Note that this is done after iterating through all data points; that is, it
    is influenced by all data points. Alternatives are to perform this update per
    data point or over a subset, known as a **batch**.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这是在遍历所有数据点之后完成的；也就是说，它受到所有数据点的影响。另一种选择是针对每个数据点或子集（称为**批次**）执行此更新。
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After iterating over each data point, we adjust the coefficients `B` and `W`
    using their accumulated gradients.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在遍历每个数据点之后，我们使用它们的累积梯度调整系数`B`和`W`。
- en: 'After each epoch, `trainingCallback` is called to draw a line using the current
    model''s coefficients (its current best fit line that fits the data); the progress
    of this is shown in the following diagram:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 每经过一个时代，就会调用`trainingCallback`来使用当前模型的系数（其当前最佳拟合线，该线适合数据）绘制一条线；这个过程在下面的图中显示：
- en: '![](img/92f56310-c232-481b-947c-6072e198f4f7.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/92f56310-c232-481b-947c-6072e198f4f7.png)'
- en: 'Admittedly, this is difficult to interpret without a key! But the pattern will
    hopefully be obvious; with each iteration, our line better fits the data. After
    100 epochs, we end up with this model:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 诚然，没有关键信息很难解释！但希望模式会很明显；随着每次迭代的进行，我们的线将更好地拟合数据。经过100个时代后，我们得到这个模型：
- en: '![](img/0ef20d7f-0f58-4561-b958-182ea6f17a50.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ef20d7f-0f58-4561-b958-182ea6f17a50.png)'
- en: The function describing this line is `y = 0.733505317339142 + 3.4474988368438
    * x`. Using this model, we can predict the **total payments for all claims** given
    the **number of claims** (by simply substituting *x* with the **number of claims**).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 描述这条线的函数是`y = 0.733505317339142 + 3.4474988368438 * x`。使用这个模型，我们可以根据**索赔数量**（只需将*x*替换为**索赔数量**）预测**所有索赔的总支付额**。
- en: Supported learning algorithms
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持的学习算法
- en: 'In the previous example, we used **l****inear regression** (algorithm) to build
    a model that predicts the total payments for all claims (output) given the number
    of claims (input). This is one of many algorithms available for ML; a few of them
    are plotted in the following diagram, grouped into **unsupervised** or **supervised**,
    and **continuous** or **categorical**:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们使用**线性回归**（算法）构建了一个模型，该模型根据索赔数量（输入）预测所有索赔的总支付额（输出）。这是许多机器学习算法之一；以下图表中绘制了一些算法，分为**无监督**或**监督**，以及**连续**或**分类**：
- en: '![](img/2a171496-cdec-4b72-a2d2-a09dbbdc50d3.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2a171496-cdec-4b72-a2d2-a09dbbdc50d3.png)'
- en: 'The process of creating Core ML models involves translating the model from
    the source framework into something that can be run on iOS. The following diagram
    shows which learning algorithms Core ML currently supports:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 创建Core ML模型的过程涉及将模型从源框架转换为可以在iOS上运行的形式。以下图表显示了Core ML目前支持的学习算法：
- en: '![](img/eb816183-f6b1-4030-ac42-8bd66a56f8d0.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/eb816183-f6b1-4030-ac42-8bd66a56f8d0.png)'
- en: The supported algorithms and neural networks should be versatile enough for
    most ML tasks but given how fast this field is moving, it's inevitable that you
    will encounter one that is not supported. Apple have anticipated this and provides
    two protocols for extending the framework; `MLCustomLayer` can be used to create
    custom layers (which we cover in later chapters) and `MLCustomModel` for creating
    custom models.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 支持的算法和神经网络应该足够灵活，以适应大多数机器学习任务，但鉴于这个领域发展迅速，你不可避免地会遇到一些不受支持的算法。苹果公司已经预见到这一点，并提供了两种扩展框架的协议；`MLCustomLayer`可用于创建自定义层（我们将在后续章节中介绍）和`MLCustomModel`用于创建自定义模型。
- en: This has hopefully given you some idea of where Core ML fits in the general
    ML workflow and why Apple has made the design decisions it has. We will finish
    this chapter by looking at a few high-level considerations when dealing with ML
    on an iOS device, or, more generally, the edge before wrapping up.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能让你对Core ML在一般机器学习工作流程中的位置以及苹果为何做出这些设计决策有了些了解。我们将通过查看在iOS设备上处理机器学习时的一些高级考虑因素来结束本章，或者更普遍地说，在总结之前，关注边缘计算。
- en: Considerations
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考虑因素
- en: 'When performing ML on the edge, you lose some of the luxuries you tend to have
    when running on a more powerful device (albeit this is shifting all the time).
    Here is a list of considerations to keep in mind:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在边缘执行机器学习时，你会失去在更强大的设备上运行时通常拥有的某些奢侈（尽管这一切都在不断变化）。以下是一些需要记住的考虑因素：
- en: '**Model size**: Previously, we walked through building a simple linear regression
    model. The model itself consists of two floats (bias and weight coefficients),
    which of course are negligible in terms of memory requirements. But, as you dive
    into the world of deep learning, it''s common to find models hundreds of megabytes in
    size. For example, the VGG16 model is a 16-layer conventional neural network architecture
    trained on the ImageNet dataset used for image classification, available on Apple''s
    site. It is just over 500 megabytes. Currently, Apple allows apps 2 gigabytes in
    size, but asking your user to download such a large file may well put them off.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型大小**：之前，我们介绍了构建一个简单的线性回归模型。该模型本身由两个浮点数（偏差和权重系数）组成，当然在内存需求方面是可以忽略不计的。但是，当你深入到深度学习的世界时，你会发现模型的大小通常是几百兆字节。例如，VGG16模型是一个16层的传统神经网络架构，在用于图像分类的ImageNet数据集上训练，可在苹果网站上找到。它的大小正好超过500兆字节。目前，苹果允许应用的大小为2吉字节，但要求用户下载如此大的文件可能会让他们望而却步。'
- en: '**Memory**: It''s not just the executable size that you need to be mindful
    of, but also the amount of working memory available. It''s common for desktop
    machines to have memory in the range of 16-32 gigabytes, but the memory for the
    latest iPhone (iPhone 8) is just 2 gigabytes—impressive for a mobile device, but
    quite a difference from its counterpart. This constraint is likely to dictate
    what model you choose, more so than how much memory it takes on disk. It is also
    worth mentioning that it''s not just the model weights you''ll need to load into
    the memory; you will also need to load in any label data and, of course, the input
    data you are performing inference on.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存**：你需要注意的不仅仅是可执行文件的大小，还有可用的工作内存量。桌面机器通常具有16-32吉字节的内存，但最新iPhone（iPhone 8）的内存仅为2吉字节——对于一个移动设备来说非常令人印象深刻，但与其对应设备相比，差距很大。这种限制可能会决定你选择哪种模型，而不是它在磁盘上占用的内存量。还值得一提的是，你需要加载到内存中的不仅仅是模型权重；你还需要加载任何标签数据，当然，还有你正在执行推理的输入数据。'
- en: '**Speed**: This, of course, is correlated to the model size (in normal circumstances)
    and relevant to your specific use case. Just keep in mind that performing inference
    is only one part of the workflow. You have pre-processing and post-processing
    tasks that also need to be taken into account, such as loading and pre-processing
    the input data. In some cases, you may have to trade off accuracy with performance
    and size.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：这当然与模型大小（在正常情况下）相关，并适用于您的特定用例。只需记住，执行推理只是工作流程的一部分。您还需要考虑预处理和后处理任务，例如加载和预处理输入数据。在某些情况下，您可能需要在准确性和性能、大小之间进行权衡。'
- en: '**Supported algorithms and data types**: In the previous section, we presented
    the current algorithms that Core ML supports. Along with these, Core ML supports
    a subset of data types, summarized in the following table for convenience:'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持算法和数据类型**：在前一节中，我们介绍了Core ML当前支持的算法。除此之外，Core ML还支持一部分数据类型，以下表格中为了方便起见进行了总结：'
- en: '| **Input type** | **Data type** |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| **输入类型** | **数据类型** |'
- en: '| --- | --- |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Numeric | `Double`, `Int64` |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 数字 | `Double`, `Int64` |'
- en: '| Categories | `String`, `Int64` |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | `String`, `Int64` |'
- en: '| Images | `CVPixelBuffer` |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 图像 | `CVPixelBuffer` |'
- en: '| Arrays | `MLMultiArray` |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 数组 | `MLMultiArray` |'
- en: '| Dictionaries  | `[String : Double]`, `[Int64, Double]` |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 字典 | `[String : Double]`, `[Int64, Double]` |'
- en: Here, we have presented just a few of the considerations at a high level when
    performing ML on a mobile device. The specifics will be dependent on your use
    case and models available, but it's worth keeping these in the back of your mind
    and reminding yourself that these, albeit very powerful devices, are still mobile
    devices. They run on a battery and are therefore subject to the typical considerations
    and optimizations normally required for a mobile project. These considerations
    are even more applicable to those who plan to create their own model, which should
    be most of you if you plan to take advantage of ML.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们仅从高层次上介绍了在移动设备上执行机器学习时的一些考虑因素。具体细节将取决于您的用例和可用的模型，但值得将这些考虑因素放在心中，并提醒自己，尽管这些设备功能强大，但它们仍然是移动设备。它们运行在电池上，因此需要考虑通常对移动项目所需的典型考虑和优化。对于计划创建自己模型的人来说，这些考虑因素尤为重要，如果您的计划是利用机器学习。
- en: Summary
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the difference between training and inference,
    along with the typical ML workflow and where Core ML fits in. We also saw how
    Core ML is not just a single framework, but rather a suite of tools that facilitate
    getting pretrained models into the iOS platform and making them available to your
    application via a familiar and simple interface. Thus, it democratizes ML and
    puts it into the hands of many iOS app developers.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了训练和推理之间的区别，以及典型的机器学习工作流程以及Core ML如何融入其中。我们还看到了Core ML不仅仅是一个框架，而是一套工具，它有助于将预训练模型引入iOS平台，并通过熟悉且简单的界面使它们对您的应用程序可用。因此，它使机器学习民主化，并将其交到许多iOS应用开发者的手中。
- en: 'It has been suggested that the explosion in diverse apps contributed to the
    success of the adoption of smartphones; if this is true, then prepare yourself
    for the next explosion of AI-enhanced apps. And take comfort knowing that you
    are in the perfect place to begin and lead this journey, where we will explore
    many concepts and examples related to computer vision using Core ML, including
    these:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 有观点认为，各种应用的激增有助于智能手机采用的成功；如果这是真的，那么请准备好迎接下一个增强型AI应用的爆炸式增长。并且请放心，您正处于开始和引领这一旅程的完美位置，我们将探索许多与Core
    ML相关的计算机视觉概念和示例，包括以下内容：
- en: Recognizing objects through the video feed of your camera
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过摄像头视频流识别物体
- en: Leveraging object detection to build intelligent image search, allowing you
    to search for images with specific objects and their position relative to one
    another
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用目标检测构建智能图像搜索，允许您搜索具有特定物体及其相对位置的图像
- en: Recognizing facial expressions and inferring the emotional state of a person
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别面部表情并推断人的情绪状态
- en: Recognizing hand-drawn sketches using convolutional neural networks and then
    with recurrent neural networks
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卷积神经网络识别手绘草图，然后使用循环神经网络
- en: Learning the secrets behind Prisma's style transfer and implementing your own
    version
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习Prisma风格转换背后的秘密并实现自己的版本
- en: Finally, using image segmentation to create the action shot effect
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，使用图像分割创建动作镜头效果
- en: There is plenty to get through, so let's get started!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多内容需要了解，让我们开始吧！
