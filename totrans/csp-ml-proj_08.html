<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Handwritten Digit Recognition</h1>
                
            
            <article>
                
<p class="calibre2">We have looked at how to build recommendation models using multi-class classification models. In this chapter, we are going to expand our knowledge and experience of building multi-class classification models with an image dataset. Image recognition is a well-known <strong class="calibre4">machine learning</strong> (<strong class="calibre4">ML</strong>) problem and is one of the topics that are actively being researched. One image recognition problem that has high applicability to our lives is recognizing handwritten letters and digits. A good example of the application of a handwritten image recognition system is the address recognition system that is used at post offices. Using such a technology, post offices can now automatically and more quickly identify addresses that are written by hand, and expedite and improve overall mailing services.</p>
<p class="calibre2">In this chapter, we are going to build machine learning models for handwritten digit recognition. We are going to start with a dataset that contains grayscale pixel-by-pixel information about over 40,000 handwritten digit images. We will look at the distributions of the values in each pixel and discuss how sparse this grayscale image dataset is. Then, we are going to discuss when and how to apply dimensionality reduction techniques, more specifically <strong class="calibre4">Principal Component Analysis</strong> (<strong class="calibre4">PCA</strong>), and how we can benefit from this technique for our image recognition project. We will be exploring different learning algorithms, such as logistic regression and Naive Bayes, and will also cover how to build an <strong class="calibre4">Artificial Neural Network</strong> (<strong class="calibre4">ANN</strong>), which forms the backbone of deep learning technologies, using the Accord.NET framework. Then, we will compare the prediction performances of these ML models by looking at various evaluation metrics, and discuss which model performed the best for the handwritten digit recognition project.</p>
<p class="calibre2">In this chapter, we will cover the following topics:</p>
<ul class="calibre10">
<li class="calibre11">Problem definition for the handwritten digit recognition project</li>
<li class="calibre11">Data analysis for an image dataset</li>
<li class="calibre11">Feature engineering and dimensionality reduction</li>
<li class="calibre11">ML models for h<span>andwritten digit recognition</span></li>
<li class="calibre11">Evaluating multi-class classification models</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Problem definition</h1>
                
            
            <article>
                
<p class="calibre2">Image recognition technology can be applied to, and can be found easily in, our daily lives. At post offices, image recognition systems are used to programmatically understand addresses that are written by hand. Social network services, such as Facebook, use image recognition technology for automatic people tag suggestions, for instance, when you want to tag people in your photos. Also, as briefly mentioned in the very first chapter of this book, Microsoft's Kinect uses image recognition technology for its motion-sensing games. Of these real-life applications, we are going to experiment with building a handwritten digit recognition system. As you can imagine, such digit image recognition models and systems can be used for automated handwritten address recognition at post offices. Before we had this ability to teach machines to identify and understand handwritten digits, people had to go through and look at each letter to find out the destination and the origin of individual letters. However, now that we can train machines to understand handwritten addresses, mailing processes have become much easier and faster.</p>
<p class="calibre2">In order to build a handwritten digit recognition model, we are going to use the <strong class="calibre4">MNIST</strong> dataset, which has over 60,000 handwritten digit images. The <strong class="calibre4">MNIST</strong> dataset contains 28 x 28 images that are in grayscale. You can find more information at this link: <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" class="calibre9">http://yann.lecun.com/exdb/mnist/</a>. For this project, we will be using a cleaned and processed MNIST dataset that can be found at this link: <a href="https://www.kaggle.com/c/digit-recognizer/data" class="calibre9">https://www.kaggle.com/c/digit-recognizer/data</a>. With this data, we will first look at how the digits are distributed across the dataset, and how sparse the feature set is. Then, we are going to use PCA for dimensionality reduction and to visualize the differences in the distributions of features among different classes. With this PCA-transformed data, we are going to train a few ML models to compare their prediction performances. On top of logistic regression and Naive Bayes classification algorithms, we are going to experiment with the ANN, as it is known to work well for image datasets. We will look at accuracy, precision versus recall, and <strong class="calibre4">area under the curve</strong> (<strong class="calibre4">AUC</strong>), to compare the prediction performances among different machine learning models.</p>
<p class="calibre2"><span class="calibre5">To summarize our problem definition for the handwritten digit recognition project:</span></p>
<ul class="calibre10">
<li class="calibre11">What is the problem? We need a handwritten digit recognition model that can classify each handwritten image into a corresponding digit class, so that it can be used for applications such as the address recognition system.</li>
<li class="calibre11">Why is it a problem? Without such a model, it takes an enormous amount of human labor to identify and organize letters by addresses. If we have a technology that can recognize handwritten digits that are written on letters, it can significantly reduce the amount of human labor required for the same task.</li>
<li class="calibre11">What are some of the approaches to solving this problem? We are going to use publicly available data that contains numerous examples of handwritten digit images. With this data, we are going to build machine learning models that can classify each image into one of 10 digits.</li>
<li class="calibre11">What are the success criteria? We want a machine learning model that accurately classifies each image with the corresponding digit. Since this model will eventually be used for address recognition, we want high precision rates, even if we have to sacrifice recall rates.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Data analysis for the image dataset</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">Let's start looking into this image dataset. As mentioned in the previous section, we will be using the data from this link: <a href="https://www.kaggle.com/c/digit-recognizer/data" target="_blank" class="calibre9">https://www.kaggle.com/c/digit-recognizer/data</a>. You can download the <kbd class="calibre12">train.csv</kbd> data from the link and store it in a place from where you can load it into your C# environment.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Target variable distribution</h1>
                
            
            <article>
                
<p class="calibre2">The first thing we are going to look at is the distribution of the target variables. Our target variable is encoded in the <kbd class="calibre12">label</kbd> column, which can take values between 0 and 9, and represents the digit that the image belongs to. The following code snippet shows how we aggregated the data by the target variable and counted the number of examples for each digit:</p>
<pre class="calibre19">var digitCount = featuresDF.AggregateRowsBy&lt;string, int&gt;(<br class="title-page-name"/>    new string[] { "label" },<br class="title-page-name"/>    new string[] { "pixel0" },<br class="title-page-name"/>    x =&gt; x.ValueCount<br class="title-page-name"/>).SortRows("pixel0");<br class="title-page-name"/><br class="title-page-name"/>digitCount.Print();<br class="title-page-name"/><br class="title-page-name"/>var barChart = DataBarBox.Show(<br class="title-page-name"/>    digitCount.GetColumn&lt;string&gt;("label").Values.ToArray(),<br class="title-page-name"/>    digitCount["pixel0"].Values.ToArray()<br class="title-page-name"/>).SetTitle(<br class="title-page-name"/>    "Digit Count"<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">As in other chapters, we used the <kbd class="calibre12">AggregateRowsBy</kbd> method in Deedle's data frame to aggregate data by the target variable, <kbd class="calibre12">label</kbd>, count the number of records in each label, and sort by the counts. Similar to previous chapters, we are using the <kbd class="calibre12">DataBarBox</kbd> class to display a bar plot of target variable distributions in the dataset. The following is the bar plot that you will see when you run this code:</span></p>
<div class="mce-root"><img src="../images/00119.jpeg" class="calibre87"/></div>
<p class="calibre2"><span class="calibre5">In the console output, you will see the following:</span></p>
<div class="mce-root"><img class="alignnone52" src="../images/00120.gif"/></div>
<p class="calibre2"><span class="calibre5">As you can see from the bar plot and this console output, the digit <kbd class="calibre12">1</kbd>, occurs the most in the dataset, and the digit <kbd class="calibre12">5</kbd>, occurs the least. However, there is no one class that takes the majority of the examples in the dataset, and the target variables are pretty well balanced and spread across different classes.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Handwritten digit images</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">Before we start looking into the feature set, let's first look at actual images of handwritten digits. In each record of our dataset, we have the grayscale values for 784 pixels for each of the 28 x 28 images. In order to build an image from this flattened dataset, we need to first convert each array of 784-pixel values into a two-dimensional array. The following code shows the helper function we wrote to create an image from a flattened array:</span></p>
<pre class="calibre19">private static void CreateImage(int[] rows, string digit)<br class="title-page-name"/>{<br class="title-page-name"/>    int width = 28;<br class="title-page-name"/>    int height = 28;<br class="title-page-name"/>    int stride = width * 4;<br class="title-page-name"/>    int[,] pixelData = new int[width, height];<br class="title-page-name"/><br class="title-page-name"/>    for (int i = 0; i &lt; width; ++i)<br class="title-page-name"/>    {<br class="title-page-name"/>        for (int j = 0; j &lt; height; ++j)<br class="title-page-name"/>        {<br class="title-page-name"/>            byte[] bgra = new byte[] { (byte)rows[28 * i + j], (byte)rows[28 * i + j], (byte)rows[28 * i + j], 255 };<br class="title-page-name"/>            pixelData[i, j] = BitConverter.ToInt32(bgra, 0);<br class="title-page-name"/>        }<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    Bitmap bitmap;<br class="title-page-name"/>    unsafe<br class="title-page-name"/>    {<br class="title-page-name"/>        fixed (int* ptr = &amp;pixelData[0, 0])<br class="title-page-name"/>        {<br class="title-page-name"/>            bitmap = new Bitmap(width, height, stride, PixelFormat.Format32bppRgb, new IntPtr(ptr));<br class="title-page-name"/>        }<br class="title-page-name"/>    }<br class="title-page-name"/>    bitmap.Save(<br class="title-page-name"/>        String.Format(@"\\Mac\Home\Documents\c-sharp-machine-learning\ch.8\input-data\{0}.jpg", digit)<br class="title-page-name"/>    );<br class="title-page-name"/>}</pre>
<p class="calibre2">As you can see from this code, it first initializes a two-dimensional integer array, <kbd class="calibre12">pixelData</kbd>, which is going to store the pixel data. Since we know each image is a 28 x 28 image, we are going to take the first 28 pixels in the flattened data as the first row in the two-dimensional integer array, the second set of 28 pixels as the second row, and so forth. Inside the <kbd class="calibre12">for</kbd> loop, we are converting the value of each pixel into a <strong class="calibre4">Blue-Green-Red-Alpha</strong> (<strong class="calibre4">BGRA</strong>) byte array, named <kbd class="calibre12">bgra</kbd>. As we know the images are in grayscale, we can use the same value for blue, green, and red components. Once we have converted the flattened pixel data into a 28 x 28 two-dimensional integer array, we can now build images of the handwritten digit images. We are using the <kbd class="calibre12">Bitmap</kbd> class to reconstruct these handwritten digit images. The following code shows how we used this helper function to build images for each digit:</p>
<pre class="calibre19">ISet&lt;string&gt; exportedLabels = new HashSet&lt;string&gt;();<br class="title-page-name"/>for(int i = 0; i &lt; featuresDF.RowCount; i++)<br class="title-page-name"/>{<br class="title-page-name"/>    exportedLabels.Add(featuresDF.Rows[i].GetAs&lt;string&gt;("label"));<br class="title-page-name"/><br class="title-page-name"/>    CreateImage(<br class="title-page-name"/>        featuresDF.Rows[i].ValuesAll.Select(x =&gt; (int)x).Where((x, idx) =&gt; idx &gt; 0).ToArray(),<br class="title-page-name"/>        featuresDF.Rows[i].GetAs&lt;string&gt;("label")<br class="title-page-name"/>    );<br class="title-page-name"/><br class="title-page-name"/>    if(exportedLabels.Count() &gt;= 10)<br class="title-page-name"/>    {<br class="title-page-name"/>        break;<br class="title-page-name"/>    }<br class="title-page-name"/>}</pre>
<p class="calibre2">When you run this code, you will see the following images being stored on your local drive:</p>
<div class="mce-root"><img class="alignnone53" src="../images/00121.gif"/></div>
<p class="calibre2"><span class="calibre5">You can use the same code to generate more images, which will help you better understand what raw images of handwritten digits look like.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Image features - pixels</h1>
                
            
            <article>
                
<p class="calibre2">Let's now look at image features. In our dataset, we have integer values for each pixel in each image that represent a grayscale value. It will be helpful to understand the ranges of values each pixel can take, and whether we can find any noticeable differences in the distributions of that pixel data among different handwritten digit classes.</p>
<p class="calibre2">We will first take a look at individual distributions of pixel data. The following code snippet shows how you can calculate the quartiles for each pixel in our dataset:</p>
<pre class="calibre19">List&lt;string&gt; featureCols = new List&lt;string&gt;();<br class="title-page-name"/>foreach (string col in featuresDF.ColumnKeys)<br class="title-page-name"/>{<br class="title-page-name"/>    if (featureCols.Count &gt;= 20)<br class="title-page-name"/>    {<br class="title-page-name"/>        break;<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    if (col.StartsWith("pixel"))<br class="title-page-name"/>    {<br class="title-page-name"/>        if (featuresDF[col].Max() &gt; 0)<br class="title-page-name"/>        {<br class="title-page-name"/>            featureCols.Add(col);<br class="title-page-name"/><br class="title-page-name"/>            Console.WriteLine(String.Format("\n\n-- {0} Distribution -- ", col));<br class="title-page-name"/>            double[] quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>                featuresDF[col].ValuesAll.ToArray(),<br class="title-page-name"/>                new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>            );<br class="title-page-name"/>            Console.WriteLine(<br class="title-page-name"/>                "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>                quantiles[0], quantiles[1], quantiles[2], quantiles[3], quantiles[4]<br class="title-page-name"/>            );<br class="title-page-name"/>        }<br class="title-page-name"/><br class="title-page-name"/>    }<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">Similar to the case previous chapters, we used the <kbd class="calibre12">Quantiles</kbd> method in <kbd class="calibre12">Accord.Statistics.Measures</kbd> to get the quartiles for each pixel. As you might recall from previous chapters, quartiles are the values that separate the data into four sections. In other words, the first quartile (<kbd class="calibre12">Q1</kbd>) represents the 25% percentile that is the middle point between the minimum value and the median value. The second quartile (<kbd class="calibre12">Q2</kbd>) represents the median value, and the third quartile (<kbd class="calibre12">Q3</kbd>) represents the 75% percentile that is the middle point between the median and the maximum. In this code example, we are only computing quartiles for the first 20 pixels that have values other than 0, as you can see in lines 4-7, and in line 11. When you run this code, you will get an output that looks like the following:</span></p>
<div class="mce-root"><img class="alignnone54" src="../images/00122.gif"/></div>
<p class="calibre2"><span class="calibre5">Here, we are only showing the first five distributions. As you can see from this output, the majority of the pixel values are 0. If you look at the images that we reconstructed in the previous section, the majority of the pixels in the image are black and only a subset of the pixels are used to show digits. These pixels in black are encoded as <kbd class="calibre12">0</kbd> in our pixel data, and thus it is expected that many pixels have 0 values for the corresponding image.</span></p>
<p class="calibre2">Let's build some scatter plots, so that we can understand this data better visually. The following code builds scatter plots of distributions of the first 20 non-zero pixel features for each handwritten digit:</p>
<pre class="calibre19">string[] featureColumns = featureCols.ToArray();<br class="title-page-name"/><br class="title-page-name"/>foreach (string label in digitCount.GetColumn&lt;string&gt;("label").Values)<br class="title-page-name"/>{<br class="title-page-name"/>    var subfeaturesDF = featuresDF.Rows[<br class="title-page-name"/>        featuresDF.GetColumn&lt;string&gt;("label").Where(x =&gt; x.Value == label).Keys<br class="title-page-name"/>    ].Columns[featureColumns];<br class="title-page-name"/><br class="title-page-name"/>    ScatterplotBox.Show(<br class="title-page-name"/>        BuildXYPairs(<br class="title-page-name"/>            subfeaturesDF.Columns[featureColumns].ToArray2D&lt;double&gt;(),<br class="title-page-name"/>            subfeaturesDF.RowCount,<br class="title-page-name"/>            subfeaturesDF.ColumnCount<br class="title-page-name"/>        )<br class="title-page-name"/>    ).SetTitle(String.Format("Digit: {0} - 20 sample Pixels", label));<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">If you look closely at this code, we first build a <kbd class="calibre12">featureColumns</kbd> string array from the <kbd class="calibre12">featureCols</kbd></span>, <span class="calibre5"><kbd class="calibre12">List</kbd> object. The <kbd class="calibre12">List</kbd> object, <kbd class="calibre12">featureCols</kbd>, is a list of the first 20 pixels that have values other than 0, and this was built from the previous code when we were computing quartiles. We are using the same helper function, <kbd class="calibre12">BuildXYPairs</kbd>, that we used in the previous chapter to transform the data frame into an array of x-y pairs, where the <kbd class="calibre12">x</kbd> values are the indexes of each pixel and the <kbd class="calibre12">y</kbd> values are the actual pixel value. Using this helper function, we use the <kbd class="calibre12">ScatterplotBox</kbd> class to display a scatter plot that shows the pixel distribution for each of the 20 sample pixels.</span></p>
<p class="calibre2">The following is a scatter plot for the 0 digit:</p>
<div class="mce-root"><img src="../images/00123.jpeg" class="calibre88"/></div>
<p class="calibre2"><span class="calibre5">The majority of the first 20 pixels have 0 values for all the images in the 0 digit class. Of those 20 pixels that we show in this scatter plot, there are only three pixels that have values other than 0. Let's look at the distributions of these pixels for a different digit class.</span></p>
<p class="calibre2">The following scatter plot is for the 1 digit class:</p>
<div class="mce-root"><img src="../images/00124.jpeg" class="calibre89"/></div>
<p class="calibre2"><span class="calibre5">Similar to the case of the 0 digit class, of those 20 pixels that we show here, the majority have 0 values and only three pixels have values other than 0. Compared to the previous scatter plot for of the 0 digit class, the distributions of the pixel data are slightly different for the 1 digit class.</span></p>
<p class="calibre2">The following is for the 2 digit class:</p>
<div class="mce-root"><img src="../images/00125.jpeg" class="calibre90"/></div>
<p class="calibre2"><span class="calibre5">This scatter plot shows quite different distributions for the 20 pixels that we show here. The majority of those 20 pixels have values ranging between 0 and 255, and only a few have 0 values for all the images. This kind of difference in the distributions of the feature set will help our ML models learn how to correctly classify handwritten digits.</span></p>
<p class="calibre2">Lastly, we are going to look at one more scatter plot, where we will see how the target variables are distributed across two different pixels. We used the following code to generate a sample two-dimensional scatter plot:</p>
<pre class="calibre19">double[][] twoPixels = featuresDF.Columns[<br class="title-page-name"/>    new string[] { featureColumns[15], featureColumns[16] }<br class="title-page-name"/>].Rows.Select(<br class="title-page-name"/>    x =&gt; Array.ConvertAll&lt;object, double&gt;(x.Value.ValuesAll.ToArray(), o =&gt; Convert.ToDouble(o))<br class="title-page-name"/>).ValuesAll.ToArray();<br class="title-page-name"/><br class="title-page-name"/>ScatterplotBox.Show(<br class="title-page-name"/>    String.Format("{0} vs. {1}", featureColumns[15], featureColumns[16]), <br class="title-page-name"/>    twoPixels,<br class="title-page-name"/>    featuresDF.GetColumn&lt;int&gt;("label").Values.ToArray()<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">For illustration purposes, we chose the fifteenth and sixteenth indexed features, which turn out to be <kbd class="calibre12">pixel43</kbd> and <kbd class="calibre12">pixel44</kbd>. When you run this code, you will see the following scatter plot:</span></p>
<div class="mce-root"><img src="../images/00126.jpeg" class="calibre91"/></div>
<p class="calibre2"><span class="calibre5">We can see some distinctions among different classes, but since the majority of the pixel values for both <kbd class="calibre12">pixel43</kbd> and <kbd class="calibre12">pixel44</kbd> are 0, it is quite difficult to draw a clear distinction among different target classes by looking at this scatter plot. In the next section, we are going to look at how to use</span> PCA<span class="calibre5"> and its principal components to create another version of this scatter plot that can help us identify a clearer distinction among different target classes when we visualize the data.</span></p>
<p class="calibre2"><span class="calibre5">The full code for this data analysis step can be found at this link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.8/DataAnalyzer.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.8/DataAnalyzer.cs</a>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Feature engineering and dimensionality reduction</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">So far, we have looked at the distributions of the target variables and pixel data. In this section, we are going to start discussing building train and test sets for our ML modeling step, and then how we can use</span> PCA<span class="calibre5"><strong class="calibre4"> </strong>for dimensionality reduction and to visualize data using the principal components.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Splitting the sample set into train versus test sets</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">The first task we are going to do in this step is to randomly split our dataset into train and test sets. Let's first look at the code:</span></p>
<pre class="calibre19">double trainSetProportiona = 0.7;<br class="title-page-name"/><br class="title-page-name"/>var rnd = new Random();<br class="title-page-name"/>var trainIdx = featuresDF.RowKeys.Where((x, i) =&gt; rnd.NextDouble() &lt;= trainSetProportiona);<br class="title-page-name"/>var testIdx = featuresDF.RowKeys.Where((x, i) =&gt; !trainIdx.Contains(i));<br class="title-page-name"/><br class="title-page-name"/>var trainset = featuresDF.Rows[trainIdx];<br class="title-page-name"/>var testset = featuresDF.Rows[testIdx];<br class="title-page-name"/><br class="title-page-name"/>var trainLabels = trainset.GetColumn&lt;int&gt;("label").Values.ToArray();<br class="title-page-name"/><br class="title-page-name"/>string[] nonZeroPixelCols = trainset.ColumnKeys.Where(x =&gt; trainset[x].Max() &gt; 0 &amp;&amp; !x.Equals("label")).ToArray();<br class="title-page-name"/><br class="title-page-name"/>double[][] data = trainset.Columns[nonZeroPixelCols].Rows.Select(<br class="title-page-name"/>    x =&gt; Array.ConvertAll&lt;object, double&gt;(x.Value.ValuesAll.ToArray(), o =&gt; Convert.ToDouble(o))<br class="title-page-name"/>).ValuesAll.ToArray();</pre>
<p class="calibre2"><span class="calibre5">As you can see from the preceding code, we are taking roughly about 70% of our data for training, and the rest for testing. Here, we are using the <kbd class="calibre12">Random</kbd> class to generate random numbers to split the sample set into train and test sets using the indexes of the records. Once we have built train and test sets, we are removing columns or pixels that have 0 values for all the images (line 12). This is because if a feature doesn't vary among different target classes, it doesn't have any information about those target classes for ML models to learn.</span></p>
<p class="calibre2">Now that we have train and test sets, let's check on the distributions of target classes in both train and test sets. The following code can be used for the aggregation:</p>
<pre class="calibre19">var digitCount = trainset.AggregateRowsBy&lt;string, int&gt;(<br class="title-page-name"/>    new string[] { "label" },<br class="title-page-name"/>    new string[] { "pixel0" },<br class="title-page-name"/>    x =&gt; x.ValueCount<br class="title-page-name"/>).SortRows("pixel0");<br class="title-page-name"/><br class="title-page-name"/>digitCount.Print();<br class="title-page-name"/><br class="title-page-name"/>var barChart = DataBarBox.Show(<br class="title-page-name"/>    digitCount.GetColumn&lt;string&gt;("label").Values.ToArray(),<br class="title-page-name"/>    digitCount["pixel0"].Values.ToArray()<br class="title-page-name"/>).SetTitle(<br class="title-page-name"/>    "Train Set - Digit Count"<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>digitCount = testset.AggregateRowsBy&lt;string, int&gt;(<br class="title-page-name"/>    new string[] { "label" },<br class="title-page-name"/>    new string[] { "pixel0" },<br class="title-page-name"/>    x =&gt; x.ValueCount<br class="title-page-name"/>).SortRows("pixel0");<br class="title-page-name"/><br class="title-page-name"/>digitCount.Print();<br class="title-page-name"/><br class="title-page-name"/>barChart = DataBarBox.Show(<br class="title-page-name"/>    digitCount.GetColumn&lt;string&gt;("label").Values.ToArray(),<br class="title-page-name"/>    digitCount["pixel0"].Values.ToArray()<br class="title-page-name"/>).SetTitle(<br class="title-page-name"/>    "Test Set - Digit Count"<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">When you run this code, you will see the following plot for the target variable distribution in the train set:</span></p>
<div class="mce-root"><img src="../images/00127.jpeg" class="calibre92"/></div>
<p class="calibre2"><span class="calibre5">And, the following is what we see for the test set:</span></p>
<div class="mce-root"><img src="../images/00128.jpeg" class="calibre93"/></div>
<p class="calibre2"><span class="calibre5">These distributions look similar to what we saw in the data analysis step, when we analyzed the target variable distribution in the overall dataset. Let's now start discussing how we can app</span>ly PCA t<span class="calibre5">o our train set.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Dimensionality reduction by PCA</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">We saw that many of our feature or pixel values are 0, when we were analyzing our data. In such cases, apply</span>ing PCA c<span class="calibre5">an be helpful for reducing the dimensions of the data, while minimizing the loss of information from the reduced dimensions. Simply p</span>ut, PCA <span class="calibre5">is used to explain a dataset and its structure through linear combinations of the original features. So, each principal component is a linear combination of the features. Let's start looking at how we can run</span> PCA in C#<span class="calibre5">, using the Accord.NET framework.</span></p>
<p class="calibre2">The following is how you can initialize and train a PCA:</p>
<pre class="calibre19">var pca = new PrincipalComponentAnalysis(<br class="title-page-name"/>    PrincipalComponentMethod.Standardize<br class="title-page-name"/>);<br class="title-page-name"/>pca.Learn(data);</pre>
<p class="calibre2"><span class="calibre5">Once a <kbd class="calibre12">PrincipalComponentAnalysis</kbd> is trained with the data, it contains all the information about the linear combinations for each principal component and can be applied to transform other data. We used <kbd class="calibre12">PrincipalComponentMethod.Standardize</kbd> to standardize our data before applying PCA. This is because PCA is sensitive to the scale of each feature. So, we want to standardize our dataset before applying PCA.</span></p>
<p class="calibre2">In order to PCA-transform other data, you can use the <kbd class="calibre12">Transform</kbd> method, as shown in the following code snippet:</p>
<pre class="calibre19">double[][] transformed = pca.Transform(data);</pre>
<p class="calibre2">Now that we have learned how we can apply PCA to our dataset, let's look at the first two principal components and see if we can find any noticeable patterns in the target variable distributions. The following code shows how we can build a scatter plot of the first two components with target classes color-coded:</p>
<pre class="calibre19">double[][] first2Components = transformed.Select(x =&gt; x.Where((y, i) =&gt; i &lt; 2).ToArray()).ToArray();<br class="title-page-name"/><br class="title-page-name"/>ScatterplotBox.Show("Component #1 vs. Component #2", first2Components, trainLabels);</pre>
<p class="calibre2"><span class="calibre5">Once you run this code, you will see the following scatter plot:</span></p>
<div class="mce-root"><img src="../images/00129.jpeg" class="calibre94"/></div>
<p class="calibre2"><span class="calibre5">When you compare this chart with the one between <kbd class="calibre12">pixel43</kbd> and <kbd class="calibre12">pixel44</kbd> that we looked at during the data analysis step, this looks quite different. From this scatter plot of the first two principal components, we can see that the target classes are more discernible. Although it is not perfectly separable from these two components, we can see that if we combine more components into our analysis and modeling, it will get easier to separate one target class from another.</span></p>
<p class="calibre2">Another important aspect of PCA that we should look at is the amount of variance explained by each principal component. Let's take a look at the following code:</p>
<pre class="calibre19">DataSeriesBox.Show(<br class="title-page-name"/>    pca.Components.Select((x, i) =&gt; (double)i),<br class="title-page-name"/>    pca.Components.Select(x =&gt; x.CumulativeProportion)<br class="title-page-name"/>).SetTitle("Explained Variance");<br class="title-page-name"/><br class="title-page-name"/>System.IO.File.WriteAllLines(<br class="title-page-name"/>    Path.Combine(dataDirPath, "explained-variance.csv"),<br class="title-page-name"/>    pca.Components.Select((x, i) =&gt; String.Format("{0},{1:0.0000}", i, x.CumulativeProportion))<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">We can retrieve the cumulative proportion of the variance in our data explained by each PCA component by using the <kbd class="calibre12">CumulativeProportion</kbd> property. In order to get the individual proportion explained by each PCA component, you can use the <kbd class="calibre12">Proportion</kbd> property of each PCA component. Then, we will use the <kbd class="calibre12">DataSeriesBox</kbd> class to plot a line chart to display the cumulative proportions of the variance explained by each component.</span></p>
<p class="calibre2">When you run this code, it will produce the following plot:</p>
<div class="mce-root"><img src="../images/00130.jpeg" class="calibre95"/></div>
<p class="calibre2"><span class="calibre5">As you can see from this plot, about 90% of the variance in the dataset can be explained by the first 200 components. With 600 components, we can explain almost 100% of the variance in our dataset. Compared to the total of 784 pixels we had as our features in the raw dataset, this is a big reduction in the dimension of our data. Depending on how much variance you want to capture for your ML models, you can use this chart to decide the number of components that is most suitable for your modeling process.</span></p>
<p class="calibre2">Finally, we need to export the train and test sets, so that we can use them for the following model building step. You can use the following code to export the PCA-transformed train and test sets:</p>
<pre class="calibre19">Console.WriteLine("exporting train set...");<br class="title-page-name"/>var trainTransformed = pca.Transform(<br class="title-page-name"/>    trainset.Columns[nonZeroPixelCols].Rows.Select(<br class="title-page-name"/>        x =&gt; Array.ConvertAll&lt;object, double&gt;(x.Value.ValuesAll.ToArray(), o =&gt; Convert.ToDouble(o))<br class="title-page-name"/>    ).ValuesAll.ToArray()<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>System.IO.File.WriteAllLines(<br class="title-page-name"/>    Path.Combine(dataDirPath, "pca-train.csv"),<br class="title-page-name"/>    trainTransformed.Select((x, i) =&gt; String.Format("{0},{1}", String.Join(",", x), trainset["label"].GetAt(i)))<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("exporting test set...");<br class="title-page-name"/>var testTransformed = pca.Transform(<br class="title-page-name"/>    testset.Columns[nonZeroPixelCols].Rows.Select(<br class="title-page-name"/>        x =&gt; Array.ConvertAll&lt;object, double&gt;(x.Value.ValuesAll.ToArray(), o =&gt; Convert.ToDouble(o))<br class="title-page-name"/>    ).ValuesAll.ToArray()<br class="title-page-name"/>);<br class="title-page-name"/>System.IO.File.WriteAllLines(<br class="title-page-name"/>    Path.Combine(dataDirPath, "pca-test.csv"),<br class="title-page-name"/>    testTransformed.Select((x, i) =&gt; String.Format("{0},{1}", String.Join(",", x), testset["label"].GetAt(i)))<br class="title-page-name"/>);</pre>
<p class="calibre2">The full code for this feature engineering and dimensionality reduction step can be found at this link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.8/FeatureEngineering.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.8/FeatureEngineering.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">ML models for handwritten digit recognition</h1>
                
            
            <article>
                
<p class="calibre2">Now that we have everything ready for building ML models, let's start building those models. In this section, we will cover how to sub-select the features based on the PCA results and then discuss how we can build logistic regression and Naive Bayes classifiers for the handwritten digit recognition model. We are going to introduce a new learning model, the neural network, and explain how to build one for this project, using the Accord.NET framework.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Loading data</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">The first step in building a ML model for handwritten digit recognition is to load the data that we built from the previous section. You can use the following code to load the train and test sets that we created previously:</span></p>
<pre class="calibre19">// Load the data into a data frame<br class="title-page-name"/>string trainDataPath = Path.Combine(dataDirPath, "pca-train.csv");<br class="title-page-name"/>Console.WriteLine("Loading {0}\n\n", trainDataPath);<br class="title-page-name"/>var trainDF = Frame.ReadCsv(<br class="title-page-name"/>    trainDataPath,<br class="title-page-name"/>    hasHeaders: false,<br class="title-page-name"/>    inferTypes: true<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>string testDataPath = Path.Combine(dataDirPath, "pca-test.csv");<br class="title-page-name"/>Console.WriteLine("Loading {0}\n\n", testDataPath);<br class="title-page-name"/>var testDF = Frame.ReadCsv(<br class="title-page-name"/>    testDataPath,<br class="title-page-name"/>    hasHeaders: false,<br class="title-page-name"/>    inferTypes: true<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>string[] colnames = trainDF.ColumnKeys.Select(<br class="title-page-name"/>    (x, i) =&gt; i &lt; trainDF.ColumnKeys.Count() - 1 ? String.Format("component-{0}", i + 1) : "label"<br class="title-page-name"/>).ToArray();<br class="title-page-name"/><br class="title-page-name"/>trainDF.RenameColumns(colnames);<br class="title-page-name"/>testDF.RenameColumns(colnames);</pre>
<p class="calibre2"><span class="calibre5">For our experimentation with different models in this chapter, we will be using the principal components that cumulatively explain about 70% of the variance in our dataset. Take a look at the following code to see how we filtered for the components of our interest:</span></p>
<pre class="calibre19">// Capturing 70% of the variance<br class="title-page-name"/>string[] featureCols = colnames.Where((x, i) =&gt; i &lt;= 90).ToArray();<br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/>double[][] trainInput = BuildJaggedArray(<br class="title-page-name"/>    trainDF.Columns[featureCols].ToArray2D&lt;double&gt;(), trainDF.RowCount, featureCols.Length<br class="title-page-name"/>);<br class="title-page-name"/>int[] trainOutput = trainDF.GetColumn&lt;int&gt;("label").ValuesAll.ToArray();<br class="title-page-name"/><br class="title-page-name"/>double[][] testInput = BuildJaggedArray(<br class="title-page-name"/>    testDF.Columns[featureCols].ToArray2D&lt;double&gt;(), testDF.RowCount, featureCols.Length<br class="title-page-name"/>);<br class="title-page-name"/>int[] testOutput = testDF.GetColumn&lt;int&gt;("label").ValuesAll.ToArray();</pre>
<p class="calibre2"><span class="calibre5">As you can see in the first line of this code, we are taking the first 91 components (up to the ninetieth index) as the features for our models. If you recall from the previous step or look at the plot for the cumulative variance proportion explained by the components, you will see that the first 91 components capture about 70% of the variance in our dataset. Then, we create a two-dimensional array of doubles that we will use for training and testing our ML models. The following code shows the helper function, <kbd class="calibre12">BuildJaggedArray</kbd>, that we wrote to convert a data frame into a two-dimensional array:</span></p>
<pre class="calibre19">private static double[][] BuildJaggedArray(double[,] ary2d, int rowCount, int colCount)<br class="title-page-name"/>{<br class="title-page-name"/>    double[][] matrix = new double[rowCount][];<br class="title-page-name"/>    for(int i = 0; i &lt; rowCount; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        matrix[i] = new double[colCount];<br class="title-page-name"/>        for(int j = 0; j &lt; colCount; j++)<br class="title-page-name"/>        {<br class="title-page-name"/>            matrix[i][j] = double.IsNaN(ary2d[i, j]) ? 0.0 : ary2d[i, j];<br class="title-page-name"/>        }<br class="title-page-name"/>    }<br class="title-page-name"/>    return matrix;<br class="title-page-name"/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Logistic regression classifier</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">The first learning algorithm we are going to experiment with for handwritten digit recognition is logistic regression. We wrote a method, named <kbd class="calibre12">BuildLogitModel</kbd>, which takes in the inputs and outputs to the model, trains a logistic regression classifier, and then evaluates the performance. The following code shows how this method is written:</span></p>
<pre class="calibre19">private static void BuildLogitModel(double[][] trainInput, int[] trainOutput, double[][] testInput, int[] testOutput)<br class="title-page-name"/>{<br class="title-page-name"/>    var logit = new MultinomialLogisticLearning&lt;GradientDescent&gt;()<br class="title-page-name"/>    {<br class="title-page-name"/>        MiniBatchSize = 500<br class="title-page-name"/>    };<br class="title-page-name"/>    var logitModel = logit.Learn(trainInput, trainOutput);<br class="title-page-name"/><br class="title-page-name"/>    int[] inSamplePreds = logitModel.Decide(trainInput);<br class="title-page-name"/>    int[] outSamplePreds = logitModel.Decide(testInput);<br class="title-page-name"/><br class="title-page-name"/>    // Accuracy<br class="title-page-name"/>    double inSampleAccuracy = 1 - new ZeroOneLoss(trainOutput).Loss(inSamplePreds);<br class="title-page-name"/>    double outSampleAccuracy = 1 - new ZeroOneLoss(testOutput).Loss(outSamplePreds);<br class="title-page-name"/>    Console.WriteLine("* In-Sample Accuracy: {0:0.0000}", inSampleAccuracy);<br class="title-page-name"/>    Console.WriteLine("* Out-of-Sample Accuracy: {0:0.0000}", outSampleAccuracy);<br class="title-page-name"/><br class="title-page-name"/>    // Build confusion matrix<br class="title-page-name"/>    int[][] confMatrix = BuildConfusionMatrix(<br class="title-page-name"/>        testOutput, outSamplePreds, 10<br class="title-page-name"/>    );<br class="title-page-name"/>    System.IO.File.WriteAllLines(<br class="title-page-name"/>        Path.Combine(<br class="title-page-name"/>            @"&lt;path-to-dir&gt;", <br class="title-page-name"/>            "logit-conf-matrix.csv"<br class="title-page-name"/>        ),<br class="title-page-name"/>        confMatrix.Select(x =&gt; String.Join(",", x))<br class="title-page-name"/>    );<br class="title-page-name"/><br class="title-page-name"/>    // Precision Recall<br class="title-page-name"/>    PrintPrecisionRecall(confMatrix);<br class="title-page-name"/>    DrawROCCurve(testOutput, outSamplePreds, 10, "Logit");<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">Similar to the previous chapter, we are using the <kbd class="calibre12">MultinomialLogisticLearning</kbd> class to train a logistic regression classifier. Once this model is trained, we start evaluating by various evaluation metrics, which we will discuss in more detail in the following section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Naive Bayes classifier</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">The second model we are going to experiment with is a Naive Bayes classifier. Similar to the previous case involving the logistic regression classifier, we wrote a helper function, <kbd class="calibre12">BuildNBModel</kbd>, that takes in the inputs and outputs, trains a Naive Bayes classifier, and then evaluates the trained model. The code looks as follows:</span></p>
<pre class="calibre19">private static void BuildNBModel(double[][] trainInput, int[] trainOutput, double[][] testInput, int[] testOutput)<br class="title-page-name"/>{<br class="title-page-name"/>    var teacher = new NaiveBayesLearning&lt;NormalDistribution&gt;();<br class="title-page-name"/>    var nbModel = teacher.Learn(trainInput, trainOutput);<br class="title-page-name"/><br class="title-page-name"/>    int[] inSamplePreds = nbModel.Decide(trainInput);<br class="title-page-name"/>    int[] outSamplePreds = nbModel.Decide(testInput);<br class="title-page-name"/><br class="title-page-name"/>    // Accuracy<br class="title-page-name"/>    double inSampleAccuracy = 1 - new ZeroOneLoss(trainOutput).Loss(inSamplePreds);<br class="title-page-name"/>    double outSampleAccuracy = 1 - new ZeroOneLoss(testOutput).Loss(outSamplePreds);<br class="title-page-name"/>    Console.WriteLine("* In-Sample Accuracy: {0:0.0000}", inSampleAccuracy);<br class="title-page-name"/>    Console.WriteLine("* Out-of-Sample Accuracy: {0:0.0000}", outSampleAccuracy);<br class="title-page-name"/><br class="title-page-name"/>    // Build confusion matrix<br class="title-page-name"/>    int[][] confMatrix = BuildConfusionMatrix(<br class="title-page-name"/>        testOutput, outSamplePreds, 10<br class="title-page-name"/>    );<br class="title-page-name"/>    System.IO.File.WriteAllLines(<br class="title-page-name"/>        Path.Combine(<br class="title-page-name"/>            @"&lt;path-to-dir&gt;",<br class="title-page-name"/>            "nb-conf-matrix.csv"<br class="title-page-name"/>        ),<br class="title-page-name"/>        confMatrix.Select(x =&gt; String.Join(",", x))<br class="title-page-name"/>    );<br class="title-page-name"/><br class="title-page-name"/>    // Precision Recall<br class="title-page-name"/>    PrintPrecisionRecall(confMatrix);<br class="title-page-name"/>    DrawROCCurve(testOutput, outSamplePreds, 10, "NB");<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">As you might recall from the previous chapter, we are using the <kbd class="calibre12">NaiveBayesLearning</kbd> class to train a Naive Bayes classifier. We are using <kbd class="calibre12">NormalDistribution</kbd>, as all the features for our ML models are the principal components from the previous PCA step, and the values of these components are continuous values.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Neural network classifier</h1>
                
            
            <article>
                
<p class="calibre2">The last learning algorithm that we are going to experiment with is the ANN. As you might know already, the neural network model is the backbone of all of the deep learning technologies. The neural network model is known to perform well for image datasets, so we will compare the performance of this model against the other models to see how much performance gain we get by using the neural network over the other classification models. In order to build neural network models in C# using the Accord.NET framework, you will need to install the <kbd class="calibre12">Accord.Neuro</kbd> package first. You can install the <kbd class="calibre12">Accord.Neuro</kbd> package by using the following command in the <strong class="calibre4">NuGet Package Manager Console</strong>:</p>
<pre class="calibre19"><span>Install-Package</span><span> Accord.Neuro</span></pre>
<p class="calibre2">Let's now take a look at how we can build a neural network model in C#, using the Accord.NET framework. The code looks like the following:</p>
<pre class="calibre19">private static void BuildNNModel(double[][] trainInput, int[] trainOutput, double[][] testInput, int[] testOutput)<br class="title-page-name"/>{<br class="title-page-name"/>    double[][] outputs = Accord.Math.Jagged.OneHot(trainOutput);<br class="title-page-name"/><br class="title-page-name"/>    var function = new BipolarSigmoidFunction(2);<br class="title-page-name"/>    var network = new ActivationNetwork(<br class="title-page-name"/>        new BipolarSigmoidFunction(2), <br class="title-page-name"/>        91, <br class="title-page-name"/>        20,<br class="title-page-name"/>        10<br class="title-page-name"/>    );<br class="title-page-name"/>    <br class="title-page-name"/>    var teacher = new LevenbergMarquardtLearning(network);<br class="title-page-name"/><br class="title-page-name"/>    Console.WriteLine("\n-- Training Neural Network");<br class="title-page-name"/>    int numEpoch = 10;<br class="title-page-name"/>    double error = Double.PositiveInfinity;<br class="title-page-name"/>    for (int i = 0; i &lt; numEpoch; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        error = teacher.RunEpoch(trainInput, outputs);<br class="title-page-name"/>        Console.WriteLine("* Epoch {0} - error: {1:0.0000}", i + 1, error);<br class="title-page-name"/>    }<br class="title-page-name"/>    Console.WriteLine("");<br class="title-page-name"/><br class="title-page-name"/>    List&lt;int&gt; inSamplePredsList = new List&lt;int&gt;();<br class="title-page-name"/>    for (int i = 0; i &lt; trainInput.Length; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        double[] output = network.Compute(trainInput[i]);<br class="title-page-name"/>        int pred = output.ToList().IndexOf(output.Max());<br class="title-page-name"/>        inSamplePredsList.Add(pred);<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    List&lt;int&gt; outSamplePredsList = new List&lt;int&gt;();<br class="title-page-name"/>    for (int i = 0; i &lt; testInput.Length; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        double[] output = network.Compute(testInput[i]);<br class="title-page-name"/>        int pred = output.ToList().IndexOf(output.Max());<br class="title-page-name"/>        outSamplePredsList.Add(pred);<br class="title-page-name"/>    }<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">Let's take a closer look at this code. We first transform the training labels from a one-dimensional array into a two-dimensional array, where the columns are the target classes and the values are 1 if the given record belongs to the given target class, and 0 if it does not. We are using the <kbd class="calibre12">Accord.Math.Jagged.OneHot</kbd> method to perform one-hot encoding for the training labels. Then, we build a neural network by using the <kbd class="calibre12">ActivationNetwork</kbd> class. The <kbd class="calibre12">ActivationNetwork</kbd> class takes three parameters: the activation function, the input count, and the information about the layers. For the activation function, we are using a sigmoid function, <kbd class="calibre12">BipolarSigmoidFunction</kbd>. The input count is straightforward, as it is the number of features that we are going to use to train this model, which is 91. For this model, we only used one hidden layer with 20 neurons. For a deeper neural network, you can use more than one hidden layer and can also experiment with different numbers of neurons in each hidden layer. Lastly, the last parameter of the <kbd class="calibre12">ActivationNetwork</kbd> constructor represents the output count. Since the target variable is the digit class, it can take values between 0 and 9, and thus the number of output neurons we need is 10. </span><span class="calibre5">Once this network is built, we can use the <kbd class="calibre12">LevenbergMarquardtLearning</kbd> learning algorithm to train the network. </span></p>
<p class="calibre2">Once we have set up the network and the learning algorithm, we can actually start training a neural network model. As you might know already, a neural network model needs to be run through the dataset multiple times (epochs) during its learning phase for better predictability. You can use the <kbd class="calibre12">RunEpoch</kbd> method to train and update the neural network model in each epoch. To save some time, we are only running 10 epochs to train our neural network model. However, we recommend you try increasing this value, as it can improve the performance of your neural network model. The following shows how the error measure decreases as we train and update the neural network model in each epoch:</p>
<div class="mce-root"><img class="alignnone55" src="../images/00131.gif"/></div>
<p class="calibre2">As you can see from this output, the error measure decreases significantly in each epoch. One thing to note here is that the amount of reduction in the error measure decreases in each additional epoch. When you are building a neural network model with large numbers of epochs, you can monitor the amount of gain in each run and decide to stop when there is no more significant performance gain.</p>
<p class="calibre2"><span class="calibre5">The full code that we used for the model building step can be found at this link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.8/Modeling.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.8/Modeling.cs</a>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Evaluating multi-class classification models</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">In this section, we are going to evaluate the three models that we built in the previous section. We are going to revisit the validation metrics that we used previously for the classification models, and compare the performances of each model against the others.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Confusion matrices</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">First, let's look at confusion matrices. The following code shows how you can build a confusion matrix with the predicted output and the actual output:</span></p>
<pre class="calibre19">private static int[][] BuildConfusionMatrix(int[] actual, int[] preds, int numClass)<br class="title-page-name"/>{<br class="title-page-name"/>    int[][] matrix = new int[numClass][];<br class="title-page-name"/>    for (int i = 0; i &lt; numClass; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        matrix[i] = new int[numClass];<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    for (int i = 0; i &lt; actual.Length; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        matrix[actual[i]][preds[i]] += 1;<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    return matrix;<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">This method is similar to the one we wrote in the previous chapter, except that it is returning a two-dimensional array, instead of a string array. We are going to use this two-dimensional array output for calculating precision and recall rates in the next section.</span></p>
<p class="calibre2">The confusion matrix for the logistic regression classifier looks like the following:</p>
<div class="mce-root"><img class="alignnone56" src="../images/00132.gif"/></div>
<p class="calibre2"><span class="calibre5">For the Naive Bayes classifier, you will get a confusion matrix that looks similar to the following table:</span></p>
<div class="mce-root"><img class="alignnone57" src="../images/00133.gif"/></div>
<p class="calibre2"><span class="calibre5">Lastly, for the neural network model, the confusion matrix looks like the following:</span></p>
<div class="mce-root"><img class="alignnone58" src="../images/00134.gif"/></div>
<p class="calibre2">From these confusion matrices, the neural network model outperforms the other two models, and the logistic regression model seems to come in second.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Accuracy and precision/recall</h1>
                
            
            <article>
                
<p class="calibre2">The second metric that we are going to look at is the accuracy measure. We are use <kbd class="calibre12">ZeroOneLoss</kbd> to compute the loss, and then subtract it from <kbd class="calibre12">1</kbd> to get the accuracy number. The code to compute the accuracy measure is as follows:</p>
<pre class="calibre19">// Accuracy<br class="title-page-name"/>double inSampleAccuracy = 1 - new ZeroOneLoss(trainOutput).Loss(inSamplePreds);<br class="title-page-name"/>double outSampleAccuracy = 1 - new ZeroOneLoss(testOutput).Loss(outSamplePreds);<br class="title-page-name"/>Console.WriteLine("* In-Sample Accuracy: {0:0.0000}", inSampleAccuracy);<br class="title-page-name"/>Console.WriteLine("* Out-of-Sample Accuracy: {0:0.0000}", outSampleAccuracy);</pre>
<p class="calibre2"><span class="calibre5">The third and fourth metrics that we are going to look at are the precision and recall rates. Unlike before, we have 10 classes for the target prediction. So, we are going to have to calculate precision and recall rates separately for each of the target classes. The code looks like the following:</span></p>
<pre class="calibre19">private static void PrintPrecisionRecall(int[][] confMatrix)<br class="title-page-name"/>{<br class="title-page-name"/>    for (int i = 0; i &lt; confMatrix.Length; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        int totalActual = confMatrix[i].Sum();<br class="title-page-name"/>        int correctPredCount = confMatrix[i][i];<br class="title-page-name"/><br class="title-page-name"/>        int totalPred = 0;<br class="title-page-name"/>        for(int j = 0; j &lt; confMatrix.Length; j++)<br class="title-page-name"/>        {<br class="title-page-name"/>            totalPred += confMatrix[j][i];<br class="title-page-name"/>        }<br class="title-page-name"/><br class="title-page-name"/>        double precision = correctPredCount / (float)totalPred;<br class="title-page-name"/>        double recall = correctPredCount / (float)totalActual;<br class="title-page-name"/><br class="title-page-name"/>        Console.WriteLine("- Digit {0}: precision - {1:0.0000}, recall - {2:0.0000}", i, precision, recall);<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">As you can see from this code, the input to this <kbd class="calibre12">PrintPrecisionRecall</kbd> method is the confusion matrix that we built from the previous section. In this method, it iterates through each of the target classes and computes the precision and recall rates.</span></p>
<p class="calibre2">The following is the output that we get when we compute accuracy, precision, and recall for the logistic regression model:</p>
<div class="mce-root"><img class="alignnone59" src="../images/00135.gif"/></div>
<p class="calibre2">For the Naive Bayes model, we get the following results for the metrics:</p>
<div class="mce-root"><img class="alignnone60" src="../images/00136.gif"/></div>
<p class="calibre2">Lastly, for the neural network model, the performance results look as follows:</p>
<div class="mce-root"><img class="alignnone61" src="../images/00137.gif"/></div>
<p class="calibre2"><span class="calibre5">As you might notice from these results, the neural network model outperformed the other two models. Both the overall accuracy and the precision/recall rates are the highest for the neural network model, when compared to the logistic regression and Naive Bayes models. The logistic regression model seems to come in as the second best model among the three that we built.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">One versus Rest AUC</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">The last evaluation measure that we are going to look at is the <strong class="calibre4">Receiver Operating Characteristic</strong></span> (<span class="calibre5"><strong class="calibre4">ROC</strong></span>) c<span class="calibre5">urve and the</span> AUC. <span class="calibre5">One thing we need to do differently in this chapter, when we are building a ROC curve and an AUC, is that we need to build one for each of the target classes. Let's take a look at the code first:</span></p>
<pre class="calibre19">private static void DrawROCCurve(int[] actual, int[] preds, int numClass, string modelName)<br class="title-page-name"/>{<br class="title-page-name"/>    ScatterplotView spv = new ScatterplotView();<br class="title-page-name"/>    spv.Dock = DockStyle.Fill;<br class="title-page-name"/>    spv.LinesVisible = true;<br class="title-page-name"/><br class="title-page-name"/>    Color[] colors = new Color[] {<br class="title-page-name"/>        Color.Blue, Color.Red, Color.Orange, Color.Yellow, Color.Green,<br class="title-page-name"/>        Color.Gray, Color.LightSalmon, Color.LightSkyBlue, Color.Black, Color.Pink<br class="title-page-name"/>    };<br class="title-page-name"/><br class="title-page-name"/>    for (int i = 0; i &lt; numClass; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        // Build ROC for Train Set<br class="title-page-name"/>        bool[] expected = actual.Select(x =&gt; x == i ? true : false).ToArray();<br class="title-page-name"/>        int[] predicted = preds.Select(x =&gt; x == i ? 1 : 0).ToArray();<br class="title-page-name"/><br class="title-page-name"/>        var trainRoc = new ReceiverOperatingCharacteristic(expected, predicted);<br class="title-page-name"/>        trainRoc.Compute(1000);<br class="title-page-name"/><br class="title-page-name"/>        // Get Train AUC<br class="title-page-name"/>        double auc = trainRoc.Area;<br class="title-page-name"/>        double[] xVals = trainRoc.Points.Select(x =&gt; 1 - x.Specificity).ToArray();<br class="title-page-name"/>        double[] yVals = trainRoc.Points.Select(x =&gt; x.Sensitivity).ToArray();<br class="title-page-name"/><br class="title-page-name"/>        // Draw ROC Curve<br class="title-page-name"/>        spv.Graph.GraphPane.AddCurve(<br class="title-page-name"/>            String.Format(<br class="title-page-name"/>                "Digit: {0} - AUC: {1:0.00}",<br class="title-page-name"/>                i, auc<br class="title-page-name"/>            ),<br class="title-page-name"/>            xVals, yVals, colors[i], SymbolType.None<br class="title-page-name"/>        );<br class="title-page-name"/>        spv.Graph.GraphPane.AxisChange();<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    spv.Graph.GraphPane.Title.Text = String.Format(<br class="title-page-name"/>        "{0} ROC - One vs. Rest",<br class="title-page-name"/>        modelName<br class="title-page-name"/>    );<br class="title-page-name"/><br class="title-page-name"/>    Form f1 = new Form();<br class="title-page-name"/>    f1.Width = 700;<br class="title-page-name"/>    f1.Height = 500;<br class="title-page-name"/>    f1.Controls.Add(spv);<br class="title-page-name"/>    f1.ShowDialog();<br class="title-page-name"/>}</pre>
<p class="calibre2"><span class="calibre5">As you can see from this <kbd class="calibre12">DrawROCCurve</kbd> method that we wrote, we iterate through each target class in a <kbd class="calibre12">for</kbd> loop, and reformat the predicted and actual labels by encoding <kbd class="calibre12">1</kbd> if each label matches with the target class, and 0 if it does not. After we have done this encoding, we can then use the <kbd class="calibre12">ReceiverOperatingCharacteristic</kbd> class to compute the AUC and build the ROC curve.</span></p>
<p class="calibre2">The following is the ROC curve for the logistic regression model:</p>
<div class="mce-root"><img class="alignnone62" src="../images/00138.jpeg"/></div>
<p class="calibre2">For the Naive Bayes model, the ROC curve looks as follows:</p>
<div class="mce-root"><img src="../images/00139.jpeg" class="calibre96"/></div>
<p class="calibre2">Lastly, the ROC curve for the neural network model looks like the following:</p>
<div class="mce-root"><img class="alignnone63" src="../images/00140.jpeg"/></div>
<p class="calibre2"><span class="calibre5">As expected from the previous metrics that we have looked at, the results look the best for the neural network model, and the logistic regression model comes in as second-best. For the Naive Bayes model, there are some digits that it didn't compute well. For example, the Naive Bayes model struggles to classify the digits 6 and 7 well. However, the AUC numbers for all of the target classes are close to 1 for the neural network, which suggests that the model is trained well to identify digits for handwritten images. </span></p>
<p class="calibre2">From looking at the confusion matrix, the accuracy, precision and recall rates, and the ROC curves, we can conclude that the neural network model works the best among the three classifiers that we trained in this chapter. This reaffirms the fact that neural networks work well on image datasets and image recognition problems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">In this chapter, we built our first image recognition model that can identify handwritten digits in grayscale images. We started this chapter by discussing how this type of model can be widely used in real-life applications, and how we are planning to build a handwritten digit recognition model. Then, we started looking into the dataset. We first looked at the distributions of target classes to see if the sample set is a well-balanced set. When we were analyzing the pixel data, we noticed that the majority of the pixel values were 0, and we could intuitively make sense of it by reconstructing the images from the pixel data. During the feature engineering step, we discussed how we can use PCA for dimensionality reduction. </span></p>
<p class="calibre2"><span class="calibre5">With these PCA-transformed features, we then started building various machine learning models. On top of the logistic regression and Naive Bayes models that we are already familiar with, we introduced a new ML model, neural network. We learned how to initialize the <kbd class="calibre12">ActivationNetwork</kbd> model with <kbd class="calibre12">BipolarSigmoidFunction</kbd> as an activation function. We then started training the neural network with the <kbd class="calibre12">LevenbergMarquardtLearning</kbd> learning algorithm over 10 epochs. We saw how error measures decrease in each additional epoch, and discussed how the amount of gain in the error rate is in diminishing returns for additional epochs. In the model evaluation step, we combined multiple validation metrics for classification models. For the machine learning models we built in this chapter, we looked at the confusion matrix, prediction accuracy, precision and recall rates, and the ROC curves and AUC. We noticed how the neural network model outperformed the other two models, which reaffirmed that neural network models work well for image data.</span></p>
<p class="calibre2">In the next chapter, we are going to switch gears and start building models for anomaly detection. We are going to work on a cyber attack detection project using PCA. With the Network Intrusion dataset, we will discuss how to use PCA to detect cyber attacks, and run multiple experiments to find the optimal threshold at which to notify us about potential cyber attacks.</p>


            </article>

            
        </section>
    </body></html>