<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Autoencoders</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we are going to look at an unsupervised model family whose performance has been boosted by modern deep learning techniques. Autoencoders offer a different approach to classic problems such as dimensionality reduction or dictionary learning, but unlike many other algorithms, they don't suffer the capacity limitations that affect many famous models. Moreover, they can exploit specific neural layers (such as convolutions) to extract pieces of information based on specialized criteria. In this way, the internal representations can be more robust to different kinds of distortions and much more efficient in terms of the amount of information they can process.</p>
<p>In particular, we are going to discuss the following:</p>
<ul>
<li>Standard autoencoders</li>
<li>Denoising autoencoders</li>
<li>Sparse autoencoders</li>
<li>Variational autoencoders</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Autoencoders</h1>
                </header>
            
            <article>
                
<p>In the previous chapters, we discussed how real datasets are very often high-dimensional representations of samples that lie on low-dimensional manifolds (this is one of the semi-supervised pattern's assumptions, but it's generally true). As the complexity of a model is proportional to the dimensionality of the input data, many techniques have been analyzed and optimized in order to reduce the actual number of <em>valid components</em>. For example, PCA selects the features according to the relative explained variance, while ICA and generic dictionary learning techniques look for basic atoms that can be combined to rebuild the original samples. In this chapter, we are going to analyze a family of models based on a slightly different approach, but whose capabilities are dramatically increased by the employment of deep learning methods.</p>
<p>A generic <strong>autoencoder</strong> is a model that is split into two separate (but not completely autonomous) components called an <strong>Encoder</strong> and a <strong>Decoder</strong>. The task of the encoder is to transform an input sample into an encoded feature vector, while the task of the decoder is the opposite: rebuilding the original sample using the feature vector as input. The following diagram shows a schematic representation of a generic model:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d193d496-7b5e-494f-bd76-4dd061a611ec.png" style="width:28.67em;height:12.42em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Schema of a generic autoencoder</div>
<p>More formally, we can describe the encoder as a parametrized function:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1119ad07-4885-4d70-b284-6a7605a9e978.png" style="width:17.83em;height:1.92em;"/></div>
<p>The output <em>z<sub>i</sub></em> is a vectorial code whose dimensionality is normally quite lower than the inputs. Analogously, the decoder is described as the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/a57ab307-c63a-4395-9098-440a507acab1.png" style="width:8.92em;height:2.00em;"/></p>
<p class="mce-root">The goal of a standard algorithm is to minimize a cost function that is proportional to the reconstruction error. A classic method is based on the mean squared error (working on a dataset with <em>M</em> samples):</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b1579613-65da-42f3-b2ec-7c8a3acc242f.png" style="width:40.92em;height:4.25em;"/></p>
<p>This function depends only on the input samples (which are constant) and the parameter vectors; therefore, this is <em>de facto</em> an unsupervised method where we can control the internal structure and the constraints imposed on the <em>z<sub>i </sub></em><span>code</span><span>. From a probabilistic viewpoint, if the input </span><span><em>x</em></span><em><sub>i </sub></em><span>samples</span><span> are drawn from a </span><em>p(X) </em><span>data-generating process, our goal is to find a </span><em>q(•) </em><span>parametric distribution that minimizes the Kullback–Leibler divergence with <em>p(X)</em>. Considering the previous definitions, we can define </span><em><span>q(</span><span>•</span></em><span><em>)</em> as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1901744e-a487-4f9d-95eb-2e26367c1a69.png" style="width:13.33em;height:1.83em;"/></p>
<p>Therefore, the Kullback–Leibler divergence becomes the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8ccc7428-9f9d-4003-8477-430246f12cdf.png" style="width:37.92em;height:3.50em;"/></p>
<p>The first term represents the negative entropy of the original distribution, which is constant and isn't involved in the optimization process. The other term is the cross-entropy between the <em>p</em> and <em>q</em>. If we assume Gaussian distributions for <em>p</em> and <em>q</em>, the mean squared error is proportional to the cross-entropy (for optimization purposes, it's equivalent to it), and therefore this cost function is still valid under a probabilistic approach. Alternatively, it's possible to consider Bernoulli distributions for <em>p</em> and <em>q</em>, and the cross-entropy becomes the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/57185459-91e2-4b61-9fee-75335a8af9c2.png" style="width:26.50em;height:3.17em;"/></p>
<p>The main difference between the two approaches is that while a mean squared error can be applied to <em>x<sub>i</sub> ∈ ℜ<sup>q</sup></em> (or multidimensional matrices), Bernoulli distributions need <em><span>x</span><sub>i</sub></em> <span><em>∈ [0, 1]</em><sup><em>q</em> </sup>(formally, this condition should be <em>x<sub>i</sub> ∈ {0, 1}<sup>q</sup></em>; however, the optimization can also be successfully performed when the values are not binary). The same constraint is necessary for the reconstructions; therefore, when using neural networks, the most common choice is to employ sigmoid layers.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An example of a deep convolutional autoencoder with TensorFlow</h1>
                </header>
            
            <article>
                
<p>This example (like all the others in this and the following chapters) is based on TensorFlow (for information about the installation of TensorFlow, please refer to the information box at the end of the section), because this framework allows a greater flexibility that is sometimes much more problematic with Keras. We will approach this example pragmatically, and so we are not going to explore all the features because they are beyond the scope of this book; however, interested readers can refer to <em>Deep Learning with TensorFlow - Second Edition, Zaccone G., Karim R., Packt</em>.</p>
<p>In this example, we are going to create a deep convolutional autoencoder and train it using the Fashion MNIST dataset. The first step is loading the data (using the Keras helper function), normalizing, and in order to speed up the computation, limiting the training set to 1,000 samples:</p>
<pre>import numpy as np<br/><br/>from keras.datasets import fashion_mnist<br/><br/>(X_train, _), (_, _) = fashion_mnist.load_data()<br/><br/>nb_samples = 1000<br/>nb_epochs = 400<br/>batch_size = 200<br/>code_length = 256<br/><br/>X_train = X_train.astype(np.float32)[0:nb_samples] / 255.0<br/><br/>width = X_train.shape[1]<br/>height = X_train.shape[2]<strong><br/></strong></pre>
<p>At this point, we can create the <kbd>Graph</kbd>, setting up the whole architecture, which is made up of the following:</p>
<ul>
<li>The encoder (all layers have p<span>adding "same" and ReLU activation):</span>
<ul>
<li>Convolution with 32 filters, kernel size equal to (3 × 3), and strides (2 × 2)</li>
<li>Convolution with 64 filters, kernel size equal to (3 × 3), and strides (1× 1)</li>
<li>Convolution with 128 filters, kernel size equal to (3 × 3), and strides (1 × 1)</li>
</ul>
</li>
</ul>
<ul>
<li>The decoder:
<ul>
<li>Transpose convolution with 128 filters, kernel size equal to (3 × 3), and strides (2 × 2)</li>
<li>Transpose convolution with 64 filters, kernel size equal to (3 × 3), and strides (1× 1)</li>
<li>Transpose convolution with 32 filters, kernel size equal to (3 × 3), and strides (1 × 1)</li>
<li>Transpose convolution with 1 filter, kernel size equal to (3 × 3), strides (1 × 1), and sigmoid activation</li>
</ul>
</li>
</ul>
<p>As the images are (28 × 28), we prefer to resize each batch to the dimensions of (32 × 32) to easily manage all the subsequent operations that are based on sizes which are a power of 2:</p>
<pre>import tensorflow as tf<br/><br/>graph = tf.Graph()<br/><br/>with graph.as_default():<br/>    input_images = tf.placeholder(tf.float32, shape=(None, width, height, 1))<br/>    <br/>    r_input_images = tf.image.resize_images(input_images, (32, 32))<br/>    <br/>    # Encoder<br/>    conv_0 = tf.layers.conv2d(inputs=r_input_images,<br/>                              filters=32,<br/>                              kernel_size=(3, 3),<br/>                              strides=(2, 2),<br/>                              activation=tf.nn.relu,<br/>                              padding='same')<br/>    <br/>    conv_1 = tf.layers.conv2d(inputs=conv_0,<br/>                              filters=64,<br/>                              kernel_size=(3, 3),<br/>                              activation=tf.nn.relu,<br/>                              padding='same')<br/>    <br/>    conv_2 = tf.layers.conv2d(inputs=conv_1,<br/>                              filters=128,<br/>                              kernel_size=(3, 3),<br/>                              activation=tf.nn.relu,<br/>                              padding='same')<br/>    <br/>    # Code layer<br/>    code_input = tf.layers.flatten(inputs=conv_2)<br/>    <br/>    code_layer = tf.layers.dense(inputs=code_input,<br/>                                 units=code_length,<br/>                                 activation=tf.nn.sigmoid)<br/>    <br/>    # Decoder<br/>    decoder_input = tf.reshape(code_layer, (-1, 16, 16, 1))<br/>    <br/>    convt_0 = tf.layers.conv2d_transpose(inputs=decoder_input,<br/>                                         filters=128,<br/>                                         kernel_size=(3, 3),<br/>                                         strides=(2, 2),<br/>                                         activation=tf.nn.relu,<br/>                                         padding='same')<br/>    <br/>    convt_1 = tf.layers.conv2d_transpose(inputs=convt_0,<br/>                                         filters=64,<br/>                                         kernel_size=(3, 3),<br/>                                         activation=tf.nn.relu,<br/>                                         padding='same')<br/>    <br/>    convt_2 = tf.layers.conv2d_transpose(inputs=convt_1,<br/>                                         filters=32,<br/>                                         kernel_size=(3, 3),<br/>                                         activation=tf.nn.relu,<br/>                                         padding='same')<br/>    <br/>    convt_3 = tf.layers.conv2d_transpose(inputs=convt_2,<br/>                                         filters=1,<br/>                                         kernel_size=(3, 3),<br/>                                         activation=tf.sigmoid,<br/>                                         padding='same')<br/>    <br/>    # Loss<br/>    loss = tf.nn.l2_loss(convt_3 - r_input_images)<br/>    <br/>    # Training step<br/>    training_step = tf.train.AdamOptimizer(0.001).minimize(loss)<strong> </strong></pre>
<p>The loss function is a standard L2 without any other constraint. I invite the reader to test different optimizers and learning rates to employ a solution that guarantees the minimum loss value. After defining the <kbd>Graph</kbd>, it's possible to set up an <kbd>InteractiveSession</kbd> (or a standard one), initialize all variables, and begin the training process:</p>
<pre>import numpy as np<br/>import tensorflow as tf<br/><br/>session = tf.InteractiveSession(graph=graph)<br/>tf.global_variables_initializer().run()<br/><br/>for e in range(nb_epochs):<br/>    np.random.shuffle(X_train)<br/>    <br/>    total_loss = 0.0<br/>    <br/>    for i in range(0, nb_samples - batch_size, batch_size):<br/>        X = np.zeros((batch_size, width, height, 1), dtype=np.float32)<br/>        X[:, :, :, 0] = X_train[i:i + batch_size, :, :]<br/>        <br/>        _, n_loss = session.run([training_step, loss], <br/>                                feed_dict={<br/>                                    input_images: X<br/>                                })<br/>        total_loss += n_loss<br/>        <br/>    print('Epoch {}) Total loss: {}'.format(e + 1, total_loss))</pre>
<p>Once the training process is finished, we can check the average code length for the whole dataset (this information is useful to compare this result with the one achieved by imposing a sparsity constraint):</p>
<pre>import numpy as np<br/><br/>codes = session.run([code_layer], <br/>                    feed_dict={<br/>                        input_images: np.expand_dims(X_train, axis=3),<br/>                    })[0]<br/><br/>print(np.mean(codes))<br/>0.5545144</pre>
<p>This value is very small, indicating that the representations are already rather sparse; however, we are going to compare it with the mean obtained by a sparse autoencoder. We can now process a few images (10) by encoding and decoding them:</p>
<pre>import numpy as np<br/><br/>Xs = np.reshape(X_train[0:10], (10, width, height, 1))<br/><br/>Ys = session.run([convt_3], <br/>                 feed_dict={<br/>                     input_images: Xs<br/>                })<br/><br/>Ys = np.squeeze(Ys[0] * 255.0)</pre>
<p>The result is shown in the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/107520ee-94a1-4dc3-ba5b-f6416cf0d4f5.png" style="width:75.42em;height:16.50em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Original images (upper row); decoded images (lower row)</div>
<p>As you can see, the reconstructions are rather lossy, but the autoencoder successfully learned how to reduce the dimensionality of the input samples. As an exercise, I invite the reader to split the code into two separate sections (encoder and decoder) and to optimize the architecture in order to achieve better accuracy on the whole Fashion MNIST dataset.</p>
<div class="packt_infobox">TensorFlow is available for Linux, Windows, and OS X with both CPU and CUDA GPU support. In many cases, it's possible to install it using the <kbd>pip install -U tensorflow </kbd><span>command;</span><span> </span><span>however, I suggest that you read the updated instructions for each platform at </span><a href="https://www.tensorflow.org/install/">https://www.tensorflow.org/install/</a><span>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Denoising autoencoders</h1>
                </header>
            
            <article>
                
<p>Autoencoders can be used to determine under-complete representations of a dataset; however, Bengio et al. (in <span>P.</span> <span>Vincent,</span> <span>H.</span> <span>Larochelle,</span> <span>I.</span> <span>Lajoie,</span> <span>Y.</span> <span>Bengio, and</span> <span>P.</span> <span>Manzagol's book</span> <em>Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion,</em> from the <em>Journal</em> <em>of Machine Learning Research 11/2010</em><span>) proposed to use them not to learn the exact representation of a sample in order to rebuild it from a low-dimensional code, but rather to denoise input samples. This is not a brand new idea, because, for example, Hopfield networks (proposed a few decades ago) had the same purpose, but its limitations in terms of capacity led researchers to look for different methods. Nowadays, deep autoencoders can easily manage high-dimensional data (such as images) with a consequent space requirement, that's why many people are now reconsidering the idea of teaching a network how to rebuild a sample image starting from a corrupted one.</span></p>
<p>Formally, there are not many differences between denoising autoencoders and standard autoencoders. However, in this case, the encoder must work with noisy samples:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/9b1ba7e8-705a-4b9a-a017-59bd6da0cf05.png" style="width:20.75em;height:1.92em;"/></div>
<p>The decoder's cost function remains the same. If the noise is sampled for each batch, repeating the process for a sufficiently large number of iterations allows the autoencoder to learn how to rebuild the original image when some fragments are missing or corrupted. To achieve this goal, the authors suggested different possible kinds of noise. The most common choice is to sample Gaussian noise, which has some helpful features and is coherent with many real noisy processes:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/59e89e7a-90c5-44d8-90db-4500f1499453.png" style="width:33.92em;height:1.83em;"/></p>
<p>Another possibility is to employ an input dropout layer, zeroing some random elements:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/495a9795-f1a1-4574-a0ac-4a0deda8a2c4.png" style="width:32.75em;height:1.83em;"/></p>
<p>This choice is clearly more drastic, and the rate must be properly tuned. A very large number of dropped pixels can irreversibly delete many pieces of information and the reconstruction can become more difficult and <em>rigid</em> (our purpose is to extend the autoencoder's ability to other samples drawn from the same distribution). Alternatively, it's possible to mix up Gaussian noise and the dropout's, switching between them with a fixed probability. Clearly, the models must be more complex than standard autoencoders because now they have to cope with missing information; the same concept applies to the code length: very under-complete code wouldn't be able to provide all the elements needed to reconstruct the original image in the most accurate way. I suggest testing all the possibilities, in particular when the noise is constrained by external conditions (for example, old photos or messages transmitted through channels affected by precise noise processes). If the model must also be employed for never-before-seen samples, it's extremely important to select samples that represent the true distribution, <span>using data augmentation techniques (limited to operations compatible with the specific problem) whenever the number of elements is not enough to reach the desired level of accuracy.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An example of a denoising autoencoder with TensorFlow</h1>
                </header>
            
            <article>
                
<p>In this example (based on the previous one), we are going to employ a very similar architecture, but as the goal is denoising the images, we will impose a code length equal to (width × height), setting all the strides to (1 × 1), and therefore we won't need to resize the images anymore:</p>
<pre>import tensorflow as tf<br/><br/>graph = tf.Graph()<br/><br/>with graph.as_default():<br/>    input_noisy_images = tf.placeholder(tf.float32, shape=(None, width, height, 1))<br/>    input_images = tf.placeholder(tf.float32, shape=(None, width, height, 1))<br/>    <br/>    # Encoder<br/>    conv_0 = tf.layers.conv2d(inputs=input_noisy_images,<br/>                              filters=32,<br/>                              kernel_size=(3, 3),<br/>                              activation=tf.nn.relu,<br/>                              padding='same')<br/>    <br/>    conv_1 = tf.layers.conv2d(inputs=conv_0,<br/>                              filters=64,<br/>                              kernel_size=(3, 3),<br/>                              activation=tf.nn.relu,<br/>                              padding='same')<br/>    <br/>    conv_2 = tf.layers.conv2d(inputs=conv_1,<br/>                              filters=128,<br/>                              kernel_size=(3, 3),<br/>                              activation=tf.nn.relu,<br/>                              padding='same')<br/>    <br/>    # Code layer<br/>    code_input = tf.layers.flatten(inputs=conv_2)<br/>    <br/>    code_layer = tf.layers.dense(inputs=code_input,<br/>                                 units=width * height,<br/>                                 activation=tf.nn.sigmoid)<br/>    <br/>    # Decoder<br/>    decoder_input = tf.reshape(code_layer, (-1, width, height, 1))<br/>    <br/>    convt_0 = tf.layers.conv2d_transpose(inputs=decoder_input,<br/>                                         filters=128,<br/>                                         kernel_size=(3, 3),<br/>                                         activation=tf.nn.relu,<br/>                                         padding='same')<br/>    <br/>    convt_1 = tf.layers.conv2d_transpose(inputs=convt_0,<br/>                                         filters=64,<br/>                                         kernel_size=(3, 3),<br/>                                         activation=tf.nn.relu,<br/>                                         padding='same')<br/>    <br/>    convt_2 = tf.layers.conv2d_transpose(inputs=convt_1,<br/>                                         filters=32,<br/>                                         kernel_size=(3, 3),<br/>                                         activation=tf.nn.relu,<br/>                                         padding='same')<br/>    <br/>    convt_3 = tf.layers.conv2d_transpose(inputs=convt_2,<br/>                                         filters=1,<br/>                                         kernel_size=(3, 3),<br/>                                         activation=tf.sigmoid,<br/>                                         padding='same')<br/>    <br/>    # Loss<br/>    loss = tf.nn.l2_loss(convt_3 - input_images)<br/>    <br/>    # Training step<br/>    training_step = tf.train.AdamOptimizer(0.001).minimize(loss)</pre>
<p>In this case, we need to pass both the noisy images (through the <kbd>placeholder input_noisy_images</kbd>) and the original ones (which are used to compute the final L2 loss function). For our example, we have decided to employ Gaussian noise with a standard deviation of <kbd>σ = 0.2</kbd> (clipping the final values so that they are always constrained between 0 and 1):</p>
<pre>import numpy as np<br/>import tensorflow as tf<br/><br/>session = tf.InteractiveSession(graph=graph)<br/>tf.global_variables_initializer().run()<br/><br/>for e in range(nb_epochs):<br/>    total_loss = 0.0<br/>    <br/>    for i in range(0, nb_samples - batch_size, batch_size):<br/>        X = np.zeros((batch_size, width, height, 1), dtype=np.float32)<br/>        X[:, :, :, 0] = X_train[i:i + batch_size, :, :]<br/>        Xn = np.clip(X + np.random.normal(0.0, 0.2, size=(batch_size, width, height, 1)), 0.0, 1.0)<br/>        <br/>        _, n_loss = session.run([training_step, loss], <br/>                                feed_dict={<br/>                                    input_images: X,<br/>                                    input_noisy_images: Xn<br/>                                })<br/>        total_loss += n_loss<br/>        <br/>    print('Epoch {}) Total loss: {}'.format(e + 1, total_loss))</pre>
<p>The result after 200 epochs is shown in the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/430f3d36-e54f-4420-9fd4-622f797a49ac.png" style="width:73.67em;height:15.50em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Noisy samples (upper row); denoised samples (lower row)</div>
<p>The denoising autoencoder has successfully learned to rebuild the original images in the presence of Gaussian noise. I invite the reader to test other methods (such as using an initial dropout) and increase the noise level to understand what the maximum corruption is that this model can effectively remove.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sparse autoencoders</h1>
                </header>
            
            <article>
                
<p>In general, standard autoencoders produce dense internal representations. This means that most of the values are different from zero. In some cases, however, it's more useful to have sparse codes that can better represent the atoms belonging to a dictionary. In this case, if <em>z<sub>i</sub></em> = (0, 0, <em>z<sub>i</sub><sup>n</sup></em>, ..., 0, <em><span>z</span><sub>i</sub><sup>m</sup></em>, ...), we can consider each sample as the overlap of specific atoms weighted accordingly. To achieve this objective, we can simply apply an L1 penalty to the code layer, as explained in <a href="acff0775-f21c-4b6d-8ef2-c78713e21364.xhtml" target="_blank">Chapter 1</a>, <em>Machine Learning</em> <em>Models</em> <em>Fundamentals</em>. The loss function for a single sample therefore becomes the following:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/29b6cc9e-af0c-4533-b5a7-f578a866da9d.png" style="width:22.17em;height:1.92em;"/></div>
<p class="mce-root CDPAlignLeft CDPAlign">In this case, we need to consider the extra hyperparameter α, which must be tuned to increase the sparsity without a negative impact on the accuracy. As a general rule of thumb, I suggest starting with a value equal to 0.01 and reducing it until the desired result has been achieved. In most cases, higher values yield very poor performance, and therefore they are generally avoided.</p>
<p>A different approach has been proposed by Andrew Ng (in his book <em>Sparse Autoencoder, CS294A, Stanford University</em>). If we consider the code layer as a set of independent Bernoulli random variables, we can enforce sparsity by considering a generic reference Bernoulli variable with a very low mean (for example, <em>p<sub>r</sub></em> = 0.01) and adding the Kullback–Leibler divergence between the generic element <em>z<sub>i</sub><sup>(j)</sup></em> and <em>p<sub>r</sub></em> to the cost function. For a single sample, the extra term is as follows (<em>p</em> is the code length):</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b39a7eec-78fc-4f40-9149-a3f3a69ef8c7.png" style="width:33.58em;height:4.08em;"/></p>
<p>The resulting loss function becomes the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f84c138c-77bb-4cfa-8f0e-0b072d9360dc.png" style="width:21.25em;height:1.92em;"/></p>
<p class="mce-root">The effect of this penalty is similar to L1 (with the same considerations about the <span>α</span> <span>hyperparameter), but many experiments have confirmed that the resulting cost function is easier to optimize, and it's possible to achieve the same level of sparsity that reaches higher reconstruction accuracies. When working with sparse autoencoders, the code length is often larger because of the assumption that a single element is made up of a small number of atoms (compared to the dictionary size). As a result, I suggest that you evaluate the level of sparsity with different code lengths and select the combination that maximizes the former and minimizes the latter.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding sparseness to the Fashion MNIST deep convolutional autoencoder</h1>
                </header>
            
            <article>
                
<p>In this example, we are going to add an L1 regularization term to the cost function that was defined in the first exercise:</p>
<pre>import tensorflow as tf<br/><br/>...<br/><br/># Loss<br/>sparsity_constraint = tf.reduce_sum(0.001 * tf.norm(code_layer, ord=1, axis=1))<br/>loss = tf.nn.l2_loss(convt_3 - r_input_images) + sparsity_constraint<br/><br/>...<strong> </strong></pre>
<p>The training process is exactly the same, and therefore we can directly show the final code mean after 200 epochs:</p>
<pre>import numpy as np<br/><br/>codes = session.run([code_layer], <br/>                    feed_dict={<br/>                        input_images: np.expand_dims(X_train, axis=3),<br/>                    })[0]<br/><br/>print(np.mean(codes))<br/>0.45797634</pre>
<p>As you can see, the mean is now lower, indicating that more code values are close to 0. I invite the reader to implement the other strategy, considering that it's easier to create a constant vector filled with small values (for example, 0.01) and exploit the vectorization properties offered by TensorFlow. I also suggest simplifying the Kullback–Leibler divergence by splitting it into an entropy term <em>H(p<sub>r</sub>)</em> (which is constant) and a cross-entropy <em>H(z, p<sub>r</sub>)</em> <span>term</span><span>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Variational autoencoders</h1>
                </header>
            
            <article>
                
<p>A <strong>variational autoencoder</strong> (<strong>VAE</strong>) is a generative model proposed by Kingma and Wellin (in their work <em>Auto-Encoding Variational Bayes, arXiv:1312.6114 [stat.ML]</em>) that partially resembles a standard autoencoder, but it has some fundamental internal differences. The goal, in fact, is not finding an encoded representation of a dataset, but determining the parameters of a generative process that is able to yield all possible outputs given an input data-generating process.</p>
<p>Let's take the example of a model based on a learnable parameter vector <em>θ</em> and a set of latent variables <em>z</em> that have a probability density function <em>p(z;<span>θ)</span></em>. Our goal can therefore be expressed as the research of the <em>θ</em> <span>parameters</span> <span>that maximize the likelihood of the marginalized distribution <em>p(x;</em></span><span><em>θ)</em> (obtained through the integration of the joint probability <em>p(x,z;θ</em></span>)<span>):</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/95315e07-cf03-4353-bb7a-4a7128d08681.png" style="width:29.42em;height:3.17em;"/></p>
<p>If this problem could be easily solved in closed form, a large set of samples drawn from the <em>p(x)</em> <span>data generating process</span> <span>would be enough to find a</span> <em><span>p(x;</span><span>θ)</span></em> <span>good approximation</span><span>. Unfortunately, the previous expression is intractable in the majority of cases because the true prior <em>p(z)</em> is unknown (this is a secondary issue, as we can easily make some helpful assumptions) and the posterior distribution <em>p(x|z;θ)</em> is almost always close to zero. The first problem can be solved by selecting a simple prior (the most common choice is <em>z ∼ N(0, I)</em>), but the second one is still very hard because only a few <em>z</em> values can lead to the generation of acceptable samples. This is particularly true when the dataset is very high dimensional and complex (for example, images). Even if there are millions of combinations, only a small number of them can yield realistic samples (if the images are photos of cars, we expect four wheels in the lower part, but it's still possible to generate samples where the wheels are on the top). For this reason, we need to exploit a method to reduce the sample space. Variational Bayesian methods (read</span> <em>C.</em> <span>Fox and S. Roberts's work <em>A Tutorial on Variational Bayesian Inference</em> from <em>Orchid</em> for further information</span><span>) are based on the idea of employing <em>proxy</em> distributions, which are easy to sample and, in this case, whose density is very high (that is, the probability of generating a reasonable output is much higher than the true posterior).</span></p>
<p><span>In this case, we define an approximate posterior, considering the architecture of a standard autoencoder. In particular, we can introduce a</span> <em>q(z|x;θ<sub>q</sub>)</em> <span>distribution</span> <span>that acts as an encoder (that doesn't behave determinastically anymore), which can be easily modeled with a neural network. Our goal, of course, is to find the best</span> <em><span>θ</span><sub>q</sub></em> <span>parameter set</span><span> to maximize the similarity between <em>q</em> and the true posterior distribution <em>p(z|x;θ)</em>. This result can be achieved by minimizing the Kullback–Leibler divergence:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b18cfc5e-0f3f-46ae-851c-b4794a60d700.png" style="width:62.50em;height:9.58em;"/></p>
<p class="CDPAlignCenter CDPAlign CDPAlignLeft">In the last formula, the term <em>log p(x;</em><span><em>θ)</em> doesn't depend on <em>z</em>, and therefore it can be extracted from the expected value operator and the expression can be manipulated to simplify it:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/96a6d5c0-f5c8-4920-9ca5-8736ae50a881.png" style="width:62.50em;height:7.17em;"/></p>
<p>The equation can be also rewritten as the following:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/56866363-4d7f-4463-8c41-e41f7ae56d30.png" style="width:62.50em;height:4.67em;"/></div>
<p>On the right-hand side, we <span>now</span> <span>have the term <strong>ELBO</strong> (short for <strong>evidence lower bound</strong>) and the Kullback–Leibler divergence</span> <span>between the probabilistic encoder</span> <em><span>q(z|x;θ</span><sub>q</sub><span>)</span></em> <span>and the true posterior distribution <em>p(z|x;</em></span><span><em>θ)</em>. As we want to maximize the log-probability of a sample under the</span> <span><em>θ</em></span> <span>parametrization,</span> <span>and considering that the KL divergence is always non-negative, we can</span> <span>only</span> <span>work with the ELBO (which is a lot easier to manage than the other term). Indeed, the loss function that we are going to optimize is the negative ELBO.</span> <span>To achieve this goal, we need two more important steps.</span></p>
<p><span>The first one is choosing an appropriate structure for <em>q(z|x;θ<sub>q</sub>)</em>. As <em>p(z;θ)</em> is assumed to be normal, we can supposedly model <em>q(z|x;θ<sub>q</sub>)</em> as a multivariate Gaussian distribution, splitting the probabilistic encoder into two blocks fed with the same lower layers:</span></p>
<ul>
<li>A mean <em>μ(z|x;θ<sub>q</sub>)</em> generator that outputs a <em>μ<sub>i</sub> ∈ ℜ<sup>p</sup></em> vector</li>
<li>A <em>Σ(z|x;θ<sub>q</sub></em><em>)</em> covariance generator (assuming a diagonal matrix) <span>that outputs a <em>σ<sub>i</sub> ∈ ℜ<sup>p</sup></em> vector so that <em>Σ<sub>i</sub>=</em>diag<em>(σ<sub>i</sub>)</em></span></li>
</ul>
<p>In this way, <em><span>q(z|x;θ</span><sub>q</sub></em><span><em>) = N(μ(z|x;θ<sub>q</sub>), Σ(z|x;θ<sub>q</sub>))</em>, and therefore the second term on the right-hand side is the Kullback<em>-</em>Leibler divergence between two Gaussian distributions that can be easily expressed as follows (<em>p</em> is the dimension of both the mean and covariance vector):</span></p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8f7f2056-f177-4232-85d8-b8000a39adcb.png" style="width:73.00em;height:3.33em;"/></div>
<p>This operation is simpler than expected because, as <span><em>Σ</em> is diagonal, the trace corresponds to the sum of the elements <em>Σ<sub>1</sub></em> + <em>Σ<sub>2</sub></em> + [...] + <em>Σ<sub>p</sub></em> and log(|<em>Σ</em>|) = log(<em>Σ<sub>1</sub>Σ<sub>2</sub>...Σ<sub>p</sub></em>) = log <em>Σ<sub>1</sub></em> + log <em>Σ<sub>2</sub></em> + ... + log <em>Σ<sub>p</sub></em>.</span></p>
<p>At this point, maximizing the right-hand side of the previous expression is equivalent to maximizing the expected value of the log probability to generate acceptable samples and minimizing the discrepancy between the normal prior and the Gaussian distribution synthesized by the encoder. Everything seems much simpler now, but there is still a problem to solve. We want to use neural networks and the stochastic gradient descent algorithm, and therefore we need differentiable functions. As the Kullback<em>-</em>Leibler divergence can be computed only using minibatches with <em>n</em> elements (the approximation becomes close to the true value after a sufficient number of iterations), it's necessary to sample <em>n</em> values from the distribution <em><span>N(μ(z|x;θ</span><sub>q</sub><span>),</span> <span>Σ</span><span>(</span><span>z|x;θ</span><sub>q</sub></em><span><em>)</em>) and, unfortunately, this operation is not differentiable. To solve this problem, the authors suggested a reparameterization trick: instead of sampling from <em>q(z|x;θ<sub>q</sub>)</em>, we can sample from a normal distribution, <em>ε ∼ N(0, I)</em>, and build the actual samples as <em>μ(z|x;θ<sub>q</sub>)</em> + <em>ε · Σ(z|x;θ<sub>q</sub>)</em><sup>2</sup>. Considering that <em>ε</em> is a constant vector during a batch (both the forward and backward phases), it's easy to compute the gradient with respect to the previous expression and optimize both the decoder and the encoder.</span></p>
<p>The last element to consider is the first term on the right-hand side of the expression that we want to maximize:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f5497892-3ca4-4615-becd-3f428a38df72.png" style="width:45.33em;height:3.25em;"/></p>
<p class="mce-root">This term represents the negative cross-entropy between the actual distribution and the reconstructed one. As discussed in the first section, there are two feasible choices: Gaussian or Bernoulli distributions. In general, variational autoencoders employ a Bernoulli distribution with input samples and reconstruction values constrained between 0 and 1. However, many experiments have confirmed that the mean squared error can speed up the training process, and therefore I suggest that the reader test both methods and pick the one that guarantees the best performance (both in terms of accuracy and training speed).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An example of a variational autoencoder with TensorFlow</h1>
                </header>
            
            <article>
                
<p>Let's continue working with the Fashion MNIST dataset to build a variational autoencoder. As explained, the output of the encoder is now split into two components: the mean and covariance vectors (both with dimensions equal to <em>(width · height)</em>) and the decoder input is obtained by sampling from a normal distribution and projecting the code components. The complete <kbd>Graph</kbd> is as follows:</p>
<pre>import tensorflow as tf<br/><br/>graph = tf.Graph()<br/><br/>with graph.as_default():<br/>    input_images = tf.placeholder(tf.float32, shape=(batch_size, width, height, 1))<br/>    <br/>    # Encoder<br/>    conv_0 = tf.layers.conv2d(inputs=input_images,<br/>                              filters=32,<br/>                              kernel_size=(3, 3),<br/>                              strides=(2, 2),<br/>                              activation=tf.nn.relu,<br/>                              padding='same')<br/>    <br/>    conv_1 = tf.layers.conv2d(inputs=conv_0,<br/>                              filters=64,<br/>                              kernel_size=(3, 3),<br/>                              strides=(2, 2),<br/>                              activation=tf.nn.relu,<br/>                              padding='same')<br/>    <br/>    conv_2 = tf.layers.conv2d(inputs=conv_1,<br/>                              filters=128,<br/>                              kernel_size=(3, 3),<br/>                              activation=tf.nn.relu,<br/>                              padding='same')<br/>    <br/>    # Code layer<br/>    code_input = tf.layers.flatten(inputs=conv_2)<br/>    <br/>    code_mean = tf.layers.dense(inputs=code_input,<br/>                                units=width * height)<br/>    <br/>    code_log_variance = tf.layers.dense(inputs=code_input,<br/>                                        units=width * height)<br/>    <br/>    code_std = tf.sqrt(tf.exp(code_log_variance))<br/>    <br/>    # Normal samples<br/>    normal_samples = tf.random_normal(mean=0.0, stddev=1.0, shape=(batch_size, width * height))<br/>    <br/>    # Sampled code<br/>    sampled_code = (normal_samples * code_std) + code_mean<br/>    <br/>    # Decoder<br/>    decoder_input = tf.reshape(sampled_code, (-1, 7, 7, 16))<br/>    <br/>    convt_0 = tf.layers.conv2d_transpose(inputs=decoder_input,<br/>                                         filters=64,<br/>                                         kernel_size=(3, 3),<br/>                                         strides=(2, 2),<br/>                                         activation=tf.nn.relu,<br/>                                         padding='same')<br/>    <br/>    convt_1 = tf.layers.conv2d_transpose(inputs=convt_0,<br/>                                        filters=32,<br/>                                        kernel_size=(3, 3),<br/>                                        strides=(2, 2),<br/>                                        activation=tf.nn.relu,<br/>                                        padding='same')<br/>    <br/>    convt_2 = tf.layers.conv2d_transpose(inputs=convt_1,<br/>                                        filters=1,<br/>                                        kernel_size=(3, 3),<br/>                                        padding='same')<br/>    <br/>    convt_output = tf.nn.sigmoid(convt_2)<br/>    <br/>    <br/>    # Loss<br/>    reconstruction = tf.nn.sigmoid_cross_entropy_with_logits(logits=convt_2, labels=input_images)<br/>    kl_divergence = 0.5 * tf.reduce_sum(tf.square(code_mean) + tf.square(code_std) - tf.log(1e-8 + tf.square(code_std)) - 1, axis=1) <br/>    <br/>    loss = tf.reduce_sum(reconstruction) + kl_divergence<br/>    <br/>    # Training step<br/>    training_step = tf.train.AdamOptimizer(0.001).minimize(loss)</pre>
<p>As you can see, the only differences are as follows:</p>
<ul>
<li>The generation of the encoder input is <kbd>(normal_samples * code_std) + code_mean</kbd></li>
<li>The use of sigmoid cross-entropy as reconstruction loss</li>
<li>The presence of the Kullback<em>-</em>Leibler divergence as a regularization term</li>
</ul>
<p>The training process is identical to the first example in this chapter, as the sampling operations are performed directly by TensorFlow. The result after 200 epochs is shown in the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ab30ddbf-f422-4504-95ea-388e16d1561c.png" style="width:46.17em;height:9.92em;"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Variational autoencoder output</div>
<p>As an exercise, I invite the reader to use RGB datasets (such as Cifar-10, which is found at <a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a>) to test the generation ability of the VAE by comparing the output samples with the one drawn from the original distribution.</p>
<div class="packt_infobox">In these kinds of experiments, where the random numbers are generated by <span>both</span> <span>NumPy and TensorFlow, the random seeds are always set equal to 1,000 (</span><kbd>np.random.seed(1000)</kbd> <span>and</span> <kbd>tf.set_random_seed(1000)</kbd><span>). Other values or subsequent tests without resetting the seeds can yield slightly different results.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we presented autoencoders as unsupervised models that can learn to represent high-dimensional datasets with lower-dimensional codes. They are structured into two separate blocks (which, however, are trained together): an encoder, responsible for mapping the input sample to an internal representation, and a decoder, which must perform the inverse operation, rebuilding the original image starting from the code.</p>
<p>We have also discussed how autoencoders can be used to denoise samples and how it's possible to impose a sparsity constraint on the code layer to resemble the concept of standard dictionary learning. The last topic was about a slightly different pattern called a variational autoencoder. The idea is to build a generative model that is able to reproduce all the possible samples belonging to a training distribution.</p>
<p class="mce-root">In the next chapter, we are going to briefly introduce a very important model family called <strong>generative adversarial networks</strong> (<strong>GANs</strong>), which are not very different from the purposes of a variational autoencoder, but which have a much more flexible approach.</p>


            </article>

            
        </section>
    </body></html>