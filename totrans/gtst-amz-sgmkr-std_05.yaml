- en: '*Chapter 3*: Data Preparation with SageMaker Data Wrangler'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第3章*：使用SageMaker数据整理进行数据准备'
- en: With SageMaker Data Wrangler, you can perform exploratory data analysis and
    data preprocessing for ML modeling with a point and click experience. You will
    be able to quickly iterate through data transformation and quick modeling to see
    if your transform recipe improves model performance, learning if there is implicit
    bias in the data against sensitive groups, and having a clear record of what transformation
    has been done on the processed data.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SageMaker数据整理，你可以通过点击和点击的方式执行数据探索分析和数据预处理，以便进行机器学习建模。你将能够快速迭代数据转换和快速建模，以查看你的转换配方是否提高了模型性能，学习数据中是否存在对敏感群体的隐含偏见，并清楚地记录对处理数据的转换。
- en: 'In this chapter, we will be learning how to use **SageMaker Data Wrangler**
    in the following sections:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下部分如何使用**SageMaker数据整理**：
- en: Getting started with SageMaker Data Wrangler for customer churn prediction
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用SageMaker数据整理进行客户流失预测
- en: Importing data from sources
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从源导入数据
- en: Exploring data with visualization
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用可视化探索数据
- en: Applying transformation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用转换
- en: Exporting data for ML training
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导出数据以进行机器学习训练
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you will need to access materials in [https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter03](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter03).
    You need to make sure your IAM execution role has the AmazonAthenaFullAccess policy.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，你需要访问[https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter03](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter03)中的材料。你需要确保你的IAM执行角色具有AmazonAthenaFullAccess策略。
- en: Getting started with SageMaker Data Wrangler for customer churn prediction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用SageMaker数据整理进行客户流失预测
- en: Customer churn is a serious problem for businesses. Losing a customer is definitely
    not something you want to see if you are a business owner. You want to your customers
    to be happy with your product or service and continue to use them for, well, forever.
    Customer churn is always going to happen but being able to understand how and
    why a customer leaves the service or why a customer is not buying your product
    anymore is critical for your business. Being able to predict ahead of time would
    be even better.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 客户流失对企业来说是一个严重的问题。如果你是业务所有者，失去客户绝对不是你希望看到的。你希望你的客户对你的产品或服务感到满意，并且永远继续使用它们。客户流失总是会发生，但能够理解客户为何离开服务或为何不再购买你的产品是至关重要的，提前预测会更好。
- en: In this chapter, we will perform exploratory data analysis and data transformation
    with SageMaker Data Wrangler, and at the end of the chapter, we will be training
    an ML model using the **XGBoost algorithm** on the wrangled data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用SageMaker数据整理进行数据探索分析和数据转换，并在本章结束时，我们将使用**XGBoost算法**在整理后的数据上训练一个机器学习模型。
- en: Preparing the use case
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备用例
- en: 'We are going to take a synthetic `chapter03/1-prepare_data.ipynb` notebook
    and execute the it. You will get a copy of the data, then perform these steps:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个合成的`chapter03/1-prepare_data.ipynb`笔记本并执行它。你将获得数据副本，然后执行以下步骤：
- en: Split the data into three data frames, `customer_info`, `account_info`, and
    `utility`, so that we can demonstrate joining in SageMaker Data Wrangler.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为三个数据框，`customer_info`、`account_info`和`utility`，以便我们可以在SageMaker数据整理中演示连接。
- en: Mask out values randomly to create missingness in the data so that we can demonstrate
    functionalities of SageMaker Data Wrangler.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机屏蔽值以在数据中创建缺失值，以便我们可以演示SageMaker数据整理的功能。
- en: Save the three data frames in an S3 bucket and make `utility` available in Amazon
    Athena so that we can simulate importing data from multiple sources.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将三个数据框保存到S3存储桶中，并在Amazon Athena中使`utility`可用，以便我们可以模拟从多个来源导入数据。
- en: Launching SageMaker Data Wrangler
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动SageMaker数据整理
- en: 'You can access SageMaker Data Wrangler in any of the following ways:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下任何一种方式访问SageMaker数据整理：
- en: Click through **File** | **New** | **Data Wrangler Flow** (*Figure 3.1*).
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击**文件** | **新建** | **数据整理流程** (*图3.1*).
- en: From the Launcher, click on **New data flow** (*Figure 3.1*).
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从启动器中，点击**新建数据流** (*图3.1*).
- en: '![Figure 3.1 – Creating a new Data Wrangler flow'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.1 – 创建新的数据整理流程'
- en: '](img/B17447_03_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_03_01.jpg)'
- en: Figure 3.1 – Creating a new Data Wrangler flow
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 创建新的数据整理流程
- en: From the left sidebar, **SageMaker resources**, choose Data Wrangler in the
    drop-down menu and click **New flow** (*Figure 3.2*).
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从左侧侧边栏，**SageMaker 资源**，在下拉菜单中选择数据整理器，并点击 **新建流程** (*图 3.2*)。
- en: '![Figure 3.2 – Creating a new Data Wrangler flow file from the registry. You
    can find all the flow files you have here too'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2 – 从注册表中创建新的数据整理流程文件。您也可以在这里找到您所有的流程文件'
- en: '](img/B17447_03_02.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_03_02.jpg)'
- en: Figure 3.2 – Creating a new Data Wrangler flow file from the registry. You can
    find all the flow files you have here too
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 从注册表中创建新的数据整理流程文件。您也可以在这里找到您所有的流程文件
- en: Notably, from `untitled.flow`, created in the current working directory. A *data
    flow file*, with the extension `.flow`, is a file that records all the steps you
    do with SageMaker Data Wrangler from the UI. It is a JSON-based file that can
    be easily transferred and reused. SageMaker Studio and Data Wrangler can interpret
    the content of the JSON file and render the transformations and analyses you do
    for the dataset. What's happening behind the scenes during this wait time is SageMaker
    Studio is launching a data wrangler *KernelGateway* app with a dedicated *ml.m5.4xlarge*
    instance to support the activities we are going to perform inside SageMaker Data
    Wrangler and to avoid contention with other notebook kernels. Once it's ready,
    you should see the view presented in *Figure 3.3*.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，从当前工作目录中创建的 `untitled.flow`。一个 *数据流文件*，扩展名为 `.flow`，是一个记录您使用 SageMaker 数据整理器从
    UI 执行的所有步骤的文件。它是一个基于 JSON 的文件，可以轻松传输和重用。SageMaker Studio 和数据整理器可以解释 JSON 文件的内容，并呈现您为数据集执行的转换和分析。在此等待期间幕后发生的事情是
    SageMaker Studio 正在启动一个数据整理器 *KernelGateway* 应用程序，并使用一个专门的 *ml.m5.4xlarge* 实例来支持我们在
    SageMaker 数据整理器内部要执行的活动，以避免与其他笔记本内核的冲突。一旦准备就绪，您应该会看到 *图 3.3* 中展示的视图。
- en: '![Figure 3.3 – Starting point of a data wrangling journey with SageMaker Data
    Wrangler'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.3 – 使用 SageMaker 数据整理器开始数据整理之旅'
- en: '](img/B17447_03_03.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_03_03.jpg)'
- en: Figure 3.3 – Starting point of a data wrangling journey with SageMaker Data
    Wrangler
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – 使用 SageMaker 数据整理器开始数据整理之旅
- en: Before we proceed, let's rename the flow file to `wrangling-customer-churn.flow`
    or something to your liking by right-clicking on the file in the file explorer
    and selecting **Rename**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们通过在文件资源管理器中右键单击文件并选择 **重命名** 来将流程文件重命名为 `wrangling-customer-churn.flow`
    或您喜欢的名称。
- en: Now let's get started with SageMaker Data Wrangler.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们开始使用 SageMaker 数据整理器。
- en: Importing data from sources
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从源导入数据
- en: 'The first step in the data preparation journey is to import data from a source(s).
    There are four options from which data can be imported: `chapter03/1-prepare_data.ipynb`
    notebook.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备之旅的第一步是从源（s）导入数据。有四个选项可以从其中导入数据：`chapter03/1-prepare_data.ipynb` 笔记本。
- en: Importing from S3
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 S3 导入
- en: 'Please follow the next steps to import the CSV files into the S3 bucket. We
    want to load the `customer_info` and `account_info` tables:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照以下步骤将 CSV 文件导入到 S3 存储桶。我们希望加载 `customer_info` 和 `account_info` 表：
- en: From the view in *Figure 3.3*, select **Amazon S3** as the source. You should
    see a list of S3 buckets.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 *图 3.3* 中的视图选择 **Amazon S3** 作为源。您应该会看到一个 S3 存储桶列表。
- en: Locate the data following the path of the SageMaker default bucket that has
    the naming convention `sagemaker-<region>-<accountid>`. Then descend into the
    `sagemaker-studio-book/chapter03/data/` folder to find the CSV files.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定位到具有命名约定 `sagemaker-<region>-<accountid>` 的 SageMaker 默认存储桶的路径。然后进入 `sagemaker-studio-book/chapter03/data/`
    文件夹以找到 CSV 文件。
- en: Select `telco_churn_customer_info.csv` and inspect the data. Make sure the file
    type is CSV and `ml.m5.4xlarge` instance with 16 vCPUs and 64 GiB of RAM. Sampling
    can be helpful to make sure the dataset fits into the memory when you have a large
    dataset. Click **Import**.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 `telco_churn_customer_info.csv` 并检查数据。确保文件类型是 CSV，并使用具有 16 个 vCPU 和 64 GiB
    RAM 的 `ml.m5.4xlarge` 实例。采样可以帮助确保在大数据集时数据集适合内存。点击 **导入**。
- en: Repeat steps 1–3 for `telco_churn_account_info.csv`.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对 `telco_churn_account_info.csv` 重复步骤 1–3。
- en: '![Figure 3.4 – Data flow after two CSV files are imported'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.4 – 导入两个 CSV 文件后的数据流'
- en: '](img/B17447_03_04.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_03_04.jpg)'
- en: Figure 3.4 – Data flow after two CSV files are imported
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 – 导入两个 CSV 文件后的数据流
- en: Once the two CSV files are loaded, you should see the view in *Figure 3.4* in
    the `utility`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 两个 CSV 文件加载完成后，您应该在 `utility` 中的 *图 3.4* 中看到视图。
- en: Importing from Athena
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 Athena 导入
- en: 'As our `utility` table is being registered as an Amazon Athena table, we can
    import it from Athena with the following steps:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的`utility`表正在注册为Amazon Athena表，我们可以按照以下步骤从Athena导入它：
- en: Click on the **Import** tab and select **Amazon Athena** as the source. You
    should see the view shown in *Figure 3.5*.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**导入**选项卡，并选择**Amazon Athena**作为源。你应该能看到*图3.5*中显示的视图。
- en: For the two drop-down options, select **AwsDataCatalog** for **Data catalog**
    and select **telco_db** for **Database**. And for **Advanced configuration**,
    you can check/uncheck **Enable sampling**. As shown in **Location of query results**,
    you can find the output of the query in the location.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于两个下拉选项，选择**AwsDataCatalog**作为**数据目录**，并选择**telco_db**作为**数据库**。对于**高级配置**，你可以勾选/取消勾选**启用采样**。如**查询结果位置**所示，你可以在该位置找到查询的输出。
- en: '![Figure 3.5 – Importing data from Amazon Athena'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.5 – 从Amazon Athena导入数据'
- en: '](img/B17447_03_05.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_03_05.jpg)'
- en: Figure 3.5 – Importing data from Amazon Athena
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – 从Amazon Athena导入数据
- en: After you select the database, you will see the available tables on the right
    side in the `telco_churn_utility` table in our Amazon Athena database. You can
    click on the eye icon to preview the table so that we know how the table looks,
    as in *Figure 3.6*, and how to form a more complex query.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择数据库后，你将在我们的Amazon Athena数据库中的`telco_churn_utility`表右侧看到可用的表。你可以点击眼睛图标来预览表格，以便我们知道表格的外观，如*图3.6*所示，以及如何形成一个更复杂的查询。
- en: '![Figure 3.6 – Previewing the table'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.6 – 预览表格'
- en: '](img/B17447_03_06.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_03_06.jpg)'
- en: Figure 3.6 – Previewing the table
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 – 预览表格
- en: 'Let''s get all the data through a query. Please put the following query statement
    into the query box. Then click **Run**:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过查询获取所有数据。请将以下查询语句放入查询框中。然后点击**运行**：
- en: '[PRE0]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You will find the query result below the query box. We get all the rows and
    columns with the previous statement. Inspect the data and click on the **Import**
    button at the top.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将在查询框下方找到查询结果。我们通过前面的语句获取了所有行和列。检查数据并点击顶部上的**导入**按钮。
- en: Provide a dataset name, such as `telco_churn_utility`.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供一个数据集名称，例如`telco_churn_utility`。
- en: You should see all three tables being loaded into the data flow in the **Data
    Flow** tab. By clicking on the plus sign when you hover over any of the rightmost
    nodes, you will see actions that you can perform on such tables, as shown in *Figure
    3.7*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ']你应该在**数据流**选项卡中看到所有三个表被加载到数据流中。当你悬停在任何一个最右侧的节点上并点击加号时，你会看到可以对这样的表执行的操作，如*图3.7*所示。'
- en: '![Figure 3.7 – Actions after tables are imported'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.7 – 表格导入后的操作'
- en: '](img/B17447_03_07.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17447_03_07.jpg)'
- en: Figure 3.7 – Actions after tables are imported
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 – 表格导入后的操作
- en: Next, we should check the data types, or the schema of the tables, to make sure
    that they are being inferred correctly during the import process.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们应该检查数据类型，或表的模式，以确保在导入过程中正确推断。
- en: Editing the data type
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编辑数据类型
- en: The data type dictates how each data column is read by Data Wrangler and how
    it should be processed. There are **Long**, **Float**, **Boolean**, **String**,
    and **Date** types in Data Wrangler. **Long** holds data that is in integer form.
    **Float** allows floating points in the data. **Boolean** represents binary values
    such as *0/1* and *Yes/No*. **String** makes the data a text-based entry. **Date**
    holds data that is in the form of text (*dd-MM-yyyy*) but is interpreted as a
    date instead of a string and allows date-related operations and comparison.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 数据类型决定了数据整理器如何读取每个数据列以及如何处理它。数据整理器中有**Long**、**Float**、**Boolean**、**String**和**Date**类型。**Long**用于存储整数形式的数据。**Float**允许数据中有浮点数。**Boolean**表示二进制值，如*0/1*和*是/否*。**String**使数据成为基于文本的条目。**Date**以文本形式（*dd-MM-yyyy*）存储数据，但被解释为日期而不是字符串，并允许进行日期相关操作和比较。
- en: The types of transformation that can be applied to data depends on the data
    type. For example, you can only apply a numerical operation on columns of the
    `Long` and `Float` types. Therefore, it is important to get the data types correctly
    defined before proceeding even though Data Wrangler does infer data types while
    importing.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 可以应用于数据上的转换类型取决于数据类型。例如，你只能在`Long`和`Float`类型的列上应用数值运算。因此，在继续之前正确定义数据类型非常重要，即使数据整理器在导入时也会推断数据类型。
- en: 'So, let''s check and edit the data types of the imported tables in Data Wrangler:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们检查并编辑在数据整理器中导入的表的数据类型：
- en: From the view shown in *Figure 3.7*, click on the plus sign next to `telco_churn_account_info.csv`
    and select **Edit data types**.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从如图 *3.7* 所示的视图中，点击 `telco_churn_account_info.csv` 旁边的加号，并选择 **Edit data types**。
- en: As shown in *Figure 3.8*, `Long` integer type. To change it, in **CONFIGURE
    TYPES** in the right panel, click on **Type** for the **Account Length** column,
    and select **Long**.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如 *图 3.8* 所示，`Long` 整数类型。要更改它，在右侧面板的 **CONFIGURE TYPES** 中，点击 **Account Length**
    列的 **Type**，然后选择 **Long**。
- en: '`String`. But they should be of the Boolean type to conserve memory. Change
    them to `Boolean` by selecting `Boolean` in **CONFIGURE TYPES**.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`String`。但它们应该是布尔类型以节省内存。通过在 **CONFIGURE TYPES** 中选择 `Boolean` 来将它们更改为 `Boolean`。'
- en: Click **Preview** to see how the data looks after the data type change. See
    *Figure 3.8*.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Preview** 以查看数据类型更改后的数据外观。见图 *3.8*。
- en: '![Figure 3.8 – Editing data types in Data Wrangler'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.8 – Editing data types in Data Wrangler]'
- en: '](img/B17447_03_08.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_08.jpg]'
- en: Figure 3.8 – Editing data types in Data Wrangler
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8 – 在 Data Wrangler 中编辑数据类型
- en: We can see that **Account Length** is now of the **Long** type with integer
    values intact and that **Int'l Plan** and **Vmail Plan** are **Boolean** with
    yes/no converted to true/false, as shown in the table. Data type conversion does
    not result in data loss or anything so we can proceed to apply the edit.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，**Account Length** 现在是 **Long** 类型，整数值保持不变，而 **Int'l Plan** 和 **Vmail
    Plan** 是 **Boolean** 类型，将是/否转换为 true/false，如表中所示。数据类型转换不会导致数据丢失或类似情况，因此我们可以继续应用编辑。
- en: Click `String` type to `Boolean` type. This is because the period, **.**, in
    the values would invalidate the conversion. You can try changing it and preview
    the change. You will see the whole column being erased. We will deal with this
    column with transformation later.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `String` 类型以将其更改为 `Boolean` 类型。这是因为值中的点 **.** 会使转换无效。你可以尝试更改它并预览更改。你会看到整个列被删除。我们将在稍后处理此列的转换。
- en: 'We''ve changed and confirmed the data type for the first table. We should do
    the same for the other two tables:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已更改并确认了第一个表的数据类型。我们应该对其他两个表做同样的事情：
- en: Click **Back to data flow** to return to the data flow.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Back to data flow** 返回数据流。
- en: Click on the plus sign next to `telco_churn_customer_info.csv` and select **Edit
    data types**.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `telco_churn_customer_info.csv` 旁边的加号，并选择 **Edit data types**。
- en: Change `Long` to `String`. Though this column has integer values, they should
    be treated as `locality` rather than numeric features.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `Long` 更改为 `String`。尽管此列包含整数值，但它们应被视为 `locality` 而不是数值特征。
- en: Click **Preview**, then **Apply**.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Preview**，然后 **Apply**。
- en: Click **Back to data flow** to return to the data flow.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Back to data flow** 返回数据流。
- en: Click on the plus sign next to the last table, `telco_churn_utility`, then select
    **Edit data types**.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击最后一个表 `telco_churn_utility` 旁边的加号，然后选择 **Edit data types**。
- en: Change `cust_serv_calls` from `Float` to `Long`.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `cust_serv_calls` 从 `Float` 更改为 `Long`。
- en: Click **Preview**, then **Apply**.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Preview**，然后 **Apply**。
- en: Click **Back to data flow** to return to the data flow.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Back to data flow** 返回数据流。
- en: We've verified and fixed the data type for the three tables. Now it is time
    to join them together as one table.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已验证并修复了三个表的数据类型。现在是时候将它们合并为一个表了。
- en: Joining tables
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接表
- en: 'Joining tables is one of the most common steps when you are working with multiple
    data sources and the most important step to enrich your features when you are
    building an ML model. Think on relational database terms. Your tables maintain
    some sort of relationship that allows you to put them all together to get a big
    picture. We will be joining the three tables by `customerID` column with Data
    Wrangler. Please follow the next steps:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 连接表是在处理多个数据源时最常见的一步，也是你在构建机器学习模型时丰富特征最重要的步骤。从关系数据库的角度思考。你的表保持某种关系，这允许你将它们全部放在一起以获得整体视图。我们将通过
    `customerID` 列使用 Data Wrangler 将三个表连接起来。请按照以下步骤操作：
- en: Click on the plus sign next to `telco_churn_account_info.csv` and select **Join**.
    You should see the view shown in *Figure 3.9*.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `telco_churn_account_info.csv` 旁边的加号，并选择 **Join**。你应该能看到如图 *3.9* 所示的视图。
- en: '![Figure 3.9 – Joining tables in SageMaker Data Wrangler'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.9 – Joining tables in SageMaker Data Wrangler]'
- en: '](img/B17447_03_09.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_09.jpg]'
- en: Figure 3.9 – Joining tables in SageMaker Data Wrangler
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9 – 在 SageMaker Data Wrangler 中连接表
- en: '`telco_churn_account_info.csv` is chosen as `telco_churn_customer_info.csv`
    as **Right**. You should see the linkage between the two tables, as shown in *Figure
    3.10*.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`telco_churn_account_info.csv` 被选为 `telco_churn_customer_info.csv` 的 **Right**。你应该能看到两个表之间的链接，如图
    *3.10* 所示。'
- en: '![Figure 3.10 – Joining tables'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.10 – Joining tables]'
- en: '](img/B17447_03_10.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_10.jpg]'
- en: Figure 3.10 – Joining tables
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 3.10 – 连接表
- en: Click **Configure** to continue.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**配置**以继续。
- en: As shown in *Figure 3.11*, select `join` type as we expect to get all the data
    in, then select **CustomerID** for both **Left** and **Right** as the key to join.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如*图3.11*所示，选择**连接**类型，因为我们希望获取所有数据，然后选择**左侧**和**右侧**的**CustomerID**作为连接的键。
- en: '![Figure 3.11 – Joining tables with Full outer and select keys'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.11 – 使用全外连接和选择键连接表'
- en: '](img/B17447_03_11.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_11.jpg]'
- en: Figure 3.11 – Joining tables with Full outer and select keys
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 3.11 – 使用全外连接和选择键连接表
- en: Click `CustomerID_0` and `CustomerID_1`. We will deal with this later in the
    *Applying transformation* section.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`CustomerID_0`和`CustomerID_1`。我们将在*应用转换*部分稍后处理这个问题。
- en: Click **Add** in the top right to complete the join.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在右上角点击**添加**以完成连接。
- en: Now we need to join the last table. Click on the plus sign next to the joined
    table and select **Join**.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要连接最后一个表。点击连接表旁边的加号，并选择**连接**。
- en: Select `telco_churn_utility` as **Right**, then click **Configure**.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**右侧**的`telco_churn_utility`，然后点击**配置**。
- en: Again, select `CustomerID_0` for `customer_id` for **Right** to join.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，为**右侧**的`customer_id`选择`CustomerID_0`以进行连接。
- en: Click **Apply** to preview the joined dataset. Yes, the tables are joined, but
    with the keys duplicated, which can be addressed later in the *Applying transformation*
    section. No worries.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**应用**以预览合并后的数据集。是的，表已经合并，但键被重复了，这可以在*应用转换*部分稍后解决。不用担心。
- en: Click **Add** in the top right to complete the join. You will be brought back
    to the data flow. You should see the flow, as shown in *Figure 3.12*.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在右上角点击**添加**以完成连接。您将被带回到数据流。您应该看到如图*图3.12*所示的数据流。
- en: '![Figure 3.12 – Data flow after joining three tables'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.12 – 连接三个表后的数据流'
- en: '](img/B17447_03_12.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_12.jpg]'
- en: Figure 3.12 – Data flow after joining three tables
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 3.12 – 连接三个表后的数据流
- en: Note
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you find anything that was done wrong, don't worry, just click on the plus
    sign on the node that has the mistake and select **Delete** to remove the node.
    But do keep in mind that if you delete a node that is not the last node, all the
    downstream nodes will be deleted too.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您发现有任何错误，请不要担心，只需点击有错误的节点旁边的加号，并选择**删除**以删除该节点。但请记住，如果您删除的不是最后一个节点，所有下游节点也将被删除。
- en: 'We are ready to move on to the next phase: getting to explore the dataset!'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好进入下一阶段：探索数据集！
- en: Exploring data with visualization
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用可视化探索数据
- en: '**Exploratory data analysis** (**EDA**) provides insights into the data at
    hand and helps us strategize the data transformation so that ML modeling can be
    the most performant. Analyzing and visualizing data with programming is robust
    and scalable but it requires lots of coding and development. Using SageMaker Data
    Wrangler, you can easily create charts and figures in the UI. Currently, SageMaker
    Data Wrangler supports the following types of chart and analysis that do not require
    coding: **histogram**, **scatter plot**, **bias report**, **multicollinearity**,
    **quick model**, **target leakage**, and **table summary**. Let''s take a look
    at how they work one by one.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索性数据分析**（**EDA**）为我们手头的数据提供洞察力，并帮助我们制定数据转换策略，以便机器学习建模可以表现得最好。使用编程分析并可视化数据是强大且可扩展的，但它需要大量的编码和开发。使用SageMaker
    Data Wrangler，您可以在UI中轻松创建图表和图形。目前，SageMaker Data Wrangler支持以下类型的图表和分析，无需编码：**直方图**、**散点图**、**偏差报告**、**多重共线性**、**快速模型**、**目标泄露**和**表格摘要**。让我们逐一看看它们是如何工作的。'
- en: Understanding the frequency distribution with a histogram
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用直方图理解频率分布
- en: 'The histogram helps us understand the frequency distribution of a variable
    whose values are bucketed into discrete intervals with a bar graph. We can use
    the histogram function in SageMaker Data Wrangler to see, for example, how long
    callers spend making calls in the daytime. To do this, please follow these steps:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图帮助我们理解一个变量的频率分布，该变量的值被分桶到离散的区间，并用条形图表示。我们可以使用SageMaker Data Wrangler中的直方图功能来查看，例如，白天通话者通话多长时间。为此，请按照以下步骤操作：
- en: Click the plus sign next to the **2nd Join** node and select **Add analysis**.
    You should see the view shown in *Figure 3.13*.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**2nd Join**节点旁边的加号，并选择**添加分析**。您应该看到如图*图3.13*所示的视图。
- en: '![Figure 3.13 – Adding an analysis in SageMaker Data Wrangler'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.13 – 在SageMaker Data Wrangler中添加分析'
- en: '](img/B17447_03_13.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_13.jpg]'
- en: Figure 3.13 – Adding an analysis in SageMaker Data Wrangler
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 3.13 – 在SageMaker Data Wrangler中添加分析
- en: Fill in a name for the analysis in `day_mins_histogram`.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`day_mins_histogram`中填写分析的名称。
- en: Choose **day_mins** for **X axis**.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**X轴**为**day_mins**。
- en: Click **Preview** to see the chart, as shown in *Figure 3.14*.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**预览**以查看图表，如图*图3.14*所示。
- en: '![Figure 3.14 – Histogram of minutes of call time in the daytime'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.14 – 白天通话时间的分钟数直方图'
- en: '](img/B17447_03_14.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_14.jpg](img/B17447_03_14.jpg)'
- en: Figure 3.14 – Histogram of minutes of call time in the daytime
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 – 白天通话时间的分钟数直方图
- en: 'This is great! You created your first visualization in SageMaker Data Wrangler
    to see the frequency distribution of call time in the daytime among all customers.
    We see that most customers'' calls are shorter than 8 minutes and few calls are
    longer than 12 minutes. But this is an overall view. As a data scientist, you
    might want to know how customers who left the service behave differently from
    the customers who continue to use the service. We should slice and dice the data
    based on the target status: **Churn?**. We can do it through the **Facet by**
    option. We will proceed to modify the chart and not save the current chart.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这太棒了！你在SageMaker Data Wrangler中创建了第一个可视化，以查看所有客户白天通话时间的频率分布。我们看到大多数客户的通话时间短于8分钟，很少有通话时间超过12分钟。但这只是一个总体视图。作为一名数据科学家，你可能想知道离开服务的客户与继续使用服务的客户的行为有何不同。我们应该根据目标状态：**Churn?**来切片和切块数据。我们可以通过**按**选项来完成。我们将继续修改图表，而不是保存当前的图表。
- en: Choose **Churn?** for **Facet by** and click **Preview**. You should see an
    updated chart, as in *Figure 3.15*.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**按**和点击**预览**。你应该看到更新后的图表，如图*图3.15*所示。
- en: '![Figure 3.15 – Histogram of the day_mins variable by target'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.15 – 按目标变量day_mins的直方图'
- en: '](img/B17447_03_15.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_15.jpg](img/B17447_03_15.jpg)'
- en: Figure 3.15 – Histogram of the day_mins variable by target
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 – 按目标变量day_mins的直方图
- en: We can conclude that customers who left the service (the **True.** chart) most
    frequently make calls for around 6-10 minutes while the customers who stayed with
    the service (the **False.** chart) talk less on calls. What an interesting observation.
    Let's save the analysis.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出结论，离开服务的客户（**True**图表）最频繁的通话时间约为6-10分钟，而继续使用服务的客户（**False**图表）通话时间较短。多么有趣的观察。让我们保存这个分析。
- en: Click **Save** to save and return to the page where all analyses are saved.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**保存**以保存并返回保存所有分析的页面。
- en: In the **All Analyses** view, you can see charts and analyses you created for
    each node at any given state. We have created a histogram. Let's go on to create
    another chart.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在**所有分析**视图中，你可以看到在任何给定状态下为每个节点创建的图表和分析。我们已经创建了一个直方图。让我们继续创建另一个图表。
- en: Scatter plots
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 散点图
- en: 'A data scientist might be wondering if customers who call more in the daytime
    also call often in the evening. Or you might be curious if any correlation exists
    between the customer''s account length and call time. You can use a **scatter
    plot** to visualize this characteristic. Let''s create a scatter plot for the
    data:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家可能会想知道白天通话较多的客户是否在晚上也经常通话。或者你可能好奇客户的账户长度和通话时间之间是否存在任何相关性。你可以使用**散点图**来可视化这个特征。让我们为数据创建一个散点图：
- en: On the **Analysis** page, click **Create new analysis** at the top right.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**分析**页面，点击右上角的**创建新分析**。
- en: Choose `AccountLength_CallTime_Scatter`.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`AccountLength_CallTime_Scatter`。
- en: Choose **Account Length** for **X axis** and **day_mins** for **Y axis**.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**X轴**为**账户长度**和**Y轴**为**day_mins**。
- en: Click **Preview**. You should see a chart, as shown in *Figure 3.16*.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**预览**。你应该看到一个图表，如图*图3.16*所示。
- en: '![Figure 3.16 – Scatter plot of Account Length versus day_mins'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.16 – 账户长度与day_mins的散点图'
- en: '](img/B17447_03_16.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_16.jpg](img/B17447_03_16.jpg)'
- en: Figure 3.16 – Scatter plot of Account Length versus day_mins
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16 – 账户长度与day_mins的散点图
- en: There does not seem to be any correlation visually between the two variables.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 从视觉上看，这两个变量之间似乎没有相关性。
- en: Histograms and scatter plots are the two most common tools for EDA that you
    probably are familiar with. With SageMaker Data Wrangler, you can use ML-oriented
    analyses such as Quick Model to help you determine your data transformation strategy.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图和散点图是EDA中最常用的两种工具，你可能很熟悉。使用SageMaker Data Wrangler，你可以使用面向ML的分析，如Quick Model，帮助你确定数据转换策略。
- en: Previewing ML model performance with Quick Model
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Quick Model预览ML模型性能
- en: 'Quick Model is another tool that helps you quickly get a sense of whether your
    data provides any predictive power with the variables presented in the data. This
    tool is useful and can be used frequently. Let''s see how it works:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 快速模型是另一个帮助你快速了解数据是否提供了任何预测能力的工具。这个工具很有用，可以经常使用。让我们看看它是如何工作的：
- en: On the **Analysis** page, click **Create new analysis** in the top right.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**分析**页面上，点击右上角的**创建新分析**。
- en: Choose **Quick Model** for **Analysis type**.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**快速模型**作为**分析类型**。
- en: Add a name in `first_quickmodel`.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`first_quickmodel`中添加一个名称。
- en: Choose **Churn?** for **Label** and click **Preview**.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**流失？**作为**标签**并点击**预览**。
- en: '![Figure 3.17 – Quick Model result that shows the F1 score of the model performance
    on a test set and feature importance'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.17 – 快速模型结果，显示了测试集上模型性能的F1分数和特征重要性'
- en: '](img/B17447_03_17.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_03_17.jpg)'
- en: Figure 3.17 – Quick Model result that shows the F1 score of the model performance
    on a test set and feature importance
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17 – 快速模型结果，显示了测试集上模型性能的F1分数和特征重要性
- en: SageMaker Data Wrangler takes a minute or so and returns a bar chart, as shown
    in *Figure 3.17*, showing the feature importance and an F1 score on a randomly
    split test set from the given dataset. We have not applied any transformation
    or data cleaning, as you can see in the following data table. SageMaker Data Wrangler
    employs a popular algorithm called **random forest classification** to train a
    model and test it out on a hold-out test set. We can see a preliminary result
    of a 0.851 F1 score, with **night_charge** being the most important feature in
    predicting customer churn status. We can also see that there are features that
    do not provide much predictive power, such as **Int'l Plan** and **VMail Plan**.
    And there are redundant features such as **CustomerID_*** that should not have
    been included in the modeling. This gives us hints to make sure to include **night_charge**
    and other high-importance features in the actual modeling and that we can leave
    out **Int'l Plan** and **VMail Plan** if we are restricted by the number of features
    we can use. Let's ink the analysis on the paper.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Data Wrangler需要一分钟左右的时间，并返回一个条形图，如图*图3.17*所示，显示了特征重要性和从给定数据集中随机分割的测试集上的F1分数。正如您在以下数据表中看到的那样，我们没有应用任何转换或数据清理。SageMaker
    Data Wrangler使用一个流行的算法**随机森林分类**来训练模型并在一个保留的测试集上测试它。我们可以看到一个初步的0.851 F1分数，其中**night_charge**是预测客户流失状态的最重要特征。我们还可以看到有一些特征没有提供太多的预测能力，例如**国际套餐**和**VMail套餐**。还有一些冗余的特征，如**CustomerID_***，这些特征不应该包含在建模中。这给我们提供了提示，确保在真正的建模中包括**night_charge**和其他高重要性特征，如果我们受限于可以使用的特征数量，我们可以排除**国际套餐**和**VMail套餐**。让我们在纸上记录分析结果。
- en: Click **Save** to save the analysis.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**保存**以保存分析。
- en: As we just did our first quick modeling, to get a sense of the model performance
    we are getting, it is also a good idea to test whether we are running into any
    data leakage or target leakage problems.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们刚刚进行了第一次快速建模，为了了解我们得到的模型性能，测试我们是否遇到了任何数据泄漏或目标泄漏问题也是一个好主意。
- en: Revealing target leakage
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 揭示目标泄漏
- en: 'Target leakage means that there are features in the data that are highly correlated
    or basically a proxy representation of the target variable. For example, if our
    dataset contains a column that records the date of termination for each churned
    customer, then this column is going to contain those who churned, resulting in
    an extremely high modeling accuracy if we include it in the modeling. The problem
    in this example is that come prediction time in the real world, it is very unlikely
    to have the date of termination when the job of the model is to predict future
    churn. Let''s see if our dataset contains any target leakage:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 目标泄漏意味着数据中存在与目标变量高度相关或基本上是目标变量的代理表示的特征。例如，如果我们的数据集包含一个记录每个流失客户终止日期的列，那么这个列将包含流失的客户，如果我们将其包含在建模中，将导致建模精度极高。在这个例子中的问题是，在现实世界的预测时间，当模型的任务是预测未来的流失时，几乎不可能有终止日期。让我们看看我们的数据集中是否包含任何目标泄漏：
- en: On the **Analysis** page, click **Create new analysis** in the top right.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**分析**页面上，点击右上角的**创建新分析**。
- en: Choose **Target Leakage** for **Analysis type**.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**目标泄漏**作为**分析类型**。
- en: Add a name in `churn_target_leakage`.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`churn_target_leakage`中添加一个名称。
- en: Input `25` for **Max features** because we have 24 columns in the table.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为**最大特征数**输入`25`，因为我们有24列在表中。
- en: Choose **classification** for **Problem Type**.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**分类**作为**问题类型**。
- en: Choose **Churn?** for **Target** and click **Preview**.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 **Churn?** 作为 **Target** 并点击 **Preview**。
- en: '![Figure 3.18 – Target leakage result showing features that are safe and that
    are possibly redundant (color-coded with a legend to the right of the chart)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.18 – 显示安全特征和可能冗余特征的**目标泄漏结果**（图表右侧带有图例着色）'
- en: '](img/B17447_03_18.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17447_03_18.jpg)'
- en: Figure 3.18 – Target leakage result showing features that are safe and that
    are possibly redundant (color-coded with a legend to the right of the chart)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18 – 显示安全特征和可能冗余特征的**目标泄漏结果**（图表右侧带有图例着色）
- en: 'The target leakage analysis computes the cross-validated area under the ROC
    for each individual feature against the target, as explained in the text above
    the chart in *Figure 3.18*. This analysis shows that no feature is determined
    as potential target leakage, which is a good sign. The result also confirms the
    conclusions we learned from the quick modeling exercise:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 目标泄漏分析计算每个特征相对于目标的交叉验证 ROC 曲线下面积，如 *图3.18* 上方的文本所述。此分析表明没有特征被确定为潜在的目标泄漏，这是一个好兆头。结果还证实了我们从快速建模练习中学到的结论：
- en: a) `night_charge` is important in predicting churn and provides a high level
    of predictive ability.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: a) `night_charge` 在预测流失方面很重要，并提供高水平的预测能力。
- en: b) `VMail Plan` is providing little predictive ability.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: b) `VMail Plan` 提供的预测能力很小。
- en: c) `CustomerID_*` is redundant in the dataset.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: c) `CustomerID_*` 在数据集中是多余的。
- en: Let's save the analysis.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们保存分析。
- en: Click **Save** to save the analysis.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Save** 保存分析。
- en: We learned about feature predictive power through the last two analyses. We
    should also take a look at how we can create a custom visualization with SageMaker
    Data Wrangler.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过最后两个分析了解了特征预测能力。我们还应该看看如何使用 SageMaker Data Wrangler 创建自定义可视化。
- en: Creating custom visualizations
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建自定义可视化
- en: 'SageMaker Data Wrangler uses **Altair** ([https://altair-viz.github.io/](https://altair-viz.github.io/))
    to create visualizations programmatically. We can create any custom visualization
    with code in SageMaker Data Wrangler as well for greater flexibility. For example,
    we can create a boxplot for **night_charge** by **Churn?** status to understand
    the statistical distribution of the two groups:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Data Wrangler 使用 **Altair** ([https://altair-viz.github.io/](https://altair-viz.github.io/))
    以编程方式创建可视化。我们还可以在 SageMaker Data Wrangler 中使用代码创建任何自定义可视化，以获得更大的灵活性。例如，我们可以通过
    `Churn?` 状态创建 `night_charge` 的箱线图，以了解两组的统计分布：
- en: On the **All Analyses** page, click **Create new analysis** in the top right.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **All Analyses** 页面上，点击右上角的 **Create new analysis**。
- en: Click the **Code** tab right next to **Configure**.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击紧挨着 **Configure** 的 **Code** 选项卡。
- en: Add a name, such as `boxplot_night_charge_by_churn`.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个名称，例如 `boxplot_night_charge_by_churn`。
- en: 'Input the following code in the coding area. Be sure to import the `altair`
    library:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在编码区域输入以下代码。请确保导入 `altair` 库：
- en: '[PRE1]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Click **Preview**.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Preview**。
- en: You should see a box plot representing the distribution of `Churn?` status,
    as shown in *Figure 3.19*. If you hover over the box plot, you can see the descriptive
    statistics of the data.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到一个表示 `Churn?` 状态分布的箱线图，如图 *图3.19* 所示。如果你悬停在箱线图上，你可以看到数据的描述性统计。
- en: '![Figure 3.19 – Creating a custom boxplot using the Altair library'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.19 – 使用 Altair 库创建自定义箱线图'
- en: '](img/B17447_03_19.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17447_03_19.jpg)'
- en: Figure 3.19 – Creating a custom boxplot using the Altair library
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19 – 使用 Altair 库创建自定义箱线图
- en: Click **Save** to save the custom visualization.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Save** 保存自定义可视化。
- en: What's worth noting is that these analyses and visualizations are saved as part
    of the flow file so that you can have full visibility of how you wrangle the data.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，这些分析和可视化作为流程文件的一部分保存，这样你可以全面了解你如何处理数据。
- en: With these analyses, we now have a good understanding of how we should transform
    and wrangle the data.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些分析，我们现在对如何转换和处理数据有了很好的理解。
- en: Applying transformation
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用转换
- en: 'You can easily apply data transformation using SageMaker Data Wrangler because
    there are numerous built-in transformations you can use out of the box without
    any coding. So far, we have observed the following from the analyses that we need
    to handle next in order to build up an ML dataset:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以轻松地使用 SageMaker Data Wrangler 应用数据转换，因为有许多内置的转换可以直接使用，无需任何编码。到目前为止，我们已经从需要处理以构建
    ML 数据集的分析中观察到以下内容：
- en: Missing data in some features.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些特征存在缺失数据。
- en: The `Churn?` column is now in string format with `True.` and `False.` as values.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Churn?` 列现在以字符串格式存储，值为 `True.` 和 `False.`。'
- en: Redundant `CustomerID_*` columns after joins.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接后冗余的`CustomerID_*`列。
- en: Features that are not providing predictive power, including but not limited
    to `Phone`, `VMail Plan`, and `Int'l Plan`.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不提供预测能力的特征，包括但不限于`Phone`、`VMail Plan`和`Int'l Plan`。
- en: We also would like to perform the following transformations for ML purposes
    because we want to train an XGBoost model to predict the `Churn?` status afterwards.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望为了机器学习目的执行以下转换，因为我们想训练一个XGBoost模型来预测随后的`Churn?`状态。
- en: Encoding categorical variables, that is, `State` and `Area Code` features.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对分类变量进行编码，即`State`和`Area Code`特征。
- en: 'Let''s get started:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧：
- en: In the **Data Flow** tab, click on the plus sign next to the **2nd Join** node,
    and select **Add transform**. You should see the view shown in *Figure 3.20,*
    with a table on the left and a list of transformations on the right.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**数据流**选项卡中，点击**2nd Join**节点旁边的加号，选择**添加转换**。您应该看到如图*图 3.20*所示的视图，左侧有一个表格，右侧有一系列转换列表。
- en: '![Figure 3.20 – A workspace to transform your data. You can expand each transform
    on the right side to see options'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.20 – 一个转换数据的工作空间。您可以在右侧展开每个转换以查看选项'
- en: '](img/B17447_03_20.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17447_03_20.jpg]'
- en: Figure 3.20 – A workspace to transform your data. You can expand each transform
    on the right side to see options
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.20 – 一个转换数据的工作空间。您可以在右侧展开每个转换以查看选项'
- en: To drop **CustomerID_***, click **Manage columns** to expand the transform,
    select **Drop column** in **Transform**, and select **CustomerID_0** for **Column
    to drop**.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要删除**CustomerID_***，点击**管理列**以展开转换，在**转换**中选择**删除列**，并选择**CustomerID_0**作为**要删除的列**。
- en: Click `CustomerID_0` is now gone, as shown in *Figure 3.21*.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如*图 3.21*所示，现在`CustomerID_0`已消失。
- en: '![Figure 3.21 – Dropping columns in SageMaker Data Wrangler'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.21 – 在SageMaker Data Wrangler中删除列'
- en: '](img/B17447_03_21.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17447_03_21.jpg]'
- en: Figure 3.21 – Dropping columns in SageMaker Data Wrangler
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.21 – 在SageMaker Data Wrangler中删除列]'
- en: Click **Add** to put the transformation into effect.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**添加**以使转换生效。
- en: Repeat steps 2–4 to drop `CustomerID_1` and `customer_id`.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤2-4以删除`CustomerID_1`和`customer_id`。
- en: If done correctly, you should see four steps applied on the **Previous steps**
    tab to the right, as shown in *Figure 3.22*.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果操作正确，您应该在右侧的**上一步**选项卡上看到四个步骤，如图*图 3.22*所示。
- en: '![Figure 3.22 – Reviewing previous steps in the Previous steps tab'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.22 – 在“上一步”选项卡中查看之前的步骤'
- en: '](img/B17447_03_22.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17447_03_22.jpg]'
- en: Figure 3.22 – Reviewing previous steps in the Previous steps tab
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.22 – 在“上一步”选项卡中查看之前的步骤'
- en: Note
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you realize you did anything incorrectly and want to revert to a previous
    transformation, you can **Remove** steps from the last one, one at a time, as
    shown in *Figure 3.22*.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您意识到您做了任何错误的事情并想恢复到之前的转换，您可以像*图 3.22*所示的那样，一次删除最后一步，直到恢复。
- en: Moving on to handling missing data in `cust_serv_calls`, expand `Account Length`
    for **Input column**, and **Approximate Median** for **Imputing strategy**. We
    can leave **Output column** empty to instruct SageMaker Data Wrangler to overwrite
    the existing column.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续处理`cust_serv_calls`中的缺失数据，展开**输入列**中的`Account Length`，以及**近似中位数**作为**插补策略**。我们可以留空**输出列**以指示SageMaker
    Data Wrangler覆盖现有列。
- en: Click `102,` as shown in *Figure 3.23*.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`102`，如图*图 3.23*所示。
- en: '![Figure 3.23 – Account Length is filled with the median value, 102'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.23 – 账户长度填充了中位数，102'
- en: '](img/B17447_03_23.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17447_03_23.jpg]'
- en: Figure 3.23 – Account Length is filled with the median value, 102
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.23 – 账户长度填充了中位数，102'
- en: Click **Add** to put the transformation into effect.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**添加**以使转换生效。
- en: Repeat steps 6–8 for `cust_serv_calls`.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对`cust_serv_calls`重复步骤6-8。
- en: There are features that do not provide much predictive capability based on the
    quick model and target leakage analyses worth dropping too. `Phone` is one of
    the features that is shown to contain little to no useful information. Also, as
    is common knowledge, we know phone numbers are mostly randomly assigned when you
    sign up for a service. On the other hand, even though `VMail Plan` and `Int'l
    Plan` provide no predictive information, they are of the simple `Boolean` type
    and do have real meaning. It might not hurt as much to carry these features into
    modeling. So, let's drop the `Phone` feature.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些特征根据快速模型和目标泄漏分析没有提供太多预测能力，值得删除。`Phone` 是那些显示包含很少或没有有用信息的特征之一。另外，众所周知，当你注册一项服务时，电话号码大多是随机分配的。另一方面，尽管
    `VMail Plan` 和 `Int'l Plan` 提供了没有预测信息，但它们是简单的 `布尔` 类型，确实有实际意义。将这些特征带入建模可能不会造成太大伤害。所以，让我们删除
    `Phone` 特征。
- en: Repeat steps 2–4 to drop `Phone`.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤 2–4 删除 `Phone`。
- en: Moving on to transforming categorical features, we have `State` and `Area Code`,
    which represent the location of a customer. We could apply one-hot encoding to
    transform them. However, we may risk the `Area Code`, the next best action would
    be to drop it. Let's perform one-hot encoding to `State` and drop `Area Code`.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 继续转换分类特征，我们有 `State` 和 `Area Code`，它们代表客户的地理位置。我们可以应用独热编码来转换它们。然而，我们可能会冒险删除
    `Area Code`，下一个最好的行动是删除它。让我们对 `State` 进行独热编码并删除 `Area Code`。
- en: Expand **Encode categorical**, choose **One-hot encode** for **Transform**,
    select **State** for **Input column**, select **Columns** for **Output style**,
    and leave other options as their defaults.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 展开 **编码分类**，选择 **独热编码** 作为 **转换**，选择 **状态** 作为 **输入列**，选择 **列** 作为 **输出样式**，并保留其他选项为默认值。
- en: Click `State` column is replaced with `State_*` sparse features, with each representing
    whether customers are of a particular state (0 for false and 1 for true).
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `状态` 列被替换为 `State_*` 稀疏特征，每个特征代表客户是否处于特定状态（0 为假，1 为真）。
- en: Click **Add** to put the transformation into effect.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **添加** 使转换生效。
- en: Repeat steps 2–4 to drop `Area Code`.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤 2–4 删除 `Area Code`。
- en: Last but not least, the target feature, `Churn?,` needs some wrangling. It has
    a weird period that messed up the data type conversion previously. Furthermore,
    the SageMaker built-in XGBoost algorithm we are going to use for modeling later
    requires the target feature to be in the first column. Let's apply a text operation
    and move the column.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，目标特征 `Churn?` 需要进行一些处理。它有一个奇怪的句号，这之前破坏了数据类型转换。此外，我们将要使用的 SageMaker
    内置 XGBoost 算法要求目标特征位于第一列。让我们应用一个文本操作并移动该列。
- en: Expand `Churn?` for `.` (a period) for **Symbols**.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 展开 `Churn?` 为 `.`（一个句号）作为 **符号**。
- en: Click `Churn?` has been removed, as shown in *Figure 3.24*. Click **Add** to
    put the transformation into effect.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `Churn?` 已被移除，如 *图 3.24* 所示。点击 **添加** 使转换生效。
- en: '![Figure 3.24 – Ending period removed in the Churn? column'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.24 – Churn? 列中移除了结束句号'
- en: '](img/B17447_03_24.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17447_03_24.jpg]'
- en: Figure 3.24 – Ending period removed in the Churn? column
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.24 – Churn? 列中移除了结束句号
- en: We can now use the data type parser to convert the True/False into a Boolean
    representation. Expand **Parse column as type**, choose **Churn?** for **Column**,
    and select **Boolean** in the **To** drop-down menu.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用数据类型解析器将 True/False 转换为布尔表示。展开 **解析列类型**，选择 **Churn?** 作为 **列**，并在 **到**
    下拉菜单中选择 **布尔**。
- en: Click `Boolean` type. Click **Add** to put the transformation into effect.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `布尔` 类型。点击 **添加** 使转换生效。
- en: To move **Churn?** to the front, expand **Manage columns**, select **Move column**
    for **Transform**, select **Move to start** for **Move type**, and choose **Churn?**
    for **Column to move**.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将 **Churn?** 移到前面，展开 **管理列**，选择 **移动列** 作为 **转换**，选择 **移动到开始** 作为 **移动类型**，并选择
    **Churn?** 作为 **要移动的列**。
- en: Click **Preview** to see the transformation. Now the **Churn?** column becomes
    the first feature. Click **Add** to put the transformation into effect.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **预览** 以查看转换。现在 **Churn?** 列成为第一个特征。点击 **添加** 使转换生效。
- en: We've just applied eleven transformations to the dataset. We can run a quick
    modeling analysis to make sure we are on the right track in terms of modeling.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚对数据集应用了十一个转换。我们可以运行一个快速建模分析，以确保我们在建模方面处于正确的轨道。
- en: Exploring performance while wrangling
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在处理数据时探索性能
- en: 'You can always add an analysis at any point in time while wrangling the data
    in SageMaker Data Wrangler. This allows you to analyze the data after key transformation
    and verify the predictive power with Quick Model. Let''s add an analysis for the
    wrangled data:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用SageMaker Data Wrangler整理数据时，您可以在任何时间点添加分析。这允许您在关键转换后分析数据，并使用Quick Model验证预测能力。让我们为整理后的数据添加一个分析：
- en: Click the **Analysis** tab.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**分析**选项卡。
- en: Choose **Quick Model** for **Analysis type**, add a name in **Analysis name**,
    and select **Churn?** for **Label**.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**快速模型**作为**分析类型**，在**分析名称**中添加一个名称，并选择**流失？**作为**标签**。
- en: Click **Preview** to see the modeling result, as shown in *Figure 3.25*. The
    model's F1 score has improved from *0.851* to *0.871*. We are on the right track.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**预览**以查看建模结果，如图*图3.25*所示。模型的F1分数已从*0.851*提升到*0.871*。我们正走在正确的道路上。
- en: '![Figure 3.25 – Quick modeling after all transformations'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.25 – 所有转换后的快速建模'
- en: '](img/B17447_03_25.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_03_25.jpg]'
- en: Figure 3.25 – Quick modeling after all transformations
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.25 – 所有转换后的快速建模
- en: Click **Add** to put the analysis on the canvas.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**添加**将分析放置在画布上。
- en: So far, we have used SageMaker Data Wrangler to analyze the telco churn dataset
    in depth and wrangled the data according to the findings from the analyses. Quick
    Model is showing an improved F1 score in predicting customer churn. We should
    move on to see what options we have with this work.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经使用SageMaker Data Wrangler深入分析了电信客户流失数据集，并根据分析结果整理了数据。Quick Model在预测客户流失方面显示出改进的F1分数。我们应该继续看看这项工作中我们有哪些选择。
- en: Exporting data for ML training
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导出数据用于机器学习训练
- en: 'SageMaker Data Wrangler supports the following export options: **Save to S3**,
    **Pipeline**, **Python Code**, and **Feature Store**. The data transformations
    we have applied so far are not really applied to the data yet. The transformation
    steps need to be executed to get the final transformed data. When we export our
    flow file with the preceding options, SageMaker Data Wrangler automatically generates
    code and notebooks to guide you through the execution process so that we do not
    have to write any code, but it leaves flexibility for us to customize the code.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Data Wrangler支持以下导出选项：**保存到S3**、**管道**、**Python代码**和**特征存储**。我们迄今为止应用的数据转换尚未真正应用于数据。需要执行转换步骤以获取最终转换后的数据。当我们使用前面的选项导出我们的流程文件时，SageMaker
    Data Wrangler会自动生成代码和笔记本，以指导您完成执行过程，这样我们就不必编写任何代码，但它为我们留下了自定义代码的灵活性。
- en: The four export options satisfy many use cases. **Save to S3** is an obvious
    one and offers lots of flexibility. If you would like to get the transformed data
    in an S3 bucket so that you can train an ML model in Amazon SageMaker, you can
    also download it locally from S3 and import it to other tools if you need to.
    The **Pipeline** option creates a SageMaker pipeline that can easily be called
    a repeatable workflow. Such workflows can be configured as event-triggered or
    time-triggered so that you can automate the data transformation as a pipeline.
    We will learn more about SageMaker Pipelines in [*Chapter 10*](B17447_10_ePub_RK.xhtml#_idTextAnchor134),
    *Monitoring ML Models in Production with SageMaker Model Monitor*. **Python Code**
    offers the most visibility and flexibility. You can see how each transformation
    is implemented by Amazon SageMaker, run the code in a Spark environment, and get
    the data processed. With the **Feature Store** option, you get an automatically
    generated Jupyter notebook that will process the data and create a feature group
    in SageMaker Feature Store. We will learn more about SageMaker Feature Store in
    [*Chapter 5*](B17447_05_ePub_RK.xhtml#_idTextAnchor077), *Building and Training
    ML Models with SageMaker Studio IDE*.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 四种导出选项满足了许多用例。**保存到S3**是一个明显的选项，并且提供了很多灵活性。如果您希望将转换后的数据保存在S3桶中以便在Amazon SageMaker中训练机器学习模型，您也可以从S3本地下载它，并在需要时将其导入到其他工具中。**管道**选项创建了一个可以轻松重复调用的SageMaker管道。此类工作流程可以配置为事件触发或时间触发，以便您可以自动化数据转换作为管道。我们将在[*第10章*](B17447_10_ePub_RK.xhtml#_idTextAnchor134)中了解更多关于SageMaker管道的内容，*使用SageMaker
    Model Monitor监控生产中的机器学习模型*。**Python代码**提供了最大的可见性和灵活性。您可以看到Amazon SageMaker如何实现每个转换，在Spark环境中运行代码，并获取处理后的数据。使用**特征存储**选项，您将获得一个自动生成的Jupyter笔记本，该笔记本将处理数据并在SageMaker
    Feature Store中创建一个特征组。我们将在[*第5章*](B17447_05_ePub_RK.xhtml#_idTextAnchor077)中了解更多关于SageMaker
    Feature Store的内容，*使用SageMaker Studio IDE构建和训练机器学习模型*。
- en: 'For this example, I''d like to show you the option **Save to S3**, which includes
    ML training in the automatically generated notebook:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我想向您展示 **保存到 S3** 的选项，它包括在自动生成的笔记本中的机器学习训练：
- en: First, save the flow file so that the exported resource will pick up the latest
    change. In the menu bar, select **File**->**Save Data Wrangler Flow**.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，保存流文件，以便导出的资源可以获取最新的更改。在菜单栏中，选择 **文件**->**保存数据 Wrangler 流**。
- en: Click on the **Export** tab, click the **Steps** node, and select the last step,
    **Move column**, in the list of transformations. By clicking a step, all the steps
    leading to the step chosen will be selected.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **导出** 选项卡，点击 **步骤** 节点，并在转换列表中选择最后一个步骤，**移动列**。通过点击一个步骤，将选择到所选步骤的所有步骤。
- en: Click **Export step** in the top right, and click **Save to S3**.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在右上角点击 **导出步骤**，然后点击 **保存到 S3**。
- en: A new Python Jupyter notebook should pop out. This notebook contains code to
    process the SageMaker Data Wrangler flow file using SageMaker Processing and to
    save the processed data in S3\. This is our first encounter with SageMaker Processing
    in action. In short, it allows us to use appropriate compute resources to perform
    data processing, model evaluation, and statistical analysis. With SageMaker Processing,
    you are no longer bound by the compute resource available locally in the Studio
    notebook environment; instead, the processing script and Data Wrangler flow file
    can be run on a right-size compute instance(s). You can see things in action in
    the following steps.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 应该会弹出一个新的 Python Jupyter 笔记本。这个笔记本包含使用 SageMaker Processing 处理 SageMaker Data
    Wrangler 流文件并保存处理后的数据到 S3 的代码。这是我们第一次遇到 SageMaker Processing 的实际应用。简而言之，它允许我们使用适当的计算资源来执行数据处理、模型评估和统计分析。使用
    SageMaker Processing，您不再受 Studio 笔记本环境中本地可用的计算资源限制；相反，处理脚本和 Data Wrangler 流文件可以在适当大小的计算实例（s）上运行。您可以在以下步骤中看到实际操作。
- en: Please execute all the cells before **(Optional) Next Steps** section.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **（可选）下一步** 部分之前，请执行所有单元格。
- en: Note
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: You may configure the notebook in the section where you see 💡 **Configurable
    Settings**.
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以在看到 💡 **可配置设置** 的部分配置笔记本。
- en: 'The SageMaker Processing job may take a couple of minutes. At the end of the
    processing job, the processed data is available in an S3 bucket. You should see
    the following output from the cell:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 处理作业可能需要几分钟。在处理作业结束时，处理后的数据将可用在 S3 桶中。您应该从单元格中看到以下输出：
- en: '[PRE2]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The following optional sections are the interesting modeling part. Let's run
    these steps to train an ML model to predict churn using SageMaker's built-in XGBoost
    algorithm.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 以下可选部分是有趣的建模部分。让我们运行这些步骤来训练一个使用 SageMaker 内置的 XGBoost 算法预测客户流失的机器学习模型。
- en: 'Reassign the value of `run_optional_steps` to `True`:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `run_optional_steps` 的值重新分配为 `True`：
- en: '[PRE3]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The default objective metric, `reg:squarederror`, for XGBoost is for regression
    use cases. Change it to `binary:logistic` because we have a binary classification
    use case:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: XGBoost 的默认目标指标 `reg:squarederror` 用于回归用例。由于我们有一个二分类用例，请将其更改为 `binary:logistic`：
- en: '[PRE4]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Execute all the remaining cells in the notebook to start a training job.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行笔记本中所有剩余的单元格以启动训练作业。
- en: 'The training job will take a minute or two to finish. You can see the actions
    behind the scenes printed out as output in the last cell. We will learn more about
    SageMaker training and training algorithms in [*Chapter 5*](B17447_05_ePub_RK.xhtml#_idTextAnchor077)*,
    Building and Training ML Models with SageMaker Studio IDE*. Once finished, the
    model is saved in S3 as well, which can be used in hosting in Amazon SageMaker
    or the model can be used locally. We will learn more about hosting options in
    [*Chapter 7*](B17447_07_ePub_RK.xhtml#_idTextAnchor099), *Hosting ML Models in
    the Cloud: Best Practices*'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 训练作业可能需要一分钟左右的时间来完成。您可以在最后一个单元格中看到幕后操作的动作输出。我们将在 [*第五章*](B17447_05_ePub_RK.xhtml#_idTextAnchor077)*，使用
    SageMaker Studio IDE 构建和训练机器学习模型* 中了解更多关于 SageMaker 训练和训练算法的内容。一旦完成，模型也会保存在 S3
    中，可用于在 Amazon SageMaker 中托管，或者模型也可以在本地使用。我们将在 [*第七章*](B17447_07_ePub_RK.xhtml#_idTextAnchor099)，*云中托管机器学习模型：最佳实践*
    中了解更多关于托管选项的内容。
- en: Summary
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we showed how to use SageMaker Data Wrangler using a telco
    customer churn dataset. We learned how to import data from various sources, join
    tables, analyze with advanced ML-based analyses, and create visualizations with
    SageMaker Data Wrangler. We then applied transformations easily with built-in
    transforms available out of the box from SageMaker Data Wrangler without any code.
    At the end of the chapter, we showed how to export the transformed data to an
    S3 bucket and how to easily train an ML model using the automatically generated
    notebook.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们展示了如何使用 SageMaker Data Wrangler 通过电信客户流失数据集进行操作。我们学习了如何从各种来源导入数据，合并表格，使用基于高级机器学习的分析进行数据分析，以及使用
    SageMaker Data Wrangler 创建可视化。然后，我们无需编写任何代码，就可以轻松地使用 SageMaker Data Wrangler 内置的转换功能进行转换。在章节的最后，我们展示了如何将转换后的数据导出到
    S3 桶，以及如何使用自动生成的笔记本轻松训练机器学习模型。
- en: In the next chapter, we will learn about the concept of a feature store in a
    machine learning project, and how to set up a feature store using **SageMaker
    Feature Store**. SageMaker Feature Store unifies the features across teams so
    that teams can remove redundant feature engineering pipelines. It also serves
    as a central repository for both model training and model serving use cases because
    of its unique design pattern to have an offline store for easy querying for selecting
    training datasets and an online store for low latency transactions required in
    the model serving environment.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习机器学习项目中特征存储的概念，以及如何使用 **SageMaker Feature Store** 来设置特征存储。SageMaker
    Feature Store 统一了团队之间的特征，以便团队可以移除冗余的特征工程管道。由于其独特的设计模式，它还充当模型训练和模型服务用例的中央存储库，因为它具有离线存储以方便查询选择训练数据集，以及在线存储以支持模型服务环境中所需的低延迟事务。
