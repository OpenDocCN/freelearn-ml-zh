- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Machine Learning Phases and Privacy Threats/Attacks in Each Phase
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ é˜¶æ®µå’Œæ¯ä¸ªé˜¶æ®µçš„éšç§å¨èƒ/æ”»å‡»æ¦‚è¿°
- en: 'In this chapter, we will provide a quick refresher on the different types of
    **machine learning** (**ML**): supervised, unsupervised, and reinforcement learning.
    We will also review the essential phases or pipelines of ML. You may already be
    familiar with these; if not, this chapter will serve as a foundational introduction.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†å¿«é€Ÿå›é¡¾ä¸åŒç±»å‹çš„**æœºå™¨å­¦ä¹ **ï¼ˆ**ML**ï¼‰ï¼šç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬è¿˜å°†å›é¡¾MLçš„åŸºæœ¬é˜¶æ®µæˆ–æµç¨‹ã€‚ä½ å¯èƒ½å·²ç»ç†Ÿæ‚‰è¿™äº›å†…å®¹ï¼›å¦‚æœä¸ç†Ÿæ‚‰ï¼Œæœ¬ç« å°†ä½œä¸ºä¸€ä¸ªåŸºç¡€æ€§çš„ä»‹ç»ã€‚
- en: Subsequently, we will delve into the crucial topic of privacy preservation within
    each phase of the ML process. Specifically, we will explore the importance of
    maintaining privacy in training data, input data, model storage, and inference/output
    data. Additionally, we will examine various privacy attacks that can occur in
    each phase, such as training data extraction attacks, model inversion attacks,
    and model inference attacks. Through detailed examples, we will gain an understanding
    of how these attacks function and discuss strategies to safeguard against them.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: éšåï¼Œæˆ‘ä»¬å°†æ·±å…¥ç ”ç©¶MLè¿‡ç¨‹ä¸­çš„æ¯ä¸ªé˜¶æ®µéšç§ä¿æŠ¤çš„å…³é”®ä¸»é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ¢è®¨åœ¨è®­ç»ƒæ•°æ®ã€è¾“å…¥æ•°æ®ã€æ¨¡å‹å­˜å‚¨å’Œæ¨ç†/è¾“å‡ºæ•°æ®ä¸­ä¿æŒéšç§çš„é‡è¦æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å°†æ£€æŸ¥æ¯ä¸ªé˜¶æ®µå¯èƒ½å‘ç”Ÿçš„å„ç§éšç§æ”»å‡»ï¼Œä¾‹å¦‚è®­ç»ƒæ•°æ®æå–æ”»å‡»ã€æ¨¡å‹åæ¼”æ”»å‡»å’Œæ¨¡å‹æ¨ç†æ”»å‡»ã€‚é€šè¿‡è¯¦ç»†çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†äº†è§£è¿™äº›æ”»å‡»æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œå¹¶è®¨è®ºé˜²èŒƒç­–ç•¥ã€‚
- en: 'We will cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ¶µç›–ä»¥ä¸‹ä¸»è¦ä¸»é¢˜ï¼š
- en: ML types
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ç±»å‹
- en: Overview of ML phases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLé˜¶æ®µæ¦‚è¿°
- en: Privacy threats/attacks in the ML phases
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ é˜¶æ®µä¸­çš„éšç§å¨èƒ/æ”»å‡»
- en: ML types
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ç±»å‹
- en: Some of you may already be familiar with the different types of ML, namely supervised
    ML, unsupervised ML, and reinforcement learning. In the next sections, we will
    provide a quick refresher on these ML types, summarizing what you may have already
    learned.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›äººå¯¹ä¸åŒçš„MLç±»å‹å¯èƒ½å·²ç»ç†Ÿæ‚‰ï¼Œå³ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å¿«é€Ÿå›é¡¾è¿™äº›MLç±»å‹ï¼Œæ€»ç»“ä½ å¯èƒ½å·²ç»å­¦åˆ°çš„å†…å®¹ã€‚
- en: Supervised ML
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç›‘ç£å­¦ä¹ 
- en: Supervised ML models involve the development of a mathematical model using a
    set of input data and corresponding actual output. The input data is known as
    the training data, while the output is referred to as the predicted output. These
    models employ mathematical functions to learn from the training data and aim to
    minimize the errors between the predicted output and the expected output using
    an optimal function. The training data, which consists of input examples, is typically
    represented in formats such as arrays, vectors, matrices, or tensors. This data
    is often referred to as feature data or feature vectors, where each attribute
    within the data is considered a feature.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç›‘ç£å­¦ä¹ æ¨¡å‹æ¶‰åŠä½¿ç”¨ä¸€ç»„è¾“å…¥æ•°æ®å’Œç›¸åº”çš„å®é™…è¾“å‡ºå¼€å‘ä¸€ä¸ªæ•°å­¦æ¨¡å‹ã€‚è¾“å…¥æ•°æ®è¢«ç§°ä¸ºè®­ç»ƒæ•°æ®ï¼Œè€Œè¾“å‡ºè¢«ç§°ä¸ºé¢„æµ‹è¾“å‡ºã€‚è¿™äº›æ¨¡å‹ä½¿ç”¨æ•°å­¦å‡½æ•°ä»è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ ï¼Œå¹¶æ—¨åœ¨ä½¿ç”¨æœ€ä¼˜å‡½æ•°æœ€å°åŒ–é¢„æµ‹è¾“å‡ºå’Œé¢„æœŸè¾“å‡ºä¹‹é—´çš„è¯¯å·®ã€‚ç”±è¾“å…¥ç¤ºä¾‹ç»„æˆçš„æ•°æ®é€šå¸¸ä»¥æ•°ç»„ã€å‘é‡ã€çŸ©é˜µæˆ–å¼ é‡ç­‰æ ¼å¼è¡¨ç¤ºã€‚è¿™ç§æ•°æ®é€šå¸¸è¢«ç§°ä¸ºç‰¹å¾æ•°æ®æˆ–ç‰¹å¾å‘é‡ï¼Œå…¶ä¸­æ•°æ®ä¸­çš„æ¯ä¸ªå±æ€§éƒ½è¢«è§†ä¸ºä¸€ä¸ªç‰¹å¾ã€‚
- en: '| **Type** | **Example** | **Details** |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| **ç±»å‹** | **ç¤ºä¾‹** | **ç»†èŠ‚** |'
- en: '| Scalar | 1 | A scalar is a single number. |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| æ ‡é‡ | 1 | æ ‡é‡æ˜¯ä¸€ä¸ªå•ç‹¬çš„æ•°å­—ã€‚ |'
- en: '| Vector | [ 1 2 3 4 ] | A vector is an array of numbers or objects with different
    data types. |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| å‘é‡ | [ 1 2 3 4 ] | å‘é‡æ˜¯ç”±ä¸åŒæ•°æ®ç±»å‹çš„æ•°å­—æˆ–å¯¹è±¡ç»„æˆçš„æ•°ç»„ã€‚ |'
- en: '| Matrix | [1Â 2Â 3Â 4Â 5Â 6Â 7Â 8Â 9] | A matrix is an array of numbers arranged in
    rows and columns. In order to access the matrix, we need two indexes: column number
    and row number. |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| çŸ©é˜µ | [1Â 2Â 3Â 4Â 5Â 6Â 7Â 8Â 9] | çŸ©é˜µæ˜¯æŒ‰è¡Œå’Œåˆ—æ’åˆ—çš„æ•°å­—æ•°ç»„ã€‚ä¸ºäº†è®¿é—®çŸ©é˜µï¼Œæˆ‘ä»¬éœ€è¦ä¸¤ä¸ªç´¢å¼•ï¼šåˆ—å·å’Œè¡Œå·ã€‚ |'
- en: '| Tensor | [[ 1 2] [ 3 4] [ 5 6][ 7 8 ] [9 0] [ 0 1]] | A tensor is an *n*-dimensional
    array with *n>2*. |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| å¼ é‡ | [[ 1 2] [ 3 4] [ 5 6][ 7 8 ] [9 0] [ 0 1]] | å¼ é‡æ˜¯ä¸€ä¸ª*n*-ç»´æ•°ç»„ï¼Œå…¶ä¸­*n>2*ã€‚ |'
- en: Table 2.1 â€“ Examples of scalar, vector, matrix, and tensor
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨2.1 â€“ æ ‡é‡ã€å‘é‡ã€çŸ©é˜µå’Œå¼ é‡çš„ç¤ºä¾‹
- en: In mathematical terms, supervised learning in ML can be represented by a model,
    with parameters, *ğœƒ*. This model acts as a mapping function between input *x*
    and output *y*, denoted as *y =* ğ‘“ *(x,* ğœƒ*).* In this context, *x* represents
    a vector of attributes or features with a dimensionality of *ğ‘›*. The output or
    label *y* can vary in dimension depending on the specific learning task.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•°å­¦æœ¯è¯­ä¸­ï¼ŒMLä¸­çš„ç›‘ç£å­¦ä¹ å¯ä»¥ç”¨ä¸€ä¸ªå¸¦æœ‰å‚æ•°*ğœƒ*çš„æ¨¡å‹æ¥è¡¨ç¤ºã€‚è¯¥æ¨¡å‹å……å½“è¾“å…¥*x*å’Œè¾“å‡º*y*ä¹‹é—´çš„æ˜ å°„å‡½æ•°ï¼Œè¡¨ç¤ºä¸º*y =* ğ‘“ *(x,* ğœƒ*).*
    åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­ï¼Œ*x*ä»£è¡¨ä¸€ä¸ªå…·æœ‰*ğ‘›*ç»´åº¦çš„å±æ€§æˆ–ç‰¹å¾å‘é‡ã€‚è¾“å‡ºæˆ–æ ‡ç­¾*y*çš„ç»´åº¦å¯ä»¥æ ¹æ®ç‰¹å®šçš„å­¦ä¹ ä»»åŠ¡è€Œå˜åŒ–ã€‚
- en: To train the model, a training set T, is utilized, which consists of data points
    in the form of T = {(x , yğ‘–)}, where *ğ‘–* ranges from 1 to n, representing the
    number of inputâ€“output pairs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨äº†ä¸€ä¸ªè®­ç»ƒé›†Tï¼Œå®ƒç”±å½¢å¼ä¸ºT = {(x, yğ‘–)}çš„æ•°æ®ç‚¹ç»„æˆï¼Œå…¶ä¸­*ğ‘–*çš„èŒƒå›´ä»1åˆ°nï¼Œä»£è¡¨è¾“å…¥-è¾“å‡ºå¯¹çš„æ•°ç›®ã€‚
- en: 'Supervised ML algorithms typically fall into two categories: regression and
    classification. These algorithms aim to learn patterns and relationships within
    the training data to make predictions or assign labels to new, unseen data.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç›‘ç£æœºå™¨å­¦ä¹ ç®—æ³•é€šå¸¸åˆ†ä¸ºä¸¤ç±»ï¼šå›å½’å’Œåˆ†ç±»ã€‚è¿™äº›ç®—æ³•æ—¨åœ¨å­¦ä¹ è®­ç»ƒæ•°æ®ä¸­çš„æ¨¡å¼å’Œå…³ç³»ï¼Œä»¥ä¾¿å¯¹æ–°ã€æœªè§è¿‡çš„æ•°æ®è¿›è¡Œé¢„æµ‹æˆ–åˆ†é…æ ‡ç­¾ã€‚
- en: Regression
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å›å½’
- en: A target variable in ML is the variable that we aim to predict or forecast.
    It is also often termed as the dependent variable. It is what the ML model is
    trained to predict using independent or feature variables. For example, in a house
    price prediction model, the house price would be the target variable.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œç›®æ ‡å˜é‡æ˜¯æˆ‘ä»¬æ—¨åœ¨é¢„æµ‹æˆ–é¢„æµ‹çš„å˜é‡ã€‚å®ƒä¹Ÿå¸¸è¢«ç§°ä¸ºå› å˜é‡ã€‚å®ƒæ˜¯æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒç”¨æ¥ä½¿ç”¨ç‹¬ç«‹æˆ–ç‰¹å¾å˜é‡é¢„æµ‹çš„å˜é‡ã€‚ä¾‹å¦‚ï¼Œåœ¨æˆ¿ä»·é¢„æµ‹æ¨¡å‹ä¸­ï¼Œæˆ¿ä»·å°†æ˜¯ç›®æ ‡å˜é‡ã€‚
- en: Regression is a fundamental concept in ML that focuses on predicting continuous
    numerical values based on input variables. It is a supervised learning technique
    that involves analyzing the relationship between the input features and the target
    variable. The goal of regression is to build a mathematical model that can accurately
    estimate or approximate the value of the target variable when provided with new
    input data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å›å½’æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ä¸ªåŸºæœ¬æ¦‚å¿µï¼Œå®ƒä¾§é‡äºæ ¹æ®è¾“å…¥å˜é‡é¢„æµ‹è¿ç»­æ•°å€¼ã€‚å®ƒæ˜¯ä¸€ç§ç›‘ç£å­¦ä¹ æŠ€æœ¯ï¼Œæ¶‰åŠåˆ†æè¾“å…¥ç‰¹å¾ä¸ç›®æ ‡å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚å›å½’çš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªæ•°å­¦æ¨¡å‹ï¼Œå½“æä¾›æ–°çš„è¾“å…¥æ•°æ®æ—¶ï¼Œå¯ä»¥å‡†ç¡®åœ°ä¼°è®¡æˆ–è¿‘ä¼¼ç›®æ ‡å˜é‡çš„å€¼ã€‚
- en: In regression, the target variable, also known as the dependent variable, is
    a continuous value. The input variables, also called independent variables or
    features, can be numerical or categorical. The regression model seeks to understand
    the relationship between these input variables and the target variable, enabling
    predictions to be made for unseen data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å›å½’ä¸­ï¼Œç›®æ ‡å˜é‡ï¼Œä¹Ÿç§°ä¸ºå› å˜é‡ï¼Œæ˜¯ä¸€ä¸ªè¿ç»­å€¼ã€‚è¾“å…¥å˜é‡ï¼Œä¹Ÿç§°ä¸ºç‹¬ç«‹å˜é‡æˆ–ç‰¹å¾ï¼Œå¯ä»¥æ˜¯æ•°å€¼æˆ–åˆ†ç±»çš„ã€‚å›å½’æ¨¡å‹æ—¨åœ¨ç†è§£è¿™äº›è¾“å…¥å˜é‡ä¸ç›®æ ‡å˜é‡ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œèƒ½å¤Ÿå¯¹æœªè§æ•°æ®åšå‡ºé¢„æµ‹ã€‚
- en: The performance of a regression model is typically measured by evaluating the
    closeness of its predictions to the actual target values. Various regression algorithms
    exist, such as linear regression, polynomial regression, and more complex techniques
    such as support vector regression and random forest regression. These algorithms
    use mathematical optimization methods to fit a regression function that minimizes
    the difference between predicted values and the true values of the target variable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å›å½’æ¨¡å‹çš„æ€§èƒ½é€šå¸¸é€šè¿‡è¯„ä¼°å…¶é¢„æµ‹å€¼ä¸å®é™…ç›®æ ‡å€¼ä¹‹é—´çš„æ¥è¿‘ç¨‹åº¦æ¥è¡¡é‡ã€‚å­˜åœ¨å„ç§å›å½’ç®—æ³•ï¼Œå¦‚çº¿æ€§å›å½’ã€å¤šé¡¹å¼å›å½’ï¼Œä»¥åŠæ›´å¤æ‚çš„æ”¯æŒå‘é‡å›å½’å’Œéšæœºæ£®æ—å›å½’ç­‰æŠ€æœ¯ã€‚è¿™äº›ç®—æ³•ä½¿ç”¨æ•°å­¦ä¼˜åŒ–æ–¹æ³•æ¥æ‹Ÿåˆå›å½’å‡½æ•°ï¼Œä»¥æœ€å°åŒ–é¢„æµ‹å€¼ä¸ç›®æ ‡å˜é‡çš„çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ã€‚
- en: Regression analysis finds applications in numerous fields, including finance,
    economics, healthcare, and social sciences, where it is used for tasks such as
    price prediction, demand forecasting, risk assessment, and trend analysis. By
    leveraging regression algorithms, valuable insights can be gained from data, allowing
    for informed decision-making and accurate predictions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å›å½’åˆ†æåœ¨ä¼—å¤šé¢†åŸŸéƒ½æœ‰åº”ç”¨ï¼ŒåŒ…æ‹¬é‡‘èã€ç»æµå­¦ã€åŒ»ç–—ä¿å¥å’Œç¤¾ä¼šç§‘å­¦ï¼Œå…¶ä¸­å®ƒè¢«ç”¨äºè¯¸å¦‚ä»·æ ¼é¢„æµ‹ã€éœ€æ±‚é¢„æµ‹ã€é£é™©è¯„ä¼°å’Œè¶‹åŠ¿åˆ†æç­‰ä»»åŠ¡ã€‚é€šè¿‡åˆ©ç”¨å›å½’ç®—æ³•ï¼Œå¯ä»¥ä»æ•°æ®ä¸­è·å¾—æœ‰ä»·å€¼çš„è§è§£ï¼Œä»è€Œå®ç°æ˜æ™ºçš„å†³ç­–å’Œå‡†ç¡®çš„é¢„æµ‹ã€‚
- en: Regression model example
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å›å½’æ¨¡å‹ç¤ºä¾‹
- en: Hereâ€™s a straightforward example of predicting a target variable using two input
    features. In this scenario, a model is trained on a set of historical data, typically
    representing the data from the last X days.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨ä¸¤ä¸ªè¾“å…¥ç‰¹å¾é¢„æµ‹ç›®æ ‡å˜é‡çš„ç®€å•ç¤ºä¾‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ˜¯åœ¨ä¸€ç»„å†å²æ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œé€šå¸¸ä»£è¡¨è¿‡å»Xå¤©çš„æ•°æ®ã€‚
- en: The purpose is to forecast or predict the target variable based on the provided
    input data. By analyzing patterns and relationships in the historical dataset,
    the trained model can make predictions about the target variable when presented
    with new input data. This process allows for forecasting future values or understanding
    potential outcomes based on the given inputs. The modelâ€™s accuracy and performance
    are evaluated based on how well it can predict the target variable compared to
    the actual values. By leveraging historical data and utilizing ML algorithms,
    valuable insights can be gained, enabling accurate predictions and informed decision-making.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®çš„æ˜¯æ ¹æ®æä¾›çš„è¾“å…¥æ•°æ®é¢„æµ‹æˆ–é¢„æµ‹ç›®æ ‡å˜é‡ã€‚é€šè¿‡åˆ†æå†å²æ•°æ®é›†ä¸­çš„æ¨¡å¼å’Œå…³ç³»ï¼Œè®­ç»ƒå¥½çš„æ¨¡å‹å¯ä»¥åœ¨å‘ˆç°æ–°çš„è¾“å…¥æ•°æ®æ—¶å¯¹ç›®æ ‡å˜é‡è¿›è¡Œé¢„æµ‹ã€‚è¿™ä¸ªè¿‡ç¨‹å…è®¸æ ¹æ®ç»™å®šçš„è¾“å…¥é¢„æµ‹æœªæ¥çš„å€¼æˆ–ç†è§£æ½œåœ¨çš„ç»“æœã€‚æ¨¡å‹çš„å‡†ç¡®æ€§å’Œæ€§èƒ½æ˜¯æ ¹æ®å…¶é¢„æµ‹ç›®æ ‡å˜é‡çš„èƒ½åŠ›ä¸å®é™…å€¼ç›¸æ¯”æ¥è¯„ä¼°çš„ã€‚é€šè¿‡åˆ©ç”¨å†å²æ•°æ®å’Œåˆ©ç”¨æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå¯ä»¥è·å¾—æœ‰ä»·å€¼çš„è§è§£ï¼Œä»è€Œå®ç°å‡†ç¡®çš„é¢„æµ‹å’Œæ˜æ™ºçš„å†³ç­–ã€‚
- en: '| Feature 1 value | Feature 2 value | Target variable value |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| ç‰¹å¾1å€¼ | ç‰¹å¾2å€¼ | ç›®æ ‡å˜é‡å€¼ |'
- en: '| 10 | 10 | 130 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 10 | 130 |'
- en: '| 10 | 20 | 180 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 20 | 180 |'
- en: '| 20 | 20 | 210 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 20 | 210 |'
- en: '| 20 | 30 | 260 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 30 | 260 |'
- en: '| 30 | 50 | ?? |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 50 | ?? |'
- en: Table 2.2 â€“ regression model example
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨2.2 â€“ å›å½’æ¨¡å‹ç¤ºä¾‹
- en: This example was implemented using the scikit-learn library. I have used Python
    version 3.8 and scikit-learn version 1.2.1.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤ç¤ºä¾‹ä½¿ç”¨scikit-learnåº“å®ç°ã€‚æˆ‘ä½¿ç”¨äº†Python 3.8å’Œscikit-learn 1.2.1ç‰ˆæœ¬ã€‚
- en: 'These are the steps followed in this example:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯åœ¨æœ¬ä¾‹ä¸­éµå¾ªçš„æ­¥éª¤ï¼š
- en: Install Jupyter Notebook (**pip** **install notebook**).
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®‰è£…Jupyter Notebookï¼ˆ**pip** **install notebook**ï¼‰ã€‚
- en: Open a Python Jupyter notebook (**jupyter notebook**).
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰“å¼€ä¸€ä¸ªPython Jupyterç¬”è®°æœ¬ï¼ˆ**jupyter notebook**ï¼‰ã€‚
- en: Install sci-kit learn libraries (**pip install -****U scikit-learn**).
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®‰è£…sci-kit learnåº“ï¼ˆ**pip install -****U scikit-learn**ï¼‰ã€‚
- en: Type the following code and run the model code.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¾“å…¥ä»¥ä¸‹ä»£ç å¹¶è¿è¡Œæ¨¡å‹ä»£ç ã€‚
- en: 'You can directly execute the code using the Jupyter notebook provided in the
    GitHub location of this bookâ€”`LinearRegression.ipynb`â€”located at [https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%202/LinearRegression.ipynb](https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%202/LinearRegression.ipynb):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨æœ¬ä¹¦GitHubä½ç½®æä¾›çš„Jupyterç¬”è®°æœ¬æ‰§è¡Œä»£ç â€”`LinearRegression.ipynb`â€”ä½äº[https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%202/LinearRegression.ipynb](https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%202/LinearRegression.ipynb)ï¼š
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, target variable y is linearly dependent on input variables
    X0 and X1 with the linear equation y= 3X0+ 5X1+50 (50 is the intercept of the
    line).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œç›®æ ‡å˜é‡yä¸è¾“å…¥å˜é‡X0å’ŒX1å‘ˆçº¿æ€§ç›¸å…³ï¼Œçº¿æ€§æ–¹ç¨‹ä¸ºy= 3X0+ 5X1+50ï¼ˆ50æ˜¯ç›´çº¿çš„æˆªè·ï¼‰ã€‚
- en: The model uses the root mean square value as an optimal function and predicts
    the target variable. In this case, it predicts 100% accuracy because of the strong
    linear relationship between the features and the target variable.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹ä½¿ç”¨å‡æ–¹æ ¹å€¼ä½œä¸ºæœ€ä¼˜å‡½æ•°ï¼Œå¹¶é¢„æµ‹ç›®æ ‡å˜é‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”±äºç‰¹å¾å’Œç›®æ ‡å˜é‡ä¹‹é—´å¼ºçƒˆçš„çº¿æ€§å…³ç³»ï¼Œå®ƒé¢„æµ‹äº†100%çš„å‡†ç¡®ç‡ã€‚
- en: Model persistence and retrieving the persisted model for inference
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ¨¡å‹æŒä¹…åŒ–å’Œæ£€ç´¢æŒä¹…åŒ–æ¨¡å‹ä»¥è¿›è¡Œæ¨ç†
- en: After developing and testing the model using training data and validating it
    with test data, the next step is to persist the model. This allows for easy sharing
    with other developers or engineers without revealing the training data and intricate
    model details. Additionally, if the model demonstrates sufficient accuracy during
    training, it can be deployed in production environments.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½¿ç”¨è®­ç»ƒæ•°æ®å¼€å‘å’Œæµ‹è¯•æ¨¡å‹ä»¥åŠä½¿ç”¨æµ‹è¯•æ•°æ®è¿›è¡ŒéªŒè¯ä¹‹åï¼Œä¸‹ä¸€æ­¥æ˜¯æŒä¹…åŒ–æ¨¡å‹ã€‚è¿™å…è®¸ä¸å…¶ä»–å¼€å‘äººå‘˜æˆ–å·¥ç¨‹å¸ˆè½»æ¾å…±äº«ï¼Œè€Œæ— éœ€é€éœ²è®­ç»ƒæ•°æ®å’Œå¤æ‚çš„æ¨¡å‹ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œå¦‚æœæ¨¡å‹åœ¨è®­ç»ƒæœŸé—´è¡¨ç°å‡ºè¶³å¤Ÿçš„å‡†ç¡®åº¦ï¼Œå®ƒå¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²ã€‚
- en: To persist the model, various formats are supported to store it in the disk
    or file system. The specific format utilized depends on the framework used to
    develop the ML or **deep learning** (**DL**) model. By employing these formats,
    the model can be stored and accessed efficiently, facilitating seamless integration
    into production systems or collaborations with other team members.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æŒä¹…åŒ–æ¨¡å‹ï¼Œæ”¯æŒå¤šç§æ ¼å¼ä»¥å°†å…¶å­˜å‚¨åœ¨ç£ç›˜æˆ–æ–‡ä»¶ç³»ç»Ÿä¸­ã€‚å…·ä½“ä½¿ç”¨çš„æ ¼å¼å–å†³äºå¼€å‘æœºå™¨å­¦ä¹ æˆ–**æ·±åº¦å­¦ä¹ **ï¼ˆ**DL**ï¼‰æ¨¡å‹æ‰€ä½¿ç”¨çš„æ¡†æ¶ã€‚é€šè¿‡ä½¿ç”¨è¿™äº›æ ¼å¼ï¼Œæ¨¡å‹å¯ä»¥é«˜æ•ˆåœ°å­˜å‚¨å’Œè®¿é—®ï¼Œä¾¿äºæ— ç¼é›†æˆåˆ°ç”Ÿäº§ç³»ç»Ÿæˆ–ä¸å…¶ä»–å›¢é˜Ÿæˆå‘˜çš„åˆä½œä¸­ã€‚
- en: Persisting the model enables reproducibility and scalability, as it can be shared,
    reused, and deployed in different environments without the need to retrain it
    from scratch. It also helps protect proprietary information and intellectual property
    associated with the model, allowing organizations to safeguard their valuable
    research and development efforts.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æŒä¹…åŒ–æ¨¡å‹å¯ä»¥å®ç°å¯é‡å¤æ€§å’Œå¯æ‰©å±•æ€§ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨ä¸åŒçš„ç¯å¢ƒä¸­å…±äº«ã€é‡ç”¨å’Œéƒ¨ç½²ï¼Œè€Œæ— éœ€ä»å¤´å¼€å§‹é‡æ–°è®­ç»ƒã€‚å®ƒè¿˜æœ‰åŠ©äºä¿æŠ¤ä¸æ¨¡å‹ç›¸å…³çš„ä¸“æœ‰ä¿¡æ¯å’ŒçŸ¥è¯†äº§æƒï¼Œä½¿ç»„ç»‡èƒ½å¤Ÿä¿æŠ¤å…¶å®è´µçš„ç ”ç©¶å’Œå¼€å‘å·¥ä½œã€‚
- en: '![Figure 2.1 â€“ Model persistence and retrieval](img/B16573_02_01.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.1 â€“ æ¨¡å‹æŒä¹…åŒ–å’Œæ£€ç´¢](img/B16573_02_01.jpg)'
- en: Figure 2.1 â€“ Model persistence and retrieval
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2.1 â€“ æ¨¡å‹æŒä¹…åŒ–å’Œæ£€ç´¢
- en: 'The following table shows some formats that are widely used and accepted in
    the community:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è¡¨æ˜¾ç¤ºäº†ç¤¾åŒºä¸­å¹¿æ³›ä½¿ç”¨å’Œæ¥å—çš„æ ¼å¼ï¼š
- en: '| Framework | Model persistence format | Details |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| æ¡†æ¶ | æ¨¡å‹æŒä¹…åŒ–æ ¼å¼ | è¯¦æƒ… |'
- en: '| scikit-learn[https://scikit-learn.org/](https://scikit-learn.org/) | JoblibPickle
    | The Joblib and pickle formats donâ€™t require any code changes.The pickle format
    has security issues, so most frameworks donâ€™t advise using the pickle format for
    model persistence because arbitrary code can be executed during unpickling. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| scikit-learn[https://scikit-learn.org/](https://scikit-learn.org/) | JoblibPickle
    | Joblib å’Œ pickle æ ¼å¼ä¸éœ€è¦ä»»ä½•ä»£ç æ›´æ”¹ã€‚pickle æ ¼å¼å­˜åœ¨å®‰å…¨é—®é¢˜ï¼Œå› æ­¤å¤§å¤šæ•°æ¡†æ¶ä¸å»ºè®®ä½¿ç”¨ pickle æ ¼å¼è¿›è¡Œæ¨¡å‹æŒä¹…åŒ–ï¼Œå› ä¸ºåœ¨ååºåˆ—åŒ–è¿‡ç¨‹ä¸­å¯ä»¥æ‰§è¡Œä»»æ„ä»£ç ã€‚|'
- en: '| TensorFlow/Keras[https://www.tensorflow.org/](https://www.tensorflow.org/)
    | JSONYAMLHDF5 | This is model data stored in JSON format or YAML format, and
    these formats are text-based formats, so they are language-agnostic.Weights are
    saved in HDF5 format. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow/Keras[https://www.tensorflow.org/](https://www.tensorflow.org/)
    | JSONYAMLHDF5 | è¿™æ˜¯ä»¥ JSON æˆ– YAML æ ¼å¼å­˜å‚¨çš„æ¨¡å‹æ•°æ®ï¼Œè¿™äº›æ ¼å¼æ˜¯åŸºäºæ–‡æœ¬çš„æ ¼å¼ï¼Œå› æ­¤å®ƒä»¬æ˜¯è¯­è¨€æ— å…³çš„ã€‚æƒé‡ä»¥ HDF5 æ ¼å¼ä¿å­˜ã€‚|'
- en: '| PyTorch[https://pytorch.org/](https://pytorch.org/) | state_dictPickle |
    For neural network models to store weights and biases. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch[https://pytorch.org/](https://pytorch.org/) | state_dictPickle |
    ç”¨äºç¥ç»ç½‘ç»œæ¨¡å‹å­˜å‚¨æƒé‡å’Œåå·®ã€‚|'
- en: '| ONNX | Onnx | Models need to be converted to ONNX format and exported and
    loaded/executed using ONNX Runtime so that they can be run either on CPU- or GPU-based
    servers. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| ONNX | Onnx | æ¨¡å‹éœ€è¦è½¬æ¢ä¸º ONNX æ ¼å¼ï¼Œå¹¶ä½¿ç”¨ ONNX Runtime å¯¼å‡ºå’ŒåŠ è½½/æ‰§è¡Œï¼Œä»¥ä¾¿å®ƒä»¬å¯ä»¥åœ¨åŸºäº CPU æˆ– GPU
    çš„æœåŠ¡å™¨ä¸Šè¿è¡Œã€‚|'
- en: Table 2.3 â€“ Examples of scalar, vector, matrix, and tensor
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 2.3 â€“ æ ‡é‡ã€å‘é‡ã€çŸ©é˜µå’Œå¼ é‡çš„ç¤ºä¾‹
- en: 'The following code shows how to store and retrieve a model in the Joblib format
    using Python:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä»£ç å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Python å­˜å‚¨å’Œæ£€ç´¢ Joblib æ ¼å¼çš„æ¨¡å‹ï¼š
- en: What is Joblib?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ Joblibï¼Ÿ
- en: Joblib ([https://joblib.readthedocs.io/en/latest/](https://joblib.readthedocs.io/en/latest/))
    is a set of tools to provide lightweight pipelining in Python to persist (or serialize)
    the Python objects. Joblib version 1.2.0 is used in this code.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Joblib ([https://joblib.readthedocs.io/en/latest/](https://joblib.readthedocs.io/en/latest/))
    æ˜¯ä¸€ç»„å·¥å…·ï¼Œç”¨äºåœ¨ Python ä¸­æä¾›è½»é‡çº§ç®¡é“ï¼Œä»¥æŒä¹…åŒ–ï¼ˆæˆ–åºåˆ—åŒ–ï¼‰Python å¯¹è±¡ã€‚æœ¬ä»£ç ä¸­ä½¿ç”¨ Joblib ç‰ˆæœ¬ 1.2.0ã€‚
- en: 'The Jupyter notebook for this example is `LinearRegression_SaveModel.ipynb`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¾‹çš„ Jupyter ç¬”è®°æœ¬ä¸º `LinearRegression_SaveModel.ipynb`ï¼š
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once the model is persisted in a file system or a file, then the file can be
    shared with other developers or engineers without sharing any of the training
    data or model details used in the code. Other developers/engineers can then load
    this file and use it for further predictions or deploy it in production for production
    usage. This is explained in *Figure 2**.1*. This model is saved in the current
    directory and has the name `sample_model.sav`; you can make use of any extension
    as it doesnâ€™t matter which extension is used. The source code is in `Linear_Regression_Load_Model.ipynb`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ¨¡å‹åœ¨æ–‡ä»¶ç³»ç»Ÿæˆ–æ–‡ä»¶ä¸­æŒä¹…åŒ–ï¼Œåˆ™å¯ä»¥ä¸å…¶ä»–å¼€å‘äººå‘˜æˆ–å·¥ç¨‹å¸ˆå…±äº«è¯¥æ–‡ä»¶ï¼Œè€Œæ— éœ€å…±äº«ä»£ç ä¸­ä½¿ç”¨çš„ä»»ä½•è®­ç»ƒæ•°æ®æˆ–æ¨¡å‹ç»†èŠ‚ã€‚å…¶ä»–å¼€å‘äººå‘˜/å·¥ç¨‹å¸ˆç„¶åå¯ä»¥åŠ è½½æ­¤æ–‡ä»¶å¹¶ç”¨äºè¿›ä¸€æ­¥çš„é¢„æµ‹æˆ–å°†å…¶éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒä¸­è¿›è¡Œç”Ÿäº§ä½¿ç”¨ã€‚è¿™å·²åœ¨
    *å›¾ 2**.1 ä¸­è§£é‡Šã€‚è¯¥æ¨¡å‹ä¿å­˜åœ¨å½“å‰ç›®å½•ä¸­ï¼Œåç§°ä¸º `sample_model.sav`ï¼›æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•æ‰©å±•åï¼Œå› ä¸ºå®ƒå¹¶ä¸é‡è¦ä½¿ç”¨å“ªä¸ªæ‰©å±•åã€‚æºä»£ç åœ¨
    `Linear_Regression_Load_Model.ipynb` ä¸­ï¼š
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Classification
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åˆ†ç±»
- en: A classification model employs different algorithms to predict an output or
    dependent variable based on the relationship between the input variables. Classification
    algorithms are specifically designed to predict discrete values, such as spam/not
    spam, male/female, yes/no, and so on. Each of these predicted values is referred
    to as a label or class.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»æ¨¡å‹ä½¿ç”¨ä¸åŒçš„ç®—æ³•æ ¹æ®è¾“å…¥å˜é‡ä¹‹é—´çš„å…³ç³»é¢„æµ‹è¾“å‡ºæˆ–å› å˜é‡ã€‚åˆ†ç±»ç®—æ³•ä¸“é—¨è®¾è®¡ç”¨äºé¢„æµ‹ç¦»æ•£å€¼ï¼Œä¾‹å¦‚åƒåœ¾é‚®ä»¶/éåƒåœ¾é‚®ä»¶ã€ç”·æ€§/å¥³æ€§ã€æ˜¯/å¦ç­‰ã€‚è¿™äº›é¢„æµ‹å€¼ä¸­çš„æ¯ä¸€ä¸ªéƒ½è¢«ç§°ä¸ºæ ‡ç­¾æˆ–ç±»åˆ«ã€‚
- en: In binary classification scenarios, there are only two possible class labels,
    e.g., determining whether an email is spam or not spam. On the other hand, multi-label
    classification involves predicting multiple class labels simultaneously. An example
    could be classifying images into various categories such as cat, dog, and bird.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨äºŒå…ƒåˆ†ç±»åœºæ™¯ä¸­ï¼Œåªæœ‰ä¸¤ä¸ªå¯èƒ½çš„ç±»åˆ«æ ‡ç­¾ï¼Œä¾‹å¦‚ï¼Œç¡®å®šä¸€å°ç”µå­é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ã€‚å¦ä¸€æ–¹é¢ï¼Œå¤šæ ‡ç­¾åˆ†ç±»æ¶‰åŠåŒæ—¶é¢„æµ‹å¤šä¸ªç±»åˆ«æ ‡ç­¾ã€‚ä¸€ä¸ªä¾‹å­æ˜¯å°†å›¾åƒåˆ†ç±»åˆ°å„ç§ç±»åˆ«ï¼Œå¦‚çŒ«ã€ç‹—å’Œé¸Ÿã€‚
- en: Classification models are trained using historical data that contains both the
    input variables and their corresponding class labels. The algorithms learn from
    this labeled data and establish patterns and relationships to make accurate predictions
    on new, unseen data. The performance of a classification model is evaluated based
    on metrics such as accuracy, precision, recall, and F1 score. These metrics assess
    how well the model can correctly assign the appropriate class labels to new instances
    based on their input features.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»æ¨¡å‹ä½¿ç”¨åŒ…å«è¾“å…¥å˜é‡åŠå…¶å¯¹åº”ç±»åˆ«æ ‡ç­¾çš„å†å²æ•°æ®è¿›è¡Œè®­ç»ƒã€‚ç®—æ³•ä»è¿™äº›æœ‰æ ‡ç­¾çš„æ•°æ®ä¸­å­¦ä¹ ï¼Œå¹¶å»ºç«‹æ¨¡å¼å’Œå…³ç³»ï¼Œä»¥ä¾¿åœ¨æ–°ã€æœªè§è¿‡çš„æ•°æ®ä¸Šåšå‡ºå‡†ç¡®çš„é¢„æµ‹ã€‚åˆ†ç±»æ¨¡å‹çš„æ€§èƒ½åŸºäºå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°ç­‰æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ã€‚è¿™äº›æŒ‡æ ‡è¯„ä¼°æ¨¡å‹æ ¹æ®å…¶è¾“å…¥ç‰¹å¾æ­£ç¡®åˆ†é…é€‚å½“çš„ç±»åˆ«æ ‡ç­¾åˆ°æ–°å®ä¾‹çš„èƒ½åŠ›ã€‚
- en: Classification models find extensive applications in various domains, including
    spam filtering, sentiment analysis, customer churn prediction, fraud detection,
    and medical diagnosis. By leveraging different classification algorithms, valuable
    insights can be gained from data, enabling informed decision-making and efficient
    problem-solving.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»æ¨¡å‹åœ¨å„ä¸ªé¢†åŸŸéƒ½æœ‰å¹¿æ³›çš„åº”ç”¨ï¼ŒåŒ…æ‹¬åƒåœ¾é‚®ä»¶è¿‡æ»¤ã€æƒ…æ„Ÿåˆ†æã€å®¢æˆ·æµå¤±é¢„æµ‹ã€æ¬ºè¯ˆæ£€æµ‹å’ŒåŒ»ç–—è¯Šæ–­ã€‚é€šè¿‡åˆ©ç”¨ä¸åŒçš„åˆ†ç±»ç®—æ³•ï¼Œå¯ä»¥ä»æ•°æ®ä¸­è·å¾—æœ‰ä»·å€¼çš„è§è§£ï¼Œä»è€Œå®ç°æ˜æ™ºçš„å†³ç­–å’Œé«˜æ•ˆçš„é—®é¢˜è§£å†³ã€‚
- en: '| **Classification type** | **Details** | **Examples** | **Algorithms** |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| **åˆ†ç±»ç±»å‹** | **è¯¦ç»†ä¿¡æ¯** | **ç¤ºä¾‹** | **ç®—æ³•** |'
- en: '| Binary | Predicts one of two classes based on the training data | Yes/noSpam/not
    spamPass/failCancer/no cancer | Logistic regressionK-nearest neighborsDecision
    treesSupport vector machineNaive Bayes |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| äºŒå…ƒ | åŸºäºè®­ç»ƒæ•°æ®é¢„æµ‹ä¸¤ä¸ªç±»åˆ«ä¸­çš„ä¸€ä¸ª | æ˜¯/å¦åƒåœ¾é‚®ä»¶/éåƒåœ¾é‚®ä»¶é€šè¿‡/å¤±è´¥ç™Œç—‡/æ— ç™Œç—‡ | é€»è¾‘å›å½’Kæœ€è¿‘é‚»å†³ç­–æ ‘æ”¯æŒå‘é‡æœºæœ´ç´ è´å¶æ–¯
    |'
- en: '| Multi-class | Predicts one of more than two classes | Based on symptoms,
    e.g., cold, flu, or COVID-19 | K-nearest neighborsDecision treesNaive BayesRandom
    forestGradient boosting |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| å¤šåˆ†ç±» | é¢„æµ‹ä¸¤ä¸ªä»¥ä¸Šç±»åˆ«ä¸­çš„ä¸€ä¸ª | åŸºäºç—‡çŠ¶ï¼Œä¾‹å¦‚ï¼Œæ„Ÿå†’ã€æµæ„Ÿæˆ–COVID-19 | Kæœ€è¿‘é‚»å†³ç­–æ ‘æœ´ç´ è´å¶æ–¯éšæœºæ£®æ—æ¢¯åº¦æå‡ |'
- en: '| Multi-label | Has two or more class labels | Prediction of the topic based
    on the content: finance, politics, science, language, or all of them | Multi-label
    decision treesMulti-label random forestsMulti-label gradient boosting |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| å¤šæ ‡ç­¾ | æœ‰ä¸¤ä¸ªæˆ–æ›´å¤šç±»åˆ«æ ‡ç­¾ | æ ¹æ®å†…å®¹é¢„æµ‹ä¸»é¢˜ï¼šé‡‘èã€æ”¿æ²»ã€ç§‘å­¦ã€è¯­è¨€æˆ–æ‰€æœ‰è¿™äº› | å¤šæ ‡ç­¾å†³ç­–æ ‘å¤šæ ‡ç­¾éšæœºæ£®æ—å¤šæ ‡ç­¾æ¢¯åº¦æå‡ |'
- en: '| Extreme | Classification task in which the number of candidate labels is
    huge | Amazon 3M dataset, where the number of labels is 2,812,281 | DL algorithmsMore
    algorithms: [http://manikvarma.org/downloads/XC/XMLRepository.html](http://manikvarma.org/downloads/XC/XMLRepository.html)
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| æç«¯ | å€™é€‰æ ‡ç­¾æ•°é‡å·¨å¤§çš„åˆ†ç±»ä»»åŠ¡ | äºšé©¬é€Š3Mæ•°æ®é›†ï¼Œå…¶ä¸­æ ‡ç­¾æ•°é‡ä¸º2,812,281 | æ·±åº¦å­¦ä¹ ç®—æ³•æ›´å¤šç®—æ³•ï¼š[http://manikvarma.org/downloads/XC/XMLRepository.html](http://manikvarma.org/downloads/XC/XMLRepository.html)
    |'
- en: Table 2.4 â€“ Classification types and associated algorithms
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨2.4 â€“ åˆ†ç±»ç±»å‹å’Œç›¸å…³ç®—æ³•
- en: Classification example
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: åˆ†ç±»ç¤ºä¾‹
- en: 'In this example, we will utilize the decision tree classification algorithm
    to determine the likelihood of a patientâ€™s survival based on two features: age
    and whether they have a pre-existing cancer condition.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨å†³ç­–æ ‘åˆ†ç±»ç®—æ³•ï¼Œæ ¹æ®ä¸¤ä¸ªç‰¹å¾ï¼šå¹´é¾„å’Œæ˜¯å¦æœ‰æ—¢å¾€ç™Œç—‡çŠ¶å†µï¼Œæ¥ç¡®å®šæ‚£è€…ç”Ÿå­˜çš„å¯èƒ½æ€§ã€‚
- en: The decision tree classification algorithm is a widely used technique in ML
    that constructs a tree-like model of decisions. It analyzes the provided data
    to create a structure that represents the decision-making process.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å†³ç­–æ ‘åˆ†ç±»ç®—æ³•æ˜¯æœºå™¨å­¦ä¹ ä¸­å¹¿æ³›ä½¿ç”¨çš„æŠ€æœ¯ï¼Œå®ƒæ„å»ºäº†ä¸€ä¸ªå†³ç­–çš„æ ‘çŠ¶æ¨¡å‹ã€‚å®ƒåˆ†ææä¾›çš„æ•°æ®ä»¥åˆ›å»ºä¸€ä¸ªè¡¨ç¤ºå†³ç­–è¿‡ç¨‹çš„ç»“æ„ã€‚
- en: In our scenario, the age of the patient and their cancer status will be used
    as input features for classification. By examining a labeled dataset consisting
    of patient information, including age, cancer status, and survival outcome, the
    algorithm learns patterns and establishes decision rules.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„åœºæ™¯ä¸­ï¼Œæ‚£è€…çš„å¹´é¾„å’Œä»–ä»¬çš„ç™Œç—‡çŠ¶æ€å°†è¢«ç”¨ä½œåˆ†ç±»çš„è¾“å…¥ç‰¹å¾ã€‚é€šè¿‡æ£€æŸ¥åŒ…å«æ‚£è€…ä¿¡æ¯çš„æœ‰æ ‡ç­¾æ•°æ®é›†ï¼ŒåŒ…æ‹¬å¹´é¾„ã€ç™Œç—‡çŠ¶æ€å’Œç”Ÿå­˜ç»“æœï¼Œç®—æ³•å­¦ä¹ æ¨¡å¼å¹¶å»ºç«‹å†³ç­–è§„åˆ™ã€‚
- en: 'Once the model is trained, it becomes capable of predicting the survival outcome
    for new patients who have not been previously encountered. By considering the
    age and cancer status of these patients, the model traverses the decision tree
    until reaching a leaf node that signifies the predicted outcome: whether the patient
    is expected to survive or not.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ¨¡å‹ç»è¿‡è®­ç»ƒï¼Œå®ƒå°±èƒ½å¤Ÿé¢„æµ‹ä¹‹å‰æœªæ›¾é‡åˆ°çš„æ–°æ‚£è€…çš„å­˜æ´»ç»“æœã€‚é€šè¿‡è€ƒè™‘è¿™äº›æ‚£è€…çš„å¹´é¾„å’Œç™Œç—‡çŠ¶å†µï¼Œæ¨¡å‹éå†å†³ç­–æ ‘ï¼Œç›´åˆ°è¾¾åˆ°è¡¨ç¤ºé¢„æµ‹ç»“æœçš„å¶èŠ‚ç‚¹ï¼šæ‚£è€…æ˜¯å¦é¢„æœŸä¼šå­˜æ´»ã€‚
- en: By employing the decision tree classification algorithm in this example, we
    aim to classify patientsâ€™ survival probabilities based on their age and cancer
    status. This valuable insight can aid medical professionals in assessing patient
    prognosis and informing treatment decisions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åœ¨è¿™ä¸ªä¾‹å­ä¸­ä½¿ç”¨å†³ç­–æ ‘åˆ†ç±»ç®—æ³•ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ ¹æ®æ‚£è€…çš„å¹´é¾„å’Œç™Œç—‡çŠ¶å†µæ¥åˆ†ç±»æ‚£è€…çš„å­˜æ´»æ¦‚ç‡ã€‚è¿™ä¸€å®è´µçš„è§è§£å¯ä»¥å¸®åŠ©åŒ»ç–—ä¸“ä¸šäººå‘˜è¯„ä¼°æ‚£è€…é¢„åå¹¶å‘ŠçŸ¥æ²»ç–—å†³ç­–ã€‚
- en: '| **Age (years)** | **Has/had cancer (1 = yes, 0 =** **no)** | **Survived (1
    = yes,** **0 =no)** |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| **å¹´é¾„ï¼ˆå¹´ï¼‰** | **æ˜¯å¦æœ‰/æ›¾ç»æœ‰ç™Œç—‡ï¼ˆ1 = æ˜¯ï¼Œ0 = å¦ï¼‰** | **å­˜æ´»ï¼ˆ1 = æ˜¯ï¼Œ0 = å¦ï¼‰** |'
- en: '| 10 | 1 | 1 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 1 |'
- en: '| 20 | 1 | 1 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 1 | 1 |'
- en: '| 30 | 1 | 1 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 1 |'
- en: '| 80 | 1 | 0 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 1 | 0 |'
- en: '| 75 | 0 | 0 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 0 | 0 |'
- en: '| 78 | 0 | 0 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 0 | 0 |'
- en: '| 35 | 1 | ?? (predict) |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 35 | 1 | ?? (é¢„æµ‹) |'
- en: '| 78 | 1 | ?? (predict) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 1 | ?? (é¢„æµ‹) |'
- en: Table 2.5 â€“ Toy dataset for classification example
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨2.5 â€“ åˆ†ç±»ç¤ºä¾‹çš„ç©å…·æ•°æ®é›†
- en: In this toy dataset, the model needs to predict whether the last two patients
    survive or not (classification with two labels) based on the trained historical
    data of the model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç©å…·æ•°æ®é›†ä¸­ï¼Œæ¨¡å‹éœ€è¦æ ¹æ®æ¨¡å‹è®­ç»ƒçš„å†å²æ•°æ®é¢„æµ‹æœ€åä¸¤ä½æ‚£è€…çš„å­˜æ´»æƒ…å†µï¼ˆå…·æœ‰ä¸¤ä¸ªæ ‡ç­¾çš„åˆ†ç±»ï¼‰ã€‚
- en: The source code is in `Classification_Example.ipynb`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æºä»£ç ä½äº`Classification_Example.ipynb`ã€‚
- en: 'Scikit-learn provides various Python classes for classification algorithms.
    Since we have chosen the decision tree algorithm for this example, import the
    necessary classes and prepare the data in a format that the model accepts:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learnä¸ºåˆ†ç±»ç®—æ³•æä¾›äº†å„ç§Pythonç±»ã€‚ç”±äºæˆ‘ä»¬åœ¨è¿™ä¸ªä¾‹å­ä¸­é€‰æ‹©äº†å†³ç­–æ ‘ç®—æ³•ï¼Œå› æ­¤å¯¼å…¥å¿…è¦çš„ç±»å¹¶å‡†å¤‡æ¨¡å‹æ¥å—çš„æ ¼å¼åŒ–çš„æ•°æ®ï¼š
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this case, the model predicted that the 35-year-old patient would survive
    but the 78-year-old patient would not survive based on the training data provided.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ ¹æ®æä¾›çš„è®­ç»ƒæ•°æ®é¢„æµ‹ï¼Œ35å²çš„æ‚£è€…ä¼šå­˜æ´»ï¼Œè€Œ78å²çš„æ‚£è€…ä¸ä¼šå­˜æ´»ã€‚
- en: 'To understand more about decision trees and how the trees are split, letâ€™s
    look at the following line of code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è¦äº†è§£å†³ç­–æ ‘åŠå…¶åˆ†è£‚æ–¹å¼ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä»¥ä¸‹ä»£ç è¡Œï¼š
- en: '[PRE4]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will plot the tree based on the input features and how the tree is split.
    This is useful when more features are in the training data and we need to know
    which feature has more importance:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†åŸºäºè¾“å…¥ç‰¹å¾å’Œæ ‘çš„åˆ†è£‚æ–¹å¼ç»˜åˆ¶æ ‘ã€‚å½“è®­ç»ƒæ•°æ®ä¸­æœ‰æ›´å¤šç‰¹å¾ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å“ªä¸ªç‰¹å¾æ›´é‡è¦æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ï¼š
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Figure 2.2 - Visualizing tree splitting](img/B16573_02_02.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾2.2 - æ ‘åˆ†è£‚çš„å¯è§†åŒ–](img/B16573_02_02.jpg)'
- en: Figure 2.2 - Visualizing tree splitting
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2.2 - æ ‘åˆ†è£‚çš„å¯è§†åŒ–
- en: Once the model is trained and tested, it can be persisted in a file system or
    directly used for production.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ¨¡å‹ç»è¿‡è®­ç»ƒå’Œæµ‹è¯•ï¼Œå®ƒå°±å¯ä»¥åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æŒä¹…åŒ–æˆ–ç›´æ¥ç”¨äºç”Ÿäº§ã€‚
- en: In the last example, we persisted the model in the Joblib format.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šä¸€ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨Joblibæ ¼å¼æŒä¹…åŒ–äº†æ¨¡å‹ã€‚
- en: Letâ€™s now try to persist the model with the ONNX format to learn more about
    it.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å°è¯•ä½¿ç”¨ONNXæ ¼å¼æŒä¹…åŒ–æ¨¡å‹ï¼Œä»¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚
- en: Model persistence using the ONNX format and executing the model
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ONNXæ ¼å¼æŒä¹…åŒ–æ¨¡å‹å’Œæ‰§è¡Œæ¨¡å‹
- en: '**ONNX**, short for **Open Neural Network Exchange**, is an open source format
    designed for ML and DL models. Its purpose is to facilitate the interoperability
    of models across different frameworks. It accomplishes this by providing an extensible
    computation graph model and defining a set of built-in operators and standard
    data types.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**ONNX**ï¼Œå³**å¼€æ”¾ç¥ç»ç½‘ç»œäº¤æ¢**ï¼Œæ˜¯ä¸€ä¸ªä¸ºæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹è®¾è®¡çš„å¼€æºæ ¼å¼ã€‚å…¶ç›®çš„æ˜¯ä¿ƒè¿›ä¸åŒæ¡†æ¶ä¹‹é—´æ¨¡å‹çš„äº’æ“ä½œæ€§ã€‚å®ƒé€šè¿‡æä¾›ä¸€ä¸ªå¯æ‰©å±•çš„è®¡ç®—å›¾æ¨¡å‹å¹¶å®šä¹‰ä¸€ç»„å†…ç½®è¿ç®—ç¬¦å’Œæ ‡å‡†æ•°æ®ç±»å‹æ¥å®ç°è¿™ä¸€ç‚¹ã€‚'
- en: With ONNX, ML/DL models can be easily converted to the ONNX format, allowing
    for seamless deployment, export, loading, and execution using ONNX Runtime. ONNX
    Runtime is a powerful tool that enables high-performance execution of ML models
    on either CPU or GPU. Importantly, it does not rely on dependencies on the specific
    training framework used to develop the models. By leveraging ONNX and ONNX Runtime,
    developers can ensure that their models are portable across various frameworks
    and can be efficiently executed. More details about ONNX can be found at [https://github.com/onnx/onnx](https://github.com/onnx/onnx).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ONNXï¼ŒML/DLæ¨¡å‹å¯ä»¥è½»æ¾è½¬æ¢ä¸ºONNXæ ¼å¼ï¼Œå…è®¸ä½¿ç”¨ONNX Runtimeæ— ç¼éƒ¨ç½²ã€å¯¼å‡ºã€åŠ è½½å’Œæ‰§è¡Œã€‚ONNX Runtimeæ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œå®ƒå¯ä»¥åœ¨CPUæˆ–GPUä¸Šå®ç°é«˜æ€§èƒ½çš„MLæ¨¡å‹æ‰§è¡Œã€‚é‡è¦çš„æ˜¯ï¼Œå®ƒä¸ä¾èµ–äºç”¨äºå¼€å‘æ¨¡å‹çš„ç‰¹å®šè®­ç»ƒæ¡†æ¶çš„ä¾èµ–é¡¹ã€‚é€šè¿‡åˆ©ç”¨ONNXå’ŒONNX
    Runtimeï¼Œå¼€å‘è€…å¯ä»¥ç¡®ä¿ä»–ä»¬çš„æ¨¡å‹å¯ä»¥åœ¨å„ç§æ¡†æ¶ä¹‹é—´ç§»æ¤ï¼Œå¹¶ä¸”å¯ä»¥é«˜æ•ˆåœ°æ‰§è¡Œã€‚æœ‰å…³ONNXçš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[https://github.com/onnx/onnx](https://github.com/onnx/onnx)ã€‚
- en: Converting the sklearn sample model to the ONNX format
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å°†sklearnæ ·æœ¬æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼
- en: 'Converting the model to ONNX format requires the frameworks `onnx`, `onnxruntime`,
    and `skl2onnx` for scikit-learn. Install the frameworks in the following maner:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼éœ€è¦`onnx`ã€`onnxruntime`å’Œ`skl2onnx`æ¡†æ¶ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•å®‰è£…è¿™äº›æ¡†æ¶çš„æ–¹æ³•ï¼š
- en: '[PRE6]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once the frameworks are installed, execute the following code to convert the
    model to ONNX format (the source code is in `Model_Persistence_Load_ONNX_Format.ipynb`):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æ¡†æ¶å®‰è£…å®Œæˆåï¼Œæ‰§è¡Œä»¥ä¸‹ä»£ç å°†æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼ï¼ˆæºä»£ç ä½äº`Model_Persistence_Load_ONNX_Format.ipynb`ï¼‰ï¼š
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In this case, to convert the ML model that was developed using `sklearn` to
    ONNX format, first, the data types used in the training need to be provided:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ­¤æƒ…å†µä¸‹ï¼Œè¦å°†ä½¿ç”¨`sklearn`å¼€å‘çš„MLæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼ï¼Œé¦–å…ˆéœ€è¦æä¾›è®­ç»ƒä¸­ä½¿ç”¨çš„æ•°æ®ç±»å‹ï¼š
- en: '[PRE8]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Later, use the methods provided to convert the model to ONNX format and specify
    the classifier that is used in `sklearn`. In our examples, we have used decision
    trees and named the model `clf`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œä½¿ç”¨æä¾›çš„æ–¹æ³•å°†æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼ï¼Œå¹¶æŒ‡å®šåœ¨`sklearn`ä¸­ä½¿ç”¨çš„åˆ†ç±»å™¨ã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å†³ç­–æ ‘ï¼Œå¹¶å°†æ¨¡å‹å‘½åä¸º`clf`ï¼š
- en: '[PRE9]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once the model is converted to ONNX format, store it in the disk and name the
    model file (in our example, `survive.onnx`):'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼ï¼Œå°†å…¶å­˜å‚¨åœ¨ç£ç›˜ä¸Šï¼Œå¹¶å‘½åæ¨¡å‹æ–‡ä»¶ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œä¸º`survive.onnx`ï¼‰ï¼š
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now the model is stored in ONNX format and it can be loaded and executed on
    any framework that supports ONNX Runtime.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¨¡å‹å·²å­˜å‚¨ä¸ºONNXæ ¼å¼ï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ”¯æŒONNX Runtimeçš„ä»»ä½•æ¡†æ¶ä¸ŠåŠ è½½å’Œæ‰§è¡Œã€‚
- en: Loading the ML model using ONNX format and executing the model
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ONNXæ ¼å¼åŠ è½½MLæ¨¡å‹å¹¶æ‰§è¡Œæ¨¡å‹
- en: 'The following lines of code show how to load the model stored in ONNX format
    and how to use the model for inference. ONNX version 1.14.1 is used in this code
    (the source code is in `Model_Persistence_Load_ONNX_Format.ipynb`):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä»£ç è¡Œå±•ç¤ºäº†å¦‚ä½•åŠ è½½å­˜å‚¨åœ¨ONNXæ ¼å¼çš„æ¨¡å‹ä»¥åŠå¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚æœ¬ä»£ç ä½¿ç”¨ONNXç‰ˆæœ¬1.14.1ï¼ˆæºä»£ç ä½äº`Model_Persistence_Load_ONNX_Format.ipynb`ï¼‰ï¼š
- en: '[PRE11]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Unsupervised ML
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ— ç›‘ç£æœºå™¨å­¦ä¹ 
- en: In unsupervised ML, the model is trained using unlabeled training data, which
    means there are no target labels or classes provided. Instead, unsupervised ML
    models focus on understanding the inherent patterns and structures within the
    data. Unlike supervised learning, where the model learns from labeled examples,
    unsupervised machine learning models uncover hidden patterns and relationships
    within the data without any predefined class labels. This allows for the discovery
    of previously unknown insights and patterns that may not be readily apparent.
    By leveraging unsupervised ML techniques, analysts and data scientists can gain
    valuable insights from unlabeled data, uncover hidden structures, and make data-driven
    decisions based on the inherent patterns discovered in the dataset.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ— ç›‘ç£æœºå™¨å­¦ä¹ ä¸­ï¼Œæ¨¡å‹ä½¿ç”¨æœªæ ‡è®°çš„è®­ç»ƒæ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¿™æ„å‘³ç€æ²¡æœ‰æä¾›ç›®æ ‡æ ‡ç­¾æˆ–ç±»åˆ«ã€‚ç›¸åï¼Œæ— ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹ä¸“æ³¨äºç†è§£æ•°æ®ä¸­çš„å†…åœ¨æ¨¡å¼å’Œç»“æ„ã€‚ä¸ç›‘ç£å­¦ä¹ ä¸åŒï¼Œç›‘ç£å­¦ä¹ ä¸­çš„æ¨¡å‹ä»æ ‡è®°çš„ç¤ºä¾‹ä¸­å­¦ä¹ ï¼Œæ— ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æ²¡æœ‰ä»»ä½•é¢„å®šä¹‰çš„ç±»åˆ«æ ‡ç­¾çš„æƒ…å†µä¸‹æ­ç¤ºæ•°æ®ä¸­çš„éšè—æ¨¡å¼å’Œå…³ç³»ã€‚è¿™å…è®¸å‘ç°ä»¥å‰æœªçŸ¥çš„è§è§£å’Œæ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼å¯èƒ½å¹¶ä¸æ˜æ˜¾ã€‚é€šè¿‡åˆ©ç”¨æ— ç›‘ç£æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œåˆ†æå¸ˆå’Œæ•°æ®ç§‘å­¦å®¶å¯ä»¥ä»æœªæ ‡è®°çš„æ•°æ®ä¸­è·å¾—æœ‰ä»·å€¼çš„è§è§£ï¼Œæ­ç¤ºéšè—çš„ç»“æ„ï¼Œå¹¶æ ¹æ®æ•°æ®é›†ä¸­å‘ç°çš„å†…åœ¨æ¨¡å¼åšå‡ºæ•°æ®é©±åŠ¨çš„å†³ç­–ã€‚
- en: Clustering
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: èšç±»
- en: Clustering is a primary technique used in unsupervised ML. It involves grouping
    similar data points together based on their intrinsic characteristics. By examining
    the data and identifying similarities, unsupervised models create clusters, which
    represent distinct groups or patterns within the dataset.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»æ˜¯ç”¨äºæ— ç›‘ç£æœºå™¨å­¦ä¹ çš„ä¸»è¦æŠ€æœ¯ã€‚å®ƒæ¶‰åŠæ ¹æ®æ•°æ®ç‚¹çš„å†…åœ¨ç‰¹å¾å°†ç›¸ä¼¼çš„æ•°æ®ç‚¹åˆ†ç»„åœ¨ä¸€èµ·ã€‚é€šè¿‡æ£€æŸ¥æ•°æ®å’Œè¯†åˆ«ç›¸ä¼¼æ€§ï¼Œæ— ç›‘ç£æ¨¡å‹åˆ›å»ºèšç±»ï¼Œè¿™äº›èšç±»ä»£è¡¨äº†æ•°æ®é›†ä¸­çš„ä¸åŒç»„æˆ–æ¨¡å¼ã€‚
- en: Clustering algorithms, such as k-means clustering, hierarchical clustering,
    or density-based clustering, are commonly employed in unsupervised ML to organize
    data into meaningful groups. These clusters can help in data exploration, anomaly
    detection, customer segmentation, and other data-driven tasks.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»ç®—æ³•ï¼Œå¦‚ k-means èšç±»ã€å±‚æ¬¡èšç±»æˆ–åŸºäºå¯†åº¦çš„èšç±»ï¼Œåœ¨æ— ç›‘ç£æœºå™¨å­¦ä¹ ä¸­å¸¸ç”¨äºå°†æ•°æ®ç»„ç»‡æˆæœ‰æ„ä¹‰çš„ç»„ã€‚è¿™äº›ç°‡æœ‰åŠ©äºæ•°æ®æ¢ç´¢ã€å¼‚å¸¸æ£€æµ‹ã€å®¢æˆ·ç»†åˆ†å’Œå…¶ä»–æ•°æ®é©±åŠ¨ä»»åŠ¡ã€‚
- en: Clustering example
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: èšç±»ç¤ºä¾‹
- en: Letâ€™s consider a scenario where a company aims to offer transportation services
    to its employees and wants to cluster them based on their residential locations.
    To achieve this, the company can utilize a clustering model that takes the longitude
    and latitude coordinates of each employeeâ€™s residence as input data. The ML model
    will cluster the employees based on the specified cluster size, which can be equal
    to the number of vehicles available for transportation. By analyzing the spatial
    data of employeesâ€™ locations, the clustering model will group individuals who
    live in close proximity to one another. This grouping enables the company to efficiently
    allocate vehicles to each cluster.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªå…¬å¸æ—¨åœ¨ä¸ºå…¶å‘˜å·¥æä¾›è¿è¾“æœåŠ¡ï¼Œå¹¶å¸Œæœ›æ ¹æ®ä»–ä»¬çš„å±…ä½åœ°å¯¹ä»–ä»¬è¿›è¡Œèšç±»çš„åœºæ™¯ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œå…¬å¸å¯ä»¥åˆ©ç”¨ä¸€ä¸ªèšç±»æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»¥æ¯ä¸ªå‘˜å·¥å±…ä½åœ°çš„ç»çº¬åº¦åæ ‡ä½œä¸ºè¾“å…¥æ•°æ®ã€‚æœºå™¨å­¦ä¹ æ¨¡å‹å°†æ ¹æ®æŒ‡å®šçš„ç°‡å¤§å°å¯¹å‘˜å·¥è¿›è¡Œèšç±»ï¼Œç°‡å¤§å°å¯ä»¥ç­‰äºå¯ç”¨äºè¿è¾“çš„è½¦è¾†æ•°é‡ã€‚é€šè¿‡åˆ†æå‘˜å·¥çš„åœ°ç†ä½ç½®ç©ºé—´æ•°æ®ï¼Œèšç±»æ¨¡å‹å°†æŠŠå±…ä½åœ°ç›¸è¿‘çš„ä¸ªäººåˆ†ç»„ã€‚è¿™ç§åˆ†ç»„ä½¿å…¬å¸èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†è½¦è¾†åˆ†é…åˆ°æ¯ä¸ªç°‡ã€‚
- en: Once the clustering model is trained and established, it can predict the appropriate
    cluster for new employees based on their residential coordinates. This allows
    the company to easily determine which cluster the new employee should join, facilitating
    seamless transportation arrangements.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦èšç±»æ¨¡å‹è®­ç»ƒå¹¶å»ºç«‹ï¼Œå®ƒå¯ä»¥æ ¹æ®æ–°å‘˜å·¥çš„å±…ä½åæ ‡é¢„æµ‹ä»–ä»¬é€‚å½“çš„ç°‡ã€‚è¿™ä½¿å¾—å…¬å¸å¯ä»¥è½»æ¾åœ°ç¡®å®šæ–°å‘˜å·¥åº”åŠ å…¥å“ªä¸ªç°‡ï¼Œä»è€Œä¾¿äºæ— ç¼çš„è¿è¾“å®‰æ’ã€‚
- en: By utilizing ML clustering techniques in this scenario, the company can effectively
    organize its transportation services and optimize resource allocation based on
    employeesâ€™ residential locations.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åœ¨è¿™ä¸ªåœºæ™¯ä¸­åˆ©ç”¨æœºå™¨å­¦ä¹ èšç±»æŠ€æœ¯ï¼Œå…¬å¸å¯ä»¥æœ‰æ•ˆåœ°ç»„ç»‡å…¶è¿è¾“æœåŠ¡ï¼Œå¹¶æ ¹æ®å‘˜å·¥çš„å±…ä½åœ°ä¼˜åŒ–èµ„æºé…ç½®ã€‚
- en: '| **Employee number** | **Latitude (****o N)** | **Longitude (****o E)** |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| **å‘˜å·¥ç¼–å·** | **çº¬åº¦ï¼ˆ****åŒ—çº¬ï¼‰** | **ç»åº¦ï¼ˆ****ä¸œç»ï¼‰** |'
- en: '| --- | --- | --- |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | 12.93 | 77.4472 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 12.93 | 77.4472 |'
- en: '| 2 | 12.32 | 77.4472 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 12.32 | 77.4472 |'
- en: '| 3 | 12.51 | 77.4472 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 12.51 | 77.4472 |'
- en: '| 4 | 12.62 | 77.4472 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 12.62 | 77.4472 |'
- en: '| 5 | 12.73 | 77.4472 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 12.73 | 77.4472 |'
- en: '| 6 | 12.84 | 76.4158 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 12.84 | 76.4158 |'
- en: '| 7 | 12.91 | 76.4158 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 12.91 | 76.4158 |'
- en: '| 8 | 12.41 | 76.4158 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 12.41 | 76.4158 |'
- en: '| 9 | 12.92 | 76.4158 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 12.92 | 76.4158 |'
- en: '| 10 | 12.55 | 76.4158 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 12.55 | 76.4158 |'
- en: Table 2.6 â€“ Toy dataset for clustering example
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨2.6 â€“ èšç±»ç¤ºä¾‹çš„ç©å…·æ•°æ®é›†
- en: The `sklearn` framework supports various clustering algorithms, and we will
    use the K-means clustering algorithm in this example to cluster the given data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn` æ¡†æ¶æ”¯æŒå„ç§èšç±»ç®—æ³•ï¼Œåœ¨æœ¬ä¾‹ä¸­æˆ‘ä»¬å°†ä½¿ç”¨ K-means èšç±»ç®—æ³•å¯¹ç»™å®šæ•°æ®è¿›è¡Œèšç±»ã€‚'
- en: The K-means algorithm is a centroid-based algorithm, where each cluster is associated
    with a centroid. The main aim of this algorithm is to minimize the sum of distances
    between the input data point and their corresponding cluster.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: K-means ç®—æ³•æ˜¯ä¸€ç§åŸºäºè´¨å¿ƒçš„ç®—æ³•ï¼Œå…¶ä¸­æ¯ä¸ªç°‡éƒ½ä¸ä¸€ä¸ªè´¨å¿ƒç›¸å…³è”ã€‚è¯¥ç®—æ³•çš„ä¸»è¦ç›®çš„æ˜¯æœ€å°åŒ–è¾“å…¥æ•°æ®ç‚¹ä¸å…¶å¯¹åº”ç°‡ä¹‹é—´çš„è·ç¦»ä¹‹å’Œã€‚
- en: The source code is in `Clustering_Example.ipynb`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: æºä»£ç ä½äº `Clustering_Example.ipynb`ã€‚
- en: 'Import the `sklearn` K-means clustering classes and prepare the training data
    as a `numpy` array format:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼å…¥ `sklearn` K-means èšç±»ç±»ï¼Œå¹¶å°†è®­ç»ƒæ•°æ®å‡†å¤‡ä¸º `numpy` æ•°ç»„æ ¼å¼ï¼š
- en: '[PRE12]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In this case, the first five employees are assigned to cluster `1` and the
    remaining are assigned to cluster `0`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå‰äº”ä¸ªå‘˜å·¥è¢«åˆ†é…åˆ°ç°‡ `1`ï¼Œå…¶ä½™çš„åˆ†é…åˆ°ç°‡ `0`ï¼š
- en: '| Employee number | Latitude (o N) | Longitude (o E) | Assigned cluster |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| å‘˜å·¥ç¼–å· | çº¬åº¦ï¼ˆåŒ—çº¬ï¼‰ | ç»åº¦ï¼ˆä¸œç»ï¼‰ | åˆ†é…çš„ç°‡ |'
- en: '| 1 | 12.93 | 77.4472 | 1 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 12.93 | 77.4472 | 1 |'
- en: '| 2 | 12.32 | 77.4472 | 1 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 12.32 | 77.4472 | 1 |'
- en: '| 3 | 12.51 | 77.4472 | 1 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 12.51 | 77.4472 | 1 |'
- en: '| 4 | 12.62 | 77.4472 | 1 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 12.62 | 77.4472 | 1 |'
- en: '| 5 | 12.73 | 77.4472 | 1 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 12.73 | 77.4472 | 1 |'
- en: '| 6 | 12.84 | 76.4158 | 0 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 12.84 | 76.4158 | 0 |'
- en: '| 7 | 12.91 | 76.4158 | 0 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 12.91 | 76.4158 | 0 |'
- en: '| 8 | 12.41 | 76.4158 | 0 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 12.41 | 76.4158 | 0 |'
- en: '| 9 | 12.92 | 76.4158 | 0 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 12.92 | 76.4158 | 0 |'
- en: '| 10 | 12.55 | 76.4158 | 0 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 12.55 | 76.4158 | 0 |'
- en: Table 2.7 - Assigned cluster
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨2.7 - åˆ†é…çš„ç°‡
- en: The cluster model learned based on the input and formed two clusters. K-means
    is a clustering algorithm that finds the center of the cluster, divides the data
    into clusters, and predicts the new data based on the nearest cluster.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºè¾“å…¥å­¦ä¹ å¹¶å½¢æˆçš„èšç±»æ¨¡å‹åˆ†ä¸ºä¸¤ä¸ªç°‡ã€‚K-meansæ˜¯ä¸€ç§èšç±»ç®—æ³•ï¼Œå®ƒæ‰¾åˆ°ç°‡çš„ä¸­å¿ƒï¼Œå°†æ•°æ®åˆ’åˆ†ä¸ºç°‡ï¼Œå¹¶æ ¹æ®æœ€è¿‘çš„ç°‡é¢„æµ‹æ–°æ•°æ®ã€‚
- en: 'The following is the list of clustering algorithms supported by the `sklearn`
    framework:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ç”±`sklearn`æ¡†æ¶æ”¯æŒçš„èšç±»ç®—æ³•åˆ—è¡¨ï¼š
- en: Affinity propagation
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸ä¼¼æ€§ä¼ æ’­
- en: Agglomerative clustering
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: èšç±»
- en: BIRCH
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BIRCH
- en: DBSCAN
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DBSCAN
- en: K-means
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-means
- en: Mini-batch K-means
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mini-batch K-means
- en: Mean shift
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡å€¼æ¼‚ç§»
- en: OPTICS
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OPTICS
- en: Spectral clustering
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è°±èšç±»
- en: Mixture of Gaussians
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é«˜æ–¯æ··åˆæ¨¡å‹
- en: Reinforced ML
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¼ºåŒ–æœºå™¨å­¦ä¹ 
- en: '**Reinforcement learning** (**RL**) is a type of ML technique that enables
    an agent to learn in an interactive environment by trial and error using feedback
    from its own actions and experiences. The agent learns a series of actions that
    lead to the final goal, maximizing its total rewards. RL differs from supervised
    learning in that the model learns from taking actions and observing the results,
    not from explicit teaching.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¼ºåŒ–å­¦ä¹ **ï¼ˆ**RL**ï¼‰æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œå®ƒä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé€šè¿‡å°è¯•é”™è¯¯ï¼Œåˆ©ç”¨è‡ªèº«è¡ŒåŠ¨å’Œç»éªŒä¸­çš„åé¦ˆåœ¨äº¤äº’å¼ç¯å¢ƒä¸­å­¦ä¹ ã€‚æ™ºèƒ½ä½“å­¦ä¹ ä¸€ç³»åˆ—å¯¼è‡´æœ€ç»ˆç›®æ ‡çš„è¡ŒåŠ¨ï¼Œæœ€å¤§åŒ–å…¶æ€»å¥–åŠ±ã€‚RLä¸ç›‘ç£å­¦ä¹ ä¸åŒï¼Œå› ä¸ºæ¨¡å‹æ˜¯ä»é‡‡å–è¡ŒåŠ¨å’Œè§‚å¯Ÿç»“æœä¸­å­¦ä¹ ï¼Œè€Œä¸æ˜¯ä»æ˜ç¡®çš„æ•™å­¦ä¸­å­¦ä¹ ã€‚'
- en: One classic use case of RL is in gaming, such as teaching a model to play and
    excel at chess. The model starts with no knowledge of the game but learns by making
    moves and seeing the outcome of the game it plays, with the aim of maximizing
    the reward (i.e., winning the game).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ çš„ä¸€ä¸ªç»å…¸ç”¨ä¾‹æ˜¯åœ¨æ¸¸æˆé¢†åŸŸï¼Œä¾‹å¦‚æ•™æ¨¡å‹ä¸‹æ£‹å¹¶å–å¾—ä¼˜å¼‚æˆç»©ã€‚æ¨¡å‹å¼€å§‹æ—¶å¯¹æ¸¸æˆä¸€æ— æ‰€çŸ¥ï¼Œä½†é€šè¿‡ç§»åŠ¨å’Œè§‚å¯Ÿæ‰€ç©æ¸¸æˆçš„ç»“æœæ¥å­¦ä¹ ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–å¥–åŠ±ï¼ˆå³èµ¢å¾—æ¸¸æˆï¼‰ã€‚
- en: 'In the context of RL, exploration and exploitation are two strategies that
    an agent can use to navigate through the environment:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼ºåŒ–å­¦ä¹ çš„èƒŒæ™¯ä¸‹ï¼Œæ¢ç´¢å’Œåˆ©ç”¨æ˜¯æ™ºèƒ½ä½“å¯ä»¥ç”¨æ¥åœ¨ç¯å¢ƒä¸­å¯¼èˆªçš„ä¸¤ä¸ªç­–ç•¥ï¼š
- en: '**Exploration**: This is when the agent seeks to learn more about its environment.
    It means trying out different actions and gathering more information to learn
    about each possible actionâ€™s reward. The agent aims to balance out the reward
    it gets from known information with the possibility of receiving an even higher
    reward from unknown areas. However, exploration might involve the risk of the
    agent making non-optimal choices.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¢ç´¢**ï¼šè¿™æ˜¯æ™ºèƒ½ä½“è¯•å›¾äº†è§£æ›´å¤šå…³äºå…¶ç¯å¢ƒçš„æ—¶å€™ã€‚è¿™æ„å‘³ç€å°è¯•ä¸åŒçš„è¡ŒåŠ¨å¹¶æ”¶é›†æ›´å¤šä¿¡æ¯ï¼Œä»¥äº†è§£æ¯ä¸ªå¯èƒ½è¡ŒåŠ¨çš„å¥–åŠ±ã€‚æ™ºèƒ½ä½“çš„ç›®æ ‡æ˜¯å¹³è¡¡ä»å·²çŸ¥ä¿¡æ¯ä¸­è·å¾—çš„å¥–åŠ±ä¸ä»æœªçŸ¥åŒºåŸŸè·å¾—æ›´é«˜å¥–åŠ±çš„å¯èƒ½æ€§ã€‚ç„¶è€Œï¼Œæ¢ç´¢å¯èƒ½æ¶‰åŠæ™ºèƒ½ä½“åšå‡ºéæœ€ä¼˜é€‰æ‹©çš„é£é™©ã€‚'
- en: '**Exploitation**: Here, the agent uses the information it has already learned
    to make the best action that will maximize its reward. It means using known information
    to maximize success instead of further exploring. The benefit of exploitation
    is that it allows for more assured, immediate rewards, but excessive exploitation
    can lead to suboptimal results as it may neglect even better options. The challenge
    lies in finding the right balance, as focusing too much on exploration might mean
    the agent will lose out on immediate rewards while focusing extensively on exploitation
    might prevent the agent from exploring options that could lead to larger rewards
    in the future. This trade-off is often referred to as the explorationâ€“exploitation
    dilemma.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åˆ©ç”¨**ï¼šåœ¨è¿™é‡Œï¼Œæ™ºèƒ½ä½“ä½¿ç”¨å®ƒå·²ç»å­¦ä¹ åˆ°çš„ä¿¡æ¯æ¥é‡‡å–æœ€ä½³è¡ŒåŠ¨ï¼Œä»¥æœ€å¤§åŒ–å…¶å¥–åŠ±ã€‚è¿™æ„å‘³ç€ä½¿ç”¨å·²çŸ¥ä¿¡æ¯æ¥æœ€å¤§åŒ–æˆåŠŸï¼Œè€Œä¸æ˜¯è¿›ä¸€æ­¥æ¢ç´¢ã€‚åˆ©ç”¨çš„å¥½å¤„æ˜¯å®ƒå…è®¸è·å¾—æ›´ç¡®å®šã€å³æ—¶çš„å¥–åŠ±ï¼Œä½†è¿‡åº¦åˆ©ç”¨å¯èƒ½å¯¼è‡´æ¬¡ä¼˜ç»“æœï¼Œå› ä¸ºå®ƒå¯èƒ½å¿½ç•¥äº†æ›´å¥½çš„é€‰é¡¹ã€‚æŒ‘æˆ˜åœ¨äºæ‰¾åˆ°æ­£ç¡®çš„å¹³è¡¡ï¼Œå› ä¸ºè¿‡åˆ†å…³æ³¨æ¢ç´¢å¯èƒ½æ„å‘³ç€æ™ºèƒ½ä½“ä¼šå¤±å»å³æ—¶å¥–åŠ±ï¼Œè€Œè¿‡åˆ†å…³æ³¨åˆ©ç”¨å¯èƒ½é˜»æ­¢æ™ºèƒ½ä½“æ¢ç´¢å¯èƒ½å¯¼è‡´æœªæ¥æ›´å¤§å¥–åŠ±çš„é€‰é¡¹ã€‚è¿™ç§æƒè¡¡é€šå¸¸è¢«ç§°ä¸ºæ¢ç´¢-åˆ©ç”¨å›°å¢ƒã€‚'
- en: Example problem using RLâ€”the multi-armed bandit problem
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨RLçš„ç¤ºä¾‹é—®é¢˜â€”â€”å¤šè‡‚è€è™æœºé—®é¢˜
- en: The multi-armed bandit problem is a classic problem in the field of RL that
    captures the fundamental trade-off between exploration and exploitation. The name
    is derived from a hypothetical experiment in which you face several slot machines
    (also known as â€œone-armed banditsâ€) with different fixed payouts. Because of these
    differing payouts, your goal is to maximize your total payout over a certain number
    of attempts by figuring out which machines to play, how many times to play each
    machine, and in what sequenceâ€”hence, the â€œmulti-armed bandit problem.â€
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šè‡‚è€è™æœºé—®é¢˜æ˜¯å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„ä¸€ä¸ªç»å…¸é—®é¢˜ï¼Œå®ƒæ•æ‰äº†æ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´çš„åŸºæœ¬æƒè¡¡ã€‚è¿™ä¸ªåå­—æ¥æºäºä¸€ä¸ªå‡è®¾çš„å®éªŒï¼Œåœ¨è¿™ä¸ªå®éªŒä¸­ï¼Œä½ é¢å¯¹å‡ ä¸ªå…·æœ‰ä¸åŒå›ºå®šæ”¶ç›Šçš„è€è™æœºï¼ˆä¹Ÿç§°ä¸ºâ€œå•è‡‚è€è™æœºâ€ï¼‰ã€‚ç”±äºè¿™äº›ä¸åŒçš„æ”¶ç›Šï¼Œä½ çš„ç›®æ ‡æ˜¯é€šè¿‡å¯¹å“ªäº›æœºå™¨è¿›è¡Œæ¸¸æˆã€æ¯æ¬¡ç©å¤šå°‘æ¬¡ä»¥åŠä»¥ä½•ç§é¡ºåºè¿›è¡Œæ¸¸æˆæ¥æœ€å¤§åŒ–åœ¨ä¸€å®šæ¬¡æ•°å°è¯•ä¸­çš„æ€»æ”¶ç›Šâ€”â€”å› æ­¤ï¼Œè¿™å°±æ˜¯â€œå¤šè‡‚è€è™æœºé—®é¢˜â€ã€‚
- en: The primary challenge in the multi-armed bandit problem is balancing the immediate
    rewards from exploitative actions (playing the machine that you believe currently
    has the highest expected payout) with the possible benefits from exploration (trying
    out others that might have higher expected payouts but youâ€™re less certain about).
    This tension between exploration and exploitation is at the core of many reinforcement
    learning problems.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šè‡‚è€è™æœºé—®é¢˜çš„ä¸»è¦æŒ‘æˆ˜åœ¨äºå¹³è¡¡æ¥è‡ªåˆ©ç”¨æ€§åŠ¨ä½œï¼ˆç©ä½ è®¤ä¸ºå½“å‰å…·æœ‰æœ€é«˜é¢„æœŸæ”¶ç›Šç‡çš„æœºå™¨ï¼‰çš„å³æ—¶å¥–åŠ±ä¸æ¥è‡ªæ¢ç´¢ï¼ˆå°è¯•å…¶ä»–å¯èƒ½å…·æœ‰æ›´é«˜é¢„æœŸæ”¶ç›Šä½†ä¸å¤ªç¡®å®šçš„æœºå™¨ï¼‰çš„æ½œåœ¨æ”¶ç›Šã€‚è¿™ç§æ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´çš„ç´§å¼ å…³ç³»æ˜¯è®¸å¤šå¼ºåŒ–å­¦ä¹ é—®é¢˜çš„æ ¸å¿ƒã€‚
- en: 'The following is example code for reinforcement learningâ€”the source code is
    in `BandIt_RL_Example.ipynb`:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä¸ºå¼ºåŒ–å­¦ä¹ çš„ç¤ºä¾‹ä»£ç â€”â€”æºä»£ç ä½äº`BandIt_RL_Example.ipynb`ä¸­ï¼š
- en: '[PRE13]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this example, the epsilon-greedy strategy is used, where epsilon is `1`.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ä¾‹ä¸­ï¼Œä½¿ç”¨äº†Îµ-è´ªå©ªç­–ç•¥ï¼Œå…¶ä¸­Îµä¸º`1`ã€‚
- en: This is a very simplistic example and real-world RL problems require much more
    sophisticated algorithms (e.g., Q-learning, policy gradient, etc.) and are therefore
    implemented using specialized libraries.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ä¾‹å­ï¼Œè€Œç°å®ä¸–ç•Œçš„å¼ºåŒ–å­¦ä¹ é—®é¢˜éœ€è¦æ›´å¤æ‚çš„ç®—æ³•ï¼ˆä¾‹å¦‚Qå­¦ä¹ ã€ç­–ç•¥æ¢¯åº¦ç­‰ï¼‰ï¼Œå› æ­¤ä½¿ç”¨ä¸“é—¨çš„åº“æ¥å®ç°ã€‚
- en: In this section, we have covered the different types of ML and provided examples
    of how to save and load models for inference and prediction. Moving forward, the
    next section will delve into the various phases of ML, providing a detailed exploration.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸åŒç±»å‹çš„æœºå™¨å­¦ä¹ ï¼Œå¹¶æä¾›äº†å¦‚ä½•ä¿å­˜å’ŒåŠ è½½æ¨¡å‹ä»¥è¿›è¡Œæ¨ç†å’Œé¢„æµ‹çš„ç¤ºä¾‹ã€‚æ¥ä¸‹æ¥ï¼Œä¸‹ä¸€èŠ‚å°†æ·±å…¥æ¢è®¨æœºå™¨å­¦ä¹ çš„å„ä¸ªé˜¶æ®µï¼Œæä¾›è¯¦ç»†çš„æ¢ç´¢ã€‚
- en: Overview of ML phases
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ é˜¶æ®µæ¦‚è¿°
- en: ML encompasses a variety of techniques and approaches, and it involves several
    distinct phases or stages in the process of developing and deploying ML models.
    These phases help guide engineers through the iterative and cyclical nature of
    ML projects, allowing them to build effective and accurate models.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ åŒ…å«å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œå®ƒæ¶‰åŠåœ¨å¼€å‘å’Œéƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹è¿‡ç¨‹ä¸­çš„å‡ ä¸ªä¸åŒçš„é˜¶æ®µæˆ–é˜¶æ®µã€‚è¿™äº›é˜¶æ®µæœ‰åŠ©äºæŒ‡å¯¼å·¥ç¨‹å¸ˆé€šè¿‡æœºå™¨å­¦ä¹ é¡¹ç›®çš„è¿­ä»£å’Œå¾ªç¯æ€§è´¨ï¼Œä½¿ä»–ä»¬èƒ½å¤Ÿæ„å»ºæœ‰æ•ˆä¸”å‡†ç¡®çš„æ¨¡å‹ã€‚
- en: The ML process typically consists of several key phases, each serving a specific
    purpose and contributing to the overall success of the project. These phases are
    not always strictly linear, and iterations may occur between them to refine and
    improve the models. The specific steps and terminology used may vary depending
    on the ML methodology employed, but the core phases remain consistent.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ è¿‡ç¨‹é€šå¸¸åŒ…æ‹¬å‡ ä¸ªå…³é”®é˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœåŠ¡äºç‰¹å®šç›®çš„ï¼Œå¹¶æœ‰åŠ©äºé¡¹ç›®çš„æ•´ä½“æˆåŠŸã€‚è¿™äº›é˜¶æ®µå¹¶ä¸æ€»æ˜¯ä¸¥æ ¼çº¿æ€§ï¼Œå®ƒä»¬ä¹‹é—´å¯èƒ½å‘ç”Ÿè¿­ä»£ï¼Œä»¥ç²¾ç‚¼å’Œæ”¹è¿›æ¨¡å‹ã€‚å…·ä½“æ­¥éª¤å’Œæœ¯è¯­çš„ä½¿ç”¨å¯èƒ½å› é‡‡ç”¨çš„æœºå™¨å­¦ä¹ æ–¹æ³•è€Œå¼‚ï¼Œä½†æ ¸å¿ƒé˜¶æ®µä¿æŒä¸€è‡´ã€‚
- en: The ML phases provide a systematic framework for developing and deploying ML
    models, guiding practitioners through the complexities and challenges inherent
    in building effective solutions. By following these phases, practitioners can
    maximize their chances of success and create ML models that deliver valuable insights
    and predictions in a wide range of applications.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ é˜¶æ®µæä¾›äº†ä¸€ä¸ªç³»ç»Ÿæ¡†æ¶ï¼Œç”¨äºå¼€å‘å’Œéƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ŒæŒ‡å¯¼å®è·µè€…é€šè¿‡æ„å»ºæœ‰æ•ˆè§£å†³æ–¹æ¡ˆå›ºæœ‰çš„å¤æ‚æ€§å’ŒæŒ‘æˆ˜ã€‚é€šè¿‡éµå¾ªè¿™äº›é˜¶æ®µï¼Œå®è·µè€…å¯ä»¥æœ€å¤§åŒ–æˆåŠŸçš„æœºä¼šï¼Œå¹¶åˆ›å»ºèƒ½å¤Ÿåœ¨å¹¿æ³›åº”ç”¨ä¸­æä¾›æœ‰ä»·å€¼å’Œé¢„æµ‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚
- en: The main phases of ML
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ çš„ä¸»è¦é˜¶æ®µ
- en: 'The following are the main phases of ML:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä¸ºæœºå™¨å­¦ä¹ çš„ä¸»è¦é˜¶æ®µï¼š
- en: '**Data collection**: This phase involves gathering relevant data from various
    sources, such as databases, APIs, or manual collection. The data should be representative
    of the problem domain and cover a wide range of scenarios.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ•°æ®æ”¶é›†**ï¼šè¿™ä¸ªé˜¶æ®µæ¶‰åŠä»å„ç§æ¥æºæ”¶é›†ç›¸å…³æ•°æ®ï¼Œä¾‹å¦‚æ•°æ®åº“ã€APIæˆ–æ‰‹åŠ¨æ”¶é›†ã€‚æ•°æ®åº”ä»£è¡¨é—®é¢˜åŸŸï¼Œå¹¶æ¶µç›–å¹¿æ³›çš„åœºæ™¯ã€‚'
- en: '**Data preparation**: In this phase, the collected data is preprocessed and
    transformed into a suitable format for analysis. This may include tasks such as
    cleaning the data, handling missing values, removing outliers, and normalizing
    or scaling the features.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ•°æ®å‡†å¤‡**ï¼šåœ¨è¿™ä¸ªé˜¶æ®µï¼Œæ”¶é›†åˆ°çš„æ•°æ®è¢«é¢„å¤„ç†å¹¶è½¬æ¢ä¸ºé€‚åˆåˆ†æçš„å½¢å¼ã€‚è¿™å¯èƒ½åŒ…æ‹¬è¯¸å¦‚æ¸…ç†æ•°æ®ã€å¤„ç†ç¼ºå¤±å€¼ã€å»é™¤å¼‚å¸¸å€¼ä»¥åŠå½’ä¸€åŒ–æˆ–ç¼©æ”¾ç‰¹å¾ç­‰ä»»åŠ¡ã€‚'
- en: '**Feature engineering**: Feature engineering involves selecting and creating
    relevant features from the available data that will enhance the modelâ€™s predictive
    power. This phase requires domain knowledge and creativity to extract meaningful
    insights from the data.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾å·¥ç¨‹**ï¼šç‰¹å¾å·¥ç¨‹æ¶‰åŠä»å¯ç”¨æ•°æ®ä¸­é€‰æ‹©å’Œåˆ›å»ºç›¸å…³ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å°†å¢å¼ºæ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ã€‚è¿™ä¸ªé˜¶æ®µéœ€è¦é¢†åŸŸçŸ¥è¯†å’Œåˆ›é€ åŠ›ï¼Œä»¥ä»æ•°æ®ä¸­æå–æœ‰æ„ä¹‰çš„è§è§£ã€‚'
- en: '**Model development**: In this phase, a suitable ML algorithm or model is selected
    based on the problem at hand. The model is trained on the prepared data to learn
    patterns and relationships within the data.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹å¼€å‘**ï¼šåœ¨è¿™ä¸ªé˜¶æ®µï¼Œæ ¹æ®æ‰‹å¤´çš„é—®é¢˜é€‰æ‹©åˆé€‚çš„æœºå™¨å­¦ä¹ ç®—æ³•æˆ–æ¨¡å‹ã€‚æ¨¡å‹åœ¨å‡†å¤‡å¥½çš„æ•°æ®ä¸Šè®­ç»ƒï¼Œä»¥å­¦ä¹ æ•°æ®ä¸­çš„æ¨¡å¼å’Œå…³ç³»ã€‚'
- en: '**Model evaluation**: The trained model is evaluated using appropriate evaluation
    metrics to assess its performance. This helps in understanding how well the model
    generalizes to unseen data and whether it meets the desired criteria for accuracy
    and reliability.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹è¯„ä¼°**ï¼šä½¿ç”¨é€‚å½“çš„è¯„ä¼°æŒ‡æ ‡å¯¹è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œä»¥è¯„ä¼°å…¶æ€§èƒ½ã€‚è¿™æœ‰åŠ©äºäº†è§£æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä»¥åŠå®ƒæ˜¯å¦æ»¡è¶³å‡†ç¡®æ€§å’Œå¯é æ€§æ–¹é¢çš„é¢„æœŸæ ‡å‡†ã€‚'
- en: '**Model optimization**: If the modelâ€™s performance is not satisfactory, this
    phase involves fine-tuning the model by adjusting hyperparameters or trying different
    algorithms to improve its performance. The optimization process aims to achieve
    the best possible results.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹ä¼˜åŒ–**ï¼šå¦‚æœæ¨¡å‹çš„æ€§èƒ½ä¸æ»¡æ„ï¼Œè¿™ä¸ªé˜¶æ®µæ¶‰åŠé€šè¿‡è°ƒæ•´è¶…å‚æ•°æˆ–å°è¯•ä¸åŒçš„ç®—æ³•æ¥å¾®è°ƒæ¨¡å‹ï¼Œä»¥æé«˜å…¶æ€§èƒ½ã€‚ä¼˜åŒ–è¿‡ç¨‹æ—¨åœ¨å®ç°æœ€ä½³å¯èƒ½çš„ç»“æœã€‚'
- en: '**Model Deployment**: Once the model is trained and optimized, it is deployed
    in a production environment where it can make predictions on new, unseen data.
    This phase involves integrating the model into existing systems or creating an
    interface for users to interact with the model.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹éƒ¨ç½²**ï¼šä¸€æ—¦æ¨¡å‹ç»è¿‡è®­ç»ƒå’Œä¼˜åŒ–ï¼Œå®ƒå°±è¢«éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¯ä»¥åœ¨æ–°çš„ã€æœªè§è¿‡çš„æ•°æ®ä¸Šè¿›è¡Œé¢„æµ‹ã€‚è¿™ä¸ªé˜¶æ®µæ¶‰åŠå°†æ¨¡å‹é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿä¸­æˆ–ä¸ºç”¨æˆ·åˆ›å»ºä¸æ¨¡å‹äº¤äº’çš„ç•Œé¢ã€‚'
- en: '**Model monitoring and maintenance**: After deployment, the model needs to
    be monitored to ensure it continues to perform well over time. Monitoring involves
    tracking performance metrics, identifying drift in data distribution, and updating
    the model if necessary. Regular maintenance is essential to keeping the model
    up to date and accurate.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹ç›‘æ§å’Œç»´æŠ¤**ï¼šéƒ¨ç½²åï¼Œéœ€è¦ç›‘æ§æ¨¡å‹ä»¥ç¡®ä¿å…¶éšç€æ—¶é—´çš„æ¨ç§»ç»§ç»­è¡¨ç°è‰¯å¥½ã€‚ç›‘æ§æ¶‰åŠè·Ÿè¸ªæ€§èƒ½æŒ‡æ ‡ã€è¯†åˆ«æ•°æ®åˆ†å¸ƒçš„æ¼‚ç§»ï¼Œå¹¶åœ¨å¿…è¦æ—¶æ›´æ–°æ¨¡å‹ã€‚å®šæœŸç»´æŠ¤å¯¹äºä¿æŒæ¨¡å‹æœ€æ–°å’Œå‡†ç¡®è‡³å…³é‡è¦ã€‚'
- en: These phases provide a systematic approach to building and deploying ML models,
    enabling organizations to leverage the power of data and make informed decisions.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›é˜¶æ®µæä¾›äº†ä¸€ä¸ªç³»ç»Ÿçš„æ–¹æ³•æ¥æ„å»ºå’Œéƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä½¿ç»„ç»‡èƒ½å¤Ÿåˆ©ç”¨æ•°æ®çš„åŠ›é‡å¹¶åšå‡ºæ˜æ™ºçš„å†³ç­–ã€‚
- en: Sub-phases in the ML process
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ è¿‡ç¨‹ä¸­çš„å­é˜¶æ®µ
- en: 'The following diagram shows the phases of the ML process:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢çš„å›¾æ˜¾ç¤ºäº†æœºå™¨å­¦ä¹ è¿‡ç¨‹çš„é˜¶æ®µï¼š
- en: '![Figure 2.3 â€“ ML phases](img/B16573_02_03.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾2.3 â€“ æœºå™¨å­¦ä¹ é˜¶æ®µ](img/B16573_02_03.jpg)'
- en: Figure 2.3 â€“ ML phases
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2.3 â€“ æœºå™¨å­¦ä¹ é˜¶æ®µ
- en: 'These are the main phases:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯ä¸»è¦é˜¶æ®µï¼š
- en: Data preparation phase
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡é˜¶æ®µ
- en: ML model phase (design and development)
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ æ¨¡å‹é˜¶æ®µï¼ˆè®¾è®¡å’Œå¼€å‘ï¼‰
- en: ML operations phase
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ æ“ä½œé˜¶æ®µ
- en: Letâ€™s look at these in more detail.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ›´è¯¦ç»†åœ°çœ‹çœ‹è¿™äº›ã€‚
- en: Data preparation phase
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡é˜¶æ®µ
- en: The data preparation phase deals with data collection, extraction, and manipulation.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡é˜¶æ®µå¤„ç†æ•°æ®æ”¶é›†ã€æå–å’Œæ“ä½œã€‚
- en: '| **Phase** | **Sub-phases** | **Details** |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| **é˜¶æ®µ** | **å­é˜¶æ®µ** | **ç»†èŠ‚** |'
- en: '| Data preparation | Data collection | Identify the data that needs to be analyzed
    |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| æ•°æ®å‡†å¤‡ | æ•°æ®æ”¶é›† | ç¡®å®šéœ€è¦åˆ†æçš„æ•°æ® |'
- en: '| Data extraction | Extract the data from the data source |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| æ•°æ®æå– | ä»æ•°æ®æºä¸­æå–æ•°æ® |'
- en: '| Data manipulation | Data transformation, missing data, duplicate data, noise,
    and data preprocessing |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| æ•°æ®æ“ä½œ | æ•°æ®è½¬æ¢ã€ç¼ºå¤±æ•°æ®ã€é‡å¤æ•°æ®ã€å™ªå£°å’Œæ•°æ®é¢„å¤„ç† |'
- en: '| **Exploratory data** **analysis** (**EDA**) | EDA and handling data |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| **æ¢ç´¢æ€§æ•°æ®åˆ†æ**ï¼ˆEDAï¼‰ | EDA å’Œæ•°æ®å¤„ç† |'
- en: Table 2.8 - Data preparation phase
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 2.8 - æ•°æ®å‡†å¤‡é˜¶æ®µ
- en: 'The following figure shows the data preparation sub-phases:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹å›¾å±•ç¤ºäº†æ•°æ®å‡†å¤‡å­é˜¶æ®µï¼š
- en: Data Preparation Phase
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡é˜¶æ®µ
- en: '![Figure 2.4 â€“ ML data preparation sub-phases](img/B16573_02_04.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.4 â€“ æœºå™¨å­¦ä¹ æ•°æ®å‡†å¤‡å­é˜¶æ®µ](img/B16573_02_04.jpg)'
- en: Figure 2.4 â€“ ML data preparation sub-phases
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2.4 â€“ æœºå™¨å­¦ä¹ æ•°æ®å‡†å¤‡å­é˜¶æ®µ
- en: ML model phase
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ æ¨¡å‹é˜¶æ®µ
- en: This phase is subdivided into several phases to deal with feature engineering,
    actual model identification, the training and testing of models, and so on.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤é˜¶æ®µè¢«ç»†åˆ†ä¸ºå‡ ä¸ªé˜¶æ®µï¼Œä»¥å¤„ç†ç‰¹å¾å·¥ç¨‹ã€å®é™…æ¨¡å‹è¯†åˆ«ã€æ¨¡å‹çš„è®­ç»ƒå’Œæµ‹è¯•ç­‰ã€‚
- en: '| **Phase** | **Sub-phases** | **Details** |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| **é˜¶æ®µ** | **å­é˜¶æ®µ** | **è¯¦ç»†ä¿¡æ¯** |'
- en: '| ML model | Model identification | This involves classification, clustering,
    re-enforcement, time series analysis, and so on. |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| æœºå™¨å­¦ä¹ æ¨¡å‹ | æ¨¡å‹è¯†åˆ« | è¿™æ¶‰åŠåˆ°åˆ†ç±»ã€èšç±»ã€å¼ºåŒ–å­¦ä¹ ã€æ—¶é—´åºåˆ—åˆ†æç­‰ã€‚|'
- en: '| Feature engineering | In this phase, features are selected from the data.
    |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| ç‰¹å¾å·¥ç¨‹ | åœ¨æ­¤é˜¶æ®µï¼Œä»æ•°æ®ä¸­é€‰æ‹©ç‰¹å¾ã€‚|'
- en: '| Input data preparation for the model | This involves data processed and data
    prepared in the format the model expects. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| ä¸ºæ¨¡å‹å‡†å¤‡è¾“å…¥æ•°æ® | è¿™æ¶‰åŠåˆ°ä»¥æ¨¡å‹æœŸæœ›çš„æ ¼å¼å¤„ç†å’Œå‡†å¤‡çš„æ•°æ®ã€‚|'
- en: '| Split the data (train, test, and validate) | Split the entire data into three
    partsâ€”training data, test data, and validation dataâ€”to train, test, and validate
    the models. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| åˆ†å‰²æ•°æ®ï¼ˆè®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯ï¼‰ | å°†æ•´ä¸ªæ•°æ®åˆ†å‰²æˆä¸‰ä¸ªéƒ¨åˆ†â€”â€”è®­ç»ƒæ•°æ®ã€æµ‹è¯•æ•°æ®å’ŒéªŒè¯æ•°æ®ï¼Œä»¥è®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯æ¨¡å‹ã€‚|'
- en: '| Train the model with the training dataset | In this phase, the model is trained
    with the training data. |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| ä½¿ç”¨è®­ç»ƒæ•°æ®é›†è®­ç»ƒæ¨¡å‹ | åœ¨æ­¤é˜¶æ®µï¼Œæ¨¡å‹ä½¿ç”¨è®­ç»ƒæ•°æ®è¿›è¡Œè®­ç»ƒã€‚|'
- en: '| Test the model with the testing dataset | The ML model is tested with the
    test data to find out the accuracy of predictions. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| ä½¿ç”¨æµ‹è¯•æ•°æ®é›†æµ‹è¯•æ¨¡å‹ | ä½¿ç”¨æµ‹è¯•æ•°æ®æµ‹è¯•æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä»¥æ‰¾å‡ºé¢„æµ‹çš„å‡†ç¡®æ€§ã€‚|'
- en: '| Version of data, model, model parameters, and results | Version control is
    applied to datasets used, as well as to the model and its parameters, along with
    the results of each experiment. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| æ•°æ®ã€æ¨¡å‹ã€æ¨¡å‹å‚æ•°å’Œç»“æœç‰ˆæœ¬ | å¯¹ä½¿ç”¨çš„æ•°æ®é›†ã€æ¨¡å‹åŠå…¶å‚æ•°ä»¥åŠæ¯ä¸ªå®éªŒçš„ç»“æœåº”ç”¨ç‰ˆæœ¬æ§åˆ¶ã€‚|'
- en: '| Validate the dataset with the trained model | This is similar to test data
    but the samples are from the validation dataset. |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| ä½¿ç”¨è®­ç»ƒæ¨¡å‹éªŒè¯æ•°æ®é›† | è¿™ç±»ä¼¼äºæµ‹è¯•æ•°æ®ï¼Œä½†æ ·æœ¬æ¥è‡ªéªŒè¯æ•°æ®é›†ã€‚|'
- en: '| Predict results with new data (inference) | For inference, use the new data
    and find out the results. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| ä½¿ç”¨æ–°æ•°æ®é¢„æµ‹ç»“æœï¼ˆæ¨ç†ï¼‰ | å¯¹äºæ¨ç†ï¼Œä½¿ç”¨æ–°æ•°æ®å¹¶æ‰¾å‡ºç»“æœã€‚|'
- en: Table 2.9 - ML model phase
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 2.9 - æœºå™¨å­¦ä¹ æ¨¡å‹é˜¶æ®µ
- en: 'The following figure shows the ML model sub-phases:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹å›¾å±•ç¤ºäº†æœºå™¨å­¦ä¹ æ¨¡å‹å­é˜¶æ®µï¼š
- en: '![Figure 2.5 â€“ ML model sub-phases](img/B16573_02_05.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.5 â€“ æœºå™¨å­¦ä¹ æ¨¡å‹å­é˜¶æ®µ](img/B16573_02_05.jpg)'
- en: Figure 2.5 â€“ ML model sub-phases
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2.5 â€“ æœºå™¨å­¦ä¹ æ¨¡å‹å­é˜¶æ®µ
- en: ML operations phase
  id: totrans-244
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ æ“ä½œé˜¶æ®µ
- en: This phase is mainly focused on the operations of the models in production.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤é˜¶æ®µä¸»è¦å…³æ³¨ç”Ÿäº§ä¸­æ¨¡å‹çš„æ“ä½œã€‚
- en: '| Phase | Sub-phases | Details |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| é˜¶æ®µ | å­é˜¶æ®µ | è¯¦ç»†ä¿¡æ¯ |'
- en: '| ML operations(MLOps) | Package model artifacts | Persist the model (store
    the weights and biases) in ONNX format or other formats. |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| æœºå™¨å­¦ä¹ æ“ä½œï¼ˆMLOpsï¼‰ | æ‰“åŒ…æ¨¡å‹å·¥ä»¶ | å°†æ¨¡å‹ï¼ˆå­˜å‚¨æƒé‡å’Œåå·®ï¼‰æŒä¹…åŒ–å­˜å‚¨ä¸º ONNX æ ¼å¼æˆ–å…¶ä»–æ ¼å¼ã€‚|'
- en: '| Deploy model | This involves the production deployment of the model.(A/B
    testing, canary deployment, shadow models, etc.) |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| éƒ¨ç½²æ¨¡å‹ | è¿™æ¶‰åŠåˆ°æ¨¡å‹çš„å®é™…ç”Ÿäº§éƒ¨ç½²ã€‚ï¼ˆA/B æµ‹è¯•ã€é‡‘ä¸é›€éƒ¨ç½²ã€å½±å­æ¨¡å‹ç­‰ï¼‰|'
- en: '| Validate the inference results |  |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| éªŒè¯æ¨ç†ç»“æœ |  |'
- en: '| Monitor model performance | Monitor the performance model, i.e, whether the
    accuracy stays constant or degrades over a period. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| ç›‘æ§æ¨¡å‹æ€§èƒ½ | ç›‘æ§æ¨¡å‹æ€§èƒ½ï¼Œå³å‡†ç¡®æ€§æ˜¯å¦åœ¨ä¸€æ®µæ—¶é—´å†…ä¿æŒä¸å˜æˆ–ä¸‹é™ã€‚|'
- en: '| Retrain the model and repeat the ML model life cycle | Retrain the model
    if the model performance degrades and handle model drift and data drift accordingly.
    |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| é‡æ–°è®­ç»ƒæ¨¡å‹å¹¶é‡å¤æœºå™¨å­¦ä¹ æ¨¡å‹ç”Ÿå‘½å‘¨æœŸ | å¦‚æœæ¨¡å‹æ€§èƒ½ä¸‹é™ï¼Œåˆ™é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œå¹¶ç›¸åº”åœ°å¤„ç†æ¨¡å‹æ¼‚ç§»å’Œæ•°æ®æ¼‚ç§»ã€‚|'
- en: Table 2.10 - ML operations
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 2.10 - æœºå™¨å­¦ä¹ æ“ä½œ
- en: 'The following figure shows the ML operations sub-phases:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹å›¾å±•ç¤ºäº†æœºå™¨å­¦ä¹ æ“ä½œå­é˜¶æ®µï¼š
- en: '![Figure 2.6 â€“ ML operations sub-phases](img/B16573_02_06.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.6 â€“ æœºå™¨å­¦ä¹ æ“ä½œå­é˜¶æ®µ](img/B16573_02_06.jpg)'
- en: Figure 2.6 â€“ ML operations sub-phases
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2.6 â€“ æœºå™¨å­¦ä¹ æ“ä½œå­é˜¶æ®µ
- en: We have thoroughly covered the development of ML models and the various phases
    involved in the process. In the upcoming section, our focus will shift to exploring
    the privacy threats and attacks that can occur in each phase of ML. We will delve
    into understanding these threats and discuss effective mitigation strategies to
    safeguard the privacy of the data and models involved. By addressing these privacy
    concerns at each stage, we can ensure the responsible and secure implementation
    of ML techniques.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»è¯¦ç»†ä»‹ç»äº†æœºå™¨å­¦ä¹ æ¨¡å‹çš„å‘å±•ä»¥åŠè¯¥è¿‡ç¨‹ä¸­æ¶‰åŠçš„å„ç§é˜¶æ®µã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬çš„é‡ç‚¹å°†è½¬å‘æ¢ç´¢æœºå™¨å­¦ä¹ æ¯ä¸ªé˜¶æ®µå¯èƒ½å‘ç”Ÿçš„éšç§å¨èƒå’Œæ”»å‡»ã€‚æˆ‘ä»¬å°†æ·±å…¥äº†è§£è¿™äº›å¨èƒï¼Œå¹¶è®¨è®ºæœ‰æ•ˆçš„ç¼“è§£ç­–ç•¥ï¼Œä»¥ä¿æŠ¤æ•°æ®å’Œæ¨¡å‹æ¶‰åŠçš„éšç§ã€‚é€šè¿‡åœ¨æ¯ä¸ªé˜¶æ®µè§£å†³è¿™äº›éšç§é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿æœºå™¨å­¦ä¹ æŠ€æœ¯çš„è´Ÿè´£ä»»å’Œå®‰å…¨å®æ–½ã€‚
- en: Privacy threats/attacks in ML phases
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ é˜¶æ®µä¸­çš„éšç§å¨èƒ/æ”»å‡»
- en: ML projects are developed in collaboration with data engineers, ML engineers,
    and software engineers, and each one plays a different role in order to develop
    end-to-end systems to predict and provide insights.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ é¡¹ç›®æ˜¯ç”±æ•°æ®å·¥ç¨‹å¸ˆã€æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå’Œè½¯ä»¶å·¥ç¨‹å¸ˆåä½œå¼€å‘çš„ï¼Œæ¯ä¸ªè§’è‰²éƒ½åœ¨å¼€å‘ç«¯åˆ°ç«¯ç³»ç»Ÿä»¥é¢„æµ‹å’Œæä¾›è§è§£ä¸­æ‰®æ¼”ä¸åŒçš„è§’è‰²ã€‚
- en: Collaborative roles in ML projects
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ é¡¹ç›®ä¸­çš„åä½œè§’è‰²
- en: 'ML projects are collaborative efforts involving various roles such as data
    engineers, ML engineers, and software engineers. Each role contributes in different
    ways to develop end-to-end systems that can predict outcomes and provide valuable
    insights. Letâ€™s explore the roles and their responsibilities in the ML project
    life cycle:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ é¡¹ç›®æ˜¯æ¶‰åŠå„ç§è§’è‰²å¦‚æ•°æ®å·¥ç¨‹å¸ˆã€æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå’Œè½¯ä»¶å·¥ç¨‹å¸ˆçš„åä½œåŠªåŠ›ã€‚æ¯ä¸ªè§’è‰²ä»¥ä¸åŒçš„æ–¹å¼ä¸ºå¼€å‘ç«¯åˆ°ç«¯ç³»ç»Ÿåšå‡ºè´¡çŒ®ï¼Œè¿™äº›ç³»ç»Ÿèƒ½å¤Ÿé¢„æµ‹ç»“æœå¹¶æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚è®©æˆ‘ä»¬æ¥æ¢è®¨åœ¨æœºå™¨å­¦ä¹ é¡¹ç›®ç”Ÿå‘½å‘¨æœŸä¸­å„ä¸ªè§’è‰²çš„èŒè´£ï¼š
- en: '**Data engineer**: The data engineer primarily focuses on the data preparation
    phase. They are responsible for extracting data from one or multiple sources and
    ensuring its quality and suitability for the ML project. Data engineers work on
    tasks such as data cleaning, transformation, and feature selection to prepare
    the data for ML modeling.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ•°æ®å·¥ç¨‹å¸ˆ**ï¼šæ•°æ®å·¥ç¨‹å¸ˆä¸»è¦å…³æ³¨æ•°æ®å‡†å¤‡é˜¶æ®µã€‚ä»–ä»¬è´Ÿè´£ä»ä¸€ä¸ªæˆ–å¤šä¸ªæ¥æºæå–æ•°æ®ï¼Œå¹¶ç¡®ä¿å…¶è´¨é‡é€‚åˆæœºå™¨å­¦ä¹ é¡¹ç›®ã€‚æ•°æ®å·¥ç¨‹å¸ˆä»äº‹æ•°æ®æ¸…æ´—ã€è½¬æ¢å’Œç‰¹å¾é€‰æ‹©ç­‰ä»»åŠ¡ï¼Œä»¥å‡†å¤‡æ•°æ®ç”¨äºæœºå™¨å­¦ä¹ å»ºæ¨¡ã€‚'
- en: '**ML engineer**: ML engineers play a crucial role in designing and developing
    ML models. They leverage the data provided by the data engineer to train and test
    the models. ML engineers are responsible for selecting appropriate algorithms
    or model architectures, tuning hyperparameters, and optimizing the models for
    accuracy and efficiency. They validate the model against validation test data
    and provide APIs for inference or export/deployment of the model into production.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ**ï¼šæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆåœ¨è®¾è®¡å’Œå¼€å‘æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ã€‚ä»–ä»¬åˆ©ç”¨æ•°æ®å·¥ç¨‹å¸ˆæä¾›çš„æ•°æ®æ¥è®­ç»ƒå’Œæµ‹è¯•æ¨¡å‹ã€‚æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆè´Ÿè´£é€‰æ‹©åˆé€‚çš„ç®—æ³•æˆ–æ¨¡å‹æ¶æ„ï¼Œè°ƒæ•´è¶…å‚æ•°ï¼Œå¹¶ä¼˜åŒ–æ¨¡å‹ä»¥æé«˜å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚ä»–ä»¬ä½¿ç”¨éªŒè¯æµ‹è¯•æ•°æ®éªŒè¯æ¨¡å‹ï¼Œå¹¶æä¾›æ¨ç†æˆ–æ¨¡å‹å¯¼å‡º/éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒçš„APIã€‚'
- en: '**Model consumer**: The model consumer can be an individual or another application
    that interacts with the ML model. They make API calls and provide input to the
    model for prediction or inference. Model consumers utilize the insights generated
    by the ML model to make informed decisions or take appropriate actions.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ¶ˆè´¹è€…**ï¼šæ¨¡å‹æ¶ˆè´¹è€…å¯ä»¥æ˜¯ä¸ªäººæˆ–å¦ä¸€ä¸ªä¸æœºå™¨å­¦ä¹ æ¨¡å‹äº¤äº’çš„åº”ç”¨ç¨‹åºã€‚ä»–ä»¬é€šè¿‡APIè°ƒç”¨å‘æ¨¡å‹æä¾›è¾“å…¥ä»¥è¿›è¡Œé¢„æµ‹æˆ–æ¨ç†ã€‚æ¨¡å‹æ¶ˆè´¹è€…åˆ©ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹ç”Ÿæˆçš„è§è§£åšå‡ºæ˜æ™ºçš„å†³ç­–æˆ–é‡‡å–é€‚å½“çš„è¡ŒåŠ¨ã€‚'
- en: Privacy threats/attacks in ML
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ä¸­çš„éšç§å¨èƒ/æ”»å‡»
- en: In the context of ML, an adversary refers to an entity or system that actively
    tries to undermine or exploit the machine learning model or system. The goal of
    an adversary is typically to manipulate the modelâ€™s behavior, gain unauthorized
    access to sensitive information, or deceive the system by exploiting vulnerabilities.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœºå™¨å­¦ä¹ çš„èƒŒæ™¯ä¸‹ï¼Œå¯¹æ‰‹æŒ‡çš„æ˜¯ä¸€ä¸ªè¯•å›¾ç§¯æç ´åæˆ–åˆ©ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹æˆ–ç³»ç»Ÿçš„å®ä½“æˆ–ç³»ç»Ÿã€‚å¯¹æ‰‹çš„ç›®æ ‡é€šå¸¸æ˜¯æ“çºµæ¨¡å‹çš„è¡Œä¸ºï¼Œæœªç»æˆæƒè®¿é—®æ•æ„Ÿä¿¡æ¯ï¼Œæˆ–è€…é€šè¿‡åˆ©ç”¨æ¼æ´æ¬ºéª—ç³»ç»Ÿã€‚
- en: Adversaries can take various forms and have different motives.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ‰‹å¯ä»¥é‡‡å–å„ç§å½¢å¼ï¼Œå…·æœ‰ä¸åŒçš„åŠ¨æœºã€‚
- en: 'Here are a few examples:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€äº›ä¾‹å­ï¼š
- en: '**Adversarial examples**: In this case, the adversary aims to create input
    samples (e.g., images or text) that are intentionally crafted to mislead or deceive
    the ML model. Adversarial examples are designed to exploit vulnerabilities in
    the modelâ€™s decision-making process, leading to incorrect predictions or misclassifications.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¯¹æŠ—æ ·æœ¬**ï¼šåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ”»å‡»è€…çš„ç›®æ ‡æ˜¯åˆ›å»ºæ—¨åœ¨è¯¯å¯¼æˆ–æ¬ºéª—MLæ¨¡å‹çš„è¾“å…¥æ ·æœ¬ï¼ˆä¾‹å¦‚ï¼Œå›¾åƒæˆ–æ–‡æœ¬ï¼‰ã€‚å¯¹æŠ—æ ·æœ¬æ—¨åœ¨åˆ©ç”¨æ¨¡å‹å†³ç­–è¿‡ç¨‹ä¸­çš„æ¼æ´ï¼Œå¯¼è‡´é”™è¯¯é¢„æµ‹æˆ–è¯¯åˆ†ç±»ã€‚'
- en: '**Data poisoning**: An adversary may try to inject malicious or misleading
    data into the training dataset. By inserting carefully crafted samples, the adversary
    aims to manipulate the modelâ€™s training process, leading to biased or compromised
    results. This can be particularly problematic in scenarios where the training
    data is collected from untrusted or unreliable sources.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ•°æ®ä¸­æ¯’**ï¼šæ”»å‡»è€…å¯èƒ½ä¼šå°è¯•å°†æ¶æ„æˆ–è¯¯å¯¼æ€§æ•°æ®æ³¨å…¥è®­ç»ƒæ•°æ®é›†ä¸­ã€‚é€šè¿‡æ’å…¥ç²¾å¿ƒåˆ¶ä½œçš„æ ·æœ¬ï¼Œæ”»å‡»è€…æ—¨åœ¨æ“çºµæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¯¼è‡´ç»“æœåå·®æˆ–å—æŸã€‚è¿™åœ¨ä»ä¸å¯ä¿¡æˆ–ä¸å¯é æ¥æºæ”¶é›†è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å°¤å…¶æˆé—®é¢˜ã€‚'
- en: '**Model inversion**: An adversary might attempt to extract sensitive information
    from a trained model. By providing specific input and observing the modelâ€™s output,
    the adversary aims to infer confidential or private data that was used to train
    the model, such as **personally identifiable information** (**PII**) or proprietary
    knowledge.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹åæ¼”**ï¼šæ”»å‡»è€…å¯èƒ½ä¼šå°è¯•ä»è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­æå–æ•æ„Ÿä¿¡æ¯ã€‚é€šè¿‡æä¾›ç‰¹å®šè¾“å…¥å¹¶è§‚å¯Ÿæ¨¡å‹çš„è¾“å‡ºï¼Œæ”»å‡»è€…æ—¨åœ¨æ¨æ–­ç”¨äºè®­ç»ƒæ¨¡å‹çš„æœºå¯†æˆ–ç§äººæ•°æ®ï¼Œä¾‹å¦‚**ä¸ªäººèº«ä»½ä¿¡æ¯**ï¼ˆ**PII**ï¼‰æˆ–ä¸“æœ‰çŸ¥è¯†ã€‚'
- en: '**Evasion attacks**: Adversaries can also launch evasion attacks, also known
    as adversarial attacks, during the deployment phase. In these attacks, the adversary
    tries to bypass or manipulate the modelâ€™s defenses by carefully modifying input
    samples. For example, in the case of a spam email classifier, an adversary may
    add specific patterns or keywords to trick the model into classifying a malicious
    email as legitimate.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é€ƒé¿æ”»å‡»**ï¼šæ”»å‡»è€…ä¹Ÿå¯ä»¥åœ¨éƒ¨ç½²é˜¶æ®µå‘èµ·é€ƒé¿æ”»å‡»ï¼Œä¹Ÿç§°ä¸ºå¯¹æŠ—æ”»å‡»ã€‚åœ¨è¿™äº›æ”»å‡»ä¸­ï¼Œæ”»å‡»è€…é€šè¿‡ä»”ç»†ä¿®æ”¹è¾“å…¥æ ·æœ¬æ¥å°è¯•ç»•è¿‡æˆ–æ“çºµæ¨¡å‹çš„é˜²å¾¡æœºåˆ¶ã€‚ä¾‹å¦‚ï¼Œåœ¨åƒåœ¾é‚®ä»¶åˆ†ç±»å™¨çš„æƒ…å†µä¸‹ï¼Œæ”»å‡»è€…å¯èƒ½ä¼šæ·»åŠ ç‰¹å®šçš„æ¨¡å¼æˆ–å…³é”®è¯æ¥æ¬ºéª—æ¨¡å‹ï¼Œå°†å…¶åˆ†ç±»ä¸ºåˆæ³•çš„æ¶æ„é‚®ä»¶ã€‚'
- en: To mitigate the impact of adversaries, researchers and practitioners develop
    robust ML models and techniques, such as adversarial training, defensive distillation,
    and input sanitization. These approaches aim to enhance the resilience of ML systems
    against adversarial attacks and maintain their performance and reliability in
    the presence of potential threats.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å‡è½»æ”»å‡»è€…çš„å½±å“ï¼Œç ”ç©¶äººå‘˜å’Œä»ä¸šè€…å¼€å‘äº†é²æ£’çš„MLæ¨¡å‹å’ŒæŠ€æœ¯ï¼Œä¾‹å¦‚å¯¹æŠ—è®­ç»ƒã€é˜²å¾¡è’¸é¦å’Œè¾“å…¥å‡€åŒ–ã€‚è¿™äº›æ–¹æ³•æ—¨åœ¨å¢å¼ºMLç³»ç»Ÿå¯¹å¯¹æŠ—æ”»å‡»çš„å¼¹æ€§ï¼Œå¹¶åœ¨æ½œåœ¨å¨èƒå­˜åœ¨çš„æƒ…å†µä¸‹ä¿æŒå…¶æ€§èƒ½å’Œå¯é æ€§ã€‚
- en: Throughout the ML life cycle, privacy threats or attacks can occur, posing risks
    to the confidentiality of sensitive information. In the context of ML, adversaries
    attempt to gain unauthorized access to confidential data used in ML, the core
    ML model, or specific features of the data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•´ä¸ªMLç”Ÿå‘½å‘¨æœŸä¸­ï¼Œéšç§å¨èƒæˆ–æ”»å‡»éƒ½å¯èƒ½å‘ç”Ÿï¼Œå¯¹æ•æ„Ÿä¿¡æ¯çš„æœºå¯†æ€§æ„æˆé£é™©ã€‚åœ¨MLçš„èƒŒæ™¯ä¸‹ï¼Œæ”»å‡»è€…è¯•å›¾æœªç»æˆæƒè®¿é—®ç”¨äºMLçš„æœºå¯†æ•°æ®ã€æ ¸å¿ƒMLæ¨¡å‹æˆ–æ•°æ®çš„ç‰¹å®šç‰¹å¾ã€‚
- en: 'There are two primary types of attacks, white-box and black-box:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸¤ç§ä¸»è¦çš„æ”»å‡»ç±»å‹ï¼Œç™½ç›’å’Œé»‘ç›’ï¼š
- en: '**White-box attack**: A white-box attack assumes that the adversary has full
    knowledge and access to the ML model, including its architecture, input, output,
    and weights. The attacker exploits this information to extract confidential details.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç™½ç›’æ”»å‡»**ï¼šç™½ç›’æ”»å‡»å‡è®¾æ”»å‡»è€…å¯¹MLæ¨¡å‹æœ‰å…¨é¢çš„çŸ¥è¯†å’Œè®¿é—®æƒé™ï¼ŒåŒ…æ‹¬å…¶æ¶æ„ã€è¾“å…¥ã€è¾“å‡ºå’Œæƒé‡ã€‚æ”»å‡»è€…åˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥æå–æœºå¯†ç»†èŠ‚ã€‚'
- en: '**Black-box attack**: In contrast, a black-box attack assumes that the attacker
    only has access to the input and output of the ML model. They have no knowledge
    of the underlying architecture or weights used in the ML/DL model. Despite the
    limited information, they aim to infer sensitive information from the model.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é»‘ç›’æ”»å‡»**ï¼šç›¸æ¯”ä¹‹ä¸‹ï¼Œé»‘ç›’æ”»å‡»å‡è®¾æ”»å‡»è€…åªèƒ½è®¿é—®MLæ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºã€‚ä»–ä»¬å¯¹åº•å±‚æ¶æ„æˆ–ML/DLæ¨¡å‹ä¸­ä½¿ç”¨çš„æƒé‡ä¸€æ— æ‰€çŸ¥ã€‚å°½ç®¡ä¿¡æ¯æœ‰é™ï¼Œä½†ä»–ä»¬æ—¨åœ¨ä»æ¨¡å‹ä¸­æ¨æ–­æ•æ„Ÿä¿¡æ¯ã€‚'
- en: 'Privacy threats/attacks classification:'
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: éšç§å¨èƒ/æ”»å‡»åˆ†ç±»ï¼š
- en: The following are the privacy attacks on the ML models for classification
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å¯¹åˆ†ç±»æœºå™¨å­¦ä¹ æ¨¡å‹çš„éšç§æ”»å‡»
- en: '**Membership inference attack**: This attack aims to determine whether a particular
    data point was part of the training dataset used to train the ML model. The adversary
    tries to infer membership information by exploiting the modelâ€™s responses.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æˆå‘˜æ¨ç†æ”»å‡»**ï¼šè¿™ç§æ”»å‡»æ—¨åœ¨ç¡®å®šç‰¹å®šæ•°æ®ç‚¹æ˜¯å¦æ˜¯ç”¨äºè®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒæ•°æ®é›†çš„ä¸€éƒ¨åˆ†ã€‚æ”»å‡»è€…è¯•å›¾é€šè¿‡åˆ©ç”¨æ¨¡å‹çš„å“åº”æ¥æ¨æ–­æˆå‘˜ä¿¡æ¯ã€‚'
- en: '**Model extraction attack**: In this attack, the adversary attempts to extract
    the entire or partial ML model architecture, weights, or parameters. This attack
    allows the attacker to replicate the ML model for their own purposes, potentially
    leading to intellectual property theft.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æå–æ”»å‡»**ï¼šåœ¨è¿™ç§æ”»å‡»ä¸­ï¼Œæ”»å‡»è€…è¯•å›¾æå–æ•´ä¸ªæˆ–éƒ¨åˆ†æœºå™¨å­¦ä¹ æ¨¡å‹æ¶æ„ã€æƒé‡æˆ–å‚æ•°ã€‚è¿™ç§æ”»å‡»å…è®¸æ”»å‡»è€…å¤åˆ¶æœºå™¨å­¦ä¹ æ¨¡å‹ä»¥ä¾›è‡ªå·±ä½¿ç”¨ï¼Œå¯èƒ½å¯¼è‡´çŸ¥è¯†äº§æƒç›—çªƒã€‚'
- en: '**Reconstruction attack**: This attack focuses on reconstructing sensitive
    information from the ML modelâ€™s outputs. The attacker aims to infer private data
    or specific features that were used to generate the modelâ€™s predictions. By understanding
    and addressing these privacy threats, ML practitioners can take appropriate measures
    to safeguard sensitive data and ensure the security of ML models throughout their
    life cycle.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é‡å»ºæ”»å‡»**ï¼šè¿™ç§æ”»å‡»ä¸“æ³¨äºä»æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¾“å‡ºä¸­é‡å»ºæ•æ„Ÿä¿¡æ¯ã€‚æ”»å‡»è€…çš„ç›®æ ‡æ˜¯æ¨æ–­å‡ºç”¨äºç”Ÿæˆæ¨¡å‹é¢„æµ‹çš„ç§æœ‰æ•°æ®æˆ–ç‰¹å®šç‰¹å¾ã€‚é€šè¿‡ç†è§£å’Œåº”å¯¹è¿™äº›éšç§å¨èƒï¼Œæœºå™¨å­¦ä¹ ä»ä¸šè€…å¯ä»¥é‡‡å–é€‚å½“çš„æªæ–½æ¥ä¿æŠ¤æ•æ„Ÿæ•°æ®ï¼Œå¹¶ç¡®ä¿æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨å…¶æ•´ä¸ªç”Ÿå‘½å‘¨æœŸä¸­çš„å®‰å…¨æ€§ã€‚'
- en: Weâ€™ll look at these in more detail in the following sections.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­æ›´è¯¦ç»†åœ°æ¢è®¨è¿™äº›é—®é¢˜ã€‚
- en: Membership inference attack
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æˆå‘˜æ¨ç†æ”»å‡»
- en: Assume a classification model is developed with certain input training data,
    X { x1, x2, x3, â€¦. Xn} to predict certain labels, y, using a function, F.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾å¼€å‘äº†ä¸€ä¸ªåˆ†ç±»æ¨¡å‹ï¼Œä½¿ç”¨æŸäº›è¾“å…¥è®­ç»ƒæ•°æ®X {x1, x2, x3, â€¦. Xn}ï¼Œé€šè¿‡å‡½æ•°Fé¢„æµ‹æŸäº›æ ‡ç­¾yã€‚
- en: A membership inference attack tries to determine whether an input sample, x,
    was used as part of the training dataset, X, or not. Basically, an adversary (attacker)
    needs to find out whether the data point at hand belongs to the original dataset
    that is used for training the ML model or not.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: æˆå‘˜æ¨ç†æ”»å‡»è¯•å›¾ç¡®å®šè¾“å…¥æ ·æœ¬xæ˜¯å¦æ˜¯è®­ç»ƒæ•°æ®é›†Xçš„ä¸€éƒ¨åˆ†ã€‚åŸºæœ¬ä¸Šï¼Œæ”»å‡»è€…ï¼ˆæ”»å‡»è€…ï¼‰éœ€è¦æ‰¾å‡ºå½“å‰æ•°æ®ç‚¹æ˜¯å¦å±äºç”¨äºè®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„åŸå§‹æ•°æ®é›†ã€‚
- en: '![Figure 2.7 â€“ Membership inference attack - Example](img/B16573_02_07.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾2.7 â€“ æˆå‘˜æ¨ç†æ”»å‡» - ç¤ºä¾‹](img/B16573_02_07.jpg)'
- en: Figure 2.7 â€“ Membership inference attack - Example
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2.7 â€“ æˆå‘˜æ¨ç†æ”»å‡» - ç¤ºä¾‹
- en: '(Image source: Suha Hussain, PrivacyRaven, [https://blog.openmined.org/privacyraven-comprehensive-privacy-testing-for-deep-learning/](https://blog.openmined.org/privacyraven-comprehensive-privacy-testing-for-deep-learning/))'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆå›¾ç‰‡æ¥æºï¼šSuha Hussainï¼ŒPrivacyRavenï¼Œ[https://blog.openmined.org/privacyraven-comprehensive-privacy-testing-for-deep-learning/](https://blog.openmined.org/privacyraven-comprehensive-privacy-testing-for-deep-learning/))
- en: Letâ€™s look at an example. Suppose an adversary wants to determine whether a
    particular personâ€™s data was used in the training data or not without the knowledge
    of that person. Later, this data is used to derive insights on whether to approve
    that personâ€™s insurance policy or not.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªä¾‹å­ã€‚å‡è®¾ä¸€ä¸ªæ”»å‡»è€…æƒ³è¦ç¡®å®šæŸä¸ªç‰¹å®šäººçš„æ•°æ®æ˜¯å¦è¢«ç”¨äºè®­ç»ƒæ•°æ®ä¸­ï¼Œè€Œä¸éœ€è¦çŸ¥é“è¿™ä¸ªäººã€‚åæ¥ï¼Œè¿™äº›æ•°æ®è¢«ç”¨æ¥æ¨æ–­æ˜¯å¦æ‰¹å‡†è¯¥äººçš„ä¿é™©æ”¿ç­–ã€‚
- en: This is the most popular category of attacks and was first introduced by Shokri
    et al.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ”»å‡»ä¸­æœ€å—æ¬¢è¿çš„ç±»åˆ«ï¼Œæœ€åˆç”±Shokriç­‰äººæå‡ºã€‚
- en: 'Here is the reference to the full paper: *Reza Shokri, Marco Stronati, Congzheng
    Song, and Vitaly Shmatikov. 2017\. Membership inference attacks against machine
    learning models. In 2017 IEEE Symposium on Security and Privacy (SP). IEEE, San
    Francisco, CA,* *USA, 3â€“18.*'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å®Œæ•´è®ºæ–‡çš„å¼•ç”¨ï¼š*Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov.
    2017\. Membership inference attacks against machine learning models. In 2017 IEEE
    Symposium on Security and Privacy (SP). IEEE, San Francisco, CA,* *USA, 3â€“18.*
- en: This is a kind of black-box testing attack because the adversary doesnâ€™t have
    the details of the actual ML model; all they have is the set of input data and
    inference results from the model.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ç§é»‘ç›’æµ‹è¯•æ”»å‡»ï¼Œå› ä¸ºæ”»å‡»è€…æ²¡æœ‰å®é™…æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ï¼›ä»–ä»¬æ‰€æ‹¥æœ‰çš„åªæ˜¯è¾“å…¥æ•°æ®é›†å’Œæ¨¡å‹æ¨æ–­ç»“æœã€‚
- en: 'This is what the paper says about this approach:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡å…³äºè¿™ç§æ–¹æ³•æ˜¯è¿™æ ·è¯´çš„ï¼š
- en: â€œThe attacker queries the target model with a data record and obtains the modelâ€™s
    prediction on that record. The prediction is a vector of probabilities, one per
    class, that the record belongs to a certain class. This prediction vector, along
    with the label of the target record, is passed to the attack model, which determines
    whether the record was in or out of the target modelâ€™s training dataset.â€
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: â€œæ”»å‡»è€…ç”¨ä¸€ä¸ªæ•°æ®è®°å½•æŸ¥è¯¢ç›®æ ‡æ¨¡å‹ï¼Œå¹¶è·å–è¯¥æ¨¡å‹å¯¹è¯¥è®°å½•çš„é¢„æµ‹ã€‚é¢„æµ‹æ˜¯ä¸€ä¸ªå‘é‡ï¼Œæ¯ä¸ªç±»åˆ«ä¸€ä¸ªæ¦‚ç‡ï¼Œè¡¨ç¤ºè®°å½•å±äºæŸä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚è¿™ä¸ªé¢„æµ‹å‘é‡ï¼Œè¿åŒç›®æ ‡è®°å½•çš„æ ‡ç­¾ä¸€èµ·ï¼Œè¢«ä¼ é€’ç»™æ”»å‡»æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç¡®å®šè®°å½•æ˜¯å¦åœ¨ç›®æ ‡æ¨¡å‹çš„è®­ç»ƒæ•°æ®é›†ä¸­ã€‚â€
- en: 'The following figure also comes from the aforementioned paper ([https://arxiv.org/pdf/1610.05820.pdf](https://arxiv.org/pdf/1610.05820.pdf)):'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä¸ªå›¾ä¹Ÿæ¥è‡ªä¸Šè¿°è®ºæ–‡ï¼ˆ[https://arxiv.org/pdf/1610.05820.pdf](https://arxiv.org/pdf/1610.05820.pdf)ï¼‰ï¼š
- en: '![Figure 2.8 â€“ Membership inference attack - Example](img/B16573_02_08.jpg)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾2.8 â€“ æˆå‘˜æ¨ç†æ”»å‡» - ç¤ºä¾‹](img/B16573_02_08.jpg)'
- en: Figure 2.8 â€“ Membership inference attack - Example
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2.8 â€“ æˆå‘˜æ¨ç†æ”»å‡» - ç¤ºä¾‹
- en: Membership inference attackâ€”basic example
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æˆå‘˜æ¨ç†æ”»å‡»â€”åŸºæœ¬ç¤ºä¾‹
- en: In a membership inference attack, an adversary attempts to determine whether
    a specific data point was used in the training set of an ML model, as stated earlier.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆå‘˜æ¨ç†æ”»å‡»ä¸­ï¼Œæ”»å‡»è€…è¯•å›¾ç¡®å®šç‰¹å®šæ•°æ®ç‚¹æ˜¯å¦è¢«ç”¨äºæœºå™¨å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒé›†ä¸­ï¼Œå¦‚å‰æ‰€è¿°ã€‚
- en: 'Hereâ€™s an example using a simple decision tree classifier (the source code
    can be found in `Membership_Inference_basic_example.ipynb`):'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªä½¿ç”¨ç®€å•çš„å†³ç­–æ ‘åˆ†ç±»å™¨çš„ä¾‹å­ï¼ˆæºä»£ç å¯ä»¥åœ¨`Membership_Inference_basic_example.ipynb`ä¸­æ‰¾åˆ°ï¼‰ï¼š
- en: '[PRE14]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this example, we load the `Iris` dataset from scikit-learn and split it into
    a training set and a test set. We then train a decision tree classifier on the
    training set. Next, we select a data point (or set of points) from the test set
    and attempt to determine whether it was present in the training set by predicting
    its class. If the predicted class matches the actual class from the test set,
    we infer that the target data point was in the training set, indicating a successful
    attack. Remember, conducting membership inference attacks without proper authorization
    is unethical and often illegal.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä»scikit-learnä¸­åŠ è½½äº†`Iris`æ•°æ®é›†ï¼Œå¹¶å°†å…¶åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ç„¶åæˆ‘ä»¬åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒä¸€ä¸ªå†³ç­–æ ‘åˆ†ç±»å™¨ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä»æµ‹è¯•é›†ä¸­é€‰æ‹©ä¸€ä¸ªæ•°æ®ç‚¹ï¼ˆæˆ–ä¸€ç»„æ•°æ®ç‚¹ï¼‰ï¼Œå¹¶é€šè¿‡é¢„æµ‹å…¶ç±»åˆ«æ¥å°è¯•ç¡®å®šå®ƒæ˜¯å¦å­˜åœ¨äºè®­ç»ƒé›†ä¸­ã€‚å¦‚æœé¢„æµ‹çš„ç±»åˆ«ä¸æµ‹è¯•é›†ä¸­çš„å®é™…ç±»åˆ«ç›¸åŒ¹é…ï¼Œæˆ‘ä»¬æ¨æ–­ç›®æ ‡æ•°æ®ç‚¹åœ¨è®­ç»ƒé›†ä¸­ï¼Œè¿™è¡¨æ˜æ”»å‡»æˆåŠŸã€‚è®°ä½ï¼Œæœªç»é€‚å½“æˆæƒè¿›è¡Œæˆå‘˜æ¨ç†æ”»å‡»æ˜¯ä¸é“å¾·çš„ï¼Œé€šå¸¸æ˜¯éæ³•çš„ã€‚
- en: Membership inference attackâ€”advanced example
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æˆå‘˜æ¨ç†æ”»å‡»â€”é«˜çº§ç¤ºä¾‹
- en: Letâ€™s consider a scenario where an adversary seeks to determine whether a specific
    individualâ€™s data is present in the training data without any prior knowledge
    of that person. This scenario involves discovering whether a personâ€™s name exists
    within a hospitalâ€™s sensitive clinical data. The adversary intends to exploit
    this information to make decisions, such as granting or denying an insurance policy,
    based on the insights gained.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªåœºæ™¯ï¼Œå…¶ä¸­æ”»å‡»è€…è¯•å›¾ç¡®å®šç‰¹å®šä¸ªäººçš„æ•°æ®æ˜¯å¦å­˜åœ¨äºè®­ç»ƒæ•°æ®ä¸­ï¼Œè€Œå¯¹è¯¥ä¸ªäººæ²¡æœ‰ä»»ä½•å…ˆå‰çš„äº†è§£ã€‚è¿™ä¸ªåœºæ™¯æ¶‰åŠå‘ç°ä¸€ä¸ªäººçš„åå­—æ˜¯å¦å­˜åœ¨äºåŒ»é™¢çš„æ•æ„Ÿä¸´åºŠæ•°æ®ä¸­ã€‚æ”»å‡»è€…æ‰“ç®—åˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥åšå‡ºå†³ç­–ï¼Œä¾‹å¦‚æ ¹æ®ä»è®­ç»ƒæ•°æ®ä¸­è·å¾—çš„è®¤è¯†æ¥æˆäºˆæˆ–æ‹’ç»ä¿é™©æ”¿ç­–ã€‚
- en: To illustrate this scenario, letâ€™s use a sample dataset (for illustrative purposes
    only) similar to the classification example we previously discussed. The dataset
    focuses on predicting whether a patient will live for the next 5 to 10 years or
    not based on factors such as age and existing diseases.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯´æ˜è¿™ç§æƒ…å†µï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç±»ä¼¼æˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„åˆ†ç±»ç¤ºä¾‹çš„æ ·æœ¬æ•°æ®é›†ï¼ˆä»…ç”¨äºè¯´æ˜ç›®çš„ï¼‰ã€‚è¯¥æ•°æ®é›†ä¾§é‡äºæ ¹æ®å¹´é¾„å’Œç°æœ‰ç–¾ç—…ç­‰å› ç´ é¢„æµ‹æ‚£è€…æ˜¯å¦èƒ½åœ¨æœªæ¥5åˆ°10å¹´å†…ç”Ÿå­˜ã€‚
- en: In this context, the adversaryâ€™s goal is to identify whether the data related
    to a specific person, whose identity they are unaware of, is present in the training
    data. By discovering this information, the adversary can potentially manipulate
    decisions related to insurance policies based on the insights gained from the
    training data.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ”»å‡»è€…çš„ç›®æ ‡æ˜¯ç¡®å®šä¸ç‰¹å®šäººå‘˜ç›¸å…³çš„æ•°æ®ï¼ˆä»–ä»¬ä¸çŸ¥é“è¯¥äººå‘˜çš„èº«ä»½ï¼‰æ˜¯å¦å­˜åœ¨äºè®­ç»ƒæ•°æ®ä¸­ã€‚é€šè¿‡å‘ç°è¿™äº›ä¿¡æ¯ï¼Œæ”»å‡»è€…å¯ä»¥åŸºäºä»è®­ç»ƒæ•°æ®ä¸­è·å¾—çš„è®¤è¯†æ¥æ“çºµä¸ä¿é™©æ”¿ç­–ç›¸å…³çš„å†³ç­–ã€‚
- en: It is important to note that this example serves to highlight a potential privacy
    threat and does not aim to validate its accuracy or real-world applicability.
    The objective is to raise awareness about the importance of safeguarding sensitive
    data and implementing robust privacy measures to prevent unauthorized access and
    misuse.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ­¤ç¤ºä¾‹æ—¨åœ¨çªå‡ºæ½œåœ¨çš„éšç§å¨èƒï¼Œå¹¶ä¸æ—¨åœ¨éªŒè¯å…¶å‡†ç¡®æ€§æˆ–å®é™…åº”ç”¨æ€§ã€‚ç›®æ ‡æ˜¯æé«˜äººä»¬å¯¹ä¿æŠ¤æ•æ„Ÿæ•°æ®ä»¥åŠå®æ–½å¼ºå¤§çš„éšç§æªæ–½ä»¥é˜²æ­¢æœªç»æˆæƒçš„è®¿é—®å’Œæ»¥ç”¨çš„è®¤è¯†ã€‚
- en: '| Age (years) | Has/had cancer (1 = yes, 0 = no) | Survived ( 1 = yes, 0 =
    no) |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| å¹´é¾„ï¼ˆå¹´ï¼‰ | æ˜¯å¦æ‚£æœ‰ç™Œç—‡ï¼ˆ1 = æ˜¯ï¼Œ0 = å¦ï¼‰ | æ˜¯å¦å­˜æ´»ï¼ˆ1 = æ˜¯ï¼Œ0 = å¦ï¼‰ |'
- en: '| 10 | 1 | 1 |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 1 |'
- en: '| 20 | 1 | 1 |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 1 | 1 |'
- en: '| 30 | 1 | 1 |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 1 |'
- en: '| 80 | 1 | 0 |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 1 | 0 |'
- en: '| 75 | 0 | 0 |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 0 | 0 |'
- en: '| 78 | 0 | 0 |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 0 | 0 |'
- en: Table 2.11 - Training data
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 2.11 - è®­ç»ƒæ•°æ®
- en: 'The source code for this ML model can be found in `Membership_Inference_advanced_example.ipynb`:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æœºå™¨å­¦ä¹ æ¨¡å‹çš„æºä»£ç å¯åœ¨ `Membership_Inference_advanced_example.ipynb` ä¸­æ‰¾åˆ°ï¼š
- en: '[PRE15]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Inference results with sample test data
  id: totrans-318
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ ·æœ¬æµ‹è¯•æ•°æ®çš„æ¨ç†ç»“æœ
- en: 'The adversary creates synthetic test data with diverse inputs to evaluate the
    modelâ€™s performance. Their objective is to determine whether the given patient
    data exists in the training dataset or not using the modelâ€™s predictions:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: æ”»å‡»è€…åˆ›å»ºå…·æœ‰ä¸åŒè¾“å…¥çš„åˆæˆæµ‹è¯•æ•°æ®ä»¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚ä»–ä»¬çš„ç›®æ ‡æ˜¯ç¡®å®šç»™å®šçš„æ‚£è€…æ•°æ®æ˜¯å¦å­˜åœ¨äºè®­ç»ƒæ•°æ®é›†ä¸­ï¼Œä½¿ç”¨æ¨¡å‹é¢„æµ‹ï¼š
- en: '[PRE16]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The results are in the table format; 1 means the person has cancer and the
    predicted probability column shows the percentage of predicted probability:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœä»¥è¡¨æ ¼å½¢å¼å‘ˆç°ï¼›1 è¡¨ç¤ºè¯¥äººæ‚£æœ‰ç™Œç—‡ï¼Œé¢„æµ‹æ¦‚ç‡åˆ—æ˜¾ç¤ºé¢„æµ‹æ¦‚ç‡çš„ç™¾åˆ†æ¯”ï¼š
- en: '| Age | Cancer | Class predicted | Predicted probability |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| å¹´é¾„ | ç™Œç—‡ | é¢„æµ‹ç±»åˆ« | é¢„æµ‹æ¦‚ç‡ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 25 | 1 | 1 | 100 |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 1 | 1 | 100 |'
- en: '| 25 | 0 | 1 | 100 |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 0 | 1 | 100 |'
- en: '| 30 | 1 | 1 | 100 |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 1 | 100 |'
- en: '| 30 | 0 | 1 | 100 |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 0 | 1 | 100 |'
- en: '| 45 | 1 | 1 | 100 |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| 45 | 1 | 1 | 100 |'
- en: '| 45 | 0 | 1 | 100 |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 45 | 0 | 1 | 100 |'
- en: '| 50 | 1 | 1 | 100 |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 1 | 1 | 100 |'
- en: '| 50 | 0 | 1 | 100 |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 0 | 1 | 100 |'
- en: '| 60 | 1 | 0 | 0 |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 1 | 0 | 0 |'
- en: '| 60 | 0 | 0 | 0 |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 0 | 0 | 0 |'
- en: '| 75 | 1 | 0 | 0 |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 1 | 0 | 0 |'
- en: '| 75 | 0 | 0 | 0 |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 0 | 0 | 0 |'
- en: '| 80 | 1 | 0 | 0 |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 1 | 0 | 0 |'
- en: '| 80 | 0 | 0 | 0 |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 0 | 0 | 0 |'
- en: '| 90 | 1 | 0 | 0 |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| 90 | 1 | 0 | 0 |'
- en: '| 90 | 0 | 0 | 0 |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 90 | 0 | 0 | 0 |'
- en: '| 100 | 1 | 0 | 0 |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 1 | 0 | 0 |'
- en: '| 100 | 0 | 0 | 0 |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 0 | 0 | 0 |'
- en: '| 10 | 1 | 0 | 100 |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 0 | 100 |'
- en: '| 20 | 1 | 0 | 100 |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 1 | 0 | 100 |'
- en: '| 30 | 1 | 0 | 100 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 0 | 100 |'
- en: '| 78 | 0 | 1 | 0 |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 0 | 1 | 0 |'
- en: Table 2.12 - Predicted probability
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 2.12 - é¢„æµ‹æ¦‚ç‡
- en: Next, the adversary proceeds to develop shadow models and a final attack model.
    These models are designed to predict whether a given data record was used in the
    training dataset. By utilizing each record and its predicted class, along with
    the corresponding predicted probabilities, the adversary infers whether the data
    record was part of the training set or not.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæ”»å‡»è€…å¼€å§‹å¼€å‘å½±å­æ¨¡å‹å’Œæœ€ç»ˆçš„æ”»å‡»æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹æ—¨åœ¨é¢„æµ‹ç»™å®šçš„æ•°æ®è®°å½•æ˜¯å¦ç”¨äºè®­ç»ƒæ•°æ®é›†ã€‚é€šè¿‡åˆ©ç”¨æ¯ä¸ªè®°å½•åŠå…¶é¢„æµ‹ç±»åˆ«ï¼Œä»¥åŠç›¸åº”çš„é¢„æµ‹æ¦‚ç‡ï¼Œæ”»å‡»è€…æ¨æ–­è¯¥æ•°æ®è®°å½•æ˜¯å¦æ˜¯è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†ã€‚
- en: '![Figure 2.9 â€“ Shadow models](img/B16573_02_09.jpg)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.9 â€“ å½±å­æ¨¡å‹](img/B16573_02_09.jpg)'
- en: Figure 2.9 â€“ Shadow models
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2.9 â€“ å½±å­æ¨¡å‹
- en: The preceding figure was sourced from the paper at [https://arxiv.org/pdf/1610.05820.pdf](https://arxiv.org/pdf/1610.05820.pdf).
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: å‰é¢çš„å›¾è¡¨æ¥æºäºè®ºæ–‡[https://arxiv.org/pdf/1610.05820.pdf](https://arxiv.org/pdf/1610.05820.pdf)ã€‚
- en: The attacker model makes use of the class label 'In' for the given input record
    used in the training, while 'out' means it is not used.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: æ”»å‡»æ¨¡å‹ä½¿ç”¨ç±»åˆ«æ ‡ç­¾ 'In' è¡¨ç¤ºç”¨äºè®­ç»ƒçš„ç»™å®šè¾“å…¥è®°å½•ï¼Œè€Œ 'out' è¡¨ç¤ºå®ƒæ²¡æœ‰è¢«ä½¿ç”¨ã€‚
- en: 'This is the training data for the final attack model:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æœ€ç»ˆæ”»å‡»æ¨¡å‹çš„è®­ç»ƒæ•°æ®ï¼š
- en: '| Age | Cancer | Class predicted | Predicted probability | Record used in the
    training set (in = 1, out = 0) |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| å¹´é¾„ | ç™Œç—‡ | é¢„æµ‹ç±»åˆ« | é¢„æµ‹æ¦‚ç‡ | è®­ç»ƒé›†ä¸­ä½¿ç”¨çš„è®°å½•ï¼ˆin = 1ï¼Œout = 0ï¼‰ |'
- en: '| 25 | 1 | 1 | 100 | 1 |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 1 | 1 | 100 | 1 |'
- en: '| 25 | 0 | 1 | 100 | 1 |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 0 | 1 | 100 | 1 |'
- en: '| 30 | 1 | 1 | 100 | 1 |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 1 | 100 | 1 |'
- en: '| 30 | 0 | 1 | 100 | 1 |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 0 | 1 | 100 | 1 |'
- en: '| 45 | 1 | 1 | 100 | 1 |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 45 | 1 | 1 | 100 | 1 |'
- en: '| 45 | 0 | 1 | 100 | 1 |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 45 | 0 | 1 | 100 | 1 |'
- en: '| 50 | 1 | 1 | 100 | 1 |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 1 | 1 | 100 | 1 |'
- en: '| 50 | 0 | 1 | 100 | 1 |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 0 | 1 | 100 | 1 |'
- en: '| 10 | 1 | 0 | 100 | 1 |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 0 | 100 | 1 |'
- en: '| 20 | 1 | 0 | 100 | 1 |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 1 | 0 | 100 | 1 |'
- en: '| 30 | 1 | 0 | 100 | 1 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 0 | 100 | 1 |'
- en: '| 60 | 1 | 0 | 0 | 0 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 1 | 0 | 0 | 0 |'
- en: '| 60 | 0 | 0 | 0 | 0 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 0 | 0 | 0 | 0 |'
- en: '| 75 | 1 | 0 | 0 | 0 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 1 | 0 | 0 | 0 |'
- en: '| 75 | 0 | 0 | 0 | 0 |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 0 | 0 | 0 | 0 |'
- en: '| 80 | 1 | 0 | 0 | 0 |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 1 | 0 | 0 | 0 |'
- en: '| 80 | 0 | 0 | 0 | 0 |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 0 | 0 | 0 | 0 |'
- en: '| 90 | 1 | 0 | 0 | 0 |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 90 | 1 | 0 | 0 | 0 |'
- en: '| 90 | 0 | 0 | 0 | 0 |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 90 | 0 | 0 | 0 | 0 |'
- en: '| 100 | 1 | 0 | 0 | 0 |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 1 | 0 | 0 | 0 |'
- en: '| 100 | 0 | 0 | 0 | 0 |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 0 | 0 | 0 | 0 |'
- en: '| 78 | 0 | 1 | 0 | 0 |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 0 | 1 | 0 | 0 |'
- en: Table 2.13 - Training data for final attack model
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨2.13 - æœ€ç»ˆæ”»å‡»æ¨¡å‹çš„è®­ç»ƒæ•°æ®
- en: Membership inference attacks can be easily executed with remarkable accuracy
    in simple linear models, as shown in the preceding example. ML models hosted in
    the cloud are susceptible to such inference attacks, as researchers have successfully
    demonstrated membership attack models with accuracies exceeding 90%.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: æˆå‘˜æ¨ç†æ”»å‡»å¯ä»¥åœ¨ç®€å•çš„çº¿æ€§æ¨¡å‹ä¸­è½»æ¾æ‰§è¡Œï¼Œå¹¶ä¸”å‡†ç¡®æ€§éå¸¸é«˜ï¼Œå¦‚å‰ä¾‹æ‰€ç¤ºã€‚æ‰˜ç®¡åœ¨äº‘ä¸­çš„æœºå™¨å­¦ä¹ æ¨¡å‹å®¹æ˜“å—åˆ°æ­¤ç±»æ¨ç†æ”»å‡»ï¼Œå› ä¸ºç ”ç©¶äººå‘˜å·²ç»æˆåŠŸæ¼”ç¤ºäº†å‡†ç¡®ç‡è¶…è¿‡90%çš„æˆå‘˜æ”»å‡»æ¨¡å‹ã€‚
- en: Techniques to mitigate membership inference attacks
  id: totrans-378
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å‡è½»æˆå‘˜æ¨ç†æ”»å‡»çš„æŠ€æœ¯
- en: Membership inference attacks can be a concern in ML models that involve sensitive
    data.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¶‰åŠæ•æ„Ÿæ•°æ®çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œæˆå‘˜æ¨ç†æ”»å‡»å¯èƒ½æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚
- en: 'Some techniques to mitigate membership inference attacks are as follows:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€äº›å‡è½»æˆå‘˜æ¨ç†æ”»å‡»çš„æŠ€æœ¯ï¼š
- en: '**Limit access to sensitive information**: One of the simplest ways to mitigate
    membership inference attacks is to limit access to sensitive information. By minimizing
    the amount of sensitive data that is exposed, you reduce the potential for attackers
    to perform membership inference.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é™åˆ¶å¯¹æ•æ„Ÿä¿¡æ¯çš„è®¿é—®**ï¼šå‡è½»æˆå‘˜æ¨ç†æ”»å‡»çš„ä¸€ç§ç®€å•æ–¹æ³•å°±æ˜¯é™åˆ¶å¯¹æ•æ„Ÿä¿¡æ¯çš„è®¿é—®ã€‚é€šè¿‡æœ€å°åŒ–æš´éœ²çš„æ•æ„Ÿæ•°æ®é‡ï¼Œå¯ä»¥å‡å°‘æ”»å‡»è€…æ‰§è¡Œæˆå‘˜æ¨ç†çš„å¯èƒ½æ€§ã€‚'
- en: '**Differential privacy**: Differential privacy is a technique that adds noise
    to the training data or the modelâ€™s output, making it harder for an attacker to
    determine whether a specific record was part of the training set. Applying differential
    privacy mechanisms can help protect against membership inference attacks. We will
    learn about differential privacy in the next chapter.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å·®åˆ†éšç§**ï¼šå·®åˆ†éšç§æ˜¯ä¸€ç§å‘è®­ç»ƒæ•°æ®æˆ–æ¨¡å‹è¾“å‡ºæ·»åŠ å™ªå£°çš„æŠ€æœ¯ï¼Œä½¿å¾—æ”»å‡»è€…æ›´éš¾ç¡®å®šç‰¹å®šè®°å½•æ˜¯å¦æ˜¯è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†ã€‚åº”ç”¨å·®åˆ†éšç§æœºåˆ¶å¯ä»¥å¸®åŠ©æŠµå¾¡æˆå‘˜æ¨ç†æ”»å‡»ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ç« å­¦ä¹ å·®åˆ†éšç§ã€‚'
- en: '**Training set augmentation**: By augmenting the training set with additional
    synthetic or generated data, you can make it more difficult for attackers to distinguish
    between genuine training instances and potential members. Augmentation techniques
    such as data generation, perturbation, or adding noise can help to increase the
    privacy of the training set.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒé›†å¢å¼º**ï¼šé€šè¿‡å‘è®­ç»ƒé›†æ·»åŠ é¢å¤–çš„åˆæˆæˆ–ç”Ÿæˆæ•°æ®ï¼Œå¯ä»¥ä½¿å¾—æ”»å‡»è€…æ›´éš¾åŒºåˆ†çœŸå®è®­ç»ƒå®ä¾‹å’Œæ½œåœ¨æˆå‘˜ã€‚æ•°æ®ç”Ÿæˆã€æ‰°åŠ¨æˆ–æ·»åŠ å™ªå£°ç­‰å¢å¼ºæŠ€æœ¯å¯ä»¥å¸®åŠ©æé«˜è®­ç»ƒé›†çš„éšç§æ€§ã€‚'
- en: '**Regularization and dropout**: Applying regularization techniques such as
    L1 or L2 regularization and incorporating dropout layers in neural networks can
    improve model robustness and reduce overfitting. Regularization can help in reducing
    the memorization of training instances, making it harder for attackers to infer
    membership.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ­£åˆ™åŒ–å’Œdropout**ï¼šåº”ç”¨L1æˆ–L2æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œå¹¶åœ¨ç¥ç»ç½‘ç»œä¸­å¼•å…¥dropoutå±‚å¯ä»¥æé«˜æ¨¡å‹çš„é²æ£’æ€§å¹¶å‡å°‘è¿‡æ‹Ÿåˆã€‚æ­£åˆ™åŒ–æœ‰åŠ©äºå‡å°‘è®­ç»ƒå®ä¾‹çš„è®°å¿†ï¼Œä½¿å¾—æ”»å‡»è€…æ›´éš¾æ¨æ–­æˆå‘˜èº«ä»½ã€‚'
- en: '**Model compression**: When sharing models or making predictions, consider
    using model compression techniques to reduce the amount of information leaked
    about the training data. Techniques such as quantization, pruning, or knowledge
    distillation can help reduce the modelâ€™s sensitivity to the training set.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹å‹ç¼©**ï¼šåœ¨å…±äº«æ¨¡å‹æˆ–è¿›è¡Œé¢„æµ‹æ—¶ï¼Œè€ƒè™‘ä½¿ç”¨æ¨¡å‹å‹ç¼©æŠ€æœ¯ä»¥å‡å°‘å…³äºè®­ç»ƒæ•°æ®çš„æ³„éœ²ä¿¡æ¯é‡ã€‚ä¾‹å¦‚ï¼Œé‡åŒ–ã€å‰ªææˆ–çŸ¥è¯†è’¸é¦ç­‰æŠ€æœ¯å¯ä»¥å¸®åŠ©é™ä½æ¨¡å‹å¯¹è®­ç»ƒé›†çš„æ•æ„Ÿæ€§ã€‚'
- en: '**Ensemble methods**: Training an ensemble of multiple models with different
    architectures or using different algorithms can make it more difficult for attackers
    to perform accurate membership inference. Ensemble methods make it harder for
    an attacker to learn the specific patterns in the training data.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é›†æˆæ–¹æ³•**ï¼šé€šè¿‡è®­ç»ƒå…·æœ‰ä¸åŒæ¶æ„æˆ–ä½¿ç”¨ä¸åŒç®—æ³•çš„å¤šä¸ªæ¨¡å‹ï¼Œå¯ä»¥ä½¿å¾—æ”»å‡»è€…æ›´éš¾æ‰§è¡Œå‡†ç¡®çš„æˆå‘˜æ¨ç†ã€‚é›†æˆæ–¹æ³•ä½¿å¾—æ”»å‡»è€…æ›´éš¾å­¦ä¹ è®­ç»ƒæ•°æ®ä¸­çš„ç‰¹å®šæ¨¡å¼ã€‚'
- en: '**Secure aggregation**: If the model is trained using a distributed setting,
    secure aggregation protocols can be employed to ensure that individual contributions
    from different parties are protected and the membership information is not exposed.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®‰å…¨èšåˆ**ï¼šå¦‚æœæ¨¡å‹æ˜¯åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è®­ç»ƒçš„ï¼Œå¯ä»¥ä½¿ç”¨å®‰å…¨èšåˆåè®®æ¥ç¡®ä¿ä¸åŒå„æ–¹è´¡çŒ®çš„ä¸ªä½“ä¿¡æ¯å¾—åˆ°ä¿æŠ¤ï¼Œå¹¶ä¸”æˆå‘˜ä¿¡æ¯ä¸ä¼šè¢«æ³„éœ²ã€‚'
- en: '**Randomized response**: Randomized response techniques can be used to introduce
    noise into the modelâ€™s outputs during inference, making it harder for an attacker
    to determine membership status. Randomized response mechanisms ensure plausible
    deniability for individual records.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**éšæœºå“åº”**ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥ä½¿ç”¨éšæœºå“åº”æŠ€æœ¯å‘æ¨¡å‹è¾“å‡ºå¼•å…¥å™ªå£°ï¼Œä½¿æ”»å‡»è€…æ›´éš¾ç¡®å®šæˆå‘˜èµ„æ ¼çŠ¶æ€ã€‚éšæœºå“åº”æœºåˆ¶ç¡®ä¿äº†ä¸ªäººè®°å½•çš„å¯ä¿¡å¦è®¤æ€§ã€‚'
- en: '**Access control and authorization**: Implementing access control measures
    and strong authorization mechanisms can help restrict access to sensitive models
    and data, limiting the exposure to potential attackers.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è®¿é—®æ§åˆ¶å’Œæˆæƒ**ï¼šå®æ–½è®¿é—®æ§åˆ¶æªæ–½å’Œå¼ºå¤§çš„æˆæƒæœºåˆ¶å¯ä»¥å¸®åŠ©é™åˆ¶å¯¹æ•æ„Ÿæ¨¡å‹å’Œæ•°æ®çš„è®¿é—®ï¼Œå‡å°‘æ½œåœ¨æ”»å‡»è€…çš„æš´éœ²ã€‚'
- en: '**Model monitoring**: Continuously monitoring the modelâ€™s behavior for any
    unusual patterns or unexpected outputs can help detect potential membership inference
    attacks. Monitoring can involve techniques such as outlier detection, adversarial
    robustness checks, or statistical analysis of model outputs.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹ç›‘æ§**ï¼šæŒç»­ç›‘æ§æ¨¡å‹çš„è¡Œä¸ºï¼Œä»¥æ£€æµ‹ä»»ä½•å¼‚å¸¸æ¨¡å¼æˆ–æ„å¤–çš„è¾“å‡ºï¼Œæœ‰åŠ©äºæ£€æµ‹æ½œåœ¨çš„æˆå‘˜æ¨æ–­æ”»å‡»ã€‚ç›‘æ§å¯èƒ½æ¶‰åŠå¼‚å¸¸æ£€æµ‹ã€å¯¹æŠ—é²æ£’æ€§æ£€æŸ¥æˆ–æ¨¡å‹è¾“å‡ºçš„ç»Ÿè®¡åˆ†æç­‰æŠ€æœ¯ã€‚'
- en: Itâ€™s important to note that no single technique can provide complete protection
    against membership inference attacks. A combination of multiple techniques and
    a comprehensive approach to privacy and security is usually required to effectively
    mitigate these attacks.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: é‡è¦çš„æ˜¯è¦æ³¨æ„ï¼Œæ²¡æœ‰å•ä¸€çš„æŠ€æœ¯å¯ä»¥æä¾›å¯¹æˆå‘˜æ¨æ–­æ”»å‡»çš„å®Œå…¨ä¿æŠ¤ã€‚é€šå¸¸éœ€è¦ç»“åˆå¤šç§æŠ€æœ¯å’Œå¯¹éšç§å’Œå®‰å…¨çš„å…¨é¢æ–¹æ³•æ¥æœ‰æ•ˆåœ°å‡è½»è¿™äº›æ”»å‡»ã€‚
- en: Model extraction attack
  id: totrans-392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹æå–æ”»å‡»
- en: A model extraction attack is a type of black-box attack in which the adversary
    aims to extract information, and possibly recreate a model, by creating a substitute
    model (denoted as *ğ‘“*â€™) that closely emulates the behavior of the original model
    being targeted (denoted as *ğ‘“*).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æå–æ”»å‡»æ˜¯ä¸€ç§é»‘ç›’æ”»å‡»ï¼Œå…¶ä¸­æ”»å‡»è€…é€šè¿‡åˆ›å»ºä¸€ä¸ªæ›¿ä»£æ¨¡å‹ï¼ˆè¡¨ç¤ºä¸º *ğ‘“*â€™ï¼‰ï¼Œè¯¥æ¨¡å‹ç´§å¯†æ¨¡æ‹Ÿè¢«é’ˆå¯¹çš„åŸå§‹æ¨¡å‹ï¼ˆè¡¨ç¤ºä¸º *ğ‘“*ï¼‰çš„è¡Œä¸ºï¼Œæ—¨åœ¨æå–ä¿¡æ¯ï¼Œå¹¶å¯èƒ½é‡æ–°åˆ›å»ºæ¨¡å‹ã€‚
- en: Letâ€™s consider a scenario where we have developed an ML model specifically designed
    to predict whether a given post/tweet pertains to a disaster or not. We provide
    APIs to consumers, enabling them to access these prediction capabilities, and
    charge a fee for each API request made.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªåœºæ™¯ï¼Œå³æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªä¸“é—¨ç”¨äºé¢„æµ‹ç»™å®šå¸–å­/æ¨æ–‡æ˜¯å¦ä¸ç¾éš¾ç›¸å…³çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚æˆ‘ä»¬å‘æ¶ˆè´¹è€…æä¾›APIï¼Œä½¿ä»–ä»¬èƒ½å¤Ÿè®¿é—®è¿™äº›é¢„æµ‹åŠŸèƒ½ï¼Œå¹¶å¯¹æ¯ä¸ªAPIè¯·æ±‚æ”¶è´¹ã€‚
- en: '![Figure 2.10 - Securing ML Model Integrity](img/B16573_02_10.jpg)'
  id: totrans-395
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾2.10 - ä¿æŠ¤æœºå™¨å­¦ä¹ æ¨¡å‹å®Œæ•´æ€§](img/B16573_02_10.jpg)'
- en: Figure 2.10 - Securing ML Model Integrity
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2.10 - ä¿æŠ¤æœºå™¨å­¦ä¹ æ¨¡å‹å®Œæ•´æ€§
- en: The adversary takes advantage of the API provided and systematically submits
    thousands of input tweets in order to obtain their respective predictions. Subsequently,
    the adversary proceeds to construct a new ML model using these tweets, which were
    obtained by querying the API exposed by the original author. The predicted results
    obtained from the API serve as the class labels for this new model, indicating
    whether the tweets are classified as disaster-related or not.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ‰‹åˆ©ç”¨æä¾›çš„APIï¼Œç³»ç»Ÿåœ°æäº¤æ•°åƒæ¡è¾“å…¥æ¨æ–‡ä»¥è·å–ç›¸åº”çš„é¢„æµ‹ã€‚éšåï¼Œå¯¹æ‰‹ç»§ç»­æ„å»ºä¸€ä¸ªæ–°çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œè¿™äº›æ¨æ–‡æ˜¯é€šè¿‡æŸ¥è¯¢åŸå§‹ä½œè€…æš´éœ²çš„APIè·å¾—çš„ã€‚ä»APIè·å¾—çš„é¢„æµ‹ç»“æœä½œä¸ºæ–°æ¨¡å‹çš„ç±»åˆ«æ ‡ç­¾ï¼ŒæŒ‡ç¤ºæ¨æ–‡æ˜¯å¦è¢«åˆ†ç±»ä¸ºä¸ç¾éš¾ç›¸å…³ã€‚
- en: '![Figure 2.11 â€“ Model extraction attackâ€”adversary ML model](img/B16573_02_11.jpg)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾2.11 â€“ æ¨¡å‹æå–æ”»å‡»â€”å¯¹æ‰‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹](img/B16573_02_11.jpg)'
- en: Figure 2.11 â€“ Model extraction attackâ€”adversary ML model
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2.11 â€“ æ¨¡å‹æå–æ”»å‡»â€”å¯¹æ‰‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹
- en: In certain instances, the ML model developed by the adversary may exhibit superior
    accuracy compared to the original authorâ€™s ML model. As a consequence, this can
    significantly affect the revenue of the original authorâ€™s company. The adversary
    may exploit this advantage by exposing similar inference APIs, charging substantially
    lower fees than the original author, and potentially engaging in the theft of
    intellectual property. Furthermore, the model extraction attack enables the adversary
    to gain access to private information associated with the ML model, further exacerbating
    the potential damages caused.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯¹æ‰‹å¼€å‘çš„æœºå™¨å­¦ä¹ æ¨¡å‹å¯èƒ½æ¯”åŸå§‹ä½œè€…çš„æœºå™¨å­¦ä¹ æ¨¡å‹å…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§ã€‚å› æ­¤ï¼Œè¿™å¯èƒ½ä¼šä¸¥é‡å½±å“åŸå§‹ä½œè€…å…¬å¸çš„æ”¶å…¥ã€‚å¯¹æ‰‹å¯èƒ½é€šè¿‡å…¬å¼€ç±»ä¼¼çš„æ¨ç†APIï¼Œæ”¶å–æ¯”åŸå§‹ä½œè€…ä½å¾—å¤šçš„è´¹ç”¨ï¼Œå¹¶å¯èƒ½æ¶‰åŠçŸ¥è¯†äº§æƒçš„ç›—çªƒã€‚æ­¤å¤–ï¼Œæ¨¡å‹æå–æ”»å‡»ä½¿å¯¹æ‰‹èƒ½å¤Ÿè®¿é—®ä¸æœºå™¨å­¦ä¹ æ¨¡å‹ç›¸å…³çš„ç§äººä¿¡æ¯ï¼Œè¿›ä¸€æ­¥åŠ å‰§äº†å¯èƒ½é€ æˆçš„æŸå®³ã€‚
- en: Example of a model extraction attack
  id: totrans-401
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ¨¡å‹æå–æ”»å‡»çš„ç¤ºä¾‹
- en: The source code for this example can be found in `Model` `Extraction_Attack
    Example.ipynb`.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¾‹çš„æºä»£ç å¯ä»¥åœ¨`Model` `Extraction_Attack Example.ipynb`ä¸­æ‰¾åˆ°ã€‚
- en: In this example, we start by creating a sample dataset that consists of two
    features (*X*) and their corresponding labels (*y*). Subsequently, we train a
    logistic regression model on this dataset using the `LogisticRegression` class
    from scikit-learn.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªç‰¹å¾(*X*)åŠå…¶å¯¹åº”æ ‡ç­¾(*y*)çš„æ ·æœ¬æ•°æ®é›†ã€‚éšåï¼Œæˆ‘ä»¬ä½¿ç”¨scikit-learnçš„`LogisticRegression`ç±»åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹ã€‚
- en: The attackerâ€™s code aims to execute a model extraction attack by training a
    new `LogisticRegression` model (`extracted_model`) on the same dataset. The attackerâ€™s
    objective is to replicate the original modelâ€™s behavior without having direct
    access to its internal workings.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: æ”»å‡»è€…çš„ä»£ç æ—¨åœ¨é€šè¿‡åœ¨ç›¸åŒçš„æ•°æ®é›†ä¸Šè®­ç»ƒä¸€ä¸ªæ–°çš„`LogisticRegression`æ¨¡å‹(`extracted_model`)æ¥æ‰§è¡Œæ¨¡å‹æå–æ”»å‡»ã€‚æ”»å‡»è€…çš„ç›®æ ‡æ˜¯å¤åˆ¶åŸå§‹æ¨¡å‹çš„è¡Œä¸ºï¼Œè€Œä¸ç›´æ¥è®¿é—®å…¶å†…éƒ¨å·¥ä½œåŸç†ã€‚
- en: Once the extracted model is successfully generated, it can be utilized for unauthorized
    purposes, such as making predictions on new data (`new_data`) without requiring
    access to the original model. This unauthorized usage raises concerns regarding
    the security and integrity of the original modelâ€™s functionality.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æå–çš„æ¨¡å‹æˆåŠŸç”Ÿæˆï¼Œå®ƒå¯ä»¥è¢«ç”¨äºæœªç»æˆæƒçš„ç›®çš„ï¼Œä¾‹å¦‚åœ¨æ–°æ•°æ®(`new_data`)ä¸Šåšå‡ºé¢„æµ‹ï¼Œè€Œæ— éœ€è®¿é—®åŸå§‹æ¨¡å‹ã€‚è¿™ç§æœªç»æˆæƒçš„ä½¿ç”¨å¼•å‘äº†å…³äºåŸå§‹æ¨¡å‹åŠŸèƒ½å®‰å…¨å’Œå®Œæ•´æ€§çš„æ‹…å¿§ã€‚
- en: 'The following is the source code for the model extraction attack (`Model` `Extraction_Attack
    Example.ipynb`):'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸ºæ¨¡å‹æå–æ”»å‡»ç¼–å†™çš„æºä»£ç (`Model` `Extraction_Attack Example.ipynb`)ï¼š
- en: '[PRE17]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Techniques to mitigate model extraction attacks
  id: totrans-408
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å‡ç¼“æ¨¡å‹æå–æ”»å‡»çš„æŠ€æœ¯
- en: Mitigating model extraction attacks, where an adversary tries to extract the
    underlying modelâ€™s architecture, parameters, or functionality, is crucial for
    protecting intellectual property and maintaining the security of sensitive models.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼“è§£æ¨¡å‹æå–æ”»å‡»ï¼Œå³å¯¹æ‰‹è¯•å›¾æå–åº•å±‚æ¨¡å‹çš„æ¶æ„ã€å‚æ•°æˆ–åŠŸèƒ½ï¼Œå¯¹äºä¿æŠ¤çŸ¥è¯†äº§æƒå’Œç»´æŠ¤æ•æ„Ÿæ¨¡å‹çš„å®‰å…¨è‡³å…³é‡è¦ã€‚
- en: 'Some of the techniques to mitigate model extraction attacks are as follows:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ç¼“æ¨¡å‹æå–æ”»å‡»çš„ä¸€äº›æŠ€æœ¯å¦‚ä¸‹ï¼š
- en: '**Model watermarking**: Embedding a unique watermark into the modelâ€™s parameters
    or architecture can help identify the origin of the model and deter unauthorized
    extraction. Watermarking techniques can be designed to be resilient against removal
    attempts or modifications while remaining imperceptible to normal model operations.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ°´å°**: å°†ä¸€ä¸ªç‹¬ç‰¹çš„æ°´å°åµŒå…¥æ¨¡å‹çš„å‚æ•°æˆ–æ¶æ„ä¸­ï¼Œå¯ä»¥å¸®åŠ©è¯†åˆ«æ¨¡å‹çš„æ¥æºå¹¶é˜»æ­¢æœªç»æˆæƒçš„æå–ã€‚æ°´å°æŠ€æœ¯å¯ä»¥è®¾è®¡æˆå¯¹ç§»é™¤å°è¯•æˆ–ä¿®æ”¹å…·æœ‰æŠµæŠ—åŠ›ï¼ŒåŒæ—¶åœ¨æ­£å¸¸æ¨¡å‹æ“ä½œä¸­ä¿æŒä¸å¯å¯Ÿè§‰ã€‚'
- en: '**Model obfuscation**: Applying obfuscation techniques to the modelâ€™s code
    or architecture can make it harder for attackers to understand the internal workings
    of the model. Obfuscation can involve techniques such as code obfuscation, function
    renaming, control flow diversification, or encryption to protect the modelâ€™s implementation
    details.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ··æ·†**: å¯¹æ¨¡å‹çš„ä»£ç æˆ–æ¶æ„åº”ç”¨æ··æ·†æŠ€æœ¯å¯ä»¥ä½¿æ”»å‡»è€…æ›´éš¾ç†è§£æ¨¡å‹çš„å†…éƒ¨å·¥ä½œåŸç†ã€‚æ··æ·†å¯èƒ½æ¶‰åŠä»£ç æ··æ·†ã€å‡½æ•°é‡å‘½åã€æ§åˆ¶æµå¤šæ ·åŒ–æˆ–åŠ å¯†ç­‰æŠ€æœ¯ï¼Œä»¥ä¿æŠ¤æ¨¡å‹çš„å®ç°ç»†èŠ‚ã€‚'
- en: '**Secure model sharing**: When sharing models with authorized users or collaborators,
    itâ€™s important to employ secure sharing mechanisms. This can involve encryption
    during transit and at rest, strong access control measures, and secure authentication
    and authorization protocols to prevent unauthorized access to the model.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®‰å…¨æ¨¡å‹å…±äº«**: å½“ä¸æˆæƒç”¨æˆ·æˆ–åˆä½œè€…å…±äº«æ¨¡å‹æ—¶ï¼Œé‡è¦çš„æ˜¯è¦é‡‡ç”¨å®‰å…¨çš„å…±äº«æœºåˆ¶ã€‚è¿™å¯èƒ½åŒ…æ‹¬åœ¨ä¼ è¾“å’Œé™æ­¢çŠ¶æ€ä¸‹çš„åŠ å¯†ã€å¼ºå¤§çš„è®¿é—®æ§åˆ¶æªæ–½ä»¥åŠå®‰å…¨çš„èº«ä»½éªŒè¯å’Œæˆæƒåè®®ï¼Œä»¥é˜²æ­¢å¯¹æ¨¡å‹çš„æœªç»æˆæƒè®¿é—®ã€‚'
- en: '**Model compression**: Using model compression techniques such as quantization,
    pruning, or knowledge distillation can make the model more compact and reduce
    the amount of information that can be extracted. Compressed models often have
    fewer parameters and structural details, making them more resistant to model extraction
    attacks.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹å‹ç¼©**: ä½¿ç”¨é‡åŒ–ã€å‰ªææˆ–çŸ¥è¯†è’¸é¦ç­‰æ¨¡å‹å‹ç¼©æŠ€æœ¯å¯ä»¥ä½¿æ¨¡å‹æ›´åŠ ç´§å‡‘ï¼Œå¹¶å‡å°‘å¯ä»¥æå–çš„ä¿¡æ¯é‡ã€‚å‹ç¼©æ¨¡å‹é€šå¸¸å…·æœ‰æ›´å°‘çš„å‚æ•°å’Œç»“æ„ç»†èŠ‚ï¼Œè¿™ä½¿å¾—å®ƒä»¬å¯¹æ¨¡å‹æå–æ”»å‡»æ›´å…·æŠµæŠ—åŠ›ã€‚'
- en: '**Fine-grained access control**: Implementing fine-grained access control mechanisms
    can limit the exposure of sensitive models. This can involve providing access
    to only the necessary components or functionalities of the model based on user
    roles and permissions.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç»†ç²’åº¦è®¿é—®æ§åˆ¶**ï¼šå®æ–½ç»†ç²’åº¦è®¿é—®æ§åˆ¶æœºåˆ¶å¯ä»¥é™åˆ¶æ•æ„Ÿæ¨¡å‹çš„æš´éœ²ã€‚è¿™å¯èƒ½åŒ…æ‹¬æ ¹æ®ç”¨æˆ·è§’è‰²å’Œæƒé™ä»…æä¾›å¯¹æ¨¡å‹å¿…è¦ç»„ä»¶æˆ–åŠŸèƒ½çš„è®¿é—®ã€‚'
- en: '**Secure execution environment**: Running the model in a secure execution environment
    can help protect against extraction attacks. Techniques such as secure enclaves
    (e.g., Intel SGX or AMD SEV), **trusted execution environments** (**TEEs**), and
    **secure multiparty computation** (**MPC**) can provide isolation and integrity
    guarantees for executing models, preventing unauthorized access to the modelâ€™s
    internals. We will learn more about TEE in [*Chapter 9*](B16573_09.xhtml#_idTextAnchor204).'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®‰å…¨æ‰§è¡Œç¯å¢ƒ**ï¼šåœ¨å®‰å…¨çš„æ‰§è¡Œç¯å¢ƒä¸­è¿è¡Œæ¨¡å‹å¯ä»¥å¸®åŠ©é˜²æ­¢æå–æ”»å‡»ã€‚ä¾‹å¦‚ï¼Œå®‰å…¨åŒºåŸŸï¼ˆå¦‚è‹±ç‰¹å°”SGXæˆ–AMD SEVï¼‰ã€**å¯ä¿¡æ‰§è¡Œç¯å¢ƒ**ï¼ˆ**TEEs**ï¼‰å’Œ**å®‰å…¨å¤šæ–¹è®¡ç®—**ï¼ˆ**MPC**ï¼‰ç­‰æŠ€æœ¯å¯ä»¥ä¸ºæ‰§è¡Œæ¨¡å‹æä¾›éš”ç¦»å’Œå®Œæ•´æ€§ä¿è¯ï¼Œé˜²æ­¢æœªç»æˆæƒè®¿é—®æ¨¡å‹çš„å†…éƒ¨ä¿¡æ¯ã€‚æˆ‘ä»¬å°†åœ¨[*ç¬¬9ç« *](B16573_09.xhtml#_idTextAnchor204)ä¸­äº†è§£æ›´å¤šå…³äºTEEçš„å†…å®¹ã€‚'
- en: '**Model metadata protection**: Protecting the metadata associated with the
    model, such as the training data, hyperparameters, or training process details,
    can make it harder for attackers to extract meaningful information about the model.
    Techniques such as differential privacy or data perturbation can help preserve
    privacy in model metadata.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹å…ƒæ•°æ®ä¿æŠ¤**ï¼šä¿æŠ¤ä¸æ¨¡å‹ç›¸å…³çš„å…ƒæ•°æ®ï¼Œå¦‚è®­ç»ƒæ•°æ®ã€è¶…å‚æ•°æˆ–è®­ç»ƒè¿‡ç¨‹ç»†èŠ‚ï¼Œå¯ä»¥ä½¿æ”»å‡»è€…æ›´éš¾æå–æœ‰å…³æ¨¡å‹çš„æœ‰æ„ä¹‰ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå·®åˆ†éšç§æˆ–æ•°æ®æ‰°åŠ¨ç­‰æŠ€æœ¯å¯ä»¥å¸®åŠ©åœ¨æ¨¡å‹å…ƒæ•°æ®ä¸­ä¿æŒéšç§ã€‚'
- en: '**Monitoring for abnormal model usage**: Implementing model monitoring and
    anomaly detection mechanisms can help identify suspicious activities, such as
    repeated queries or excessive model interactions, which could indicate unauthorized
    extraction attempts. Monitoring can trigger alerts or initiate defensive actions
    when potential attacks are detected.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç›‘æ§å¼‚å¸¸æ¨¡å‹ä½¿ç”¨**ï¼šå®æ–½æ¨¡å‹ç›‘æ§å’Œå¼‚å¸¸æ£€æµ‹æœºåˆ¶å¯ä»¥å¸®åŠ©è¯†åˆ«å¯ç–‘æ´»åŠ¨ï¼Œå¦‚é‡å¤æŸ¥è¯¢æˆ–è¿‡åº¦æ¨¡å‹äº¤äº’ï¼Œè¿™å¯èƒ½è¡¨æ˜æœªç»æˆæƒçš„æå–å°è¯•ã€‚å½“æ£€æµ‹åˆ°æ½œåœ¨æ”»å‡»æ—¶ï¼Œç›‘æ§å¯ä»¥è§¦å‘è­¦æŠ¥æˆ–å¯åŠ¨é˜²å¾¡è¡ŒåŠ¨ã€‚'
- en: '**Legal and licensing measures**: Implementing legal protections, such as copyright,
    patent, or licensing agreements, can provide additional legal recourse and deter
    unauthorized model extraction and usage.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ³•å¾‹å’Œè®¸å¯æªæ–½**ï¼šå®æ–½æ³•å¾‹ä¿æŠ¤ï¼Œå¦‚ç‰ˆæƒã€ä¸“åˆ©æˆ–è®¸å¯åè®®ï¼Œå¯ä»¥æä¾›é¢å¤–çš„æ³•å¾‹æ•‘æµå¹¶é˜»æ­¢æœªç»æˆæƒçš„æ¨¡å‹æå–å’Œä½¿ç”¨ã€‚'
- en: As we discussed with the membership inference attack, itâ€™s important to note
    that no single technique can provide complete protection against model extraction
    attacks; a combination of multiple techniques is usually required. The choice
    of mitigation techniques depends on the specific threat model, the sensitivity
    of the model, and the desired level of protection.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬è®¨è®ºçš„æˆå‘˜æ¨ç†æ”»å‡»ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ²¡æœ‰å•ä¸€çš„æŠ€æœ¯å¯ä»¥æä¾›å¯¹æ¨¡å‹æå–æ”»å‡»çš„å®Œå…¨ä¿æŠ¤ï¼›é€šå¸¸éœ€è¦å¤šç§æŠ€æœ¯çš„ç»„åˆã€‚ç¼“è§£æŠ€æœ¯çš„é€‰æ‹©å–å†³äºå…·ä½“çš„å¨èƒæ¨¡å‹ã€æ¨¡å‹æ•æ„Ÿæ€§ä»¥åŠæ‰€éœ€çš„ä¿æŠ¤æ°´å¹³ã€‚
- en: 'We have learned about membership inference attacks and model extraction attacks
    on ML models. Letâ€™s now explore the third type of privacy attack on ML models:
    the reconstruction attack.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»äº†è§£äº†é’ˆå¯¹æœºå™¨å­¦ä¹ æ¨¡å‹çš„æˆå‘˜æ¨ç†æ”»å‡»å’Œæ¨¡å‹æå–æ”»å‡»ã€‚ç°åœ¨è®©æˆ‘ä»¬æ¢ç´¢æœºå™¨å­¦ä¹ æ¨¡å‹çš„ç¬¬ä¸‰ç§éšç§æ”»å‡»ï¼šé‡å»ºæ”»å‡»ã€‚
- en: Reconstruction attacksâ€”model inversion attacks
  id: totrans-422
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é‡å»ºæ”»å‡»â€”â€”æ¨¡å‹åè½¬æ”»å‡»
- en: Reconstruction attacks try to recreate one or more instances of training data
    and/or their respective class labels. The reconstruction may be partial or full,
    depending on the strength of the original model. A fully successful attack can
    generate more realistic training data and various samples to match exact class
    label predictions.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: é‡å»ºæ”»å‡»è¯•å›¾é‡å»ºä¸€ä¸ªæˆ–å¤šä¸ªè®­ç»ƒæ•°æ®å®ä¾‹åŠå…¶ç›¸åº”çš„ç±»æ ‡ç­¾ã€‚é‡å»ºå¯èƒ½æ˜¯éƒ¨åˆ†æˆ–å®Œæ•´çš„ï¼Œè¿™å–å†³äºåŸå§‹æ¨¡å‹çš„åŠ›é‡ã€‚ä¸€æ¬¡å®Œå…¨æˆåŠŸçš„æ”»å‡»å¯ä»¥ç”Ÿæˆæ›´çœŸå®çš„è®­ç»ƒæ•°æ®å’Œå„ç§æ ·æœ¬ï¼Œä»¥åŒ¹é…ç²¾ç¡®çš„ç±»æ ‡ç­¾é¢„æµ‹ã€‚
- en: Model inversion or attribute inference are kinds of reconstruction attacks.
    They come under the black-box attack category because the attacker doesnâ€™t need
    to know the details of the modelâ€™s structure or internal workings. They only need
    access to the modelâ€™s output based on some input data. Using that, they can infer
    details about the data used to train the model.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹åè½¬æˆ–å±æ€§æ¨ç†éƒ½æ˜¯é‡å»ºæ”»å‡»çš„ä¸€ç§ã€‚å®ƒä»¬å±äºé»‘ç›’æ”»å‡»ç±»åˆ«ï¼Œå› ä¸ºæ”»å‡»è€…ä¸éœ€è¦äº†è§£æ¨¡å‹ç»“æ„çš„ç»†èŠ‚æˆ–å†…éƒ¨å·¥ä½œåŸç†ã€‚ä»–ä»¬åªéœ€è¦æ ¹æ®ä¸€äº›è¾“å…¥æ•°æ®è®¿é—®æ¨¡å‹çš„è¾“å‡ºã€‚åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œä»–ä»¬å¯ä»¥æ¨æ–­å‡ºç”¨äºè®­ç»ƒæ¨¡å‹çš„æ•°æ®çš„è¯¦ç»†ä¿¡æ¯ã€‚
- en: A step-by-step example of creating a model inversion attack
  id: totrans-425
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: åˆ›å»ºæ¨¡å‹åè½¬æ”»å‡»çš„é€æ­¥ç¤ºä¾‹
- en: In this example, we first create a simple dataset with two input features (`X`)
    and binary labels (`y`). We train a logistic regression model using this dataset.
    The `model_inversion_attack` function attempts to invert the model by finding
    an input that produces the desired output probability.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªè¾“å…¥ç‰¹å¾ï¼ˆ`X`ï¼‰å’ŒäºŒè¿›åˆ¶æ ‡ç­¾ï¼ˆ`y`ï¼‰çš„ç®€å•æ•°æ®é›†ã€‚æˆ‘ä»¬ä½¿ç”¨æ­¤æ•°æ®é›†è®­ç»ƒä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹ã€‚`model_inversion_attack`
    å‡½æ•°è¯•å›¾é€šè¿‡æ‰¾åˆ°äº§ç”Ÿæ‰€éœ€è¾“å‡ºæ¦‚ç‡çš„è¾“å…¥æ¥åè½¬æ¨¡å‹ã€‚
- en: Please note that this is a basic example to illustrate the concept of model
    inversion attacks. In real-world scenarios, model inversion attacks can be more
    complex and require sophisticated techniques to handle larger and more complex
    models.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºæœ¬ç¤ºä¾‹ï¼Œç”¨äºè¯´æ˜æ¨¡å‹åè½¬æ”»å‡»çš„æ¦‚å¿µã€‚åœ¨å®é™…åœºæ™¯ä¸­ï¼Œæ¨¡å‹åè½¬æ”»å‡»å¯èƒ½æ›´åŠ å¤æ‚ï¼Œéœ€è¦æ›´é«˜çº§çš„æŠ€æœ¯æ¥å¤„ç†æ›´å¤§å’Œæ›´å¤æ‚çš„æ¨¡å‹ã€‚
- en: 'The full source code can be found in `Model_Inversion_LR_Sample.ipynb`:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæ•´çš„æºä»£ç å¯ä»¥åœ¨ `Model_Inversion_LR_Sample.ipynb` ä¸­æ‰¾åˆ°ï¼š
- en: '[PRE18]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Letâ€™s explore a more complex example to understand model inversion attacks.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¢ç´¢ä¸€ä¸ªæ›´å¤æ‚çš„ä¾‹å­æ¥ç†è§£æ¨¡å‹åè½¬æ”»å‡»ã€‚
- en: Model inversion attacks in neural networks
  id: totrans-431
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œä¸­çš„æ¨¡å‹åè½¬æ”»å‡»
- en: Neural networks are a class of ML models inspired by the structure and functioning
    of the human brain. They are designed to recognize complex patterns and relationships
    in data. Neural networks consist of interconnected layers of artificial neurons,
    known as nodes or units, which collectively form a network.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œæ˜¯ä¸€ç±»å—äººç±»å¤§è„‘ç»“æ„å’ŒåŠŸèƒ½å¯å‘çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚å®ƒä»¬è¢«è®¾è®¡ç”¨æ¥è¯†åˆ«æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼å’Œå…³ç³»ã€‚ç¥ç»ç½‘ç»œç”±ç›¸äº’è¿æ¥çš„äººå·¥ç¥ç»å…ƒå±‚ç»„æˆï¼Œç§°ä¸ºèŠ‚ç‚¹æˆ–å•å…ƒï¼Œå…±åŒå½¢æˆä¸€ä¸ªç½‘ç»œã€‚
- en: Each neuron receives input signals, applies a mathematical operation to them,
    and produces an output signal. These signals are passed through the network, with
    weights assigned to the connections between neurons determining the strength of
    the signal. Neural networks are trained using a process called backpropagation,
    which adjusts the weights based on the errors between predicted and actual outputs.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªç¥ç»å…ƒæ¥æ”¶è¾“å…¥ä¿¡å·ï¼Œå¯¹å®ƒä»¬åº”ç”¨æ•°å­¦è¿ç®—ï¼Œå¹¶äº§ç”Ÿè¾“å‡ºä¿¡å·ã€‚è¿™äº›ä¿¡å·é€šè¿‡ç½‘ç»œä¼ é€’ï¼Œç¥ç»å…ƒä¹‹é—´çš„è¿æ¥æƒé‡å†³å®šäº†ä¿¡å·çš„å¼ºåº¦ã€‚ç¥ç»ç½‘ç»œé€šè¿‡ç§°ä¸ºåå‘ä¼ æ’­çš„è¿‡ç¨‹è¿›è¡Œè®­ç»ƒï¼Œè¯¥è¿‡ç¨‹æ ¹æ®é¢„æµ‹è¾“å‡ºå’Œå®é™…è¾“å‡ºä¹‹é—´çš„è¯¯å·®è°ƒæ•´æƒé‡ã€‚
- en: The hidden layers of a neural network enable it to learn and represent intricate
    nonlinear relationships in the data, making it capable of solving highly complex
    tasks such as image and speech recognition, natural language processing, and even
    playing games. Popular neural network architectures include feedforward neural
    networks, **convolutional neural networks** (**CNNs**), and **recurrent neural**
    **networks** (**RNNs**).
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œçš„éšè—å±‚ä½¿å…¶èƒ½å¤Ÿå­¦ä¹ å¹¶è¡¨ç¤ºæ•°æ®ä¸­çš„å¤æ‚éçº¿æ€§å…³ç³»ï¼Œä½¿å…¶èƒ½å¤Ÿè§£å†³é«˜åº¦å¤æ‚çš„é—®é¢˜ï¼Œå¦‚å›¾åƒå’Œè¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ï¼Œç”šè‡³ç©æ¸¸æˆã€‚æµè¡Œçš„ç¥ç»ç½‘ç»œæ¶æ„åŒ…æ‹¬å‰é¦ˆç¥ç»ç½‘ç»œã€**å·ç§¯ç¥ç»ç½‘ç»œ**ï¼ˆ**CNNs**ï¼‰å’Œ**å¾ªç¯ç¥ç»ç½‘ç»œ**ï¼ˆ**RNNs**ï¼‰ã€‚
- en: Neural networks have achieved remarkable success in various fields, demonstrating
    state-of-the-art performance in many domains. They have become a fundamental tool
    in machine learning and continue to advance the boundaries of artificial intelligence
    by enabling sophisticated decision-making and pattern recognition capabilities.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œåœ¨å„ä¸ªé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œåœ¨è®¸å¤šé¢†åŸŸå±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å®ƒä»¬å·²æˆä¸ºæœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåŸºæœ¬å·¥å…·ï¼Œå¹¶é€šè¿‡å®ç°å¤æ‚çš„å†³ç­–å’Œæ¨¡å¼è¯†åˆ«èƒ½åŠ›ï¼Œç»§ç»­æ¨åŠ¨äººå·¥æ™ºèƒ½çš„è¾¹ç•Œã€‚
- en: We will not delve into the intricacies of neural networks, as this exceeds the
    scope of this book.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸ä¼šæ·±å…¥æ¢è®¨ç¥ç»ç½‘ç»œçš„å¤æ‚æ€§ï¼Œå› ä¸ºè¿™è¶…å‡ºäº†æœ¬ä¹¦çš„èŒƒå›´ã€‚
- en: In this example, we will demonstrate how an adversary can generate input data
    using the output of a neural network model. The adversaryâ€™s goal is to reconstruct
    the original input that led to a specific output prediction by leveraging the
    characteristics of the modelâ€™s behavior. By reverse-engineering the relationship
    between the modelâ€™s output and the corresponding input data, the adversary can
    gain insights into the original data points used for training the model.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºæ”»å‡»è€…å¦‚ä½•åˆ©ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹çš„è¾“å‡ºç”Ÿæˆè¾“å…¥æ•°æ®ã€‚æ”»å‡»è€…çš„ç›®æ ‡æ˜¯åˆ©ç”¨æ¨¡å‹è¡Œä¸ºçš„ç‰¹å¾ï¼Œé‡å»ºå¯¼è‡´ç‰¹å®šè¾“å‡ºé¢„æµ‹çš„åŸå§‹è¾“å…¥ã€‚é€šè¿‡é€†å‘å·¥ç¨‹æ¨¡å‹è¾“å‡ºä¸ç›¸åº”è¾“å…¥æ•°æ®ä¹‹é—´çš„å…³ç³»ï¼Œæ”»å‡»è€…å¯ä»¥æ·±å…¥äº†è§£ç”¨äºè®­ç»ƒæ¨¡å‹çš„åŸå§‹æ•°æ®ç‚¹ã€‚
- en: '![Figure 2.12 â€“ Neural network models of the original author and the adversary](img/B16573_02_12.jpg)'
  id: totrans-438
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.12 â€“ åŸä½œè€…å’Œæ”»å‡»è€…çš„ç¥ç»ç½‘ç»œæ¨¡å‹](img/B16573_02_12.jpg)'
- en: Figure 2.12 â€“ Neural network models of the original author and the adversary
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2.12 â€“ åŸä½œè€…å’Œå¯¹æ‰‹çš„ç¥ç»ç½‘ç»œæ¨¡å‹
- en: Input data
  id: totrans-440
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è¾“å…¥æ•°æ®
- en: In this example, we utilize the **Modified National Institute of Standards and
    Technology** (**MNIST**) dataset to train a neural network model. The MNIST dataset
    comprises 60,000 grayscale images of handwritten single digits between 0 and 9\.
    Each image is a small square with dimensions of 28 x 28 pixels.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ **Modified National Institute of Standards and Technology** ï¼ˆ**MNIST**ï¼‰æ•°æ®é›†æ¥è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹ã€‚MNIST
    æ•°æ®é›†åŒ…å« 60,000 å¼  0 åˆ° 9 ä¹‹é—´çš„æ‰‹å†™å•æ•°å­—çš„ç°åº¦å›¾åƒã€‚æ¯å¼ å›¾åƒéƒ½æ˜¯ä¸€ä¸ª 28 x 28 åƒç´ çš„å°æ­£æ–¹å½¢ã€‚
- en: Original authors model
  id: totrans-442
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: åŸä½œè€…æ¨¡å‹
- en: '[PRE19]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„
- en: Download the dataset from Github ([https://github.com/pytorch/tutorials/blob/main/_static/mnist.pkl.gz](https://github.com/pytorch/tutorials/blob/main/_static/mnist.pkl.gz))
    and keep it in the **data/mnist** directory.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: ä» Github ([https://github.com/pytorch/tutorials/blob/main/_static/mnist.pkl.gz](https://github.com/pytorch/tutorials/blob/main/_static/mnist.pkl.gz))
    ä¸‹è½½æ•°æ®é›†å¹¶å°†å…¶ä¿å­˜åœ¨ **data/mnist** ç›®å½•ä¸­ã€‚
- en: 'The full source code can be found in `Model_Inversion_Attack_Example.ipynb`.
    We are using PyTorch version 1.13.1 here:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæ•´çš„æºä»£ç å¯ä»¥åœ¨ `Model_Inversion_Attack_Example.ipynb` ä¸­æ‰¾åˆ°ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ PyTorch ç‰ˆæœ¬ 1.13.1ï¼š
- en: '[PRE20]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After loading the data, you can visualize one sample image using the Matplotlib
    library and obtain its shape. Hereâ€™s the code snippet:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½æ•°æ®åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ Matplotlib åº“å¯è§†åŒ–ä¸€ä¸ªæ ·æœ¬å›¾åƒå¹¶è·å–å…¶å½¢çŠ¶ã€‚ä»¥ä¸‹æ˜¯ä»£ç ç‰‡æ®µï¼š
- en: '[PRE21]'
  id: totrans-449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This results in the following output:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†äº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼š
- en: '![](img/B16573_02_13.jpg)'
  id: totrans-451
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16573_02_13.jpg)'
- en: '`(50000, 784) 5`'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '`(50000, 784) 5`'
- en: 'Now, convert the training samples into the tensor format in order to use the
    same in the neural network model as input:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå°†è®­ç»ƒæ ·æœ¬è½¬æ¢ä¸ºå¼ é‡æ ¼å¼ï¼Œä»¥ä¾¿åœ¨ç¥ç»ç½‘ç»œæ¨¡å‹ä¸­ä½œä¸ºè¾“å…¥ä½¿ç”¨ï¼š
- en: '[PRE22]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Letâ€™s build a simple sequential neural network model with linear layers using
    **rectified linear unit** (**ReLU**) as an activation function:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨ä½œä¸ºæ¿€æ´»å‡½æ•°çš„ **rectified linear unit** ï¼ˆ**ReLU**ï¼‰æ„å»ºä¸€ä¸ªç®€å•çš„é¡ºåºç¥ç»ç½‘ç»œæ¨¡å‹ï¼š
- en: '[PRE23]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '`AuthorsNN` class extends the `nn.Module` class from PyTorch. This class represents
    a neural network model designed for a classification task. Hereâ€™s a breakdown
    of the preceding code and its functionality:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '`AuthorsNN` ç±»æ‰©å±•äº† PyTorch çš„ `nn.Module` ç±»ã€‚æ­¤ç±»ä»£è¡¨ä¸€ä¸ªç”¨äºåˆ†ç±»ä»»åŠ¡çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚ä»¥ä¸‹æ˜¯å‰é¢ä»£ç åŠå…¶åŠŸèƒ½çš„åˆ†è§£ï¼š'
- en: '**The AuthorsNN class**: This class represents the neural network model designed
    by the author(s). It inherits from the **nn.Module** class, which is the base
    class for all neural network modules in PyTorch.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**The AuthorsNN ç±»**ï¼šæ­¤ç±»ä»£è¡¨ä½œè€…ï¼ˆä»¬ï¼‰è®¾è®¡çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚å®ƒç»§æ‰¿è‡ª PyTorch ä¸­æ‰€æœ‰ç¥ç»ç½‘ç»œæ¨¡å—çš„åŸºç±» **nn.Module**ã€‚'
- en: '**The __init__ method**: This method is the constructor of the **AuthorsNN**
    class and is called when an instance of the class is created. Inside this method,
    the architecture of the model is defined:'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**__init__ æ–¹æ³•**ï¼šæ­¤æ–¹æ³•æ˜¯ **AuthorsNN** ç±»çš„æ„é€ å‡½æ•°ï¼Œåœ¨åˆ›å»ºç±»çš„å®ä¾‹æ—¶è¢«è°ƒç”¨ã€‚åœ¨æ­¤æ–¹æ³•å†…éƒ¨ï¼Œå®šä¹‰äº†æ¨¡å‹çš„æ¶æ„ï¼š'
- en: '**self.first_sec** is a sequential module consisting of two layers:'
  id: totrans-460
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**self.first_sec** æ˜¯ä¸€ä¸ªç”±ä¸¤ä¸ªå±‚ç»„æˆçš„é¡ºåºæ¨¡å—ï¼š'
- en: '**nn.Linear(784, 450)** represents a linear layer with 784 input features and
    450 output features.'
  id: totrans-461
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.Linear(784, 450)** ä»£è¡¨ä¸€ä¸ªå…·æœ‰ 784 ä¸ªè¾“å…¥ç‰¹å¾å’Œ 450 ä¸ªè¾“å‡ºç‰¹å¾çš„çº¿æ€§å±‚ã€‚'
- en: '**nn.ReLU()** applies the ReLU activation function to introduce non-linearity.'
  id: totrans-462
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.ReLU()** åº”ç”¨ ReLU æ¿€æ´»å‡½æ•°ä»¥å¼•å…¥éçº¿æ€§ã€‚'
- en: '**self.second_sec** is another sequential module consisting of three layers:'
  id: totrans-463
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**self.second_sec** æ˜¯å¦ä¸€ä¸ªç”±ä¸‰ä¸ªå±‚ç»„æˆçš„é¡ºåºæ¨¡å—ï¼š'
- en: '**nn.Linear(450, 450)** represents a linear layer with 450 input features and
    450 output features.'
  id: totrans-464
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.Linear(450, 450)** ä»£è¡¨ä¸€ä¸ªå…·æœ‰ 450 ä¸ªè¾“å…¥ç‰¹å¾å’Œ 450 ä¸ªè¾“å‡ºç‰¹å¾çš„çº¿æ€§å±‚ã€‚'
- en: '**nn.ReLU()** applies the ReLU activation function.'
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.ReLU()** åº”ç”¨ ReLU æ¿€æ´»å‡½æ•°ã€‚'
- en: '**nn.Linear(450, 10)** represents a linear layer with 450 input features and
    10 output features, corresponding to the number of classes.'
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.Linear(450, 10)** ä»£è¡¨ä¸€ä¸ªå…·æœ‰ 450 ä¸ªè¾“å…¥ç‰¹å¾å’Œ 10 ä¸ªè¾“å‡ºç‰¹å¾çš„çº¿æ€§å±‚ï¼Œå¯¹åº”äºç±»åˆ«çš„æ•°é‡ã€‚'
- en: '**nn.Softmax(dim=-1)** applies the softmax activation function to convert the
    raw output scores into probabilities, ensuring they sum to **1** across classes.'
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.Softmax(dim=-1)** å°†åŸå§‹è¾“å‡ºåˆ†æ•°åº”ç”¨ softmax æ¿€æ´»å‡½æ•°è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œç¡®ä¿å®ƒä»¬åœ¨å„ä¸ªç±»åˆ«ä¸­æ€»å’Œä¸º **1**ã€‚'
- en: '**The forward method**: This method defines the forward pass of the model,
    specifying how input data flows through the network. The input, **x**, is passed
    through **self.first_sec**, followed by **self.second_sec**, and the resulting
    output is returned.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‰å‘æ–¹æ³•**ï¼šæ­¤æ–¹æ³•å®šä¹‰äº†æ¨¡å‹çš„å‰å‘ä¼ é€’ï¼ŒæŒ‡å®šè¾“å…¥æ•°æ®å¦‚ä½•é€šè¿‡ç½‘ç»œã€‚è¾“å…¥ **x** é€šè¿‡ **self.first_sec**ï¼Œç„¶åæ˜¯ **self.second_sec**ï¼Œæœ€ç»ˆè¿”å›è¾“å‡ºç»“æœã€‚'
- en: 'The following code creates an instance of the `AuthorsNN` class named `auth_nn`.
    This instance represents the initialized neural network model:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä»£ç åˆ›å»ºäº†ä¸€ä¸ªåä¸º`auth_nn`çš„`AuthorsNN`ç±»å®ä¾‹ã€‚æ­¤å®ä¾‹ä»£è¡¨åˆå§‹åŒ–çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼š
- en: '[PRE24]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Printing `auth_nn` will display information about the model, such as its architecture
    and the number of trainable parameters:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰“å°`auth_nn`å°†æ˜¾ç¤ºæœ‰å…³æ¨¡å‹çš„ä¿¡æ¯ï¼Œä¾‹å¦‚å…¶æ¶æ„å’Œå¯è®­ç»ƒå‚æ•°çš„æ•°é‡ï¼š
- en: '[PRE25]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, we define a loss function in order to measure the error between the actual
    data versus the predicted data:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•°æ¥è¡¡é‡å®é™…æ•°æ®ä¸é¢„æµ‹æ•°æ®ä¹‹é—´çš„è¯¯å·®ï¼š
- en: '[PRE26]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: To enhance the network, letâ€™s add the Adam optimizer function. This is an optimization
    algorithm that replaces **stochastic gradient descent** (**SGD**) for training
    DL models.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¢å¼ºç½‘ç»œï¼Œè®©æˆ‘ä»¬æ·»åŠ Adamä¼˜åŒ–å™¨å‡½æ•°ã€‚è¿™æ˜¯ä¸€ä¸ªä¼˜åŒ–ç®—æ³•ï¼Œç”¨äºæ›¿æ¢è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶ä½¿ç”¨çš„**éšæœºæ¢¯åº¦ä¸‹é™**ï¼ˆ**SGD**ï¼‰ã€‚
- en: 'It combines the desirable aspects of the `AdaGrad` and `RMSProp` algorithms,
    making it suitable for handling sparse gradients in noisy problem scenarios:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒç»“åˆäº†`AdaGrad`å’Œ`RMSProp`ç®—æ³•çš„ä¼˜ç‚¹ï¼Œä½¿å…¶é€‚åˆå¤„ç†å™ªå£°é—®é¢˜åœºæ™¯ä¸­çš„ç¨€ç–æ¢¯åº¦ï¼š
- en: '[PRE27]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Here, we import the `optim` module from PyTorch. After instantiating the `AuthorsNN`
    class, we define the Adam optimizer using the `optim.Adam()` function. The optimizer
    is initialized with the modelâ€™s parameters (`auth_nn.parameters()`), enabling
    it to optimize the model during training.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»PyTorchä¸­å¯¼å…¥`optim`æ¨¡å—ã€‚åœ¨å®ä¾‹åŒ–`AuthorsNN`ç±»ä¹‹åï¼Œæˆ‘ä»¬ä½¿ç”¨`optim.Adam()`å‡½æ•°å®šä¹‰Adamä¼˜åŒ–å™¨ã€‚ä¼˜åŒ–å™¨ä½¿ç”¨æ¨¡å‹çš„å‚æ•°ï¼ˆ`auth_nn.parameters()`ï¼‰åˆå§‹åŒ–ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼˜åŒ–æ¨¡å‹ã€‚
- en: 'Next, print `optimizer` to provide details about the modelâ€™s optimizerâ€™s configuration:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæ‰“å°`optimizer`ä»¥æä¾›æœ‰å…³æ¨¡å‹ä¼˜åŒ–å™¨é…ç½®çš„è¯¦ç»†ä¿¡æ¯ï¼š
- en: '[PRE28]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This results in the following output:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†äº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼š
- en: '[PRE29]'
  id: totrans-482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, train the neural network model with the MNIST training dataset that we
    loaded earlier and wrap it in a Python function:'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä½¿ç”¨æˆ‘ä»¬ä¹‹å‰åŠ è½½çš„MNISTè®­ç»ƒæ•°æ®é›†æ¥è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå¹¶å°†å…¶å°è£…åœ¨ä¸€ä¸ªPythonå‡½æ•°ä¸­ï¼š
- en: '[PRE30]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Letâ€™s break this code down:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åˆ†è§£è¿™æ®µä»£ç ï¼š
- en: '**The** **train** **function**: This function trains the neural network model
    (**ann**) for a specified number of epochs (**num_epochs**). The function assumes
    the presence of input data (**x_train**) and corresponding target labels (**y_train**)
    used for training the model. Here, **ann.train()** is called to set the model
    in training mode, enabling functionalities such as dropout and batch normalization.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**trainå‡½æ•°**ï¼šæ­¤å‡½æ•°ä½¿ç”¨æŒ‡å®šçš„epochæ•°é‡ï¼ˆ**num_epochs**ï¼‰è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆ**ann**ï¼‰ã€‚è¯¥å‡½æ•°å‡å®šå­˜åœ¨ç”¨äºè®­ç»ƒæ¨¡å‹çš„æ•°æ®ï¼ˆ**x_train**ï¼‰å’Œç›¸åº”çš„ç›®æ ‡æ ‡ç­¾ï¼ˆ**y_train**ï¼‰ã€‚åœ¨æ­¤ï¼Œè°ƒç”¨**ann.train()**å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œå¯ç”¨è¯¸å¦‚dropoutå’Œæ‰¹é‡å½’ä¸€åŒ–ç­‰åŠŸèƒ½ã€‚'
- en: '**The training loop**: For each epoch in the range of **num_epochs**, the following
    steps are executed:'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒå¾ªç¯**ï¼šåœ¨**num_epochs**çš„èŒƒå›´å†…ï¼Œå¯¹æ¯ä¸ªepochæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š'
- en: '**output = ann(x_train)**: Forward passes through the model, obtaining the
    output predictions.'
  id: totrans-488
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**output = ann(x_train)**ï¼šé€šè¿‡æ¨¡å‹è¿›è¡Œå‰å‘ä¼ é€’ï¼Œè·å¾—è¾“å‡ºé¢„æµ‹ã€‚'
- en: '**loss = loss_func(output, y_train)**: Computes the loss between the predicted
    output and the ground truth labels.'
  id: totrans-489
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**loss = loss_func(output, y_train)**ï¼šè®¡ç®—é¢„æµ‹è¾“å‡ºä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„æŸå¤±ã€‚'
- en: '**optimizer.zero_grad()**: Clears the gradients accumulated from the previous
    iteration.'
  id: totrans-490
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**optimizer.zero_grad()**ï¼šæ¸…é™¤ä¹‹å‰è¿­ä»£ç´¯ç§¯çš„æ¢¯åº¦ã€‚'
- en: '**loss.backward()**: Performs backpropagation to compute the gradients of the
    modelâ€™s parameters with respect to the loss.'
  id: totrans-491
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**loss.backward()**ï¼šæ‰§è¡Œåå‘ä¼ æ’­ä»¥è®¡ç®—æ¨¡å‹å‚æ•°ç›¸å¯¹äºæŸå¤±çš„æ¢¯åº¦ã€‚'
- en: '**optimizer.step()**: Updates the modelâ€™s parameters by applying the computed
    gradients using the chosen optimizer.'
  id: totrans-492
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**optimizer.step()**ï¼šé€šè¿‡åº”ç”¨è®¡ç®—å‡ºçš„æ¢¯åº¦å¹¶ä½¿ç”¨é€‰æ‹©çš„ä¼˜åŒ–å™¨æ¥æ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚'
- en: '**print(epoch, loss.item()**): Prints the current epoch number and the **loss**
    value.'
  id: totrans-493
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**print(epoch, loss.item()**): æ‰“å°å½“å‰epochç¼–å·å’Œ**loss**å€¼ã€‚'
- en: 'The **pass** statement: A placeholder that does nothing in this context and
    can be removed if not needed.'
  id: totrans-494
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**passè¯­å¥**ï¼šåœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­ä»€ä¹ˆéƒ½ä¸åšçš„å ä½ç¬¦ï¼Œå¦‚æœä¸éœ€è¦å¯ä»¥åˆ é™¤ã€‚'
- en: 'Now, train the neural network model with the MNIST training dataset that we
    loaded earlier with the authorâ€™s neural network model, which was built in the
    previous step with `100` epochs:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä½¿ç”¨æˆ‘ä»¬ä¹‹å‰åŠ è½½çš„MNISTè®­ç»ƒæ•°æ®é›†ä»¥åŠä½œè€…åœ¨ä¹‹å‰æ­¥éª¤ä¸­æ„å»ºçš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆä½¿ç”¨`100`ä¸ªepochï¼‰æ¥è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ï¼š
- en: '[PRE31]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Once the model is trained, it can be used for further predictions. Now, we will
    construct the adversary attacker model with the objective of recreating the training
    data.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå°±å¯ä»¥ç”¨äºè¿›ä¸€æ­¥çš„é¢„æµ‹ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªå¯¹æŠ—æ”»å‡»è€…æ¨¡å‹ï¼Œå…¶ç›®æ ‡æ˜¯é‡æ–°åˆ›å»ºè®­ç»ƒæ•°æ®ã€‚
- en: Adversary model to get the trained input data
  id: totrans-498
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å¯¹æŠ—æ¨¡å‹ä»¥è·å–è®­ç»ƒè¾“å…¥æ•°æ®
- en: 'Considering that the authorâ€™s model has been trained on the MNIST dataset and
    we have access to the size `450` vector output from the modelâ€™s first section
    (`first_sec`), we can utilize this information for our attack. Next, we will develop
    our adversary model. This model takes a size `450` vector as input, which corresponds
    to the output of the targetâ€™s first section. The adversary modelâ€™s objective is
    to generate a size `784` vector, matching the size of the original input data:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘åˆ°ä½œè€…çš„æ¨¡å‹æ˜¯åœ¨MNISTæ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰è®¿é—®æ¨¡å‹ç¬¬ä¸€éƒ¨åˆ†ï¼ˆ`first_sec`ï¼‰è¾“å‡ºçš„`450`å‘é‡å¤§å°ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™äº›ä¿¡æ¯è¿›è¡Œæ”»å‡»ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¼€å‘æˆ‘ä»¬çš„å¯¹æŠ—æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹ä»¥ä¸€ä¸ªå¤§å°ä¸º`450`çš„å‘é‡ä½œä¸ºè¾“å…¥ï¼Œè¿™å¯¹åº”äºç›®æ ‡çš„ç¬¬ä¸€éƒ¨åˆ†çš„è¾“å‡ºã€‚å¯¹æŠ—æ¨¡å‹çš„ç›®æ ‡æ˜¯ç”Ÿæˆä¸€ä¸ªå¤§å°ä¸º`784`çš„å‘é‡ï¼Œä¸åŸå§‹è¾“å…¥æ•°æ®çš„å¤§å°ç›¸åŒ¹é…ï¼š
- en: '[PRE32]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Based on the information available, the authorsâ€™ original model was trained
    on a dataset consisting of handwritten images. This knowledge provides us with
    an understanding of the modelâ€™s training data source.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ç°æœ‰ä¿¡æ¯ï¼Œä½œè€…çš„åŸæ¨¡å‹æ˜¯åœ¨åŒ…å«æ‰‹å†™å›¾åƒçš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„ã€‚è¿™ä¸€çŸ¥è¯†ä½¿æˆ‘ä»¬èƒ½å¤Ÿç†è§£æ¨¡å‹çš„è®­ç»ƒæ•°æ®æ¥æºã€‚
- en: To train our adversary model, we can utilize the MNIST test data. Specifically,
    we will use the first 1,000 rows of the MNIST test data to train our adversary
    model. After training, we can evaluate the accuracy of the adversary model using
    the MNIST test data ranging from the 1,000th row to the 2,000th row.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„å¯¹æŠ—æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨MNISTæµ‹è¯•æ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨MNISTæµ‹è¯•æ•°æ®çš„å‰1000è¡Œæ¥è®­ç»ƒæˆ‘ä»¬çš„å¯¹æŠ—æ¨¡å‹ã€‚è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»ç¬¬1000è¡Œåˆ°ç¬¬2000è¡Œçš„MNISTæµ‹è¯•æ•°æ®æ¥è¯„ä¼°å¯¹æŠ—æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚
- en: 'Letâ€™s train the adversary model:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è®­ç»ƒå¯¹æŠ—æ¨¡å‹ï¼š
- en: '[PRE33]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To assess the similarity between the recreated data and the original trained
    images from the training dataset, we can utilize the Matplotlib library to visualize
    the images. By plotting the recreated image, we can determine the level of resemblance
    it holds with the original trained images:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯„ä¼°é‡å»ºæ•°æ®ä¸è®­ç»ƒæ•°æ®é›†ä¸­åŸå§‹è®­ç»ƒå›¾åƒä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨Matplotlibåº“æ¥å¯è§†åŒ–å›¾åƒã€‚é€šè¿‡ç»˜åˆ¶é‡å»ºå›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®šå®ƒä¸åŸå§‹è®­ç»ƒå›¾åƒçš„ç›¸ä¼¼ç¨‹åº¦ï¼š
- en: '[PRE34]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This results in the following output:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¼è‡´äº†ä»¥ä¸‹è¾“å‡ºï¼š
- en: '![](img/B16573_02_14.jpg)'
  id: totrans-508
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16573_02_14.jpg)'
- en: It is evident that the images generated using model inversion attacks closely
    resemble the training data. This example demonstrates the successful recreation
    of training data without requiring complete knowledge of the model details, thereby
    achieving a model inversion attack.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç„¶ï¼Œä½¿ç”¨æ¨¡å‹åæ¼”æ”»å‡»ç”Ÿæˆçš„å›¾åƒä¸è®­ç»ƒæ•°æ®éå¸¸ç›¸ä¼¼ã€‚è¿™ä¸ªä¾‹å­å±•ç¤ºäº†æˆåŠŸé‡å»ºè®­ç»ƒæ•°æ®è€Œä¸éœ€è¦å®Œå…¨äº†è§£æ¨¡å‹ç»†èŠ‚ï¼Œä»è€Œå®ç°äº†æ¨¡å‹åæ¼”æ”»å‡»ã€‚
- en: Techniques to mitigate model inversion attacks
  id: totrans-510
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å‡è½»æ¨¡å‹åæ¼”æ”»å‡»çš„æŠ€æœ¯
- en: Mitigating model inversion attacks, where an adversary tries to infer sensitive
    training data from a trained modelâ€™s outputs, is crucial for preserving privacy
    and protecting sensitive information.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è½»æ¨¡å‹åæ¼”æ”»å‡»ï¼Œå³æ”»å‡»è€…è¯•å›¾ä»è®­ç»ƒæ¨¡å‹çš„è¾“å‡ºä¸­æ¨æ–­æ•æ„Ÿè®­ç»ƒæ•°æ®ï¼Œå¯¹äºä¿æŠ¤éšç§å’Œæ•æ„Ÿä¿¡æ¯è‡³å…³é‡è¦ã€‚
- en: 'Some techniques to mitigate model inversion attacks include the following:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è½»æ¨¡å‹åæ¼”æ”»å‡»çš„ä¸€äº›æŠ€æœ¯åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š
- en: '**Differential privacy**: Applying differential privacy mechanisms during the
    training process can help protect against model inversion attacks. Differential
    privacy adds controlled noise to the training data or modelâ€™s outputs, making
    it harder for an attacker to extract specific sensitive information from the modelâ€™s
    predictions. We will learn more about differential privacy in the next two chapters.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å·®åˆ†éšç§**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åº”ç”¨å·®åˆ†éšç§æœºåˆ¶å¯ä»¥å¸®åŠ©æŠµå¾¡æ¨¡å‹åæ¼”æ”»å‡»ã€‚å·®åˆ†éšç§é€šè¿‡å‘è®­ç»ƒæ•°æ®æˆ–æ¨¡å‹çš„è¾“å‡ºæ·»åŠ å—æ§å™ªå£°ï¼Œä½¿å¾—æ”»å‡»è€…ä»æ¨¡å‹çš„é¢„æµ‹ä¸­æå–ç‰¹å®šæ•æ„Ÿä¿¡æ¯å˜å¾—æ›´åŠ å›°éš¾ã€‚æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„ä¸¤ç« ä¸­å­¦ä¹ æ›´å¤šå…³äºå·®åˆ†éšç§çš„çŸ¥è¯†ã€‚'
- en: '**Limit access to sensitive output**: Restricting access to sensitive model
    output or predictions can help mitigate model inversion attacks. By carefully
    controlling who has access to the output and under what circumstances, you can
    reduce the risk of an adversary inferring sensitive training data.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é™åˆ¶å¯¹æ•æ„Ÿè¾“å‡ºçš„è®¿é—®**ï¼šé™åˆ¶å¯¹æ•æ„Ÿæ¨¡å‹è¾“å‡ºæˆ–é¢„æµ‹çš„è®¿é—®å¯ä»¥å¸®åŠ©å‡è½»æ¨¡å‹åæ¼”æ”»å‡»ã€‚é€šè¿‡ä»”ç»†æ§åˆ¶è°å¯ä»¥è®¿é—®è¾“å‡ºä»¥åŠåœ¨ä»€ä¹ˆæƒ…å†µä¸‹è®¿é—®ï¼Œå¯ä»¥é™ä½æ”»å‡»è€…æ¨æ–­æ•æ„Ÿè®­ç»ƒæ•°æ®çš„é£é™©ã€‚'
- en: '**Preprocessing and postprocessing**: Applying preprocessing and postprocessing
    techniques to the data and modelâ€™s output can help protect against model inversion
    attacks. For example, data anonymization, aggregation, or transformation techniques
    can be applied to remove or obfuscate sensitive information from the input or
    output. We will learn more about data anonymization and aggregation in the subsequent
    chapters.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é¢„å¤„ç†å’Œåå¤„ç†**ï¼šå¯¹æ•°æ®å’Œæ¨¡å‹è¾“å‡ºåº”ç”¨é¢„å¤„ç†å’Œåå¤„ç†æŠ€æœ¯å¯ä»¥å¸®åŠ©æŠµå¾¡æ¨¡å‹åæ¼”æ”»å‡»ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥åº”ç”¨æ•°æ®åŒ¿ååŒ–ã€èšåˆæˆ–è½¬æ¢æŠ€æœ¯æ¥ä»è¾“å…¥æˆ–è¾“å‡ºä¸­ç§»é™¤æˆ–æ¨¡ç³Šæ•æ„Ÿä¿¡æ¯ã€‚æˆ‘ä»¬å°†åœ¨åç»­ç« èŠ‚ä¸­äº†è§£æ›´å¤šå…³äºæ•°æ®åŒ¿ååŒ–å’Œèšåˆçš„å†…å®¹ã€‚'
- en: '**Regularization**: Incorporating regularization techniques such as L1 or L2
    regularization during the model training process can help improve privacy by reducing
    the modelâ€™s reliance on specific sensitive features. Regularization can help prevent
    overfitting and limit the leakage of sensitive information through the modelâ€™s
    predictions.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ­£åˆ™åŒ–**ï¼šåœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ç»“åˆæ­£åˆ™åŒ–æŠ€æœ¯ï¼Œå¦‚L1æˆ–L2æ­£åˆ™åŒ–ï¼Œå¯ä»¥å¸®åŠ©é€šè¿‡å‡å°‘æ¨¡å‹å¯¹ç‰¹å®šæ•æ„Ÿç‰¹å¾çš„ä¾èµ–æ¥æé«˜éšç§æ€§ã€‚æ­£åˆ™åŒ–å¯ä»¥å¸®åŠ©é˜²æ­¢è¿‡æ‹Ÿåˆå¹¶é™åˆ¶é€šè¿‡æ¨¡å‹é¢„æµ‹æ³„éœ²çš„æ•æ„Ÿä¿¡æ¯ã€‚'
- en: '**Generative adversarial networks** (**GANs**): Using generative models such
    as GANs can help protect against model inversion attacks. By generating synthetic
    data that preserves the statistical properties of the original data, GANs can
    provide alternative output for the attacker without revealing specific sensitive
    training instances.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ**ï¼ˆ**GANs**ï¼‰ï¼šä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼Œå¦‚GANsï¼Œå¯ä»¥å¸®åŠ©æŠµå¾¡æ¨¡å‹åæ¼”æ”»å‡»ã€‚é€šè¿‡ç”Ÿæˆä¿ç•™åŸå§‹æ•°æ®ç»Ÿè®¡ç‰¹æ€§çš„åˆæˆæ•°æ®ï¼ŒGANså¯ä»¥ä¸ºæ”»å‡»è€…æä¾›æ›¿ä»£è¾“å‡ºï¼Œè€Œä¸ä¼šæ³„éœ²ç‰¹å®šçš„æ•æ„Ÿè®­ç»ƒå®ä¾‹ã€‚'
- en: '**Secure multi-party computation** (**MPC**): Leveraging secure MPC protocols
    can enable multiple parties to collaboratively train a model while keeping their
    individual training data private. Secure MPC ensures that no party can access
    the sensitive data of others, thereby mitigating model inversion attacks.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®‰å…¨å¤šæ–¹è®¡ç®—**ï¼ˆ**MPC**ï¼‰ï¼šåˆ©ç”¨å®‰å…¨MPCåè®®å¯ä»¥ä½¿å¤šä¸ªæ–¹èƒ½å¤Ÿåä½œè®­ç»ƒæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒå„è‡ªçš„è®­ç»ƒæ•°æ®ç§å¯†ã€‚å®‰å…¨MPCç¡®ä¿æ²¡æœ‰ä»»ä½•ä¸€æ–¹å¯ä»¥è®¿é—®å…¶ä»–æ–¹çš„æ•æ„Ÿæ•°æ®ï¼Œä»è€Œå‡è½»æ¨¡å‹åæ¼”æ”»å‡»ã€‚'
- en: '**Secure aggregation**: In scenarios where models are trained using a distributed
    setting, secure aggregation protocols can be employed to prevent sensitive information
    leakage during the aggregation of model updates. This protects against model inversion
    attacks during the training process.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®‰å…¨èšåˆ**ï¼šåœ¨æ¨¡å‹ä½¿ç”¨åˆ†å¸ƒå¼è®¾ç½®è¿›è¡Œè®­ç»ƒçš„æƒ…å¢ƒä¸­ï¼Œå¯ä»¥é‡‡ç”¨å®‰å…¨èšåˆåè®®æ¥é˜²æ­¢åœ¨æ¨¡å‹æ›´æ–°èšåˆè¿‡ç¨‹ä¸­æ•æ„Ÿä¿¡æ¯æ³„éœ²ã€‚è¿™å¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿æŠ¤å…å—æ¨¡å‹åæ¼”æ”»å‡»ã€‚'
- en: '**Access control and authorization**: Implementing access control measures
    and strong authorization mechanisms can help restrict access to sensitive model
    output, limiting the exposure to potential attackers. Only authorized entities
    should have access to sensitive predictions or output.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è®¿é—®æ§åˆ¶å’Œæˆæƒ**ï¼šå®æ–½è®¿é—®æ§åˆ¶æªæ–½å’Œå¼ºå¤§çš„æˆæƒæœºåˆ¶å¯ä»¥å¸®åŠ©é™åˆ¶å¯¹æ•æ„Ÿæ¨¡å‹è¾“å‡ºçš„è®¿é—®ï¼Œå‡å°‘æ½œåœ¨æ”»å‡»è€…çš„æš´éœ²ã€‚åªæœ‰æˆæƒå®ä½“åº”æœ‰æƒè®¿é—®æ•æ„Ÿé¢„æµ‹æˆ–è¾“å‡ºã€‚'
- en: '**Synthetic data generation**: Instead of training models directly on sensitive
    data, using synthetic data generated from the original data can help mitigate
    model inversion attacks. Synthetic data retains the statistical characteristics
    of the original data but does not expose sensitive information.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åˆæˆæ•°æ®ç”Ÿæˆ**ï¼šä¸æ˜¯ç›´æ¥åœ¨æ•æ„Ÿæ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯ä½¿ç”¨ä»åŸå§‹æ•°æ®ç”Ÿæˆçš„åˆæˆæ•°æ®å¯ä»¥å¸®åŠ©ç¼“è§£æ¨¡å‹åæ¼”æ”»å‡»ã€‚åˆæˆæ•°æ®ä¿ç•™äº†åŸå§‹æ•°æ®çš„ç»Ÿè®¡ç‰¹æ€§ï¼Œä½†ä¸ä¼šæš´éœ²æ•æ„Ÿä¿¡æ¯ã€‚'
- en: '**Model monitoring**: Continuously monitoring the modelâ€™s behavior for any
    unusual patterns or unexpected output can help detect potential model inversion
    attacks. Monitoring can involve techniques such as outlier detection, adversarial
    robustness checks, or statistical analysis of model predictions.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹ç›‘æ§**ï¼šæŒç»­ç›‘æ§æ¨¡å‹çš„è¡Œä¸ºï¼Œå¯»æ‰¾ä»»ä½•å¼‚å¸¸æ¨¡å¼æˆ–æ„å¤–è¾“å‡ºï¼Œå¯ä»¥å¸®åŠ©æ£€æµ‹æ½œåœ¨çš„æ¨¡å‹åæ¼”æ”»å‡»ã€‚ç›‘æ§å¯èƒ½æ¶‰åŠå¼‚å¸¸æ£€æµ‹ã€å¯¹æŠ—é²æ£’æ€§æ£€æŸ¥æˆ–æ¨¡å‹é¢„æµ‹çš„ç»Ÿè®¡åˆ†æç­‰æŠ€æœ¯ã€‚'
- en: Like the previous two attacks, Itâ€™s important to note that choosing mitigation
    techniques depends on the specific context, the sensitivity of the data, and the
    desired level of privacy protection. Multiple techniques can be combined to achieve
    stronger privacy guarantees against model inversion attacks.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å‰ä¸¤æ¬¡æ”»å‡»ä¸€æ ·ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œé€‰æ‹©ç¼“è§£æŠ€æœ¯å–å†³äºå…·ä½“æƒ…å¢ƒã€æ•°æ®çš„æ•æ„Ÿæ€§å’Œæ‰€éœ€çš„éšç§ä¿æŠ¤æ°´å¹³ã€‚å¯ä»¥å°†å¤šç§æŠ€æœ¯ç»“åˆèµ·æ¥ï¼Œä»¥å®ç°æ›´å¼ºçš„éšç§ä¿éšœï¼ŒæŠµå¾¡æ¨¡å‹åæ¼”æ”»å‡»ã€‚
- en: Summary
  id: totrans-524
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: To summarize, we have covered different types of ML (supervised and unsupervised)
    and explored how to save and execute models in various formats. Additionally,
    we delved into the different phases of ML (data extraction, data preparation,
    model development, model deployment, and inferencing) and discussed the privacy
    threats and attacks associated with each phase in detail.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“æ¥è¯´ï¼Œæˆ‘ä»¬å·²ç»æ¶µç›–äº†ä¸åŒç±»å‹çš„æœºå™¨å­¦ä¹ ï¼ˆç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ ï¼‰ï¼Œå¹¶æ¢è®¨äº†å¦‚ä½•ä»¥å„ç§æ ¼å¼ä¿å­˜å’Œæ‰§è¡Œæ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ·±å…¥æ¢è®¨äº†æœºå™¨å­¦ä¹ çš„ä¸åŒé˜¶æ®µï¼ˆæ•°æ®æå–ã€æ•°æ®å‡†å¤‡ã€æ¨¡å‹å¼€å‘ã€æ¨¡å‹éƒ¨ç½²å’Œæ¨ç†ï¼‰ï¼Œå¹¶è¯¦ç»†è®¨è®ºäº†ä¸æ¯ä¸ªé˜¶æ®µç›¸å…³çš„éšç§å¨èƒå’Œæ”»å‡»ã€‚
- en: In the next chapter, we will dive deeper into privacy-preserving data analysis
    and focus on understanding the concept of differential privacy. This will allow
    us to explore techniques and methodologies that ensure privacy while conducting
    data analysis tasks. By gaining a thorough understanding of differential privacy,
    we can better safeguard sensitive information and mitigate privacy risks in the
    context of ML.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ›´æ·±å…¥åœ°æ¢è®¨éšç§ä¿æŠ¤æ•°æ®åˆ†æï¼Œå¹¶ä¸“æ³¨äºç†è§£å·®åˆ†éšç§çš„æ¦‚å¿µã€‚è¿™å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ¢ç´¢ç¡®ä¿åœ¨æ‰§è¡Œæ•°æ®åˆ†æä»»åŠ¡æ—¶ä¿æŒéšç§çš„æŠ€æœ¯å’Œæ–¹æ³•ã€‚é€šè¿‡å…¨é¢ç†è§£å·®åˆ†éšç§ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°ä¿æŠ¤æ•æ„Ÿä¿¡æ¯å¹¶å‡è½»æœºå™¨å­¦ä¹ ç¯å¢ƒä¸­çš„éšç§é£é™©ã€‚
