- en: '*Chapter 6*: Advanced Model Building – Part II'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part I*, we detailed the process for building an enterprise-grade
    **supervised learning** model on the H2O platform. In this chapter, we round out
    our advanced model-building topics by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Demonstrating how to build H2O supervised learning models within an Apache Spark
    pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing H2O's **unsupervised learning** method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussing best practices for updating H2O models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documenting requirements to ensure H2O model reproducibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We begin this chapter by introducing Sparkling Water pipelines, a method for
    embedding H2O models natively within a Spark pipeline. In enterprise settings
    where Spark is heavily utilized, we have found this to be a popular method for
    building and deploying H2O models. We demonstrate by building a Sparkling Water
    pipeline for **sentiment analysis** using data from online reviews of Amazon food
    products.
  prefs: []
  type: TYPE_NORMAL
- en: We then introduce the unsupervised learning methods available in H2O. Using
    credit card transaction data, we build an anomaly detection model using isolation
    forests. In this context, the unsupervised model would be used to flag suspicious
    credit card transactions in a financial fraud-prevention effort.
  prefs: []
  type: TYPE_NORMAL
- en: We conclude this chapter by addressing issues pertinent to models built in this
    chapter, as well as in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)*,
    Advanced Model Building – Part I*. These are best practices for updating H2O models
    and ensuring reproducibility of H2O model results.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Modeling in Sparkling Water
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UL methods in H2O
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practices for updating H2O models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring H2O model reproducibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code and datasets we introduce in this chapter can be found in the GitHub
    repository at [https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O](https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O).
    If you have not set up your H2O environment at this point, see [*Appendix*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268)
    *– Alternative Methods to Launch H2O Clusters for This Book,* to do so.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling in Sparkling Water
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We saw in [*Chapter 2*](B16721_02_Final_SK_ePub.xhtml#_idTextAnchor024), *Platform
    Components and Key Concepts,* that Sparkling Water is simply H2O-3 in an Apache
    Spark environment. From the Python coder''s point of view, H2O-3 code is virtually
    identical to Sparkling Water code. If the code is the same, why have a separate
    section for modeling in Sparkling Water? There are two important reasons, as outlined
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: Sparkling Water enables data scientists to leverage Spark's extensive data processing
    capabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sparkling Water provides access to production Spark pipelines. We expand upon
    these reasons next.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spark is rightly known for its data operations that effortlessly scale with
    increasing data volume. Since the presence of Spark in an enterprise setting is
    now almost a given, data scientists should add Spark to their skills toolbelt.
    This is not nearly as hard as it seems, since Spark can be operated from Python
    (using PySpark) with data operations written primarily in Spark SQL. For experienced
    Python and **Structured Query Language** (**SQL**) coders, this is a very easy
    transition indeed.
  prefs: []
  type: TYPE_NORMAL
- en: In the Lending Club example from [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part I*, data munging and **feature engineering** tasks
    were carried out using native H2O commands on the H2O cluster. These H2O data
    commands work in Sparkling Water as well. However, in an enterprise that has invested
    in a Spark data infrastructure, replacing H2O data commands with their Spark equivalents
    makes a lot of sense. It would then pass the cleaned dataset to H2O to handle
    the subsequent modeling steps. This is our recommended workflow in Sparkling Water.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Spark pipelines are frequently used in enterprise production settings
    for **extract, transform, and load** (**ETL**) and other data processing tasks.
    Sparkling Water's integration of H2O algorithms into Spark pipelines allows for
    seamless training and deployment of H2O models in a Spark environment. In the
    remainder of this section, we show how Spark pipelines can be combined with H2O
    modeling to create a Sparkling Water pipeline. This pipeline is easily promoted
    into production, a topic that we return to in detail in [*Chapter 10*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178),
    *H2O Model Deployment Patterns*.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Sparkling Water pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Figure 6.1* illustrates the Sparkling Water pipeline training and deployment
    process. The pipeline starts with an input data source for model training. Data
    cleaning and feature engineering steps are built sequentially from Spark transformers,
    with the outputs of one transformer becoming the inputs of the subsequent transformer.
    Once the dataset is in a modeling-ready format, H2O takes over to specify and
    build a model. We wrap all the transformer and model steps into a pipeline that
    is trained and then exported for production.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the production environment, we import the pipeline and introduce new data
    to it (in the following diagram, we assume this happens via a data stream, but
    the data could be arriving in batches as well). The pipeline outputs H2O model
    predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Sparkling Water pipeline train and deploy illustration'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 – Sparkling Water pipeline train and deploy illustration
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's create a pipeline to implement sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a sentiment analysis pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We next create a Sparkling Water pipeline for an sentiment analysis classification
    problem. Sentiment analysis is used to model whether a customer has positive or
    negative feelings toward a product or company. It typically requires **natural
    language processing** (**NLP**) to create predictors from text. For our example,
    we use a preprocessed version of the *Amazon Fine Food reviews* dataset from the
    **Stanford Network Analysis Platform** (**SNAP**) repository. (See [https://snap.stanford.edu/data/web-FineFoods.html](https://snap.stanford.edu/data/web-FineFoods.html)
    for the original data.)
  prefs: []
  type: TYPE_NORMAL
- en: Let's first verify that Spark is available on our system.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Spark startup in Jupyter notebook with PySparkling kernel'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.2 – Spark startup in Jupyter notebook with PySparkling kernel
  prefs: []
  type: TYPE_NORMAL
- en: You can see in the Spark output that the **SparkSession** has been started and
    the **SparkContext** initiated.
  prefs: []
  type: TYPE_NORMAL
- en: PySpark and PySparkling
  prefs: []
  type: TYPE_NORMAL
- en: '**PySpark** is Apache''s Python interface for Spark. It provides a shell for
    interactive Spark sessions and access to Spark components such as Spark SQL, DataFrames,
    and Streaming. **PySparkling** is the H2O extension of **PySpark**, enabling H2O
    services to be started on a Spark cluster from Python. Our Jupyter notebook uses
    a PySpark shell.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *internal backend* mode of Sparkling Water, H2O resources piggyback
    on their Spark counterparts, all within the same **Java virtual machine** (**JVM**).
    As illustrated inthe following diagram, an **H2OContext** that sits on top of
    the **SparkContext** is launched and H2O is initialized in each worker node of
    the Spark cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Sparkling Water internal backend mode'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.3 – Sparkling Water internal backend mode
  prefs: []
  type: TYPE_NORMAL
- en: 'PySparkling is used to create an H2OContext and initialize worker nodes, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Sparkling Water cluster immediately after launch'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.4 – Sparkling Water cluster immediately after launch
  prefs: []
  type: TYPE_NORMAL
- en: After the H2O server is launched, we interact with it using Python commands.
    We will start by importing the raw data.
  prefs: []
  type: TYPE_NORMAL
- en: Importing the raw Amazon data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We import the Amazon training data into a `reviews_spark` Spark DataFrame,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As an alternative, we could have imported the data using H2O and then converted
    the `reviews_h2o` H2O frame to the `reviews_spark` Spark DataFrame, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This approach has the advantage of allowing us to use H2O Flow for interactive
    data exploration, as demonstrated in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part I*, before converting to a Spark DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we print out the data schema to show the input variables and variable
    types. This is done with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting data schema is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Schema for Amazon Fine Food raw data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.5 – Schema for Amazon Fine Food raw data
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, we use only the `Time`, `Summary`, and overall `Score` columns
    in this analysis. `Time` is a date-time string, `Score` is an integer value between
    1 and 5, from which sentiment is derived, and `Summary` is a short text summary
    of the product review. Note that the `Text` column contains the actual product
    review. A better model choice would include `Text` in place of—or perhaps in addition
    to—`Summary`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the input data schema into the `schema.json` file using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Saving the input data schema will make the deployment of the Sparkling Water
    pipeline a very simple matter.
  prefs: []
  type: TYPE_NORMAL
- en: Input Data and Production Data Structure
  prefs: []
  type: TYPE_NORMAL
- en: Saving the data schema for deployment presumes that production data will use
    the same schema. As a data scientist building a Sparkling Water pipeline, we strongly
    recommend that your training input data exactly follows the production data schema.
    It is worth the extra effort to track this information down prior to model build
    rather than having to reengineer something at the deployment stage.
  prefs: []
  type: TYPE_NORMAL
- en: Defining Spark pipeline stages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Spark pipelines are created by stringing individual data operations or transformers
    together. Each transformer takes as its input the output data from the preceding
    stage, which makes development for a data scientist very simple. A large job can
    be broken down into individual tasks that are daisy-chained together.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark operates through lazy evaluation. This means that computations
    do not execute immediately; rather, operations are cached and execution occurs
    when an action of some sort is triggered. This approach has many advantages, including
    allowing Spark to optimize its compute.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, all the data cleaning and feature engineering steps will be
    created through Spark transformers. The pipeline is finalized by training an H2O
    XGBoost model. For clarity, we will define a stage number for each transformer
    as we proceed in building the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Stage 1 – Creating a transformer to select required columns
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Spark `SQLTransformer` class allows us to use SQL to munge data. The fact
    that most data scientists are already experienced with SQL makes for smooth adoption
    of Spark for data operations. `SQLTransformer` will be widely used in this pipeline.
    Run the following code to import the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a `colSelect` transformer, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we select the `Score`, `Time`, and `Summary` columns,
    converting the timestamp to a readable date-time string. `__THIS__` in the `FROM`
    statement references the output from the previous transformer stage. Since this
    is the first stage, `__THIS__` refers to the input data.
  prefs: []
  type: TYPE_NORMAL
- en: 'During development, it is helpful to check results at each stage by calling
    the transformer directly. This makes it easy to debug transformer code and understand
    which inputs will be available for the next stage. Calling the transformer will
    cause Spark to execute it along with all unevaluated upstream code. The following
    code snippet illustrates how to call the transformer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The first few rows are shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Results from the colSelect stage 1 transformer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.6 – Results from the colSelect stage 1 transformer
  prefs: []
  type: TYPE_NORMAL
- en: This first transformer has taken the original data and boiled it down to three
    columns. We will operate on each column separately to create our modeling-ready
    dataset. Let's begin with the `Time` column.
  prefs: []
  type: TYPE_NORMAL
- en: Stage 2 – Defining a transformer to create multiple time features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The goal of this model is to predict sentiment: was the review positive or
    negative? Date and time are factors that could arguably influence sentiment. Perhaps
    people give better reviews on Friday evenings because there is a weekend upcoming.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Time` column is stored internally as a timestamp. To be useful in modeling,
    we need to extract the date-and-time information in a format that is understandable
    by the predictive algorithms we employ. We define an `expandTime` transformer
    using SparkSQL data methods (such as `hour`, `month`, and `year`) to engineer
    multiple new features from the raw timestamp information, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `Score` and `Summary` are selected in the `expandTime` code, but
    we do not operate on them. This simply passes those columns along to subsequent
    transformers. We engineer several features from the `Time` column: `Day`, `Month`,
    `Year`, `WeekNum`, `Weekday`, `HourOfDay`, `Weekend`, and `Season`. And once more,
    `__THIS__` refers to the output from the `colSelect` stage 1 transformer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To check our progress in development and perhaps debug our code, we inspect
    the output of the second stage, which uses as its input the first-stage results
    stored in `selected`, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Results from the expandTime stage 2 transformer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.7 – Results from the expandTime stage 2 transformer
  prefs: []
  type: TYPE_NORMAL
- en: The output confirms that we have successfully replaced the `Time` column with
    a collection of newly created features.
  prefs: []
  type: TYPE_NORMAL
- en: Stage 3 – Creating a response from Score while removing neutral reviews
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this stage, we create our `Sentiment` response variable using values from
    the `Score` column. We could model *positive* versus *not positive* as the response,
    but we choose to remove neutral reviews (`Score=3`) and compare `Positive` with
    `Negative`. This is a standard approach in **net promoter score** (**NPS**) analyses
    and is common in sentiment analysis. It makes sense because we assume that records
    with a neutral response contain little information the model could learn from.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create our `createResponse` transformer like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The `IF` statement assigns scores of 1 or 2 to `Negative` sentiment and all
    others to `Positive`, filtering out neutral reviews with the `WHERE` clause. Now,
    inspect the results of this intermediate step by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Results from the createResponse stage 3 transformer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.8 – Results from the createResponse stage 3 transformer
  prefs: []
  type: TYPE_NORMAL
- en: The only remaining feature engineering steps are those replacing the text in
    the `Summary` column with appropriately representative numerical values. Stages
    4 through 8 will leverage Spark's built-in NLP data transformation capabilities
    to create features based on the text in `Summary`. While this is not a formal
    deep dive into NLP, we will describe each transformation step in enough detail
    to make our model understandable.
  prefs: []
  type: TYPE_NORMAL
- en: Stage 4 – Tokenizing the summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Tokenization breaks a text sequence into individual terms. Spark provides a
    simple `Tokenizer` class and a more flexible `RegexTokenizer` class, which we
    use here. The `pattern` parameter specifies a `"[!,\" ]"` `\"` escaped quote in
    the regex), and we specify `This` and `this` will be considered identical terms
    upon later processing. The code is illustrated in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Inspect the tokenized values from `Summary`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Results from the regexTokenizer stage 4 transformer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.9 – Results from the regexTokenizer stage 4 transformer
  prefs: []
  type: TYPE_NORMAL
- en: Phrases have now been broken up into lists of individual terms or tokens. Since
    our goal is to extract information from these tokens, we next filter out words
    that carry little information.
  prefs: []
  type: TYPE_NORMAL
- en: Stage 5 – Removing stop words
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some words occur so frequently in language that they have very little predictive
    value. These are termed *stop words* and we use Spark''s `StopWordsRemover` transformer
    to delete them, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s compare the tokenized results before and after removing stop words,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are displayed in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Results from the removeStopWords stage 5 transformer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.10 – Results from the removeStopWords stage 5 transformer
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspecting the results in *Figure 6.10* is illustrative. For the most part,
    removing stop words such as `as`, `it`, or `the` has little effect on meaning:
    the *Great! Just as good as the expensive brands!* statement being reduced to
    tokens `[great, good, expensive, brands]` seems reasonable. But what about *Not
    as advertised!* being reduced to `[advertised]`? The `not` in the statement would
    seem to carry important information that is lost by its removal. This is a valid
    concern that could be addressed by NLP concepts such as n-grams (bigrams, trigrams,
    and so on). For an example demonstrating Sparkling Water pipelines, we will acknowledge
    this as a potential issue but move on for simplicity.'
  prefs: []
  type: TYPE_NORMAL
- en: NLP in predictive modeling represents information in text as numbers. A popular
    approach is **term frequency-inverse document frequency** (**TF-IDF**). TF is
    simply the number of times a term appears in a document divided by the number
    of words in a document. In a corpus (collection of documents), IDF measures how
    rare a term is across its constituent documents. A term such as *linear* may have
    high frequency, but its information value decreases as the number of documents
    it appears in increases. On the other hand, a word such as *motorcycle* may have
    lower frequency but also be found in fewer documents in a corpus, making its information
    content higher. Multiplying TF by IDF gives a rescaled TF value that has proven
    quite useful. TF-IDF values are maximized when a term is found frequently but
    only in one document (*Which article reviewed motorcycles?*).
  prefs: []
  type: TYPE_NORMAL
- en: TF-IDF is widely used in information retrieval, text mining, recommender systems,
    and search engines, as well as in predictive modeling. The next two pipeline stages
    will compute the TF and IDF values, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Stage 6 – Hashing words for TF
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our preferred way to compute TF in Spark is `CountVectorizer`, which preserves
    the mapping from the index back to the word using an internal vocabulary. That
    is, `countVectorizerModel.vocabulary[5]` looks up the word stored in index 5.
  prefs: []
  type: TYPE_NORMAL
- en: 'A trick for building better TF-IDF models is to remove terms that are too infrequent
    by setting the `minDF` parameter as an integer or proportion, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`minDF = 100`: Omit terms that appear in fewer than 100 documents'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`minDF = 0.05`: Omit terms that appear in fewer than 5% of documents'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `maxDF` parameter is also available for removing terms that occur too frequently
    across a corpus. For instance, setting `maxDF = 0.95` in NLP for document retrieval
    might improve model performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a `countVectorizer` transformer, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that our corpus is the output column of the `removeStopWords` transformer,
    with each row as a document. We output the frequencies and set `minDF` to 100\.
    Because `countVectorizer` is a model, it is a good idea to manually train it before
    executing it in the pipeline. This is a good practice for any model that is a
    pipeline component as it allows us to determine its behavior and perhaps fine-tune
    it before pipeline execution commences. The code is illustrated in the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'We can explore this model by inspecting its vocabulary size and individual
    terms, as well as any other appropriate due diligence. Here''s the code we''d
    need to accomplish this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'The vocabulary results are shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.11 – Vocabulary size and vocabulary of the countVecModel transformer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.11 – Vocabulary size and vocabulary of the countVecModel transformer
  prefs: []
  type: TYPE_NORMAL
- en: 'Our total vocabulary size shown in *Figure 6.11* is 1,431 terms. Inspect the
    data with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'The vectorized result is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Intermediate results from the countVecModel transformer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.12 – Intermediate results from the countVecModel transformer
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6.12* shows the cleaned summary tokens with TF vectors side by side
    for each row. To describe the output for the first row, the 1431 value is the
    vocabulary size. The next sequence of values—`[1,10,11,38]`—refers to the indices
    of the `[good, quality, dog, food]` terms in the vocabulary vector. The last series
    of values— `[1.0,1.0,1.0,1.0]`—are the TFs for their respective terms. Thus, `dog`
    is referenced by index `11` and occurs once in the `CleanedSummary` column.'
  prefs: []
  type: TYPE_NORMAL
- en: Stage 7 – Creating an IDF model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We use Spark''s `IDF` estimator to scale frequencies from `countVectorizer`,
    yielding TF-IDF values. We execute the following code to accomplish this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Manually train the IDF model to see the results before we execute the pipeline,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Inspect the data again, noting especially the scaled TF-IDF frequencies, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'The first five rows of the resulting TF-IDF model are shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.13 – TF-IDF frequencies from the Spark transformer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.13 – TF-IDF frequencies from the Spark transformer
  prefs: []
  type: TYPE_NORMAL
- en: Stage 8 – Selecting modeling dataset columns
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In addition to the `Sentiment` response variable and all the features engineered
    from the `Time` variable, the output of `idf` includes the original `Summary`
    column as well as `Tokenized`, `CleanedSummary`, `frequencies`, and `TFIDF`. Of
    these, we wish to keep only `TFIDF`. The following code selects the desired columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: Now that we are finished building our model-ready data, the next step is to
    build a predictive model using one of H2O's supervised learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Stage 9 – Creating an XGBoost model using H2O
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Up to this point, all our data wrangling and feature engineering efforts have
    used Spark methods exclusively. Now, we turn to H2O to train an XGBoost model
    on the `Sentiment` column. For simplicity, we train using default settings. The
    code is illustrated in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: Note – Training Models in Sparkling Water
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082), *Advanced
    Model Building – Part I*, we demonstrated in detail a process for building and
    tuning a high-quality XGBoost model. We stop at a simple baseline model here to
    emphasize the utility of the overall pipeline. In a real application, much more
    effort should be spent on the modeling component of this pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Sparkling Water pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have all the transformers defined, we are ready to create a pipeline.
    Doing so is simple—we just name each transformer in order in the `stages` list
    parameter of `Pipeline`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'Training the pipeline model is made simple by using the `fit` method. We pass
    as a parameter the Spark DataFrame containing the raw data, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: During the `pipeline.fit` process, the data munging and feature engineering
    stages are all applied to the raw data in the order defined before the XGBoost
    model is fit. These pipeline stages operate identically after deployment in production
    with the XGBoost stage, producing predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Looking ahead – a production preview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Putting the Sparkling Water pipeline into production is simply a matter of
    *saving* the `pipeline` model, *loading* it onto the production system, then calling
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: In [*Chapter 10*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178), *H2O Model
    Deployment Patterns*, we show how to deploy this pipeline as a Spark streaming
    application, with the pipeline receiving raw streaming data and outputting predictions
    in real time.
  prefs: []
  type: TYPE_NORMAL
- en: UL methods in H2O
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: H2O includes several unsupervised learning algorithms including **Generalized
    Low Rank Models** (**GLRM**), **Principal Component Analysis** (**PCA**), and
    an aggregator for dimensionality reduction. Clustering use cases can utilize k-means
    clustering, H2O aggregator, GLRM, or PCA. Unsupervised learning also underlies
    a set of useful feature transformers used in predictive modeling applications—for
    example, the distance of an observation to a specific data cluster identified
    by an unsupervised method. In addition, H2O provides an isolation forest algorithm
    for anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: What is anomaly detection?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Most **machine learning** (**ML**) algorithms attempt, in some manner, to find
    patterns in data. These patterns are leveraged to make predictions in supervised
    learning models. Many unsupervised learning algorithms try to uncover patterns
    through clustering similar data or estimating boundaries between data segments.
    Unsupervised anomaly detection algorithms take the opposite approach: data points
    that do not follow known patterns are what we want to discover.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this context, the term *anomaly* is value-free. It may refer to an unusual
    observation because it is the first of its kind; more data could yield additional
    similar observations. Anomalies might be indicative of unexpected events and serve
    as a diagnostic. For instance, a failed sensor in a manufacturing data-collection
    application could yield atypical measurements. Anomalies may also indicate malicious
    actors or actions: security breaches and fraud are two classic examples resulting
    in anomalous data points.'
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection approaches may include supervised, semi-supervised, or unsupervised
    methods. Supervised models are the gold standard in fraud detection. However,
    obtaining labels for each observation can be costly and is often not feasible.
    An unsupervised approach is required when labels are absent. Semi-supervised approaches
    refer to situations where only some of the data records are labeled, usually a
    small minority of records.
  prefs: []
  type: TYPE_NORMAL
- en: Isolation forest is a unsupervised learning algorithm for anomaly detection—we'll
    introduce this next.
  prefs: []
  type: TYPE_NORMAL
- en: Isolation forests in H2O
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The isolation forest algorithm is based on decision trees and a clever observation:
    outliers tend to be split out very early in the building of a decision tree. But
    decision trees are a supervised method, so how is this unsupervised? The trick
    is to create a target column of random values and train a decision tree on it.
    We repeat this many times and record the average depth at which observations are
    split into their own leaf. The earlier an observation is isolated, the more likely
    it is to be anomalous. Depending on the use case, these anomalous points may be
    filtered out or escalated for further investigation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see a representation of an isolation forest in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14 – An isolation forest'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.14 – An isolation forest
  prefs: []
  type: TYPE_NORMAL
- en: We show how to build an isolation forest in H2O using the Kaggle credit card
    transaction data ([https://www.kaggle.com/mlg-ulb/creditcardfraud](https://www.kaggle.com/mlg-ulb/creditcardfraud)).
    There are 492 fraudulent and 284,807 non-fraudulent transactions in this dataset,
    which makes the target class highly imbalanced. Because we are demonstrating an
    unsupervised anomaly detection approach, we will drop the labeled target during
    the model build.
  prefs: []
  type: TYPE_NORMAL
- en: 'The H2O code for loading the data is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'We fit our isolation forest using the `H2OIsolationForestEstimator` method.
    We set the number of trees to `100` and omit the last column, which contains the
    target class label, as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the model is trained, prediction is straightforward, as we can see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15 – Isolation forest predictions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.15 – Isolation forest predictions
  prefs: []
  type: TYPE_NORMAL
- en: 'The predictions in *Figure 6.15* consist of two columns: the normalized anomaly
    score and the average number of splits across all trees to isolate the observation.
    Note that the anomaly score is perfectly correlated with mean length, increasing
    as mean length decreases.'
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we go from either an anomaly score or mean length to an actual prediction?
    One of the best ways is through a quantile-based threshold. If we have an idea
    about the prevalence of fraud, we can find the corresponding quantile value of
    the score and use it as a threshold for our predictions. Suppose we know that
    5% of our transactions are fraudulent. Then, we estimate the correct quantile
    using the following H2O code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting quantile output is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16 – Choosing a quantile-based threshold'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.16 – Choosing a quantile-based threshold
  prefs: []
  type: TYPE_NORMAL
- en: 'We now can use the threshold to predict the anomalous class using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'The first 10 observations of the `predictions` frame are shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.17 – Identifying anomalous values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_06_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.17 – Identifying anomalous values
  prefs: []
  type: TYPE_NORMAL
- en: The `predict` column in *Figure 6.17* has only one observation greater than
    0.198324, the threshold for the 95th percentile shown in *Figure 6.16*. The `predicted_class`
    column indicates this with a value of `1`. Also, note that the `mean_length` value
    for this observation of `6.14` is less than the mean length values for the other
    nine observations.
  prefs: []
  type: TYPE_NORMAL
- en: The `class` column contains the transaction fraud indicator that we omitted
    in building the unsupervised isolation forest model. For the anomalous observation,
    a class value of `0` indicates that the transaction was not fraudulent. When we
    have access to an actual target value as in this example, we could use the `predicted_class`
    and `class` columns to study the effectiveness of the anomaly detection algorithm
    in detecting fraud. We should note that the definition of fraud and anomalous
    in this context are not equivalent. In other words, not all frauds are anomalous
    and not all anomalies will indicate fraud. These two models have separate, albeit
    complementary, purposes.
  prefs: []
  type: TYPE_NORMAL
- en: We now turn our attention to updating models.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for updating H2O models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the famous British statistician George Box stated, *All models are wrong,
    but some are useful*. Good modelers are aware of the purpose as well as the limitations
    of their models. This should be especially true for those who build enterprise
    models that go into production.
  prefs: []
  type: TYPE_NORMAL
- en: One such limitation is that predictive models as a rule degrade over time. This
    is largely because, in the real world, things change. Perhaps what we are modeling—customer
    behavior, for example—itself changes, and the data we collect reflects that change.
    Even if customer behavior is static but our mix of business changes (think more
    teenagers and fewer retirees), our model's predictions will likely degrade. In
    both cases but for different reasons, the population that was sampled to create
    our predictive model is not the same now as it was before.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting model degradation and searching for its root cause is the subject
    of diagnostics and model monitoring, which we do not address here. Rather, once
    a model is no longer satisfactory, what should a data scientist do? We address
    retraining and checkpointing models in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Retraining models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Developing a parametric model entails:'
  prefs: []
  type: TYPE_NORMAL
- en: Finding the correct structural form for the process being modeled and then
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using data to estimate the parameters of that structure. Over time, if the structure
    of the model remains the same but the data changes, then we could *refit* (or
    *retrain* or *re-estimate* or *update*) the model's parameter estimates. This
    is a simple and relatively straightforward procedure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: However, if the underlying process changes in a way that means the structural
    form of the model is no longer valid, then modeling consists of both discovering
    the correct form of the model and estimating parameters. This is almost, but not
    quite, the same thing as starting from scratch. *Rebuilding* or *updating the
    model* (as opposed to *updating the parameter estimates*) are better terms for
    this larger activity.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of ML or other nonparametric models, the structural form of the
    model is determined by the data along with any parameter estimates. This is one
    of the selling points of nonparametric models: they are incredibly data-driven
    and nearly assumption-free. The differences between refitting or retraining and
    rebuilding have little meaning in this context; these terms become, in effect,
    synonyms.'
  prefs: []
  type: TYPE_NORMAL
- en: Checkpointing models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Checkpoint** option in H2O lets you save the state of a model build, allowing
    a new model to be built as a *continuation* of a previously generated model rather
    than building one from scratch. This can be used to update a model in production
    with additional, more current data.
  prefs: []
  type: TYPE_NORMAL
- en: The checkpoint option is available for **Distributed Random Forest** (**DRF**),
    **Gradient Boosting Machine** (**GBM**), XGBoost, and **deep learning** (**DL**)
    algorithms. For tree-based algorithms, the number of trees specified must be greater
    than the number of trees in the referenced model. That is, if the original model
    included 20 trees and you specify 30 trees, then 10 new trees will be built. The
    same concept is true for DL using epochs rather than trees.
  prefs: []
  type: TYPE_NORMAL
- en: 'Checkpointing is feasible for these algorithms *only* when the following are
    the same as the checkpointed model:'
  prefs: []
  type: TYPE_NORMAL
- en: The training data model type, response type, columns, categorical factor levels,
    and the total number of predictors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The identical validation dataset if one was used in the checkpointed model (cross-validation
    is not currently supported for checkpointing)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additional parameters that you can specify with checkpointing vary based on
    the algorithm that was used for model training.
  prefs: []
  type: TYPE_NORMAL
- en: Checkpointing Caveats
  prefs: []
  type: TYPE_NORMAL
- en: Although it is technically feasible, we do not recommend checkpointing on new
    data for GBM or XGBoost algorithms. Recall that boosting works by fitting sequential
    models to the residuals of previous models. The early splits are thus the most
    important. By the time new data has been introduced, the structure of the model
    has been largely determined in its absence.
  prefs: []
  type: TYPE_NORMAL
- en: Checkpointing **random forest** models does not suffer from these concerns due
    to differences between boosting and bagging.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring H2O model reproducibility
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a laboratory or experimental setting, repeating a process under the same
    protocols and conditions should lead to similar results. Natural variability may
    of course occur, but this can be measured and attributed to appropriate factors.
    This is termed *repeatability*. The enterprise data scientist should ensure that
    their model builds are well coded and sufficiently documented to make the process
    repeatable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Reproducibility** in the context of model building is a much stronger condition:
    the results when a process is repeated must be identical. From a regulatory or
    compliance perspective, reproducibility may be required.'
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, reproducibility requires the same hardware, software, data,
    and settings. Let's review this specifically for H2O setups. We begin with two
    cases depending on the H2O cluster type.
  prefs: []
  type: TYPE_NORMAL
- en: Case 1 – Reproducibility in single-node clusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A single-node cluster is the simplest H2O hardware configuration. Reproducibility
    can be attained if the following conditions are met:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Software requirements**: The same version of H2O-3 or Sparkling Water is
    used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data requirements**: The same training data is used (note that H2O requires
    files to be imported individually rather than as an entire directory to guarantee
    reproducibility).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sample_rate`, `sample_rate_per_class`, `col_sample_rate`, `col_sample_rate_per_level`,
    `col_sample_rate_per_tree`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If early stopping is enabled, reproducibility is only guaranteed when the `score_tree_interval` parameter
    is explicitly set and the same validation dataset is used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Case 2 – Reproducibility in multi-node clusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Adding nodes to a cluster creates additional hardware conditions that must
    be met in order to achieve reproducibility. The software, data, and settings requirements
    are the same as in single-node clusters detailed previously in *Case 1*. These
    requirements are outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: The hardware cluster must be configured identically. Specifically, clusters
    must have the same number of nodes with the same number of CPU cores per node
    or—alternatively—the same restriction on the number of threads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cluster's leader node must initiate model training. In Hadoop, the leader
    node is automatically returned to the user. In standalone deployments, the leader
    node must be manually identified. See the H2O documentation for more details.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For reproducibility, you must ensure that the cluster configuration is identical.
    The parallelization level (number of nodes and CPU cores/threads) controls how
    a dataset is partitioned in memory. H2O runs its tasks in a predictable order
    on these partitions. If the number of partitions is different, the results will
    not be reproducible.
  prefs: []
  type: TYPE_NORMAL
- en: In cases where the cluster configuration is not identical, it may be possible
    to constrain the resources of computations being reproduced. This process involves
    replicating data partitions in the original environment. We refer you to the H2O
    documentation for more information.
  prefs: []
  type: TYPE_NORMAL
- en: Reproducibility for specific algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The complexity of DL, GBM, and **automated ML** (**AutoML**) algorithms introduces
    additional constraints that must be met in order to ensure reproducibility. We
    will review these requirements in this section.
  prefs: []
  type: TYPE_NORMAL
- en: DL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: H2O DL models are not reproducible by default for performance reasons. There
    is a `reproducible` option that can be enabled, but we recommend doing this only
    for small data. The model takes significantly more time to generate because only
    one thread is used for computation.
  prefs: []
  type: TYPE_NORMAL
- en: GBM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GBM is deterministic up to floating-point rounding errors when reproducibility
    criteria are met for single- or multi-node clusters.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To ensure reproducibility in AutoML, the following criteria must be met:'
  prefs: []
  type: TYPE_NORMAL
- en: DL must be excluded.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `max_models` constraint rather than `max_runtime_secs` must be used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a rule, time-based constraints are resource-limited. This means that AutoML
    may be able to train more models on one run than another if available compute
    resources differ between runs. Specifying the number of models to build will ensure
    reproducibility.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for reproducibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To ensure reproducibility, think of the four requirement categories emphasized
    earlier: hardware, software, data, and settings. These categories are explained
    in more detail here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hardware**: You should always document the hardware resources the H2O cluster
    is running on—this includes the number of nodes, CPU cores, and threads. (This
    information can be found in the log files.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software**: You should document the version of H2O-3 or Sparkling Water used.
    (This information can be found in the log files.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data**: Obviously, you must use the same input data. You should save all
    scripts that were used to process the data prior to model training. All data column
    modifications should be documented (for example, if you converted a numeric column
    to a categorical one).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Settings**: Save the H2O logs and the H2O binary model. The logs contain
    a wealth of information. More importantly, the binary model contains the H2O version
    (software) and the parameters used to train the model (settings).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have rounded out our advanced modeling topics by showing
    how to build H2O models in Spark pipelines with a hands-on sentiment analysis
    modeling example. We summarized the unsupervised learning methods available in
    H2O and showed how to build an anomaly detection model using the isolation forest
    algorithm for a credit card fraud transaction use case. We also reviewed how to
    update models, including refitting versus checkpointing, and showed requirements
    to ensure model reproducibility.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127), *Understanding
    ML Models,* we discuss approaches for understanding and reviewing our ML models.
  prefs: []
  type: TYPE_NORMAL
