# 2

# 数据管理和传输

在[*第一章*](B18493_01.xhtml#_idTextAnchor015)《高性能计算基础》中，我们介绍了HPC应用的概念、为什么我们需要HPC以及它在不同行业的应用案例。在我们开始开发HPC应用之前，我们需要将所需数据迁移到云端。在本章中，我们将揭示管理和传输数据到云端的一些挑战以及缓解这些挑战的方法。我们将深入了解**AWS在线和离线数据传输服务**，使用这些服务您可以安全地将数据传输到AWS云端，同时保持数据完整性和一致性。我们将涵盖不同的数据传输场景，并提供如何为每个场景选择正确服务的指导。

在本章中，我们将涵盖以下主题：

+   数据管理的重要性

+   将数据迁移到云端的挑战

+   如何安全地将大量数据传输到云端

+   AWS在线数据传输服务

+   AWS离线数据传输服务

这些主题将帮助您了解如何以最小的干扰、成本和时间将**千兆字节**（**GB**）、**兆字节**（**TB**）或**拍字节**（**PB**）的数据传输到云端。 

让我们开始了解数据管理及其在HPC应用中的作用。

# 数据管理的重要性

**数据管理**是有效捕捉、存储和整理公司内不同应用程序创建的数据的过程，以确保在需要时数据准确、一致且可用。它包括制定管理您端到端数据生命周期的政策和程序。以下是一些特定于高性能计算（HPC）应用的数据生命周期元素，因此建立数据管理政策至关重要：

+   清洗和转换原始数据以执行详细的无误分析。

+   设计和构建数据管道以自动将数据从一个系统传输到另一个系统。

+   **提取、转换和加载**（**ETL**）数据到适当的数据存储系统，例如数据库、数据仓库、对象存储或文件系统，这些系统来自不同的数据源。

+   构建数据目录以存储元数据，使其更容易找到和跟踪数据血缘。

+   遵循您数据治理模型中概述的政策和程序。这也包括遵守数据被捕获和存储的国家联邦和地区当局的合规要求。例如，如果您是美国加利福尼亚州的一家医疗保健组织，您将需要遵守联邦和州的数据隐私法，包括**健康保险可携带性和问责制法案**（**HIPAA**）和加利福尼亚州的健康数据隐私法，即**医疗信息保密法案**（**CMIA**）。此外，您还需要遵守**加利福尼亚消费者隐私法案**（**CCPA**），该法案自2020年1月1日起生效，与医疗数据相关。如果您在欧洲，您将必须遵守欧盟的**通用数据保护条例**（**GDPR**）规定的数据指南。

+   在数据静止或传输过程中保护您的数据不受未经授权的访问。

现在我们已经了解了数据管理在HPC应用程序中的重要性，让我们看看将大量数据传输到云中的挑战。

# 将数据迁移到云中的挑战

为了开始在云上构建高性能计算（HPC）应用程序，您需要在云上拥有数据，并且还需要考虑您数据生命周期的各个方面，以便能够有效地管理数据。一种方法是编写用于传输数据的自定义代码，这将耗时且可能涉及以下挑战：

+   保留文件的权限和元数据。

+   确保数据传输不会影响其他现有应用程序的性能、可用性和可伸缩性，尤其是在在线数据传输（通过网络传输数据）的情况下。

+   在非工作时间安排数据传输，以确保不会阻碍其他应用程序。

+   在结构化数据方面，您可能需要考虑模式转换和数据库迁移。

+   维护数据完整性和验证传输。

+   监控数据传输的状态，能够查找先前传输的历史记录，并实施重试机制以确保传输成功。

+   确保没有重复项——一旦数据已传输，系统不应再次触发传输。

+   在传输过程中保护数据，这包括在传输中和静止时加密数据。

+   确保数据完整到达且未被损坏。您需要一个机制来检查到达目的地的数据与从源读取的数据匹配，以验证数据一致性。

+   最后但同样重要的是，您将不得不管理、版本控制和优化您的数据复制脚本。

AWS提供的数据传输和迁移服务可以帮助你在不编写和管理代码的情况下安全地将数据传输到云端，帮助你克服上述挑战。为了根据你的业务需求选择正确的服务，你首先需要构建一个数据传输策略。我们将在本章的下一节讨论AWS数据传输服务。让我们首先了解在构建你的策略时需要考虑的项目。

简而言之，你的数据传输策略需要考虑以下因素，以便以最小的干扰、时间和成本来迁移数据：

+   你在开发HPC应用时需要哪种类型的数据——例如，结构化数据、非结构化数据（如图像和PDF文档），或者两者的组合？

+   对于非结构化数据，你目前使用哪种文件系统来存储文件？是在**网络附加存储**（**NAS**）还是**存储区域网络**（**SAN**）上？

+   目前购买了多少存储空间可用，根据你数据增长的速度，在计划购买更多存储之前，这些存储空间还能使用多久？

+   对于结构化数据，你使用哪种数据库？

+   你是否受限于数据库许可证？如果是，它们何时到期，许可证的成本是多少？

+   你需要将多少数据传输到云端？

+   使用这些数据的其他应用有哪些？

+   这些应用是否需要本地访问数据？如果数据迁移到云端，现有的应用会有任何性能影响吗？

+   你的网络带宽是多少？是否足够用于网络数据传输？

+   你需要多快地将数据迁移到云端？

根据这些问题的答案，你可以制定你的数据策略，并选择合适的AWS服务，帮助你轻松地迁移数据并减轻前面提到的挑战。为了更好地理解，让我们转到下一个主题，看看如何通过一个简单的示例来安全地将大量数据传输到云端。

# 如何安全地将大量数据传输到云端

为了理解这个主题，让我们从一个简单的例子开始，您想要构建和训练一个计算机视觉深度学习模型来检测您的制造生产线上的产品缺陷。您在每个生产线上安装了摄像头，每天可以捕获数百张图片。每张图片的大小可以达到5 MB，您大约有1 TB的数据，目前存储在本地NAS文件系统中，您希望使用这些数据来训练您的机器学习模型。您大约有1 Gbps的网络带宽，需要在2-4周内开始训练模型。如果数据移动到云中，不会对其他应用程序产生影响，并且构建计算机视觉模型不需要结构化数据。让我们将以下信息重新组织成以下结构，这将成为您的数据策略文档的一部分：

+   **目标**: 将1 TB的图像数据传输到云中，其中文件大小可以达到5 MB。需要自动化数据传输，每晚复制大约10 GB的图片到云中。此外，在复制数据到云中时需要保留元数据和文件权限。

+   **时间表**: 2-4周

+   **数据类型**: 非结构化数据 – JPG或PNG格式的图像文件

+   **依赖项**: 无

+   **对现有应用程序的影响**: 无

+   **网络带宽**: 1 Gbps

+   **现有存储类型**: 网络附加存储

+   **数据传输目的**: 使用多个GPU在计算机视觉深度学习模型上执行分布式训练

+   **数据目的地**: 亚马逊S3，它是AWS上存储大量数据的最高效、最安全且最具成本效益的对象存储

+   **敏感数据**: 无，但数据不应可供公众访问

+   **本地数据访问**: 不需要

由于您有5 TB的数据，最大文件大小为5 MB，需要安全地传输到亚马逊S3，您可以使用AWS DataSync服务。这是一个AWS在线数据传输服务，通过使用**虚拟专用云**（**VPC**）端点迁移数据，以避免您的数据通过公开互联网。我们将在本章后面的部分详细讨论所有AWS数据传输服务。

下面的架构图直观地展示了数据传输的过程：

![图2.1 – 使用AWS DataSync和VPC端点进行数据传输](img/B18493_02_001.jpg)

图2.1 – 使用AWS DataSync和VPC端点进行数据传输

AWS DataSync代理在您的本地存储（在这种情况下为NAS）和AWS之间传输数据。您在本地网络中的虚拟机（**VM**）上部署代理，其中您的数据源位于。采用这种方法，您可以在使用**网络文件系统**（**NFS**）和**服务器消息块**（**SMB**）协议传输数据时最小化网络开销。

让我们在下一节更深入地了解AWS DataSync。

# AWS在线数据传输服务

在线数据传输服务是 AWS 为通过互联网在本地系统与 AWS 云之间传输数据而构建的即用型解决方案。它们包括以下服务：

+   AWS DataSync

+   AWS Transfer Family

+   Amazon S3 转加速

+   Amazon Kinesis

+   AWS Snowcone

让我们详细了解一下这些服务，以了解我们可以使用相关服务的场景。

## AWS DataSync

AWS DataSync 帮助您以快速、安全的方式克服从本地到 AWS 存储服务以及 AWS 存储服务之间传输数据的挑战。它还使您能够自动化或安排数据传输以优化网络带宽的使用，这可能与其他应用程序共享。您可以监控数据传输任务，添加数据完整性检查以确保数据传输成功，并验证数据在传输过程中未被损坏，同时保留文件权限和相关元数据。DataSync 提供与多个文件系统的集成，并允许您在以下资源之间传输数据：

+   本地文件服务器和对象存储：

    +   NFS 文件服务器

    +   SMB 文件服务器

    +   **Hadoop 分布式文件系统** (**HDFS**)

    +   自管理对象存储

+   AWS 存储服务：

    +   **Snow Family Devices**

    +   **Amazon Simple Storage Service** (**Amazon S3**) 存储桶

    +   **Amazon Elastic File System** (**EFS**)

    +   **Amazon FSx for Windows File Server**

    +   **Amazon FSx for Lustre** 文件系统

重要提示

我们将在 [*第 4 章*](B18493_04.xhtml#_idTextAnchor074)，*数据存储* 中详细讨论 AWS 存储服务。

### 用例

如前所述，AWS DataSync 用于通过网络传输数据到云。现在让我们看看一些可以使用 DataSync 的具体用例：

+   混合云工作负载，其中数据由本地应用程序生成，需要将数据从本地移动到 AWS 云进行处理，以及从 AWS 云返回本地。这可能包括医疗保健、制造、生命科学中的高性能计算应用、金融服务中的大数据分析以及研究目的。

+   将数据快速通过网络迁移到 AWS 存储服务，如 Amazon S3，您需要确保数据安全且完整地到达。DataSync 默认启用了传输过程中的加密和数据完整性。您还可以选择启用额外的数据验证检查，以比较源数据和目标数据。

+   数据归档，您希望将不常访问的数据（冷数据）直接存入 AWS 云中持久和长期存储，例如 **Amazon S3 Glacier** 或 **S3 Glacier Deep Archive**。这有助于您释放本地存储容量并降低成本。

+   安排数据传输作业，在一天中的特定时间自动重复启动，以优化网络带宽使用，这可能与其他应用程序共享。例如，在生命科学领域，你可能希望每天上传由本地应用程序生成的基因组数据，以进行数据处理和训练机器学习模型。你可以使用DataSync安排数据传输任务，并根据需要监控它们。

### AWS DataSync的工作原理

我们将使用架构图来展示DataSync如何将本地自管理存储系统与AWS存储服务以及AWS存储资源之间的数据传输。

我们将从本地存储到AWS存储服务开始。

#### 从本地到AWS存储服务的数据传输

*图2.2*中的架构图描述了从本地到AWS存储资源的数据传输：

![图2.2 – 使用AWS DataSync从本地到AWS存储服务进行数据传输](img/B18493_02_002.jpg)

图2.2 – 使用AWS DataSync从本地到AWS存储服务进行数据传输

**DataSync代理**是一个虚拟机，它从本地存储读取数据并将数据写入。你可以使用DataSync控制台或API配置和激活你的代理。这个过程将你的代理与你的AWS账户关联起来。一旦代理被激活，你就可以从控制台或API创建数据传输任务以启动数据传输。DataSync在传输过程中加密并执行数据完整性检查，以确保数据安全传输。你还可以启用额外的检查来验证复制到目标的数据与在源处读取的数据相同。此外，你还可以监控你的数据传输任务。DataSync传输数据所需的时间取决于你的网络带宽、数据量以及网络流量。然而，单个数据传输任务能够利用10-Gbps的网络链路。

#### AWS存储资源之间的数据传输

让我们深入了解一下，使用AWS DataSync在AWS存储资源之间进行数据传输。

*图2.3*中的架构图描述了在同一AWS账户中使用DataSync在AWS存储资源之间进行的数据传输。相同的架构也适用于同一区域内的数据传输以及跨区域传输：

![图2.3 – 使用AWS DataSync在AWS存储资源之间进行数据传输](img/B18493_02_003.jpg)

图2.3 – 使用AWS DataSync在AWS存储资源之间进行数据传输

如架构图所示，DataSync在同一个账户的AWS资源之间传输数据时不使用代理。然而，如果你想在不同AWS账户之间传输数据，那么你需要在AWS区域中设置并激活DataSync Amazon EC2代理。

总结来说，您可以使用AWS DataSync进行从本地到AWS存储服务的在线数据传输，以及AWS存储资源之间的数据传输。AWS DataSync快速、安全且经济高效地传输数据，同时确保数据完整性和一致性，无需编写和管理数据复制脚本。

现在，让我们继续介绍另一个AWS数据传输服务——AWS Transfer Family，它用于扩展您定期进行的商业对商业文件传输到Amazon S3和Amazon EFS。

## AWS Transfer Family

文件传输协议，如**文件传输协议**（**FTP**）、**安全文件传输协议**（**SFTP**）和**安全文件传输协议**（**FTPS**），在包括金融服务、医疗保健、制造业和零售在内的不同行业的商业对商业数据交换工作流程中普遍使用。AWS Transfer Family有助于扩展和迁移这些文件工作流程到AWS云。它使用FTP、SFTP和FTPS协议进行数据传输。它使您能够将文件传输到和从Amazon EFS和Amazon S3。

### 用例

正如讨论的那样，AWS Transfer Family使用FTP、SFTP和FTPS等协议，在商业对商业环境中进行数据交换工作流程。那么，让我们了解一些使用AWS Transfer Family将数据传输到和从Amazon S3和Amazon EFS的常见用例：

+   在您的组织内部或与第三方供应商之间安全地传输文件。一些行业，包括金融服务、生命科学和医疗保健，由于数据的敏感性和遵守如**支付卡行业数据安全标准**（**PCI DSS**）、HIPAA或GDPR等法规的必要性，必须确保有安全的文件传输工作流程。

+   为了向您的客户分发基于订阅的内容。例如，BluTV是土耳其一家著名的基于订阅的视频点播服务，它在全球范围内可用，并为土耳其语和阿拉伯语观众提供服务。之前，他们自行管理云上的SFTP设置，遇到了很多问题，例如管理用于将S3挂载到Amazon EC2的开源项目，以及需要额外资源时的扩展问题。在将他们的设置迁移到完全管理的AWS Transfer Family SFTP之后，他们不再需要监控文件传输，管理开源项目，或为未使用的资源付费。

+   在 AWS 上建立一个数据仓库（也称为数据湖），用于存储来自不同数据源和第三方（如供应商或合作伙伴）的结构化和非结构化数据。例如，FINRA，一个由美国政府授权的非营利组织，负责监管美国股票经纪人，它在 Amazon S3 上有一个数据湖作为其数据的主要来源。FINRA 使用 AWS Transfer Family 的 SFTP 服务来减轻运营负担，同时保持与现有身份验证系统连接，以便在将 SFTP 服务迁移到 AWS 的过程中避免任何中断。

既然我们已经讨论了一些 AWS Transfer Family 的用例，让我们看看它是如何工作的。

### AWS Transfer Family 的工作原理

*图2.4* 中的架构展示了如何使用 AWS Transfer Family 将文件从本地文件服务器传输到 Amazon S3 或 Amazon EFS，然后可以用于下游文件处理工作流程，例如内容分发、机器学习和数据分析：

![图2.4 – 使用 AWS Transfer Family 的文件传输工作流程](img/B18493_02_004.jpg)

图2.4 – 使用 AWS Transfer Family 的文件传输工作流程

您可以配置任何标准文件传输协议客户端，例如 WinSCP、FileZilla 或 OpenSSH，使用 AWS Transfer Family 首先传输到 Amazon S3 或 EFS。它将首先根据您配置的身份提供者类型对用户进行身份验证，一旦用户通过身份验证，它将启动文件传输。

到目前为止，我们已经看到了如何使用 AWS DataSync 和 AWS Transfer Family 通过网络传输数据，并了解了它们的用例以及这些服务如何以经济高效的方式在安全传输数据的同时减少运营负担。现在让我们看看如何使用 Amazon S3 传输加速来加速数据传输到 S3。

## Amazon S3 传输加速

**Amazon S3 传输加速**（**S3TA**）是 Amazon S3 存储桶中的一个功能，允许您在长距离上加速数据传输到 S3 存储桶，无论互联网流量如何，无需任何特殊客户端或专有网络协议。您可以使用传输加速功能将到和从 Amazon S3 的传输速度提高 50-500%。

一些用例包括以下内容：

+   从分布式位置到基于 Amazon S3 构建的数据湖（集中式数据存储库）的大文件，如实验室图像或媒体，进行时间敏感的传输。

+   具有文件上传或下载功能的 Web 或移动应用程序，其中用户地理位置分散，且距离目标 S3 存储桶较远。S3TA 可以加速这种远程文件传输，并帮助您提供更好的用户体验。

它使用Amazon CloudFront的全球分布式边缘位置、AWS骨干网络和网络协议优化来路由流量，这加快了传输速度，减少了互联网流量的可变性，并有助于在逻辑上缩短远程应用程序到S3的距离。

重要提示

使用Amazon S3传输加速会有额外费用。

我们已经讨论了使用在线数据传输服务，如AWS DataSync、AWS Transfer Family和S3TA，通过网络将数据从本地存储传输到AWS存储资源。可能存在一些场景，您希望将实时流数据传输到AWS云，例如，来自物联网传感器的遥测数据、用于在线流媒体应用的视频等。为此，我们将更深入地介绍Amazon Kinesis，这是一个由AWS构建的完全管理的流服务。

## Amazon Kinesis

**Amazon Kinesis**是一个**完全管理**的服务，用于在任何规模上实时收集、处理和分析流数据。流数据可以包括应用程序日志、音频、视频、网站点击流或物联网传感器数据，用于深度学习、机器学习、分析和其他应用。它允许您在数据到达时实时执行数据分析，而不是等待所有数据传输完成后再进行处理。

Amazon Kinesis包括以下服务：

+   **Kinesis视频流**：当您需要从连接的设备安全地将视频流传输到AWS进行应用，如处理、分析或机器学习以实时驱动洞察时使用。它具有内置的自动扩展机制，用于提供从数百万个设备接收视频流所需的基础设施。它自动加密静态数据和传输中的数据。它使用Amazon S3作为其底层存储，允许您可靠地存储和检索数据。这有助于您通过将其与其他完全管理的AWS服务集成或使用AWS上流行的开源机器学习框架来开发实时计算机视觉应用。*图2.5*展示了如何使用Kinesis视频流收集、处理和存储来自媒体设备的视频流，用于机器学习、分析和回放，并与其他媒体应用集成：

![图2.5 – 捕获、处理和存储用于机器学习、分析和回放的视频流](img/B18493_02_005.jpg)

图2.5 – 捕获、处理和存储用于机器学习、分析和回放的视频流

+   **Kinesis Data Streams**：这是一个全托管的无服务器服务，用于以经济高效的方式在任何规模上安全地传输数据。您可以通过调整您的容量每秒传输数吉字节的数据，或者以按需模式使用它来自动扩展和配置底层基础设施，以满足应用程序所需的容量。它具有与其他 AWS 服务内置的集成，并且您只需为使用的部分付费。*图 2.6* 展示了如何使用 Kinesis Data Streams 从不同的来源摄取、处理和存储生成的流数据，以实时获得洞察：

![图 2.6 – 将来自不同来源的数据捕获到 Amazon Kinesis Data Streams](img/B18493_02_006.jpg)

图 2.6 – 将来自不同来源的数据捕获到 Amazon Kinesis Data Streams

+   **Kinesis Data Firehose**：用于将数据安全地流式传输到基于 Amazon S3 构建的数据湖或数据仓库，如 Amazon Redshift，以进行进一步处理或分析，无需构建数据处理管道。让我们看看使用 Kinesis Data Firehose 的一些好处：

    +   它使您能够通过安全地提取、转换和加载流数据来轻松创建交付流，无需管理底层基础设施。

    +   它具有内置的自扩展功能，可以提供流应用程序所需的资源，无需任何持续管理。

    +   它使您能够使用内置或自定义转换来转换原始流数据。它支持将数据转换为不同的格式，如 Apache Parquet，并且可以动态分区数据，而无需构建任何自定义处理逻辑。

    +   您可以使用 Kinesis Firehose 中的机器学习模型来增强您的数据流，在数据传输到目的地时进行分析和推理。它通过实时监控和创建警报来提供增强的网络安全性，当使用 **安全信息和事件管理**（**SIEM**）工具检测到潜在威胁时。

    +   您可以连接到 30 多个 AWS 服务和流式传输目的地，这些服务与 Kinesis Data Firehose 完全集成。

*图 2.7* 展示了如何使用 Amazon Kinesis Data Firehose 进行 ETL 用例，而无需编写长行代码或管理大规模的自身基础设施：

![图 2.7 – 使用 Amazon Kinesis Data Firehose 进行 ETL](img/B18493_02_007.jpg)

图 2.7 – 使用 Amazon Kinesis Data Firehose 进行 ETL

+   **Kinesis Data Analytics**：此功能用于实时处理数据流，使用无服务器和完全管理的**Apache Flink**或SQL，从数据源如Amazon S3、Amazon Kinesis Data Streams和**Amazon Managed Apache Kafka**（**MSK**）（用于摄取和处理流数据）。它还可以用于从基于过去数据趋势的长时间运行的有状态计算中触发实时操作，如异常检测。它具有内置的自适应扩展机制，以匹配您的输入数据流的体积和吞吐量。您只需为使用的部分付费；与之相关的没有最低费用或设置成本。它可以帮助您实时了解数据，例如，通过为您的游戏应用程序构建排行榜，分析传感器数据，日志分析，Web点击流分析，构建流式ETL应用程序，或持续生成指标以了解数据趋势。

*图2.8*展示了典型的Kinesis Data Analytics应用程序的工作方式。它有三个主要组件：

+   一个用于执行实时分析的数据流输入源

+   **Amazon Kinesis Data Analytics Studio Notebook**，用于使用SQL查询和Python或Scala程序分析流数据

+   最后，它将处理后的结果存储在目标服务或应用程序上，例如Amazon Redshift或Amazon DynamoDB（NoSQL数据库）和Amazon Kinesis Data Streams：

![图2.8 – 使用Amazon Kinesis Data Analytics实时处理流数据](img/B18493_02_008.jpg)

图2.8 – 使用Amazon Kinesis Data Analytics实时处理流数据

在本节中，我们讨论了如何使用Amazon Kinesis将流数据传输和传输到AWS存储。有一些用例，如边缘计算和边缘存储，您可以使用**AWS Snowcone**，这是一种用于边缘计算、存储和数据传输的便携、坚固且安全的设备。接下来，让我们看看如何从AWS Snowcone在线传输数据到AWS。

## AWS Snowcone

AWS Snowcone是一种小型、坚固且便携的设备，用于运行边缘计算工作负载、边缘存储和数据传输。该设备重约4.5磅（2.1千克），具有多层安全和加密。它有8 TB的存储空间，而AWS Snowcone的**固态硬盘**（**SSD**）版本提供14 TB。Snowcone的一些常见用例如下：

+   医疗物联网，用于从紧急医疗车辆向医院传输关键和敏感数据，以加快数据处理速度并减少响应时间，更好地服务患者。然后，您可以安全地将数据传输到AWS云。

+   工业物联网，用于捕获传感器或机器数据，因为它可以承受工厂地板上发现的极端温度、振动和湿度，而传统的边缘设备可能无法工作。

+   从自动驾驶汽车和无人机捕获和存储传感器数据。

您可以使用 AWS DataSync，如 *AWS DataSync* 部分所述，通过网络从各种 AWS Snowcone 设备传输千兆字节的数据。

当您需要通过网络将高达千兆字节的数据传输到 AWS 时，AWS 在线数据传输服务非常有用。数据传输所需的时间取决于您的可用网络带宽和互联网流量。当您需要从偏远地点传输数据，或者当您的网络带宽被现有应用程序大量使用时，您就需要一个替代机制来离线传输数据。让我们在下一节中讨论 AWS 离线数据传输服务。

# AWS 离线数据传输服务

为了以安全且经济高效的方式通过离线方法传输高达千兆字节的数据，您可以使用 **AWS Snow Family 设备**。有时，您的应用程序可能需要在边缘进行增强性能，您希望在数据源附近处理和分析数据，以便提供实时有意义的见解。这意味着您需要 AWS 云之外的 AWS 管理的硬件和软件服务。AWS Snow Family 可以帮助您在数据中心外以及网络连接有限的偏远地点运行操作。

它包括以下设备：

+   **AWS Snowcone**：在 *AWS 在线数据传输服务* 部分中，我们介绍了 Snowcone 的使用方法，并讨论了如何使用 AWS DataSync 在边缘收集和存储数据，然后将其传输到 AWS 云。在网络带宽有限的情况下，您还可以通过将设备发送到 AWS 设施来进行离线数据传输。它包括一个电子墨水运输标签，这也有助于跟踪。

+   **AWS Snowball**：此设备用于数据迁移和边缘计算。它提供两种选择：

    +   Snowball Edge 计算优化版拥有 42 TB 的块存储或与 Amazon S3 兼容的存储，配备 52 个 vCPU 和可选的 GPU，用于边缘计算用例，如机器学习、视频分析和在具有间歇性网络连接的环境中的大数据处理，例如工业和交通用例，或在国防或军事应用中发现的极端偏远地区。

    +   Snowball Edge 存储优化版拥有 80 TB 的可用块存储或与 Amazon S3 兼容的对象存储，配备 40 个 vCPU 以在边缘进行计算。它主要用于本地存储或大规模离线数据传输到 AWS 云。

+   AWS Snowmobile 用于在 45 英尺长的运输集装箱中迁移高达 100 PB 的数据，该集装箱具有防篡改、防水和多层逻辑和物理安全性的温度控制功能。它非常适合需要传输埃字节或数百个佩字节数据的使用场景，这可能是由于数据中心关闭而发生的。您需要从 AWS Snow Family 控制台订购它，并且它作为网络附加的数据存储到达您的现场，连接到您的本地网络以执行高速数据传输。一旦数据被移动到设备上，它将被运回 AWS 设施，然后数据被上传到指定的 Amazon S3 存储桶。为确保数据在传输过程中的安全性以及数据成功交付到 AWS 设施，它配备了灭火、加密、专用安全人员、GPS 跟踪、警报监控、24/7 视频监控和护送安全车辆。

既然我们已经了解了 AWS 提供的各种离线数据传输选项，让我们了解订购设备的过程。

## 从 AWS Snow Family 订购设备的流程

要订购 AWS Snowmobile，您需要联系 AWS 销售支持。对于 Snowcone 或 Snowball 设备，您可以按照以下步骤操作：

1.  登录 AWS 控制台，在搜索栏中输入 `AWS Snow Family`。点击**AWS Snow Family**，这将带您进入 AWS Snow Family 控制台，如图 *图 2.9* 所示：

![图 2.9 – AWS Snow Family 控制台](img/B18493_02_009.jpg)

图 2.9 – AWS Snow Family 控制台

1.  点击阅读**订购 AWS Snow Family 设备**的橙色按钮，这将打开另一个屏幕，如图 *图 2.10* 所示。这将为您提供创建订购设备工作的步骤：

![图 2.10 – AWS Snow Family – 创建新工作](img/B18493_02_010.jpg)

图 2.10 – AWS Snow Family – 创建新工作

1.  点击**下一步**进入**步骤 2**，**开始导入到 S3 作业**，如图 *图 2.11* 所示：

![图 2.11 – 开始导入到 S3 作业](img/B18493_02_011.jpg)

图 2.11 – 开始导入到 S3 作业

1.  仔细阅读说明，勾选确认框，然后点击**下一步**进入**步骤 3**，**选择您的运输偏好**，如图 *图 2.12* 所示：

![图 2.12 – 选择您的运输偏好](img/B18493_02_012.jpg)

图 2.12 – 选择您的运输偏好

1.  填写您的运输详情，选择您首选的运输速度，然后点击**下一步**进入**步骤 4**，**选择您的工作详情**，如图 *图 2.13* 所示。请确保输入有效的地址，因为如果您的地址不正确，将会收到错误信息：

![图 2.13 – 选择您的工作详情](img/B18493_02_013.jpg)

图 2.13 – 选择您的工作详情

在此屏幕上，您可以选择您的 Snow 设备、电源、Snowcone 的无线选项、S3 存储桶、使用 EC2 实例进行计算，以及安装经过 AWS IoT Greengrass 验证的 AMI 的选项。

请注意，S3存储桶将显示为您的设备上的目录，并且这些目录中的数据将被传输回S3。如果您已选择AWS IoT Greengrass AMI在设备上运行IoT工作负载，您还需要选择**远程设备管理**选项，以便使用OpsHub或Snowball Client远程打开和管理设备。

重要提示

在*步骤4*中提到的所有选项在*图2.13* – *选择您的作业详情*中均未显示，但将在您的控制台屏幕上显示。

1.  在填写完作业详情后，点击**下一步**按钮进入**步骤5**，**选择您的安全首选项**，如图2.14所示：

![图2.14 – 选择您的安全首选项](img/B18493_02_014.jpg)

图2.14 – 选择您的安全首选项

1.  在此屏幕上选择您作业的权限和加密设置，这将帮助您在数据传输过程中保护您的数据，然后点击**下一步**进入**步骤6**，**选择您的通知首选项**，如图2.15所示：

![图2.15 – 选择您的通知首选项](img/B18493_02_015.jpg)

图2.15 – 选择您的通知首选项

1.  要接收关于工作状态变化的电子邮件通知，您可以选择现有的**简单通知服务**（**SNS**）主题或创建一个新的SNS主题。点击**下一步**进入**步骤7**，**审查并创建您的作业**，如图2.16所示：

![图2.16 – 审查并创建您的作业](img/B18493_02_016.jpg)

图2.16 – 审查并创建您的作业

1.  您可以审查从**步骤1**到**步骤7**输入的所有详细信息，然后点击**创建作业**按钮。

1.  作业创建完成后，将带您进入**作业**屏幕，如图2.17所示，在那里您可以查看作业的详细信息，包括状态：

![图2.17 – Snow Family作业](img/B18493_02_017.jpg)

图2.17 – Snow Family作业

重要提示

在**操作**下拉菜单中，您还有取消作业、编辑作业名称和克隆作业的选项。

在本节中，我们了解了AWS Snow Family设备，这些设备可以根据我们的应用需求、网络连接、可用带宽和数据源的位置离线传输数据。我们还讨论了如何使用这些设备不仅用于数据传输，还用于边缘计算。

关于这个话题最常问的问题之一是，我们如何根据网络速度和可用带宽来计算将数据移动到云中的时间？为此，AWS提供了一个基于最佳情况的简单公式，如下所示：

![](img/B18493_02_F01.jpg)

例如，如果我们有一个1.544 Mbps的网络连接，并且我们想要将1 TB的数据移动到和从AWS云中，那么理论上在80%的网络利用率下通过您的网络连接传输所需的最短时间是82天。

重要提示

请注意，此公式仅提供高级估计；实际所需时间可能会根据网络流量和可用带宽的变化而有所不同。

现在让我们简要地回顾一下本章中我们讨论的所有主题。

# 摘要

在本章中，我们讨论了数据管理的各个方面，包括数据治理以及符合数据所在国家联邦和地区当局的法律要求。我们还讨论了为了在云上构建高性能计算（HPC）应用，我们需要在云上拥有数据，并探讨了将此数据转移到云上的挑战。为了减轻这些挑战，我们可以使用托管的 AWS 数据传输服务，并且为了选择适用于您应用程序的服务，我们讨论了构建数据策略的要素。

然后，我们通过一个示例说明了如何将PB级数据转移到云上，以便理解数据传输策略中涉及的概念。最后，我们深入探讨了基于您的网络带宽、连接性、应用程序类型、数据传输速度和数据源位置，针对在线和离线数据传输的各种 AWS 数据传输服务。现在，我们了解了将数据传输到云上的机制、涉及的挑战以及如何减轻这些挑战，在下一章中，我们将专注于了解 AWS 为运行 HPC 应用程序提供的各种计算选项，以及如何根据应用程序需求进行优化。

# 进一步阅读

以下是本章的一些额外资源：

+   *迁移PB级数据*: [https://aws.amazon.com/getting-started/projects/migrate-petabyte-scale-data/](https://aws.amazon.com/getting-started/projects/migrate-petabyte-scale-data/)

+   *AWS 上 HPC 简介*: [https://d1.awsstatic.com/whitepapers/Intro_to_HPC_on_AWS.pdf](https://d1.awsstatic.com/whitepapers/Intro_to_HPC_on_AWS.pdf)

+   *数据管理 versus 数据治理*: [https://www.tableau.com/learn/articles/data-management-vs-data-governance](https://www.tableau.com/learn/articles/data-management-vs-data-governance)

+   *什么是 DataSync？*: [https://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html](https://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html)

+   *S3 转速加速*: [https://aws.amazon.com/s3/transfer-acceleration/](https://aws.amazon.com/s3/transfer-acceleration/)

+   *AWS 转移家族客户*: [https://aws.amazon.com/aws-transfer-family/customers/](https://aws.amazon.com/aws-transfer-family/customers/)

+   *Kinesis 数据流*: [https://aws.amazon.com/kinesis/data-streams/](https://aws.amazon.com/kinesis/data-streams/)

+   *Kinesis 视频流*: [https://aws.amazon.com/kinesis/video-streams/](https://aws.amazon.com/kinesis/video-streams/)

+   *Kinesis 数据分析*: [https://aws.amazon.com/kinesis/data-analytics/](https://aws.amazon.com/kinesis/data-analytics/)

+   *AWS Snowcone*: [https://aws.amazon.com/snowcone](https://aws.amazon.com/snowcone)

+   *AWS Snow Family*: [https://aws.amazon.com/snow/](https://aws.amazon.com/snow/)

+   *云数据迁移*: [https://aws.amazon.com/cloud-data-migration/](https://aws.amazon.com/cloud-data-migration/)
