<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Chatbots</h1>
                </header>
            
            <article>
                
<p>The era of chatbots has now arrived, a new technological phenomenon that has helped generate a new way of interacting with machines, consequently creating businesses. Chatbots are robots that interact with users through a chat and are able to assist them by carrying out extremely limited tasks: providing information on a current account, buying a ticket, receiving news about the weather, and so on.</p>
<p>A chatbot processes the text presented by the user, before responding based on a complex set of algorithms that interpret and identify what the user has said. After deducting what the user requires, it determines a set of appropriate responses based on the information extracted from the context. Some chatbots offer an extraordinarily authentic conversational experience, in which it is very difficult to determine if the agent is a bot or a human being.</p>
<p>Chatbots are also one of the most exciting innovations brought about by AI. In this chapter, after introducing the main concepts on which all of this technology is based, we will present the methods for building contextual chatbots and implement a simple chatbot end-to-end application on GCP.</p>
<p>Topics covered:</p>
<ul>
<li>Chatbot fundamentals</li>
<li>Chatbot design techniques</li>
<li>Natural language processing</li>
<li>Google Cloud Dialogflow</li>
<li>Chatbot building and implementation on GCP</li>
</ul>
<p>At the end of the chapter, the reader will have completed a hands-on introduction to chatbots and learned how to train a contextual chatbot while implementing it in a real web application.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chatbots fundamentals</h1>
                </header>
            
            <article>
                
<p>Chat bots, or chatbots, are programs that can interact through a chat with a human being, simulating their behavior. A conversation is then established between the human and the robot. Since the first developments in computer science, in collaboration with other disciplines, scholars have tried to reproduce<span> </span><span>typically human cognitive processes</span><span> through the use of machines. They are usually used for simple and repetitive activities, which may otherwise take a lot of time or which are not worth assigning a human resource.</span></p>
<p>Given their complexity, it is obvious that, in this case, you cannot speak of a satisfactory simulation of people's own behavior, but  can nevertheless begin to refer to the concept of AI.</p>
<p>The bot can execute a scheme and show its operation. Bots can do anything, from responding to messages automatically to allowing online purchases. They can receive news of any kind, release weather conditions, or show music videos, all exclusively via chat.</p>
<p>There are several platforms that implement the ability to use bots. These include: Telegram, Skype, Messenger, Slack, SMS, and email. The bots allow you to use these platforms—applications already known and used by the user for other features (such as messaging)<span>—</span>to perform within them the most disparate functions, saving the user's effort to use and install additional applications on the user's device.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chatbot history</h1>
                </header>
            
            <article>
                
<p>The history of chatbots begins much earlier than you may think. We are in England in the mid-20<sup>th</sup> century when Alan Turing, asking the question <em>Can machines think?</em>, proposes a test that links intelligence to the ability to hold a conversation. Since then, the challenge of creating software capable of simulating human language in an increasingly accurate manner has never stopped.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The imitation game</h1>
                </header>
            
            <article>
                
<p class="mce-root">In the 1950s, Alan Turing wrote an article called <em>Computing machinery and intelligence</em>, in which the problem was about establishing a criterion for determining whether a machine can think. The criterion is based on <em>The imitation game</em>, in which there is a computer <strong>A</strong>, a human <strong>B</strong>, and another human <strong>C</strong> (the interrogator). Human <strong>C</strong> must establish who is <strong>A</strong> and who is <strong>B</strong>. The interrogator asks both of them questions, to which <strong>A</strong> and <strong>B</strong> respond in writing. Computer <strong>A</strong> wins the game when <strong>C</strong> mistakes in judging <strong>A</strong>'s identity, believing it to be human. The following diagram shows an imitation game scheme:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-748 image-border" src="assets/585c227a-747a-46cb-8482-41057192280a.png" style=""/></div>
<p>Turing's game—despite numerous criticisms claiming that this criterion is not enough to establish whether a machine can think<span>—</span>has given rise to a challenge over the last decades that has led to the creation of software simulating human language in a way that is more and more accurate.</p>
<div class="packt_infobox">
<p>In 1990, a competition called the <strong>Loebner prize</strong> was established, based on the Turing test, to reward the computer whose behavior is most similar to human thought. This competition takes place every year. Here's the official website of the competition: <a href="http://www.aisb.org.uk/events/loebner-prize" target="_blank">http://www.aisb.org.uk/events/loebner-prize</a>.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Eliza</h1>
                </header>
            
            <article>
                
<p>In 1966, Joseph Weizenbaum created Eliza, a program that set out to create a parody of a conversation between a therapist and his patient in their initial phase. In it, an exchange of simple questions that do not require great emotional depth takes place. In the following screenshot, a simple Eliza chatbot is shown:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-746 image-border" src="assets/905b8ec8-7c09-4711-8368-6deea5989245.png" style=""/></div>
<p>Eliza relies on the use of regular expressions to transform user input into its outputs, so as to give continuity to the conversation as well as apparent consistency. At other times, it produces no contextual observations but stuff that is perfectly in line with the attitude of a psychotherapist, such as <em>very interesting</em>, <em>please</em>, <em>go on</em>, or c<em>an you elaborate on that?</em></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Parry</h1>
                </header>
            
            <article>
                
<p>Remaining in the medical field, Parry simulated the behavior of a person with paranoid schizophrenia. It was developed in 1972 by psychiatrist Kenneth Colby as a practice tool for his students before they could deal with real patients.</p>
<p>In a slight variation of the Turing test, psychiatrists were asked to read Parry's transcripts and those of real patients to distinguish which of the two they came from. It was an incredible result for that time; the psychiatrists managed to identify a difference in the behavior only 48 percent of the time.</p>
<p>In January 1973, as a demonstration during an international computer conference, computer science pioneer Vint Cerf decided to take bots to their logical conclusion. Using ARPANET, he set up a conversation between Eliza and Parry. It was a bicoastal meeting of the computer minds; <span>Eliza</span> was based at MIT and <span>Parry</span> at Stanford. The following is a brief excerpt of the conversation between the two bots:</p>
<ul>
<li>Eliza: <em>Good Evening. Tell me your problems. Please terminate input with a period or a question mark.</em></li>
<li><span>Parry</span>: <em>People get on my nerves sometimes.</em></li>
<li><span>Eliza</span>: <em>I am not sure I understand you fully.</em></li>
<li><span>Parry</span>: <em>You should pay more attention.</em></li>
<li><span>Eliza</span>: <em>Suppose you should pay more attention.</em></li>
<li><span>Parry</span>: <em>You're entitled to your own opinion.</em></li>
<li><span>Eliza</span>: <em>What makes you think I am entitled to my own opinion?</em></li>
<li><span>Parry</span>: <em>It bothers me just to be around people in general.</em></li>
<li><span>Eliza</span>: <em>Please go on.</em></li>
<li><span>Parry</span>: <em>I went to the track at Bay Meadows a while back.</em></li>
<li><span>Eliza</span>: <em>What does that suggest to you?</em></li>
<li><span>Parry</span>: <em>I went to the races.</em></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Jabberwacky</h1>
                </header>
            
            <article>
                
<p>Jabberwacky was created by programmer Rollo Carpenter in 1988. The aim of the bot was to pass the Turing test. Jabberwacky was able to simulate a human voice in a humorous way. Currently, <span>developments </span>are still ongoing on the bot, aimed at implementing the system on robots or talking pets, based on sound learning.</p>
<p>This is a bot based on machine learning; in fact, to interact with us, it uses only the material learned and borrows some of our intelligence while increasing its knowledge. Without hardcoded rules, it is based entirely on the principles of feedback.</p>
<p>Cleverbot is a variant of Jabberwacky released in 1997 that achieved great results; in 2011, it participated in a Turing test at IIT Guwahati in India and was considered a human at a 59.3% probability.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dr. Sbaitso</h1>
                </header>
            
            <article>
                
<p>Dr. Sbaitso was also designed to simulate the behavior of a psychologist able to solve emotional problems of users, and was usable by personal computers with the MS-DOS operating system. It was developed by Creative Labs in 1992, with the aim of demonstrating the ability of sound cards to generate a synthesized voice. The following screenshot shows the MS-DOS window with the welcome message in Dr. Sbaitso:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-742 image-border" src="assets/ea6fa792-4b3d-4971-a778-4b9f2a9c787d.png" style=""/></div>
<p class="NormalPACKT"><span>Most of the questions were</span> <kbd>WHY DO YOU FEEL THAT WAY?</kbd><span>. Thus avoiding more complicated interactions. When he received a sentence he could not understand, he usually answered <kbd>THAT'S NOT MY PROBLEM</kbd>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ALICE</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span><strong>Artificial Linguistic Internet Computer Entity</strong> (<strong>ALICE</strong>) was created as open source software based on <strong>Natural Language Processing</strong> (<strong>NLP</strong>). It was designed with the <strong>Artificial Intelligence Markup Language</strong> (<strong>AIML</strong>) by scientist Richard S. Wallace in 1995. Alice's interpretation system was based on a minimal approach. The meaning of a sentence was elaborated through specific keywords or terms (roots), avoiding in-depth and complex analyzes. Alice won the Loebner prize three times: in 2000, 2001, and 2004.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SmarterChild</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span>SmarterChild was a very successful chatbot and was available on AOL instant messenger and MSN messenger. Developed by ActiveBuddy Inc. in 2001, it was used by over 30 million users. From the rapid success of SmarterChild are derived marketing-oriented bots for Radiohead, Austin Powers, Intel, Keebler, Sporting News, and others.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IBM Watson</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT">Watson <span><span>is </span></span>an AI system developed by IBM in 2006, able to answer questions expressed in natural language. In the beginning, Watson was created to compete for an American television quiz called <strong>Jeopardy!</strong> At the first participation, however, it managed to answer only 35% of the questions. Following several improvements by an IBM team, Watson tried again in 2011, and this time it managed to defeat the human champions of the quiz.</p>
<p class="NormalPACKT"><span>During the game, Watson worked without being connected to the internet, exploiting an occupation of 4 terabytes of disk space. Later, it was used in many other completely different contexts, such as managing lung cancer treatment decisions at the Memorial Sloan-Kettering Cancer Center.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a bot</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span>In the first chatbots, quite simple algorithms were used to analyze the input message and return an output response; these algorithms were intended to simulate the computer's understanding of what was proposed in the input by providing consistent responses as output. As time passed and technology evolved, more and more sophisticated AI methods were created, with which the chatbots were able to establish conversations closer and closer to real ones between humans. From what basics is it necessary to start in order to correctly design chatbots? Fundamental topics in the bot building are intents, entities, and context. In the following section, we will analyze them to understand how to use them efficiently.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Intents</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span>The intent of a user is their purpose, the ultimate goal. Examples are ordering something, wanting to activate something on the user window, looking for shows, or simply saying goodbye. A chatbot should be able to perform some actions based on the intent it detects from the user's message.</span></p>
<p class="NormalPACKT"><span>Suppose we want to create a chatbot for a store that sells IT-related products. As a preliminary procedure, it is necessary to consider what actions the chatbot will be able to execute once requested by the user. For example, the chatbot will need to respond to the user with appropriate information when a user asks to see the products the store sells by supplying it: <strong>I want to buy a mouse</strong>. Similarly, when the user sends a message, such as <strong>Looking for a store in Rome</strong>, the chatbot should be able to locate all the stores near that particular location. To perform each of these actions, the chatbot must be able to distinguish between the two intentions of the user: searching for a product or a point of sale. In the following diagram, two possible intents are expressed by the user:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-752 image-border" src="assets/50d16893-9572-4706-9ef8-daccd32bb800.png" style=""/></div>
<p class="NormalPACKT"><span>Detecting intents from the user's message is a very common problem in the field of machine learning. This is the technique called <strong>text classification</strong>, in which the objective of the program is to classify documents/phrases in several classes that represent the intent of the user. Understanding what the user's request is is the intelligent part of the chatbot because there are many ways in which a request can be expressed in natural language. The chatbot will try to interpret the user's request by identifying the closes</span>t intent. Naturally, <span>the association will not always be precise; in fact, a ranking of possible interpretations is returned. But from this point of view the answers can be improved by providing more alternative examples of the same requests.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Entities</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span>Entities are the relevant subjects contained in the message coming from the user, for example, an object, a color, or a date. If the intent is to activate something on a web page, the user may also indicate what, like a button or a window. Entities are therefore the keywords that the chatbot can recognize. Thanks to these entities, the chatbot is able to identify the topic of the conversation, thus providing targeted information as output. In the following diagram, two possible entities are identified by the chatbot:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-743 image-border" src="assets/4a401ba2-673a-4e98-a9a5-8e6740dc162e.png" style=""/></div>
<p>Suppose we had the following message as an input: <kbd>I want to buy a monitor</kbd>. It is clear that the user wants to buy an IT product, but if the bot is not able to identify the type of product that the user is trying to buy, the information <span>returned</span><span> </span><span>will be about all types of IT products, many of which are not of interest to the user. If the chatbot is able to detect that the user is trying to buy a monitor, then it will only return information on this type of IT product, thus reducing the options available. And this is to the user's benefit.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Context</h1>
                </header>
            
            <article>
                
<p>Chatbots were created with the aim of simplifying and automating processes. So a chatbot fails if it complicates a process previously managed by humans in a simple way. For example, suppose you search for weather information. If you use the phone to request information, the service provider may use your phone number to look up your account information as your address. The same procedure should apply to chatbots. The context of a chatbot is extremely important if you aim to create a robot that is more or less efficient than using the phone.</p>
<p>When we talk about context in terms of chatbots, we refer to the fact that the bot is able to identify what it already knows and able to look only for the unknown information it needs to provide an appropriate solution. In this case, it has to provide information on weather in that area in the coming days. If this weather information chatbot uses the context appropriately, then it should not ask for information it already knows. The use of information already held by the bot, thanks to the maintenance of the context, makes the procedure for returning information much faster.</p>
<p>Once the intents and entities are put into the system, the logical flow of the conversation is created, because what distinguishes a conversation from simple <strong>Frequently Asked Questions</strong> (<strong>FAQs</strong>) is the context. Thanks to the context, it is possible to connect the user's current input to the previously mentioned one.</p>
<p>The context is passed back and forth between the chatbot and the user. It is the responsibility of the chatbot to maintain the context from one shift to the next of the conversation. A context includes a unique identifier for each conversation with a user, as well as a counter that is incremented at each turn of the conversation. If we do not preserve the context, every round of input seems to be the beginning of a new conversation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chatbots</h1>
                </header>
            
            <article>
                
<p>We do not have to start from scratch to design a chatbot. In fact, we can use the experience gained over time by programmers in the development of applications that we have analyzed in previous sections. All the information collected represents a know-how from which we can draw useful cues for our applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Essential requirements</h1>
                </header>
            
            <article>
                
<p>To start, we can take a look at the requirements that a great chatbot <span>must fulfill </span>to ensure the success of the service it provides. The following list mentions some key elements of chatbot design that we must keep in mind:</p>
<ul>
<li><strong>Guarantee minimum manual effort by the user</strong>: This represents the starting point in the design of a chatbot. For the success of the service, it is essential that the user is accompanied in their choices by minimizing manual intervention. This is achieved by drastically reducing the number of touches, keystrokes, or mouse clicks required to help the bot determine the best solution to the problem. To do this, you need to ensure that most of the options are provided by the same chatbot, with the user simply having to select the right option. In this way, considerable time savings are achieved in the interaction between user and chatbot.</li>
<li><strong>Predict the right options</strong>: To make sure that the system displays only the options related to that context, the right options must be provided through a series of choices. To achieve this, the system must be able to identify the user's needs. User needs must be identified with the least number of questions and manual efforts by users.</li>
<li><strong>Customization of the chatbot</strong>: This is the possibility to construct a different user chatbot interaction depending on the characteristics of the user of the service. For example, it is possible to make the system memorize user profiles, previous interactions, the interactions of other users in the system, the current context and environmental know-how. Each of these attributes must be understood together with others to truly understand users and what they may need now.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The importance of the text</h1>
                </header>
            
            <article>
                
<p>Before any text interpretation strategies can be applied, it is necessary to carry out a series of elaborations. In particular, the following phases are important:</p>
<ul>
<li><strong>Text cleaning</strong>: The text is cleaned of all the elements that can alter subsequent analyzes (for example, spaces at the beginning and at the end of the message)</li>
<li><strong>Verification of the characters of the text</strong>: It checks whether the text contains characters equivalent to others that could invalidate subsequent analysis</li>
<li><strong>Text normalization</strong>: Transformation of uppercase characters into lowercase is done so that the same word written with a capital letter instead of lowercase is interpreted in the same way (this approach is not always optimal since capitalization can sometimes have a discriminatory value)</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Word transposition</h1>
                </header>
            
            <article>
                
<p>This technique has been widely used by chatbots of the Eliza type. It consists of reformulating the input message to generate a corresponding output. For example, if the user writes <em>you are a chatbot</em> the answer of the chatbot will be <em>so you think I'm a chatbot</em>.</p>
<p>The substitutions that are made using this technique concern mainly personal pronouns (you → me) and verbs (you are → I am), <span>therefore</span><span> </span><span>transforming all forms in the first person into forms in the second person and vice versa.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Checking a value against a pattern</h1>
                </header>
            
            <article>
                
<p>Anyone who has ever used word processing programs has had to face the problem of searching for a text string within the period. Perhaps without knowing it, we came across the pattern matching problem. Pattern matching is a procedure in which you check whether a token sequence has a certain pattern, that is, a combination of characters that respects a certain pattern.</p>
<div>
<p>A lexical token, or simply token, is a string with an assigned and thus identified meaning. It is structured as a pair consisting of a token name and an optional token value. The token name is a category of lexical unit.</p>
</div>
<p>As for the interpretation of the inputs by a chatbot, pattern matching can be useful for recognizing certain message sets. For example, thanks to pattern matching, you can answer <em>Hello!</em> to all the messages that contain the word <em>hello</em> or <em>hi</em>; or you can recognize that a message is of question type by checking whether the last token is <em>?</em>.</p>
<p>A very useful tool for pattern recognition is regular expression, which offers a notation system for identifying sets of strings.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Maintaining context</h1>
                </header>
            
            <article>
                
<p>Storing the context is a strategy used to keep track of what has been said before, and to be able to reuse it for the conversation. This becomes necessary when the response of the chatbot cannot be based only on the last message sent by the user but must draw information from some previous message.</p>
<p>To better understand the usefulness of context management, let's take an example:</p>
<ul>
<li>User: <em>My name is Giuseppe.</em></li>
<li>Chatbot: <em>Okay Giuseppe.</em></li>
<li>User: <em>What is my name?</em></li>
<li>Chatbot: <em>You told me before calling you Giuseppe.</em></li>
</ul>
<p>If the user has not yet declared his name, the chatbot's answer will have to be something like:</p>
<ul>
<li>User: <em>What is my name?</em></li>
<li>Chatbot: <em>You still have not told me your name.</em></li>
</ul>
<p>It is <span>therefore </span><span>easy to understand how to manage the context to formulate an answer. This is extremely important in order to give the chatbot a much less mechanical and more human appearance.</span></p>
<p>Having memory of previous messages is also useful for detecting when the user sends a message repeatedly, or it can prevent the same chatbot from sending the same message by checking the value of the last message before choosing the next one.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chatbots architecture</h1>
                </header>
            
            <article>
                
<p>The main module of a chatbot is the dialogue manager. This module controls the flow of human-machine interaction. It receives the user's request as input and decides what the system's response should be. It will memorize the dialogue context in some form, for example, through pairs of key values, to manage the conversation on several steps between the user and the system.</p>
<p>For the dialogue manager to be able to choose the right answer for the request made by the user, it is necessary to understand the user's intention. In the most advanced chatbots, which are able to understand human language, the user's expressions will be translated into a semantic representation consisting of user intent and entity. This operation will be carried out by a module of natural language comprehension. This module must be previously trained to understand a series of user intent previously identified by the developer. This module is based on the <strong>natural language understanding</strong> (<strong>NLU</strong>) component.</p>
<p>In the case of voice input, the system must also be equipped with a voice recognition module that can translate the input into text before passing it to the natural language comprehension module. At the end of the operation, the system response (output) must first be treated with a speech synthesizer module that converts the textual response of the system into speech.</p>
<p>When user input is understood, the dialogue manager takes actions. To perform the action or generate the response, the dialogue manager retrieves the required information from the data sources. After this, a response message is generated by the response generation component and sent back to the user. The following diagram is a chatbot architecture scheme:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-745 image-border" src="assets/451904ec-d703-4bbb-84f9-81a7f5f6bae4.png" style=""/></div>
<p>To keep track of the context, the dialogue manager keeps the conversation status to know if the request is related to the previous conversation or introduces a new topic into the conversation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Natural language processing</h1>
                </header>
            
            <article>
                
<p>NLP is a field of computational linguistics that deals with the interaction between computers and natural languages.</p>
<div class="packt_tip">
<p>Computational linguistics deals with analysis and processing of natural language through the use of computer methodologies. It focuses on the development of descriptive formalisms of the functioning of natural language, such that they can be transformed into programs that can be executed by computers.</p>
</div>
<p>Traditionally, computers require that you interact with them through a programming language, so it should be a way of communicating that is precise, unambiguous, and highly structured, using a finite number of known commands. On the contrary, human language is not precise; it is often ambiguous, and the linguistic structure can depend on many different variables, such as dialects and various social contexts.</p>
<p>For this reason, NLP is an extremely important sector, as it studies and tries to solve all the difficulties encountered by a computer when it has to interpret or analyze human language. The numerous ambiguities of human language make comprehension of a human language by an algorithm particularly difficult. To understand a discourse, it is necessary to have more extensive knowledge of reality and of the surrounding world. Mere knowledge of the meaning of every single word is, in fact, not sufficient to correctly interpret the message of the sentence; on the contrary, it can lead to contradictory and meaningless communications.</p>
<p>The study of natural language takes place by phases performed in a precise sequence and characterized by a growing semantic value, as described here:</p>
<ul>
<li>Articulate and decode the sounds of a language that allows us to identify sounds and letters.</li>
<li>Know the words of a language, their structure (plural/singular), and their organization (noun, verb, and adjective). Lexical analysis identifies the lexicons that make up the language and find a definition in the dictionary. Morphological analysis identifies the plural/singular structure, verbal mode, and verbal time; and it assigns to each word its own morphological class, understood as adjective, noun, and verb.</li>
<li>Composition of words in complex constituents (part-of-speech). The syntax identifies the parts of the speech as subject, predicate, complement, or groups of words with a single meaning such as hot dog, or the nominal and verbal part with derivation of the full syntactic tree.</li>
<li>Assignment of meanings to simple and complex linguistic expressions. Semantics tries to identify the meaning of words according to the context.</li>
<li>Use of sentences in contexts, situations and ways appropriate for communication purposes. The pragmatist observes how and for what purposes the language is used, distinguishing whether it is a question of narration, dialogue, metaphor, and so on.</li>
</ul>
<p>The results obtained are then applied to the two main categories of NLP:</p>
<ul>
<li><strong>Natural Language Generation</strong> (<strong>NLG</strong>), which deals with the conversion of information from a database to a human-readable language</li>
<li>NLU, which transforms a human language into forms of representation that are easily manipulated by programs</li>
</ul>
<p>NLP faces many problems:</p>
<ul>
<li><strong>Speech segmentation</strong>: Conversion of a vocal track into characters and words with complete meaning</li>
<li><strong>Text segmentation</strong>: Recognition of individual words in texts written with ideograms instead of letters (Chinese, Japanese, Thai, and so on)</li>
<li><strong>Part-of-speech tagging</strong>: Identification of the grammatical elements of a sentence such as noun, adjective, verb, pronoun</li>
<li><strong>Word sense disambiguation</strong>: Deduction from the context of the meaning of a term normally used to indicate multiple concepts</li>
<li><strong>Imperfect or irregular input</strong>: Recognition and correction of any regional accents, typos, or errors produced by optical character recognition tools</li>
</ul>
<p>The difficulties of elaboration in the linguistic field can also be explained by considering the most evident characteristics of natural language itself:</p>
<ul>
<li>Flexibility, because it uses different ways to affirm the same fact</li>
<li>Ambiguity, because the same statement can have more than one meaning</li>
<li>Dynamism, caused by the continuous creation of new words</li>
</ul>
<p>Precisely because of these particularities, the understanding of natural language is often considered an AI-complete problem, that is, a problem whose resolution is compared to the equivalent of the creation of an AI. In fact, understanding texts requires understanding of the concepts associated with them, and therefore it requires extensive knowledge of reality and a great ability to manipulate it.</p>
<div class="packt_tip">
<p><strong>AI-complete</strong> are defined as the most difficult problems; that is, they present computational problems equivalent to that of solving the problem of AI itself—making computers as intelligent as people. The term AI-complete therefore indicates a problem that would not be solved by a simple specific algorithm.</p>
</div>
<p>For people, language comprehension is the result of a mental process that cannot be reproduced in a machine; moreover, language is a form of communication and interaction between people that reflects the surface of meaning and allows people to understand one another. While a computer, however sophisticated its software is, is nevertheless based on procedures determined a priori.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Natural language understanding</h1>
                </header>
            
            <article>
                
<p>NLU consists of reading a text expressed in natural language; determining its meaning by attributing a meaning to terms, sentences, and paragraphs present in it, and making inferences about these elements in order to elicit their explicit or implicit properties. In particular, one of the most salient issues in modeling a textual representation is to capture semantic relationships between concepts. To solve this task, several methodologies have been proposed in the literature, some of which talk of access to external knowledge bases. Others, instead, construct semantic distributive spaces, analyzing the content of the text collection without making use of prior knowledge.</p>
<p>Under the NLU definition, there is a wide range of computer applications, ranging from simple operations such as short commands given to robots, to complex operations, such as full comprehension of texts. In the real world, there is now a widespread use of algorithms based on NLU; for example, classification of text for attribution of labels in an email does not require a thorough understanding of the text, but it needs to deal with many vocabulary items.</p>
<p>The process of disassembling and parsing of text input is very complex, because of the occurrence of unknown and unexpected features in the input and the need to determine the appropriate syntactic and semantic schemes to apply to it (factors that are predetermined) when outputting the language. In the following diagram, you can see a flowchart of the NLU process:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-744 image-border" src="assets/a5db4d82-8a8a-4980-a170-3e0576b4ab0b.png" style=""/></div>
<p>NLU, helps us to analyze semantic features of input text and extract metadata from content, such as categories, concepts, emotion, entities, keywords, metadata, relations, and semantic roles. Through NLU, the developer makes a translation of text into a machine-readable formal representation, making relevant aspects of its content explicit.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Google Cloud Dialogflow</h1>
                </header>
            
            <article>
                
<p>The widespread use of conversational virtual assistance apps, from chatbots to IoT devices, capable of interacting with the most natural language possible, implies the need to create ever more engaging personal interactions. The challenge is twofold: not only that of recognizing and transmitting optimized basic information, but also that of involving users and helping them in their objectives. This presupposes the ability of the automatic system to adapt, as much as possible, its own language to that of the user to whom it is addressed, thanks to the analysis of data and the power of machine learning and AI technologies.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dialogflow overview</h1>
                </header>
            
            <article>
                
<p>Google responds to this challenge with Dialogflow, a platform for creating voice and text conversation applications based on machine learning. It supports 14 languages ​​and can be integrated with major chat platforms such as Google Assistant, Facebook Messenger, Slack, Skype, Telegram, and its own applications through the service APIs.</p>
<p>Recently, given the great demand from developers to add business functionality to the standard version, Google announced the release of Dialogflow Enterprise Edition, available in beta.</p>
<p>The following are some features offered by Dialogflow:</p>
<ul>
<li><strong>Conversational interactions based on machine learning</strong>: Dialogflow uses NLP to create faster conversation experiences and iterate faster. Just give some examples of what users may say, and Dialogflow will create a specific model that can learn which actions to activate and which data to extract to provide the most relevant and accurate answers.</li>
<li><strong>Create once and deploy everywhere</strong>: Use Dialogflow to create a conversational app and deploy it to your website, app, or 32 different platforms, including Google Assistant and other popular messaging services. Dialogflow also includes multilingual support and multilingual experiences to reach users from all over the world.</li>
<li><strong>Advanced fulfillment options</strong>: Fulfillment means the corresponding action in response to what the user says, such as processing a food order or activating the right answer to the user's question. For this purpose Dialogflow allows you to connect to any web hook whether it is hosted in the public Cloud or locally. The Dialogflow integrated code editor allows you to encode, test and implement these actions directly in the Dialogflow console.</li>
<li><strong>Voice recognition with speech recognition</strong>: Dialogflow enables the conversational app to respond to commands or voice conversations. It is available in a single API call that combines speech recognition with natural language comprehension.</li>
</ul>
<p>In addition to the understanding of natural language, it is also the flexibility of Dialogflow that allows developers to go beyond decision structures and features, such as deep integration with Cloud functions to write basic serverless scripts directly into its interface that distinguishes Dialogflow from some of its competitors. Dialogflow also simplifies the connection to other applications, regardless of where they are hosted. This is something you need if you want to integrate your conversational app with your ordering and shipping systems, for example.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Basics Dialogflow elements</h1>
                </header>
            
            <article>
                
<p>Before analyzing in detail a practical case of building a chatbot, it is advisable to analyze in detail the basic elements of Dialogflow. We'll now cover the most used elements in chatbot building.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Agents</h1>
                </header>
            
            <article>
                
<p>An agent is a program that responds to a specific task. It could be a hostess for hotel room reservations. Or it could be a business expert who knows all the products and price lists of an online store. Or it could a competent support technician for the household appliances we purchased. Or it could be the onboard computer of a car.</p>
<p>What is important is that an agent has a specific purpose and a limited baggage of knowledge; we are not interested in playing chess with the bot that makes flight bookings, and in any case it would not be able to do so.</p>
<p>With Dialogflow, the creation of an agent is very simple; just go to the initial page of the service, click on the <span class="packt_screen">CREATE AGENT</span> button, and give it a name, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/98059904-a3fb-4d62-92b5-75d75fe371ba.png" style=""/></div>
<div class="packt_infobox">
<p>To access Dialogflow, just use the URL <a href="https://dialogflow.com/">https://dialogflow.com/</a>. You can register or use a Google account and log in.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Intent</h1>
                </header>
            
            <article>
                
<p>An intent is what an end user can ask an agent. Booking a hotel room is an intent; another intent is the consultation of lunch hours, or the cancellation of a reservation that is already made.</p>
<p>Understanding what the user's request is is the intelligent part of the agent because there are many ways in which a request can be expressed in natural language, that is, what we humans talk about.</p>
<p>The agent will try to interpret the user's request by identifying the closest intent. Naturally, the association is not always precise; in fact a ranking of possible interpretations is returned. But, from this point of view, we can improve the answers by providing more alternative examples of the same requests. Also it is possible to apply machine learning algorithms in order to learn from the previous answers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Entity</h1>
                </header>
            
            <article>
                
<p>If an intent matches a request, the entity corresponds to the details. In booking a hotel room you need to know the exact date, the people who will stay, or the user's requests. From the design point of view of the agent, an entity such as hotel room is defined and it contains all the necessary details.</p>
<p>Dialogflow has a series of already-created system entities that facilitate the management of simpler concepts (for example, dates). The developer can define a series of entities (Dev entity) to generalize the behavior of the agent. Finally, the end user creates an entity for each request. A Dev entity can have values determined by a list, perform a mapping, or be in turn made up of other entities, and much more.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Action</h1>
                </header>
            
            <article>
                
<p>Until now, we have dealt with interpreting the user's request; now it is a matter of answering. In reality, the concept is broader; once we have understood a request, we can fulfill it, for example, by booking the room, opening a ticket, or communicating with the restaurant. But if what we are <span>making</span> is a chatbot, the answer will probably correspond to the action.</p>
<p>An action corresponds to the step your application will take when a specific intent has been triggered by a user's input. Both the action name and its parameters are defined in the action section of an intent.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Context</h1>
                </header>
            
            <article>
                
<p>What time does the guest arrive at the hotel? What did you eat? These are meaningless phrases without a context but become comprehensible in the context of a broader dialogue; this is what a context is for. The syntax for collecting a parameter from the context is very simple:</p>
<pre>  # context_name.parameter_name</pre>
<p>With Dialogflow, a context is maintained for 10 minutes or five requests.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a chatbot with Dialogflow</h1>
                </header>
            
            <article>
                
<p>After analyzing the main components of Dialogflow, it is time to focus on a practical application. In fact, we will create a simple chatbot that will help users to retrieve weather information about the most beautiful city in the world.</p>
<p>The first thing to do is to create the agent, that is, the project containing intents, entities, and answers that you want to deliver to the user. The intent is the mechanisms that collect what the user is requesting (using the entities) and direct the agent to respond accordingly. For simple answers that do not include information collected outside the conversation, you can define the answers directly in the intent. You can perform more advanced responses using your own logic and the web hooks for implementation.</p>
<div>
<p>The web hook is the URL to be invoked that hosts the code that implements the actions to be performed. Unlike other environments, Dialogflow also allows you to use the HTTP protocol (and not just the HTTPS protocol).</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Agent creation</h1>
                </header>
            
            <article>
                
<p>To create an agent, perform the following steps:</p>
<ol>
<li>If you don't have a Dialogflow account, sign up. If you have an account, log in.</li>
<li>Click on <span class="packt_screen">Create Agent</span> in the left navigation and fill in the fields. The following window is opened:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/0494622c-3864-42b9-a9ab-c93b2fc13b01.png" style=""/></div>
<p style="padding-left: 60px">In this window, we will have to set some parameters:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li>The name of the agent.</li>
<li>Primary language for your agent.</li>
<li>Time zone setting. Date and time are resolved using this time zone.</li>
<li>Google project. This enables Cloud functions, actions on Google, and permissions management.</li>
</ul>
</li>
</ul>
<div class="packt_tip">A series of agents (prebuilt agents) are already available for some types of requests that can be customized and enriched for your needs. The number of agents available depends on the language; more than 30 different agents are available in English.</div>
<ol start="3">
<li>Click on the <span class="packt_screen">Save</span> button.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Intent definition</h1>
                </header>
            
            <article>
                
<p>As we said previously, the user's intent is their purpose, the ultimate goal. Examples are ordering something, wanting to activate something on the user window, looking for shows, or simply saying goodbye. A chatbot should be able to perform some actions based on the intent it detects from the user's message.</p>
<p>To create an intent, click on the plus icon next to <span class="packt_screen">Intents</span>; the following window is opened:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/da5e5cf7-ab94-4968-8941-21c8922c16cd.png"/></div>
<p>In this window, we will have to set some parameters:</p>
<ul>
<li><span class="packt_screen">Intent name</span>: The name of the intent.</li>
<li><span class="packt_screen">Contexts</span>: This is used to manage the flow of the conversation.</li>
<li><span class="packt_screen">Events</span>: This is a feature that allows you to invoke intents by an event name instead of a user query. Events can be used by external services to trigger Dialogflow intents, for example, Google Assistant's built-in intents.</li>
<li><span class="packt_screen">Training phrases</span>: The phrases that identify the intent must be reported in natural language. You can use both examples (example mode identified with the " icon) and templates (template mode identified with the @ icon). Other examples of sentences are provided, the more the agent will be intelligent or he will be able to better recognize the user requests and to resolve ambiguities.</li>
<li><span class="packt_screen">Action and parameters</span>: This specifies the possible action to be executed and its parameters that can be extracted from the dialogue.</li>
<li><span class="packt_screen">Response</span>: The answers to be returned to the user when the intent has been recognized must be reported. To make it more human-like, you can enter different variations for the same answer. The answers can also be parameterized, and depending on the integration used, they can consist of rich messages.</li>
<li><span class="packt_screen">Fulfillment</span>: Call a web service to connect your backend. Send the intent, parameters, and context to your Cloud function or a web service. Execute the necessary logic and respond with a written, spoken, or visual response.</li>
</ul>
<p>When an example sentence is inserted, it is automatically noted, recognizing the parts that are collected as entity. An agent always contains a default fallback intent that collects all the cases in which no other intent has been recognized.</p>
<p>The first intent we want to insert has the purpose to specify the position related to our weather forecast. We said that an intent represents the user's purpose, so we need to think what questions the user may ask to receive weather forecasts. We need different intentions because there are many ways to ask the same thing. The process of identifying the intent is to map all the possible ways that the user can use to express an intent. The requests that we may expect from a user should be specified in the training phrases section. To start, let's insert the following phrases:</p>
<ul>
<li><kbd>What's the weather like in Rome</kbd></li>
<li><kbd>How's the weather in Rome</kbd></li>
<li><kbd>Weather in Rome</kbd></li>
<li><kbd>Rome weather forecast</kbd></li>
</ul>
<p>To insert a single phrase, simply add the user expression in the <span class="packt_screen">Training phrases</span> text field and then press <em>Enter</em> to add another phrase. We will notice that the sentence will be added to our declaration of intent. In particular, we can see that the word <span class="packt_screen">Rome</span> is highlighted. This means that it was noted as a parameter assigned to existing city entities, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-750 image-border" src="assets/0eedbdb4-6f76-4885-94c3-844a413f3130.png" style=""/></div>
<p>We continue to insert the sentences. After defining the location, it is necessary to define the time. It is clear that the user will need to know the predictions on a specific day, today or tomorrow for example. Then we also include these phrases:</p>
<ul>
<li><kbd>What is the weather today</kbd></li>
<li><kbd>Weather for tomorrow</kbd></li>
<li><kbd>Weather forecast in Rome today</kbd></li>
</ul>
<p>As before, the time parameter is also highlighted, this time with a different color. The last sentence is interesting as it contains both a <kbd>date</kbd> parameter and a <kbd>geo-city</kbd> parameter, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-751 image-border" src="assets/c0724bda-d70e-4400-9bcc-f2ea5072afa6.png" style=""/></div>
<p>To start, we leave the other fields as is and focus only on the answer that the chatbot will have to provide to the user. So far, we have not considered any external reference from which to retrieve the information requested by the user. This means that at least for now, we will have to insert vague answers like these:</p>
<ul>
<li><kbd>I'm sorry, I do not have this information right now</kbd></li>
<li><kbd>Forecasts for $date are not available</kbd></li>
<li><kbd>The weather forecast for $date in $geo-city is not available</kbd></li>
</ul>
<p>In the last two phrases, we have inserted the following reference entities: <kbd>$date</kbd> and <kbd>$geo-city</kbd>. So, when the agent responds, it takes into account the parameter values gathered and will use a reply that includes those values that it picked up.</p>
<p>Once we're done, we click on the <span class="packt_screen">Save</span> button. The following messages appear at the bottom right of the window:</p>
<ul>
<li><span class="packt_screen">Intent saved</span></li>
<li><span class="packt_screen">Agent training started</span></li>
<li><span class="packt_screen">Agent training completed</span></li>
</ul>
<p>The meaning is clear. Now that your agent can understand basic requests from the user, try out what you have made so far. To try the newly created agent, we can use the appropriate box available in the console at the top right. To do this, we simply need to type in a request. Let's try our agent by typing a slightly different request from the examples given in the <em>Training phrases</em> section. For example, we ask: <kbd>Hows the weather in Rome today</kbd>. After this, we press <em>Enter</em> and the following window is returned:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/cdf1b90f-4364-4fed-bf43-a84d316a997f.png" style=""/></div>
<p>We can understand the frustration of the user who has not recovered the searched information, but we can already be satisfied as the agent has correctly interpreted the question and provided a plausible answer. Remember that, at least for now, the forecast data is not available and this is what the agent said. Also, as anticipated, the agent has identified the two reference entities and reused them to construct the response.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we discovered the amazing world of chatbots. Chatbots are robots, that interact with users through a chat and are able to assist them by carrying out extremely limited tasks: providing information on a current account, buying a ticket, receiving news about the weather, and so forth.</p>
<p>To begin with, we took a look at the fundamentals of the topic, starting with the history of chatbots in the 1950s, with the efforts of Alan Turing and various subsequent implementations of chatbots that perfected the basic concepts. Eliza, Parry, Jabberwacky, Dr. Sbaitso, ALICE, SmarterChild, and IBM Watson are the most important examples. As time passed and technology evolved, more and more sophisticated AI methods were created.</p>
<p>After introducing the basic concepts, we focused on the design techniques of chatbots and then moved on to analyze the architecture of a chatbot. We explored the interesting fields of NLP and NLU.</p>
<p>In the last part of the chapter, we covered Google Cloud Dialogflow, a platform for creating voice and text conversation applications based on machine learning. It supports 14 languages and can be integrated with major chat platforms. Finally, we created a simple chatbot that helps users to retrieve weather information about the most beautiful city in the world, that is, Rome. This can be an opportunity to travel, at least with the mind.</p>


            </article>

            
        </section>
    </body></html>