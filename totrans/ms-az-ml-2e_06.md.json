["```py\nfrom azureml.core import Datastore\ndefault_datastore = Datastore.get_default(ws)\n```", "```py\n    $ az storage account create -h\n    ```", "```py\n    az storage account create \\\n         --name mldemoblob8765 \\\n         --resource-group mldemo \\\n         --location westus \\\n         --sku Standard_LRS \\\n         --kind StorageV2\n    ```", "```py\n    az storage container create \\\n        --name mlfiles \\\n        --account-name mldemoblob8765\n    ```", "```py\nThere are no credentials provided in your command and environment, we will query for account key for your storage account. It is recommended to provide --connection-string, --account-key or --sas-token in your command as credentials.\n```", "```py\naz storage container list \\\n    --account-name mldemoblob8765 \\\n    --auth-mode login\n```", "```py\n    az ml datastore create -h\n    ```", "```py\n    $schema: https://azuremlschemas.azureedge.net/latest/azureBlob.schema.json\n    name: mldemoblob\n    type: azure_blob\n    description: main ML blob storage\n    account_name: mldemoblob8765\n    container_name: mlfiles\n    credentials:\n      sas_token: <your_token>\n    ```", "```py\n    az storage container generate-sas \\\n        --account-name mldemoblob8765 \\\n        --name mlfiles \\\n        --expiry 2023-01-01 \\\n        --permissions acdlrw\n    ```", "```py\nxx=XXXX-XX-XX&xx=xxxx&xxx=xxx&xx=xxxxxxxxxxx&xx=XXXX-XX-XXXXX:XX:XXX&xx=XXXX-XX-XXXXX:XX:XXX&xxx=xxxxx&xxx=XXxXXXxxxxxXXXXXXXxXxxxXXXXXxxXXXXXxXXXXxXXXxXXxXX\n```", "```py\n    az ml datastore create \\\n        --workspace-name mldemows \\\n        --resource-group mldemo \\\n        --file ./blobdatastore.yml\n    ```", "```py\n\"account_name\": \"mldemoblob8765\",\n\"container_name\": \"mlfiles\",\n\"credentials\": {},\n\"description\": \"main ML blob storage\",\n\"endpoint\": \"core.windows.net\",\n\"id\": <yourid>,\n\"name\": \"mldemoblob\",\n\"protocol\": \"https\",\n\"resourceGroup\": \"mldemo\",\n\"tags\": {},\n\"type\": \"azure_blob\"\n```", "```py\naz datafactory create \\\n    --location \"West US 2\" \\\n    --name \"mldemoDF8765\" \\\n    --resource-group \"mldemo\"\n```", "```py\n    az storage blob upload \\\n        --account-name mldemoblob8765 \\\n        --file ./melb_data.csv \\\n        --container-name mlfiles \\\n    --name melb_data.csv \n    ```", "```py\nfrom azureml.core import Dataset\npath = 'https://...windows.net/demo/Titanic.csv'\nds = Dataset.Tabular.from_delimited_files(path)\n```", "```py\nfrom azureml.core import Dataset, Datastore\ndatastore_name = \"mldata\"\ndatastore = Datastore.get(ws, datastore_name)\nds = Dataset.File.from_files((datastore, \"cifar10/\"))\n```", "```py\nds = ds.register(ws, name=\"titanic\",\n                 create_new_version=True)\n```", "```py\nfrom azureml.core import Dataset\nds = Dataset.get_by_name(ws, name=\"titanic\", version=1)\n```", "```py\npanads_df = ds.to_pandas_dataframe()\npandas_df.head()\n```", "```py\nspark_df = ds.to_spark_dataframe()\nspark_df.show()\n```", "```py\ndask_df = ds.to_dask_dataframe()\ndask_df.head()\n```", "```py\n    import pandas as pd\n    path ='https://...windows.net/demo/Titanic.csv'\n    df = pd.read_csv(path)\n    print(df.head())\n    ```", "```py\nimport argparse\nimport pandas as pd\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input\", type=str)\nargs = parser.parse_args()\ndf = pd.read_csv(args.input)\nprint(df.head())\n```", "```py\nsrc = ScriptRunConfig(\n  source_directory=\"code\",\n  script='access_data_from_path.py',\n  arguments=['--input', path],\n  environment=get_current_env())\n```", "```py\n    from azureml.core import Dataset\n    path ='https://...windows.net/demo/Titanic.csv'\n    ds = Dataset.Tabular.from_delimited_files(path)\n    print(ds.to_pandas_dataframe().head())\n    ```", "```py\nimport argparse\nfrom azureml.core import Dataset, Run\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input\", type=str)\nargs = parser.parse_args()\nrun = Run.get_context()\nws = run.experiment.workspace\nds = Dataset.get_by_id(ws, id=args.input)\nprint(ds.to_pandas_dataframe().head())\n```", "```py\nsrc = ScriptRunConfig(\n  source_directory=\"code\",\n  script='access_data_from_dataset.py',\n  arguments=['--input', ds.as_named_input('titanic')],\n  environment=get_current_env())\n```", "```py\n...\nAfter variable expansion, calling script [access_data_from_dataset.py] with arguments:['--input', '04f8ad60-5a51-4319-92fe-cdfa7f6c9adc']\n```", "```py\nfrom azureml.core import Dataset\ndataset = Dataset.get_by_name(ws, \"cifar10\")\n```", "```py\nimport os\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input\", type=str)\nargs = parser.parse_args()\nprint(\"Dataset path: {}\".format(args.input))\nprint(os.listdir(args.input))\n```", "```py\nfrom azureml.core import ScriptRunConfig\nsrc = ScriptRunConfig(\n  source_directory=\"code\",\n  script='access_dataset.py',\n  arguments=['--input',\n    dataset.as_named_input('cifar10').as_download()],\n  environment=get_current_env())\n```", "```py\nfolder = '/tmp/cifar10-data'\npaths = dataset.download(folder)\n```", "```py\nfrom azureml.core import ScriptRunConfig\nsrc = ScriptRunConfig(\n  source_directory=\"code\",\n  script='access_dataset.py',\n  arguments=['--input',\n    dataset.as_named_input('cifar10').as_mount()],\n  environment=get_current_env())\n```", "```py\nimport os\nfolder = '/tmp/cifar10-data'\n# Or you can also use the start and stop methods\nmount_context = dataset.mount(folder)\ntry:\n  mount_context.start() \n  print(os.listdir(folder))\nfinally:\n  mount_context.stop()\n```", "```py\nwith dataset.mount() as mount_context:\n  print(os.listdir(mount_context.mount_point))\n```", "```py\nfrom azureml.opendatasets import PublicHolidays\nfrom dateutil import parser\nend_date = parser.parse(\"Jan 10 2000 12:00AM\")\nstart_date = parser.parse(\"Jan 10 2010 12:00AM\")\nds = PublicHolidays(start_date=start_date, \n                    end_date=end_date)\ndf = ds.to_pandas_dataframe()\n```", "```py\nfrom azureml.opendatasets import UsPopulationZip\npopulation = UsPopulationZip()\npopulation_df = population.to_pandas_dataframe()\n```", "```py\nfrom azureml.opendatasets import UsLaborEHENational\nds = UsLaborEHENational()\ndf = ds.to_pandas_dataframe()\n```"]