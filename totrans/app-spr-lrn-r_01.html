<html><head></head><body>
		<div id="_idContainer011" class="Content">
			<h1 id="_idParaDest-13"><em class="italics"><a id="_idTextAnchor013"/>Chapter 1:</em></h1>
		</div>
		<div id="_idContainer012" class="Content">
			<h1 id="_idParaDest-14"><a id="_idTextAnchor014"/>R for Advanced Analytics</h1>
		</div>
		<div id="_idContainer013" class="Content">
			<h2>Learning Objectives</h2>
			<p>By the end of this chapter, you will be able to:</p>
			<ul>
				<li class="bullets">Explain advanced R programming constructs</li>
				<li class="bullets">Print the summary statistics of a real-world dataset</li>
				<li class="bullets">Read data from CSV, text, and JSON files</li>
				<li class="bullets">Write R markdown files for code reproducibility</li>
				<li class="bullets">Explain R data structures such as data.frame, data.table, lists, arrays, and matrices</li>
				<li class="bullets">Implement the cbind, rbind, merge, reshape, aggregate, and apply functions</li>
				<li class="bullets">Use packages such as dplyr, plyr, caret, tm, and many more</li>
				<li class="bullets">Create visualizations using ggplot</li>
			</ul>
			<p>In this chapter, we will set the foundation for programming with R and understand the various syntax and data structures for advanced analytics.</p>
		</div>
		<div id="_idContainer026" class="Content">
			<h2 id="_idParaDest-15"><a id="_idTextAnchor015"/>Introduction</h2>
			<p>R was one of the early programming languages developed for statistical computing and data analysis with good support for visualization. With the rise of data science, R emerged as an undoubted choice of programming language among many data science practitioners. Since R was open-source and extremely powerful in building sophisticated statistical models, it quickly found adoption in both industry and academia.</p>
			<p>Tools and software such as SAS and SPSS were only affordable by large corporations, and traditional programming languages such as C/C++ and Java were not suitable for performing complex data analysis and building model. Hence, the need for a much more straightforward, comprehensive, community-driven, cross-platform compatible, and flexible programming language was a necessity.</p>
			<p>Though Python programming language is increasingly becoming popular in recent times because of its industry-wide adoption and robust production-grade implementation, R is still the choice of programming language for quick prototyping of advanced machine learning models. R has one of the most populous collection of packages (a collection of functions/methods for accomplishing a complicated procedure, which otherwise requires a lot of time and effort to implement). At the time of writing this book, the <strong class="keyword">Comprehensive R Archive Network</strong> (<strong class="keyword">CRAN</strong>), a network of FTP and web servers around the world that store identical, up-to-date, versions of code and documentation for R, has more than 13,000 packages.</p>
			<p>While there are numerous books and online resources on learning the fundamentals of R, in this chapter, we will limit the scope only to cover the important topics in R programming that will be used extensively in many data science projects. We will use a real-world dataset from the UCI Machine Learning Repository to demonstrate the concepts. The material in this chapter will be useful for learners who are new to R Programming. The upcoming chapters in supervised learning concepts will borrow many of the implementations from this chapter.</p>
			<h2 id="_idParaDest-16"><a id="_idTextAnchor016"/>Working with Real-World Datasets</h2>
			<p>There are plenty of open datasets available online these days. The following are some popular sources of open datasets:</p>
			<ul>
				<li><strong class="bold">Kaggle</strong>: A platform for hosting data science competitions. The official website is <a href="https://www.kaggle.com/">https://www.kaggle.com/</a>.</li>
				<li><strong class="bold">UCI Machine Learning Repository</strong>: A collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms. You can visit the official page via navigating to <a href="https://archive.ics.uci.edu/ml/index.php">https://archive.ics.uci.edu/ml/index.php</a> URL.</li>
				<li><strong class="bold">data.gov.in</strong>: Open Indian government data platform, which is available at <a href="https://data.gov.in/">https://data.gov.in/</a>.</li>
				<li><strong class="bold">World Bank Open Data</strong>: Free and open access to global development data, which can be accessed from <a href="https://data.worldbank.org/">https://data.worldbank.org/</a>.</li>
			</ul>
			<p>Increasingly, many private and public organizations are willing to make their data available for public access. However, it is restricted to only complex datasets where the organization is looking for solutions to their data science problem through crowd-sourcing platforms such as Kaggle. There is no substitute for learning from data acquired internally in the organization as part of a job that offers all kinds of challenges in processing and analyzing.</p>
			<p>Significant learning opportunity and challenge concerning data processing comes from the public data sources as well, as not all the data from these sources are clean and in a standard format. JSON, Excel, and XML are some other formats used along with CSV, though CSV is predominant. Each format needs a separate encoding and decoding method and hence a reader package in R. In our next section, we will discuss various data formats and how to process the available data in detail.</p>
			<p>Throughout this chapter and in many others, we will use the direct marketing campaigns (phone calls) of a Portuguese banking institution dataset from UCI Machine Learning Repository. (<a href="https://archive.ics.uci.edu/ml/datasets/bank+marketing">https://archive.ics.uci.edu/ml/datasets/bank+marketing</a>). The following table describes the fields in detail:</p>
			<div>
				<div id="_idContainer014" class="IMG---Figure">
					<img src="image/C12624_01_01.jpg" alt="Figure 1.1: Portuguese banking institution dataset from UCI Machine Learning Repository (Part 1)&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 1.1: Portuguese banking institution dataset from UCI Machine Learning Repository (Part 1)</h6>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/C12624_01_02.jpg" alt="Figure 1.2: Portuguese banking institution dataset from UCI Machine Learning Repository (Part 2)"/>
				</div>
			</div>
			<h6>Figure 1.2: Portuguese banking institution dataset from UCI Machine Learning Repository (Part 2)</h6>
			<p>In the following exercise, we will download the <strong class="inline">bank.zip</strong> dataset as a ZIP file and unzip it using the <strong class="inline">unzip</strong> method.</p>
			<h3 id="_idParaDest-17"><a id="_idTextAnchor017"/>Exercise 1: Using the unzip Method for Unzipping a Downloaded File</h3>
			<p>In this exercise, we will write an R script to download the Portuguese Bank Direct Campaign dataset from UCI Machine Learning Repository and extract the content of the ZIP file in a given folder using the <strong class="inline">unzip</strong> function.</p>
			<p>Preform these steps to complete the exercise:</p>
			<ol>
				<li>First, open R Studio on your system.</li>
				<li>Now, set the working directory of your choice using the following command:<p class="snippet">wd &lt;- "&lt;WORKING DIRECTORY&gt;"</p><p class="snippet">setwd(wd)</p><h4>Note</h4><p class="callout">R codes in this book are implemented using the R version 3.2.2.</p></li>
				<li>Download the ZIP file containing the datasets using the <strong class="inline">download.file()</strong> method:<p class="snippet">url &lt;- "https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip"</p><p class="snippet">destinationFileName &lt;- "bank.zip"</p><p class="snippet">download.file(url, destinationFileName,method = "auto", quiet=FALSE)</p></li>
				<li>Now, before we unzip the file in the working directory using the <strong class="inline">unzip()</strong> method, we need to choose a file and save its file path in R (for Windows) or specify the complete path:<p class="snippet">zipFile&lt;-file.choose()</p></li>
				<li>Define the folder where the ZIP file is unzipped:<p class="snippet">outputDir &lt;- wd</p></li>
				<li>Finally, unzip the ZIP file using the following command:<p class="snippet">unzip(zipFile, exdir=outputDir)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer016" class="IMG---Figure">
					<img src="image/C12624_01_03.jpg" alt="Figure 1.3: Unzipping the bank.zip file&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 1.3: Unzipping the bank.zip file</h6>
			<h2 id="_idParaDest-18"><a id="_idTextAnchor018"/>Reading Data from Various Data Formats</h2>
			<p>Data from digital systems is generated in various forms: browsing history on an e-commerce website, clickstream data, the purchase history of a customer, social media interactions, footfalls in a retail store, images from satellite and drones, and numerous other formats and types of data. We are living in an exciting time when technology is significantly changing lives, and enterprises are leveraging it to create their next data strategy to make better decisions.</p>
			<p>It is not enough to be able to collect a huge amount of different types of data; we also need to leverage value out of it. A CCTV footage captured throughout a day will help the law and order teams of the government in improving the real-time surveillance of public places. The challenge remains in how we will process a large volume of heterogeneous data formats within a single system.</p>
			<p>Transaction data in the <strong class="bold">Customer Relationship Management</strong> (<strong class="bold">CRM</strong>) application would mostly be tabular and feed in social media is mostly text, audio, video, and images.</p>
			<p>We can categorize the data formats as structured—tabular data such as CSV and database tables; unstructured—textual data such as tweets, FB posts, and word documents; and semi-structured. Unlike textual, which is hard for machines to process and understand, semi-structured provides associated metadata, which makes it easy for computers to process it. It's popularly used with many web applications for data exchange, and JSON is an example of the semi-structured data format.</p>
			<p>In this section, we will see how to load, process, and transform various data formats in R. Within the scope of this book, we will work with CSV, text, and JSON data.</p>
			<h3 id="_idParaDest-19"><a id="_idTextAnchor019"/>CSV Files</h3>
			<p>CSV files are the most common type of data storage and exchange formats for structured data. R provides a method called <strong class="inline">read.csv()</strong> for reading data from a CSV file. It will read the data into a <strong class="inline">data.frame</strong> (more about it in the next section). There are many arguments that the method takes; the two required arguments are a path to the <strong class="inline">filename</strong> and <strong class="inline">sep</strong>, which specifies the character that separates the column values. The <strong class="inline">summary()</strong> method describes the six summary statistics, <strong class="bold">min</strong>, <strong class="bold">first quartile</strong>, <strong class="bold">median</strong>, <strong class="bold">mean</strong>, <strong class="bold">third quartile</strong>, and <strong class="bold">max</strong>.</p>
			<p>In the following exercise, we'll read a CSV file and summarize its column.</p>
			<h3 id="_idParaDest-20"><a id="_idTextAnchor020"/>Exercise 2: Reading a CSV File and Summarizing its Column</h3>
			<p>In this exercise, we will read the previously extracted CSV file and use the <strong class="inline">summary</strong> function to print the min, max, mean, median, 1st quartile, and 3rd quartile values of numeric variables and count the categories of the categorical variable.</p>
			<p>Carry out these steps to read a CSV file and later summarize its columns:</p>
			<ol>
				<li value="1">First, use the <strong class="inline">read.csv</strong> method and load the <strong class="inline">bank-full.csv</strong> into a DataFrame:<p class="snippet">df_bank_detail &lt;- read.csv("bank-full.csv", sep = ';')</p></li>
				<li>Print the summary of the DataFrame:<p class="snippet">summary(df_bank_detail)</p><p>The output is as follows:</p><p class="snippet">##       age                 job           marital          education    </p><p class="snippet">##  Min.   :18.00   blue-collar:9732   divorced: 5207   primary  : 6851  </p><p class="snippet">##  1st Qu.:33.00   management :9458   married :27214   secondary:23202  </p><p class="snippet">##  Median :39.00   technician :7597   single  :12790   tertiary :13301  </p><p class="snippet">##  Mean   :40.94   admin.     :5171                    unknown  : 1857  </p><p class="snippet">##  3rd Qu.:48.00   services   :4154                                     </p><p class="snippet">##  Max.   :95.00   retired    :2264                                     </p></li>
			</ol>
			<h3 id="_idParaDest-21"><a id="_idTextAnchor021"/>JSON</h3>
			<p>JSON is the next most commonly used data format for sharing and storing data. It is unlike CSV files, which only deal with rows and columns of data where each has a definite number of columns. For example, in the e-commerce data of the customers, each row could be representing a customer with their information stored in separate columns. For a customer, if a column has no value, the field is stored as NULL.</p>
			<p>JSON provides an added flexibility of having a varying number of fields for each customer. This type of flexibility relieves the developer from the burden of maintaining a schema as we have in traditional relational databases, wherein the same customer data might be spread across multiple tables to optimize for storage and querying time.</p>
			<p>JSON is more of a key-value store type of storage, where all we care about is the keys (such as the name, age, and DOB) and their corresponding values. While this sounds flexible, proper care has to be taken, otherwise manageability might at times, go out of control. Fortunately, with the advent of big data technologies in recent days, many document stores (a subclass of the key-value store), popularly also known as <strong class="keyword">NoSQL</strong> databases, are available for storing, retrieving, and processing data in such formats.</p>
			<p>In the following exercise, the JSON file has data for cardamom (spices and condiments) cultivation district-wise in Tamil Nadu, India, for the year 2015-16. The keys include <strong class="bold">area</strong> (hectare), <strong class="bold">production</strong> (in quintals), and <strong class="bold">productivity</strong> (average yield per hectare).</p>
			<p>The <strong class="inline">jsonlite</strong> package provides an implementation to read and convert a JSON file into DataFrame, which makes the analysis simpler. The <strong class="inline">fromJSON</strong> method reads a JSON file, and if the <strong class="inline">flatten</strong> argument in the <strong class="inline">fromJSON</strong> function is set to <strong class="inline">TRUE</strong>, it gives a DataFrame.</p>
			<h3 id="_idParaDest-22"><a id="_idTextAnchor022"/>Exercise 3: Reading a JSON file and Storing the Data in DataFrame</h3>
			<p>In this exercise, we will read a JSON file and store the data in the DataFrame.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Download the data from <a href="https://data.gov.in/catalog/area-production-productivity-spices-condiments-district-wise-tamil-nadu-year-2015-16">https://data.gov.in/catalog/area-production-productivity-spices-condiments-district-wise-tamil-nadu-year-2015-16</a>.</li>
				<li>First, use the following command to install the packages required for the system of read the JSON file:<p class="snippet">install jsonlite package</p><p class="snippet">install.packages("jsonlite")</p><p class="snippet">library(jsonlite)</p></li>
				<li>Next, read the JSON file using the <strong class="inline">fromJSON</strong> method, as illustrated here:<p class="snippet">json_file &lt;- "crop.json"</p><p class="snippet">json_data &lt;- jsonlite::fromJSON(json_file, flatten = TRUE)</p></li>
				<li>The second element in the list contains the DataFrame with crop production value. Retrieve it from <strong class="inline">json_data</strong> and store as a DataFrame named <strong class="inline">crop_production</strong>:<p class="snippet">crop_production &lt;- data.frame(json_data[[2]])</p></li>
				<li>Next, use the following command to rename the columns:<p class="snippet">colnames(crop_production) &lt;- c("S.No","District","Area","Production","PTY")</p></li>
				<li>Now, print the top six rows using the <strong class="inline">head()</strong> function:<p class="snippet">head(crop_production)</p><p>The output is as follows:</p><p class="snippet">##   S.No   District Area Production  PTY</p><p class="snippet">## 1    1   Ariyalur   NA         NA   NA</p><p class="snippet">## 2    2 Coimbatore  808         26 0.03</p><p class="snippet">## 3    3  Cuddalore   NA         NA   NA</p><p class="snippet">## 4    4 Dharmapuri   NA         NA   NA</p><p class="snippet">## 5    5   Dindigul  231          2 0.01</p><p class="snippet">## 6    6      Erode   NA         NA   NA</p></li>
			</ol>
			<h3 id="_idParaDest-23"><a id="_idTextAnchor023"/>Text</h3>
			<p>Unstructured data is the language of the web. All the social media, blogs, web pages, and many other sources of information are textual and untidy to extract any meaningful information. An increasing amount of research work is coming out from the <strong class="keyword">Natural Language Processing</strong> (<strong class="keyword">NLP</strong>) field, wherein computers are becoming better in understanding not only the meaning of the word but also the context in which it's used in a sentence. The rise of computer chatbot, which responds to a human query, is the most sophisticated form of understanding textual information.</p>
			<p>In R, we will use the <strong class="inline">tm</strong> text mining package to show how to read, process, and retrieve meaningful information from text data. We will use a small sample of the <strong class="bold">Amazon Food Review</strong> dataset in Kaggle (<a href="https://www.kaggle.com/snap/amazon-fine-food-reviews">https://www.kaggle.com/snap/amazon-fine-food-reviews</a>) for the exercise in this section.</p>
			<p>In the <strong class="inline">tm</strong> package, collections of text documents are called <strong class="keyword">Corpus</strong>. One implementation of Corpus in the <strong class="inline">tm</strong> package is <strong class="inline">VCorpus</strong> (<strong class="bold">volatile corpus</strong>). Volatile corpus is named after the fact that it's stored in-memory for fast processing. To check the metadata information of the <strong class="inline">VCorpus</strong> object, we can use the <strong class="inline">inspect()</strong> method. The following exercise uses the <strong class="inline">lapply</strong> method for looping through the first two reviews and casting the text as a character. You will learn more about the <strong class="inline">apply</strong> family of function in the <em class="italics">The Apply Family of Functions</em> section.</p>
			<h3 id="_idParaDest-24"><a id="_idTextAnchor024"/>Exercise 4: Reading a CSV File with Text Column and Storing the Data in VCorpus</h3>
			<p>In this exercise, we will read a CSV file with the text column and store the data in VCorpus.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, let's load the text mining package from the R into the system to read the text file:<p class="snippet">library(tm)</p></li>
				<li>Now, read the first top 10 reviews from the file:<p class="snippet">review_top_10 &lt;- read.csv("Reviews_Only_Top_10_Records.csv")</p></li>
				<li>To store the text column in <strong class="inline">VCorpus</strong>, use the following command:<p class="snippet">review_corpus &lt;- VCorpus(VectorSource(review_top_10$Text))</p></li>
				<li>To inspect the structure of first two reviews, execute the following command:<p class="snippet">inspect(review_corpus[1:2])</p><p>The output is as follows:</p><p class="snippet">## &lt;&lt;VCorpus&gt;&gt;</p><p class="snippet">## Metadata:  corpus specific: 0, document level (indexed): 0</p><p class="snippet">## Content:  documents: 2</p><p class="snippet">## [[1]]</p><p class="snippet">## &lt;&lt;PlainTextDocument&gt;&gt;</p><p class="snippet">## Metadata:  7</p><p class="snippet">## Content:  chars: 263</p><p class="snippet">## [[2]]</p><p class="snippet">## &lt;&lt;PlainTextDocument&gt;&gt;</p><p class="snippet">## Metadata:  7</p><p class="snippet">## Content:  chars: 190</p></li>
				<li>Using <strong class="inline">lapply</strong>, cast the first review as character and print:<p class="snippet">lapply(review_corpus[1:2], as.character)</p><p class="snippet">## $'1'</p><p class="snippet">## [1] "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most."</p><p class="snippet">## $'2'</p><p class="snippet">## [1] "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</p></li>
			</ol>
			<p>We will revisit the <strong class="inline">review_corpus</strong> dataset in a later section to show how to convert the unstructured textual information to structured tabular data.</p>
			<p>Apart from CSV, Text, and JSON, there are numerous other data formats depending upon the source of data and its usage. R has a rich collection of libraries that helps with many formats. R can import not only the standard formats (apart from the previous three) such as HTML tables and XML but also formats specific to an analytical tool such as SAS and SPSS. This democratization led to a significant migration of industry experts who were earlier working in the propriety tools (costly and often found with only the large corporations) to open source analytical programming languages such as R and Python.</p>
			<h2 id="_idParaDest-25"><a id="_idTextAnchor025"/>Write R Markdown Files for Code Reproducibility</h2>
			<p>The considerable success of analytics is a result of the way the information and knowledge network around the subject started to spread. More open source communities emerged, developers were happily sharing their work with the outer world, and many data projects were becoming reproducible. This change meant that work started by one person was soon getting adapted, improvised, and modified in many different forms by a community of people before it got adopted in an entirely different domain than the one from where it initially emerged. Imagine every research work that gets published in conference submitting a collection of code and data that is easily reproducible along with their research paper. This change is accelerating the pace at which an idea meets reality, and innovation will start to boom.</p>
			<p>Now, let's see how to create such reproducible work in a single file that we call the <strong class="bold">R Markdown</strong> file. In the following activity, we will demonstrate how to create a new R Markdown file in RStudio. A detailed intro to R Markdown could be found at <a href="https://rmarkdown.rstudio.com/lesson-1.html">https://rmarkdown.rstudio.com/lesson-1.html</a>.</p>
			<p>In the next activity, you will recreate the code shown in <em class="italics">Exercise 4</em>, <em class="italics">Reading a CSV File with Text Column and Storing the Data in VCorpus</em>, into an R Markdown. Observe in <em class="italics">Figure 4.2</em> that you have just written the explanation and the code in R Markdown, and when the <strong class="bold">Knit to Word</strong> action is performed, it interweaves the explanation, code, and its output neatly into a word document.</p>
			<h3 id="_idParaDest-26"><a id="_idTextAnchor026"/>Activity 1: Create an R Markdown File to Read a CSV File and Write a Summary of Data</h3>
			<p>In this activity, we will create a R Markdown file to read a CSV file and print a small summary of the data in a word file:</p>
			<p>Perform the following steps to complete the activity:</p>
			<ol>
				<li value="1">Open RStudio and navigate to the <strong class="bold">R Markdown</strong> option:<div id="_idContainer017" class="IMG---Figure"><img src="image/C12624_01_04.jpg" alt="Figure 1.4: Creating a new R Markdown file in Rstudio"/></div><h6>Figure 1.4: Creating a new R Markdown file in Rstudio</h6></li>
				<li>Provide the <strong class="bold">Title</strong> and <strong class="bold">Author</strong> name for the document and select the <strong class="bold">Default Output Format</strong> as <strong class="bold">Word</strong>:<div id="_idContainer018" class="IMG---Figure"><img src="image/C12624_01_05.jpg" alt="Figure 1.5: Using the read.csv method to read the data&#13;&#10;"/></div><h6>Figure 1.5: Using the read.csv method to read the data</h6></li>
				<li>Use the <strong class="inline">read.csv()</strong> method to read the <strong class="inline">bank-full.csv</strong> file.</li>
				<li>Finally, print the summary into a word file using the <strong class="inline">summary</strong> method.<p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/C12624_01_06.jpg" alt="Figure 1.6: Final output after using the summary method"/>
				</div>
			</div>
			<h6>Figure 1.6: Final output after using the summary method</h6>
			<h4>Note</h4>
			<p class="callout">The solution for this activity can be found at page 438.</p>
			<h2 id="_idParaDest-27"><a id="_idTextAnchor027"/>Data Structures in R</h2>
			<p>In any programming language, data structures are the fundamental units of storing information and making it ready for further processing. Depending on the type of data, various forms of data structures are available for <strong class="bold">storing</strong> and <strong class="bold">processing</strong>. Each of the data structures explained in the next section has its characteristic features and applicability.</p>
			<p>In this section, we will explore each of it and how to use it with our data.</p>
			<h3 id="_idParaDest-28"><a id="_idTextAnchor028"/>Vector</h3>
			<p><strong class="bold">Vector</strong> is the most fundamental of all the data structures, and the values are stored in a 1-D array. Vector is the most suitable for a single variable with a series of values. In <em class="italics">Exercise 3</em>, <em class="italics">Reading a JSON File and Storing the Data in DataFrame</em>, refer to step 4 where we assigned a DataFrame its column names and concatenated using the <strong class="inline">c()</strong> method, as shown here:</p>
			<p class="snippet">c_names &lt;- c("S.No","District","Area","Production","PTY")</p>
			<p>We can extract the second value in the vector by specifying the index in square brackets next to the vector name. Let's review the following code where we subset the value in the second index:</p>
			<p class="snippet">c_names[2]</p>
			<p>The output is as follows:</p>
			<p class="snippet">## [1] "District"</p>
			<p>The collection of string concatenated with the <strong class="inline">c()</strong> method is a vector. It can store a homogenous collection of characters, integers, or floating point values. While trying to store an integer with character, an implicit type cast will happen, which will convert all the values to character.</p>
			<h4>Caution</h4>
			<p class="callout">Note that it might not be the expected behavior every time. Caution is required, especially when the data is not clean. It may otherwise cause errors that are harder to find than the usual programming errors.</p>
			<h3 id="_idParaDest-29"><a id="_idTextAnchor029"/>Matrix</h3>
			<p><strong class="bold">Matrix</strong> is the higher dimension data structure used for storing <em class="italics">n</em>-dimensional data. It is suitable for storing tabular data. Similar to vector, the matrix also allows only homogenous collection of data in its rows and columns.</p>
			<p>The following code generates 16 random numbers drawn from a binomial distribution with a parameter, number of trials <strong class="inline">(size) = 100</strong>, and success probability equal to <strong class="inline">0.4</strong>. The <strong class="inline">rbinom()</strong> method in R is useful for generating such random numbers:</p>
			<p class="snippet">r_numbers &lt;- rbinom(n = 16, size = 100, prob = 0.4)</p>
			<p>Now, to store <strong class="inline">r_number</strong> as a matrix, use the following command:</p>
			<p class="snippet">matrix(r_numbers, nrow = 4, ncol = 4)</p>
			<p>The output is as follows:</p>
			<p class="snippet">##      [,1] [,2] [,3] [,4]</p>
			<p class="snippet">## [1,]   48   39   37   39</p>
			<p class="snippet">## [2,]   34   41   32   38</p>
			<p class="snippet">## [3,]   40   34   42   46</p>
			<p class="snippet">## [4,]   37   42   36   44</p>
			<p>Let's extend the text mining example we took in <em class="italics">Exercise 4</em>, <em class="italics">Reading a CSV File with Text Column and Storing the Data in VCorpus</em>, to understand the usage of matrix in text mining.</p>
			<p>Consider the following two reviews. Use the <strong class="inline">lapply</strong> to type cast the first review to <strong class="inline">as.character</strong> and print:</p>
			<p class="snippet">lapply(review_corpus[1:2], as.character)</p>
			<p>The output is as follows:</p>
			<p class="snippet">## $'1'</p>
			<p class="snippet">## [1] "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat, and it smells better. My Labrador is finicky, and she appreciates this product better than  most."</p>
			<p class="snippet">## $'2'</p>
			<p class="snippet">## [1] "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</p>
			<p>Now, in the following exercise, we will transform the data to remove stopwords, whitespaces, and punctuations from these two paragraphs. We will then perform stemming (both <em class="italics">looking</em> and <em class="italics">looked</em> will be reduced to look). Also, for consistency, convert all the text into lowercase.</p>
			<h3 id="_idParaDest-30"><a id="_idTextAnchor030"/>Exercise 5: Performing Transformation on the Data to Make it Available for the Analysis</h3>
			<p>In this exercise, we will perform the transformation on the data to make it available for further analysis.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, use the following commands to convert all the characters in the data to lowercase:<p class="snippet">top_2_reviews &lt;- review_corpus[1:2]</p><p class="snippet">top_2_reviews &lt;- tm_map(top_2_reviews,content_transformer(tolower))</p><p class="snippet">lapply(top_2_reviews[1], as.character)</p><p>The output is as follows:</p><p class="snippet">## [1] "I have bought several of the vitality canned dog food products and have found them all to be of good quality. the product looks more like a stew than a processed meat and it smells better. my labrador is finicky, and she appreciates this product better than  most."</p></li>
				<li>Next, remove the stopwords from the data, such as, <strong class="inline">a</strong>, <strong class="inline">the</strong>, <strong class="inline">an</strong>, and many more:<p class="snippet">top_2_reviews &lt;- tm_map(top_2_reviews,removeWords, stopwords("english"))</p><p class="snippet">lapply(top_2_reviews[1], as.character)</p><p>The output is as follows:</p><p class="snippet">## [1] "  bought several   vitality canned dog food products   found      good quality.  product looks  like  stew   processed meat   smells better.  labrador  finicky   appreciates  product better   ."</p></li>
				<li>Remove extra whitespaces between words using the following command:<p class="snippet">top_2_reviews &lt;- tm_map(top_2_reviews,stripWhitespace)</p><p class="snippet">lapply(top_2_reviews[1], as.character)</p><p>The output is as follows:</p><p class="snippet">## [1] " bought several vitality canned dog food products found good quality. product looks like stew processed meat smells better. labrador finicky appreciates product better ."</p></li>
				<li>Perform the stemming process, which will only keep the root of the word. For example, <strong class="inline">looking</strong> and <strong class="inline">looked</strong> will become <strong class="inline">look</strong>:<p class="snippet">top_2_reviews &lt;- tm_map(top_2_reviews,stemDocument)</p><p class="snippet">lapply(top_2_reviews[1], as.character)</p><p>The output is as follows:</p><p class="snippet">## [1] " bought sever vital can dog food product found good quality. product look like stew process meat smell better. labrador finicki appreci product better ."</p><p>Now that we have the text processed and cleaned up, we can create a document matrix that stores merely the frequency of the occurrence of distinct words in the two reviews. We will demonstrate how to count each word contained in the review. Each row of the matrix represents one review, and the columns are distinct words. Most of the values are zero because not all the words will be present in each review. In this example, we have a sparsity of 49%, which means only 51% of the matrix contains non-zero values.</p></li>
				<li>Create <strong class="bold">Document Term Matrix</strong> (<strong class="bold">DTM</strong>), in which each row will represent one tweet (also referred to as Doc) and each column a unique word from the corpus:<p class="snippet">dtm &lt;- DocumentTermMatrix(top_2_reviews)</p><p class="snippet">inspect(dtm)</p><p>The output is as follows:</p><p class="snippet">## &lt;&lt;DocumentTermMatrix (documents: 2, terms: 37)&gt;&gt;</p><p class="snippet">## Non-/sparse entries: 38/36</p><p class="snippet">## Sparsity           : 49%</p><p class="snippet">## Maximal term length: 10</p><p class="snippet">## Weighting          : term frequency (tf)</p><p class="snippet">## </p><p class="snippet">##     Terms</p><p class="snippet">## Docs "jumbo". actual appreci arriv better better. bought can dog error</p><p class="snippet">##    1        0      0       1     0      1       1      1   1   1     0</p><p class="snippet">##    2        1      1       0     1      0       0      0   0   0     1</p><p class="snippet">##     Terms</p><p class="snippet">## Docs finicki food found good intend jumbo label labrador like look meat</p><p class="snippet">##    1       1    1     1    1      0     0     0        1    1    1    1</p><p class="snippet">##    2       0    0     0    0      1     1     1        0    0    0    0</p><p class="snippet">0</p><p>We can use this document term matrix in a plenty of ways. For the sake of the brevity of this introduction to the matrix, we will skip the details of the Document Term Matric here.</p><p>The DTM shown in the previous code is in the list format. In order to convert it to the matrix, we can use the <strong class="inline">as.matrix()</strong> method again. The matrix contains two documents (reviews) and 37 unique words. The count of a particular word in a document is retrieved by specifying the row and column index or name in the matrix.</p></li>
				<li>Now, store the results in a matrix using the following command:<p class="snippet">dtm_matrix &lt;- as.matrix(dtm)</p></li>
				<li>To find the dimension of the matrix, that is, 2 documents and 37 words, use the following command:<p class="snippet">dim(dtm_matrix)</p><p>The output is as follows:</p><p class="snippet">## [1]  2 37</p></li>
				<li>Now, print a subset of the matrix:<p class="snippet">dtm_matrix[1:2,1:7]</p><p>The output is as follows:</p><p class="snippet">##     Terms</p><p class="snippet">## Docs "jumbo". actual appreci arriv better better. bought</p><p class="snippet">##    1        0      0       1     0      1       1      1</p><p class="snippet">##    2        1      1       0     1      0       0      0</p></li>
				<li>Finally, count the word <strong class="inline">product</strong> in document 1 using the following command:<p class="snippet">dtm_matrix[1,"product"]</p><p>The output is as follows:</p><p class="snippet">## [1] 3</p></li>
			</ol>
			<h3 id="_idParaDest-31"><a id="_idTextAnchor031"/>List</h3>
			<p>While vector and matrix both are useful structures to be used in various computations in a program, it might not be sufficient for storing a real-world dataset, which most often contains data of mix types, like a customer table in CRM application has the customer name and age together in two columns. The list offers a structure to allow for storing two different types of data together.</p>
			<p>In the following exercise, along with generating 16 random numbers, we have used the <strong class="inline">sample()</strong> method to generate 16 characters from the English alphabet. The <strong class="inline">list</strong> method stores both the integers and characters together.</p>
			<h3 id="_idParaDest-32"><a id="_idTextAnchor032"/>Exercise 6: Using the List Method for Storing Integers and Characters Together</h3>
			<p>In this exercise, we will use the <strong class="inline">list</strong> method to store randomly generated numbers and characters. The random numbers will be generated using the <strong class="inline">rbinom</strong> function, and the random characters will be selected from English alphabets A-Z.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, generate 16 random numbers drawn from a binomial distribution with parameter size equals <strong class="inline">100</strong> and the probability of success equals <strong class="inline">0.4</strong>:<p class="snippet">r_numbers &lt;- rbinom(n = 16, size = 100, prob = 0.4)</p></li>
				<li>Now, select 16 alphabets from English <strong class="inline">LETTERS</strong> without repetition:<p class="snippet">#sample() will generate 16 random letters from the English alphabet without repetition</p><p class="snippet">r_characters &lt;- sample(LETTERS, size = 16, replace = FALSE)</p></li>
				<li>Put <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong> into a single list. The <strong class="inline">list()</strong> function will create the data structure list with <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong>:<p class="snippet">list(r_numbers, r_characters)</p><p>The output is as follows:</p><p class="snippet">## [[1]]</p><p class="snippet">##  [1] 48 53 38 31 44 43 36 47 43 38 43 41 45 40 44 50</p><p class="snippet">## </p><p class="snippet">## [[2]]</p><p class="snippet">##  [1] "V" "C" "N" "Z" "E" "L" "A" "Y" "U" "F" "H" "D" "O" "K" "T" "X"</p><p>In the following step, we will see a list with the integer and character vectors stored together.</p></li>
				<li>Now, let's store and retrieve integer and character vectors from a list:<p class="snippet">r_list &lt;- list(r_numbers, r_characters)</p></li>
				<li>Next, retrieve values in the character vector using the following command:<p class="snippet">r_list[[2]]</p><p>The output is as follows:</p><p class="snippet">##  [1] "V" "C" "N" "Z" "E" "L" "A" "Y" "U" "F" "H" "D" "O" "K" "T" "X"</p></li>
				<li>Finally, retrieve the first value in the character vector:<p class="snippet">(r_list[[2]])[1]</p><p>The output is as follows:</p><p class="snippet">## [1] "V" </p><p>Though this solves the requirement of storing heterogeneous data types together, its still doesn't put any integrity checks on the relationship between the values in the two vectors. If we would like to assign every <em class="italics">letter</em> to one <em class="italics">integer</em>. In the previous output, <strong class="inline">V</strong> represents <strong class="inline">48</strong>, <strong class="inline">C</strong> represents <strong class="inline">53</strong>, and so on.</p><p>A list is not robust to handle such one-to-one mapping. Consider the following code, instead of <strong class="inline">16</strong> characters, if we generate 18 random characters, and it still allows for storing it in a list. The last two characters have no associated mapping with the integer now.</p></li>
				<li>Now, generate 16 random numbers drawn from a binomial distribution with parameter size equal to <strong class="inline">100</strong> and probability of success equal to <strong class="inline">0.4</strong>:<p class="snippet">r_numbers &lt;- rbinom(n = 16, size = 100, prob = 0.4)</p></li>
				<li>Select any 18 alphabets from English <strong class="inline">LETTERS</strong> without repetition:<p class="snippet">r_characters &lt;- sample(LETTERS, 18, FALSE)</p></li>
				<li>Place <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong> into a single list:<p class="snippet">list(r_numbers, r_characters)</p><p>The output is as follows:</p><p class="snippet">## [[1]]</p><p class="snippet">##  [1] 48 53 38 31 44 43 36 47 43 38 43 41 45 40 44 50</p><p class="snippet">## </p><p class="snippet">## [[2]]</p><p class="snippet">##  [1] "V" "C" "N" "Z" "E" "L" "A" "Y" "U" "F" "H" "D" "O" "K" "T" "X" "P"  "Q"</p></li>
			</ol>
			<h3 id="_idParaDest-33"><a id="_idTextAnchor033"/>Activity 2: Create a List of Two Matrices and Access the Values</h3>
			<p>In this activity, you will create two matrices and retrieve a few values using the index of the matrix. You will also perform operations such as multiplication and subtraction.</p>
			<p>Perform the following steps to complete the activity:</p>
			<ol>
				<li value="1">Create two matrices of size <strong class="inline">10 x 4</strong> and <strong class="inline">4 x 5</strong> by randomly generated numbers from a binomial distribution (use <strong class="inline">rbinom</strong> method). Call the matrix <strong class="inline">mat_A</strong> and <strong class="inline">mat_B</strong>, respectively.</li>
				<li>Now, store the two matrices in a list.</li>
				<li>Using the list, access the row 4 and column 2 of <strong class="inline">mat_A</strong> and store it in variable <strong class="inline">A</strong>, and access row 2 and column 1 of <strong class="inline">mat_B</strong> and store it in variable <strong class="inline">B</strong>.</li>
				<li>Multiply the <strong class="inline">A</strong> and <strong class="inline">B</strong> matrices and subtract from row 2 and column 1 of <strong class="inline">mat_A</strong>.<h4>Note</h4><p class="callout">The solution for this activity can be found at page 440.</p></li>
			</ol>
			<h2 id="_idParaDest-34"><a id="_idTextAnchor034"/>DataFrame</h2>
			<p>With the limitation of vector, matrix, and list, a data structure suitable for real-world datasets was a much-needed requirement for data science practitioners. DataFrames are an elegant way of storing and retrieving tabular data. We have already seen how DataFrame handles the rows and columns of data in <em class="italics">Exercise 3</em>, <em class="italics">Reading a JSON File and Storing the Data in DataFrame</em>. DataFrames will be extensively used throughout the book.</p>
			<h3 id="_idParaDest-35"><a id="_idTextAnchor035"/>Exercise 7: Performing Integrity Checks Using DataFrame</h3>
			<p>Let's revisit <em class="italics">step 6</em> of <em class="italics">Exercise 6</em>, <em class="italics">Using the List Method for Storing Integers and Characters Together</em>, where we discussed the integrity check when we attempted to store two unequal length vectors in a list and will see how DataFrame handles it differently. We will, once again, generate random numbers (<strong class="inline">r_numbers</strong>) and random characters (<strong class="inline">r_characters</strong>).</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, generate 16 random numbers drawn from a binomial distribution with parameter size equal to <strong class="inline">100</strong> and probability of success equal to <strong class="inline">0.4</strong>:<p class="snippet">r_numbers &lt;- rbinom(n = 16, size = 100, prob = 0.4)</p></li>
				<li>Select any 18 alphabets from English <strong class="inline">LETTERS</strong> without repetition:<p class="snippet">r_characters &lt;- sample(LETTERS, 18, FALSE)</p></li>
				<li>Put <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong> into a single DataFrame:<p class="snippet">data.frame(r_numbers, r_characters)</p><p>The output is as follows:</p><p class="snippet">Error in data.frame(r_numbers, r_characters) : </p><p class="snippet">  arguments imply differing number of rows: 16, 18</p><p>As you can see, the error in the previous output shows that the last two LETTERS, that is, <strong class="inline">P</strong> and <strong class="inline">Q</strong>, have no mapping with a corresponding random <strong class="inline">INTEGER</strong> generated using the binomial distribution.</p></li>
			</ol>
			<p>Accessing any particular row and column in the DataFrame is similar to the matrix. We will show many tricks and techniques to best use the power of indexing in the DataFrame, which also includes some of the filtering options.</p>
			<p>Every row in a DataFrame is a result of the tightly coupled collection of columns. Each column clearly defines the relationship each row of data has with every other one. If there is no corresponding value available in a column, it will be filled with NA. For example, a customer in a CRM application might not have filled their marital status, whereas a few other customers filled it. So, it becomes essential during application design to specify which columns are mandatory and which are optional.</p>
			<h3 id="_idParaDest-36"><a id="_idTextAnchor036"/>Data Table</h3>
			<p>With the growing adaption of DataFrame came a time when its limitations started to surface. Particularly with large datasets, DataFrame performs poorly. In the complex analysis, we often create many intermediate DataFrames to store the results. However, R is built on an in-memory computation architecture, and it heavily depends on RAM. Unlike disk space, RAM is limited to either 4 or 8 GB in many standard desktops and laptops. DataFrame is not built efficiently to manage the memory during the computation, which often results in <strong class="inline">out of memory error</strong>, especially when working with large datasets.</p>
			<p>In order to handle this issue, <strong class="inline">data.table</strong> inherited the <strong class="inline">data.frame</strong> functionality and offers fast and memory-efficient version for the following task on top of it:</p>
			<ul>
				<li>File reader and writer</li>
				<li>Aggregations</li>
				<li>Updates</li>
				<li>Equi, non-equi, rolling, range, and interval joins</li>
			</ul>
			<p>Efficient memory management makes the development fast and reduces the latency between operations. The following exercise shows the significant difference <strong class="inline">data.table</strong> makes in computation time as compared to <strong class="inline">data.frame</strong>. First, we read the complete <strong class="bold">Amazon Food Review</strong> dataset, which is close to 286 MB and contains half a million records (this is quite a big dataset for R), using the <strong class="inline">fread()</strong> method, which is one of the fast reading methods from <strong class="inline">data.table</strong>.</p>
			<h3 id="_idParaDest-37"><a id="_idTextAnchor037"/>Exercise 8: Exploring the File Read Operation</h3>
			<p>In this exercise, we will only show file read operations. You are encouraged to test the other functionalities (<a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html">https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html</a>) and compare the data table capabilities over DataFrame.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, load the data table package using the following command:<p class="snippet">library(data.table)</p></li>
				<li>Read the dataset using the <strong class="inline">fread()</strong> method of the <strong class="inline">data.table</strong> package:<p class="snippet">system.time(fread("Reviews_Full.csv"))</p><p>The output is as follows:</p><p class="snippet">Read 14.1% of 568454 rows</p><p class="snippet">Read 31.7% of 568454 rows</p><p class="snippet">Read 54.5% of 568454 rows</p><p class="snippet">Read 72.1% of 568454 rows</p><p class="snippet">Read 79.2% of 568454 rows</p><p class="snippet">Read 568454 rows and 10 (of 10) columns from 0.280 GB file in 00:00:08</p><p class="snippet">##    user  system elapsed </p><p class="snippet">##    3.62    0.15    3.78</p></li>
				<li>Now, read the same CSV file using the <strong class="inline">read.csv()</strong> method of base package:<p class="snippet">system.time(read.csv("Reviews_Full.csv"))</p><p>The output is as follows:</p><p class="snippet">##    user  system elapsed </p><p class="snippet">##    4.84    0.05    4.91</p></li>
			</ol>
			<p>Observe that <strong class="inline">3.78</strong> seconds elapsed for reading it through the <strong class="inline">fread()</strong> method, while the <strong class="inline">read.csv</strong> function took <strong class="inline">4.91</strong> seconds. The execution speed is almost <em class="italics">30%</em> faster. As the size of the data increasing, this difference is even more significant.</p>
			<p>In the previous output, the <strong class="inline">user</strong> time is the time spent by the current R session, and <strong class="inline">system</strong> time is the time spent by the operating system to complete the process. It's possible that you may get a different value after executing the <strong class="inline">system.time</strong> method even if you use the same dataset. It depends a lot on how busy your CPU was at the time of running the method. However, we should read the output of the <strong class="inline">system.time</strong> method relative to the comparison we are carrying out and not relative to the absolute values.</p>
			<p>When the size of the dataset is too large, we have too many intermediate operations to get to the final output. However, keep in mind that <strong class="inline">data.table</strong> is not the magic wand that allows us to deal with a dataset of any size in R. The size of RAM still plays a significant role, and <strong class="inline">data.table</strong> is no substitute for distributed and parallel processing big data systems. However, even for the smaller dataset, the usage of <strong class="inline">data.table</strong> has shown much better performance than <strong class="inline">data.frames</strong>.</p>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor038"/>Data Processing and Transformation</h2>
			<p>So far, we have seen different ways to read and store data. Now, let's focus on the kind of data processing and transformation required to perform data analysis and draw insights or build models. Data in its raw form is hardly of any use, so it becomes essential to process it to make it suitable for any useful purpose. This section focuses on many methods in R that have widespread usage during data analysis.</p>
			<h3 id="_idParaDest-39"><a id="_idTextAnchor039"/>cbind</h3>
			<p>As the name suggests, it combines two or more vector, matrix, DataFrame, or table by column. <strong class="inline">cbind</strong> is useful when we have more than one vector, matrix, or DataFrame that need to be combined into one for analysis or visualization. The output of <strong class="inline">cbind</strong> varies based on the input data. The following exercise provides a few examples of <strong class="inline">cbind</strong>, which combines two vectors.</p>
			<h3 id="_idParaDest-40"><a id="_idTextAnchor040"/>Exercise 9: Exploring the cbind Function</h3>
			<p>In this exercise, we will implement the <strong class="inline">cbind</strong> function to combine two DataFrame objects.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Generate 16 random numbers drawn from a binomial distribution with parameter size equal to <strong class="inline">100</strong> and probability of success equal to <strong class="inline">0.4</strong>:<p class="snippet">r_numbers &lt;- rbinom(n = 16, size = 100, prob = 0.4)</p></li>
				<li>Next, print the <strong class="inline">r_numbers</strong> values using the following command:<p class="snippet">r_numbers</p><p>The output is as follows:</p><p class="snippet">##  [1] 38 46 40 42 45 39 37 35 44 39 46 41 31 32 34 43</p></li>
				<li>Select any 16 alphabets from English <strong class="inline">LETTERS</strong> without repetition:<p class="snippet">r_characters &lt;- sample(LETTERS, 18, FALSE)</p></li>
				<li>Now, print the <strong class="inline">r_characters</strong> values using the following command:<p class="snippet">r_characters</p><p>The output is as follows:</p><p class="snippet">##  [1] "C" "K" "Z" "I" "E" "A" "X" "O" "H" "Y" "T" "B" "N" "F" "U" "V" "S"</p><p class="snippet">## [18] "P"</p></li>
				<li>Combine <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong> using <strong class="inline">cbind</strong>:<p class="snippet">cbind(r_numbers, r_characters)</p><p>The output is as follows:</p><p class="snippet">## Warning in cbind(r_numbers, r_characters): number of rows of result is not a multiple of vector length (arg 1)</p><p class="snippet">##       r_numbers r_characters</p><p class="snippet">##  [1,] "38"      "C"         </p><p class="snippet">##  [2,] "46"      "K"         </p><p class="snippet">##  [3,] "40"      "Z"         </p><p class="snippet">##  [4,] "42"      "I"         </p><p class="snippet">##  [5,] "45"      "E"         </p><p class="snippet">##  [6,] "39"      "A"         </p><p class="snippet">##  [7,] "37"      "X"         </p><p class="snippet">##  [8,] "35"      "O"         </p><p class="snippet">##  [9,] "44"      "H"         </p><p class="snippet">"</p></li>
				<li>Print the class (type of data structure) we obtain after using <strong class="inline">cbind</strong>:<p class="snippet">class(cbind(r_numbers, r_characters))</p><p>The output is as follows:</p><p class="snippet">## [1] "matrix"</p><p>Observe a warning message in the output of <strong class="inline">cbind</strong> in the 5th step of this exercise:</p><p class="snippet">number of rows of result is not a multiple of vector length (arg 1)</p><p class="snippet">r_numbers r_characters</p></li>
			</ol>
			<p>The error means that the lengths of <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong> are not same (16 and 18, respectively). Note that the <strong class="inline">cbind()</strong> method, unlike <strong class="inline">as.data.frame()</strong>, doesn't throw an error. Instead, it automatically performs what is known as <strong class="bold">Recycling</strong>, and the vector of shorter length gets recycled. In the output, the <strong class="inline">r_numbers</strong> <strong class="inline">38</strong> and <strong class="inline">48</strong> are recycled from the top to fill the 17th and 18th index.</p>
			<p>Consider that we write the following command instead:</p>
			<p class="snippet">cbind(as.data.frame(r_numbers), as.data.frame(r_characters))</p>
			<p>It will now throw an error as we had shown earlier in the DataFrame section:</p>
			<p class="snippet">Error in data.frame(..., check.names = FALSE) : </p>
			<p class="snippet">  arguments imply differing number of rows: 16, 18</p>
			<p>One needs to be careful by always checking for the dimensions and the class of data. Otherwise, it may lead to unwanted results. When we give two vectors, it creates a matrix by default on doing a <strong class="inline">cbind</strong>.</p>
			<h4>Note</h4>
			<p class="callout">Since we are not setting any seed value, the output of sample and <strong class="inline">rbinom</strong> will differ in each execution of the code.</p>
			<h3 id="_idParaDest-41"><a id="_idTextAnchor041"/>rbind</h3>
			<p><strong class="inline">rbind</strong> is like <strong class="inline">cbind</strong>, but it combines by row instead of column. For <strong class="inline">rbind</strong> to work, the number of columns should be equal in both the DataFrames. It is useful in cases when we want to append an additional set of observations with an existing dataset where all the columns of the original dataset are the same and are in the same order. Let's explore <strong class="inline">rbind</strong> in the following exercise.</p>
			<h3 id="_idParaDest-42"><a id="_idTextAnchor042"/>Exercise 10: Exploring the rbind Function</h3>
			<p>In this exercise, we will combine two DataFrames using the <strong class="inline">rbind</strong> function.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Generate 16 random numbers drawn from a binomial distribution with parameter size equal to <strong class="inline">100</strong> and probability of success equal to 0.4:<p class="snippet">r_numbers &lt;- rbinom(n = 18, size = 100, prob = 0.4)</p></li>
				<li>Next, print the <strong class="inline">r_numbers</strong> values:<p class="snippet">r_numbers</p><p>The output is as follows:</p><p class="snippet">##  [1] 38 46 40 42 45 39 37 35 44 39 46 41 31 32 34 43</p></li>
				<li>Select any 16 alphabets from English <strong class="inline">LETTERS</strong> without repetition:<p class="snippet">r_characters &lt;- sample(LETTERS, 18, FALSE)</p></li>
				<li>Now, print the <strong class="inline">r_characters</strong> using the following command:<p class="snippet">r_characters</p><p>The output is as follows:</p><p class="snippet">##  [1] "C" "K" "Z" "I" "E" "A" "X" "O" "H" "Y" "T" "B" "N" "F" "U" "V" "S"</p><p class="snippet">## [18] "P"</p></li>
				<li>Finally, use the <strong class="inline">rbind</strong> method to print the combined value of <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong>:<p class="snippet">rbind(r_numbers, r_characters)</p><p>The output is as follows:</p><p class="snippet">##              [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]</p><p class="snippet">## r_numbers    "37" "44" "38" "38" "41" "35" "38" "40" "38" "45"  "37" </p><p class="snippet">## r_characters "Q"  "Y"  "O"  "L"  "A"  "G"  "V"  "S"  "B"  "U"   "D"  </p><p class="snippet">##              [,12] [,13] [,14] [,15] [,16] [,17] [,18]</p><p class="snippet">## r_numbers    "40"  "41"  "42"  "36"  "44"  "37"  "44" </p><p class="snippet">## r_characters "R"   "T"   "P"   "F"   "X"   "C"   "I"</p></li>
			</ol>
			<p>From the last step, observe that the <strong class="inline">rbind</strong> function concatenates (binds) the <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong> as two rows of data, unlike <strong class="inline">cbind</strong>, where it was stacked in two columns. Except for the output, all the other rules of <strong class="inline">cbind</strong> apply to <strong class="inline">rbind</strong> as well.</p>
			<h3 id="_idParaDest-43"><a id="_idTextAnchor043"/>The merge Function</h3>
			<p>The<strong class="inline"> merge()</strong> function in R is particularly useful when there is more than one DataFrame to join using a common column (what we call a <strong class="bold">primary key</strong> in the database world). Merge has two different implementations for the DataFrame and data table, which behave mostly in the same way.</p>
			<h3 id="_idParaDest-44"><a id="_idTextAnchor044"/>Exercise 11: Exploring the merge Function</h3>
			<p>In this exercise, we will generate two DataFrames, that is, <strong class="inline">df_one</strong> and <strong class="inline">df_two</strong>, such that the <strong class="inline">r_numbers</strong> column uniquely identifies each row in each of the DataFrame.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<p><strong class="bold">First DataFrame</strong></p>
			<ol>
				<li value="1">Use the <strong class="inline">set.seed()</strong> method to ensure that the same random numbers are generated every time the code is run:<p class="snippet">set.seed(100)</p></li>
				<li>Next, generate any 16 random numbers between 1 to 30 without repetition:<p class="snippet">r_numbers &lt;- sample(1:30,10, replace = FALSE)</p></li>
				<li>Generate any 16 characters from the English alphabet with repetition:<p class="snippet">r_characters &lt;- sample(LETTERS, 10, TRUE)</p></li>
				<li>Combine <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong> into one DataFrame named <strong class="inline">df_one</strong>:<p class="snippet">df_one &lt;- cbind(as.data.frame(r_numbers), as.data.frame(r_characters))</p><p class="snippet">df_one</p><p>The output is as follows:</p><p class="snippet">##    r_numbers r_characters</p><p class="snippet">## 1         10            Q</p><p class="snippet">## 2          8            W</p><p class="snippet">## 3         16            H</p><p class="snippet">## 4          2            K</p><p class="snippet">## 5         13            T</p><p class="snippet">## 6         26            R</p><p class="snippet">## 7         20            F</p><p class="snippet">## 8          9            J</p><p class="snippet">## 9         25            J</p><p class="snippet">## 10         4            R</p></li>
			</ol>
			<p><strong class="bold">Second DataFrame</strong></p>
			<ol>
				<li value="1">Use the <strong class="inline">set.seed()</strong> method for preserving the same random numbers over multiple runs:<p class="snippet">set.seed(200)</p></li>
				<li>Next, generate any 16 random numbers between 1 to 30 without repetition:<p class="snippet">r_numbers &lt;- sample(1:30,10, replace = FALSE)</p></li>
				<li>Now, generate any 16 characters from the English alphabet with repetition:<p class="snippet">r_characters &lt;- sample(LETTERS, 10, TRUE)</p></li>
				<li>Combine <strong class="inline">r_numbers</strong> and <strong class="inline">r_characters</strong> into one DataFrame named <strong class="inline">df_two</strong>:<p class="snippet">df_two &lt;- cbind(as.data.frame(r_numbers), as.data.frame(r_characters))</p><p class="snippet">df_two</p><p>The output is as follows:</p><p class="snippet">##    r_numbers r_characters</p><p class="snippet">## 1         17            L</p><p class="snippet">## 2         30            Q</p><p class="snippet">## 3         29            D</p><p class="snippet">## 4         19            Q</p><p class="snippet">## 5         18            J</p><p class="snippet">## 6         21            H</p><p class="snippet">## 7         26            O</p><p class="snippet">## 8          3            D</p><p class="snippet">## 9         12            X</p><p class="snippet">## 10         5            Q</p></li>
			</ol>
			<p>Once we create the <strong class="inline">df_one</strong> and <strong class="inline">df_two</strong> DataFrames using the <strong class="inline">cbind()</strong> function, we are ready to perform some merge (will use the word JOIN, which means the same as <strong class="inline">merge()</strong>).</p>
			<p>Now, let's see how different type of joins give different results.</p>
			<p>In the world of databases, JOINs are used to combine two or more than two tables using a common primary key. In databases, we use Structured Query Language (SQL) to perform the JOINs. In R, the <strong class="inline">merge()</strong> function helps us with the same functionality as SQL offers in databases. Also, instead of tables, we have DataFrames here, which is again a table with rows and columns of data.</p>
			<h3 id="_idParaDest-45"><a id="_idTextAnchor045"/>Inner Join</h3>
			<p>In <em class="italics">Exercise 11</em>, <em class="italics">Exploring the merge Function</em>, we created two DataFrames: <strong class="inline">df_one</strong> and <strong class="inline">df_ two</strong>. We will now join the two DataFrames using <strong class="bold">Inner Join</strong>. Observe that only the value <strong class="inline">26</strong> (row number <strong class="inline">7</strong>) in the <strong class="inline">r_numbers</strong> column is common between the two DataFrames, where the corresponding character in the <strong class="inline">r_characters</strong> column is <strong class="inline">R</strong> in <strong class="inline">df_one</strong> and character <strong class="inline">O</strong> in <strong class="inline">df_two</strong>. In the output, <strong class="inline">X</strong> corresponds to the <strong class="inline">df_one</strong> DataFrame and <strong class="inline">Y</strong> correspond to the <strong class="inline">df_two</strong> DataFrame.</p>
			<p>To merge the <strong class="inline">df_one</strong> and <strong class="inline">df_two</strong> DataFrames using the <strong class="inline">r_numbers</strong> column, use the following command:</p>
			<p class="snippet">merge(df_one, df_two, by = "r_numbers")</p>
			<p class="snippet">##   r_numbers r_characters.x r_characters.y</p>
			<p class="snippet">## 1        26              R              O</p>
			<h3 id="_idParaDest-46"><a id="_idTextAnchor046"/>Left Join</h3>
			<p><strong class="bold">Left Join</strong> gives all the values of <strong class="inline">df_one</strong> in the <strong class="inline">r_numbers</strong> column and adds <strong class="inline">&lt;NA&gt;</strong> as a value wherever the corresponding value in <strong class="inline">df_two</strong> is not found. For example, for <strong class="inline">r_number = 2</strong>, there is no value in <strong class="inline">df_two</strong>, whereas for <strong class="inline">r_number = 26</strong>, values in <strong class="inline">df_one</strong> and <strong class="inline">df_two</strong>, for the <strong class="inline">r_characters</strong> column is <strong class="inline">R</strong> and <strong class="inline">O</strong>, respectively.</p>
			<p>To merge the <strong class="inline">df_one</strong> and <strong class="inline">df_two</strong> DataFrames using the <strong class="inline">r_numbers</strong> column, use the following command:</p>
			<p class="snippet">merge(df_one, df_two, by = "r_numbers", all.x = TRUE)</p>
			<p class="snippet">##    r_numbers r_characters.x r_characters.y</p>
			<p class="snippet">## 1          2              K           &lt;NA&gt;</p>
			<p class="snippet">## 2          4              R           &lt;NA&gt;</p>
			<p class="snippet">## 3          8              W           &lt;NA&gt;</p>
			<p class="snippet">## 4          9              J           &lt;NA&gt;</p>
			<p class="snippet">## 5         10              Q           &lt;NA&gt;</p>
			<p class="snippet">## 6         13              T           &lt;NA&gt;</p>
			<p class="snippet">## 7         16              H           &lt;NA&gt;</p>
			<p class="snippet">## 8         20              F           &lt;NA&gt;</p>
			<p class="snippet">## 9         25              J           &lt;NA&gt;</p>
			<p class="snippet">## 10        26              R              O</p>
			<h3 id="_idParaDest-47"><a id="_idTextAnchor047"/>Right Join</h3>
			<p><strong class="bold">Right Joins</strong> works just like Left Join, except for that the values in the <strong class="inline">r_character</strong> columns of <strong class="inline">df_one</strong> are <strong class="inline">&lt;NA&gt;</strong> wherever a match is not found. Again, <strong class="inline">r_numbers = 26</strong> is the only match.</p>
			<p>To merge the <strong class="inline">df_one</strong> and <strong class="inline">df_two</strong> DataFrames using the <strong class="inline">r_numbers</strong> column, use the following command:</p>
			<p class="snippet">merge(df_one, df_two, by = "r_numbers", all.y = TRUE)</p>
			<p class="snippet">##    r_numbers r_characters.x r_characters.y</p>
			<p class="snippet">## 1          3           &lt;NA&gt;              D</p>
			<p class="snippet">## 2          5           &lt;NA&gt;              Q</p>
			<p class="snippet">## 3         12           &lt;NA&gt;              X</p>
			<p class="snippet">## 4         17           &lt;NA&gt;              L</p>
			<p class="snippet">## 5         18           &lt;NA&gt;              J</p>
			<p class="snippet">## 6         19           &lt;NA&gt;              Q</p>
			<p class="snippet">## 7         21           &lt;NA&gt;              H</p>
			<p class="snippet">## 8         26              R              O</p>
			<p class="snippet">## 9         29           &lt;NA&gt;              D</p>
			<p class="snippet">## 10        30           &lt;NA&gt;              Q</p>
			<h3 id="_idParaDest-48"><a id="_idTextAnchor048"/>Full Join</h3>
			<p>Unlike Left and Right Join, <strong class="bold">Full Join</strong> gives all the unique values of the <strong class="inline">r_numbers</strong> column from both the DataFrames and adds <strong class="inline">&lt;NA&gt;</strong> in the <strong class="inline">r_characters</strong> column from the respective DataFrame. Observe that only the <strong class="inline">r_number = 26</strong> row has values from both the DataFrame.</p>
			<p>To merge the <strong class="inline">df_one</strong> and <strong class="inline">df_two</strong> DataFrames using the <strong class="inline">r_numbers</strong> column, use the following command:</p>
			<p class="snippet">merge(df_one, df_two, by = "r_numbers", all = TRUE)</p>
			<p class="snippet">##    r_numbers r_characters.x r_characters.y</p>
			<p class="snippet">## 1          2              K           &lt;NA&gt;</p>
			<p class="snippet">## 2          3           &lt;NA&gt;              D</p>
			<p class="snippet">## 3          4              R           &lt;NA&gt;</p>
			<p class="snippet">## 4          5           &lt;NA&gt;              Q</p>
			<p class="snippet">## 5          8              W           &lt;NA&gt;</p>
			<p class="snippet">## 6          9              J           &lt;NA&gt;</p>
			<p class="snippet">## 7         10              Q           &lt;NA&gt;</p>
			<p class="snippet">## 8         12           &lt;NA&gt;              X</p>
			<p class="snippet">## 9         13              T           &lt;NA&gt;</p>
			<p class="snippet">## 10        16              H           &lt;NA&gt;</p>
			<p class="snippet">## 11        17           &lt;NA&gt;              L</p>
			<p class="snippet">## 12        18           &lt;NA&gt;              J</p>
			<p class="snippet">## 13        19           &lt;NA&gt;              Q</p>
			<p class="snippet">…</p>
			<h3 id="_idParaDest-49"><a id="_idTextAnchor049"/>The reshape Function</h3>
			<p>Data is known to be in a <strong class="bold">wide</strong> format if each subject has only a single row, with each measurement present as a different variable or column. Similarly, it is a <strong class="bold">long</strong> format if each measurement has a single observation (thus, multiple rows per subject). The <strong class="inline">reshape</strong> function is used often to convert between wide and long formats for a variety of operations to make the data useful for computation or analysis. In many visualizations, we use <strong class="inline">reshape()</strong> to convert wide format to long and vice versa.</p>
			<p>We will use the Iris dataset. This dataset contains variables named <strong class="inline">Sepal.Length</strong>, <strong class="inline">Sepal.Width</strong>, <strong class="inline">Petal.Length</strong>, and <strong class="inline">Petal.Width</strong>, whose measurements are given in centimeters, for 50 flowers from each of 3 species of Iris, namely <em class="italics">setosa</em>, <em class="italics">versicolor</em>, and <em class="italics">virginica</em>.</p>
			<h3 id="_idParaDest-50"><a id="_idTextAnchor050"/>Exercise 12: Exploring the reshape Function</h3>
			<p>In this exercise, we will explore the reshape function.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">First, print the top five rows of the iris dataset using the following command:<p class="snippet">head(iris)</p><p>The output of the previous command is as follows:</p><p class="snippet">##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species</p><p class="snippet">## 1          5.1         3.5          1.4         0.2  setosa</p><p class="snippet">## 2          4.9         3.0          1.4         0.2  setosa</p><p class="snippet">## 3          4.7         3.2          1.3         0.2  setosa</p><p class="snippet">## 4          4.6         3.1          1.5         0.2  setosa</p><p class="snippet">## 5          5.0         3.6          1.4         0.2  setosa</p><p class="snippet">## 6          5.4         3.9          1.7         0.4  setosa</p></li>
				<li>Now, create a variable called <strong class="inline">Type</strong> based on the following condition. When <strong class="inline">Sepal.Width &gt; 2</strong> and <strong class="inline">Sepal Width &lt;= 3</strong>, we will assign <strong class="inline">TYPE 1</strong> or <strong class="inline">TYPE 2</strong>. The type column is for demo purpose only and has no particular logic:<p class="snippet">iris$Type &lt;- ifelse((iris$Sepal.Width&gt;2 &amp; iris$Sepal.Width &lt;=3),"TYPE 1","TYPE 2")</p></li>
				<li>Store the <strong class="inline">Type</strong>, <strong class="inline">Sepal.Width</strong>, and <strong class="inline">Species</strong> columns in the <strong class="inline">df_iris</strong> DataFrame:<p class="snippet">df_iris &lt;- iris[,c("Type","Sepal.Width","Species")]</p></li>
				<li>Next, reshape <strong class="inline">df_iris</strong> into wide DataFrame using the following <strong class="inline">reshape</strong> command:<p class="snippet">reshape(df_iris,idvar = "Species", timevar = "Type", direction = "wide")</p><p>The output is as follows:</p><p class="snippet">##        Species Sepal.Width.TYPE 2 Sepal.Width.TYPE 1</p><p class="snippet">## 1       setosa                3.5                3.0</p><p class="snippet">## 51  versicolor                3.2                2.3</p><p class="snippet">## 101  virginica                3.3                2.7</p><p>You will get a warning while running the <strong class="inline">reshape</strong> command, saying as follows:</p><p class="snippet">multiple rows match for Type=TYPE 2: first taken multiple rows match for Type=TYPE 1: first taken</p></li>
			</ol>
			<p>This warning means there were multiple values for <strong class="inline">Type 1</strong> and <strong class="inline">Type 2</strong> for the three species, so the reshape has picked the first occurrence of each of the species. In this case, the <strong class="inline">1</strong>, <strong class="inline">51</strong>, and <strong class="inline">101</strong> row numbers. We will now see how we could handle this transformation better in the <strong class="inline">aggregate</strong> function.</p>
			<h3 id="_idParaDest-51"><a id="_idTextAnchor051"/>The aggregate Function</h3>
			<p>Aggregation is a useful method for computing statistics such as count, averages, standard deviations, and quartiles, and it also allows for writing a custom function. In the following code, the formula (formula is a name of the data structure in R, not a mathematical equation) for each Iris species computes the mean of the numeric measures sepal and petal width and length. The first of the aggregate function argument is a formula that takes species and all the other measurements to compute the mean from all the observations.</p>
			<p class="snippet">aggregate(formula =. ~ Species, data = iris, FUN = mean)</p>
			<p>The output of the previous command is as follows:</p>
			<p class="snippet">##      Species Sepal.Length Sepal.Width Petal.Length Petal.Width</p>
			<p class="snippet">## 1     setosa        5.006       3.428        1.462       0.246</p>
			<p class="snippet">## 2 versicolor        5.936       2.770        4.260       1.326</p>
			<p class="snippet">## 3  virginica        6.588       2.974        5.552       2.026</p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor052"/>The Apply Family of Functions</h2>
			<p>If one has to debate on a few powerful features of R programming, the <strong class="inline">apply</strong> family of functions, would find a mention. It is used commonly to avoid using looping structures such as <strong class="inline">for</strong> and <strong class="inline">while</strong> even though they are available in R.</p>
			<p>First, it's slow to run <strong class="inline">for</strong> loops in R and second, the implementation of the <strong class="inline">apply</strong> functions in R is based on efficient programming languages such as C/C++, which makes it extremely fast to loop.</p>
			<p>There are many functions in the <strong class="inline">apply</strong> family. Depending on the structure of the input and output required, we select the appropriate function:</p>
			<ul>
				<li><strong class="inline">apply()</strong></li>
				<li><strong class="inline">lapply()</strong></li>
				<li><strong class="inline">sapply()</strong></li>
				<li><strong class="inline">vapply()</strong></li>
				<li><strong class="inline">mapply()</strong></li>
				<li><strong class="inline">rapply()</strong></li>
				<li><strong class="inline">tapply()</strong></li>
			</ul>
			<p>We will discuss a few in this section.</p>
			<h3 id="_idParaDest-53"><a id="_idTextAnchor053"/>The apply Function</h3>
			<p>The <strong class="inline">apply()</strong> function takes an array, including a matrix, as input and returns a vector, array, or list of values obtained by applying a function to margins of an array or matrix.</p>
			<h3 id="_idParaDest-54"><a id="_idTextAnchor054"/>Exercise 13: Implementing the apply Function</h3>
			<p>In this exercise, we will count the number of vowels in each column of a 100 x 100 matrix of random letters from the English alphabet. The <strong class="inline">MARGIN = 1</strong> function will scan each row, and <strong class="inline">MARGIN = 2</strong> will specify the column. The same function will the count vowels in each row.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Create a 100 x 100 matrix of random letters (<strong class="inline">ncol</strong> is the number of columns and <strong class="inline">nrow</strong> is the number of rows) using the following command:<p class="snippet">r_characters &lt;- matrix(sample(LETTERS, 10000, replace = TRUE), ncol = 100, nrow = 100)</p></li>
				<li>Now, create a function named <strong class="inline">c_vowel</strong> to count the number of vowels in a given array:<p class="snippet">c_vowel &lt;- function(x_char){</p><p class="snippet">  return(sum(x_char %in% c("A","I","O","U")))</p><p class="snippet">}</p></li>
				<li>Next, use the <strong class="inline">apply</strong> function to run through each column of the matrix, and use the <strong class="inline">c_vowel</strong> function as illustrated here:<p class="snippet">apply(r_characters, MARGIN = 2, c_vowel)</p><p>The output is as follows:</p><p class="snippet">##   [1] 17 16 10 11 12 25 16 14 14 12 20 13 16 14 14 20 10 12 11 16 10 20 15</p><p class="snippet">##  [24] 10 14 13 17 14 14 13 15 19 18 21 15 13 19 21 24 18 13 20 15 15 15 19</p><p class="snippet">##  [47] 13  6 18 11 16 16 11 13 20 14 12 17 11 14 14 16 13 11 23 14 17 14 22</p><p class="snippet">##  [70] 11 18 10 18 21 19 14 18 12 13 15 16 10 15 19 14 13 16 15 12 12 14 10</p><p class="snippet">##  [93] 16 16 20 16 13 22 15 15</p></li>
			</ol>
			<h3 id="_idParaDest-55"><a id="_idTextAnchor055"/>The lapply Function</h3>
			<p>The <strong class="inline">lapply</strong> function looks similar to <strong class="inline">apply()</strong>, with a difference that it takes input as a <em class="italics">list</em> and returns a <em class="italics">list</em> as output. After rewriting our previous example in the following exercise, the output of class function shows that the output is a list.</p>
			<h3 id="_idParaDest-56"><a id="_idTextAnchor056"/>Exercise 14: Implementing the lapply Function</h3>
			<p>In this exercise, we will take a list of vectors and count the number of vowels.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Create a list with two vector of random letters, each of size 100:<p class="snippet">r_characters &lt;- list(a=sample(LETTERS, 100, replace = TRUE),</p><p class="snippet">                     b=sample(LETTERS, 100, replace = TRUE))</p></li>
				<li>Use the <strong class="inline">lapply</strong> function to run through on list <strong class="inline">a</strong> and <strong class="inline">b</strong>, and the <strong class="inline">c_vowel</strong> function to count the number of vowels from the list:<p class="snippet">lapply(r_characters, c_vowel)</p><p>The output is as follows:</p><p class="snippet">## $a</p><p class="snippet">## [1] 19</p><p class="snippet">## $b</p><p class="snippet">## [1] 10</p></li>
				<li>Check the class (type) of the output. The <strong class="inline">class()</strong> function provides the type of data structure:<p class="snippet">out_list &lt;- lapply(r_characters, c_vowel)</p><p class="snippet">class(out_list)</p><p>The output is as follows:</p><p class="snippet">## [1] "list"</p></li>
			</ol>
			<h3 id="_idParaDest-57"><a id="_idTextAnchor057"/>The sapply Function</h3>
			<p>The <strong class="inline">sapply</strong> function is just a wrapper on the <strong class="inline">lapply</strong> function, where the output is a vector or matrix instead of a list. In the following code, observe the type of the output after applying <strong class="inline">sapply</strong> difference. The output returns a vector of integers, as we can check with the <strong class="inline">class()</strong> function:</p>
			<p class="snippet">sapply(r_characters, c_vowel)</p>
			<p class="snippet">##  a  b </p>
			<p class="snippet">## 19 10</p>
			<p>To print the class of the output, use the following command:</p>
			<p class="snippet">out_vector &lt;- sapply(r_characters, c_vowel)</p>
			<p class="snippet">class(out_vector)</p>
			<p>The output of the previous command is as follows:</p>
			<p class="snippet">## [1] "integer"</p>
			<h3 id="_idParaDest-58"><a id="_idTextAnchor058"/>The tapply Function</h3>
			<p>Apply a function to each cell of a ragged array, that is, to each (non-empty) group of values given by a unique combination of the levels of certain factors. The <strong class="inline">tapply</strong> function is quite useful when it comes to working on a subset level of data. For example, in our <strong class="inline">aggregate</strong> function, if we were to get an aggregate like standard deviation for the type of Iris species, we could use <strong class="inline">tapply</strong>. The following code shows how to use the <strong class="inline">tapply</strong> function:</p>
			<p>First, calculate the standard deviation of sepal length for each Iris species:</p>
			<p class="snippet">tapply(iris$Sepal.Length, iris$Species,sd)</p>
			<p>The output is as follows:</p>
			<p class="snippet">##     setosa versicolor  virginica </p>
			<p class="snippet">##  0.3524897  0.5161711  0.6358796</p>
			<p>Next, calculate the standard deviation of sepal width for each of the Iris species:</p>
			<p class="snippet">tapply(iris$Sepal.Width, iris$Species,sd)</p>
			<p>The output of the previous command is as follows:</p>
			<p class="snippet">##     setosa versicolor  virginica </p>
			<p class="snippet">##  0.3790644  0.3137983  0.3224966</p>
			<p>Now, let's explore some popular and useful R packages that might be of value while building complex data processing methods, machine learning models, or data visualization.</p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor059"/>Useful Packages</h2>
			<p>While there are more than thirteen thousand packages in the CRAN repository, some of the packages have a unique place and utility for some major functionality. So far, we saw many examples of data manipulations such as join, aggregate, reshaping, and sub-setting. The R packages we will discuss next will provide a plethora of functions, providing a wide range of data processing and transformation capabilities.</p>
			<h3 id="_idParaDest-60"><a id="_idTextAnchor060"/>The dplyr Package</h3>
			<p>The <strong class="inline">dplyr</strong> package helps in the most common data manipulation challenges through five different methods, namely, <strong class="inline">mutate()</strong>, <strong class="inline">select()</strong>, <strong class="inline">filter()</strong>, <strong class="inline">summarise()</strong>, and <strong class="inline">arrange()</strong>. Let's revisit our direct marketing campaigns (phone calls) of a Portuguese banking institution dataset from UCI Machine Learning Repository to test out all these methods.</p>
			<p>The <strong class="inline">%&gt;%</strong> symbol in the following exercise is called <strong class="bold">chain operator</strong>. The output of the one operation is sent to the next one without explicitly creating a new variable. Such a chaining operation is storage efficient and makes the readability of the code easy.</p>
			<h3 id="_idParaDest-61"><a id="_idTextAnchor061"/>Exercise 15: Implementing the dplyr Package</h3>
			<p>In this exercise, we are interested in knowing the average bank balance of people doing blue-collar jobs by their marital status. Use the functions from the <strong class="inline">dplyr</strong> package to get the answer.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Import the <strong class="inline">bank-full.csv</strong> file into the <strong class="inline">df_bank_detail</strong> object using the <strong class="inline">read.csv()</strong> function:<p class="snippet">df_bank_detail &lt;- read.csv("bank-full.csv", sep = ';')</p></li>
				<li>Now, load the <strong class="inline">dplyr</strong> library:<p class="snippet">library(dplyr)</p></li>
				<li>Select (filter) all the observations where the <strong class="inline">job</strong> column contains the value <strong class="inline">blue-collar</strong> and then group by the martial status to generate the summary statistic, <strong class="inline">mean</strong>:<p class="snippet">df_bank_detail %&gt;%</p><p class="snippet">  filter(job == "blue-collar") %&gt;%</p><p class="snippet">  group_by(marital) %&gt;%</p><p class="snippet">  summarise(</p><p class="snippet">    cnt = n(),</p><p class="snippet">    average = mean(balance, na.rm = TRUE)</p><p class="snippet">  )</p><p>The output is as follows:</p><p class="snippet">## # A tibble: 3 x 3</p><p class="snippet">##    marital   cnt   average</p><p class="snippet">##     &lt;fctr&gt; &lt;int&gt;     &lt;dbl&gt;</p><p class="snippet">## 1 divorced   750  820.8067</p><p class="snippet">## 2  married  6968 1113.1659</p><p class="snippet">## 3   single  2014 1056.1053</p></li>
				<li>Let's find out the bank balance of customers with secondary education and default as <strong class="inline">yes</strong>:<p class="snippet">df_bank_detail %&gt;%</p><p class="snippet">  mutate(sec_edu_and_default = ifelse((education == "secondary" &amp; default == "yes"), "yes","no")) %&gt;%</p><p class="snippet">  select(age, job, marital,balance, sec_edu_and_default) %&gt;%</p><p class="snippet">  filter(sec_edu_and_default == "yes") %&gt;%</p><p class="snippet">  group_by(marital) %&gt;%</p><p class="snippet">  summarise(</p><p class="snippet">    cnt = n(),</p><p class="snippet">    average = mean(balance, na.rm = TRUE)</p><p class="snippet">  )</p><p>The output is as follows:</p><p class="snippet">## # A tibble: 3 x 3</p><p class="snippet">##    marital   cnt    average</p><p class="snippet">##     &lt;fctr&gt; &lt;int&gt;      &lt;dbl&gt;</p><p class="snippet">## 1 divorced    64   -8.90625</p><p class="snippet">## 2  married   243  -74.46914</p><p class="snippet">## 3   single   151 -217.43046</p></li>
			</ol>
			<p>Much of complex analysis is done with ease. Note that the <strong class="inline">mutate()</strong> method helps in creating custom columns with certain calculation or logic.</p>
			<h3 id="_idParaDest-62"><a id="_idTextAnchor062"/>The tidyr Package</h3>
			<p>The <strong class="inline">tidyr</strong> package has three essential functions—<strong class="inline">gather()</strong>, <strong class="inline">separate()</strong>, and <strong class="inline">spread()</strong>—for cleaning messy data.</p>
			<p>The <strong class="inline">gather()</strong> function converts <strong class="bold">wide</strong> DataFrame to long by taking multiple columns and gathering them into key-value pairs.</p>
			<h3 id="_idParaDest-63"><a id="_idTextAnchor063"/>Exercise 16: Implementing the tidyr Package</h3>
			<p>In this exercise, we will explore the <strong class="inline">tidyr</strong> package and the functions associated with it.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Import the <strong class="inline">tidyr</strong> library using the following command:<p class="snippet">library(tidyr)</p></li>
				<li>Next, set the <strong class="inline">seed</strong> to 100 using the following command:<p class="snippet">set.seed(100)</p></li>
				<li>Create an <strong class="inline">r_name</strong> object and store the 5 person names in it:<p class="snippet">r_name &lt;- c("John", "Jenny", "Michael", "Dona", "Alex")</p></li>
				<li>For the <strong class="inline">r_food_A</strong> object, generate 16 random numbers between 1 to 30 without repetition:<p class="snippet">r_food_A &lt;- sample(1:150,5, replace = FALSE)</p></li>
				<li>Similarly, for the <strong class="inline">r_food_B</strong> object, generate 16 random numbers between 1 to 30 without repetition:<p class="snippet">r_food_B &lt;- sample(1:150,5, replace = FALSE)</p></li>
				<li>Create and print the data from the DataFrame using the following command:<p class="snippet">df_untidy &lt;- data.frame(r_name, r_food_A, r_food_B)</p><p class="snippet">df_untidy</p><p>The output is as follows:</p><p class="snippet">##    r_name r_food_A r_food_B</p><p class="snippet">## 1    John       47       73</p><p class="snippet">## 2   Jenny       39      122</p><p class="snippet">## 3 Michael       82       55</p><p class="snippet">## 4    Dona        9       81</p><p class="snippet">## 5    Alex       69       25</p></li>
				<li>Use the <strong class="inline">gather()</strong> method from the <strong class="inline">tidyr</strong> package:<p class="snippet">df_long &lt;- df_untidy %&gt;%</p><p class="snippet">  gather(food, calories, r_food_A:r_food_B)</p><p class="snippet">df_long</p><p>The output is as follows:</p><p class="snippet">##     r_name     food calories</p><p class="snippet">## 1     John r_food_A       47</p><p class="snippet">## 2    Jenny r_food_A       39</p><p class="snippet">## 3  Michael r_food_A       82</p><p class="snippet">## 4     Dona r_food_A        9</p><p class="snippet">## 5     Alex r_food_A       69</p><p class="snippet">## 6     John r_food_B       73</p><p class="snippet">## 7    Jenny r_food_B      122</p><p class="snippet">## 8  Michael r_food_B       55</p><p class="snippet">## 9     Dona r_food_B       81</p><p class="snippet">## 10    Alex r_food_B       25</p></li>
				<li>The <strong class="inline">spread()</strong> function works the other way around of <strong class="inline">gather()</strong>, that is, it takes a long format and converts it into wide format:<p class="snippet">df_long %&gt;%</p><p class="snippet">  spread(food,calories)</p><p class="snippet">##    r_name r_food_A r_food_B</p><p class="snippet">## 1    Alex       69       25</p><p class="snippet">## 2    Dona        9       81</p><p class="snippet">## 3   Jenny       39      122</p><p class="snippet">## 4    John       47       73</p><p class="snippet">## 5 Michael       82       55</p></li>
				<li>The <strong class="inline">separate()</strong> function is useful in places where columns are a combination of values and is used for making it a key column for other purposes. We can separate out the key if it has a common separator character:<p class="snippet">key &lt;- c("John.r_food_A", "Jenny.r_food_A", "Michael.r_food_A", "Dona.r_food_A", "Alex.r_food_A", "John.r_food_B", "Jenny.r_food_B", "Michael.r_food_B", "Dona.r_food_B", "Alex.r_food_B")</p><p class="snippet">calories &lt;- c(74, 139, 52, 141, 102, 134, 27, 94, 146, 20)</p><p class="snippet">df_large_key &lt;- data.frame(key,calories)  </p><p class="snippet">df_large_key</p><p>The output is as follows:</p><p class="snippet">##                 key calories</p><p class="snippet">## 1     John.r_food_A       74</p><p class="snippet">## 2    Jenny.r_food_A      139</p><p class="snippet">## 3  Michael.r_food_A       52</p><p class="snippet">## 4     Dona.r_food_A      141</p><p class="snippet">## 5     Alex.r_food_A      102</p><p class="snippet">## 6     John.r_food_B      134</p><p class="snippet">## 7    Jenny.r_food_B       27</p><p class="snippet">## 8  Michael.r_food_B       94</p><p class="snippet">## 9     Dona.r_food_B      146</p><p class="snippet">## 10    Alex.r_food_B       20</p><p class="snippet">df_large_key %&gt;%</p><p class="snippet">  separate(key, into = c("name","food"), sep = "\\.")</p><p class="snippet">##       name     food calories</p><p class="snippet">## 1     John r_food_A       74</p><p class="snippet">## 2    Jenny r_food_A      139</p><p class="snippet">## 3  Michael r_food_A       52</p><p class="snippet">## 4     Dona r_food_A      141</p><p class="snippet">## 5     Alex r_food_A      102</p><p class="snippet">## 6     John r_food_B      134</p><p class="snippet">## 7    Jenny r_food_B       27</p><p class="snippet">## 8  Michael r_food_B       94</p><p class="snippet">## 9     Dona r_food_B      146</p><p class="snippet">## 10    Alex r_food_B       20</p></li>
			</ol>
			<h3 id="_idParaDest-64"><a id="_idTextAnchor064"/>Activity 3: Create a DataFrame with Five Summary Statistics for All Numeric Variables from Bank Data Using dplyr and tidyr</h3>
			<p>This activity will make you accustomed to selecting all numeric fields from the bank data and produce the summary statistics on numeric variables.</p>
			<p>Perform the following steps to complete the activity:</p>
			<ol>
				<li value="1">Extract all numeric variables from bank data using <strong class="inline">select()</strong>.</li>
				<li>Using the <strong class="inline">summarise_all()</strong> method, compute min, 1st quartile, 3rd quartile, median, mean, max, and standard deviation.<h4>Note</h4><p class="callout">You can learn more about the <strong class="inline">summarise_all</strong> function at <a href="https://www.rdocumentation.org/packages/dplyr/versions/0.5.0/topics/summarise_all">https://www.rdocumentation.org/packages/dplyr/versions/0.5.0/topics/summarise_all</a>.</p></li>
				<li>Store the result in a DataFrame of wide format named <strong class="inline">df_wide</strong>.</li>
				<li>Now, to convert wide format to deep, use the gather, separate, and spread functions of the <strong class="inline">tidyr</strong> package.</li>
				<li>The final output should have one row for each variable and one column each of min, 1st quartile, 3rd quartile, median, mean, max, and standard deviation.<p>Once you complete the activity, you should have the final output as follows:</p><p class="snippet">## # A tibble: 4 x 8</p><p class="snippet">##        var   min   q25 median   q75    max       mean         sd</p><p class="snippet">## *    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;</p><p class="snippet">## 1      age    18    33     39    48     95   40.93621   10.61876</p><p class="snippet">## 2  balance -8019    72    448  1428 102127 1362.27206 3044.76583</p><p class="snippet">## 3 duration     0   103    180   319   4918  258.16308  257.52781</p><p class="snippet">## 4    pdays    -1    -1     -1    -1    871   40.19783  100.12875</p><h4>Note</h4><p class="callout">The solution for this activity can be found on page 440.</p></li>
			</ol>
			<h3 id="_idParaDest-65"><a id="_idTextAnchor065"/>The plyr Package</h3>
			<p>What we saw with the <strong class="inline">apply</strong> functions could be done through the <strong class="inline">plyr</strong> package on a much bigger scale and robustness. The <strong class="inline">plyr</strong> package provides the ability to split the dataset into subsets, apply a common function to each subset, and combine the results into a single output. The advantage of using <strong class="inline">plyr</strong> over the <strong class="inline">apply</strong> function is features like the following:</p>
			<ul>
				<li>Speed of code execution</li>
				<li>Parallelization of processing using <strong class="inline">foreach</strong> loop</li>
				<li>Support for list, DataFrame, and matrices</li>
				<li>Better debugging of errors</li>
			</ul>
			<p>All the function names in <strong class="inline">plyr</strong> are clearly defined based on input and output. For example, if an input is a DataFrame and output is list, the function name would be <strong class="inline">dlply</strong>.</p>
			<p>The following figure from the <em class="italics">The Split-Apply-Combine Strategy for Data Analysis</em> paper displays all the different <strong class="inline">plyr</strong> functions:</p>
			<div>
				<div id="_idContainer020" class="IMG---Figure">
					<img src="image/C12624_01_07.jpg" alt="Figure 1.7: Functions in the plyr packages&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 1.7: Functions in the plyr packages</h6>
			<p>The <strong class="inline">_</strong> means the output will be discarded.</p>
			<h3 id="_idParaDest-66"><a id="_idTextAnchor066"/>Exercise 17: Exploring the plyr Package</h3>
			<p>In this exercise, we will see how split-apply-combine makes things simple with the flexibility of controlling the input and output.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Load the <strong class="inline">plyr</strong> package using the following command:<p class="snippet">library(plyr)</p></li>
				<li>Next, use the slightly tweaked version of the <strong class="inline">c_vowel</strong> function we created in the earlier example in <em class="italics">Exercise 13</em>, <em class="italics">Exploring the apply Function</em>:<p class="snippet">c_vowel &lt;- function(x_char){</p><p class="snippet">  return(sum(as.character(x_char[,"b"]) %in% c("A","I","O","U")))</p><p class="snippet">}</p></li>
				<li>Set the <strong class="inline">seed</strong> to <strong class="inline">101</strong>:<p class="snippet">set.seed(101)</p></li>
				<li>Store the value in the <strong class="inline">r_characters</strong> object:<p class="snippet">r_characters &lt;- data.frame(a=rep(c("Split_1","Split_2","Split_3"),1000),</p><p class="snippet">                     b= sample(LETTERS, 3000, replace = TRUE))</p><h4>Note</h4><p class="callout"><strong class="inline">Input = DataFrame to output = list</strong></p></li>
				<li>Use the <strong class="inline">dlply()</strong> function and print the split in the row format:<p class="snippet">dlply(r_characters, c_vowel)</p><p>The output is as follows:</p><p class="snippet">## $Split_1</p><p class="snippet">## [1] 153</p><p class="snippet">## </p><p class="snippet">## $Split_2</p><p class="snippet">## [1] 154</p><p class="snippet">## </p><p class="snippet">## $Split_3</p><p class="snippet">## [1] 147</p><h4>Note</h4><p class="callout"><strong class="inline">Input = data.frame to output = array</strong></p></li>
				<li>We can simply replace dlply with the <strong class="inline">daply()</strong> function and print the split in the column format as an array:<p class="snippet">daply(r_characters, c_vowel)</p><p>The output is as follows:</p><p class="snippet">## Split_1 Split_2 Split_3 </p><p class="snippet">##     153     154     147</p><h4>Note</h4><p class="callout"><strong class="inline">Input = DataFrame to output = DataFrame</strong></p></li>
				<li>Use the <strong class="inline">ddply()</strong> function and print the split:<p class="snippet">ddply(r_characters, c_vowel)</p><p>The output is as follows:</p><p class="snippet">##         a  V1</p><p class="snippet">## 1 Split_1 153</p><p class="snippet">## 2 Split_2 154</p><p class="snippet">## 3 Split_3 147</p></li>
			</ol>
			<p>In steps 5, 6, and 7, observe how we created a list, array, and data as an output for DataFrame input. All we must do is use a different function from <strong class="inline">plyr</strong>. This makes it easy to type cast between many possible combinations.</p>
			<h3 id="_idParaDest-67"><a id="_idTextAnchor067"/>The caret Package</h3>
			<p>The <strong class="inline">caret</strong> package is particularly useful for building a predictive model, and it provides a structure for seamlessly following the entire process of building a predictive model. Starting from splitting data to training and testing dataset and variable importance estimation, we will extensively use the <strong class="inline">caret</strong> package in our chapters on regression and classification. In summary, <strong class="inline">caret</strong> provides tools for:</p>
			<ul>
				<li>Data splitting</li>
				<li>Pre-processing</li>
				<li>Feature selection</li>
				<li>Model training</li>
				<li>Model tuning using resampling</li>
				<li>Variable importance estimation</li>
			</ul>
			<p>We will revisit the caret package with examples in <em class="italics">Chapter 4</em>, <em class="italics">Regression</em>, and <em class="italics">Chapter 5</em>, <em class="italics">Classification</em>.</p>
			<h2 id="_idParaDest-68"><a id="_idTextAnchor068"/>Data Visualization</h2>
			<p>An essential part of what we call <strong class="bold">Exploratory Data Analysis</strong> (<strong class="bold">EDA</strong>), more on this in <em class="italics">Chapter 2</em>, <em class="italics">Exploratory Analysis of Data</em>, is the ability to visualize data in a way that communicates insights elegantly and makes storytelling far more comprehensible. Not only does data visualization help us in communicating better insights, but it also helps with spotting anomalies. Before we get there, let's look at some of the most common visualizations that we often use in data analysis. All the examples in this section will be in <strong class="inline">ggplot2</strong>, a powerful package in R. Just like <strong class="inline">dplyr</strong> and <strong class="inline">plyr</strong>, <strong class="inline">ggplot2</strong> is built on the <strong class="bold">Grammar of Graphics</strong>, which is a tool that enables us to describe the components of a graphic concisely.</p>
			<h4>Note</h4>
			<p class="callout">Good grammar will allow us to gain insight into the composition of complicated graphics and reveal unexpected connections between seemingly different graphics.</p>
			<p class="callout">(Cox 1978) [Cox, D. R. (1978), "Some Remarks on the Role in Statistics of Graphical Methods," Applied Statistics, 27 (1), 4–9. [3,26].</p>
			<h3 id="_idParaDest-69"><a id="_idTextAnchor069"/>Scatterplot</h3>
			<p>A scatterplot is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. If the points are color-coded, an additional variable can be displayed.</p>
			<p>It is the most common type of chart and is extremely useful in spotting patterns in the data, especially between two variables. We will use our bank data again to do some EDA. Let's use the Portuguese bank direct campaign dataset for the visualizations:</p>
			<p class="snippet">df_bank_detail &lt;- read.csv("bank-full.csv", sep = ';')</p>
			<p><strong class="inline">ggplot</strong> works in a layered way of stacking different elements of the plot. In the following example of this section, in the first layer, we provide the data to the <strong class="inline">ggplot()</strong> method and then map it with aesthetic details like <em class="italics">x</em> and <em class="italics">y</em>-axis, in the example, the <strong class="inline">age</strong> and <strong class="inline">balance</strong> values, respectively. Finally, to be able to identify some reasoning associated with few high bank balances, we added a color based on the type of job.</p>
			<p>Execute the following command to plot the scatterplot of age and balance:</p>
			<p class="snippet">ggplot(data = df_bank_detail) +</p>
			<p class="snippet">  geom_point(mapping = aes(x = age, y = balance, color = job))</p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/C12624_01_08.jpg" alt="Figure 1.8: Scatterplot of age and balance.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 1.8: Scatterplot of age and balance.</h6>
			<p>From <em class="italics">Figure 1.8</em>, the distribution of bank balance with age looks much normal, with middle age showing a high bank balance whereas youngsters and old people are on the lower side of the spectrum.</p>
			<p>Interestingly, some outlier values seem to be coming from management and retired professionals.</p>
			<p>In data visualization, it's always tempting to see a graph and jump to a conclusion. A data visual is for consuming the data better and not for drawing causal inference. Usually, an interpretation by an analyst is always vetted by a business. Graphs that are aesthetically pleasing often tempt you to put it into presentation deck. So, next time a beautiful chart gets into your presentation deck, carefully analyze what you are going to say.</p>
			<h3 id="_idParaDest-70"><a id="_idTextAnchor070"/>Scatter Plot between Age and Balance split by Marital Status</h3>
			<p>In this section, we will draw three scatter plots in a single plot between age and balance split by marital status (one for each single, divorced, and married individuals).</p>
			<p>Now, you could split the distribution by marital status. The patterns seem to be consistent among the single, married, and divorced individuals. We used a method called <strong class="inline">facet_wrap()</strong> as the third layer in <strong class="inline">ggplot</strong>. It takes a <strong class="inline">marital</strong> variable as a formula:</p>
			<p class="snippet">ggplot(data = df_bank_detail) +</p>
			<p class="snippet">  geom_point(mapping = aes(x = age, y = balance, color = job)) +</p>
			<p class="snippet">  facet_wrap(~ marital, nrow = 1)</p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/C12624_01_09.jpg" alt="Figure 1.9: Scatter plot between age and balance split by marital status&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 1.9: Scatter plot between age and balance split by marital status</h6>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor071"/>Line Charts</h2>
			<p>A line chart or line graph is a type of chart that displays information as a series of data points called <strong class="bold">markers</strong> connected by straight line segments.</p>
			<p><strong class="inline">ggplot</strong> uses an elegant <strong class="inline">geom()</strong> method, which helps in quickly switching between two visual objects. In the previous example, we saw <strong class="inline">geom_point()</strong> for the scatterplot. In line charts, the observations are connected by a line in the order of the variable on the <em class="italics">x</em>-axis. The shaded area surrounding the line represents the <em class="italics">95%</em> confidence interval, that is, there is 95% confidence that the actual regression line lies within the shaded area. We will discuss more on this idea in <em class="italics">Chapter 4</em>, <em class="italics">Regression</em>.</p>
			<p>In the following plot, we show the line chart of age and bank balance for single, married, and divorced individuals. It is not clear whether there is some trend, but one can see the pattern among the three categories:</p>
			<p class="snippet">ggplot(data = df_bank_detail) +</p>
			<p class="snippet">  geom_smooth(mapping = aes(x = age, y = balance, linetype = marital))</p>
			<p class="snippet">## 'geom_smooth()' using method = 'gam'</p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/C12624_01_10.jpg" alt="Figure 1.10: Line graph of age and balance&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 1.10: Line graph of age and balance</h6>
			<h2 id="_idParaDest-72"><a id="_idTextAnchor072"/>Histogram</h2>
			<p>A histogram is a visualization consisting of rectangles whose area is proportional to the frequency of a variable and whose width is equal to the class interval.</p>
			<p>The height of the bar in a histogram represents the number of observations in each group. In the following example, we are counting the number of observations for each type of job and marital status. <strong class="bold">y</strong> is a binary variable checking whether the client subscribed a term deposit or not (<strong class="bold">yes</strong>, <strong class="bold">no</strong>) as a response to the campaign call.</p>
			<p>It looks like blue-collar individuals are responding to the campaign calls the least, and individuals in management jobs are subscribing to the term deposit the most:</p>
			<p class="snippet">ggplot(data = df_bank_detail) +</p>
			<p class="snippet">  geom_bar(mapping = aes(x=job, fill = y)) +</p>
			<p class="snippet">  theme(axis.text.x = element_text(angle=90, vjust=.8, hjust=0.8))</p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/C12624_01_11.jpg" alt="Figure 1.11: Histogram of count and job&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 1.11: Histogram of count and job</h6>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor073"/>Boxplot</h2>
			<p>A boxplot is a standardized way of displaying the distribution of data based on a five number summary (minimum, first quartile (Q1), median, third quartile (Q3), and maximum). Probably, boxplot is the only chart that encapsulates much information in a beautiful looking representation compared to any other charts. Observe the summary of the <strong class="inline">age</strong> variable by each <strong class="inline">job</strong> type. The five summary statistics, that is, min, first quartile, median, mean, third quartile, and max, are described succinctly by a boxplot.</p>
			<p>The 25th and 75th percentiles, in the first and third quartiles, are shown by lower and upper hinges, respectively. The upper whisper, which extends from the hinges to the maximum value, is within an IQR of 1.5 *, from the hinge. This is where the IQR is the inter-quartile range or distance between the two quartiles. This is similar in case of the lower hinge. All the points that are outside the hinges are called <strong class="bold">outliers</strong>:</p>
			<p class="snippet">tapply(df_bank_detail$age, df_bank_detail$job, summary)</p>
			<p>The output is as follows:</p>
			<p class="snippet">## $admin.</p>
			<p class="snippet">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </p>
			<p class="snippet">##   20.00   32.00   38.00   39.29   46.00   75.00 </p>
			<p class="snippet">## </p>
			<p class="snippet">## $'blue-collar'</p>
			<p class="snippet">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </p>
			<p class="snippet">##   20.00   33.00   39.00   40.04   47.00   75.00 </p>
			<p class="snippet">## </p>
			<p class="snippet">## $entrepreneur</p>
			<p class="snippet">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </p>
			<p class="snippet">##   21.00   35.00   41.00   42.19   49.00   84.00 </p>
			<p class="snippet">## </p>
			<p class="snippet">## $housemaid</p>
			<p class="snippet">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </p>
			<p class="snippet">##   22.00   38.00   47.00   46.42   55.00   83.00 </p>
			<p class="snippet">## </p>
			<p class="snippet">## $management</p>
			<p class="snippet">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </p>
			<p class="snippet">##   21.00   33.00   38.00   40.45   48.00   81.00 </p>
			<p class="snippet">## </p>
			<p class="snippet">## $retired</p>
			<p class="snippet">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </p>
			<p class="snippet">##   24.00   56.00   59.00   61.63   67.00   95.00 </p>
			<p class="snippet">## </p>
			<p class="snippet">## $'self-employed'</p>
			<p class="snippet">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </p>
			<p class="snippet">##   22.00   33.00   39.00   40.48   48.00   76.00 </p>
			<p class="snippet">## </p>
			<p class="snippet">0</p>
			<p>In the following boxplot, we are looking at the summary of age with respect to each job type. The size of the box that is set to <strong class="inline">varwidth = TRUE</strong> in <strong class="inline">geom_boxplot</strong> shows the number of observations in the particular job type. The wider the box, the larger the number of observations:</p>
			<p class="snippet">ggplot(data = df_bank_detail, mapping = aes(x=job, y = age, fill = job)) +</p>
			<p class="snippet">  geom_boxplot(varwidth = TRUE) +</p>
			<p class="snippet">  theme(axis.text.x = element_text(angle=90, vjust=.8, hjust=0.8))</p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/C12624_01_12.jpg" alt="Figure 1.12: Boxplot of age and job&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 1.12: Boxplot of age and job</h6>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor074"/>Summary</h2>
			<p>In this chapter, we visited some basics of R programming data types, data structures, and important functions and packages. We described vectors, matrix, list, DataFrame, and data tables as different forms of storing data. In the data processing and transformation space, we explore the <strong class="inline">cbind</strong>, <strong class="inline">rbind</strong>, <strong class="inline">merge</strong>, <strong class="inline">reshape</strong>, <strong class="inline">aggregate</strong>, and <strong class="inline">apply</strong> family of functions.</p>
			<p>We also discussed the most important packages in R such as <strong class="inline">dplyr</strong>, <strong class="inline">tidyr</strong>, and <strong class="inline">plyr</strong>. In the end, the <strong class="inline">ggplot2</strong> data visualization package was used to demonstrate various types of visualization and how to draw insights from them.</p>
			<p>In the next chapter, we will use all that you have learned in this chapter for performing Exploratory Data Analysis (EDA). In EDA, data transformation and visualization you learned here will be useful for drawing inferences from data.</p>
		</div>
	</body></html>