- en: Image Recognition with Deeplearning4j
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Deeplearning4j进行图像识别
- en: Images have become ubiquitous in web services, social networks, and web stores.
    In contrast to humans, computers have great difficulty in understanding what is
    in the image and what it represents. In this chapter, we'll first look at the
    challenges behind teaching computers how to understand images, and then focus
    on an approach based on deep learning. We'll look at a high-level theory thats
    required to configure a deep learning model and discuss how to implement a model
    that is able to classify images using a Java library, Deeplearning4j.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 图像在Web服务、社交网络和在线商店中无处不在。与人类相比，计算机在理解图像及其所代表的内容方面有很大困难。在本章中，我们将首先探讨教会计算机如何理解图像的挑战，然后重点介绍基于深度学习的方法。我们将探讨配置深度学习模型所需的高级理论，并讨论如何使用Java库Deeplearning4j实现一个能够通过分类图像的模型。
- en: 'This chapter will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introducing image recognition
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍图像识别
- en: Discussing deep learning fundamentals
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论深度学习基础
- en: Building an image recognition model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建图像识别模型
- en: Introducing image recognition
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍图像识别
- en: A typical goal of image recognition is to detect and identify an object in a
    digital image. Image recognition is applied in factory automation to monitor product
    quality; surveillance systems to identify potentially risky activities, such as
    moving persons or vehicles; security applications to provide biometric identification
    through fingerprints, iris, or facial features; autonomous vehicles to reconstruct
    conditions on the road and environment; and so on.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图像识别的一个典型目标是检测和识别数字图像中的对象。图像识别应用于工厂自动化以监控产品质量；监控系统以识别潜在风险活动，如移动的人或车辆；安全应用通过指纹、虹膜或面部特征提供生物识别；自动驾驶汽车以重建道路和环境条件；等等。
- en: 'Digital images are not presented in a structured way with attribute-based descriptions;
    instead, they are encoded as the amount of color in different channels, for instance,
    black-white and red-green-blue channels. The learning goal is to identify patterns
    that are associated with a particular object. The traditional approach for image
    recognition consists of transforming an image into different forms, for instance,
    to identify object corners, edges, same-color blobs, and basic shapes. Such patterns
    are then used to train a learner to distinguish between objects. Some notable
    examples of traditional algorithms are listed here:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数字图像不是以基于属性的描述方式呈现的；相反，它们被编码为不同通道中的颜色量，例如，黑白和红绿蓝通道。学习目标是识别与特定对象相关的模式。图像识别的传统方法包括将图像转换为不同的形式，例如，识别物体角落、边缘、同色块和基本形状。然后使用这些模式来训练一个学习者区分对象。以下是一些传统算法的显著例子：
- en: Edge detection finds boundaries of objects within an image
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边缘检测找到图像中对象的边界
- en: Corner detection identifies intersections of two edges or other interesting
    points, such as line endings, curvature maxima or minima, and so on
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 角点检测识别两条边缘或其他有趣点（如线端、曲率极大值或极小值等）的交点
- en: Blob detection identifies regions that differ in a property, such as brightness
    or color, compared to its surrounding regions
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 块检测识别与周围区域在属性（如亮度或颜色）上不同的区域
- en: Ridge detection identifies additional interesting points in the image using
    smooth functions
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 岭谷检测使用平滑函数在图像中识别额外的有趣点
- en: '**Scale invariant feature transform** (**SIFT**) is a robust algorithm that
    can match objects, even if their scale or orientation differs from the representative
    samples in the database'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尺度不变特征变换**（**SIFT**）是一种鲁棒的算法，即使对象的尺度或方向与数据库中的代表性样本不同，也能匹配对象'
- en: Hough transform identifies particular patterns in the image
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hough变换识别图像中的特定模式
- en: A more recent approach is based on deep learning. Deep learning is a form of
    neural network, which mimics how the brain processes information. The main advantage
    of deep learning is that it's possible to design neural networks that can automatically
    extract relevant patterns, which in turn can be used to train a learner. With
    recent advances in neural networks, image recognition accuracy has significantly
    boosted. For instance, the **ImageNet** challenge, where competitors are provided
    more than 1.2 million images from 1,000 different object categories, reports that
    the error rate of the best algorithm was reduced from 28% in 2010, using **support
    vector machines** (**SVM**), to only 7% in 2014, using a deep neural network.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更近期的方法是基于深度学习。深度学习是一种神经网络形式，它模仿大脑处理信息的方式。深度学习的主要优势在于可以设计出能够自动提取相关模式的神经网络，这些模式反过来又可以用来训练学习器。随着神经网络技术的最新进展，图像识别的准确性得到了显著提升。例如，**ImageNet**
    挑战赛，其中参赛者获得了来自1,000个不同物体类别的超过1,200万张图片，报告称，最佳算法的错误率从2010年的28%（使用**支持向量机**（**SVM**））降低到了2014年的仅7%（使用深度神经网络）。
- en: In this chapter, we'll take a quick look at neural networks, starting from the
    basic building block, the perceptron,and gradually introducing more complex structures.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将快速浏览神经网络，从基本构建块感知器开始，逐渐引入更复杂的结构。
- en: Neural networks
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络
- en: The first neural networks, which were introduced in the sixties, were inspired
    by biological neural networks. The idea of a neural network is to map the biological
    nervous system, that is, how the brain processes information. It consists of layers
    with interconnected neurons working together. In computer terms, they are also
    known as an **artificial neural network** (**ANN**). With computers, it requires
    training to make this model learn, the same as a human brain. A neuron in the
    brain gets activated on receiving a signal from nearby interconnected neurons,
    and the same applies to an ANN. Recent advances in neural networks has proved
    that deep neural networks fit very well in pattern recognition tasks, as they
    are able to automatically extract interesting features and learn the underlying
    presentation. In this section, we'll refresh ourselves on the fundamental structures
    and components, from a single perceptron to deep networks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最早期的神经网络，在六十年代被引入，其灵感来源于生物神经网络。神经网络的想法是映射生物神经系统，即大脑如何处理信息。它由相互连接的神经元层组成，共同工作。在计算机术语中，它们也被称为**人工神经网络**（**ANN**）。使用计算机，需要训练来使这个模型学习，就像人类大脑一样。大脑中的神经元在接收到来自附近相互连接的神经元的信号时会被激活，对人工神经网络也是如此。神经网络技术的最新进展已经证明，深度神经网络非常适合模式识别任务，因为它们能够自动提取有趣的特征并学习其背后的表示。在本节中，我们将回顾从单个感知器到深度网络的基本结构和组件。
- en: Perceptron
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感知器
- en: 'A perceptron is a basic neural network building block and one of the earliest
    supervised algorithms. It is defined as a sum of features, which is multiplied
    by the corresponding weights and a bias. When the input signals is received, it
    multiplies with the assigned weights. These weights are defined for each incoming
    signal or input, and the weight gets adjusted continuously during the learning
    phase. The adjustment of weight depends on the error of the last result. After
    multiplying with the respective weights, all of the inputs are summed up with
    some offset value called **bias**. The value of the bias is also adjusted by the
    weights. So, it starts with random weights and bias, and with each iteration,
    the weights and bias are adjusted so that the next result moves toward the desired
    output. At the end, the final result is turned into an output signal. The function
    that sums all of this together is called the **sum transfer function,** and it
    is fed into an activation function. If the binary step activation function reaches
    a threshold, the output is 1, otherwise it is 0, which gives us a binary classifier.
    A schematic illustration is shown in the following diagram:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器是基本神经网络构建块之一，也是最早的监督算法之一。它被定义为特征的总和，这些特征乘以相应的权重和一个偏差。当接收到输入信号时，它将这些信号与分配的权重相乘。这些权重为每个传入的信号或输入定义，并在学习阶段持续调整。权重的调整取决于最后结果的误差。将所有输入与一些称为**偏差**的偏移值相乘后，所有输入都加在一起。偏差的值也由权重调整。因此，它从随机的权重和偏差开始，并在每次迭代中调整权重和偏差，以便下一个结果向期望的输出移动。最后，最终结果被转换成输出信号。将所有这些加在一起的功能称为**求和传递函数**，并将其输入到激活函数中。如果二元步激活函数达到阈值，则输出为1，否则为0，这为我们提供了一个二元分类器。以下图显示了示意图：
- en: '![](img/9d234876-bb61-48f0-98b4-33d0da465223.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9d234876-bb61-48f0-98b4-33d0da465223.png)'
- en: Training perceptrons involves a fairly simple learning algorithm that calculates
    the errors between the calculated output values and correct training output values,
    and uses this to create an adjustment to the weights, thus implementing a form
    of gradient descent. This algorithm is usually called the **delta rule**.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 训练感知器涉及一个相当简单的学习算法，该算法计算计算输出值与正确训练输出值之间的误差，并使用此误差来创建对权重的调整，从而实现一种梯度下降的形式。此算法通常称为**delta规则**。
- en: A single-layer perceptron is not very advanced, and nonlinearly separable functions,
    such as XOR, cannot be modeled using it. To address this issue, a structure with
    multiple perceptrons was introduced, called the **multilayer perceptron**, also
    known as the **feedforward neural network**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 单层感知器并不非常先进，无法使用它来模拟非线性可分函数，如XOR。为了解决这个问题，引入了一种具有多个感知器的结构，称为**多层感知器**，也称为**前馈神经网络**。
- en: Feedforward neural networks
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前馈神经网络
- en: 'A feedforward neural network is an ANN that consists of several perceptrons,
    which are organized into layers, as shown in the following diagram: input layer,
    output layer, and one or more hidden layers. The hidden layers have nothing to
    do with the outside world, hence the name. Each layer perceptron, also known as
    a neuron, has direct connections to the perceptrons in the next layer, whereas
    connections between two neurons carry a weight thats similar to the perceptron
    weights. So, all the perceptrons in one layer are connected with the perceptrons
    in the next layer, and the information is fed forward to the next layer. This
    diagram shows a network with a four-unit **Input layer**, corresponding to the
    size of the  feature vector of length `4`, a four-unit **Hidden layer**, and a
    two-unit **Output layer**, where each unit corresponds to one class value:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 前馈神经网络是一种由多个感知器组成的ANN，这些感知器被组织成层，如下面的图所示：输入层、输出层和一层或多层隐藏层。隐藏层与外界没有任何联系，因此得名。每个层感知器，也称为神经元，与下一层的感知器有直接连接，而两个神经元之间的连接则携带一个与感知器权重相似的权重。因此，同一层的所有感知器都与下一层的感知器相连，信息被正向传递到下一层。此图显示了一个具有四个单元的**输入层**的网络，对应于长度为`4`的特征向量大小，一个四个单元的**隐藏层**和一个两个单元的**输出层**，其中每个单元对应一个类别值：
- en: '![](img/6ab8b4ab-f8aa-4184-8620-bd78071abb2c.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6ab8b4ab-f8aa-4184-8620-bd78071abb2c.png)'
- en: A feedforward neural network learns by finding the relationship between input
    and output values, which are fed into the network multiple times. The most popular
    approach to training multilayer networks is backpropagation. In backpropagation,
    the calculated output values are compared with the correct values in the same
    way as in the delta rule. The error is then fed back through the network by various
    techniques, adjusting the weights of each connection in order to reduce the value
    of the error. The error is calculated using the squared difference between the
    output value of the network and the original output value. The error indicates
    how far we are from the original output values. This process is repeated for a
    sufficiently large number of training cycles, until the error is under a certain
    threshold.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 前馈神经网络通过寻找输入和输出值之间的关系来学习，这些值被多次输入到网络中。训练多层网络最流行的方法是反向传播。在反向传播中，计算出的输出值与相同方式下的正确值进行比较，就像在delta规则中一样。然后，通过各种技术将错误反馈到网络中，调整每个连接的权重，以减少错误的值。错误是通过网络输出值与原始输出值之间的平方差来计算的。错误表示我们离原始输出值的距离。这个过程在足够多的训练周期中重复进行，直到错误低于某个阈值。
- en: 'A feedforward neural network can have more than one hidden layer, where each
    additional hidden layer builds a new abstraction atop the preceding layers. This
    often leads to more accurate models; however, increasing the number of hidden
    layers leads to two known issues:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 前馈神经网络可以有多于一个的隐藏层，其中每个额外的隐藏层在先前的层之上构建一个新的抽象。这通常会导致更精确的模型；然而，增加隐藏层的数量会导致两个已知问题：
- en: '**Vanishing gradients problem**: With more hidden layers, the training with
    backpropagation becomes less and less useful for passing information to the front
    layers, causing these layers to train very slowly'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度消失问题**：随着隐藏层的增加，使用反向传播的训练越来越不适用于将信息传递到前层，导致这些层训练速度非常慢'
- en: '**Overfitting**: The model fits the training data too well and performs poorly
    on real examples'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合**：模型对训练数据拟合得太好，在真实示例上的表现不佳'
- en: Let's look at some other networks structures that address these issues.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些其他网络结构，它们解决了这些问题。
- en: Autoencoder
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动编码器
- en: '**An autoencoder** is a feedforward neural network that aims to learn how to
    compress the original dataset. Its aim is to copy input to its output. Therefore,
    instead of mapping features to the input layer and labels to the output layer,
    we will map the features to both the input and output layers. The number of units
    in the hidden layers is usually different from the number of units in the input
    layers, which forces the network to either expand or reduce the number of original
    features. This way, the network will learn the important features, while effectively
    applying dimensionality reduction.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**自动编码器**是一种前馈神经网络，旨在学习如何压缩原始数据集。其目标是复制输入到输出。因此，我们不会将特征映射到输入层，将标签映射到输出层，而是将特征映射到输入和输出层。隐藏层中的单元数量通常不同于输入层中的单元数量，这迫使网络增加或减少原始特征的数量。这样，网络将学习重要的特征，同时有效地应用降维。'
- en: 'An example network is shown in the following diagram. The three-unit input
    layer is first expanded into a four-unit layer and then compressed into a single-unit
    layer. The other side of the network restores the single layer unit back in to
    the four-unit layer, and then to the original three-input layer:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图中展示了网络的一个示例。三个单元的输入层首先扩展为四个单元的层，然后压缩为单个单元的层。网络的另一侧将单个层单元恢复到四个单元层，然后回到原始的三个输入层：
- en: '![](img/f229c5d1-e298-4e0f-b8e0-eaf36699f2be.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f229c5d1-e298-4e0f-b8e0-eaf36699f2be.png)'
- en: Once the network is trained, we can take the left-hand side to extract the image
    features like we would with traditional image processing. It consists of encoders
    and decoders, where the encoder's work is to create or make hidden a layer or
    layers that captures the essence of the input, and the decoders reconstruct the input
    from the layers.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦网络被训练，我们可以从左侧提取图像特征，就像使用传统的图像处理一样。它由编码器和解码器组成，其中编码器的工作是创建或隐藏一个或多个层，以捕捉输入的本质，而解码器则从这些层中重建输入。
- en: 'The autoencoders can be also combined into **stacked autoencoders**, as shown
    in the following diagram. First, we will discuss the hidden layer in a basic autoencoder,
    as described previously. Then, we will take the learned hidden layer (green circles)
    and repeat the procedure, which in effect learns a more abstract presentation.
    We can repeat this procedure multiple times, transforming the original features
    into increasingly reduced dimensions. At the end, we will take all of the hidden
    layers and stack them into a regular feedforward network, as shown at the top-right
    part of the diagram:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e053137e-b22e-4ff8-ad2c-65eea70d5c4a.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
- en: Restricted Boltzmann machine
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**A restricted Boltzman machine** (**RBM**) is an undirected neural network,
    also denoted as **generative stochastic networks** (**GSNs**), and can learn probability
    distribution over its set of inputs. As the name suggests, they originate from
    the Boltzman machine, a recurrent neural network that was introduced in the eighties.
    In a Boltzmann machine, every node or neuron is connected with all other nodes,
    which makes it difficult to process when the node count increases. Restricted
    means that the neurons must form two fully connected layers, an input layer and
    a hidden layer, as shown in the following diagram:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4595eeb9-cbda-4f68-b845-a9f3b9bf91d6.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
- en: Unlike feedforward networks, the connections between the visible and hidden
    layers are undirected, hence the values can be propagated in both visible-to-hidden
    and hidden-to-visible directions.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Training RBMs is based on the contrastive divergence algorithm, which uses a
    gradient descent procedure, similar to backpropagation, to update weights, and
    Gibbs sampling is applied on the Markov chain to estimate the gradient, that is
    the direction on how to change the weights.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'RBMs can also be stacked to create a class known as **deep belief networks**
    (**DBNs**). In this case, the hidden layer of an RBM acts as a visible layer for
    the RBM layer, as shown in the following diagram:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3710f522-4873-439c-a0b0-89625751661a.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: 'The training, in this case, is incremental: training layer by layer.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Deep convolutional networks
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A network structure that recently achieved very good results at image recognition
    benchmarks is the **convolutional neural network** (**CNN**) or ConvNet. CNNs
    are a type of feedforward neural network that are structured in such a way that
    it emulates the behavior of the visual cortex, exploiting 2D structures of an
    input image, that is, patterns that exhibit spatially local correlation. It works
    on the basic principles of how the brain recalls or remembers images. We, as humans,
    remember images on the basis of features only. Given the features, our brain will
    start forming the image itself. In computers, consider the following diagram,
    which shows how a feature is detected:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28592e50-146d-45af-9de0-426d399d967f.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: 'In the same way, many features are detected from the image, as shown in the
    following diagram:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，可以从图像中检测到许多特征，如下图所示：
- en: '![](img/26759343-9494-4e76-a340-39649c60028c.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/26759343-9494-4e76-a340-39649c60028c.png)'
- en: A CNN consists of a number of convolutional and subsampling layers, optionally
    followed by fully connected layers. An example of this shown in the following
    diagram. The input layer reads all of the pixels in an image and then we apply
    multiple filters. In the following diagram, four different filters are applied.
    Each filter is applied to the original image; for example, one pixel of a 6 x
    6 filter is calculated as the weighted sum of a 6 x 6 square of input pixels and
    corresponding 6 x 6 weights. This effectively introduces filters that are similar
    to standard image processing, such as smoothing, correlation, edge detection,
    and so on. The resulting image is called a **feature map**. In the example in
    the following diagram, we have four feature maps, one for each filter.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: CNN由多个卷积和子采样层组成，可选地后面跟着全连接层。以下图示展示了这一示例。输入层读取图像中的所有像素，然后我们应用多个滤波器。在以下图中，应用了四个不同的滤波器。每个滤波器都应用于原始图像；例如，一个6
    x 6滤波器的一个像素是通过计算6 x 6输入像素的加权总和以及相应的6 x 6权重来计算的。这有效地引入了类似于标准图像处理的滤波器，如平滑、相关性、边缘检测等。生成的图像称为**特征图**。在以下图的示例中，我们有四个特征图，每个滤波器一个。
- en: 'The next layer is the subsampling layer, which reduces the size of the input.
    Each feature map is subsampled typically with mean or max pooling over a contiguous
    region of 2 x 2 (up to 5 x 5 for large images). For example, if the feature map
    size is 16 x 16 and the subsampling region is 2 x 2, the reduced feature map size
    is 8 x 8, where 4 pixels (a 2 x 2 square) are combined into a single pixel by
    calculating the max, min, mean, or some other functions:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个层是子采样层，它减小了输入的大小。每个特征图通常通过在连续区域（对于大图像可达2 x 2到5 x 5）上的平均或最大池化进行子采样。例如，如果特征图大小为16
    x 16，子采样区域为2 x 2，则减小后的特征图大小为8 x 8，其中4个像素（一个2 x 2的正方形）通过计算最大值、最小值、平均值或其他函数合并成一个单独的像素：
- en: '![](img/eb58d84f-21ad-423b-b211-fd1e634e2a48.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb58d84f-21ad-423b-b211-fd1e634e2a48.png)'
- en: The network may contain several consecutive convolution and subsampling layers,
    as shown in the preceding diagram. A particular feature map is connected to the
    next reduced/convoluted feature map, while feature maps at the same layer are
    not connected to each other.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 网络可能包含几个连续的卷积和子采样层，如前图所示。特定的特征图连接到下一个减小/卷积的特征图，而同一层的特征图之间不相互连接。
- en: After the last subsampling or convolutional layer, there is usually a fully
    connected layer, identical to the layers in a standard multilayer neural network,
    which represents the target data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个子采样或卷积层之后，通常有一个全连接层，与标准多层神经网络中的层相同，它表示目标数据。
- en: A CNN is trained using a modified backpropagation algorithm that takes the subsampling
    layers into account and updates the convolutional filter weights based on all
    the values where this filter is applied.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的训练使用了一种修改后的反向传播算法，该算法考虑了子采样层，并根据该滤波器应用的所有值更新卷积滤波器权重。
- en: 'Some good CNN designs can be found at the ImageNet competition results page:
    [http://www.image-net.org/](http://www.image-net.org/). An example is *AlexNet*,
    which is described in the *ImageNet Classification with Deep Covolutional Neural
    Networks* paper by *A. Krizhevsky et al*.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一些好的CNN设计可以在ImageNet竞赛结果页面上找到：[http://www.image-net.org/](http://www.image-net.org/)。一个例子是*A.
    Krizhevsky等人*在*ImageNet分类与深度卷积神经网络*论文中描述的*A. Krizhevsky*。
- en: This concludes our review of the main neural network structures. In the following
    section, we'll move on to the actual implementation.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对主要神经网络结构的回顾。在下一节中，我们将继续实际实现。
- en: Image classification
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分类
- en: In this section, we will discuss how to implement some of the neural network
    structures with the Deeplearning4j library. Let's get started.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何使用Deeplearning4j库实现一些神经网络结构。让我们开始吧。
- en: Deeplearning4j
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Deeplearning4j
- en: As we discussed in [Chapter 2](6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml),
    *Java Libraries and Platforms for Machine Learning*, Deeplearning4j is an open
    source, distributed deep learning project in Java and Scala. Deeplearning4j relies
    on Spark and Hadoop for MapReduce, trains models in parallel, and iteratively
    averages the parameters they produce in a central model. A detailed library summary
    is presented in [Chapter 2](6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml), *Java
    Libraries and Platforms for Machine Learning*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[第2章](6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml)“Java机器学习库和平台”中讨论的那样，Deeplearning4j是一个开源的、基于Java和Scala的分布式深度学习项目。Deeplearning4j依赖于Spark和Hadoop进行MapReduce，并行训练模型，并在中心模型中迭代平均它们产生的参数。详细的库总结在[第2章](6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml)“Java机器学习库和平台”中给出。
- en: Getting DL4J
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取DL4J
- en: 'The most convenient way to get Deeplearning4j is through the Maven repository:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 获取Deeplearning4j最方便的方式是通过Maven仓库：
- en: 'Start a new Eclipse project and pick Maven Project, as shown in the following
    screenshot:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动一个新的Eclipse项目，选择Maven项目，如下面的截图所示：
- en: '![](img/8aed3b3c-3950-4926-b37c-4bbfc82bc7df.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8aed3b3c-3950-4926-b37c-4bbfc82bc7df.png)'
- en: 'Open the `pom.xml` file and add the following dependencies under the `<dependencies>`
    section:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`pom.xml`文件，并在`<dependencies>`部分添加以下依赖项：
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Finally, right-click on Project, select Maven, and pick Update project.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，右键单击项目，选择Maven，然后选择更新项目。
- en: MNIST dataset
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MNIST数据集
- en: 'One of the most famous datasets is the MNIST dataset, which consists of handwritten
    digits, as shown in the following image. The dataset consists of 60,000 training
    and 10,000 test images:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的数据库集之一是MNIST数据集，它由手写数字组成，如下面的图像所示。该数据集包括60,000个训练图像和10,000个测试图像：
- en: '![](img/d3340f60-5ca7-425a-bb00-97edef834272.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d3340f60-5ca7-425a-bb00-97edef834272.png)'
- en: The dataset is commonly used in image recognition problems to benchmark algorithms.
    The worst recorded error rate is 12%, with no preprocessing and using an SVM in
    a one-layer neural network. Currently, as of 2016, the lowest error rate is only
    0.21%, using the **DropConnect** neural network, followed by a deep convolutional
    network at 0.23%, and a deep feedforward network at 0.35%.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集通常用于图像识别问题中的算法基准测试。记录的最坏错误率是12%，没有预处理，在一个层神经网络中使用SVM。目前，截至2016年，最低错误率仅为0.21%，使用**DropConnect**神经网络，其次是深度卷积网络，错误率为0.23%，以及深度前馈网络，错误率为0.35%。
- en: Now, let's look at how to load the dataset.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何加载数据集。
- en: Loading the data
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'Deeplearning4j provides the MNIST dataset loader out of the box. The loader
    is initialized as `DataSetIterator`. First let''s import the `DataSetIterator`
    class and all of the supported datasets that are part of the `impl` package, for
    example, iris, MNIST, and others:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Deeplearning4j自带MNIST数据集加载器。加载器初始化为`DataSetIterator`。首先，让我们导入`DataSetIterator`类以及`impl`包中所有支持的数据库集，例如iris、MNIST等：
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we''ll define some constants, for instance, the images consist of 28
    x 28 pixels and there are 10 target classes and 60,000 samples. We''ll initialize
    a new `MnistDataSetIterator` class that will download the dataset and its labels.
    The parameters are the iteration batch size, total number of examples, and whether
    the datasets should be binarized or not:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一些常量，例如图像由28 x 28像素组成，有10个目标类别和60,000个样本。我们将初始化一个新的`MnistDataSetIterator`类，该类将下载数据集及其标签。参数是迭代批处理大小、示例总数以及数据集是否应该二值化：
- en: '[PRE2]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Having an already-implemented data importer is really convenient, but it won't
    work on your data. Let's take a quick look at how it is implemented and what needs
    to be modified to support your dataset. If you're eager to start implementing
    neural networks, you can safely skip the rest of this section and return to it
    when you need to import your own data.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个已经实现的数据导入器非常方便，但它不会在你的数据上工作。让我们快速看一下它的实现方式以及需要修改什么以支持你的数据集。如果你急于开始实现神经网络，你可以安全地跳过本节的其余部分，并在需要导入自己的数据时返回。
- en: To load the custom data, you'll need to implement two classes: `DataSetIterator`,
    which holds all of the information about the dataset, and `BaseDataFetcher`, which
    actually pulls the data either from a file, database, or the web. Sample implementations
    are available on GitHub at [https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j-core/src/main/java/org/deeplearning4j/datasets/iterator/impl](https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j-core/src/main/java/org/deeplearning4j/datasets/iterator/impl).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载自定义数据，你需要实现两个类：`DataSetIterator`，它包含有关数据集的所有信息，以及`BaseDataFetcher`，它实际上从文件、数据库或网络中提取数据。示例实现可在GitHub上找到，地址为[https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j-core/src/main/java/org/deeplearning4j/datasets/iterator/impl](https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j-core/src/main/java/org/deeplearning4j/datasets/iterator/impl)。
- en: Another option is to use the **Canova** library, which was developed by the
    same authors, at [http://deeplearning4j.org/canovadoc/](http://deeplearning4j.org/canovadoc/).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项是使用由同一作者开发的**Canova**库，该库的文档位于[http://deeplearning4j.org/canovadoc/](http://deeplearning4j.org/canovadoc/)。
- en: Building models
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建模型
- en: In this section, we'll discuss how to build an actual neural network model.
    We'll start with a basic single-layer neural network to establish a benchmark
    and discuss the basic operations. Later, we'll improve this initial result with
    DBN and a multilayer convolutional network.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何构建实际的神经网络模型。我们将从一个基本的单层神经网络开始，以建立基准并讨论基本操作。稍后，我们将使用DBN和多层卷积网络来改进这个初始结果。
- en: Building a single-layer regression model
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建单层回归模型
- en: 'Let''s start by building a single-layer regression model based on the softmax
    activation function, as shown in the following diagram. As we have a single layer,
    **Input** to the neural network will be all the figure pixels, that is, 28 x 28
    = **748** neurons. The number of **Output** neurons is **10**, one for each digit.
    The network layers are fully connected, as shown in the following diagram:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从基于softmax激活函数的单层回归模型开始构建，如下面的图所示。由于我们只有一个层，神经网络的**输入**将是所有图像像素，即28 x 28
    = **748**个神经元。**输出**神经元的数量是**10**，每个数字一个。网络层是完全连接的，如下面的图所示：
- en: '![](img/7a5ce7ad-1fe2-46db-95f4-8e456cefd72d.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7a5ce7ad-1fe2-46db-95f4-8e456cefd72d.png)'
- en: 'A neural network is defined through a `NeuralNetConfiguration.Builder()` object
    as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络通过`NeuralNetConfiguration.Builder()`对象定义，如下所示：
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We will define the parameters for gradient search in order to perform iterations
    with the conjugate gradient optimization algorithm. The `momentum` parameter determines
    how fast the optimization algorithm converges to an local optimum. The higher
    the `momentum`, the faster the training; but higher speed can lower the model''s
    accuracy:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义梯度搜索的参数，以便使用共轭梯度优化算法进行迭代。`momentum`参数决定了优化算法收敛到局部最优的速度。`momentum`值越高，训练速度越快；但过高的速度可能会降低模型的准确性：
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Next, we will specify that the network has one layer and also define the error
    function, `NEGATIVELOGLIKELIHOOD`, internal perceptron activation function, `softmax`,
    and the number of input and output layers that correspond to the total
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将指定网络有一层，并定义错误函数`NEGATIVELOGLIKELIHOOD`，内部感知器激活函数`softmax`以及与总输入和输出层相对应的数量。
- en: 'image pixels and the number of target variables, as shown in the following
    code block:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图像像素和目标变量的数量，如下面的代码块所示：
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, we will set the network to `pretrain`, disable backpropagation, and
    actually build the untrained network structure:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将网络设置为`pretrain`，禁用反向传播，并实际构建未训练的网络结构：
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once the network structure is defined, we can use it to initialize a new `MultiLayerNetwork`,
    as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了网络结构，我们就可以使用它来初始化一个新的`MultiLayerNetwork`，如下所示：
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we will point the model to the training data by calling the `setListeners`
    method, as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过调用`setListeners`方法将模型指向训练数据，如下所示：
- en: '[PRE8]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will also call the `fit(int)` method to trigger end-to-end network training:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将调用`fit(int)`方法来触发端到端网络训练：
- en: '[PRE9]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To evaluate the model, we will initialize a new `Evaluation` object that will
    store batch results:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估模型，我们将初始化一个新的`Evaluation`对象，该对象将存储批处理结果：
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can then iterate over the dataset in batches in order to keep the memory
    consumption at a reasonable rate and store the results in an `eval` object:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以按批处理迭代数据集，以保持合理的内存消耗并存储在`eval`对象中的结果：
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, we can get the results by calling the `stats()` function:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以通过调用`stats()`函数来获取结果：
- en: '[PRE12]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'A basic one-layer model achieves the following accuracy:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Getting 89.22% accuracy, that is, a 10.88% error rate, on the MNIST dataset
    is quite bad. We'll improve this by going from a simple one-layer network to the
    moderately sophisticated deep belief network using Restricted Boltzmann machines
    and a Multilayer Convolutional Network.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Building a deep belief network
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll build a deep belief network (DBN) based on the RBM,
    as shown in the following diagram. The network consists of four layers. The first
    layer recedes the **748** inputs to **500** neurons, then to **250**, followed
    by **200**, and finally to the last **10** target values:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7859d3a0-9129-4f63-9274-6e95a9819d6a.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: 'As the code is the same as in the previous example, let''s take a look at how
    to configure such a network:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We will define the gradient optimization algorithm, as shown in the following
    code:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We will also specify that our network will have four layers:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The input to the first layer will be `748` neurons and the output will be `500`
    neurons. We''ll use the root mean squared error cross entropy, and the Xavier
    algorithm to initialize weights by automatically determining the scale of initialization
    based on the number of input and output neurons, as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The next two layers will have the same parameters, except for the number of
    input and output neurons:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, the last layer will map the neurons to outputs, where we''ll use the `softmax`
    activation function, as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The rest of the training and evaluation is the same as in the single-layer network
    example. Note that training a deep network might take significantly more time
    compared to a single-layer network. The accuracy should be around 93%.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at another deep network.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Building a multilayer convolutional network
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this final example, we''ll discuss how to build a convolutional network,
    as shown in the following diagram. The network will consist of seven layers. First,
    we''ll repeat two pairs of convolutional and subsampling layers with max pooling.
    The last subsampling layer is then connected to a densely connected feedforward
    neuronal network, consisting of 120 neurons, 84 neurons, and 10 neurons in the
    last three layers, respectively. Such a network effectively forms the complete
    image recognition pipeline, where the first four layers correspond to feature
    extraction and the last three layers correspond to the learning model:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/56a26eae-f5f1-4d22-b174-2c2c43484a8a.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: 'Network configuration is initialized as we did earlier:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We will specify the gradient descent algorithm and its parameters, as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We will also specify the seven network layers, as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The input to the first convolutional layer is the complete image, while the
    output is six feature maps. The convolutional layer will apply a 5 x 5 filter,
    and the result will be stored in a 1 x 1 cell:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The second layer is a subsampling layer that will take a 2 x 2 region and store
    the max result in a 2 x 2 element:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The next two layers will repeat the previous two layers:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两层将重复前两层：
- en: '[PRE25]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, we will wire the output of the subsampling layer into a dense feedforward
    network, consisting of `120` neurons, and then through another layer, into `84` neurons,
    as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将子采样层的输出连接到一个由`120`个神经元组成的密集前馈网络，然后通过另一个层连接到`84`个神经元，如下所示：
- en: '[PRE26]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The final layer connects `84` neurons with `10` output neurons:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一层将`84`个神经元与`10`个输出神经元连接：
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: To train this structure, we can reuse the code that we developed in the previous
    two examples. Again, the training might take some time. The network accuracy should
    be around 98%.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练这个结构，我们可以重用我们在前两个示例中开发的代码。再次强调，训练可能需要一些时间。网络的准确率应该在大约98%左右。
- en: Since model training significantly relies on linear algebra, training can be
    significantly sped up by using a **graphics processing unit** (**GPU**) for an
    order of magnitude. As the GPU backend, at the time of writing this book, is undergoing
    a rewrite, please check the latest documentation at [http://deeplearning4j.org/documentation](http://deeplearning4j.org/documentation).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型训练在很大程度上依赖于线性代数，因此可以通过使用**图形处理单元**（**GPU**）来显著加快训练速度。由于撰写本书时，GPU后端正在进行重写，请查阅最新的文档[http://deeplearning4j.org/documentation](http://deeplearning4j.org/documentation)。
- en: As we saw in different examples, increasingly complex neural networks allow
    us to extract relevant features automatically, thus completely avoiding traditional
    image processing. However, the price we pay for this is an increased processing
    time and a lot of learning examples to make this approach efficient.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在不同示例中看到的那样，越来越复杂的神经网络使我们能够自动提取相关特征，从而完全避免传统的图像处理。然而，我们为此付出的代价是处理时间的增加以及大量的学习示例来使这种方法有效。
- en: Summary
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed how to recognize patterns in images in order to
    distinguish between different classes by covering fundamental principles of deep
    learning and discussing how to implement them with the Deeplearning4j library.
    We started by refreshing the basic neural network structure and discussed how
    to implement them to solve handwritten digit recognition problems.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何通过覆盖深度学习的基本原理并讨论如何使用Deeplearning4j库来实现它们，来识别图像中的模式以区分不同的类别。我们首先刷新了基本神经网络结构，并讨论了如何实现它们来解决手写数字识别问题。
- en: In the next chapter, we'll look into patterns further; however, instead of patterns
    in images, we'll tackle patterns with temporal dependencies, which can be found
    in sensor data.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将进一步探讨模式；然而，我们将处理具有时间依赖性的模式，这些模式可以在传感器数据中找到。
