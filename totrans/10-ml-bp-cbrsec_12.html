<html><head></head><body>
		<div id="_idContainer110">
			<h1 id="_idParaDest-179" class="chapter-number"><a id="_idTextAnchor023"/>11</h1>
			<h1 id="_idParaDest-180">Protecting User Privacy with Federated Machine Learning</h1>
			<p>In recent times, the issue of user privacy has gained traction in the information technology world. Privacy means that the user is in complete control of their data – they can choose how the data is collected, stored, and used. Often, this also implies that data cannot be shared with other entities. Apart from this, there may be other reasons why companies may not want to share data, such as confidentiality, lack of trust, and protecting intellectual property. This can be a huge impediment to <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) models; large models, particularly deep neural networks, cannot train properly without <span class="No-Break">adequate data.</span></p>
			<p>In this chapter, we will learn<a id="_idIndexMarker802"/> about a privacy-preserving technique for ML known as <strong class="bold">federated machine learning</strong> (<strong class="bold">FML</strong>). Many kinds of fraud data are sensitive; they have user-specific information and also reveal weaknesses in the company’s detection measures. Therefore, companies may not want to share them with one another. FML makes it possible to learn from data without having access to the data by sharing just the learned <span class="No-Break">model itself.</span></p>
			<p>In this chapter, we will cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>An introduction to federated <span class="No-Break">machine learning</span></li>
				<li>Implementing <span class="No-Break">federated averaging</span></li>
				<li>Reviewing the privacy-utility trade-off in <strong class="bold">federated </strong><span class="No-Break"><strong class="bold">learning</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">FL</strong></span><span class="No-Break">)</span></li>
			</ul>
			<p>By the end of this chapter, you will have a detailed understanding of federated machine learning, and be able to implement any task (security or non-security related) as a federated <span class="No-Break">learning task.</span></p>
			<h1 id="_idParaDest-181">Technical requirements</h1>
			<p>You can find the code files for this chapter on GitHub <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%2010"><span class="No-Break">https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%201</span></a><span class="No-Break">1</span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-182">An introduction to federated machine learning</h1>
			<p>Let us first look at what federated<a id="_idIndexMarker803"/> learning is and why it is a valuable tool. We will first look at privacy challenges that are faced while applying machine learning, followed by how and why we apply <span class="No-Break">federated learning.</span></p>
			<h2 id="_idParaDest-183">Privacy challenges in machine learning</h2>
			<p>Traditional ML involves a series<a id="_idIndexMarker804"/> of steps that we have discussed multiple times so far: data preprocessing, feature extraction, model training, and tuning the model for best performance. However, this involves the data being exposed to the model and, therefore, is based on the premise of the availability of data. The more data we have available, the more accurate the model <span class="No-Break">will be.</span></p>
			<p>However, there is often a scarcity of data in the real world. Labels are hard to come by, and there is no centrally aggregated data source. Rather, data is collected and processed by multiple entities who may not want to <span class="No-Break">share it.</span></p>
			<p>This is true more often than not in the security space. Because the data involved is sensitive and the stakes are high, entities who collect the data may not want to share it with others or post <span class="No-Break">it publicly.</span></p>
			<p>The following are examples <span class="No-Break">of this:</span></p>
			<ul>
				<li>Consider a credit card company. The company has labeled data on transactions that were reported to be fraud. However, it may not want to share the data, as exposing the data may unintentionally expose implementation details or intellectual property. User-level information in the data may also be personally identifying, and there may be privacy risks associated with sharing it. Therefore, every credit card company has access to a small set of data – but no company will share it with <span class="No-Break">other companies.</span></li>
				<li>Consider a network security or antivirus company that uses statistics and ML to detect malware. It will have examples of applications that it has analyzed and manually labeled as malware. However, sharing the data may leak information about attacks and undermine the company’s public image. It also may give away clues to attackers on how to circumvent detection. Thus, all antivirus companies will have data but do not share <span class="No-Break">it publicly.</span></li>
			</ul>
			<p>You can draw similar parallels in almost all areas of cybersecurity: click fraud detection, identification of fake news, flagging abusive and hate speech content on social media, and <span class="No-Break">so on.</span></p>
			<p>Entities that own the data are not thrilled about sharing it, which makes training ML models harder. Additionally, no entity can learn from the data acquired by other entities. Valuable knowledge and signals may be lost in the process, and models built on subsets of data will have <span class="No-Break">inherent biases.</span></p>
			<p>Thus, it is extremely<a id="_idIndexMarker805"/> challenging, if not impossible, to construct a dataset that is good enough to train an ML model while maintaining privacy. Federated learning is an approach used to overcome <span class="No-Break">this challenge.</span></p>
			<h2 id="_idParaDest-184">How federated machine learning works</h2>
			<p>FML (or simply FL) is a type of ML<a id="_idIndexMarker806"/> that allows multiple devices or organizations to collaborate on building a shared ML model without sharing their data. In traditional ML, all data is aggregated and processed in a central location, but in FML, the data remains distributed across multiple devices or locations, and the model is trained in a <span class="No-Break">decentralized manner.</span></p>
			<p>The fundamental concept in federated learning is to share the learned model instead of sharing the data. Because of this, individual entities can share knowledge about patterns and parameters without having to disclose the data. We will now see how this is achieved in a <span class="No-Break">step-by-step manner.</span></p>
			<h3>Step 1 – data partitioning</h3>
			<p>The data is partitioned<a id="_idIndexMarker807"/> across multiple devices or locations, where<a id="_idIndexMarker808"/> each one is known as a client. Each client has its own local data that is not shared with other devices. For example, in a medical setting, each hospital may have patient data that it is not willing to share with other hospitals. In the case of fraud detection, each credit card company will have examples of fraud. Note that every client will have data in varying sizes and distributions; however, all clients must preprocess their data in the same way to produce a uniform input vector of data. An example scenario is shown in <span class="No-Break"><em class="italic">Figure 11</em></span><em class="italic">.1</em>; there are multiple clients shown, and each client draws data from different sources (a USB drive, a cloud server, a local file, a database, and so on). At each<a id="_idIndexMarker809"/> client, however, data is processed into the same <span class="No-Break">standard form:</span></p>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="image/B19327_11_01.jpg" alt="Figure 11.1 – Every client processes the data into a standard form"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1 – Every client processes the data into a standard form</p>
			<h3>Step 2 – global model initialization</h3>
			<p>A central server or client, known<a id="_idIndexMarker810"/> as an aggregator, initializes a global<a id="_idIndexMarker811"/> model. In this step, the model is initialized randomly, with parameters and weights drawn from a uniform normal distribution. The global model defines the structure and architecture that will be used by each client. The global model<a id="_idIndexMarker812"/> is distributed to each client for training, as shown in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer100" class="IMG---Figure">
					<img src="image/B19327_11_02.jpg" alt="Figure 11.2 – Global model distributed to clients"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.2 – Global model distributed to clients</p>
			<h3>Step 3 – local training</h3>
			<p>After receiving the global<a id="_idIndexMarker813"/> model, each client trains the local model on the data they have. The local model is trained using standard ML techniques, such as stochastic gradient descent, and updates are made to the local model using the data available on that device. Up until now, the steps we have followed are similar to what an individual client would do in traditional ML. Each client will train and produce its own local model, as shown in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer101" class="IMG---Figure">
					<img src="image/B19327_11_03.jpg" alt="Figure 11.3 – Local model training by clients"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.3 – Local model training by clients</p>
			<h3>Step 4 – model aggregation</h3>
			<p>The updated local models<a id="_idIndexMarker814"/> are then sent back to the central server or cloud, where they are aggregated to create an updated global model. This aggregation process can take different forms, such as averaging the local models or using more complex methods. To calculate the updated aggregated model, the received parameters are averaged and assigned to the new model. Recall that we distribute the global model to each client; thus, each client will have the same structure of the underlying model, which<a id="_idIndexMarker815"/> makes aggregation possible. In most cases, the strategy known as <strong class="bold">federated averaging</strong> is used. We calculate the average weighted by the size of the data; clients with more data are likely to produce a better model, and so their weights are assigned more importance in the average; this process is demonstrated in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer102" class="IMG---Figure">
					<img src="image/B19327_11_04.jpg" alt="Figure 11.4 – Model aggregation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.4 – Model aggregation</p>
			<h3>Step 5 – model distribution</h3>
			<p>The aggregated model calculated<a id="_idIndexMarker816"/> in the previous step is distributed to each client. The client now takes this model and fine-tunes it using the local client data, thus updating it again. This time, however, the initialization is not random. The model parameters are the aggregated ones, meaning that they incorporate the learnings of all client nodes. After updating the model, it is sent back to the central server for aggregation. This continues for a fixed number of <span class="No-Break">communication rounds.</span></p>
			<p>In summary, federated machine learning enables multiple devices or organizations to collaborate on building a shared ML model without sharing their data. This approach can improve data privacy, security, and efficiency, while still providing accurate and <span class="No-Break">useful models.</span></p>
			<h2 id="_idParaDest-185">The benefits of federated learning</h2>
			<p>In this section, we will discuss the key advantages of <span class="No-Break">federated learning.</span></p>
			<h3>Data privacy</h3>
			<p>Data privacy<a id="_idIndexMarker817"/> is one of the most significant advantages of federated ML. In traditional ML approaches, data is collected and stored in a central location, and this can lead to concerns about data privacy and security. In federated learning, however, data remains on local devices or servers, and models are trained without ever sharing the raw data with a central server. This means that data remains secure and there is no risk of a data breach. Additionally, data owners retain control over their data, which is especially important in sensitive industries such as healthcare or finance, where privacy is of <span class="No-Break">utmost importance.</span></p>
			<h3>Lower cost</h3>
			<p>Federated machine learning can be a cost-effective solution for organizations as it allows them to leverage the computational power of multiple devices or servers without having to invest in expensive hardware or cloud computing services. This is because the devices or servers that are used to train the models already exist, and there is no need to purchase additional infrastructure. Additionally, the costs associated with transferring large amounts of data to a central server for analysis are also reduced as data remains on local devices <span class="No-Break">or servers.</span></p>
			<h3>Speed</h3>
			<p>Federated machine learning can also speed up the training process as each device or server can contribute to the training process. This is because models are trained locally on each device or server, and the updates are sent back to the central server, where they are combined to create a global model. Since each device or server is responsible for training only a subset of the data, the training process can be faster than traditional ML approaches. Additionally, because data remains on local devices or servers, there is no need to transfer large amounts of data to a central server, reducing network latency and speeding up the <span class="No-Break">training process.</span></p>
			<h3>Performance</h3>
			<p>FML allows models to be trained on more diverse datasets, leading to improved model accuracy. This is because data is distributed across multiple devices or servers, and each device or server may have slightly different data characteristics. By training models on a diverse set of data, models become more robust and can better generalize to new data. Additionally, models trained using FL can better account for the variability in the data and perform better<a id="_idIndexMarker818"/> in <span class="No-Break">real-world scenarios.</span></p>
			<h2 id="_idParaDest-186">Challenges in federated learning</h2>
			<p>Although federated machine<a id="_idIndexMarker819"/> learning offers significant benefits, such as preserving data privacy, there are several challenges that must be addressed to make it practical <span class="No-Break">and effective.</span></p>
			<h3>Communication and network latency</h3>
			<p>Federated machine learning involves multiple parties collaborating to train a model without sharing their data with each other. However, this requires frequent communication and exchange of large amounts of data and model updates between parties. The communication overhead and network latency can be significant, especially when the parties are located in different geographical locations and have limited bandwidth. This can slow down the training process and make it difficult to coordinate the training of <span class="No-Break">the model.</span></p>
			<h3>Data heterogeneity</h3>
			<p>Federated machine learning involves different parties using their own data and hardware to train the model. This can lead to heterogeneity in the data and hardware, making it difficult to design a model that can effectively leverage the strengths of each party while mitigating the weaknesses. For example, some parties may have high-quality data, while others may have noisy data. Some parties may have powerful hardware, while others may have limited processing capabilities. It is important to design a model that can accommodate these differences and ensure that the training process is fair <span class="No-Break">and unbiased.</span></p>
			<h3>Data imbalance and distribution shift</h3>
			<p>In federated learning, the data used by different parties may be highly imbalanced and may have different statistical properties. This can lead to distributional shifts and bias in the model, making it difficult to ensure that the model is fair and unbiased. For example, if one party has significantly more data than the other parties, the model may be biased toward that party’s data. It is important to address these issues by carefully selecting the data used for training and by using techniques such as data augmentation and sample weighting to mitigate the effects of data imbalance and <span class="No-Break">distributional shifts.</span></p>
			<h3>Free riders and rogue clients</h3>
			<p>Federated learning is designed to preserve the privacy of the data owned by different parties. However, this also makes it challenging to ensure the security and privacy of the model and the data during training. For example, it may be difficult to ensure that the model updates sent by each party are genuine and have not been tampered with or corrupted. Additionally, it may be difficult to ensure that the data owned by each party remains private and secure, especially when parties are not fully trusted. It is important to develop secure and privacy-preserving techniques for federated learning to mitigate <span class="No-Break">these risks.</span></p>
			<h3>Federated optimization</h3>
			<p>Federated machine learning requires the use of novel optimization techniques that can handle the distributed nature of the training process. These techniques must be able to aggregate the model updates from multiple parties while preserving the privacy and security of the data. This can be challenging, especially when dealing with large-scale datasets. Additionally, the optimization techniques used in federated learning must be efficient and scalable, as the training process can involve a large number of parties and a large amount <span class="No-Break">of data.</span></p>
			<p>Overall, addressing these challenges requires a combination of advanced algorithms, techniques, and infrastructure. Despite these challenges, federated machine learning has the potential to enable a new era of collaborative ML while preserving privacy <span class="No-Break">and security.</span></p>
			<p>This concludes our discussion<a id="_idIndexMarker820"/> of federated learning theory. Now that you have a good understanding of how the process works and what the pitfalls involved are, let us implement <span class="No-Break">it practically.</span></p>
			<h1 id="_idParaDest-187">Implementing federated averaging</h1>
			<p>In this section, we will implement federated averaging<a id="_idIndexMarker821"/> with a practical use case in Python. Note that while we are using the MNIST dataset here as an example, this can easily be replicated for any dataset of <span class="No-Break">your choosing.</span></p>
			<h2 id="_idParaDest-188">Importing libraries</h2>
			<p>We begin by importing<a id="_idIndexMarker822"/> the necessary libraries. We will need our standard Python libraries, along with some libraries from Keras, which will allow us to create our deep learning model. The following code snippet imports <span class="No-Break">these libraries:</span></p>
			<pre class="source-code">
import numpy as np
import random
import cv2
from imutils import paths
import os
# SkLearn Libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score
# TensorFlow Libraries
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras import backend as K</pre>
			<p>Let us now turn to the data we <span class="No-Break">are using.</span></p>
			<h2 id="_idParaDest-189">Dataset setup</h2>
			<p>The dataset we will be using<a id="_idIndexMarker823"/> is the MNIST dataset. The MNIST dataset is a popular benchmark dataset used in ML research. It is a collection of 70,000 grayscale images of handwritten digits, with each image being 28 x 28 pixels in size. The images are split into a training set of 60,000 examples and a test set of <span class="No-Break">10,000 examples.</span></p>
			<p>The goal of the dataset is to train an ML model to correctly classify each image into the corresponding digit from 0 to 9. The dataset has been widely used for training and testing various ML algorithms such as neural networks, support vector machines, and decision trees. The MNIST dataset has become a standard benchmark for evaluating the performance of image recognition algorithms, and it has been used as a starting point for many new ML researchers. It has also been used in many tutorials and online courses to teach the basics of image recognition <span class="No-Break">and ML:</span></p>
			<pre class="source-code">
def load_mnist_data(dataroot):
    X = list()
    y = list()
    for label in os.listdir(dataroot):
      label_dir_path = dataroot + "/"+label
      for imgFile in os.listdir(label_dir_path):
        img_file_path = label_dir_path + "/" + imgFile
        image_gray = cv2.imread(img_file_path, cv2.IMREAD_GRAYSCALE)
        image = np.array(image_gray).flatten()
        X.append(image/255)
        y.append(label)
    return X, y</pre>
			<p>This completes the code<a id="_idIndexMarker824"/> to load and <span class="No-Break">preprocess data.</span></p>
			<h2 id="_idParaDest-190">Client setup</h2>
			<p>Next, we need to write<a id="_idIndexMarker825"/> a function that will initialize our client nodes. Note that in the real world, each client or entity will have its own data. However, as we are simulating this scenario, we will implement this manually. The function takes in the data and labels it as input, and returns partitioned data as output. It will break the data into roughly equal chunks and assign each chunk to <span class="No-Break">one client:</span></p>
			<pre class="source-code">
def create_client_nodes(X,y,num_clients=10,
prefix='CLIENT_'):
    #create a list of client names
    client_names = []
    for i in range(num_clients):
      client_names.append(prefix + str(i))
    #randomize the data
    data = list(zip(X, y))
    random.shuffle(data)
    #shard data and place at each client
    per_client = len(data)//num_clients
    client_chunks = []
    start = 0
    end = 0
    for i in range(num_clients):
      end = start + per_client
      if end &gt; len(data):
        client_chunks.append(data[start:])
      else:
        client_chunks.append(data[start:end])
        start = end
    return {client_names[i] : client_chunks[i] for i in range(len(client_names))}</pre>
			<p>We will also write a helper<a id="_idIndexMarker826"/> function that, when given a chunk of data, will shuffle it, prepare it into tensors as needed, and return it <span class="No-Break">to us:</span></p>
			<pre class="source-code">
def collapse_chunk(chunk, batch_size=32):
    X, y = zip(*chunk)
    dataset = tf.data.Dataset.from_tensor_slices((list(X), list(y)))
    return dataset.shuffle(len(y)).batch(batch_size)</pre>
			<p>It is now time to turn to <span class="No-Break">the modeling.</span></p>
			<h2 id="_idParaDest-191">Model implementation</h2>
			<p>Now, we will write a function<a id="_idIndexMarker827"/> that creates our actual classification model. This function takes in the hidden layer sizes as a parameter in the form of an array. At a high level, this function will perform the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>Initialize a sequential <span class="No-Break">Keras model.</span></li>
				<li>Create the input layer based on the shape of the input data. Here, it is known to be <strong class="source-inline">784</strong>, as we are using the <span class="No-Break">MNIST data.</span></li>
				<li>Set the activation<a id="_idIndexMarker828"/> function of the input layer to be a <strong class="bold">rectified linear </strong><span class="No-Break"><strong class="bold">unit</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ReLU</strong></span><span class="No-Break">).</span></li>
				<li>Parse the list of hidden layer sizes passed in as a parameter, and create hidden layers one by one. For example, the <strong class="source-inline">[200, 200, 200]</strong> parameter means that there are three hidden layers, each with <span class="No-Break">200 neurons.</span></li>
				<li>Create the final layer. This will have the number of nodes equal to the number of classes, which, in this case, <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">10</strong></span><span class="No-Break">.</span></li>
				<li>Set the activation of the final layer as <strong class="source-inline">softmax</strong> so it returns normalized <span class="No-Break">output probabilities.</span></li>
			</ol>
			<p>Here is an implementation of <span class="No-Break">these steps:</span></p>
			<pre class="source-code">
def MNIST_DeepLearning_Model(hidden_layer_sizes = [200, 200, 200]):
  input_dim = 784
  num_classes = 10
  model = Sequential()
  model.add(Dense(200, input_shape=(input_dim,)))
  model.add(Activation("relu"))
  for hidden in hidden_layer_sizes:
    model.add(Dense(hidden))
    model.add(Activation("relu"))
  model.add(Dense(num_classes))
  model.add(Activation("softmax"))
  return model</pre>
			<p>This function will initialize and return a model of the <span class="No-Break">desired structure.</span></p>
			<h2 id="_idParaDest-192">Weight scaling</h2>
			<p>Next, we will write<a id="_idIndexMarker829"/> a function that scales the weights. Note that as part of federated learning, we will aggregate the weights. If there is a wide disparity between the data sizes, it will reflect in the model performance. A model with smaller training data must contribute less to the aggregate. Therefore, we calculate a scaling factor for each client or node. This factor is simply the proportion of the global training data this client has access to. If there are 1,000 records globally, and client A has 210 records, the scaling factor <span class="No-Break">is 0.21:</span></p>
			<pre class="source-code">
def scale_weights(all_clients,this_client,weights):
  # First calculate scaling factor
  # Obtain batch size
  batch_size = list(all_clients[this_client])[0][0].shape[0]
# Compute global data size
  sizes = []
  for client in all_clients.keys():
    sizes.append(tf.data.experimental.cardinality(all_clients[client]).numpy())
  global_data_size = np.sum(sizes)*batch_size
  # Compute data size in this client
  this_client_size = tf.data.experimental.cardinality(all_clients[this_client]).numpy()*batch_size
  # Scaling factor is the ratio of the two
  scaling_factor = this_client_size / global_data_size
  scaled_weights = []
  for weight in weights:
    scaled_weights.append(scaling_factor * weight)
  return scaled_weights</pre>
			<h2 id="_idParaDest-193">Global model initialization</h2>
			<p>Now, let us initialize<a id="_idIndexMarker830"/> the global model. This will be the shared central model that will hold the updated parameters in every <span class="No-Break">communication round:</span></p>
			<pre class="source-code">
global_model = MNIST_DeepLearning_Model(hidden_layer_sizes = [200, 200, 200])
global_model.summary()</pre>
			<p>This will show you the structure of the <span class="No-Break">created model:</span></p>
			<div>
				<div id="_idContainer103" class="IMG---Figure">
					<img src="image/B19327_11_05.jpg" alt="Figure 11.5 – Model structure"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.5 – Model structure</p>
			<p>So far, we have written functions to help us with the data and model. Now it is time to put them <span class="No-Break">into action!</span></p>
			<h2 id="_idParaDest-194">Setting up the experiment</h2>
			<p>We will now use the function<a id="_idIndexMarker831"/> we defined earlier to load the training data. After binarizing the labels (that is, converting them into one-hot-encoding form), we will split the data into training and test sets. We will reserve 20% of the data <span class="No-Break">for testing:</span></p>
			<pre class="source-code">
dataroot = './trainingSet'
X, y = load_mnist_data(dataroot)
y_binarized = LabelBinarizer().fit_transform(y)
X_train, X_test, y_train, y_test = train_test_split(X,
                                      y_binarized,
                                      test_size=0.2,
                                      random_state=123)</pre>
			<p>We will see the function we defined earlier to assign data to clients. This will return us a dictionary of client and data pairs, on which we will apply the chunk-collapsing function <span class="No-Break">we wrote:</span></p>
			<pre class="source-code">
clients = create_client_nodes(X_train, y_train, num_clients=10)
clients_data = {}
for client_name in clients.keys():
    clients_data[client_name] = collapse_chunk(clients[client_name])
#process and batch the test set
test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))</pre>
			<p>Next, we will set a few parameters for our experiment. Note that as we have a multi-class classification problem, the choice of categorical cross-entropy as the loss is obvious. The learning rate and the number of communication rounds are hyperparameters – you can experiment<a id="_idIndexMarker832"/> <span class="No-Break">with them:</span></p>
			<pre class="source-code">
learn_rate = 0.01
num_rounds = 40
loss='categorical_crossentropy'
metrics = ['accuracy']</pre>
			<p>Now that we have everything set up, we can actually carry out <span class="No-Break">federated learning.</span></p>
			<h2 id="_idParaDest-195">Putting it all together</h2>
			<p>Now we will actually carry<a id="_idIndexMarker833"/> out the federated learning process in multiple communication rounds. At a high level, here is what we are doing in each <span class="No-Break">communication round:</span></p>
			<ol>
				<li>Obtain the weights from the global model and shuffle <span class="No-Break">client chunks.</span></li>
				<li>For <span class="No-Break">every client:</span><ol><li>Initialize a local model <span class="No-Break">for training.</span></li><li>Set the weights of the local model to the current <span class="No-Break">global model.</span></li><li>Train the local model with data from <span class="No-Break">this client.</span></li><li>Based on the amount of data available in this client, obtain scaled weights from this newly <span class="No-Break">trained model.</span></li></ol></li>
				<li>For memory management purposes, clear the local <span class="No-Break">Keras session.</span></li>
				<li>Compute the average of all the weights obtained in <em class="italic">step 2</em>. As these are scaled weights, the average is a <span class="No-Break">weighted one.</span></li>
				<li>Set the average weights to be the weights for the new <span class="No-Break">global model.</span></li>
				<li>Evaluate the accuracy of this model (new global model with the newly <span class="No-Break">assigned weights).</span></li>
				<li>Print information about loss <span class="No-Break">and accuracy.</span></li>
				<li>Repeat <em class="italic">steps 1–7</em> for each communication round. In every round, the global model is <span class="No-Break">gradually updated.</span></li>
			</ol>
			<p>Here’s the code to implement<a id="_idIndexMarker834"/> <span class="No-Break">these steps:</span></p>
			<pre class="source-code">
 for round in range(num_rounds):
    # Get the weights of the global model
    global_weights = global_model.get_weights()
    scaled_local_weights = []
    # Shuffle the clients
    # This will remove any inherent bias
    client_names= list(clients_data.keys())
    random.shuffle(client_names)
    # Create initial local models
    for client in client_names:
        # Create the model
        local_client_model = MNIST_DeepLearning_Model(hidden_layer_sizes = [200])
        # Compile the model
        local_client_model.compile(loss=loss,
        optimizer=
             tf.keras.optimizers.Adam(learning_rate=0.01),
        metrics=metrics)
        # The model will have random weights
        # We need to reset it to the weights of the current global model
        local_client_model.set_weights(global_weights)
        # Train local model
        local_client_model.fit(clients_data[client],
epochs=1,verbose = 0)
        # Scale model weights
        # Based on this client model's local weights
        scaled_weights = scale_weights(clients_data, client,local_client_model.get_weights())
        # Record the value
        scaled_local_weights.append(scaled_weights)
        # Memory management
        K.clear_session()
    # Communication round has ended
    # Need to compute the average gradients from all local models
    average_weights = []
    for gradients in zip(*scaled_local_weights):
        # Calculate mean per-layer weights
        layer_mean = tf.math.reduce_sum(gradients, axis=0)
        # This becomes new weight for that layer
        average_weights.append(layer_mean)
    # Update global model with newly computed gradients
    global_model.set_weights(average_weights)
    # Evaluate performance of model at end of round
    losses = []
    accuracies = []
    for(X_test, Y_test) in test_batched:
        # Use model for inference
        Y_pred = global_model.predict(X_test)
        # Calculate loss based on actual and predicted value
        loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
        loss_value = loss_fn(Y_test, Y_pred)
        losses.append(loss_value)
        # Calculate accuracy based on actual and predicted value
        accuracy_value = accuracy_score(tf.argmax(Y_pred, axis=1),tf.argmax(Y_test, axis=1))
        accuracies.append(accuracy_value)
    # Print Information
    print("ROUND: {} ---------- GLOBAL ACCURACY: {:.2%}".format(round, accuracy_value))</pre>
			<p>The result here will be a series<a id="_idIndexMarker835"/> of statements that show how the loss and accuracy changed from round to round. Here is what the first 10 rounds <span class="No-Break">look like:</span></p>
			<div>
				<div id="_idContainer104" class="IMG---Figure">
					<img src="image/B19327_11_06.jpg" alt="Figure 11.6 – First 10 rounds in the training loop"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.6 – First 10 rounds in the training loop</p>
			<p>And this is how<a id="_idIndexMarker836"/> the last 10 <span class="No-Break">rounds look:</span></p>
			<div>
				<div id="_idContainer105" class="IMG---Figure">
					<img src="image/B19327_11_07.jpg" alt="Figure 11.7 – Last 10 rounds in the training loop"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.7 – Last 10 rounds in the training loop</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Due to the random initialization of initial weights and shuffling, the results will change every time we run this. Therefore, the numbers you obtain when you try to recreate this will be different than what is shown here. This <span class="No-Break">is expected.</span></p>
			<p>We can visualize these trends<a id="_idIndexMarker837"/> with a plot that will show us the loss over <span class="No-Break">the rounds:</span></p>
			<pre class="source-code">
import matplotlib.pyplot as plt
plt.plot(range(num_rounds), losses)
plt.xlabel("Communication Rounds")
plt.ylabel("Loss")</pre>
			<p>The output would be something <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer106" class="IMG---Figure">
					<img src="image/B19327_11_08.jpg" alt="Figure 11.8 – Loss trend over rounds"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.8 – Loss trend over rounds</p>
			<p>Similarly, we can plot <span class="No-Break">the accuracy:</span></p>
			<pre class="source-code">
import matplotlib.pyplot as plt
plt.plot(range(num_rounds), accuracies)
plt.xlabel("Communication Rounds")
plt.ylabel("Accuracy")</pre>
			<p>This will produce <a id="_idIndexMarker838"/>the <span class="No-Break">following plot:</span></p>
			<div>
				<div id="_idContainer107" class="IMG---Figure">
					<img src="image/B19327_11_09.jpg" alt="Figure 11.9 – Accuracy trend over rounds"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.9 – Accuracy trend over rounds</p>
			<p>Thus, with federated machine learning, we were able to improve the accuracy of the global model<a id="_idIndexMarker839"/> from around 72% to over 92%. Interestingly, you can see that the accuracy somewhat drops around round 25 or 0. This is probably because of overfitting the data on some particular client’s local <span class="No-Break">training data.</span></p>
			<h1 id="_idParaDest-196">Reviewing the privacy-utility trade-off in federated learning</h1>
			<p>In the previous section, we examined<a id="_idIndexMarker840"/> the effectiveness of federated learning<a id="_idIndexMarker841"/> and looked at the model performance over multiple communication rounds. However, to quantify the effectiveness, we need to compare this against <span class="No-Break">two benchmarks:</span></p>
			<ul>
				<li>A model trained on the entire data with no <span class="No-Break">federation involved</span></li>
				<li>A local model trained on its own <span class="No-Break">data only</span></li>
			</ul>
			<p>The differences in accuracy in these three cases (federated, global only, and local only) will indicate the trade-offs we are making and the gains we achieve. In the previous section, we looked at the accuracy we obtain via federated learning. To understand the utility-privacy trade-off, let us discuss two extreme cases – a fully global and a fully <span class="No-Break">local model.</span></p>
			<h2 id="_idParaDest-197">Global model (no privacy)</h2>
			<p>When we train a global model<a id="_idIndexMarker842"/> directly, we use all the data to train a single model. Thus, all parties involved would be publicly sharing their data with each other. The central aggregator would have access to all of the data. In this case, as the data is shared, there is no privacy afforded <span class="No-Break">to clients.</span></p>
			<p>To train the global model on the entire data, we will re-initialize the global model and fit it with the entire training data (instead of individual client data). Here is the code snippet <span class="No-Break">for that:</span></p>
			<pre class="source-code">
# Initialize global model
global_model = MNIST_DeepLearning_Model(hidden_layer_sizes = [200, 200, 200])
global_model.compile(loss=loss,optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),metrics=metrics)
# Create dataset from entire data
full_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\.shuffle(len(y_train))\.batch(32)
# Fit the model
global_model.fit(full_dataset, epochs = 10)</pre>
			<p>You should see output<a id="_idIndexMarker843"/> as follows, which shows the accuracy and loss through <span class="No-Break">each epoch:</span></p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B19327_11_10.jpg" alt="Figure 11.10 – Global model training"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.10 – Global model training</p>
			<p>We see that the fully global model performs much better (it starts at 92% and finishes at 95%) in just a few epochs. This means that it is more powerful than the federated model. This is the trade-off we make in the federated learning; we have to sacrifice performance and accuracy <span class="No-Break">for privacy.</span></p>
			<h2 id="_idParaDest-198">Local model (full privacy)</h2>
			<p>Now, to evaluate the performance<a id="_idIndexMarker844"/> of our local model, we will pick a random client (say client 8) and train a model only on that <span class="No-Break">client’s data:</span></p>
			<pre class="source-code">
# Initialize local client
local_client_model = MNIST_DeepLearning_Model(hidden_layer_sizes = [200, 200, 200])
local_client_model.compile(loss=loss,optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),metrics=metrics)
# Train on only one client data
local_client_model.fit(clients_data['CLIENT_8'],epochs=10)</pre>
			<p>The result is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B19327_11_11.jpg" alt="Figure 11.11 – Local model training"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.11 – Local model training</p>
			<p>Here, we see that the model started off really poorly (an accuracy of less than 20%, which is worse even than a random guessing classifier). Over the epochs, the model performance improved. However, the accuracy at the end was a little above 48%, which is worse than the <span class="No-Break">federated model.</span></p>
			<h2 id="_idParaDest-199">Understanding the trade-off</h2>
			<p>The results we have obtained<a id="_idIndexMarker845"/> from the previous two subsections show us <span class="No-Break">two things:</span></p>
			<ul>
				<li>A model that performs federated learning performs better than a model trained only on a client’s local data. Thus, a client is able to benefit from the model learned by other clients through parameter sharing and aggregation, which can be achieved without <span class="No-Break">sharing data.</span></li>
				<li>A global model trained on the entire data performs better than the federated <span class="No-Break">learning model.</span></li>
			</ul>
			<p>This clearly demonstrates the privacy-utility trade-off. As we increase the privacy (apply federated learning), the utility of the data decreases, as reflected in the model performance. At no privacy (all clients share data and use it to train a global model), utility is <span class="No-Break">the highest.</span></p>
			<p>While the trade-off may be harder to understand given the dataset we have used here (after all, what privacy concerns do we face in sharing images of handwritten digits?), it becomes more obvious as we enter the security domain. Recall that in the very first chapter, we discussed how ML in the security domain is different than in other domains, such as image recognition or advertisement targeting, as the stakes are <span class="No-Break">higher here.</span></p>
			<p>Instead of image recognition, consider this to be a credit card fraud detection scenario. The client nodes are various banks and credit card companies. Every company has labeled examples of fraud that they do not want <span class="No-Break">to share.</span></p>
			<p>If the companies share all of the data with each other, it will allow them to train a global model. As different companies will have different patterns and examples of fraud, the model generated will be able to detect multiple attack patterns. This will benefit each company involved; company <em class="italic">A</em> will be able to detect a certain kind of fraud even if it has never seen it before if another company, <em class="italic">B</em>, has ever observed it. However, at the same time, companies risk their proprietary data being leaked and personally identifying user data being exposed. There also may be reputational harm if the occurrence of fraud comes to light. Therefore, the high performance and generalizability come at the cost of a loss <span class="No-Break">of privacy.</span></p>
			<p>On the other hand, consider that the companies do not share any data at all. Thus, each company will be able to train a model on the data it has access to. In this case, company <em class="italic">A</em> will not be able to detect out-of-distribution fraud or novel attack patterns that it has not seen before. This will result in a low recall in detecting fraud and might cause severe losses to the company. Therefore, the high privacy and confidentiality come at the cost of reduced performance and potential <span class="No-Break">financial loss.</span></p>
			<p>Federated learning is able to solve both of these issues and provide us with the perfect middle ground between privacy and utility. Because federated learning involves sharing model parameters and not data, privacy can be maintained, and personal information will not be released. At the same time, because the models are shared and aggregated, learnings from one client<a id="_idIndexMarker846"/> will be beneficial to others <span class="No-Break">as well.</span></p>
			<h2 id="_idParaDest-200">Beyond the MNIST dataset</h2>
			<p>In this chapter, we chose<a id="_idIndexMarker847"/> the MNIST dataset for our experiments. While MNIST is a popular benchmark for image processing, it is not ideal for security applications. However, we chose it for two reasons. First, it is a fairly large and well-distributed dataset that makes federated learning simpler. Other public datasets are relatively small, which means that when sharded, clients have only a small amount of data that is not enough to produce a reasonable model. Second, being an image dataset, it is naturally suited to be processed by <span class="No-Break">neural networks.</span></p>
			<p>The applications of federated learning are not limited to images. You are encouraged to explore all of the problems we have looked at in this book so far (malware, fake news, and intrusion detection) and implement them in a federated manner. To do so, only two changes <span class="No-Break">are required:</span></p>
			<ul>
				<li>Change the data loading mechanism to read from the appropriate data source instead <span class="No-Break">of MNIST</span></li>
				<li>Change the deep learning model structure to reflect the input and output dimensions specific to <span class="No-Break">the dataset</span></li>
			</ul>
			<p>The rest of the steps (initializing the model, sharding the data, communication rounds, and so on) all remain the same. You should implement federated learning in various cybersecurity areas and observe the <span class="No-Break">privacy-utility trade-off.</span></p>
			<h1 id="_idParaDest-201">Summary</h1>
			<p>In this chapter, we learned about a privacy preservation mechanism for ML known as federated learning. In traditional ML, all data is aggregated and processed in a central location, but in FML, the data remains distributed across multiple devices or locations, and the model is trained in a decentralized manner. In FML, we share the model and not <span class="No-Break">the data.</span></p>
			<p>We discussed the core concepts and working of FML, followed by an implementation in Python. We also benchmarked the performance of federated learning against traditional ML approaches to examine the privacy-utility trade-off. This chapter provided an introduction to an important aspect of ML and one that is gaining rapid traction in today’s privacy-centric <span class="No-Break">technology world.</span></p>
			<p>In the next chapter, we will go a step further and look at the hottest topic in ML privacy today – <span class="No-Break">differential privacy.</span></p>
		</div>
	</body></html>