- en: Advanced Ways of Improving Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we learned to build a model, then we performed diagnostic analysis on
    it. Then, we determined how accurate the model was, and in this chapter, we will
    extend our model-building skills. We will learn how to not view a model as an
    endpoint, but as a starting position to move forward toward improving models.
    Basically, we will learn how to improve individual models by building more than
    one model. We have several ways in which we can do that, and we are going to talk
    about them in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics that will be covered in this chapter are as follows. These are also
    the ways in which we can improve individual models:'
  prefs: []
  type: TYPE_NORMAL
- en: Combining models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Propensity scores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meta-level modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Error modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boosting and bagging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous outcomes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several ways in which models can be combined. We are going to look
    at each method in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Combining by voting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's use an example to understand this method of combining models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider that we have run three models and created a table like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c7806c54-cba4-4c04-be11-4115f2e18485.png)'
  prefs: []
  type: TYPE_IMG
- en: We have the confidence for each model and its prediction. Let's see how we can
    combine these models.
  prefs: []
  type: TYPE_NORMAL
- en: If we take a look at the first row, we can see that each of these models is
    predicting that a person is going to leave. Hence, if we combine the predictions,
    we are still predicting that the person is going to leave. The confidence value,
    or the final confidence, is acquired by adding up the confidence values of all
    the models and dividing by the number of total models, three in our case.
  prefs: []
  type: TYPE_NORMAL
- en: If we look at the second row, we can see that two of these models predict that
    the person is going to leave; and one model is predicting that the person is going
    to stay; we can infer that the combined prediction will be that the person will
    leave. Here, we calculate the confidence values by adding up the confidence of
    the models that predicted the combined prediction, Leave, divided by the total
    number of models, which is three. Hence, the final confidence value is low in
    the second row.
  prefs: []
  type: TYPE_NORMAL
- en: This is combining models by voting, where only the predictions that occur a
    number of times are  considered for combining.
  prefs: []
  type: TYPE_NORMAL
- en: Combining by highest confidence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is another method of combining models. Consider the following table, for
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4fd27279-8af9-4997-8b9d-50401e224256.png)'
  prefs: []
  type: TYPE_IMG
- en: In this example, we won't consider what the model is predicting; instead, we
    will just focus on high confidence values. If we look at the first row, each of
    the models has predicted Leave. But Model 1 has the highest confidence, and so
    the combined prediction is taken as Leave and the final confidence is the highest
    confidence acquired.
  prefs: []
  type: TYPE_NORMAL
- en: If we look at the second row, the model with highest confidence is Model 3 and
    it has predicted that the person is going to stay, and hence, the combined prediction
    becomes Stay and the final confidence becomes the highest confidence.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing combining models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to see how we can combine different models:'
  prefs: []
  type: TYPE_NORMAL
- en: Get Electronics_Data on Canvas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the dataset to a Partition node from the Field Ops palette.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split the data into training and testing datasets, we have done before.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the Partition node to the Neural Net model and run this model with a
    random seed set to `5000` and run it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will now build a **support vector machine** (**SVM**) model. As we are heading
    towards combining models, we will go to the Partition node and connect it with
    an SVM model from the Modeling palette.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the SVM model by recalling the edits we had made in the Expert tab from
    [Chapter 2](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml), *Getting Started with
    Machine Learning*. Go to the Expert tab, select the mode as Expert. Change the
    Regularization parameter, C and set it to `5`, the middle value, and change the
    Kernel type to Polynomial, as that's what gave us an accurate and consistent model
    earlier on using the same data. Also, change the Degree value to `2`. We are changing
    the parameters to these values because we acquired proper results earlier when
    we first saw a demonstration of this model in [Chapter 2](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml),
    *Getting Started with Machine Learning*. Click on Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect both the SVM and the Neural Net model that were generated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the Output palette and connect the generated SVM model to a Table.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the table using the Run icon on top. You will see the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a3ce3b75-6b27-4fa9-89f5-aa5333160068.png)'
  prefs: []
  type: TYPE_IMG
- en: In this, you can see the results from the partition node, the predictions from
    the Neural Net model, its confidence, and even the predictions from the SVM model
    and its confidence. You can close this window.
  prefs: []
  type: TYPE_NORMAL
- en: We will now analyze the model by connecting the SVM-generated model to an Analysis
    node from the Output palette.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Edit the Analysis node, check the Coincidence matrices, and click on Run. You
    will see the following results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b60dd1dc-71dc-4780-a089-f9d88ef0c7c8.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see how well each of the models has performed. If you scroll down, you
    can see that the models have agreed 88% of the time on predictions in the training
    dataset, and about 87% of the time in the testing dataset. When these models agreed,
    they were actually correct a fair amount of the time. This brings us to evaluate
    the possibility of combining these two models.
  prefs: []
  type: TYPE_NORMAL
- en: We are now moving on to combine the models. We will first combine using Modeler,
    but we will also see how we can combine models outside of a modeler.
  prefs: []
  type: TYPE_NORMAL
- en: Combining models in Modeler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For combining models within a modeler, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to the SVM model and connect it to the Ensemble node from the Field Ops palette.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s edit the Ensemble node. The Ensemble node knows that it is combining
    the results of two models as it shows two models in ensemble. Choose the Target
    field for Ensemble as the Status from the drop-down button on the right. If the
    Filter out fields generated by ensemble models is checked, it will filter out
    the already generated fields from the previous models, hence, we will deselect
    it. Next, select the Ensemble method. This is a list 0f ways in which we can combine
    the model. Here, we will select Voting as we have already seen this. We will talk
    about the propensity scores later on in this chapter. Then we have to select what
    happens when there is a tie; here, we will select Highest confidence as we have
    seen this too and click on OK, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/bd87ac6b-18d5-476e-9b22-8ab613e75eeb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see the results of our combination. For this, connect the Ensemble node
    to the Analysis node and click on the Run button on top. The following will be
    the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f1151314-0192-4a57-9166-298e5263210e.png)'
  prefs: []
  type: TYPE_IMG
- en: First, we have the results of the Neural Net model, followed by the results
    of the SVM model and then finally, we can see the results of the combined model.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the overall accuracy in the testing dataset is 82%, which means
    that there is a slight improvement. We were able to improve the accuracy by combining
    two models by 2% which is great as a starting point. Let's see how we can combine
    models from outside of Modeler.
  prefs: []
  type: TYPE_NORMAL
- en: Combining models outside Modeler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This method can be used when you are using any data-mining software other than
    SPSS Modeler.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to the Field Ops palette and connect the SVM-generated model to a Derive
    node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will use the Derive node to create a new field. We will edit this node and
    name it `Combined_Prediction`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Derive this field as a Conditional. You will see an `if-else` condition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's tell Modeler that if the predictions from all the models are equal then
    the combined prediction will be that prediction itself. To do this, let's add
    an expression in the first `if` condition as, the prediction from the Neural Net
    model, $N-Status select = the prediction of the SVM model, $S-Status; go to the
    `Then` condition, click on the expression builder and select, the prediction of
    the Neural Net model, $N-Status or alternatively, you can even select a prediction
    from the SVM model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Write in the `Else` condition, this statement: You can select the variable
    names from the list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b2e480d6-9a22-49f4-a1ff-3eada9573d36.png)'
  prefs: []
  type: TYPE_IMG
- en: This statement means that we will select the **Highest confidence** from any
    of the models if the predictions of the two models do not match. And if the confidence
    of the prediction from the Neural Net model is higher than that of the SVM model,
    then we will go with the prediction of the Neural Net model. Otherwise, if the
    confidence of the prediction of the SVM model is higher than the Neural Net model,
    then we will go with the SVM model. But, if both the conditions don't satisfy,
    then we will put a `0`, and then we have to end with an `endif` statement. Click
    on OK.
  prefs: []
  type: TYPE_NORMAL
- en: 'Connect the Combined_prediction node to the Table mode and let''s see the results
    take a look at the results, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2d884fe8-d782-4865-96c7-cbc9412229c0.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, in the 12th row, we can see that the neural network predicted a customer
    as Churned whereas the SVM predicted it as Current, but as the confidence of the
    Neural Net prediction was higher, the combined prediction was picked as Churned.
  prefs: []
  type: TYPE_NORMAL
- en: You can analyze this model and see for yourself that the numbers that will be
    acquired will be similar to the numbers that we had using the Ensemble node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is how we combined two models to improve accuracy and we saw how we can
    get the combined results from the two models. You can try this out with three
    or more models. You will be amazed at how well combining models can work. We will
    now see another advanced method to improve the model.
  prefs: []
  type: TYPE_NORMAL
- en: Using propensity scores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Propensity scores are very useful because they tell you the likelihood of something
    happening. Confidence values for models reflect confidence in our predictions
    so a high degree of confidence doesn't help us determine if we're going to have
    a customer that's going to stay or leave a company, instead it indicates the confidence
    that we have in our prediction. Sometimes it's helpful to modify the confidence
    value so that a high confidence value means a prediction that a person is going
    to leave and a low confidence value indicates that a person is going to stay.
    Basically, we end up creating a propensity to leave score which would be helpful
    so that we could make interventions, different marketing efforts, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this table, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2579696c-ecb3-4400-9829-07f9c8de4441.png)'
  prefs: []
  type: TYPE_IMG
- en: We have two values for Leaving and two values for Staying, each with the confidence
    values that we have in those predictions. In this example, let's assume that we
    are trying to calculate the propensity of losing a customer. We will create a
    propensity score; this means that when a person is predicted to leave, the propensity
    score is the same thing as a confidence value. So you can see that for the first
    person, we're predicting they are going to leave, and as we have a high degree
    of confidence in that prediction, therefore the propensity score is pretty high.
    For the second person, we're predicting they are also going to leave, but the
    confidence in that prediction is not quite as high, so therefore, we can see that
    the propensity score is not quite so high either.
  prefs: []
  type: TYPE_NORMAL
- en: While predicting the opposite, if we are predicting that a third person is going
    to stay but the confidence in that prediction is not very great, really what we're
    doing is taking 1 minus the confidence value of the opposite of what we really
    want, and that ends up being the propensity score. Finally, in the last example,
    we have a person that we're predicting is going to stay. The confidence in that
    prediction is extremely high, so therefore, the likelihood of that person leaving
    is very low.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure sums up the propensity formulas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e55068c9-388b-4aa2-909a-bc9207fcfeed.png)'
  prefs: []
  type: TYPE_IMG
- en: In essence, what propensity scores do is modify confidence values so that you
    can see the likelihood of something happening. So, if you could put them all on
    some kind of spectrum it would be possible to see, for example, that there are
    some people for whom there is a high degree of confidence that they are going
    to leave, so maybe there's not much that we can do about that. We have another
    group of people for whom we have a high degree of confidence that they're going
    to stay, so the propensity of them leaving is pretty low. Again, we may not necessarily
    need to worry about them that much, but maybe the people we need to focus on are
    the people in the middle, because they're the predictions that are not quite as
    extreme, and so we cannot be quite as confident about those predictions. Potentially,
    we can do something with that group. We might be able to change their minds, or
    something like that, and that's how propensity scores can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Implementations of propensity scores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To see how we can use propensity scores to our advantage, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Get your dataset on the canvas and connect it to a Partition node, dividing
    the dataset into two parts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the Partition node to a Chaid model from the Modeling tab. You could
    use any model here, but let's use this as it will be used in our next example
    as well.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Chaid will build a decision tree model. To edit, go to the Model Options tab,
    where there is a section that asks for Propensity Scores. There are two types;
    a raw propensity score is for the training dataset and the adjusted propensity
    score is for the testing or validation dataset. We will select the raw propensity
    score for now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ea658e0a-6679-404c-bd44-55cdab3879ba.png)'
  prefs: []
  type: TYPE_IMG
- en: Click on Run. Connect the generated model to a Table node from the Output palette
    and run the Table. Observe the Table and see that we have another variable added
    known as the propensity score, and when a customer is predicted to be churned,
    and if their confidence score is low, the propensity score is *1-confidence* of
    what we really want. But for the Current customer, we have a propensity score
    similar to the confidence value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you wish to see a graphical representation of this, connect the generated
    model, to the Histogram node from the Graphs palette. Edit the Histogram, in the
    field box, and select the propensity score variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/008e5975-611e-4434-b90f-bc3b849a06f0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on Run to see the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/af0b244e-277b-4e36-8912-7227ecc4091b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Notice that the propensity scores will range from 0.0 to 1.0\. But the confidence
    values have only two values, and they have a range from 0.5 to 1.0\. To see this
    again, go to the histogram and from the Fields option, select the Confidence variable,
    then click on Run. You will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b681f5ae-ebc6-4856-904e-f648f623f24b.png)'
  prefs: []
  type: TYPE_IMG
- en: Hence, we transformed the confidence values into a propensity score and now
    that propensity score is giving us information about the likelihood, in this case,
    of somebody staying as a customer. We could have done it the other way, where
    we were finding the propensity score for the likelihood of losing a customer,
    but we could just invert those scores and it would end up creating that for us.
    In any case, we can use those propensity scores now to do something with them,
    to see which customers are the most likely ones that we're going to lose, for
    example, or those which we're going to keep. However you want to look at it, you
    know which people that are very likely to be lost and so it may not be possible
    to do anything with them. Those people that were in the middle might not be lost,
    so maybe a little more could be done for them to try to keep them as customers
    and try to understand them better.
  prefs: []
  type: TYPE_NORMAL
- en: Meta-level modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Meta-level modeling is building a model based on predictions or results from
    another model. In the previous example, we saw how to create propensity scores
    for our **Chaid** model. In this section, we will see how you can extract results
    from the **Chaid** model and feed them into a Neural Net model, and this will
    enable us to improve the results from a Neural Net model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Connect the partition node to the Neural Net node from the modeling palette.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the Neural Net model by changing the Random seed to `5000` from the Advanced
    options under the Build tab and click on Run. Now connect the generated Chaid
    model to the generated Neural Net model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, use the Analysis node to see the level of accuracy of these models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will get the following results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2651538a-9c6c-4ee8-91de-6ebc5e1320dd.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that the accuracy of both the models is somewhat similar, so now
    we will move on to build a different kind of Neural Net model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will take the results from the Chaid model and feed them to the Neural Net
    model. The Neural Net model will then use the results, along with all other individual
    predictors, to try to capture more than Chaid:'
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on the generated Neural Net model and delete it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the generated Chaid model to a Type node from the Field Ops palette.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scroll the Type node edit box to the bottom and set the confidence value variable
    of the Chaid model to None:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9e2551b6-5c03-4b33-ba82-8f24d44ffa44.png)'
  prefs: []
  type: TYPE_IMG
- en: Click on OK.
  prefs: []
  type: TYPE_NORMAL
- en: Connect the Type node to the Neural Net model that we already have on the canvas
    and run it using the Random seed of `5000`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you take a look at the results of the new model, you can see that the most
    important predictors are the propensity scores from the Chaid model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/662317dc-0e1c-44dd-8227-a0aad09f451b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Connect the the generated Chaid model to Analysis node and run the analysis
    to get the following result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0e52a752-684d-434d-b926-aa86c7e606bb.png)'
  prefs: []
  type: TYPE_IMG
- en: In this example, we can see that in the Neural Net model, we got a 1% increase
    in accuracy if we fed the results from the Chaid model.
  prefs: []
  type: TYPE_NORMAL
- en: Error modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Error modeling is another form of meta-level modeling but in this case we will
    be modeling cases where there were errors in our predictions. In this way, we
    can increase the accuracy of that prediction. Using an example, we will walk through
    how to do error modeling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following scenario, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb0683df-a373-4da4-a23a-bc5a6ed14f84.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we have a dataset named `LoyalTrain`. This is just a training dataset;
    we have our testing and validation dataset at a different place and will build
    a model only on the training dataset. Theer is also a Type node and a Neural Net
    model, where we are predicting the variable loyal. Run the Analysis node to see
    the results as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ded52372-c6cc-4205-bd25-f4177e98e3bf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can see that there are two categories in the outcome variable: people are
    either predicted to stay or to leave. You can also see that correct predictions
    were made in 79% of the cases. Mistakes were made in 21% of the cases. In total,
    there were 236 errors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From this example, you can also see that the Neural Net model was copied and
    placed in another part of the stream. A new variable, `CORRECT`, was also made
    using a Derive node. Let''s take a look at what''s happened here, as shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/65e71ad2-fd93-46aa-a021-10af29b15c8b.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we have created a new field as `CORRECT`, and we have kept its values
    as `True` and `False`. We are telling Modeler here that if it finds a variable,
    LOYAL, and if it is equal to the prediction of LOYAL, then the value is True;
    otherwise, it is False.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run the Distribution node placed above it, you will see the following
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/424119fa-4336-4b65-b2a6-0bca6ad9afdd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we will use the Type node to instantiate the data, after which we can
    use a C5.0 decision tree model that looks at the data in a very different way.
    Here we have built a C5.0 model that is trying to predict if we are getting a
    correct or an incorrect prediction. Click on the generated C5.0 model to see its
    results, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f708e93e-ff03-4077-b682-f45bc2d54d56.png)'
  prefs: []
  type: TYPE_IMG
- en: In this example, we can see that we have 14 rows with 4 rule(s) for a False
    prediction, that is, when we are predicting incorrectly, and 10 rule(s) for True
    values when we are predicting correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can expand the rules and click on the **%** sign above them to get the
    following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c58a081-e865-4c1a-9e5a-a2565ae64a1a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, the first rule basically states that if you''re male and you''re
    using fewer than 1 minute of international calls, fewer than 1 minute of long-distance
    calls, and your status is single, we are predicting that we will have a value
    of False. If you want to see the numbers, click on the % sign, where you will
    see the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b1a3a44a-e41d-486b-9ab1-3b8384d450ec.png)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding screenshot, first rule had 22 people, and the accuracy
    of predictions relating to them was around 82%.
  prefs: []
  type: TYPE_NORMAL
- en: 'From this, we can see that there are certain kinds of mistakes cropping up
    while we are making the predictions. We might therefore need to use another kind
    of model instead of a Neural Net model. To do this, click on the Generate option
    and select the Rule Trace Node, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a1f3277c-c8a4-426e-8cbc-8177a04d7f4f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This step created the FALSE_TRUE node that you can see in the example scenario
    as the Start icon. This creates all of our rules. If you wish to take a look inside
    it, click on the Start + icon on the Tools tab, where you should see the following
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d42de6f6-3fb3-4c61-8eab-ec70ecae1c8b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s now take a look at the first rule. Click on the expression builder in
    that rule, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f58fb2fe-48ac-48da-b8f5-ebddab672ba6.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the rule appears to state that if you're male and you're using fewer than
    1 minute of international calls, fewer than 1 minute of long-distance calls, and
    your status is also single, we're predicting that you're going to have a value
    of False. You can see the accuracy in that prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go back using the Start icon. Here, we have the classify node, `Split`. Let''s
    see what we have done so far, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4f68ae73-f951-4022-9aed-dd9c01b17c94.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We have taken the variable RULE and clicked on Get, which gave us all of these
    different original values of False, which we renamed to Incorrect and all the
    values of True, which were renamed to Correct, and then we had just the Correct
    Predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ec547e81-6ddc-42f5-a169-323d8d890d41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We have now built the Neural Net model. If you run the Analysis node of the
    generated Neural Net model from the Correct Predictions, you should see the following
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28266a65-c6fd-40af-9336-4a1d478b1a18.png)'
  prefs: []
  type: TYPE_IMG
- en: Remember that the overall accuracy of the earlier model was around 79%, which
    has now improved to around 84%.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have also done the same thing for incorrect predictions in a separate field
    from the Type node. Let''s have a look at that, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/40117de4-64a4-460f-8f66-48277f984a9e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We built a C5.0 model for incorrect predictions, so let''s take a look at its
    analysis, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dec38d60-e165-4cb6-a00c-cc4a4e5ade56.png)'
  prefs: []
  type: TYPE_IMG
- en: The C5.0 model has done a great job at predicting the incorrect values where
    the Neural Net model didn't work well; we now have an overall accuracy of 89%.
  prefs: []
  type: TYPE_NORMAL
- en: Let's sum up what we did here. We had a dataset that we split into correct and
    incorrect results and separately modeled each one to give us fewer errors than
    we used one model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need to combine the predictions from the two models. For this, go to
    the Error 2 Stream from the Streams tab at the right, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/265f52b9-f13d-4e27-86bf-33cdaf06c82f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we have combined the predictions of both the models and have used a Derive
    node Prediction, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1322cc1a-1431-48df-87cd-08f70911f8a7.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we have specified that if a prediction is correct, the prediction of the
    Neural Net model should be opted for. If a prediction is incorrect, we should
    opt for the prediction of the C5.0 model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, having added the Matrix node, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c07fa06b-e595-4f41-bb43-ec56a34afbc5.png)'
  prefs: []
  type: TYPE_IMG
- en: What we can see in the preceding screenshot is that we have correctly predicted
    that 437 people will leave with 118 errors, and that 498 people will stay with
    just 55 errors. This means there is a total number of 173 errors.
  prefs: []
  type: TYPE_NORMAL
- en: Our original model made 236 errors, so we have brought down the number of errors
    by a great extent. Just by using two different models for different groups of
    people and by combining them with, we have produced an output with 63 fewer errors.
  prefs: []
  type: TYPE_NORMAL
- en: This is error modeling. In error modelling you can build one model, see what
    the results look like, and then decide from there whether to build two or three
    models for different types of people, because it can't be assumed that one size
    fits all. Therefore, we can build different kinds of models, feed different types
    of data to those models, and then ultimately combine the results of each model
    to produce a final prediction that can end up having fewer errors in terms of
    the predictive modeling undertaken.
  prefs: []
  type: TYPE_NORMAL
- en: Boosting and bagging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The idea behind boosting is that by building successive models that are built
    to predict the misclassifications of earlier models you're performing a form of
    error modeling. Bagging, on the other hand, is sampling with replacement. With
    this method, new training datasets are generated which are of the same size as
    the original dataset. For our example in this section, will be using a bootstrap
    sample.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we're going to see how to do boosting and bagging, which are
    two methods of improving a model.
  prefs: []
  type: TYPE_NORMAL
- en: Boosting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to do boosting with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Get your data on a canvas and partition it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a Neural Net model for the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the Neural Net model with a Random seed set to `5000`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect an Analysis node and run it with Coincidence matrices checked – you
    will see that the testing accuracy is 81% and the overall accuracy is 80%.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, boost the Neural Net model. For this, go to the Neural Net model and edit
    it. Go to Objectives under Build options and click on Enhance model accuracy (boosting).
    Boosting can be used with any size of dataset. The idea here is that we're building
    successive models that are built to predict the misclassifications of earlier
    models. So, basically, we end up building a model. There'll be some errors, so
    a second model should be built where the errors of the first model are given more
    weight so that we're able to understand them better. Then, when we build a second
    model, there are going to be errors, so we end up building a third model where
    the errors of the second model are given more weight again so that we try to understand
    them better, and so forth. Whenever you're doing boosting and bagging, you always
    have to make sure you have a training and a testing dataset because there's a
    very good chance that you're going to capitalize on chance, and that you might
    find sample-specific information because we're focusing on the errors that we're
    finding within that specific sample. We'll now click on Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s take a look at our generated model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/5ce2de68-ad80-4cbd-a5e4-5ce279231e75.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The first tab that we have here in our generated model is showing us what the
    Ensemble model looks like: that''s combining the 10 models that we''ve created.
    You can see its overall accuracy is about 98%: that''s the model that''s been
    chosen as the best model. You can also see what the reference model is—that would
    be the first model that was built—and then you can see the naive model and, really,
    that''s no model, that''s just where we''re predicting the mode or the most common
    response.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go down to the second icon:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ddc7969a-8722-4c53-988a-aadd7f4b0c58.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, you can see the Predictor Importance. Across the 10 models that we ended
    up building, we can see that the Premier variable was the most important predictor
    and then you can see what the other predictors were in terms of their order of
    importance. This is the same kind of information that we would see typically with
    a general Neural Net model, but this information comes from across all the different
    models that we built.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we go down to the next icon we can see Predictor Frequency:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e237b5dd-1edb-4a38-b606-72bb67c75bb2.png)'
  prefs: []
  type: TYPE_IMG
- en: This shows us how frequently each one of the different predictors was used in
    the model. For a Neural Net model this is not so interesting because Neural Net
    models generally do not drop predictors, but if we had a decision tree model,
    for example, this could be a little more interesting because there you do drop
    predictors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go down to the next tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3c80ce0a-da3c-4de0-a374-28f0a6c19119.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot is showing us the level of accuracy of the model. You
    can see that it flattens out and, at some point, there's no longer much of an
    improvement. In this case, it's a gradual increase in terms of accuracy. Sometimes,
    in some models, you see perhaps five models that there's a huge jump in accuracy
    and then it just stabilizes. Maybe you wouldn't necessarily need to build any
    more models. In our case, we ended up building 10 models. Our overall accuracy
    was extremely high. If we had seen much lower accuracy, perhaps because we saw
    a gradual increase, maybe we would want to use 15 models instead of 10, for example.
    That's where you would see this kind of information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s scroll down a little further and let''s see the final table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/02ba2c0d-ac25-4f39-8f20-ff527d686dff.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we can see the number of predictors and we can also see the number of
    cases that we had in the model as well. Finally, we see the number of synapses,
    which are basically the number of weights or the number of connections that we
    have within this model. So, you can see how well each one of these individual
    models is doing. Each new version of a model is giving more weight to where we
    had more errors in the data and that's basically the idea here.
  prefs: []
  type: TYPE_NORMAL
- en: Run the Analysis node, finally, and you can see that for the training dataset
    the overall accuracy was about 98%. But in the testing dataset the overall accuracy
    was about 80% that's what we really care about, the testing dataset. In this case,
    we see that there's a big difference between training and testing and that's generally
    going to be the situation when talking about boosting models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make sure that whatever result you get is really worth it, and that it's really
    an improvement over just running the model on its own. In this case, when we just
    ran one model, remember that the overall accuracy on the testing data set was
    at about 80%; that's what we have here. So really, boosting didn't do much for
    us in this particular situation. In other situations, it certainly can, but again
    you want really to be able to weigh that, and in this case boost seemed to be
    probably not really worth it for us in this situation.
  prefs: []
  type: TYPE_NORMAL
- en: Bagging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s go back into the Neural Net model and, this time, what we''re going
    to do is bagging instead of boosting:'
  prefs: []
  type: TYPE_NORMAL
- en: Go over to the Objectives tab and select Enhance model stability – it's sampling
    with replacement. Do not do bagging when you have small datasets or outliers.
    The main idea behind bagging is that new training datasets are generated that
    are of the same size as the original training dataset and this is done by using
    sampling with replacement. We're actually bootstrapping in this kind of situation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Run for the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s take a look at our generated model. This is the model that we ended
    up building:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/41820b52-d713-4c53-b7bf-2c47a2c0e7dd.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that the combining rule is achieved by voting but there are other ways
    in which we can combine models and, in fact, we can choose the option to show
    all the combining rules. We won’t see the details for all the models because the
    screenshots are the same as with boosting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the Analysis node to get the following results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4467c320-7c2c-4511-9d45-ecf3360f8c61.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that, by doing the bagging, we got a 4% increase in accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: We will now see how to predict continuous outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting continuous outcomes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Until now, we have spent all of our time talking about categorical outcomes
    and most of those examples apply to continuous outcomes, but in this section we're
    going to focus exclusively on continuous outcome variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'As I mentioned previously, when we''re talking about continuous outcome predictions
    or variables, everything that we''ve talked about in this book still applies:
    the main difference, though, is going to be in terms of how we end up combining
    predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, in this example, we can see that we built three models and we have predictions
    from each one of those models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad40d5e6-8fe5-40fd-bc5f-7e856ee27814.png)'
  prefs: []
  type: TYPE_IMG
- en: When we want to combine the predictions, all we do is take a mathematical average.
    The mean of these previous models ends up being the combined prediction because
    we're not predicting individual categories as we were when we had a categorical
    outcome variable. Instead, we're predicting actual numeric values and if we want
    to combine predictions from these different models, all we do, simply, is take
    the average of the models. For example, in the first row, the first model predicted
    a value of 7, the next model predicted a value of 9, and the third model predicted
    8\. We take those values, we add them up, we divide them by the number of models,
    and the combined prediction ends up being a value of 8\. That's the way you would
    combine your models.
  prefs: []
  type: TYPE_NORMAL
- en: But when we have continuous outcome variables, we do not have a confidence value,
    so we don't need to worry about the actual confidence values for those kind of
    models.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we're going to use the bank dataset. Bring it onto the canvas.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s just take a look at what that data looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/18a8aa3b-bba8-444d-87c8-02eae8cf61f7.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, there are several fields. We will predict a variable, salnow,
    that's our target variable based on a beginning salary, gender, the amount of
    time that someone has worked at this organization, their age, their level of education,
    the number of years that they have worked prior to coming to this organization,
    the job category that they're in, whether they're from a minority, and then the
    interaction of race and gender.
  prefs: []
  type: TYPE_NORMAL
- en: Partition the dataset and go on to create a Neural Net model. Run the Neural
    Net model with default settings. Take a look at the newly generated model.
  prefs: []
  type: TYPE_NORMAL
- en: Let's also build the SVM model just as we have done before. We will compare
    the results of both the models.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the output for the SVM model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/03c2bef9-241f-4f8f-b2a5-117d41fde46f.png)'
  prefs: []
  type: TYPE_IMG
- en: Connect the two generated models and connect the SVM model to a Table and run
    the table.
  prefs: []
  type: TYPE_NORMAL
- en: Scroll towards the end and you can see a Partition node and predictions of the
    two models. Notice that there are no confidence values for these continuous outcome
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'This also means that we won''t get the propensity scores for these models either.
    Bring an Analysis node and connect the SVM model to the Analysis node and run
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/58d64813-3dec-4fb2-9ba9-5d2a57a92a97.png)'
  prefs: []
  type: TYPE_IMG
- en: The analysis is a little bit different than what we used to get with the categorical
    variables. You can see that there is a Minimum Error, and a Maximum Error for
    both the training and the testing datasets. The model has done a worst job in
    over- or under-predicting the values.
  prefs: []
  type: TYPE_NORMAL
- en: Mean Error is just averaging of the errors. The best way to look at the accuracy
    of these models is by looking at the Mean Absolute Error. As you can see, we have
    a lower value for the training dataset as compared to the testing dataset. These
    values need to be similar. You can see the mean absolute value for the SVM model.
    You can also see the Standard Deviation. This needs to be as small as possible
    because this shows that we have less variation in the model. Another criterion
    is the correlation coefficient. That is extremely high for both the datasets;
    these values must be similar to each other. People use linear coefficients to
    validate the usefulness of a model, but sometimes we don't have linear relationships.
    So, in such cases, we will use the mean absolute error value as the best measure
    of assessing how the model is performing. **Occurrences** are the number of cases
    that we have for each dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now combine the model:'
  prefs: []
  type: TYPE_NORMAL
- en: Connect the last generated node to an ensemble node from the Field Ops palette.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edit the Ensemble node. Deselect the Filter out field and click OK.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the Ensemble node to the Table node already present and run the Table.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can see that we have predictions from the SVM, Neural Net, and if we average
    those two, we have the predictions from the combined model. We also have our standard
    errors as well. For those who are not using modeler, a Derive node can be used
    to calculate the averages of these models and get a combined result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To see the results, connect the Ensembles node to an Analysis node and run
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ce42d8e1-d88d-47ea-90ef-56caf40e7293.png)'
  prefs: []
  type: TYPE_IMG
- en: This was an example of how we can work with continuous variables.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how we can make additional advance operations on models
    to get better results. Hopefully, you have a deeper insight into how data is fetched
    to train a machine and how we can make a better model by training it on different
    types of data.
  prefs: []
  type: TYPE_NORMAL
