<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Data Science Process</h1>
                </header>
            
            <article>
                
<p>Over the past decade, organizations have seen a rapid growth in data. Harnessing insight from that data is crucial to the growth and sustenance of these organizations. Yet, groups chartered with extracting value from data fail for various reasons. In this chapter, we will cover how organizations can avoid the potential pitfalls of data science.</p>
<p>There is a larger discussion about the quality and governance of data, which we will not be covering here. Experienced data scientists recognize the challenges with data and account for them in their processes. In general, some of these challenges include the following:</p>
<ul>
<li>Poor data quality and consistency</li>
<li>Silos of data driven by individual business teams</li>
<li>Technologies that are hard ...</li></ul></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">TDSP stages</h1>
                </header>
            
            <article>
                
<p>The <strong>Team Data Science Process</strong> (<strong>TDSP</strong>) is a methodology created by Microsoft to guide the full life cycle of data science projects in organizations. It is not meant to be a complete solution, but simply a framework by which teams can add structure to their processes and achieve the full business value of their analytics.</p>
<p>Besides TDSP, the other prevalent methodology that organizations have been adopting is called <strong>CRISP-DM</strong> (short for <strong>Cross-Industry Standard Process for Data Mining</strong>). This methodology has been around since the mid-1990s. There were several attempts to update it in the 2000s, but they were abandoned. The primary focus of CRISP-DM was data mining, but its principles can be extended to data science as well. The major steps listed in CRISP-DM are as follows: business understanding, data understanding, data preparation, modeling, evaluation, and deployment. For practitioners, these steps may seem redundant, but for organizations that are new to deriving value from data, this is a great framework to build a process around. In fact, a lot of the data science tools released on the market by various vendors inherently have functionality that drives users through these steps.</p>
<p>There are several gaps in the CRISP-DM methodology when applied to data science. The most glaring one is the need to connect business outcomes with every step of the process. Challenges in data quality, data sources, biases, algorithm quality, and scalability need to be addressed beyond what is listed here.</p>
<p>TDSP is not an alternative to CRISP-DM, but can be viewed as an additional framework that can be augmented to include existing workflows around data. TDSP is more task-focused, but shares some of the same concepts at a high level with CRISP-DM.</p>
<p>One of the core tenets of TDSP is that the outcome of the data science life cycle a<span>s shown in the following diagram </span>is intelligent applications that deliver value to the business. New data science projects can leverage portions of TDSP with the expectation that they will graduate as they become more mature and leverage the other steps of the process. In that sense, TDSP is meant to be iterative and agile. Depending on the nature and maturity of the project, some processes can be eliminated.</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-855 image-border" src="Images/cfc4ea6a-af97-4bc1-be15-49e0882fd254.png" style="width:162.50em;height:107.17em;" width="1950" height="1286"/></p>
<p>There are five broad stages defined in TDSP, as follows:</p>
<ul>
<li>Business understanding</li>
<li>Data acquisition and understanding</li>
<li>Modeling</li>
<li>Deployment</li>
<li>Customer acceptance</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Business understanding</h1>
                </header>
            
            <article>
                
<p>In this stage of TDSP, there are two tasks that drive its goals:</p>
<ul>
<li>Defining objectives</li>
<li>Identifying data sources</li>
</ul>
<p>Let's break down and analyze each of these tasks and look at how they help derive business understanding.</p>
<p>The defining objectives task includes the following factors:</p>
<ul>
<li><strong>Model targets</strong>: The success of the project is driven by the business goal, which is, in turn, driven by some variable(s) tracked during the analysis. These variables are called <strong>model targets</strong>, and there may be multiple metrics associated with the model targets that predicate their success. An example of frequently used model targets are revenue forecasts, or the probability of a transaction being fraudulent.</li>
<li><strong>Relevant questions</strong>: You can define ...</li></ul></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Deliverable</h1>
                </header>
            
            <article>
                
<p>The deliverable as follows:</p>
<ul>
<li><strong>Charter document</strong>: This document is used to keep track of the various aspects of the project. These include business background, scope, personnel, plan, architecture, metrics, and communication. A template for this document is provided here: <a href="https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Charter.md">https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Charter.md</a>.</li>
<li><strong>Data sources</strong>: This document describes all the data sources and any required transformations to incorporate them into the project. Any processed data or engineered features are also kept track of. A template of this deliverable is shown here: <a href="https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Data_Report/Data%20Defintion.md">https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Data_Report/Data%20Defintion.md</a>.</li>
<li><strong>Data dictionaries</strong>: This document provides detailed descriptions for each of the data sources. This may include table schemas and data types with examples. A template for this deliverable is provided here: <a href="https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/Data_Dictionaries">https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/Data_Dictionaries</a>.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Data acquisition and understanding</h1>
                </header>
            
            <article>
                
<p>In this stage of TDSP, there are three tasks that drive its goals:</p>
<ul>
<li><strong>Ingest data</strong>: To make the exploration and modeling of the data easier, it is ideal to have the source data moved into a single analytics system as much as possible. Within Azure, the ability to move data across the different services is made easy through various tools, keeping these kinds of use cases in mind.</li>
</ul>

<ul>
<li><strong>Explore data</strong>: Understanding the nature of the data is key to successful analytics projects. In most organizations, data comes with a lot of flaws: outliers, missing values, bad values, and so on. Visualizing the data and analyzing the characteristics of the data is a prerequisite for successful data science projects. This is also ...</li></ul></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Deliverable</h1>
                </header>
            
            <article>
                
<p><span>The deliverable as follows:</span></p>
<ul>
<li><strong>Data quality report</strong>: The IDEAR tool can help create reports that summarize the source data and target variable.</li>
<li><strong>Solution architecture</strong>: At this stage of the project, a diagram or description of the data flow can be drawn to show the scoring and retraining (if needed) of pipelines.</li>
<li class="mce-root"><strong>Checkpoint decision</strong><span>: Based on the initial evaluation of the data, you can make a decision regarding whether to pursue the project beyond this phase. If the expected business value is not clear at this stage, a decision can be made on getting additional data or discontinuing the project. In some cases, the stakeholders might consider reframing.</span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Modeling</h1>
                </header>
            
            <article>
                
<p>In this stage, there are three main tasks that deliver its goals:</p>
<ul>
<li><strong>Feature engineering</strong>: In many use cases, the raw data by itself may not be a good indicator of the target variable. Depending on the algorithms being used, it may be necessary to transform some data features into new features that allow its effective use.</li>
</ul>
<p style="padding-left: 60px">This task is considered part of the art of effective data science projects. It requires an effective combination of the insights obtained from the data exploration task and domain expertise. There is also the predicament of picking the correct number of features to build the model. Using too many variables may add unnecessary noise to the model, while choosing too few may not accurately predict the target variable(s). ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Deliverable</h1>
                </header>
            
            <article>
                
<p><span>The deliverable as follows:</span></p>
<ul>
<li><strong>Feature sets</strong>: The features chosen to build the model are recorded as part of the Data Definition report. If any of the features are generated from the raw data, the code to generate the features is recorded in this report.</li>
<li><strong>Model report</strong>: A standard report will show how each model performed against the various metrics. These metrics may include accuracy metrics, as well as the speed and efficiency of the model.</li>
<li><strong>Checkpoint</strong>: Evaluate the performance of the model and determine whether it is good enough to deploy to production systems.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Deployment</h1>
                </header>
            
            <article>
                
<p>The main tasks involved in this stage are to deploy the model and the data pipeline into a production-like environment for consumption by an application.</p>
<p>Once you have a model or collection of models that deliver the required business metrics, you can operationalize them for different applications. Models are typically exposed by some API interface that allows the application to interact with them and generate predictions for various inputs. These APIs can typically handle batch or real-time, or a hybrid of these two, for its input data. The web service itself will be typically resilient, robust, and scalable. This is achieved by keeping track of various metrics of the web service to keep track of the load on the service and help ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Deliverable</h1>
                </header>
            
            <article>
                
<p>The deliverable as follows:</p>
<ul>
<li>A dashboard that shows the health and key metrics of the prediction system</li>
<li>A modeling report that shows the deployment details</li>
<li>A solution architecture document capturing the various components of the solution</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Customer acceptance</h1>
                </header>
            
            <article>
                
<p>The main tasks involved in this stage are as follows:</p>
<ul>
<li><strong>System validation</strong>: Confirming that the deployed model and data pipeline meet the stakeholders needs</li>
<li><strong>Project hand-off</strong>: Hand the system off to the group that is going to run the system in production</li>
</ul>
<p>The customer should verify that the end-to-end solution meets the business needs as defined in the initial business understanding phase. Does the system make timely predictions that satisfy the metrics chosen for the application?</p>
<p>All the documentation is reviewed and finalized and handed off to the group in charge of running operations. This group will be responsible for taking the work done thus far and maintaining it over its life cycle.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Deliverable</h1>
                </header>
            
            <article>
                
<p>An exit report for the project is delivered at the end of this stage. It contains all the details of the project that are required to operate and maintain the system to its full design potential. A template of the exit report is provided here: <a href="https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md">https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md</a>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Tools for TDSP</h1>
                </header>
            
            <article>
                
<p>Microsoft has released a set of tools that make it easier for organizations to follow the TDSP process. One of those tools is the IDEAR utility released for CRAN-R, Microsoft R, and Python. Another tool is the <strong>Automated Modeling and Reporting</strong> (<strong>AMAR</strong>) utility. In this section, we will look into how we can leverage these tools in the TDSP process.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">IDEAR tool for R</h1>
                </header>
            
            <article>
                
<p>To install this tool, navigate to <a href="https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils/R/Run-IDEAR.R">https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils/R/Run-IDEAR.R</a> in order to retrieve the code required for this tool. Download the GitHub repository to make it easier to navigate the different files required for this exercise.</p>
<p>Open R Studio on your computer, navigate to the preceding file, and open it. In the top-right corner of the code tab, click on <span class="packt_screen">Source</span> to execute the package, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-934 image-border" src="Images/683781cb-40c2-4c95-a371-57cd37c25c63.png" style="width:120.00em;height:51.08em;" width="1440" height="613"/></p>
<p>Then, the following prompt will be shown:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/6b75f3c9-9cdc-4fd2-ac92-aca93dd2faf0.png" style="width:33.92em;height:12.58em;" width="784" height="285"/></p>
<p>An example <kbd>.yaml</kbd> file can be loaded from the following location. Select <kbd>para-adult.yaml</kbd> as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/fbfbbfb7-3925-40b1-8900-175631dbe2dd.png" width="737" height="498"/></p>
<p>This will open a data quality report for the data example described in the YAML file, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/9a2d7744-d074-4baf-b883-7a5ae352fef9.png" width="1914" height="574"/></p>
<p class="mce-root"/>
<p>You can use the menu on the left-hand side to navigate through the different sections of the output. The first section is the <span class="packt_screen">Task Summary</span>, which gives a summary of the file read by listing the file location, the names of the different types of variables, and the data science task type (for example, classification):</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/f8377493-c0fa-4cd5-b74c-6804265c2232.png" width="1272" height="378"/></p>
<p>Click on <span class="packt_screen">Data Summary</span> to get to the next section. Under 2.1 in the following screenshot, you can see a sample of the data by picking the top n number of rows desired:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-936 image-border" src="Images/1d573a0f-259c-41c2-95bd-e0848150721e.png" style="width:101.33em;height:52.92em;" width="1216" height="635"/></p>
<p>This is a great way to visually examine the data that is loaded for discrepancies. Section 2.2 of the following screenshot shows a summary of the data by counting the number of rows and columns:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/385d97ee-8ae4-47ae-aa59-6f5e54d7bf06.png" style="width:41.08em;height:11.92em;" width="877" height="239"/></p>
<p>In Section 2.3, the report displays the names and types of the columns, indicating whether they are numeric or categorical:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/9254bdff-b9ac-4f68-8b9e-ca22205d7465.png" style="width:31.83em;height:32.67em;" width="692" height="709"/></p>
<p>Section 2.4 of the report examines the quality of the data. This report maps the percentage of missing data for each of the variables. The heat map formatting helps to detect any missing data pattern:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/5c3f7855-a778-42d4-97c2-bb4c4801b7b3.png" width="1218" height="922"/></p>
<p>Section 2.5 summarizes the basic statistics of the data by showing the percentiles for the numeric data and the frequency count for the categorical data:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/66b52eb6-c4e1-419b-a710-ba73b019913b.png" width="1230" height="748"/></p>
<p>Now we move on to Section 3, where we dive deeper into each of the individual variables to investigate them further. In Section 3.1, you can see more detailed statistics of each variable:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/f1eecfd2-e544-4242-a3fc-2d53685af2ad.png" width="1224" height="811"/></p>
<p>In Section 3.2, you can visualize the target variable:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-943 image-border" src="Images/fe0b7459-cd7b-4f9a-938e-09c63214f727.png" style="width:90.50em;height:62.42em;" width="1086" height="749"/></p>
<p>In Section 3.3, you can visualize any of the numerical variables and look at quantiles and the distribution of the data:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-944 image-border" src="Images/ca646959-ec01-47b0-b3cf-d6d54518cc7b.png" style="width:98.50em;height:69.25em;" width="1182" height="831"/></p>
<p>In Section 3.4, you can visualize the categorical variables, showing the frequency of the distinct categories within them:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/2afe3a8a-4cf2-4aba-9708-497394e4fa09.png" width="1204" height="852"/></p>
<p>In Section 4, the report helps you to analyze the relationship between the different variables. This is important for understanding which variables are important for building the model, and which can be dropped. In Section 4.1, you can rank the impact of the variables relative to a reference variable:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/2ad08159-539b-47a5-a99c-67efc00ba918.png" width="1219" height="856"/></p>
<p>In Section 4.2, you can examine the correlation between two categorical variables. For example, in the following plot, we see that males have more income than females:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-945 image-border" src="Images/d134c73b-99c2-4113-8bbc-c7e76c94c36d.png" style="width:94.42em;height:65.33em;" width="1133" height="784"/></p>
<p>Similarly, in Section 4.3, you can see the interaction between two numerical variables:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/2783e63c-09ce-408b-9fd5-e2a4f04ceb1a.png" width="1205" height="759"/></p>
<p>In Section 4.4, you can use different correlation methods to calculate the correlation between numerical variables:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/952259a7-a935-4a40-8a68-24664e5ce2ce.png" width="1204" height="948"/></p>
<p>In Section 4.5, you can visualize the interactions between numerical and categorical variables using box plots:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/37e71ad1-3d5c-4842-b5e1-63b476ee4691.png" width="1170" height="732"/></p>
<p>The next three sections focus on multivariate statistics. Section 4.6 leverages <strong>Principal Component Analysis</strong> (<strong>PCA</strong>) to look at the distribution of data in a reduced variable space:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/adb63ce8-389f-4810-9b35-4f2337a775dc.png" width="1242" height="870"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In Section 4.7, you can project numerical variables to 2D space using the t-SNE method. In Section 4.8, you can project both numerical and categorical variables to PCA and visualize them simultaneously:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/d915a61d-ce98-43f2-a66d-3fba6f17fc82.png" width="1269" height="858"/></p>
<p>In Section 5, if you click on the <span class="packt_screen">Generate Report </span><span>button,</span> it will create a summary report with all the summaries from the preceding sections.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Automated modeling and reporting (AMAR) in R</h1>
                </header>
            
            <article>
                
<p>The AMR tool is a customizable, semi-automated utility built into R to train and evaluate single or multiple machine learning models. It has features such as parameter sweeping to find the model that fits the desired metrics.</p>
<p>Once the report is generated, it contains the following information:</p>
<ul>
<li>A model description</li>
<li>A model evaluation and comparison</li>
<li>A ranking of the features</li>
</ul>
<p>In general, the information described in the report can help increase the following:</p>
<ul>
<li>The quality of the feature variables</li>
<li>The level of difficulty for the machine learning task</li>
<li>Guidance for subsequent feature engineering and modeling</li>
</ul>
<p>The AMAR tool is available at the following GitHub location: <a href="https://github.com/Azure/Azure-TDSP-Utilities/tree/master/DataScienceUtilities/Modeling">https://github.com/Azure/Azure-TDSP-Utilities/tree/master/DataScienceUtilities/Modeling ...</a></p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In conclusion, we have introduced you to the TDSP in this chapter and covered each of the different steps that are involved <span>in detail</span>. This process is meant to augment other existing processes rather than replace them. We also looked at various TDSP utilities that Microsoft has provided that make it easier to build some structure into the data science life cycle. In the next few chapters, we will look at each of the options available within Azure to build AI solutions for your business needs.</p>


            </article>

            
        </section>
    </div>



  </body></html>