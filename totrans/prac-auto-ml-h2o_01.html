<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer018">
<h1 class="chapter-number" id="_idParaDest-15"><a id="_idTextAnchor017"/>1</h1>
<h1 id="_idParaDest-16"><a id="_idTextAnchor018"/>Understanding H2O AutoML Basics </h1>
<p><strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) is the process of building analytical<a id="_idIndexMarker000"/> or statistical models using computer systems that learn from historical data and identify patterns in them. These systems then use these patterns and try to make predictive decisions that can provide value to businesses and research alike. However, the sophisticated mathematical knowledge required to implement an ML system that can provide any concrete value has discouraged several people from experimenting with it, leaving tons of undiscovered potential that they could have benefited from.</p>
<p><strong class="bold">Automated Machine Learning</strong> (<strong class="bold">AutoML</strong>) is one of the latest ML technologies that has accelerated <a id="_idIndexMarker001"/>the adoption of ML by organizations of all sizes. It is the process of automating all these complex tasks involved in the ML life cycle. AutoML hides away all these complexities and automates them behind the scenes. This allows anyone to easily implement ML without any hassle and focus more on the results.</p>
<p>In this chapter, we will learn about one such AutoML technology by H2O.ai (<a href="https://www.h2o.ai/">https://www.h2o.ai/</a>), which is simply named H2O AutoML. We will provide a brief history of AutoML in general and what problems it solves, as well as a bit about H2O.ai and its H2O AutoML technology. Then, we will code a simple ML implementation using H2O’s AutoML technology and build our first ML model.</p>
<p>By the end of this chapter, you will understand what exactly AutoML is, the company H2O.ai, and its technology H2O AutoML. You will also understand what minimum requirements are needed to use H2O AutoML, as well as how easy it is to train your very first ML model using H2O AutoML without having to understand any complex mathematical rocket science.</p>
<p>In this chapter, we are going to cover the following topics:</p>
<ul>
<li>Understanding AutoML and H2O AutoML</li>
<li>Minimum system requirements to use H2O AutoML</li>
<li>Installing Java</li>
<li>Basic implementation of H2O using Python</li>
<li>Basic implementation of H2O using R</li>
<li>Training your first ML model using H2O AutoML</li>
</ul>
<h1 id="_idParaDest-17"><a id="_idTextAnchor019"/>Technical requirements</h1>
<p>For this chapter, you will need the following:</p>
<ul>
<li>A decent web browser (Chrome, Firefox, or Edge), the latest version of your preferred web browser.</li>
<li>An <strong class="bold">Integrated Development Environment</strong> (<strong class="bold">IDE</strong>) of your choice</li>
<li>Jupyter Notebook by Project Jupyter (<a href="https://jupyter.org/">https://jupyter.org/</a>) (optional)</li>
</ul>
<p>All the code examples for this chapter can be found on GitHub at <a href="https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%201">https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%201</a>.</p>
<h1 id="_idParaDest-18"><a id="_idTextAnchor020"/>Understanding AutoML and H2O AutoML</h1>
<p>Before we begin our journey with H2O AutoML, it is important to understand what exactly AutoML is and what part it plays in the entire ML pipeline. In this section, we will try to understand the various steps involved in the ML pipeline and where AutoML fits into it. Then, we will explore what makes H2O’s AutoML so unique among the various AutoML technologies.</p>
<p>Let’s start by learning a bit about AutoML in general.</p>
<h2 id="_idParaDest-19"><a id="_idTextAnchor021"/>AutoML</h2>
<p>AutoML is the process of automating<a id="_idIndexMarker002"/> the various steps that are performed while developing a viable ML system for predictions. A typical ML pipeline consists of the following steps:</p>
<ol>
<li><strong class="bold">Data Collection</strong>: This is the very first step<a id="_idIndexMarker003"/> in an ML pipeline. Data is collected from various sources. The sources can generate different types of data, such as categorical, numeric, textual, time series, or even visual and auditory data. All these types of data are aggregated together based <a id="_idIndexMarker004"/>on the requirements and are merged into a common structure. This could be a comma-separated value file, a parquet file, or even a table from a database.</li>
<li><strong class="bold">Data Exploration</strong>: Once data has been collected, it is explored <a id="_idIndexMarker005"/>using basic analytical techniques to identify what it contains, the completeness and correctness of the data, and if the data shows potential patterns that can build a model.</li>
<li><strong class="bold">Data Preparation</strong>: Missing values, duplicates, and noisy data can all affect the quality of the model<a id="_idIndexMarker006"/> as they introduce incorrect learning. Hence, the raw data that is collected and explored needs to be pre-processed to remove all anomalies using specific data processing methods.</li>
<li><strong class="bold">Data Transformation</strong>: A lot of ML models work<a id="_idIndexMarker007"/> with different types of data. Some can work with categorical data, while some can only work with numeric data. That is why you may need to convert certain types of data from one form into the other. This allows the dataset to be fed properly during model training.</li>
<li><strong class="bold">Model Selection</strong>: Once the dataset is ready, an ML model<a id="_idIndexMarker008"/> is selected to be trained. The model is chosen based on what type of data the dataset contains, what information is to be extracted from the dataset, as well as which model suits the data. </li>
<li><strong class="bold">Model Training</strong>: This is where the model<a id="_idIndexMarker009"/> is trained. The ML system will learn from the processed dataset and create a model. This training can be influenced by several factors, such as data attribute weighting, learning rate, and other hyperparameters.</li>
<li><strong class="bold">Hyperparameter Tuning</strong>: Apart from model training, another<a id="_idIndexMarker010"/> factor that needs to be considered is the model’s architecture. The model’s architecture depends on the type of algorithm used, such as the number of trees in a random forest or neurons in a neural network. We don’t immediately know which architecture is optimal for a given model, so experimentation<a id="_idIndexMarker011"/> is needed. The parameters<a id="_idIndexMarker012"/> that define the architecture of a model are called hyperparameters; finding the best combination of hyperparameter values is known as <strong class="bold">hyperparameter tuning</strong>. </li>
<li><strong class="bold">Prediction</strong>: The final step of the ML pipeline<a id="_idIndexMarker013"/> is prediction. Based on the patterns in the dataset that were learned by the model during training, the model can now make a generalized prediction on unseen data.</li>
</ol>
<p>For non-experts, all these steps and their complexities can be overwhelming. Every step in the ML pipeline process has been developed over years of research and there are vast topics within themselves. AutoML<a id="_idIndexMarker014"/> is the process that automates the majority of these steps, from data exploration to hyperparameter tuning, and provides the best possible models to make predictions on. This helps companies focus on solving real-world problems with results rather than ML processes and workflows.</p>
<p>Now that you understand the different steps in an ML pipeline and how the steps are automated by AutoML, let’s see why H2O’s AutoML technology is one of the leading technologies in the industry.</p>
<h2 id="_idParaDest-20"><a id="_idTextAnchor022"/>H2O AutoML</h2>
<p>H2O AutoML is an AutoML software technology<a id="_idIndexMarker015"/> developed by H2O.ai that simplifies how ML systems are developed by providing user-friendly interfaces that help non-experts experiment with ML. It is an in-memory, distributed, fast, and scalable ML and analytics platform that works on big data and can be used for enterprise needs.</p>
<p>It is written in Java and uses key-value storage to access data, models, and other ML objects that are involved. It runs on a cluster system and uses the multi-threaded MapReduce framework to parallelize data operations. It is also easy to communicate with it as it uses simple REST APIs. Finally, it has a web interface that provides a detailed graphical view of data and model details.</p>
<p>Not only does H2O AutoML automate<a id="_idIndexMarker016"/> the majority of the sophisticated steps involved in the ML life cycle, but it also provides a lot of flexibility for even expert data scientists to implement specialized model training processes. H2O AutoML provides a simple wrapper function that encapsulates several of the model training tasks that would otherwise be complicated to orchestrate. It also has extensive explainability functions that can describe the various details of the model training life cycle. This provides easy-to-export details of the models that users can use to explain the performance and justifications of the models that have been trained.</p>
<p>The best part about H2O AutoML is that it is entirely open source. You can find H2O’s source code at <a href="https://github.com/h2oai">https://github.com/h2oai</a>. It is actively maintained by a community of developers serving in both open as well as closed sources companies. At the time of writing, it is on its third major version, which indicates that it is quite a mature technology and is feature-intensive – that is, it supports several major companies in the world. It also supports several programming languages, including R, Scala, Python, and Java, that can run on several operating systems and provides support for a wide variety of data sources that are involved in the ML <a id="_idIndexMarker017"/>life cycle, such as Hadoop Distributed File System, Hive, Amazon S3, and even <strong class="bold">Java Database Connectivity</strong> (<strong class="bold">JDBC</strong>).</p>
<p>Now that you understand the basics of AutoML and how powerful H2O AutoML is, let’s see what the minimum requirements are for a system to run H2O AutoML without any performance issues.</p>
<h1 id="_idParaDest-21"><a id="_idTextAnchor023"/>Minimum system requirements to use H2O AutoML</h1>
<p>H2O is very easy to install, but certain<a id="_idIndexMarker018"/> minimum standard requirements need to be met for it to run smoothly and efficiently. The following are some of the minimum requirements needed by H2O in terms of hardware capabilities, along with other software support:</p>
<ul>
<li> The minimum hardware required by H2O is as follows:<ul><li><strong class="bold">Memory</strong>: H2O runs on an in-memory architecture, so it is limited by the physical memory of the system that uses it. Thus, to be able to process huge chunks of data, the more memory the system, has the better.</li><li><strong class="bold">Central Processing Unit</strong> (<strong class="bold">CPU</strong>): By default, H2O will use the maximum available CPUs of the system. However, at a minimum, it will need 4 CPUs.</li><li><strong class="bold">Graphical Processing Unit</strong> (<strong class="bold">GPU</strong>): GPU support is only available for XGBoost models in AutoML if the GPUs are NVIDIA GPUs (GPU Cloud, DGX Station, DGX-1, or DGX-2) or if it is a CUDA 8 GPU.</li></ul></li>
<li>The operating systems<a id="_idIndexMarker019"/> that support H2O are as follows:<ul><li><strong class="bold">Ubuntu 12.04</strong></li><li><strong class="bold">OS X 10.9 or later</strong></li><li><strong class="bold">Windows 7 or later</strong></li><li><strong class="bold">CentOS 6 or later</strong></li></ul></li>
<li>The programming languages that support H2O are as follows:<ul><li><strong class="bold">Java</strong>: Java is mandatory for H2O. H2O requires a 64-bit JDK to build H2O and a 64-bit JRE to run its binary: <ul><li><strong class="bold">Java versions supported</strong>: Java SE 15, 14, 13, 12, 11, 10, 9, and 8</li></ul></li><li><strong class="bold">Other Languages</strong>: The following languages are only required if H2O is being run in those environments:<ul><li>Python 2.7.x, 3.5.x, or 3.6.x</li><li>Scala 2.10 or later</li><li>R version 3 or later</li></ul></li></ul></li>
<li><strong class="bold">Additional requirements</strong>: The following requirements are only needed if H2O is being run in these environments:<ul><li><strong class="bold">Hadoop</strong>: Cloudera CDH 5.4 or later, Hortonworks HDP 2.2 or later, MapR 4.0 or later, or IBM Open Platform 4.2</li><li><strong class="bold">Conda</strong>: 2.7, 3.5, or 3.6</li><li><strong class="bold">Spark</strong>: Version 2.1, 2.2, or 2.3</li></ul></li>
</ul>
<p>Once we have a system that meets the minimum requirements, we need to focus on H2O’s functional dependencies on other software. H2O has only one dependency and that is Java. Let’s see why<a id="_idIndexMarker020"/> Java is important for H2O and how we can download and install the correct supported Java version.</p>
<h1 id="_idParaDest-22"><a id="_idTextAnchor024"/>Installing Java</h1>
<p>H2O’s core code is written in Java. It needs <strong class="bold">Java Runtime Environment</strong> (<strong class="bold">JRE</strong>) installed in your system<a id="_idIndexMarker021"/> to spin up an H2O server cluster. H2O also trains<a id="_idIndexMarker022"/> all the ML algorithms in a multi-threaded manner, which uses the Java Fork/Join framework on top of its MapReduce framework. Hence, having the latest Java version that is compatible with H2O to run H2O smoothly is highly recommended.</p>
<p>You can install the latest stable<a id="_idIndexMarker023"/> version of Java from <a href="https://www.oracle.com/java/technologies/downloads/">https://www.oracle.com/java/technologies/downloads/</a>.</p>
<p>When installing Java, it is important to be aware of which bit version your system runs on. If it is a 64-bit version, then make sure you are installing the 64-bit Java version for your operating system. If it is 32-bit, then go for the 32-bit version.</p>
<p>Now that we have installed the correct Java version, we can download and install H2O. Let’s look at a simple example of how we can do that using Python.</p>
<h1 id="_idParaDest-23"><a id="_idTextAnchor025"/>Basic implementation of H2O using Python</h1>
<p>Python is one of the most popular<a id="_idIndexMarker024"/> languages in the ML field of computer <a id="_idIndexMarker025"/>programming. It is widely used in all industries and has tons of actively maintained ML libraries that provide a lot of support in creating ML pipelines.</p>
<p>We will start by installing the Python programming language and then installing H2O using Python.</p>
<h2 id="_idParaDest-24"><a id="_idTextAnchor026"/>Installing Python</h2>
<p>Installing Python is very straightforward. It does<a id="_idIndexMarker026"/> not matter whether it is Python 2.7 or Python 3 and above as H2O works completely fine with both versions of the language. However, if you are using anything older than Python 2.7, then you will need to upgrade your version.</p>
<p>It is best to go with Python 3 as it is the current standard and Python 2.7 is outdated. Along with Python, you will also need <strong class="source-inline">pip</strong>, Python’s package manager. Now, let’s learn how to install Python on various operating systems:</p>
<ul>
<li>On Linux (Ubuntu, Mint, Debian): <ul><li>For Python 2.7, run the following command in the system Terminal:<p class="source-code"><strong class="bold">sudo apt-get python-pip </strong></p></li><li>For Python 3, run the following command in the system Terminal: <p class="source-code"><strong class="bold">sudo apt-get python3-pip</strong></p></li></ul></li>
<li>On macOS: macOS version<a id="_idIndexMarker027"/> 10.8 comes with Python 2.7 pre-installed. If you want to install Python 3, then go to https://python.org, go to the <strong class="bold">Downloads</strong> section, and download the latest version of Python 3 for macOS.</li>
<li>On Windows: Unlike macOS, Windows does not come with any pre-installed Python language support. You will need to download a Python installer for Windows from <a href="https://python.org">https://python.org</a>. The installer will depend on your Windows operating system – that is, if it is 64-bit or 32-bit.</li>
</ul>
<p>Now that you know how to install the correct version of Python, let’s download and install the H2O Python module using Python.</p>
<h2 id="_idParaDest-25"><a id="_idTextAnchor027"/>Installing H2O using Python</h2>
<p>H2O has a Python module<a id="_idIndexMarker028"/> available in the Python package index. To install the <strong class="source-inline">h2o</strong> Python<a id="_idIndexMarker029"/> module, all you need to do is to execute the following command in your Terminal:</p>
<p class="source-code">pip install h2o</p>
<p>And that’s pretty much it.</p>
<p>To test if it has been successfully downloaded and installed, follow these steps:</p>
<ol>
<li value="1">Open your Python Terminal.</li>
<li>Import the <strong class="source-inline">h2o</strong> module by running the following command:<p class="source-code">import h2o</p></li>
<li>Initialize H2O to spin up a local <strong class="source-inline">h2o</strong> server by running the following command:<p class="source-code">h2o.init()</p></li>
</ol>
<p>The following screenshot<a id="_idIndexMarker030"/> shows the results you should <a id="_idIndexMarker031"/>get after initializing <strong class="source-inline">h2o</strong>:</p>
<div>
<div class="IMG---Figure" id="_idContainer011">
<img alt="Figure 1.1 – H2O execution using Python " height="321" src="image/B17298_01_001.jpg" width="715"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> </p>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – H2O execution using Python</p>
<p>Let’s have a quick look at the output we got. First, it ran successfully, so mission accomplished.</p>
<p>After executing <strong class="source-inline">h2o.init()</strong> by reading the output logs, you will see that H2O checked if there is already an H2O server instance running on localhost with port 54321. In this scenario, there wasn’t any H2O server instance running previously, so H2O attempted to start a local server on the same port. If it had found an already existing local H2O instance on the port, then it would have reused the same instance for any further H2O command executions. </p>
<p>Then, it used Java version 16 to start the H2O instance. You may see a different Java version, depending on which version you have installed in your system. </p>
<p>Next, you will see the location of the <strong class="source-inline">h2o jar</strong> file that the server<a id="_idIndexMarker032"/> was started from, followed by the location of the <strong class="bold">Java Virtual Machine</strong> (<strong class="bold">JVM</strong>) logs.</p>
<p>Once the server is up<a id="_idIndexMarker033"/> and running, it shows the URL of the H2O server locally<a id="_idIndexMarker034"/> hosted on your system and the status of the H2O Python library’s connection to the server. </p>
<p>Lastly, you will see some basic metadata regarding the server’s configuration. This metadata may be slightly different from what you see in your execution as it depends a lot on the specifications of your system. For example, by default, H2O will use all the cores available on your system for processing. So, if you have an 8-core system, then the <strong class="source-inline">H2O_cluster_allowed_cores</strong> property value will be <strong class="source-inline">8</strong>. Alternatively, if you decide to use only four cores, then you can execute <strong class="source-inline">h2o.init(nthreads=4)</strong> to use only four cores, reflecting the same in the server configuration output.</p>
<p>Now that you know how to implement H2O using Python, let’s learn how to do the same in the R programming language.</p>
<h1 id="_idParaDest-26"><a id="_idTextAnchor028"/>Basic implementation of H2O using R</h1>
<p>The R programming language<a id="_idIndexMarker035"/> is a very popular language in the field of ML and data science<a id="_idIndexMarker036"/> because of its extensive support for statistical and data manipulation operations. It is widely used by data scientists and data miners for developing analytical software.</p>
<p>We will start by installing the R programming language and then installing H2O using R.</p>
<h2 id="_idParaDest-27"><a id="_idTextAnchor029"/>Installing R</h2>
<p>An international team<a id="_idIndexMarker037"/> of developers maintains the R programming language. They have a dedicated web page for the R programming language called <strong class="bold">The Comprehensive R Archive Network</strong> (<strong class="bold">CRAN</strong>): <a href="https://cran.r-project.org/">https://cran.r-project.org/</a>. There are different ways<a id="_idIndexMarker038"/> of installing R, depending<a id="_idIndexMarker039"/> on what operating system you use:</p>
<ul>
<li>On Linux (Ubuntu, Mint, Debian):</li>
</ul>
<p>Execute the following command in the system Terminal:</p>
<p class="source-code"><strong class="bold">sudo apt-get instal<a id="_idTextAnchor030"/>l r-base</strong></p>
<ul>
<li>On macOS: To install R, go to <a href="https://cran.r-project.org/">https://cran.r-project.org/</a>, go to the <strong class="bold">Download R for macOS</strong> hyperlink, and download the latest release of R for macOS.</li>
<li>On Windows: Similar to how you install R on macOS, you can download the <strong class="source-inline">.exe</strong> file from <a href="https://cran.r-project.org/">https://cran.r-project.org/</a>, go to the <strong class="bold">Download R for Windows</strong> hyperlink, and download the latest release of R for Windows.</li>
</ul>
<p>Another great way of installing<a id="_idIndexMarker040"/> R on macOS and Windows is through RStudio. RStudio simplifies the installation of R-supported software and is also a very good IDE for R programming<a id="_idIndexMarker041"/> in general. You can download R studio from <a href="https://www.rstudio.com/">https://www.rstudio.com/</a>.</p>
<p>Now that you know how to install the correct version of R, let’s download and install the H2O R package using the R programming language.</p>
<h2 id="_idParaDest-28"><a id="_idTextAnchor031"/>Installing H2O using R</h2>
<p>Similar to Python, H2O provide<a id="_idIndexMarker042"/> support for the R programming language<a id="_idIndexMarker043"/> as well.</p>
<p>To install the R packages, follow these steps:</p>
<ol>
<li value="1">First, we need to download the H2O R package dependencies. For this, execute the following command in your R Terminal:<p class="source-code">install.packages(c("RCurl", "jsonlite"))</p></li>
<li>Then, to install the actual <strong class="source-inline">h2o</strong> package, execute the following command in your R Terminal:<p class="source-code">install.packages("h2o")</p></li>
</ol>
<p>And you are done.</p>
<ol>
<li value="3">To test if it has been successfully downloaded and installed, open your R Terminal, import the <strong class="source-inline">h2o</strong> library, and execute the <strong class="source-inline">h2o.init()</strong> command. This will spin up a local H2O server. </li>
</ol>
<p>The results can be seen in the following screenshot:</p>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> </p>
<div>
<div class="IMG---Figure" id="_idContainer012">
<img alt="Figure 1.2 – H2O execution using R " height="485" src="image/B17298_01_002.jpg" width="670"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – H2O execution using R</p>
<p>Let’s have a quick look at the output we got. </p>
<p>After executing <strong class="source-inline">h2o.init()</strong>, the H2O client<a id="_idIndexMarker044"/> will check if there is an H2O server instance already running<a id="_idIndexMarker045"/> on the system. The H2O server is usually run locally on port 54321 by default. If it had found an already existing local H2O instance on the port, then it would have reused the same instance. However, in this scenario, there wasn’t any H2O server instance running on port 54321, which is why H2O attempted to start a local server on the same port. </p>
<p>Next, you will see the location of the JVM logs. Once the server is up and running, the H2O client tries to connect to it and the status of the connection to the server is displayed. Lastly, you will see some basic metadata regarding the server’s configuration. This metadata may be slightly different from what you see in your execution as it depends a lot on the specifications of your system. For example, by default, H2O will use all the cores available on your system for processing. So, if you have an 8-core system, then the <strong class="source-inline">H2O_cluster_allowed_cores</strong> property value will be <strong class="source-inline">8</strong>. Alternatively, if you decide to use only four cores, then you can execute the <strong class="source-inline">h2o.init(nthreads=4)</strong> command to use only four cores, thus reflecting the same in the server configuration output.</p>
<p>Now that you know how<a id="_idIndexMarker046"/> to implement H2O using Python and R, let’s create <a id="_idIndexMarker047"/>our very first ML model and make predictions on it using H2O AutoML.</p>
<h1 id="_idParaDest-29"><a id="_idTextAnchor032"/>Training your first ML model using H2O AutoML</h1>
<p>All ML pipelines, whether they’re automated<a id="_idIndexMarker048"/> or not, eventually follow the same steps<a id="_idIndexMarker049"/> that were discussed in the <em class="italic">Understanding AutoML and H2O AutoML</em> section in this chapter.</p>
<p>For this implementation, we will be using<a id="_idIndexMarker050"/> the Iris flower dataset. This dataset can be found <a id="_idTextAnchor033"/>at <a href="https://archive.ics.uci.edu/ml/datasets/iris">https://archive.ics.uci.edu/ml/datasets/iris</a>.</p>
<h2 id="_idParaDest-30"><a id="_idTextAnchor034"/>Understanding the Iris flower dataset</h2>
<p>The Iris flower dataset, also known as Fisher’s Iris dataset, is one of the most popular multivariate datasets – that is, a dataset<a id="_idIndexMarker051"/> in which there are two or more variables that are analyzed<a id="_idIndexMarker052"/> per observation during model training. The dataset consists of 50 samples of three different varieties of the Iris flower. The features in the dataset include the length and width of the petals and sepals in centimeters. The dataset is often used for studying various classification techniques in ML because of its simplicity. The classification is performed by using the length and width of the petals and sepals as features that determine the class of the Iris flower.</p>
<p>The following screenshot shows a small sample of the dataset:</p>
<div>
<div class="IMG---Figure" id="_idContainer013">
<img alt="Figure 1.3 – Iris dataset " height="586" src="image/B17298_01_003.jpg" width="1170"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – Iris dataset</p>
<p>The columns in the dataset<a id="_idIndexMarker053"/> represent the following:</p>
<ul>
<li><strong class="bold">C1</strong>: Sepal length in cm</li>
<li><strong class="bold">C2</strong>: Sepal width in cm</li>
<li><strong class="bold">C3</strong>: Petal length in cm</li>
<li><strong class="bold">C4</strong>: Petal width in cm</li>
<li><strong class="bold">C5</strong>: Class:<ul><li>Iris-setosa</li><li>Iris-versicolour</li><li>Iris-virginica</li></ul></li>
</ul>
<p>In this scenario, <strong class="bold">C1</strong>, <strong class="bold">C2</strong>, <strong class="bold">C3</strong>, and <strong class="bold">C4</strong> represent the features that are used to determine <strong class="bold">C5</strong>, the class of the Iris flower.</p>
<p>Now that you understand the contents<a id="_idIndexMarker054"/> of the dataset that we are going to be working with, let’s implement our model training code.</p>
<h2 id="_idParaDest-31"><a id="_idTextAnchor035"/>Model training</h2>
<p><strong class="bold">Model training</strong> is the process of finding the best combination<a id="_idIndexMarker055"/> of biases and weights for a given ML algorithm so that it minimizes a loss function. A <strong class="bold">loss function</strong> is a way of measuring how far the predicted<a id="_idIndexMarker056"/> value is from the actual value. So, minimizing it indicates that the model is getting closer to making accurate predictions – in other words, it’s learning. The ML algorithm builds a mathematical representation of the relationship between the various features in the dataset and the target label. Then, we use this mathematical representation to predict the potential value of the target label for certain feature values. The accuracy of the predicted values depends a lot on the quality of the dataset, as well as the combination of weights and biases against features used during model training. However, all of this is entirely automated by AutoML and, as such, is not a concern for us.</p>
<p>With that in mind, let’s learn how to quickly and easily create an ML model using H2O in Python.</p>
<h3>Model training and prediction in Python</h3>
<p>The H2O Python module makes<a id="_idIndexMarker057"/> it easy to use H2O in a Python program. The inbuilt<a id="_idIndexMarker058"/> functions in the H2O Python<a id="_idIndexMarker059"/> module are straightforward to use and hide away a lot of the complexities of using H2O.</p>
<p>Follow these steps to train your very first model in Python using H2O AutoML:</p>
<ol>
<li value="1">Import the H2O module: <p class="source-code">import h2o</p></li>
<li>Initialize H2O to spin up a local H2O server:<p class="source-code">h2o.init()</p></li>
</ol>
<p>The <strong class="source-inline">h2o.init()</strong> command starts up or reuses an H2O server instance running locally on port 54321. </p>
<ol>
<li value="3">Now, you can import the dataset by using the <strong class="source-inline">h2o.import_file()</strong> command while passing the location of the dataset into your system. </li>
<li>Next, import the dataset<a id="_idIndexMarker060"/> by passing the location<a id="_idIndexMarker061"/> where you downloaded<a id="_idIndexMarker062"/> the dataset:<p class="source-code">data = h2o.import_file("Dataset/iris.data")</p></li>
<li>Now, you need to identify which columns of the DataFrame are the features and which are the labels. A <strong class="bold">label</strong> is something that we <a id="_idIndexMarker063"/>want to predict, while <strong class="bold">features</strong> are attributes of the label <a id="_idIndexMarker064"/>that help identify the label. We train models on these features and then predict the value of the label, given a specific set of feature values. Referring to the dataset in the <em class="italic">Understanding the Iris flower dataset</em> section, let’s set all the column names – <strong class="source-inline">C1</strong>, <strong class="source-inline">C2</strong>, <strong class="source-inline">C3</strong>, <strong class="source-inline">C4</strong>, and <strong class="source-inline">C5</strong> – as a list of features:<p class="source-code">features = data.columns</p></li>
<li>Based on our DataFrame, the <strong class="source-inline">C5</strong> column, which denotes the class of the Iris flower, is the column that we want to eventually predict once the model has been trained. Hence, we denote <strong class="source-inline">C5</strong> as the label and remove it from the remaining set of column names, which we will note as features. Set the target label and remove it from the list of features:<p class="source-code">label = "C5"</p><p class="source-code">features.remove(label)</p></li>
<li>Split the DataFrame into training and testing DataFrames:<p class="source-code">train_dataframe, test_dataframe = data.split_frame([0.8])</p></li>
</ol>
<p>The <strong class="source-inline">data.split_frame([0.8])</strong> command splits the DataFrame into two – a training DataFrame and another for testing. The training DataFrame contains 80% of the data, while the testing DataFrame contains the remaining 20%. We will use the training DataFrame to train the model and the testing DataFrame to run predictions on the model once it has been trained to test how the model performs.</p>
<p class="callout-heading">Tip</p>
<p class="callout">If you are curious as to how H2O splits the dataset based on ratios and how it randomizes the data between different splits, feel free<a id="_idIndexMarker065"/> to explore and experiment with the <strong class="source-inline">split_frame</strong> function. You can find more details at https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/_modules/h2o/frame.xhtml#H2OFrame.split_frame.</p>
<ol>
<li value="8">Initialize the<a id="_idIndexMarker066"/> H2O AutoML object. Here, we have set the <strong class="source-inline">max_model</strong> parameter to <strong class="source-inline">10</strong> to limit <a id="_idIndexMarker067"/>the number of models that will be trained<a id="_idIndexMarker068"/> by H<a id="_idTextAnchor036"/>2O, set AutoML to <strong class="source-inline">10</strong>, and set the random <strong class="source-inline">seed</strong> generator to <strong class="source-inline">1</strong>:<p class="source-code">aml=h2o.automl.H2OAutoML(max_models=10, seed = 1)</p></li>
<li>Now, trigger the AutoML training by passing in the feature columns – that is <strong class="source-inline">C1</strong>, <strong class="source-inline">C2</strong>, <strong class="source-inline">C3</strong>, and <strong class="source-inline">C4</strong> – in (<em class="italic">x</em>), the label column <strong class="source-inline">C5</strong> in (<em class="italic">y</em>), and the <strong class="source-inline">train_dataframe</strong> DataFrame using the <strong class="source-inline">aml.train()</strong> command. This is when H2O starts its automated model training. </li>
<li>Train the model using the H2O AutoML object:<p class="source-code">aml.train(x = features, y = label, training_frame = train_dataframe)</p></li>
</ol>
<p>During the training, H2O will analyze the type of the label column. For numerical labels, H2O treats the ML problem as a regression problem. If the label is categorical, then it treats the problem as a classification problem. For the Iris flower dataset, the <strong class="source-inline">C5</strong> column is a categorical value containing class values. H2O will analyze this column and correctly identify that it is a classification problem and train classification models.</p>
<p>H2O AutoML trains several models behind the scenes using different types of ML algorithms. All the models that have been trained are evaluated on the test dataset and their performance is measured. H2O also provides detailed information about all the models, which users can use to further experiment on the data or compare different ML algorithms and understand which ones are more suitable to solve their ML problem. H2O can end up training 20-30 models, which can take a while. However, since we have passed the <strong class="source-inline">max_models</strong> parameter as <strong class="source-inline">10</strong>, we are limiting the number of models that will be trained so that we can see the output of the training process quickly. More on ensemble learning will be discussed in <a href="B17298_05.xhtml#_idTextAnchor109"><em class="italic">Chapter 5</em></a>, <em class="italic">Understanding AutoML Algorithms</em>.</p>
<ol>
<li value="11">Once the training<a id="_idIndexMarker069"/> has finished, AutoML creates<a id="_idIndexMarker070"/> a Leaderboard of all the models it has trained, ranking<a id="_idIndexMarker071"/> them from the best performing to the worst. This ranking is achieved by comparing all the models’ error metrics. <strong class="bold">Error metrics</strong> are values<a id="_idIndexMarker072"/> that measure how many errors the model makes when making predictions on a sample test dataset with the actual label values. Lower error metrics indicate that the model makes fewer errors during prediction, which indicates that it is a better model compared to one with a higher error metric. Extract the AutoML Leaderboard:<p class="source-code">model_leaderboard = aml.leaderboard</p></li>
<li>Display the AutoML Leaderboard:<p class="source-code">model_leaderboard.head(rows=model_leaderboard.nrows)</p></li>
</ol>
<p>The Leaderboard will look as follows:</p>
<div>
<div class="IMG---Figure" id="_idContainer014">
<img alt="Figure 1.4 – H2O AutoML Leaderboard (Python) " height="713" src="image/B17298_01_004.jpg" width="872"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – H2O AutoML Leaderboard (Python)</p>
<p>The Leaderboard<a id="_idIndexMarker073"/> includes the<a id="_idIndexMarker074"/> following details:</p>
<ul>
<li><strong class="source-inline">model_id</strong>: This represents<a id="_idIndexMarker075"/> the ID of the model.</li>
<li><strong class="source-inline">mean_per_class_error</strong>: This metric is used to measure the average of the errors of each class in your multi-class dataset.</li>
<li><strong class="source-inline">logloss</strong>: This metric is used to measure the negative average of the log of corrected predicted probabilities for each instance.</li>
<li><strong class="bold">Root Mean Squared Error</strong> (<strong class="bold">RMSE</strong>): This metric is used to measure<a id="_idIndexMarker076"/> the standard deviation of prediction errors.</li>
<li><strong class="bold">Mean Squared Error</strong> (<strong class="bold">MSE</strong>): This metric is used to measure the average<a id="_idIndexMarker077"/> of the squares of the errors.</li>
</ul>
<p>The Leaderboard sorts the models based on certain default metrics, depending on the type of ML problem, unless specifically mentioned during AutoML training. The Leaderboard<a id="_idIndexMarker078"/> sorts the models based on the <strong class="bold">AUC</strong> metric for binary classification, <strong class="source-inline">mean_per_class_error</strong> for multinomial classification, and <strong class="bold">deviance</strong> for regression.</p>
<p>The metrics are different<a id="_idIndexMarker079"/> measures of error in the model’s performance. So, the smaller<a id="_idIndexMarker080"/> the error value, the better<a id="_idIndexMarker081"/> the model is for making accurate predictions. We will explore the different model performance metrics in <a href="B17298_06.xhtml#_idTextAnchor129"><em class="italic">Chapter 6</em></a>,<em class="italic"> Understanding H2O AutoML Leaderboard and Other Performance Metrics</em>.</p>
<p>In this case, <strong class="source-inline">GLM_1_AutoML_1_20211221_224844</strong> is the best model according to H2O AutoML since it is a multinomial classification problem and this model has the lowest <strong class="source-inline">mean_per_class_error</strong>.</p>
<p>You may notice that despite passing the <strong class="source-inline">max_model</strong> value as <strong class="source-inline">10</strong>, when triggering AutoML for training, we see more than 10 models in the Leaderboard. This is because only 10 models have been trained; the remaining models<a id="_idIndexMarker082"/> are Stacked Ensemble models. <strong class="bold">Stacked Ensemble</strong> models are models that are created from what other models have learned and are not technically trained in the normal sense. We will learn more about Stacked Ensemble models in <a href="B17298_05.xhtml#_idTextAnchor109"><em class="italic">Chapter 5</em></a>, <em class="italic">Understanding AutoML Algorithms</em>, and more about the Leaderboard in <a href="B17298_06.xhtml#_idTextAnchor129"><em class="italic">Chapter 6</em></a>, <em class="italic">Understanding H2O AutoML Leaderboard and Other Performance Metrics</em>.</p>
<p>Congratulations! You have officially trained your very first ML model using H2O AutoML and it is now ready to be used to make predictions.</p>
<p>Making predictions is very straightforward: we will use the <strong class="source-inline">test_dataframe</strong> DataFrame that was created from the <strong class="source-inline">data.split_frame([0.8])</strong> command. </p>
<p>Execute the following command in Python:</p>
<p class="source-code">aml.predict(test_dataframe)</p>
<p>That’s it – everything is wrapped inside the <strong class="source-inline">predict</strong> function of the model object.</p>
<p>After executing the prediction, you will see the following results:</p>
<div>
<div class="IMG---Figure" id="_idContainer015">
<img alt="Figure 1.5 – H2O AutoML model prediction (Python) " height="467" src="image/B17298_01_005.jpg" width="822"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5 – H2O AutoML model prediction (Python)</p>
<p>The prediction result shows a table where every row is a representation of predictions for the rows present in the test DataFrame. The <strong class="source-inline">predict</strong> column indicates what Iris class it is for that row, while the remaining columns are the calculated probabilities of the Iris classes, as denoted in the column’s name, by the model after reading the feature values of that row. In short, the model predicts that for <em class="italic">row 1</em>, there is a <em class="italic">99.6763%</em> chance that it is Iris-setosa.</p>
<p>Congratulations! You have now made<a id="_idIndexMarker083"/> an accurate prediction using<a id="_idIndexMarker084"/> your newly trained model using AutoML.</p>
<p>Now that we’ve seen how<a id="_idIndexMarker085"/> easy it is to use H2O AutoML in Python, let’s learn how to do the same in the R programming language.</p>
<h3>Model training and prediction in R</h3>
<p>Similar to Python, training<a id="_idIndexMarker086"/> and making predictions using<a id="_idIndexMarker087"/> H2O AutoML in the R programming<a id="_idIndexMarker088"/> language is also very easy. H2O has a lot of support for the R programming language and, as such, has encapsulated much of the sophistication of ML behind ready-to-use functions.</p>
<p>Let’s look at a model training example that uses H2O AutoML in the R programming language on the Iris flower dataset.</p>
<p>You will notice that training models<a id="_idIndexMarker089"/> in R is similar to how we do it in Python, with<a id="_idIndexMarker090"/> the only difference being the slight change<a id="_idIndexMarker091"/> in syntax.</p>
<p>Follow these steps:</p>
<ol>
<li value="1">Import the <strong class="source-inline">H2O</strong> library: <p class="source-code">library(h2o)</p></li>
<li>Initialize H2O to spin up a local H2O server:<p class="source-code">h2o.init()</p></li>
</ol>
<p><strong class="source-inline">h2o.init()</strong> will start up an H2O server instance that’s running locally on port 54321 and connect to it. If an H2O server already exists on the same port, then it will reuse it.</p>
<ol>
<li value="3">Import the dataset using <strong class="source-inline">h2o.importFile(“Dataset/iris.data”)</strong> while passing the location of the dataset in your system as a parameter. Import the dataset:<p class="source-code">data &lt;- h2o.importFile("Dataset/iris.data")</p></li>
<li>Now, you need to set which columns of the dataframe are the features and which column is the label. Set the <strong class="source-inline">C5</strong> column as the target label and the remaining column names as the list of features:<p class="source-code">label &lt;- "C5"</p><p class="source-code">features &lt;- setdiff(names(data), label)</p></li>
<li>Split the DataFrame into two parts:<p class="source-code">parts &lt;- h2o.splitFrame(data, 0.8)</p></li>
</ol>
<p>One DataFrame will be used for training, while the other will be used for testing/validating the model being trained. <strong class="source-inline">parts &lt;- h2o.splitFrame(data, 0.8)</strong> splits the DataFrame into two parts. One DataFrame contains 80% of the data, while the other contains the remaining 20%. Now, assign the DataFrame that contains 80% of the data as the training DataFrame and the other as the testing or validation DataFrame.</p>
<ol>
<li value="6">Assign the first part as the training DataFrame:<p class="source-code">train_dataframe &lt;- parts[[1]]</p></li>
<li>Assign the second part as the testing DataFrame:<p class="source-code">test_dataframe &lt;- parts[[2]]</p></li>
<li>Now that the dataset<a id="_idIndexMarker092"/> has been imported and its features<a id="_idIndexMarker093"/> and labels have been identified, let’s pass<a id="_idIndexMarker094"/> them to H2O’s AutoML to train models. This means that you can implement the AutoML model training function in R using <strong class="source-inline">h2o.automl()</strong>. Train the model using H2O AutoML:<p class="source-code">aml &lt;- h2o.automl(x = features, y = label, training_frame = train_dataframe, max_models=10, seed = 1)</p></li>
<li>Extract the AutoML Leaderboard:<p class="source-code">model_leaderboard &lt;- aml@leaderboard</p></li>
<li>Display the AutoML Leaderboard:<p class="source-code">print(model_leaderboard, n = nrow(model_leaderboard))</p></li>
</ol>
<p>Once the training has finished, AutoML will create a Leaderboard of all the models it has trained, ranking them from the best performing to the worst.</p>
<p>The Leaderboard will display the results as follows:</p>
<div>
<div class="IMG---Figure" id="_idContainer016">
<img alt="Figure 1.6 – H2O AutoML Leaderboard (R) " height="376" src="image/B17298_01_006.jpg" width="758"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.6 – H2O AutoML Leaderboard (R)</p>
<p>The Leaderboard includes the same details as we saw in the Leaderboard we got when training models in Python.</p>
<p>However, you may notice that<a id="_idIndexMarker095"/> the best model that’s suggested in this Leaderboard<a id="_idIndexMarker096"/> is different from the one we<a id="_idIndexMarker097"/> got in our previous experiment. </p>
<p>In this case, <strong class="source-inline">GBM_3_AutoML_8_20211222_02555</strong> is the best model according to H2O AutoML, while in the previous experiment, it was <strong class="source-inline">GLM_1_AutoML_1_20211221_224844</strong>. This may be due to several factors, such as a different random number being generated for the seed value during model training or different data values being split across the training and testing DataFrames between the two experiments. This is what makes ML tricky – every step that you perform in a model training pipeline can greatly affect the overall performance of your trained model. At the end of the day, ML is a best-effort approach to making the most accurate predictions.</p>
<p>Congratulations – you have officially trained your ML model using H2O AutoML in R. Now, let’s learn how to make predictions on it. We will use the testing DataFrame we created after the split function to make predictions on the model we trained.</p>
<p>Execute the following command in R to make predictions:</p>
<p class="source-code">predictions &lt;- h2o.predict(aml, test_dataframe)</p>
<p>The <strong class="source-inline">predict</strong> function of the <strong class="source-inline">h2o</strong> object accepts two parameters. One is the model object, which in our case is the <strong class="source-inline">aml</strong> object, while the other is the DataFrame to make predictions on. By default, the <strong class="source-inline">aml</strong> object will use the best model in the Leaderboard to make predictions.</p>
<p>After executing the prediction, you will see the following results:</p>
<div>
<div class="IMG---Figure" id="_idContainer017">
<img alt="Figure 1.7 – H2O AutoML model prediction (R) " height="321" src="image/B17298_01_001.jpg" width="715"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.7 – H2O AutoML model prediction (R)</p>
<p>The results show a table with similar details that we saw in our previous experiment with Python. Every row is a representation of predictions for the rows present in the test DataFrame. The <strong class="source-inline">predict</strong> column indicates what Iris class it is for that row, while the remaining columns are the calculated probabilities of the Iris classes.</p>
<p>Congratulations – you have made<a id="_idIndexMarker098"/> an accurate prediction<a id="_idIndexMarker099"/> using your newly<a id="_idIndexMarker100"/> trained model using AutoML in R. Now, let’s summarize this chapter.</p>
<h1 id="_idParaDest-32"><a id="_idTextAnchor037"/>Summary</h1>
<p>In this chapter, we understood the various steps in an ML pipeline and how AutoML plays a part in automating some of those steps. Then, we prepared our system to use H2O AutoML by installing the basic requirements. Once our system was ready, we implemented a simple application in Python and R that uses H2O AutoML to train a model on the Iris flower dataset. Finally, we understood the Leaderboard results and made successful predictions on the ML model that we just trained. All of this helped us test the waters of H2O AutoML, thus opening doors to more advanced concepts of H2O AutoML.</p>
<p>In the next chapter, we will explore H2O’s web <strong class="bold">User Interface</strong> (<strong class="bold">UI</strong>) so that we can understand and observe various ML details using an interactive visual interface. </p>
</div>
</div></body></html>