- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Statistical Estimation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计估计
- en: In this chapter, we will introduce you to a range of statistical techniques
    that enable you to make inferences and estimations using both numerical and categorical
    data. We will explore key concepts and methods, such as hypothesis testing, confidence
    intervals, and estimation techniques, that empower us to make generalizations
    about populations from a given sample.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将向您介绍一系列统计技术，这些技术使您能够使用数值和分类数据来进行推断和估计。我们将探讨关键概念和方法，如假设检验、置信区间和估计技术，这些技术使我们能够从给定的样本中对总体进行概括。
- en: By the end of this chapter, you will grasp the core concepts of statistical
    inference and be able to perform hypothesis testing in different scenarios.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将掌握统计推断的核心概念，并能够在不同场景下进行假设检验。
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Statistical inference for categorical data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类数据的统计推断
- en: Statistical inference for numerical data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值数据的统计推断
- en: Constructing the bootstrapped confidence interval
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建自助法置信区间
- en: Introducing the central limit theorem used in t-distribution
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍t分布中使用的中心极限定理
- en: Constructing the confidence interval for the population mean using the t-distribution
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用t分布构建总体均值的置信区间
- en: Performing hypothesis testing for two means
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对两个均值进行假设检验
- en: Introducing ANOVA
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍方差分析（ANOVA）
- en: 'To run the code in this chapter, you will need to have the latest versions
    of the following packages:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本章中的代码，您需要以下软件包的最新版本：
- en: '`dplyr`, 1.0.10'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dplyr`，1.0.10'
- en: '`ggplot2`, 3.4.0'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ggplot2`，3.4.0'
- en: '`socviz`, 1.2'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`socviz`，1.2'
- en: '`infer`, 1.0.4'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`infer`，1.0.4'
- en: Please note that the versions mentioned in the preceding list are the latest
    ones at the time I am writing this book. All the code and data for this chapter
    is available at [https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_11/working.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_11/working.R).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面提到的版本是在我撰写本书时的最新版本。本章的所有代码和数据均可在[https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_11/working.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_11/working.R)找到。
- en: Statistical inference for categorical data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类数据的统计推断
- en: A categorical variable has distinct categories or levels, rather than numerical
    values. Categorical data is common in our daily lives, such as gender (male or
    female, although a modern view may differ), type of property sales (new property
    or resale), and industry. The ability to make sound inferences about these variables
    is thus essential for drawing meaningful conclusions and making well-informed
    decisions in diverse contexts.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分类变量具有不同的类别或水平，而不是数值。分类数据在我们的日常生活中很常见，例如性别（男性或女性，尽管现代观点可能不同）、房产销售类型（新房或二手房）和行业。因此，对这些变量进行合理推断的能力对于在多种情境下得出有意义的结论和做出明智的决策至关重要。
- en: Being a categorical variable often means we cannot pass it to a `string` values
    such as `"finance"` or `"technology"`) to the model, a common approach is to one-hot
    encode the variable into multiple columns, with each column corresponding to a
    specific industry, indicating a binary value of `0` or `1`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作为分类变量，通常意味着我们无法将其传递给模型中的字符串值（如 `"finance"` 或 `"technology"`），一种常见的方法是将变量一热编码成多个列，每列对应一个特定行业，表示二进制值
    `0` 或 `1`。
- en: In this section, we will explore various statistical techniques designed specifically
    to handle categorical data, enabling us to derive valuable insights and make inferences
    about populations based on available samples. We will also discuss important concepts,
    such as proportions, independence, and goodness of fit, which form the foundation
    for understanding and working with categorical variables, covering both cases
    with a single parameter and multiple parameters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨专门用于处理分类数据的各种统计技术，使我们能够根据可用的样本得出有价值的见解并对总体进行推断。我们还将讨论重要概念，如比例、独立性和拟合优度，这些概念是理解和处理分类变量的基础，包括单参数和多参数的情况。
- en: Let us start by discussing the inference for a single parameter.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从单个参数的推断开始讨论。
- en: Statistical inference for a single parameter
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单个参数的统计推断
- en: A population parameter, the subject of interest and to be inferred, is a fixed
    quantity that describes a particular statistical attribute of a population, including
    the mean, proportion, or standard deviation. This quantity often stays hidden
    from us. For example, in order to get the most popular major in a university,
    we need to count the number of enrolled students in each major across the whole
    university and then return the major with the biggest count.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一个总体参数，我们感兴趣并要推断的主题，是一个描述总体特定统计属性的固定数量，包括均值、比例或标准差。这个数量通常对我们来说是隐藏的。例如，为了得到大学中最受欢迎的专业，我们需要计算整个大学每个专业注册的学生数量，然后返回计数最大的专业。
- en: In the context of statistical inference for a single parameter, we aim to estimate
    this unknown parameter or test hypotheses about its value based on the information
    gathered from a sample. In other words, we would use statistical inference tools
    to infer unknown population parameters based on the known sample at hand. In the
    previous example, we would infer the most popular major of the whole university
    by a limited sample of students enrolled in a specific academic year.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在单参数统计推断的背景下，我们的目标是估计这个未知参数或基于从样本收集的信息来测试其值的相关假设。换句话说，我们会使用统计推断工具，根据已知的样本来推断未知的人口参数。在前一个例子中，我们会通过特定学术年度注册的学生有限样本来推断整个大学最受欢迎的专业。
- en: Let us first explore the **General Social Survey** (**GSS**) dataset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先探索 **一般社会调查**（**GSS**）数据集。
- en: Introducing the General Social Survey dataset
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍一般社会调查数据集
- en: The GSS is a comprehensive dataset widely used by researchers and policymakers
    to understand social, cultural, and political trends in the United States. The
    GSS has been continued by the **National Opinion Research Center** (**NORC**)
    at the University of Chicago since 1972, with the objective of collecting data
    on a broad range of topics, including attitudes, behaviors, and opinions on various
    issues.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: GSS 是一个综合数据集，被研究人员和政策制定者广泛用于理解美国的社会、文化和政治趋势。自 1972 年以来，GSS 由芝加哥大学的 **国家民意研究中心**（**NORC**）持续进行，目的是收集关于广泛主题的数据，包括态度、行为和对各种问题的观点。
- en: 'Let us load the GSS dataset from the `socviz` package (remember to install
    this package via `install.packages("socviz")`):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 `socviz` 包中加载 GSS 数据集（请记住通过 `install.packages("socviz")` 安装此包）：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The GSS dataset is now stored in the `gss_lon` variable, which contains a total
    of 62,466 rows and 25 columns, as shown here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: GSS 数据集现在存储在 `gss_lon` 变量中，包含总共 62,466 行和 25 列，如下所示：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The GSS dataset contains numerous variables that cover diverse topics, such
    as education, income, family structure, political beliefs, and religious affiliation.
    Let us examine the structure of the dataset using the `glimpse()` function from
    the `dplyr` package, designed to help you quickly explore and understand the structure
    of the data:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: GSS 数据集包含许多变量，涵盖了各种主题，如教育、收入、家庭结构、政治信仰和宗教归属。让我们使用 `dplyr` 包中的 `glimpse()` 函数来检查数据集的结构，该函数旨在帮助您快速探索和理解数据结构：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Figure 11**.1* shows a screenshot of the first few variables returned.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11*.1 显示了返回的前几个变量的截图。'
- en: '![Figure 11.1 – Showing the first few rows of the result from running the glimpse()
    function](img/B18680_11_001.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – 展示运行 glimpse() 函数的结果的前几行](img/B18680_11_001.jpg)'
- en: Figure 11.1 – Showing the first few rows of the result from running the glimpse()
    function
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – 展示运行 glimpse() 函数的结果的前几行
- en: Next, we will look at calculating a specific statistic based on a categorical
    variable.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看基于分类变量的特定统计量的计算。
- en: Calculating the sample proportion
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算样本比例
- en: The `siblings` column in the dataset is a categorical variable that tracks the
    number of siblings in the family. In the following exercise, we would like to
    calculate the proportion of survey respondents whose family has two siblings in
    the latest year, 2016.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的 `siblings` 列是一个分类变量，追踪家庭中的兄弟姐妹数量。在接下来的练习中，我们希望计算在最新的一年，即 2016 年，家庭有两个兄弟姐妹的受访者比例。
- en: Exercise 11.1 – calculating the sample proportion of siblings
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 11.1 – 计算兄弟姐妹的样本比例
- en: 'In this exercise, we first obtain a summary of the `siblings` column and subset
    the dataset to focus on the year 2016, which will then be used to calculate the
    proportion of surveys with a specific number of siblings in the family:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们首先获取`siblings`列的摘要，并对数据集进行子集化以关注2016年，然后将其用于计算家庭中有特定数量兄弟姐妹的调查比例：
- en: 'Obtain a summary of the `siblings` column using the `summary()` function:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`summary()`函数获取`siblings`列的摘要：
- en: '[PRE3]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The result suggests that most surveys are conducted for families with six siblings
    or more!
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果表明，大多数调查是在有六个或更多兄弟姐妹的家庭中进行的！
- en: 'Subset the dataset for the year 2016:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对2016年的数据集进行子集化：
- en: '[PRE4]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Running the code generates the chart in *Figure 11**.2*.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行代码生成图*11.2*。
- en: '![Figure 11.2 – Visualizing the frequency count of the number of siblings in
    a bar chart](img/B18680_11_002.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图11.2 – 以柱状图可视化兄弟姐妹数量的频率计数](img/B18680_11_002.jpg)'
- en: Figure 11.2 – Visualizing the frequency count of the number of siblings in a
    bar chart
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 – 以柱状图可视化兄弟姐妹数量的频率计数
- en: 'Calculate the proportion of surveys with two siblings:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算有两个兄弟姐妹的调查比例：
- en: '[PRE5]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, we use the `summarize()` function to calculate the mean of a series of
    binary values, which corresponds to the proportion of surveys with two siblings.
    We then use the `pull()` function to obtain the proportion from the resulting
    DataFrame.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用`summarize()`函数计算一系列二元值的平均值，这对应于有两个兄弟姐妹的调查比例。然后我们使用`pull()`函数从结果DataFrame中获取比例。
- en: We use the sample proportion to estimate the population statistic. In other
    words, we calculate the proportion of families with two siblings based on the
    available samples to approximate the corresponding proportion if we were to calculate
    the same based on all the data in the population. Such an estimate comes with
    a confidence interval that quantifies the list of possible values for the population
    proportion.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用样本比例来估计总体统计量。换句话说，我们根据可用的样本数据计算有两个兄弟姐妹的家庭比例，以近似如果我们基于总体中的所有数据计算相同的比例时对应的比例。这样的估计伴随着一个置信区间，该区间量化了总体比例的可能值列表。
- en: The next section shows how to calculate the confidence interval for the sample
    proportion.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将展示如何计算样本比例的置信区间。
- en: Calculating the confidence interval
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算置信区间
- en: The confidence interval is an important tool in making inferences about the
    population parameters based on sample data. A confidence interval provides an
    estimated range within which a population parameter, such as proportion, is likely
    to be found with a specified confidence level, such as 95%. When working with
    sample proportions, calculating confidence intervals allows us to understand the
    true proportion in the population better and gauge the uncertainty associated
    with the estimation of the population proportion.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间是基于样本数据对总体参数进行推断的重要工具。置信区间提供了一个估计范围，其中包含一个总体参数，如比例，在指定的置信水平（如95%）下可能被找到。当处理样本比例时，计算置信区间使我们能够更好地理解总体中的真实比例，并评估与总体比例估计相关的不确定性。
- en: 'We can use the following steps to calculate the confidence interval:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下步骤来计算置信区间：
- en: Calculate the sample proportion,  ˆ p  (pronounced as p-hat). This is the value
    we calculated based on the sample data in 2016\. In other contexts,  ˆ p  is calculated
    by dividing the number of successes (for the attribute of interest) by the total
    sample size.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算样本比例，ˆp（读作p-hat）。这是我们基于2016年的样本数据计算出的值。在其他情况下，ˆp是通过将成功的数量（对于感兴趣的属性）除以总样本量来计算的。
- en: Determine the desired level of confidence, commonly denoted as (1 − α) x 100%,
    where α represents the level of significance. In other words, it is the probability
    of rejecting the null hypothesis when it is true. The most frequently used confidence
    levels are 90%, 95%, and 99%.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定所需的置信水平，通常表示为(1 − α) x 100%，其中α代表显著性水平。换句话说，这是在原假设为真时拒绝零假设的概率。最常用的置信水平是90%，95%和99%。
- en: 'Calculate the standard error of the sample proportion, which is given by the
    following formula:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算样本比例的标准误差，其公式如下：
- en: SE = √ _   ˆ p (1 −  ˆ p ) _ n
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: SE = √(ˆp(1 − ˆp) / n)
- en: 'Here, the standard error also corresponds to the standard deviation of the
    sample proportion, which is assumed to follow a Bernoulli distribution with a
    success probability of  ˆ p  (recall the introduction of Bernoulli distribution
    in the previous chapter). Such calculation relies on two assumptions: the observations
    in the samples are independent and there are sufficient observations in the sample.
    A common rule of thumb for checking the second assumption is to ensure both n ˆ p 
    > 10 and n(1 −  ˆ p ) > 10.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，标准误差也对应于样本比例的标准差，假设它遵循成功概率为ˆp的伯努利分布（回想一下前一章中伯努利分布的介绍）。这种计算依赖于两个假设：样本中的观测值是独立的，样本中有足够的观测值。检查第二个假设的一个常见经验法则是确保nˆp
    > 10和n(1 − ˆp) > 10。
- en: Alternatively, instead of assuming a Bernoulli distribution, we can use the
    bootstrap procedure to estimate the standard error without any distributional
    assumption. Bootstrap is a non-parametric method that involves resampling the
    data with replacement to create new samples, calculating the statistic of interest
    (in this case, the proportion) for each resampled dataset, and estimating the
    standard error from the variability of the calculated statistics across the resampled
    datasets.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们不必假设伯努利分布，可以使用自举过程来估计标准误差，而不做任何分布假设。自举是一种非参数方法，涉及有放回地重新抽样数据以创建新的样本，对每个重新抽样的数据集计算感兴趣的统计量（在这种情况下，是比例），并从计算统计量的变异性中估计标准误差。
- en: 4. Find the critical value (z-score) corresponding to the preset confidence
    level. This can be done using the `qnorm()` function, which gives us the quantiles
    of the standard normal distribution.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 找到对应于预设置信水平的临界值（z分数）。这可以通过`qnorm()`函数完成，它给出了标准正态分布的分位数。
- en: '5. Compute the **margin of error** (**ME**) as the product of the standard
    error and the critical value:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 5. 计算误差范围（ME）为标准误差与临界值的乘积：
- en: ME = SE * z _ score
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ME = SE * z _ score
- en: '6. Calculate the confidence interval by adding and subtracting the ME from
    the sample proportion, giving the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 6. 通过从样本比例中加减ME来计算置信区间，得到以下结果：
- en: Lower limit =  ˆ p  − ME
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 下限 = ˆp − ME
- en: Upper limit =  ˆ p  + ME
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 上限 = ˆp + ME
- en: The confidence interval provides a list of possible values for the population
    proportion according to the specific confidence level. See *Figure 11**.3* for
    a summary of the calculation process.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间根据特定的置信水平提供了总体比例的可能值列表。参见*图11.3*对计算过程的总结。
- en: '![Figure 11.3 – Summarizing the process of calculating the confidence interval
    based on sample proportion](img/B18680_11_003.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图11.3 – 基于样本比例计算置信区间的过程总结](img/B18680_11_003.jpg)'
- en: Figure 11.3 – Summarizing the process of calculating the confidence interval
    based on sample proportion
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 – 基于样本比例计算置信区间的过程总结
- en: Let us stay with the bootstrap procedure a little longer. Without assuming any
    specific distribution, the bootstrap procedure is a flexible approach that can
    provide more accurate estimates of the standard error, especially for small sample
    sizes or when the data is not well behaved. However, It can be computationally
    intensive, especially for large datasets or when many bootstrap replications are
    generated.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再深入探讨一下自举过程。不假设任何特定分布，自举过程是一种灵活的方法，可以提供更准确的标准误差估计，特别是对于小样本量或数据表现不佳的情况。然而，它可能计算量很大，尤其是在大型数据集或生成许多自举复制时。
- en: '*Figure 11**.4* provides a schematic overview of the bootstrap procedure. Let’s
    review:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11.4* 提供了自举过程的示意图。让我们回顾一下：'
- en: First, we start with the whole dataset and specify the variable of interest,
    which is the `siblings` variable in this case. This is achieved via the `specify()`
    function.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们从整个数据集开始，并指定感兴趣的变量，在这个例子中是`兄弟姐妹`变量。这是通过`specify()`函数实现的。
- en: Next, we draw samples from the variable with replacement, where the new sample
    will be the same size as the original dataset. Such resampling introduces randomness
    to the resulting dataset.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们从变量中抽取样本，进行有放回抽样，其中新样本的大小与原始数据集相同。这种重抽样引入了随机性到结果数据集中。
- en: We repeat the process many times, leading to a collection of bootstrapped artificial
    datasets using the `generate()` function.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们重复这个过程多次，使用`generate()`函数得到一系列通过自举得到的伪数据集。
- en: For each replicated dataset, we will calculate the sample statistic of interest,
    which is the proportion of observations with two siblings in this case. This is
    done via the `calculate()` function.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个复制的数据集，我们将计算感兴趣的样本统计量，在这种情况下是具有两个兄弟姐妹的观察值的比例。这是通过`calculate()`函数完成的。
- en: These sample statistics derived using repeated sampling of the original dataset
    will then form a distribution, called the bootstrapped distribution (plotted via
    `ggplot()`), whose standard deviation (extracted via the `summarize()` function)
    will be a good approximation of the standard error.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些通过重复抽样原始数据集得到的样本统计量将形成一个分布，称为自助法分布（通过`ggplot()`绘制），其标准差（通过`summarize()`函数提取）将是对标准误的良好近似。
- en: '![Figure 11.4 – The schematic overview of obtaining the standard error using
    the bootstrap procedure](img/B18680_11_004.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图11.4 – 使用自助法程序获取标准误的示意图](img/B18680_11_004.jpg)'
- en: Figure 11.4 – The schematic overview of obtaining the standard error using the
    bootstrap procedure
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4 – 使用自助法程序获取标准误的示意图
- en: The bootstrapped samples convey different levels of uncertainty in the sample
    statistic and jointly form a density distribution of multiple artificial sample
    statistics. The standard deviation of the bootstrapped distribution then gives
    the standard error of the sample statistic. Note that functions such as `specify()`,
    `generate()`, and `calculate()` all come from the `infer` package in R. Remember
    to install this package before continuing with the following code.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过自助法得到的样本传达了样本统计量不同水平的不确定性，并共同形成多个人工样本统计量的密度分布。自助法分布的标准差随后给出样本统计量的标准误。请注意，如`specify()`、`generate()`和`calculate()`等函数均来自R中的`infer`包。在继续以下代码之前，请记住安装此包。
- en: Let us go through the following exercise to understand the bootstrap procedure
    for calculating the confidence interval.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下练习来了解计算置信区间的自助法程序。
- en: Exercise 11.2 – calculating the confidence interval via bootstrap
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习11.2 – 通过自助法计算置信区间
- en: 'In this exercise, we will explore calculating the confidence interval of the
    sample proportion. The confidence interval includes the list of estimates within
    which the true population proportion may assume, given the observed samples. It
    is a way to quantify the uncertainty in estimating the population proportion based
    on the actual observations. Besides a step-by-step walk-through of the calculation
    process using bootstrap, we will also compare the result with the alternative
    approach using the assumed Bernoulli distribution:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将探索计算样本比例的置信区间。置信区间包括一系列估计值，在这些估计值中，给定观察到的样本，真实总体比例可能取值。这是基于实际观察来量化估计总体比例不确定性的方法。除了使用自助法逐步计算过程外，我们还将比较使用假设的伯努利分布的替代方法的结果：
- en: 'Build a set of bootstrapped sample statistics using the specify-generate-calculate
    procedure from the `infer` package described earlier. Remember to build a binary
    variable to indicate the binary condition of having an observation with two siblings:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前面描述的`infer`包中的指定-生成-计算程序构建一组自助法样本统计量。请记住构建一个二元变量来指示具有两个兄弟姐妹的观察值的二元条件：
- en: '[PRE6]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we first create a binary indicator variable using the `if_else()` function
    to denote whether the family in the current survey has two siblings. We also remove
    rows with `NA` values in this column. Next, we use the `specify()` function to
    indicate the `siblings_two_ind` variable of interest and the level that corresponds
    to a success. We then use the `generate()` function to generate `500` bootstrapped
    samples, and use the `calculate()` function to obtain the corresponding sample
    statistic (proportion of success) in each bootstrapped sample by setting `stat
    = "``prop"`.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们首先使用`if_else()`函数创建一个二元指标变量，以表示当前调查中的家庭是否有两个兄弟姐妹。我们还删除了此列中具有`NA`值的行。接下来，我们使用`specify()`函数指出感兴趣的`siblings_two_ind`变量及其对应的成功级别。然后，我们使用`generate()`函数生成`500`个自助法样本，并使用`calculate()`函数通过设置`stat
    = "prop"`来获取每个自助法样本中相应的样本统计量（成功比例）。
- en: 'Let us observe the contents in the bootstrapped sample statistics:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们观察自助法样本统计量中的内容：
- en: '[PRE7]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The result shows that the `bs` object is a `tibble` DataFrame with 500 rows
    (corresponding to the total number of the bootstrapped sample) and 2 columns.
    The first column (`replicate`) denotes the number of bootstrapped samples, and
    the second column (`stat`) indicates the proportion of success (that is, the number
    of rows with `siblings_two_ind==2` divided by the total number of rows) in the
    bootstrapped sample.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示，`bs`对象是一个包含500行（对应于bootstrap样本的总数）和2列的`tibble` DataFrame。第一列（`replicate`）表示bootstrap样本的数量，第二列（`stat`）表示bootstrap样本中成功的比例（即`siblings_two_ind==2`的行数除以总行数）。
- en: 'Plot the bootstrapped sample statistics in a density plot:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在密度图中绘制bootstrap样本统计量：
- en: '[PRE8]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Running the code generates the plot in *Figure 11**.5*. The spread of this distribution,
    which relates to the standard deviation, directly determines the magnitude of
    the standard error. Also, if we were to increase the number of bootstrapped samples,
    we would expect a smoother density curve.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码生成*图11.5*的图表。这个分布的分散程度，与标准差相关，直接决定了标准误差的大小。此外，如果我们增加bootstrap样本的数量，我们预期密度曲线会更加平滑。
- en: '![Figure 11.5 – Visualizing the density plot of all bootstrapped sample proportions](img/B18680_11_005.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图11.5 – 可视化所有bootstrap样本比例的密度图](img/B18680_11_005.jpg)'
- en: Figure 11.5 – Visualizing the density plot of all bootstrapped sample proportions
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 – 可视化所有bootstrap样本比例的密度图
- en: 'Calculate the standard error as the standard deviation of the empirical distribution
    based on the bootstrapped sample proportions:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将标准误差计算为基于bootstrap样本比例的实证分布的标准差：
- en: '[PRE9]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, we use the `sd()` function to calculate the standard deviation of the
    `stat` column in `bs`, and then return the value via the `pull()` function. The
    standard error will then be scaled by the predetermined z-score and subtracted
    from and added to the original sample proportion to obtain the confidence interval.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用`sd()`函数计算`bs`中`stat`列的标准差，然后通过`pull()`函数返回该值。然后，标准误差将根据预定的z分数进行缩放，并从原始样本比例（`p_hat`）中减去和加上，以获得置信区间。
- en: 'Calculate the confidence interval of the original sample proportion with a
    95% confidence interval:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用95%置信区间计算原始样本比例的置信区间：
- en: '[PRE10]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, since a 95% confidence level corresponds to a z-score of 2, we multiply
    it with the standard error before subtracting from and adding to the original
    sample proportion (`p_hat`) to obtain the confidence interval.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，由于95%置信水平对应于z分数2，我们在从原始样本比例（`p_hat`）中减去和加上之前，将其与标准误差相乘以获得置信区间。
- en: 'Calculate the confidence interval using the structure information by assuming
    a Bernoulli distribution for the probability of success:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设成功的概率服从伯努利分布，使用结构信息计算置信区间：
- en: '[PRE11]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, we use the explicit form of the variance of the Bernoulli distribution
    to calculate the standard error. The result shows a fairly similar confidence
    interval compared with the one obtained using the bootstrap approach.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用伯努利分布的方差显式形式来计算标准误差。结果显示的置信区间与使用bootstrap方法获得的置信区间相当相似。
- en: The confidence interval provides a measure of uncertainty for our estimate of
    the unknown population proportion using the observed sample proportion. Let us
    look at how to interpret the confidence interval in the next section.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间为我们使用观察到的样本比例估计未知总体比例的不确定性提供了一个不确定性度量。让我们看看如何在下一节中解释置信区间。
- en: Interpreting the confidence interval of the sample proportion
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解释样本比例的置信区间
- en: Interpreting the confidence interval of the sample proportion involves understanding
    the meaning of the interval and the associated confidence level. In our previous
    example, the bootstrap approach reports a confidence interval of `[0.1938821,
    0.2226099]`. There are two levels of interpretation for this confidence interval.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 解释样本比例的置信区间涉及理解区间的含义和相关的置信水平。在我们之前的例子中，bootstrap方法报告的置信区间为`[0.1938821, 0.2226099]`。对于这个置信区间有两个层面的解释。
- en: First, the range of the confidence interval suggests that the true population
    proportion of families with two siblings is likely to fall between 19.39% and
    22.26%. This range is based on the sample data and estimates the uncertainty in
    the true proportion.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，置信区间的范围表明，具有两个兄弟姐妹的家庭的真实比例很可能在19.39%到22.26%之间。这个范围基于样本数据，并估计了真实比例的不确定性。
- en: Second, the 95% confidence interval means that if we were to conduct the survey
    many times (either in 2016 or other years), we would generate different random
    samples of the same size, based on which we can calculate the 95% confidence interval
    for each sample. Among these artificial samples, we will obtain a collection of
    intervals, and approximately 95% of them would include the true population proportion
    within the interval.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，95%的置信区间意味着如果我们多次进行调查（无论是2016年还是其他年份），我们会生成不同大小的随机样本，基于这些样本我们可以计算每个样本的95%置信区间。在这些人工样本中，我们将获得一系列区间，其中大约95%的区间将包含真实的总体比例。
- en: Note that the confidence interval is still an estimate, and the true population
    proportion may fall outside the calculated interval. However, the confidence interval
    provides a useful way to quantify the uncertainty in the estimate and gives a
    list of plausible values for the true population proportion based on the observed
    samples.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，置信区间仍然是一个估计值，真实的总体比例可能落在计算出的区间之外。然而，置信区间提供了一种有用的方法来量化估计的不确定性，并基于观察到的样本给出真实总体比例的可能值的列表。
- en: The next section introduces hypothesis testing for the sample proportion.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将介绍对样本比例的假设检验。
- en: Hypothesis testing for the sample proportion
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对样本比例进行假设检验
- en: Hypothesis testing for the sample proportion is very much related to the confidence
    interval introduced in a previous section, which captures the level of uncertainty
    in the estimate for the unknown proportion based on the population data. Naturally,
    a sample with fewer observations leads to a wide confidence interval. Hypothesis
    testing for the sample proportion aims to determine whether there is enough evidence
    in a sample to support or reject a claim about the population proportion. The
    process starts with a null hypothesis (H0), which represents the baseline assumption
    about the population proportion. Correspondingly, there is an alternative hypothesis
    (H1) that represents the claim or statement we are testing against the null hypothesis.
    Hypothesis testing then compares the observed sample proportion to a specified
    null hypothesis in order to assess whether we have enough evidence to reject the
    null hypothesis in favor of the alternative hypothesis.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对样本比例的假设检验与前面章节中引入的置信区间密切相关，它捕捉了基于总体数据对未知比例估计的不确定性水平。自然地，观察值较少的样本会导致置信区间较宽。对样本比例的假设检验旨在确定样本中是否有足够的证据来支持或拒绝关于总体比例的声明。这个过程从零假设（H0）开始，它代表了关于总体比例的基本假设。相应地，存在一个备择假设（H1），它代表了我们对零假设进行测试的声明或陈述。然后，假设检验将观察到的样本比例与指定的零假设进行比较，以评估我们是否有足够的证据来拒绝零假设，并支持备择假设。
- en: 'Let us go through an overview of the procedure involved in carrying out hypothesis
    testing:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们概述一下进行假设检验所涉及的程序：
- en: '**Formulate the hypothesis**. In this step, we set up the null hypothesis (H0)
    and alternative hypothesis (H1). The null hypothesis often says there is no effect,
    and the situation remains the status quo, as indicated by an equality sign in
    H0\. On the other hand, the alternative hypothesis states that there is an effect
    or difference, as indicated by an inequality sign in H1\. For example, we can
    set the following hypotheses for H0 and H1:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**制定假设**。在这个步骤中，我们设定零假设（H0）和备择假设（H1）。零假设通常表示没有效果，情况保持现状，如H0中的等号所示。另一方面，备择假设表示存在效果或差异，如H1中的不等号所示。例如，我们可以为H0和H1设定以下假设：'
- en: 'H0: p = p 0 (the population proportion is equal to a specified value, p 0)'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'H0: p = p 0（总体比例等于指定的值，p 0）'
- en: 'H1: p ≠ p 0 (the population proportion is not equal to p 0)'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'H1: p ≠ p 0（总体比例不等于p 0）'
- en: '**Choose a significance level (**𝜶**)**. The significance level is a probability
    threshold we use to reject the null hypothesis when it is true. Widely used significance
    levels include 0.05 (5%) and 0.01 (1%).'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择显著性水平（**𝜶**）**。显著性水平是我们用来在原假设为真时拒绝原假设的概率阈值。广泛使用的显著性水平包括0.05（5%）和0.01（1%）。'
- en: '**Calculate the test statistic**. Now that we observe a sample proportion based
    on the actual data, we can calculate the probability of observing such a sample
    proportion *if* the null hypothesis were true. This starts with calculating the
    test statistic (z-score) for the sample proportion using the following formula:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算检验统计量**。现在我们根据实际数据观察到一个样本比例，我们可以计算在零假设为真的情况下观察到这样一个样本比例的概率。这始于使用以下公式计算样本比例的检验统计量（z分数）：'
- en: z =   ˆ p  − p 0 _ √ ___________ p 0(1 − p 0) / n
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: z = ˆp − p0 * √___________ * p0(1 − p0) / n
- en: where  ˆ p  is the sample proportion, p 0 is the population proportion assuming
    the null hypothesis, and n is the sample size. There are two things to note there.
    First, the denominator resembles the standard deviation based on the sample proportion
    covered earlier. Indeed, we are assuming a Bernoulli distribution with a success
    probability of p 0\. With a total of n observations, the standard deviation for
    the sample proportion variable is √ ___________ p 0(1 − p 0) / n . Second, the
    whole term corresponds to the process of converting a number into a z-score of
    a specific distribution, a topic covered in the previous chapter. Here, we assume
    a normal distribution with mean p 0 and standard deviation √ ___________ p 0(1
    − p 0) / n . We can then convert the observed sample proportion  ˆ p  to the corresponding
    z-score for ease of calculation later on.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 其中ˆp是样本比例，p0是在零假设下的总体比例，n是样本大小。有两点需要注意。首先，分母类似于前面提到的基于样本比例的标准差。确实，我们假设一个伯努利分布，成功概率为p0。在总共n个观察值中，样本比例变量的标准差是√___________
    * p0(1 − p0) / n。其次，整个项对应于将一个数值转换为特定分布的z分数的过程，这是前一章讨论的主题。在这里，我们假设一个均值为p0，标准差为√___________
    * p0(1 − p0) / n的正态分布。然后我们可以将观察到的样本比例ˆp转换为相应的z分数，以便于后续计算。
- en: Note that we can also use the bootstrap approach to calculate the empirical
    p-value under the null hypothesis.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们还可以使用自助法在零假设下计算经验p值。
- en: 4. **Determine the p-value**. The z-score is a measure that falls on a standard
    Gaussian distribution. It is a test statistic, and we are often interested in
    the probability of observing the test statistic at this or an even more extreme
    value. This is called the p-value, denoted as  ˆ p , when we assume the null hypothesis
    is true. In other words, we try to assess how likely it is to observe some phenomenon,
    assuming the null hypothesis is true. If the probability of observing  ˆ p  or
    an even more extreme number is very small, we have confidence that the null hypothesis
    is false, and we can reject H0 in favor of H1.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 4. **确定p值**。z分数是一个落在标准高斯分布上的度量。它是一个检验统计量，我们通常对观察到的检验统计量在此或更极端值上的概率感兴趣。这被称为p值，记为ˆp，当我们假设零假设为真时。换句话说，我们试图评估在零假设为真的情况下观察某些现象的可能性。如果观察到ˆp或更极端数值的概率非常小，我们有信心零假设是错误的，我们可以拒绝H0并支持H1。
- en: 'Note that for a two-tailed test, we can also calculate the p-value using the
    standard normal distribution and doubling the single-side probability:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于双尾检验，我们还可以使用标准正态分布并加倍单侧概率来计算p值：
- en: p-value = 2P(Z > |z|)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: p-value = 2P(Z > |z|)
- en: 5. **Make a decision**. Finally, we compare the p-value to the preset significance
    level (α) and use the following rule to make a decision.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 5. **做出决定**。最后，我们将p值与预设的显著性水平（α）进行比较，并使用以下规则做出决定。
- en: If the p-value ≤ α, reject the null hypothesis in favor of the alternative hypothesis.
    Doing so suggests that there is enough evidence to suggest that the population
    proportion differs from the hypothesized proportion p 0.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果p值 ≤ α，则拒绝零假设，支持备择假设。这样做表明有足够的证据表明总体比例与假设比例p0不同。
- en: If the p-value > α, fail to reject the null hypothesis. This means that there
    is not enough evidence to suggest that the population proportion is different
    from p 0.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果p值 > α，则不能拒绝零假设。这意味着没有足够的证据表明总体比例与p0不同。
- en: Conducting the hypothesis testing follows a similar process. The only difference
    is the use of the `hypothesise()` function (placed after `specify()`), which serves
    as a null hypothesis. We then perform the same bootstrap procedure to obtain a
    density plot of the bootstrapped sample proportions, followed by calculating the
    total probability of obtaining a proportion at least as extreme as the one indicated
    in the null hypothesis.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through an exercise to review the process of performing hypothesis
    testing for the sample proportion.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.3 – performing hypothesis testing for the sample proportion
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will set up a hypothetical population proportion in a
    null hypothesis and test the validity of this hypothesis based on the observed
    sample proportion:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot the frequency count of families with and without two siblings in 2016
    in a bar plot:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Running the code generates the plot in *Figure 11**.6*, which shows that families
    with two siblings account for around ¼ of all families.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.6 – Visualizing the frequency count of families with two siblings](img/B18680_11_006.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
- en: Figure 11.6 – Visualizing the frequency count of families with two siblings
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the sample proportion of families with two siblings:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, we first build a series of binary outcomes using `siblings_two_ind=="Y"`.
    Taking the average of this column gives the ratio of `TRUE` values, which gets
    executed in a `summarize()` context. We then extract the value of the sample proportion
    using `pull()`.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the specify-hypothesise-generate-calculate procedure to generate a collection
    of bootstrapped sample proportions under the null hypothesis, which specifies
    a population proportion of `0.19`:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Generate the density plot of the bootstrapped sample proportions along with
    the proportion suggested by the null hypothesis via a vertical line:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Running the code generates the plot in *Figure 11**.7*. The probability of observing
    a value at least as extreme as the one indicated by the red line (according to
    the null hypothesis) is thus the total area under the density curve toward the
    right of the red line. We then double the result to account for the opposite direction.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Visualizing the density plot of the bootstrapped sample proportions
    for hypothesis testing](img/B18680_11_007.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
- en: Figure 11.7 – Visualizing the density plot of the bootstrapped sample proportions
    for hypothesis testing
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the p-value:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Since this result is less than the preset significance level of 5%, we have
    sufficient evidence to favor the alternative hypothesis and reject the null hypothesis.
    In other words, the assumed 19% is statistically different from the true population
    proportion with a confidence level of up to 95%. We can therefore draw the conclusion
    that the true population proportion is not 19%.
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The next section looks at the inference for the difference in sample proportions
    between two categorical variables.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Inference for the difference in sample proportions
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The setting now is that we have two categorical variables. Take gender and
    degree, for example. The data will report a proportion of degree holders for both
    females and males. A natural question to ask is whether males are more likely
    to get a degree than females. A particular dataset will report a snapshot of these
    proportions, which may or may not suggest a higher percentage of degree holders
    are males. The tools from hypothesis testing could then come in to answer the
    following question: if males are a higher proportion of degree holders in the
    dataset, is such difference statistically significant? In other words, are males
    more likely to get a degree than females, or vice versa? This section attempts
    to answer this type of question.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Inference for the difference in sample proportions between two categorical variables
    (for example, gender and degree) involves comparing the proportions of samples
    for each level in two different populations. This type of analysis is commonly
    used in experiments or observational studies to determine the existence of a significant
    difference in proportions between two groups. The main goal is to estimate the
    difference between the population proportions and determine whether this difference
    is statistically significant.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: The procedure for hypothesis testing is similar to before. We first formulate
    the null hypothesis, which assumes no difference between the proportion of the
    two populations, that is, p 1 = p 2, or p 1 − p 2 = 0\. The alternative hypothesis
    then states that their difference is not zero; that is, p 1 − p 2 ≠ 0\. Next,
    we choose a specific significance level and calculate the sample statistic (difference
    in sample proportion, including the pooled proportion between the two categorical
    variables) and the test statistic (via either a closed-form expression based on
    the assumed distribution or using the bootstrap method). Finally, we obtain the
    p-value and decide whether the observed result under the null hypothesis possesses
    statistical significance or not.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through a concrete exercise following our previous example.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.4 – performing hypothesis testing for the difference in sample proportions
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we focus on how to conduct hypothesis testing for the difference
    in the sample proportion between gender and status of higher degree. Here, we
    define a higher degree as a bachelor’s and above. The proportion of higher-degree
    holders will likely differ between the male and female groups, and we will test
    whether such a difference is significant given the observed data:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a binary column called `higher_degree` to the previous DataFrame, `gss2016`,
    to indicate the status of higher degree, including bachelor’s and above:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Print the ratio between the two levels for `gender` and `higher_degree`:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Plot these counts in a bar chart:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Running the code generates the chart in *Figure 11**.8*.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Visualizing the frequency count of gender and higher-degree
    status](img/B18680_11_008.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
- en: Figure 11.8 – Visualizing the frequency count of gender and higher-degree status
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also plot them in percentages by specifying `position = "fill"` in the
    `geom_bar()` function:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Running the code generates the chart in *Figure 11**.9*, which suggests no obvious
    difference in the proportion of higher-degree holders between the male and female
    groups.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Visualizing the frequency count of gender and higher-degree
    status](img/B18680_11_009.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 – Visualizing the frequency count of gender and higher-degree status
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the difference in sample proportions of higher-degree holders between
    males and females:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The result also shows that the difference is quite small, with the female group
    being 0.7% higher than the male group (refer to the slightly higher blue bar of
    the female group in the previous figure). Let us see whether such a difference
    is statistically significant.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate one bootstrap sample set under the null hypothesis, which states that
    there is no difference in the ratio of higher-degree holders between the male
    and female groups:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Here, we use `higher_degree` as the response variable and `sex` as the explanatory
    variable in a logistic regression setting (to be introduced in [*Chapter 13*](B18680_13.xhtml#_idTextAnchor279)).
    Under the null hypothesis, we randomly sample from the original dataset and create
    a new artificial dataset of the same shape.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Repeat the same bootstrap sampling procedures 500 times and calculate the difference
    in sample proportions of higher-degree holders between female and male groups
    (note the sequence here) for each set of bootstrapped samples:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Plot these bootstrapped sample statistics in a density curve and plot the observed
    difference as a vertical red line:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Running the code generates the plot in *Figure 11**.10*, which shows that the
    red line is not located toward the extreme side of the empirical distribution.
    This suggests that the p-value, which will be calculated next, may be high.
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Showing the density plot for the bootstrapped sample statistics
    and observed differences](img/B18680_11_010.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 – Showing the density plot for the bootstrapped sample statistics
    and observed differences
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'Compute the two-tailed p-value:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The result shows a pretty high p-value, which suggests that we lack sufficient
    evidence to reject the null hypothesis. In other words, there is not enough information
    to suggest that the proportion of higher-degree holders between males and females
    is different.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The hypothesis testing relies on a predefined significance level. That significance
    level, denoted as α, has something to do with the statistical error of the procedure.
    The next section introduces two common types of statistical error when performing
    hypothesis testing.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Type I and Type II errors
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are two types of errors when conducting hypothesis testing and making
    a decision about the null hypothesis (H0) and the alternative hypothesis (H1).
    They are called Type I and Type II errors.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: The Type I error refers to false positives. It happens when the null hypothesis
    is true but mistakenly rejected. In other words, we find evidence in our sample
    data that suggests a significant effect or difference exists and we favor the
    alternative hypothesis, even though it does not actually exist in the population.
    We denote the probability of experiencing a Type I error as α. It is also called
    the significance level, which was set to `0.05` in the previous example. A 5%
    significance level means that there is a 5% chance of rejecting the null hypothesis
    when it is true. The significance level thus represents the probability of committing
    a false positive error.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The Type II error focuses on the false negative case. It occurs when we fail
    to reject a false null hypothesis. In other words, we do not find evidence in
    our sample data to reject the null hypothesis, even though it does exist in the
    population. The probability of making a Type II error is denoted by β, which is
    also referred to as the power of the test. The complement of the power, denoted
    as 1 − β, represents the probability of rejecting the null hypothesis when it
    is false.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Type I errors involve falsely rejecting the null hypothesis, while Type II errors
    involve failing to reject the null hypothesis when false. Both types of errors
    are important considerations in hypothesis testing because they can lead to incorrect
    conclusions. To minimize the risk of these errors, we can make a careful choice
    regarding the significance level (α) and also ensure that their study has sufficient
    power (1 − β). The power of a test depends on the sample size, the effect size
    (which is a quantitative measure of the magnitude of an empirical relationship
    between variables), and the chosen significance level. Larger sample sizes and
    larger effect sizes both increase the power of a test, reducing the likelihood
    of Type II errors.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 11**.11* provides an overview of the different types of outcomes in
    a hypothesis test. Note that the false positive and false negative are related
    to the quality of the decision. Depending on the type of a false decision, we
    would classify the errors as either Type I or Type II errors.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – Overview of different types of outcomes in a hypothesis test](img/B18680_11_011.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 – Overview of different types of outcomes in a hypothesis test
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: The next section introduces the chi-square test, which tests the independence
    of two categorical variables.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Testing the independence of two categorical variables
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To check the independence of two categorical variables, the process involves
    checking the existence of a statistically significant relationship between them.
    One common procedure is the chi-square test for independence. It works by comparing
    the observed frequencies in a contingency table with the expected frequencies
    under the assumption of independence.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Let us first review the contingency table for two categorical variables.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the contingency table
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A contingency table, also known as a cross-tabulation or crosstab, is a table
    used to display the frequency distribution of two or more categorical variables.
    It summarizes the relationships between the variables by showing how their categories
    intersect or co-occur in the data. It provides a good summary of the relationships
    between categorical variables.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us stick with the example of the relationship between gender and degree.
    This time, we will look at all types of degrees, as shown in the following code:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To indicate its relationship with gender, we can plot the degree together with
    gender in a stacked bar plot as before:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Running the code generates the plot in *Figure 11**.12*.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12 – Visualizing the relationship between gender and degree in
    a bar plot](img/B18680_11_012.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 – Visualizing the relationship between gender and degree in a bar
    plot
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the figure provides no information on the exact count for each category.
    To obtain the exact frequency for each category of the two variables, we can use
    the contingency table:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here, we used the `table()` function to generate the contingency table after
    selecting both `sex` and `degree`.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: The next section introduces the chi-square test to test for the independence
    between these two categorical variables.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Applying the chi-square test for independence between two categorical variables
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The chi-square test is a statistical test used to decide a possibly significant
    relationship (dependence) between two categorical variables in a collection of
    observed samples. It can be used to test for independence or goodness of fit.
    In this chapter, we focus mainly on the test for independence between two categorical
    variables. The test compares the observed frequencies with the expected ones in
    a contingency table, assuming that the variables are independent. If the observed
    and expected frequencies are significantly different, the test suggests that the
    variables are not independent; in other words, they are dependent on each other.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the same approach as before, we can generate an artificial bootstrapped
    dataset to obtain a sample statistic, called the chi-square statistic. This dataset
    is generated by permuting the original dataset under the assumption of independence
    in the null hypothesis. In the following code, we generate one permutated dataset
    of the same shape as the original dataset, assuming independence under the null
    hypothesis:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, we create 500 permutated datasets and extract the corresponding chi-square
    statistic:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To run the test, we obtain the expected frequency for each cell in the contingency
    table under the assumption of independence between the categorical variables.
    The expected frequency for a cell is computed as (*row sum * column sum*) */*
    *overall sum*:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here, we first obtain the row-wise and column-wise sum, as well as the total
    sum. We then use the `outer()` function to obtain the outer product between these
    two vectors, which is then scaled by the total sum to obtain the expected frequency
    count in each cell.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we compute the observed chi-square statistic based on the available samples:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We can then plot the observed chi-square statistic within the density curve
    of previous bootstrapped sample statistics to get a sense of where the observed
    statistic is located, based on which we will be able to calculate the corresponding
    p-value:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Running the code generates the plot in *Figure 11**.13*, which shows a high
    p-value.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.13 – Visualizing the density curve of bootstrapped chi-square statistics
    and the observed statistic](img/B18680_11_013.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
- en: Figure 11.13 – Visualizing the density curve of bootstrapped chi-square statistics
    and the observed statistic
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can calculate the p-value. As shown in the following code, the p-value
    of `0.72` is indeed quite high, and thus there is no sufficient evidence to reject
    the null hypothesis:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In the next section, we will shift to look at statistical inference for numerical
    data.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Statistical inference for numerical data
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will switch to look at statistical inference using numerical
    data. We will cover two approaches. The first approach relies on the bootstrapping
    procedure and permutes the original dataset to create additional artificial datasets,
    which can then be used to derive the confidence intervals. The second approach
    uses a theoretical assumption on the distribution of the bootstrapped samples
    and relies on the t-distribution to achieve the same result. We will learn how
    to perform a t-test, derive a confidence interval, and conduct an **analysis of**
    **variance** (**ANOVA**).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: As discussed earlier, bootstrapping is a non-parametric resampling method that
    allows us to estimate the sampling distribution of a particular statistic, such
    as the mean, median, or proportion, as in the previous section. This is achieved
    by repeatedly drawing random samples with replacement from the original data.
    By doing so, we can calculate confidence intervals and perform hypothesis tests
    without relying on specific distributional assumptions.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the t-distribution is a probability distribution used for hypothesis
    testing if the sample size is small and the standard deviation of the population
    data remains unknown. It is a more general approach that assumes the bootstrapped
    samples follow a specific distribution. We will then use this distribution to
    estimate confidence intervals and perform the hypothesis test.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: The t-test is a widely used statistical test that allows us to compare the mean
    values of two groups or test whether the mean of a single group is equal to a
    specific value. This time, our interest is the mean of a group since the variable
    is numeric. The test relies on the t-distribution and takes into account the sample
    sizes, sample means, and sample variances.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Confidence intervals offer a list of possible values, where the true population
    statistic, such as the mean or proportion, is likely to lie, with a specified
    level of confidence (specified by the significance level α).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, ANOVA extends the t-test used when there are more than two groups
    to compare. ANOVA helps us determine possible significant differences among the
    group means by dividing the total variability of the observed data into two parts:
    between-group variability and within-group variability. It tests the null hypothesis
    that the mean values of all groups are equal. If the null hypothesis is rejected,
    we can continue to identify which specific group means differ from each other.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Let us start with generating a bootstrap distribution for the median.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Generating a bootstrap distribution for the median
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed earlier, when building a bootstrap distribution for a single statistic,
    we first generate a collection of bootstrap samples via sampling with replacement,
    and then record the relevant statistic (in this case, the median) of each distribution.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through an exercise to build the collection of bootstrap samples.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.5 – generating a bootstrap distribution for the sample median
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will apply the same specify-generate-calculate workflow
    using the `infer` package to generate a bootstrap distribution for the sample
    median using the `mtcars` dataset.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `mtcars` dataset and view its structure:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The result shows that we have a dataset with 32 rows and 11 columns. In the
    following steps, we will use the `mpg` variable and generate a bootstrap distribution
    of its median:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate 10,000 bootstrap samples according to the `mpg` variable and obtain
    the median of all samples:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Here, we specify `stat = "median"` in the `calculate()` function to extract
    the median in each bootstrap sample.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '2. Plot the bootstrap distribution as a density curve of the bootstrapped sample
    statistics:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Running the code generates the plot in *Figure 11**.14*.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.14 – Visualizing the density curve of the bootstrapped sample median](img/B18680_11_014.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
- en: Figure 11.14 – Visualizing the density curve of the bootstrapped sample median
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: The next section looks at constructing the bootstrapped confidence interval.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Constructing the bootstrapped confidence interval
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have looked at how to construct the bootstrapped confidence interval using
    the standard error method. This involves adding and subtracting the scaled standard
    error from the observed sample statistic. It turns out that there is another,
    simpler method, which just uses the percentile of the bootstrap distribution to
    obtain the confidence interval.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us continue with the previous example. Say we would like to calculate the
    95% confidence interval of the previous bootstrap distribution. We can achieve
    this by calculating the upper and lower quantiles (97.5% and 2.5%, respectively)
    of the bootstrap distribution. The following code achieves this:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let us also calculate the bootstrap confidence interval using the standard
    error method, as shown in the following code:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: As expected, the result is close to the one obtained using the percentile method.
    However, the standard error method is a more accurate method than the percentile
    method.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: The next section covers re-centering a bootstrap distribution upon testing a
    null hypothesis.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Re-centering a bootstrap distribution
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bootstrap distribution from the previous section is generated by randomly
    sampling the original dataset with replacement. Each set of bootstrap samples
    maintains the same size as the original sample sets. However, we cannot directly
    use this bootstrap distribution for hypothesis testing.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Upon introducing a null hypothesis, what we did in the previous hypothesis test
    section for two categorical variables is re-generated a new bootstrap distribution
    under the null hypothesis. We then place the observed sample statistic as a vertical
    red line along the bootstrap distribution to calculate the p-value, representing
    the probability of experiencing a phenomenon at least as extreme as the observed
    sample statistic. The only additional step is to generate the bootstrap distribution
    under the null hypothesis.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: When generating bootstrap samples under the null hypothesis, the main idea is
    to remove the effect we are testing for and create samples, assuming the null
    hypothesis is true. In other words, we create samples that would be expected if
    there were no difference between the groups. For example, when comparing means
    between two groups, we would subtract the overall mean from each observation to
    center the data around 0 before performing the random sampling with replacement.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: There is another way to achieve this. Recall that the original bootstrap distribution,
    by design, is centered around the observed sample statistic. Upon introducing
    the null hypothesis, we could simply move the original bootstrap distribution
    to be centered around the statistic in the null hypothesis, which is the null
    value. This shifted bootstrap distribution represents the same distribution if
    we were to remove the effect in the original dataset and then perform bootstrap
    sampling again. We can then place the observed sample statistic along the shifted
    bootstrap distribution to calculate the corresponding p-value, which represents
    the ratio of simulations that generate a sample statistic at least as favorable
    to the alternative hypothesis as the actual sample statistic. *Figure 11**.15*
    demonstrates this process.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.15 – Shifting the bootstrap distribution to be centered around
    the null value](img/B18680_11_015.jpg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
- en: Figure 11.15 – Shifting the bootstrap distribution to be centered around the
    null value
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us generate the bootstrap distribution for hypothesis testing for the previous
    example. We want to test the null hypothesis with a population median of 16 for
    the `mpg` variable. The following code generates the bootstrapped sample statistics,
    where we specify the null value via `med = 16` and the point estimate with `null
    = "point"` in the `hypothesize()` function:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, we plot these bootstrapped sample statistics in a density plot, along
    with the observed sample statistic as a vertical red line:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Running the code generates the plot in *Figure 11**.16*, which shows a small
    p-value.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.16 – Density plot of bootstrapped sample medians and observed sample
    median (vertical red line)](img/B18680_11_016.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
- en: Figure 11.16 – Density plot of bootstrapped sample medians and observed sample
    median (vertical red line)
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will cover another distribution-based inference approach
    based on the **central limit** **theorem** (**CLT**).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the central limit theorem used in t-distribution
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CLT says that the distribution from the sum (or average) of many independent
    and identically distributed random variables would jointly form a normal distribution,
    regardless of the underlying distribution of these individual variables. Due to
    the CLT, normal distribution is often used to approximate the sampling distribution
    of various statistics, such as the sample mean and the sample proportion.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: The t-distribution is related to the CLT in the context of statistical inference.
    When we’re estimating a population mean from a sample, we often have no access
    to the true standard deviation of the population. Instead, we resort to the sample
    standard deviation as an estimate. In this case, the sampling distribution of
    the sample mean doesn’t follow a normal distribution, but rather a t-distribution.
    In other words, when we extract the sample mean from a set of observed samples,
    and we are unsure of the population standard deviation (as is often the case when
    working with actual data), the sample mean can be modeled as a realization from
    the t-distribution.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: The t-distribution is a family of continuous probability distributions that
    are symmetric and bell-shaped, which shows similarity to the normal distribution.
    However, the t-distribution shows heavier tails, which accounts for the greater
    uncertainty due to estimating the population standard deviation from the observed
    data. That is, observations of a t-distribution are more likely to fall into distant
    tails (such as beyond two standard deviations away from the mean) than the normal
    distribution. The shape of the t-distribution relies on the **degrees of freedom**
    (**df**), which depends on the sample size and determines the thickness of the
    tails. As more samples are collected, the df moves up, and the t-distribution
    gradually approximates the normal distribution.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: We briefly covered the `qt()` function used to find the cutoffs under the t-distribution
    in the previous chapter. Now let us go through an exercise to get more familiar
    with calculations related to the t-distribution.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.6 – understanding the t-distribution
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `pt()` function to find probabilities under
    the t-distribution. For a given cutoff quantile value, `q`, and a given `df`,
    the `pt(q, df)` function gives us the probability under the t-distribution with
    `df` for values of `t` less than `q`. In other words, we have P(t df < T) = `pt(q
    = T, df)`. We can also use the `qt()` function to find the quantiles for a specific
    probability under the t-distribution. That is, if P(t df < T) = p, then T = `qt(p,
    df)`:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the probability under the t-distribution with 10 df below `T=3`:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Find the probability under the t-distribution with 10 df above `T=3`:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Note that we first calculate the probability of being below a specific cutoff
    value under the t-distribution, and then take the complement to find the probability
    above the threshold.
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Find the probability under the t-distribution with `100` df above `T=3`:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Since `df=100` has a better approximation to the normal distribution than `df=10`,
    the resulting probability, `z`, is thus smaller than `y`.
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Find the 95th percentile of the t-distribution with 10 df:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Find the cutoff value that bounds the upper end of the middle 95th percentile
    of the t-distribution with `10` df:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Here, the upper end of the middle 95th percentile refers to the 97.5th percentile.
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Find the cutoff value that bounds the upper end of the middle 95th percentile
    of the t-distribution with `100` df:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The next section discusses how to construct the confidence interval for the
    population mean using the t-distribution.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: Constructing the confidence interval for the population mean using the t-distribution
  id: totrans-307
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us review the process of statistical inference for the population mean.
    We start with a limited sample, from which we can derive the sample mean. Since
    we want to estimate the population mean, we would like to perform statistical
    inference based on the observed sample mean and quantify the range where the population
    statistic may exist.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the average miles per gallon, shown in the following code, is
    around 20 in the `mtcars` dataset:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Given this result, we won’t be surprised to encounter another similar dataset
    with an average `mpg` of 19 or 21\. However, we would be surprised if the value
    is 5, 50, or even 100\. When assessing a new collection of samples, we need a
    way to quantify the variability of the sample mean across multiple samples. We
    have learned two ways to do this: use the bootstrap approach to simulate artificial
    samples or use the CLT to approximate such variability. We will focus on the CLT
    approach in this section.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the CLT, the sample mean of any sampling distribution would be
    approximately normally distributed, regardless of the original distribution. In
    other words, we have the following:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: _ x  ∼ N(mean = μ, SE =  σ _ √ _ n  )
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that this is a theoretical distribution we are unable to obtain. For example,
    the population standard deviation, σ, stays unknown, and we only have access to
    the observed samples. Instead, we would estimate the standard error using the
    sample standard deviation, s, giving the following:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: _ x  ∼ N(mean = μ, SE =  s _ √ _ n  )
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: We would then employ the t-distribution of n − 1 degree of freedom to make an
    inference for the population mean as it gives thicker tails due to the additional
    uncertainty introduced by s.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: In addition, note that the approximation using the CLT relies on a few assumptions.
    For example, the samples need to be independent of each other. This is often satisfied
    when the samples are randomly selected, or if the samples account for less than
    10% of the total population if they are selected without replacement. The sample
    size also needs to be larger to account for potential skewness in the samples.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 'We can construct the 95% confidence interval using the `t.test()` function,
    as shown in the following code:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Here, we are performing a one-sample t-test, where the default null hypothesis
    states that the population mean is 0\. The result shows a very small p-value,
    suggesting that we could reject the null hypothesis in favor of the alternative
    hypothesis; that is, the population mean is not 0\. The 95% confidence interval
    (between `17.91768` and `22.26357`) is also constructed based on the t-distribution
    with a `df` of `31` and a t-statistic of `18.857`.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: The next section reviews the hypothesis testing for two means using both bootstrap
    simulation and t-test approximation.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: Performing hypothesis testing for two means
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore the process of comparing two sample means using
    hypothesis testing. When comparing two sample means, we want to determine whether
    a significant difference exists between the means of two distinct populations
    or groups.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Suppose now we have two groups of samples. These two groups could represent
    a specific value before and after treatment for each sample. Our objective is
    thus to compare the sample statistics of these two groups, such as the sample
    mean, and determine whether the treatment has an effect. To do this, we can perform
    a hypothesis test to compare mean values from the two independent distributions
    using either bootstrap simulation or t-test approximation.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: When using the t-test in the hypothesis test to compare the mean values of two
    independent samples, the two-sample t-test assumes normal distribution for the
    data, and that the variances of the two populations are equal. However, in cases
    where these assumptions may not hold, alternative non-parametric tests or resampling
    methods, such as bootstrap, can be employed to make inferences about the population
    means.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through an exercise to see these two methods of hypothesis testing
    in play.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.7 – comparing two means
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will explore two approaches (t-test and bootstrap) to
    compare two sample means and calculate the confidence interval of the difference
    in sample means:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a dummy dataset that consists of two groups of samples:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Here, we created a `tibble` DataFrame with the `value` column indicating the
    sample observation and the `group` column indicating the group number. We would
    like to assess the difference in the sample mean between these two groups.
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform bootstrap sampling `1000` times and calculate the bootstrap statistics
    under the null hypothesis that these two groups are independent of each other,
    and there is no difference in their means:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Here, the pipeline for the hypothesis test starts by specifying the response
    (`value`) and explanatory (`group`) variables, setting up the null hypothesis,
    generating bootstrap samples under the null hypothesis, and then calculating the
    test statistic (in this case, the difference in means) for each bootstrap sample.
    The null hypothesis states that we assume the sample mean values for both groups
    come from the same population, and that any observed difference is merely due
    to chance.
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the confidence interval based on the bootstrap statistics:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Perform a two-sample t-test using the `t.test()` function:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The result shows that the 95% confidence interval based on the t-distribution
    is close but still different from the one obtained via bootstrap sampling. We
    can also perform the t-test by passing in the model form:'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The next section introduces ANOVA, or the analysis of variance.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: Introducing ANOVA
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**ANOVA** is a statistical hypothesis testing method used to compare the means
    of more than two groups, which extends the two-sample t-test discussed in the
    previous section. The goal of ANOVA is to test potential significant differences
    among the group means (the between-group variability) while accounting for the
    variability within each group (the within-group variability).'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: 'ANOVA relies on the F-statistic in hypothesis testing. The F-statistic is a
    ratio of two estimates of variance: the between-group variance and the within-group
    variance. The between-group variance measures the differences among the group
    means, while the within-group variance represents the variability within each
    group. The F-statistic can be calculated based on these two group variances.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: In hypothesis testing, the null hypothesis for ANOVA states that all group means
    are equal, and any observed differences are due to chance. The alternative hypothesis,
    on the other hand, suggests that at least one group’s mean differs from the others.
    If the F-statistic is sufficiently large, the between-group variance is significantly
    greater than the within-group variance, which provides evidence against the null
    hypothesis.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us look at a concrete example. We first load the `PlantGrowth` dataset,
    which contains the weights of plants after they have been subjected to three different
    treatments:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Next, we perform the one-way ANOVA test using the same specify-hypothesize-generate-calculate
    procedure. Specifically, we first specify the response variable (`weight`) and
    the explanatory variable (`group`). We then set up the null hypothesis, stating
    no difference in the means of the groups, using `hypothesize(null = "independence")`.
    Next, we generate 1,000 permuted datasets using `generate(reps = 1000, type =
    "permute")`. Finally, we calculate the F-statistic for each permuted dataset using
    `calculate(stat = "``F")`:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Last, we can calculate the p-value using the observed F-statistic and the distribution
    of the F-statistics obtained from the permuted datasets. When the p-value is smaller
    than the preset significance level (for example, `0.05`), we could reject the
    null hypothesis and say that there is a significant difference among the means
    of the groups:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The result suggests that we do not have enough confidence to reject the null
    hypothesis.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered different types of statistical inferences for hypothesis
    testing, targeting both numerical and categorical data. We introduced inference
    methods for a single variable, two variables, and multiple variables, using either
    proportion (for categorical variable) or mean (for numerical variable) as the
    sample statistic. The hypothesis testing procedure, including both the parametric
    approach using model-based approximation and the non-parametric approach using
    bootstrap-based simulations, offers valuable tools such as the confidence interval
    and p-value. These tools allow us to make a decision about whether we can reject
    the null hypothesis in favor of the alternative hypothesis. Such a decision also
    relates to the Type I and Type II errors.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will cover one of the most widely used statistical
    and ML models: linear regression.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
