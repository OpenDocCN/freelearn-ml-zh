- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Statistical Estimation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡ä¼°è®¡
- en: In this chapter, we will introduce you to a range of statistical techniques
    that enable you to make inferences and estimations using both numerical and categorical
    data. We will explore key concepts and methods, such as hypothesis testing, confidence
    intervals, and estimation techniques, that empower us to make generalizations
    about populations from a given sample.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†å‘æ‚¨ä»‹ç»ä¸€ç³»åˆ—ç»Ÿè®¡æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯ä½¿æ‚¨èƒ½å¤Ÿä½¿ç”¨æ•°å€¼å’Œåˆ†ç±»æ•°æ®æ¥è¿›è¡Œæ¨æ–­å’Œä¼°è®¡ã€‚æˆ‘ä»¬å°†æ¢è®¨å…³é”®æ¦‚å¿µå’Œæ–¹æ³•ï¼Œå¦‚å‡è®¾æ£€éªŒã€ç½®ä¿¡åŒºé—´å’Œä¼°è®¡æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯ä½¿æˆ‘ä»¬èƒ½å¤Ÿä»ç»™å®šçš„æ ·æœ¬ä¸­å¯¹æ€»ä½“è¿›è¡Œæ¦‚æ‹¬ã€‚
- en: By the end of this chapter, you will grasp the core concepts of statistical
    inference and be able to perform hypothesis testing in different scenarios.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°æœ¬ç« ç»“æŸæ—¶ï¼Œæ‚¨å°†æŒæ¡ç»Ÿè®¡æ¨æ–­çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¹¶èƒ½å¤Ÿåœ¨ä¸åŒåœºæ™¯ä¸‹è¿›è¡Œå‡è®¾æ£€éªŒã€‚
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« å°†æ¶µç›–ä»¥ä¸‹ä¸»è¦å†…å®¹ï¼š
- en: Statistical inference for categorical data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç±»æ•°æ®çš„ç»Ÿè®¡æ¨æ–­
- en: Statistical inference for numerical data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°å€¼æ•°æ®çš„ç»Ÿè®¡æ¨æ–­
- en: Constructing the bootstrapped confidence interval
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„å»ºè‡ªåŠ©æ³•ç½®ä¿¡åŒºé—´
- en: Introducing the central limit theorem used in t-distribution
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»‹ç»tåˆ†å¸ƒä¸­ä½¿ç”¨çš„ä¸­å¿ƒæé™å®šç†
- en: Constructing the confidence interval for the population mean using the t-distribution
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨tåˆ†å¸ƒæ„å»ºæ€»ä½“å‡å€¼çš„ç½®ä¿¡åŒºé—´
- en: Performing hypothesis testing for two means
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹ä¸¤ä¸ªå‡å€¼è¿›è¡Œå‡è®¾æ£€éªŒ
- en: Introducing ANOVA
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»‹ç»æ–¹å·®åˆ†æï¼ˆANOVAï¼‰
- en: 'To run the code in this chapter, you will need to have the latest versions
    of the following packages:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è¿è¡Œæœ¬ç« ä¸­çš„ä»£ç ï¼Œæ‚¨éœ€è¦ä»¥ä¸‹è½¯ä»¶åŒ…çš„æœ€æ–°ç‰ˆæœ¬ï¼š
- en: '`dplyr`, 1.0.10'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dplyr`ï¼Œ1.0.10'
- en: '`ggplot2`, 3.4.0'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ggplot2`ï¼Œ3.4.0'
- en: '`socviz`, 1.2'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`socviz`ï¼Œ1.2'
- en: '`infer`, 1.0.4'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`infer`ï¼Œ1.0.4'
- en: Please note that the versions mentioned in the preceding list are the latest
    ones at the time I am writing this book. All the code and data for this chapter
    is available at [https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_11/working.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_11/working.R).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå‰é¢æåˆ°çš„ç‰ˆæœ¬æ˜¯åœ¨æˆ‘æ’°å†™æœ¬ä¹¦æ—¶çš„æœ€æ–°ç‰ˆæœ¬ã€‚æœ¬ç« çš„æ‰€æœ‰ä»£ç å’Œæ•°æ®å‡å¯åœ¨[https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_11/working.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_11/working.R)æ‰¾åˆ°ã€‚
- en: Statistical inference for categorical data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆ†ç±»æ•°æ®çš„ç»Ÿè®¡æ¨æ–­
- en: A categorical variable has distinct categories or levels, rather than numerical
    values. Categorical data is common in our daily lives, such as gender (male or
    female, although a modern view may differ), type of property sales (new property
    or resale), and industry. The ability to make sound inferences about these variables
    is thus essential for drawing meaningful conclusions and making well-informed
    decisions in diverse contexts.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªåˆ†ç±»å˜é‡å…·æœ‰ä¸åŒçš„ç±»åˆ«æˆ–æ°´å¹³ï¼Œè€Œä¸æ˜¯æ•°å€¼ã€‚åˆ†ç±»æ•°æ®åœ¨æˆ‘ä»¬çš„æ—¥å¸¸ç”Ÿæ´»ä¸­å¾ˆå¸¸è§ï¼Œä¾‹å¦‚æ€§åˆ«ï¼ˆç”·æ€§æˆ–å¥³æ€§ï¼Œå°½ç®¡ç°ä»£è§‚ç‚¹å¯èƒ½ä¸åŒï¼‰ã€æˆ¿äº§é”€å”®ç±»å‹ï¼ˆæ–°æˆ¿æˆ–äºŒæ‰‹æˆ¿ï¼‰å’Œè¡Œä¸šã€‚å› æ­¤ï¼Œå¯¹è¿™äº›å˜é‡è¿›è¡Œåˆç†æ¨æ–­çš„èƒ½åŠ›å¯¹äºåœ¨å¤šç§æƒ…å¢ƒä¸‹å¾—å‡ºæœ‰æ„ä¹‰çš„ç»“è®ºå’Œåšå‡ºæ˜æ™ºçš„å†³ç­–è‡³å…³é‡è¦ã€‚
- en: Being a categorical variable often means we cannot pass it to a `string` values
    such as `"finance"` or `"technology"`) to the model, a common approach is to one-hot
    encode the variable into multiple columns, with each column corresponding to a
    specific industry, indicating a binary value of `0` or `1`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºåˆ†ç±»å˜é‡ï¼Œé€šå¸¸æ„å‘³ç€æˆ‘ä»¬æ— æ³•å°†å…¶ä¼ é€’ç»™æ¨¡å‹ä¸­çš„å­—ç¬¦ä¸²å€¼ï¼ˆå¦‚ `"finance"` æˆ– `"technology"`ï¼‰ï¼Œä¸€ç§å¸¸è§çš„æ–¹æ³•æ˜¯å°†å˜é‡ä¸€çƒ­ç¼–ç æˆå¤šä¸ªåˆ—ï¼Œæ¯åˆ—å¯¹åº”ä¸€ä¸ªç‰¹å®šè¡Œä¸šï¼Œè¡¨ç¤ºäºŒè¿›åˆ¶å€¼
    `0` æˆ– `1`ã€‚
- en: In this section, we will explore various statistical techniques designed specifically
    to handle categorical data, enabling us to derive valuable insights and make inferences
    about populations based on available samples. We will also discuss important concepts,
    such as proportions, independence, and goodness of fit, which form the foundation
    for understanding and working with categorical variables, covering both cases
    with a single parameter and multiple parameters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸“é—¨ç”¨äºå¤„ç†åˆ†ç±»æ•°æ®çš„å„ç§ç»Ÿè®¡æŠ€æœ¯ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿæ ¹æ®å¯ç”¨çš„æ ·æœ¬å¾—å‡ºæœ‰ä»·å€¼çš„è§è§£å¹¶å¯¹æ€»ä½“è¿›è¡Œæ¨æ–­ã€‚æˆ‘ä»¬è¿˜å°†è®¨è®ºé‡è¦æ¦‚å¿µï¼Œå¦‚æ¯”ä¾‹ã€ç‹¬ç«‹æ€§å’Œæ‹Ÿåˆä¼˜åº¦ï¼Œè¿™äº›æ¦‚å¿µæ˜¯ç†è§£å’Œå¤„ç†åˆ†ç±»å˜é‡çš„åŸºç¡€ï¼ŒåŒ…æ‹¬å•å‚æ•°å’Œå¤šå‚æ•°çš„æƒ…å†µã€‚
- en: Let us start by discussing the inference for a single parameter.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»å•ä¸ªå‚æ•°çš„æ¨æ–­å¼€å§‹è®¨è®ºã€‚
- en: Statistical inference for a single parameter
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å•ä¸ªå‚æ•°çš„ç»Ÿè®¡æ¨æ–­
- en: A population parameter, the subject of interest and to be inferred, is a fixed
    quantity that describes a particular statistical attribute of a population, including
    the mean, proportion, or standard deviation. This quantity often stays hidden
    from us. For example, in order to get the most popular major in a university,
    we need to count the number of enrolled students in each major across the whole
    university and then return the major with the biggest count.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ€»ä½“å‚æ•°ï¼Œæˆ‘ä»¬æ„Ÿå…´è¶£å¹¶è¦æ¨æ–­çš„ä¸»é¢˜ï¼Œæ˜¯ä¸€ä¸ªæè¿°æ€»ä½“ç‰¹å®šç»Ÿè®¡å±æ€§çš„å›ºå®šæ•°é‡ï¼ŒåŒ…æ‹¬å‡å€¼ã€æ¯”ä¾‹æˆ–æ ‡å‡†å·®ã€‚è¿™ä¸ªæ•°é‡é€šå¸¸å¯¹æˆ‘ä»¬æ¥è¯´æ˜¯éšè—çš„ã€‚ä¾‹å¦‚ï¼Œä¸ºäº†å¾—åˆ°å¤§å­¦ä¸­æœ€å—æ¬¢è¿çš„ä¸“ä¸šï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ•´ä¸ªå¤§å­¦æ¯ä¸ªä¸“ä¸šæ³¨å†Œçš„å­¦ç”Ÿæ•°é‡ï¼Œç„¶åè¿”å›è®¡æ•°æœ€å¤§çš„ä¸“ä¸šã€‚
- en: In the context of statistical inference for a single parameter, we aim to estimate
    this unknown parameter or test hypotheses about its value based on the information
    gathered from a sample. In other words, we would use statistical inference tools
    to infer unknown population parameters based on the known sample at hand. In the
    previous example, we would infer the most popular major of the whole university
    by a limited sample of students enrolled in a specific academic year.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å•å‚æ•°ç»Ÿè®¡æ¨æ–­çš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä¼°è®¡è¿™ä¸ªæœªçŸ¥å‚æ•°æˆ–åŸºäºä»æ ·æœ¬æ”¶é›†çš„ä¿¡æ¯æ¥æµ‹è¯•å…¶å€¼çš„ç›¸å…³å‡è®¾ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ç»Ÿè®¡æ¨æ–­å·¥å…·ï¼Œæ ¹æ®å·²çŸ¥çš„æ ·æœ¬æ¥æ¨æ–­æœªçŸ¥çš„äººå£å‚æ•°ã€‚åœ¨å‰ä¸€ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡ç‰¹å®šå­¦æœ¯å¹´åº¦æ³¨å†Œçš„å­¦ç”Ÿæœ‰é™æ ·æœ¬æ¥æ¨æ–­æ•´ä¸ªå¤§å­¦æœ€å—æ¬¢è¿çš„ä¸“ä¸šã€‚
- en: Let us first explore the **General Social Survey** (**GSS**) dataset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å…ˆæ¢ç´¢ **ä¸€èˆ¬ç¤¾ä¼šè°ƒæŸ¥**ï¼ˆ**GSS**ï¼‰æ•°æ®é›†ã€‚
- en: Introducing the General Social Survey dataset
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»‹ç»ä¸€èˆ¬ç¤¾ä¼šè°ƒæŸ¥æ•°æ®é›†
- en: The GSS is a comprehensive dataset widely used by researchers and policymakers
    to understand social, cultural, and political trends in the United States. The
    GSS has been continued by the **National Opinion Research Center** (**NORC**)
    at the University of Chicago since 1972, with the objective of collecting data
    on a broad range of topics, including attitudes, behaviors, and opinions on various
    issues.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: GSS æ˜¯ä¸€ä¸ªç»¼åˆæ•°æ®é›†ï¼Œè¢«ç ”ç©¶äººå‘˜å’Œæ”¿ç­–åˆ¶å®šè€…å¹¿æ³›ç”¨äºç†è§£ç¾å›½çš„ç¤¾ä¼šã€æ–‡åŒ–å’Œæ”¿æ²»è¶‹åŠ¿ã€‚è‡ª 1972 å¹´ä»¥æ¥ï¼ŒGSS ç”±èŠåŠ å“¥å¤§å­¦çš„ **å›½å®¶æ°‘æ„ç ”ç©¶ä¸­å¿ƒ**ï¼ˆ**NORC**ï¼‰æŒç»­è¿›è¡Œï¼Œç›®çš„æ˜¯æ”¶é›†å…³äºå¹¿æ³›ä¸»é¢˜çš„æ•°æ®ï¼ŒåŒ…æ‹¬æ€åº¦ã€è¡Œä¸ºå’Œå¯¹å„ç§é—®é¢˜çš„è§‚ç‚¹ã€‚
- en: 'Let us load the GSS dataset from the `socviz` package (remember to install
    this package via `install.packages("socviz")`):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä» `socviz` åŒ…ä¸­åŠ è½½ GSS æ•°æ®é›†ï¼ˆè¯·è®°ä½é€šè¿‡ `install.packages("socviz")` å®‰è£…æ­¤åŒ…ï¼‰ï¼š
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The GSS dataset is now stored in the `gss_lon` variable, which contains a total
    of 62,466 rows and 25 columns, as shown here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: GSS æ•°æ®é›†ç°åœ¨å­˜å‚¨åœ¨ `gss_lon` å˜é‡ä¸­ï¼ŒåŒ…å«æ€»å…± 62,466 è¡Œå’Œ 25 åˆ—ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The GSS dataset contains numerous variables that cover diverse topics, such
    as education, income, family structure, political beliefs, and religious affiliation.
    Let us examine the structure of the dataset using the `glimpse()` function from
    the `dplyr` package, designed to help you quickly explore and understand the structure
    of the data:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: GSS æ•°æ®é›†åŒ…å«è®¸å¤šå˜é‡ï¼Œæ¶µç›–äº†å„ç§ä¸»é¢˜ï¼Œå¦‚æ•™è‚²ã€æ”¶å…¥ã€å®¶åº­ç»“æ„ã€æ”¿æ²»ä¿¡ä»°å’Œå®—æ•™å½’å±ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ `dplyr` åŒ…ä¸­çš„ `glimpse()` å‡½æ•°æ¥æ£€æŸ¥æ•°æ®é›†çš„ç»“æ„ï¼Œè¯¥å‡½æ•°æ—¨åœ¨å¸®åŠ©æ‚¨å¿«é€Ÿæ¢ç´¢å’Œç†è§£æ•°æ®ç»“æ„ï¼š
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Figure 11**.1* shows a screenshot of the first few variables returned.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ 11*.1 æ˜¾ç¤ºäº†è¿”å›çš„å‰å‡ ä¸ªå˜é‡çš„æˆªå›¾ã€‚'
- en: '![Figure 11.1 â€“ Showing the first few rows of the result from running the glimpse()
    function](img/B18680_11_001.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.1 â€“ å±•ç¤ºè¿è¡Œ glimpse() å‡½æ•°çš„ç»“æœçš„å‰å‡ è¡Œ](img/B18680_11_001.jpg)'
- en: Figure 11.1 â€“ Showing the first few rows of the result from running the glimpse()
    function
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.1 â€“ å±•ç¤ºè¿è¡Œ glimpse() å‡½æ•°çš„ç»“æœçš„å‰å‡ è¡Œ
- en: Next, we will look at calculating a specific statistic based on a categorical
    variable.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹åŸºäºåˆ†ç±»å˜é‡çš„ç‰¹å®šç»Ÿè®¡é‡çš„è®¡ç®—ã€‚
- en: Calculating the sample proportion
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¡ç®—æ ·æœ¬æ¯”ä¾‹
- en: The `siblings` column in the dataset is a categorical variable that tracks the
    number of siblings in the family. In the following exercise, we would like to
    calculate the proportion of survey respondents whose family has two siblings in
    the latest year, 2016.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†ä¸­çš„ `siblings` åˆ—æ˜¯ä¸€ä¸ªåˆ†ç±»å˜é‡ï¼Œè¿½è¸ªå®¶åº­ä¸­çš„å…„å¼Ÿå§å¦¹æ•°é‡ã€‚åœ¨æ¥ä¸‹æ¥çš„ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›è®¡ç®—åœ¨æœ€æ–°çš„ä¸€å¹´ï¼Œå³ 2016 å¹´ï¼Œå®¶åº­æœ‰ä¸¤ä¸ªå…„å¼Ÿå§å¦¹çš„å—è®¿è€…æ¯”ä¾‹ã€‚
- en: Exercise 11.1 â€“ calculating the sample proportion of siblings
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  11.1 â€“ è®¡ç®—å…„å¼Ÿå§å¦¹çš„æ ·æœ¬æ¯”ä¾‹
- en: 'In this exercise, we first obtain a summary of the `siblings` column and subset
    the dataset to focus on the year 2016, which will then be used to calculate the
    proportion of surveys with a specific number of siblings in the family:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè·å–`siblings`åˆ—çš„æ‘˜è¦ï¼Œå¹¶å¯¹æ•°æ®é›†è¿›è¡Œå­é›†åŒ–ä»¥å…³æ³¨2016å¹´ï¼Œç„¶åå°†å…¶ç”¨äºè®¡ç®—å®¶åº­ä¸­æœ‰ç‰¹å®šæ•°é‡å…„å¼Ÿå§å¦¹çš„è°ƒæŸ¥æ¯”ä¾‹ï¼š
- en: 'Obtain a summary of the `siblings` column using the `summary()` function:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`summary()`å‡½æ•°è·å–`siblings`åˆ—çš„æ‘˜è¦ï¼š
- en: '[PRE3]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The result suggests that most surveys are conducted for families with six siblings
    or more!
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç»“æœè¡¨æ˜ï¼Œå¤§å¤šæ•°è°ƒæŸ¥æ˜¯åœ¨æœ‰å…­ä¸ªæˆ–æ›´å¤šå…„å¼Ÿå§å¦¹çš„å®¶åº­ä¸­è¿›è¡Œçš„ï¼
- en: 'Subset the dataset for the year 2016:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹2016å¹´çš„æ•°æ®é›†è¿›è¡Œå­é›†åŒ–ï¼š
- en: '[PRE4]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Running the code generates the chart in *Figure 11**.2*.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿è¡Œä»£ç ç”Ÿæˆå›¾*11.2*ã€‚
- en: '![Figure 11.2 â€“ Visualizing the frequency count of the number of siblings in
    a bar chart](img/B18680_11_002.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.2 â€“ ä»¥æŸ±çŠ¶å›¾å¯è§†åŒ–å…„å¼Ÿå§å¦¹æ•°é‡çš„é¢‘ç‡è®¡æ•°](img/B18680_11_002.jpg)'
- en: Figure 11.2 â€“ Visualizing the frequency count of the number of siblings in a
    bar chart
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.2 â€“ ä»¥æŸ±çŠ¶å›¾å¯è§†åŒ–å…„å¼Ÿå§å¦¹æ•°é‡çš„é¢‘ç‡è®¡æ•°
- en: 'Calculate the proportion of surveys with two siblings:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æœ‰ä¸¤ä¸ªå…„å¼Ÿå§å¦¹çš„è°ƒæŸ¥æ¯”ä¾‹ï¼š
- en: '[PRE5]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, we use the `summarize()` function to calculate the mean of a series of
    binary values, which corresponds to the proportion of surveys with two siblings.
    We then use the `pull()` function to obtain the proportion from the resulting
    DataFrame.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨`summarize()`å‡½æ•°è®¡ç®—ä¸€ç³»åˆ—äºŒå…ƒå€¼çš„å¹³å‡å€¼ï¼Œè¿™å¯¹åº”äºæœ‰ä¸¤ä¸ªå…„å¼Ÿå§å¦¹çš„è°ƒæŸ¥æ¯”ä¾‹ã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨`pull()`å‡½æ•°ä»ç»“æœDataFrameä¸­è·å–æ¯”ä¾‹ã€‚
- en: We use the sample proportion to estimate the population statistic. In other
    words, we calculate the proportion of families with two siblings based on the
    available samples to approximate the corresponding proportion if we were to calculate
    the same based on all the data in the population. Such an estimate comes with
    a confidence interval that quantifies the list of possible values for the population
    proportion.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨æ ·æœ¬æ¯”ä¾‹æ¥ä¼°è®¡æ€»ä½“ç»Ÿè®¡é‡ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æ ¹æ®å¯ç”¨çš„æ ·æœ¬æ•°æ®è®¡ç®—æœ‰ä¸¤ä¸ªå…„å¼Ÿå§å¦¹çš„å®¶åº­æ¯”ä¾‹ï¼Œä»¥è¿‘ä¼¼å¦‚æœæˆ‘ä»¬åŸºäºæ€»ä½“ä¸­çš„æ‰€æœ‰æ•°æ®è®¡ç®—ç›¸åŒçš„æ¯”ä¾‹æ—¶å¯¹åº”çš„æ¯”ä¾‹ã€‚è¿™æ ·çš„ä¼°è®¡ä¼´éšç€ä¸€ä¸ªç½®ä¿¡åŒºé—´ï¼Œè¯¥åŒºé—´é‡åŒ–äº†æ€»ä½“æ¯”ä¾‹çš„å¯èƒ½å€¼åˆ—è¡¨ã€‚
- en: The next section shows how to calculate the confidence interval for the sample
    proportion.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€èŠ‚å°†å±•ç¤ºå¦‚ä½•è®¡ç®—æ ·æœ¬æ¯”ä¾‹çš„ç½®ä¿¡åŒºé—´ã€‚
- en: Calculating the confidence interval
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¡ç®—ç½®ä¿¡åŒºé—´
- en: The confidence interval is an important tool in making inferences about the
    population parameters based on sample data. A confidence interval provides an
    estimated range within which a population parameter, such as proportion, is likely
    to be found with a specified confidence level, such as 95%. When working with
    sample proportions, calculating confidence intervals allows us to understand the
    true proportion in the population better and gauge the uncertainty associated
    with the estimation of the population proportion.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç½®ä¿¡åŒºé—´æ˜¯åŸºäºæ ·æœ¬æ•°æ®å¯¹æ€»ä½“å‚æ•°è¿›è¡Œæ¨æ–­çš„é‡è¦å·¥å…·ã€‚ç½®ä¿¡åŒºé—´æä¾›äº†ä¸€ä¸ªä¼°è®¡èŒƒå›´ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªæ€»ä½“å‚æ•°ï¼Œå¦‚æ¯”ä¾‹ï¼Œåœ¨æŒ‡å®šçš„ç½®ä¿¡æ°´å¹³ï¼ˆå¦‚95%ï¼‰ä¸‹å¯èƒ½è¢«æ‰¾åˆ°ã€‚å½“å¤„ç†æ ·æœ¬æ¯”ä¾‹æ—¶ï¼Œè®¡ç®—ç½®ä¿¡åŒºé—´ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ€»ä½“ä¸­çš„çœŸå®æ¯”ä¾‹ï¼Œå¹¶è¯„ä¼°ä¸æ€»ä½“æ¯”ä¾‹ä¼°è®¡ç›¸å…³çš„ä¸ç¡®å®šæ€§ã€‚
- en: 'We can use the following steps to calculate the confidence interval:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ­¥éª¤æ¥è®¡ç®—ç½®ä¿¡åŒºé—´ï¼š
- en: Calculate the sample proportion, Â Ë†Â pÂ  (pronounced as p-hat). This is the value
    we calculated based on the sample data in 2016\. In other contexts, Â Ë†Â pÂ  is calculated
    by dividing the number of successes (for the attribute of interest) by the total
    sample size.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ ·æœ¬æ¯”ä¾‹ï¼ŒË†pï¼ˆè¯»ä½œp-hatï¼‰ã€‚è¿™æ˜¯æˆ‘ä»¬åŸºäº2016å¹´çš„æ ·æœ¬æ•°æ®è®¡ç®—å‡ºçš„å€¼ã€‚åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼ŒË†pæ˜¯é€šè¿‡å°†æˆåŠŸçš„æ•°é‡ï¼ˆå¯¹äºæ„Ÿå…´è¶£çš„å±æ€§ï¼‰é™¤ä»¥æ€»æ ·æœ¬é‡æ¥è®¡ç®—çš„ã€‚
- en: Determine the desired level of confidence, commonly denoted as (1 âˆ’ Î±) x 100%,
    where Î± represents the level of significance. In other words, it is the probability
    of rejecting the null hypothesis when it is true. The most frequently used confidence
    levels are 90%, 95%, and 99%.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¡®å®šæ‰€éœ€çš„ç½®ä¿¡æ°´å¹³ï¼Œé€šå¸¸è¡¨ç¤ºä¸º(1 âˆ’ Î±) x 100%ï¼Œå…¶ä¸­Î±ä»£è¡¨æ˜¾è‘—æ€§æ°´å¹³ã€‚æ¢å¥è¯è¯´ï¼Œè¿™æ˜¯åœ¨åŸå‡è®¾ä¸ºçœŸæ—¶æ‹’ç»é›¶å‡è®¾çš„æ¦‚ç‡ã€‚æœ€å¸¸ç”¨çš„ç½®ä¿¡æ°´å¹³æ˜¯90%ï¼Œ95%å’Œ99%ã€‚
- en: 'Calculate the standard error of the sample proportion, which is given by the
    following formula:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ ·æœ¬æ¯”ä¾‹çš„æ ‡å‡†è¯¯å·®ï¼Œå…¶å…¬å¼å¦‚ä¸‹ï¼š
- en: SE = âˆšÂ _Â Â Â Ë†Â pÂ (1 âˆ’ Â Ë†Â pÂ )Â _Â n
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: SE = âˆš(Ë†p(1 âˆ’ Ë†p) / n)
- en: 'Here, the standard error also corresponds to the standard deviation of the
    sample proportion, which is assumed to follow a Bernoulli distribution with a
    success probability of Â Ë†Â pÂ  (recall the introduction of Bernoulli distribution
    in the previous chapter). Such calculation relies on two assumptions: the observations
    in the samples are independent and there are sufficient observations in the sample.
    A common rule of thumb for checking the second assumption is to ensure both nÂ Ë†Â pÂ 
    > 10 and n(1 âˆ’ Â Ë†Â pÂ ) > 10.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæ ‡å‡†è¯¯å·®ä¹Ÿå¯¹åº”äºæ ·æœ¬æ¯”ä¾‹çš„æ ‡å‡†å·®ï¼Œå‡è®¾å®ƒéµå¾ªæˆåŠŸæ¦‚ç‡ä¸ºË†pçš„ä¼¯åŠªåˆ©åˆ†å¸ƒï¼ˆå›æƒ³ä¸€ä¸‹å‰ä¸€ç« ä¸­ä¼¯åŠªåˆ©åˆ†å¸ƒçš„ä»‹ç»ï¼‰ã€‚è¿™ç§è®¡ç®—ä¾èµ–äºä¸¤ä¸ªå‡è®¾ï¼šæ ·æœ¬ä¸­çš„è§‚æµ‹å€¼æ˜¯ç‹¬ç«‹çš„ï¼Œæ ·æœ¬ä¸­æœ‰è¶³å¤Ÿçš„è§‚æµ‹å€¼ã€‚æ£€æŸ¥ç¬¬äºŒä¸ªå‡è®¾çš„ä¸€ä¸ªå¸¸è§ç»éªŒæ³•åˆ™æ˜¯ç¡®ä¿nË†p
    > 10å’Œn(1 âˆ’ Ë†p) > 10ã€‚
- en: Alternatively, instead of assuming a Bernoulli distribution, we can use the
    bootstrap procedure to estimate the standard error without any distributional
    assumption. Bootstrap is a non-parametric method that involves resampling the
    data with replacement to create new samples, calculating the statistic of interest
    (in this case, the proportion) for each resampled dataset, and estimating the
    standard error from the variability of the calculated statistics across the resampled
    datasets.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ï¼Œæˆ‘ä»¬ä¸å¿…å‡è®¾ä¼¯åŠªåˆ©åˆ†å¸ƒï¼Œå¯ä»¥ä½¿ç”¨è‡ªä¸¾è¿‡ç¨‹æ¥ä¼°è®¡æ ‡å‡†è¯¯å·®ï¼Œè€Œä¸åšä»»ä½•åˆ†å¸ƒå‡è®¾ã€‚è‡ªä¸¾æ˜¯ä¸€ç§éå‚æ•°æ–¹æ³•ï¼Œæ¶‰åŠæœ‰æ”¾å›åœ°é‡æ–°æŠ½æ ·æ•°æ®ä»¥åˆ›å»ºæ–°çš„æ ·æœ¬ï¼Œå¯¹æ¯ä¸ªé‡æ–°æŠ½æ ·çš„æ•°æ®é›†è®¡ç®—æ„Ÿå…´è¶£çš„ç»Ÿè®¡é‡ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ˜¯æ¯”ä¾‹ï¼‰ï¼Œå¹¶ä»è®¡ç®—ç»Ÿè®¡é‡çš„å˜å¼‚æ€§ä¸­ä¼°è®¡æ ‡å‡†è¯¯å·®ã€‚
- en: 4. Find the critical value (z-score) corresponding to the preset confidence
    level. This can be done using the `qnorm()` function, which gives us the quantiles
    of the standard normal distribution.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 4. æ‰¾åˆ°å¯¹åº”äºé¢„è®¾ç½®ä¿¡æ°´å¹³çš„ä¸´ç•Œå€¼ï¼ˆzåˆ†æ•°ï¼‰ã€‚è¿™å¯ä»¥é€šè¿‡`qnorm()`å‡½æ•°å®Œæˆï¼Œå®ƒç»™å‡ºäº†æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„åˆ†ä½æ•°ã€‚
- en: '5. Compute the **margin of error** (**ME**) as the product of the standard
    error and the critical value:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 5. è®¡ç®—è¯¯å·®èŒƒå›´ï¼ˆMEï¼‰ä¸ºæ ‡å‡†è¯¯å·®ä¸ä¸´ç•Œå€¼çš„ä¹˜ç§¯ï¼š
- en: ME = SE * z _ score
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ME = SE * z _ score
- en: '6. Calculate the confidence interval by adding and subtracting the ME from
    the sample proportion, giving the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 6. é€šè¿‡ä»æ ·æœ¬æ¯”ä¾‹ä¸­åŠ å‡MEæ¥è®¡ç®—ç½®ä¿¡åŒºé—´ï¼Œå¾—åˆ°ä»¥ä¸‹ç»“æœï¼š
- en: Lower limit = Â Ë†Â pÂ  âˆ’ ME
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é™ = Ë†p âˆ’ ME
- en: Upper limit = Â Ë†Â pÂ  + ME
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šé™ = Ë†p + ME
- en: The confidence interval provides a list of possible values for the population
    proportion according to the specific confidence level. See *Figure 11**.3* for
    a summary of the calculation process.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ç½®ä¿¡åŒºé—´æ ¹æ®ç‰¹å®šçš„ç½®ä¿¡æ°´å¹³æä¾›äº†æ€»ä½“æ¯”ä¾‹çš„å¯èƒ½å€¼åˆ—è¡¨ã€‚å‚è§*å›¾11.3*å¯¹è®¡ç®—è¿‡ç¨‹çš„æ€»ç»“ã€‚
- en: '![Figure 11.3 â€“ Summarizing the process of calculating the confidence interval
    based on sample proportion](img/B18680_11_003.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.3 â€“ åŸºäºæ ·æœ¬æ¯”ä¾‹è®¡ç®—ç½®ä¿¡åŒºé—´çš„è¿‡ç¨‹æ€»ç»“](img/B18680_11_003.jpg)'
- en: Figure 11.3 â€“ Summarizing the process of calculating the confidence interval
    based on sample proportion
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.3 â€“ åŸºäºæ ·æœ¬æ¯”ä¾‹è®¡ç®—ç½®ä¿¡åŒºé—´çš„è¿‡ç¨‹æ€»ç»“
- en: Let us stay with the bootstrap procedure a little longer. Without assuming any
    specific distribution, the bootstrap procedure is a flexible approach that can
    provide more accurate estimates of the standard error, especially for small sample
    sizes or when the data is not well behaved. However, It can be computationally
    intensive, especially for large datasets or when many bootstrap replications are
    generated.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å†æ·±å…¥æ¢è®¨ä¸€ä¸‹è‡ªä¸¾è¿‡ç¨‹ã€‚ä¸å‡è®¾ä»»ä½•ç‰¹å®šåˆ†å¸ƒï¼Œè‡ªä¸¾è¿‡ç¨‹æ˜¯ä¸€ç§çµæ´»çš„æ–¹æ³•ï¼Œå¯ä»¥æä¾›æ›´å‡†ç¡®çš„æ ‡å‡†è¯¯å·®ä¼°è®¡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå°æ ·æœ¬é‡æˆ–æ•°æ®è¡¨ç°ä¸ä½³çš„æƒ…å†µã€‚ç„¶è€Œï¼Œå®ƒå¯èƒ½è®¡ç®—é‡å¾ˆå¤§ï¼Œå°¤å…¶æ˜¯åœ¨å¤§å‹æ•°æ®é›†æˆ–ç”Ÿæˆè®¸å¤šè‡ªä¸¾å¤åˆ¶æ—¶ã€‚
- en: '*Figure 11**.4* provides a schematic overview of the bootstrap procedure. Letâ€™s
    review:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾11.4* æä¾›äº†è‡ªä¸¾è¿‡ç¨‹çš„ç¤ºæ„å›¾ã€‚è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹ï¼š'
- en: First, we start with the whole dataset and specify the variable of interest,
    which is the `siblings` variable in this case. This is achieved via the `specify()`
    function.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬ä»æ•´ä¸ªæ•°æ®é›†å¼€å§‹ï¼Œå¹¶æŒ‡å®šæ„Ÿå…´è¶£çš„å˜é‡ï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­æ˜¯`å…„å¼Ÿå§å¦¹`å˜é‡ã€‚è¿™æ˜¯é€šè¿‡`specify()`å‡½æ•°å®ç°çš„ã€‚
- en: Next, we draw samples from the variable with replacement, where the new sample
    will be the same size as the original dataset. Such resampling introduces randomness
    to the resulting dataset.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä»å˜é‡ä¸­æŠ½å–æ ·æœ¬ï¼Œè¿›è¡Œæœ‰æ”¾å›æŠ½æ ·ï¼Œå…¶ä¸­æ–°æ ·æœ¬çš„å¤§å°ä¸åŸå§‹æ•°æ®é›†ç›¸åŒã€‚è¿™ç§é‡æŠ½æ ·å¼•å…¥äº†éšæœºæ€§åˆ°ç»“æœæ•°æ®é›†ä¸­ã€‚
- en: We repeat the process many times, leading to a collection of bootstrapped artificial
    datasets using the `generate()` function.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é‡å¤è¿™ä¸ªè¿‡ç¨‹å¤šæ¬¡ï¼Œä½¿ç”¨`generate()`å‡½æ•°å¾—åˆ°ä¸€ç³»åˆ—é€šè¿‡è‡ªä¸¾å¾—åˆ°çš„ä¼ªæ•°æ®é›†ã€‚
- en: For each replicated dataset, we will calculate the sample statistic of interest,
    which is the proportion of observations with two siblings in this case. This is
    done via the `calculate()` function.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªå¤åˆ¶çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å°†è®¡ç®—æ„Ÿå…´è¶£çš„æ ·æœ¬ç»Ÿè®¡é‡ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯å…·æœ‰ä¸¤ä¸ªå…„å¼Ÿå§å¦¹çš„è§‚å¯Ÿå€¼çš„æ¯”ä¾‹ã€‚è¿™æ˜¯é€šè¿‡`calculate()`å‡½æ•°å®Œæˆçš„ã€‚
- en: These sample statistics derived using repeated sampling of the original dataset
    will then form a distribution, called the bootstrapped distribution (plotted via
    `ggplot()`), whose standard deviation (extracted via the `summarize()` function)
    will be a good approximation of the standard error.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿™äº›é€šè¿‡é‡å¤æŠ½æ ·åŸå§‹æ•°æ®é›†å¾—åˆ°çš„æ ·æœ¬ç»Ÿè®¡é‡å°†å½¢æˆä¸€ä¸ªåˆ†å¸ƒï¼Œç§°ä¸ºè‡ªåŠ©æ³•åˆ†å¸ƒï¼ˆé€šè¿‡`ggplot()`ç»˜åˆ¶ï¼‰ï¼Œå…¶æ ‡å‡†å·®ï¼ˆé€šè¿‡`summarize()`å‡½æ•°æå–ï¼‰å°†æ˜¯å¯¹æ ‡å‡†è¯¯çš„è‰¯å¥½è¿‘ä¼¼ã€‚
- en: '![Figure 11.4 â€“ The schematic overview of obtaining the standard error using
    the bootstrap procedure](img/B18680_11_004.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.4 â€“ ä½¿ç”¨è‡ªåŠ©æ³•ç¨‹åºè·å–æ ‡å‡†è¯¯çš„ç¤ºæ„å›¾](img/B18680_11_004.jpg)'
- en: Figure 11.4 â€“ The schematic overview of obtaining the standard error using the
    bootstrap procedure
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.4 â€“ ä½¿ç”¨è‡ªåŠ©æ³•ç¨‹åºè·å–æ ‡å‡†è¯¯çš„ç¤ºæ„å›¾
- en: The bootstrapped samples convey different levels of uncertainty in the sample
    statistic and jointly form a density distribution of multiple artificial sample
    statistics. The standard deviation of the bootstrapped distribution then gives
    the standard error of the sample statistic. Note that functions such as `specify()`,
    `generate()`, and `calculate()` all come from the `infer` package in R. Remember
    to install this package before continuing with the following code.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è‡ªåŠ©æ³•å¾—åˆ°çš„æ ·æœ¬ä¼ è¾¾äº†æ ·æœ¬ç»Ÿè®¡é‡ä¸åŒæ°´å¹³çš„ä¸ç¡®å®šæ€§ï¼Œå¹¶å…±åŒå½¢æˆå¤šä¸ªäººå·¥æ ·æœ¬ç»Ÿè®¡é‡çš„å¯†åº¦åˆ†å¸ƒã€‚è‡ªåŠ©æ³•åˆ†å¸ƒçš„æ ‡å‡†å·®éšåç»™å‡ºæ ·æœ¬ç»Ÿè®¡é‡çš„æ ‡å‡†è¯¯ã€‚è¯·æ³¨æ„ï¼Œå¦‚`specify()`ã€`generate()`å’Œ`calculate()`ç­‰å‡½æ•°å‡æ¥è‡ªRä¸­çš„`infer`åŒ…ã€‚åœ¨ç»§ç»­ä»¥ä¸‹ä»£ç ä¹‹å‰ï¼Œè¯·è®°ä½å®‰è£…æ­¤åŒ…ã€‚
- en: Let us go through the following exercise to understand the bootstrap procedure
    for calculating the confidence interval.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹ç»ƒä¹ æ¥äº†è§£è®¡ç®—ç½®ä¿¡åŒºé—´çš„è‡ªåŠ©æ³•ç¨‹åºã€‚
- en: Exercise 11.2 â€“ calculating the confidence interval via bootstrap
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 11.2 â€“ é€šè¿‡è‡ªåŠ©æ³•è®¡ç®—ç½®ä¿¡åŒºé—´
- en: 'In this exercise, we will explore calculating the confidence interval of the
    sample proportion. The confidence interval includes the list of estimates within
    which the true population proportion may assume, given the observed samples. It
    is a way to quantify the uncertainty in estimating the population proportion based
    on the actual observations. Besides a step-by-step walk-through of the calculation
    process using bootstrap, we will also compare the result with the alternative
    approach using the assumed Bernoulli distribution:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢è®¡ç®—æ ·æœ¬æ¯”ä¾‹çš„ç½®ä¿¡åŒºé—´ã€‚ç½®ä¿¡åŒºé—´åŒ…æ‹¬ä¸€ç³»åˆ—ä¼°è®¡å€¼ï¼Œåœ¨è¿™äº›ä¼°è®¡å€¼ä¸­ï¼Œç»™å®šè§‚å¯Ÿåˆ°çš„æ ·æœ¬ï¼ŒçœŸå®æ€»ä½“æ¯”ä¾‹å¯èƒ½å–å€¼ã€‚è¿™æ˜¯åŸºäºå®é™…è§‚å¯Ÿæ¥é‡åŒ–ä¼°è®¡æ€»ä½“æ¯”ä¾‹ä¸ç¡®å®šæ€§çš„æ–¹æ³•ã€‚é™¤äº†ä½¿ç”¨è‡ªåŠ©æ³•é€æ­¥è®¡ç®—è¿‡ç¨‹å¤–ï¼Œæˆ‘ä»¬è¿˜å°†æ¯”è¾ƒä½¿ç”¨å‡è®¾çš„ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æ›¿ä»£æ–¹æ³•çš„ç»“æœï¼š
- en: 'Build a set of bootstrapped sample statistics using the specify-generate-calculate
    procedure from the `infer` package described earlier. Remember to build a binary
    variable to indicate the binary condition of having an observation with two siblings:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å‰é¢æè¿°çš„`infer`åŒ…ä¸­çš„æŒ‡å®š-ç”Ÿæˆ-è®¡ç®—ç¨‹åºæ„å»ºä¸€ç»„è‡ªåŠ©æ³•æ ·æœ¬ç»Ÿè®¡é‡ã€‚è¯·è®°ä½æ„å»ºä¸€ä¸ªäºŒå…ƒå˜é‡æ¥æŒ‡ç¤ºå…·æœ‰ä¸¤ä¸ªå…„å¼Ÿå§å¦¹çš„è§‚å¯Ÿå€¼çš„äºŒå…ƒæ¡ä»¶ï¼š
- en: '[PRE6]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we first create a binary indicator variable using the `if_else()` function
    to denote whether the family in the current survey has two siblings. We also remove
    rows with `NA` values in this column. Next, we use the `specify()` function to
    indicate the `siblings_two_ind` variable of interest and the level that corresponds
    to a success. We then use the `generate()` function to generate `500` bootstrapped
    samples, and use the `calculate()` function to obtain the corresponding sample
    statistic (proportion of success) in each bootstrapped sample by setting `stat
    = "``prop"`.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨`if_else()`å‡½æ•°åˆ›å»ºä¸€ä¸ªäºŒå…ƒæŒ‡æ ‡å˜é‡ï¼Œä»¥è¡¨ç¤ºå½“å‰è°ƒæŸ¥ä¸­çš„å®¶åº­æ˜¯å¦æœ‰ä¸¤ä¸ªå…„å¼Ÿå§å¦¹ã€‚æˆ‘ä»¬è¿˜åˆ é™¤äº†æ­¤åˆ—ä¸­å…·æœ‰`NA`å€¼çš„è¡Œã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨`specify()`å‡½æ•°æŒ‡å‡ºæ„Ÿå…´è¶£çš„`siblings_two_ind`å˜é‡åŠå…¶å¯¹åº”çš„æˆåŠŸçº§åˆ«ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨`generate()`å‡½æ•°ç”Ÿæˆ`500`ä¸ªè‡ªåŠ©æ³•æ ·æœ¬ï¼Œå¹¶ä½¿ç”¨`calculate()`å‡½æ•°é€šè¿‡è®¾ç½®`stat
    = "prop"`æ¥è·å–æ¯ä¸ªè‡ªåŠ©æ³•æ ·æœ¬ä¸­ç›¸åº”çš„æ ·æœ¬ç»Ÿè®¡é‡ï¼ˆæˆåŠŸæ¯”ä¾‹ï¼‰ã€‚
- en: 'Let us observe the contents in the bootstrapped sample statistics:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è§‚å¯Ÿè‡ªåŠ©æ³•æ ·æœ¬ç»Ÿè®¡é‡ä¸­çš„å†…å®¹ï¼š
- en: '[PRE7]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The result shows that the `bs` object is a `tibble` DataFrame with 500 rows
    (corresponding to the total number of the bootstrapped sample) and 2 columns.
    The first column (`replicate`) denotes the number of bootstrapped samples, and
    the second column (`stat`) indicates the proportion of success (that is, the number
    of rows with `siblings_two_ind==2` divided by the total number of rows) in the
    bootstrapped sample.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç»“æœæ˜¾ç¤ºï¼Œ`bs`å¯¹è±¡æ˜¯ä¸€ä¸ªåŒ…å«500è¡Œï¼ˆå¯¹åº”äºbootstrapæ ·æœ¬çš„æ€»æ•°ï¼‰å’Œ2åˆ—çš„`tibble` DataFrameã€‚ç¬¬ä¸€åˆ—ï¼ˆ`replicate`ï¼‰è¡¨ç¤ºbootstrapæ ·æœ¬çš„æ•°é‡ï¼Œç¬¬äºŒåˆ—ï¼ˆ`stat`ï¼‰è¡¨ç¤ºbootstrapæ ·æœ¬ä¸­æˆåŠŸçš„æ¯”ä¾‹ï¼ˆå³`siblings_two_ind==2`çš„è¡Œæ•°é™¤ä»¥æ€»è¡Œæ•°ï¼‰ã€‚
- en: 'Plot the bootstrapped sample statistics in a density plot:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å¯†åº¦å›¾ä¸­ç»˜åˆ¶bootstrapæ ·æœ¬ç»Ÿè®¡é‡ï¼š
- en: '[PRE8]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Running the code generates the plot in *Figure 11**.5*. The spread of this distribution,
    which relates to the standard deviation, directly determines the magnitude of
    the standard error. Also, if we were to increase the number of bootstrapped samples,
    we would expect a smoother density curve.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œä»£ç ç”Ÿæˆ*å›¾11.5*çš„å›¾è¡¨ã€‚è¿™ä¸ªåˆ†å¸ƒçš„åˆ†æ•£ç¨‹åº¦ï¼Œä¸æ ‡å‡†å·®ç›¸å…³ï¼Œç›´æ¥å†³å®šäº†æ ‡å‡†è¯¯å·®çš„å¤§å°ã€‚æ­¤å¤–ï¼Œå¦‚æœæˆ‘ä»¬å¢åŠ bootstrapæ ·æœ¬çš„æ•°é‡ï¼Œæˆ‘ä»¬é¢„æœŸå¯†åº¦æ›²çº¿ä¼šæ›´åŠ å¹³æ»‘ã€‚
- en: '![Figure 11.5 â€“ Visualizing the density plot of all bootstrapped sample proportions](img/B18680_11_005.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.5 â€“ å¯è§†åŒ–æ‰€æœ‰bootstrapæ ·æœ¬æ¯”ä¾‹çš„å¯†åº¦å›¾](img/B18680_11_005.jpg)'
- en: Figure 11.5 â€“ Visualizing the density plot of all bootstrapped sample proportions
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.5 â€“ å¯è§†åŒ–æ‰€æœ‰bootstrapæ ·æœ¬æ¯”ä¾‹çš„å¯†åº¦å›¾
- en: 'Calculate the standard error as the standard deviation of the empirical distribution
    based on the bootstrapped sample proportions:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ ‡å‡†è¯¯å·®è®¡ç®—ä¸ºåŸºäºbootstrapæ ·æœ¬æ¯”ä¾‹çš„å®è¯åˆ†å¸ƒçš„æ ‡å‡†å·®ï¼š
- en: '[PRE9]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, we use the `sd()` function to calculate the standard deviation of the
    `stat` column in `bs`, and then return the value via the `pull()` function. The
    standard error will then be scaled by the predetermined z-score and subtracted
    from and added to the original sample proportion to obtain the confidence interval.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨`sd()`å‡½æ•°è®¡ç®—`bs`ä¸­`stat`åˆ—çš„æ ‡å‡†å·®ï¼Œç„¶åé€šè¿‡`pull()`å‡½æ•°è¿”å›è¯¥å€¼ã€‚ç„¶åï¼Œæ ‡å‡†è¯¯å·®å°†æ ¹æ®é¢„å®šçš„zåˆ†æ•°è¿›è¡Œç¼©æ”¾ï¼Œå¹¶ä»åŸå§‹æ ·æœ¬æ¯”ä¾‹ï¼ˆ`p_hat`ï¼‰ä¸­å‡å»å’ŒåŠ ä¸Šï¼Œä»¥è·å¾—ç½®ä¿¡åŒºé—´ã€‚
- en: 'Calculate the confidence interval of the original sample proportion with a
    95% confidence interval:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨95%ç½®ä¿¡åŒºé—´è®¡ç®—åŸå§‹æ ·æœ¬æ¯”ä¾‹çš„ç½®ä¿¡åŒºé—´ï¼š
- en: '[PRE10]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, since a 95% confidence level corresponds to a z-score of 2, we multiply
    it with the standard error before subtracting from and adding to the original
    sample proportion (`p_hat`) to obtain the confidence interval.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œç”±äº95%ç½®ä¿¡æ°´å¹³å¯¹åº”äºzåˆ†æ•°2ï¼Œæˆ‘ä»¬åœ¨ä»åŸå§‹æ ·æœ¬æ¯”ä¾‹ï¼ˆ`p_hat`ï¼‰ä¸­å‡å»å’ŒåŠ ä¸Šä¹‹å‰ï¼Œå°†å…¶ä¸æ ‡å‡†è¯¯å·®ç›¸ä¹˜ä»¥è·å¾—ç½®ä¿¡åŒºé—´ã€‚
- en: 'Calculate the confidence interval using the structure information by assuming
    a Bernoulli distribution for the probability of success:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‡è®¾æˆåŠŸçš„æ¦‚ç‡æœä»ä¼¯åŠªåˆ©åˆ†å¸ƒï¼Œä½¿ç”¨ç»“æ„ä¿¡æ¯è®¡ç®—ç½®ä¿¡åŒºé—´ï¼š
- en: '[PRE11]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, we use the explicit form of the variance of the Bernoulli distribution
    to calculate the standard error. The result shows a fairly similar confidence
    interval compared with the one obtained using the bootstrap approach.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æ–¹å·®æ˜¾å¼å½¢å¼æ¥è®¡ç®—æ ‡å‡†è¯¯å·®ã€‚ç»“æœæ˜¾ç¤ºçš„ç½®ä¿¡åŒºé—´ä¸ä½¿ç”¨bootstrapæ–¹æ³•è·å¾—çš„ç½®ä¿¡åŒºé—´ç›¸å½“ç›¸ä¼¼ã€‚
- en: The confidence interval provides a measure of uncertainty for our estimate of
    the unknown population proportion using the observed sample proportion. Let us
    look at how to interpret the confidence interval in the next section.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ç½®ä¿¡åŒºé—´ä¸ºæˆ‘ä»¬ä½¿ç”¨è§‚å¯Ÿåˆ°çš„æ ·æœ¬æ¯”ä¾‹ä¼°è®¡æœªçŸ¥æ€»ä½“æ¯”ä¾‹çš„ä¸ç¡®å®šæ€§æä¾›äº†ä¸€ä¸ªä¸ç¡®å®šæ€§åº¦é‡ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åœ¨ä¸‹ä¸€èŠ‚ä¸­è§£é‡Šç½®ä¿¡åŒºé—´ã€‚
- en: Interpreting the confidence interval of the sample proportion
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è§£é‡Šæ ·æœ¬æ¯”ä¾‹çš„ç½®ä¿¡åŒºé—´
- en: Interpreting the confidence interval of the sample proportion involves understanding
    the meaning of the interval and the associated confidence level. In our previous
    example, the bootstrap approach reports a confidence interval of `[0.1938821,
    0.2226099]`. There are two levels of interpretation for this confidence interval.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: è§£é‡Šæ ·æœ¬æ¯”ä¾‹çš„ç½®ä¿¡åŒºé—´æ¶‰åŠç†è§£åŒºé—´çš„å«ä¹‰å’Œç›¸å…³çš„ç½®ä¿¡æ°´å¹³ã€‚åœ¨æˆ‘ä»¬ä¹‹å‰çš„ä¾‹å­ä¸­ï¼Œbootstrapæ–¹æ³•æŠ¥å‘Šçš„ç½®ä¿¡åŒºé—´ä¸º`[0.1938821, 0.2226099]`ã€‚å¯¹äºè¿™ä¸ªç½®ä¿¡åŒºé—´æœ‰ä¸¤ä¸ªå±‚é¢çš„è§£é‡Šã€‚
- en: First, the range of the confidence interval suggests that the true population
    proportion of families with two siblings is likely to fall between 19.39% and
    22.26%. This range is based on the sample data and estimates the uncertainty in
    the true proportion.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œç½®ä¿¡åŒºé—´çš„èŒƒå›´è¡¨æ˜ï¼Œå…·æœ‰ä¸¤ä¸ªå…„å¼Ÿå§å¦¹çš„å®¶åº­çš„çœŸå®æ¯”ä¾‹å¾ˆå¯èƒ½åœ¨19.39%åˆ°22.26%ä¹‹é—´ã€‚è¿™ä¸ªèŒƒå›´åŸºäºæ ·æœ¬æ•°æ®ï¼Œå¹¶ä¼°è®¡äº†çœŸå®æ¯”ä¾‹çš„ä¸ç¡®å®šæ€§ã€‚
- en: Second, the 95% confidence interval means that if we were to conduct the survey
    many times (either in 2016 or other years), we would generate different random
    samples of the same size, based on which we can calculate the 95% confidence interval
    for each sample. Among these artificial samples, we will obtain a collection of
    intervals, and approximately 95% of them would include the true population proportion
    within the interval.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶æ¬¡ï¼Œ95%çš„ç½®ä¿¡åŒºé—´æ„å‘³ç€å¦‚æœæˆ‘ä»¬å¤šæ¬¡è¿›è¡Œè°ƒæŸ¥ï¼ˆæ— è®ºæ˜¯2016å¹´è¿˜æ˜¯å…¶ä»–å¹´ä»½ï¼‰ï¼Œæˆ‘ä»¬ä¼šç”Ÿæˆä¸åŒå¤§å°çš„éšæœºæ ·æœ¬ï¼ŒåŸºäºè¿™äº›æ ·æœ¬æˆ‘ä»¬å¯ä»¥è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„95%ç½®ä¿¡åŒºé—´ã€‚åœ¨è¿™äº›äººå·¥æ ·æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†è·å¾—ä¸€ç³»åˆ—åŒºé—´ï¼Œå…¶ä¸­å¤§çº¦95%çš„åŒºé—´å°†åŒ…å«çœŸå®çš„æ€»ä½“æ¯”ä¾‹ã€‚
- en: Note that the confidence interval is still an estimate, and the true population
    proportion may fall outside the calculated interval. However, the confidence interval
    provides a useful way to quantify the uncertainty in the estimate and gives a
    list of plausible values for the true population proportion based on the observed
    samples.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç½®ä¿¡åŒºé—´ä»ç„¶æ˜¯ä¸€ä¸ªä¼°è®¡å€¼ï¼ŒçœŸå®çš„æ€»ä½“æ¯”ä¾‹å¯èƒ½è½åœ¨è®¡ç®—å‡ºçš„åŒºé—´ä¹‹å¤–ã€‚ç„¶è€Œï¼Œç½®ä¿¡åŒºé—´æä¾›äº†ä¸€ç§æœ‰ç”¨çš„æ–¹æ³•æ¥é‡åŒ–ä¼°è®¡çš„ä¸ç¡®å®šæ€§ï¼Œå¹¶åŸºäºè§‚å¯Ÿåˆ°çš„æ ·æœ¬ç»™å‡ºçœŸå®æ€»ä½“æ¯”ä¾‹çš„å¯èƒ½å€¼çš„åˆ—è¡¨ã€‚
- en: The next section introduces hypothesis testing for the sample proportion.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€èŠ‚å°†ä»‹ç»å¯¹æ ·æœ¬æ¯”ä¾‹çš„å‡è®¾æ£€éªŒã€‚
- en: Hypothesis testing for the sample proportion
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯¹æ ·æœ¬æ¯”ä¾‹è¿›è¡Œå‡è®¾æ£€éªŒ
- en: Hypothesis testing for the sample proportion is very much related to the confidence
    interval introduced in a previous section, which captures the level of uncertainty
    in the estimate for the unknown proportion based on the population data. Naturally,
    a sample with fewer observations leads to a wide confidence interval. Hypothesis
    testing for the sample proportion aims to determine whether there is enough evidence
    in a sample to support or reject a claim about the population proportion. The
    process starts with a null hypothesis (H0), which represents the baseline assumption
    about the population proportion. Correspondingly, there is an alternative hypothesis
    (H1) that represents the claim or statement we are testing against the null hypothesis.
    Hypothesis testing then compares the observed sample proportion to a specified
    null hypothesis in order to assess whether we have enough evidence to reject the
    null hypothesis in favor of the alternative hypothesis.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ ·æœ¬æ¯”ä¾‹çš„å‡è®¾æ£€éªŒä¸å‰é¢ç« èŠ‚ä¸­å¼•å…¥çš„ç½®ä¿¡åŒºé—´å¯†åˆ‡ç›¸å…³ï¼Œå®ƒæ•æ‰äº†åŸºäºæ€»ä½“æ•°æ®å¯¹æœªçŸ¥æ¯”ä¾‹ä¼°è®¡çš„ä¸ç¡®å®šæ€§æ°´å¹³ã€‚è‡ªç„¶åœ°ï¼Œè§‚å¯Ÿå€¼è¾ƒå°‘çš„æ ·æœ¬ä¼šå¯¼è‡´ç½®ä¿¡åŒºé—´è¾ƒå®½ã€‚å¯¹æ ·æœ¬æ¯”ä¾‹çš„å‡è®¾æ£€éªŒæ—¨åœ¨ç¡®å®šæ ·æœ¬ä¸­æ˜¯å¦æœ‰è¶³å¤Ÿçš„è¯æ®æ¥æ”¯æŒæˆ–æ‹’ç»å…³äºæ€»ä½“æ¯”ä¾‹çš„å£°æ˜ã€‚è¿™ä¸ªè¿‡ç¨‹ä»é›¶å‡è®¾ï¼ˆH0ï¼‰å¼€å§‹ï¼Œå®ƒä»£è¡¨äº†å…³äºæ€»ä½“æ¯”ä¾‹çš„åŸºæœ¬å‡è®¾ã€‚ç›¸åº”åœ°ï¼Œå­˜åœ¨ä¸€ä¸ªå¤‡æ‹©å‡è®¾ï¼ˆH1ï¼‰ï¼Œå®ƒä»£è¡¨äº†æˆ‘ä»¬å¯¹é›¶å‡è®¾è¿›è¡Œæµ‹è¯•çš„å£°æ˜æˆ–é™ˆè¿°ã€‚ç„¶åï¼Œå‡è®¾æ£€éªŒå°†è§‚å¯Ÿåˆ°çš„æ ·æœ¬æ¯”ä¾‹ä¸æŒ‡å®šçš„é›¶å‡è®¾è¿›è¡Œæ¯”è¾ƒï¼Œä»¥è¯„ä¼°æˆ‘ä»¬æ˜¯å¦æœ‰è¶³å¤Ÿçš„è¯æ®æ¥æ‹’ç»é›¶å‡è®¾ï¼Œå¹¶æ”¯æŒå¤‡æ‹©å‡è®¾ã€‚
- en: 'Let us go through an overview of the procedure involved in carrying out hypothesis
    testing:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¦‚è¿°ä¸€ä¸‹è¿›è¡Œå‡è®¾æ£€éªŒæ‰€æ¶‰åŠçš„ç¨‹åºï¼š
- en: '**Formulate the hypothesis**. In this step, we set up the null hypothesis (H0)
    and alternative hypothesis (H1). The null hypothesis often says there is no effect,
    and the situation remains the status quo, as indicated by an equality sign in
    H0\. On the other hand, the alternative hypothesis states that there is an effect
    or difference, as indicated by an inequality sign in H1\. For example, we can
    set the following hypotheses for H0 and H1:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åˆ¶å®šå‡è®¾**ã€‚åœ¨è¿™ä¸ªæ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬è®¾å®šé›¶å‡è®¾ï¼ˆH0ï¼‰å’Œå¤‡æ‹©å‡è®¾ï¼ˆH1ï¼‰ã€‚é›¶å‡è®¾é€šå¸¸è¡¨ç¤ºæ²¡æœ‰æ•ˆæœï¼Œæƒ…å†µä¿æŒç°çŠ¶ï¼Œå¦‚H0ä¸­çš„ç­‰å·æ‰€ç¤ºã€‚å¦ä¸€æ–¹é¢ï¼Œå¤‡æ‹©å‡è®¾è¡¨ç¤ºå­˜åœ¨æ•ˆæœæˆ–å·®å¼‚ï¼Œå¦‚H1ä¸­çš„ä¸ç­‰å·æ‰€ç¤ºã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºH0å’ŒH1è®¾å®šä»¥ä¸‹å‡è®¾ï¼š'
- en: 'H0: p = pÂ 0 (the population proportion is equal to a specified value, pÂ 0)'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'H0: p = pÂ 0ï¼ˆæ€»ä½“æ¯”ä¾‹ç­‰äºæŒ‡å®šçš„å€¼ï¼ŒpÂ 0ï¼‰'
- en: 'H1: p â‰  pÂ 0 (the population proportion is not equal to pÂ 0)'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'H1: p â‰  pÂ 0ï¼ˆæ€»ä½“æ¯”ä¾‹ä¸ç­‰äºpÂ 0ï¼‰'
- en: '**Choose a significance level (**ğœ¶**)**. The significance level is a probability
    threshold we use to reject the null hypothesis when it is true. Widely used significance
    levels include 0.05 (5%) and 0.01 (1%).'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é€‰æ‹©æ˜¾è‘—æ€§æ°´å¹³ï¼ˆ**ğœ¶**ï¼‰**ã€‚æ˜¾è‘—æ€§æ°´å¹³æ˜¯æˆ‘ä»¬ç”¨æ¥åœ¨åŸå‡è®¾ä¸ºçœŸæ—¶æ‹’ç»åŸå‡è®¾çš„æ¦‚ç‡é˜ˆå€¼ã€‚å¹¿æ³›ä½¿ç”¨çš„æ˜¾è‘—æ€§æ°´å¹³åŒ…æ‹¬0.05ï¼ˆ5%ï¼‰å’Œ0.01ï¼ˆ1%ï¼‰ã€‚'
- en: '**Calculate the test statistic**. Now that we observe a sample proportion based
    on the actual data, we can calculate the probability of observing such a sample
    proportion *if* the null hypothesis were true. This starts with calculating the
    test statistic (z-score) for the sample proportion using the following formula:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®¡ç®—æ£€éªŒç»Ÿè®¡é‡**ã€‚ç°åœ¨æˆ‘ä»¬æ ¹æ®å®é™…æ•°æ®è§‚å¯Ÿåˆ°ä¸€ä¸ªæ ·æœ¬æ¯”ä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—åœ¨é›¶å‡è®¾ä¸ºçœŸçš„æƒ…å†µä¸‹è§‚å¯Ÿåˆ°è¿™æ ·ä¸€ä¸ªæ ·æœ¬æ¯”ä¾‹çš„æ¦‚ç‡ã€‚è¿™å§‹äºä½¿ç”¨ä»¥ä¸‹å…¬å¼è®¡ç®—æ ·æœ¬æ¯”ä¾‹çš„æ£€éªŒç»Ÿè®¡é‡ï¼ˆzåˆ†æ•°ï¼‰ï¼š'
- en: z = Â Â Ë†Â pÂ  âˆ’ pÂ 0Â _Â âˆšÂ ___________Â pÂ 0(1 âˆ’ pÂ 0) / n
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: z = Ë†p âˆ’ p0 * âˆš___________ * p0(1 âˆ’ p0) / n
- en: where Â Ë†Â pÂ  is the sample proportion, pÂ 0 is the population proportion assuming
    the null hypothesis, and n is the sample size. There are two things to note there.
    First, the denominator resembles the standard deviation based on the sample proportion
    covered earlier. Indeed, we are assuming a Bernoulli distribution with a success
    probability of pÂ 0\. With a total of n observations, the standard deviation for
    the sample proportion variable is âˆšÂ ___________Â pÂ 0(1 âˆ’ pÂ 0) / nÂ . Second, the
    whole term corresponds to the process of converting a number into a z-score of
    a specific distribution, a topic covered in the previous chapter. Here, we assume
    a normal distribution with mean pÂ 0 and standard deviation âˆšÂ ___________Â pÂ 0(1
    âˆ’ pÂ 0) / nÂ . We can then convert the observed sample proportion Â Ë†Â pÂ  to the corresponding
    z-score for ease of calculation later on.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­Ë†pæ˜¯æ ·æœ¬æ¯”ä¾‹ï¼Œp0æ˜¯åœ¨é›¶å‡è®¾ä¸‹çš„æ€»ä½“æ¯”ä¾‹ï¼Œnæ˜¯æ ·æœ¬å¤§å°ã€‚æœ‰ä¸¤ç‚¹éœ€è¦æ³¨æ„ã€‚é¦–å…ˆï¼Œåˆ†æ¯ç±»ä¼¼äºå‰é¢æåˆ°çš„åŸºäºæ ·æœ¬æ¯”ä¾‹çš„æ ‡å‡†å·®ã€‚ç¡®å®ï¼Œæˆ‘ä»¬å‡è®¾ä¸€ä¸ªä¼¯åŠªåˆ©åˆ†å¸ƒï¼ŒæˆåŠŸæ¦‚ç‡ä¸ºp0ã€‚åœ¨æ€»å…±nä¸ªè§‚å¯Ÿå€¼ä¸­ï¼Œæ ·æœ¬æ¯”ä¾‹å˜é‡çš„æ ‡å‡†å·®æ˜¯âˆš___________
    * p0(1 âˆ’ p0) / nã€‚å…¶æ¬¡ï¼Œæ•´ä¸ªé¡¹å¯¹åº”äºå°†ä¸€ä¸ªæ•°å€¼è½¬æ¢ä¸ºç‰¹å®šåˆ†å¸ƒçš„zåˆ†æ•°çš„è¿‡ç¨‹ï¼Œè¿™æ˜¯å‰ä¸€ç« è®¨è®ºçš„ä¸»é¢˜ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å‡è®¾ä¸€ä¸ªå‡å€¼ä¸ºp0ï¼Œæ ‡å‡†å·®ä¸ºâˆš___________
    * p0(1 âˆ’ p0) / nçš„æ­£æ€åˆ†å¸ƒã€‚ç„¶åæˆ‘ä»¬å¯ä»¥å°†è§‚å¯Ÿåˆ°çš„æ ·æœ¬æ¯”ä¾‹Ë†pè½¬æ¢ä¸ºç›¸åº”çš„zåˆ†æ•°ï¼Œä»¥ä¾¿äºåç»­è®¡ç®—ã€‚
- en: Note that we can also use the bootstrap approach to calculate the empirical
    p-value under the null hypothesis.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨è‡ªåŠ©æ³•åœ¨é›¶å‡è®¾ä¸‹è®¡ç®—ç»éªŒpå€¼ã€‚
- en: 4. **Determine the p-value**. The z-score is a measure that falls on a standard
    Gaussian distribution. It is a test statistic, and we are often interested in
    the probability of observing the test statistic at this or an even more extreme
    value. This is called the p-value, denoted as Â Ë†Â pÂ , when we assume the null hypothesis
    is true. In other words, we try to assess how likely it is to observe some phenomenon,
    assuming the null hypothesis is true. If the probability of observing Â Ë†Â pÂ  or
    an even more extreme number is very small, we have confidence that the null hypothesis
    is false, and we can reject H0 in favor of H1.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 4. **ç¡®å®špå€¼**ã€‚zåˆ†æ•°æ˜¯ä¸€ä¸ªè½åœ¨æ ‡å‡†é«˜æ–¯åˆ†å¸ƒä¸Šçš„åº¦é‡ã€‚å®ƒæ˜¯ä¸€ä¸ªæ£€éªŒç»Ÿè®¡é‡ï¼Œæˆ‘ä»¬é€šå¸¸å¯¹è§‚å¯Ÿåˆ°çš„æ£€éªŒç»Ÿè®¡é‡åœ¨æ­¤æˆ–æ›´æç«¯å€¼ä¸Šçš„æ¦‚ç‡æ„Ÿå…´è¶£ã€‚è¿™è¢«ç§°ä¸ºpå€¼ï¼Œè®°ä¸ºË†pï¼Œå½“æˆ‘ä»¬å‡è®¾é›¶å‡è®¾ä¸ºçœŸæ—¶ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬è¯•å›¾è¯„ä¼°åœ¨é›¶å‡è®¾ä¸ºçœŸçš„æƒ…å†µä¸‹è§‚å¯ŸæŸäº›ç°è±¡çš„å¯èƒ½æ€§ã€‚å¦‚æœè§‚å¯Ÿåˆ°Ë†pæˆ–æ›´æç«¯æ•°å€¼çš„æ¦‚ç‡éå¸¸å°ï¼Œæˆ‘ä»¬æœ‰ä¿¡å¿ƒé›¶å‡è®¾æ˜¯é”™è¯¯çš„ï¼Œæˆ‘ä»¬å¯ä»¥æ‹’ç»H0å¹¶æ”¯æŒH1ã€‚
- en: 'Note that for a two-tailed test, we can also calculate the p-value using the
    standard normal distribution and doubling the single-side probability:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå¯¹äºåŒå°¾æ£€éªŒï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨æ ‡å‡†æ­£æ€åˆ†å¸ƒå¹¶åŠ å€å•ä¾§æ¦‚ç‡æ¥è®¡ç®—på€¼ï¼š
- en: p-value = 2P(Z > |z|)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: p-value = 2P(Z > |z|)
- en: 5. **Make a decision**. Finally, we compare the p-value to the preset significance
    level (Î±) and use the following rule to make a decision.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 5. **åšå‡ºå†³å®š**ã€‚æœ€åï¼Œæˆ‘ä»¬å°†på€¼ä¸é¢„è®¾çš„æ˜¾è‘—æ€§æ°´å¹³ï¼ˆÎ±ï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶ä½¿ç”¨ä»¥ä¸‹è§„åˆ™åšå‡ºå†³å®šã€‚
- en: If the p-value â‰¤ Î±, reject the null hypothesis in favor of the alternative hypothesis.
    Doing so suggests that there is enough evidence to suggest that the population
    proportion differs from the hypothesized proportion pÂ 0.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœpå€¼ â‰¤ Î±ï¼Œåˆ™æ‹’ç»é›¶å‡è®¾ï¼Œæ”¯æŒå¤‡æ‹©å‡è®¾ã€‚è¿™æ ·åšè¡¨æ˜æœ‰è¶³å¤Ÿçš„è¯æ®è¡¨æ˜æ€»ä½“æ¯”ä¾‹ä¸å‡è®¾æ¯”ä¾‹p0ä¸åŒã€‚
- en: If the p-value > Î±, fail to reject the null hypothesis. This means that there
    is not enough evidence to suggest that the population proportion is different
    from pÂ 0.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœpå€¼ > Î±ï¼Œåˆ™ä¸èƒ½æ‹’ç»é›¶å‡è®¾ã€‚è¿™æ„å‘³ç€æ²¡æœ‰è¶³å¤Ÿçš„è¯æ®è¡¨æ˜æ€»ä½“æ¯”ä¾‹ä¸p0ä¸åŒã€‚
- en: Conducting the hypothesis testing follows a similar process. The only difference
    is the use of the `hypothesise()` function (placed after `specify()`), which serves
    as a null hypothesis. We then perform the same bootstrap procedure to obtain a
    density plot of the bootstrapped sample proportions, followed by calculating the
    total probability of obtaining a proportion at least as extreme as the one indicated
    in the null hypothesis.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through an exercise to review the process of performing hypothesis
    testing for the sample proportion.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.3 â€“ performing hypothesis testing for the sample proportion
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will set up a hypothetical population proportion in a
    null hypothesis and test the validity of this hypothesis based on the observed
    sample proportion:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot the frequency count of families with and without two siblings in 2016
    in a bar plot:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Running the code generates the plot in *Figure 11**.6*, which shows that families
    with two siblings account for around Â¼ of all families.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.6 â€“ Visualizing the frequency count of families with two siblings](img/B18680_11_006.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
- en: Figure 11.6 â€“ Visualizing the frequency count of families with two siblings
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the sample proportion of families with two siblings:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, we first build a series of binary outcomes using `siblings_two_ind=="Y"`.
    Taking the average of this column gives the ratio of `TRUE` values, which gets
    executed in a `summarize()` context. We then extract the value of the sample proportion
    using `pull()`.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the specify-hypothesise-generate-calculate procedure to generate a collection
    of bootstrapped sample proportions under the null hypothesis, which specifies
    a population proportion of `0.19`:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Generate the density plot of the bootstrapped sample proportions along with
    the proportion suggested by the null hypothesis via a vertical line:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Running the code generates the plot in *Figure 11**.7*. The probability of observing
    a value at least as extreme as the one indicated by the red line (according to
    the null hypothesis) is thus the total area under the density curve toward the
    right of the red line. We then double the result to account for the opposite direction.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.7 â€“ Visualizing the density plot of the bootstrapped sample proportions
    for hypothesis testing](img/B18680_11_007.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
- en: Figure 11.7 â€“ Visualizing the density plot of the bootstrapped sample proportions
    for hypothesis testing
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the p-value:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Since this result is less than the preset significance level of 5%, we have
    sufficient evidence to favor the alternative hypothesis and reject the null hypothesis.
    In other words, the assumed 19% is statistically different from the true population
    proportion with a confidence level of up to 95%. We can therefore draw the conclusion
    that the true population proportion is not 19%.
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The next section looks at the inference for the difference in sample proportions
    between two categorical variables.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Inference for the difference in sample proportions
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The setting now is that we have two categorical variables. Take gender and
    degree, for example. The data will report a proportion of degree holders for both
    females and males. A natural question to ask is whether males are more likely
    to get a degree than females. A particular dataset will report a snapshot of these
    proportions, which may or may not suggest a higher percentage of degree holders
    are males. The tools from hypothesis testing could then come in to answer the
    following question: if males are a higher proportion of degree holders in the
    dataset, is such difference statistically significant? In other words, are males
    more likely to get a degree than females, or vice versa? This section attempts
    to answer this type of question.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Inference for the difference in sample proportions between two categorical variables
    (for example, gender and degree) involves comparing the proportions of samples
    for each level in two different populations. This type of analysis is commonly
    used in experiments or observational studies to determine the existence of a significant
    difference in proportions between two groups. The main goal is to estimate the
    difference between the population proportions and determine whether this difference
    is statistically significant.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: The procedure for hypothesis testing is similar to before. We first formulate
    the null hypothesis, which assumes no difference between the proportion of the
    two populations, that is, pÂ 1 = pÂ 2, or pÂ 1 âˆ’ pÂ 2 = 0\. The alternative hypothesis
    then states that their difference is not zero; that is, pÂ 1 âˆ’ pÂ 2 â‰  0\. Next,
    we choose a specific significance level and calculate the sample statistic (difference
    in sample proportion, including the pooled proportion between the two categorical
    variables) and the test statistic (via either a closed-form expression based on
    the assumed distribution or using the bootstrap method). Finally, we obtain the
    p-value and decide whether the observed result under the null hypothesis possesses
    statistical significance or not.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through a concrete exercise following our previous example.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.4 â€“ performing hypothesis testing for the difference in sample proportions
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we focus on how to conduct hypothesis testing for the difference
    in the sample proportion between gender and status of higher degree. Here, we
    define a higher degree as a bachelorâ€™s and above. The proportion of higher-degree
    holders will likely differ between the male and female groups, and we will test
    whether such a difference is significant given the observed data:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a binary column called `higher_degree` to the previous DataFrame, `gss2016`,
    to indicate the status of higher degree, including bachelorâ€™s and above:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Print the ratio between the two levels for `gender` and `higher_degree`:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Plot these counts in a bar chart:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Running the code generates the chart in *Figure 11**.8*.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.8 â€“ Visualizing the frequency count of gender and higher-degree
    status](img/B18680_11_008.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
- en: Figure 11.8 â€“ Visualizing the frequency count of gender and higher-degree status
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also plot them in percentages by specifying `position = "fill"` in the
    `geom_bar()` function:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Running the code generates the chart in *Figure 11**.9*, which suggests no obvious
    difference in the proportion of higher-degree holders between the male and female
    groups.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 â€“ Visualizing the frequency count of gender and higher-degree
    status](img/B18680_11_009.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 â€“ Visualizing the frequency count of gender and higher-degree status
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the difference in sample proportions of higher-degree holders between
    males and females:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The result also shows that the difference is quite small, with the female group
    being 0.7% higher than the male group (refer to the slightly higher blue bar of
    the female group in the previous figure). Let us see whether such a difference
    is statistically significant.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate one bootstrap sample set under the null hypothesis, which states that
    there is no difference in the ratio of higher-degree holders between the male
    and female groups:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Here, we use `higher_degree` as the response variable and `sex` as the explanatory
    variable in a logistic regression setting (to be introduced in [*Chapter 13*](B18680_13.xhtml#_idTextAnchor279)).
    Under the null hypothesis, we randomly sample from the original dataset and create
    a new artificial dataset of the same shape.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Repeat the same bootstrap sampling procedures 500 times and calculate the difference
    in sample proportions of higher-degree holders between female and male groups
    (note the sequence here) for each set of bootstrapped samples:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Plot these bootstrapped sample statistics in a density curve and plot the observed
    difference as a vertical red line:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Running the code generates the plot in *Figure 11**.10*, which shows that the
    red line is not located toward the extreme side of the empirical distribution.
    This suggests that the p-value, which will be calculated next, may be high.
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.10 â€“ Showing the density plot for the bootstrapped sample statistics
    and observed differences](img/B18680_11_010.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 â€“ Showing the density plot for the bootstrapped sample statistics
    and observed differences
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'Compute the two-tailed p-value:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The result shows a pretty high p-value, which suggests that we lack sufficient
    evidence to reject the null hypothesis. In other words, there is not enough information
    to suggest that the proportion of higher-degree holders between males and females
    is different.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The hypothesis testing relies on a predefined significance level. That significance
    level, denoted as Î±, has something to do with the statistical error of the procedure.
    The next section introduces two common types of statistical error when performing
    hypothesis testing.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Type I and Type II errors
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are two types of errors when conducting hypothesis testing and making
    a decision about the null hypothesis (H0) and the alternative hypothesis (H1).
    They are called Type I and Type II errors.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: The Type I error refers to false positives. It happens when the null hypothesis
    is true but mistakenly rejected. In other words, we find evidence in our sample
    data that suggests a significant effect or difference exists and we favor the
    alternative hypothesis, even though it does not actually exist in the population.
    We denote the probability of experiencing a Type I error as Î±. It is also called
    the significance level, which was set to `0.05` in the previous example. A 5%
    significance level means that there is a 5% chance of rejecting the null hypothesis
    when it is true. The significance level thus represents the probability of committing
    a false positive error.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The Type II error focuses on the false negative case. It occurs when we fail
    to reject a false null hypothesis. In other words, we do not find evidence in
    our sample data to reject the null hypothesis, even though it does exist in the
    population. The probability of making a Type II error is denoted by Î², which is
    also referred to as the power of the test. The complement of the power, denoted
    as 1 âˆ’ Î², represents the probability of rejecting the null hypothesis when it
    is false.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Type I errors involve falsely rejecting the null hypothesis, while Type II errors
    involve failing to reject the null hypothesis when false. Both types of errors
    are important considerations in hypothesis testing because they can lead to incorrect
    conclusions. To minimize the risk of these errors, we can make a careful choice
    regarding the significance level (Î±) and also ensure that their study has sufficient
    power (1 âˆ’ Î²). The power of a test depends on the sample size, the effect size
    (which is a quantitative measure of the magnitude of an empirical relationship
    between variables), and the chosen significance level. Larger sample sizes and
    larger effect sizes both increase the power of a test, reducing the likelihood
    of Type II errors.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 11**.11* provides an overview of the different types of outcomes in
    a hypothesis test. Note that the false positive and false negative are related
    to the quality of the decision. Depending on the type of a false decision, we
    would classify the errors as either Type I or Type II errors.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 â€“ Overview of different types of outcomes in a hypothesis test](img/B18680_11_011.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 â€“ Overview of different types of outcomes in a hypothesis test
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: The next section introduces the chi-square test, which tests the independence
    of two categorical variables.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Testing the independence of two categorical variables
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To check the independence of two categorical variables, the process involves
    checking the existence of a statistically significant relationship between them.
    One common procedure is the chi-square test for independence. It works by comparing
    the observed frequencies in a contingency table with the expected frequencies
    under the assumption of independence.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Let us first review the contingency table for two categorical variables.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the contingency table
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A contingency table, also known as a cross-tabulation or crosstab, is a table
    used to display the frequency distribution of two or more categorical variables.
    It summarizes the relationships between the variables by showing how their categories
    intersect or co-occur in the data. It provides a good summary of the relationships
    between categorical variables.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us stick with the example of the relationship between gender and degree.
    This time, we will look at all types of degrees, as shown in the following code:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To indicate its relationship with gender, we can plot the degree together with
    gender in a stacked bar plot as before:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Running the code generates the plot in *Figure 11**.12*.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12 â€“ Visualizing the relationship between gender and degree in
    a bar plot](img/B18680_11_012.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 â€“ Visualizing the relationship between gender and degree in a bar
    plot
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the figure provides no information on the exact count for each category.
    To obtain the exact frequency for each category of the two variables, we can use
    the contingency table:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here, we used the `table()` function to generate the contingency table after
    selecting both `sex` and `degree`.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: The next section introduces the chi-square test to test for the independence
    between these two categorical variables.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Applying the chi-square test for independence between two categorical variables
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The chi-square test is a statistical test used to decide a possibly significant
    relationship (dependence) between two categorical variables in a collection of
    observed samples. It can be used to test for independence or goodness of fit.
    In this chapter, we focus mainly on the test for independence between two categorical
    variables. The test compares the observed frequencies with the expected ones in
    a contingency table, assuming that the variables are independent. If the observed
    and expected frequencies are significantly different, the test suggests that the
    variables are not independent; in other words, they are dependent on each other.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the same approach as before, we can generate an artificial bootstrapped
    dataset to obtain a sample statistic, called the chi-square statistic. This dataset
    is generated by permuting the original dataset under the assumption of independence
    in the null hypothesis. In the following code, we generate one permutated dataset
    of the same shape as the original dataset, assuming independence under the null
    hypothesis:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, we create 500 permutated datasets and extract the corresponding chi-square
    statistic:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To run the test, we obtain the expected frequency for each cell in the contingency
    table under the assumption of independence between the categorical variables.
    The expected frequency for a cell is computed as (*row sum * column sum*) */*
    *overall sum*:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here, we first obtain the row-wise and column-wise sum, as well as the total
    sum. We then use the `outer()` function to obtain the outer product between these
    two vectors, which is then scaled by the total sum to obtain the expected frequency
    count in each cell.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we compute the observed chi-square statistic based on the available samples:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We can then plot the observed chi-square statistic within the density curve
    of previous bootstrapped sample statistics to get a sense of where the observed
    statistic is located, based on which we will be able to calculate the corresponding
    p-value:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Running the code generates the plot in *Figure 11**.13*, which shows a high
    p-value.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.13 â€“ Visualizing the density curve of bootstrapped chi-square statistics
    and the observed statistic](img/B18680_11_013.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
- en: Figure 11.13 â€“ Visualizing the density curve of bootstrapped chi-square statistics
    and the observed statistic
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can calculate the p-value. As shown in the following code, the p-value
    of `0.72` is indeed quite high, and thus there is no sufficient evidence to reject
    the null hypothesis:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In the next section, we will shift to look at statistical inference for numerical
    data.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Statistical inference for numerical data
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will switch to look at statistical inference using numerical
    data. We will cover two approaches. The first approach relies on the bootstrapping
    procedure and permutes the original dataset to create additional artificial datasets,
    which can then be used to derive the confidence intervals. The second approach
    uses a theoretical assumption on the distribution of the bootstrapped samples
    and relies on the t-distribution to achieve the same result. We will learn how
    to perform a t-test, derive a confidence interval, and conduct an **analysis of**
    **variance** (**ANOVA**).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: As discussed earlier, bootstrapping is a non-parametric resampling method that
    allows us to estimate the sampling distribution of a particular statistic, such
    as the mean, median, or proportion, as in the previous section. This is achieved
    by repeatedly drawing random samples with replacement from the original data.
    By doing so, we can calculate confidence intervals and perform hypothesis tests
    without relying on specific distributional assumptions.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the t-distribution is a probability distribution used for hypothesis
    testing if the sample size is small and the standard deviation of the population
    data remains unknown. It is a more general approach that assumes the bootstrapped
    samples follow a specific distribution. We will then use this distribution to
    estimate confidence intervals and perform the hypothesis test.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: The t-test is a widely used statistical test that allows us to compare the mean
    values of two groups or test whether the mean of a single group is equal to a
    specific value. This time, our interest is the mean of a group since the variable
    is numeric. The test relies on the t-distribution and takes into account the sample
    sizes, sample means, and sample variances.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Confidence intervals offer a list of possible values, where the true population
    statistic, such as the mean or proportion, is likely to lie, with a specified
    level of confidence (specified by the significance level Î±).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, ANOVA extends the t-test used when there are more than two groups
    to compare. ANOVA helps us determine possible significant differences among the
    group means by dividing the total variability of the observed data into two parts:
    between-group variability and within-group variability. It tests the null hypothesis
    that the mean values of all groups are equal. If the null hypothesis is rejected,
    we can continue to identify which specific group means differ from each other.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Let us start with generating a bootstrap distribution for the median.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Generating a bootstrap distribution for the median
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed earlier, when building a bootstrap distribution for a single statistic,
    we first generate a collection of bootstrap samples via sampling with replacement,
    and then record the relevant statistic (in this case, the median) of each distribution.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through an exercise to build the collection of bootstrap samples.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.5 â€“ generating a bootstrap distribution for the sample median
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will apply the same specify-generate-calculate workflow
    using the `infer` package to generate a bootstrap distribution for the sample
    median using the `mtcars` dataset.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `mtcars` dataset and view its structure:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The result shows that we have a dataset with 32 rows and 11 columns. In the
    following steps, we will use the `mpg` variable and generate a bootstrap distribution
    of its median:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate 10,000 bootstrap samples according to the `mpg` variable and obtain
    the median of all samples:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Here, we specify `stat = "median"` in the `calculate()` function to extract
    the median in each bootstrap sample.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '2. Plot the bootstrap distribution as a density curve of the bootstrapped sample
    statistics:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Running the code generates the plot in *Figure 11**.14*.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.14 â€“ Visualizing the density curve of the bootstrapped sample median](img/B18680_11_014.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
- en: Figure 11.14 â€“ Visualizing the density curve of the bootstrapped sample median
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: The next section looks at constructing the bootstrapped confidence interval.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Constructing the bootstrapped confidence interval
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have looked at how to construct the bootstrapped confidence interval using
    the standard error method. This involves adding and subtracting the scaled standard
    error from the observed sample statistic. It turns out that there is another,
    simpler method, which just uses the percentile of the bootstrap distribution to
    obtain the confidence interval.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us continue with the previous example. Say we would like to calculate the
    95% confidence interval of the previous bootstrap distribution. We can achieve
    this by calculating the upper and lower quantiles (97.5% and 2.5%, respectively)
    of the bootstrap distribution. The following code achieves this:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let us also calculate the bootstrap confidence interval using the standard
    error method, as shown in the following code:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: As expected, the result is close to the one obtained using the percentile method.
    However, the standard error method is a more accurate method than the percentile
    method.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: The next section covers re-centering a bootstrap distribution upon testing a
    null hypothesis.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Re-centering a bootstrap distribution
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bootstrap distribution from the previous section is generated by randomly
    sampling the original dataset with replacement. Each set of bootstrap samples
    maintains the same size as the original sample sets. However, we cannot directly
    use this bootstrap distribution for hypothesis testing.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Upon introducing a null hypothesis, what we did in the previous hypothesis test
    section for two categorical variables is re-generated a new bootstrap distribution
    under the null hypothesis. We then place the observed sample statistic as a vertical
    red line along the bootstrap distribution to calculate the p-value, representing
    the probability of experiencing a phenomenon at least as extreme as the observed
    sample statistic. The only additional step is to generate the bootstrap distribution
    under the null hypothesis.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: When generating bootstrap samples under the null hypothesis, the main idea is
    to remove the effect we are testing for and create samples, assuming the null
    hypothesis is true. In other words, we create samples that would be expected if
    there were no difference between the groups. For example, when comparing means
    between two groups, we would subtract the overall mean from each observation to
    center the data around 0 before performing the random sampling with replacement.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: There is another way to achieve this. Recall that the original bootstrap distribution,
    by design, is centered around the observed sample statistic. Upon introducing
    the null hypothesis, we could simply move the original bootstrap distribution
    to be centered around the statistic in the null hypothesis, which is the null
    value. This shifted bootstrap distribution represents the same distribution if
    we were to remove the effect in the original dataset and then perform bootstrap
    sampling again. We can then place the observed sample statistic along the shifted
    bootstrap distribution to calculate the corresponding p-value, which represents
    the ratio of simulations that generate a sample statistic at least as favorable
    to the alternative hypothesis as the actual sample statistic. *Figure 11**.15*
    demonstrates this process.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.15 â€“ Shifting the bootstrap distribution to be centered around
    the null value](img/B18680_11_015.jpg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
- en: Figure 11.15 â€“ Shifting the bootstrap distribution to be centered around the
    null value
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us generate the bootstrap distribution for hypothesis testing for the previous
    example. We want to test the null hypothesis with a population median of 16 for
    the `mpg` variable. The following code generates the bootstrapped sample statistics,
    where we specify the null value via `med = 16` and the point estimate with `null
    = "point"` in the `hypothesize()` function:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, we plot these bootstrapped sample statistics in a density plot, along
    with the observed sample statistic as a vertical red line:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Running the code generates the plot in *Figure 11**.16*, which shows a small
    p-value.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.16 â€“ Density plot of bootstrapped sample medians and observed sample
    median (vertical red line)](img/B18680_11_016.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
- en: Figure 11.16 â€“ Density plot of bootstrapped sample medians and observed sample
    median (vertical red line)
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will cover another distribution-based inference approach
    based on the **central limit** **theorem** (**CLT**).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the central limit theorem used in t-distribution
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CLT says that the distribution from the sum (or average) of many independent
    and identically distributed random variables would jointly form a normal distribution,
    regardless of the underlying distribution of these individual variables. Due to
    the CLT, normal distribution is often used to approximate the sampling distribution
    of various statistics, such as the sample mean and the sample proportion.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: The t-distribution is related to the CLT in the context of statistical inference.
    When weâ€™re estimating a population mean from a sample, we often have no access
    to the true standard deviation of the population. Instead, we resort to the sample
    standard deviation as an estimate. In this case, the sampling distribution of
    the sample mean doesnâ€™t follow a normal distribution, but rather a t-distribution.
    In other words, when we extract the sample mean from a set of observed samples,
    and we are unsure of the population standard deviation (as is often the case when
    working with actual data), the sample mean can be modeled as a realization from
    the t-distribution.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: The t-distribution is a family of continuous probability distributions that
    are symmetric and bell-shaped, which shows similarity to the normal distribution.
    However, the t-distribution shows heavier tails, which accounts for the greater
    uncertainty due to estimating the population standard deviation from the observed
    data. That is, observations of a t-distribution are more likely to fall into distant
    tails (such as beyond two standard deviations away from the mean) than the normal
    distribution. The shape of the t-distribution relies on the **degrees of freedom**
    (**df**), which depends on the sample size and determines the thickness of the
    tails. As more samples are collected, the df moves up, and the t-distribution
    gradually approximates the normal distribution.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: We briefly covered the `qt()` function used to find the cutoffs under the t-distribution
    in the previous chapter. Now let us go through an exercise to get more familiar
    with calculations related to the t-distribution.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.6 â€“ understanding the t-distribution
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `pt()` function to find probabilities under
    the t-distribution. For a given cutoff quantile value, `q`, and a given `df`,
    the `pt(q, df)` function gives us the probability under the t-distribution with
    `df` for values of `t` less than `q`. In other words, we have P(tÂ df < T) = `pt(q
    = T, df)`. We can also use the `qt()` function to find the quantiles for a specific
    probability under the t-distribution. That is, if P(tÂ df < T) = p, then T = `qt(p,
    df)`:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the probability under the t-distribution with 10 df below `T=3`:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Find the probability under the t-distribution with 10 df above `T=3`:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Note that we first calculate the probability of being below a specific cutoff
    value under the t-distribution, and then take the complement to find the probability
    above the threshold.
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Find the probability under the t-distribution with `100` df above `T=3`:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Since `df=100` has a better approximation to the normal distribution than `df=10`,
    the resulting probability, `z`, is thus smaller than `y`.
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Find the 95th percentile of the t-distribution with 10 df:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Find the cutoff value that bounds the upper end of the middle 95th percentile
    of the t-distribution with `10` df:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Here, the upper end of the middle 95th percentile refers to the 97.5th percentile.
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Find the cutoff value that bounds the upper end of the middle 95th percentile
    of the t-distribution with `100` df:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The next section discusses how to construct the confidence interval for the
    population mean using the t-distribution.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: Constructing the confidence interval for the population mean using the t-distribution
  id: totrans-307
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us review the process of statistical inference for the population mean.
    We start with a limited sample, from which we can derive the sample mean. Since
    we want to estimate the population mean, we would like to perform statistical
    inference based on the observed sample mean and quantify the range where the population
    statistic may exist.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the average miles per gallon, shown in the following code, is
    around 20 in the `mtcars` dataset:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Given this result, we wonâ€™t be surprised to encounter another similar dataset
    with an average `mpg` of 19 or 21\. However, we would be surprised if the value
    is 5, 50, or even 100\. When assessing a new collection of samples, we need a
    way to quantify the variability of the sample mean across multiple samples. We
    have learned two ways to do this: use the bootstrap approach to simulate artificial
    samples or use the CLT to approximate such variability. We will focus on the CLT
    approach in this section.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the CLT, the sample mean of any sampling distribution would be
    approximately normally distributed, regardless of the original distribution. In
    other words, we have the following:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: _Â xÂ  âˆ¼ N(mean = Î¼, SE = Â ÏƒÂ _Â âˆšÂ _Â nÂ Â )
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that this is a theoretical distribution we are unable to obtain. For example,
    the population standard deviation, Ïƒ, stays unknown, and we only have access to
    the observed samples. Instead, we would estimate the standard error using the
    sample standard deviation, s, giving the following:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: _Â xÂ  âˆ¼ N(mean = Î¼, SE = Â sÂ _Â âˆšÂ _Â nÂ Â )
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: We would then employ the t-distribution of n âˆ’ 1 degree of freedom to make an
    inference for the population mean as it gives thicker tails due to the additional
    uncertainty introduced by s.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: In addition, note that the approximation using the CLT relies on a few assumptions.
    For example, the samples need to be independent of each other. This is often satisfied
    when the samples are randomly selected, or if the samples account for less than
    10% of the total population if they are selected without replacement. The sample
    size also needs to be larger to account for potential skewness in the samples.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 'We can construct the 95% confidence interval using the `t.test()` function,
    as shown in the following code:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Here, we are performing a one-sample t-test, where the default null hypothesis
    states that the population mean is 0\. The result shows a very small p-value,
    suggesting that we could reject the null hypothesis in favor of the alternative
    hypothesis; that is, the population mean is not 0\. The 95% confidence interval
    (between `17.91768` and `22.26357`) is also constructed based on the t-distribution
    with a `df` of `31` and a t-statistic of `18.857`.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: The next section reviews the hypothesis testing for two means using both bootstrap
    simulation and t-test approximation.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: Performing hypothesis testing for two means
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore the process of comparing two sample means using
    hypothesis testing. When comparing two sample means, we want to determine whether
    a significant difference exists between the means of two distinct populations
    or groups.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Suppose now we have two groups of samples. These two groups could represent
    a specific value before and after treatment for each sample. Our objective is
    thus to compare the sample statistics of these two groups, such as the sample
    mean, and determine whether the treatment has an effect. To do this, we can perform
    a hypothesis test to compare mean values from the two independent distributions
    using either bootstrap simulation or t-test approximation.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: When using the t-test in the hypothesis test to compare the mean values of two
    independent samples, the two-sample t-test assumes normal distribution for the
    data, and that the variances of the two populations are equal. However, in cases
    where these assumptions may not hold, alternative non-parametric tests or resampling
    methods, such as bootstrap, can be employed to make inferences about the population
    means.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through an exercise to see these two methods of hypothesis testing
    in play.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.7 â€“ comparing two means
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will explore two approaches (t-test and bootstrap) to
    compare two sample means and calculate the confidence interval of the difference
    in sample means:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a dummy dataset that consists of two groups of samples:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Here, we created a `tibble` DataFrame with the `value` column indicating the
    sample observation and the `group` column indicating the group number. We would
    like to assess the difference in the sample mean between these two groups.
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform bootstrap sampling `1000` times and calculate the bootstrap statistics
    under the null hypothesis that these two groups are independent of each other,
    and there is no difference in their means:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Here, the pipeline for the hypothesis test starts by specifying the response
    (`value`) and explanatory (`group`) variables, setting up the null hypothesis,
    generating bootstrap samples under the null hypothesis, and then calculating the
    test statistic (in this case, the difference in means) for each bootstrap sample.
    The null hypothesis states that we assume the sample mean values for both groups
    come from the same population, and that any observed difference is merely due
    to chance.
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the confidence interval based on the bootstrap statistics:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Perform a two-sample t-test using the `t.test()` function:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The result shows that the 95% confidence interval based on the t-distribution
    is close but still different from the one obtained via bootstrap sampling. We
    can also perform the t-test by passing in the model form:'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The next section introduces ANOVA, or the analysis of variance.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: Introducing ANOVA
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**ANOVA** is a statistical hypothesis testing method used to compare the means
    of more than two groups, which extends the two-sample t-test discussed in the
    previous section. The goal of ANOVA is to test potential significant differences
    among the group means (the between-group variability) while accounting for the
    variability within each group (the within-group variability).'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: 'ANOVA relies on the F-statistic in hypothesis testing. The F-statistic is a
    ratio of two estimates of variance: the between-group variance and the within-group
    variance. The between-group variance measures the differences among the group
    means, while the within-group variance represents the variability within each
    group. The F-statistic can be calculated based on these two group variances.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: In hypothesis testing, the null hypothesis for ANOVA states that all group means
    are equal, and any observed differences are due to chance. The alternative hypothesis,
    on the other hand, suggests that at least one groupâ€™s mean differs from the others.
    If the F-statistic is sufficiently large, the between-group variance is significantly
    greater than the within-group variance, which provides evidence against the null
    hypothesis.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us look at a concrete example. We first load the `PlantGrowth` dataset,
    which contains the weights of plants after they have been subjected to three different
    treatments:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Next, we perform the one-way ANOVA test using the same specify-hypothesize-generate-calculate
    procedure. Specifically, we first specify the response variable (`weight`) and
    the explanatory variable (`group`). We then set up the null hypothesis, stating
    no difference in the means of the groups, using `hypothesize(null = "independence")`.
    Next, we generate 1,000 permuted datasets using `generate(reps = 1000, type =
    "permute")`. Finally, we calculate the F-statistic for each permuted dataset using
    `calculate(stat = "``F")`:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Last, we can calculate the p-value using the observed F-statistic and the distribution
    of the F-statistics obtained from the permuted datasets. When the p-value is smaller
    than the preset significance level (for example, `0.05`), we could reject the
    null hypothesis and say that there is a significant difference among the means
    of the groups:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The result suggests that we do not have enough confidence to reject the null
    hypothesis.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered different types of statistical inferences for hypothesis
    testing, targeting both numerical and categorical data. We introduced inference
    methods for a single variable, two variables, and multiple variables, using either
    proportion (for categorical variable) or mean (for numerical variable) as the
    sample statistic. The hypothesis testing procedure, including both the parametric
    approach using model-based approximation and the non-parametric approach using
    bootstrap-based simulations, offers valuable tools such as the confidence interval
    and p-value. These tools allow us to make a decision about whether we can reject
    the null hypothesis in favor of the alternative hypothesis. Such a decision also
    relates to the Type I and Type II errors.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will cover one of the most widely used statistical
    and ML models: linear regression.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
