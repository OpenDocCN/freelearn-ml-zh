- en: Getting Started with Data Mining
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据挖掘入门
- en: We are collecting information about our world on a scale that has never been
    seen before in the history of humanity. Along with this trend, we are now placing
    more day-to-day importance on the use of this information in everyday life. We
    now expect our computers to translate web pages into other languages, predict
    the weather with high accuracy, suggest books we would like, and to diagnose our
    health issues. These expectations will grow into the future, both in application
    breadth and efficacy. **Data Mining** is a methodology that we can employ to train
    computers to make decisions with data and forms the backbone of many high-tech
    systems of today.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在以人类历史上前所未有的规模收集有关我们世界的各种信息。随着这一趋势的发展，我们现在更加重视在日常生活中的使用这些信息。我们期望我们的计算机能够将网页翻译成其他语言，以高精度预测天气，推荐我们喜欢的书籍，以及诊断我们的健康问题。这些期望将在未来不断增长，无论是在应用范围还是效果上。**数据挖掘**是一种我们可以采用的方法，用于训练计算机通过数据做出决策，并构成了今天许多高科技系统的核心。
- en: The **Python** programming language is fast growing in popularity, for a good
    reason. It gives the programmer flexibility, it has many modules to perform different
    tasks, and Python code is usually more readable and concise than in any other
    languages. There is a large and an active community of researchers, practitioners,
    and beginners using Python for data mining.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python**编程语言因其良好的原因而越来越受欢迎。它为程序员提供了灵活性，拥有许多模块来执行不同的任务，而且Python代码通常比其他任何语言都更易于阅读和简洁。有一个庞大且活跃的研究人员、实践者和初学者社区，他们使用Python进行数据挖掘。'
- en: In this chapter, we will introduce data mining with Python. We will cover the
    following topics
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Python介绍数据挖掘。我们将涵盖以下主题
- en: What is data mining and where can we use it?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是数据挖掘，我们可以在哪里使用它？
- en: Setting up a Python-based environment to perform data mining
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置一个基于Python的环境以进行数据挖掘
- en: An example of affinity analysis, recommending products based on purchasing habits
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （亲和力分析的）一个例子，根据购买习惯推荐产品
- en: An example of (a classic) classification problem, predicting the plant species
    based on its measurement
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （一个经典的）分类问题的例子，根据植物测量值预测植物种类
- en: Introducing data mining
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍数据挖掘
- en: Data mining provides a way for a computer to learn how to make decisions with
    data. This decision could be predicting tomorrow's weather, blocking a spam email
    from entering your inbox, detecting the language of a website, or finding a new
    romance on a dating site. There are many different applications of data mining,
    with new applications being discovered all the time.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘为计算机提供了一种通过数据做出决策的方法。这个决策可以是预测明天的天气，阻止垃圾邮件进入您的收件箱，检测网站的语种，或者在交友网站上找到新的恋情。数据挖掘有许多不同的应用，而且新的应用正在不断被发现。
- en: Data mining is part algorithm design, statistics, engineering, optimization,
    and computer science. However, combined with these *base* skills in the area,
    we also need to apply **domain knowledge (expert knowledge)**of the area we are
    applying the data mining. Domain knowledge is critical for going from good results
    to great results. Applying data mining effectively usually requires this domain-specific
    knowledge to be integrated with the algorithms.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘部分是算法设计、统计学、工程学、优化和计算机科学的结合。然而，结合这些领域的**基础**技能，我们还需要应用我们在应用数据挖掘的领域的**领域知识（专业知识）**。领域知识对于从良好结果到卓越结果至关重要。有效地应用数据挖掘通常需要将这些特定领域的知识与算法相结合。
- en: Most data mining applications work with the same **high-level** view, where
    a model learns from some data and is applied to other data, although the details
    often change quite considerably.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据挖掘应用都采用相同的**高级**视图，其中模型从某些数据中学习，并将其应用于其他数据，尽管细节往往变化很大。
- en: Data mining applications involve creating data sets and tuning the algorithm
    as explained in the following steps
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘应用涉及创建数据集和调整算法，以下步骤将进行解释
- en: 'We start our data mining process by creating a dataset, describing an aspect
    of the real world. Datasets comprise of the following two aspects:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过创建数据集开始我们的数据挖掘过程，描述现实世界的一个方面。数据集包括以下两个方面：
- en: '**Samples**: These are objects in the real world, such as a book, photograph,
    animal, person, or any other object. Samples are also referred to as observations,
    records or rows, among other naming conventions.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样本**：这些是现实世界中的对象，例如一本书、照片、动物、人或任何其他对象。样本也被称为观察、记录或行，以及其他命名约定。'
- en: '**Features**: These are descriptions or measurements of the samples in our
    dataset. Features could be the length, frequency of a specific word, the number
    of legs on an animal, date it was created, and so on. Features are also referred
    to as variables, columns, attributes or covariant, again among other naming conventions.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征**：这些是我们数据集中样本的描述或测量。特征可以是长度、特定单词的频率、动物的腿数、创建日期等等。特征也被称为变量、列、属性或协变量，以及其他命名约定。'
- en: The next step is tuning the data mining algorithm. Each data mining algorithm
    has parameters, either within the algorithm or supplied by the user. This tuning
    allows the algorithm to learn how to make decisions about the data.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是调整数据挖掘算法。每个数据挖掘算法都有参数，这些参数要么在算法内部，要么由用户提供。这种调整使算法能够学习如何对数据进行决策。
- en: 'As a simple example, we may wish the computer to be able to categorize people
    as *short* or *tall*. We start by collecting our dataset, which includes the heights
    of different people and whether they are considered short or tall:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作为简单的例子，我们可能希望计算机能够将人们分类为**矮**或**高**。我们首先收集我们的数据集，其中包括不同人的身高以及他们是否被认为是矮或高：
- en: '| **Person** | **Height** | **Short or tall?** |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| **人员** | **身高** | **矮或高？** |'
- en: '| 1 | 155cm | Short |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 155cm | 矮 |'
- en: '| 2 | 165cm | Short |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 165cm | 矮 |'
- en: '| 3 | 175cm | Tall |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 175cm | 高 |'
- en: '| 4 | 185cm | Tall |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 185cm | 高 |'
- en: As explained above, the next step involves tuning the parameters of our algorithm.
    As a simple algorithm; if the height is more than *x*, the person is tall. Otherwise,
    they are short. Our training algorithms will then look at the data and decide
    on a good value for *x*. For the preceding data, a reasonable value for this threshold
    would be 170 cm. A person taller than 170 cm is considered tall by the algorithm.
    Anyone else is considered short by this measure. This then lets our algorithm
    classify new data, such as a person with height 167 cm, even though we may have
    never seen a person with those measurements before.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，下一步涉及调整我们算法的参数。作为一个简单的算法；如果身高超过**x**，则该人被认为是高的。否则，他们被认为是矮的。然后我们的训练算法将查看数据并决定**x**的合适值。对于前面的数据，这个阈值的一个合理值是170厘米。算法认为身高超过170厘米的人是高的。其他人都被认为是矮的。这样，我们的算法就可以对新的数据进行分类，例如身高为167厘米的人，即使我们之前从未见过这样的人。
- en: In the preceding data, we had an obvious feature type. We wanted to know if
    people are short or tall, so we collected their heights. This feature engineering
    is a critical problem in data mining. In later chapters, we will discuss methods
    for choosing good features to collect in your dataset. Ultimately, this step often
    requires some expert domain knowledge or at least some trial and error.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的数据中，我们有一个明显的特征类型。我们想知道人们是矮还是高，所以我们收集了他们的身高。这个特征工程是数据挖掘中的一个关键问题。在后面的章节中，我们将讨论选择在数据集中收集的良好特征的方法。最终，这一步通常需要一些专业知识或至少一些试错。
- en: In this book, we will introduce data mining through Python. In some cases, we
    choose clarity of code and workflows, rather than the most optimized way to perform
    every task. This clarity sometimes involves skipping some details that can improve
    the algorithm's speed or effectiveness.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将通过Python介绍数据挖掘。在某些情况下，我们选择代码和流程的清晰性，而不是执行每个任务的最优化方式。这种清晰性有时涉及到跳过一些可以提高算法速度或有效性的细节。
- en: Using Python and the Jupyter Notebook
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python和Jupyter Notebook
- en: In this section, we will cover installing Python and the environment that we
    will use for most of the book, the **Jupyter** Notebook. Furthermore, we will
    install the **NumPy** module, which we will use for the first set of examples.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍安装Python以及我们将用于本书大部分内容的**Jupyter** Notebook。此外，我们还将安装**NumPy**模块，我们将使用它来进行第一组示例。
- en: The Jupyter Notebook was, until very recently, called the IPython Notebook.
    You'll notice the term in web searches for the project. Jupyter is the new name,
    representing a broadening of the project beyond using just Python.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook直到最近还被称为IPython Notebook。你会在项目相关的网络搜索中注意到这个术语。Jupyter是新的名称，代表着项目范围的扩大，而不仅仅是使用Python。
- en: Installing Python
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Python
- en: The Python programming language is a fantastic, versatile, and an easy to use
    language.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Python编程语言是一种出色、多功能且易于使用的语言。
- en: For this book, we will be using Python 3.5, which is available for your system
    from the Python Organization's website [https://www.python.org/downloads/](https://www.python.org/downloads/).
    However, I recommend that you use Anaconda to install Python, which you can download
    from the official website at [https://www.continuum.io/downloads](https://www.continuum.io/downloads).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这本书，我们将使用Python 3.5，该版本可以从Python组织的网站[https://www.python.org/downloads/](https://www.python.org/downloads/)获取。然而，我建议你使用Anaconda来安装Python，你可以从官方网站[https://www.continuum.io/downloads](https://www.continuum.io/downloads)下载。
- en: There will be two major versions to choose from, Python 3.5 and Python 2.7\.
    Remember to download and install Python 3.5, which is the version tested throughout
    this book. Follow the installation instructions on that website for your system.
    If you have a strong reason to learn version 2 of Python, then do so by downloading
    the Python 2.7 version. Keep in mind that some code may not work as in the book,
    and some workarounds may be needed.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你将有两个主要版本可供选择，Python 3.5和Python 2.7。请记住下载并安装Python 3.5，这是本书中测试过的版本。按照该网站上的安装说明进行安装。如果你有强烈理由学习Python
    2版本，那么可以通过下载Python 2.7版本来实现。请注意，有些代码可能不会像书中那样工作，可能需要一些解决方案。
- en: In this book, I assume that you have some knowledge of programming and Python
    itself. You do not need to be an expert with Python to complete this book, although
    a good level of knowledge will help. I will not be explaining general code structures
    and syntax in this book, except where it is different from what is considered
    *normal* python coding practice.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我假设你对编程和Python本身有一些了解。你不需要成为Python的专家就能完成这本书，尽管良好的知识水平会有所帮助。我不会在本书中解释一般的代码结构和语法，除非它与被认为是*正常*的Python编码实践不同。
- en: If you do not have any experience with programming, I recommend that you pick
    up the *Learning Python* book from Packt Publishing, or the book *Dive Into Python*,
    available online at [www.diveintopython3.net](http://www.diveintopython3.net)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有编程经验，我建议你从Packt Publishing出版的《Learning Python》这本书开始学习，或者在线可用的《Dive Into
    Python》这本书，可在[www.diveintopython3.net](http://www.diveintopython3.net)找到。
- en: 'The Python organization also maintains a list of two online tutorials for those
    new to Python:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Python组织还维护了一份针对Python新手的两个在线教程列表：
- en: 'For non-programmers who want to learn to program through the Python language:'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于想通过Python语言学习编程的非程序员：
- en: '[https://wiki.python.org/moin/BeginnersGuide/NonProgrammers](https://wiki.python.org/moin/BeginnersGuide/NonProgrammers)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://wiki.python.org/moin/BeginnersGuide/NonProgrammers](https://wiki.python.org/moin/BeginnersGuide/NonProgrammers)'
- en: 'For programmers who already know how to program, but need to learn Python specifically:'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于已经知道如何编程但需要学习Python的程序员：
- en: '[https://wiki.python.org/moin/BeginnersGuide/Programmers](https://wiki.python.org/moin/BeginnersGuide/Programmers)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://wiki.python.org/moin/BeginnersGuide/Programmers](https://wiki.python.org/moin/BeginnersGuide/Programmers)'
- en: Windows users will need to set an environment variable to use Python from the
    command line, where other systems will usually be immediately executable. We set
    it in the following steps
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Windows用户需要设置一个环境变量才能从命令行使用Python，而其他系统通常可以立即执行。我们将在以下步骤中设置它。
- en: First, find where you install Python 3 onto your computer; the default location
    is `C:\Python35`.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，找到你在电脑上安装Python 3的位置；默认位置是`C:\Python35`。
- en: 'Next, enter this command into the command line (cmd program): set the environment
    to `PYTHONPATH=%PYTHONPATH%;C:\Python35`.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将此命令输入到命令行（cmd程序）中：设置环境为`PYTHONPATH=%PYTHONPATH%;C:\Python35`。
- en: Remember to change the `C:\Python35` if your installation of Python is in a
    different folder.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的Python安装在不同的文件夹中，请记住将`C:\Python35`进行更改。
- en: Once you have Python running on your system, you should be able to open a command
    prompt and can run the following code to be sure it has installed correctly.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的系统上运行了Python，你应该能够打开命令提示符，并可以运行以下代码以确保它已正确安装。
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that we will be using the dollar sign ($) to denote that a command that
    you type into the terminal (also called a shell or `cmd` on Windows). You do not
    need to type this character (or retype anything that already appears on your screen).
    Just type in the rest of the line and press Enter.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们将使用美元符号（$）来表示你需要在终端（在Windows上也称为shell或`cmd`）中输入的命令。你不需要输入这个字符（或重新输入屏幕上已经出现的内容）。只需输入剩余的行并按Enter键。
- en: After you have the above `"Hello, world!"` example running, exit the program
    and move on to installing a more advanced environment to run Python code, the
    Jupyter Notebook.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在您运行了上述 `"Hello, world!"` 示例之后，退出程序，然后继续安装一个更高级的环境来运行 Python 代码，即 Jupyter Notebook。
- en: Python 3.5 will include a program called **pip**, which is a package manager
    that helps to install new libraries on your system. You can verify that `pip`
    is working on your system by running the `$ pip freeze` command, which tells you
    which packages you have installed on your system. Anaconda also installs their
    package manager, `conda`, that you can use. If unsure, use `conda` first, use
    `pip` only if that fails.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3.5 将包含一个名为 **pip** 的程序，它是一个包管理器，可以帮助您在系统上安装新的库。您可以通过运行 `$ pip freeze`
    命令来验证 `pip` 是否在您的系统上工作，该命令会告诉您您在系统上安装了哪些包。Anaconda 还安装了他们的包管理器 `conda`，您可以使用它。如果不确定，请先使用
    `conda`，如果失败再使用 `pip`。
- en: Installing Jupyter Notebook
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Jupyter Notebook
- en: '**Jupyter** is a platform for Python development that contains some tools and
    environments for running Python and has more features than the standard interpreter.
    It contains the powerful Jupyter Notebook, which allows you to write programs
    in a web browser. It also formats your code, shows output, and allows you to annotate
    your scripts. It is a great tool for exploring datasets and we will be using it
    as our main environment for the code in this book.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**Jupyter** 是一个 Python 开发平台，其中包含一些用于运行 Python 的工具和环境，它比标准解释器具有更多功能。它包含强大的 Jupyter
    Notebook，允许您在网页浏览器中编写程序。它还会格式化您的代码，显示输出，并允许您注释脚本。它是探索数据集的出色工具，我们将使用它作为本书代码的主要环境。'
- en: 'To install the Jupyter Notebook on your computer, you can type the following
    into a command line prompt (not into Python):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的计算机上安装 Jupyter Notebook，您可以在命令行提示符中输入以下内容（不要在 Python 中输入）：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You will not need administrator privileges to install this, as Anaconda keeps
    packages in the user's directory.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您不需要管理员权限来安装它，因为 Anaconda 将包存储在用户的目录中。
- en: 'With the Jupyter Notebook installed, you can launch it with the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了 Jupyter Notebook 后，您可以使用以下命令启动它：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Running this command will do two things. First, it will create a Jupyter Notebook
    instance - the backend - that will run in the command prompt you just used. Second,
    it will launch your web browser and connect to this instance, allowing you to
    create a new notebook. It will look something like the following screenshot (where
    you need to replace `/home/bob` with your current working directory):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此命令将执行两个操作。首先，它将在您刚刚使用的命令提示符中创建一个 Jupyter Notebook 实例（后端）。其次，它将启动您的网页浏览器并连接到此实例，允许您创建一个新的笔记本。它看起来可能像以下截图（其中您需要将
    `/home/bob` 替换为您的当前工作目录）：
- en: '![](img/image_01_001.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_001.png)'
- en: To stop the Jupyter Notebook from running, open the command prompt that has
    the instance running (the one you used earlier to run the `jupyter notebook  `
    command). Then, press *Ctrl* + *C* and you will be prompted `Shutdown this notebook
    server (y/[n])?`. Type *y* and press *Enter* and the Jupyter Notebook will shut
    down.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要停止 Jupyter Notebook 的运行，请打开运行实例的命令提示符（你之前用来运行 `jupyter notebook` 命令的那个）。然后，按
    *Ctrl* + *C*，你将收到提示 `Shutdown this notebook server (y/[n])?`。输入 *y* 并按 *Enter*，Jupyter
    Notebook 将会关闭。
- en: Installing scikit-learn
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 scikit-learn
- en: The `scikit-learn` package is a machine learning library, written in Python
    (but also containing code in other languages). It contains numerous algorithms,
    datasets, utilities, and frameworks for performing machine learning. Scikit-learnis
    built upon the scientific python stack, including libraries such as the `NumPy`
    and `SciPy` for speed. Scikit-learn is fast and scalable in many instances and
    useful for all skill ranges from beginners to advanced research users. We will
    cover more details of scikit-learn in [Chapter 2](b453da40-2d85-4978-aca0-3121de2f984e.xhtml),
    *Classifying with scikit-learn Estimators.*
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn` 包是一个机器学习库，用 Python 编写（但也包含其他语言的代码）。它包含许多算法、数据集、实用工具和框架，用于执行机器学习。Scikit-learn
    建立在科学 Python 堆栈之上，包括 `NumPy` 和 `SciPy` 等库，以提高速度。Scikit-learn 在许多情况下都快速且可扩展，适用于从初学者到高级研究用户的所有技能水平。我们将在第
    2 章 [使用 scikit-learn 估算器进行分类](b453da40-2d85-4978-aca0-3121de2f984e.xhtml)中详细介绍
    scikit-learn。'
- en: 'To install `scikit-learn`, you can use the `conda` utility that comes with
    Python 3, which will also install the `NumPy` and `SciPy` libraries if you do
    not already have them. Open a terminal with administrator/root privileges and
    enter the following command:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`scikit-learn`，您可以使用随Python 3一起提供的`conda`实用程序，如果您还没有安装，它还会安装`NumPy`和`SciPy`库。以管理员/根权限打开一个终端，并输入以下命令：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Users of major Linux distributions such as Ubuntu or Red Hat may wish to install
    the official package from their package manager.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的Linux发行版用户，如Ubuntu或Red Hat，可能希望从他们的包管理器中安装官方包。
- en: Not all distributions have the latest versions of scikit-learn, so check the
    version before installing it. The minimum version needed for this book is 0.14\.
    My recommendation for this book is to use Anaconda to manage this for you, rather
    than installing using your system's package manager.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有发行版都有scikit-learn的最新版本，所以在安装之前请检查版本。本书所需的最低版本是0.14。我推荐使用Anaconda来为您管理这些，而不是使用系统包管理器进行安装。
- en: Those wishing to install the latest version by compiling the source, or view
    more detailed installation instructions, can go to [http://scikit-learn.org/stable/install.html](http://scikit-learn.org/stable/install.html)
    and refer the official documentation on installing scikit-learn.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 想要通过编译源代码安装最新版本或查看更详细的安装说明的用户，可以访问[http://scikit-learn.org/stable/install.html](http://scikit-learn.org/stable/install.html)并参考安装scikit-learn的官方文档。
- en: A simple affinity analysis example
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个简单的亲和力分析示例
- en: In this section, we jump into our first example. A common use case for data
    mining is to improve sales, by asking a customer who is buying a product if he/she
    would like another similar product as well. You can perform this analysis through
    affinity analysis, which is the study of when things exist together, namely. correlate
    to each other.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将进入我们的第一个示例。数据挖掘的一个常见用途是通过询问购买产品的客户是否希望购买另一个类似的产品来提高销售额。您可以通过亲和力分析执行此分析，亲和力分析是研究事物共存时的情况，即相互关联。
- en: To repeat the now-infamous phrase taught in statistics classes, *correlation
    is not causation*. This phrase means that the results from affinity analysis cannot
    give a cause. In our next example, we perform affinity analysis on product purchases.
    The results indicate that the products are purchased together, but not that buying
    one product causes the purchase of the other. The distinction is important, critically
    so when determining how to use the results to affect a business process, for instance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了重复在统计学课程中教授的臭名昭著的短语，*相关性不等于因果关系*。这个短语的意思是，亲和力分析的结果不能给出原因。在我们的下一个例子中，我们对产品购买进行亲和力分析。结果显示产品是共同购买的，但并不意味着购买一个产品会导致另一个产品的购买。这种区别很重要，尤其是在确定如何使用结果影响业务流程时，例如。
- en: What is affinity analysis?
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是亲和力分析？
- en: 'Affinity analysis is a type of data mining that gives similarity between samples
    (objects). This could be the similarity between the following:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 亲和力分析是一种数据挖掘类型，它给出了样本（对象）之间的相似性。这可能是以下内容的相似性：
- en: '**Users** on a website, to provide varied services or targeted advertising'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站上的**用户**，以提供多样化的服务或定向广告
- en: '**Items** to sell to those users, to provide recommended movies or products'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**商品**，以向这些用户销售，提供推荐电影或产品'
- en: '**Human genes**, to find people that share the same ancestors'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人类基因**，以找到有相同祖先的人'
- en: We can measure affinity in several ways. For instance, we can record how frequently
    two products are purchased together. We can also record the accuracy of the statement
    when a person buys object 1 and when they buy object 2\. Other ways to measure
    affinity include computing the similarity between samples, which we will cover
    in later chapters.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过几种方式来衡量亲和力。例如，我们可以记录两个产品一起购买的多频繁。我们还可以记录当一个人购买对象1和对象2时陈述的准确性。衡量亲和力的其他方法包括计算样本之间的相似性，这些内容我们将在后面的章节中介绍。
- en: Product recommendations
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 产品推荐
- en: One of the issues with moving a traditional business online, such as commerce,
    is that tasks that used to be done by humans need to be automated for the online
    business to scale and compete with existing automated businesses. One example
    of this is up-selling, or selling an extra item to a customer who is already buying.
    Automated product recommendations through data mining are one of the driving forces
    behind the e-commerce revolution that is turning billions of dollars per year
    into revenue.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 将传统业务（如商业）转移到线上时遇到的一个问题是，以前由人类完成的工作需要自动化，以便在线业务可以扩展并与其他现有自动化业务竞争。其中一个例子是向上销售，即向已经购买商品的客户销售额外商品。通过数据挖掘进行自动化的产品推荐是电子商务革命背后的推动力之一，每年将数十亿美元转化为收入。
- en: 'In this example, we are going to focus on a basic product recommendation service.
    We design this based on the following idea: when two items are historically purchased
    together, they are more likely to be purchased together in the future. This sort
    of thinking is behind many product recommendation services, in both online and
    offline businesses.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将关注一个基本的产品推荐服务。我们基于以下想法来设计它：当两个项目历史上一起购买时，它们在未来更有可能一起购买。这种思维方式是许多在线和线下产品推荐服务背后的理念。
- en: A very simple algorithm for this type of product recommendation algorithm is
    to simply find any historical case where a user has brought an item and to recommend
    other items that the historical user brought. In practice, simple algorithms such
    as this can do well, at least better than choosing random items to recommend.
    However, they can be improved upon significantly, which is where data mining comes
    in.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这类产品推荐算法，一个非常简单的算法是简单地找到任何历史案例，其中用户购买了一个项目，然后推荐用户历史上购买的其他项目。在实践中，像这样的简单算法可以做得很好，至少比随机推荐项目要好。然而，它们可以显著改进，这就是数据挖掘的用武之地。
- en: 'To simplify the coding, we will consider only two items at a time. As an example,
    people may buy bread and milk at the same time at the supermarket. In this early
    example, we wish to find simple rules of the form:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化编码，我们将一次只考虑两个项目。例如，人们可能在超市同时购买面包和牛奶。在这个早期示例中，我们希望找到以下形式的简单规则：
- en: '*If a person buys product X, then they are likely to purchase product Y*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果一个人购买了产品X，那么他们很可能会购买产品Y*'
- en: More complex rules involving multiple items will not be covered such as people
    buying sausages and burgers being more likely to buy tomato sauce.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 不会涉及多个项目的更复杂规则，例如人们购买香肠和汉堡更有可能购买番茄酱。
- en: Loading the dataset with NumPy
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NumPy加载数据集
- en: 'The dataset can be downloaded from the code package supplied with the book,
    or from the official GitHub repository at:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以从本书提供的代码包中下载，或从官方GitHub仓库下载：
- en: '[https://github.com/dataPipelineAU/LearningDataMiningWithPython2](https://github.com/dataPipelineAU/LearningDataMiningWithPython2)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/dataPipelineAU/LearningDataMiningWithPython2](https://github.com/dataPipelineAU/LearningDataMiningWithPython2)'
- en: Download this file and save it on your computer, noting the path to the dataset.
    It is easiest to put it in the directory you'll run your code from, but we can
    load the dataset from anywhere on your computer.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 下载此文件并将其保存在你的电脑上，注意数据集的路径。将其放在你将运行代码的目录中是最容易的，但我们可以从电脑上的任何位置加载数据集。
- en: For this example, I recommend that you create a new folder on your computer
    to store your dataset and code. From here, open your Jupyter Notebook, navigate
    to this folder, and create a new notebook.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我建议你在电脑上创建一个新的文件夹来存储你的数据集和代码。从这里，打开你的Jupyter Notebook，导航到这个文件夹，并创建一个新的笔记本。
- en: The dataset we are going to use for this example is a NumPy two-dimensional
    array, which is a format that underlies most of the examples in the rest of the
    book. The array looks like a table, with rows representing different samples and
    columns representing different features.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要用于这个示例的数据集是一个NumPy二维数组，这种格式是本书其余部分大多数示例的基础。这个数组看起来像一张表格，行代表不同的样本，列代表不同的特征。
- en: 'The cells represent the value of a specific feature of a specific sample. To
    illustrate, we can load the dataset with the following code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 单元代表特定样本特定特征的值。为了说明，我们可以用以下代码加载数据集：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Enter the previous code into the first cell of your (Jupyter) Notebook. You
    can then run the code by pressing Shift + Enter (which will also add a new cell
    for the next section of code). After the code is run, the square brackets to the
    left-hand side of the first cell will be assigned an incrementing number, letting
    you know that this cell has completed. The first cell should look like the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 将前面的代码输入到你的（Jupyter）笔记本的第一个单元格中。然后你可以通过按Shift + Enter来运行代码（这也会为下一部分的代码添加一个新的单元格）。代码运行后，第一个单元格左侧的方括号将被分配一个递增的数字，让你知道这个单元格已经完成。第一个单元格应该看起来像以下这样：
- en: '![](img/B06162_1-1.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B06162_1-1.png)'
- en: For code that will take more time to run, an asterisk will be placed here to
    denote that this code is either running or scheduled to run. This asterisk will
    be replaced by a number when the code has completed running (including if the
    code completes because it failed).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于运行时间较长的代码，这里将放置一个星号来表示该代码正在运行或已安排运行。当代码运行完成时（包括如果代码因失败而完成），星号将被一个数字替换。
- en: 'This dataset has 100 samples and five features, which we will need to know
    for the later code. Let''s extract those values using the following code:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集有100个样本和五个特征，我们将在后面的代码中需要这些值。让我们使用以下代码提取这些值：
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If you choose to store the dataset somewhere other than the directory your Jupyter
    Notebooks are in, you will need to change the `dataset_filename` value to the
    new location.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择将数据集存储在Jupyter Notebooks所在的目录之外，你需要将`dataset_filename`的值更改为新位置。
- en: 'Next, we can show some of the rows of the dataset to get an understanding of
    the data. Enter the following line of code into the next cell and run it, to print
    the first five lines of the dataset:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以展示数据集的一些行，以了解数据。将以下代码行输入下一个单元格并运行它，以打印数据集的前五行：
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The result will show you which items were bought in the first five transactions
    listed:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将显示在列出的前五笔交易中购买了哪些商品：
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Downloading the example code
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码
- en: 'You can download the example code files from your account at [http://www.packtpub.com](http://www.packtpub.com/)
    for all the Packt Publishing books you have purchased. If you purchased this book
    elsewhere, you could visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you. I''ve also setup a GitHub
    repository that contains a live version of the code, along with new fixes, updates
    and so on. You can retrieve the code and datasets at the repository here: [https://github.com/dataPipelineAU/LearningDataMiningWithPython2](https://github.com/dataPipelineAU/LearningDataMiningWithPython2)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从你购买的所有Packt Publishing书籍的账户中下载示例代码文件[http://www.packtpub.com](http://www.packtpub.com/)。如果你在其他地方购买了这本书，你可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给你。我还设置了一个GitHub仓库，其中包含代码的实时版本，以及新的修复、更新等。你可以在以下仓库中检索代码和数据集：[https://github.com/dataPipelineAU/LearningDataMiningWithPython2](https://github.com/dataPipelineAU/LearningDataMiningWithPython2)
- en: 'You can read the dataset can by looking at each row (horizontal line) at a
    time. The first row `(0, 1, 0, 0, 0)` shows the items purchased in the first transaction.
    Each column (vertical row) represents each of the items. They are bread, milk,
    cheese, apples, and bananas, respectively. Therefore, in the first transaction,
    the person bought cheese, apples, and bananas, but not bread or milk. Add the
    following line in a new cell to allow us to turn these feature numbers into actual
    words:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过一次查看每一行（水平线）来读取数据集。第一行`(0, 1, 0, 0, 0)`显示了第一笔交易中购买的商品。每一列（垂直行）代表每种商品。它们分别是面包、牛奶、奶酪、苹果和香蕉。因此，在第一笔交易中，这个人购买了奶酪、苹果和香蕉，但没有购买面包或牛奶。在新的单元格中添加以下行，以便我们将这些特征数字转换为实际单词：
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Each of these features contains binary values, stating only whether the items
    were purchased and not how many of them were purchased. A*1* indicates that *at
    least 1* item was bought of this type, while a *0* indicates that absolutely none
    of that item was purchased. For a real world dataset, using exact figures or a
    larger threshold would be required.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征中的每一个都包含二进制值，仅表示是否购买了商品，而不表示购买的数量。*1*表示至少购买了这种类型的一种商品，而*0*表示完全没有购买这种商品。对于现实世界的数据集，使用精确的数字或更大的阈值是必要的。
- en: Implementing a simple ranking of rules
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现规则的简单排序
- en: We wish to find rules of the type *If a person buys product X, then they are
    likely to purchase product Y.* We can quite easily create a list of all the rules
    in our dataset by simply finding all occasions when two products are purchased
    together. However, we then need a way to determine good rules from bad ones allowing
    us to choose specific products to recommend.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望找到类型为*如果一个人购买产品X，那么他们很可能会购买产品Y*的规则。我们可以通过简单地找到两个产品一起购买的所有场合来轻松地创建我们数据集中所有规则的一个列表。然而，然后我们需要一种方法来确定好的规则和不好的规则，以便我们可以选择特定的产品进行推荐。
- en: 'We can evaluate rules of this type in many ways, on which we will focus on
    two: **support** and **confidence.**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用许多方式评估这类规则，我们将关注其中的两种：**支持度**和**置信度**。
- en: Support is the number of times that a rule occurs in a dataset, which is computed
    by simply counting the number of samples for which the rule is valid. It can sometimes
    be normalized by dividing by the total number of times the premise of the rule
    is valid, but we will simply count the total for this implementation.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度是规则在数据集中出现的次数，这通过简单地计算规则有效的样本数量来计算。有时可以通过将总数除以规则前提有效的总次数来归一化，但在这个实现中我们将简单地计算总数。
- en: The **premise** is the requirements for a rule to be considered active. The
    **conclusion** is the output of the rule. For the example *if a person buys an
    apple, they also buy a banana*, the rule is only valid if the premise happens
    - a person buys an apple. The rule's conclusion then states that the person will
    buy a banana.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**前提**是规则被认为是活跃的要求。**结论**是规则的输出。对于例子*如果一个人买苹果，他们也买香蕉*，只有当前提发生时——一个人买了苹果——该规则才是有效的。然后，规则的结论声明这个人会买香蕉。'
- en: While the support measures how often a rule exists, confidence measures how
    accurate they are when they can be used. You can compute this by determining the
    percentage of times the rule applies when the premise applies. We first count
    how many times a rule applies to our data and divide it by the number of samples
    where the premise (the `if` statement) occurs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然支持度衡量规则存在的频率，但置信度衡量当它们可以使用时它们的准确性。你可以通过确定规则在前提适用时应用的百分比来计算这个值。我们首先计算规则在我们的数据中应用的次数，然后除以前提（即`if`语句）出现的样本数量。
- en: As an example, we will compute the support and confidence for the rule *if a
    person buys apples, they also buy bananas.*
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 作为例子，我们将计算规则*如果一个人买苹果，他们也买香蕉*的支持度和置信度。
- en: 'As the following example shows, we can tell whether someone bought apples in
    a transaction, by checking the value of `sample[3]`, where we assign a sample
    to a row of our matrix:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下示例所示，我们可以通过检查`sample[3]`的值来判断某人在交易中是否购买了苹果，其中我们将一个样本分配到矩阵的某一行：
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Similarly, we can check if bananas were bought in a transaction by seeing if
    the value of `sample[4]` is equal to 1 (and so on). We can now compute the number
    of times our rule exists in our dataset and, from that, the confidence and support.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以通过查看`sample[4]`的值是否等于1（等等）来检查交易中是否购买了香蕉。我们现在可以计算我们的规则在数据集中出现的次数，从而计算出置信度和支持度。
- en: Now we need to compute these statistics for all rules in our database. We will
    do this by creating a dictionary for both *valid rules* and *invalid rules*. The
    key to this dictionary will be a tuple (premise and conclusion). We will store
    the indices, rather than the actual feature names. Therefore, we would store (3
    and 4) to signify the previous rule *If a person buys apples, they will also buy
    bananas.* If the premise and conclusion are given, the rule is considered valid.
    While if the premise is given but the conclusion is not, the rule is considered
    invalid for that sample.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要计算数据库中所有规则的这些统计数据。我们将为此创建两个字典，一个用于*有效规则*，另一个用于*无效规则*。这个字典的键将是一个元组（前提和结论）。我们将存储索引，而不是实际的特征名称。因此，我们会存储（3和4）来表示之前的规则*如果一个人买了苹果，他们也会买香蕉*。如果前提和结论都给出，则该规则被认为是有效的。而如果前提给出但结论没有给出，则该规则对该样本被认为是无效的。
- en: 'The following steps will help us to compute the confidence and support for
    all possible rules:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助我们计算所有可能规则的置信度和支持度：
- en: 'We first set up some dictionaries to store the results. We will use `defaultdict`
    for this, which sets a default value if a key is accessed that doesn''t yet exist.
    We record the number of valid rules, invalid rules, and occurrences of each premise:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先设置一些字典来存储结果。我们将使用`defaultdict`，它会在访问一个尚不存在的键时设置一个默认值。我们记录有效规则的数目、无效规则的数目以及每个前提的出现次数：
- en: '[PRE10]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Next, we compute these values in a large loop. We iterate over each sample in
    the dataset and then loop over each feature as a premise. When again loop over
    each feature as a possible conclusion, mapping the relationship premise to conclusion.
    If the sample contains a person who bought the premise and the conclusion, we
    record this in `valid_rules`. If they did not purchase the conclusion product,
    we record this in `invalid_rules`.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们在一个大的循环中计算这些值。我们遍历数据集中的每个样本，然后遍历每个特征作为前提。再次遍历每个特征作为可能的结论，映射前提到结论的关系。如果样本包含一个购买了前提和结论的人，我们在`valid_rules`中记录这个信息。如果他们没有购买结论产品，我们在`invalid_rules`中记录这个信息。
- en: 'For sample in X:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于样本X中的每个样本：
- en: '[PRE11]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If the premise is valid for this sample (it has a value of *1*), then we record
    this and check each conclusion of our rule. We skip over any conclusion that is
    the same as the premise-this would give us rules such as: *if a person buys Apples,
    then they buy Apples*, which obviously doesn''t help us much.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前提对这个样本是有效的（它有一个值为*1*），那么我们记录这个信息并检查我们规则的每个结论。我们跳过任何与前提相同的结论——这会给我们规则，如：*如果一个人买了苹果，那么他们也买了苹果*，这显然对我们帮助不大。
- en: 'We have now completed computing the necessary statistics and can now compute
    the *support* and *confidence* for each rule. As before, the support is simply
    our `valid_rules` value:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经完成了必要的统计计算，现在可以计算每个规则的*支持度*和*置信度*。和之前一样，支持度只是我们的`valid_rules`值：
- en: '[PRE12]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can compute the confidence in the same way, but we must loop over each rule
    to compute this:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用相同的方式计算置信度，但我们必须遍历每个规则来计算这个值：
- en: '[PRE13]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We now have a dictionary with the support and confidence for each rule. We
    can create a function that will print out the rules in a readable format. The
    signature of the rule takes the premise and conclusion indices, the support and
    confidence dictionaries we just computed, and the features array that tells us
    what the `features` mean. Then we print out the `Support` and `Confidence` of
    this rule:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个包含每个规则的支持度和置信度的字典。我们可以创建一个函数，以可读的格式打印出这些规则。规则的签名接受前提和结论索引、我们刚刚计算的支持度和置信度字典，以及一个告诉我们`features`含义的特征数组。然后我们打印出该规则的`Support`和`Confidence`：
- en: '[PRE14]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can test the code by calling it in the following way-feel free to experiment
    with different premises and conclusions:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下方式调用代码来测试它——请随意尝试不同的前提和结论：
- en: '[PRE15]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Ranking to find the best rules
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 排序以找到最佳规则
- en: Now that we can compute the support and confidence of all rules, we want to
    be able to find the *best* rules. To do this, we perform a ranking and print the
    ones with the highest values. We can do this for both the support and confidence
    values.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们能够计算所有规则的支持度和置信度，我们希望能够找到*最佳*的规则。为此，我们进行排名并打印出具有最高值的规则。我们可以对支持和置信度值都这样做。
- en: 'To find the rules with the highest support, we first sort the support dictionary.
    Dictionaries do not support ordering by default; the `items()` function gives
    us a list containing the data in the dictionary. We can sort this list using the
    `itemgetter` class as our key, which allows for the sorting of nested lists such
    as this one. Using `itemgetter(1)` allows us to sort based on the values. `Setting
    reverse=True` gives us the highest values first:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到支持度最高的规则，我们首先对支持度字典进行排序。字典默认不支持排序；`items()`函数给我们一个包含字典中数据的列表。我们可以使用`itemgetter`类作为我们的键来对这个列表进行排序，这允许我们排序如此类似的嵌套列表。使用`itemgetter(1)`允许我们根据值进行排序。将`reverse=True`设置为真，我们可以首先得到最高的值：
- en: '[PRE16]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can then print out the top five rules:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以打印出前五条规则：
- en: '[PRE17]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The result will look like the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来如下：
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Similarly, we can print the top rules based on confidence. First, compute the
    sorted confidence list and then print them out using the same method as before.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以根据置信度打印出最佳规则。首先，计算排序后的置信度列表，然后使用之前相同的方法打印它们。
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Two rules are near the top of both lists. The first is *If a person buys apples,
    they will also buy cheese*, and the second is *If a person buys cheese, they will
    also buy bananas*. A store manager can use rules like these to organize their
    store. For example, if apples are on sale this week, put a display of cheeses
    nearby. Similarly, it would make little sense to put both bananas on sale at the
    same time as cheese, as nearly 66 percent of people buying cheese will probably
    buy bananas -our sale won't increase banana purchases all that much.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 两条规则在两个列表的顶部附近。第一条是*如果一个人买了苹果，他们也会买奶酪*，第二条是*如果一个人买了奶酪，他们也会买香蕉*。商店经理可以使用这样的规则来组织他们的商店。例如，如果本周苹果打折，就在附近放置奶酪的展示。同样，将香蕉和奶酪同时打折几乎没有意义，因为近66%买奶酪的人可能会买香蕉——我们的促销不会大幅增加香蕉的销量。
- en: 'Jupyter Notebook will display graphs inline, right in the notebook. Sometimes,
    however, this is not always configured by default. To configure Jupyter Notebook
    to display graphs inline, use the following line of code: `%matplotlib inline`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook 将在笔记本中内联显示图表。然而，有时这并不是默认配置的。要配置 Jupyter Notebook 以内联显示图表，请使用以下代码行：`%matplotlib
    inline`
- en: We can visualize the results using a library called `matplotlib`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用名为 `matplotlib` 的库来可视化结果。
- en: 'We are going to start with a simple line plot showing the confidence values
    of the rules, in order of confidence. `matplotlib` makes this easy - we just pass
    in the numbers, and it will draw up a simple but effective plot:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从展示规则置信度的简单折线图开始，按置信度顺序排列。`matplotlib` 使得这变得简单——我们只需传入数字，它就会绘制出一个简单但有效的图表：
- en: '[PRE20]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](img/image_01_003.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_01_003.png)'
- en: Using the previous graph, we can see that the first five rules have decent confidence,
    but the efficacy drops quite quickly after that. Using this information, we might
    decide to use just the first five rules to drive business decisions. Ultimately
    with exploration techniques like this, the result is up to the user.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前的图表，我们可以看到前五条规则有相当高的置信度，但在此之后效果迅速下降。利用这些信息，我们可能会决定只使用前五条规则来驱动商业决策。最终，使用这种探索技术，结果取决于用户。
- en: 'Data mining has great exploratory power in examples like this. A person can
    use data mining techniques to explore relationships within their datasets to find
    new insights. In the next section, we will use data mining for a different purpose:
    prediction and classification.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这样的例子中，数据挖掘具有强大的探索能力。一个人可以使用数据挖掘技术来探索其数据集中的关系，以发现新的见解。在下一节中，我们将使用数据挖掘来实现不同的目的：预测和分类。
- en: A simple classification example
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个简单的分类示例
- en: In the affinity analysis example, we looked for correlations between different
    variables in our dataset. In classification, we have a single variable that we
    are interested in and that we call the **class** (also called the target). In
    the earlier example, if we were interested in how to make people buy more apples,
    we would explore the rules related to apples and use those to inform our decisions.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在亲和力分析示例中，我们寻找了数据集中不同变量之间的相关性。在分类中，我们有一个我们感兴趣的单一变量，我们称之为**类别**（也称为目标）。在先前的例子中，如果我们对人们如何购买更多苹果感兴趣，我们会探索与苹果相关的规则，并使用这些规则来指导我们的决策。
- en: What is classification?
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是分类？
- en: 'Classification is one of the largest uses of data mining, both in practical
    use and in research. As before, we have a set of samples that represents objects
    or things we are interested in classifying. We also have a new array, the class
    values. These class values give us a categorization of the samples. Some examples
    are as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是数据挖掘应用最广泛的一种，无论是在实际应用还是在研究中。与之前一样，我们有一组代表我们感兴趣分类的对象或事物的样本。我们还有一个新的数组，即类别值。这些类别值为我们提供了样本的分类。以下是一些例子：
- en: 'Determining the species of a plant by looking at its measurements. The class
    value here would be: *Which species is this?*'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过观察植物的测量值来确定其种类。这里的类别值将是：*这是哪种物种？*
- en: 'Determining if an image contains a dog. The class would be: *Is there a dog
    in this image?*'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定图像中是否包含狗。类别将是：*这张图像中是否有狗？*
- en: 'Determining if a patient has cancer, based on the results of a specific test.
    The class would be: *Does this patient have cancer?*'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据特定测试的结果来确定患者是否患有癌症。类别将是：*这位患者是否有癌症？*
- en: While many of the examples previous are binary (yes/no) questions, they do not
    have to be, as in the case of plant species classification in this section.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然许多先前的例子是二元（是/否）问题，但它们不必是，就像本节中植物物种分类的例子一样。
- en: The goal of classification applications is to train a model on a set of samples
    with known classes and then apply that model to new unseen samples with unknown
    classes. For example, we want to train a spam classifier on my past e-mails, which
    I have labeled as spam or not spam. I then want to use that classifier to determine
    whether my next email is spam, without me needing to classify it myself.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 分类应用的目的是在已知类别的样本集上训练一个模型，然后将该模型应用于具有未知类别的未见样本。例如，我们想在标记为垃圾邮件或非垃圾邮件的过去电子邮件上训练一个垃圾邮件分类器。然后我想使用这个分类器来确定我的下一封电子邮件是否是垃圾邮件，而无需我自己进行分类。
- en: Loading and preparing the dataset
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据集和准备数据
- en: 'The dataset we are going to use for this example is the famous Iris database
    of plant classification. In this dataset, we have 150 plant samples and four measurements
    of each: **sepal length**, **sepal width**, **petal length**, and **petal width**
    (all in centimeters). This classic dataset (first used in 1936!) is one of the
    classic datasets for data mining. There are three classes: **Iris Setosa**, **Iris
    Versicolour**, and **Iris Virginica**. The aim is to determine which type of plant
    a sample is, by examining its measurements.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要用于此示例的数据集是著名的植物分类的鸢尾花数据库。在此数据集中，我们有150个植物样本，每个样本有四个测量值：**萼片长度**、**萼片宽度**、**花瓣长度**和**花瓣宽度**（所有单位均为厘米）。这个经典数据集（首次使用于1936年！）是数据挖掘的经典数据集之一。有三个类别：**鸢尾花塞托萨**、**鸢尾花变色**和**鸢尾花维吉尼卡**。目标是通过对样本的测量来确定样本属于哪种植物类型。
- en: 'The `scikit-learn` library contains this dataset built-in, making the loading
    of the dataset straightforward:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn` 库内置了此数据集，使得数据集的加载变得简单：'
- en: '[PRE21]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You can also `print(dataset.DESCR)` to see an outline of the dataset, including
    some details about the features.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用 `print(dataset.DESCR)` 来查看数据集的概述，包括一些关于特征细节的信息。
- en: The features in this dataset are continuous values, meaning they can take any
    range of values. Measurements are a good example of this type of feature, where
    a measurement can take the value of 1, 1.2, or 1.25 and so on. Another aspect
    of continuous features is that feature values that are close to each other indicate
    similarity. A plant with a sepal length of 1.2 cm is like a plant with a Sepal
    width of 1.25 cm.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本数据集中的特征是连续值，这意味着它们可以取任何范围的值。测量值是这种类型特征的很好例子，其中测量值可以是1、1.2或1.25等。连续特征的另一个方面是，彼此接近的特征值表示相似性。一个萼片长度为1.2厘米的植物就像一个萼片宽度为1.25厘米的植物。
- en: In contrast are categorical features. These features, while often represented
    as numbers, cannot be compared in the same way. In the Iris dataset, the class
    values are an example of a categorical feature. The class 0 represents Iris Setosa;
    class 1 represents Iris Versicolour, and class 2 represents Iris Virginica. The
    numbering doesn't mean that Iris Setosa is more similar to Iris Versicolour than
    it is to Iris Virginica-despite the class value being more similar. The numbers
    here represent categories. All we can say is whether categories are the same or
    different.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，分类特征。这些特征虽然通常以数字表示，但不能以相同的方式进行比较。在鸢尾花数据集中，类别值是分类特征的例子。类别0代表鸢尾花塞托萨；类别1代表鸢尾花变色，类别2代表鸢尾花维吉尼卡。这里的编号并不意味着鸢尾花塞托萨比鸢尾花变色更相似，尽管类别值更相似。这里的数字代表类别。我们只能说类别是否相同或不同。
- en: There are other types of features too, which we will cover in later chapters.
    These include pixel intensity, word frequency and n-gram analysis.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他类型的特征，我们将在后面的章节中介绍。这些包括像素强度、词频和n-gram分析。
- en: While the features in this dataset are continuous, the algorithm we will use
    in this example requires categorical features. Turning a continuous feature into
    a categorical feature is a process called discretization.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然此数据集中的特征是连续的，但我们将在此示例中使用的算法需要分类特征。将连续特征转换为分类特征的过程称为离散化。
- en: 'A simple discretization algorithm is to choose some threshold, and any values
    below this threshold are given a value 0\. Meanwhile, any above this are given
    the value 1\. For our threshold, we will compute the mean (average) value for
    that feature. To start with, we compute the mean for each feature:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单的离散化算法是选择一个阈值，任何低于此阈值的值都被赋予值0。同时，任何高于此阈值的值都被赋予值1。对于我们的阈值，我们将计算该特征的平均值（平均值）。首先，我们计算每个特征的平均值：
- en: '[PRE22]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The result from this code will be an array of length 4, which is the number
    of features we have. The first value is the mean of the values for the first feature
    and so on. Next, we use this to transform our dataset from one with continuous
    features to one with discrete categorical features:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码的结果将是一个长度为 4 的数组，这是我们拥有的特征数量。第一个值是第一个特征的值的平均值，依此类推。接下来，我们使用这个结果将我们的数据集从具有连续特征的集合转换为具有离散分类特征的集合：
- en: '[PRE23]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We will use this new `X_d` dataset (for *X discretized*) for our **training
    and testing**, rather than the original dataset (*X*).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个新的 `X_d` 数据集（*X 离散化*）进行我们的 **训练和测试**，而不是原始数据集（*X*）。
- en: Implementing the OneR algorithm
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现 OneR 算法
- en: '**OneR** is a simple algorithm that simply predicts the class of a sample by
    finding the most frequent class for the feature values. **OneR** is shorthand
    for *One Rule*, indicating we only use a single rule for this classification by
    choosing the feature with the best performance. While some of the later algorithms
    are significantly more complex, this simple algorithm has been shown to have good
    performance in some real-world datasets.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**OneR** 是一个简单的算法，它通过找到特征值的最高频率类别来预测样本的类别。**OneR** 是 *One Rule* 的缩写，表示我们只使用一个规则进行这种分类，通过选择表现最好的特征。虽然一些后续的算法要复杂得多，但这个简单的算法在现实世界的一些数据集中已被证明有良好的性能。'
- en: The algorithm starts by iterating over every value of every feature. For that
    value, count the number of samples from each class that has that feature value.
    Record the most frequent class of the feature value, and the error of that prediction.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 算法首先遍历每个特征的每个值。对于这个值，计算具有该特征值的每个类别的样本数量。记录特征值的最高频率类别和预测的错误。
- en: For example, if a feature has two values, *0* and *1*, we first check all samples
    that have the value *0*. For that value, we may have 20 in Class *A*, 60 in Class
    *B*, and a further 20 in Class *C*. The most frequent class for this value is
    *B*, and there are 40 instances that have different classes. The prediction for
    this feature value is *B* with an error of 40, as there are 40 samples that have
    a different class from the prediction. We then do the same procedure for the value
    *1* for this feature, and then for all other feature value combinations.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果一个特征有两个值，*0* 和 *1*，我们首先检查所有具有值 *0* 的样本。对于这个值，我们可能在类别 *A* 中有 20 个，在类别 *B*
    中有 60 个，以及在类别 *C* 中有进一步的 20 个。对于这个值最频繁的类别是 *B*，并且有 40 个实例具有不同的类别。对于这个特征值的预测是 *B*，错误率为
    40，因为有 40 个样本与预测的类别不同。然后，我们对这个特征的值 *1* 执行相同的程序，然后对其他所有特征值组合执行。
- en: Once these combinations are computed, we compute the error for each feature
    by summing up the errors for all values for that feature. The feature with the
    lowest total error is chosen as the *One Rule* and then used to classify other
    instances.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计算了这些组合，我们就通过累加该特征的值的错误来计算每个特征的错误。具有最低总错误的特征被选为 *One Rule*，然后用于分类其他实例。
- en: 'In code, we will first create a function that computes the class prediction
    and error for a specific feature value. We have two necessary imports, `defaultdict`
    and `itemgetter`, that we used in earlier code:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我们首先创建一个函数，用于计算特定特征值的类别预测和错误。我们有两个必要的导入，`defaultdict` 和 `itemgetter`，我们在之前的代码中使用过：
- en: '[PRE24]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, we create the function definition, which needs the dataset, classes,
    the index of the feature we are interested in, and the value we are computing.
    It loops over each sample, and counts the number of time each feature value corresponds
    to a specific class. We then choose the most frequent class for the current feature/value
    pair:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个函数定义，该函数需要数据集、类别、我们感兴趣的特征的索引以及我们正在计算的值。它遍历每个样本，并计算每个特征值对应特定类别的次数。然后，我们选择当前特征/值对的最高频率类别：
- en: '[PRE25]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As a final step, we also compute the error of this rule. In the `OneR` algorithm,
    any sample with this feature value would be predicted as being the most frequent
    class. Therefore, we compute the error by summing up the counts for the other
    classes (not the most frequent). These represent training samples that result
    in error or an incorrect classification.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们还计算了这个规则的错误。在 `OneR` 算法中，任何具有这个特征值的样本都会被预测为最频繁的类别。因此，我们通过累加其他类别的计数（不是最频繁的）来计算错误。这些代表导致错误或分类错误的训练样本。
- en: With this function, we can now compute the error for an entire feature by looping
    over all the values for that feature, summing the errors, and recording the predicted
    classes for each value.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个函数，我们现在可以通过遍历该特征的值、汇总误差并记录每个值的预测类别来计算整个特征的误差。
- en: 'The function needs the dataset, classes, and feature index we are interested
    in. It then iterates through the different values and finds the most accurate
    feature value to use for this specific feature, as the rule in `OneR`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数需要数据集、类别以及我们感兴趣的属性索引。然后它遍历不同的值，并找到用于此特定属性的、最准确的属性值，正如 `OneR` 规则：
- en: '[PRE26]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Let's have a look at this function in a little more detail.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这个函数。
- en: 'After some initial tests, we then find all the unique values that the given
    feature takes. The indexing in the next line looks at the whole column for the
    given feature and returns it as an array. We then use the set function to find
    only the unique values:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些初步测试之后，我们找到给定属性所具有的所有唯一值。下一行的索引查看给定属性的整个列，并将其作为数组返回。然后我们使用 set 函数来找到唯一的值：
- en: '[PRE27]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Next, we create our dictionary that will store the predictors. This dictionary
    will have feature values as the keys and classification as the value. An entry
    with key 1.5 and value 2 would mean that, when the feature has a value set to
    1.5, classify it as belonging to class 2\. We also create a list storing the errors
    for each feature value:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个字典来存储预测值。这个字典将以属性值作为键，分类作为值。键为 1.5，值为 2 的条目意味着，当属性值设置为 1.5 时，将其分类为属于类别
    2。我们还创建了一个列表来存储每个属性值的误差：
- en: '[PRE28]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'As the main section of this function, we iterate over all the unique values
    for this feature and use our previously defined `train_feature_value` function
    to find the most frequent class and the error for a given feature value. We store
    the results as outlined earlier:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这个函数的主要部分，我们遍历这个特征的唯一值，并使用之前定义的 `train_feature_value` 函数来找到给定属性值的最大频率类别和误差。我们按照前面概述的方式存储结果：
- en: 'Finally, we compute the total errors of this rule and return the predictors
    along with this value:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算这个规则的总体误差，并返回预测值以及这个值：
- en: '[PRE29]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Testing the algorithm
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试算法
- en: When we evaluated the affinity analysis algorithm of the earlier section, our
    aim was to explore the current dataset. With this classification, our problem
    is different. We want to build a model that will allow us to classify previously
    unseen samples by comparing them to what we know about the problem.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们评估前面章节中的亲和力分析算法时，我们的目标是探索当前数据集。与此分类不同，我们想要构建一个模型，通过将其与我们对该问题的了解进行比较，使我们能够对以前未见样本进行分类。
- en: 'For this reason, we split our machine-learning workflow into two stages: training
    and testing. In training, we take a portion of the dataset and create our model.
    In testing, we apply that model and evaluate how effectively it worked on the
    dataset. As our goal is to create a model that can classify previously unseen
    samples, we cannot use our testing data for training the model. If we do, we run
    the risk of **overfitting**.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将机器学习工作流程分为两个阶段：训练和测试。在训练阶段，我们取数据集的一部分来创建我们的模型。在测试阶段，我们应用这个模型并评估它在数据集上的有效性。由于我们的目标是创建一个可以分类以前未见样本的模型，我们不能使用测试数据来训练模型。如果我们这样做，我们就有可能发生**过度拟合**。
- en: 'Overfitting is the problem of creating a model that classifies our training
    dataset very well but performs poorly on new samples. The solution is quite simple:
    never use training data to test your algorithm. This simple rule has some complex
    variants, which we will cover in later chapters; but, for now, we can evaluate
    our `OneR` implementation by simply splitting our dataset into two small datasets:
    a training one and a testing one. This workflow is given in this section.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 过度拟合是创建一个模型，该模型在训练数据集上分类得很好，但在新样本上表现不佳的问题。解决方案很简单：永远不要使用训练数据来测试你的算法。这个简单规则有一些复杂的变体，我们将在后面的章节中介绍；但，现在，我们可以通过简单地分割我们的数据集为两个小数据集：一个用于训练，一个用于测试来评估我们的
    `OneR` 实现。这个工作流程在本节中给出。
- en: 'The `scikit-learn` library contains a function to split data into training
    and testing components:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn` 库包含一个函数可以将数据分割成训练和测试组件：'
- en: '[PRE30]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This function will split the dataset into two sub-datasets, per a given ratio
    (which by default uses 25 percent of the dataset for testing). It does this randomly,
    which improves the confidence that the algorithm will perform as expected in real
    world environments (where we expect data to come in from a random distribution):'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将数据集根据给定的比例（默认情况下使用数据集的 25% 用于测试）分成两个子数据集。它是随机进行的，这提高了算法在现实世界环境中按预期执行（我们期望数据来自随机分布）的置信度：
- en: '[PRE31]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We now have two smaller datasets: `Xd_train` contains our data for training
    and `Xd_test` contains our data for testing. `y_train` and `y_test` give the corresponding
    class values for these datasets.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有两个较小的数据集：`Xd_train` 包含我们的训练数据，`Xd_test` 包含我们的测试数据。`y_train` 和 `y_test`
    给出了这些数据集对应的类别值。
- en: We also specify a `random_state`. Setting the random state will give the same
    split every time the same value is entered. It will *look* random, but the algorithm
    used is deterministic, and the output will be consistent. For this book, I recommend
    setting the random state to the same value that I do, as it will give you the
    same results that I get, allowing you to verify your results. To get truly random
    results that change every time you run it, set `random_state` to `None`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还指定了一个 `random_state`。设置随机状态将在每次输入相同值时给出相同的分割。它看起来是随机的，但使用的算法是确定性的，输出将是一致的。对于这本书，我建议将随机状态设置为与我相同的值，这样你将得到与我相同的结果，允许你验证你的结果。要获得每次运行都变化的真正随机结果，请将
    `random_state` 设置为 `None`。
- en: 'Next, we compute the predictors for all the features for our dataset. Remember
    to only use the training data for this process. We iterate over all the features
    in the dataset and use our previously defined functions to train the predictors
    and compute the errors:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算数据集中所有特征的预测器。记住，只使用训练数据来完成这个过程。我们遍历数据集中的所有特征，并使用先前定义的函数来训练预测器和计算错误：
- en: '[PRE32]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, we find the best feature to use as our *One Rule*, by finding the feature
    with the lowest error:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过找到具有最低错误的特征来找到用作我们的 *One Rule* 的最佳特征：
- en: '[PRE33]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We then create our `model` by storing the predictors for the best feature:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过存储最佳特征的预测器来创建我们的 `model`：
- en: '[PRE34]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Our model is a dictionary that tells us which feature to use for our *One Rule*
    and the predictions that are made based on the values it has. Given this model,
    we can predict the class of a previously unseen sample by finding the value of
    the specific feature and using the appropriate predictor. The following code does
    this for a given sample:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型是一个字典，它告诉我们应该使用哪个特征来进行我们的 *One Rule* 以及基于这些值的预测。有了这个模型，我们可以通过找到特定特征的值并使用适当的预测器来预测一个先前未见过的样本的类别。以下代码为给定样本执行此操作：
- en: '[PRE35]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Often we want to predict several new samples at one time, which we can do using
    the following function. It simply uses the above code, but iterate over all the
    samples in a dataset, obtaining the prediction for each sample:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 经常我们希望一次预测多个新样本，我们可以使用以下函数来完成。它只是简单地使用上面的代码，但遍历数据集中的所有样本，为每个样本获取预测：
- en: '[PRE36]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'For our `testing` dataset, we get the predictions by calling the following
    function:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的 `testing` 数据集，我们通过调用以下函数来获取预测：
- en: '[PRE37]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We can then compute the accuracy of this by comparing it to the known classes:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过将其与已知类别进行比较来计算这个准确率：
- en: '[PRE38]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This algorithm gives an accuracy of 65.8 percent, which is not bad for a single
    rule!
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法给出了 65.8% 的准确率，对于一个单一规则来说并不坏！
- en: Summary
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced data mining using Python. If you could run the
    code in this section (note that the full code is available in the supplied code
    package), then your computer is set up for much of the rest of the book. Other
    Python libraries will be introduced in later chapters to perform more specialized
    tasks.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了使用 Python 进行数据挖掘。如果你能运行本节中的代码（注意，完整的代码包含在提供的代码包中），那么你的计算机已经为本书的大部分内容做好了设置。其他
    Python 库将在后面的章节中介绍，以执行更专业的任务。
- en: We used the Jupyter Notebook to run our code, which allows us to immediately
    view the results of a small section of the code. Jupyter Notebook is a useful
    tool that will be used throughout the book.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Jupyter Notebook 运行我们的代码，这使得我们可以立即查看代码小段的结果。Jupyter Notebook 是一个有用的工具，将在整本书中使用。
- en: We introduced a simple affinity analysis, finding products that are purchased
    together. This type of exploratory analysis gives an insight into a business process,
    an environment, or a scenario. The information from these types of analysis can
    assist in business processes, find the next big medical breakthrough, or create
    the next artificial intelligence.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了一种简单的亲和分析，寻找一起购买的产品。这种类型的探索性分析可以深入了解业务流程、环境或场景。这些类型分析的信息可以帮助业务流程，找到下一个重大的医学突破，或者创造下一个人工智能。
- en: Also, in this chapter, there was a simple classification example using the `OneR`
    algorithm. This simple algorithm simply finds the best feature and predicts the
    class that most frequently had this value in the training dataset.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在本章中，我们使用`OneR`算法提供了一个简单的分类示例。这个简单的算法只是找到最佳特征，并预测在训练数据集中最频繁出现此值的类别。
- en: To expand on the outcomes of this chapter, think about how you would implement
    a variant of `OneR` that can take multiple feature/value pairs into consideration.
    Take a shot at implementing your new algorithm and evaluating it. Remember to
    test your algorithm on a separate dataset to the training data. Otherwise, you
    run the risk of over fitting your data.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 为了扩展本章的成果，思考一下你将如何实现一个可以同时考虑多个特征/值对的`OneR`算法变体。尝试实现你的新算法并对其进行评估。记住，要在与训练数据不同的数据集上测试你的算法。否则，你可能会面临数据过拟合的风险。
- en: Over the next few chapters, we will expand on the concepts of classification
    and affinity analysis. We will also introduce classifiers in the scikit-learn
    package and use them to do our machine learning, rather than writing the algorithms
    ourselves.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几章中，我们将扩展分类和亲和分析的概念。我们还将介绍scikit-learn包中的分类器，并使用它们来进行机器学习，而不是自己编写算法。
