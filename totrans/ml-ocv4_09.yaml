- en: Implementing a Spam Filter with Bayesian Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用贝叶斯学习实现垃圾邮件过滤器
- en: 'Before we get to grips with advanced topics, such as cluster analysis, deep
    learning, and ensemble models, let''s turn our attention to a much simpler model
    that we have overlooked so far: the Naive Bayes classifier.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨高级主题，例如聚类分析、深度学习和集成模型之前，让我们将注意力转向一个我们迄今为止尚未注意到的简单模型：朴素贝叶斯分类器。
- en: Naive Bayes classifiers have their roots in Bayesian inference, named after
    the famed statistician and philosopher Thomas Bayes (1701-1761). Bayes' theorem
    famously describes the probability of an event based on prior knowledge of conditions
    that might lead to the event. We can use Bayes' theorem to build a statistical
    model that not only can classify data but can also provide us with an estimate
    of how likely it is that our classification is correct. In our case, we can use
    Bayesian inference to dismiss an email as spam with high confidence and to determine
    the probability of a woman having breast cancer, given a positive screening test.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器的根源在于贝叶斯推理，以著名的统计学家和哲学家托马斯·贝叶斯（1701-1761）的名字命名。贝叶斯定理著名地描述了基于可能导致事件的条件先验知识的事件概率。我们可以使用贝叶斯定理构建一个统计模型，该模型不仅可以对数据进行分类，还可以为我们提供关于我们的分类是否正确的概率估计。在我们的情况下，我们可以使用贝叶斯推理以高置信度将电子邮件视为垃圾邮件，并确定在阳性筛查测试的情况下女性患有乳腺癌的概率。
- en: We have now gained enough experience with the mechanics of implementing machine
    learning methods, and so we should no longer be afraid to try and understand the
    theory behind them. Don't worry, we won't write a book on it, but we need some
    understanding of the theory to appreciate a model's inner workings. After that,
    I am sure you will find that Bayesian classifiers are easy to implement, are computationally
    efficient, and tend to perform quite well on relatively small datasets. In this
    chapter, we will understand the Naive Bayes classifier and then implement our
    first Bayesian classifier. We will then classify emails using the Naive Bayes
    classifier.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在在实现机器学习方法的机制方面已经积累了足够的经验，因此我们不应再害怕尝试并理解其背后的理论。不用担心，我们不会为此写一本书，但我们需要对理论有一些了解，以便欣赏模型的内部工作原理。之后，我相信您会发现朴素贝叶斯分类器易于实现，计算效率高，并且在相对较小的数据集上表现相当好。在本章中，我们将了解朴素贝叶斯分类器，然后实现我们的第一个贝叶斯分类器。然后，我们将使用朴素贝叶斯分类器对电子邮件进行分类。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understanding the Naive Bayes classifier
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解朴素贝叶斯分类器
- en: Implementing your first Bayesian classifier
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现您的第一个贝叶斯分类器
- en: Classifying emails using the Naive Bayes classifier
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯分类器对电子邮件进行分类
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can refer to the code for this chapter from the following link: [https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter07](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter07).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从以下链接获取本章的代码：[https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter07](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter07)。
- en: 'Here is a summary of the software and hardware requirements:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是软件和硬件要求的总结：
- en: You will need OpenCV version 4.1.x (4.1.0 or 4.1.1 will both work just fine).
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要 OpenCV 版本 4.1.x（4.1.0 或 4.1.1 都可以正常工作）。
- en: You will need Python version 3.6 (any Python version 3.x will be fine).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要 Python 3.6 版本（任何 3.x 版本的 Python 都可以）。
- en: You will need Anaconda Python 3 for installing Python and the required modules.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要 Anaconda Python 3 来安装 Python 和所需的模块。
- en: You can use any OS—macOS, Windows, and Linux-based OSes—with this book. We recommend
    you have at least 4 GB RAM in your system.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用任何操作系统——macOS、Windows 和基于 Linux 的操作系统——使用本书。我们建议您的系统至少有 4 GB 的 RAM。
- en: You don't need to have a GPU to run the code provided along with this book.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不需要 GPU 来运行本书提供的代码。
- en: Understanding Bayesian inference
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解贝叶斯推理
- en: Although Bayesian classifiers are relatively simple to implement, the theory
    behind them can be quite counter-intuitive at first, especially if you are not
    too familiar with probability theory yet. However, the beauty of Bayesian classifiers
    is that they understand the underlying data better than all of the classifiers
    we have encountered so far. For example, standard classifiers, such as the *k*-nearest
    neighbor algorithm or decision trees, might be able to tell us the target label
    of a never-before-seen data point. However, these algorithms have no concept of
    how likely it is for their predictions to be right or wrong. We call them discriminative
    models. Bayesian models, on the other hand, have an understanding of the underlying
    probability distribution that caused the data. We call them generative models
    because they don't just put labels on existing data points—they can also generate
    new data points with the same statistics.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管贝叶斯分类器相对容易实现，但它们背后的理论一开始可能相当反直觉，尤其是如果你对概率理论还不够熟悉的话。然而，贝叶斯分类器的美妙之处在于，它们比我们迄今为止遇到的所有分类器更能理解底层数据。例如，标准分类器，如*k*最近邻算法或决策树，可能能够告诉我们一个从未见过的数据点的目标标签。然而，这些算法没有概念去理解它们的预测是正确还是错误的可能性。我们称它们为判别模型。另一方面，贝叶斯模型理解了导致数据的底层概率分布。我们称它们为生成模型，因为它们不仅对现有数据点进行标记——它们还可以生成具有相同统计数据的新的数据点。
- en: If this last paragraph was a bit over your head, you might enjoy the following
    brief on probability theory. It will be important for the upcoming sections.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果最后一段让你感到有些难以理解，你可能喜欢以下关于概率理论的简要介绍。它对于接下来的章节将非常重要。
- en: Taking a short detour through probability theory
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过概率理论进行短暂的小憩
- en: 'In order to appreciate Bayes'' theorem, we need to get a hold of the following
    technical terms:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了欣赏贝叶斯定理，我们需要掌握以下技术术语：
- en: '**Random variable**: This is a variable whose value depends on chance. A good
    example is the act of flipping a coin, which might turn up heads or tails. If
    a random variable can take on only a limited number of values, we call it discrete
    (such as a coin flip or a dice roll); otherwise, we call it a continuous random
    variable (such as the temperature on a given day). Random variables are often
    typeset as capital letters.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机变量**：这是一个其值取决于偶然性的变量。一个很好的例子是抛硬币的行为，它可能显示正面或反面。如果一个随机变量只能取有限数量的值，我们称其为离散的（如抛硬币或掷骰子）；否则，我们称其为连续随机变量（如某一天的温度）。随机变量通常用大写字母表示。'
- en: '**Probability**: This is a measure of how likely it is for an event to occur.
    We denote the probability of an event, *e*, happening as *p(e)*, which must be
    a number between 0 and 1 (or between ...'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率**：这是衡量一个事件发生可能性的度量。我们用*p(e)*表示事件*e*发生的概率，它必须是一个介于0和1之间的数（或者介于...'
- en: Understanding Bayes' theorem
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解贝叶斯定理
- en: There are quite a few scenarios where it would be really good to know how likely
    it is for our classifier to make a mistake. For example, in [Chapter 5](5e1a6c2e-f10d-4599-993c-16e772b10a50.xhtml),
    *Using Decision Trees to Make a Medical Diagnosis*, we trained a decision tree
    to diagnose women with breast cancer based on some medical tests. You can imagine
    that, in this case, we would want to avoid a misdiagnosis at all costs; diagnosing
    a healthy woman with breast cancer (a false positive) would be both soul-crushing
    and lead to unnecessary, expensive medical procedures, whereas missing a woman's
    breast cancer (a false negative) might eventually cost the woman her life.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在很多情况下，知道我们的分类器出错的可能性是非常有用的。例如，在[第5章](5e1a6c2e-f10d-4599-993c-16e772b10a50.xhtml)，*使用决策树进行医疗诊断*中，我们训练了一个决策树，根据一些医学测试来诊断患有乳腺癌的女性。你可以想象，在这种情况下，我们无论如何都想避免误诊；将健康女性误诊为乳腺癌（假阳性）不仅会让人心碎，还会导致不必要的、昂贵的医疗程序，而错过女性的乳腺癌（假阴性）可能会最终导致女性失去生命。
- en: 'It''s good to know we have Bayesian models to count on. Let''s walk through
    a specific (and quite famous) example from [http://yudkowsky.net/rational/bayes](http://yudkowsky.net/rational/bayes):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 知道我们有贝叶斯模型可以依赖是件好事。让我们通过一个具体（并且相当著名）的例子来了解一下，来自[http://yudkowsky.net/rational/bayes](http://yudkowsky.net/rational/bayes)：
- en: '"1% of women at age forty who participate in routine screening have breast
    cancer. 80% of women with breast cancer will get positive mammographies. 9.6%
    of women without breast cancer will also get positive mammographies. A woman in
    this age group had a positive mammography in a routine screening. What is the
    probability that she actually has breast cancer?"'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '"40岁参加常规筛查的1%的女性患有乳腺癌。80%的乳腺癌女性会得到阳性乳腺钼靶检查结果。9.6%的没有乳腺癌的女性也会得到阳性乳腺钼靶检查结果。这个年龄组的女性在常规筛查中得到了阳性乳腺钼靶检查结果。她实际上患有乳腺癌的概率是多少？"'
- en: What do you think the answer is?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为答案是什么？
- en: Well, given that her mammography was positive, you might reason that the probability
    of her having cancer is quite high (somewhere near 80%). It seems much less likely
    that the woman would belong to 9.6% with false positives, so the real probability
    is probably somewhere between 70% and 80%.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，鉴于她的乳腺钼靶检查结果为阳性，你可能会认为她患有癌症的概率相当高（大约在80%左右）。这位女性属于9.6%的假阳性女性的可能性似乎要小得多，所以真正的概率可能在大约70%到80%之间。
- en: I'm afraid that's not correct.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我恐怕这不是正确的。
- en: 'Here''s one way to think about this problem. For the sake of simplicity, let''s
    assume we''re looking at some concrete number of patients, say 10,000\. Before
    the mammography screening, the 10,000 women can be divided into two groups:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一种思考这个问题的方法。为了简化，让我们假设我们正在观察一些具体的患者数量，比如说10,000。在乳腺钼靶检查之前，这10,000名女性可以分为两组：
- en: '**Group X**: 100 women *with* breast cancer'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**X组**：100名患有乳腺癌的女性'
- en: '**Group Y**: 9,900 women *without* breast cancer'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Y组**：9,900名没有乳腺癌的女性'
- en: 'So far, so good. If we sum up the numbers in the two groups, we get a total
    of 10,000 patients, confirming that nobody has been lost in the math. After the
    mammography screening, we can divide the 10,000 women into four groups:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切顺利。如果我们把两组的人数加起来，我们得到总共10,000名患者，这证实了在数学上没有人丢失。在乳腺钼靶检查之后，我们可以将这10,000名女性分成四个组：
- en: '**Group 1**: 80 women with breast cancer and a positive mammography'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一组**：80名患有乳腺癌且乳腺钼靶检查结果为阳性的女性'
- en: '**Group 2**: 20 women with breast cancer and a negative mammography'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第二组**：20名患有乳腺癌且乳腺钼靶检查结果为阴性的女性'
- en: '**Group 3**: Around 950 women without breast cancer and with a positive mammography'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第三组**：大约950名没有乳腺癌且乳腺钼靶检查结果为阳性的女性'
- en: '**Group 4**: Approx. 8,950 women without breast cancer and with a negative
    mammography'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第四组**：大约8,950名没有乳腺癌且乳腺钼靶检查结果为阴性的女性'
- en: From the preceding analysis, you can see that the sum of all the four groups
    is 10,000\. The sum of **Group 1** and **Group 2** (with breast cancer) corresponds
    to **Group** **X**, and the sum of **Group 3** and **Group 4** (without breast
    cancer) corresponds to **Group Y**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的分析中，你可以看到所有四个组的总和是10,000。**第一组**和**第二组**（患有乳腺癌）的总和对应于**组** **X**，而**第三组**和**第四组**（没有乳腺癌）的总和对应于**组**
    **Y**。
- en: 'This might become clearer when we draw it out:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能在我们画出来时会更清晰：
- en: '![](img/bbf90aac-09df-48e2-8fd2-5be6460eccbb.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bbf90aac-09df-48e2-8fd2-5be6460eccbb.png)'
- en: In this diagram, the top half corresponds to **Group X**, and the bottom half
    corresponds to **Group Y**. Analogously, the left half corresponds to all women
    with positive mammographies, and the right half corresponds to all women with
    negative mammographies.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图表中，上半部分对应于**X组**，下半部分对应于**Y组**。类似地，左半部分对应于所有阳性乳腺钼靶检查的女性，右半部分对应于所有阴性乳腺钼靶检查的女性。
- en: 'Now, it is easier to see that what we are looking for concerns only the left
    half of the diagram. The proportion of cancer patients with positive results within
    the group of all patients with positive results is the proportion of Group 1 within
    Groups 1 and 3:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，更容易看出我们正在寻找的只与图表的左半部分有关。在所有阳性结果患者组中，癌症患者阳性结果的比率是组1在组1和组3中的比率：
- en: '*80 / (80 + 950) = 80 / 1,030 = 7.8%*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*80 / (80 + 950) = 80 / 1,030 = 7.8%*'
- en: 'In other words, if you offer a mammography to 10,000 patients, then out of
    the 1,030 with a positive mammographies, there would be 80 patients with positive
    mammography having cancer. The answer a doctor should give a positive mammography
    patient if she asks about the chance she has breast cancer: roughly 1 out of 13
    will have cancer, given that 13 patients ask this question.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，如果你向10,000名患者提供乳腺钼靶检查，那么在1,030名阳性乳腺钼靶检查结果中，会有80名患者患有癌症。如果一位阳性乳腺钼靶检查患者询问她患乳腺癌的机会，医生应该给出的答案：在13名询问这个问题的患者中，大约有1名会患有癌症。
- en: 'What we just calculated is called a **conditional probability**: what is our
    **degree of belief** that a woman has breast cancer **under the condition** of
    (we also say **given**) a positive mammography? As in the last subsection, we
    denote this with *p(cancer|mammography)*, or *p(C|M)* for short. Using capital
    letters once again enforces the idea that both health and the mammography can
    have several outcomes, depending on several underlying (and possibly unknown)
    causes. Therefore, they are random variables.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才计算的这个被称为**条件概率**：在（我们也可以说**给定**）乳腺摄影结果为阳性的情况下，一个女性患有乳腺癌的**信念程度**是多少？正如上一个子节中所述，我们用
    *p(cancer|mammography)* 或 *p(C|M)* 来表示。再次使用大写字母是为了强调健康和乳腺摄影都可以有几种结果，这取决于几个潜在（可能未知）的原因。因此，它们是随机变量。
- en: 'Then, we can express *P(C|M)* with the following formula:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以用以下公式表示 *P(C|M)*：
- en: '![](img/b561a41b-448a-49cc-8be0-3772a3e0f27f.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b561a41b-448a-49cc-8be0-3772a3e0f27f.png)'
- en: Here, *p(C, M)* denotes the probability that both *C* and *M* are true (meaning
    the probability that a woman both has cancer and a positive mammography). This
    is equivalent to the probability of a woman belonging to Group 1, as shown earlier.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*p(C, M)* 表示 *C* 和 *M* 都为真的概率（意味着一个女性既有癌症又有阳性乳腺摄影的概率）。这相当于前面提到的属于第1组的女性概率。
- en: The comma (*,*) means logical *and*, and the tilde (*~*) stands for logical
    *not*. Hence, *p(~C, M)* denotes the probability that *C* is not true and *M*
    is true (meaning the probability that a woman does not have cancer but has a positive
    mammography). This is equivalent to the probability of a woman belonging to Group
    3\. So, the denominator basically adds up women in Group 1 (*p(C, M)*) and Group
    3 (*p(~C, M)*).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 逗号（*，*）表示逻辑**与**，波浪号（*~*）表示逻辑**非**。因此，*p(~C, M)* 表示 *C* 不为真且 *M* 为真的概率（意味着一个女性没有癌症但有阳性乳腺摄影）。这相当于属于第3组的女性概率。因此，分母基本上是第1组（*p(C,
    M)*）和第3组（*p(~C, M)*）中女性的总和。
- en: 'But wait! Those two groups together simply denote the probability of a woman
    having a positive mammography, *p(M)*. Therefore, we can simplify the preceding
    equation:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 但是等等！这两个组合在一起简单地表示一个女性有阳性乳腺摄影的概率，*p(M)*。因此，我们可以简化前面的方程：
- en: '![](img/55a3d8a8-bb02-4a6f-888c-8f322fab1880.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/55a3d8a8-bb02-4a6f-888c-8f322fab1880.png)'
- en: 'The Bayesian version is to re-interpret what *p(C, M)* means. We can express
    *p(C, M)* as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯版本是对 *p(C, M)* 的重新解释。我们可以将 *p(C, M)* 表达如下：
- en: '![](img/98a72194-6ede-4115-af51-7446f71a6a0e.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/98a72194-6ede-4115-af51-7446f71a6a0e.png)'
- en: Now it gets a bit confusing. Here, *p(C)* is simply the probability that a woman
    has cancer (corresponding to the aforementioned Group X). Given that a woman has
    cancer, what is the probability that her mammography will be positive? From the
    problem question, we know it is 80%. This is *p(M|C)*, the probability of *M* given
    *C*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有点复杂了。在这里，*p(C)* 只是女性患有癌症的概率（对应于前面提到的组X）。考虑到一个女性患有癌症，她的乳腺摄影结果为阳性的概率是多少？从问题中我们知道是80%。这是
    *p(M|C)*，即在 *C* 的条件下 *M* 的概率。
- en: 'Replacing *p(C, M)* in the first equation with this new formula, we get the
    following equation:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 将第一个方程中的 *p(C, M)* 用这个新公式替换，我们得到以下方程：
- en: '![](img/fc3c16dd-2798-44e8-976d-6a474464d8ac.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc3c16dd-2798-44e8-976d-6a474464d8ac.png)'
- en: 'In the Bayesian world, these terms all have their specific names:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在贝叶斯世界中，这些术语都有它们特定的名称：
- en: '*p(C|M)* is called the **posterior**, which is always the thing we want to
    compute. In our example, this corresponds to the degree of belief that a woman
    has breast cancer, given a positive mammography.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p(C|M)* 被称为**后验**，这是我们总是想要计算的东西。在我们的例子中，这对应于在乳腺摄影结果为阳性时，一个女性患有乳腺癌的信念程度。'
- en: '*p(C)* is called the **prior** as it corresponds to our initial knowledge about
    how common breast cancer is. We also call this our initial degree of belief in
    *C*.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p(C)* 被称为**先验**，因为它对应于我们对乳腺癌有多普遍的初始知识。我们也将这称为我们对 *C* 的初始信念程度。'
- en: '*p(M|C)* is called the **likelihood**.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p(M|C)* 被称为**似然**。'
- en: '*p(M)* is called **evidence**.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p(M)* 被称为**证据**。'
- en: 'So, you can rewrite the equation one more time, as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以再次重写方程，如下所示：
- en: '![](img/bf3d09c1-5036-4405-b41b-2fab3f42f49e.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf3d09c1-5036-4405-b41b-2fab3f42f49e.png)'
- en: Mostly, there is interest only in the numerator of that fraction because the
    denominator does not depend on *C,* so the denominator is constant and can be
    neglected.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，人们只对那个分数的分子感兴趣，因为分母不依赖于 *C*，所以分母是常数，可以忽略不计。
- en: Understanding the Naive Bayes classifier
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解朴素贝叶斯分类器
- en: 'So far, we have only talked about one piece of evidence. However, in most real-world
    scenarios, we have to predict an outcome (such as a random variable, *Y*) given
    multiple pieces of evidence (such as random variables *X[1]* and *X[2]*). So,
    instead of calculating *p(Y|X),* we would often have to calculate *p(Y|X[1], X[2],
    ..., X[n])*. Unfortunately, this makes the math very complicated. For two random
    variables, *X[1]* and *X[2]*, the joint probability would be computed like this:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了一个证据。然而，在大多数实际场景中，我们必须在给定多个证据（例如随机变量 *X[1]* 和 *X[2]*）的情况下预测一个结果（例如随机变量
    *Y*）。因此，我们通常需要计算 *p(Y|X[1], X[2], ..., X[n])*，而不是计算 *p(Y|X)*。不幸的是，这使得数学变得非常复杂。对于两个随机变量
    *X[1]* 和 *X[2]*，联合概率可以这样计算：
- en: '![](img/5e0699f8-d90a-44d6-930a-678af88be987.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5e0699f8-d90a-44d6-930a-678af88be987.png)'
- en: The ugly part is the term *p(X[1]|X[2], C)*, which says that the conditional
    probability of *X[1]* depends on all other variables, including *C*. This gets
    even ...
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 丑陋的部分是术语 *p(X[1]|X[2], C)*，它表示 *X[1]* 的条件概率依赖于所有其他变量，包括 *C*。这甚至 ...
- en: Implementing your first Bayesian classifier
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现你的第一个贝叶斯分类器
- en: But enough with the math, let's do some coding!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 但数学就到这里吧，让我们来做一些编码！
- en: In the previous chapter, we learned how to generate a number of Gaussian blobs
    using scikit-learn. Do you remember how that is done?
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用 scikit-learn 生成多个高斯云团。你还记得是如何做到这一点的吗？
- en: Creating a toy dataset
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个玩具数据集
- en: 'The function I''m referring to resides within scikit-learn''s `datasets` module.
    Let''s create 100 data points, each belonging to one of two possible classes,
    and group them into two Gaussian blobs. To make the experiment reproducible, we
    specify an integer to pick a seed for `random_state`. You can again pick whatever
    number you prefer. Here, I went with Thomas Bayes'' year of birth (just for kicks):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我所指的是 scikit-learn 的 `datasets` 模块中的函数。让我们创建 100 个数据点，每个数据点属于两个可能类别中的一个，并将它们分组成两个高斯云团。为了使实验可重复，我们指定一个整数来选择
    `random_state` 的种子。你可以选择你喜欢的任何数字。在这里，我选择了托马斯·贝叶斯出生的那一年（只是为了好玩）：
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s have a look at the dataset we just created using our trusty friend,
    Matplotlib:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用我们忠实的朋友 Matplotlib 查看我们刚刚创建的数据集：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Classifying the data with a normal Bayes classifier
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用正态贝叶斯分类器对数据进行分类
- en: We will then use the same procedure as in earlier chapters to train a **normal
    Bayes classifier**. Wait, why not a Naive Bayes classifier? Well, it turns out
    OpenCV doesn't really provide a true Naive Bayes classifier. Instead, it comes
    with a Bayesian classifier that doesn't necessarily expect features to be independent,
    but rather expects the data to be clustered into Gaussian blobs. This is exactly the
    kind of dataset we created earlier!
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与早期章节中相同的程序来训练一个 **正态贝叶斯分类器**。等等，为什么不使用朴素贝叶斯分类器呢？好吧，结果是 OpenCV 并没有真正提供朴素贝叶斯分类器。相反，它提供了一个贝叶斯分类器，这个分类器并不一定期望特征是独立的，而是期望数据被聚类成高斯云团。这正是我们之前创建的数据集类型！
- en: 'By following these steps, you will learn how to build a classifier with a normal
    Bayes classifier:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这些步骤，你将学习如何使用正态贝叶斯分类器构建一个分类器：
- en: 'We can create a new classifier using the following function:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用以下函数创建一个新的分类器：
- en: '[PRE2]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, training is done via the `train` method:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过 `train` 方法进行训练：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once the classifier has been trained successfully, it will return `True`. We
    go through the motions of predicting and scoring the classifier, just like we
    have done a million times before:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦分类器成功训练，它将返回 `True`。我们像以前成千上万次做的那样，进行预测和评分分类器：
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Even better—we can reuse the plotting function from the last chapter to inspect
    the decision boundary! If you recall, the idea was to create a mesh grid that
    would encompass all data points and then classify every point on the grid. The
    mesh grid is created via the NumPy function of the same name:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更好——我们可以重用上一章中的绘图函数来检查决策边界！如果你还记得，想法是创建一个网格，它将包含所有数据点，然后对网格上的每个点进行分类。网格是通过具有相同名称的
    NumPy 函数创建的：
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `meshgrid` function will return two floating-point matrices, `xx` and `yy`,
    that contain the *x* and *y* coordinates of every coordinate point on the grid.
    We can flatten these matrices into column vectors using the `ravel` function and
    stack them to form a new matrix, `X_hypo`:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`meshgrid` 函数将返回两个浮点矩阵，`xx` 和 `yy`，它们包含网格上每个坐标点的 *x* 和 *y* 坐标。我们可以使用 `ravel`
    函数将这些矩阵展平成列向量，并将它们堆叠起来形成一个新矩阵，`X_hypo`：'
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`X_hypo` now contains all *x* values in `X_hypo[:, 0]` and all *y* values in
    `X_hypo[:, 1]`. This is a format that the `predict` function can understand:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`X_hypo` 现在包含 `X_hypo[:, 0]` 中的所有 *x* 值和 `X_hypo[:, 1]` 中的所有 *y* 值。这是 `predict`
    函数可以理解的格式：'
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'However, we want to be able to use models from both OpenCV and scikit-learn.
    The difference between the two is that OpenCV returns multiple variables (a Boolean
    flag indicating success/failure and the predicted target labels), whereas scikit-learn
    returns only the predicted target labels. Hence, we can check whether the `ret`
    output is a tuple, in which case, we know we''re dealing with OpenCV. In this
    case, we store the second element of the tuple (`ret[1]`). Otherwise, we are dealing
    with scikit-learn and don''t need to index into `ret`:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然而，我们希望能够使用来自 OpenCV 和 scikit-learn 的模型。这两个之间的区别在于 OpenCV 返回多个变量（一个表示成功/失败的布尔标志和预测的目标标签），而
    scikit-learn 只返回预测的目标标签。因此，我们可以检查 `ret` 输出是否是一个元组，如果是，我们知道我们正在处理 OpenCV。在这种情况下，我们存储元组的第二个元素（`ret[1]`）。否则，我们正在处理
    scikit-learn，并且不需要索引到 `ret`：
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'All that''s left to do is to create a contour plot where `zz` indicates the
    color of every point on the grid. On top of that, we plot the data points using
    our trusty scatter plot:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 剩下的工作就是创建一个等高线图，其中 `zz` 表示网格上每个点的颜色。在此基础上，我们使用我们信任的散点图来绘制数据点：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We call the function by passing a model (`model_norm`), a feature matrix (`X`),
    and a target label vector (`y`):'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过传递一个模型（`model_norm`）、一个特征矩阵（`X`）和一个目标标签向量（`y`）来调用该函数：
- en: '[PRE10]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output looks like this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 输出看起来像这样：
- en: '![](img/67d6aaae-c7d9-4b3f-ae04-df35a7fbd1cf.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/67d6aaae-c7d9-4b3f-ae04-df35a7fbd1cf.png)'
- en: 'So far, so good. The interesting part is that a Bayesian classifier also returns
    the probability with which each data point has been classified:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切顺利。有趣的部分是，贝叶斯分类器还返回每个数据点被分类的概率：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The function returns a Boolean flag (`True` for success and `False` for failure),
    the predicted target labels (`y_pred`), and the conditional probabilities (`y_proba`).
    Here, `y_proba` is an *N x* 2 matrix that indicates, for every one of the *N*
    data points, the probability with which it was classified as either class 0 or
    class 1:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数返回一个布尔标志（成功时为`True`，失败时为`False`），预测的目标标签（`y_pred`）和条件概率（`y_proba`）。在这里，`y_proba`是一个
    *N x* 2 矩阵，它表示对于 *N* 个数据点中的每一个，它被分类为类别 0 或类别 1 的概率：
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This means that, for the first data point (top row), the probability of it belonging
    to class 0 (that is, *p(C[0]|X)*) is 0.15 (or 15%)). Similarly, the probability
    of belonging to class 1 is *p(C[1]|X)* = *0.05.*
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，对于第一个数据点（顶部行），属于类别 0 的概率（即 *p(C[0]|X)*）是 0.15（或 15%）。同样，属于类别 1 的概率是 *p(C[1]|X)*
    = *0.05*。
- en: The reason why some of the rows show values greater than 1 is that OpenCV does
    not really return probability values. Probability values are always between 0
    and 1, and each row in the preceding matrix should add up to 1\. Instead, what
    is being reported is a **likelihood**, which is basically the numerator of the
    conditional probability equation, *p(C)* *p(M|C)*. The denominator, *p*(*M*),
    does not need to be computed. All we need to know is that *0.15 > 0.05* (top row).
    Hence, the data point most likely belongs to class 0.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一些行显示的值大于 1 的原因是 OpenCV 并不真正返回概率值。概率值总是在 0 和 1 之间，并且前面矩阵中的每一行都应该加起来等于 1。相反，报告的是
    **似然性**，这基本上是条件概率方程的分子，*p(C)* *p(M|C)*。分母 *p*(*M*) 不需要计算。我们只需要知道 *0.15 > 0.05*（顶部行）。因此，数据点最有可能属于类别
    0。
- en: Classifying the data with a Naive Bayes classifier
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯分类器对数据进行分类
- en: 'The following steps will help you build a Naive Bayes classifier:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助您构建一个朴素贝叶斯分类器：
- en: 'We can compare the result to a true Naive Bayes classifier by asking scikit-learn
    for help:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过向 scikit-learn 求助来将结果与真正的朴素贝叶斯分类器进行比较：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As usual, training the classifier is done via the `fit` method:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通常，通过 `fit` 方法进行分类器的训练：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Scoring the classifier is built in:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类器的评分是内置的：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Again a perfect score! However, in contrast to OpenCV, this classifier''s `predict_proba`
    method returns true probability values, because all values are between 0 and 1
    and because all rows add up to 1:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次获得完美分数！然而，与 OpenCV 相比，这个分类器的 `predict_proba` 方法返回的是真正的概率值，因为所有值都在 0 和 1 之间，并且所有行加起来等于
    1：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Visualizing conditional probabilities
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化条件概率
- en: 'By referring to the following steps, you will be able to visualize conditional
    probabilities:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 通过参考以下步骤，您将能够可视化条件概率：
- en: 'For this, we will slightly modify the plot function from the previous example.
    We start out by creating a mesh grid between (`x_min`, `x_max`) and (`y_min`,
    `y_max`):'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将对前一个示例中的绘图函数进行轻微修改。我们首先在 (`x_min`，`x_max`) 和 (`y_min`，`y_max`) 之间创建一个网格图：
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Then, we flatten `xx` and `yy` and add them column-wise to the feature matrix, `X_hypo`:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将 `xx` 和 `yy` 展平，并将它们按列添加到特征矩阵 `X_hypo` 中：
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If we want to make this function work with both OpenCV and scikit-learn, we
    need to implement a switch for `predictProb` (in the case of OpenCV) and `predict_proba`
    (in the case of scikit-learn). For this, we check whether `model` has a method
    called `predictProb`. If the method exists, we can call it; otherwise, we assume
    we''re dealing with a model from scikit-learn:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想让这个函数同时与 OpenCV 和 scikit-learn 一起工作，我们需要为 `predictProb`（在 OpenCV 的情况下）和
    `predict_proba`（在 scikit-learn 的情况下）实现一个开关。为此，我们检查 `model` 是否有一个名为 `predictProb`
    的方法。如果该方法存在，我们可以调用它；否则，我们假设我们正在处理来自 scikit-learn 的模型：
- en: '[PRE19]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Like in `In [16]`, which we saw earlier, `y_proba` will be a 2D matrix containing,
    for each data point, the probability of the data belonging to class 0 (in `y_proba[:,
    0]`) and to class 1 (in `y_proba[:, 1]`). An easy way to convert these two values
    into a color that the contour function can understand is to simply take the difference
    of the two probability values:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如同在 `In [16]` 中我们所看到的，`y_proba` 将是一个二维矩阵，对于每个数据点，它包含数据属于类别 0（在 `y_proba[:, 0]`
    中）和类别 1（在 `y_proba[:, 1]` 中）的概率。将这些两个值转换为 contour 函数可以理解的颜色的简单方法就是简单地取这两个概率值的差：
- en: '[PRE20]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The last step is to plot `X_test` as a scatter plot on top of the colored mesh
    grid:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是将 `X_test` 作为散点图绘制在彩色网格图之上：
- en: '[PRE21]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we are ready to call the function:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好调用该函数：
- en: '[PRE22]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The result looks like this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来像这样：
- en: '![](img/9cb91905-247c-46b9-a208-fadaf2df1d9d.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9cb91905-247c-46b9-a208-fadaf2df1d9d.png)'
- en: The preceding screenshot shows conditional probabilities of a Naive Bayes classifier.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张截图显示了朴素贝叶斯分类器的条件概率。
- en: Classifying emails using the Naive Bayes classifier
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯分类器对电子邮件进行分类
- en: The final task of this chapter will be to apply our newly gained skills to a
    real spam filter! This task deals with solving a binary-class (spam/ham) classification
    problem using the Naive Bayes algorithm.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最终任务将是将我们新获得的知识应用到实际的垃圾邮件过滤器中！这个任务涉及使用朴素贝叶斯算法解决二元分类（垃圾邮件/ham）分类问题。
- en: Naive Bayes classifiers are actually a very popular model for email filtering.
    Their naivety lends itself nicely to the analysis of text data, where each feature
    is a word (or a **bag of words**), and it would not be feasible to model the dependence
    of every word on every other word.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器实际上是电子邮件过滤中一个非常流行的模型。它们的朴素性非常适合文本数据的分析，其中每个特征都是一个单词（或一个 **词袋**），并且不可能对每个单词与其他每个单词的依赖关系进行建模。
- en: 'There are a bunch of good email datasets out there, such as the following:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有大量好的电子邮件数据集，例如以下这些：
- en: 'The Hewlett-Packard spam database: [https://archive.ics.uci.edu/ml/machine-learning-databases/spambase](https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'The Hewlett-Packard spam database: [https://archive.ics.uci.edu/ml/machine-learning-databases/spambase](https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/)'
- en: 'The Enrom-Spam dataset: [http://www.aueb.gr/users/ion/data/enron-spam ...](http://www.aueb.gr/users/ion/data/enron-spam)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Enrom-Spam 数据集：[http://www.aueb.gr/users/ion/data/enron-spam ...](http://www.aueb.gr/users/ion/data/enron-spam)
- en: Loading the dataset
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据集
- en: 'You can refer to these steps to load the dataset:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考以下步骤来加载数据集：
- en: If you downloaded the latest code from GitHub, you will find several `.zip`
    files in the `notebooks/data/chapter7` directory. These files contain raw email
    data (with fields for To:, Cc:, and text body) that are either classified as spam
    (with the `SPAM = 1` class label) or not (also known as ham, the `HAM = 0` class
    label).
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '如果你从 GitHub 下载了最新代码，你将在 `notebooks/data/chapter7` 目录下找到几个 `.zip` 文件。这些文件包含原始电子邮件数据（包含
    To:、Cc: 和正文字段），这些数据要么被分类为垃圾邮件（带有 `SPAM = 1` 类别标签），要么不是（也称为 ham，`HAM = 0` 类别标签）。'
- en: 'We build a variable called `sources`, which contains all of the raw data files:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个名为 `sources` 的变量，它包含所有原始数据文件：
- en: '[PRE23]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The first step is to extract these files into subdirectories. For this, we
    can use the `extract_tar` function we wrote in the previous chapter:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是从子目录中提取这些文件。为此，我们可以使用我们在上一章中编写的 `extract_tar` 函数：
- en: '[PRE24]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'To apply the function to all data files in the sources, we need to run a loop.
    The `extract_tar` function expects a path to the `.tar.gz` file—which we build
    from `datadir` and an entry in `sources`—and a directory to extract the files
    to (`datadir`). This will extract all emails in, for example, `data/chapter7/beck-s.tar.gz`
    to the `data/chapter7/beck-s/` subdirectory:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了将函数应用于源中的所有数据文件，我们需要运行一个循环。`extract_tar`函数期望一个指向`.tar.gz`文件的路径——我们通过`datadir`和一个`sources`中的条目构建它——以及一个提取文件的目录（`datadir`）。这将把例如`data/chapter7/beck-s.tar.gz`中的所有电子邮件提取到`data/chapter7/beck-s/`子目录中：
- en: '[PRE25]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now here''s the tricky bit. Every one of these subdirectories contains many
    other directories, wherein the text files reside. So, we need to write two functions:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是有点棘手的部分。这些子目录中的每一个都包含许多其他目录，其中包含文本文件。因此，我们需要编写两个函数：
- en: '`read_single_file(filename)`: This is a function that extracts the relevant
    content from a single file called `filename`.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`read_single_file(filename)`：这是一个从名为`filename`的单个文件中提取相关内容的函数。'
- en: '`read_files(path)`: This is a function that extracts the relevant content from
    all files in a particular directory called `path`.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`read_files(path)`：这是一个从名为`path`的特定目录中的所有文件中提取相关内容的函数。'
- en: 'To extract the relevant content from a single file, we need to be aware of
    how each file is structured. The only thing we know is that the header section
    of the email (From:, To:, and Cc:) and the main body of text are separated by
    a newline character, `''\n''`. So, what we can do is iterate over every line in
    the text file and keep only those lines that belong to the main text body, which
    will be stored in the variable lines. We also want to keep a Boolean flag, `past_header`,
    around, which is initially set to `False` but will be flipped to `True` once we
    are past the header section:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从单个文件中提取相关内容，我们需要了解每个文件的结构。我们知道的唯一事情是电子邮件的标题部分（From:, To:, 和 Cc:）和正文文本通过换行符`'\n'`分隔。因此，我们可以遍历文本文件中的每一行，只保留属于正文文本的行，这些行将被存储在变量`lines`中。我们还想保留一个布尔标志`past_header`，它最初被设置为`False`，但一旦我们通过了标题部分，它将被切换到`True`：
- en: 'We start by initializing those two variables:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先初始化这两个变量：
- en: '[PRE26]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then, we check whether a file with the name `filename` exists. If it does,
    we start looping over it line by line:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们检查名为`filename`的文件是否存在。如果存在，我们开始逐行遍历它：
- en: '[PRE27]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: You may have noticed the `encoding="latin-1"` part. Since some of the emails
    are not in Unicode, this is an attempt to decode the files correctly.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到了`encoding="latin-1"`部分。由于一些电子邮件不是Unicode，这是尝试正确解码文件的一种尝试。
- en: We do not want to keep the header information, so we keep looping until we encounter
    the `'\n'` character, at which point we flip `past_header` from `False` to `True`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不想保留标题信息，因此我们持续循环，直到遇到`'\n'`字符，此时我们将`past_header`从`False`切换到`True`。
- en: 'At this point, the first condition of the following `if-else` clause is met,
    and we append all remaining lines in the text file to the `lines` variable:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一点上，以下`if-else`语句的第一个条件得到满足，我们将文本文件中剩余的所有行追加到`lines`变量中：
- en: '[PRE28]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In the end, we concatenate all lines into a single string, separated by the
    newline character, and return both the full path to the file and the actual content
    of the file:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将所有行连接成一个单独的字符串，由换行符分隔，并返回文件的完整路径和实际内容：
- en: '[PRE29]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The job of the second function will be to loop over all files in a folder and
    call `read_single_file` on them:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个函数的任务将是遍历文件夹中的所有文件并对它们调用`read_single_file`：
- en: '[PRE30]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Here, `yield` is a keyword that is similar to `return`. The difference is that
    `yield` returns a generator instead of the actual values, which is desirable if
    you expect to have a large number of items to iterate over.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`yield`是一个与`return`类似的关键字。区别在于`yield`返回一个生成器而不是实际值，如果你预期要遍历大量项目，这是所希望的。
- en: Building a data matrix using pandas
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pandas构建数据矩阵
- en: 'Now, it''s time to introduce another essential data science tool that comes
    preinstalled with Python Anaconda: **pandas**. pandas is built on NumPy and provides
    several useful tools and methods to deal with data structures in Python. Just
    as we generally import NumPy under the alias, `np`, it is common to import pandas
    under the `pd` alias:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候介绍另一个Python Anaconda预安装的必要数据科学工具了：**pandas**。pandas建立在NumPy之上，并为Python中的数据结构提供了几个有用的工具和方法。就像我们通常使用别名`np`导入NumPy一样，通常使用别名`pd`导入pandas：
- en: '[PRE31]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'pandas provide a useful data structure called a DataFrame, which can be understood
    as a generalization of a 2D NumPy array, as shown here:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: pandas提供了一个有用的数据结构，称为DataFrame，它可以理解为2D NumPy数组的推广，如下所示：
- en: '[PRE32]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Preprocessing the data
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: 'Scikit-learn offers several options when it comes to encoding text features,
    which we discussed in [Chapter 4](142fec63-a847-4cde-9de9-c34805d2bb84.xhtml),
    *Representing Data and Engineering Features*. One of the simplest methods of encoding
    text data, as you may recall, is by **word count**; for each phrase, you count
    the number of occurrences of each word within it. In scikit-learn, this is easily
    done using `CountVectorizer`:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn在编码文本特征方面提供了几个选项，我们在[第4章](142fec63-a847-4cde-9de9-c34805d2bb84.xhtml)，“表示数据和特征工程”中讨论了这些选项。如您所回忆的，编码文本数据的最简单方法之一是通过**词频**；对于每个短语，您计算其中每个单词出现的次数。在scikit-learn中，这可以通过使用`CountVectorizer`轻松完成：
- en: '[PRE33]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The result is a giant matrix, which tells us that we harvested a total of 52,076
    emails that collectively contain 643,270 different words. However, scikit-learn
    is smart and saved the data in a sparse matrix:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个巨大的矩阵，它告诉我们我们总共收集了52,076封电子邮件，这些电子邮件总共包含643,270个不同的单词。然而，scikit-learn很聪明，它将数据保存为稀疏矩阵：
- en: '[PRE34]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To build the vector of target labels (`y`), we need to access data in the pandas
    DataFrame. This can be done by treating the DataFrame like a dictionary, where
    the `values` attribute will give us access to the underlying NumPy array:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建目标标签向量（`y`），我们需要访问pandas DataFrame中的数据。这可以通过将DataFrame视为一个字典来完成，其中`values`属性将使我们能够访问底层的NumPy数组：
- en: '[PRE35]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Training a normal Bayes classifier
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练普通贝叶斯分类器
- en: 'From here on out, things are (almost) like they always were. We can use scikit-learn
    to split the data into training and test sets (let''s reserve 20% of all data
    points for testing):'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，事情（几乎）就像以前一样。我们可以使用scikit-learn将数据分为训练集和测试集（让我们保留所有数据点的20%用于测试）：
- en: '[PRE36]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We can instantiate a new normal Bayes classifier with OpenCV:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用OpenCV实例化一个新的普通贝叶斯分类器：
- en: '[PRE37]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: However, OpenCV does not know about sparse matrices (at least its Python interface
    does not). If we were to pass `X_train` and `y_train` to the `train` function
    as we did earlier, OpenCV would complain that the data matrix is not a NumPy array.
    ...
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，OpenCV不知道稀疏矩阵（至少它的Python接口不知道）。如果我们像之前一样将`X_train`和`y_train`传递给`train`函数，OpenCV会抱怨数据矩阵不是一个NumPy数组。
    ... '
- en: Training on the full dataset
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在完整数据集上训练
- en: 'However, if you want to classify the full dataset, we need a more sophisticated
    approach. We turn to scikit-learn''s Naive Bayes classifier, as it understands
    how to handle sparse matrices. In fact, if you didn''t pay attention and treated
    `X_train` like every NumPy array before, you might not even notice that anything
    is different:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您想对整个数据集进行分类，我们需要一个更复杂的方法。我们转向scikit-learn的朴素贝叶斯分类器，因为它理解如何处理稀疏矩阵。事实上，如果您没有注意，并将`X_train`像之前的每个NumPy数组一样对待，您可能甚至都没有注意到有任何不同：
- en: '[PRE38]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Here, we used `MultinomialNB` from the `naive_bayes` module, which is the version
    of Naive Bayes classifier that is best suited to handling categorical data, such
    as word counts.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了来自`naive_bayes`模块的`MultinomialNB`，这是最适合处理分类数据（如词频）的朴素贝叶斯分类器版本。
- en: 'The classifier is trained almost instantly and returns the scores for both
    the training and test sets:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器几乎立即训练完成，并返回训练集和测试集的分数：
- en: '[PRE39]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'And there we have it: 94.4% accuracy on the test set! Pretty good for not doing
    much other than using the default values, isn''t it?'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，这就是了：测试集上的准确率达到了94.4%！对于没有做太多其他事情（除了使用默认值）来说，这已经相当不错了，不是吗？
- en: However, what if we were super critical of our own work and wanted to improve
    the result even further? There are a couple of things we could do.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们对自己的工作非常挑剔，并希望进一步提高结果，我们可以做几件事情。
- en: Using n-grams to improve the result
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用n-gram来提高结果
- en: 'One thing to do is to use *n*-gram counts instead of plain word counts. So
    far, we have relied on what is known as a bag of words: we simply threw every
    word of an email into a bag and counted the number of its occurrences. However,
    in real emails, the order in which words appear can carry a great deal of information!'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一件事情是使用*n*-gram计数而不是简单的词频。到目前为止，我们依赖于所谓的词袋模型：我们只是将电子邮件中的每个单词扔进一个袋子，并计算其出现的次数。然而，在真实的电子邮件中，单词出现的顺序可以携带大量信息！
- en: 'This is exactly what *n*-gram counts are trying to convey. You can think of
    an *n*-gram as a phrase that is *n* words long. For example, the phrase *Statistics
    has its moments* contains the following 1-grams: *Statistics*, *has*, *its*, and
    *moments*. It also has the following 2-grams: *Statistics has*, *has its*, and
    *its moments*. It also has two 3-grams (*Statistics has its* and *has its moments*)
    and only a single ...'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是*n*-gram计数试图传达的内容。你可以将*n*-gram想象成一个由*n*个单词组成的短语。例如，短语*Statistics has its
    moments*包含了以下1-gram：*Statistics*，*has*，*its*和*moments*。它还包含了以下2-gram：*Statistics
    has*，*has its*和*its moments*。它还有两个3-gram（*Statistics has its*和*has its moments*）以及仅有一个...
