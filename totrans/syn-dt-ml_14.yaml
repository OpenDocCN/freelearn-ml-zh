- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Synthetic-to-Real Domain Adaptation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduces you to a well-known issue that usually limits the usability
    of synthetic data, called the domain gap problem. In this chapter, you will learn
    various approaches to bridge this gap, which will help you to better leverage
    synthetic data. At the same time, the chapter discusses current state-of-the-art
    research on synthetic-to-real domain adaptation. Thus, you will learn which methods
    you may use for your own problems. Then, it represents the challenges and issues
    in this context to better comprehend the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The domain gap problem in ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaches for synthetic-to-real domain adaptation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthetic-to-real domain adaptation – issues and challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The domain gap problem in ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will understand what the domain gap is and why it is a
    problem in ML. The domain gap is one of the main issues that limit the usability
    of synthetic data in practice. It usually refers to the dissimilarity between
    the distributions and properties of data in two or more domains. It is not just
    associated with synthetic data. However, it is a common problem in ML. It is very
    common to notice a degradation in the performance of ML models when tested on
    similar but slightly different datasets. For more information, please refer to
    *Who is closer: A computational method for domain gap* *evaluation* ([https://doi.org/10.1016/j.patcog.2021.108293](https://doi.org/10.1016/j.patcog.2021.108293)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main reasons for the domain gap between datasets can be linked to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Sensitivity to sensors’ variations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discrepancy in class and feature distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concept drift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s discuss each of these points in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Sensitivity to sensors’ variations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In computer vision, your ML model may perform well on images captured using
    certain cameras, setups, and parameters but drastically fail under similar inputs
    captured with different cameras or using different parameters. For instance, your
    computer vision model may work well on videos captured from a first-person view
    but drastically fail on videos captured from a third-person view. Therefore, we
    can see that even the same task, such as action recognition, is usually studied
    with an emphasis on the person’s viewpoint, as in *First-person Activity Recognition
    by Modelling Subject-Action Relevance* ([https://doi.org/10.1109/IJCNN55064.2022.9892547](https://doi.org/10.1109/IJCNN55064.2022.9892547)).
    Another example is the camera’s **Field of View** (**FoV**). Some computer vision
    tasks, such as semantic segmentation, are also studied under certain camera FoVs.
    A semantic segmentation method trained on the Cityscapes and Synscapes datasets,
    which are captured under a standard FoV, will fail at segmenting fisheye images
    captured by a super-wide fisheye lens. For an example, please refer to *FPDM:
    Fisheye Panoptic segmentation dataset for Door* *Monitoring* ([https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9959151](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9959151)).'
  prefs: []
  type: TYPE_NORMAL
- en: Discrepancy in class and feature distributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Discrepancy or inconsistency in the distribution of attributes, classes, and
    features is one of the main reasons for the domain gap between synthetic and real
    domains or even in the same real domain when you train and test on different datasets.
    This can be clearly observed when working on time series-based problems. Many
    times, the training data becomes outdated and does not come from the same distribution
    as the test or evaluation data. For example, an ML model trained to predict inflation
    rates based on data collected one year ago may not perform well once applied to
    current data because of the domain gap problem. This is because the source and
    target data distributions and characteristics are now different from expected.
  prefs: []
  type: TYPE_NORMAL
- en: Concept drift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Concept drift refers to the change in the relation between the input (features)
    and output (target). Let’s take an illustrative example. Assume we have designed
    an object classifier and the “printer” is one of our objects of interest. As you
    can see in *Figure 14**.1*, the shape, color, appearance, and other features of
    the “printer” concept have drastically changed over time, from early typewriters,
    to inkjet printers, to laser printers. Thus, if your training data contained only
    old printers (typewriters), it would simply struggle to accurately classify modern
    printers because of the domain gap problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – An example of concept drift (source: Pixabay)](img/B18494_14_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.1 – An example of concept drift (source: Pixabay)'
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s explore the main solutions to mitigate the domain gap problem specifically
    between synthetic and real domains.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches for synthetic-to-real domain adaptation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, you will learn the key approaches for synthetic-to-real domain
    adaptation. We will discuss the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: Domain randomization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adversarial domain adaptation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature-based domain adaptation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start with one of the most commonly used approaches for domain adaptation.
  prefs: []
  type: TYPE_NORMAL
- en: Domain randomization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Domain randomization** is a mechanism or procedure usually used to mitigate
    the domain gap problem and improve the performance of ML models on the target
    domain. This approach aims at randomizing the main properties and attributes of
    the training data or environment, such as simulators to increase the diversity
    of the scenarios the ML model is exposed to in the training stage. Thus, we can
    increase the robustness of the ML model for scenarios that it may encounter in
    the future. For more information, please refer to *Domain Randomization for Transferring
    Deep Neural Networks from Simulation to the Real* *World* ([https://arxiv.org/pdf/1703.06907.pdf](https://arxiv.org/pdf/1703.06907.pdf)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s examine the main elements that are usually randomized in two interesting
    fields: computer vision and NLP.'
  prefs: []
  type: TYPE_NORMAL
- en: Computer vision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In almost any computer vision problem, task, or system, we have the following
    four main elements, as shown in *Figure 14**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.2 – Main elements to randomize in computer vision](img/B18494_14_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.2 – Main elements to randomize in computer vision
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s discuss each of these elements in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: '**Objects**: They are usually the primary focus of computer vision. They populate
    the scene and interact with each other, the lighting, and the environment. Many
    major tasks in computer vision, such as object detection, recognition, segmentation,
    and tracking, are fundamentally related to the appearance of these images in the
    3D world and how the world is projected by camera as 2D images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Utilizing domain randomization to mitigate the domain gap, we can, for instance,
    randomize the following elements to diversify the object’s appearance:'
  prefs: []
  type: TYPE_NORMAL
- en: Textures and materials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Colors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shapes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dimensions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deformation and animation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, deciding which factors are more relevant depends on the task
    and the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '**Lighting**: Although lighting is necessary to make the objects visible to
    the observer, it creates a daunting problem for almost all computer vision tasks.
    A slight variation in lighting conditions drastically changes the appearance of
    objects, thus changing the pixels’ intensity, which makes these objects rather
    hard for ML-based computer vision models to recognize, detect, or track.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thus, to make our ML model robust under various lighting conditions, we may
    need to diversify the following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: Lighting intensity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lighting color and temperature
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Light sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lighting anomalies: flares, glares, and flickering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Camera and sensor characteristics**: A camera captures visual data from the
    scene, which is the most generic and conventional input for computer vision models.
    Thus, to ensure that our ML model generalizes well even under new camera setups,
    we need to diversify, for instance, the camera setups in the training stage. This
    can be done by varying the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Camera position
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Orientation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Altitude
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewpoints
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Aperture, exposure, and focus
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, a change in camera parameters such as focal length may also drastically
    change how the world is captured and perceived. Thus, it will directly affect
    how the computer vision system recognizes the world, too. Therefore, we may need
    to consider the following sensor characteristic variations in our training data:'
  prefs: []
  type: TYPE_NORMAL
- en: Lens distortion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vignetting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chromatic aberration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scratches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Haze
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Light leakage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Environmental factors**: Even when the scene, lighting, and camera parameters
    are the same, environmental factors can substantially change how the scene may
    look. For example, a weather condition such as fog works as a low-pass filter
    that removes details of objects that are far from the camera. Thus, it makes extracting
    robust features for these scenarios harder. Consequently, many ML models may fail
    or struggle in similar cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In many situations, we cannot clearly identify the environmental factors our
    computer vision system will work under, therefore we may need to randomize the
    following factors:'
  prefs: []
  type: TYPE_NORMAL
- en: Weather conditions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time of day
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indoor and outdoor environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pollution level
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wind effects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Terrain and landscapes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Road conditions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Crowd density
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Background clutter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geographical locations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, and based on what we have learned in this section, to mitigate the
    domain gap between source (training) and target (evaluation) domains, we need
    to diversify and randomize the scenarios that our ML model will learn during training.
    Next, let’s delve into utilizing domain randomization for NLP problems.
  prefs: []
  type: TYPE_NORMAL
- en: NLP
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Similar to what we discussed in computer vision, domain randomization can also
    be utilized for NLP problems. Usually, it can be deployed to make the NLP models
    more robust and accurate. For more information, please refer to *Scaling Up and
    Distilling Down: Language-Guided Robot Skill* *Acquisition* ([https://arxiv.org/abs/2307.14535](https://arxiv.org/abs/2307.14535)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in *Figure 14**.3*, there are four key elements that can be
    randomized to improve the generalizability of NLP models in practice:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.3 – Main elements to randomize in NLP](img/B18494_14_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.3 – Main elements to randomize in NLP
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s discuss these elements in detail as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Textual variations**: To improve the NLP model’s generalizability and robustness
    to real-world problems, many textual variations are introduced to augment and
    complement the training data. This is usually done by varying the following elements:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vocabulary
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentence structure
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentence length
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Context**: NLP models can be utilized in different contexts and for various
    applications. For example, ChatGPT can be used to answer questions about various
    topics, such as healthcare, math, finance, and history. It can be utilized to
    propose travel plans or even to summarize text. Thus, it is crucial to diversify
    these elements in the training data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Topic
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Domain
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Textual genres, such as social media, research papers, and novels
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Linguistic factors**: An ideal NLP model should be able to handle and respond
    to queries with different formats and styles. Additionally, it should be capable
    of understanding sentiments in various applications. Thus, the following factors
    should be randomized during the training stage to ensure better performance in
    practice:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Style, such as formal, informal, technical, or colloquial
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment, such as positive, negative, or neutral expressions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Noise and perturbations**: Introducing perturbations in the training data
    and guiding the NLP model on how to perform these scenarios will ensure that your
    ML model learns how to respond correctly to these issues. The real world is noisy
    and thus it is crucial to pay attention to the following factors in the training
    stage to cover these well-known imperfections usually observed in textual data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spelling errors
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Grammar errors
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Punctuation errors
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let’s explore another interesting domain adaptation method.
  prefs: []
  type: TYPE_NORMAL
- en: Adversarial domain adaptation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Adversarial domain adaptation** is another powerful technique used to bridge
    the gap between synthetic and real domains based on GANs. In this domain adaptation
    method, the generator tries to extract domain-independent features while the discriminator
    tries to identify the source of the data: synthetic or real. Once the model is
    trained and the discriminator can no longer identify the source of the data domain,
    the generator can then generate domain-invariant features. For more information,
    please refer to *Adversarial Discriminative Domain* *Adaptation* ([https://arxiv.org/pdf/1702.05464.pdf](https://arxiv.org/pdf/1702.05464.pdf)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s briefly discuss one example from computer vision that illustrates how
    this synthetic-to-real domain adaptation method can be utilized. For example,
    let’s consider the vehicle re-identification problem. It was shown that utilizing
    synthetic and real data for training using adversarial domain adaptation improved
    the performance on two evaluation real datasets, *CityFlow-ReID* ([https://paperswithcode.com/dataset/cityflow](https://paperswithcode.com/dataset/cityflow))
    and *VeRi* ([https://github.com/VehicleReId/VeRi](https://github.com/VehicleReId/VeRi)),
    with a good margin compared to other solutions. The approach was trained on a
    mixture of synthetic and real vehicle re-identification datasets. The ML model
    was guided to learn discriminative features, especially from the real training
    images. At the same time, it was directed to learn the features that are common
    between synthetic and real domains. For more details, please refer to *StRDAN:
    Synthetic-to-Real Domain Adaptation Network for Vehicle Re-Identification* ([https://arxiv.org/abs/2004.12032](https://arxiv.org/abs/2004.12032)).
    Next, let’s look at another approach used for domain adaptation.'
  prefs: []
  type: TYPE_NORMAL
- en: Feature-based domain adaptation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike the previous approach, **feature-based domain adaptation** aims at learning
    a transformation that extracts domain-independent features across synthetic and
    real domains. This approach transfers the features of both domains into a new
    representation and then minimizes the discrepancy between the synthetic and real
    domains. In other words, this method tries to align the feature distributions
    in both domains with each other. Thus, the approach urges the ML model to learn
    essential features while discarding domain-specific details and variations. For
    instance, if the ML model is learning semantic segmentation by being trained on
    the *Synscapes* ([https://synscapes.on.liu.se](https://synscapes.on.liu.se)) and
    *Cityscapes* ([https://www.cityscapes-dataset.com](https://www.cityscapes-dataset.com))
    datasets, we want the model to learn how to segment humans, cars, traffic lights,
    and other objects by somehow learning the meaning of these objects. For instance,
    humans usually walk on pedestrian areas or sidewalks and they usually have a capsule-like
    shape. These are the sorts of high-level and domain-invariant features that we
    want the model to learn.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, for a detailed overview of domain adaption methods, please refer to
    *A Brief Review of Domain Adaptation* ([https://arxiv.org/pdf/2010.03978v1.pdf](https://arxiv.org/pdf/2010.03978v1.pdf)).
    Now, we have learned about some of the key approaches usually utilized for synthetic-to-real
    domain adaptation. Next, let’s delve into their common limitations and how to
    overcome them in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic-to-real domain adaptation – issues and challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, you will explore the main issues and challenges of synthetic-to-real
    domain adaptation. This will help you to understand the limitations of this approach.
    Additionally, it will give you a better insight into how to overcome these issues
    in your own problem. Therefore, we will focus on the following issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Unseen domain
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limited real data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computational complexity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthetic data limitations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multimodal data complexity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s discuss them in detail in the following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Unseen domain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many cases, the aim is to make sure that your ML model will generalize well
    to new domains. If we know the domain, domain adaptation methods may work. However,
    sometimes it is not possible to predict the properties of this new domain. For
    example, assume you have a computer vision model that works well in Europe but
    you also want this algorithm to work well in China, Africa, the Middle East, or
    even on Mars! It is not always possible to have advanced knowledge of the environment
    or the domain where the ML model will be deployed to make appropriate adaptations.
  prefs: []
  type: TYPE_NORMAL
- en: Limited real data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we know, real data is scarce and expensive. Thus, supervised domain adaptation
    methods cannot be easily applied to all ML problems. Additionally, the limited
    availability of paired data between synthetic and real domains makes the problem
    even harder. Thus, it is indeed complex and cumbersome to learn the mapping from
    a synthetic to a real domain.
  prefs: []
  type: TYPE_NORMAL
- en: Computational complexity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Domain adaptation methods are computationally expensive and may require resources,
    time, experience, substantial budget, and domain experts. Thus, it is not easy,
    and it is sometimes challenging to train these models, especially adversarial
    domain adaptation ones.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Synthetic data has some limitations, especially if the data is not generated
    appropriately. Synthetic data may lack the diversity and realism of real data.
    Thus, it makes it even harder for adaptation methods to bridge the gap. Please
    refer to [*Chapter 13*](B18494_13.xhtml#_idTextAnchor216).
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal data complexity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recent state-of-the-art computer vision systems such *Tesla Vision Autopilot*
    utilize data captured from different sources, such as cameras, LiDAR sensors,
    radar sensors, accelerometers, and gyroscopes. However, generating and annotating
    the real data and matching it with synthetic data is not a straightforward process.
    For example, it is possible to generate semantic segmentation, optical flow, or
    other relevant ground truths, but it is very difficult to simulate the behavior
    of accelerometers and gyroscopes in virtual worlds. Additionally, it is very complex
    to develop a simulator that provides all these ground truths together. In parallel
    to that, it is rather hard for domain adaptation to learn how to appropriately
    adapt the data from one domain to another.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned the essence of the domain gap problem in ML. Additionally,
    you explored the main solutions to mitigate this problem. We focused on domain
    randomization in computer vision and NLP. Then, you learned about the main issues
    and limitations of synthetic-to-real domain adaptation. In the next chapter, we
    will explore and highlight diversity issues in synthetic data to better comprehend
    the pros and cons of synthetic data in ML.
  prefs: []
  type: TYPE_NORMAL
