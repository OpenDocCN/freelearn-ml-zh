- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations! You have just made a big step toward becoming a machine learning
    practitioner. Not only are you familiar with a wide variety of fundamental machine
    learning algorithms, but you also know how to apply them to both supervised and
    unsupervised learning problems. Moreover, you were introduced to a new and exciting
    topic, OpenVINO Toolkit. In the previous chapter, we learned how to install OpenVINO
    and run an interactive face detection and image classification demo, among others.
    I am sure you have enjoyed learning about those topics.
  prefs: []
  type: TYPE_NORMAL
- en: Before we part ways, I want to give you some final words of advice, point you
    toward some additional resources, and give you some suggestions on how you can
    further improve your machine learning and data science skills. In this chapter,
    we will learn how to approach a machine learning problem and build our own estimator.
    We will learn how to write our own OpenCV-based classifier in C++ and a scikit-learn-based
    classifier in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Approaching a machine learning problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing your own OpenCV-based classifier in C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing your own scikit-learn-based classifier in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where to go from here
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can refer to the code for this chapter from the following link: [https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter13](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter13).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a summary of the software and hardware requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: You will need OpenCV version 4.1.x (4.1.0 or 4.1.1 will both work just fine).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will need Python version 3.6 (any Python version 3.x will be fine).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will need Anaconda Python 3 for installing Python and the required modules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use any OS—macOS, Windows, and Linux-based OSes along with this book.
    We recommend you have at least 4 GB RAM in your system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You don't need to have a GPU to run the code provided along with this book.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaching a machine learning problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you see a new machine learning problem in the wild, you might be tempted
    to jump ahead and throw your favorite algorithm at the problem—perhaps the one
    you understood best or had the most fun implementing. But knowing beforehand which
    algorithm will perform best on your specific problem is not often possible.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, you need to take a step back and look at the bigger picture. Before
    you get in too deep, you will want to define the actual problem you are trying
    to solve. For example, do you already have a specific goal in mind, or are you
    just looking to do some exploratory analysis and find something interesting in
    the data? Often, you will start with a general goal, such as detecting spam email
    messages, making movie recommendations, or automatically tagging your friends
    in pictures uploaded to a social media platform. However, as we have seen throughout
    this book, there are often several ways to solve a problem. For example, we recognized
    handwritten digits using logistic regression, k-means clustering, and deep learning.
    Defining the problem will help you to ask the right questions and make the right
    choices along the way.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a rule of thumb, you can use the following five-step procedure to approach
    machine learning problems in the wild:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Categorize the problem**: This is a two-step process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Categorize by input**: Simply speaking, if you have labeled data, it''s a
    supervised learning problem. If you have unlabeled data and want to find structure,
    it''s an unsupervised learning problem. If you want to optimize an objective function
    by interacting with an environment, it''s a reinforcement learning problem.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Categorize by output**: If the output of your model is a number, it''s a
    regression problem. If the output of your model is a class (or category), it''s
    a classification problem. If the output of your model is a set of input groups,
    it''s a clustering problem.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Find the available algorithms**: Now that you have categorized the problem,
    you can identify the algorithms that are applicable and practical to implement
    using the tools at our disposal. Microsoft has created a handy algorithm cheat
    sheet that shows which algorithms can be used for which category of problems.
    Although the cheat sheet is tailored toward **Microsoft Azure**, you might find
    it generally helpful.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The machine learning algorithm cheat sheet PDF (by Microsoft Azure) can be downloaded
    from [http://aka.ms/MLCheatSheet](http://aka.ms/MLCheatSheet).
  prefs: []
  type: TYPE_NORMAL
- en: '**Implement all of the applicable algorithms** (**prototyping**): For any given
    problem, there are usually a handful of candidate algorithms that could do the
    job. So, how do you know which one to pick? Often, the answer to this problem
    is not straightforward, so you have to resort to trial and error. Prototyping
    is best done in two steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should aim for a quick and dirty implementation of several algorithms with
    minimal feature engineering. At this stage, you should mainly be interested in
    seeing which algorithm behaves better at a coarse scale. This step is a bit like
    hiring: you''re looking for any reason to shorten your list of candidate algorithms.
    Once you have reduced the list to a few candidate algorithms, the real prototyping
    begins.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ideally, you would want to set up a machine learning pipeline that compares
    the performance of each algorithm on the dataset using a set of carefully selected
    evaluation criteria (see [Chapter 11](904bc419-cb0e-44cd-ae3f-8ce97e15baa2.xhtml),
    *Selecting the Right Model with Hyperparameter Tuning*). At this stage, you should
    only be dealing with a handful of algorithms, so you can turn your attention to
    where the real magic lies: feature engineering.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Feature engineering**: Perhaps even more important than choosing the right
    algorithm is choosing the right features to represent the data. You can read all
    about feature engineering in [Chapter 4](142fec63-a847-4cde-9de9-c34805d2bb84.xhtml),
    *Representing Data and Engineering Features*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Optimize hyperparameters**: Finally, you also want to optimize an algorithm''s
    hyperparameters. Examples might include the number of principal components of
    PCA, the parameter, *k*, in the k-nearest neighbor algorithm, or the number of
    layers and learning rate in a neural network. You can look at [Chapter 11](904bc419-cb0e-44cd-ae3f-8ce97e15baa2.xhtml),
    *Selecting the Right Model with Hyperparameter Tuning*, for inspiration.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building your own estimator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, we visited a whole variety of machine learning tools and algorithms
    that OpenCV provides straight out of the box. And, if for some reason, OpenCV
    does not provide exactly what we are looking for, we can always fall back on scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: However, when tackling more advanced problems, you might find yourself wanting
    to perform some very specific data processing that neither OpenCV nor scikit-learn
    provide, or you might want to make slight adjustments to an existing algorithm.
    In this case, you may want to create your own estimator.
  prefs: []
  type: TYPE_NORMAL
- en: Writing your own OpenCV-based classifier in C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since OpenCV is one of those Python libraries that does not contain a single
    line of Python code under the hood (I''m kidding, but it''s close), you will have
    to implement your custom estimator in C++. This can be done in four steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement a C++ source file that contains the main source code. You need to
    include two header files, one that contains all the core functionality of OpenCV
    (`opencv.hpp`) and another that contains the machine learning module (`ml.hpp`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, an estimator class can be created by inheriting from the `StatModel`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you define `constructor` and `destructor` of the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you also have to define some methods. These are what you would fill in
    to make the classifier actually do some work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The main work is done in the `train` method, which comes in two flavors (accepting
    either `cv::ml::TrainData` or `cv::InputArray` as input):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You also need to provide a `predict` method and a `scoring` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The last thing to do is to include a `main` function that instantiates the
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Write a CMake file called `CMakeLists.txt`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Compile the file on the command line by typing the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the executable `MyClass` method, which was generated by the last command
    and which should lead to the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Writing your own scikit-learn-based classifier in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alternatively, you can write your own classifier using the scikit-learn library.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can do this by importing `BaseEstimator` and `ClassifierMixin`. The latter
    will provide a corresponding `score` method, which works for all classifiers:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, first, you can overwrite the `score` method to provide your own metric
    `score` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can define a class that inherits from both `BaseEstimator` and `ClassifierMixin`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: You need to provide a constructor, `fit` and `predict` methods. The constructor
    defines all the parameters ...
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Where to go from here
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of this book was to introduce you to the world of machine learning
    and prepare you to become a machine learning practitioner. Now that you know everything
    about the fundamental algorithms, you might want to investigate some topics in
    more depth.
  prefs: []
  type: TYPE_NORMAL
- en: Although it is not necessary to understand all of the details of all of the
    algorithms we implemented in this book, knowing some of the theory behind them
    might just make you a better data scientist.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are looking for more advanced material, then you might want to consider
    some of the following classics:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Stephen Marsland, *Machine Learning: An Algorithmic Perspective,* *Second Edition*,
    Chapman and Hall/Crc, ISBN 978-146658328-3, 2014'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Christopher M. Bishop, *Pattern Recognition and Machine Learning*. Springer,
    ISBN 978-038731073-2, 2007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Trevor Hastie, Robert Tibshirani, and Jerome Friedman, *The Elements of Statistical
    Learning: Data Mining, Inference, and Prediction*. *Second Edition*, Springer,
    ISBN 978-038784857-0, 2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When it comes to software libraries, we already learned about two essential
    ones—OpenCV and scikit-learn. Often, using Python is great for trying out and
    evaluating models, but larger web services and applications are more commonly
    written in Java or C++.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the C++ package is **Vowpal Wabbit** (VW), which comes with its
    own command-line interface. For running machine learning algorithms on a cluster,
    people often use `mllib`, a **Scala** library built on top of **Spark**. If you
    are not married to Python, you might also consider using R, another common language
    of data scientists. R is a language designed specifically for statistical analysis
    and is famous for its visualization capabilities and the availability of many
    (often highly specialized) statistical modeling packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'No matter which software you choose going forward, I guess the most important
    advice is to keep practicing your skills. But you already knew that. There are
    a number of excellent datasets out there that are just waiting for you to analyze
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, we made great use of the example datasets that are built
    into scikit-learn. In addition, scikit-learn provides a way to load datasets from
    external services, such as [mldata.org](http://mldata.org/). Refer to [http://scikit-learn.org/stable/datasets/index.html](http://scikit-learn.org/stable/datasets/index.html)
    for more information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaggle is a company that hosts a wide range of datasets as well as competitions
    on their website, [http://www.kaggle.com](http://www.kaggle.com). Competitions
    are often hosted by a variety of companies, nonprofit organizations, and universities,
    and the winner can take home some serious monetary prizes. A disadvantage of competitions
    is that they already provide a particular metric to optimize and usually a fixed,
    preprocessed dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The OpenML platform ([http://www.openml.org](http://www.mldata.org)) hosts over
    20,000 datasets with over 50,000 associated machine learning tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another popular choice is the UC Irvine Machine Learning Repository ([http://archive.ics.uci.edu/ml/index.php](http://archive.ics.uci.edu/ml/index.php)),
    hosting over 370 popular and well-maintained datasets through a searchable interface.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, if you are looking for more example code in Python, a number of excellent
    books nowadays come with their own GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Jake Vanderplas, *Python Data Science Handbook: Essential Tools for Working
    with Data*. O''Reilly, ISBN 978-149191205-8, 2016, [https://github.com/jakevdp/PythonDataScienceHandbook](https://github.com/jakevdp/PythonDataScienceHandbook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Andreas Muller and Sarah Guido, *Introduction to Machine Learning with Python:
    A Guide for Data Scientists*. O''Reilly, ISBN 978-144936941-5, 2016, [https://github.com/amueller/introduction_to_ml_with_python](https://github.com/amueller/introduction_to_ml_with_python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sebastian Raschka, *Python Machine Learning*. Packt, ISBN 978-178355513-0, 2015,
    [https://github.com/rasbt/python-machine-learning-book](https://github.com/rasbt/python-machine-learning-book)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to approach a machine learning problem and built
    our own estimator. We learned how to write our own OpenCV-based classifier in
    C++ and scikit-learn-based classifier in Python.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we covered a lot of theory and practice. We discussed a wide variety
    of fundamental machine learning algorithms, both supervised or unsupervised, and
    illustrated best practices as well as ways to avoid common pitfalls, and we touched
    upon a variety of commands and packages for data analysis, machine learning, and
    visualization.
  prefs: []
  type: TYPE_NORMAL
- en: If you made it this far, you have already made a big step toward machine learning
    mastery. From here on out, I am confident you will do just fine on your own.
  prefs: []
  type: TYPE_NORMAL
- en: All that's left to say is farewell! ...
  prefs: []
  type: TYPE_NORMAL
