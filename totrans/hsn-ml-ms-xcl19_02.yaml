- en: Implementing Machine Learning Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning has been a matter of study for many years. How human beings acquire
    new knowledge, from basic survival skills to advanced abstract subjects, is difficult
    to understand and reproduce in the computer world. Machines learn by comparing
    examples and by finding similarities in them.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way for a machine (and also for a human being) to learn is to simplify
    the problem that needs to be solved. A simplified version of reality, called a
    model, is useful for this task. Some of the relevant issues to be studied are
    the minimum number of samples, underfitting and overfitting, relevant features,
    and how well a model can learn. Different types of target variables require different
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, the following topics will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding learning and models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focusing on model features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studying machine learning models in practice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are no technical requirements for this chapter, since it is introductory.
    The data shown in the sections should be input into an Excel spreadsheet in order
    to be able to follow the examples.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding learning and models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The way that humans learn has been studied for many decades now. There are
    a handful of psychological theories that try to explain how we acquire knowledge,
    use it, and generalize it in order to apply what we know to completely new scenarios.
    Taking one step back, we could ask ourselves: what does it mean to learn? We could
    say that, once we learn something, we are able to repeat it in a more or less
    detailed way. In reality, learning implies much more than just copying a behavior
    or memorizing a piece of poetry. In fact, we understand what we learn and are
    able to generalize that knowledge, which helps us to react correctly to new people,
    places, and situations.'
  prefs: []
  type: TYPE_NORMAL
- en: The need to create a machine that somehow mimics our human behavior and intelligence
    has been desired for a very long time. Hundreds of years ago, kings were amazed
    by chess-playing machines, musical instruments that did not require a human player,
    and mysterious boxes that answered all kinds of questions. These, many times fake,
    inventions show that one of the greatest dreams of humans is to create an intelligent
    being, which is able to replicate easy or difficult tasks that are usually performed
    by people, even when intelligence is an elusive and not easily-defined thing.
  prefs: []
  type: TYPE_NORMAL
- en: Many years have passed, and technology has evolved in such a way that we can
    now create machines that *think*, or at least seem to. In fact, most of the systems
    that we call *intelligent* are just able to perform repetitive tasks or react
    to external inputs according to whatever we have showed them by way of example.
    As we progress through the chapter, we will see that some of the defined characteristics
    of human learning and intelligence are already part of modern machine learning
    systems and some are still the subject of science fiction novels.
  prefs: []
  type: TYPE_NORMAL
- en: By definition, machine learning means to teach a machine or an algorithm to
    perform tasks. We have been doing this for many years now – it is called **programming**.
    We give a computer a set of instructions, the order in which they should be executed,
    and a number of options of how to react to a limited number of inputs. If the
    input is not known, or if we ask the computer to do something that is not contained
    in the program, then it will fail, showing an error. The difference between this
    traditional paradigm and machine learning is that we will never tell the computer
    exactly what to do. We will either let it discover patterns or show it samples
    of what we want. We will use programming, of course, but just to define algorithms
    that *learn* in the sense that was described previously. From finding the straight
    line that better represents a set of points to driving a car, everything a machine
    can do is learned in this way.
  prefs: []
  type: TYPE_NORMAL
- en: As babies, we start exploring the world around us. Since we are too young to
    understand words or examples, we basically experience the world through our senses.
    We learn the difference between hard and soft, rough and smooth, hot and cold.
    We can call for attention when we need something, and we can even gain an understanding
    of the patience levels of our parents and pets. In most cases, nobody sits next
    to us to explain what we see, hear, feel, taste, and smell. This is an example
    of what we call *unsupervised learning*.
  prefs: []
  type: TYPE_NORMAL
- en: In unsupervised learning, the training data is "unlabeled". Without our help
    or intervention, the algorithm/s (or program/s) will find the required connections
    or unsuspected patterns in the data and learn the details and properties of the
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Later, as we grow up, we understand words and start naming things. Our parents
    tell us when we see a dog or a cat, we learn our names and theirs, and we learn
    to identify our toys from among other children's toys (and fight over them). Without
    even realizing it, we relate some characteristics of objects, animals, and people
    to their names. These are examples of what is known as *supervised learning*.
    In the case of a computer, the algorithm is shown as a set of variables that are
    representative of the properties of the problem and then it learns how these features
    relate to the name of the label.
  prefs: []
  type: TYPE_NORMAL
- en: Science has shown us the immense complexity of the world that surrounds us.
    Every branch of scientific knowledge needs advanced mathematical calculations
    and even completely new ways of looking at data. However, the vast majority of
    what we can explain is only a fraction of the real world. Whenever we describe
    a physical phenomenon, an economic or financial event, or try to understand the
    behavior of individuals and groups, we rely on simplified versions of the real
    problem. These are called **models** and they make it possible for us to build
    a mental representation of whatever we are trying to explain. If the model is
    accurate enough, we will be able to *predict* some future event, or get some approximate
    value for a certain outcome. As you should have realized by now, this is incredibly
    powerful. For example, if an artillery soldier is capable of calculating, with
    accurate precision, where the cannonball is going to hit, then his army has a
    clear advantage over the enemy in battle. A model is a simplified version of reality
    that is used to understand a problem and eventually make predictions. Understanding
    something that your opponent ignores always represents an advantage.
  prefs: []
  type: TYPE_NORMAL
- en: Learning by example – the linear regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine that you and a friend own a small ice cream shop. You are discussing
    how many **kilograms** (**kg**) of ice cream to produce each day and you both
    agree on the fact that the hotter the weather is, the more ice cream will be sold.
    You add that this is not the only factor to take into account, but there are other
    variables that can also affect the number of sales. As rational people and good
    analysts, you decide to run a small experiment by recording the mean temperature
    during the shop opening hours and the amount of ice cream that is sold. The summer
    turns out to be particularly rainy, and the temperature variation is high, which
    helps you to achieve a good range for the variables. The final dataset looks like
    the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Mean temperature (°C)** | **Ice cream sold (kg)** |'
  prefs: []
  type: TYPE_TB
- en: '| 26 | 45 |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | 42.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 29 | 53.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | 35.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 32.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 19 | 34.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 21 | 33.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 18 | 35 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 32.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 25 | 40.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 25 | 39.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 32 |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | 44.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | 39.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | 33 |'
  prefs: []
  type: TYPE_TB
- en: '| 17 | 26.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 21 | 37.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 29 | 49.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 25 | 40.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 24 | 44 |'
  prefs: []
  type: TYPE_TB
- en: 'Your model states that the amount of ice cream sold is (directly) proportional
    to the mean temperature. In order to test this hypothesis, we can make a scatter
    plot of the collected data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the full range of cells containing the table, click on Insert menu,
    and select Charts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/02346ee9-a54d-4382-b82d-b50a275fd3f4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, click on Scatter, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1ce4865a-687b-4bf5-b563-2961bf1d36ed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After writing the names of the axis titles, you should get a chart that is
    similar to the following chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/69dca98a-1ef2-449a-860b-8c6ba69ee3e4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We see that there is indeed a linear correlation and that it is positive (the
    larger the temperature value, the more ice cream you sell). We can then represent
    the model using a linear equation, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*IC = a * T + b* (1)'
  prefs: []
  type: TYPE_NORMAL
- en: Here, *IC* is the amount of ice cream sold, *T* is the mean temperature, and
    *a* and *b* are constant values to be calculated by a linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: To obtain the values of *a* and *b*, we can use Excel's Analysis ToolPak data
    analysis add-in*.* If you have not enabled it, refer link [https://support.office.com/en-ie/article/use-the-analysis-toolpak-to-perform-complex-data-analysis-6c67ccf0-f4a9-487c-8dec-bdb5a2cefab6](https://support.office.com/en-ie/article/use-the-analysis-toolpak-to-perform-complex-data-analysis-6c67ccf0-f4a9-487c-8dec-bdb5a2cefab6) for
    instructions on how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the data range in your worksheet, go to Data in the main menu and then
    select Data Analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/856925f7-bf15-4cdf-8e85-5487c52cdf25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the pop-up menu, select Regression and click on OK:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b709d8ff-f462-4297-8e70-ac6a6a1a8b79.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Make sure that the *x* and *y* ranges are correct (*x* is temperature and *y*
    is ice cream amount). Select Line Fit Plots to see the regression line on top
    of the data points in a new diagram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1012d61f-557f-47ea-ad17-52aa327f4d46.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Looking at the output, we see that the line that best fits the data can be
    written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*IC = 1.5* T + 6* (2)'
  prefs: []
  type: TYPE_NORMAL
- en: There is a standard error for *a* of *±0.2*, and for *b* of *±4*. The *R²* value
    is *0.78*, which means that the fit is not very good and only 78% of the variation
    in ice cream sales can be explained by the mean temperature. So, you and your
    friend were both right!
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the fitted line:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c7cfc8a5-d159-4fec-88c1-2daa6f6ee4c5.png)'
  prefs: []
  type: TYPE_IMG
- en: It is clear that the line represents the data quite well, but some points are
    a little bit off, showing that you need to take other factors into consideration
    when predicting ice cream consumption. In any case, given the mean forecasted
    temperature for one day, you can use equation *(2)* to have a rough estimation
    of how much ice cream to produce to cover the possible demand.
  prefs: []
  type: TYPE_NORMAL
- en: Keep the rest of the linear regression results to hand, as we are going to use
    some of them in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Focusing on model features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a simplified representation of reality, a model also includes a set of variables
    that contain the relevant information that describes the different parts of the
    problem we are representing. These variables can be something as concrete as 1
    kg of ice cream, as we saw in our previous example, or as abstract as a numerical
    value that represents how similar the meaning is of two words in a text document.
  prefs: []
  type: TYPE_NORMAL
- en: In the particular case of a machine learning model, these variables are called
    **features***.* Choosing significant features that provide relevant information
    about the phenomenon that we try to explain or predict is of paramount importance.
    If we consider unsupervised learning, then the relevant features are those that
    better represent the clustering or association of information in the dataset.
    For supervised learning, the most important features are those that highly correlate
    with the target variable – that is, the value that we want to predict or explain.
  prefs: []
  type: TYPE_NORMAL
- en: The quality of the insights that can be obtained from a machine learning model
    depends on the features used as input to the model. **Feature selection** and
    **feature engineering** are regularly-used techniques to improve a model's input.
    Feature selection is the process of selecting a subset of relevant features for
    use in any identified model construction. It can also be termed as variable selection
    or attribute selection. While building any machine learning model, feature selection
    and data cleaning should be the first and most important steps. Feature engineering
    is defined as the process of using the domain knowledge of the identified data
    to create features that make the machine learning algorithm(s) to work. If this
    is done correctly, then it will increase the predictive power of machine learning
    algorithms by creating features from new data that is fed into this model or system.
  prefs: []
  type: TYPE_NORMAL
- en: In our previous example, the model features are the mean temperature and the
    amount of ice cream sold. Since we have already proved that there are more variables
    involved, we could add some additional features to better explain the daily ice
    cream consumption. For example, we could take into account which day of the week
    we are recording data for and include this information as another feature. Additionally,
    any other relevant information can be represented, more or less accurately, into
    a feature. In supervised learning, it is customary to call the input variables
    *features*, and the target or predicted variable *label.*
  prefs: []
  type: TYPE_NORMAL
- en: Features can be numerical (such as the temperature in our previous example),
    or categorical (such as the day of the week). Since everything in computers is
    represented as numerical data, categorical data should be converted into numerical
    form by assigning categories to numbers. One-hot encoding is a process by which
    categorical variables are converted into a numerical form (or *encoded*) so that
    they can be input into machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following our example, we could translate the day-of-the-week into day number,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Day-of-the-week** | **Day number** |'
  prefs: []
  type: TYPE_TB
- en: '| Monday | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Tuesday | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Wednesday | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Thursday | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Friday | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| Saturday | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Sunday | 7 |'
  prefs: []
  type: TYPE_TB
- en: This encoding reflects the order of the days and reserves the highest values
    for the weekend.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say that you want to be more specific and predict the amount of ice
    cream for each flavor that you sell. For ease, let''s say that you produce four
    different flavors: chocolate, strawberry, lemon, and vanilla. Could you just assign
    one number to each flavor, in the same way that you did in the day-of-the-week
    encoding? The answer, as we shall see, is negative. Let''s try it and see what
    is wrong:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Flavor | Flavor number |'
  prefs: []
  type: TYPE_TB
- en: '| Chocolate | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Strawberry | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Lemon | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Vanilla | 4 |'
  prefs: []
  type: TYPE_TB
- en: 'By using this encoding, we are implicitly saying that chocolate is closer to
    strawberry than to vanilla (1 unit versus 3 units), which is not a real property
    of the flavors. The right way of translating to numbers is to create binary variables.
    This approach is known as one-hot encoding and looks like the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Flavor** | **Is it chocolate?** | **Is it strawberry?** | **Is it lemon?**
    | **Is it vanilla?** |'
  prefs: []
  type: TYPE_TB
- en: '| Chocolate | 1 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Strawberry | 0 | 1 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Lemon | 0 | 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Vanilla | 0 | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: This method creates some overhead, since it increases the number of features
    by creating one binary variable for each possible value of the original variable.
    On the positive side, it correctly calculates the properties of the feature. We
    will see some examples of this in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the type of target variable, we can classify them into *regression
    models* (that is, continuous target variables) or *classification models* (that
    is, discrete target variables). For example, if we want to predict a real number
    or an integer number, we use regression, whereas if we are trying to predict a
    tag with a finite number of options, we use classification.
  prefs: []
  type: TYPE_NORMAL
- en: Studying machine learning models in practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have already seen a very simple example and used it to explain some basic
    concepts. In the next chapter, we are going to explore more complex models. We
    restricted ourselves to a very small dataset, just for clarity and to start our
    journey towards mastering machine learning with an easy task. There are some general
    considerations that we need to be aware of when working with machine learning
    models to solve real problems:'
  prefs: []
  type: TYPE_NORMAL
- en: The amount of data is usually very large. In fact, a larger dataset helps to
    get a more accurate model and a more reliable prediction. Extremely large datasets,
    usually called *big data,* can present storage and manipulation challenges.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data is never clean and ready to use, so data cleansing is extremely important
    and takes a lot of time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of features required to correctly represent a real-life problem is
    often large. The feature engineering techniques previously mentioned are impossible
    to perform by hand, so automatic methods must be devised and applied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is far more important to assess the predictive power of a combination of
    input features than the significance of each individual one. Some simple examples
    of how to select features are given in [Chapter 5](0da64bd8-0bc9-491b-875c-7ec7c35c6165.xhtml),
    *Correlations and the Importance of Variables*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is very unlikely that we will get a very good result with the first model
    that we apply. Testing and evaluating many different machine learning models implies
    repeating the same steps several times and usually requires automation as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dataset should be large enough to use a percentage of the data for training
    purposes (usually 80%) and the rest for testing. Evaluating the accuracy of a
    model only on the training data is misleading. A model can be very precise at
    explaining and predicting the training dataset, but it can fail to generalize
    and deliver wrong results when presented with new, previously unseen data values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training and test data should be selected, usually at random, from the same
    full dataset. Trying to make a prediction based on input that lies far away from
    the training range is unlikely to give good results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Supervised machine learning models are usually trained using a fraction of
    the input data and tested on the remaining part. The model can be then used to
    predict the outcome when fed with new and unknown feature values, as shown in
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d4756867-e08c-4225-8e33-e27a64ec0109.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A typical supervised machine learning project includes the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining the data and merging different data sources (there is more on this
    in [Chapter 3](146c3aff-32a3-4008-8985-c1fd7db22739.xhtml), *Importing Data into
    Excel from Different Data Sources*)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cleansing the data (you can refer to [Chapter 4](f93bc229-5658-466c-a7e2-ad082617bca9.xhtml),
    *Data Cleansing and Preliminary Data Analysis*)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preliminary analysis and feature engineering (you can refer to [Chapter 5](0da64bd8-0bc9-491b-875c-7ec7c35c6165.xhtml),
    *Correlations and the Importance of Variables*)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Trying different models and parameters for each of them, and training them by
    using a percentage of the full dataset and using the rest for testing
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploying the model so that it can be used in a continuous analysis flow and
    not only in small, isolated tests
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Predicting values for new input data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This procedure will become clear in the examples shown in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing underfitting and overfitting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the preceding list, step *4* implies an iterative process where we try models,
    parameters, and features until we get the best result that we can. Let''s now
    think about a classification problem, where we want to separate squares from circles,
    as shown in the following diagram. At the beginning of the process, we will probably
    be in a situation that is similar to the first chart (on the left-hand side).
    The model fails to efficiently separate the two shapes and both sides are a mixture
    of both squares and circles. This is called **underfitting** and refers to a model
    that fails to represent the characteristics of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bb28af32-321e-44b7-b54c-c7f06a4e2d44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As we continue tuning parameters and adjusting the model to the training dataset,
    we might find ourselves in a situation that is similar to the third chart (on
    the right-hand side). The model accurately splits the dataset, leaving only one
    shape on each side of the border line. Even if this seems correct, it completely
    lacks generalization. The result adjusts so well to the training data that it
    will be completely wrong to we test it against a different dataset. This problem
    is called **overfitting**.
  prefs: []
  type: TYPE_NORMAL
- en: To solve the problem of overfitting in our model, we need to increase its adaptability.
    However, making it too flexible can also make it bad at predicting. To avoid this,
    the usual solution is to use *regularization* techniques. There are many similar
    techniques that can be found in specialized literature, but they are beyond the
    scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: The center chart shows a more flexible model; it represents the dataset, but
    is general enough to deal with new, previously unseen data. It is often time-consuming
    and it can be difficult to get the right balance in order to build a good machine
    learning model.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whenever we obtain a result, it is is only as accurate as the model that represents
    the real problem. It is, therefore, extremely important to understand which methods
    can be used to evaluate the performance of our models.
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with *classification* *models* we can use the following methods.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing classification accuracy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is the ratio of the number of **correct predictions** (**CP**) to the
    total number of samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e43d024f-97c4-4cb1-9dc4-e0357b2e7ef2.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *CP* is the number of accurate or correct predictions, and *TP* is the
    total count of all the predictions that have been made.
  prefs: []
  type: TYPE_NORMAL
- en: Building the confusion matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s now think about a binary classification problem. We have a set of samples
    belonging to two classes: *YES* or *NO*. We can build a machine learning model
    that outputs a class for each input set of variables. By testing our model on
    200 samples, we will get the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **N=200** | **Predicted NO** | **Predicted YES** |'
  prefs: []
  type: TYPE_TB
- en: '| **Actual NO** | 60 | 15 |'
  prefs: []
  type: TYPE_TB
- en: '| **Actual YES** | 25 | 100 |'
  prefs: []
  type: TYPE_TB
- en: 'There are four elements to the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True positives (TP)**: The number of times that the model predicts YES and
    the actual value is YES. In our example, this is 100 times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True negatives (TN)**: The number of times that the model predicts NO and
    the actual value is NO. In our example, this is 60 times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False positives (FP)**: The number of times that the model predicts YES and
    the actual value is NO. In our example, this is 15 times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False negatives (FN)**: The number of times that the model predicts NO and
    the actual value is YES. In this example, this is 25 times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, we calculate the confusion matrix in the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/51beb0b2-3b62-4f8e-a087-ba9830df55b0.png)'
  prefs: []
  type: TYPE_IMG
- en: Calculating the Area Under Curve (AUC)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The AUC of a classification model is defined as the probability that the model
    will rank a random positive example above a random negative example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the confusion matrix, we can define other quantities as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be372292-b22f-486f-a734-9725a417db80.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The **True Positive Rate** (**TPR**) or sensitivity is the the ratio of data
    points correctly predicted as positive, with respect to all the data points that
    have a true value of *YES*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7de4c40c-9d05-4c8f-9334-000805b7b8ff.png)'
  prefs: []
  type: TYPE_IMG
- en: The **False Positive Rate** (**FPR**) or specificity is the ratio of *NO* data
    points incorrectly predicted as *YES*, with respect to all *NO* data points.
  prefs: []
  type: TYPE_NORMAL
- en: 'Both quantities have values in the [0, 1] range. FPR and TPR are both computed
    at different threshold values and a graph is constructed. The curve is known as
    **Receiving Operating Characteristic** (**ROC**); AUC is the area under that curve,
    as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/393c0bcf-36a6-4bfa-95e3-6426e56129ea.png)'
  prefs: []
  type: TYPE_IMG
- en: If we instead want to evaluate regression models, we can use the following techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the Mean Absolute Error (MAE)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MAE is the mean value of the absolute difference between the real values (*y[j]*)
    and the predicted values (*ŷ[j]*). It cannot tell us the direction of the error,
    meaning that the prediction could be above or below the true value. If we have
    a total of *N* data points, we can calculate MAE as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/666440a4-f39b-4049-ba24-b597f8d7dce9.png)'
  prefs: []
  type: TYPE_IMG
- en: Calculating the Mean Squared Error (MSE)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MSE takes the average of the square of the difference between the actual values
    and predicted values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de88ba04-619c-4baf-a5f4-e21fb32afdba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'No matter what evaluation method we choose, it is extremely important to take
    into account the business part of the problem. The optimal solution is not always
    to have the most accurate model, but the one that better satisfies your business
    needs. It may be the case that a not-so-accurate model that can be built quickly
    is better than a perfect one that takes a year to produce. Taking into account
    the dataset imbalance and business needs is important for fine-tuning the model
    in order to improve the confusion matrix values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72e10596-4454-4a1d-afbe-1be65a1a3d4e.png)'
  prefs: []
  type: TYPE_IMG
- en: Another important factor to consider is whether we have, in the case of a classification
    problem, a balanced dataset. A dominant class will lead to a model that mostly
    predicts the same result every time. For example, a dataset with 99% *YES* labels
    will produce a machine learning model after training that predicts *YES* for 99%
    of the input (and it will be right!). There are many known techniques used to
    balance a dataset and find the problems in our data.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we briefly discussed the learning process for machines, which,
    to some extent, mimics that of human beings. We described how a model, which is
    a simplified representation of the problem that we want to solve, can be used
    to apply machine learning to find a solution.
  prefs: []
  type: TYPE_NORMAL
- en: Using a linear regression model, we built a simple supervised predictive model
    and explained how to use it. We then discussed the difference between regression
    and classification, and showed the properties of the input variables and features.
  prefs: []
  type: TYPE_NORMAL
- en: Underfitting and overfitting are two of the main concerns when training a machine
    learning model. We explained what they are and suggested methods to avoid them.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, different types of target variables require different algorithms and
    evaluation methods to test the quality of the model – we discussed this in detail
    in the final sections.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to solve some real-life problems using machine
    learning and explore how some supervised and unsupervised models are built.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the main difference between classical computer programming and machine
    learning?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are models classified, considering the type of target variable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the different types of models, depending on how they learn?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the main steps when creating and using a machine learning model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The output of the regression performed in Excel contains information about the
    residuals. What are they and how are they related to the MAE and MSE?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain underfitting and overfitting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can categorical features be used to feed machine learning models?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Machine Learning For Beginners*: [https://towardsdatascience.com/machine-learning-for-beginners-d247a9420dab](https://towardsdatascience.com/machine-learning-for-beginners-d247a9420dab)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Machine Learning basics — It''s your cup of tea*: [https://hackernoon.com/machine-learning-basics-its-your-cup-of-tea-af4baf060ace](https://hackernoon.com/machine-learning-basics-its-your-cup-of-tea-af4baf060ace)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
