- en: Implementing Machine Learning Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现机器学习算法
- en: Learning has been a matter of study for many years. How human beings acquire
    new knowledge, from basic survival skills to advanced abstract subjects, is difficult
    to understand and reproduce in the computer world. Machines learn by comparing
    examples and by finding similarities in them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 学习多年来一直是研究的课题。人类如何获取新知识，从基本的生存技能到高级的抽象主题，在计算机世界中难以理解并复制。机器通过比较示例并找出它们之间的相似性来学习。
- en: The easiest way for a machine (and also for a human being) to learn is to simplify
    the problem that needs to be solved. A simplified version of reality, called a
    model, is useful for this task. Some of the relevant issues to be studied are
    the minimum number of samples, underfitting and overfitting, relevant features,
    and how well a model can learn. Different types of target variables require different
    algorithms.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器（以及人类）学习最简单的方法是简化需要解决的问题。现实的一个简化版本，称为模型，对这个任务很有用。需要研究的相关问题包括样本的最小数量、欠拟合和过拟合、相关特征以及模型能够学习得多好。不同类型的目标变量需要不同的算法。
- en: 'In this chapter, the following topics will be covered:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将涵盖以下主题：
- en: Understanding learning and models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解学习和模型
- en: Focusing on model features
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关注模型特征
- en: Studying machine learning models in practice
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实践中研究机器学习模型
- en: Evaluating models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: There are no technical requirements for this chapter, since it is introductory.
    The data shown in the sections should be input into an Excel spreadsheet in order
    to be able to follow the examples.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章没有技术要求，因为它是一个入门章节。为了能够跟随示例，章节中显示的数据应输入到Excel电子表格中。
- en: Understanding learning and models
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解学习和模型
- en: 'The way that humans learn has been studied for many decades now. There are
    a handful of psychological theories that try to explain how we acquire knowledge,
    use it, and generalize it in order to apply what we know to completely new scenarios.
    Taking one step back, we could ask ourselves: what does it mean to learn? We could
    say that, once we learn something, we are able to repeat it in a more or less
    detailed way. In reality, learning implies much more than just copying a behavior
    or memorizing a piece of poetry. In fact, we understand what we learn and are
    able to generalize that knowledge, which helps us to react correctly to new people,
    places, and situations.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 人类的学习方式已经被研究了几十年。有一些心理学理论试图解释我们如何获取知识，如何使用它，以及如何将其推广以将我们所知应用于全新的场景。退一步来说，我们可以问自己：学习意味着什么？我们可以这样说，一旦我们学会了某样东西，我们就能以或多或少详细的方式重复它。实际上，学习远不止是复制一种行为或记住一首诗。事实上，我们理解我们所学的，并且能够概括这种知识，这有助于我们正确地应对新的人、新的地方和新的情况。
- en: The need to create a machine that somehow mimics our human behavior and intelligence
    has been desired for a very long time. Hundreds of years ago, kings were amazed
    by chess-playing machines, musical instruments that did not require a human player,
    and mysterious boxes that answered all kinds of questions. These, many times fake,
    inventions show that one of the greatest dreams of humans is to create an intelligent
    being, which is able to replicate easy or difficult tasks that are usually performed
    by people, even when intelligence is an elusive and not easily-defined thing.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 需要创建一种能够以某种方式模仿我们人类行为和智能的机器，这个需求已经存在了很长时间。几百年前，国王们对下棋的机器、不需要人类演奏者的乐器以及能够回答各种问题的神秘盒子感到惊讶。这些许多时候是虚假的发明表明，人类最大的梦想之一就是创造一个智能体，它能够复制人们通常执行的任务，即使智能是一个难以捉摸且不易定义的东西。
- en: Many years have passed, and technology has evolved in such a way that we can
    now create machines that *think*, or at least seem to. In fact, most of the systems
    that we call *intelligent* are just able to perform repetitive tasks or react
    to external inputs according to whatever we have showed them by way of example.
    As we progress through the chapter, we will see that some of the defined characteristics
    of human learning and intelligence are already part of modern machine learning
    systems and some are still the subject of science fiction novels.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 多年过去了，技术已经发展到我们可以现在创造出能够“思考”的机器，或者至少看起来是这样。事实上，我们称之为“智能”的大多数系统只是能够执行重复性任务或根据我们所展示的例子对外部输入做出反应。随着我们进入本章，我们将看到人类学习和智能的一些定义特征已经成为了现代机器学习系统的一部分，而一些则仍然是科幻小说的主题。
- en: By definition, machine learning means to teach a machine or an algorithm to
    perform tasks. We have been doing this for many years now – it is called **programming**.
    We give a computer a set of instructions, the order in which they should be executed,
    and a number of options of how to react to a limited number of inputs. If the
    input is not known, or if we ask the computer to do something that is not contained
    in the program, then it will fail, showing an error. The difference between this
    traditional paradigm and machine learning is that we will never tell the computer
    exactly what to do. We will either let it discover patterns or show it samples
    of what we want. We will use programming, of course, but just to define algorithms
    that *learn* in the sense that was described previously. From finding the straight
    line that better represents a set of points to driving a car, everything a machine
    can do is learned in this way.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义，机器学习意味着教会机器或算法执行任务。我们已经在做这件事很多年了——这被称为**编程**。我们给计算机一组指令，它们应该被执行的顺序，以及如何对有限数量的输入做出反应的几种选择。如果输入未知，或者如果我们要求计算机执行程序中不包含的操作，那么它将失败，显示错误。这种传统范式与机器学习之间的区别在于，我们永远不会告诉计算机确切要做什么。我们要么让它发现模式，要么展示我们想要的样本。我们当然会使用编程，但只是为了定义那些*学习*的算法，正如之前所描述的那样。从找到更好地代表一组点的直线到驾驶汽车，机器能做的每一件事都是通过这种方式学习的。
- en: As babies, we start exploring the world around us. Since we are too young to
    understand words or examples, we basically experience the world through our senses.
    We learn the difference between hard and soft, rough and smooth, hot and cold.
    We can call for attention when we need something, and we can even gain an understanding
    of the patience levels of our parents and pets. In most cases, nobody sits next
    to us to explain what we see, hear, feel, taste, and smell. This is an example
    of what we call *unsupervised learning*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 作为婴儿，我们开始探索我们周围的世界。由于我们太小，无法理解词语或例子，我们基本上是通过我们的感官来体验世界的。我们学会区分硬和软、粗糙和平滑、热和冷。当我们需要某样东西时，我们可以呼唤注意，甚至可以理解我们父母和宠物的耐心程度。在大多数情况下，没有人坐在我们旁边来解释我们看到、听到、感觉到、尝到和闻到的东西。这就是我们所说的*无监督学习*的例子。
- en: In unsupervised learning, the training data is "unlabeled". Without our help
    or intervention, the algorithm/s (or program/s) will find the required connections
    or unsuspected patterns in the data and learn the details and properties of the
    dataset.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督学习中，训练数据是“未标记的”。在没有我们的帮助或干预的情况下，算法/（或程序/）将在数据中找到所需的联系或未预料到的模式，并学习数据集的细节和属性。
- en: Later, as we grow up, we understand words and start naming things. Our parents
    tell us when we see a dog or a cat, we learn our names and theirs, and we learn
    to identify our toys from among other children's toys (and fight over them). Without
    even realizing it, we relate some characteristics of objects, animals, and people
    to their names. These are examples of what is known as *supervised learning*.
    In the case of a computer, the algorithm is shown as a set of variables that are
    representative of the properties of the problem and then it learns how these features
    relate to the name of the label.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们长大，我们开始理解词语并开始命名事物。当我们看到狗或猫时，我们的父母会告诉我们，我们学会了自己的名字和他们的名字，我们学会从其他孩子的玩具中识别出自己的玩具（并且为它们而争斗）。在不经意间，我们将物体、动物和人的某些特征与它们的名称联系起来。这些都是我们所说的*监督学习*的例子。在计算机的情况下，算法被展示为一组代表问题属性的变量集合，然后它学习这些特征如何与标签的名称相关联。
- en: Science has shown us the immense complexity of the world that surrounds us.
    Every branch of scientific knowledge needs advanced mathematical calculations
    and even completely new ways of looking at data. However, the vast majority of
    what we can explain is only a fraction of the real world. Whenever we describe
    a physical phenomenon, an economic or financial event, or try to understand the
    behavior of individuals and groups, we rely on simplified versions of the real
    problem. These are called **models** and they make it possible for us to build
    a mental representation of whatever we are trying to explain. If the model is
    accurate enough, we will be able to *predict* some future event, or get some approximate
    value for a certain outcome. As you should have realized by now, this is incredibly
    powerful. For example, if an artillery soldier is capable of calculating, with
    accurate precision, where the cannonball is going to hit, then his army has a
    clear advantage over the enemy in battle. A model is a simplified version of reality
    that is used to understand a problem and eventually make predictions. Understanding
    something that your opponent ignores always represents an advantage.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 科学已经向我们展示了我们所处世界的巨大复杂性。科学知识的每一个分支都需要高级数学计算，甚至完全新的看待数据的方式。然而，我们所能解释的绝大多数只是真实世界的一小部分。每当描述一个物理现象、经济或金融事件，或者试图理解个人和群体的行为时，我们依赖于对真实问题的简化版本。这些被称为**模型**，它们使我们能够构建我们试图解释的任何事物的心理表征。如果模型足够准确，我们就能预测某些未来的事件，或者为某种结果得到一个近似值。正如你现在应该意识到的，这是非常强大的。例如，如果一个炮兵能够精确计算出炮弹将落在哪里，那么他的军队在战斗中将明显优于敌人。模型是现实的简化版本，用于理解问题并最终做出预测。理解你的对手忽视的东西始终是一种优势。
- en: Learning by example – the linear regression model
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过实例学习——线性回归模型
- en: 'Imagine that you and a friend own a small ice cream shop. You are discussing
    how many **kilograms** (**kg**) of ice cream to produce each day and you both
    agree on the fact that the hotter the weather is, the more ice cream will be sold.
    You add that this is not the only factor to take into account, but there are other
    variables that can also affect the number of sales. As rational people and good
    analysts, you decide to run a small experiment by recording the mean temperature
    during the shop opening hours and the amount of ice cream that is sold. The summer
    turns out to be particularly rainy, and the temperature variation is high, which
    helps you to achieve a good range for the variables. The final dataset looks like
    the following table:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你和一位朋友拥有一家小型冰淇淋店。你们正在讨论每天应该生产多少千克的冰淇淋，并且你们都同意天气越热，售出的冰淇淋就越多。你补充说，这并不是唯一需要考虑的因素，还有其他变量也可能影响销售数量。作为理性的人和优秀的分析师，你们决定通过记录商店营业时间内的平均温度和售出的冰淇淋数量来进行一个小实验。夏天特别多雨，温度变化大，这有助于你得到一个良好的变量范围。最终的数据库看起来如下表：
- en: '| **Mean temperature (°C)** | **Ice cream sold (kg)** |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| **平均温度 (°C)** | **售出的冰淇淋 (kg)** |'
- en: '| 26 | 45 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 26 | 45 |'
- en: '| 23 | 42.5 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 23 | 42.5 |'
- en: '| 29 | 53.5 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 29 | 53.5 |'
- en: '| 23 | 35.5 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 23 | 35.5 |'
- en: '| 15 | 32.5 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 32.5 |'
- en: '| 19 | 34.5 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 19 | 34.5 |'
- en: '| 21 | 33.5 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 21 | 33.5 |'
- en: '| 18 | 35 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 18 | 35 |'
- en: '| 15 | 32.5 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 32.5 |'
- en: '| 25 | 40.5 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 40.5 |'
- en: '| 25 | 39.5 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 39.5 |'
- en: '| 16 | 32 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 16 | 32 |'
- en: '| 23 | 44.5 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 23 | 44.5 |'
- en: '| 23 | 39.5 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 23 | 39.5 |'
- en: '| 20 | 33 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 33 |'
- en: '| 17 | 26.5 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 17 | 26.5 |'
- en: '| 21 | 37.5 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 21 | 37.5 |'
- en: '| 29 | 49.5 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 29 | 49.5 |'
- en: '| 25 | 40.5 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 40.5 |'
- en: '| 24 | 44 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 24 | 44 |'
- en: 'Your model states that the amount of ice cream sold is (directly) proportional
    to the mean temperature. In order to test this hypothesis, we can make a scatter
    plot of the collected data:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你的模型表明售出的冰淇淋数量与平均温度成正比。为了测试这个假设，我们可以绘制收集到的数据的散点图：
- en: 'Select the full range of cells containing the table, click on Insert menu,
    and select Charts:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择包含表格的全部单元格范围，点击插入菜单，然后选择图表：
- en: '![](img/02346ee9-a54d-4382-b82d-b50a275fd3f4.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/02346ee9-a54d-4382-b82d-b50a275fd3f4.png)'
- en: 'Now, click on Scatter, as follows:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，点击散点图，如下所示：
- en: '![](img/1ce4865a-687b-4bf5-b563-2961bf1d36ed.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1ce4865a-687b-4bf5-b563-2961bf1d36ed.png)'
- en: 'After writing the names of the axis titles, you should get a chart that is
    similar to the following chart:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在写下坐标轴标题后，你应该得到一个类似于以下图表的图表：
- en: '![](img/69dca98a-1ef2-449a-860b-8c6ba69ee3e4.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/69dca98a-1ef2-449a-860b-8c6ba69ee3e4.png)'
- en: 'We see that there is indeed a linear correlation and that it is positive (the
    larger the temperature value, the more ice cream you sell). We can then represent
    the model using a linear equation, as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到确实存在线性相关性，并且它是正相关的（温度值越大，你卖出的冰淇淋就越多）。然后我们可以使用线性方程来表示这个模型，如下所示：
- en: '*IC = a * T + b* (1)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*IC = a * T + b* (1)'
- en: Here, *IC* is the amount of ice cream sold, *T* is the mean temperature, and
    *a* and *b* are constant values to be calculated by a linear regression.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*IC* 是卖出的冰淇淋数量，*T* 是平均温度，而 *a* 和 *b* 是需要通过线性回归计算出的常数。
- en: To obtain the values of *a* and *b*, we can use Excel's Analysis ToolPak data
    analysis add-in*.* If you have not enabled it, refer link [https://support.office.com/en-ie/article/use-the-analysis-toolpak-to-perform-complex-data-analysis-6c67ccf0-f4a9-487c-8dec-bdb5a2cefab6](https://support.office.com/en-ie/article/use-the-analysis-toolpak-to-perform-complex-data-analysis-6c67ccf0-f4a9-487c-8dec-bdb5a2cefab6) for
    instructions on how to do it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得 *a* 和 *b* 的值，我们可以使用 Excel 的分析工具包数据分析插件*。如果你还没有启用它，请参考链接 [https://support.office.com/en-ie/article/use-the-analysis-toolpak-to-perform-complex-data-analysis-6c67ccf0-f4a9-487c-8dec-bdb5a2cefab6](https://support.office.com/en-ie/article/use-the-analysis-toolpak-to-perform-complex-data-analysis-6c67ccf0-f4a9-487c-8dec-bdb5a2cefab6)
    了解如何操作。
- en: 'Select the data range in your worksheet, go to Data in the main menu and then
    select Data Analysis:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的工作表中选择数据范围，然后在主菜单中选择数据，接着选择数据分析：
- en: '![](img/856925f7-bf15-4cdf-8e85-5487c52cdf25.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/856925f7-bf15-4cdf-8e85-5487c52cdf25.png)'
- en: 'In the pop-up menu, select Regression and click on OK:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在弹出菜单中选择回归，然后点击确定：
- en: '![](img/b709d8ff-f462-4297-8e70-ac6a6a1a8b79.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b709d8ff-f462-4297-8e70-ac6a6a1a8b79.png)'
- en: 'Make sure that the *x* and *y* ranges are correct (*x* is temperature and *y*
    is ice cream amount). Select Line Fit Plots to see the regression line on top
    of the data points in a new diagram:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保x和y的范围是正确的（x是温度，y是冰淇淋数量）。选择线形拟合图，在新图表中查看数据点上的回归线：
- en: '![](img/1012d61f-557f-47ea-ad17-52aa327f4d46.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1012d61f-557f-47ea-ad17-52aa327f4d46.png)'
- en: 'Looking at the output, we see that the line that best fits the data can be
    written as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 观察输出结果，我们看到最佳拟合数据线可以表示如下：
- en: '*IC = 1.5* T + 6* (2)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*IC = 1.5* T + 6* (2)'
- en: There is a standard error for *a* of *±0.2*, and for *b* of *±4*. The *R²* value
    is *0.78*, which means that the fit is not very good and only 78% of the variation
    in ice cream sales can be explained by the mean temperature. So, you and your
    friend were both right!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*a* 的标准误差为 *±0.2*，*b* 的标准误差为 *±4*。*R²* 值为 *0.78*，这意味着拟合不是很好，只有 78% 的冰淇淋销售变化可以通过平均温度来解释。所以，你和你的朋友都是对的！'
- en: 'The following diagram shows the fitted line:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表显示了拟合线：
- en: '![](img/c7cfc8a5-d159-4fec-88c1-2daa6f6ee4c5.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7cfc8a5-d159-4fec-88c1-2daa6f6ee4c5.png)'
- en: It is clear that the line represents the data quite well, but some points are
    a little bit off, showing that you need to take other factors into consideration
    when predicting ice cream consumption. In any case, given the mean forecasted
    temperature for one day, you can use equation *(2)* to have a rough estimation
    of how much ice cream to produce to cover the possible demand.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，这条线很好地代表了数据，但有些点稍微偏离了一些，这表明在预测冰淇淋消费时需要考虑其他因素。无论如何，给定某一天的预测平均温度，你可以使用方程 *(2)*
    来大致估计需要生产多少冰淇淋来满足可能的消费需求。
- en: Keep the rest of the linear regression results to hand, as we are going to use
    some of them in the following sections.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 保留线性回归的其他结果，因为我们将在接下来的章节中使用其中的一些。
- en: Focusing on model features
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关注模型特征
- en: As a simplified representation of reality, a model also includes a set of variables
    that contain the relevant information that describes the different parts of the
    problem we are representing. These variables can be something as concrete as 1
    kg of ice cream, as we saw in our previous example, or as abstract as a numerical
    value that represents how similar the meaning is of two words in a text document.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对现实的简化表示，模型还包括一组变量，这些变量包含描述我们代表问题不同部分的相关信息。这些变量可以是像我们之前例子中看到的那样具体，比如 1 公斤的冰淇淋，或者像文本文档中两个单词意义相似度的数值表示那样抽象。
- en: In the particular case of a machine learning model, these variables are called
    **features***.* Choosing significant features that provide relevant information
    about the phenomenon that we try to explain or predict is of paramount importance.
    If we consider unsupervised learning, then the relevant features are those that
    better represent the clustering or association of information in the dataset.
    For supervised learning, the most important features are those that highly correlate
    with the target variable – that is, the value that we want to predict or explain.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在特定的机器学习模型情况下，这些变量被称为**特征**。选择提供有关我们试图解释或预测的现象的相关信息的显著特征至关重要。如果我们考虑无监督学习，那么相关的特征是那些更好地表示数据集中信息聚类或关联的特征。对于监督学习，最重要的特征是与目标变量高度相关的特征——即我们想要预测或解释的值。
- en: The quality of the insights that can be obtained from a machine learning model
    depends on the features used as input to the model. **Feature selection** and
    **feature engineering** are regularly-used techniques to improve a model's input.
    Feature selection is the process of selecting a subset of relevant features for
    use in any identified model construction. It can also be termed as variable selection
    or attribute selection. While building any machine learning model, feature selection
    and data cleaning should be the first and most important steps. Feature engineering
    is defined as the process of using the domain knowledge of the identified data
    to create features that make the machine learning algorithm(s) to work. If this
    is done correctly, then it will increase the predictive power of machine learning
    algorithms by creating features from new data that is fed into this model or system.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 从机器学习模型中可以获得的洞察力的质量取决于输入到模型中的特征。**特征选择**和**特征工程**是常用的技术，用于提高模型的输入。特征选择是选择相关特征子集的过程，用于任何已识别的模型构建。它也可以称为变量选择或属性选择。在构建任何机器学习模型时，特征选择和数据清洗应该是第一步和最重要的步骤。特征工程被定义为使用已识别数据的领域知识来创建特征的过程，这些特征使机器学习算法能够工作。如果这样做正确，那么它将通过从输入到该模型或系统的新的数据中创建特征来增加机器学习算法的预测能力。
- en: In our previous example, the model features are the mean temperature and the
    amount of ice cream sold. Since we have already proved that there are more variables
    involved, we could add some additional features to better explain the daily ice
    cream consumption. For example, we could take into account which day of the week
    we are recording data for and include this information as another feature. Additionally,
    any other relevant information can be represented, more or less accurately, into
    a feature. In supervised learning, it is customary to call the input variables
    *features*, and the target or predicted variable *label.*
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的例子中，模型特征是平均温度和销售的冰淇淋数量。由于我们已经证明还有更多变量参与其中，我们可以添加一些额外的特征来更好地解释每日冰淇淋的消费。例如，我们可以考虑我们正在记录数据的那一天，并将这一信息作为另一个特征。此外，任何其他相关信息都可以或多或少地表示为一个特征。在监督学习中，通常将输入变量称为*特征*，将目标或预测变量称为*标签*。
- en: Features can be numerical (such as the temperature in our previous example),
    or categorical (such as the day of the week). Since everything in computers is
    represented as numerical data, categorical data should be converted into numerical
    form by assigning categories to numbers. One-hot encoding is a process by which
    categorical variables are converted into a numerical form (or *encoded*) so that
    they can be input into machine learning algorithms.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 特征可以是数值的（例如我们之前的例子中的温度），也可以是分类的（例如一周中的某一天）。由于计算机中的所有东西都是以数值数据表示的，因此分类数据应该通过将类别分配给数字来转换为数值形式。独热编码是一种将分类变量转换为数值形式（或*编码*）的过程，以便它们可以被输入到机器学习算法中。
- en: 'Following our example, we could translate the day-of-the-week into day number,
    as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 按照我们的例子，我们可以将星期转换为星期数，如下所示：
- en: '| **Day-of-the-week** | **Day number** |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| **星期** | **星期数** |'
- en: '| Monday | 1 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 星期一 | 1 |'
- en: '| Tuesday | 2 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 星期二 | 2 |'
- en: '| Wednesday | 3 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 星期三 | 3 |'
- en: '| Thursday | 4 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 星期四 | 4 |'
- en: '| Friday | 5 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 星期五 | 5 |'
- en: '| Saturday | 6 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 星期六 | 6 |'
- en: '| Sunday | 7 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 星期日 | 7 |'
- en: This encoding reflects the order of the days and reserves the highest values
    for the weekend.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这种编码反映了星期的顺序，并为周末保留了最高的值。
- en: 'Let''s say that you want to be more specific and predict the amount of ice
    cream for each flavor that you sell. For ease, let''s say that you produce four
    different flavors: chocolate, strawberry, lemon, and vanilla. Could you just assign
    one number to each flavor, in the same way that you did in the day-of-the-week
    encoding? The answer, as we shall see, is negative. Let''s try it and see what
    is wrong:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想更具体地预测你销售的每种口味的冰淇淋数量。为了方便起见，让我们说我们生产四种不同的口味：巧克力、草莓、柠檬和香草。你能否为每种口味分配一个数字，就像你在星期几编码中所做的那样？答案，正如我们将看到的，是否定的。让我们试一试，看看哪里出了问题：
- en: '| Flavor | Flavor number |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 口味 | 口味编号 |'
- en: '| Chocolate | 1 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 巧克力 | 1 |'
- en: '| Strawberry | 2 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 草莓 | 2 |'
- en: '| Lemon | 3 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 柠檬 | 3 |'
- en: '| Vanilla | 4 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 香草 | 4 |'
- en: 'By using this encoding, we are implicitly saying that chocolate is closer to
    strawberry than to vanilla (1 unit versus 3 units), which is not a real property
    of the flavors. The right way of translating to numbers is to create binary variables.
    This approach is known as one-hot encoding and looks like the following table:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用这种编码，我们隐含地表示巧克力比香草更接近草莓（1个单位与3个单位），这不是口味的一个真实属性。将属性转换为数字的正确方式是创建二进制变量。这种方法被称为独热编码，如下表所示：
- en: '| **Flavor** | **Is it chocolate?** | **Is it strawberry?** | **Is it lemon?**
    | **Is it vanilla?** |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| **口味** | **它是巧克力吗？** | **它是草莓吗？** | **它是柠檬吗？** | **它是香草吗？** |'
- en: '| Chocolate | 1 | 0 | 0 | 0 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 巧克力 | 1 | 0 | 0 | 0 |'
- en: '| Strawberry | 0 | 1 | 0 | 0 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 草莓 | 0 | 1 | 0 | 0 |'
- en: '| Lemon | 0 | 0 | 1 | 0 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 柠檬 | 0 | 0 | 1 | 0 |'
- en: '| Vanilla | 0 | 0 | 0 | 1 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 香草 | 0 | 0 | 0 | 1 |'
- en: This method creates some overhead, since it increases the number of features
    by creating one binary variable for each possible value of the original variable.
    On the positive side, it correctly calculates the properties of the feature. We
    will see some examples of this in the next chapter.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法产生了一些开销，因为它通过为原始变量的每个可能值创建一个二进制变量来增加特征的数量。从积极的一面来看，它正确地计算了特征的性质。我们将在下一章中看到一些例子。
- en: Depending on the type of target variable, we can classify them into *regression
    models* (that is, continuous target variables) or *classification models* (that
    is, discrete target variables). For example, if we want to predict a real number
    or an integer number, we use regression, whereas if we are trying to predict a
    tag with a finite number of options, we use classification.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 根据目标变量的类型，我们可以将它们分类为*回归模型*（即连续目标变量）或*分类模型*（即离散目标变量）。例如，如果我们想预测一个实数或整数，我们使用回归，而如果我们试图预测一个具有有限选项的标签，我们使用分类。
- en: Studying machine learning models in practice
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践中研究机器学习模型
- en: 'We have already seen a very simple example and used it to explain some basic
    concepts. In the next chapter, we are going to explore more complex models. We
    restricted ourselves to a very small dataset, just for clarity and to start our
    journey towards mastering machine learning with an easy task. There are some general
    considerations that we need to be aware of when working with machine learning
    models to solve real problems:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了一个非常简单的例子，并使用它来解释一些基本概念。在下一章中，我们将探索更复杂的模型。为了清晰起见，并开始我们的机器学习之旅，我们只限制在一个非常小的数据集上。当使用机器学习模型解决实际问题时应注意一些一般性考虑：
- en: The amount of data is usually very large. In fact, a larger dataset helps to
    get a more accurate model and a more reliable prediction. Extremely large datasets,
    usually called *big data,* can present storage and manipulation challenges.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据量通常非常大。实际上，更大的数据集有助于获得更精确的模型和更可靠的预测。通常称为*大数据*的极大数据集可能会带来存储和处理挑战。
- en: Data is never clean and ready to use, so data cleansing is extremely important
    and takes a lot of time.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据永远不会干净且可直接使用，因此数据清洗非常重要，并且需要花费大量时间。
- en: The number of features required to correctly represent a real-life problem is
    often large. The feature engineering techniques previously mentioned are impossible
    to perform by hand, so automatic methods must be devised and applied.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确表示现实生活问题所需的特征数量通常很大。之前提到的特征工程技术无法手工完成，因此必须设计并应用自动方法。
- en: It is far more important to assess the predictive power of a combination of
    input features than the significance of each individual one. Some simple examples
    of how to select features are given in [Chapter 5](0da64bd8-0bc9-491b-875c-7ec7c35c6165.xhtml),
    *Correlations and the Importance of Variables*.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估一组输入特征的预测能力远比评估每个单独特征的显著性重要。第5章（[0da64bd8-0bc9-491b-875c-7ec7c35c6165.xhtml](0da64bd8-0bc9-491b-875c-7ec7c35c6165.xhtml)）中给出了如何选择特征的简单示例，*相关性与变量的重要性*
- en: It is very unlikely that we will get a very good result with the first model
    that we apply. Testing and evaluating many different machine learning models implies
    repeating the same steps several times and usually requires automation as well.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不太可能第一次应用模型就能得到非常好的结果。测试和评估许多不同的机器学习模型意味着要重复相同的步骤多次，通常还需要自动化。
- en: The dataset should be large enough to use a percentage of the data for training
    purposes (usually 80%) and the rest for testing. Evaluating the accuracy of a
    model only on the training data is misleading. A model can be very precise at
    explaining and predicting the training dataset, but it can fail to generalize
    and deliver wrong results when presented with new, previously unseen data values.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集应该足够大，以便可以使用其中的一部分数据进行训练（通常为80%），其余部分用于测试。仅基于训练数据评估模型的准确性是误导性的。一个模型可能在解释和预测训练数据集时非常精确，但当面对新的、之前未见过的数据值时，可能无法泛化并给出错误的结果。
- en: Training and test data should be selected, usually at random, from the same
    full dataset. Trying to make a prediction based on input that lies far away from
    the training range is unlikely to give good results.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据和测试数据应从同一完整数据集中随机选择。试图基于远离训练范围的数据进行预测不太可能得到好的结果。
- en: 'Supervised machine learning models are usually trained using a fraction of
    the input data and tested on the remaining part. The model can be then used to
    predict the outcome when fed with new and unknown feature values, as shown in
    the following diagram:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习模型通常使用输入数据的一部分进行训练，并在剩余部分上进行测试。然后，该模型可以用来预测当输入新的和未知特征值时的结果，如下面的图所示：
- en: '![](img/d4756867-e08c-4225-8e33-e27a64ec0109.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d4756867-e08c-4225-8e33-e27a64ec0109.png)'
- en: 'A typical supervised machine learning project includes the following steps:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的监督机器学习项目包括以下步骤：
- en: Obtaining the data and merging different data sources (there is more on this
    in [Chapter 3](146c3aff-32a3-4008-8985-c1fd7db22739.xhtml), *Importing Data into
    Excel from Different Data Sources*)
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取数据并合并不同的数据源（关于此内容的更多信息请参阅[第3章](146c3aff-32a3-4008-8985-c1fd7db22739.xhtml)，*从不同数据源导入Excel数据*)
- en: Cleansing the data (you can refer to [Chapter 4](f93bc229-5658-466c-a7e2-ad082617bca9.xhtml),
    *Data Cleansing and Preliminary Data Analysis*)
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清洗数据（您可以参考[第4章](f93bc229-5658-466c-a7e2-ad082617bca9.xhtml)，*数据清洗和初步数据分析*)
- en: Preliminary analysis and feature engineering (you can refer to [Chapter 5](0da64bd8-0bc9-491b-875c-7ec7c35c6165.xhtml),
    *Correlations and the Importance of Variables*)
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初步分析和特征工程（您可以参考[第5章](0da64bd8-0bc9-491b-875c-7ec7c35c6165.xhtml)，*相关性与变量的重要性*)
- en: Trying different models and parameters for each of them, and training them by
    using a percentage of the full dataset and using the rest for testing
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试不同的模型及其参数，并使用完整数据集的一部分进行训练，其余部分用于测试
- en: Deploying the model so that it can be used in a continuous analysis flow and
    not only in small, isolated tests
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型部署以便在连续的分析流程中使用，而不仅仅是进行小规模的、孤立的测试
- en: Predicting values for new input data
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测新输入数据的值
- en: This procedure will become clear in the examples shown in the next chapter.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章的示例中，此过程将变得清晰。
- en: Comparing underfitting and overfitting
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较欠拟合和过拟合
- en: 'In the preceding list, step *4* implies an iterative process where we try models,
    parameters, and features until we get the best result that we can. Let''s now
    think about a classification problem, where we want to separate squares from circles,
    as shown in the following diagram. At the beginning of the process, we will probably
    be in a situation that is similar to the first chart (on the left-hand side).
    The model fails to efficiently separate the two shapes and both sides are a mixture
    of both squares and circles. This is called **underfitting** and refers to a model
    that fails to represent the characteristics of the dataset:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的列表中，步骤 *4* 意味着一个迭代过程，我们尝试模型、参数和特征，直到我们得到最佳结果。现在让我们考虑一个分类问题，我们想要将正方形与圆形分开，如图所示。在过程的开始，我们可能会处于与第一张图（左侧）类似的情况。模型未能有效地分离这两种形状，两侧都是正方形和圆形的混合。这被称为
    **欠拟合**，指的是一个无法表示数据集特征的模型：
- en: '![](img/bb28af32-321e-44b7-b54c-c7f06a4e2d44.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bb28af32-321e-44b7-b54c-c7f06a4e2d44.jpg)'
- en: As we continue tuning parameters and adjusting the model to the training dataset,
    we might find ourselves in a situation that is similar to the third chart (on
    the right-hand side). The model accurately splits the dataset, leaving only one
    shape on each side of the border line. Even if this seems correct, it completely
    lacks generalization. The result adjusts so well to the training data that it
    will be completely wrong to we test it against a different dataset. This problem
    is called **overfitting**.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续调整参数并将模型调整到训练数据集，我们可能会发现自己处于与第三张图（右侧）类似的情况。模型准确地分割了数据集，使得边界线两侧只留下一个形状。即使这看起来是正确的，但它完全缺乏泛化能力。结果调整得太适合训练数据，以至于当我们用不同的数据集对其进行测试时，它将完全错误。这个问题被称为
    **过拟合**。
- en: To solve the problem of overfitting in our model, we need to increase its adaptability.
    However, making it too flexible can also make it bad at predicting. To avoid this,
    the usual solution is to use *regularization* techniques. There are many similar
    techniques that can be found in specialized literature, but they are beyond the
    scope of this book.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决我们模型中的过拟合问题，我们需要增加其适应性。然而，使其过于灵活也可能使其在预测方面表现不佳。为了避免这种情况，通常的解决方案是使用 *正则化*
    技术。在专门的文献中可以找到许多类似的技术，但它们超出了本书的范围。
- en: The center chart shows a more flexible model; it represents the dataset, but
    is general enough to deal with new, previously unseen data. It is often time-consuming
    and it can be difficult to get the right balance in order to build a good machine
    learning model.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 中心图表显示了一个更灵活的模型；它代表数据集，但足够泛化，可以处理新的、之前未见过的数据。这通常很耗时，并且很难找到正确的平衡，以构建一个好的机器学习模型。
- en: Evaluating models
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: Whenever we obtain a result, it is is only as accurate as the model that represents
    the real problem. It is, therefore, extremely important to understand which methods
    can be used to evaluate the performance of our models.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们获得一个结果时，它只与表示真实问题的模型一样准确。因此，了解哪些方法可以用来评估我们模型的性能至关重要。
- en: When dealing with *classification* *models* we can use the following methods.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理 *分类* *模型* 时，我们可以使用以下方法。
- en: Analyzing classification accuracy
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析分类准确率
- en: 'This is the ratio of the number of **correct predictions** (**CP**) to the
    total number of samples:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这是正确预测数（**CP**）与样本总数之比：
- en: '![](img/e43d024f-97c4-4cb1-9dc4-e0357b2e7ef2.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e43d024f-97c4-4cb1-9dc4-e0357b2e7ef2.png)'
- en: Here, *CP* is the number of accurate or correct predictions, and *TP* is the
    total count of all the predictions that have been made.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*CP* 代表准确或正确的预测数量，而 *TP* 代表所有已做预测的总数。
- en: Building the confusion matrix
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建混淆矩阵
- en: 'Let''s now think about a binary classification problem. We have a set of samples
    belonging to two classes: *YES* or *NO*. We can build a machine learning model
    that outputs a class for each input set of variables. By testing our model on
    200 samples, we will get the following results:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑一个二元分类问题。我们有一组属于两个类别的样本：*YES* 或 *NO*。我们可以构建一个机器学习模型，该模型为每个输入变量集输出一个类别。通过在200个样本上测试我们的模型，我们将得到以下结果：
- en: '| **N=200** | **Predicted NO** | **Predicted YES** |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| **N=200** | **预测 NO** | **预测 YES** |'
- en: '| **Actual NO** | 60 | 15 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| **实际 NO** | 60 | 15 |'
- en: '| **Actual YES** | 25 | 100 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| **实际 YES** | 25 | 100 |'
- en: 'There are four elements to the confusion matrix:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵有四个要素：
- en: '**True positives (TP)**: The number of times that the model predicts YES and
    the actual value is YES. In our example, this is 100 times.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性（TP）**：模型预测为YES且实际值为YES的次数。在我们的例子中，这是100次。'
- en: '**True negatives (TN)**: The number of times that the model predicts NO and
    the actual value is NO. In our example, this is 60 times.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性（TN）**：模型预测为NO且实际值为NO的次数。在我们的例子中，这是60次。'
- en: '**False positives (FP)**: The number of times that the model predicts YES and
    the actual value is NO. In our example, this is 15 times.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性（FP）**：模型预测为YES且实际值为NO的次数。在我们的例子中，这是15次。'
- en: '**False negatives (FN)**: The number of times that the model predicts NO and
    the actual value is YES. In this example, this is 25 times.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性（FN）**：模型预测为NO且实际值为YES的次数。在这个例子中，这是25次。'
- en: 'Then, we calculate the confusion matrix in the following equation:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们按照以下方程计算混淆矩阵：
- en: '![](img/51beb0b2-3b62-4f8e-a087-ba9830df55b0.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/51beb0b2-3b62-4f8e-a087-ba9830df55b0.png)'
- en: Calculating the Area Under Curve (AUC)
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算曲线下面积（AUC）
- en: The AUC of a classification model is defined as the probability that the model
    will rank a random positive example above a random negative example.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型的AUC定义为模型将随机正例排在随机负例之上的概率。
- en: 'Using the confusion matrix, we can define other quantities as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 使用混淆矩阵，我们可以定义其他量如下：
- en: '![](img/be372292-b22f-486f-a734-9725a417db80.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/be372292-b22f-486f-a734-9725a417db80.png)'
- en: 'The **True Positive Rate** (**TPR**) or sensitivity is the the ratio of data
    points correctly predicted as positive, with respect to all the data points that
    have a true value of *YES*:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**真阳性率（TPR）**或灵敏度是正确预测为正的数据点与具有真实值为*YES*的所有数据点的比率：'
- en: '![](img/7de4c40c-9d05-4c8f-9334-000805b7b8ff.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7de4c40c-9d05-4c8f-9334-000805b7b8ff.png)'
- en: The **False Positive Rate** (**FPR**) or specificity is the ratio of *NO* data
    points incorrectly predicted as *YES*, with respect to all *NO* data points.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**假阳性率（FPR）**或特异性是错误地将*NO*数据点预测为*YES*的比率，与所有*NO*数据点的比率。'
- en: 'Both quantities have values in the [0, 1] range. FPR and TPR are both computed
    at different threshold values and a graph is constructed. The curve is known as
    **Receiving Operating Characteristic** (**ROC**); AUC is the area under that curve,
    as shown in the following figure:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个量都在[0, 1]范围内。FPR和TPR在不同的阈值值下计算，并构建一个图表。这条曲线被称为**接受者操作特征**（**ROC**）；AUC是该曲线下的面积，如图所示：
- en: '![](img/393c0bcf-36a6-4bfa-95e3-6426e56129ea.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/393c0bcf-36a6-4bfa-95e3-6426e56129ea.png)'
- en: If we instead want to evaluate regression models, we can use the following techniques.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想评估回归模型，可以使用以下技术。
- en: Calculating the Mean Absolute Error (MAE)
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算平均绝对误差（MAE）
- en: 'MAE is the mean value of the absolute difference between the real values (*y[j]*)
    and the predicted values (*ŷ[j]*). It cannot tell us the direction of the error,
    meaning that the prediction could be above or below the true value. If we have
    a total of *N* data points, we can calculate MAE as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: MAE是真实值（*y[j]*）和预测值（*ŷ[j]*）之间绝对差值的平均值。它不能告诉我们错误的方向，这意味着预测可能高于或低于真实值。如果我们有总共*N*个数据点，我们可以这样计算MAE：
- en: '![](img/666440a4-f39b-4049-ba24-b597f8d7dce9.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/666440a4-f39b-4049-ba24-b597f8d7dce9.png)'
- en: Calculating the Mean Squared Error (MSE)
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算平均平方误差（MSE）
- en: 'MSE takes the average of the square of the difference between the actual values
    and predicted values:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: MSE取实际值和预测值之间差异的平方的平均值：
- en: '![](img/de88ba04-619c-4baf-a5f4-e21fb32afdba.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/de88ba04-619c-4baf-a5f4-e21fb32afdba.png)'
- en: 'No matter what evaluation method we choose, it is extremely important to take
    into account the business part of the problem. The optimal solution is not always
    to have the most accurate model, but the one that better satisfies your business
    needs. It may be the case that a not-so-accurate model that can be built quickly
    is better than a perfect one that takes a year to produce. Taking into account
    the dataset imbalance and business needs is important for fine-tuning the model
    in order to improve the confusion matrix values:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们选择哪种评估方法，考虑问题的业务部分都极其重要。最佳解决方案不一定是拥有最精确的模型，而是更好地满足您的业务需求的模型。可能的情况是，一个可以快速构建的不是很精确的模型比一个需要一年时间才能完成的完美模型更好。考虑到数据集不平衡和业务需求，对模型进行微调以改进混淆矩阵值是很重要的：
- en: '![](img/72e10596-4454-4a1d-afbe-1be65a1a3d4e.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/72e10596-4454-4a1d-afbe-1be65a1a3d4e.png)'
- en: Another important factor to consider is whether we have, in the case of a classification
    problem, a balanced dataset. A dominant class will lead to a model that mostly
    predicts the same result every time. For example, a dataset with 99% *YES* labels
    will produce a machine learning model after training that predicts *YES* for 99%
    of the input (and it will be right!). There are many known techniques used to
    balance a dataset and find the problems in our data.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的重要因素是，在分类问题的情况下，我们是否有一个平衡的数据集。一个占主导地位的类别将导致一个每次预测结果几乎相同的模型。例如，一个99%
    *YES* 标签的数据集在训练后会产生一个机器学习模型，该模型对99%的输入预测为 *YES*（并且它是正确的！）有许多已知的技巧用于平衡数据集并找出我们数据中的问题。
- en: Summary
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we briefly discussed the learning process for machines, which,
    to some extent, mimics that of human beings. We described how a model, which is
    a simplified representation of the problem that we want to solve, can be used
    to apply machine learning to find a solution.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们简要讨论了机器的学习过程，这在某种程度上模仿了人类的学习过程。我们描述了如何使用一个模型，它是我们想要解决的问题的简化表示，来应用机器学习以找到解决方案。
- en: Using a linear regression model, we built a simple supervised predictive model
    and explained how to use it. We then discussed the difference between regression
    and classification, and showed the properties of the input variables and features.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性回归模型，我们构建了一个简单的监督预测模型，并解释了如何使用它。然后我们讨论了回归和分类之间的区别，并展示了输入变量和特征的性质。
- en: Underfitting and overfitting are two of the main concerns when training a machine
    learning model. We explained what they are and suggested methods to avoid them.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练机器学习模型时，欠拟合和过拟合是两个主要问题。我们解释了它们是什么，并提出了避免它们的方法。
- en: Finally, different types of target variables require different algorithms and
    evaluation methods to test the quality of the model – we discussed this in detail
    in the final sections.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，不同类型的目标变量需要不同的算法和评估方法来测试模型的质量——我们详细讨论了这一点在最后几节。
- en: In the next chapter, we are going to solve some real-life problems using machine
    learning and explore how some supervised and unsupervised models are built.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将使用机器学习来解决一些实际问题，并探讨一些监督学习和无监督模型是如何构建的。
- en: Questions
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the main difference between classical computer programming and machine
    learning?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 经典计算机编程与机器学习的主要区别是什么？
- en: How are models classified, considering the type of target variable?
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到目标变量的类型，模型是如何分类的？
- en: What are the different types of models, depending on how they learn?
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据它们的学习方式，有哪些不同类型的模型？
- en: What are the main steps when creating and using a machine learning model?
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建和使用机器学习模型的主要步骤是什么？
- en: The output of the regression performed in Excel contains information about the
    residuals. What are they and how are they related to the MAE and MSE?
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Excel中执行的回归分析的结果包含关于残差的信息。它们是什么，它们与MAE和MSE有何关系？
- en: Explain underfitting and overfitting.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释欠拟合和过拟合。
- en: How can categorical features be used to feed machine learning models?
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何使用分类特征来为机器学习模型提供数据？
- en: Further reading
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Machine Learning For Beginners*: [https://towardsdatascience.com/machine-learning-for-beginners-d247a9420dab](https://towardsdatascience.com/machine-learning-for-beginners-d247a9420dab)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习入门指南*：[https://towardsdatascience.com/machine-learning-for-beginners-d247a9420dab](https://towardsdatascience.com/machine-learning-for-beginners-d247a9420dab)'
- en: '*Machine Learning basics — It''s your cup of tea*: [https://hackernoon.com/machine-learning-basics-its-your-cup-of-tea-af4baf060ace](https://hackernoon.com/machine-learning-basics-its-your-cup-of-tea-af4baf060ace)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习基础 — 这是你的茶杯里的茶*：[https://hackernoon.com/machine-learning-basics-its-your-cup-of-tea-af4baf060ace](https://hackernoon.com/machine-learning-basics-its-your-cup-of-tea-af4baf060ace)'
