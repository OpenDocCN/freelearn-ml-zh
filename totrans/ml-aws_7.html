<html><head></head><body>
		<div class="Content" id="_idContainer277">
			<p class="hidden">&gt;</p>
		</div>
		<div class="Content" id="_idContainer278">
			<h1 id="_idParaDest-126"><a id="_idTextAnchor132"/>Appendix A</h1>
		</div>
		<div class="Content" id="_idContainer279">
			<h2><a id="_idTextAnchor133"/>About</h2>
			<p>This section is included to assist the students to perform the activities present in the book. It includes detailed steps that are to be performed by the students to complete and achieve the objectives of the book.</p>
		</div>
		<div class="Content" id="_idContainer353">
			<h2 id="_idParaDest-127"><a id="_idTextAnchor134"/>Chapter 1: Introduction to Amazon Web Services</h2>
			<h3 id="_idParaDest-128"><a id="_idTextAnchor135"/>Activity 1: Importing and exporting the data into S3 with the CLI.</h3>
			<ol>
				<li>Verify the configuration is correct by executing, "<strong class="inline">aws s3 ls</strong>" to output your bucket name (bucket name will be unique):<div class="IMG---Figure" id="_idContainer280"><img alt="Figure 1.34: Command line" src="image/image0024.jpg"/></div><h6>Figure 1.34: Command line</h6></li>
				<li>Execute "aws s3 ls &lt;bucket-name&gt;" to output the text file <strong class="inline">pos_sentiment__leaves_of_grass.txt</strong>" in the bucket.<div class="IMG---Figure" id="_idContainer281"><img alt="Figure 1.35: Command line" src="image/image0037.jpg"/></div><h6>Figure 1.35: Command line</h6></li>
				<li>Create a new S3 bucket with the following command (to note: your bucket name needs to be unique. Refer to the S3 <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html">"Rules for Bucket Naming</a>" for specific details):<div class="IMG---Figure" id="_idContainer282"><img alt="Figure 1.36: Command line" src="image/image0044.jpg"/></div><h6>Figure 1.36: Command line</h6></li>
				<li>In the command prompt, navigate to the "<strong class="inline">neg_sentiment__dracula.txt</strong>" location Execute, "<strong class="inline">aws s3 cp neg_sentiment__dracula.txt</strong>" to import the text file to your S3 bucket.<p> </p><div class="IMG---Figure" id="_idContainer283"><img alt="Figure 1.37: Command line" src="image/image0064.jpg"/></div><h6>Figure 1.37: Command line</h6></li>
				<li>Navigate to the "<strong class="inline">peter_pan.txt</strong>" file location with your command line. Import the file "<strong class="inline">peter_pan.txt</strong>" to your S3 bucket (named "<strong class="inline">aws-test-ml-and-ai-two</strong>" in this example) with the following command:<p> </p><div class="IMG---Figure" id="_idContainer284"><img alt="Figure 1.38: Command line" src="image/image0085.jpg"/></div><h6>Figure 1.38: Command line</h6></li>
				<li>Navigate to your Desktop in the command line. Create a new local folder named "<strong class="inline">s3_exported_files</strong>" with the command "<strong class="inline">mkdir s3_exported_files</strong>" <div class="IMG---Figure" id="_idContainer285"><img alt="Figure 1.39: Command line" src="image/image0115.jpg"/></div><h6>Figure 1.39: Command line</h6></li>
				<li>Next, recursively export both files ("<strong class="inline">neg_sentiment__dracula.txt</strong>" and "<strong class="inline">peter_pan.txt</strong>") from the S3 bucket to your local directory with the "- -recursive" parameter. See below for the command's execution.<p> </p><div class="IMG---Figure" id="_idContainer286"><img alt="Figure 1.40: Command line" src="image/image0124.jpg"/></div><h6>Figure 1.40: Command line</h6></li>
				<li>Verify the objects were exported successfully to your local folder with the, "<strong class="inline">dir</strong>" command (see below):</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer287">
					<img alt="Figure 1.8: Output" src="image/image0144.jpg"/>
				</div>
			</div>
			<h6>Figure 1.41: Output</h6>
			<h3 id="_idParaDest-129"><a id="_idTextAnchor136"/>Activity 2: Test Amazon Comprehends API features.</h3>
			<p>In this section, we will learn about display text analysis output using a partial text file input in the API explorer. We will be exploring API's is a skill to save development time by making sure the output is in a desired format for your project. Thus, we will test Comprehend's text analysis features. </p>
			<p>We will consider an example suppose you are an entrepreneur creating a chatbot. You identified a business topic and corresponding text documents with content that will allow the chatbot to make your business successful. Your next step is to identify/verify an AWS service to parse the text document for sentiment, language, key phrases, and entities. Before investing time in writing a complete program, you want to test the AWS service's features via the AWS management console's interface. To ensure that it happen correctly, you will need to have search the web for an article (written in English or Spanish) that contains a subject matter (sports, movies, current events, etc.) that you are interested. And, also AWS Management Console accessible via the root user's account</p>
			<p>You are aware exploring API's is a skill to save development time by making sure the output is in a desired format for your project.</p>
			<ol>
				<li value="1">Click in the <strong class="inline">Search</strong> bar of AWS Services to search the service name<div class="IMG---Figure" id="_idContainer288"><img alt="Figure 1.42:Searching of AWS Service" src="image/image0164.jpg"/></div><h6>Figure 1.42: Searching of AWS Service</h6></li>
				<li>Search the <strong class="inline">Amazon Comprehend</strong> option and select the option you will be directed. Get started screen.<div class="IMG---Figure" id="_idContainer289"><img alt="Figure 1.10: Selecting the Service" src="image/image0184.jpg"/></div><h6>Figure 1.43: Selecting the Service</h6></li>
				<li>You will be directed to the <strong class="inline">API explorer</strong>. Navigation to Topic modeling and Documentation. The middle is a GUI to explore the API, and the right side provides real-time output for text input.<div class="IMG---Figure" id="_idContainer290"><img alt="Figure 1.44: API Explorer " src="image/image0204.jpg"/></div><h6>Figure 1.44: API Explorer</h6></li>
				<li>Click clear text to clear all default services. Navigate to open the following URL in a new tab <a href="http://www.gutenberg.org/cache/epub/1322/pg1322.txt">http://www.gutenberg.org/cache/epub/1322/pg1322.txt</a><div class="IMG---Figure" id="_idContainer291"><img alt="Figure 1.45: API Explorer Screen" src="image/image0224.jpg"/></div><h6>Figure 1.45: API Explorer Screen</h6></li>
				<li>Copy the first poem, and paste it in the Explorer and click Analyze to see the output <div class="IMG---Figure" id="_idContainer292"><img alt="Figure 1.46: Analyzing the Output " src="image/image0244.jpg"/></div><h6>Figure 1.46: Analyzing the Output </h6></li>
				<li>Review the right side of the screen for Entity, Key phrases, Language, and scroll down to view Sentiment. </li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer293">
					<img alt="Figure 1.47: Result" src="image/image0263.jpg"/>
				</div>
			</div>
			<h6>Figure 1.47: Result</h6>
			<p>You now know how to explore an API, and how to display sentiment output for the same.</p>
			<h2 id="_idParaDest-130"><a id="_idTextAnchor137"/>Chapter 2: Summarizing Text Documents Using NLP</h2>
			<h3 id="_idParaDest-131"><a id="_idTextAnchor138"/>Activity 3: Integrating Lambda with Amazon Comprehend to perform text analysis</h3>
			<ol>
				<li value="1">Next, we will upload the "<strong class="inline">test_s3trigger_configured.txt</strong>" file to our S3 bucket to verify the lambda s3_trigger function was configured successfully.</li>
				<li>Navigate to the s3 page: <a href="https://console.aws.amazon.com/s3/">https://console.aws.amazon.com/s3/</a></li>
				<li>Click the bucket name you are using to test the <strong class="inline">s3_trigger</strong> function (in my case: "<strong class="inline">aws-ml-s3-trigger</strong>").<div class="IMG---Figure" id="_idContainer294"><img alt="Figure 2.37: S3 bucket list" src="image/image0284.jpg"/></div><h6>Figure 2.37: S3 bucket list</h6></li>
				<li><strong class="bold">Click</strong> Upload. <div class="IMG---Figure" id="_idContainer295"><img alt="Figure 2.38: S3 bucket list Upload screen" src="image/image0303.jpg"/></div><h6>Figure 2.38: S3 bucket list Upload screen</h6></li>
				<li>The following screen will display.<div class="IMG---Figure" id="_idContainer296"><img alt="Figure 2.39: S3 Upload bucket &quot;add files&quot; screen." src="image/image0323.jpg"/></div><h6>Figure 2.39: S3 Upload bucket "add files" screen.</h6></li>
				<li><strong class="bold">Click</strong> Add files. <div class="IMG---Figure" id="_idContainer297"><img alt="Figure 2.40: S3 Add files selection screen." src="image/image0343.jpg"/></div><h6>Figure 2.40: S3 Add files selection screen.</h6></li>
				<li>Navigate to the "<strong class="inline">test_s3trigger_configured.txt</strong>" file location. Select the file. </li>
				<li><strong class="bold">Navigate</strong> to the text file's location and open the file. The file contains the following text: </li>
				<li>"I am a test file to verify the s3 trigger was successfully configured!"</li>
				<li>Before we execute the s3_trigger, consider the output based on the following aspects of the text: sentiment (positive, negative, or neutral), entities (quantity, person, place, etc.), and key phrases. <h4>Note</h4><p class="callout">The "test_s3trigger_configured.txt" is available at the following GitHub repository: <a href="https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_c/test_s3trigger_configured.txt">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_c/test_s3trigger_configured.txt</a> </p></li>
				<li>Click <strong class="bold">Upload</strong>.<div class="IMG---Figure" id="_idContainer298"><img alt="Figure 2.41: S3 file added to bucket for Lambda trigger test." src="image/image0363.jpg"/></div><h6>Figure 2.41: S3 file added to bucket for Lambda trigger test</h6></li>
				<li>Navigate back to the <strong class="inline">s3_trigger</strong>. <strong class="bold">Click</strong> Monitoring <div class="IMG---Figure" id="_idContainer299"><img alt="Figure 2.42: Select Monitoring tab" src="image/image0382.jpg"/></div><h6>Figure 2.42: Select Monitoring tab</h6></li>
				<li>Click View logs in CloudWatch.<div class="IMG---Figure" id="_idContainer300"><img alt="Figure 2.43: Select the View logs in CloudWatch" src="image/image0401.jpg"/></div><h6>Figure 2.43: Select the View logs in CloudWatch</h6></li>
				<li>Click on <strong class="bold">the Log Stream</strong>.<div class="IMG---Figure" id="_idContainer301"><img alt="Figure 2.44: Select the Log Stream" src="image/image0422.jpg"/></div><h6>Figure 2.44: Select the Log Stream</h6></li>
				<li> Select the circle option next to Text to expand the output:<div class="IMG---Figure" id="_idContainer302"><img alt="Figure 2.9: Click the circle option to expand the lambda output" src="image/image0442.jpg"/></div><h6>Figure 2.9: Click the circle option to expand the lambda output</h6></li>
				<li>Below is the first few lines of the output, and to see the entire output you need to Scroll down to view all of the results (see below).  We will interpret the total output in the next step.<div class="IMG---Figure" id="_idContainer303"><img alt="Figure 2.45: The top portion of the s3_trigger  output" src="image/image0462.jpg"/></div><h6>Figure 2.45: The top portion of the s3_trigger  output</h6></li>
				<li><strong class="bold">Sentiment_response</strong> -&gt; Classified as 60.0% likely to be Positive</li>
				<li>Sentiment_response: <p>{'Sentiment': 'POSITIVE','SentimentScore':{'Positive': 0.6005121469497681,'Negative': 0.029164031147956848, 'Neutral': 0.3588017225265503, 'Mixed': 0.01152205839753151}, </p><p><strong class="bold">entity_response</strong> --&gt; Classified as 70.5% likely the type is Quantity</p><p>entity_response: </p><p>{Entities':[{'Score':0.7053232192993164, 'Type': 'QUANTITY','Text': '3 trigger', 'BeginOffset': 35, 'EndOffset': 44}], </p><p><strong class="bold">key_phases_response</strong>  -&gt; Classified as 89.9% likely "a test file" and 98.5% likely 'the s3 trigger" are the key phrases. </p><p>key_phases_response: </p><p> {'KeyPhrases': [{'Score': 0.8986637592315674, 'Text': 'a test file', 'BeginOffset': 8, 'EndOffset': 19}, {'Score': 0.9852105975151062, 'Text': 'the s3 trigger', 'BeginOffset': 30, 'EndOffset': 44}],</p></li>
			</ol>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor139"/>Chapter 3: Perform Topic Modeling and Theme Extraction</h2>
			<h3 id="_idParaDest-133"><a id="_idTextAnchor140"/>Activity 4: Perform Topic modeling on a set of documents with unknown topics</h3>
			<ol>
				<li value="1">Navigate to following link for obtaining  the text data file that contain negative review comments <a href="https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/localfoldernegative_movie_review_files/cv000_29416.txt">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/localfoldernegative_movie_review_files/cv000_29416.txt</a> </li>
				<li>Navigate to S3: <a href="https://s3.console.aws.amazon.com/s3/home">https://s3.console.aws.amazon.com/s3/home</a> </li>
				<li>Click the bucket for the "<strong class="inline">input-for-topic-modeling</strong>". <div class="IMG---Figure" id="_idContainer304"><img alt="Figure 3.43: S3 home screen for 'input-for-topic-modeling'" src="image/image0481.jpg"/></div><h6>Figure 3.43: S3 home screen for 'input-for-topic-modeling'</h6></li>
				<li>Click Create folder.<div class="IMG---Figure" id="_idContainer305"><img alt="Figure 3.44: Click Create folder" src="image/image050.jpg"/></div><h6>Figure 3.44: Click Create folder</h6></li>
				<li>Type "<strong class="inline">negative_movie_review_files</strong>", and click <strong class="bold">Save</strong>.<div class="IMG---Figure" id="_idContainer306"><img alt="Figure 3.45: Click Save" src="image/image052.jpg"/></div><h6>Figure 3.45: Click Save</h6><h4>Note: </h4><p class="callout">For this step, you may either follow along the exercise and type in the code or obtain it from the source code folder <strong class="inline">text_files_to_s3.py </strong>and paste it into the editor. The source code is available via GitHub in the following repository: <a href="https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/text_files_to_s3.py">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/text_files_to_s3.py</a></p></li>
				<li>Firstly, you will import the os and boto3 packages using the following comment <p class="snippet">import os</p><p class="snippet">import boto3</p></li>
				<li>Next, type in your unique bucket name. <p class="snippet">BUCKET_NAME = '&lt;insert a unique bucket name&gt;' </p><p class="snippet">BUCKET_FOLDER = 'negative_movie_review_files/' </p></li>
				<li>Next, get the working directory of the local path to the text files:<p class="snippet">LOCAL_PATH = os.getcwd() +'\\local_folder__negative_movie_review_files\\'</p></li>
				<li>Create a list of all text files:<p class="snippet">text_files_list = [f for f in os.listdir(LOCAL_PATH) if f.endswith('.txt')]</p></li>
				<li>Iterate on all files, and upload each to s3:<p class="snippet">for filename in text_files_list:</p><p class="snippet">    s3.upload_file(LOCAL_PATH + filename, BUCKET_NAME, BUCKET_FOLDER + filename)</p></li>
				<li>Next, in your command prompt, navigate into to the "<strong class="inline">activity__topic_modeling_on_documents</strong>" directory and execute the code with the following: python <strong class="inline">text_files_to_s3.py</strong></li>
				<li>The result is 1000 text files uploaded to the S3 <strong class="inline">negative_movie_review_files</strong> folder. See below for the top S3 output (see below):<div class="IMG---Figure" id="_idContainer307"><img alt="Figure 3.47: negative_movie_review_files in S3" src="image/image054.jpg"/></div><h6>Figure 3.47: negative_movie_review_files in S3</h6></li>
				<li>Next, navigate to AWS Comprehend. Click the comprehend link: <a href="https://console.aws.amazon.com/comprehend/home">https://console.aws.amazon.com/comprehend/home</a>.<div class="IMG---Figure" id="_idContainer308"><img alt="Figure 3.48: Amazon Comprehend home screen" src="image/image056.jpg"/></div><h6>Figure 3.48: Amazon Comprehend home screen</h6></li>
				<li>Now, click on the <strong class="bold">Organization</strong>.<div class="IMG---Figure" id="_idContainer309"><img alt="Figure 3.49: Select Organization" src="image/image058.jpg"/></div><h6>Figure 3.49: Select Organization</h6></li>
				<li>Now, click on the Create job.<div class="IMG---Figure" id="_idContainer310"><img alt="Figure 3.50: Click Create job" src="image/image060.jpg"/></div><h6>Figure 3.50: Click Create job</h6></li>
				<li>Now, type "<strong class="inline">unknown_topic_structure_job</strong>" in the Name input field.<div class="IMG---Figure" id="_idContainer311"><img alt="Figure 3.51: Enter 'unknown_topic_strucutre_job'" src="image/image062.jpg"/></div><h6>Figure 3.51: Enter 'unknown_topic_strucutre_job'</h6></li>
				<li>Now, scroll down to the Choose input data section, and click Search.<div class="IMG---Figure" id="_idContainer312"><img alt="Figure 3.52: Select Search button" src="image/image064.jpg"/></div><h6>Figure 3.52: Select Search button</h6></li>
				<li>Click the arrow next to bucket you selected to input files for topic modeling ("<strong class="inline">aws-ml-input-for-topic-modeling</strong>"). <div class="IMG---Figure" id="_idContainer313"><img alt="Figure 3.53: Expand S3 bucket sub-folders" src="image/image066.jpg"/></div><h6>Figure 3.53: Expand S3 bucket sub-folders</h6></li>
				<li>Click the circle next to the "<strong class="inline">negative_movie_review_files</strong>" folder.<div class="IMG---Figure" id="_idContainer314"><img alt="Figure 3.54: Select the negative_movie_review_files folder" src="image/image068.jpg"/></div><h6>Figure 3.54: Select the negative_movie_review_files folder</h6></li>
				<li>Now, click Select to choose the file.<div class="IMG---Figure" id="_idContainer315"><img alt="Figure 3.55: Click the Select button" src="image/image070.jpg"/></div><h6>Figure 3.55: Click the Select button</h6></li>
				<li>You will be redirected to the Amazon Comprehend main page. Select "<strong class="bold">One document per file</strong>" selection from the Input format drop down.<div class="IMG---Figure" id="_idContainer316"><img alt="Figure 3.56: Select One document per file option" src="image/image072.jpg"/></div><h6>Figure 3.56: Select One document per file option</h6></li>
				<li> Next, enter 40 in the Number of topics input field.<div class="IMG---Figure" id="_idContainer317"><img alt="Figure 3.57: Enter 40 topics" src="image/image074.jpg"/></div><h6>Figure 3.57: Enter 40 topics</h6></li>
				<li>Scroll down to the Choose output location, and click Search <div class="IMG---Figure" id="_idContainer318"><img alt="Figure 3.58: Click Search" src="image/image076.jpg"/></div><h6>Figure 3.58: Click Search</h6></li>
				<li>Select the output bucket you uniquely named for the topic modeling output.<div class="IMG---Figure" id="_idContainer319"><img alt="Figure 3.59: Select the S3 bucket for the topic modeling outtput" src="image/image078.jpg"/></div><h6>Figure 3.59: Select the S3 bucket for the topic modeling outtput</h6></li>
				<li>Click on the Select button.<div class="IMG---Figure" id="_idContainer320"><img alt="Figure 3.60: Confirm by clicking the Select button" src="image/image080.jpg"/></div><h6>Figure 3.60: Confirm by clicking the Select button</h6></li>
				<li>Click the dropdown and select the "<strong class="inline">AmazonComprehendServiceRole-myTopicModeingRole</strong>" IAM role.<div class="IMG---Figure" id="_idContainer321"><img alt="Figure 3.61: Select the existing IAM role" src="image/image082.jpg"/></div><h6>Figure 3.61: Select the existing IAM role</h6></li>
				<li>Click on <strong class="bold">Create</strong> job button.<div class="IMG---Figure" id="_idContainer322"><img alt="Figure 3.62: Click Create job&#13;&#10;" src="image/image084.jpg"/></div><h6>Figure 3.62: Click Create job</h6></li>
				<li>The topic modeling job status will first display "<strong class="bold">Submitted</strong>."<div class="IMG---Figure" id="_idContainer323"><img alt="Figure 3.63: Status 'Submitted&quot;&#13;&#10;" src="image/image088.jpg"/></div><h6>Figure 3.63: Status 'Submitted"</h6></li>
				<li>The topic modeling job status will next display "<strong class="bold">In progress</strong>". The topic modeling job duration is about 6 minutes.<div class="IMG---Figure" id="_idContainer324"><img alt="Figure 3.64: &quot;In progress&quot; status" src="image/image0881.jpg"/></div><h6>Figure 3.64: "In progress" status</h6></li>
				<li>When the status changes to "Completed." Click the "<strong class="inline">unknown_topic_structure_job</strong>" link. <div class="IMG---Figure" id="_idContainer325"><img alt="Figure 3.65: Select the hyperlinked topic modeling link" src="image/image090.jpg"/></div><h6>Figure 3.65: Select the hyperlinked topic modeling link</h6></li>
				<li>Scroll down and click the topic modeling output hyperlink (*yours will display a different unique topic modeling job alphanumeric character string). <div class="IMG---Figure" id="_idContainer326"><img alt="Figure 3.66: Click the topic modeling output S3 location&#13;&#10;" src="image/image092.jpg"/></div><h6>Figure 3.66: Click the topic modeling output S3 location</h6></li>
				<li>You will be directed to the S3 output folder for the topic modeling job. Click the hyperlinked folder.<div class="IMG---Figure" id="_idContainer327"><img alt="Figure 3.67: Hyperlinked folder location" src="image/image094.jpg"/></div><h6>Figure 3.67: Hyperlinked folder location</h6></li>
				<li>Click the output folder.<div class="IMG---Figure" id="_idContainer328"><img alt="Figure 3.68: Click output" src="image/image096.jpg"/></div><h6>Figure 3.68: Click output</h6></li>
				<li>Click the <strong class="inline">output.tar.gz</strong> file.<div class="IMG---Figure" id="_idContainer329"><img alt="Figure 3.69: Click output.tar.gz file" src="image/image098.jpg"/></div><h6>Figure 3.69: Click output.tar.gz file</h6></li>
				<li>Click on Download as.<div class="IMG---Figure" id="_idContainer330"><img alt="Figure 3.70: Click Download as" src="image/image100.jpg"/></div><h6>Figure 3.70: Click Download as</h6></li>
				<li> Right-click the <strong class="inline">output.tar.gz</strong> file and click <strong class="bold">Save</strong> link as…<div class="IMG---Figure" id="_idContainer331"><img alt="Figure 3.71: Select Save link as..." src="image/image102.jpg"/></div><h6>Figure 3.71: Select Save link as...</h6></li>
				<li>Select the Desktop and click Save.<div class="IMG---Figure" id="_idContainer332"><img alt="Figure 3.72: Click Save" src="image/image104.jpg"/></div><h6>Figure 3.72: Click Save</h6></li>
				<li>Navigate to the Desktop. Right-click the output.tar.gz file and select <strong class="bold">Extract Here</strong>. Right-click the output.tar file and select Extract  Here<div class="IMG---Figure" id="_idContainer333"><img alt="Figure 3.73: Select Extract Here" src="image/image106.jpg"/></div><h6>Figure 3.73: Select Extract Here</h6></li>
				<li>The result is two CSV files: <strong class="inline">doc-topics.csv</strong> and <strong class="inline">topic-terms.csv</strong>. Click and download the topic modeling output.<p>For Reference the extracted CSV files are available via the following GitHub directory:</p><p><a href="https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/SOLUTION__topic_modeling_output/doc-topics.csv">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/SOLUTION__topic_modeling_output/doc-topics.csv</a> </p><p><a href="https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/SOLUTION__topic_modeling_output/topic-terms.csv">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/SOLUTION__topic_modeling_output/topic-terms.csv</a></p><h4> Note</h4><p class="callout">For this step, you may either follow along the exercise and type in the code or obtain it from the source code folder in the file <strong class="inline">local_csv_to_s3_for_analysis.py</strong> and paste it into an editor. For reference, the source code is available via GitHub in the following repository:<a href="https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/local_csv_to_s3_for_analysis.py">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson3/activity/local_csv_to_s3_for_analysis.py</a></p></li>
				<li>Firstly, we will  Import boto3<p class="snippet">import boto3</p></li>
				<li>Next, import pandas<p class="snippet">import pandas as pd </p></li>
				<li>Create the S3 client object. <p class="snippet">s3 = boto3.client('s3')</p></li>
				<li>Next, create a unique name for the s3 bucket to store your source CSV files. Here, the selected "<strong class="inline">unknown-tm-analysis</strong>" but you will need to create a unique name.<p class="snippet">bucket_name = '&lt;insert a unique bucket name&gt;' #  </p></li>
				<li>Next, create a new bucket.<p class="snippet">s3.create_bucket(Bucket=bucket_name)</p></li>
				<li>Create a list of the CSV file names to import.<p class="snippet">filenames_list = ['doc-topics.csv', 'topic-terms.csv']</p></li>
				<li>Iterate on each file to upload to S3<p class="snippet">for filename in filenames_list:</p><p class="snippet">    s3.upload_file(filename, bucket_name, filename)</p></li>
				<li>Next, check if the filename is '<strong class="inline">doc-topics.csv</strong>'<p class="snippet">    if filename == 'doc-topics.csv':</p></li>
				<li>Now, get the <strong class="inline">doc-topics.csv</strong> file object and assign it to the '<strong class="inline">obj</strong>' variable.  <p class="snippet">obj = s3.get_object(Bucket=bucket_name, Key=filename)</p></li>
				<li>Next, read the csv obj and assign it to the <strong class="inline">doc_topics variable</strong>. <p class="snippet">        doc_topics = pd.read_csv(obj['Body'])</p><p class="snippet">    else:</p><p class="snippet">        obj = s3.get_object(Bucket=bucket_name, Key=filename)</p><p class="snippet">        topic_terms = pd.read_csv(obj['Body'])</p></li>
				<li> Merge files on topic column to obtain the most common terms per document.<p class="snippet">merged_df = pd.merge(doc_topics, topic_terms, on='topic')</p></li>
				<li>Print the <strong class="inline">merged_df</strong> to the console<p class="snippet">print(merged_df) </p></li>
				<li>Next, navigate to the location of the CSV's in a command prompt, and execute the code with the following command: <p class="snippet">"python local_csv_to_s3_for_analysis.py"</p></li>
				<li>The console output is a merged dataframe that provides the docnames with their respective terms and the term's weights (see below):</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer334">
					<img alt="Figure 3.74: Activity merged topic modeling output" src="image/image108.jpg"/>
				</div>
			</div>
			<h6>Figure 3.74: Activity merged topic modeling output</h6>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor141"/>Chapter 4: Creating a Chatbot with Natural Language</h2>
			<h3 id="_idParaDest-135"><a id="_idTextAnchor142"/>Activity 5: Creating a custom bot and configure the bot</h3>
			<ol>
				<li value="1">If you are creating your first bot, choose <strong class="bold">Get Started</strong>. Otherwise, choose Bots, and then choose <strong class="bold">Create</strong>.</li>
				<li>On the <strong class="bold">Create</strong> your <strong class="bold">Lex bot</strong> page, choose Custom bot and provide the following information:<ul><li><strong class="keyword">App name</strong>: PizzaOrderingBot</li><li><strong class="keyword">Output voice</strong>: Salli</li><li><strong class="keyword">Session timeout</strong> : 5 minutes.</li><li><strong class="keyword">Child-Directed</strong>: Choose the appropriate response.</li></ul></li>
				<li>Choose <strong class="bold">Create</strong>.</li>
				<li>The console sends Amazon Lex a request to create a new bot. Amazon Lex sets the bot version to <strong class="inline">$LATEST</strong>. After creating the bot, Amazon Lex shows the bot <strong class="inline">Editortab</strong>:<div class="IMG---Figure" id="_idContainer335"><img alt="Figure 4.50: EditorTab" src="image/image109.jpg"/></div><h6>Figure 4.50: EditorTab</h6></li>
				<li>In the Amazon Lex console, choose the plus sign (+) next to Intents, and then choose <strong class="bold">Create</strong> new intent.</li>
				<li>In the <strong class="bold">Create</strong> intent dialog box, type the name of the intent (<strong class="inline">OrderPizza</strong>), and then choose <strong class="bold">Add</strong>.</li>
				<li>In the left menu, choose the plus sign (<strong class="bold">+</strong>) next to Slot types. In the <strong class="bold">Add</strong> slot type dialog box, add the following:<ul><li><strong class="keyword">Slot type name</strong> – Crusts</li><li><strong class="keyword">Description</strong> – Available crusts</li></ul></li>
				<li>Choose Restrict to Slot values and Synonyms<ul><li><strong class="keyword">Value</strong> – Type thick. Press tab and in the Synonym field type stuffed. Choose the plus sign (+). Type thin and then choose the plus sign (<strong class="bold">+</strong>) again.<p>The dialog should look like this:</p></li></ul></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer336">
					<img alt="Figure 4.51: Dialog box for slot" src="image/image110.jpg"/>
				</div>
			</div>
			<h6>Figure 4.51: Dialog box for slot</h6>
			<ol>
				<li value="9">Choose <strong class="bold">Add slot to intent</strong>.</li>
				<li>On the <strong class="bold">Intent</strong> page, choose <strong class="bold">Required</strong>. Change the name of the slot from <strong class="inline">slotOne</strong> to <strong class="inline">crust</strong>. Change the prompt to <strong class="inline">What kind of crust would you like</strong>?</li>
				<li>Repeat Step 1 through Step 4 using the values in the following table:<div class="IMG---Figure" id="_idContainer337"><img alt="Figure 4.53: Value for slot and prompt" src="image/image112.jpg"/></div><h6>Figure 4.53: Value for slot and prompt</h6></li>
				<li>On the OrderPizza configuration page, configure the intent as follows:</li>
				<li>Sample utterances – Type the following strings. The curly braces {} enclose slot names.<ul><li>I want to order pizza please</li><li>I want to order a pizza</li><li>I want to order a {pizzaKind} pizza</li><li>I want to order a {size} {pizzaKind} pizza</li><li>I want a {size} {crust} crust {pizzaKind} pizza</li><li>Can I get a pizza please</li><li>Can I get a {pizzaKind} pizza</li><li>Can I get a {size} {pizzaKind} pizza</li></ul></li>
				<li><strong class="bold">Lambda initialization and validation</strong> – Leave the default setting.</li>
				<li><strong class="bold">Confirmation prompt</strong> – Leave the default setting.</li>
				<li><strong class="bold">Fulfillment</strong> – Perform the following tasts:<ul><li>Choose AWS <strong class="inline">Lambda function</strong>.</li><li>Choose <strong class="inline">PizzaOrderProcessor</strong>.</li><li>If the <strong class="bold">Add</strong> permission to Lambda function dialog box is shown, choose <strong class="bold">OK</strong> to give the <strong class="inline">OrderPizza</strong> intent permission to call the <strong class="inline">PizzaOrderProcessorLambda</strong> function.</li><li>Leave <strong class="bold">None</strong> selected.<p>The intent should look like the following:</p></li></ul></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer338">
					<img alt="Figure 4.54: Utterance and slot editor" src="image/image113.jpg"/>
				</div>
			</div>
			<h6>Figure 4.54: Utterance and slot editor</h6>
			<ol>
				<li value="17">Configure error handling for the <strong class="inline">PizzaOrderingBot</strong> bot.</li>
				<li>Navigate to the <strong class="inline">PizzaOrderingBot</strong> bot. Choose Editor. And  then choose <strong class="inline">Error Handling</strong>.<div class="IMG---Figure" id="_idContainer339"><img alt="Figure 4.55: Editor for bot" src="image/image115.jpg"/></div><h6>Figure 4.55: Editor for bot</h6></li>
				<li>Use the Editor tab to configure bot error handling.<ul><li>Information you provide in Clarification Prompts maps to the bot's clarificationPrompt configuration.</li><li>When Amazon Lex can't determine the user intent, the service returns a response with this message</li><li>Information that you provide in the Hang-up phrase maps to the bot's abortStatement configuration.</li><li>If the service can't determine the user's intent after a set number of consecutive requests, Amazon Lex returns a response with this message.</li></ul></li>
				<li>Leave the defaults.</li>
				<li>To build the <strong class="inline">PizzaOrderingBot</strong> bot, choose <strong class="bold">Build</strong>.</li>
				<li>Amazon Lex builds a machine-learning model for the bot. When you test the bot, the console uses the runtime API to send the user input back to Amazon Lex. Amazon Lex then uses the machine learning model to interpret the user input.It can take some time to complete the build.</li>
				<li>To test the bot, in the Test Bot window, start communicating with your Amazon Lex bot. For example, you might say or type:<div class="IMG---Figure" id="_idContainer340"><img alt="Figure 4.56: Test Bot" src="image/image117.jpg"/></div><h6>Figure 4.56: Test Bot</h6></li>
				<li>Use the sample utterances that you con<a id="_idTextAnchor143"/>figured in the <strong class="inline">OrderPizza</strong> intent to test the bot. For example, the following is one of the sample utterances that you configured for the PizzaOrder intent:</li>
			</ol>
			<p class="snippet">I want a {size} {crust} crust {pizzaKind} pizza</p>
			<p>To test it, type the following:</p>
			<p class="snippet">I want a large thin crust cheese pizza</p>
			<p>When you type "I want to order a pizza," Amazon Lex detects the intent (<strong class="inline">OrderPizza</strong>). Then, Amazon Lex asks for slot information.After you provide all of the slot information, Amazon Lex invokes the Lambda function that you configured for the intent.The Lambda function returns a message ("Okay, I have ordered your ...") to Amazon Lex, which Amazon Lex returns to you..</p>
			<p><strong class="bold">Inspecting the Response</strong></p>
			<p>Underneath the chat window is a pane that enables you to inspect the response from Amazon Lex. The pane provides comprehensive information about the state of your bot that changes as you interact with your bot.</p>
			<p>The contents of the pane show you the current state of the operation.</p>
			<p><strong class="bold">Dialog State</strong> – The current state of the conversation with the user. It can be ElicitIntent, ElicitSlot, ConfirmIntent or Fulfilled.</p>
			<p><strong class="bold">Summary</strong> – Shows a simplified view of the dialog that shows the slot values for the intent being fulfilled so that you can keep track of the information flow. It shows the intent name, the number of slots and the number of slots filled, and a list of all of the slots and their associated values.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer341">
					<img alt="Figure 4.57: Summary inspect Response" src="image/image119.jpg"/>
				</div>
			</div>
			<h6>Figure 4.57: Summary inspect Response</h6>
			<p><strong class="bold">Detail</strong> – Shows the raw JSON response from the chatbot to give you a deeper view into the bot interaction and the current state of the dialog as you test and debug your chatbot. If you type in the chat window, the inspection pane shows the JSON response from the <a href="https://docs.aws.amazon.com/lex/latest/dg/API_runtime_PostText.html">PostText</a> operation. If you speak to the chat window, the inspection pane shows the response headers from the <a href="https://docs.aws.amazon.com/lex/latest/dg/API_runtime_PostContent.html">PostContent</a> operation.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer342">
					<img alt="Figure 4.58: Detail inspect response" src="image/image121.jpg"/>
				</div>
			</div>
			<h6>Figure 4.58: Detail inspect response</h6>
			<h2 id="_idParaDest-136"><a id="_idTextAnchor144"/>Chapter 5: Using Speech with the Chatbot</h2>
			<h3 id="_idParaDest-137"><a id="_idTextAnchor145"/>Activity 6: Creating a custom bot and connect the bot with Amazon Connect</h3>
			<p><strong class="bold">Create an Amazon Lex bot</strong></p>
			<p>Create a custom bot to demonstrate the Press or Say integration with Amazon Connect. The bot prompts callers to press or say a number that matches the menu option for the task to complete. In this case, the input is checking their account balance.</p>
			<ol>
				<li value="1">Open the <a href="https://console.aws.amazon.com/lex/">Amazon Lex console</a>.</li>
				<li>If you are creating your first bot, choose Get Started. Otherwise, choose Bots, Create.</li>
				<li>On the Create your Lex bot page, choose Custom bot and provide the following information:<ul><li><strong class="keyword">Bot name</strong> – For this demo, name the bot AccountBalance.</li><li><strong class="keyword">Output voice</strong> – Select the voice for your bot to use when speaking to callers. The default voice for Amazon Connect is Joana.</li><li><strong class="keyword">Session timeout</strong> – Choose how long the bot should wait to get input from a caller before ending the session.</li><li><strong class="keyword">COPPA</strong> – Choose whether the bot is subject to the Child Online Privacy Protection Act.</li><li><strong class="keyword">User utterance storage</strong> – Choose Store</li></ul></li>
				<li>Choose <strong class="bold">Create</strong>.</li>
			</ol>
			<p><strong class="bold">Configure the Amazon Lex bot</strong></p>
			<p>Determine how the bot responds to customers by providing intents, sample utterances, slots for input, and error handling.</p>
			<ol>
				<li value="1"><strong class="bold">Create</strong> intents<p>For this example, configure the bot with two intents: one to look up account information, and another to speak with an agent.</p><ul><li>Choose the <strong class="bold">+</strong> icon next to Intents, and choose Create new intent.</li><li>Name the intent <strong class="inline">AccountLookup</strong>.</li><li>Create another <strong class="inline">intent</strong>, and name it <strong class="inline">SpeakToAgent</strong>.</li></ul></li>
				<li><strong class="bold">Add</strong> sample utterances<p>After defining the intents, add some sample utterances.</p><ul><li>Select the <strong class="inline">AccountLookup</strong> intent.</li><li>Add a sample utterance, such as "<strong class="inline">Check my account balance</strong>" (don't include the quotes), and choose the <strong class="inline">+</strong> icon.</li><li>Add a second utterance, "<strong class="inline">One</strong>" (without the quotes), and choose the <strong class="bold">+</strong> icon.<br/>This assigns the utterance of "one" or key press of "1" to the AccountLookup intent.</li></ul></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer343">
					<img alt="Figure 5.29: Sample utterance " src="image/image123.jpg"/>
				</div>
			</div>
			<h6>Figure 5.29: Sample utterance </h6>
			<ul>
				<li>Select <strong class="inline">SpeakToAgent</strong>.</li>
				<li>Add a sample utterance, such as "<strong class="inline">Speak to an agent</strong>," and choose <strong class="bold">+</strong>.</li>
				<li>Add a second utterance, "<strong class="bold">Two</strong>" (without the quotes), and choose + icon.</li>
			</ul>
			<ol>
				<li value="3"><strong class="bold">Add</strong> slots<p>Before the bot can respond with the caller's account balance, it needs the account number.</p><ul><li>Under Slots, add a slot named AccountNumber.</li><li>For Slot type, select AMAZON.NUMBER.</li><li>For Prompt, add the text to be spoken when the call is answered. To highlight the new DTMF support, ask callers to enter their account number using their keypad. For example, "<strong class="inline">Using your touch-tone keypad, please enter your account number</strong>."</li><li>Make sure that the Required check box is selected, and choose the + icon.</li></ul></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer344">
					<img alt="Figure 5.30: Slot Addition" src="image/image125.jpg"/>
				</div>
			</div>
			<h6>Figure 5.30: Slot Addition</h6>
			<ol>
				<li value="4"><strong class="bold">Add </strong>responses<p>Now that you have intents, utterances, and a slot, add the responses that the bot provides to callers. Because you are creating a simple bot for this example, you are not hooking up the bot to look up real customer data. The example bot responds with text strings that you add, regardless of the account number that a caller provides.</p><ul><li>Select the <strong class="inline">AccountLookup</strong> intent.</li><li>In the Response section, add a message for the bot to say to customers. For example, "<strong class="inline">The balance for your account is $2,586.34</strong>."</li><li>Choose Save Intent.</li><li>For the <strong class="inline">SpeakToAgent</strong> intent, add a message that lets callers know that their call is being connected to an agent. For example, "<strong class="inline">Okay, an agent will be with you shortly</strong>."</li><li>Choose <strong class="bold">Save</strong> Intent.</li></ul></li>
				<li>Build and Test the Amazon Lex bot<p>After you create your bot, make sure it works as intended before you publish it.</p><ul><li>To enable the Test Bot window, choose Build. It may take a minute or two.</li><li>When it is finished building, choose Test Chatbot.<div class="IMG---Figure" id="_idContainer345"><img alt="Figure 5.31: Publish bot" src="image/image127.jpg"/></div></li></ul></li>
			</ol>
			<h6>Figure 5.31: Publish bot</h6>
			<ul>
				<li>In the Test Chatbot pane, type messages in the chat window.</li>
				<li>To test the AccountLookup intent, type "1" (without the quotes), and then type an account number.</li>
			</ul>
			<div>
				<div class="IMG---Figure" id="_idContainer346">
					<img alt="Figure 5.32: Test Bot" src="image/image129.jpg"/>
				</div>
			</div>
			<h6>Figure 5.32: Test Bot</h6>
			<ul>
				<li>To confirm that the SpeakToAgent intent is working, type "2" (without the quotes).</li>
			</ul>
			<ol>
				<li value="6">Publish the Amazon Lex bot and create an alias<ul><li>Next, publish the bot so that you can add it to a contact flow in Amazon Connect.</li><li>Choose <strong class="bold">Publish</strong>.</li><li>Provide an alias for your bot. Use the alias to specify this version of the bot in the contact flow, for example, Blog.</li><li>Choose <strong class="bold">Publish</strong>.</li></ul></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer347">
					<img alt="Figure 5.33: Publish Bot" src="image/image131.jpg"/>
				</div>
			</div>
			<h6>Figure 5.33: Publish Bot</h6>
			<ol>
				<li value="7">Add the Amazon Lex bot to an Amazon Connect instance<ul><li>To use a bot in your contact flow, add the bot to your Amazon Connect instance. You can only add bots created under the same AWS account and in the same Region as your instance.</li><li>Open the <a href="https://aws.amazon.com/connect/">Amazon Connect console</a>.</li><li>Select the Instance Alias of the instance to which to add the bot.</li><li>Choose Contact flows.</li><li>Under Amazon Lex, choose <strong class="bold">+ Add</strong> Lex Bot.</li><li>Select the <strong class="inline">AccountBalance</strong> bot and choose Save Lex Bots. If you published the bot after you opened the settings for your instance, reload the page to get it to show up.</li></ul></li>
				<li>Create a contact flow and add your Amazon Lex bot<p>Next, create a new contact flow that uses your Amazon Lex bot. Create the contact flow When you create the contact flow, you can configure the message played to callers.</p><ul><li>Log in to your Amazon Connect instance with an account that has permissions for contact flows and Amazon Lex bots.</li><li>Choose <strong class="inline">Routing</strong>, <strong class="inline">Contact flows</strong>, <strong class="inline">Create contact flow</strong>, and <strong class="inline">type a name</strong>.</li><li>Under Interact, drag a Get customer input block onto the designer, and connect it to the Entry point block.</li><li>Open the Get customer input block, and choose Text to speech (Ad hoc), Enter text.</li><li>Type a message that provides callers with information about what they can do. For example, use a message that matches the intents used in the bot, such as "To check your account balance, press or say 1. To speak to an agent, press or say 2."</li></ul></li>
				<li>Add the Amazon Lex bot to your contact flow<p>The bot is defined as the method of getting customer input.</p><ul><li>In the Get customer input block, select Amazon Lex.</li><li>For Name, use <strong class="inline">AccountBalance</strong>. For Alias, use <strong class="bold">Blog</strong>.</li><li>To specify the intents, choose Add a parameter under Intents.</li><li>Type AccountLookup, and choose Add another parameter.</li><li>Type SpeakToAgent, and choose Save.</li></ul></li>
				<li>Finish the contact flow<ul><li>After the caller interacts with the bot, finish the contact flow to complete the call for the customer.</li><li>If the caller presses 1 to get their account balance, use a Prompt block to play a message and disconnect the call.</li><li>If the caller presses 2 to speak to an agent, use a Set queue block to set the queue and transfer the caller to the queue, which ends the contact flow.</li><li>To complete the AccountLookup intent:</li><li>Under Interact, drag a Play prompt block to the designer, and connect the AccountLookup node of the Get customer input block to it. After the customer gets their account balance from the Amazon Lex bot, the message in the Play prompt block plays.</li><li>Under Terminate/Transfer, drag a Disconnect / hang up block to the designer, and connect the Play prompt block to it. After the prompt message plays, the call is disconnected.</li><li>To complete the <strong class="inline">SpeakToAgent </strong>intent:</li><li>Add a Set queue block and connect it to the <strong class="inline">SpeakToAgent</strong> node of the Get customer input block.</li><li>Add a Transfer to queue block and connect the Set queue block Success and Error nodes to it. You could also add a message that plays when the call cannot be transferred because the queue is full or an error occurs.</li><li>Choose <strong class="bold">Save</strong> &amp; <strong class="bold">Publish</strong>.<p>Your finished contact flow looks something like the following:</p></li></ul></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer348">
					<img alt="Figure 5.34: Contact Flow" src="image/image133.jpg"/>
				</div>
			</div>
			<h6>Figure 5.34: Contact Flow</h6>
			<ol>
				<li value="11">Assign the contact flow to a phone number<ul><li>When callers call in to your contact center, the contact flow to which they are sent is the one assigned to the telephone number that they dialed. To make the new contact flow active, assign it to a phone number for your instance.</li><li>Open the Amazon Connect Dashboard.</li><li>Choose View phone numbers.</li><li>Select the phone number to which to assign the contact flow.</li><li>Add a description.</li><li>In the Contact flow/IVR menu, choose the contact flow that you just created.</li><li>Choose <strong class="bold">Save</strong>.</li></ul></li>
			</ol>
			<h2 id="_idParaDest-138"><a id="_idTextAnchor146"/>Chapter 6: Analyzing Images with Computer Vision</h2>
			<h3 id="_idParaDest-139"><a id="_idTextAnchor147"/>Activity 7: Compare faces in your own images</h3>
			<div>
				<div class="IMG---Figure" id="_idContainer349">
					<img alt="Figure 6.49: First provided images for Face comparison" src="image/image135.jpg"/>
				</div>
			</div>
			<h6>Figure 6.49: First provided images for Face comparison</h6>
			<ol>
				<li value="1">Rekognition is able to recognize that the faces are of the same person with a 98% degree of confidence, even with different angles, lighting and position of glasses on the face<div class="IMG---Figure" id="_idContainer350"><img alt="Figure 6.50: Results for first provided images for Face comparison" src="image/image137.jpg"/></div><h6>Figure 6.50: Results for first provided images for Face comparison</h6></li>
				<li>The second set of images are: <a href="https://images.unsplash.com/photo-1526510747491-58f928ec870f?w=600">https://images.unsplash.com/photo-1526510747491-58f928ec870f?w=600</a> and <a href="https://images.unsplash.com/photo-1529946179074-87642f6204d7?w=600">https://images.unsplash.com/photo-1529946179074-87642f6204d7?w=600</a> .<div class="IMG---Figure" id="_idContainer351"><img alt="Figure 6.51: Second provided images for Face comparison" src="image/image138.jpg"/></div><h6>Figure 6.51: Second provided images for Face comparison</h6></li>
				<li>Once again, Rekognition recognizes the faces with a <strong class="bold">96%</strong> degree of confidence, even at different angles.</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer352">
					<img alt="Figure 6.52:  Results for second provided images for Face comparison" src="image/image140.jpg"/>
				</div>
			</div>
			<h6>Figure 6.52:  Results for second provided images for Face comparison</h6>
		</div>
	</body></html>