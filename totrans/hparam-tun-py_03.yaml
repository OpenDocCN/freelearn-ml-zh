- en: '*Chapter 2:* Introducing Hyperparameter Tuning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every **machine learning** (**ML**) project should have a clear goal and success
    metrics. The success metrics can be in the form of business and/or technical metrics.
    Evaluating business metrics is hard, and often, they can only be evaluated after
    the ML model is in production. On the other hand, evaluating technical metrics
    is more straightforward and can be done during the development phase. We, as ML
    developers, want to achieve *the best technical metrics that we can get* since
    this is something that we can optimize.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll learn one out of several ways to optimize the chosen
    technical metrics, called **hyperparameter tuning**. We will start this chapter
    by understanding what hyperparameter tuning is, along with its goal. Then, we'll
    discuss the difference between a hyperparameter and a parameter. We'll also learn
    the concept of hyperparameter space and possible distributions of hyperparameter
    values that you may find in practice.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will understand the concept of hyperparameter
    tuning and hyperparameters themselves. Understanding these concepts is crucial
    for you to get a bigger picture of what will be discussed in the next chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll be covering the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is hyperparameter tuning?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demystifying hyperparameters versus parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding hyperparameter space and distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is hyperparameter tuning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Hyperparameter tuning** is a process whereby we search for the best set of
    hyperparameters of an ML model from all of the candidate sets. It is the process
    of optimizing the technical metrics we care about. The goal of hyperparameter
    tuning is simply to get the *maximum evaluation score* on the validation set *without
    causing an overfitting issue*.'
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning is one of the *model-centric* approaches to optimizing
    a model's performance. In practice, it is suggested to *prioritize data-centric*
    approaches over a model-centric approach when it comes to optimizing a model's
    performance. Data-centric means that we are focusing on cleaning, sampling, augmenting,
    or modifying the data, while model-centric means that we are focusing on the model
    and its configuration.
  prefs: []
  type: TYPE_NORMAL
- en: To understand why data-centric is prioritized over model-centric, let's say
    you are a cook in a restaurant. When it comes to cooking, no matter how expensive
    and fancy your kitchen setups are, if the ingredients are not in a good condition,
    it's impossible to serve high-quality food to your customers. In that analogy,
    ingredients refer to the data, and kitchen setups refer to the model and its configuration.
    No matter how fancy and complex our model is, if we do not have good data or features
    in the first place, then we can't achieve the maximum evaluation score. This is
    expressed in the famous saying, **garbage in, garbage out** (**GIGO**).
  prefs: []
  type: TYPE_NORMAL
- en: In model-centric approaches, hyperparameter tuning is performed after we have
    found the most suitable model framework or architecture. So, it can be said that
    *hyperparameter tuning is the ultimate step* in optimizing the model's performance.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you are aware of hyperparameter tuning and its purpose, let's discuss
    hyperparameters themselves What actually is a hyperparameter? What is the difference
    between hyperparameters and parameters? We will discuss this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Demystifying hyperparameters versus parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *key difference* between a hyperparameter and a parameter is how its value
    is generated. A **parameter** value is generated by the model during the model-training
    phase. In other words, its value is *learned from the given data* instead of given
    by the developer. On the other hand, a **hyperparameter** value is *given by the
    developer* since it can't be estimated from the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters are like the heart of the model. Poorly estimated parameters will
    result in a poorly performing model. In fact, when we said we are training a model,
    it actually means that we are providing the data to the model so that the model
    can estimate the value of its parameters, which is usually done by performing
    some kind of optimization algorithm. Here are several examples of parameters in
    ML:'
  prefs: []
  type: TYPE_NORMAL
- en: Coefficients (![](img/Formula_B18753_02_001.png)) in linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weights (![](img/Formula_B18753_02_002.png)) in a **multilayer perceptron**
    (**MLP**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hyperparameters, on the other hand, are a set of values that support the model-training
    process. They are defined by the developer without knowing the exact impact on
    the model''s performance. That''s why we need to perform hyperparameter tuning
    to get the best out of our model. The searching process can be done via exhaustive
    search, heuristic search, Bayesian optimization, or multi-fidelity optimization,
    which will be discussed in the following chapters. Here are several examples of
    hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: Dropout rate, number of epochs, and batch size in a **neural network** (**NN**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum depth and splitting criterion in a decision tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of estimators in a random forest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You also need to be aware that there are models without hyperparameters or parameters,
    but not both of them. For instance, a linear regression model is a model that
    has only parameters but doesn't have any hyperparameters. On the other hand, **K-Nearest
    Neighbors** (**KNN**) is an instance of a model that doesn't contain any parameters
    but has a *k* hyperparameter.
  prefs: []
  type: TYPE_NORMAL
- en: More possible confusion may appear when we start writing our code and developing
    the ML model. In programming, arguments in a particular function or class are
    also often called parameters. What if we utilize a class that implements an ML
    model, such as a decision-tree model? What should we call the maximum depth or
    splitting criterion arguments that need to be passed to the class? Are they parameters
    or hyperparameters? The correct answer is *both*! They are *parameters to the
    class* and they are *hyperparameters to the decision-tree model*. It's just a
    matter of perspective!
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have learned what hyperparameters and parameters are, as
    well as what makes them different. In the next section, we will dive deeper into
    the realm of hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: "Understanding hyperparameter space \Land distributions"
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Hyperparameter space** is defined as the universal set of possible hyperparameter
    value combinations—in other words, it is the space containing all possible hyperparameter
    values that will be used as the search space during the hyperparameter-tuning
    phase. That''s why it is also often called the hyperparameter-tuning **search
    space**. This space is *predefined* before the hyperparameter-tuning phase so
    that the search will be performed only on this space.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, we want to perform hyperparameter tuning on a NN. Let's say we
    want to search what is the best value for the dropout rate, the number of epochs,
    and batch-size hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: The dropout rate is bounded in nature. Its value can only be between `0` and
    `1`, while for the number of epochs and batch-size hyperparameters, in theory,
    we can specify any positive integer value. However, there are other considerations
    that we need to think of. A higher batch size will usually produce a better model
    performance, but it will be bounded by the memory size of our physical computer.
    As for the number of epochs, if we go with too high a value, we will more likely
    be faced with an overfitting issue. That's why we need to *set boundaries* for
    the values of possible hyperparameters, which we call the hyperparameter space.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameters can be in the form of *discrete or continuous* values. A discrete
    hyperparameter can be in the form of integer or string data types, while a continuous
    hyperparameter will always be in the form of real numbers or floating data types.
  prefs: []
  type: TYPE_NORMAL
- en: When defining a hyperparameter space, for *some hyperparameter-tuning methods*,
    it is not enough to only specify the possible values of each hyperparameter we
    care about. We also need to define what is the underlying **distribution** for
    each hyperparameter. Here, a distribution acts as some kind of *policy* that rules
    how likely it is that a specific value will be tested during the hyperparameter-tuning
    phase. If it is a uniform distribution, then all possible values have the same
    probability of being chosen.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many types of probability distributions that can be used: uniform,
    log-uniform, normal, log-normal, and many more. There is no best practice when
    it comes to choosing the appropriate distribution; you can just treat it as another
    hyperparameter. It is worth noting that there are distributions specifically for
    continuous hyperparameters, and there are also distributions for discrete ones.
    For discrete hyperparameter distribution, some distributions are specifically
    designed for discrete values—for instance, an integer uniform distribution—but
    there are also distributions that are adjusted from a continuous distribution.
    The latter types of discrete distributions usually have a *discretized* or *quantized*
    prefix on their name—for instance, a quantized uniform distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth noting that *not all hyperparameters are equally significant*
    when it comes to impacting the model's performance—that's why it is recommended
    that you prioritize. We do not have to perform hyperparameter tuning on all of
    the hyperparameters of a model—just *focus on more important hyperparameters*.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have learned about hyperparameter space and the concept
    of a hyperparameter distribution and looked at examples of hyperparameter distributions
    you may find in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned all we need to know about hyperparameter tuning,
    starting from what it is, what is its goal, and when we should perform hyperparameter
    tuning. We have also discussed the difference between hyperparameters and parameters,
    the concept of hyperparameter space, and the concept of hyperparameter distributions.
    Having a clear picture of the concept of hyperparameter tuning and hyperparameters
    themselves will help you a lot in the following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: As stated previously, we will discuss all of the four categories of hyperparameter-tuning
    methods in this book. In [*Chapter 3*](B18753_03_ePub.xhtml#_idTextAnchor031),
    *Exploring Exhaustive Search*, we will start discussing the first group and the
    most widely used hyperparameter-tuning methods in practice. There will be both
    high-level and detailed explanations to help you understand each of the methods
    more easily.
  prefs: []
  type: TYPE_NORMAL
