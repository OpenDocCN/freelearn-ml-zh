- en: '*Chapter 5*: Practical Exposure to Using LIME in ML'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第5章*：在机器学习中实际使用LIME'
- en: After reading the last chapter, you should now have a good conceptual understanding
    of **Local Interpretable Model-agnostic Explanations (LIME)**. We saw how the
    LIME Python framework can explain black-box models for classification problems.
    We also discussed some of the pros and cons of the LIME framework. In practice,
    LIME is still one of the most popular XAI frameworks as it can be easily applied
    to tabular datasets and text and image datasets. LIME can provide model-agnostic
    local explanations for solving both regression and classification problems.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读上一章之后，您现在应该对**局部可解释模型无关解释（LIME）**有很好的概念理解。我们看到了LIME Python框架如何解释分类问题的黑盒模型。我们还讨论了LIME框架的一些优缺点。在实践中，LIME仍然是XAI框架中最受欢迎的之一，因为它可以轻松应用于表格数据集、文本数据集和图像数据集。LIME可以为解决回归和分类问题提供模型无关的局部解释。
- en: 'In this chapter, you will get much more in-depth practical exposure to using
    LIME in ML. These are the main topics of discussion for this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将更深入地了解如何在机器学习中使用LIME的实践。本章的主要讨论话题包括：
- en: Using LIME on tabular data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在表格数据上使用LIME
- en: Explaining image classifiers with LIME
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LIME解释图像分类器
- en: Using LIME on text data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在文本数据上使用LIME
- en: LIME for production-level systems
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME用于生产级系统
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Like the previous chapter, this chapter is very technical with code walk-throughs
    in Python and Jupyter notebooks. For this chapter, the code and dataset resources
    can be downloaded or cloned from the GitHub repository: [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter05](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter05).
    Like the previous chapters, we will be using Python and Jupyter notebooks to run
    the code and generate the necessary outputs. All other relevant details are provided
    in the notebooks, and I recommend that you all run the notebooks while going through
    the chapter content to get a better understanding of the topics covered.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一章类似，本章非常技术性，包含Python和Jupyter笔记本中的代码讲解。对于本章，代码和数据集资源可以从GitHub仓库下载或克隆：[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter05](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter05)。与前面的章节一样，我们将使用Python和Jupyter笔记本来运行代码并生成必要的输出。所有其他相关细节都提供在笔记本中，我建议您在阅读章节内容的同时运行笔记本，以更好地理解所涵盖的主题。
- en: Using LIME on tabular data
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在表格数据上使用LIME
- en: In the *Practical example of using LIME for classification problems* section
    of [*Chapter 4*](B18216_04_ePub.xhtml#_idTextAnchor076), *LIME for Model Interpretability*,
    we discussed how to set up LIME in Python and how to use LIME to explain classification
    ML models. The dataset used for the tutorial in [*Chapter 4*](B18216_04_ePub.xhtml#_idTextAnchor076)*,
    LIME for Model Interpretability* ([https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter04/Intro_to_LIME.ipynb](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter04/Intro_to_LIME.ipynb))
    was a tabular structured data. In this section, we will discuss using LIME to
    explain regression models that are built on tabular data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B18216_04_ePub.xhtml#_idTextAnchor076)的[*使用LIME解决分类问题的实际例子*](B18216_04_ePub.xhtml#_idTextAnchor076)部分，我们讨论了如何在Python中设置LIME以及如何使用LIME解释分类机器学习模型。[*第4章*](B18216_04_ePub.xhtml#_idTextAnchor076)*LIME用于模型可解释性*中使用的教程数据集([https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter04/Intro_to_LIME.ipynb](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter04/Intro_to_LIME.ipynb))是一个表格结构化数据。在本节中，我们将讨论如何使用LIME解释基于表格数据的回归模型。
- en: Setting up LIME
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置LIME
- en: 'Before starting the code walk-through, I would ask you to check the following
    notebook, [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_tabular_data.ipynb](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_tabular_data.ipynb),
    which already contains the steps needed to understand the concept that we are
    going to discuss now in more depth. I assume that most of the Python libraries
    that we will use for this tutorial are already installed on your system. But if
    not, please run the following command to install the upgraded versions of the
    Python libraries that we are going to use:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始代码讲解之前，我会要求您检查以下笔记本，[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_tabular_data.ipynb](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_tabular_data.ipynb)，其中已经包含了理解我们现在将要深入讨论的概念所需的步骤。我假设我们将用于本教程的大多数Python库已经安装在了您的系统上。但如果还没有安装，请运行以下命令来安装我们将要使用的Python库的升级版本：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Discussion about the dataset
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于数据集的讨论
- en: For this tutorial, we will use the *Diabetes dataset* from *scikit-learn datasets*
    ([https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset)).
    This dataset is used to predict the *disease progression level* of diabetes. It
    contains around *442 samples* with *10 baseline features* – *age*, *sex*, *body
    mass index (bmi)*, *average blood pressure (bp)*, *total serum cholesterol (s1)*,
    *low-density lipoproteins (s2)*, *high-density lipoproteins (s3)*, *total cholesterol
    / HDL (s4)*, *possibly log of serum triglycerides level (s5)*, and *blood sugar
    level (s6)*. The dataset is quite interesting and relevant, considering that the
    underlying problem of monitoring diabetes progression is an important practical
    problem.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程，我们将使用来自*scikit-learn datasets*的*Diabetes dataset*（[https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset)）。这个数据集用于预测糖尿病的*疾病进展水平*。它包含大约*442个样本*和*10个基线特征*
    – *年龄*，*性别*，*体重指数 (bmi)*，*平均血压 (bp)*，*总血清胆固醇 (s1)*，*低密度脂蛋白 (s2)*，*高密度脂蛋白 (s3)*，*总胆固醇
    / HDL (s4)*，*可能的对血清甘油三酯水平的对数 (s5)*，以及*血糖水平 (s6)*。考虑到监测糖尿病进展的潜在问题是重要的实际问题，这个数据集既有趣又相关。
- en: 'The feature variables provided in the dataset are already normalized by centering
    the feature values around the mean and scaling by the standard deviation times
    the number of samples (N):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中提供的特征变量已经通过将特征值围绕均值中心化并按标准差乘以样本数（N）进行缩放进行了归一化：
- en: '![](img/Formula01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula01.jpg)'
- en: More information about the original dataset can be found at [https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于原始数据集的信息可以在[https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html)找到。
- en: 'To load the dataset, just execute the following lines of code:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载数据集，只需执行以下代码行：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can perform the necessary EDA steps if needed, but since our main focus
    is to use LIME for explaining black-box models, we will not spend too much effort
    on EDA for the purpose of this tutorial.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，您可以执行必要的EDA步骤，但由于我们的主要重点是使用LIME来解释黑盒模型，我们不会在本教程中花费太多精力在EDA上。
- en: Discussions about the model
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于模型的讨论
- en: As demonstrated in the notebook tutorial, we have used a **Gradient Boosting
    Regressor** (**GBR**) ([https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html))
    model to train our predictive model. However, any regression ML algorithm can
    be used instead of GBR as the model itself is regarded as any black-box model
    by the LIME algorithm. Also, when we evaluated the trained model on the unseen
    data, we observed a **Mean Absolute Percentage Error (MAPE)** of 0.37, a **Mean
    Square Error (MSE)** of 2,538, and an **R-squared coefficient** score of 0.6\.
    All these results indicate that our model is not very good and definitely has
    room for improvement. So, if such a model is deployed in production-level systems,
    there can be many questions asked by the end stakeholders as it is always difficult
    for them to trust models that are not accurate. Also, algorithms such as GBR are
    not inherently interpretable and the complexity of the algorithm depends on hyperparameters
    including the number of estimators and the depth of the tree. Thus, model explainability
    frameworks such as LIME are not just an add-on step, but a necessary part of the
    process of building ML models. Next, we will see how easily LIME can be applied
    to explain black-box regression models with just a few lines of code.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如笔记本教程中所示，我们使用了一个**梯度提升回归器**（**GBR**）([https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html))模型来训练我们的预测模型。然而，任何回归机器学习算法都可以用来代替GBR，因为LIME算法将模型本身视为任何黑盒模型。此外，当我们对未见过的数据进行模型评估时，我们观察到**平均绝对百分比误差（MAPE）**为0.37，**均方误差（MSE）**为2,538，以及**R平方系数**评分为0.6。所有这些结果都表明我们的模型并不很好，肯定还有改进的空间。因此，如果这样的模型在生产级系统中部署，最终利益相关者可能会提出许多问题，因为他们总是难以信任不准确模型。此外，如GBR之类的算法本身不具有可解释性，算法的复杂性取决于超参数，包括估计器的数量和树的深度。因此，模型可解释性框架如LIME不仅仅是附加步骤，而是构建机器学习模型过程中的必要部分。接下来，我们将看到LIME如何通过几行代码轻松地应用于解释黑盒回归模型。
- en: Application of LIME
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LIME的应用
- en: 'As we have seen in the previous chapter, we can easily support the LIME framework
    for tabular data with the following commands:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在上一章中看到的，我们可以轻松使用以下命令支持LIME框架对表格数据的支持：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once the LIME module is successfully imported, we will need to create an explainer
    object:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦成功导入LIME模块，我们需要创建一个解释器对象：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, we just need to take the data instance and provide local explainability
    to it:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们只需要获取数据实例并为其提供局部可解释性：
- en: '[PRE10]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We will get the following output from the preceding lines of code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从前面的代码行中获得以下输出：
- en: '![Figure 5.1 – Output visualization from the LIME framework when applied to
    a regression model trained on a tabular dataset'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1 – 将LIME框架应用于在表格数据集上训练的回归模型时的输出可视化'
- en: '](img/B18216_05_001.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18216_05_001.jpg)'
- en: Figure 5.1 – Output visualization from the LIME framework when applied to a
    regression model trained on a tabular dataset
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 将LIME框架应用于在表格数据集上训练的回归模型时的输出可视化
- en: '*Figure 5.1* illustrates the visualization-based explanations provided by the
    LIME framework.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5.1*说明了LIME框架提供的基于可视化的解释。'
- en: 'Next, let''s try to understand what the output visualization in *Figure 5.1*
    is telling us:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们尝试理解*图5.1*中的输出可视化在告诉我们什么：
- en: The left-most visualization from *Figure 5.1* shows a range of possible values
    and the position of the model's predicted outcome. Intuitively speaking, all model
    predictions should lie within the minimum and the maximum possible value as this
    indicates to the user to compare the current forecast with the best-case and the
    worst-case values.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图5.1*中最左侧的可视化显示了可能的值范围和模型预测结果的位置。直观地说，所有模型预测都应该位于最小值和最大可能值之间，因为这表明用户将当前预测与最佳和最坏情况值进行比较。'
- en: The middle visualization shows which features contribute to the prediction being
    on the higher side or the lower side. Considering our prior knowledge of diabetes,
    a higher BMI, as well as raised blood pressure and serum triglyceride levels,
    do indicate increasing progression of the disease.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中间的可视化显示了哪些特征对预测结果偏高或偏低有贡献。考虑到我们对糖尿病的先验知识，较高的BMI、升高的血压和血清甘油三酯水平确实表明疾病进展的增加。
- en: The right-most visualization in *Figure 5.1* shows us the actual local data
    values for the most important features identified, arranged in descending order
    of their relevance.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图5.1*中最右侧的可视化显示了识别出的最重要的特征的实际局部数据值，按其相关性降序排列。'
- en: The explanations provided by the LIME framework are human-interpretable to a
    great extent and do give us an indication of the feature-value pairs used by the
    black-box model to make predictions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LIME框架提供的解释在很大程度上是可由人类理解的，并且确实为我们提供了关于黑色盒模型用于预测的特征值对的指示。
- en: So, this is how we can use LIME to explain black-box regression models trained
    on tabular data with just a few lines of code. But, as we discussed in [*Chapter
    4*](B18216_04_ePub.xhtml#_idTextAnchor076), *LIME for Model Interpretability*,
    under the *Potential pitfalls* section, explanations provided by LIME are not
    always holistic and may have some inconsistencies. This is something we all need
    to be mindful of. However, LIME explanations, coupled with a thorough EDA, data-centric
    XAI, counterfactual explanations, and other model explainability methods, can
    provide a powerful, holistic explainability to black-box models trained on tabular
    datasets.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这就是我们如何仅用几行代码就能使用LIME来解释在表格数据上训练的黑色盒回归模型的方法。但是，正如我们在[*第4章*](B18216_04_ePub.xhtml#_idTextAnchor076)中讨论的，“*LIME模型可解释性*”部分下的“*潜在陷阱*”部分，LIME提供的解释并不总是全面的，可能存在一些不一致性。这是我们都需要注意的事情。然而，LIME的解释，结合彻底的EDA、以数据为中心的XAI、反事实解释和其他模型可解释性方法，可以为在表格数据集上训练的黑色盒模型提供强大而全面的解释性。
- en: Now, let's explore how to use LIME for classifiers trained on unstructured data
    such as images in the next section.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在下一节中探讨如何使用LIME来解释在非结构化数据上训练的分类器，例如图像。
- en: Explaining image classifiers with LIME
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LIME解释图像分类器
- en: In the previous section, we have seen how we can easily apply LIME to explain
    models trained on tabular data. However, the main challenge always comes while
    explaining complex deep learning models trained on unstructured data such as images.
    Generally, deep learning models are much more efficient than conventional ML models
    on image data as these models have the ability to perform *auto feature extraction*.
    They can extract complex *low-level features* such as *stripes*, *edges*, *contours*,
    *corners*, and *motifs*, and even *higher-level features* such as *larger shapes*
    and *certain parts of the object*. These higher-level features are usually referred
    to as **Regions of Interest** **(RoI)** in the image, or **superpixels**, as they
    are collections of pixels of the image that cover a particular area of the image.
    Now, the low-level features are not human-interpretable, but the high-level features
    are human-interpretable, as any non-technical end user will relate to the images
    with respect to the higher-level features. LIME also works in a similar fashion.
    The algorithm tries to highlight the superpixels in images that contribute positively
    or negatively to the model's decision-making process. So, let's see how LIME can
    be used to explain image classifiers.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到了如何轻松地将LIME应用于解释在表格数据上训练的模型。然而，解释在图像等非结构化数据上训练的复杂深度学习模型始终是主要挑战。通常，深度学习模型在图像数据上比传统的机器学习模型更有效率，因为这些模型具有执行*自动特征提取*的能力。它们可以提取复杂的*低级特征*，如*条纹*、*边缘*、*轮廓*、*角点*和*模式*，甚至*高级特征*，如*更大的形状*和*物体的某些部分*。这些高级特征通常被称为图像中的**感兴趣区域**
    **(RoI**)或**超像素**，因为它们是覆盖图像特定区域的像素集合。现在，低级特征不是人类可解释的，但高级特征是可解释的，因为任何非技术终端用户都会根据高级特征与图像相关联。LIME也以类似的方式工作。算法试图突出图像中那些对模型决策过程产生积极或消极影响的超像素。所以，让我们看看LIME如何被用来解释图像分类器。
- en: Setting up the required Python modules
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置所需的Python模块
- en: 'Before we begin the code walk-through, please check the notebook provided in
    the code repository: [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_image_data.ipynb](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_image_data.ipynb).
    The notebook contains the necessary details required for the practical application
    of the concepts. In this section, I will give you a walk-through of the code and
    explain all the steps covered in the notebook tutorial. Use the following command
    to install the upgraded versions of the Python libraries if not already installed:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始代码讲解之前，请检查代码仓库中提供的笔记本：[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_image_data.ipynb](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_image_data.ipynb)。该笔记本包含了实际应用这些概念所需的必要细节。在本节中，我将为您讲解代码，并解释笔记本教程中涵盖的所有步骤。如果尚未安装，请使用以下命令安装Python库的升级版本：
- en: '[PRE13]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Next, let's discuss the model used in this example.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论本例中使用的模型。
- en: Using a pre-trained TensorFlow model as our black-box model
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用预训练的TensorFlow模型作为我们的黑盒模型
- en: 'For this tutorial, we have used a *pre-trained TensorFlow Keras Xception model*
    as our black-box model. The model is pre-trained on the ImageNet dataset ([https://www.image-net.org/](https://www.image-net.org/)),
    which is one of the most popular benchmarking datasets for image classification.
    The pre-trained model can be loaded with the following lines of code:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个教程，我们使用了一个*预训练的TensorFlow Keras Xception模型*作为我们的黑盒模型。该模型在ImageNet数据集([https://www.image-net.org/](https://www.image-net.org/))上进行了预训练，这是图像分类中最受欢迎的基准数据集之一。可以使用以下代码行加载预训练模型：
- en: '[PRE14]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In order to use any inference data for image classification, we will also need
    to perform the necessary preprocessing steps. Please refer to the notebook at
    [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_image_data](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_image_data).ipynb
    for the necessary pre-processing methods.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用任何推理数据进行图像分类，我们还需要执行必要的预处理步骤。请参阅[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_image_data](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_image_data).ipynb中的必要预处理方法。
- en: Application of LIME Image Explainers
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LIME图像解释器的应用
- en: 'In this subsection, we will see how the LIME framework can be used to identify
    *super-pixels* or regions from the image used by the model to predict the specific
    outcome. We will first need to define an image `explainer` object:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将看到如何使用LIME框架来识别模型用于预测特定结果的图像中的*超像素*或区域。我们首先需要定义一个图像`explainer`对象：
- en: '[PRE16]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, we will need to pass the inference data (`normalized_img[0]`) to the
    `explainer` object and use the LIME framework to highlight superpixels that have
    the maximum positive and negative influence on the model''s prediction:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要将推理数据（`normalized_img[0]`）传递给`explainer`对象，并使用LIME框架突出显示对模型预测有最大正负影响的超像素：
- en: '[PRE17]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'As an output to the preceding lines of code, we will get certain highlighted
    portions of the image that contribute to the model''s prediction, in both a positive
    and negative manner:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 作为前面代码行的输出，我们将得到图像中某些突出显示的部分，这些部分以正负两种方式对模型的预测有贡献：
- en: '![Figure 5.2 – (Left) Original inference image. (Middle) Most important image
    superpixel. (Right) Image with superposed mask superpixel on the original data
    highlighted in green'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.2 – (左) 原始推理图像。(中) 最重要的图像超像素。(右) 在原始数据上叠加的绿色掩码超像素图像'
- en: '](img/B18216_05_002.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18216_05_002.jpg)'
- en: Figure 5.2 – (Left) Original inference image. (Middle) Most important image
    superpixel. (Right) Image with superposed mask superpixel on the original data
    highlighted in green
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – (左) 原始推理图像。(中) 最重要的图像超像素。(右) 在原始数据上叠加的绿色掩码超像素图像
- en: In *Figure 5.2*, the left-most image was used as the inference image. When the
    trained model was applied to the inference image, the top prediction of the model
    was a *tiger shark*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图5.2*中，最左侧的图像被用作推理图像。当训练模型应用于推理图像时，模型的最高预测是*虎鲨*。
- en: The prediction was actually correct. However, in order to explain the model,
    the LIME algorithm can highlight the superpixel, which has the maximum influence
    on the prediction. From the middle and the right-most images in *Figure 5.2*,
    we can see that the black-box model was actually good and trustworthy as the relevant
    superpixel captured by the LIME algorithm indicates the presence of a tiger shark.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 预测实际上是正确的。然而，为了解释模型，LIME算法可以突出对预测影响最大的超像素。从*图5.2*的中间和最右侧的图像中，我们可以看到黑盒模型实际上是很好且值得信赖的，因为LIME算法捕获的相关超像素表明存在虎鲨。
- en: 'The superpixel estimated by the LIME algorithm can be displayed using the following
    lines of code:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: LIME算法估计的超像素可以使用以下代码行显示：
- en: '[PRE30]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We can also form a heatmap highlighting the importance of each of the superpixels,
    which gives us further insight into the functioning of the black-box model:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以形成一个热力图，突出每个超像素的重要性，这使我们进一步了解黑盒模型的工作原理：
- en: '[PRE33]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output obtained is shown in *Figure 5.3*:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 获得的输出显示在*图5.3*中：
- en: '![Figure 5.3 – (Left) Image showing all the superpixels picked up by the LIME
    algorithm.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.3 – (左) LIME算法选取的所有超像素的图像。'
- en: (Right) Heatmap of the superpixels based on their importance in terms of the
    model's prediction
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: (右) 根据模型预测的重要性对超像素的热力图
- en: '](img/B18216_05_003.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18216_05_003.jpg)'
- en: Figure 5.3 – (Left) Image showing all the superpixels picked up by the LIME
    algorithm. (Right) Heatmap of the superpixels based on their importance in terms
    of the model's prediction
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – (左) LIME算法选取的所有超像素的图像。(右) 根据模型预测的重要性对超像素的热力图
- en: The heatmap from *Figure 5.3* provides us with some insight into important superpixels,
    which is also easy when it comes to any non-technical user interpreting any black-box
    model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5.3*中的热力图为我们提供了一些关于重要超像素的见解，对于任何非技术用户解释任何黑盒模型来说也很容易。'
- en: So, we have seen how LIME can explain even complicated deep learning models
    trained on image data in just a few lines of code. I found LIME to be one of the
    most effective algorithms to visually explain deep learning-based image classifiers
    without presenting any complicated statistical or numerical values or complicated
    graphical visualizations. Unlike tabular data, I felt explanations provided to
    image classifiers are more robust, stable, and human-interpretable. It is definitely
    one of my favorite methods for interpreting image classifiers, and before moving
    any image classification model to production, I strongly recommend applying LIME
    as an additional evaluation step to gain more confidence in the trained model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经看到LIME如何仅用几行代码就能解释在图像数据上训练的复杂深度学习模型。我发现LIME是可视化解释基于深度学习的图像分类器最有效的算法之一，无需展示任何复杂的统计或数值或复杂的图形可视化。与表格数据不同，我觉得提供给图像分类器的解释更加稳健、稳定且易于人类理解。这绝对是我最喜欢的解释图像分类器的方法之一，在将任何图像分类模型投入生产之前，我强烈建议应用LIME作为一个额外的评估步骤，以增强对训练模型的信心。
- en: In the next section, let's explore LIME for models trained on text data.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们探索在文本数据上训练的LIME。
- en: Using LIME on text data
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在文本数据上使用LIME
- en: In the previous section, we discussed how LIME is an effective approach to explaining
    complicated black-box models trained on image datasets. Like images, text is also
    a form of unstructured data, which is very much different from structured tabular
    data. Explaining such black-box models trained on unstructured data is always
    very challenging. But LIME can also be applied to models trained on text data.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们讨论了LIME是如何成为解释在图像数据集上训练的复杂黑盒模型的有效方法。与图像一样，文本也是一种非结构化数据，这与结构化的表格数据有很大不同。解释在非结构化数据上训练的黑盒模型始终是非常具有挑战性的。但LIME也可以应用于在文本数据上训练的模型。
- en: Using the LIME algorithm, we can analyze whether the presence of a particular
    word or group of words increases the probability of predicting a specific outcome.
    In other words, LIME helps to highlight the importance of text tokens or words
    that can influence the model's outcome toward a particular class. In this section,
    we will see how LIME can be used to interpret text classifiers.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LIME算法，我们可以分析特定单词或单词组的存在是否会增加预测特定结果的可能性。换句话说，LIME有助于突出影响模型结果向特定类别发展的文本标记或单词的重要性。在本节中，我们将看到如何使用LIME来解释文本分类器。
- en: Installing the required Python modules
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装所需的Python模块
- en: 'Like the previous tutorials, the complete notebook tutorial is available at
    [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_text_data.ipynb](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_text_data.ipynb).
    Although the necessary instructions needed to run the notebook are clearly documented
    in the notebook itself, similar to the previous tutorials, I will provide the
    necessary details to walk you through the implementation. Using the following
    commands, you can install the modules required to run the code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的教程一样，完整的笔记本教程可在[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_text_data.ipynb](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_text_data.ipynb)找到。尽管运行笔记本所需的必要说明已在笔记本本身中清楚地记录，类似于之前的教程，我仍将提供必要的细节来指导你完成实现。使用以下命令，你可以安装运行代码所需的模块：
- en: '[PRE39]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'For text-related operations on the underlying dataset, I will be mainly using
    the NLTK Python framework. So, you will need to download certain `nltk` modules
    by executing the following commands:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于底层数据集上的文本相关操作，我主要将使用NLTK Python框架。因此，你需要通过执行以下命令下载某些`nltk`模块：
- en: '[PRE40]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: In the tutorial, we will try to explain a text classifier designed to perform
    sentiment analysis by classifying the text data into positive and negative classes.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在教程中，我们将尝试解释一个设计用于执行情感分析的文本分类器，该分类器通过将文本数据分类为正面和负面类别来执行情感分析。
- en: Discussions about the dataset used for training the model
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于用于训练模型的训练集的讨论
- en: 'We have used the **Sentiment Polarity dataset v2.0** consisting of *Movie reviews*
    for this tutorial used for sentiment analysis from text data. The dataset consists
    of about 1,000 samples of positive and negative movie reviews. More information
    about the dataset can be found on the source website: [https://www.cs.cornell.edu/people/pabo/movie-review-data/](https://www.cs.cornell.edu/people/pabo/movie-review-data/).
    The dataset is also provided in the GitHub repository of this chapter: [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter05](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter05).'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们使用了包含*电影评论*的**情感极性数据集v2.0**，用于从文本数据中进行情感分析。该数据集包含大约1,000个正面和负面电影评论样本。有关数据集的更多信息可以在源网站上找到：[https://www.cs.cornell.edu/people/pabo/movie-review-data/](https://www.cs.cornell.edu/people/pabo/movie-review-data/)。该数据集也提供在本章的GitHub仓库中：[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter05](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter05)。
- en: Sentiment Polarity dataset v2.0
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 情感极性数据集v2.0
- en: 'This data was first used in Bo Pang and Lillian Lee, "A Sentimental Education:
    Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts", Proceedings
    of the ACL, 2004.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这份数据最初被用于Bo Pang和Lillian Lee的论文，“情感教育：基于最小割的基于主观性的情感分析”，ACL会议论文集，2004年。
- en: Discussions about the text classification model
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于文本分类模型的讨论
- en: 'Unlike the previous image classifier tutorial, we have not used a pre-trained
    model. We have trained an **XGBoost Classifier** ([https://xgboost.readthedocs.io/en/stable/](https://xgboost.readthedocs.io/en/stable/))
    from scratch with the necessary data preprocessing, preparation, and feature extraction
    steps as covered in the notebook. XGBoost is an ensemble learning boosting algorithm
    that is not inherently interpretable. So, we will consider this as our black-box
    text classification model. We are not focused on improving the model''s accuracy
    with necessary hyperparameter tuning, as LIME is completely model-agnostic. For
    this tutorial, we have created a scikit-learn pipeline to apply feature extraction
    first using **TFIDF Vectorizer** (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html),
    and then the trained model:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的图像分类器教程不同，我们没有使用预训练模型。我们从头开始训练了一个**XGBoost分类器**([https://xgboost.readthedocs.io/en/stable/](https://xgboost.readthedocs.io/en/stable/))，包括笔记本中涵盖的必要的数据预处理、准备和特征提取步骤。XGBoost是一种集成学习提升算法，本质上不可解释。因此，我们将它视为我们的黑盒文本分类模型。我们并不专注于通过必要的超参数调整来提高模型的准确性，因为LIME是完全模型无关的。对于本教程，我们创建了一个scikit-learn管道，首先使用**TFIDF向量器**（https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html）进行特征提取，然后应用训练好的模型：
- en: '[PRE44]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: In the next subsection, we will see how the LIME framework can be easily applied
    with text data as well.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将看到如何轻松地将LIME框架应用于文本数据。
- en: Applying LIME Text Explainers
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用LIME文本解释器
- en: 'Like the previous tutorials with image and tabular data, applying LIME is simple
    with text data in a few lines of code. We will now define the LIME `explainer`
    object:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前关于图像和表格数据的教程一样，使用文本数据应用LIME也非常简单，只需几行代码。现在，我们将定义LIME `解释器` 对象：
- en: '[PRE45]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Then, we will use the inference data instance to provide local explainability
    for that particular data instance:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用推理数据实例为该特定数据实例提供局部可解释性：
- en: '[PRE47]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: And that's it! In just a few lines of code, we can explain the text classifier
    that actually relies on TFIDF numerical features, but the explainability is provided
    with a human interpretable perspective as words that can positively or negatively
    influence the model outcome are highlighted. It is easier for any non-technical
    user to understand the working of the text model in this way, rather than providing
    explanations using numerically encoded features.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！仅仅几行代码，我们就能解释基于TFIDF数值特征的文本分类器，但解释性是以人类可解释的视角提供的，即突出那些可以积极或消极影响模型结果的关键词。以这种方式解释文本模型的工作原理，对于任何非技术用户来说都更容易理解，而不是使用数值编码的特征来提供解释。
- en: Now, let's take a look at the output visualization provided by LIME when applied
    to text data.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看LIME应用于文本数据时提供的输出可视化。
- en: '![Figure 5.4 – Output visualization when LIME is applied to a text classifier'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.4 – 应用LIME到文本分类器时的输出可视化'
- en: '](img/B18216_05_004.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18216_05_004.jpg)'
- en: Figure 5.4 – Output visualization when LIME is applied to a text classifier
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 – 应用LIME到文本分类器时的输出可视化
- en: In *Figure 5.4*, we can see the output visualization of the LIME framework when
    applied to text data.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图5.4*中，我们可以看到当LIME应用于文本数据时的输出可视化。
- en: The output visualization is very similar to what we have observed with tabular
    data. It shows us the *prediction probability*, which can be used as a *model
    confidence* score. The algorithm highlights the most influential words that determine
    the model outcome, with a feature importance score. For example, from *Figure
    5.4*, we can see that the inference data instance is predicted as negative by
    the model (which is predicted correctly as demonstrated in the notebook). The
    presence of words such as *waste*, *bad*, and *ridiculous* does indicate a *negative
    review*. This is human-interpretable as well, since if you ask a non-technical
    user to justify why the review is classified as negative, the user might refer
    to the usage of frequently used words in negative reviews or words used in sentences
    with a negative tone.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 输出可视化与我们观察到的表格数据非常相似。它显示了*预测概率*，这可以用作*模型置信度*分数。算法突出了决定模型结果的最具影响力的关键词，并带有特征重要性分数。例如，从*图5.4*中，我们可以看到推理数据实例被模型预测为负面（正如在笔记本中演示的那样，预测是正确的）。存在诸如*waste*、*bad*和*ridiculous*等词语确实表明了*负面评论*。这对于人类解释也是可行的，因为如果你要求一个非技术用户解释为什么评论被分类为负面，用户可能会提到在负面评论中频繁使用的词语或在具有负面语调的句子中使用的词语。
- en: Thus, we can see that LIME can be easily applied with text classifiers as well.
    Even with text data, the algorithm is simple, yet effective in providing a human-interpretable
    explanation. I would definitely recommend using LIME to explain black-box text
    classifiers as an additional model evaluation or quality inspection step.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到LIME可以轻松地应用于文本分类器。即使在文本数据中，该算法简单而有效，能够提供人类可解释的解释。我肯定会推荐使用LIME来解释黑盒文本分类器，作为额外的模型评估或质量检查步骤。
- en: But so far, we have seen the application of LIME Python frameworks in the Jupyter
    notebook environment. The immediate question that you might have is – *Can we
    scale LIME for use in production-level systems?* Let's find out in the next section.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 但到目前为止，我们只看到了LIME Python框架在Jupyter笔记本环境中的应用。你可能立即会问一个问题——*我们能否将LIME扩展到用于生产级系统？*
    让我们在下一节中找出答案。
- en: LIME for production-level systems
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LIME用于生产级系统
- en: 'The short answer to the question posted toward the end of the last section
    is *Yes*. LIME can definitely be scaled for use in production-level systems due
    to the following main reasons:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上一节末尾提出的问题的简短回答是*是的*。由于以下主要原因，LIME肯定可以扩展到用于生产级系统：
- en: '**Minimal implementation complexity**: The API structure of the LIME Python
    framework is concise and well structured. This allows us to add model explainability
    in just a few lines of code. For providing local explainability to inference data
    instances, the runtime complexity of the LIME algorithm is very low and, hence,
    this approach can also work for real-time applications.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最小化实现复杂性**：LIME Python框架的API结构简洁且结构良好。这使得我们只需几行代码就能添加模型可解释性。为了向推理数据实例提供局部可解释性，LIME算法的运行时复杂度非常低，因此这种方法也可以用于实时应用。'
- en: '**Easy integration with other software applications**: The API structure of
    the framework is modular. For consuming the explainability results, we do not
    need to solely depend on the in-built visualizations provided by the framework.
    We can utilize the raw explainability results and create our own custom visualization
    dashboards or reports. Also, we can create custom web API methods and host the
    web APIs on remote cloud servers, creating our own model explainability cloud-based
    service that can be integrated easily with other software applications. We will
    cover this in more detail in [*Chapter 10*](B18216_10_ePub.xhtml#_idTextAnchor209),
    *XAI Industry Best Practices*.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于与其他软件应用集成**：框架的API结构是模块化的。对于消费可解释性结果，我们不需要完全依赖于框架提供的内置可视化。我们可以利用原始的可解释性结果，创建我们自己的自定义可视化仪表板或报告。此外，我们可以创建自定义Web
    API方法，并在远程云服务器上托管这些Web API，创建我们自己的基于云的模型可解释性服务，该服务可以轻松与其他软件应用集成。我们将在[*第10章*](B18216_10_ePub.xhtml#_idTextAnchor209)中更详细地介绍这一点，*XAI行业最佳实践*。'
- en: '**Does not require heavy computational resources**: The LIME framework works
    well with low computational resources. For real-time applications, the algorithms
    used need to be very fast and should have the ability to run on low computational
    resources, as otherwise, the user experience is affected.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不需要大量计算资源**：LIME框架与低计算资源很好地协同工作。对于实时应用，使用的算法需要非常快，并且应该能够在低计算资源上运行，否则用户体验会受到负面影响。'
- en: '**Easy to set up and package**: As we have already seen before running the
    tutorial notebooks, LIME is very easy to set up and does not have a dependency
    on packages that are difficult to install. Similarly, any Python program using
    LIME is easy to package or **containerize**. Most production-level systems have
    automated CI/CD pipelines to create **Docker containers** (https://www.docker.com/resources/what-container),
    which are deployed on production-level systems. The engineering effort needed
    to containerize a Python program using a LIME framework is low and hence it is
    easy to productionalize such software applications.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于设置和打包**：正如我们在运行教程笔记本之前所看到的，LIME非常容易设置，并且不依赖于难以安装的包。同样，任何使用LIME的Python程序都很容易打包或**容器化**。大多数生产级系统都有自动化的CI/CD管道来创建**Docker容器**（https://www.docker.com/resources/what-container），这些容器部署在生产级系统上。使用LIME框架容器化Python程序所需的工程工作量很低，因此很容易将此类软件应用程序投入生产。'
- en: These are the key reasons why LIME is the preferred model explainability method
    used in industrial applications, despite some of its well-known pitfalls.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是LIME成为工业应用中首选模型可解释性方法的关键原因，尽管它有一些众所周知的缺陷。
- en: Summary
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have discussed the practical applications of the LIME Python
    framework on different types of datasets. The tutorials covered in the chapter
    are just the starting point and I strongly recommend you try out LIME explainability
    on other datasets. We have also discussed why LIME is a good fit for production-level
    ML systems.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了LIME Python框架在不同类型数据集上的实际应用。本章涵盖的教程只是起点，我强烈建议您尝试在其他数据集上使用LIME可解释性。我们还讨论了为什么LIME非常适合生产级机器学习系统。
- en: In the next chapter, we will discuss another very popular explainable AI Python
    framework called **SHAP**, which even considers the collective contribution of
    multiple features in influencing the model's outcome.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论另一个非常流行的可解释人工智能Python框架，称为**SHAP**，它甚至考虑了多个特征在影响模型结果时的集体贡献。
- en: References
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Please refer to the following resources to gain additional information:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下资源以获取更多信息：
- en: '*"Why Should I Trust You?" Explaining the Predictions of Any Classifier*, by
    *Ribeiro et al.*: [https://arxiv.org/pdf/1602.04938.pdf](https://arxiv.org/pdf/1602.04938.pdf)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《“我应该信任你吗？”解释任何分类器的预测》，作者：*Ribeiro等人*：[https://arxiv.org/pdf/1602.04938.pdf](https://arxiv.org/pdf/1602.04938.pdf)
- en: '*Local Interpretable Model-Agnostic Explanations (LIME): An Introduction*:
    [https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*本地可解释模型无关解释（LIME）：简介*：[https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)'
- en: '*LIME GitHub Project*: [https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*LIME GitHub 项目*：[https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)'
- en: '*Docker Blog*: [https://www.docker.com/blog/](https://www.docker.com/blog/)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Docker 博客*：[https://www.docker.com/blog/](https://www.docker.com/blog/)'
