["```py\n\n# Create a range of equally spaced numbers between -10 and 10\nx = seq(-10, 10, by = 0.1)\n# Calculate the output value for each number using sigmoid function\nsigmoid = 1 / (1 + exp(-x))\n# Plot the sigmoid function\nplot(x, sigmoid, type = \"l\", lwd = 2,\n     main = \"Sigmoid Function\",\n     xlab = \"x\",\n     ylab = \"f(x)\",\n     col = \"red\")\n# Add grid lines\ngrid()\n```", "```py\n\n    # install the caret package if you haven't done so\n    install.packages(\"caret\")\n    # load the caret package\n    library(caret)\n    # load the German Credit dataset\n    data(GermanCredit)\n    GermanCredit$Class_num = ifelse(GermanCredit$Class == \"Bad\", 1, 0)\n    ```", "```py\n\n    lm_model = lm(Class_num ~ Duration, data=GermanCredit)\n    coefs = coefficients(lm_model)\n    intercept = coefs[1]\n    slope = coefs[2]\n    ```", "```py\n\n    ggplot(GermanCredit,\n           aes(Duration, Class_num)) +\n      geom_point() +\n      geom_abline(intercept=intercept, slope=slope) +\n      theme(axis.title.x = element_text(size = 18),\n            axis.title.y = element_text(size = 18))\n    ```", "```py\n\n    ggplot(GermanCredit,\n           aes(Duration, Class_num)) +\n      geom_point() +\n      geom_abline(intercept=intercept, slope=slope) +\n      xlim(-30, 120) +\n      ylim(-0.5, 1.5) +\n      theme(axis.title.x = element_text(size = 18),\n            axis.title.y = element_text(size = 18))\n    ```", "```py\n\n    glm_model = glm(Class_num ~ Duration, data=GermanCredit, family=binomial)\n    >>> glm_model\n    Call:  glm(formula = Class_num ~ Duration, family = binomial, data = GermanCredit)\n    Coefficients:\n    (Intercept)     Duration\n       -1.66635      0.03754\n    Degrees of Freedom: 999 Total (i.e. Null);  998 Residual\n    Null Deviance:     1222\n    Residual Deviance: 1177   AIC: 1181\n    ```", "```py\n\n    ggplot(GermanCredit,\n           aes(Duration, Class_num)) +\n      geom_point() +\n      geom_abline(intercept=intercept, slope=slope) +\n      geom_smooth(\n        method = \"glm\",\n        se = FALSE,\n        method.args = list(family=binomial)\n      ) +\n      theme(axis.title.x = element_text(size = 18),\n            axis.title.y = element_text(size = 18))\n    ```", "```py\n\n    # Get coefficients from logistic model\n    intercept_glm = coef(glm_model)[1]\n    slope_glm = coef(glm_model)[2]\n    # Generate sequence of x-values\n    x_values = seq(from = min(GermanCredit$Duration) - 150,\n                    to = max(GermanCredit$Duration) + 150,\n                    by = 0.1)\n    # Compute probabilities using logistic function\n    y_values = 1 / (1 + exp(-(intercept_glm + slope_glm * x_values)))\n    # Data frame for plot\n    plot_df = data.frame(x = x_values, y = y_values)\n    # Plot\n    ggplot() +\n      geom_point(data = GermanCredit, aes(Duration, Class_num)) +\n      geom_abline(intercept=intercept, slope=slope) +\n      geom_line(data = plot_df, aes(x, y), color = \"blue\") +\n      theme_minimal() +\n      xlim(-30, 120) +\n      ylim(-0.5, 1.5) +\n      theme(axis.title.x = element_text(size = 18),\n            axis.title.y = element_text(size = 18))\n    ```", "```py\n\n    library(tibble)\n    library(dplyr)\n    # making predictions\n    pred_df = tibble(\n      Duration = seq(5, 80, 2)\n    )\n    pred_df = pred_df %>%\n      mutate(\n        pred_prob = predict(glm_model, pred_df, type=\"response\")\n      )\n    ```", "```py\n\n    ggplot() +\n      geom_point(data = GermanCredit, aes(Duration, Class_num)) +\n      geom_point(data = pred_df, aes(Duration, pred_prob) , color=\"blue\") +\n      theme(axis.title.x = element_text(size = 18),\n            axis.title.y = element_text(size = 18))\n    ```", "```py\n\n    # getting the most likely outcome\n    pred_df = pred_df %>%\n      mutate(\n        most_likely_outcome = round(pred_prob)\n      )\n    ```", "```py\n\n    ggplot() +\n      geom_point(data = GermanCredit, aes(Duration, Class_num)) +\n      geom_point(data = pred_df, aes(Duration, pred_prob) , color=\"blue\") +\n      geom_point(data = pred_df, aes(Duration, most_likely_outcome) , color=\"green\") +\n      theme(axis.title.x = element_text(size = 18),\n            axis.title.y = element_text(size = 18))\n    ```", "```py\n\n# calculate log odds using predicted probabilities\npred_df = pred_df %>%\n  mutate(\n    log_odds = log(pred_prob / (1 - pred_prob))\n  )\n```", "```py\n\n# Create new data frame with all durations\nnew_data = data.frame(Duration = GermanCredit$Duration)\n# Calculate predicted classes based on predicted probabilities\npredicted_probs = predict(glm_model, new_data, type=\"response\")\n```", "```py\n\n# Convert to binary outcomes\npredicted_classes = ifelse(predicted_probs > 0.5, 1, 0)\n```", "```py\n\n# Create confusion matrix\nconf_matrix = table(predicted = predicted_classes, actual = GermanCredit$Class_num)\n>>> conf_matrix\n         actual\npredicted   0   1\n        0 670 260\n        1  30  40\n```", "```py\n\n# Accuracy\naccuracy = sum(diag(conf_matrix)) / sum(conf_matrix)\n>>> print(paste(\"Accuracy: \", accuracy))\n\"Accuracy:  0.71\"\n# Error rate\nerror_rate = 1 - accuracy\n>>> print(paste(\"Error rate: \", error_rate))\n\"Error rate:  0.29\"\n# Precision\nprecision = conf_matrix[2,2] / sum(conf_matrix[2,])\nprint(paste(\"Precision: \", precision))\n\"Precision:  0.571428571428571\"\n# Recall / Sensitivity\nrecall = conf_matrix[2,2] / sum(conf_matrix[,2])\nprint(paste(\"Recall: \", recall))\n>>> \"Recall:  0.133333333333333\"\n# Specificity\nspecificity = conf_matrix[1,1] / sum(conf_matrix[,1])\nprint(paste(\"Specificity: \", specificity))\n>>> \"Specificity:  0.957142857142857\"\n```", "```py\n\nlibrary(pROC)\n# Calculate ROC curve\nroc_obj = roc(GermanCredit$Class_num, predicted_probs)\n# Plot ROC curve\n>>> plot(roc_obj)\n```", "```py\n\n# Calculate AUC\nauc = auc(roc_obj)\n>>> print(paste(«AUC: «, auc))\n«AUC:  0.628592857142857»\n```", "```py\n\n    set.seed(2)\n    index = sample(1:nrow(GermanCredit), nrow(GermanCredit)*0.7)\n    train = GermanCredit[index, ]\n    test = GermanCredit[-index, ]\n    ```", "```py\n\n    >>> table(train$Class_num)\n      0   1\n    504 196\n    ```", "```py\n\n    # separate the minority and majority classes\n    table(train$Class_num)\n    minority_data = train[train$Class_num == 1,]\n    majority_data = train[train$Class_num == 0,]\n    ```", "```py\n\n    # undersample the majority class\n    undersampled_majority = majority_data[sample(1:nrow(majority_data), nrow(minority_data)),]\n    # combine undersampled majority class and minority class\n    undersampled_data = rbind(minority_data, undersampled_majority)\n    >>> table(undersampled_data$Class_num)\n      0   1\n    196 196\n    ```", "```py\n\n    # oversample the minority class\n    oversampled_minority = minority_data[sample(1:nrow(minority_data), nrow(majority_data), replace = TRUE),]\n    # combine majority class and oversampled minority class\n    oversampled_data = rbind(majority_data, oversampled_minority)\n    >>> table(oversampled_data$Class_num)\n      0   1\n    504 504\n    ```", "```py\n\n    # fit logistic regression models on undersampled and oversampled data\n    undersampled_model = glm(Class_num ~ Duration, family = binomial(link = 'logit'), data = undersampled_data)\n    oversampled_model = glm(Class_num ~ Duration, family = binomial(link = 'logit'), data = oversampled_data)\n    ```", "```py\n\n    # get the predicted probabilities on the test set\n    undersampled_pred = predict(undersampled_model, newdata = test, type = \"response\")\n    oversampled_pred = predict(oversampled_model, newdata = test, type = \"response\")\n    ```", "```py\n\n    # apply threshold to convert the probabilities into binary classes\n    undersampled_pred_class = ifelse(undersampled_pred > 0.5, 1, 0)\n    oversampled_pred_class = ifelse(oversampled_pred > 0.5, 1, 0)\n    ```", "```py\n\n    # calculate the confusion matrix\n    undersampled_cm = table(predicted = undersampled_pred_class, actual = test$Class_num)\n    oversampled_cm = table(predicted = oversampled_pred_class, actual = test$Class_num)\n    >>> undersampled_cm\n             actual\n    predicted   0   1\n            0 117  59\n            1  79  45\n    >>> oversampled_cm\n             actual\n    predicted   0   1\n            0 115  59\n            1  81  45\n    ```", "```py\n\n# Create a matrix of predictors and a response vector\n# For glmnet, we need to provide our data as matrices/vectors\nX = GermanCredit[1:nrow(GermanCredit), 1:9]\ny = GermanCredit$Class_num\n# Define an alpha value: 0 for ridge, 1 for lasso, between 0 and 1 for elastic net\nalpha_value = 1 # for lasso\n# Run the glmnet model\nfit = glmnet(X, y, family = \"binomial\", alpha = alpha_value)\n```", "```py\n\n# plot coefficient paths\n>>> plot(fit, xvar = \"lambda\", label = TRUE)\n```", "```py\n\nlibrary(nnet)\n# convert gear to factor\nmtcars$gear = as.factor(mtcars$gear)\n>>> table(mtcars$gear)\n3  4  5\n15 12  5\n```", "```py\n\n# fit the model\nmultinom_model = multinom(gear ~ mpg + hp + disp, data = mtcars)\n# weights:  15 (8 variable)\ninitial  value 35.155593\niter  10 value 10.945783\niter  20 value 9.011992\niter  30 value 8.827997\niter  40 value 8.805003\niter  50 value 8.759821\niter  60 value 8.742738\niter  70 value 8.737492\niter  80 value 8.736569\nfinal  value 8.735812\nconverged\n```", "```py\n\n# view summary of the model\n>>> summary(multinom_model)\nCall:\nmultinom(formula = gear ~ mpg + hp + disp, data = mtcars)\nCoefficients:\n  (Intercept)       mpg         hp        disp\n4   0.3892548 0.2707320 0.02227133 -0.04428756\n5 -17.6837050 0.6115097 0.15511207 -0.08815984\nStd. Errors:\n  (Intercept)       mpg         hp       disp\n4    17.30456 0.5917790 0.05813736 0.02735148\n5    15.46373 0.5754793 0.08651377 0.06060359\nResidual Deviance: 17.47162\nAIC: 33.47162\n```", "```py\n\n# make prediction\npredicted_gears = predict(multinom_model, newdata = mtcars)\n# view the confusion matrix\n>>> table(Predicted = predicted_gears, Actual = mtcars$gear)\n         Actual\nPredicted  3  4  5\n        3 14  0  0\n        4  1 12  1\n        5  0  0  4\n```"]