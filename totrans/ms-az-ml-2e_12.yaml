- en: '*Chapter 9*: Building ML Models Using Azure Machine Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we learned about datasets, preprocessing, feature
    extraction, and pipelines in Azure Machine Learning. In this chapter, we will
    use the knowledge we have gained so far to create and train a powerful tree-based
    ensemble classifier.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will look behind the scenes of popular ensemble classifiers such as
    **random forest**, **XGBoost**, and **LightGBM**. These classifiers perform extremely
    well in practical real-world scenarios, and all are based on decision trees under
    the hood. By understanding their main benefits, you will be able to spot problems
    that can be solved with ensemble decision tree classifiers easily.
  prefs: []
  type: TYPE_NORMAL
- en: We will also learn the difference between **gradient boosting** and **random
    forest** and what makes these tree ensembles useful for practical applications.
    Both techniques help to overcome the main weaknesses of decision trees and can
    be applied to many different classification and regression problems.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will train a LightGBM classifier on a sample dataset using all the
    techniques we have learned so far. We will write a training script that automatically
    logs all parameters, evaluation metrics, and figures, and is configurable with
    command-line arguments. We will schedule the training script on an Azure Machine
    Learning training cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Working with tree-based ensemble classifiers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training an ensemble classifier model using LightGBM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will use the following Python libraries and versions to
    create decision tree-based ensemble classifiers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`azureml-core 1.34.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`azureml-sdk 1.34.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lightgbm 3.2.1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy 1.19.5`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas 1.3.2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scikit-learn 0.24.2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`seaborn 0.11.2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matplotlib 3.4.3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similar to previous chapters, you can execute this code using either a local
    Python interpreter or a notebook environment hosted in Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'All code examples in this chapter can be found in the GitHub repository for
    this book: [https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter09](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter09).'
  prefs: []
  type: TYPE_NORMAL
- en: Working with tree-based ensemble classifiers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Supervised tree-based ensemble classification and regression techniques have
    proven very successful in many practical real-world applications in recent years.
    Hence, they are widely used today in various applications, including fraud detection,
    recommendation engines, tagging engines, and many more. All your favorite mobile
    and desktop operating systems, Office programs, and audio or video streaming services
    make heavy use of them every day.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, in this section, we will dive into the main reasons for their popularity
    and performance, both for training and scoring. If you are an expert on traditional
    ML algorithms and know the difference between boosting and bagging, you might
    as well jump right to the next section, *Training an ensemble classifier model
    using LightGBM*, where we put the theory into practice.
  prefs: []
  type: TYPE_NORMAL
- en: We will first look at decision trees, a very simple technique that is decades
    old. We encourage you to follow along even with the simple methods as they build
    the foundation of today's state-of-the-art classical supervised ML approaches.
    We will also explore the advantages of tree-based classifiers in detail to help
    you understand the differences between a classical approach and a deep learning-based
    ML model.
  prefs: []
  type: TYPE_NORMAL
- en: A single decision tree also has a lot of disadvantages associated with it and
    is therefore used only in ensemble models and never as an individual model. We
    will take a closer look at the disadvantages of individual decision trees later
    in this section. Afterwards, we will discover methods for combining multiple weak
    individual trees into a single strong ensemble classifier that builds upon the
    strengths of tree-based approaches and transforms them into what they are today—powerful
    multi-purpose supervised ML models that are integrated into almost every off-the-shelf
    ML platform.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding a simple decision tree
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's first discuss what a `if/else` statements. This function can be a continuous
    regressor function or a decision boundary function. Hence, like many other ML
    approaches, decision trees can be used for learning both regression and classification
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the preceding description, we can immediately spot a few important advantages
    of decision trees:'
  prefs: []
  type: TYPE_NORMAL
- en: One is the flexibility to work on different data distributions, data types (for
    example, numerical and categorical data), and ML problems (such as classification
    or regression).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another advantage and one of the reasons they compete with more complicated
    models is their interpretability. Tree-based models and ensembles can be visualized
    and even printed out on paper to explain the decision (output) from a prediction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third advantage lies in their practical use for training performance, model
    size, and validity. Integrating a pre-trained decision tree into a desktop, web,
    or mobile application is a lot less complex and a lot faster than a deep learning
    approach.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Please note that we don't intend to sell tree-based ensembles as the solution
    to every ML problem and to downplay the importance of deep learning approaches.
    We rather want to make you aware of the strengths of traditional approaches in
    this chapter so you can evaluate the right approach for your problem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following figure shows an example of a decision tree used to decide whether
    a person is fit or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – A simple decision tree ](img/B17928_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – A simple decision tree
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 9.1* is an example of a trained decision tree, where we can score the
    model by simply walking through each node and arriving at a class label at the
    leaf of the tree.'
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of a decision tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Decision tree-based ML models are extremely popular due to their strengths
    when working on real-world applications where data comes in all forms and shapes
    and is messy, biased, and incomplete. These are the key advantages of decision
    trees:'
  prefs: []
  type: TYPE_NORMAL
- en: They support a wide range of applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They require little data preparation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The enable interpretability of the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They provide fast training and fast scoring.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, let's focus on the *flexibility* of decision trees, which is one of their
    major strengths as opposed to many other classical/statistical ML approaches.
    While the general framework is very flexible and supports *classification* and
    *regression*, as well as *multi-output problems*, it gained a lot of popularity
    because it can handle both numerical and categorical data out of the box. Thanks
    to nested `if-else` trees, it can also handle nominal categories as well as NULL
    or missing values in data. Decision trees are popular because they don't require
    massive preprocessing and data cleansing beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: While data preparation and cleaning are important steps in every ML pipeline,
    it's still nice to have a framework that naturally supports categorical input
    data out of the box. Some ensemble tree-based classifiers are built on top of
    this advantage, for example, **CatBoost**—a gradient boosted trees implementation
    from Yandex Research with native support for categorical data.
  prefs: []
  type: TYPE_NORMAL
- en: Another important advantage of tree-based models, especially from a business
    perspective, is the *interpretability* of the model. Unlike other ML approaches,
    the output of a decision tree classifier model is not a huge parametric decision
    boundary function. Trained deep learning models often generate a model with more
    than 100 million parameters and hence behave like a black box—especially for business
    decision makers. While it is possible to gain insights and reason about the activations
    in deep learning models, it's usually very hard to reason about the effect of
    an input parameter on the output variable.
  prefs: []
  type: TYPE_NORMAL
- en: Interpretability is where tree-based approaches shine. In contrast to many other
    traditional ML approaches (such as SVM, logistic regression, or deep learning),
    a decision tree is a non-parametric model and therefore, doesn't use parameters
    to describe the function to be learned. It uses a nested decision tree that can
    be plotted, visualized, and printed out on paper. This allows decision makers
    to understand every decision (output) of a tree-based classification model—it
    may require a lot of paper, but it is always possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'While speaking about interpretability, we need to mention another important
    aspect of decision trees: the decision tree model implicitly develops a notion
    of *feature importance* during the training process. This is a very useful output
    of a trained decision tree model that we can use to rank features for preprocessing,
    without requiring to first clean the data.'
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: While feature importance can also be measured with other ML approaches, for
    example, linear regression, they usually require a cleaned and normalized dataset
    as input. Many other ML approaches, such as SVM or deep learning, don't develop
    a measure of feature importance for the individual input dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Decision tree-based approaches excel at this as they internally create each
    individual split (decision) based on an importance criterion. This results in
    an inherent understanding of how and which feature dimensions are important to
    the final model.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at another great advantage of decision trees. Decision trees have
    many practical benefits over traditional statistical models derived from the non-parametric
    approach. Tree-based models generally yield good results on a wide variety of
    input distributions and even work well when the model assumptions are violated.
    On top of that, the size of the trained tree is small compared to deep learning
    approaches, and inference/scoring is fast.
  prefs: []
  type: TYPE_NORMAL
- en: Disadvantages of a decision tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As everything in life comes with advantages and disadvantages, the same is true
    for decision trees. There are quite a few severe disadvantages associated with
    individual decision trees that should make you avoid a single decision tree classifier
    in your ML pipeline. The main weakness of a single decision tree is that the tree
    is fitted on all training samples and, hence, is very likely to *overfit*. The
    reason for this is that the model itself tends to build complex `if-else` trees
    to model a continuous function.
  prefs: []
  type: TYPE_NORMAL
- en: Another important point is that finding the optimal decision tree even for simple
    concepts is an **NP-hard problem** (also known as a **nondeterministic polynomial
    time-hard problem**). Therefore, it is solved through heuristics and the resulting
    single decision is usually not the optimal one.
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting is bad – very bad – and leads to a serious complication in ML. Once
    a model overfits, it doesn't generalize well and hence has very poor performance
    on unseen data. Therefore, predictions for new inputs will yield results that
    are worse than those measured during training. Another related problem is that
    tiny changes in the training data or the order of training samples can lead to
    very different nested trees and hence, the training convergence is unstable. Single
    decision trees are extremely prone to overfitting. On top of that, a single decision
    tree is very likely to be biased toward the class with the largest number of samples
    in your training data.
  prefs: []
  type: TYPE_NORMAL
- en: You can overcome the disadvantages of single trees, such as overfitting, instability,
    and non-optimal trees, by combining multiple decision trees through bagging and
    boosting to an **ensemble model**. There are also many tree-based optimizations,
    including **tree pruning**, to improve generalization. Popular models that use
    these techniques include **random forests** and **gradient boosted trees**, which
    overcome most of the problems of a single decision tree while keeping most of
    their benefits. We will look at these two methods in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Some more fundamental disadvantages sometimes crop up even with tree-based ensemble
    methods that are worth mentioning. Due to the nature of decision trees, tree-based
    models have difficulties learning complicated functions, such as the XOR problem.
    For these problems, it's better to use non-linear parametric models, such as neural
    networks and deep learning approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Combining classifiers with bagging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One key disadvantage of a single decision tree is overfitting to training data
    and, hence, poor generalization performance and instability from small changes
    in the training data. A **bagging** (also called *bootstrap aggregation*) classifier
    uses the simple concept of combining multiple independent models into an **ensemble
    model** trained on a subset of the training data to overcome this exact problem.
    The subsets are built by randomly picking samples from the training dataset with
    replacements. The output of the individual models is either selected through a
    majority vote for classification or mean aggregation for regression problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'By combining independent models, we can reduce the variance of the combined
    model without increasing the bias and thereby greatly improve generalization.
    However, there is another benefit to training multiple individual models: parallelization.
    Since each individual model uses a random subset of the training data, the training
    process can easily be parallelized and trained on multiple compute nodes. Therefore,
    bagging is a popular technique when training a large number of tree-based classifiers
    on a large dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: The following *Figure 9.2* shows how each classifier is trained independently
    on the same training data—each model uses a random subset with replacements. The
    combination of all individual models makes up the ensemble model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Bagging ](img/B17928_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Bagging
  prefs: []
  type: TYPE_NORMAL
- en: Bagging can be used to combine any ML model; however, it is often used with
    tree-based classifiers as they suffer most from overfitting. The idea of **random
    forest** builds on top of the bagging method combined with a random subset of
    features for each split (decision). When a feature is selected at random, the
    optimal threshold for the split is computed such that a certain *information criterion*
    is optimized (usually **GINI** or **information gain**). Hence, the random forest
    uses a random subset of the training data, random feature selection, and an optimal
    threshold for the split.
  prefs: []
  type: TYPE_NORMAL
- en: Random forests are widely used for their simple decision tree-based model combined
    with much better generalization and easy parallelization. Another benefit of taking
    a random subset of features is that this technique also works well with very high-dimensional
    inputs. Hence, when dealing with classical ML approaches, random forests are often
    used for large-scale tree ensembles.
  prefs: []
  type: TYPE_NORMAL
- en: Another popular tree-based bagging technique is the **extra-trees** (short for
    **extremely randomized trees**) algorithm, which adds another randomization step
    on the dimension split. For each split, thresholds are drawn at random and the
    best one is selected for that decision. Hence, in addition to random features,
    the extra-trees algorithm also uses random split thresholds to further improve
    generalization.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following *Figure 9.3* shows how all tree ensemble techniques are used
    for inferencing. Each tree computes an individual score while the result of each
    tree is aggregated to yield the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Majority voting ](img/B17928_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Majority voting
  prefs: []
  type: TYPE_NORMAL
- en: You can find tree-based bagging ensembles such as random forest, and sometimes
    also extra-trees, in many popular ML libraries, such as scikit-learn, Spark MLlib,
    ML.NET, and many others.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing classifiers with boosting rounds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many problems in computer science, we can replace a random greedy approach
    with a more complex but more optimal approach. The same holds true for tree ensembles
    and builds the foundation for **boosted tree ensembles**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic idea behind boosting is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We start to train an individual model on the whole training dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then we compute the predictions of the model on the training dataset and start
    weighting training samples that yield a wrong result higher.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we train another decision tree using the weighted training set. We then
    combine both decision trees into an ensemble and predict the output classes for
    the weighted training set. We then further increase the weights on the wrongly
    classified training samples of the combined model for the next boosting round.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We continue this algorithm until a stopping criterion is reached.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following *Figure 9.4* shows how the training error using boosting optimization
    decreases each iteration (boosting round) with the addition of a new tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Boosting ](img/B17928_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Boosting
  prefs: []
  type: TYPE_NORMAL
- en: The first boosting algorithm was **AdaBoost**, which combined multiple weak
    models into an ensemble by fitting it on a weighted training set that adapts each
    iteration through a learning rate. The notion of this approach was to add individual
    trees that focus on predicting something the previous trees couldn't predict.
  prefs: []
  type: TYPE_NORMAL
- en: One particular successful technique of boosting is **gradient boosted trees**
    (or **gradient boosting**). In gradient boosting, you combine the gradient descent
    optimization technique with boosting in order to generalize boosting to an arbitrary
    loss function. Now, instead of tuning the dataset samples using weights, we can
    compute the gradient of the loss function and select the optimal weights—the ones
    that minimize the loss function—during each iteration. Thanks to the usage of
    optimization, this technique yields very good results, adding to the existing
    advantages of decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient boosted tree-based ensembles are included in many popular ML libraries
    such as scikit-learn, Spark MLlib, and others. However, some individual implementations,
    such as XGBoost and LightGBM, have gained quite a lot of popularity and are available
    as standalone libraries and as plugins for scikit-learn and Spark.
  prefs: []
  type: TYPE_NORMAL
- en: Training an ensemble classifier model using LightGBM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both random forest and gradient boosted trees are powerful ML techniques due
    to the simplicity of decision trees and the benefits of combining multiple classifiers.
    In this example, we will use the popular LightGBM library from Microsoft to implement
    both techniques on a test dataset. LightGBM is a framework for gradient boosting
    that incorporates multiple tree-based learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this section, we will follow a typical best-practice approach using Azure
    Machine Learning and perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Register the dataset in Azure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a remote compute cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement a configurable training script.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the training script on the compute cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log and collect the dataset, parameters, and performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Register the trained model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Before we start with this exciting approach, we'll take a quick look at why
    we chose LightGBM as a tool for training bagged and boosted tree ensembles.
  prefs: []
  type: TYPE_NORMAL
- en: LightGBM in a nutshell
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LightGBM uses many optimizations of classical tree-based ensemble techniques
    to provide excellent performance on both categorical and continuous features.
    The latter is profiled using a histogram-based approach and converted into discrete
    bins of optimal splits, which reduces memory consumption and speeds up training.
    This makes LightGBM faster and more memory efficient than other boosting libraries
    that use pre-sorted algorithms for computing splits, and hence is a great choice
    for large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Another optimization in LightGBM is that trees are grown vertically, leaf after
    leaf, whereas other similar libraries grow trees horizontally, layer after layer.
    In a leaf-wise algorithm, the newly added leaf always has the largest decrease
    in loss. This means that these algorithms tend to achieve less loss compared to
    level-wise algorithms. However, greater depth also results in overfitting, and
    therefore you must carefully tune the maximum depth of each tree. Overall, LightGBM
    produces great results using default parameters on a large set of applications.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 7*](B17928_07_ePub.xhtml#_idTextAnchor112), *Advanced Feature Extraction
    with NLP*, we learned a lot about categorical feature embedding and extracting
    semantic meanings from textual features. We looked at common techniques for embedding
    nominal categorical variables, such as label encoding and one-hot encoding, and
    others. However, to optimize the split criterion in tree-based learners for categorical
    variables, there are better encodings to produce optimal splits. Therefore, we
    don't encode categorical variables at all in this section, but simply tell LightGBM
    which of the variables used are categorical.
  prefs: []
  type: TYPE_NORMAL
- en: One last thing to mention is that LightGBM can take advantage of GPU acceleration,
    and training can be parallelized both in a data-parallel or model-parallel way.
    We will learn more about distributed training in [*Chapter 12*](B17928_12_ePub.xhtml#_idTextAnchor189),
    *Distributed Machine Learning on Azure*.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: LightGBM is a great choice for a tree-based ensemble model, especially for very
    large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use LightGBM with the `lgbm` namespace throughout this book. We can
    then call different methods from the namespace directly by typing four characters
    less—a best-practice approach among data scientists in Python. Let''s see a simple
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'What is interesting to note is that all algorithms are trained via the `lgbm.train()`
    method and we use different parameters to specify the algorithm, application type,
    and loss function, as well as additional hyperparameters for each algorithm. LightGBM
    supports multiple decision tree-based ensemble models for bagging and boosting.
    These are the algorithm options that you can choose from, along with their names,
    to identify them for the boosting parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gbdt`: Traditional gradient boosting decision tree'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rf`: Random forest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dart`: Dropouts meet multiple additive regression trees'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`goss`: Gradient-based one-side sampling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first two options, namely, *gradient boosting decision tree* (`gbdt`), which
    is the default choice of LightGBM, and *random forest* (`rf`), are classical implementations
    of the boosting and bagging techniques, explained in the first section of this
    chapter, with LightGBM-specific optimizations. The other two techniques, *dropouts
    meet multiple additive regression trees* (`dart`) and *gradient-based one-side
    sampling* (`goss`), are specific to LightGBM and provide more optimizations for
    better results in a trade-off for training speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The objective parameter—which is one of the most important parameters—specifies
    the application type of the model, and hence the ML problem you''re trying to
    solve. In LightGBM, you have the following standard options, which are similar
    to most other decision tree-based ensemble algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '`regression`: For predicting continuous target variables'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary`: For binary classification tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`multiclass`: For multiclass classification problems'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Besides the standard choices, you can also choose between the following more
    specific objectives: `regression_l1`, `huber`, `fair`, `poisson`, `quantile`,
    `mape`, `gamma`, `cross_entropy`, and many others.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Directly related to the objective parameter of the model is the choice of loss
    function to measure and optimize the training performance. Here, too, LightGBM
    gives us the default options that are also available in most other boosting libraries,
    which we can specify via the metric parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mae`: Mean absolute error'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mse`: Mean squared error'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_logloss`: Loss for binary classification'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`multi_logloss`: Loss for multi-classification'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apart from these loss metrics, other metrics are supported as well, such as
    `rmse`, `quantile`, `mape`, `huber`, `fair`, `poisson`, and many others. In our
    classification scenario, we will choose the `dart` algorithm with the `binary`
    objective and `binary_logloss` metric.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: You can also use LightGBM as a scikit-learn estimator. To do so, call the `LGBMModel`,
    `LGBMClassifier`, or `LGBMRegressor` model from the `lightgbm` namespace. However,
    the latest features are typically only available through the LightGBM interface.
  prefs: []
  type: TYPE_NORMAL
- en: Now, knowing how to use LightGBM, we can start with the implementation of the
    data preparation and authoring script.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will read and prepare the data and register the cleaned
    data as a new dataset in Azure Machine Learning. This will allow us to access
    the data from any compute target connected with the workspace without the need
    to manually copy data around, mount disks, or set up connections to datastores.
    This was discussed in detail in [*Chapter 4*](B17928_04_ePub.xhtml#_idTextAnchor071),
    *Ingesting Data and Managing Datasets*. All the setup, scheduling, and operations
    will be done from an authoring environment—a *Jupyter notebook*.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the classification example, we will use the *Titanic dataset*, a popular
    dataset for ML practitioners to predict the binary survival probability (*survived*
    or *not survived*) for each passenger on the Titanic. The features of this dataset
    describe the passengers and contain the following attributes: passenger ID, class,
    name, sex, age, number of siblings or spouse on the ship, number of children or
    parents on the ship, ticket identification number, fare, cabin number, and embarked
    port.'
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: The details about this dataset, as well as the complete preprocessing pipeline,
    can be found in the source code that comes with this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Without knowing any more details, we''ll roll up our sleeves and set up the
    workspace and start experimentation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We import `Workspace` and `Experiment` from `azureml.core` and specify the
    name `titanic-lgbm` for this experiment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we load the dataset using pandas, and start cleaning and preprocessing
    the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding example, we load the data from a CSV file, remove unused columns,
    replaced the values of the `Sex` feature with labels `0` and `1`, and encode the
    categorical values of the `Embarked` features with labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we write a small utility function, `df_to_dataset()`, which will help
    us to store pandas DataFrames and register and persist them as Azure datasets,
    in order to reuse them with ease anywhere in the Azure Machine Learning environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, we retrieve a reference to the default datastore of our ML workspace—this
    is the Azure Blob storage that was created when we first set up the workspace.
    Then, we use a helper function to upload the dataset to this default datastore
    and reference it as a tabular dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we use the newly created helper function to register the pandas DataFrame
    as a dataset with the name `titanic_cleaned`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the dataset is registered in Azure, it can be accessed anywhere in the
    Azure Machine Learning workspace. If we now go to the UI and click on the `titanic_cleaned`
    dataset. In the UI, we can also easily inspect and preview the data, as shown
    in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Titanic dataset ](img/B17928_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Titanic dataset
  prefs: []
  type: TYPE_NORMAL
- en: One thing worth mentioning is that we will first encode categorical variables
    to integers using label encoding, but later tell LightGBM which variables contain
    categorical information in the numeric columns. This will help LightGBM to treat
    these columns differently when computing the histogram and optimal parameter splits.
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of having the dataset registered is that we can now simply pass
    the data to a training script or access it from any Python interpreter from within
    Azure Machine Learning Let's continue with the training example and create a training
    and execution environment for LightGBM.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the compute cluster and execution environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we can start training the LightGBM classifier, we need to set up our
    training cluster and a training environment with all the required Python libraries.
    For this chapter, we choose a CPU cluster with up to four nodes of the type `STANDARD_D2_V2`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write a small helper function that lets us retrieve or create a training
    cluster with a specified name and configuration. We take advantage of `ComputeTargetException`,
    which is thrown if a cluster with a specified name was not found:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We have already seen the ingredients of this script in the previous chapters,
    where we called `AmlCompute.provisioning_configuration()` to provision a new cluster.
    It is extremely helpful that you can define all your infrastructure within your
    authoring environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s retrieve or create a new training cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we want to do the same for our training environment and Python configuration.
    We implement a small `get_run_config()` function to return a remote execution
    environment with a Python configuration. This will be used to configure all the
    required Python packages for the training script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding script, we define `RunConfiguration` with the required packages
    for Azure Machine Learning such as `azureml-defaults`, and custom Python packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we use this function to configure a Python image with all the required
    `pip` packages, including `lightgbm`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The two functions used in the preceding snippets are very useful. The longer
    you work with Azure Machine Learning, the more abstractions you will build to
    easily interact with the Azure Machine Learning service.
  prefs: []
  type: TYPE_NORMAL
- en: Using the custom run configuration and custom Python packages, Azure Machine
    Learning will set up a Docker image and automatically register it in the *container
    registry*, as soon as we schedule a job using this run configuration. Let's first
    construct the training script and then schedule it on the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Building a LightGBM classifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have the dataset ready, and we''ve set up the environment and cluster
    for the training of the LightGBM classification model, we can set up the training
    script. The code from the preceding section was written in a Jupyter notebook.
    The following code in this section will now be written and stored in a Python
    file called `train_lgbm.py`. We will start building the classifier using the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we configure the run and extract the workspace configuration from the
    run. This should already look familiar as we have done this for almost every script
    that we have been scheduling on Azure Machine Learning so far:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we set up an argument parser to parse command-line parameters into LightGBM
    parameters. We start with a handful of parameters but could easily add all available
    parameters and default values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We recommend making your training scripts configurable. Use `argparse` to define
    datasets, input parameters, and default values. If you stick to this convention,
    all your model parameters will automatically be tracked in your Azure Machine
    Learning experiment. Another benefit is that you will later be able to tune the
    hyperparameters without changing a line of code in your training script.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, we can reference the cleaned dataset from the input argument and load
    it to memory using the `to_pandas_dataframe()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Having loaded the dataset as a pandas DataFrame, we can now start splitting
    the training data into training and validation sets. We will also split the target
    variable, `Survived`, from the training dataset into its own variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we tell LightGBM about categorical features, which are already transformed
    into numeric variables, but need special treatment to compute the optimal split
    values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create the actual LightGBM training and test sets from the pandas
    DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In contrast to scikit-learn, we cannot work directly with pandas DataFrames
    in LightGBM but need to use a wrapper class, `lgbm.Dataset`. This will give us
    access to all required optimizations and features, such as distributed training,
    optimization for sparse data, and meta-information about categorical features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having parsed the command-line arguments, we pass them into a parameter dictionary,
    which will then be passed to the LightGBM training method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'All parameters that are passed through command-line arguments are automatically
    logged in Azure Machine Learning. However, if you want programmatic access to
    the model parameters or to display them in the experiment overview in Azure Machine
    Learning, we can log them in the experiment. This will attach all the parameters
    to each run and make them available as parameter values in Azure Machine Learning.
    This means that we can later sort and filter the experiment runs by model parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Gradient boosting is an iterative optimization approach with a variable number
    of iterations and an optional early stopping criterion. Therefore, we also want
    to log all metrics for each iteration of the training script. Throughout this
    book, we will use a similar technique for all ML frameworks—namely, using a callback
    function that logs all available metrics to your Azure Machine Learning workspace.
    Let's write such a function using LightGBM's specification for custom callbacks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we create a callback object, which iterates over all the evaluation results
    and logs them for the run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After we have set the parameters for the LightGBM predictor, we can configure
    the training and validation procedure using the `lgbm.train()` method. We need
    to supply all arguments, parameters, and callbacks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: What's great about the preceding code is that by supplying the generic callback
    function, all training and validation scores will be logged to Azure automatically.
    Hence, we can follow the training iterations in real time, either in the UI or
    via the API—for example, inside a Jupyter widget that automatically collects all
    run information.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to evaluate the final training score, we use the trained classifier
    to predict a couple of default classification scores, such as `accuracy`, `precision`,
    and `recall`, as well as the combined `f1` score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We could already run the script and see all the metrics and the performance
    of the model in Azure. But this was just the start – we want more!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compute feature importance and track a plot of it and run it in Azure
    Machine Learning. We can do this in a few lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once this snippet is added to the training script, each training run will also
    store a feature importance plot. This is helpful to see how different metrics
    influence feature importance.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one more step we would like to add. Whenever the training script runs,
    we want to upload the trained model and register it in the model registry. By
    doing so, we can later take any training run and manually or automatically deploy
    the model to a container service. However, this can only be done by saving the
    training artifacts of each run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding snippet, we use the `joblib` package that originally was part
    of scikit-learn to save the classifier to disk. We then register the exported
    model as a LightGBM model in Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: That's it – we have written the whole training script. It's not extremely long,
    it's not super-complicated. The trickiest part is understanding how to pick some
    of the parameters of LightGBM and understanding gradient boosting in general—and
    that's why we dedicated the first half of the chapter to that topic. Let's now
    fire up the cluster and submit the training script.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling the training script on the Azure Machine Learning cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are logically jumping back to the authoring environment – the Jupyter notebook.
    The code from the previous section is stored as a `train_lgbm.py` file, and we''ll
    now get ready to submit it to the cluster. One great thing is that we made the
    training script configurable via command-line arguments, so we can tune the base
    parameters of the LightGBM model using CLI arguments. In the following steps,
    we will configure the authoring script to execute the training process:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s define the parameters for this model—we will use `dart`, with a standard
    learning rate of `0.01` and a dropout rate of `0.15`. We also pass the dataset
    as a named parameter to the training script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We specified the boosting method, `dart`. As we learned in the previous section,
    this technique performs very well but is not extremely performant and is a bit
    slower than the other options—`gbdt`, `rf`, and `goss`.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: This is also the same way that hyperparameters are passed by `HyperOpt`—the
    hyperparameter tuning tool in Azure Machine Learning—to the training script. We
    will learn a lot more about this in [*Chapter 11*](B17928_11_ePub.xhtml#_idTextAnchor178),
    *Hyperparameter Tuning and Automated Machine Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can pass the parameters to `ScriptRunConfig` and kick off the training
    script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code, we specify the file of our classifier, which is stored
    relative to the current authoring script. Azure Machine Learning will upload the
    training script to the default datastore and make it available on all cluster
    nodes that run the script.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s submit the run configuration and execute the training script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `RunDetails` method gives us an interactive widget with real-time logs of
    the remote computing service. We can see the cluster getting initialized and scaled
    up, the Docker images getting built and registered, and ultimately, also the training
    script logs.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: If you prefer other methods over an interactive Jupyter widget, you can also
    trail the logs using `run.wait_for_completion(show_output=True)` or `print(run.get_portal_url())`
    to get the URL to the experiment to run in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now switch over to the Azure Machine Learning UI and look for the run
    in the experiment. Once we click on it, we can navigate to the **Metrics** section
    and find an overview of all our logged metrics. You can see in the following *Figure
    9.6* how metrics that are logged multiple times with the same name get converted
    into vectors and displayed as line charts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.6 – Validation loss ](img/B17928_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – Validation loss
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, click on the **Images** section. When we do so, we are presented with
    the feature importance figure that we created in the training script. The following
    *Figure 9.7* shows how this looks in the Azure Machine Learning UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7 – Feature importance ](img/B17928_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – Feature importance
  prefs: []
  type: TYPE_NORMAL
- en: We saw how you can train a LightGBM classifier in Azure Machine Learning, taking
    advantage of an autoscaling Azure Machine Learning compute cluster. Logging metrics,
    figures, and parameters keeps all information about the training run in a single
    place. Together with saving snapshots of the training script, outputs, logs, and
    the trained model, this is invaluable for any professional, large-scale ML project.
  prefs: []
  type: TYPE_NORMAL
- en: What you should remember from this chapter is that gradient boosted trees are
    a very performant and scalable classical ML approach, with many great libraries,
    and support for distributed learning and GPU acceleration. LightGBM is one alternative
    offered by Microsoft that is well embedded in both the Microsoft and open source
    ecosystem. If you are looking for a classical, fast, and understandable ML model,
    our advice is to go with LightGBM.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to build a classical ML model in Azure Machine
    Learning.
  prefs: []
  type: TYPE_NORMAL
- en: You learned about decision trees, a popular technique for various classification
    and regression problems. The main strengths of decision trees are that they require
    little data preparation as they work well on categorical data and different data
    distributions. Another important benefit is their interpretability, which is especially
    important for business decisions and users. This helps you to understand when
    a decision tree-based ensemble predictor is appropriate to use.
  prefs: []
  type: TYPE_NORMAL
- en: However, we also learned about a set of weaknesses, especially regarding overfitting
    and poor generalization. Luckily, tree-based ensemble techniques such as bagging
    (bootstrap aggregation) and boosting help to overcome these problems. While bagging
    has popular methods such as random forests that parallelize very well, boosting,
    especially gradient boosting, has efficient implementations, including XGBoost
    and LightGBM.
  prefs: []
  type: TYPE_NORMAL
- en: You implemented and trained a decision tree-based classifier in Azure Machine
    Learning using the LightGBM library. LightGBM is developed at Microsoft and delivers
    great performance and training time through a couple of optimizations. These optimizations
    help LightGBM to keep a small memory footprint, even for larger datasets, and
    yield better losses with fewer iterations. You used Azure Machine Learning not
    only to execute your training script but also to track your model's training performance
    and the final classifier.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we will take a look at some popular deep learning
    techniques and how to train them using Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
