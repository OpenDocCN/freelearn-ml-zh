- en: '*Chapter 5*: Interpreting Results'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen throughout the previous chapters, Elastic ML creates extremely
    useful analysis as regards both anomaly detection and forecasting. But, up until
    this point, we've only looked at the results created by Elastic ML in a relatively
    superficial way. In this chapter, we will go deeper into learning about the results
    that are created, how they are stored, and how you can leverage those results
    in different ways to bring additional insight.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, this chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Viewing the Elastic ML results index
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomaly scores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Results index schema details
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-bucket anomalies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forecast results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Results API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom dashboards and Canvas workpads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The information in this chapter is based on the Elastic Stack as it exists in
    v7.10\.
  prefs: []
  type: TYPE_NORMAL
- en: Viewing the Elastic ML results index
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we go through much of the discussion of how users should interpret the results
    from Elastic ML''s anomaly detection jobs, it will be helpful to relate what is
    conveyed with how that information is stored within Elastic ML''s internal results
    index. To get a quick initial peek into that index, you can either query the index
    pattern directly using the `_search` API in Elasticsearch, or perhaps more intuitively,
    add the index pattern to Kibana and view the index with native Kibana tools. In
    order to do this, we must first use the following procedure to expose Elastic
    ML''s internal results index to Kibana:'
  prefs: []
  type: TYPE_NORMAL
- en: In Kibana, click on the side menu and then select **Stack Management** from
    the list:![Figure 5.1 – Selecting Stack Management
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17040_05_1.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.1 – Selecting Stack Management
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select **Index Patterns**:![Figure 5.2 – Selecting Index Patterns
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17040_05_2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.2 – Selecting Index Patterns
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select **Create index pattern**:![Figure 5.3 – Selecting the Create index pattern
    button
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17040_05_3.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.3 – Selecting the Create index pattern button
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enter `.ml-anomalies-*` for the **Index pattern name** and then toggle the **Include
    system and hidden indices switch to on**. Then, click the **Next step** button:![Figure
    5.4 – Naming the index pattern
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17040_05_4.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.4 – Naming the index pattern
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Choose `timestamp` for **Time field** and then click the **Create index pattern**
    button:![Figure 5.5 – Defining the time field
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17040_05_5.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.5 – Defining the time field
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Confirm that the index pattern is defined:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Confirming that the index pattern is defined'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.6 – Confirming that the index pattern is defined
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that the index pattern for `.ml-anomalies-*` is defined, we can use Kibana''s
    Discover to explore the contents of the results index (select **Discover** from
    the main Kibana menu):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Viewing the results index in Kibana Discover'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.7 – Viewing the results index in Kibana Discover
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''re able to view the results index in Kibana Discover, we can use
    Discover''s search and filter capabilities to explore the results in any way that
    we want. For example, you could retrieve all record-level anomalies for a certain
    anomaly detection job name where the record''s anomaly score is more than a certain
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Using Kibana Discover to search and filter anomalies'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_8.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.8 – Using Kibana Discover to search and filter anomalies
  prefs: []
  type: TYPE_NORMAL
- en: 'The syntax of this query in KQL is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see two specific occurrences that matched our query. There is a
    plethora of information in the results index, and we will systematically learn
    to decipher the bulk of that information throughout this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: While it is safe to look at and query the results within the `.ml-anomalies-*`
    index pattern, we should remember that the indices matched by this index pattern
    are system indices and it is unwise to attempt to manually modify or delete the
    contents of these indices.
  prefs: []
  type: TYPE_NORMAL
- en: The first concept to understand is that there are different kinds of results
    (hence the `result_type` field) as well as different kinds of scores that reflect
    the analysis from different angles or levels. As such, let's start with a better
    understanding of the different kinds of scoring and how those scores are calculated
    and stored within the results index.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly scores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Interpreting the results of Elastic ML''s anomaly detection jobs first requires
    the ability to recognize the fact that there are several levels of scoring unusualness,
    expressed within the results. They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`result_type:bucket`): This level summarizes the results of the entirety of
    the anomaly detection job per time bucket. Essentially, it is a representation
    of how unusual that time bucket is, given the configuration of your job.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`result_type:influencer`): This is used to better understand the most unusual
    entities (influencers) within a timespan.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`result_type:record`): This is the most detailed information regarding every
    anomalous occurrence or anomalous entity within a time bucket. Again, depending
    on the job configuration (multiple detectors, splits, and so on), there can be
    many record-level documents per time bucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, to fully appreciate how scoring is done, we also need to fully
    understand the following concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Normalization**: The concept of projecting anomalousness onto a fixed scale
    between 0 and 100.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Influencers**: Entities that induce the creation of anomalies via their influential
    contribution to the dataset at the time that the anomaly occurs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's investigate each of these five concepts in more depth in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Bucket-level scoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An anomaly score at the bucket level is akin to answering the question, "How
    unusual was this interval of time, relative to all other intervals of time for
    this job?", where that interval is defined by the anomaly detection job''s `bucket_span`.
    If your job has multiple detectors or splits in the analysis resulting in results
    for possibly many entities simultaneously, then each bucket-level result is an
    aggregated representation of all of those things. The bucket-level anomaly score
    is viewable in a few ways, the first being the **Overall** swim lane at the top
    in the Anomaly Explorer UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – The swim lanes of the Anomaly Explorer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_9.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.9 – The swim lanes of the Anomaly Explorer
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we see that the `Max anomaly score` of `88`. It is important to note
    here that the time range being shown in this view encompasses data from January
    6th through February 5th; therefore, there are about 30 "tiles" horizontally in
    the swim lanes, with each one representing one day. The anomaly detection job
    was configured to have a bucket span of 15 minutes, so each tile shows the maximum
    score from the entire day. If we were to zoom the display to only one day using
    Kibana''s time picker (the date/time range control near the top-right corner of
    the screen), we would see more detail, specifically, that the bucket-level anomalies
    in the **Overall** swim lane occurred between 02:00 A.M. and 02:30 A.M.:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10 – The swim lanes of the Anomaly Explorer, after zooming in'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.10 – The swim lanes of the Anomaly Explorer, after zooming in
  prefs: []
  type: TYPE_NORMAL
- en: It is also important to note here how the **Overall** swim lane relates (or
    doesn't relate) to the grid of swim lanes below it. This grid of swim lanes shows
    influencer-level scoring (discussed in the next section) and is therefore not
    directly related to the bucket-level scoring. This is a common misconception,
    as many people think that the **Overall** swim lane is some type of combination
    (for example, a maximum score) of the columns from the grid below it. You can
    certainly see in *Figure 5.10* that this is obviously not true, as the group of
    influencer-level scores in the second row of the grid (around 07:00 A.M.) have
    no corresponding score at the **Overall** (bucket) level. Why is this? The short
    answer is that the **Overall** swim lane is a comparison of time buckets against
    one another. Therefore, the most unusual time buckets get the highest scores,
    and time buckets that are a lot less unusual (due to the number and severity of
    individual anomalies within that time bucket) get smaller scores, or even no score
    at all. The process of determining this relative scoring is called **normalization**.
    It is an important part of the scoring at all levels and deserves some independent
    explanation.
  prefs: []
  type: TYPE_NORMAL
- en: Normalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As first introduced in [*Chapter 1*](B17040_01_Epub_AM.xhtml#_idTextAnchor016),
    *Machine Learning for IT*, we saw that raw probability values for specific anomalies
    are normalized on a scale from 0 to 100\. This process is what allows there to
    be a relative ranking of anomalousness, while also bounding the values to a fixed
    interval of values that become useful in assessing severity for the purposes of
    triage and/or alerting.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key aspect in the last sentence is this notion of relative ranking. In
    other words, the normalized values take into account things that have been seen
    by the anomaly detection job *so far* and rank them accordingly. This also means
    that previously assigned normalized scores may change over time as new anomalies
    are discovered. As such, you will notice that scores within the results index
    have both an "initial" value and the current value, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '`initial_anomaly_score`: The bucket-level anomaly score that was recorded at
    the time the anomaly was created'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`anomaly_score`: The current bucket-level normalized anomaly score'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These two values may be the same but may indeed diverge over time. The initial
    score is a fixed value, but the current score may be adjusted as additional, perhaps
    as more egregious anomalies are encountered over time. The normalization process
    happens every few hours during real-time operation, or spontaneously if the analytics
    detect drastic changes in the normalization table. It is also done if the anomaly
    detection job is *closed* (put into the closed state). Normalization may rescore
    anomalies as far back in time as whatever the `renormalization_window_days` setting
    is configured to (30 days or 100 bucket spans is the default value, and the value
    is only changeable if the job is created with the API or the Advanced job wizard
    by directly modifying the job's configuration JSON).
  prefs: []
  type: TYPE_NORMAL
- en: Influencer-level scoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An anomaly score at the influencer level is akin to answering the question,
    "What are the most unusual entities during this time?", where we are now ranking
    these entities against one another. The influencer-level scores are viewable in
    a few ways, the first being the main grid of swim lanes in the middle of the Anomaly
    Explorer UI, and the second being the **Top influencers** list along the left-hand
    side:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Influencers in the Anomaly Explorer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.11 – Influencers in the Anomaly Explorer
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we see that in the main grid of swim lanes, the country codes of the
    `geo.src` field are listed in decreasing total influencer score. Notice that despite
    the grid being set to show 10 rows per page, only six anomalous country codes
    are listed (there are no more that have significant influencer scores during this
    time period). Also, the top influencers are listed on the left-hand side, showing
    for each entity both the maximum influencer score (99 for `geo.src:IN`) as well
    as the sum of all influencer scores for this time range (223 for `geo.src:IN`).
    In this case, since there is only one influencer defined for this job, so this
    information may seem redundant. However, many jobs have more than one influencer
    defined, so the view becomes more sensible in that case. For example, if we look
    at a population analysis job on the `kibana_sample_data_logs` index in which we
    choose `distinct_count("url.keyword") over clientip` as the detector and choose
    both `clientip` and `response.keyword` as influencers, the Anomaly Explorer view
    could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.12 – Multiple influencers in the Anomaly Explorer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.12 – Multiple influencers in the Anomaly Explorer
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the grid's `clientip`, but the **Top influencers** list on the left
    show both influencer lists.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Anomaly Explorer is interactive, so if we select the critical anomaly tile
    in the **Overall** swim lane for the day of February 19th, the influencer grid
    and lists change as the filter for that period is implicitly applied:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Anomaly Explorer filtered for a specific day'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.13 – Anomaly Explorer filtered for a specific day
  prefs: []
  type: TYPE_NORMAL
- en: We now see only the relevant entities for the selected day. Now that we've gotten
    a little bit of a sense of what influencers are, you may ask what fields are good
    candidates for influencers if this is how they can be represented? Let's take
    a quick detour to discuss influencers in more depth.
  prefs: []
  type: TYPE_NORMAL
- en: Influencers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within the anomaly detection job configuration, there is the ability to define
    fields as an influencer. The concept of an influencer is a field that describes
    an entity for which you'd like to know whether it is to blame for the existence
    of the anomaly, or at least whether it had a significant contribution. Note that
    any field chosen as a candidate to be an influencer doesn't need to be part of
    the detection logic, although it is natural to pick fields that are used as splits
    or populations to also be influencers.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we revisit the example shown in *Figure 5.13*, we see that both the `clientip`
    and the `response.keyword` fields were declared as influencers for the job (where
    `clientip` was part of the detector configuration, but `response.keyword` was
    not). The client IP address of `30.156.16.164` is identified as a top influencer.
    This seems a bit of a redundant declaration, because the anomaly was for that
    client IP – but this is an expected situation when influencers are chosen for
    the fields that define the population or are the split fields. The other top influencer
    (`response.keyword`) has a value of `404`. This particular piece of information
    is extremely relevant in that it gives the user an immediate clue of whatever
    the `30.156.16.164` IP address was doing during the anomaly. If we investigate
    the anomalous IP address at the time of the anomaly, we will see that 100% of
    the requests made resulted in a response code of `404`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14 – The influencer field value of 404 dominates the results at
    the time of the anomaly'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.14 – The influencer field value of 404 dominates the results at the
    time of the anomaly
  prefs: []
  type: TYPE_NORMAL
- en: As such, the value of `404` has a high influencer score (`50`, as shown in *Figure
    5.13*). You may think that because 100% of the requests were `404`, the influencer
    score should also be 100, but it is not that simple. The influencer scores are
    normalized against other influencer scores and the influencer score is also expressing
    how unusual the value of `404` has been over time. In this specific example dataset,
    there are hundreds more occurrences of `404` over time, but most of those have
    not been associated with anomalies. As such, the influencer score for this particular
    anomaly is tempered by that fact. There may be a compelling argument for Elastic
    ML to separate these two concepts – one score that expresses the unusualness of
    the entity over time, and another score for how much a field value influences
    a particular anomaly – but for the time being, those notions are blended into
    the influencer score.
  prefs: []
  type: TYPE_NORMAL
- en: It is also key to understand that the process of finding potential influencers
    happens after Elastic ML finds the anomaly. In other words, it does not affect
    any of the probability calculations that are made as part of the detection. Once
    the anomaly has been determined, ML will systematically go through all instances
    of each candidate influencer field and remove that instance's contribution to
    the data in that time bucket. If, once removed, the remaining data is no longer
    anomalous, then via counterfactual reasoning, that instance's contribution must
    have been influential and is scored accordingly (with an `influencer_score` in
    the results).
  prefs: []
  type: TYPE_NORMAL
- en: Influencers can become a very powerful thing to leverage when viewing the results
    of not just a single ML job, but potentially several related jobs. In [*Chapter
    7*](B17040_07_Epub_AM.xhtml#_idTextAnchor131), *AIOps and Root Cause Analysis*,
    we'll see how to effectively use influencers to assist with root cause analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Record-level scoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An anomaly score at the record level is the lowest level of abstraction in
    the results and contains the most amount of detail. In the Anomaly Explorer UI,
    the record-level results are shown in the table at the bottom:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15 – Anomaly table showing record-level results'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.15 – Anomaly table showing record-level results
  prefs: []
  type: TYPE_NORMAL
- en: Notice that if the **Interval** selector is set to **Auto**, then any anomalies
    that are adjacent serially in time will be collapsed such that only the highest
    score anomaly is shown. Setting the **Interval** field to **Show all** will reveal
    each individual anomaly, if desired.
  prefs: []
  type: TYPE_NORMAL
- en: A common misconception is that the record-level anomaly score is directly related
    to the deviation articulated in the `41x higher`). The score is purely driven
    by the probability calculation, using the same normalization process that was
    described earlier. The **description** field, and even the **typical** value,
    are simplified bits of contextual information to make the anomaly easier to understand.
    In fact, as you'll see later, the **description** field isn't stored in the results
    index – it is only calculated on the fly in Kibana.
  prefs: []
  type: TYPE_NORMAL
- en: When looking at these different level anomaly records in the `.ml-anomalies-*`
    index, we can see that many fields are there for our use. Some may be obvious,
    and some may not be. In the next section, we'll systematically go through the
    schema of the results index and will describe the meaning of the important fields.
  prefs: []
  type: TYPE_NORMAL
- en: Results index schema details
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we have already hinted, inside the results index, there are a variety of
    different documents, each with their own usefulness with respect to understanding
    the results of the anomaly detection jobs. The ones we will discuss in this section
    are the ones that directly relate to the three levels of abstraction that we discussed
    previously in this chapter. They are aptly named as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`result_type:bucket`: To give bucket-level results'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`result_type:record`: To give record-level results'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`result_type:influencer`: To give influencer-level results'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The distribution of these document types will depend on the ML job configuration
    and the characteristics of the dataset being analyzed. These document types are
    written with the following heuristic:'
  prefs: []
  type: TYPE_NORMAL
- en: '`result_type:bucket`: One document is written for every bucket span''s worth
    of time. In other words, if the bucket span is 15 minutes, then there will be
    one document of this type being written every 15 minutes. Its timestamp will be
    equal to the leading edge of the bucket. For example, for the time bucket that
    encompasses the range between 11:30 and 11:45, the result document of this type
    will have a timestamp of 11:30.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`result_type:record`: One document is written for every occurrence of an anomaly
    within a time bucket. Therefore, with big datasets encompassing many entities
    (IP addresses, hostnames, and so on), a particular bucket of time could have hundreds
    or even thousands of anomaly records in a bucket during a major anomalous event
    or widespread outage. This document will also have a timestamp equal to the leading
    edge of the bucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`result_type:influencer`: One document is written for every influencer that
    is found for each anomaly record. Because there can potentially be more than one
    influencer type found for each anomaly record, this type of document can be even
    more voluminous than record results. This document will also have a timestamp
    that is equal to the leading edge of the bucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the fields within these document types is especially important
    when we get to [*Chapter 6*](B17040_06_Epub_AM.xhtml#_idTextAnchor117), *Alerting
    on ML Analysis*, because there will inevitably be a balance between alert detail
    (usually, more is preferable to less) and the number of individual alerts per
    unit of time (usually, less is preferable to more). We will revisit this when
    we start writing actual alerts.
  prefs: []
  type: TYPE_NORMAL
- en: Bucket results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the highest level of abstraction are the results at the bucket level. Remember
    that this is the aggregated results for the entire job as a function of time and
    essentially answers the question, "How unusual was this bucket of time?"
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example document in the `.ml-anomalies-*` index by using
    Kibana Discover and issuing the following KQL query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This will yield the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.16 – Bucket-level result document as seen in Kibana Discover'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.16 – Bucket-level result document as seen in Kibana Discover
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on the **>** icon next to the timestamp for the document in *Figure
    5.16* will expand it so that you can see all of the details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.17 – Bucket-level document detail in Kibana Discover'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.17 – Bucket-level document detail in Kibana Discover
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see that just one bucket-level document was returned from our query
    in *Figure 5.16*, a single anomalous time bucket (at timestamp `1613824200000`,
    or in my time zone, February 20, 2021, 07:30:00 A.M. GMT-05:00) that has an `anomaly_score`
    greater than 98\. In other words, there were no other time buckets with anomalies
    that big in this time range. Let''s look at the key fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`timestamp`: The timestamp of the leading edge of the time bucket. In Kibana,
    this field will be displayed by default in your local time zone (although it is
    stored in the index in epoch format with the time zone of UTC).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`anomaly_score`: The current normalized score of the bucket, based upon the
    range of probabilities seen over the entirety of the job. The value of this score
    may fluctuate over time as new data is processed by the job and new anomalies
    are found.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`initial_anomaly_score`: The normalized score of the bucket, that is, when
    that bucket was first analyzed by the analytics. This score, unlike `anomaly_score`,
    will not change as more data is analyzed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`event_count`: The number of raw Elasticsearch documents seen by the ML algorithms
    during the bucket''s span.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_interim`: A flag that signifies whether the bucket is finalized or whether
    is still waiting for all of the data within the bucket span to be received. This
    field is relevant for ongoing jobs that are operating in real time. For certain
    types of analysis, there could be interim results, even though not all of the
    data for the bucket has been seen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`job_id`: The name of the anomaly detection job that created this result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`processing_time_ms`: An internal performance measurement of how much processing
    time (in milliseconds) the analytics took to process this bucket''s worth of data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bucket_influencers`: An array of influencers (and details on them) that have
    been identified for this current bucket. Even if no influencers have been chosen
    as part of the job configuration, or there are no influencers as part of the analysis,
    there will always be a default influencer of the `influencer_field_name:bucket_time`
    type, which is mostly an internal record-keeping device to allow for the ordering
    of bucket-level anomalies in cases where explicit influencers cannot be determined.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a job does have named and identified influencers, then the `bucket_influencers`
    array may look like what is shown in *Figure 5.17*.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that in addition to the default entry of the `influencer_field_name:bucket_time`
    type, in this case, there is an entry for a field name of an analytics-identified
    influencer for the `geo.src` field. This is a cue that `geo.src` was a relevant
    influencer type that was discovered at the time of this anomaly. Since multiple
    influencer candidates can be chosen in the job configuration, it should be noted
    that in this case, `geo.src` is the only influencer field and no other fields
    were found to be influential. It should also be noted that, at this level of detail,
    the particular instance of `geo.src` (that is, which one) is not disclosed; that
    information will be disclosed when querying at the lower levels of abstraction,
    which we will discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Record results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At a lower level of abstraction, there are results at the record level. Giving
    the most amount of detail, record results show specific instances of anomalies
    and essentially answer the question, "What entity was unusual and by how much?"
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example document in the `.ml-anomalies-*` index by using
    Kibana Discover and issuing the following KQL query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in something similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.18 – Record-level result document as seen in Kibana Discover'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.18 – Record-level result document as seen in Kibana Discover
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on the **>** icon next to the timestamp for the document will expand
    it so that you are able to see all of the details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.19 – Record-level document detail in Kibana Discover'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.19 – Record-level document detail in Kibana Discover
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see that a few bucket-level documents were returned from our query
    in *Figure 5.18*. Let''s look at the key fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`timestamp`: The timestamp of the leading edge of the time bucket, inside which
    this anomaly occurred. This is similar as explained earlier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`job_id`: The name of the anomaly detection job that created this result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`record_score`: The current normalized score of the anomaly record, based upon
    the range of the probabilities seen over the entirety of the job. The value of
    this score may fluctuate over time as new data is processed by the job and new
    anomalies are found.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`initial_record_score`: The normalized score of the anomaly record, that is,
    when that bucket was first analyzed by the analytics. This score, unlike `record_score`,
    will not change as more data is analyzed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`detector_index`: An internal counter to keep track of the detector configuration
    that this anomaly belongs to. Obviously, with a single-detector job, this value
    will be zero, but it may be non-zero in jobs with multiple detectors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`function`: A reference to keep track of which detector function was used for
    the creation of this anomaly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_interim`: A flag that signifies whether or not the bucket is finalized
    or whether the bucket is still waiting for all of the data within the bucket span
    to be received. This field is relevant for ongoing jobs that are operating in
    real time. For certain types of analysis, there could be interim results, even
    though not all of the data for the bucket has been seen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`actual`: The actual observed value of the analyzed data in this bucket. For
    example, if the function is `count`, then this represents the number of documents
    that are encountered (and counted) in this time bucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`typical`: A representation of the expected or predicted value based upon the
    ML model for this dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`multi_bucket_impact`: A measurement (on a scale from -5 to +5) that determines
    how much this particular anomaly was influenced by the secondary multi-bucket
    analysis (explained later in the chapter), from no influence (-5) to all influence
    (+5).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`influencers`: An array of which influencers (and the values of those influencers)
    are relevant to this anomaly record.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If a job has splits defined (either with `by_field_name` and/or `partition_field_name`)
    and identified influencers, then the record results documents will have more information,
    such as what is seen in *Figure 5.19*:'
  prefs: []
  type: TYPE_NORMAL
- en: '`partition_field_name`: A cue that a partition field was defined and that an
    anomaly was found for one of the partition field values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`partition_field_value`: The value of the partition field that this anomaly
    occurred for. In other words, the entity name this anomaly was found for.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to the fields mentioned here (which would have been `by_field_name`
    and `by_field_value` if the job had been configured to use a `by` field), we also
    see an explicit instance of the `geo.src` field. This is just a shortcut – every
    partition, `by`, or `over_field_value` in the results will also have a direct
    field name.
  prefs: []
  type: TYPE_NORMAL
- en: 'If your job is doing population analysis (via the use of `over_field_name`),
    then the record results document will be organized slightly differently as the
    reporting is done with orientation as to the unusual members of the population.
    For example, if we look at a population analysis job on the `kibana_sample_data_logs`
    index in which we choose `distinct_count("url.keyword") over clientip` as the
    detector, then an example record-level results document will also contain a causes
    array:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.20 – Record-level document showing the causes array for a population
    job'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.20 – Record-level document showing the causes array for a population
    job
  prefs: []
  type: TYPE_NORMAL
- en: The `causes` array is built to compactly express all of the anomalous things
    that that IP did in that bucket. Again, many things seem redundant, but it is
    primarily because there may be different ways of aggregating the information for
    results presentation in dashboards or alerts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, in the case of this population analysis, we see that the `influencers`
    array contains both the `clientip` field and the `response.keyword` field:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.21 – Record-level document showing the influencers array for a population
    job'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.21 – Record-level document showing the influencers array for a population
    job
  prefs: []
  type: TYPE_NORMAL
- en: Let's conclude our survey of the results index schema by looking at the influencers-level
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Influencer results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Yet another lens by which to view the results is via influencers. Viewing the
    results this way allows us to answer the question, "What were the most unusual
    entities in my ML job and when were they unusual?" To understand the structure
    and content of influencer-level results, let''s look at an example document in
    the `.ml-anomalies-*` index by using Kibana Discover and issuing the following
    KQL query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 5.22 – Influencer-level result document as seen in Kibana Discover'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.22 – Influencer-level result document as seen in Kibana Discover
  prefs: []
  type: TYPE_NORMAL
- en: Notice that in this case, we didn't query on the score (`influencer_score`),
    but rather on an expected entity name and value. The last document listed (with
    an `influencer_score` of `50.174`, matches what we saw back in *Figure 5.13*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the key fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`timestamp`: The timestamp of the leading edge of the time bucket, inside which
    this influencer''s anomalous activity occurred. This is similar to what was explained
    earlier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`job_id`: The name of the anomaly detection job that created this result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`influencer_field_name`: The name of the field that was declared as an influencer
    in the job configuration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`influencer_field_value`: The value of the influencer field for which this
    result is relevant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`influencer_score`: The current normalized score of how unusual and contributory
    the influencer was to anomalies at this point.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`initial_influencer_score`: The normalized score of the influencer when that
    bucket was first analyzed by the analytics. This score, unlike `influencer_score`,
    will not change as more data is analyzed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_interim`: A flag that signifies whether or not the bucket is finalized
    or whether the bucket is still waiting for all of the data within the bucket span
    to be received. This field is relevant for ongoing jobs that are operating in
    real time. For certain types of analysis, there could be interim results, even
    though not all of the data for the bucket has been seen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have exhaustively explained the relevant fields that are available
    to the user, we can file that information away for when we build custom dashboards,
    visualizations, and sophisticated alerting in subsequent sections and chapters.
    But, before we exit this chapter, we still have a few important concepts to explore.
    Next up is a discussion on a special kind of anomaly – the multi-bucket anomaly.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-bucket anomalies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Almost everything that we've studied so far with anomalies being generated by
    Elastic ML's anomaly detection jobs has been with respect to looking at a specific
    anomaly being raised at a specific time, but quantized at the interval of `bucket_span`.
    However, we can certainly have situations in which a particular observation within
    a bucket span may not be that unusual, but an extended window of time, taken collectively
    together, might be more significantly unusual than any single observation. Let's
    see an example.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-bucket anomaly example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First shown in the example in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection*, in *Figure 3.17*, we repeat the figure here to show how multi-bucket
    anomalies exhibit themselves in the Elastic ML UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.23 – Multi-bucket anomalies first shown in Chapter 3'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.23 – Multi-bucket anomalies first shown in Chapter 3
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection*, multi-bucket anomalies are designated with a different symbol
    in the UI (a cross instead of a dot). They denote cases in which the actual singular
    value may not necessarily be anomalous, but that there is a trend that is occurring
    in a sliding window of 12 consecutive buckets. Here, you can see that there is
    a noticeable slump spanning several adjacent buckets.
  prefs: []
  type: TYPE_NORMAL
- en: Note, however, that some of the multi-bucket anomaly markers are placed on the
    data at times after the data has "recovered." This can be somewhat confusing to
    users until you realize that because the determination of multi-bucket anomalies
    is a secondary analysis (in addition to the bucket-by-bucket analysis) and because
    this analysis is a sliding window looking in arrears, the leading edge of that
    window, when the anomaly is recorded, might be after the situation has recovered.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-bucket scoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned, multi-bucket analysis is a secondary analysis. Therefore, two
    probabilities are calculated for each bucket span – the probability of the observation
    seen in the current bucket, and the probability of a multi-bucket feature – a
    kind of weighted average of the current bucket and the previous 11\. If those
    two probabilities are roughly the same order of magnitude, then `multi_bucket_impact`
    will be low (on the negative side of the -5 to +5 scale). If, on the other hand,
    the multi-bucket feature probability is wildly lower (thus more unusual), then
    `multi_bucket_impact` will be high.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the example shown in *Figure 5.23,* the UI will show the user the multi-bucket
    impact as being `high`, but will not give you the actual scoring:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.24 – Multi-bucket anomalies, with impact scoring shown'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.24 – Multi-bucket anomalies, with impact scoring shown
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if you look at the raw record-level result, you will see that `multi_bucket_impact`
    has indeed been given a value of +5:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.25 – Multi-bucket anomaly record, with the raw score shown'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.25 – Multi-bucket anomaly record, with the raw score shown
  prefs: []
  type: TYPE_NORMAL
- en: Multi-bucket anomalies give you a different perspective on the behavior of your
    data. You will want to keep in mind how they are signified and scored via the
    `multi_bucket_impact` field in order for you to include or exclude them, as required,
    from your reporting or alerting logic.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now look forward (yes, pun intended) to how results from forecasts are
    represented in the results index.
  prefs: []
  type: TYPE_NORMAL
- en: Forecast results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As explained in depth in [*Chapter 4*](B17040_04_Epub_AM.xhtml#_idTextAnchor081),
    *Forecasting*, we can get Elastic ML to extrapolate into the future the trends
    of the data that has been analyzed. Recall what we showed in *Figure 4.21*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.26 – Forecast results first shown in Chapter 4'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.26 – Forecast results first shown in Chapter 4
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember that the prediction value is the value with the highest likelihood
    (probability), and that the shaded area is the range of the 95th percentile of
    confidence. These three key values are stored in the `.ml-anomalies-*` results
    indices with the following names:'
  prefs: []
  type: TYPE_NORMAL
- en: '`forecast_prediction`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`forecast_upper`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`forecast_lower`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Querying for forecast results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When querying for the forecast results in the `.ml-anomalies-*` results indices,
    it is important to remember that forecast results are transient – they have a
    default lifespan of 14 days following creation, especially if they are created
    from the UI in Kibana. If a different expiration duration is desired, then the
    forecast will have to be invoked via the `_forecast` API endpoint and explicitly
    setting the `expires_in` duration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another thing to remember is that multiple forecasts may have been invoked
    at different moments in time on the same dataset. As shown back in *Figure 4.4*
    and repeated here, multiple forecast invocations produce multiple forecast results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.27 – A symbolic representation of invoking multiple forecasts at
    different times'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.27 – A symbolic representation of invoking multiple forecasts at different
    times
  prefs: []
  type: TYPE_NORMAL
- en: 'As such, we need a way to discern between the results. In the Kibana UI, they
    are discernable simply by looking at the **Created** date:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.28 – Viewing multiple previously run forecasts'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.28 – Viewing multiple previously run forecasts
  prefs: []
  type: TYPE_NORMAL
- en: 'However, when looking at the results index, it should be noted that each invoked
    forecast has a unique `forecast_id`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.29 – Viewing forecast results in Kibana Discover'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.29 – Viewing forecast results in Kibana Discover
  prefs: []
  type: TYPE_NORMAL
- en: This `forecast_id` is only obvious when invoking the forecast using the `_forecast`
    API because `forecast_id` is returned as part of the payload of the API call.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, if multiple forecasts were created spanning a common time frame,
    there would be more than one result with different IDs.
  prefs: []
  type: TYPE_NORMAL
- en: 'When querying the forecast results, you can think of two possible orientations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Value-focused**: The query supplies a date and time, and the result is a
    particular value for that time is returned. The question, "What is my utilization
    5 days from now?" would be a good example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time-focused**: The query supplies a value, and the result is a time at which
    that value is realized. The question, "When does my utilization reach 80%?" would
    be a good example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Obviously, either type of query is possible. To satisfy the time-focused inquiry,
    for example, we need to re-orient the query a little to ask it to return the date
    (or dates) on which the predicted values meet certain criteria. The user can query
    for the forecast results using other traditional query methods (KQL, Elasticsearch
    DSL), but to mix it up a little, we''ll submit the query using Elastic SQL in
    the Kibana Dev Tools Console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are asking whether there are any times during which the predicted
    value exceeds our limit of the value of 16,890\. The response is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In other words, we may breach the threshold on March 17 at 9:45 A.M. GMT (although
    remember from [*Chapter 4*](B17040_04_Epub_AM.xhtml#_idTextAnchor081), *Forecasting*,
    that the sample data used is from the past and therefore forecast predictions
    are also in the past). Now that we have a good understanding of how to query for
    forecast results, we could include them in dashboards and visualizations, which
    we will cover later in this chapter – or even in alerts, as we'll see in [*Chapter
    6*](B17040_06_Epub_AM.xhtml#_idTextAnchor117), *Alerting on ML Analysis*.
  prefs: []
  type: TYPE_NORMAL
- en: But, before we look at including results in custom dashboards and visualizations,
    let's cover one last brief topic – the Elastic ML results API.
  prefs: []
  type: TYPE_NORMAL
- en: Results API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If programmatic access to the results is your thing, in addition to querying
    the results indices directly, you could opt to instead query Elastic ML's results
    API. Some parts of the API are redundant to what we've already explored, and some
    parts are unique. We will now check them out in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Results API endpoints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are five different results API endpoints available:'
  prefs: []
  type: TYPE_NORMAL
- en: Get buckets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get influencers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get records
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get overall buckets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get categories
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first three API endpoints give results that are redundant in light of what
    we've already covered in this chapter by way of querying the results index directly
    (through Kibana or using the Elasticsearch `_search` API), and that method actually
    allows more flexibility, so we really won't bother discussing them here. However,
    the last two API endpoints are novel, and each deserves an explanation.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the overall buckets API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The overall buckets API call is a means by which to return summarized results
    across multiple anomaly detection jobs in a programmatic way. We''re not going
    to explore every argument of the request body, nor will we describe every field
    in the response body, as you can reference the documentation. But we will discuss
    here the important function of this API call, which is to request the results
    from an arbitrary number of jobs, and to receive a single result score (called
    `overall_score`) that encapsulates the `top_n` average of the maximum bucket `anomaly_score`
    for each job requested. As shown in the documentation, an example call is one
    that asks for the top two jobs (in the set of jobs that begin with the name `job-`)
    whose bucket anomaly score, when averaged together, is higher than `50.0`, starting
    from a specific timestamp:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following sample return:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Notice that `overall_score` is the average of the two highest scores in this
    case (the result of `overall_score` of `55.0` is the average of the `job-3` score
    of `80.0` and the `job-1` score of `30.0`), even though three anomaly detection
    jobs match the query pattern of `job-*`. While this is certainly interesting,
    perhaps for building a composite alert, you should realize the limitations in
    this reporting, especially if you can only access the bucket-level anomaly score
    and not anything from the record or influencer level. In [*Chapter 6*](B17040_06_Epub_AM.xhtml#_idTextAnchor117),
    *Alerting on ML Analysis*, we will explore some options regarding composite alerting.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the categories API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `categories` API call is only relevant for jobs that leverage categorization,
    as described in detail in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection*. The `categories` API returns some interesting internal definitions
    of the categories found during the textual analysis of the documents. If we run
    the API on the categorization job that we created back in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection* (abbreviated to only return one record for brevity), the output
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We will see the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Several elements are part of the reply:'
  prefs: []
  type: TYPE_NORMAL
- en: '`category_id`: This is the number of the category of message (incremented from
    1). It corresponds to the value of the `mlcategory` field in the results index.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`terms`: This is a list of the static, non-mutable words extracted from the
    message.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`examples`: An array of complete, unaltered sample log lines that fall into
    this category. These are used to show the users what some of the real log lines
    look like.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`grok_pattern`: A regexp-style pattern match that could be leveraged for Logstash
    or an ingest pipeline that you could use to match this message category.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_matches`: A count of the number of times this message category was seen
    in the logs throughout the anomaly detection job running on this dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perhaps the most interesting use of this API is not for anomaly detection, but
    rather around merely understanding the unique number of category types and the
    distribution of those types in your unstructured logs – to answer questions such
    as, "What kinds of messages are in my logs and how many of each type?" Some of
    this capability may be leveraged in the future to create a "data preparation"
    pipeline to assist users in ingesting unstructured logs into Elasticsearch more
    easily.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now explore how results gleaned from Elastic ML's anomaly detection and
    forecasting jobs can be leveraged in custom dashboards, visualizations, and Canvas
    workpads.
  prefs: []
  type: TYPE_NORMAL
- en: Custom dashboards and Canvas workpads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's clear that now that we know the ins and outs of the results index, which
    stores all the goodness that comes out of Elastic ML's anomaly detection and forecast
    analytics, our imagination is the limit concerning how we can then express those
    results in a way that is meaningful for our own goals. This section will briefly
    explore some of the concepts and ideas that you can use to bring Elastic ML's
    results to a big screen near you!
  prefs: []
  type: TYPE_NORMAL
- en: Dashboard "embeddables"
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One recent addition to the capabilities of Elastic ML is the ability to embed
    the Anomaly Explorer timeline ("swim lanes") into existing custom dashboards.
    To accomplish this, simply click the "three dots" menu at the top right of the
    Anomaly timeline and select the **Add to dashboard** option:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.30 – Adding the Anomaly timeline to another dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_30.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.30 – Adding the Anomaly timeline to another dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, select which part of the swim lane views you want to include
    and select which dashboard(s) you wish to add them to:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.31 – Adding the Anomaly timeline to a specific dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_31.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.31 – Adding the Anomaly timeline to a specific dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on the **Add and edit dashboard** button will then transport the user
    to the target dashboard and allow them to move and resize the embedded panels.
    For example, we can have the anomalies side by side with the other visualizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.32 – New dashboard now containing Anomaly swim lane visualizations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_32.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.32 – New dashboard now containing Anomaly swim lane visualizations
  prefs: []
  type: TYPE_NORMAL
- en: Anomalies as annotations in TSVB
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `kibana_sample_data_logs` with the following panel options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.33 – Creating a new TSVB visualization – Panel options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_33.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.33 – Creating a new TSVB visualization – Panel options
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, there is the following configuration for the `geo.src`):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.34 – Creating a new TSVB visualization – Data options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_34.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.34 – Creating a new TSVB visualization – Data options
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we have the following configuration for the `web_traffic_per_country`
    to select anomalies with record scores over `90`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.35 – Creating a new TSVB visualization – Annotation options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_35.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.35 – Creating a new TSVB visualization – Annotation options
  prefs: []
  type: TYPE_NORMAL
- en: 'Note the `record_score` and `partition_field_value`) and `Anomaly:{{record_score}}
    for {{partition_field_value}}`). Once this is done, we have the final result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.36 – Creating a new TSVB visualization complete with anomaly annotations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_36.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.36 – Creating a new TSVB visualization complete with anomaly annotations
  prefs: []
  type: TYPE_NORMAL
- en: We now have a nice visualization panel with anomalies superimposed on the original
    raw data.
  prefs: []
  type: TYPE_NORMAL
- en: Customizing Canvas workpads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kibana Canvas is the ultimate tool for creating pixel-perfect infographics that
    are data-driven from Elasticsearch. You can create highly custom-tailored reports
    with a set of customizable elements. The experience in Canvas is very different
    from standard Kibana dashboards. Canvas presents you with a workspace where you
    can build sets of slides (similar in concept to Microsoft PowerPoint) called the
    **workpad**.
  prefs: []
  type: TYPE_NORMAL
- en: To leverage anomaly detection and/or forecast results in a Canvas workpad, there
    isn't anything special that needs to be done – everything that has been learned
    so far in this chapter is applicable. This is because it is very easy to use the
    `essql` command in Canvas to query the `.ml-anomalies-*` index pattern and extract
    the information we care about.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we install the Kibana sample data, we also get a few sample Canvas workpads
    to enjoy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.37 – Sample Canvas workpads'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_37.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.37 – Sample Canvas workpads
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on the **[Logs] Web Traffic** sample workpad opens it for us to edit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.38 – Sample web traffic workpad'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_38.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.38 – Sample web traffic workpad
  prefs: []
  type: TYPE_NORMAL
- en: 'Selecting one of the elements on the page (perhaps the `324`) and then selecting
    **Expression** **editor** at the bottom-right corner of Canvas will reveal the
    details of the element:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.39 – Editing a Canvas element in the Expression editor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_39.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.39 – Editing a Canvas element in the Expression editor
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that the real "magic" of obtaining live data is embedded in the `essql`
    command – the rest of the expression is merely formatting. As a simple example,
    we can adjust the SQL with the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: One thing to note is that because the `.ml-anomalies-*` index pattern's name
    begins with a non-alphabet character, the name needs to be enclosed in double-quotes,
    and those double-quotes need to be escaped with the backslash character.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will return the total number of critical anomalies (those that have a
    `record_score` larger than `75`) for a particular anomaly detection job on that
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.40 – Displaying the count of critical anomalies'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_05_40.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.40 – Displaying the count of critical anomalies
  prefs: []
  type: TYPE_NORMAL
- en: In short, it is quite easy to use Canvas to create very beautiful and meaningful
    data visualizations and leverage information from either anomaly detection results
    or forecast results.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Elastic ML's anomaly detection and forecasting analytics creates wonderful and
    meaningful results that are explorable via the rich UI that is provided in Kibana,
    or programmatically via direct querying of the results indices and the API. Understanding
    the results of your anomaly detection and forecasting jobs and being able to appropriately
    leverage that information for further custom visualizations or alerts makes those
    custom assets even more powerful.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll leverage the results to create sophisticated and
    useful proactive alerts to further increase the operational value of Elastic ML.
  prefs: []
  type: TYPE_NORMAL
