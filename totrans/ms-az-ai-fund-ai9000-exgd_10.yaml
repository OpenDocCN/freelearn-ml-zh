- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Identify Features of Generative AI Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At last! This might be the most anticipated chapter of this book!
  prefs: []
  type: TYPE_NORMAL
- en: Unless you’ve been hiding under a rock for the last year and a half, you’ve
    probably heard of **Generative AI** (sometimes called **GenAI**). It’s the technology
    that enables services such as ChatGPT to have natural-sounding conversations and
    produce semi-original content (we’ll get into that a little bit later in this
    chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI is exploding right now, so there’s no better time to become familiar
    with its uses and applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'The objectives and skills we’ll cover in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: What is Generative AI?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify features of Generative AI models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify common scenarios for Generative AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify Responsible AI considerations for Generative AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you should be able to describe the various features
    of Generative AI, as well as articulate the importance of Responsible AI principles
    in conjunction with Generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go!
  prefs: []
  type: TYPE_NORMAL
- en: What is Generative AI?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Back in [*Chapter 1*](B22207_01.xhtml#_idTextAnchor016), *Identify Features
    of Common AI Workloads*, we introduced some broad concepts around Generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI represents one of the most exciting advancements in the field
    of AI, marking a significant shift from traditional AI systems, which are primarily
    designed to recognize patterns or make predictions based on input data (largely,
    statistical analysis and prediction). Instead, Generative AI focuses on creating
    new data instances that resemble the training data, not just in form but also
    in function. Generative AI is also useful in helping interpret data and can be
    used to identify patterns in content more quickly than traditional machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI applications leverage **large language models** (**LLMs**) for
    various **natural language processing** (**NLP**) tasks, such as sentiment analysis,
    text summarization, semantic similarity comparison between texts, and generating
    new text content. Despite the complexity of their mathematical foundations, understanding
    the architecture of LLMs can provide insights into their operational mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Identify Features of Generative AI models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll dive a little more deeply into the features of generative
    AI models, including the foundation components that enable Generative AI capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generative AI models possess several distinct features that enable them to
    generate new content, predict outcomes, and learn from data in ways that mimic
    human creativity and intelligence. Here are some of the key features of Generative
    AI models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Content generation**: One of the hallmark features of Generative AI is its
    ability to create new data instances that resemble the original data. This includes
    generating text, images, audio, and video that are similar to, but not exact replicas
    of, the training data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning data distributions**: Generative AI models are designed to understand
    and learn the underlying distribution of the data they are trained on. This allows
    them to produce outputs that are consistent with the real-world phenomena represented
    by the training data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handling ambiguity and creativity**: These models can handle ambiguous inputs
    and produce diverse outputs, showcasing a form of artificial creativity that’s
    frequently managed through a feature called **temperature**. For instance, when
    asked to generate images of animals, a generative AI model can produce various
    images of different animals in different settings (some of which may be non-existent
    in real life). Similarly, you can instruct a generative AI model to render its
    output in the style of an author or artist (such as *commentary in the style of
    Mark Twain*, *a painting of a cat in the style of Vincent van Goh*, or *lyrics
    that match the tone and tempo of Whitney Houston’s ‘I Wanna Dance* *With Somebody’*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adaptability**: Generative AI models can be adapted to various domains and
    tasks, such as creating realistic human voices, designing new molecular structures
    for drugs, or generating code based on natural language descriptions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unsupervised learning**: Many generative AI models can learn from data without
    explicit labels or annotations, which is known as unsupervised learning. This
    is particularly powerful for exploring large datasets where manual labeling is
    impractical.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interpretability and control**: Advanced generative AI models offer mechanisms
    to control and interpret the generation process, allowing users to specify certain
    attributes or guide the model toward desired outcomes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Personalization**: Generative AI can tailor content to individual preferences
    or requirements, making it highly relevant for personalized recommendations, customized
    content creation, and targeted marketing strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anomaly detection and data augmentation**: Despite being called *generative
    AI*, these models can identify unusual patterns in data (anomaly detection) and
    generate additional data points for training (data augmentation), enhancing the
    robustness and performance of other machine learning models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-modality**: Some generative AI models are multi-modal, meaning they
    can understand and generate content across different forms of data, such as converting
    text descriptions into images or translating between different languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Iterative improvement**: Generative models can refine their outputs through
    iterative processes, where initial results are progressively improved based on
    feedback or additional input, leading to higher quality and more precise outputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you’ve seen some of the things LLMs and generative AI models can do,
    let’s look specifically at what makes generative AI models such as ChatGPT or
    **Bidirectional Encoder Representations from Transformers** (**BERT**) so unique.
  prefs: []
  type: TYPE_NORMAL
- en: What’s a transformer model and how does it work?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Over the years, machine learning models dedicated to NLP have significantly
    evolved, leading to the advent of advanced LLMs based on transformer architecture.
    This architecture enhances previous techniques that are used for vocabulary modeling
    in NLP tasks, especially in terms of language generation. Transformers are trained
    on extensive text corpora (hence the terminology *LLM*), allowing them to understand
    semantic relationships between words and predict logical text sequences. With
    a comprehensive vocabulary, these models can produce responses nearly indistinguishable
    from those of actual people.
  prefs: []
  type: TYPE_NORMAL
- en: 'The transformer model architecture is fundamentally composed of two main parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Encoder block**: This component is responsible for creating semantic representations
    of words in the training vocabulary, capturing the context and meaning of each
    word within a given sequence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decoder block**: This part focuses on generating new sequences of language
    based on the semantic representations prepared by the encoder'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different implementations of transformer architecture may emphasize different
    components. For instance, Google’s **BERT** model, which is designed to enhance
    search engine results, primarily utilizes the encoder block. Conversely, OpenAI’s
    **Generative Pretrained Transformer** (**GPT**) model, aimed at generating human-like
    text, relies mainly on the decoder block.
  prefs: []
  type: TYPE_NORMAL
- en: While delving into all details of transformer models might be complex, understanding
    these fundamental elements offers a glimpse into how they underpin generative
    AI capabilities, enabling the creation of sophisticated and coherent language
    outputs.
  prefs: []
  type: TYPE_NORMAL
- en: While several processes and functions go into how these generative AI models
    work, they usually share some common concepts. We’ll cover these in the following
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: Tokenization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Tokenization** is a crucial preprocessing step in the workflow of LLMs and
    Generative AI where text data is broken down into smaller units called **tokens**.
    These tokens can be words, subwords, or even characters, depending on the model’s
    design and the granularity needed for the task. The process of tokenization allows
    models to efficiently process and understand the input text by analyzing it piece
    by piece, laying the foundation for further NLP tasks, such as language generation,
    translation, or sentiment analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: For LLMs and Generative AI, tokenization not only simplifies the complexity
    of the input text but also helps in capturing the context and semantics of the
    language. By breaking down the text into manageable units or chunks, the model
    can learn the relationships and patterns within the language, which is essential
    for generating coherent and contextually relevant text outputs that mimic human
    output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take, for example, the following sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Tokenization is essential* *for NLP.*'
  prefs: []
  type: TYPE_NORMAL
- en: In a simple word-based tokenization approach, this might be broken down into
    “Tokenization”, “is”, “essential”, “for”, “NLP”, and “.” as tokens. Each token
    then serves as an input for the LLM, which processes these tokens to understand
    the sentence’s structure and meaning. In more advanced models, such as those using
    subword tokenization, the word *Tokenization* might be further split into smaller
    tokens such as *Token* and *ization* to capture more granular linguistic features
    and handle unknown words or neologisms more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: This tokenized input enables LLMs to perform a wide range of Generative AI tasks,
    from completing sentences in a way that mimics human writing to translating sentences
    into different languages while preserving their original meaning. Through tokenization,
    LLMs can effectively navigate the complexities of human language, making it a
    foundational step in the world of NLP and Generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: Embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the context of LLMs and Generative AI, **embeddings** are high-dimensional
    vectors that are used to represent the tokens that are obtained from the tokenization
    process. These vectors capture the semantic and syntactic features of the words,
    allowing the model to understand the relationships between different words and
    their context within the text. The process of creating embeddings involves mapping
    each unique token to a point in a geometric space, where the distance and direction
    between points reflect the linguistic and contextual relationships between the
    words.
  prefs: []
  type: TYPE_NORMAL
- en: The process of generating embeddings allows LLMs to capture complex relationships
    between tokens, such as similarity, difference, and contextuality. For instance,
    words that appear in similar contexts tend to have closer embeddings in the vector
    space, which helps the model in tasks such as word prediction, sentence generation,
    and semantic analysis.
  prefs: []
  type: TYPE_NORMAL
- en: For example, taking our previously tokenized sentence, *Tokenization is essential
    for NLP*, each word (token) would be converted into an embedding – a **vector**
    (or coordinates) of real numbers. These embeddings would be used by the LLM to
    understand the sentence’s meaning and context. For instance, the model might learn
    that *Tokenization* and *NLP* are closely related concepts in the field of NLP,
    and their embeddings would be positioned closer in the vector space compared to
    unrelated words.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say the tokens were converted into the following vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Token ID** | **Token Value** | **X** | **Y** | **Z** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Tokenization | 8 | 7 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Is | -2 | 4 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Essential | -5 | -5 | -9 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | For | -7 | -7 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | NLP | 8 | 7 | 10 |'
  prefs: []
  type: TYPE_TB
- en: Table 10.1 – Tokens represented by coordinates
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Table 10.1*, each token exists in one dimension or plane (*X*, *Y*, and
    *Z*). You can think of embeddings as representing the tokens in a three-dimensional
    graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Tokens plotted on a 3D graph](img/B22207_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Tokens plotted on a 3D graph
  prefs: []
  type: TYPE_NORMAL
- en: These embeddings are learned while the language model is being trained on a
    large corpus of text. The model learns to place semantically similar tokens closer
    together in the embedding space. For example, *Tokenization* and *NLP* might be
    closer to each other than to *is* because they are related to language processing
    concepts, while *is* is a more general verb.
  prefs: []
  type: TYPE_NORMAL
- en: Attention
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The concept of **attention** in generative AI and LLMs represents a significant
    advancement in how models process and understand sequences of data, such as text.
    Attention mechanisms allow models to focus on different parts of the input data
    when performing a task, much like how human attention focuses on specific aspects
    of what we see or hear to derive meaning or make decisions.
  prefs: []
  type: TYPE_NORMAL
- en: The attention mechanism dynamically weighs the importance of different tokens
    in a sentence when generating an output. This means the model can pay more attention
    to relevant words and less to others, depending on the task at hand, such as translation,
    question-answering, or text generation.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go back to our example sentence, *Tokenization is essential for NLP*.
    When processing this sentence, an LLM with an attention mechanism might focus
    more on the words *Tokenization* and *NLP* because they are key terms that define
    the context and subject matter. The model recognizes that *essential* is important
    as it describes the relationship between *Tokenization* and *NLP* but might pay
    less attention to *is* and *for* as these serve more grammatical functions.
  prefs: []
  type: TYPE_NORMAL
- en: The attention mechanism has been a cornerstone of transformer-based models,
    enabling breakthroughs in NLP applications by providing a more nuanced and flexible
    way to handle sequences of data. This has led to the development of highly effective
    models that are capable of understanding and generating human-like text.
  prefs: []
  type: TYPE_NORMAL
- en: What’s an attention score?
  prefs: []
  type: TYPE_NORMAL
- en: '**Attention scores** are used when identifying the relative importance or weight
    of tokens in attention layers or attention mechanisms. The weight or importance
    of a token influences its relevance when making predictions. In models using **multi-head**
    attention, the inputs are transformed multiple times and multiple attention scores
    are computed, capturing different relationships in the data.'
  prefs: []
  type: TYPE_NORMAL
- en: While *Figure 10**.1* helps visualize the concept of embeddings, in the real
    world, each token is represented as a vector with hundreds or thousands of dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The overall process looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: The token embeddings (the token and its numeric vector or coordinates) are fed,
    in sequence, to the attention layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The decoder begins predicting the next token and vector in the sequence.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The attention layer evaluates the sequence and assigns a weight to the tokens.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The weights are then used to calculate a new vector and an **attention score**
    for the next token. In systems with **multi-head** attention, the attention layer
    uses different elements in the embeddings to calculate multiple alternative tokens.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The neural network uses the attention scores to predict the most likely next
    token from its entire vocabulary (acquired through the training process).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The predicted output is added to the sequence, which, in turn, is used as the
    next input, starting the process over again at *Step 1*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Just like other machine learning styles, generative AI relies on a training
    process where it is provided content. The predicted token values, based on the
    attention scores, and vectors are compared to the actual values of the next vector,
    and the loss is calculated. Like other automated machine learning models, weights
    are dynamically adjusted to reduce the loss, allowing the model to more accurately
    generate its predictions (which, in the case of Generative AI, is the response
    to the prompt).
  prefs: []
  type: TYPE_NORMAL
- en: How does generative AI put all this together?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative AI harnesses deep learning techniques, particularly **generative
    adversarial networks** (**GANs**) and **variational autoencoders**, to produce
    content that is not only novel but also realistic and contextually relevant.
  prefs: []
  type: TYPE_NORMAL
- en: What’s a GAN?
  prefs: []
  type: TYPE_NORMAL
- en: 'GANs on the concepts of neural networks. A GAN consists of two competing neural
    network models: a **generator** and a **discriminator**. The generator’s role
    is to create data that is similar to data in a training set, while the discriminator’s
    role is to distinguish between genuine data from the training set and fake or
    artificial data produced by the generator. During training, these two networks
    engage in a kind of tug-of-war; the generator continuously improves its ability
    to produce realistic data, while the discriminator improves its ability to detect
    the generated data. This process continues until the generator produces data so
    convincingly real that the discriminator can no longer distinguish it from actual
    data. This adversarial process enables GANs to generate high-quality, realistic
    data, mimicking the distribution of the original dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: At the heart of generative AI is the ability to understand and replicate the
    complexities of human creativity. By analyzing vast amounts of data – whether
    it’s text, images, sounds, or videos – generative AI algorithms learn the underlying
    patterns, styles, and structures. They then use this understanding to generate
    new content that can be indistinguishable from content created by humans. This
    capability opens up a myriad of applications, from composing music and writing
    stories to creating realistic visuals and simulating virtual environments.
  prefs: []
  type: TYPE_NORMAL
- en: Further exploration
  prefs: []
  type: TYPE_NORMAL
- en: You can experiment with some popular generative AI services right now, such
    as OpenAI’s GPT-4 ([https://chat.openai.com](https://chat.openai.com)) and Midjourney
    ([https://www.midjourney.com](https://www.midjourney.com)).
  prefs: []
  type: TYPE_NORMAL
- en: Azure generative AI is Microsoft’s foray into this revolutionary technology,
    providing tools and services that leverage the Azure AI ecosystem. This platform
    enables developers and businesses to integrate generative AI capabilities into
    their applications, creating a bridge between human creativity and machine efficiency.
    With Azure AI, users can harness the power of generative models to produce high-quality,
    innovative content across various domains, significantly reducing the time and
    effort traditionally required for content creation.
  prefs: []
  type: TYPE_NORMAL
- en: One of the standout features of Azure generative AI is its capacity for generating
    realistic images. Utilizing GANs and other state-of-the-art techniques, the platform
    can produce images that closely mimic real-life scenarios. These capabilities
    find applications in numerous industries, such as augmenting datasets for more
    effective machine learning training, generating product images for eCommerce platforms,
    and crafting detailed graphics for gaming and virtual reality experiences.
  prefs: []
  type: TYPE_NORMAL
- en: How does a GAN create images?
  prefs: []
  type: TYPE_NORMAL
- en: Whether it’s processing text or images, a GAN employs neural networks in both
    the generator and discriminator roles. Let’s say you trained the generator with
    several images of cats. The generator’s job is to produce an image of a cat by
    using the source material as inspiration (if you will), and then inserting some
    random content (noise) that may help the picture look like a cat. However, it
    won’t be actual cat image data. Then, operating as a binary classifier, the discriminator
    takes those images from the generator and determines if they look like a cat or
    not.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to visual content, Azure generative AI excels in text generation.
    By training on extensive text datasets, the platform can produce written content
    that mirrors human writing styles. This is particularly useful for generating
    narrative content, automating customer service responses, or creating informative
    text for websites and applications. The technology ensures that the generated
    text is coherent, contextually appropriate, and varied in style, further mimicking
    human language patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI, particularly as it’s implemented in Azure AI, represents a significant
    leap forward in how we approach content creation and data synthesis. By automating
    the creative process, it offers the potential to revolutionize industries, streamline
    workflows, and unleash new levels of creativity and innovation. As this technology
    continues to evolve, it will undoubtedly become an integral part of the digital
    transformation journey for many organizations worldwide, redefining what is possible
    with artificial intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Identify common scenarios for generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative AI, with its ability to create new content, has applications spanning
    numerous fields. Here are some common scenarios where generative AI is making
    a significant impact, along with examples for each.
  prefs: []
  type: TYPE_NORMAL
- en: Image generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Multimodal generative AI can create new images from textual descriptions, such
    as generating photorealistic images of objects or scenes that don’t exist, using
    models such as OpenAI’s DALL-E or Midjourney:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Generating an image with GPT4](img/B22207_10_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – Generating an image with GPT4
  prefs: []
  type: TYPE_NORMAL
- en: Text generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Generative AI can be used to produce coherent and contextually relevant text
    for articles or stories by utilizing models such as GPT-3 from OpenAI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Text generation using GPT-3.5](img/B22207_10_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Text generation using GPT-3.5
  prefs: []
  type: TYPE_NORMAL
- en: Music creation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Generative AI can compose new music pieces or songs in various genres by learning
    from a vast dataset of music, exemplified by projects such as OpenAI’s Jukebox:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Songs generated with OpenAI Jukebox](img/B22207_10_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – Songs generated with OpenAI Jukebox
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Obtaining personal data for model training can be very difficult. Generative
    AI can help fill the gap by creating realistic but artificial datasets that mimic
    the statistical properties of sensitive real-world data, enabling the development
    of machine learning models without compromising privacy.
  prefs: []
  type: TYPE_NORMAL
- en: Code generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Generative AI has begun growing in terms of development and can generate syntactically
    correct code (in many cases), as shown in *Figure 10**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – JSON content generated by GPT-3.5](img/B22207_10_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – JSON content generated by GPT-3.5
  prefs: []
  type: TYPE_NORMAL
- en: Another growing area is using Generative AI to review code, make suggestions,
    or recommend improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Voice generation and transformation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative AI can be used to convert text into lifelike speech in various languages
    and accents for applications such as audiobooks or virtual assistants via technologies
    such as Google’s WaveNet.
  prefs: []
  type: TYPE_NORMAL
- en: Drug discovery and chemical synthesis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It can accelerate the discovery of new pharmaceuticals by predicting molecular
    structures that could lead to effective drugs, as seen in the work of startups
    such as Atomwise.
  prefs: []
  type: TYPE_NORMAL
- en: Personalized content and recommendation systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative AI can tailor digital experiences to individual users by generating
    personalized content or product recommendations on platforms such as Netflix or
    Amazon.
  prefs: []
  type: TYPE_NORMAL
- en: Maintenance analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By reviewing the **Internet of Things** (**IoT**) and other sensor data, generative
    AI can detect patterns that indicate potential failure points or manufacturing
    device maintenance requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Copilots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The advent of LLMs has given rise to **copilots**, novel tools that are designed
    to assist users with common tasks through generative AI models integrated into
    various applications. These copilots, built on a unified architecture, enable
    developers to create tailored solutions for specific business needs, appearing
    as features such as chat screens alongside user files, utilizing the content created
    or searched within the product to generate relevant results.
  prefs: []
  type: TYPE_NORMAL
- en: The development process involves training LLMs with extensive data and utilizing
    services such as Azure OpenAI Service for accessing pretrained models, which can
    be deployed as-is or fine-tuned with custom data for specific applications. Copilots
    offer significant enhancements to productivity and creativity, aiding in tasks
    ranging from drafting documents to strategic planning, marking a transformative
    shift in how tasks are approached and executed in the digital workspace. One of
    the most prominent copilots currently is **Microsoft Copilot**, integrated into
    the Microsoft 365 suite of applications.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI’s capabilities extend beyond these examples, touching on areas
    such as fashion design, where AI generates new clothing styles, and gaming, where
    AI creates dynamic, evolving environments. As technology advances, the potential
    applications of generative AI continue to expand, promising to revolutionize industries
    by offering novel solutions to complex problems.
  prefs: []
  type: TYPE_NORMAL
- en: Deepfake creation and detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the scenarios we’ve looked at so far have been positive use cases for
    generative AI, a new type of tooling is emerging that has a large negative potential.
    This technology, commonly called deepfakes, revolves around generating or altering
    video and audio recordings to realistically depict content that was not originally
    said or performed by the individuals involved. From political propaganda to revenge
    pornography, generative AI’s role in creating deepfakes has already raised many
    ethical concerns (and in some cases, resulted in court battles ranging from child
    custody disputes to automobile collisions).
  prefs: []
  type: TYPE_NORMAL
- en: 'Deepfakes rely on deep learning techniques and can be seen with tools such
    as Jiggy, MyHeritage, and DeepFaceLab, as shown in *Figure 10**.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – MyHeritage customizes portraits with a historical flair](img/B22207_10_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – MyHeritage customizes portraits with a historical flair
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, similar technology is used to detect such manipulations to ensure
    authenticity and combat misinformation via platforms such as Sentinel (not to
    be confused with Microsoft Sentinel), WeVerify, and Microsoft Video Authenticator.
  prefs: []
  type: TYPE_NORMAL
- en: Quality control
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative AI has potential in the quality control space as well as it can analyze
    vast quantities of data and detect anomalies to predict potential defects. By
    being connected to a steady stream of production data, generative AI can be used
    to predict failure points and defects by identifying correlations between different
    types of anomalous activity and poor-quality product outputs.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of machine learning and human interaction technologies, generative
    AI showcases some of the most exciting and significant capabilities. However,
    with that come some of the most significant risks.
  prefs: []
  type: TYPE_NORMAL
- en: Identify Responsible AI considerations for generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Microsoft has created a framework for responsible AI and generative AI solutions
    comprised of four stages:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify potential harms that could be related to your planned solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measure the presence of those identified harms in the solution’s output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mitigate the harms at multiple levels to minimize their expression and impact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operate the solution responsibly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s look at each of those four areas.
  prefs: []
  type: TYPE_NORMAL
- en: Identify
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first stage in implementing a responsible generative AI solution is to identify
    potential harms that may result from your solution.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying potential harms or risks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You must identify possible risks associated with your generative AI project,
    which vary based on the services, models, and data you employ. Here are some common
    risks:'
  prefs: []
  type: TYPE_NORMAL
- en: Generating offensive or biased content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spreading misinformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Promoting harmful behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand the limitations and typical behaviors of your models and services,
    refer to their documentation, such as the transparency notes provided by Azure
    OpenAI Service, or specific model documentation, such as OpenAI’s system card
    for GPT-4.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs: []
  type: TYPE_NORMAL
- en: You can use specially crafted resources such as Microsoft’s *Responsible AI
    Impact Assessment Guide* ([https://aka.ms/RAIImpactAssessmentGuidePDF](https://aka.ms/RAIImpactAssessmentGuidePDF))
    and the *Responsible AI Impact Assessment template* ([https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFk](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFk))
    to outline and evaluate these potential risks.
  prefs: []
  type: TYPE_NORMAL
- en: Risk prioritization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here, you must evaluate and rank each identified risk based on its likelihood
    and potential impact. This step is crucial for focusing efforts on mitigating
    the most significant risks first. Consider both the intended application of your
    AI solution and the possibilities for misuse, and then rank the potential risks
    based on factors such as impact and likelihood.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine that you’re developing a copilot to provide diet and exercise recommendations
    based on the user’s current physical health condition, metrics, and goals. Here
    are some potential harms:'
  prefs: []
  type: TYPE_NORMAL
- en: Recommending an ineffective exercise or meal plan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommending an exercise routine that results in serious physical injury
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While recommending an ineffective meal plan doesn’t meet the stated goal of
    the copilot, recommending an exercise that puts someone at risk for serious physical
    injury or death has a might higher potential negative impact and should likely
    be addressed first.
  prefs: []
  type: TYPE_NORMAL
- en: Engage with your development team and possibly legal or policy experts to accurately
    prioritize these risks.
  prefs: []
  type: TYPE_NORMAL
- en: Testing for risks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With a prioritized list of risks, conduct targeted tests to confirm their presence
    and understand their triggers. This could involve **red team** testing (sometimes
    called **red teaming**), where specialists attempt to find and exploit vulnerabilities
    within your AI solution.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in a diet and exercise copilot scenario, tests might involve inputting
    that the user has asthma and congestive heart failure. Documenting the outcomes
    of these tests helps gauge the actual likelihood of harmful outcomes and may uncover
    additional risks.
  prefs: []
  type: TYPE_NORMAL
- en: Documentation and communication
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Document the confirmed risks and communicate this information to all relevant
    stakeholders. Keep an updated and detailed list of potential and confirmed risks
    as your solution evolves. This documentation is essential for transparency and
    informs ongoing efforts to mitigate harm in your Generative AI solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Measure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have a list of potentially harmful effects prioritized, the next phase
    is to evaluate your solution’s actual output against these risks. Start by establishing
    a baseline to understand the extent of harm your solution could cause in different
    scenarios and use this as a reference point to assess improvements as you refine
    your solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'To effectively measure your system for possible negative impacts, follow these
    three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Develop a varied set of test queries that could trigger the identified potential
    harms. For instance, if there’s a risk that the system might provide instructions
    for creating harmful substances, prepare queries that might lead to such responses,
    such as asking for ways to create harmful substances from common household items.
    In the diet and exercise copilot example, this might include preparing questions
    scenarios where you would provide the system information about at-risk health
    conditions and then ask for an exercise plan that would put the person in physical
    jeopardy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run these queries through your system and collect the responses.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assess the responses based on clear criteria to determine their potential harm.
    This could mean simply classifying them as “harmful” or “safe,” or you might establish
    a spectrum of harm severity. It’s crucial to apply consistent, predefined standards
    when evaluating the output to ensure accurate categorization of potential risks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The results of the testing process should then be shared with the project or
    solution stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: Mitigate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you’ve established a baseline and a method for assessing potentially risky
    or harmful outputs from your solution, you can implement measures to minimize
    these risks. Subsequently, reassess the updated system and evaluate the reduced
    levels of harm compared to the original baseline. Mitigating potential harms in
    a generative AI solution requires a multi-layered strategy, where various mitigation
    techniques are applied across different layers of the system.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.7* shows the four-layered approach that Microsoft proposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Reviewing the layered approach to harm mitigation](img/B22207_10_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – Reviewing the layered approach to harm mitigation
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a closer look at each of these layers.
  prefs: []
  type: TYPE_NORMAL
- en: Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **model** layer is the base AI model (or models) at the foundation of your
    solution, such as GPT-3 or GPT-4\. At the model layer, mitigating potential harms
    involves doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a model that’s suitable for the intended use of the solution. For instance,
    while GPT-4 is highly capable, a less complex model could suffice for tasks requiring
    only specific text input classification, reducing the risk of generating harmful
    content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning the chosen foundational model with custom training data to ensure
    the generated responses are tailored and relevant to the specific scenario of
    your solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you have mitigated potential issues at the model layer, it’s time to move
    on to the next layer.
  prefs: []
  type: TYPE_NORMAL
- en: Safety system
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **safety system** layer encompasses measures at the platform level that
    are designed to reduce risks, including configurations and features integrated
    into services such as Azure OpenAI Service. This layer can offer these types of
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: Content filters, which evaluate and categorize content and interactions based
    on their potential harm across four levels (safe to high) and categories (hate
    speech, sexual content, violence, and self-harm), preventing inappropriate prompts
    and responses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Algorithms for detecting misuse, such as identifying unusually high or automated
    requests indicative of bot activity and implementing alert systems for quick responses
    to any signs of abuse or harmful actions within the system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When actions activate the alerts in the safety systems (such as alerts for unusual
    or bot-type activity), it’s important to act quickly to prevent the system from
    being compromised.
  prefs: []
  type: TYPE_NORMAL
- en: Metaprompt and grounding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Mitigations at the **metaprompt and grounding** layer focus on the prompts
    that are sent to the solution. Potential harm mitigation strategies might include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Specifying **metaprompts** (a special prompt that provides guidance on how to
    handle prompts submitted by the end users) or other prompt engineering tactics
    to further enforce or refine the system’s behavior and outputs. For example, you
    might use a metaprompt to tell the model to ignore specific harmful words or phrases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a **retrieval-augmented generation** (**RAG**) system to pull data
    from trusted data sources to integrate into the prompt.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What’s RAG?
  prefs: []
  type: TYPE_NORMAL
- en: 'RAG is a method in generative AI that combines the power of LLMs with information
    retrieval systems to enhance the generation of text. This approach involves two
    key components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**•** **Retrieval component**: Before generating text, the model queries a
    database, knowledge base, or a large corpus of documents to retrieve relevant
    information based on the input prompt. This step is akin to looking up reference
    materials before writing on a topic, ensuring the information included in the
    generated content is grounded in factual and relevant sources.'
  prefs: []
  type: TYPE_NORMAL
- en: '**•** **Generation component**: This part involves a generative model, such
    as a transformer-based language model, which uses the retrieved information along
    with the original prompt to produce the final output. The model integrates the
    context and details from the retrieved documents into the generated text, enhancing
    the accuracy, relevance, and factual grounding of the content.'
  prefs: []
  type: TYPE_NORMAL
- en: User experience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **user experience** layer of a generative AI solution relates not only to
    the application interface users engage with but also to the supporting documentation
    provided to users and stakeholders. By customizing the application’s user interface
    to limit inputs to certain subjects or types and implementing input and output
    validation, the risk of generating potentially harmful responses can be reduced
    (as can error conditions resulting from incomplete or improperly formatted input).
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, it’s vital for the documentation and descriptive materials about
    the generative AI solution to communicate the system’s capabilities, limitations,
    and the foundational models it utilizes. This transparency is crucial for informing
    users of any potential risks that may not be fully mitigated by existing safeguards.
  prefs: []
  type: TYPE_NORMAL
- en: Operate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After you have identified potential harms, developed methods to measure their
    existence, and implemented mitigations to reduce their appearance in your solution,
    you can release your solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with any solution, you should apply systematic testing, as well as submit
    to your organization’s relevant governance, compliance, or legal processes. Many
    organizations require several review gates to ensure products comply with a variety
    of requirements, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Legal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marketing and branding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Privacy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once any internal reviews have been completed, it’s time to release the solution!
    Many frameworks cover various facets of daily operations for software and services
    (whether they’re developed internally or purchased). These guidelines aren’t limited
    to AI-based solutions, but rather should be applied to any deployed products and
    services:'
  prefs: []
  type: TYPE_NORMAL
- en: Phased delivery or pilot plans to slowly onboard users to the solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incident response plans
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communication plans for emergencies, planned upgrades, or outages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrade plans
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rollback plans for reverting applications and services to a previously known
    good state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abuse protection measures, such as user identity requirements and network security
    rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring for availability and outages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feedback mechanisms for reporting inaccurate or inappropriate data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Telemetry to measure system performance and gather end user experience metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing these operational tasks and guidelines should ensure you have a
    robust solution.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter discussed the features of generative AI and provided you with a
    deeper understanding of how generative AI works, including the concepts of tokenization,
    embeddings, and attention, as well as demonstrating many current real-world usage
    scenarios for generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, this chapter covered techniques for applying responsible AI considerations
    to AI solutions that you develop or implement.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll explore the Azure OpenAI service.
  prefs: []
  type: TYPE_NORMAL
- en: Exam Readiness Drill – Chapter Review Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apart from a solid understanding of key concepts, being able to think quickly
    under time pressure is a skill that will help you ace your certification exam.
    That is why working on these skills early on in your learning journey is key.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter review questions are designed to improve your test-taking skills progressively
    with each chapter you learn and review your understanding of key concepts in the
    chapter at the same time. You’ll find these at the end of each chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Before You Proceed
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have a Packt Library subscription or you haven't purchased this
    book from the Packt store, you will need to unlock the online resources to access
    the exam readiness drills. Unlocking is free and needs to be done only once. To
    learn how to do that, head over to the chapter titled [*Chapter 12*](B22207_12.xhtml#_idTextAnchor228)*,
    Accessing the* *Online Resources*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To open the Chapter Review Questions for this chapter, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click the link – [https://packt.link/AI-900_CH10](https://packt.link/AI-900_CH10).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, you can scan the following QR code (*Figure 10**.8*):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.8 – QR code that opens Chapter Review Questions for logged-in users](img/B22207_10_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.8 – QR code that opens Chapter Review Questions for logged-in users
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you log in, you’ll see a page similar to the one shown in *Figure 10**.9*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.9 – Chapter Review Questions for Chapter 10](img/B22207_10_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.9 – Chapter Review Questions for Chapter 10
  prefs: []
  type: TYPE_NORMAL
- en: Once ready, start the following practice drills, re-attempting the quiz multiple
    times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exam Readiness Drill
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the first three attempts, don’t worry about the time limit.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first time, aim for at least **40%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix your learning gaps.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The second time, aim for at least **60%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix any remaining learning
    gaps.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The third time, aim for at least **75%**. Once you score 75% or more, you start
    working on your timing.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: You may take more than **three** attempts to reach 75%. That’s okay. Just review
    the relevant sections in the chapter till you get there.
  prefs: []
  type: TYPE_NORMAL
- en: Working On Timing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your aim is to keep the score the same while trying to answer these questions
    as quickly as possible. Here’s an example of how your next attempts should look
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Attempt** | **Score** | **Time Taken** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 5 | 77% | 21 mins 30 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 6 | 78% | 18 mins 34 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 7 | 76% | 14 mins 44 seconds |'
  prefs: []
  type: TYPE_TB
- en: Table 10.2 – Sample timing practice drills on the online platform
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The time limits shown in the above table are just examples. Set your own time
    limits with each attempt based on the time limit of the quiz on the website.
  prefs: []
  type: TYPE_NORMAL
- en: With each new attempt, your score should stay above **75%** while your “time
    taken” to complete should “decrease”. Repeat as many attempts as you want till
    you feel confident dealing with the time pressure.
  prefs: []
  type: TYPE_NORMAL
