- en: '*Chapter 5*: AWS Services for Data Storing'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*：数据存储的AWS服务'
- en: AWS provides a wide range of services to store your data safely and securely.
    There are various storage options available on AWS such as block storage, file
    storage, and object storage. It is expensive to manage on-premises data storage
    due to the higher investment in hardware, admin overheads, and managing system
    upgrades. With AWS Storage services, you just pay for what you use, and you don't
    have to manage the hardware. We will also learn about various storage classes
    offered by Amazon S3 for intelligent access of the data and reducing costs. You
    can expect questions in the exam on storage classes. As we continue in this chapter,
    we will master the single-AZ and multi-AZ instances, and **RTO** (**Recovery**
    **Time** **Objective**) and **RPO** (**Recovery** **Point** **Objective**) concepts
    of Amazon RDS.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: AWS提供了一系列服务来安全地存储您的数据。在AWS上提供了多种存储选项，例如块存储、文件存储和对象存储。由于硬件投资较高、管理开销和系统升级管理，本地数据存储管理成本较高。使用AWS存储服务，您只需为使用的部分付费，无需管理硬件。我们还将了解Amazon
    S3提供的各种存储类别，以实现数据的智能访问和降低成本。您可以在考试中期待有关存储类别的题目。随着我们继续本章的学习，我们将掌握Amazon RDS的单AZ和多AZ实例，以及**RTO**（**恢复时间目标**）和**RPO**（**恢复点目标**）的概念。
- en: 'In this chapter, we will learn about storing our data securely for further
    analytics purposes by means of the following sections:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过以下部分学习如何通过以下方式安全地存储我们的数据，以便进行进一步的分析：
- en: Storing data on Amazon S3
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Amazon S3上存储数据
- en: Controlling access on S3 buckets and objects
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制S3存储桶和对象的访问
- en: Protecting data on Amazon S3
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护Amazon S3上的数据
- en: Securing S3 objects at rest and in transit
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在静态和传输中保护S3对象
- en: Using other types of data stores
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用其他类型的数据存储
- en: Relational Database Services (RDSes)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关系型数据库服务（RDS）
- en: Managing Failover in Amazon RDS
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理Amazon RDS的故障转移
- en: Taking automatic backup, RDS snapshots, and restore and read replicas
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动备份、RDS快照、恢复和读取副本
- en: Writing to Amazon Aurora with multi-master capabilities
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用具有多主能力的Amazon Aurora进行写入
- en: Storing columnar data on Amazon Redshift
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Amazon Redshift上存储列式数据
- en: Amazon DynamoDB for NoSQL databases as a service
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为NoSQL数据库服务的Amazon DynamoDB
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'All you will need for this chapter is an AWS account and the AWS CLI configured.
    The steps to configure the AWS CLI for your account are explained in detail by
    Amazon here: [https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您在本章中需要的只是AWS账户和配置好的AWS CLI。Amazon详细解释了如何为您的账户配置AWS CLI的步骤：[https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html)。
- en: 'You can download the code examples from Github, here: [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-5/](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-5/).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从GitHub下载代码示例，这里：[https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-5/](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-5/)。
- en: Storing data on Amazon S3
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Amazon S3上存储数据
- en: '**S3** is Amazon''s cloud-based object storage service and it can be accessed
    from anywhere via the internet. It is an ideal storage option for large datasets.
    It is region-based, as your data is stored in a particular region until you move
    the data to a different region. Your data will never leave that region until it
    is configured. In a particular region, data is replicated in the availability
    zones of that region; this makes S3 regionally resilient. If any of the availability
    zones fail in a region, then other availability zones will serve your requests.
    It can be accessed via the AWS Console UI, AWS CLI, or AWS API requests, or via
    standard HTTP methods.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**S3**是亚马逊基于云的对象存储服务，可以通过互联网从任何地方访问。它是大型数据集的理想存储选项。它是基于区域的，因为您的数据存储在特定区域，直到您将数据移动到另一个区域。除非您进行配置，否则您的数据永远不会离开该区域。在特定区域中，数据在该区域的可用区中进行复制；这使得S3在区域上具有弹性。如果该区域中的任何可用区发生故障，则其他可用区将处理您的请求。它可以通过AWS控制台UI、AWS
    CLI、AWS API请求或标准HTTP方法进行访问。'
- en: 'S3 has two main components: **buckets** and **objects**.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: S3有两个主要组件：**存储桶**和**对象**。
- en: Buckets are created in a specific AWS region. Buckets can contain objects, but
    cannot contain other buckets.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储桶是在特定的AWS区域中创建的。存储桶可以包含对象，但不能包含其他存储桶。
- en: Objects have two main attributes. One is **Key**, and the other is **Value**.
    Value is the content being stored, and Key is the name. The maximum size of an
    object can be 5 TB. As per the Amazon S3 documentation available here, [https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html),
    objects also have a version ID, metadata, access control information, and subresources.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象有两个主要属性。一个是**键**，另一个是**值**。值是存储的内容，键是名称。对象的最大大小可以是 5 TB。根据此处可用的亚马逊 S3 文档 [https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html)，对象还具有版本
    ID、元数据、访问控制信息和子资源。
- en: Important note
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: As per Amazon's docs, S3 provides read-after-write consistency for PUTS of new
    objects, which means that if you put a new object or create a new object and you
    immediately turn around to read the object using its key, then you get the exact
    data that you just uploaded. However, for overwrites and deletes, it behaves in
    an **eventually consistent manner**. This means that if you read an object straight
    after the delete or overwrite operation, then you may read an old copy or a stale
    version of the object. It takes some time to replicate the content of the object
    across three availability zones.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据亚马逊的文档，S3 为新对象的 PUT 操作提供写后一致性，这意味着如果你放置了一个新对象或创建了一个新对象，然后立即使用其键来读取该对象，那么你会得到你刚刚上传的确切数据。然而，对于覆盖和删除操作，它以**最终一致性**的方式表现。这意味着如果你在删除或覆盖操作后立即读取一个对象，那么你可能会读取到旧副本或过时的对象版本。将对象内容复制到三个可用区需要一些时间。
- en: 'A folder structure can be maintained logically by using a prefix. Let''s take
    an example where an image is uploaded into a bucket, `bucket-name-example`, with
    the prefix `folder-name` and the object name as `my-image.jpg`. The entire structure
    looks like this: `/bucket-name-example/folder-name/my-image.jpg`.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用前缀来逻辑上维护文件夹结构。让我们以一个例子来说明，一个图像被上传到一个名为 `bucket-name-example` 的桶中，前缀为 `folder-name`，对象名称为
    `my-image.jpg`。整个结构看起来像这样：`/bucket-name-example/folder-name/my-image.jpg`。
- en: The content of the object can be read by using the bucket name as `bucket-name-example`
    and the key as `/folder-name/my-image.jpg`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用桶名 `bucket-name-example` 和键 `/folder-name/my-image.jpg` 来读取对象的内容。
- en: 'There are several storage classes offered by Amazon for the objects being stored
    in S3:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊为存储在 S3 中的对象提供了几种存储类：
- en: '**Standard Storage**: This is the storage class for frequently accessed objects
    and for quick access. S3 Standard has a millisecond first byte latency and objects
    can be made publicly available.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准存储**：这是频繁访问的对象和快速访问的存储类。S3 标准具有毫秒级的首字节延迟，并且对象可以被公开访问。'
- en: '**Reduced Redundancy (RR)**: This option provides less redundancy than the
    Standard Storage class. Non-critical and reproducible data can be stored in this
    class. AWS S3 documentation suggests not to use this class as the Standard Storage
    class is more cost-effective.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降低冗余 (RR)**：这个选项比标准存储类提供更少的冗余。可以在此类中存储非关键且可重复的数据。AWS S3 文档建议不要使用此类，因为标准存储类更经济。'
- en: '**Standard Infrequent Access (IA)**: This option is used when you need data
    to be returned quickly, but not for frequent access. The object size has to be
    a minimum of 128 KB. The minimum storage timeframe is 30 days. If the object is
    deleted before 30 days, you are still charged for 30 days. **Standard IA** objects
    are resilient to the loss of availability zones.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准不频繁访问 (IA)**：当你需要数据快速返回但不是频繁访问时，使用此选项。对象大小必须至少为 128 KB。最小存储时间为 30 天。如果对象在
    30 天内被删除，你仍然会被收取 30 天的费用。**标准 IA** 对象对可用区的丢失具有弹性。'
- en: '**One Zone Infrequent Access**: The object of this storage class is stored
    in just one availability zone, which makes it cheaper than **Standard IA**. The
    minimum object size and storage timeframe are the same as **Standard IA**. Objects
    from this storage class are less available and less resilient. This storage class
    is used when you have another copy, or if the data can be recreated. A **One Zone
    IA** storage class should be used for long-lived data that is non-critical and
    replaceable, and where access is infrequent.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单区不频繁访问**：这种存储类别的对象仅存储在一个可用区，这使得它比**标准 IA**更便宜。最小对象大小和存储时间与**标准 IA**相同。从这个存储类别的对象更不可用且更不具弹性。当你有另一个副本或数据可以重新创建时，应使用此存储类。对于长期存储的非关键且可替换的数据，以及访问不频繁的情况，应使用**单区
    IA**存储类。'
- en: '**Glacier**: This option is used for long-term archiving and backup. It can
    take anything from minutes to hours to retrieve objects in this storage class.
    The minimum storage timeframe is 90 days. You cannot use the Amazon Glacier API
    to access the objects moved from S3 to Glacier as part of object life cycle management.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**冰川**：此选项用于长期存档和备份。检索此类存储类中的对象可能需要几分钟到几小时。最小存储时间为90天。您不能使用Amazon Glacier API访问作为对象生命周期管理一部分从S3移动到冰川的对象。'
- en: '**Glacier Deep Archive**: The minimum storage duration of this class is 180
    days. This is the least expensive storage class and has a default retrieval time
    of 12 hours.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**冰川深存档**：此类的最小存储时间为180天。这是最便宜的存储类，默认检索时间为12小时。'
- en: '**Intelligent Tiering**: This storage class is designed to reduce operational
    overheads. Users pay a monitoring fee and AWS selects a storage class between
    Standard (a frequent access tier) and Standard IA (a lower cost infrequent access
    tier) based on the access pattern of an object. This option is designed for long-lived
    data with unknown or unpredictable access patterns.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**智能分层**：这个存储类旨在减少运营开销。用户支付监控费用，AWS根据对象的访问模式在标准（频繁访问层）和标准IA（低成本不频繁访问层）之间选择一个存储类。此选项旨在用于具有未知或不可预测访问模式的长久数据。'
- en: Through sets of rules, the transition between storage classes and deletion of
    the objects can be managed easily, and are referred to as **S3 Lifecycle Configurations**.
    These rules consist of actions. These can be applied to a bucket or a group of
    objects in that bucket defined by prefixes or tags. Actions can either be **Transition
    actions** or **Expiration actions**. Transition actions define the storage class
    transition of the objects following the creation of *a user-defined* number of
    days. Expiration actions configure the deletion of versioned objects, or the deletion
    of delete markers or incomplete multipart uploads. This is very useful for managing
    costs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一系列规则，可以轻松管理存储类之间的转换和对象的删除，这些规则被称为**S3生命周期配置**。这些规则包括操作。这些操作可以应用于一个桶或该桶中由前缀或标签定义的一组对象。操作可以是**转换操作**或**过期操作**。转换操作定义了在创建*用户定义*天数后的对象的存储类转换。过期操作配置了版本化对象的删除，或删除删除标记或不完整的分片上传。这对于管理成本非常有用。
- en: 'An illustration is given in *Figure 5.1*. You can find more details available
    here: [https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html](https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图5.1*中给出了一个说明。您可以在以下链接中找到更多详细信息：[https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html](https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html)
- en: '![Figure 5.1 – A comparison table of S3 Storage classes'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1 – S3存储类的比较表]'
- en: '](img/B16735_05_001.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片/B16735_05_001.jpg]'
- en: Figure 5.1 – A comparison table of S3 Storage classes
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – S3存储类的比较表
- en: Creating buckets to hold data
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建桶以存储数据
- en: Now, let's see how to create a bucket, upload an object, and read the object
    using the AWS CLI.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何使用AWS CLI创建桶、上传对象和读取对象。
- en: 'In the first step, we will check whether we have any buckets created by using
    the `aws s3 ls` command:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步中，我们将使用`aws s3 ls`命令检查是否创建了任何桶：
- en: '[PRE0]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This command returns nothing here. So, we will create a bucket now by using
    the `mb` argument. Let''s say the bucket name is `demo-bucket-baba` in the `us-east-1`
    region:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此命令在此处没有返回任何内容。因此，我们将使用`mb`参数创建一个桶。假设桶名为`demo-bucket-baba`，位于`us-east-1`区域：
- en: '[PRE1]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As we have created a bucket now, our next step is to copy a file to our bucket
    using the `cp` argument, as shown in the following code:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经创建了一个桶，下一步是将文件复制到我们的桶中，使用`cp`参数，如下面的代码所示：
- en: '[PRE2]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To validate the file upload operation via the AWS console, please log in to
    your AWS account and go to the AWS S3 console to see the same. The AWS S3 console
    lists the result as shown in *Figure 5.2*. The console may have changed by the
    time you're reading this book!![Figure 5.2 – AWS S3 screenshot to list your files
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要通过AWS控制台验证文件上传操作，请登录您的AWS账户并转到AWS S3控制台查看相同的内容。AWS S3控制台列出了如图*图5.2*所示的结果。控制台在您阅读本书时可能已经发生变化！！[图5.2
    – AWS S3截图以列出您的文件]
- en: '](img/B16735_05_002.jpg)'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片/B16735_05_002.jpg]'
- en: '[PRE3]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'cp command and the --recursive parameter. To achieve this, you will have to
    create two buckets, demo-bucket-baba-copied and demo-bucket-baba-moved. The steps
    are as follows:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`cp`命令和`--recursive`参数。为了实现这一点，您将需要创建两个桶，demo-bucket-baba-copied和demo-bucket-baba-moved。步骤如下：'
- en: '[PRE4]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If all the commands are run successfully, then the original bucket should be
    empty at the end (as all the files have now been moved). NoteIn the certification
    exam, you will not find many questions on bucket- and object-level operations.
    However, it is always better to know the basic operations and the required steps.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果所有命令都成功运行，那么原始存储桶最终应该是空的（因为所有文件现在都已移动）。注意：在认证考试中，您不会找到很多关于存储桶和对象级操作的问题。然而，了解基本操作和所需步骤总是更好的。
- en: '[PRE5]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The buckets must be deleted to avoid costs as soon as the hands-on is finished.
    The bucket has to be empty before you supply the `rb` command:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦动手实践完成，必须删除存储桶以避免成本。在提供`rb`命令之前，存储桶必须为空：
- en: '[PRE6]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `demo-bucket-baba-moved` bucket is not empty, so we couldn''t remove the
    bucket. In such scenarios, use the `--force` parameter to delete the entire bucket
    and all its contents, as shown here:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`demo-bucket-baba-moved`存储桶不为空，因此我们无法删除该存储桶。在这种情况下，使用`--force`参数删除整个存储桶及其所有内容，如下所示：'
- en: '[PRE7]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let's take an example of a bucket, `test-bucket`, that has a prefix, `images`.
    This prefix contains four image files named `animal.jpg`, `draw-house.jpg`, `cat.jpg`,
    and `human.jpg`.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们以一个具有前缀`images`的存储桶`test-bucket`为例。这个前缀包含四个名为`animal.jpg`、`draw-house.jpg`、`cat.jpg`和`human.jpg`的图像文件。
- en: 'Now, to delete the contents inside the images, the command will be as follows:
    **aws s3 rm s3://test-bucket/images –recursive**'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，为了删除图像中的内容，命令如下：**aws s3 rm s3://test-bucket/images –recursive**
- en: The bucket should now be empty.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在存储桶应该是空的。
- en: In the next section, we are going to learn about object tags and object metadata.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习关于对象标签和对象元数据的内容。
- en: Distinguishing between object tags and object metadata
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 区分对象标签和对象元数据
- en: 'Let''s compare these two terms:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较这两个术语：
- en: '**Object Tag**: An object tag is a **key-value** pair. AWS S3 object tags can
    help you filter analytics and metrics, categorize storage, secure objects based
    on certain categorizations, track costs based on certain categorization of objects,
    and much more besides. Object tags can be used to create life cycle rules to move
    objects to cheaper storage tiers. You can have a maximum of 10 tags added to an
    object and 50 tags to a bucket. A tag key can contain 128 Unicode characters,
    while a tag value can contain 256 Unicode characters.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对象标签**：对象标签是一个**键值**对。AWS S3对象标签可以帮助您过滤分析和指标，对存储进行分类，根据某些分类对对象进行安全保护，根据对象的某些分类跟踪成本，以及更多。对象标签可以用来创建生命周期规则，将对象移动到更便宜的存储层。您可以为对象添加最多10个标签，为存储桶添加最多50个标签。标签键可以包含128个Unicode字符，而标签值可以包含256个Unicode字符。'
- en: '**Object Metadata**: Object metadata is descriptive data describing an object.
    It consists of **name-value** pairs. Object metadata is returned as HTTP headers
    on objects. They are of two types: one is **System metadata**, and the other is
    **User-defined metadata**. User-defined metadata is a custom name-value pair added
    to an object by the user. The name must begin with **x-amz-meta**. You can change
    all system metadata such as storage class, versioning, and encryption attributes
    on an object. Further details are available here: [https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对象元数据**：对象元数据是描述对象的描述性数据。它由**名称-值**对组成。对象元数据作为HTTP头在对象上返回。它们有两种类型：一种是**系统元数据**，另一种是**用户定义元数据**。用户定义元数据是用户添加到对象中的自定义名称-值对。名称必须以**x-amz-meta**开头。您可以更改对象上的所有系统元数据，如存储类、版本控制和加密属性。更多详细信息请参阅[https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html)。'
- en: Important note
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: Metadata names are case-insensitive, whereas tag names are case-sensitive.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 元数据名称不区分大小写，而标签名称区分大小写。
- en: In the next section, we are going to learn about controlling access to buckets
    and objects on Amazon S3 through different policies, including the resource policy
    and the identity policy.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习如何通过不同的策略控制Amazon S3上存储桶和对象的访问，包括资源策略和身份策略。
- en: Controlling access to buckets and objects on Amazon S3
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制对Amazon S3上存储桶和对象的访问
- en: Once the object is stored in the bucket, the next major step is to manage access.
    S3 is private by default, and access is given to other users or groups or resources
    via several methods. This means that access to the objects can be managed via
    **Access Control Lists** (**ACLs**), **Public Access Settings**, **Identity Policies**,
    and **Bucket Policies**.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦对象存储在存储桶中，下一个主要步骤就是管理访问。S3 默认是私有的，并且通过多种方法向其他用户、组或资源提供访问权限。这意味着可以通过 **访问控制列表（ACLs**）、**公共访问设置**、**身份策略**
    和 **存储桶策略** 来管理对象的访问权限。
- en: Let's look at some of these in detail.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细看看其中的一些。
- en: S3 bucket policy
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: S3 存储桶策略
- en: '`Principal` is rendered `*`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`Principal` 被渲染为 `*`：'
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: By default, everything in S3 is private to the owner. If we want to make a prefix
    public to the world, then Resource changes to `arn:aws:s3:::my-bucket/some-prefix/*`,
    and similarly, if it is intended for a specific IAM user or IAM group, then those
    details go to the principal part in the policy.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，S3 中的所有内容都对所有者私有。如果我们想将前缀公开给全世界，那么资源将变为 `arn:aws:s3:::my-bucket/some-prefix/*`，同样，如果它是为特定的
    IAM 用户或 IAM 组设计的，那么这些详细信息将进入策略中的主体部分。
- en: 'There can be conditions added to the bucket policy too. Let''s examine a use
    case where the organization wants to keep a bucket public and whitelist particular
    IP addresses. The policy would look something like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以在存储桶策略中添加条件。让我们考察一个组织希望保持存储桶公开并白名单特定 IP 地址的用例。策略可能看起来像这样：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'More examples are available in the AWS S3 developer guide, which is available
    here: [https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html](https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 更多示例可在 AWS S3 开发者指南中找到，链接如下：[https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html](https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html)。
- en: '**Block public access** is a separate setting given to the bucket owner to
    avoid any kind of mistakes in bucket policy. In a real-world scenario, the bucket
    can be made public through bucket policy by mistake; to avoid such mistakes, or
    data leaks, AWS has provided this setting. It provides a further level of security,
    irrespective of the bucket policy. You can choose this while creating a bucket,
    or it can be set after creating a bucket.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**阻止公共访问** 是为存储桶所有者提供的单独设置，以避免在存储桶策略中犯任何错误。在实际场景中，存储桶可能会由于策略错误而公开；为了避免此类错误或数据泄露，AWS
    提供了此设置。它提供了比存储桶策略更高的安全级别。你可以在创建存储桶时选择此设置，也可以在创建存储桶后设置。'
- en: '`us-east-1` in this example):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: （示例中的 `us-east-1`）：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**ACLs** are used to grant high-level permissions, typically for granting access
    to other AWS accounts. ACLs are one of the **Subresources** of a bucket or an
    object. A bucket or object can be made public quickly via ACLs. AWS doesn''t suggest
    doing this, and you shouldn''t expect questions about this on the test. It is
    good to know about this, but it is not as flexible as the **S3 bucket policy**.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**访问控制列表（ACLs**）用于授予高级权限，通常用于授予对其他 AWS 账户的访问权限。ACLs 是存储桶或对象的 **子资源** 之一。存储桶或对象可以通过
    ACLs 快速公开。AWS 不建议这样做，你也不应该在测试中期待有关此问题的问题。了解这一点是好的，但它不如 **S3 存储桶策略** 灵活。'
- en: Now, let's learn about the methods to protect our data in the next section.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在下一节中了解保护我们数据的方法。
- en: Protecting data on Amazon S3
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护 Amazon S3 上的数据
- en: In this section, we will learn how to record every version of an object. Along
    with durability, Amazon provides several techniques to secure the data in S3\.
    Some of those techniques involve enabling versioning and encrypting the objects.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何记录对象的每个版本。除了持久性之外，Amazon 还提供了几种技术来保护 S3 中的数据。其中一些技术涉及启用版本控制和加密对象。
- en: Versioning helps you to roll back to a previous version if there is any problem
    with the current object during update, delete, or put operations.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 版本控制可以帮助你在更新、删除或上传操作中，如果当前对象出现任何问题，回滚到之前的版本。
- en: Through encryption, you can control the access of an object. You need the appropriate
    key to read and write an object. We will also learn **Multi Factor Authentication
    (MFA)** for delete operations. Amazon also allows **Cross-Region Replication (CRR)**
    to maintain a copy of an object in another region, which can be used for data
    backup during any disaster, for further redundancy, or for the enhancement of
    data access speed in different regions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 通过加密，你可以控制对象的访问。你需要适当的密钥来读取和写入对象。我们还将学习**多因素认证（MFA）**用于删除操作。亚马逊还允许**跨区域复制（CRR）**，在另一个区域中维护对象的副本，这可以在任何灾难期间用于数据备份，以提供额外的冗余，或者用于提高不同区域的数据访问速度。
- en: Applying bucket versioning
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用存储桶版本控制
- en: 'Let''s now understand how we can enable bucket versioning with the help of
    some hands-on examples. Bucket versioning can be applied while creating a bucket
    from the AWS S3 console:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在通过一些实际操作示例来了解如何使用帮助启用存储桶版本控制。可以在创建存储桶时从AWS S3控制台应用存储桶版本控制：
- en: 'To enable versioning on a bucket from the command line, a bucket must be created
    first and then versioning can be enabled, as shown in the following example. In
    this example, I have created a bucket, `version-demo-mlpractice`, and enabled
    versioning through the `put-bucket-versioning` command:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从命令行启用存储桶的版本控制，必须首先创建存储桶，然后才能启用版本控制，如下例所示。在这个例子中，我已经创建了一个存储桶，`version-demo-mlpractice`，并通过`put-bucket-versioning`命令启用了版本控制：
- en: '[PRE11]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We have not created this bucket with any kind of encryption. So, if you run
    `aws s3api get-bucket-encryption --bucket version-demo-mlpractice`, then it will
    output an error that says the following:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们没有使用任何加密方式创建这个存储桶。因此，如果你运行`aws s3api get-bucket-encryption --bucket version-demo-mlpractice`，它将输出一个错误，显示以下内容：
- en: '[PRE12]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`put-bucket-encryption` API. The command will look like this:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`put-bucket-encryption` API。命令看起来是这样的：'
- en: '[PRE13]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The same can be verified using the following command: `aws s3api get-bucket-encryption
    --bucket version-demo-mlpractice`.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样可以使用以下命令进行验证：`aws s3api get-bucket-encryption --bucket version-demo-mlpractice`。
- en: We will learn more about encryption in the next section.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中了解更多关于加密的内容。
- en: Applying encryption to buckets
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用存储桶加密
- en: 'You also need to understand how enabling versioning on a bucket would help.
    There are use cases where a file is updated regularly, and versions will be created
    for the same file. To simulate this scenario, try the following example:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要了解在存储桶上启用版本控制将如何帮助。有一些用例中，文件会定期更新，并且将为同一文件创建版本。为了模拟这种场景，请尝试以下示例：
- en: 'In this example, we will create a file with versions written in it. We will
    overwrite it and retrieve it to check the versions in that file:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将创建一个包含版本信息的文件。我们将覆盖它并检索它以检查该文件中的版本：
- en: '[PRE14]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Upon retrieval, we got the latest version of the file, in other words, `Version-2`
    in this case. To check each of the versions and the latest one of them, S3 provides
    the `list-object-versions` API, as shown here. From the JSON results, you can
    deduce the latest version:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在检索时，我们得到了文件的最新版本，换句话说，在这个例子中是`Version-2`。要检查每个版本以及它们的最新版本，S3提供了`list-object-versions`
    API，如下所示。从JSON结果中，你可以推断出最新版本：
- en: '[PRE15]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'There may be a situation where you have to roll back to the earlier version
    of the current object. In the preceding example, the latest one is *Version-2*.
    You can make any desired version the latest or current version by parsing the
    *VersionId* sub resource to the `get-object` API call and uploading that object
    again. The other way is to delete the current or latest version by passing `versionId`
    to the `–version-id` parameter in the `delete-object` API request. More details
    about the API are available here: [https://docs.aws.amazon.com/cli/latest/reference/s3api/delete-object.html](https://docs.aws.amazon.com/cli/latest/reference/s3api/delete-object.html).'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可能会有这样的情况，你需要将当前对象的早期版本回滚。在前面的例子中，最新的是*Version-2*。你可以通过将*VersionId*子资源解析到`get-object`
    API调用中，并重新上传该对象，将任何所需的版本设置为最新或当前版本。另一种方法是，通过在`delete-object` API请求中将`versionId`传递到`–version-id`参数中，删除当前或最新版本。更多关于API的详细信息，请参阅此处：[https://docs.aws.amazon.com/cli/latest/reference/s3api/delete-object.html](https://docs.aws.amazon.com/cli/latest/reference/s3api/delete-object.html)。
- en: 'When you delete an object in a versioning-enabled bucket, it does not delete
    the object from the bucket. It just creates a marker called **DeleteMarker**.
    It looks like this:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你在启用了版本控制的存储桶中删除一个对象时，并不会从存储桶中删除该对象。它只是创建了一个名为**DeleteMarker**的标记。它看起来是这样的：
- en: '[PRE16]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This means that the object is not deleted. You can list it by using this command:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这意味着对象没有被删除。你可以使用以下命令列出它：
- en: '[PRE17]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now the bucket has no objects as `version-doc.txt`, and you can verify this
    using the `aws s3 ls` command because that marker became the current version of
    the object with a new ID. If you try to retrieve an object that is deleted, which
    means a delete marker is serving the current version of the object, then you will
    get a `VersionId`, as shown in the following example commands. A simple delete
    request **(without the version ID)** will not delete the delete marker and create
    another delete marker with a unique version ID. So, it''s possible to have multiple
    delete markers for the same object. It is important to note at this point that
    it will consume your storage and you will be billed for it:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在存储桶中没有名为`version-doc.txt`的对象，您可以使用`aws s3 ls`命令来验证这一点，因为该标记已成为具有新ID的对象的当前版本。如果您尝试检索已删除的对象，这意味着删除标记正在充当对象的当前版本，那么您将获得一个`VersionId`，如下面的示例命令所示。一个简单的删除请求**（不带版本ID）**不会删除删除标记并创建另一个具有唯一版本ID的删除标记。因此，对于同一对象可以有多个删除标记。在此需要注意的是，这将消耗您的存储空间，并且您将为此付费：
- en: '[PRE18]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Upon listing the bucket now, the older objects can be seen:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在现在列出存储桶时，可以看到较旧的对象：
- en: '[PRE19]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As we have already covered the exam topics and practiced most of the required
    concepts, we should delete the objects in the bucket and then delete the bucket
    to save on costs. This step deletes the versions of the object and, in turn, removes
    the object permanently.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于我们已经涵盖了考试主题并练习了大多数所需的概念，我们应该删除存储桶中的对象，然后删除存储桶以节省成本。此步骤将删除对象的版本，从而永久删除对象。
- en: 'Here, the latest version is deleted by giving the version ID to it, followed
    by the other version ID:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，通过向其提供版本ID，然后是另一个版本ID来删除最新版本：
- en: '[PRE20]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We can clearly see the empty bucket now.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们现在可以清楚地看到空存储桶了。
- en: Important note
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'AWS best practices suggest adding another layer of protection through **MFA
    delete**. Accidental bucket deletions can be prevented, and the security of the
    objects in the bucket is ensured. MFA delete can be enabled or disabled via the
    console and CLI. As documented in AWS docs, MFA delete requires two forms of authentication
    together: your security credentials, and the concatenation of a valid serial number,
    a space, and the six-digit code displayed on an approved authentication device.'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AWS最佳实践建议通过**多因素认证删除**添加另一层保护。可以防止意外删除存储桶，并确保存储桶中对象的安全性。可以通过控制台和CLI启用或禁用多因素认证删除。如AWS文档所述，多因素认证删除需要两种认证方式同时进行：您的安全凭证，以及一个有效序列号、一个空格和显示在批准的认证设备上的六位代码的组合。
- en: 'CRR helps you to separate data between different geographical regions. A typical
    use case can be business-as-usual activities during a disaster. If a region goes
    down, then another region can support the users if CRR is enabled. This improves
    the availability of the data. Another use case is to reduce latency if the same
    data is used by another compute resource, such as EC2 or AWS Lambda being launched
    in another region. You can also use CRR to copy objects to another AWS account
    that belongs to a different owner. There are a few important points that are worth
    noting down for the certification exam:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: CRR可以帮助您在不同地理区域之间分离数据。一个典型的用例是在灾难期间的正常业务活动。如果某个区域发生故障，则另一个区域可以在CRR启用的情况下支持用户。这提高了数据可用性。另一个用例是如果同一数据被另一个计算资源使用，例如在另一个区域启动的EC2或AWS
    Lambda，可以减少延迟。您还可以使用CRR将对象复制到属于不同所有者的另一个AWS账户。对于认证考试，以下是一些重要要点值得记录：
- en: In order to use CRR, versioning has to be enabled on both the source and destination
    bucket.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了使用CRR，必须在源和目标存储桶上启用版本控制。
- en: Replication is enabled on the source bucket by adding rules. As the source,
    either an entire bucket, or a prefix, or tags can be replicated.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过添加规则，在源存储桶上启用了复制。作为源，可以是整个存储桶、前缀或标签进行复制。
- en: Encrypted objects can also be replicated by assigning an appropriate encryption
    key.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过分配适当的加密密钥，加密对象也可以进行复制。
- en: The destination bucket can be in the same account or in another account. You
    can change the storage type and ownership of the object in the destination bucket.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标存储桶可以位于同一账户或另一个账户。您可以在目标存储桶中更改对象的存储类型和所有权。
- en: For CRR, an existing role can be chosen or a new IAM role can be created too.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于CRR，可以选择现有的角色或创建新的IAM角色。
- en: There can be multiple replication rules on the source bucket, with priority
    accorded to it. Rules with higher priority override rules with lower priority.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源存储桶上可以有多个复制规则，并赋予其优先级。优先级较高的规则会覆盖优先级较低的规则。
- en: When you add a replication rule, only new versions an object that are created
    after the rules are enabled get replicated.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你添加复制规则时，只有规则启用后创建的新版本对象才会被复制。
- en: If versions are deleted from the source bucket, then they are not deleted from
    the destination bucket.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果从源存储桶中删除了版本，则它们不会被从目标存储桶中删除。
- en: When you delete an object from the source bucket, it creates a delete marker
    in said source bucket. That delete marker is not replicated to the destination
    bucket by S3\.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你从源存储桶中删除一个对象时，它会在该源存储桶中创建一个删除标记。S3不会将此删除标记复制到目标存储桶。
- en: In the next section, we will cover the concept of securing S3 objects.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍保护S3对象的概念。
- en: Securing S3 objects at rest and in transit
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护静态和传输中的S3对象
- en: 'In the previous section, we learned about bucket default encryption, which
    is completely different from object-level encryption. Buckets are not encrypted,
    whereas objects are. A question may arise here: *what is bucket default encryption?*
    We will learn these concepts in this section. Data during transmission can be
    protected by using **Secure Socket Layer (SSL)** or **Transport Layer Security
    (TLS)** for the transfer of the HTTPS requests. The next step is to protect the
    data, where the authorized person can encode and decode the data.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们学习了存储桶默认加密的概念，这与对象级加密完全不同。存储桶没有被加密，而对象被加密。这里可能会出现一个问题：*什么是存储桶默认加密？*
    我们将在本节中学习这些概念。在传输过程中，可以使用**安全套接字层（SSL）**或**传输层安全性（TLS）**来保护HTTPS请求的传输。下一步是保护数据，授权人员可以编码和解码数据。
- en: 'It is possible to have different encryption settings on different objects in
    the same bucket. S3 supports **Client-Side Encryption (CSE)** and **Server-Side
    Encryption (SSE)** for objects at rest:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一个存储桶中，可以对不同的对象有不同的加密设置。S3支持对象静态存储的**客户端加密（CSE）**和**服务器端加密（SSE）**：
- en: '**Client-Side Encryption**: A client uploads the object to S3 via the S3 endpoint.
    In CSE, the data is encrypted by the client before uploading to S3\. Although
    the transit between the user and the S3 endpoint happens in an encrypted channel,
    the data in the channel is already encrypted by the client and can''t be seen.
    In transit, encryption takes place by default through HTTPS. So, AWS S3 stores
    the encrypted object and cannot read the data in any format at any point in time.
    In CSE, the client takes care of encrypting the object content. So, control stays
    with the client in terms of key management and the encryption-decryption process.
    This leads to a huge amount of CPU usage. S3 is only used for storage.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户端加密**：客户端通过S3端点将对象上传到S3。在客户端加密（CSE）中，数据在上传到S3之前由客户端加密。尽管用户和S3端点之间的传输发生在加密通道中，但通道中的数据已经被客户端加密，无法被看到。在传输过程中，默认通过HTTPS进行加密。因此，AWS
    S3存储加密对象，在任何时候都无法以任何格式读取数据。在CSE中，客户端负责加密对象内容。因此，在密钥管理和加密解密过程中，控制权始终在客户端。这导致CPU使用量巨大。S3仅用于存储。'
- en: '**Server-Side Encryption**: A client uploads the object to S3 via the S3 endpoint.
    Even though the data in transit is through an encrypted channel that uses HTTPS,
    the objects themselves are not encrypted inside the channel. Once the data hits
    S3, then it is encrypted by the S3 service. In SSE, you trust S3 to perform encryption-decryption,
    object storage, and key management. There are three types of SSE techniques available
    for S3 objects:'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务器端加密**：客户端通过S3端点将对象上传到S3。尽管传输中的数据通过使用HTTPS的加密通道，但对象本身在通道内没有被加密。一旦数据到达S3，它就会被S3服务加密。在SSE中，你信任S3执行加密解密、对象存储和密钥管理。S3对象有三种SSE技术可用：'
- en: a) SSE-C
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) SSE-C
- en: b) SSE-S3
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) SSE-S3
- en: c) SSE-KMS
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) SSE-KMS
- en: '`PUT` operation, the user has to provide a key and an object to S3\. S3 encrypts
    the object using the key provided and attaches the hash (a cipher text) to the
    object. As soon as the object is stored, S3 discards the encryption key. This
    generated hash is one-way and cannot be used to generate a new key. When the user
    provides a `GET` operation request along with the decryption key, the hash identifies
    whether the specific key was used for encryption. Then, S3 decrypts and discards
    the key.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在进行`PUT`操作时，用户必须向S3提供密钥和对象。S3使用提供的密钥加密对象，并将哈希（加密文本）附加到对象上。一旦对象被存储，S3就会丢弃加密密钥。这个生成的哈希是一次的，不能用来生成新的密钥。当用户提供带有解密密钥的`GET`操作请求时，哈希会识别是否使用了特定的密钥进行加密。然后，S3解密并丢弃密钥。
- en: '`PUT` operation, the user just provides the unencrypted object. S3 creates
    a master key to be used for the encryption process. No one can change anything
    on this master key as this is created, rotated internally, and managed by S3 end
    to end. This is a unique key for the object. It uses the AES-256 algorithm by
    default.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PUT`操作中，用户只需提供未加密的对象。S3创建一个用于加密过程的密钥。由于这个密钥是在内部创建、旋转并由S3端到端管理的，因此没有人可以更改这个主密钥。这是对象的唯一密钥。它默认使用AES-256算法。'
- en: '**Server-Side Encryption with Customer Master Keys stored in AWS Key Management
    Service (SSE-KMS)**: **AWS Key Management Service (KMS)** manages the **Customer
    Master Key (CMK)**. AWS S3 collaborates with AWS KMS and generates an AWS-managed
    CMK. This is the default master key used for **SSE-KMS**. Every time an object
    is uploaded, S3 uses a dedicated key to encrypt that object and that key is a
    **Data Encryption Key (DEK)**. The DEK is generated by KMS using the CMK. S3 is
    provided with both a plain-text version and an encrypted version of the DEK. The
    plain-text version of DEK is used to encrypt the object and then discarded. The
    encrypted version of DEK is stored along with the encrypted object. When you''re
    using SSE-KMS, it is not necessary to use the default CMK that is created by S3\.
    You can create and use a customer managed CMK, which means you can control the
    permission on it as well as the rotation of the key material. So, if you have
    a regulatory board in your organization that is concerned with rotation of the
    key or the separation of roles between encryption users and decryption users,
    then SSE-KMS is the solution. Logging and auditing is also possible on SSE-KMS
    to track the API calls made against keys.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用存储在AWS密钥管理服务（SSE-KMS）中的客户主密钥进行服务器端加密**：**AWS密钥管理服务（KMS）**管理**客户主密钥（CMK）**。AWS
    S3与AWS KMS协作并生成一个AWS管理的CMK。这是SSE-KMS默认使用的密钥。每次上传对象时，S3都会使用一个专用的密钥来加密该对象，而这个密钥是一个**数据加密密钥（DEK）**。DEK由KMS使用CMK生成。S3提供了DEK的明文版本和加密版本。DEK的明文版本用于加密对象然后被丢弃。DEK的加密版本与加密对象一起存储。当您使用SSE-KMS时，不需要使用S3创建的默认CMK。您可以创建并使用客户管理的CMK，这意味着您可以控制其上的权限以及密钥材料的旋转。因此，如果您所在的组织中有一个关注密钥旋转或加密用户与解密用户之间角色分离的监管委员会，那么SSE-KMS是解决方案。在SSE-KMS上还可以进行日志记录和审计，以跟踪针对密钥的API调用。'
- en: '`PUT` operation.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PUT`操作。'
- en: In the next section, we will learn about some of the data stores used with EC2
    instances.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将了解一些与EC2实例一起使用的数据存储。
- en: Using other types of data stores
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用其他类型的数据存储
- en: '**Elastic Block Store (EBS)** is used to create volumes in an availability
    zone. The volume can only be attached to an EC2 instance in the same availability
    zone. Amazon EBS provides both **SSD (Solid State Drive)** and **HDD (Hard Disk
    Drive)** types of volumes. For SSD-based volumes, the dominant performance attribute
    is **IOPS** (**Input Output Per Second**), and for HDD it is throughput, which
    is generally measured as MiB/s. The following table shown in *Figure 5.3* provides
    an overview of the different volumes and types:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**弹性块存储（EBS）**用于在可用区创建卷。该卷只能连接到同一可用区内的EC2实例。Amazon EBS提供**SSD（固态硬盘）**和**HDD（硬盘驱动器）**类型的卷。对于基于SSD的卷，主导的性能属性是**IOPS（每秒输入输出）**，而对于HDD则是吞吐量，通常以MiB/s来衡量。以下表格在*图5.3*中提供了不同卷和类型的概述：'
- en: '![Figure 5.3 – Different volumes and their use cases'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.3 – 不同卷及其用例]'
- en: '](img/B16735_05_003.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片/B16735_05_003.jpg]'
- en: Figure 5.3 – Different volumes and their use cases
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – 不同卷及其用例
- en: '**EBS** is resilient to an availability zone (AZ). If, for some reason, an
    AZ fails, then the volume cannot be accessed. To avoid such scenarios, **snapshots**
    can be created from the EBS volumes and snapshots are stored in S3\. Once the
    snapshot arrives at S3, the data in the snapshot becomes region-resilient. The
    first snapshot is a full copy of data on the volume and, from then onward, snapshots
    are incremental. Snapshots can be used to clone a volume. As the snapshot is stored
    in S3, a volume can be cloned in any AZ in that region. Snapshots can be shared
    between regions and volumes can be cloned from them during disaster recovery.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**EBS**对可用区（AZ）具有容错性。如果由于某种原因，一个AZ失败，那么卷将无法访问。为了避免这种情况，可以从EBS卷创建**快照**，并且快照存储在S3中。一旦快照到达S3，快照中的数据就具有区域容错性。第一个快照是卷上数据的完整副本，从那时起，快照是增量式的。快照可以用来克隆卷。由于快照存储在S3中，可以在该区域的任何AZ中克隆卷。快照可以在区域之间共享，并且可以在灾难恢复期间从它们克隆卷。'
- en: AWS KMS manages the CMK. AWS KMS uses an AWS-managed CMK for EBS, or AWS KMS
    can use a customer-managed CMK. CMK is used by EBS when an encrypted volume is
    created. CMK is used to create an encrypted DEK, which is stored with the volume
    on the physical disk. This DEK can only be decrypted using KMS, assuming the entity
    has access to decrypt. When a snapshot is created from the encrypted volume, the
    snapshot is encrypted with the same DEK. Any volume created from this snapshot
    also uses that DEK.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: AWS KMS管理CMK。AWS KMS可以使用AWS管理的CMK来管理EBS，或者AWS KMS可以使用客户管理的CMK。当创建加密卷时，EBS会使用CMK。CMK用于创建一个加密的DEK，该DEK与卷一起存储在物理磁盘上。这个DEK只能通过KMS解密，前提是该实体有解密权限。当从加密卷创建快照时，快照会使用相同的DEK进行加密。从该快照创建的任何卷也将使用该DEK。
- en: '**Instance Store** volumes are the block storage devices physically connected
    to the EC2 instance. They provide the highest performance, as the **ephemeral
    storage** attached to the instance is from the same host where the instance is
    launched. EBS can be attached to the instance at any time, but the instance store
    must be attached to the instance at the time of its launch; it cannot be attached
    later, once the instance is launched. If there is an issue on the underlying host
    of an EC2 instance, then the same instance will be launched on another host with
    a new instance store volume and the earlier instance store (ephemeral storage)
    and older data is lost. The size and capabilities of the attached volumes depend
    on the instance types and can be found in more detail here: [https://aws.amazon.com/ec2/instance-types/](https://aws.amazon.com/ec2/instance-types/).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**实例存储**卷是物理连接到EC2实例的块存储设备。由于实例附加的**临时存储**来自实例启动的主机，因此它们提供最高的性能。EBS可以在任何时候附加到实例，但实例存储必须在实例启动时附加；一旦实例启动，就不能再附加。如果EC2实例的底层主机存在问题，则相同的实例将在另一个主机上启动，并带有新的实例存储卷，而早期的实例存储（临时存储）和旧数据将丢失。附加卷的大小和能力取决于实例类型，更详细的信息可以在这里找到：[https://aws.amazon.com/ec2/instance-types/](https://aws.amazon.com/ec2/instance-types/)。'
- en: '**Elastic File System (EFS)** provides a network-based filesystem that can
    be mounted within Linux EC2 instances and can be used by multiple instances at
    once. It is an implementation of **NFSv4**. It can be used in general-purpose
    mode, max I/O performance mode (for scientific analysis or parallel computing),
    bursting mode, and provisioned throughput mode.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**弹性文件系统（EFS）**提供了一种基于网络的文件系统，可以在Linux EC2实例内部挂载，并且可以一次由多个实例使用。它是**NFSv4**的实现。它可以用于通用模式、最大I/O性能模式（用于科学分析或并行计算）、突发模式和预配吞吐量模式。'
- en: 'As we know, in the case of instance stores, the data is volatile. As soon as
    the instance is lost, the data is lost from the instance store. That is not the
    case for EFS. EFS is separate from the EC2 instance storage. EFS is a file store
    and is accessed by multiple EC2 instances via mount targets inside a VPC. On-premises
    systems can access EFS storage via hybrid networking to the VPC, such as **VPN**
    or **Direct Connect**. EFS also supports two types of storage classes: Standard
    and Infrequent Access. Standard is used for frequently accessed data. Infrequent
    Access is the cost-effective storage class for long-lived, less frequently accessed
    data. Life cycle policies can be used for the transition of data between storage
    classes.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: An instance store is preferred for max I/O requirements and if the data is replaceable
    and temporary.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Relational Database Services (RDSes)
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is one of the most commonly featuring exam topics in AWS exams. You should
    have sufficient knowledge prior to the exam. In this section, we will learn about
    Amazon's RDS.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: AWS provides several relational databases as a service to its users. Users can
    run their desired database on EC2 instances, too. The biggest drawback is that
    the instance is only available in one availability zone in a region. The EC2 instance
    has to be administered and monitored to avoid any kind of failure. Custom scripts
    will be required to maintain a data backup over time. Any database major or minor
    version update would result in downtime. Database instances running on an EC2
    instance cannot be easily scaled if the load increases on the database as replication
    is not an easy task.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: RDS provides managed database instances that can themselves hold one or more
    databases. Imagine a database server running on an EC2 instance that you do not
    have to manage or maintain. You need only access the server and create databases
    in it. AWS will manage everything else, such as the security of the instance,
    the operating system running on the instance, the database versions, and high
    availability of the database server. RDS supports multiple engines such as MySQL,
    Microsoft SQL Server, MariaDB, Amazon Aurora, Oracle, and PostgreSQL. You can
    choose any of these based on your requirements.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: The foundation of Amazon RDS is a database instance, which can support multiple
    engines and can have multiple databases created by the user. One database instance
    can be accessed only by using the database **CNAME** (CNAME is an alias for a
    canonical name in a domain name system database) of the primary instance. RDS
    uses standard database engines. So, accessing the database using some sort of
    tool in a self-managed database server is the same as accessing Amazon RDS.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: As we have now understood the requirements of Amazon RDS, let's understand the
    failover process in Amazon RDS. We will cover what services Amazon offers if something
    goes wrong with the RDS instance.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Managing failover in Amazon RDS
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: RDS instances can be **single-AZ** or **multi-AZ**. In multi-AZ, multiple instances
    work together, similar to an active-passive failover design.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: RDS实例可以是**单可用区**或**多可用区**。在多可用区中，多个实例协同工作，类似于活动-被动故障转移设计。
- en: For a single-AZ RDS instance, storage can be allocated for that instance to
    use. In a nutshell, a single-AZ RDS instance has one attached block store (EBS
    storage) available in the same availability zone. This makes the databases and
    the storage of the RDS instance vulnerable to availability zone failure. The storage
    allocated to the block storage can be SSD (gp2 or io1) or magnetic. To secure
    the RDS instance, it is advised to use a security group and provide access based
    on requirements.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单可用区RDS实例，可以为该实例分配存储。简而言之，单可用区RDS实例在同一可用区中有一个可用的附加块存储（EBS存储）。这使得RDS实例的数据库和存储容易受到可用区故障的影响。分配给块存储的存储可以是SSD（gp2或io1）或磁性存储。为了确保RDS实例的安全，建议使用安全组并根据需求提供访问权限。
- en: Multi-AZ is always the best way to design the architecture to avoid any failure
    and keep the applications highly available. With multi-AZ features, a standby
    replica is kept in sync **synchronously** with the primary instance. The standby
    instance has its own storage in the assigned availability zone. A standby replica
    cannot be accessed directly, because all RDS access is via a single database CNAME.
    You can't access the standby unless a failover happens. The standby provides no
    performance benefit, but it does constitute an improvement in terms of availability
    of the RDS instance. It can only happen in the same region, another AZ's subnet
    in the same region inside the VPC. When a multi-AZ RDS instance is online, you
    can take a backup from the standby replica without affecting the performance.
    In a single-AZ instance, availability and performance issues can be significant
    during backup operation.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 多可用区始终是避免任何故障并保持应用程序高可用性的最佳架构设计方式。利用多可用区功能，备用副本会与主体实例**同步**保持同步。备用实例在其指定的可用区有自己的存储。备用副本不能直接访问，因为所有RDS访问都是通过单个数据库CNAME。除非发生故障转移，否则无法访问备用实例。备用实例不提供性能优势，但它确实在RDS实例的可用性方面构成改进。它只能在同一区域发生，即在VPC内同一区域的另一个可用区的子网中。当多可用区RDS实例在线时，你可以从备用副本中备份，而不会影响性能。在单可用区实例中，备份操作期间可能会出现可用性和性能问题。
- en: To understand the workings of multi-AZ, let's take an example of a single-AZ
    instance and expand it to multi-AZ.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解多可用区（multi-AZ）的工作原理，让我们以一个单可用区（single-AZ）的实例为例，并将其扩展到多可用区。
- en: Imagine you have an RDS instance running in availability zone `AZ-A` of the
    `us-east-1` region inside a VPC named `db-vpc`. This becomes a primary instance
    in a single-AZ design of an RDS instance. In this case, there will be storage
    allocated to the instance in the *AZ-A* availability zone. Once you opt for multi-AZ
    deployment in another availability zone called *AZ-B*, AWS creates a standby instance
    in availability zone *AZ-B* of the *us-east-1* region inside the *db-vpc* VPC
    and allocates storage for the standby instance in *AZ-B* of the *us-east-1* region.
    Along with that, RDS will enable **synchronous replication** from the primary
    instance to the standby replica. As we have learned earlier, the only way to access
    our RDS instance is via the database CNAME, hence, the access request goes to
    the RDS primary instance. As soon as a write request comes to the endpoint, it
    writes to the primary instance. Then it writes the data to the hardware, which
    is the block storage attached to the primary instance. At the same time, the primary
    instance replicates the same data to the standby instance. Finally, the standby
    instance commits the data to its block storage.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个运行在名为`db-vpc`的VPC内`us-east-1`区域`AZ-A`的RDS实例。这成为了一个RDS实例单可用区设计的主体实例。在这种情况下，将在*AZ-A*可用区为该实例分配存储。一旦你选择在另一个名为*AZ-B*的可用区进行多可用区部署，AWS将在*db-vpc*
    VPC内*us-east-1*区域的*AZ-B*可用区创建一个备用实例，并在*us-east-1*区域的*AZ-B*为备用实例分配存储。除此之外，RDS将从主体实例到备用副本启用**同步复制**。正如我们之前所学的，访问我们的RDS实例的唯一方式是通过数据库CNAME，因此，访问请求会发送到RDS主体实例。一旦写入请求到达端点，它就会写入主体实例。然后它将数据写入硬件，这是附加到主体实例的块存储。同时，主体实例将相同的数据复制到备用实例。最后，备用实例将数据提交到其块存储。
- en: The primary instance writes the data into the hardware and replicates the data
    to the standby instance in parallel, so there is a minimal time lag (almost nothing)
    between the data commit operations in their respective hardware. If an error occurs
    with the primary instance, then RDS detects this and changes the database endpoint
    to the standby instance. The clients accessing the database may experience a very
    short interruption with this. This failover occurs within 60-120 seconds. It does
    not provide a fault-tolerant system because there will be some impact during the
    failover operation.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 主实例将数据写入硬件，并并行地将数据复制到备用实例，因此在它们各自的硬件中的数据提交操作之间有最小的时间延迟（几乎为零）。如果主实例发生错误，RDS会检测到这一点并将数据库端点更改为备用实例。访问数据库的客户端可能会经历非常短暂的中断。这种故障转移在60-120秒内发生。它不提供容错系统，因为在故障转移操作期间会有一些影响。
- en: You should now understand failover management on Amazon RDS. Let's now learn
    about taking automatic RDS backup, using snapshots to restore in the event of
    any failure, and read replicas in the next section.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在应该已经理解了Amazon RDS的故障转移管理。现在，让我们学习如何自动备份RDS，使用快照在发生任何故障时进行恢复，以及下一节中的读取副本。
- en: Taking automatic backup, RDS snapshots, and restore and read replicas
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动备份、RDS快照、恢复和读取副本
- en: In this section, we will see how RDS **Automatic Backup** and **Manual Snapshots**
    work. These features come with Amazon RDS.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解RDS的**自动备份**和**手动快照**是如何工作的。这些功能是Amazon RDS的一部分。
- en: Let's consider a database that is scheduled to take a backup at 5 A.M. every
    day. If the application fails at 11 A.M., then it is possible to restart the application
    from the backup taken at 11 A.M. with the loss of 6 hours' worth of data. This
    is called 6 hours **RPO (Recovery Point Objective)**. So, RPO is defined as the
    time between the most recent backup and the incident and this defines the amount
    of data loss. If you want to reduce this, then you have to schedule more incremental
    backups, which increases the cost and backup frequency. If your business demands
    a lower RPO value, then the business must spend more on meeting the technical
    solutions.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个每天早上5点进行备份的数据库。如果应用程序在上午11点失败，那么可以从上午11点进行的备份中重新启动应用程序，但会丢失6小时的数据。这被称为6小时**RPO（恢复点目标）**。因此，RPO是指最近一次备份和事件之间的时间，这定义了数据丢失的数量。如果您想减少这个时间，那么您必须安排更多的增量备份，这将增加成本和备份频率。如果您的业务需要更低的RPO值，那么业务必须为满足技术解决方案投入更多的资金。
- en: Now, according to our example, an engineer was assigned this task to bring the
    system online as soon as the disaster occurred. The engineer managed to bring
    the database online at 2 P.M. on the same day by adding a few extra hardware components
    to the current system and installed some updated versions of the software. This
    is called 3 hours **RTO (Recovery Time Objective)**. So, RTO is determined as
    the time between the disaster recovery and full recovery. RTO values can be reduced
    by having spare hardware and documenting the restoration process. If the business
    demands a lower RTO value, then your business must spend more money on spare hardware
    and effective system setup to perform the restoration process.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，根据我们的例子，一位工程师被分配了这个任务，在灾难发生时尽快将系统上线。工程师通过向现有系统添加一些额外的硬件组件并安装一些更新的软件版本，在同一天下午2点成功将数据库上线。这被称为3小时**RTO（恢复时间目标）**。因此，RTO是指灾难恢复和完全恢复之间的时间。通过拥有备用硬件和记录恢复过程，可以降低RTO值。如果业务需要更低的RTO值，那么您的业务必须在备用硬件和有效的系统设置上投入更多的资金以执行恢复过程。
- en: In RDS, RPO and RTO play an important role in the selection of **Automatic Backups**
    and **Manual Snapshots**. Both of these backup services use AWS-managed S3 buckets,
    which means it cannot be visible in the user's AWS S3 console. It is region-resilient
    because the backup is replicated into multiple availability zones in the AWS region.
    In case of a single-AZ RDS instance, the backup happens from the single available
    data store, and for a multi-AZ enabled RDS instance, the backup happens from the
    standby data store (the primary store remains untouched as regards the backup).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在RDS中，RPO和RTO在选择**自动备份**和**手动快照**时发挥着重要作用。这两个备份服务都使用AWS管理的S3存储桶，这意味着它不能在用户的AWS
    S3控制台中可见。它是区域弹性，因为备份被复制到AWS区域中的多个可用区。对于单AZ RDS实例，备份是从单个可用的数据存储进行的，而对于已启用多AZ的RDS实例，备份是从备用数据存储（主存储在备份方面保持不变）进行的。
- en: The snapshots are manual against RDS instances and these are stored in the AWS-managed
    S3 bucket. The first snapshot of an RDS instance is a full copy of the data and
    the onward snapshots are incremental, reflecting the change in the data. In terms
    of the time taken for the snapshot process, it is higher for the first one and,
    from then on, the incremental backup is quicker. When any snapshot occurs, it
    can impact the performance of the single-AZ RDS instance, but not the performance
    of a multi-AZ RDS instance as this happens on the standby data storage. Manual
    snapshots do not expire, have to be cleared automatically, and they live past
    the termination of an RDS instance. When you delete an RDS instance, it suggests
    making one final snapshot on your behalf and it will contain all the databases
    inside your RDS instance (there is not just a single database in an RDS instance).
    When you restore from a manual snapshot, you restore to a single point in time
    and that affects the RPO.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 快照是针对RDS实例的手动操作，并且这些快照存储在AWS管理的S3桶中。RDS实例的第一个快照是数据的完整副本，后续的快照是增量备份，反映了数据的变化。在快照过程的耗时方面，第一个快照所需时间较长，从那时起，增量备份会更快。当任何快照发生时，它可能会影响单AZ
    RDS实例的性能，但不会影响多AZ RDS实例的性能，因为这是在备用数据存储上发生的。手动快照不会过期，需要自动清除，并且它们会存在于RDS实例终止之后。当你删除RDS实例时，它会建议为你创建一个最后的快照，并且这个快照将包含你RDS实例内部的所有数据库（RDS实例中不仅仅只有一个数据库）。当你从手动快照恢复时，你将恢复到单个时间点，这会影响RPO。
- en: To automate this entire process, you can choose a time window when these snapshots
    can be taken. This is called automatic backups. These time windows can be managed
    wisely to essentially lower the RPO value of the business. Automatic backups have
    a retention period of 0 to 35 days, with 0 being disabled and the maximum is 35
    days. To quote AWS documentation, retained automated backups contain system snapshots
    and transaction logs from a database instance. They also include database instance
    properties such as allocated storage and a database instance class, which are
    required to restore it to an active instance. Databases generate transaction logs,
    which contain the actual change in data in a particular database. These transaction
    logs are also written to S3 every 5 minutes by RDS. Transaction logs can also
    be replayed on top of the snapshots to restore to a point in time of 5 minutes'
    granularity. Theoretically, the RPO can be a 5-minute point in time.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 要自动化整个流程，你可以选择一个时间窗口来捕捉这些快照。这被称为自动备份。这些时间窗口可以明智地管理，从而本质上降低业务的RPO（恢复点目标）值。自动备份的保留期为0到35天，其中0表示禁用，最大值为35天。根据AWS文档，保留的自动备份包含数据库实例的系统快照和事务日志。它们还包括数据库实例属性，如分配的存储和数据库实例类别，这些是将其恢复为活动实例所必需的。数据库生成事务日志，这些日志包含特定数据库中的实际数据变化。这些事务日志每5分钟由RDS写入S3。事务日志还可以在快照之上重放，以恢复到5分钟粒度的时间点。理论上，RPO可以是一个5分钟的时间点。
- en: When you perform a restore, RDS creates a new RDS instance, which means a new
    database endpoint to access the instance. The applications using the instances
    have to point to the new address, which significantly affects the RTO. This means
    that the restoration process is not very fast, which affects the RTO. To minimize
    the RTO during a failure, you may consider replicating the data. With replicas,
    there is a high chance of replicating the corrupted data. The only way to overcome
    this is to have snapshots and an RDS instance can be restored to a particular
    point in time prior to the corruption. **Amazon RDS Read Replicas** are unlike
    the multi-AZ replicas. In multi-AZ RDS instances, the standby replicas cannot
    be used directly for anything unless a primary instance fails, whereas **Read
    Replicas** can be used directly, but only for read operations. Read replicas have
    their own database endpoints and read-heavy applications can directly point to
    this address. They are kept in sync **asynchronously** with the primary instance.
    Read replicas can be created in the same region as the primary instance or in
    a different region. Read replicas in other regions are called **Cross-Region Read
    Replicas** and this improves the global performance of the application.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: As per AWS documentation, five direct read replicas are allowed per database
    instance and this helps to scale out the read performances. Read replicas have
    a very low RPO value due to asynchronous replication. They can be promoted to
    a read-write database instance in the case of a primary instance failure. This
    can be done quickly and it offers a fairly low RTO value.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn about Amazon's own database engine, Amazon
    Aurora.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Writing to Amazon Aurora with multi-master capabilities
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon Aurora is the most reliable relational database engine developed by Amazon
    to deliver speed in a simple and cost-effective manner. Aurora uses a cluster
    of single primary instances and zero or more replicas. Aurora's replicas can give
    you the advantage of both read replicas and multi-AZ instances in RDS. Aurora
    uses a shared cluster volume for storage and is available to all compute instances
    of the cluster (a maximum of 64 TiB). This allows the Aurora cluster to provision
    faster and improves availability and performance. Aurora uses SSD-based storage,
    which provides high IOPS and low latency. Aurora does not ask you to allocate
    storage, unlike other RDS instances; it is based on the storage that you use.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Aurora clusters have multiple endpoints, including **Cluster Endpoint** and
    **Reader Endpoint**. If there are zero replicas, then the cluster endpoint is
    the same as the reader endpoint. If there are replicas available, then the reader
    endpoint is load balanced across the reader endpoints. Cluster endpoints are used
    for reading/writing, while reader endpoints are intended for reading from the
    cluster. If you add more replicas, then AWS manages load balancing under the hood
    for the new replicas.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: When failover occurs, the replicas are promoted to read/write mode and this
    takes some time. This can be avoided in a **Multi-Master** mode of an Aurora cluster.
    This allows multiple instances to perform reads and writes at the same time.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Storing columnar data on Amazon Redshift
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon Redshift is not used for real-time transaction use, but it is used for
    data warehouse purposes. It is designed to support huge volumes of data at a petabyte
    scale. It is a column-based database used for analytics purpose, long-term processing,
    tending, and aggregation. **Redshift Spectrum** can be used to query data on S3
    without loading data to the Redshift cluster (a Redshift cluster is required though).
    It's not an OLTP, but an OLAP. **AWS QuickSight** can be integrated with Redshift
    for visualization, with a SQL-like interface that allows you to connect using
    JDBC/ODBC connections for querying the data.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Redshift uses a clustered architecture in one AZ in a VPC with faster network
    connectivity between the nodes. It is not high availability by design as it is
    tightly coupled to the AZ. A Redshift cluster has a **Leader Node**, and this
    node is responsible for all the communication between the client and the computing
    nodes of the cluster, query planning, and aggregation. **Compute Nodes** are responsible
    for running the queries submitted by the leader lode and for storing the data.
    By default, Redshift uses a public network for communicating with external services
    or any AWS services. With **Enhanced VPC Routing**, it can be controlled via customized
    networking settings.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Amazon DynamoDB for NoSQL database as a service
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Amazon DynamoDB is a NoSQL database-as-a-service product within AWS. It''s
    a fully managed key/value and document database. Accessing DynamoDB is easy via
    its endpoint. The input and output throughputs can be managed or scaled manually
    or in automatic fashion. It also supports data backup, point-in-time recovery,
    and data encryption. We will not cover the DynamoDB table structure or key structure
    in this chapter as this is not required for the certification exam. However, it
    is good to have a basic knowledge of them. For more details, please refer to the
    AWS docs available here: [https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.html](
    https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.html).'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about various data storage services from Amazon,
    and how to secure data through various policies and use these services. If you
    are working on machine learning use cases, then you may encounter such scenarios
    where you have to choose an effective data storage service for your requirements.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about the processing of stored data.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To set the region that an S3 bucket is stored in, you must first create the
    bucket and then set the region separately.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. False
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Is it mandatory to have both the source bucket and destination bucket in the
    same region in order to copy the contents of S3 buckets?
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. False
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By default, objects are private in a bucket.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. False
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By WS, a S3 object is immutable and you can only perform put and delete. Rename
    is GET and PUT of the same object with a different name.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. False
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If a user has stored an unversioned object and a versioned object in the same
    bucket, then the user can only delete the unversioned object. Versioned objects
    cannot be deleted.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. False
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Versioning applies to a complete bucket and not objects. If versioning is enabled
    on a bucket, then it can only be suspended; it cannot be disabled.
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A simple delete request on a delete marker will:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Delete the delete marker
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Create a copy of the delete marker
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Not delete the delete marker, but it will create another delete marker
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Delete the original version of the object
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Scaling and performance can be improved via RDS multi-AZ instances.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. False
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An RDS multi-AZ has nothing to do with scaling and performance. It is used for
    failover.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What protocol does EFS use?
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. SMB
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. NFS
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. EBS
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. HTTP
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which operating systems does EFS support?
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Linux only
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Windows only
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Both Windows and Linux
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Neither Windows nor Linux
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Is EFS a private service?
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Yes.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. No, it's a public service.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. It's both a private and a public service.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. It's neither a private nor a public service.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which two of the following are correct?
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Multi-AZ:Same Region::Read Replica:Multiple Region
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Multi-AZ:Multiple Region::Read Replica:Same Region
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Multi-AZ:Synchronous Replication::Read Replica:Asynchronous Replication
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Multi-AZ:ASynchronous Replication::Read Replica:Synchronous Replication
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following is correct?
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Read replicas are read-only instances.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Read replicas are read-write instances.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Read replicas are write-only instances.
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Read replicas are read-only instances, until promoted to read-write.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Where is EFS accessible from?
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Inside a VPC only
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Via AWS endpoints
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Anywhere with a public internet connection
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Inside a VPC or any on-premises locations connected to that VPC via a hybrid
    network
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which three of the following are true?
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Instance store volumes are persistent storage.
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Instance store volumes are temporary (ephemeral) storage.
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Data stored on instance store volumes can be lost if a hardware failure occurs.
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Data stored on instance store volumes can be lost when an EC2 instance restarts.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: E. Data stored on instance store volumes can be lost when an EC2 instance stops
    and starts.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Hardware failure can change the underlying host. So, there is no guarantee of
    the instance store volume. When you stop the instance and start it again, the
    instance store volume is lost due to the change of host. Instance restarting is
    different from stop and start; it means an operating system restart.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In order to enable encryption at rest using EC2 and EBS, you need to…
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Configure encryption when creating the EBS volume.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Configure encryption using the appropriate operating system's filesystem.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Configure encryption using X.509 certificates.
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Mount the EBS volume in S3 and then encrypt the bucket using a bucket policy.
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following is an action you cannot perform on an EBS snapshot?
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Create an image from a snapshot.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Create an EBS volume from a snapshot.
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Share a snapshot with another AWS account.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Make an unencrypted copy of an encrypted snapshot.
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With EBS, you need to do the following (choose two).
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Create an encrypted volume from a snapshot of another encrypted volume.
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Create an encrypted volume from an encrypted snapshot.
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Create an encrypted snapshot from an unencrypted snapshot by creating an
    encrypted copy of the unencrypted snapshot.
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Encrypt an existing volume.
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For more on EBS, visit the following link: [https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#EBSEncryption_c%20onsiderations](
    https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#EBSEncryption_c%20onsiderations).'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 1\. B
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 2\. B
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: 3\. A
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: 4\. A
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: 5\. B
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: 6\. C
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: 7\. B
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 8\. B
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 9\. A
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 10\. B
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: 11\. A, C
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: 12\. D
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 13\. D
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 14\. B, C, E
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: 15\. A
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: 16\. D
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 17\. A, C
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
