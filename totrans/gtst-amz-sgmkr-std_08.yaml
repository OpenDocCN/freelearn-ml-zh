- en: '*Chapter 6*: Detecting ML Bias and Explaining Models with SageMaker Clarify'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 6 章*：使用 SageMaker Clarify 检测 ML 偏差和解释模型'
- en: '**Machine learning** (**ML**) models are increasingly being used to help make
    business decisions across industries, such as in financial services, healthcare,
    education, and human resources (HR), thanks to the automation ML provides, with
    improved accuracy over humans. However, ML models are never perfect. They can
    make poor decisions—even unfair ones if not trained and evaluated carefully. An
    ML model can be biased in a way that hurts disadvantaged groups. Having an ability
    to understand bias in data and ML models during the ML life cycle is critical
    for creating a socially fair ML model. **SageMaker Clarify** computes ML biases
    in datasets and in ML models to help you gain an understanding of the limitation
    of ML models so that you can take appropriate action to mitigate these biases.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）模型正越来越多地被用于帮助各行各业做出商业决策，例如在金融服务、医疗保健、教育和人力资源（HR）等领域，这得益于 ML
    提供的自动化，其准确性超过了人类。然而，ML 模型从不完美。它们可能会做出糟糕的决策——如果不仔细训练和评估，甚至可能是不公平的决策。ML 模型可能会以伤害弱势群体的方式产生偏差。在
    ML 生命周期中能够理解数据和 ML 模型中的偏差对于创建一个社会公平的 ML 模型至关重要。**SageMaker Clarify** 在数据集和 ML
    模型中计算 ML 偏差，以帮助您了解 ML 模型的局限性，从而您可以采取适当的行动来减轻这些偏差。'
- en: ML models have long been considered as black box operations because it is rather
    difficult to see how a prediction is made. SageMaker Clarify computes feature
    attribution to help you explain how an ML model makes a decision so that it is
    no longer a black box to us. SageMaker Clarify integrates with SageMaker Studio
    so that you can easily review the results while building ML models. With SageMaker
    Clarify, you will be able to know more about your ML models, promote fairness
    and explainability in your ML use cases, and meet regulatory requirements if required.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ML 模型长期以来一直被视为黑盒操作，因为很难看到预测是如何做出的。SageMaker Clarify 通过计算特征归因来帮助您解释 ML 模型是如何做出决策的，这样它就不再是我们的黑盒了。SageMaker
    Clarify 与 SageMaker Studio 集成，以便您在构建 ML 模型时可以轻松地审查结果。使用 SageMaker Clarify，您将能够更多地了解您的
    ML 模型，提高您在 ML 用例中的公平性和可解释性，并在需要时满足监管要求。
- en: 'In this chapter, we will be learning about the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下主题：
- en: Understanding bias, fairness in ML, and ML explainability
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 ML 中的偏差、公平性和 ML 可解释性
- en: Detecting bias in ML
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测 ML 中的偏差
- en: Explaining ML models using **SHapley Additive exPlanations** (**SHAP**) values
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 **SHapley Additive exPlanations** （**SHAP**）值解释 ML 模型
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you need to access the code provided at [https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter06](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter06).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您需要访问提供的代码，请参阅[https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter06](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter06)。
- en: Understanding bias, fairness in ML, and ML explainability
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 ML 中的偏差、公平性和 ML 可解释性
- en: There are two types of bias in ML that we can analyze and mitigate to ensure
    fairness—**data bias** and **model bias**. **Data bias** is an imbalance in the
    training data across different groups and categories that can be introduced into
    an ML solution simply due to a sampling error, or intricately due to inherent
    reasons that are unfortunately ingrained in society. Data bias, if neglected,
    can translate into poor accuracy in general and unfair prediction against a certain
    group in a trained model. It is more critical than ever to be able to discover
    inherent biases in the data early and take action to address them. **Model bias**,
    on the other hand, refers to bias introduced by model prediction, such as the
    distribution of classification and errors among advantaged and disadvantaged groups.
    Should the model favor an advantaged group for a particular outcome or disproportionally
    predict incorrectly for a disadvantaged group, causing undesirable consequences
    in real-world ML applications such as loan-approval prediction systems, we as
    data scientists need to take action to understand why this has happened and mitigate
    the behavior.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，我们可以分析和缓解两种类型的偏差以确保公平性——**数据偏差**和**模型偏差**。**数据偏差**是指在不同群体和类别之间训练数据的不平衡，这可能是由于采样错误简单地引入到机器学习解决方案中，或者由于不幸地根植于社会中的固有原因而复杂地引入。如果忽视数据偏差，可能会在训练模型中对某个群体产生不公平的预测，并导致整体准确率下降。能够尽早发现数据中的固有偏差并采取措施解决它们比以往任何时候都更加关键。另一方面，**模型偏差**是指由模型预测引入的偏差，例如分类和错误在优势群体和劣势群体之间的分布。如果模型在特定结果上偏向优势群体，或者不成比例地错误预测劣势群体，导致在现实世界的机器学习应用（如贷款批准预测系统）中产生不良后果，我们作为数据科学家需要采取措施来了解为什么会发生这种情况并缓解这种行为。
- en: Ensuring fairness in ML starts with understanding the data and detecting biases
    within it. Data bias may lead to model bias, as it is well understood that the
    model will learn what is presented in the data, including any bias, and will replicate
    that bias in its inferences. Quantifying biases using metrics that are developed
    and accepted by the ML community is key to detection and choosing mitigation approaches.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 确保机器学习中的公平性始于理解数据并检测其中的偏差。数据偏差可能导致模型偏差，因为众所周知，模型将学习数据中呈现的内容，包括任何偏差，并将其在推理中复制。使用由机器学习社区开发和接受的指标来量化偏差对于检测和选择缓解方法至关重要。
- en: Being able to explain how the model makes a decision is another key factor to
    ensure fairness in ML models. People had long thought that ML is a magical black
    box—it predicts things better than humans can, but nobody knows why or how. But
    ML researchers have developed frameworks to help unbox the black box, the most
    notable one being SHAP. SHAP computes and assigns an importance score for each
    feature for a particular prediction. This importance score is called a **Shapley
    value** and is an implementation of cooperative game theory to allocate credit
    for a model's output among its input features. With the Shapley values for each
    feature for a prediction, we can describe how and why the model makes such a prediction
    and which feature contributes the most to this. Should there be a sensitive feature
    that contributes significantly to model prediction, we need to take action to
    address this effect.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 能够解释模型如何做出决策是确保机器学习模型公平性的另一个关键因素。人们长期以来认为机器学习是一个神秘的黑盒——它预测事物比人类更好，但没有人知道为什么或如何。但是，机器学习研究人员已经开发了框架来帮助打开这个黑盒，其中最著名的一个是SHAP。SHAP计算并为特定预测的每个特征分配一个重要性分数。这个重要性分数被称为**Shapley值**，它是合作博弈论的一种实现，用于在模型的输入特征之间分配模型输出的信用。对于预测中每个特征的Shapley值，我们可以描述模型如何以及为什么做出这样的预测，以及哪个特征对此贡献最大。如果存在对模型预测有显著贡献的敏感特征，我们需要采取措施来解决这个问题的影响。
- en: '**Amazon SageMaker Clarify** helps developers discover underlying bias in the
    training data and model prediction and explain feature importance for an ML model.
    SageMaker Clarify computes various metrics to measure bias in the data so that
    you do not have to be an expert in the science of ML bias. You can use SageMaker
    Clarify with the SageMaker **software development kit** (**SDK**) to analyze data
    and models from a notebook, which we will focus on in this chapter. SageMaker
    Clarify also integrates with Amazon SageMaker Data Wrangler so that you can detect
    bias using a simple graphical interface. SageMaker Clarify further integrates
    with **Amazon SageMaker Experiments** to provide graphical results for each experiment
    and **Amazon SageMaker Model Monitor** so that you can identify bias and feature
    importance in a trained model and in inference data in production.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon SageMaker Clarify** 帮助开发者发现训练数据和模型预测中的潜在偏差，并为机器学习模型解释特征重要性。SageMaker
    Clarify计算各种指标来衡量数据中的偏差，这样你就不必成为机器学习偏差科学的专家。你可以使用SageMaker Clarify与SageMaker **软件开发工具包**
    (**SDK**) 结合，从笔记本中分析数据和模型，这是我们本章将重点关注的。SageMaker Clarify还与Amazon SageMaker Data
    Wrangler集成，这样你可以使用简单的图形界面检测偏差。SageMaker Clarify还进一步与 **Amazon SageMaker Experiments**
    集成，为每个实验提供图形结果，并与 **Amazon SageMaker Model Monitor** 集成，这样你可以在训练模型和在生产中的推理数据中识别偏差和特征重要性。'
- en: Let's get started with an ML example to see how we can detect bias using SageMaker
    Clarify.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从机器学习的一个例子开始，看看我们如何使用SageMaker Clarify来检测偏差。
- en: Detecting bias in ML
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测机器学习中的偏差
- en: For this chapter, I'd like to use an ML adult census income dataset from the
    **University of California Irvine** (**UCI**) ML repository ([https://archive.ics.uci.edu/ml/datasets/adult](https://archive.ics.uci.edu/ml/datasets/adult)).
    This dataset contains demographic information from census data and income level
    as a prediction target. The goal of the dataset is to predict whether a person
    earns over or below **United States dollars** (**USD**) **$50,000** (**$50K**)
    per year based on the census information. This is a great example and is the type
    of ML use case that includes socially sensitive categories such as gender and
    race, and is under the most scrutiny and regulation to ensure fairness when producing
    an ML model.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，我想使用来自 **加州大学欧文分校** （**UCI**） 机器学习存储库的机器学习成人人口普查收入数据集（[https://archive.ics.uci.edu/ml/datasets/adult](https://archive.ics.uci.edu/ml/datasets/adult)）。这个数据集包含来自人口普查数据的人口统计信息以及作为预测目标的收入水平。数据集的目标是根据人口普查信息预测一个人是否每年收入超过或低于
    **美元** （**USD**） **$50,000** （**$50K**）。这是一个很好的例子，并且是包含如性别和种族等社会敏感类别的机器学习用例，在生成机器学习模型时受到最严格的审查和监管，以确保公平性。
- en: In this section, we will analyze the dataset to detect data bias in the training
    data, mitigate if there is any bias, train an ML model, and analyze whether there
    is any model bias against a particular group.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将分析数据集以检测训练数据中的数据偏差，如果存在任何偏差，我们将减轻它，训练一个机器学习模型，并分析是否存在针对特定群体的模型偏差。
- en: Detecting pretraining bias
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测预训练偏差
- en: 'Please open the notebook in `Getting-Started-with-Amazon-SageMaker-Studio``/chapter06/01-ml_fairness_clarify.ipynb`
    and follow the next steps:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 请打开笔记本 `在Amazon SageMaker Studio中入门``/chapter06/01-ml_fairness_clarify.ipynb`
    并按照以下步骤操作：
- en: We will use SageMaker Experiments to organize the analysis and training job.
    Therefore, we install `sagemaker-experiments` in the first cell, and we set up
    the SageMaker session and import the required libraries in the following two cells.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用SageMaker Experiments来组织分析和训练工作。因此，我们在第一个单元中安装 `sagemaker-experiments`，并在接下来的两个单元中设置SageMaker会话并导入所需的库。
- en: 'In the fourth cell, we load the train and test datasets from the UCI ML repository.
    The `orig_columns` values are parsed from [https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names).
    The original dataset has both string representation and ordinal representation
    for education level in the `education` and `education-num` features. Let''s just
    keep the ordinal representation and drop the `education` column. We also move
    the `target` column to the first column because we will use SageMaker''s built-in
    `XGBoost` algorithm to train an ML model to predict the target. The `target` column
    contains the label for income greater than $50K (`>50K`) and less than and equal
    to $50K (`<=50K`). You can see an illustration of this in the following screenshot:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第四个单元格中，我们从UCI ML仓库加载训练和测试数据集。`orig_columns`值是从[https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names)解析出来的。原始数据集在`education`和`education-num`特征中既有字符串表示也有序数表示的教育水平。我们只保留序数表示并删除`education`列。我们还把`target`列移到第一列，因为我们将会使用SageMaker的内置`XGBoost`算法来训练一个机器学习模型以预测目标。`target`列包含收入大于$50K（`>50K`）和小于等于$50K（`<=50K`）的标签。你可以在以下截图看到这个说明：
- en: '![Figure 6.1 – Screenshot of the DataFrame after step 2'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.1 – 第2步后的DataFrame截图'
- en: '](img/B17447_04_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_04_01.jpg)'
- en: Figure 6.1 – Screenshot of the DataFrame after step 2
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 第2步后的DataFrame截图
- en: We encode the categorical features in the train data (`df`) and test data (`df_valtest`)
    with `OrdinalEncoder` from `sklearn` to make the dataset compatible with the XGBoost
    algorithm. After the encoding, the `target` variable of values `>50K` and `<=50K`
    are encoded as `1` and `0`, respectively; there is a potentially sensitive `sex`
    category with `Male` and `Female` values encoded as `1` and `0`, respectively.
    We further take 10% of the test dataset as the validation dataset for model training.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`sklearn`中的`OrdinalEncoder`将训练数据（`df`）和测试数据（`df_valtest`）中的分类特征进行编码，以便使数据集与XGBoost算法兼容。编码后，值大于`50K`和小于等于`50K`的`target`变量分别编码为`1`和`0`；存在一个可能敏感的`sex`类别，其中`Male`和`Female`值分别编码为`1`和`0`。我们进一步将测试数据集的10%作为验证数据集用于模型训练。
- en: 'With this dataset, there are many angles from which we can analyze the data
    for bias and fairness. Intuitively, gender equality in income would be one angle
    we could start with. Let''s make some visualizations to understand it qualitatively,
    as follows:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这个数据集，我们可以从许多角度分析数据以寻找偏差和公平性。直观上，收入中的性别平等可能是一个我们可以从其开始的视角。让我们进行一些可视化来定性理解它，如下所示：
- en: '[PRE0]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the next screenshot, we can observe the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一张截图，我们可以观察到以下内容：
- en: The total number of females is about half that of males.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 女性的总数大约是男性的半数。
- en: There are many more people whose earnings are below $50K.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有更多的人的收入低于$50K。
- en: There are more males than females who earn more than $50K.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在收入超过$50K的人群中，男性比女性多。
- en: 'You can see the output here:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里看到输出：
- en: '![Figure 6.2 – Output of the plotting, showing the distribution of sex and
    income level; an imbalanced distribution in sex and income level can be observed'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.2 – 绘图输出，显示性别和收入水平的分布；在性别和收入水平上可以观察到不平衡的分布'
- en: '](img/B17447_04_02.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_04_02.jpg)'
- en: Figure 6.2 – Output of the plotting, showing the distribution of sex and income
    level; an imbalanced distribution in sex and income level can be observed
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 绘图输出，显示性别和收入水平的分布；在性别和收入水平上可以观察到不平衡的分布
- en: This distribution may be reflective of social inequality, but how do we quantify
    these skewed distributions so that we can be more aware of the bias in the dataset
    automatically and programmatically? This is where SageMaker Clarify comes into
    play.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分布可能反映了社会不平等，但我们如何量化这些偏斜的分布，以便我们可以自动和程序化地更了解数据集中的偏差？这正是SageMaker Clarify发挥作用的地方。
- en: 'SageMaker Clarify from the SageMaker SDK (`sagemaker.clarify`) uses a dedicated
    container and SageMaker Processing to compute ML bias and explain ML predictions.
    We can start by instantiating `sagemaker.clarify.SageMakerClarifyProcessor` with
    the type of compute resource that fits the dataset, as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Clarify来自SageMaker SDK（`sagemaker.clarify`）使用专用容器和SageMaker Processing来计算机器学习偏差和解释机器学习预测。我们可以通过以下方式实例化`sagemaker.clarify.SageMakerClarifyProcessor`，选择适合数据集的计算资源类型：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will use `SageMakerClarifyProcessor.run_pre_training_bias()` specifically
    to compute the data bias prior to training an ML model. The metrics it returns
    allow us to quantify data bias based on the target and facet we choose and allow
    us to take action to mitigate the bias. But first, `run_pre_training_bias()` requires
    two configurations: a `clarify.DataConfig()`, as shown in the following code block:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将专门使用`SageMakerClarifyProcessor.run_pre_training_bias()`来计算在训练ML模型之前的数据偏见。它返回的指标允许我们根据我们选择的目标和方面量化数据偏见，并允许我们采取措施减轻偏见。但是，首先`run_pre_training_bias()`需要两个配置：一个`clarify.DataConfig()`，如下面的代码块所示：
- en: '[PRE2]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Because the training data in `train_s3_uri` does not contain column headers,
    the feature columns are provided in the `headers` argument. In the `label` argument,
    we specify the target variable from the dataset, which has to be one of the column
    names in what's input in the `headers` argument.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因为`train_s3_uri`中的训练数据不包含列标题，所以特征列通过`headers`参数提供。在`label`参数中，我们指定数据集中的目标变量，它必须是`headers`参数中输入的列名之一。
- en: 'In a bias configuration, we specify the facets—that is, the sensitive categories
    that we would like to analyze using `clarify.BiasConfig()`, as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在偏见配置中，我们指定方面——即我们希望使用`clarify.BiasConfig()`分析的敏感类别，如下所示：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We would like to analyze how much gender bias (the `sex` column) there is in
    the dataset and, in particular, how the outcome (the `target` column) is impacted
    by gender. To do so, we specify a positive class (`>50K` or `1`) from the target
    in a list to the `label_values_or_threshold` argument. We specify the facet(s)
    to be `sex` and `race`. Although in this example we are mostly focused on gender
    bias, we are adding a `race` feature to showcase that you can use multiple features
    as facets and that SageMaker Clarify would analyze bias in all the facets at once.
    The last required argument, `facet_values_or_threshold`, is there to specify the
    sensitive category in the facets for SageMaker Clarify to focus on when quantifying
    the bias. `facet_values_or_threshold=[[0], None]` corresponds to `facet_name=['sex',
    'race']`. This means that we are asking Clarify to only calculate the bias metrics
    for class `0` in `sex`, which is female, while not specifying a class (`None`)
    for `race`, which will force Clarify to calculate bias metrics for all classes
    in `race`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望分析数据集中存在多少性别偏见（`sex`列），特别是结果（`target`列）如何受到性别的影响。为此，我们从目标中指定一个正类（`>50K`或`1`）到`label_values_or_threshold`参数的列表中。我们指定要分析的方面为`sex`和`race`。尽管在这个例子中我们主要关注性别偏见，但我们添加了一个`race`特征来展示您可以使用多个特征作为方面，并且SageMaker
    Clarify会同时分析所有方面的偏见。最后一个必需的参数`facet_values_or_threshold`用于指定SageMaker Clarify在量化偏见时关注的敏感类别。`facet_values_or_threshold=[[0],
    None]`对应于`facet_name=['sex', 'race']`。这意味着我们要求Clarify只计算`sex`中类`0`的偏见指标，即女性，而对于`race`没有指定一个类（`None`），这将迫使Clarify计算`race`中所有类的偏见指标。
- en: 'Once the setup is complete, we can run the processing job with the configurations,
    as follows:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦设置完成，我们可以使用配置运行处理作业，如下所示：
- en: '[PRE4]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We ask Clarify to compute all possible pretraining bias with `methods='all'`.
    SageMaker Clarify integrates with SageMaker Experiments, so we also provide an
    experiment and trial configuration for this job. In the notebook, we name the
    experiment `experiment_name = 'adult-income-clarify'`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要求Clarify计算所有可能的预训练偏见，使用`methods='all'`。SageMaker Clarify与SageMaker Experiments集成，因此我们为此作业提供了实验和试验配置。在笔记本中，我们命名实验为`experiment_name
    = 'adult-income-clarify'`。
- en: 'We can visualize the Clarify results in the `adult-income-clarify` entry, and
    right-click the new trial entry whose name is a timestamp to select **Open in
    trial component list**, as shown in the following screenshot:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以在`adult-income-clarify`条目中可视化Clarify结果，并右键单击名为时间戳的新试验条目以选择**在试验组件列表中打开**，如下面的截图所示：
- en: '![Figure 6.3 – Selecting a trial to view the SageMaker Clarify result'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.3 – 选择试验以查看SageMaker Clarify结果'
- en: '](img/B17447_04_03.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片/B17447_04_03.jpg]'
- en: Figure 6.3 – Selecting a trial to view the SageMaker Clarify result
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – 选择试验以查看SageMaker Clarify结果
- en: 'A new page with a **TRIAL COMPONENTS** list will show up in the main working
    area. We can open the **Trial details** page to see the result by right-clicking
    on the entry and selecting **Open in trial details**, as shown in the following
    screenshot:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在主工作区域将显示一个包含**试验组件**列表的新页面。我们可以通过右键单击条目并选择**在试验详情中打开**来打开**试验详情**页面查看结果，如下面的截图所示：
- en: '![Figure 6.4 – Selecting a trial component to view the SageMaker Clarify result'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.4 – 选择试验组件以查看SageMaker Clarify结果'
- en: '](img/B17447_04_04.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17447_04_04.jpg)'
- en: Figure 6.4 – Selecting a trial component to view the SageMaker Clarify result
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 选择试验组件以查看SageMaker Clarify结果
- en: 'On the **Trial** **components** page, move to the **Bias report** tab to find
    the analysis results, as shown in the following screenshot. Here, you can find
    metrics calculated by SageMaker Clarify:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**试验组件**页面，切换到**偏差报告**选项卡以找到分析结果，如下面的截图所示。在这里，您可以找到SageMaker Clarify计算的指标：
- en: '![Figure 6.5 – Reviewing the pretraining bias report on the trial details page
    in SageMaker Studio'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.5 – 在SageMaker Studio的试验详情页上审查预训练偏差报告'
- en: '](img/B17447_04_05.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17447_04_05.jpg)'
- en: Figure 6.5 – Reviewing the pretraining bias report on the trial details page
    in SageMaker Studio
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 在SageMaker Studio的试验详情页上审查预训练偏差报告
- en: With each metric, you can see a description to understand what it means. For
    further information, you can expand a line item to see how the metric is calculated,
    with an example and interpretation. Furthermore, you can find additional papers
    in the details' descriptions to read more about the mathematical definition for
    all metrics.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个指标，您都可以看到一个描述来了解它的含义。如需更多信息，您可以展开一项内容以了解指标是如何计算的，包括示例和解释。此外，您可以在详细描述中找到更多关于所有指标数学定义的论文。
- en: Note
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: 'For convenience, this **Uniform Resource Locator** (**URL**) takes you to the
    technical whitepaper: [https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf).
    This is a good read if you are interested in the math behind the metrics.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，此**统一资源定位符**（**URL**）将带您到技术白皮书：[https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)。如果您对指标背后的数学感兴趣，这是一份很好的阅读材料。
- en: Let's review the bias in the data. Most notably, it is reported that there is
    `sex` feature) as there are 0.34 or 34% fewer females compared to males. `>50K`)
    there is for males compared to females. There are 0.2 or 20% more males who earn
    >50K in the dataset than females. These two metrics alone not only confirm the
    imbalance we saw in the chart we plotted in the notebook but also quantify the
    imbalance.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾数据中的偏差。最值得注意的是，报告指出存在`sex`特征（因为女性比男性少0.34或34%），在`>50K`方面，男性比女性多0.2或20%。在数据集中，收入超过50K的男性比女性多，这两个指标单独不仅证实了我们之前在笔记本中绘制的图表中看到的失衡，而且量化了这种失衡。
- en: Note
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: There is no valid result for `clarify.BiasConfig(group_name=None)`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`clarify.BiasConfig(group_name=None)`没有有效的结果。
- en: You can view the analysis for other facets and categories we have specified
    in `clarify.BiasConfig()`—`race`, for example—by toggling the **Column analyzed
    for bias** and **Column value or threshold analyzed for bias** drop-down lists.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过切换**分析偏差的列**和**分析偏差的列值或阈值**下拉列表来查看`clarify.BiasConfig()`中指定的其他方面和类别（例如，`race`）的分析——通过切换**分析偏差的列**和**分析偏差的列值或阈值**下拉列表。
- en: SageMaker Clarify also saves a copy of the analysis in `pretraining_bias_report_output_path`
    `variable`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Clarify还会在`pretraining_bias_report_output_path`变量中保存分析副本。
- en: This imbalance in the data, if left unmitigated, could very well be ingrained
    into an ML model after training and it could start repeating what it learned from
    the biased data. Let's see how to mitigate it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不缓解这种数据失衡，它很可能在训练后嵌入到ML模型中，并开始重复从偏差数据中学到的内容。让我们看看如何缓解它。
- en: Mitigating bias and training a model
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓解偏差和训练模型
- en: 'There are a couple of data science approaches to mitigate the data imbalance,
    such as matching, oversampling, and undersampling. In this example, let''s try
    a simple matching in terms of gender and target outcome to balance the male and
    female samples and the proportion in a positive outcome (`>50K`). We''ll proceed
    as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种数据科学方法可以缓解数据不平衡，例如匹配、过采样和欠采样。在这个例子中，让我们尝试基于性别和目标结果进行简单的匹配，以平衡男性和女性样本以及正结果（`>50K`）的比例。我们将按以下步骤进行：
- en: 'Coming back to the notebook, we continue to work with the data to address the
    bias, as follows:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回到笔记本，我们继续使用数据来处理偏差，如下所示：
- en: '[PRE5]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This generates a sampled and matched dataset that has an equal amount of both
    genders and an equal proportion in the target outcome.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了一个具有相等性别数量和相等目标结果比例的采样和匹配数据集。
- en: 'We can verify the effectiveness of this approach by plotting the same charts
    and creating another pretraining bias analysis using SageMaker Clarify for this
    sampled and matched dataset with an identical bias configuration. Note that we
    are creating another trial in SageMaker Experiments to track this run and direct
    the output to a different output S3 location. The code is illustrated in the following
    snippet:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过绘制相同的图表并使用 SageMaker Clarify 对此样本和匹配的数据集创建另一个预训练偏差分析来验证这种方法的有效性。请注意，我们正在
    SageMaker Experiments 中创建另一个试验来跟踪此运行并将输出直接发送到不同的输出 S3 位置。以下代码片段展示了这个过程：
- en: '[PRE6]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We then use the same `bias_config` and call the `clarify_processor.run_pre_training_bias()`
    method as we did before to run a pre-training bias analysis job after bias mitigation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用相同的 `bias_config` 并调用之前使用的 `clarify_processor.run_pre_training_bias()`
    方法来在偏差缓解后运行预训练偏差分析作业。
- en: After the SageMaker Clarify job is done, we can open the **Bias report** feature
    on the trial details page for the new pretraining bias analysis job. You can see
    that **Class Imbalance (CI)** and **Difference in Positive Proportions in Labels
    (DPL)** are now both zeros. In fact, there are zeros across all the bias metrics.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SageMaker Clarify 作业完成后，我们可以在新预训练偏差分析作业的试验详情页上打开**偏差报告**功能。您可以看到，**类别不平衡（CI）**和**标签中正例比例差异（DPL）**现在都是零。实际上，所有偏差指标都是零。
- en: 'We have successfully zeroed out the data bias we observed previously. Let''s
    get the model training started with SageMaker''s built-in `XGBoost` algorithm,
    which is a great tool for structured data such as we have. We run this training
    job as a new trial component in the second trial, `exp_trial_2`. For the hyperparameter,
    we choose a `binary:logistic` objective for binary classification, `error` as
    an evaluation metric, and `50` rounds of optimization. The code is illustrated
    in the following snippet:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经成功消除了之前观察到的数据偏差。让我们使用 SageMaker 内置的 `XGBoost` 算法开始模型训练，这是一个非常适合我们这种结构化数据的优秀工具。我们将此训练作业作为第二个试验
    `exp_trial_2` 中的新试验组件运行。对于超参数，我们选择二分类的 `binary:logistic` 目标，`error` 作为评估指标，以及
    `50` 轮优化。以下代码片段展示了这个过程：
- en: '[PRE7]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The training job completes in about 5 minutes, including the infrastructure
    provisioning.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 训练作业包括基础设施配置，大约需要 5 分钟。
- en: 'We create a SageMaker model from the training job so that later, we can use
    it in SageMaker Clarify jobs to analyze model bias. Here''s the code to do this:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从训练作业中创建一个 SageMaker 模型，以便以后可以在 SageMaker Clarify 作业中使用它来分析模型偏差。以下是执行此操作的代码：
- en: '[PRE8]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: After the model is trained, we can use SageMaker Clarify to detect and measure
    biases that occur in the prediction.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，我们可以使用 SageMaker Clarify 来检测和测量预测中出现的偏差。
- en: Detecting post-training bias
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测训练后偏差
- en: 'The following steps analyze biases in prediction and data after the model is
    trained. To run a post-training bias analysis with SageMaker Clarify, we need
    to prepare three configurations: a **data configuration**, a **bias configuration**,
    and a **model configuration**. Proceed as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤分析模型训练后的预测和数据的偏差。要使用 SageMaker Clarify 运行训练后的偏差分析，我们需要准备三个配置：一个**数据配置**、一个**偏差配置**和一个**模型配置**。按照以下步骤进行：
- en: 'Create a new `clarify.DataConfig()` instance to analyze the matched training
    data and direct the output to a different output S3 location, as follows:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的 `clarify.DataConfig()` 实例来分析匹配的训练数据，并将输出直接发送到不同的输出 S3 位置，如下所示：
- en: '[PRE9]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The bias configuration remains the same as what we used in the pretraining bias
    analysis. We continue to analyze how model prediction is impacted by `sex`, `race`,
    and `target` distribution.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 偏差配置与我们在预训练偏差分析中使用的配置相同。我们继续分析模型预测如何受到 `sex`、`race` 和 `target` 分布的影响。
- en: When a post-training analysis job is started, a SageMaker real-time endpoint
    with the ML model is created to make a prediction on the input data for a short
    duration of time to avoid additional traffic to your production endpoint, if any.
    This endpoint is also called a shadow endpoint and will be deprovisioned once
    the analysis job finishes. For the model configuration, we specify a model and
    configure the endpoint. `accept_type` denotes the endpoint response payload format,
    and `content_type` indicates the payload format of the request to the endpoint.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当开始训练后分析作业时，会创建一个 SageMaker 实时端点，带有 ML 模型，用于在短时间内对输入数据进行预测，以避免对生产端点产生额外的流量（如果有的话）。此端点也称为影子端点，一旦分析作业完成，将取消配置。对于模型配置，我们指定一个模型并配置端点。`accept_type`
    表示端点响应的有效负载格式，而 `content_type` 表示对端点的请求的有效负载格式。
- en: 'We also specify a probability threshold of 0.5 to convert the probability output
    from the XGBoost model to binary hard labels, as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还指定了 0.5 的概率阈值，将 XGBoost 模型的概率输出转换为二进制硬标签，如下所示：
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: A prediction above 0.5 is predicted as 1 (`>50K`); otherwise, it is 0 (`<=50K`).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 预测值大于 0.5 的被预测为 1 (`>50K`)；否则，为 0 (`<=50K`)。
- en: 'Finally, we run the job with the configurations. We request to compute all
    valid post-training bias metrics, as follows:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用配置运行作业。我们请求计算所有有效的训练后偏差指标，如下所示：
- en: '[PRE11]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can also review the results on the trial details page of the second trial
    (`exp_trial_2.trial_name`), as shown in the following screenshot. We see a different
    set of metrics are shown compared to a pretraining bias analysis. A post-training
    bias job focuses on analyzing predicted labels or comparing the predictions with
    the observed target values in the data with respect to groups with different attributes:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以在第二个试验的试验详情页上查看结果 (`exp_trial_2.trial_name`)，如下所示截图。与预训练偏差分析相比，我们看到显示的指标集不同。训练后偏差作业专注于分析预测标签或比较预测与数据中具有不同属性组的观察到的目标值：
- en: '![Figure 6.6 – Reviewing the post-training bias report on the trial details
    page in SageMaker Studio'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.6 – 在 SageMaker Studio 的试验详情页上查看训练后偏差报告'
- en: '](img/B17447_04_06.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_04_06.jpg)'
- en: Figure 6.6 – Reviewing the post-training bias report on the trial details page
    in SageMaker Studio
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.6 – 在 SageMaker Studio 的试验详情页上查看训练后偏差报告
- en: 'There is very low bias in most of the measures such as **Accuracy Difference
    (AD)**, meaning that the model is equally accurate in predicting the income level
    for the two sexes. However, there is one metric that has rather high biases: **Treatment
    Equality (TE)**. This measures whether a *Type 1* error (false positive) and a
    *Type 2* error (false negative) are affecting the two genders in the same way.
    This is the difference in the ratio of false negatives to false positives between
    the male and female groups. A positive value translates to females having a lower
    ratio of false negatives to false positives. That means that the model is more
    often incorrectly predicting a female to be a high-income earner when in fact
    they are not; rather, it is the other way around. Having a higher false-positive
    rate for females compared with males is somewhat concerning and could lead to
    unfair consequences with such models.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数指标，如 **准确度差异 (AD)**，偏差非常低，这意味着模型在预测男女收入水平时具有相同的准确性。然而，有一个指标具有相当高的偏差：**处理平等
    (TE)**。这衡量的是 *Type 1* 错误（假阳性）和 *Type 2* 错误（假阴性）是否以相同的方式影响两个性别。这是男性和女性组中假阴性与假阳性的比率差异。正值表示女性具有更低的假阴性与假阳性比率。这意味着模型更频繁地错误地将女性预测为高收入者，而实际上她们并不是；相反，情况正好相反。与男性相比，女性的假阳性率更高，这可能会引起一些担忧，并可能导致模型产生不公平的后果。
- en: Note
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The technical whitepaper I shared in the *Detecting pretraining bias* section
    also has many more details on the post-training metrics. You can find the paper
    here: [https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *检测预训练偏差* 部分中分享的技术白皮书也包含了许多关于训练后指标的更多细节。您可以在以下链接找到该论文：[https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)。
- en: After understanding how to measure the bias, both pretraining and post-training,
    we should also explore how the ML model makes decisions in the way it does with
    SageMaker Clarify.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解了如何测量偏差，包括预训练和训练后，我们还应该探索 ML 模型是如何像使用 SageMaker Clarify 那样做出决策的。
- en: Explaining ML models using SHAP values
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SHAP 值解释 ML 模型
- en: SageMaker Clarify also computes model-agnostic feature attribution based on
    the concept of Shapley values. Shapley values can be used to determine the contribution
    each feature makes to model predictions. Feature attribution helps explain how
    a model makes decisions. Having a quantifiable approach to describe how a model
    makes decisions enables us to have trust in an ML model that meets regulatory
    requirements and supports the human decision-making process.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Clarify 还根据 Shapley 值的概念计算模型无关的特征归因。Shapley 值可以用来确定每个特征对模型预测的贡献。特征归因有助于解释模型是如何做出决策的。拥有一种可量化的方法来描述模型是如何做出决策的，使我们能够信任满足监管要求并支持人类决策过程的
    ML 模型。
- en: 'Similar to setting up configurations to run bias analysis jobs using SageMaker
    Clarify, it takes three configurations to set up a model explainability job: a
    **data configuration**, a **model configuration**, and an **explainability configuration**.
    Let''s follow the next steps from the same notebook:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 与使用 SageMaker Clarify 设置运行偏差分析作业的配置类似，设置模型可解释性作业需要三个配置：一个**数据配置**、一个**模型配置**和一个**可解释性配置**。让我们按照以下步骤从同一个笔记本开始：
- en: 'Create a data configuration with the training dataset (matched). This is similar
    to the data configurations we created before. The code is illustrated in the following
    snippet:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练数据集（匹配）创建一个数据配置。这与我们之前创建的数据配置类似。以下代码片段展示了代码：
- en: '[PRE12]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Create or reuse the `model_config` argument that was created before for the
    post-training bias analysis job.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建或重用之前为训练后偏差分析作业创建的 `model_config` 参数。
- en: 'Create a `clarify.SHAPConfig()` instance with a baseline. A baseline is an
    instance of a data point that would be used to compute the Shapley values with
    the input data. For the same model, you can expect to get different explanations
    with respect to different baselines, so the choice of a baseline is crucial. It
    is desirable to select a general baseline with very low information content, such
    as an average or median feature vector. In this case, in our example, we would
    interpret the model attribution as to why a particular person is predicted as
    a high-income earner compared to an average person. Alternatively, you can choose
    to explain the model with respect to a particular type of data. For example, we
    can choose a baseline from a similar demographic that represents the people in
    the inference. The code is illustrated in the following snippet:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个带有基线的 `clarify.SHAPConfig()` 实例。基线是一个数据点的实例，将用于与输入数据一起计算 Shapley 值。对于相同的模型，你可以预期根据不同的基线得到不同的解释，因此基线的选择至关重要。选择一个具有非常低信息含量的通用基线是可取的，例如平均值或中值特征向量。在这种情况下，在我们的示例中，我们将解释模型归因为什么预测某个人为高收入者，而不是一个普通人。或者，你也可以选择根据特定类型的数据来解释模型。例如，我们可以从代表推理中人群的类似人口中选择基线。以下代码片段展示了代码：
- en: '[PRE13]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In our example, let's simulate an "average" high-income (`>50K`) person from
    the training data using `mode` for the baseline. The `num_samples` argument is
    used to determine the size of the generated synthetic dataset to compute the SHAP
    values. You can also leave it empty to make Clarify choose a number automatically.
    `agg_method='mean_abs'` denotes how to aggregate for global SHAP values.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，让我们使用 `mode` 为基线模拟训练数据中的一个“平均”高收入（`>50K`）的人。`num_samples` 参数用于确定生成合成数据集的大小以计算
    SHAP 值。你也可以留空，让 Clarify 自动选择一个数字。`agg_method='mean_abs'` 表示如何聚合全局 SHAP 值。
- en: 'Afterward, we start the analysis job with the configurations, as follows:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们使用配置开始分析作业，如下所示：
- en: '[PRE14]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once the processing job completes, we can view the results on the trial details
    page in SageMaker Experiments under the `education-num` feature, which represents
    the highest education level, contributes the most to predicting the income level
    (`>50K` or `<=50K`):'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦处理作业完成，我们可以在 SageMaker Experiments 下的 `education-num` 特征的试验详情页上查看结果，该特征代表最高的教育水平，对预测收入水平（`>50K`
    或 `<=50K`）的贡献最大：
- en: '![Figure 6.7 – Reviewing the model explainability results in SHAP values in
    SageMaker Studio'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.7 – 在 SageMaker Studio 中查看模型可解释性结果 SHAP 值]'
- en: '](img/B17447_04_07.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_04_07.jpg]'
- en: Figure 6.7 – Reviewing the model explainability results in SHAP values in SageMaker
    Studio
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 – 在SageMaker Studio中查看模型可解释性结果（SHAP值）
- en: 'Besides global SHAP values, we can also review local SHAP explanations for
    any given data point to explain how a model makes predictions on this particular
    data point. SageMaker Clarify computes and saves local explanations for the entire
    dataset that is provided in `clarify.DataConfig()` in a `explainability_output_path`.
    We can plot the local SHAP values for each feature for a particular data point
    (the 500th row) with the following code:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了全局SHAP值之外，我们还可以审查任何给定数据点的局部SHAP解释，以解释模型是如何针对这个特定数据点进行预测的。SageMaker Clarify计算并保存整个数据集的局部解释，该数据集在`clarify.DataConfig()`中提供，并在`explainability_output_path`中保存。我们可以使用以下代码绘制特定数据点（第500行）的每个特征的局部SHAP值：
- en: '[PRE15]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As shown in *Figure 6.8*, we can see how the XGBoost model predicts this data
    point as <=50K. The `marital-status`, `education-num`, and `capital-gain` factors
    are the top three factors that the model thinks of this person as a low-income
    earner. Thanks to SHAP values computed by SageMaker Clarify, we can understand
    and explain how the model makes the prediction on an individual basis too.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图6.8*所示，我们可以看到XGBoost模型如何预测这个数据点为<=50K。`marital-status`、`education-num`和`capital-gain`因素是模型认为这个人是低收入者的前三个因素。多亏了SageMaker
    Clarify计算出的SHAP值，我们还可以理解和解释模型是如何针对个体进行预测的。
- en: '![Figure 6.8 – Explaining individual prediction'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.8 – 解释单个预测'
- en: '](img/B17447_06_008.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17447_06_008.jpg)'
- en: Figure 6.8 – Explaining individual prediction
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 – 解释单个预测
- en: Let's summarize the chapter after you've completed the example
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在您完成示例之后，让我们总结本章内容
- en: Summary
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored biases in ML and ML explainability with an adult
    income example. We learned that the data could contain unfair biases against a
    certain group or category in the dataset, which could translate into an ML model
    making unfair predictions. We worked through an adult income-level prediction
    example in SageMaker Studio to analyze and compute any bias prior to model training
    using **SageMaker Clarify**. Clarify produces metrics to quantify imbalance in
    the dataset that could potentially lead to unfair biases. We mitigated the imbalances
    using sampling and matching techniques and proceeded to train an ML model. We
    further analyzed the resulting ML model for potential bias in predictions using
    SageMaker Clarify. Finally, we reviewed how the ML model makes decisions using
    SageMaker Clarify and SHAP values.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过成人收入示例探讨了机器学习中的偏差和机器学习可解释性。我们了解到数据可能包含对数据集中某个特定群体或类别的不公平偏差，这可能导致机器学习模型做出不公平的预测。我们在SageMaker
    Studio中通过一个成人收入水平预测示例进行分析和计算，在模型训练之前使用**SageMaker Clarify**来识别任何偏差。Clarify生成指标来量化数据集中的不平衡，这可能导致不公平的偏差。我们通过采样和匹配技术来减轻不平衡，然后继续训练机器学习模型。我们进一步使用SageMaker
    Clarify分析了结果机器学习模型在预测中的潜在偏差。最后，我们回顾了如何使用SageMaker Clarify和SHAP值来了解机器学习模型是如何做出决策的。
- en: In the next chapter, we will learn where to go after training an ML model in
    SageMaker. Hosting an ML model in the cloud is critical for most ML use cases,
    and being able to use the right tool for model hosting from SageMaker is key to
    successful ML adoption for your organization. We will learn about various options
    for hosting an ML model and how to optimize compute resources and cost using SageMaker's
    hosting features.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习在SageMaker中训练机器学习模型之后的下一步。在云中托管机器学习模型对于大多数机器学习用例至关重要，能够从SageMaker中选择合适的工具进行模型托管对于您组织成功采用机器学习至关重要。我们将了解托管机器学习模型的多种选项以及如何使用SageMaker的托管功能来优化计算资源和成本。
