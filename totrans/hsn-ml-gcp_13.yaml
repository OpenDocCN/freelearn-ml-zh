- en: Beyond Feedforward Networks – CNN and RNN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Artificial Neural Networks** (**ANNs**) are now extremely widespread tools
    in various technologies. In the simplest application, ANNs provide a feedforward
    architecture for connections between neurons. The feedforward neural network is
    the first and simplest type of ANN devised. In the presence of basic hypotheses
    that interact with some problems, the intrinsic unidirectional structure of feedforward
    networks is strongly limiting. However, it is possible to start from it and create
    networks in which the results of computing one unit affect the computational process
    of another. It is evident that algorithms that manage the dynamics of these networks
    must meet new convergence criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll go over the main ANN architectures, such as convolutional
    NNs, recurrent NNs, and **long short-term memory** (**LSTM**). We'll explain the
    concepts behind each type of NN and tell you which problem they should be applied
    to. Each type of NN is implemented with TensorFlow on a realistic dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics covered are:'
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional networks and their applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recurrent networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LSTM architectures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of the chapter, we will understand training, testing, and evaluating
    a **convolutional neural network** (**CNN**). We will learn how to train and test
    the CNN model in Google Cloud Platform. We will cover the concepts as CNN and
    RNN architecture. We will also be able to train an LSTM model. The reader will
    learn which type of neural network to apply to different problems and how to define
    and implement them on Google Cloud Platform.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ANN is a family of models inspired from biological neural networks (the human
    brain) that, starting from the mechanisms regulating natural neural networks,
    plan to simulate human thinking. They are used to estimate or approximate functions
    that may depend on a large number of inputs, many of which are often unknown.
    ANNs are generally presented as interconnected neuron systems among which an exchange
    of messages takes place. Each connection has a related weight; the value of the
    weight is adjustable based on experience, and this makes neural networks an instrument
    adaptable to the various types of input and having the ability to learn.
  prefs: []
  type: TYPE_NORMAL
- en: 'ANNs define the neuron as a central processing unit, which performs a mathematical
    operation to generate one output from a set of inputs. The output of a neuron
    is a function of the weighted sum of the inputs plus the bias. Each neuron performs
    a very simple operation that involves activation if the total amount of signal
    received exceeds an activation threshold. In the following figure, a simple ANN
    architecture is shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c87c20a5-de1e-4326-a726-6876f608cc91.png)'
  prefs: []
  type: TYPE_IMG
- en: Essentially, CNN are ANNs. In fact, just like the latter, CNNs are made up of
    neurons connected to one another by weighted branches (weight); the training parameters
    of the nets are once again the weight and the bias.
  prefs: []
  type: TYPE_NORMAL
- en: In CNN, the connection pattern between neurons is inspired by the structure
    of the visual cortex in the animal world. The individual neurons present in this
    part of the brain (visual cortex) respond to certain stimuli in a narrow region
    of the observation, called the **receptive field**. The receptive fields of different
    neurons are partially overlapped in order to cover the entire field of vision.
    The response of a single neuron to stimuli taking place in its receptive field
    can be mathematically approximated by a convolution operation.
  prefs: []
  type: TYPE_NORMAL
- en: Everything related to the training of a neural network, that is, forward/backward
    propagation and updating of the weight, also applies in this context; moreover,
    a whole CNN always uses a single function of differentiable cost. However, CNNs
    make a specific assumption that their input has a precise data structure, such
    as an image, and this allows them to take specific properties in their architectureto
    better process such data.
  prefs: []
  type: TYPE_NORMAL
- en: The normal neural networks stratified with an FC architecture—where every neuron
    of each layer is connected to all the neurons of the previous layer (excluding
    bias neurons)—in general do not scale well with an increase in the size of input
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a practical example: suppose we want to analyze an image to detect
    objects. To start, let''s see how the image is processed. As we know, in the coding
    of an image, it is divided into a grid of small squares, each of which represents
    a pixel. At this point, to encode the color images, it will be enough to identify
    for each square a certain number of shades and different color gradations. And
    then we code each one by means of an appropriate sequence of bits. Here is a simple
    image encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3d7e6060-4f75-44d2-b22a-3cb150720eeb.png)'
  prefs: []
  type: TYPE_IMG
- en: The number of squares in the grid defines the resolution of the image. For example,
    an image that is 1,600 pixels wide and 800 pixels high (1,600 x 800) contains
    (multiplied) 1,280,000 pixels, or 1.2 megapixels. To this, we must multiply the
    three color channels, finally obtaining 1,600 x 800 x 3 = 3,840,000\. So, each
    neuron completely connected in the first hidden layer would have 3,840,000 weights.
    This is only for a single neuron; considering the whole network, the thing would
    certainly become unmanageable!
  prefs: []
  type: TYPE_NORMAL
- en: CNNs are designed to recognize visual patterns directly in images represented
    by pixels and require zero or very limited preprocessing. They are able to recognize
    extremely variable patterns, such as freehand writing and images representing
    the real world.
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, a CNN consists of several alternate convolution and subsampling
    levels (pooling) followed by one or more FC final levels in the case of classification.
    The following figure shows a classic image-processing pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cfbfe186-3a40-4f4a-a38c-fdecbf683450.png)'
  prefs: []
  type: TYPE_IMG
- en: To solve problems in the real world, these steps can be combined and stacked
    as often as necessary. For example, you can have two, three, or even more layers
    of **Convolution**. You can enter all the **Pooling** you want to reduce the size
    of the data.
  prefs: []
  type: TYPE_NORMAL
- en: As already mentioned, different types of levels are typically used in a CNN.
    In the following sections, the main ones will be covered.
  prefs: []
  type: TYPE_NORMAL
- en: Convolution layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the main type of layer; the use of one or more of these layers in a
    CNN is essential. The parameters of a convolutional layer, in practice, relate
    to a set of workable filters. Each filter is spatially small, along the width
    and height dimensions, but it extends over the entire depth of the input volume
    to which it is applied.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike normal neural networks, convolutional layers have neurons organized
    in three dimensions: **width**, **height**, and **depth**. They are shown in the
    following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98a4cb93-dbff-4d8e-867d-ba939b15ed8e.png)'
  prefs: []
  type: TYPE_IMG
- en: During forward propagation, each filter is translated—or more precisely, convolved—along
    the width and height of the input volume, producing a two-dimensional activation
    map (or feature map) for that filter. As the filter is moved along the input area,
    a scalar product operation is performed between the values ​​of the filter and
    those of the input portion to which it is applied.
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, the network will have as its objective the learning of filters
    that are activated in the presence of some specific type of feature in a given
    spatial region of the input. The queuing of all these feature maps (for all filters)
    along the depth dimension forms the output volume of a convolutional layer. Each
    element of this volume can be interpreted as the output of a neuron that observes
    only a small region of the input and which shares its parameters with the other
    neurons in the same feature map. This is because these values ​​all come from
    the application of the same filter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In summary, let''s focus our attention on the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Local receptive field**: Each neuron of a layer is (completely) connected
    to a small region of the input (called a **local receptive field**); each connection
    learns a weight.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shared weights**: Since the interesting features (edge, blob, and so on)
    can be found anywhere in the image, the neurons of the same layer share the weights.
    This means that all the neurons of the same layer will recognize the same feature,
    placed at different points of the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Convolution**: The same weight map is applied to different positions. The
    convolution output is called a **feature map**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each filter captures a feature present in the previous layer. So to extract
    different features, we need to train multiple convolutional filters. Each filter
    returns a feature map that highlights different characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Rectified Linear Units
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Rectified Linear Units** (**ReLU**) play the role of neuronal activation
    function in neural networks. A ReLU level is composed of neurons that apply the
    function f*(x) = max (0, x)*. These levels increase the non-linearity of the network
    and at the same time do not modify the receiving fields of convolution levels.
    The function of the ReLUs is preferred over others, such as the hyperbolic tangent
    or the sigmoid, since, in comparison to these, it leads to a much faster training
    process without significantly affecting the generalization accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: Pooling layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These layers are periodically inserted into a network to reduce the spatial
    size (width and height) of current representations, as well as volumes in a specific
    network stage; this serves to reduce the number of parameters and the computational
    time of the network. It also monitors overfitting. A pooling layer operates on
    each depth slice of the input volume independently to resize it spatially.
  prefs: []
  type: TYPE_NORMAL
- en: For example, this technique partitions an input image into a set of squares,
    and for each of the resulting regions, it returns the maximum value as output.
  prefs: []
  type: TYPE_NORMAL
- en: 'CNNs also use pooling layers located immediately after the convolutional layers.
    A pooling layer divides input into regions and selects a single representative
    value (max-pooling and average pooling). Using a pooling layer:'
  prefs: []
  type: TYPE_NORMAL
- en: Reduces the calculations of subsequent layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increases the robustness of the features with respect to spatial position
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is based on the concept that, once a certain feature has been identified,
    its precise position in the input is not as important as its approximate position
    in relation to the other features. In the typical CNN architecture, convolution
    levels and pooling levels are repeatedly alternated.
  prefs: []
  type: TYPE_NORMAL
- en: Fully connected layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This type of layer is exactly the same as any of the layers of a classical ANN
    with **fully connected** (**FC**) architecture. Simply in an FC layer, each neuron
    is connected to all the neurons of the previous layer, specifically to their activations.
  prefs: []
  type: TYPE_NORMAL
- en: 'This type of layer, unlike what has been seen so far in CNNs, does not use
    the property of local connectivity. An FC layer is connected to the entire input
    volume, and, therefore, as you can imagine, there will be many connections. The
    only settable parameter of this type of layer is the number of K neurons that
    make it up. What basically defines an FC layer is as follows: connecting its K
    neurons with all the input volume and calculating the activation of each of its
    K neurons.'
  prefs: []
  type: TYPE_NORMAL
- en: In fact, its output will be a single 1 x 1 x K vector, containing the calculated
    activations. The fact that after using a single FC layer you switch from an input
    volume (organized in three dimensions) to a single output vector (in a single
    dimension) suggests that after applying an FC layer, no more convoluted layers
    can be used. The main function of FC layers in the context of CNNs is to carry
    out a sort of grouping of the information obtained up to that moment, expressing
    it with a single number (the activation of one of its neurons), which will be
    used in subsequent calculations for the final classification.
  prefs: []
  type: TYPE_NORMAL
- en: Structure of a CNN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After analyzing every component of a CNN in detail, it is time to see the general
    structure of a CNN as a whole. For example, starting from the images as input
    layers, there will be a certain series of convolutional layers interspersed with
    a ReLU layer and, when necessary, the standardization and pooling layers. Finally,
    there will be a series of FC layers before the output layer. Here is an example
    of a CNN architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4fd6b63-f3f3-4956-8b4b-1b5dbc86088d.png)'
  prefs: []
  type: TYPE_IMG
- en: The basic idea is to start with a large image and continuously reduce the data
    step by step until you get a single result. The more the convolution passages
    you have, the more the neural network will be able to understand and process complex
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is an open source numerical computing library provided by Google
    for machine intelligence. It hides all of the programming required to build deep
    learning models and gives developers a black box interface to program.
  prefs: []
  type: TYPE_NORMAL
- en: In TensorFlow, nodes in the graph represent mathematical operations, while the
    graph edges represent the multidimensional data arrays (tensors) communicated
    between them. TensorFlow was originally developed by the Google brain team within
    Google's machine intelligence research for machine learning and deep neural networks
    research, but it is now available in the public domain. TensorFlow exploits GPU
    processing when configured appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: 'The generic use cases for TensorFlow are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Image recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computer vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voice/sound recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text-based processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handwriting Recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many others
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To use TensorFlow, we must first install Python. If you don't have a Python
    installation on your machine, it's time to get it. Python is a dynamic **object-oriented
    programming** (**OOP**) language that can be used for many types of software development.
    It offers strong support for integration with other languages and programs, is
    provided with a large standard library, and can be learned within a few days.
    Many Python programmers can confirm a substantial increase in productivity and
    feel that it encourages the development of higher quality code and maintainability.
  prefs: []
  type: TYPE_NORMAL
- en: Python runs on Windows, Linux/Unix, macOS X, OS/2, Amiga, Palm handhelds, and
    Nokia phones. It also works on Java and .NET virtual machines. Python is licensed
    under the OSI-approved open source license; its use is free, including for commercial
    products.
  prefs: []
  type: TYPE_NORMAL
- en: Python was created in the early 1990s by Guido van Rossum at Stichting Mathematisch
    Centrum in the Netherlands as a successor of a language called **ABC**. Guido
    remains Python's principal author, although it includes many contributions from
    others.
  prefs: []
  type: TYPE_NORMAL
- en: If you do not know which version to use, there is an English document that can
    help you choose. In principle, if you have to start from scratch, we recommend
    choosing Python 3.6\. All information about the available versions and how to
    install Python is given at [https://www.python.org/](https://www.python.org/).
  prefs: []
  type: TYPE_NORMAL
- en: 'After properly installing the Python version of our machine, we have to worry
    about installing TensorFlow. We can retrieve all library information and available
    versions of the operating system from the following link: [https://www.tensorflow.org/](https://www.tensorflow.org/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, in the install section, we can find a series of guides that explain how
    to install a version of TensorFlow that allows us to write applications in Python.
    Guides are available for the following operating systems:'
  prefs: []
  type: TYPE_NORMAL
- en: Ubuntu
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: macOS X
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, to install TensorFlow on Windows, we must choose one of the following
    types:'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow with CPU support only
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow with GPU support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To install TensorFlow, start a terminal with privileges as administrator. Then
    issue the appropriate `pip3 install` command in that terminal. To install the
    CPU-only version, enter the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'A series of code lines will be displayed on the video to keep us informed of
    the execution of the installation procedure, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0bfbadcf-f411-4353-a285-bb857b7d5c74.png)'
  prefs: []
  type: TYPE_IMG
- en: 'At the end of the process, the following code is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To validate the installation, invoke `python` from a shell as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter the following short program inside the Python interactive shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If the system outputs the following, then you are ready to begin writing TensorFlow
    programs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In this case, you will have a confirmation of correct installation of the library
    on your computer. Now you just need to use it.
  prefs: []
  type: TYPE_NORMAL
- en: Handwriting Recognition using CNN and TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Handwriting Recognition** (**HWR**) is a very commonly used procedure in
    modern technology. An image of written text can be detected offline from a piece
    of paper by optical scanning (**optical character recognition** or **OCR**) or
    intelligent word recognition. Alternatively, pen tip movements can be detected
    online (for example, from a pen computer surface, a task that is generally easier
    since there are more clues available).'
  prefs: []
  type: TYPE_NORMAL
- en: Technically, recognition of handwriting is the ability of a computer to receive
    and interpret a handwritten intelligible input from sources such as paper documents,
    photos, touchscreens, and other devices. HWR is performed through various techniques
    that generally require OCR. However, a complete script recognition system also
    manages formatting, carries out correct character segmentation, and finds the
    most plausible words.
  prefs: []
  type: TYPE_NORMAL
- en: '**Modified National Institute of Standards and Technology** (**MNIST**) is
    a large database of handwritten digits. It has a set of 70,000 examples of data.
    It is a subset of NIST''s larger dataset. The digits are of 28 x 28 pixel resolution
    and are stored in a matrix of 70,000 rows and 785 columns; 784 columns form each
    pixel value from the 28 x 28 matrix and one value is the actual digit. The digits
    have been size-normalized and centered in a fixed-size image.'
  prefs: []
  type: TYPE_NORMAL
- en: The digit images in the MNIST set were originally selected and experimented
    with by Chris Burges and Corinna Cortes using bounding box normalization and centering.
    Yann LeCun's version uses centering by center of mass within in a larger window.
    The data is available on Yann LeCun's website at
  prefs: []
  type: TYPE_NORMAL
- en: '[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each image is created as 28 x 28\. The following figure shows a sample of images
    of 0-8 from the MNIST dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4c607089-743f-4f34-930b-5d205e1a866d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'MNIST has a sample of several handwritten digits. This dataset can be fed for
    our training to an Python program and our code can recognize any new handwritten
    digit that is presented as data for prediction. This is a case where the neural
    network architecture functions as a computer vision system for an AI application.
    The following table shows the distribution of the MNIST dataset available on LeCun''s
    website:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Digit** | **Count** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 5923 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 6742 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 5958 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 6131 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 5842 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 5421 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 5918 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 6265 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 5851 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 5949 |'
  prefs: []
  type: TYPE_TB
- en: We will use the TensorFlow library to train and test the MNIST dataset. We will
    split the dataset of 70,000 rows into 60,000 training rows and 10,000 test rows.
    Next, we'll find the accuracy of the model. The model can then be used to predict
    any incoming dataset of 28 x 28 pixel handwritten digits containing numbers between
    zero and nine. For our sample Python code, we use a 100-row training dataset and
    a 10-row test dataset. In this example, we will learn to use the TensorFlow layers
    module that provides a high-level API that makes it easy to construct a neural
    network. It provides methods that facilitate creating dense (FC) layers and convolutional
    layers, adding activation functions, and applying dropout regularization.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start we will analyze the code line by line, then we will see how to process
    it with the tools made available by Google Cloud Platform. Now, let''s go through
    the code to learn how to apply a CNN to solve a HWR problem. Let''s start from
    the beginning of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'These three lines are added to write a Python 2/3 compatible code base. So
    let''s move on to importing modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In this way, we have imported the `numpy` and `tensorflow` module. Let''s analyze
    the next line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This code sets the threshold for what messages will be logged. After an initial
    phase, we pass to define the function that will allow us to build a CNN model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We have thus defined the function. Now let''s move on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code line, we have passed the input tensors in the form (`batch_size`,
    `image_width`, `image_height`, `channels`) as expected from the methods in the
    layers module, for creating convolutional and pooling layers for two-dimensional
    image data. Let''s move on to the first convolutional layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This layer creates a convolution kernel that is convolved with the layer input
    to produce a tensor of outputs. The number of filters in the convolution is 32,
    the height and width of the 2D convolution window are `[5,5]`, and the activation
    function is a ReLU function. To do this, we used the `conv2d()` method in the
    layers module. Next, we connect our first pooling layer to the convolutional layer
    we just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We used the `max_pooling2d()` method in layers to construct a layer that performs
    max pooling with a 2 x 2 filter and stride of `2`. Now we will connect a second
    convolutional layer to our CNN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will connect a second pooling layer to our CNN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will add a dense layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: With this code, we added a dense layer with 1,024 neurons and ReLU activation
    to our CNN to perform classification on the features extracted by the convolution/pooling
    layers.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, a ReLU level is composed of neurons that apply the function *f(x)
    = max (0, x)*. These levels increase the non-linearity of the network, and at
    the same time, they do not modify the receiving fields of convolution levels.
  prefs: []
  type: TYPE_NORMAL
- en: 'To improve the results, we will apply dropout regularization to our dense layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'To do this we used the dropout method in layers. Next, we will add the final
    layer to our neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the `logits` layer, which will return the raw values for our predictions.
    With the previous code, we created a dense layer with `10` neurons (one for each
    target class 0–9), with linear activation. We just have to generate the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We converted the raw values generated from our predictions into two different
    formats that our model function can return: a digit from 0–9 and the probability
    that the example is a zero, is a one, is a two, and so on. We compile our predictions
    in a dict and return an `EstimatorSpec` object. Now, we will pass to define a
    `loss` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'A `loss` function measures how closely the model''s predictions match the target
    classes. This function is used for both training and evaluation. We will configure
    our model to optimize this loss value during training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We used a learning rate of `0.001` and stochastic gradient descent as the optimization
    algorithm. Now, we will add an accuracy metric in our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To do this, we defined the `eval_metric_ops` dict in the `EVAL` mode. We have
    thus defined the architecture of our network; now it is necessary to define the
    code to train and test our network. To do this, we will add a `main()` function
    to our Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we will load training and eval data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In this piece of code, we stored the training feature data and training labels
    as `numpy` arrays in `train_data` and `train_labels`, respectively. Similarly,
    we stored the evaluation feature data and evaluation labels in `eval_data` and
    `eval_labels`, respectively. Next, we will create an `Estimator` for our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'An `Estimator` is a TensorFlow class for performing high-level model training,
    evaluation, and inference. The following code sets up logging for predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we''re ready to train our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: To do this, we have created `train_input_fn` and called `train()`on `mnist_classifier`.
    In the previous code, we fixed `steps=15000`, which means the model will train
    for 15,000 steps in all.
  prefs: []
  type: TYPE_NORMAL
- en: The time required to perform this training varies depending on the processor
    installed on our machine, but in any case, it will probably be more than 1 hour.
    To perform such training in less time, you can reduce the number of steps passed
    to the `train()` function; it is clear that this change will have a negative effect
    on the accuracy of the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will evaluate the model and print the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We called the `evaluate` method, which evaluates the metrics we specified in
    the `eval_metriced_ops` argument in the `model_fn`. Our Python code ends with
    the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: These lines are just a very quick wrapper that handles flag parsing and then
    dispatches to your own main function. At this point, we just have to copy the
    entire code into a file with a `.py` extension and run it on a machine where Python
    and TensorFlow are installed.
  prefs: []
  type: TYPE_NORMAL
- en: Run Python code on Google Cloud Shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google Cloud Shell provides command-line access to cloud resources directly
    from your browser. You can easily manage projects and resources without having
    to install the Google Cloud SDK or other tools in your system. With Cloud Shell,
    the `gcloud` command-line tool from Cloud SDK and other necessary utilities are
    always available, updated and fully authenticated when you need them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the features of the Google Cloud Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: It's a shell environment for managing resources hosted on Google Cloud Platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can manage our GCP resources with the flexibility of a Linux shell. Cloud
    Shell provides command-line access to an instance of the virtual machine in a
    terminal window that opens in the web console.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It offers integrated authorization for access to projects and resources hosted
    on Google Cloud Platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many of your favorite command-line tools, from bash and sh to emacs and vim,
    are already preinstalled and updated. Administration tools such as the MySQL client,
    Kubernetes, and Docker are configured and ready. You no longer need to worry about
    installing the latest version and all of its dependencies. Simply connect to Cloud
    Shell.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developers will have access to all favorite preconfigured development tools.
    You will find development and implementation tools for Java, Go, Python, Node.js,
    PHP, and Ruby. Run your web applications within the Cloud Shell instance and preview
    them in the browser. Then commit to the repository again with the preconfigured
    Git and Mercurial clients.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Shell provisions 5 GB of permanent disk storage space, mounted as the
    `$ HOME` directory on the Cloud Shell instance. All files stored in the `$ HOME`
    directory, including user configuration scripts and files such as `bashrc` and
    `vimrc`, persist from one session to another.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start Cloud Shell, just click on the Activate Google Cloud Shell button
    at the top of the console window, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff23e585-6877-4cbd-9c15-825aa579545f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A Cloud Shell session opens inside a new frame at the bottom of the console
    and displays a command-line prompt. It can take a few seconds for the shell session
    to be initialized. Now, our Cloud Shell session is ready to use, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e3fc2475-c7d1-4feb-bc98-9e05eade34ad.png)'
  prefs: []
  type: TYPE_IMG
- en: At this point, we need to transfer the `cnn_hwr.py` file containing the Python
    code in the Google Cloud Platform. We have seen that to do so, we can use the
    resources made available by Google Cloud Storage. Then we open the Google Cloud
    Storage browser and create a new bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that buckets are the basic containers that hold your data. Everything
    you store in Cloud Storage must be contained in a bucket. You can use buckets
    to organize your data and control access to your data, but unlike directories
    and folders, you cannot nest buckets.
  prefs: []
  type: TYPE_NORMAL
- en: 'To transfer the `cnn_hwr.py` file to Google Storage, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Just click on the CREATE BUCKET icon
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Type the name of the new bucket (`cnn-hwr`) in the create a bucket window
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After this, a new bucket is available in the buckets list
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the `cnn-hwr` bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on uploads files icon in the window opened
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the file in the dialog window opened
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click Open
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At this point, our file will be available in the new bucket, as shown in the
    following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e2410819-05e9-449f-b5f4-236d1b4d423b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we can access the file from Cloud Shell. To do this, we create a new folder
    in the shell. Type the following command in the shell prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to copy the file from the Google Storage bucket to the `CNN-HWR` folder,
    simply type this command in the shell prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s move into the folder and verify the presence of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We just have to run the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'A series of preliminary instructions is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'They indicate that the data download was successful, as was the invocation
    of the TensorFlow library. From this point on, the training of the network begins,
    which, as we have anticipated, may be quite long. At the end of the algorithm
    execution, the following information will be returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we've achieved an accuracy of `97.2` percent on our test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedforward neural networks are based on input data that is powered to the network
    and converted into output. If it is a supervised learning algorithm, the output
    is a label that can recognize the input. Basically, these algorithms connect raw
    data to specific categories by recognizing patterns. Recurrent networks, on the
    other hand, take as input not only the current input data that is powered to the
    network, but also what they have experienced over time.
  prefs: []
  type: TYPE_NORMAL
- en: An **recurrent neural network** (**RNN**) is a neural model in which a bidirectional
    flow of information is present. In other words, while the propagation of signals
    in feedforward networks takes place only in a continuous manner in a direction
    from inputs to outputs, recurrent networks are different. In them, this propagation
    can also occur from a neural layer following a previous one, or between neurons
    belonging to the same layer, and even between a neuron and itself.
  prefs: []
  type: TYPE_NORMAL
- en: The decision made by a recurrent network at a specific instant affects the decision
    it will reach immediately afterwards. So, recurrent networks have two input sources—the
    present and the recent past—that combine to determine how to respond to new data,
    just as people do in life everyday.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recurrent networks are distinguished from feedforward networks thanks to the
    feedback loop linked to their past decisions, thus accepting their output momentarily
    as inputs. This feature can be emphasized by saying that recurrent networks have
    memory. Adding memory to neural networks has a purpose: there is information in
    the sequence itself and recurrent networks use it to perform the tasks that feedforward
    networks cannot.'
  prefs: []
  type: TYPE_NORMAL
- en: Access to memory occurs through the content rather than by address or location.
    One approach to this is that the memory content is the pattern of activations
    on the nodes of an RNN. The idea is to start the network with an activation scheme
    that is a partial or noisy representation of the requested memory content and
    that the network stabilizes on the required content.
  prefs: []
  type: TYPE_NORMAL
- en: 'RNN is a class of neural network where there is at least one feedback connection
    between neurons that form a directed cycle. A typical RNN with connections between
    output layer and hidden layer is represented in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cf599c2a-4e1e-4a61-923d-fa7a950ceda9.png)'
  prefs: []
  type: TYPE_IMG
- en: In the recurring network shown in the figure, both the input level and the output
    level are used to define the weights of the hidden level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ultimately, we can think of RNNs as a variant of ANNs: these variants can be
    characterized on a different number of hidden levels and a different trend of
    the data flow. The RNN are characterized by a different trend of the data flow,
    in fact the connections between the neurons form a cycle. Unlike feedforward networks,
    RNNs can use internal memory for their processing. RNNs are a class of ANNs that
    feature connections between hidden layers that are propagated through time in
    order to learn sequences.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The way the data is kept in memory and flows at different time periods makes
    RNNs powerful and successful. RNN use cases include the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: Stock market predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image captioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weather forecast
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time-series-based forecasts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speech recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HWR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Audio or video processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robotics action sequencing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recurrent networks are designed to recognize patterns as a sequence of data
    and are helpful in prediction and forecasting. They can work on text, images,
    speech, and time series data. RNNs are among the powerful ANNs and represent the
    biological brain, including memory with processing power.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recurrent networks take inputs from the current input (like a feedforward network)
    and the output that was calculated previously. In the following figure, we compare
    a single neuron operating scheme for both a feedforward neural network and an
    RNN:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95ac9383-d0c0-4058-b8d6-2684554946cb.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see in the simple, just-proposed single neuron scheme, the feedback
    signal is added to the input signal in the RNN. Feedback is a considerable and
    significant feature. A feedback network is more likely to update and has more
    computing capacity than a simple network limited to one-way signals from input
    to output. Feedback networks show phenomena and processes not revealed by one-way
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand the differences between ANN and RNN, we consider the RNN as a
    network of neural networks, and the cyclic nature is unfolded in the following
    manner: the state of a neuron is considered at different time periods (*t-1*,
    *t*, *t+1*, and so on) until convergence or until the total number of epochs is
    reached.'
  prefs: []
  type: TYPE_NORMAL
- en: The network learning phase can be performed using gradient descent procedures
    similar to those leading to the backpropagation algorithm for feedforward networks.
    At least this is valid in the case of simple architectures and deterministic activation
    functions. When activations are stochastic, simulated annealing approaches may
    be more appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: 'RNN architectures can have many different forms. There are more variants in
    the way the data flows backwards:'
  prefs: []
  type: TYPE_NORMAL
- en: Fully recurrent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recursive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hopfield
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elman networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LSTM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gated recurrent unit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bidirectional
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recurrent MLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following pages, we will analyze the architecture of some of these networks.
  prefs: []
  type: TYPE_NORMAL
- en: Fully recurrent neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A fully RNN is a network of neurons, each with a directed (one-way) connection
    to every other neuron. Each neuron has a time-varying, real-valued activation.
    Each connection has a modifiable real-valued weight. Input neurons, output neurons,
    and hidden neurons are expected. This type of network is a multilayer perceptron
    with the previous set of hidden unit activations feeding back into the network
    along with the inputs, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7a3453ca-581a-4f84-be6f-df21024492a6.png)'
  prefs: []
  type: TYPE_IMG
- en: At each step, each non-input unit calculates its current activation as a nonlinear
    function of the weighted sum of activations of all units that connect to it.
  prefs: []
  type: TYPE_NORMAL
- en: Recursive neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A recursive network is just a generalization of a recurrent network. In a recurrent
    network, the weights are shared and dimensionality remains constant along the
    length of the sequence. In a recursive network, the weights are shared and dimensionality
    remains constant but at every node. The following figure shows what a recursive
    neural network looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dab54544-cb52-4a9c-a2ea-30990052aa8f.png)'
  prefs: []
  type: TYPE_IMG
- en: Recursive neural networks can be used for learning tree-like structures. They
    are highly useful for parsing natural scenes and language.
  prefs: []
  type: TYPE_NORMAL
- en: Hopfield recurrent neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 1982, physicist John J. Hopfield published a fundamental article in which
    a mathematical model commonly known as the **Hopfield network** was introduced.
    This network highlighted new computational capabilities deriving from the collective
    behavior of a large number of simple processing elements. A Hopfield Network is
    a form of recurrent ANN.
  prefs: []
  type: TYPE_NORMAL
- en: According to Hopfield every physical system can be considered as a potential
    memory device if it has a certain number of stable states, which act as an attractor
    for the system itself. On the basis of this consideration, he formulated the thesis
    that the stability and placement of such attractors represented spontaneous properties
    of systems consisting of considerable quantities of mutually interacting neurons.
  prefs: []
  type: TYPE_NORMAL
- en: 'Structurally, the Hopfield network constitutes a recurrent symmetrical neural
    network (therefore with a synaptic weights matrix that is symmetric), one that
    is completely connected and in which each neuron is connected to all the others,
    as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e4650f6-14ac-4d42-b5c5-009679651721.png)'
  prefs: []
  type: TYPE_IMG
- en: As already mentioned before, a recurrent network is a neural model in which
    a flow of bidirectional information is present; in other words, while in feedforward
    networks the propagation of the signals takes place only in a continuous manner
    in the direction that leads from the inputs to the outputs in the recurrent networks
    this propagation can also occur from a neural layer following a previous one or
    between neurons belonging to at the same layer (Hopfield network) and even between
    a neuron and itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dynamics of a Hopfield network is described by a nonlinear system of differential
    equations and the neuron update mechanism can be:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Asynchronous**: One neuron is updated at a time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synchronous**: All neurons are updated at the same time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous**: All the neurons are continually updated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elman neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Elman neural network is a feedforward network in which the hidden layer,
    besides being connected to the output layer, forks into another identical layer,
    called the **context layer**, to which it is connected with weights equal to one.
    At each moment of time (each time the data is passed to the neurons of the input
    layer), the neurons of the context layer maintain the previous values and pass
    them to the respective neurons of the hidden layer. The following figure shows
    an Elman network scheme:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9ef7e2f5-d6cb-4ba1-a4b8-26a326797a9e.png)'
  prefs: []
  type: TYPE_IMG
- en: Like feedforward networks, Elman's RNNs can be trained with an algorithm called
    **Backpropagation Through Time** (**BPTT**), a variant of the backpropagation
    created specifically for the RNNs. Substantially, this algorithm unrolls the neural
    network transforming it into a feedforward network, with a number of layers equal
    to the length of the sequence to be learned; subsequently, the classic backpropagation
    algorithm is applied. Alternatively, it is possible to use global optimization
    methods, such as genetic algorithms, especially with RNN topologies on which it
    is not possible to apply BPTT.
  prefs: []
  type: TYPE_NORMAL
- en: Long short-term memory networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LSTM is a particular architecture of RNN, originally conceived by Hochreiter
    and Schmidhuber in 1997\. This type of neural network has been recently rediscovered
    in the context of deep learning because it is free from the problem of vanishing
    gradient, and in practice it offers excellent results and performance.
  prefs: []
  type: TYPE_NORMAL
- en: The vanishing gradient problem affects the training of ANNs with gradient-based
    learning methods. In gradient-based methods such as backpropagation, weights are
    adjusted proportionally to the gradient of the error. Because of the way in which
    the aforementioned gradients are calculated, we obtain the effect that their module
    decreases exponentially, proceeding towards the deepest layers. The problem is
    that in some cases, the gradient will be vanishingly small, effectively preventing
    the weight from changing its value. In the worst case, this may completely stop
    the neural network from further training.
  prefs: []
  type: TYPE_NORMAL
- en: LSTM-based networks are ideal for prediction and classification of time sequences,
    and they are supplanting many classic machine learning approaches. In fact, in
    2012, Google replaced its voice recognition models, passing from the Hidden Markov
    Models (which represented the standard for over 30 years) to deep learning neural
    networks. In 2015, it switched to the RNNs LSTM combined with **connectionist
    temporal classification** (**CTC**).
  prefs: []
  type: TYPE_NORMAL
- en: CTC is a type of neural network output and associated scoring function for training
    RNNs.
  prefs: []
  type: TYPE_NORMAL
- en: This is due to the fact that LSTM networks are able to consider long-term dependencies
    between data, and in the case of speech recognition, this means managing the context
    within a sentence to improve recognition capacity.
  prefs: []
  type: TYPE_NORMAL
- en: 'An LSTM network consists of cells (LSTM blocks) linked together. Each cell
    is in turn composed of three types of ports: **input gate**, **output gate**,
    and **forget gate**. They respectively implement the write, read, and reset functions
    on the cell memory. The ports are not binary but analogical (generally managed
    by a sigmoid activation function mapped in a range (0, 1), where zero indicates
    total inhibition and 1 indicates total activation), and they are multiplicative.
    The presence of these ports allows the LSTM cells to remember information for
    an indefinite amount of time. In fact, if the input gate is below the activation
    threshold, the cell will maintain the previous state, while if it is enabled,
    the current state will be combined with the input value. As the name suggests,
    the forget gate resets the current state of the cell (when its value is brought
    to zero), and the output gate decides whether the value inside the cell must be
    taken out or not.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows an LSTM unit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/84226791-6851-4aa4-975d-682e1f237ec4.png)'
  prefs: []
  type: TYPE_IMG
- en: The approaches based on neural networks are very powerful, as they allow capture
    of the characteristics and relationships between the data. In particular, it has
    also been seen that LSTM networks, in practice, offer high performance and excellent
    recognition rates. One disadvantage is that the neural networks are black box
    models, so their behavior is not predictable, and it is not possible to trace
    the logic with which they process the data.
  prefs: []
  type: TYPE_NORMAL
- en: Handwriting Recognition using RNN and TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To practice RNNs, we will use the dataset previously used to construct the CNN.
    I refer to the MNIST dataset, a large database of handwritten digits. It has a
    set of 70,000 examples of data. It is a subset of NIST's larger dataset. Images
    of 28 x 28 pixel resolution are stored in a matrix of 70,000 rows and 785 columns;
    each pixel value from the 28 x 28 matrix and one value is the actual digit. In
    a fixed-size image, the digits have been size-normalized.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we will implement an RNN (LSTM) using the TensorFlow library to
    classify images. We will consider every image row as a sequence of pixels. Because
    the MNIST image shape is 28 x 28, we will handle 28 sequences of 28 time steps
    for every sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, we will analyze the code line by line; then we will see how to process
    it with the tools made available by Google Cloud Platform. Now, let''s go through
    the code to learn how to apply an RNN (LSTM) to solve an HWR problem. Let''s start
    from the beginning of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'These three lines are added to write a Python 2/3 compatible code base. So
    let''s move on to importing modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'In this way, we have imported the `tensorflow` module and, from `tensorflow.contrib`,
    the `rnn` module. The `tensorflow.contrib` contains volatile or experimental code.
    The `rnn` module is a module for constructing RNN Cells and additional RNN operations.
    Let''s analyze the next lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The first line is used to import the `mnist` dataset from the TensorFlow library;
    in fact, the `minist` dataset is already present in the library as an example.
    The second line reads the data from a local directory. Let''s move on to set the
    training parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The `learning_rate` is a value used by the learning algorithm to determine
    how quickly the weights are adjusted. It determines the acquisition time for neurons
    with weights that are trained using the algorithm. The `training_steps` sets the
    number of times the training process is performed. The `batch_size` is the number
    of samples you feed in your network. The `display_step` decides how many steps
    are shown the partial results of the training. Now let''s set the network parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The first parameter (`num_input`) sets the MNIST data input (image shape: 28
    x 28). The `timesteps` parameter is equivalent to the number of time steps you
    run your RNN. The `num_hidden` parameter sets the number of hidden layers of the
    neural network. Finally the `num_classes` parameter sets the MNIST total classes
    (0-9 digits). Let''s analyze the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'In these lines of code, we used a `tf.placeholder()` function. A placeholder
    is simply a variable that we will assign data to at a later date. It allows us
    to create our operations and build our computation graph without needing the data.
    In this way, we have set up the `tf.Graph` input. A `tf.Graph` contains two relevant
    kinds of information: graph structure and graph collections. TensorFlow uses a
    dataflow graph to represent your computation in terms of the dependencies between
    individual operations. This leads to a low-level programming model in which you
    first define the dataflow graph and then create a TensorFlow session to run parts
    of the graph across a set of local and remote devices. Let''s move on to define
    `weights`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Weights in a network are the most important factor for converting an input
    to impact the output. This is similar to slope in linear regression, where a weight
    is multiplied to the input to add up to form the output. Weights are numerical
    parameters that determine how strongly each of the neurons affects the other.
    Bias is like the intercept added in a linear equation. It is an additional parameter
    used to adjust the output along with the weighted sum of the inputs to the neuron.
    Now we have to define the `RNN` by creating a new function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The `unstack()` function is used to get a list of `timesteps` tensors of shape
    (`batch_size`, `n_input`). Then we have defined an `lstm` cell with TensorFlow,
    and we''ve got an `lstm` cell output. Finally, we have placed a linear activation,
    using the `RNN` in the inner loop and last output. Let''s move on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The first line of code uses the newly defined `RNN` function to build the network,
    while the second line of code predicts using the function `tf.nn.softmax()`, which
    computes `softmax` activations. Next, we will define `loss` and `optimizer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The `loss` function maps an event or values of one or more variables onto a
    real number, intuitively representing some `cost` associated with the event. We
    have used the `tf.reduce_mean()` function, which computes the mean of elements
    across the dimensions of a tensor. The `optimizer` base class provides methods
    to compute gradients for a loss and apply gradients to variables. A collection
    of subclasses implement classic optimization algorithms such as gradient descent
    and AdaGrad. Let''s go ahead to evaluate model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we will initialize the variables by assigning their default value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can start training the network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally we will calculate the accuracy for `128` mnist test images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we just have to copy the entire code into a file with a `.py`
    extension and run it on a machine where Python and TensorFlow are installed.
  prefs: []
  type: TYPE_NORMAL
- en: LSTM on Google Cloud Shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After having thoroughly analyzed the Python code, it is time to run it around
    to classify the images contained in the dataset. To do this, we work in a similar
    way to what was done in the case of the example on CNN. So we will use the Google
    Cloud Shell. Google Cloud Shell provides command-line access to Cloud resources
    directly from your browser. You can easily manage projects and resources without
    having to install the Google Cloud SDK or other tools in your system. With Cloud
    Shell, the `gcloud` command-line tool from Cloud SDK and other necessary utilities
    are always available, updated and fully authenticated when you need them.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start Cloud Shell, just click the Activate Google Cloud Shell button at
    the top of the console window, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ebe7c69a-a3d7-4867-aeeb-3f223daf727a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A Cloud Shell session opens inside a new frame at the bottom of the console
    and displays a command-line prompt. It can take a few seconds for the shell session
    to be initialized. Now, our Cloud Shell session is ready to use, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/443a8156-ece7-4c3d-a847-f7686d3b2d3a.png)'
  prefs: []
  type: TYPE_IMG
- en: At this point, we need to transfer the `rnn_hwr.py` file containing the Python
    code in the Google Cloud Platform. We have seen that to do so, we can use the
    resources made available by Google Cloud Storage. Then we open the Google Cloud
    Storage browser and create a new bucket.
  prefs: []
  type: TYPE_NORMAL
- en: 'To transfer the `cnn_hwr.py` file on Google Storage, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Just click on CREATE BUCKET icon
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Type the name of the new bucket (`rnn-hwr`) in the create a bucket window
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After this, a new bucket is available in the buckets list
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the `rnn-hwr` bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on UPLOAD FILES icon in the window opened
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the file in the dialog window opened
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click Open
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At this point, our file will be available in the new bucket, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ec3a8d23-345c-4434-8d2d-f3d2d63d6b62.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we can access the file from the Cloud Shell. To do this, we create a new
    folder in the shell. Type this command in the shell prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to copy the file from the Google Storage bucket to the `CNN-HWR` folder,
    simply type the following command in the shell prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s move into the folder and verify the presence of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We just have to run the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'A series of preliminary instructions is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'They indicate that the data download was successful, as was the invocation
    of the TensorFlow library. From this point on, the training of the network begins,
    which, as we have anticipated, may be quite long. At the end of the algorithm
    execution, the following information will be returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we've achieved an accuracy of `97.6` percent on our test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we tried to broaden the concepts underlying standard neural
    networks by adding features to solve more complex problems. To begin with, we
    discovered the architecture of CNNs. CNNs are ANNs in which the hidden layers
    are usually constituted by convolutional layers, pooling layers, FC layers, and
    normalization layers. The concepts underlying CNN were covered.
  prefs: []
  type: TYPE_NORMAL
- en: We understood training, testing, and evaluating a CNN through the analysis of
    a real case. For this purpose, an HWR problem was addressed in Google Cloud Platform.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we explored RNN. Recurrent networks take, as their input, not only current
    input data that is powered to the network but also what they have experienced
    over time. Several RNN architectures were analyzed. In particular, we focused
    on LSTM networks.
  prefs: []
  type: TYPE_NORMAL
