- en: Cyber Attack Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have been mainly developing **machine learning** (**ML**) models
    with well-balanced sample sets, where the target classes are distributed equally
    or almost equally across the sample records in the dataset. However, there are
    cases where a dataset has imbalanced class distributions. Class imbalance is especially
    common in anomaly and fraud detections. These kinds of class imbalance problems
    causes issues when training ML models, as most ML algorithms work best when the
    target classes are roughly equally distributed. In order to tackle this imbalanced
    class problem, we cannot approach it the same way we have been developing models
    for various classification and regression problems. We will need to approach it
    differently.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to discuss how we can build an anomaly detection
    model. We will be using a network intrusion dataset, **KDD Cup 1999 Data**, which
    has a large amount of network connection data where some of the connections are
    normal network connections, and some others are cyber attacks. We will first look
    at the structure of the data, types of cyber attacks present in the dataset, and
    distributions of various network features. Then, we will apply some of the feature-engineering
    techniques we have discussed in previous chapters, as the feature set contains
    both categorical and continuous variables. We are also going to apply the dimensionality
    reduction technique, **Principal Component Analysis** (**PCA**), that we discussed
    in the previous chapter. In addition to what we covered about PCA in the previous
    chapter, we are going to use PCA to build models for anomaly detection. With the
    models built using PCA, we are going to further discuss some of the ways to evaluate
    anomaly detection models, and what will work best for the cyber attack detection
    project.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Problem definition for the cyber attack detection project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analysis for the internet traffic dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature engineering and PCA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Principal component classifier for anomaly detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating anomaly detection models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problem definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Datasets with imbalanced class distributions cause problems for most ML algorithms,
    as they typically perform well for well-balanced datasets. There are various ways
    to handle class imbalance problems in ML. Resampling the dataset to balance the
    target classes is one way. You can upsample the positive training samples, where
    you randomly select and duplicate the positive training samples, so that roughly
    50% of the dataset belongs to a positive class. You can also downsample the negative
    training samples so that the number of negative training examples matches with
    the number of positive training examples. In cases of extreme class imbalance,
    you can approach it as an anomaly detection problem, where the positive events
    are considered anomalies or outliers. Anomaly detection techniques have many applications
    in real-world problems. They are often used for network intrusion detection, credit
    card fraud detection, or even medical diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to work on building an anomaly detection model
    for cyber attacks. In order to build a cyber attack detection model, we are going
    to use the **KDD Cup 1999 Data**, which has a large amount of artificial and hand-injected
    cyber attack data, along with normal network connection data. This data can be
    found at the following link: [http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).
    With this data, we are going to first look at the distributions of the cyber attack
    types and then the distributions of the network features. Since this is a simulated
    and artificial dataset, the majority of this dataset is made up of cyber attacks,
    which are abnormal and unrealistic in the real world. In order to simulate real-world
    examples of cyber attacks we are going to randomly sub-select the cyber attack
    events from the sample set and build a new training set that contains more normal
    network connections than malicious connections. With this sub-sampled dataset,
    we are going to build an anomaly detection model using PCA. Then, we are going
    to evaluate this model by looking at the cyber attack detection rate at various
    target false alarm rates.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize our problem definition for the cyber attack detection project:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the problem? We need a cyber attack detection model that can identify
    potential malicious connections from large amounts of network connections so that
    we can avoid cyber attacks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is it a problem? The number of cyber attacks increases every year and without
    being properly prepared for such attacks, our systems will become more vulnerable
    from various cyber attacks. With a cyber attack detection model, we can avoid
    becoming the victims of cyber attacks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are some of the approaches to solving this problem? We are going to use
    publicly available data that has a large amount of artificial and simulated cyber
    attack data. We are going to sub-sample this data to replicate a real-life situation
    where there are more normal network connections than abnormal and malicious connections.
    Then, we are going to use PCA and its principal components to detect anomalies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the success criteria? We want a high cyber attack detection rate, even
    if we need to sacrifice it for higher false alarm rate. This is because we are
    more concerned about allowing cyber attacks than false positive alerts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analysis for internet traffic data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start by taking a look into the internet traffic data. As mentioned previously,
    we are going to use the KDD Cup 1999 Data, which you can download from the following
    link: [http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).
    We will be using the `kddcup.data_10_percent.gz` data for this cyber attack detection
    project.
  prefs: []
  type: TYPE_NORMAL
- en: Data clean-up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we need to do is clean up the data for future steps. If you
    open the data that you just downloaded, you will notice that there is no header
    in the dataset. However, for future data analysis and model building, it is always
    beneficial to have headers associated with each column. Based on the column description
    that can be found at [http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names](http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names),
    we are going to attach headers to the raw dataset. The code to attach column names
    to the data frame looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are loading this raw dataset without headers,
    by supplying the `hasHeaders: false` flag to the `ReadCsv` method of Deedle''s
    data frame. By supplying this flag, we are telling Deedle not to take the first
    row of the dataset as the header. Once this data is loaded into a data frame,
    we are using the `RenameColumns` method to attach the names of the columns to
    the data frame.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next clean-up task we are going to take is to group the cyber attack types
    together by corresponding categories. You can find the mapping between the attack
    type and the category at the following link: [http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types](http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types).
    Using this mapping, we are going to create a new column in the data frame that
    contains information about the attack category. Let''s look at the code first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you look closely at this code, we created a `Dictionary` object that has
    mapping between an attack type and its category. For example, the attack type,
    `"back"`, is one of the **Denial-of-Service** (**DOS**) attacks and the attack
    type, `"rootkit"`, is one of the **User-to-Root** (**U2R**) attacks. Using this
    mapping, we created a new column, `"attack_category"`, and added it to the `featuresDF`.
    Now that we have cleaned the raw dataset with column names and attack categories,
    we need to export it and store it into our local drive for future use. You can
    use the following code to export this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Target variable distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have clean data to work with, we will start digging into the data.
    Let''s first look at the distributions of cyber attack categories. The code to
    get the distribution of target variables looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to the previous chapters, we are using the `AggregateRowsBy` method
    in Deedle''s data frame to group by the target variable, `attack_category`, and
    count the number of occurrences per category in the dataset. Then, we use the
    `DataBarBox` class to display a bar chart of this distribution. Once you run this
    code, the following bar chart will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00141.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And the output that shows us the number of occurrences of each cyber attack
    category looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00142.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There is one thing that is noticeable here. There are more DOS attack samples
    than normal samples in the dataset. As mentioned previously, the KDD Cup 1999
    dataset that we are using for this project is artificial and simulated data, and
    thus, it does not reflect a real-life situation, where the number of normal internet
    connections will outnumber the number of all the other cyber attacks combined.
    We will have to keep this in mind when building models in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Categorical variable distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The features that we have in this dataset are a mixture of categorical and continuous
    variables. For example, the feature named `duration`, which represents the length
    of the connection, is a continuous variable. However, the feature, named `protocol_type`,
    which represents the type of the protocol, such as `tcp`, `udp`, and so forth,
    is a categorical variable. For a complete set of feature descriptions, you can
    go to this link: [http://kdd.ics.uci.edu/databases/kddcup99/task.html](http://kdd.ics.uci.edu/databases/kddcup99/task.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we are going to take a look at the distribution differences
    in the categorical variables between the normal connections and the malicious
    connections. The following code shows how we separate the sample set into two
    subgroups, one for normal connections and another for abnormal connections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have these two subsets, let''s start comparing the distributions
    of categorical variables between normal and malicious connections. Let''s first
    take a look at the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code, we are iterating through an array of categorical variables: `protocol_type`,
    `service`, `flag`, and `land`. We will defer the feature descriptions to the description
    page that can be found at the following link: [http://kdd.ics.uci.edu/databases/kddcup99/task.html](http://kdd.ics.uci.edu/databases/kddcup99/task.html).
    For each categorical variable, we used the `AggregateRowsBy` method to group by
    each type of the variable and count the number of occurrences for each type. We
    do this aggregation once for the normal group and then once more for the attack
    group. Then, we use the `DataBarBox` class to display bar charts to visually show
    the differences in the distributions. Let''s take a look at a few plots and outputs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following bar chart is for the `protocol_type` feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00143.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The actual counts per type between the two groups look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00144.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from these outputs, there are some noticeable distinctions between
    the distributions of normal and cyber attack groups. For example, the majority
    of attacks happen on `icmp` and `tcp` protocols, while the majority of normal
    connections are on `tcp` and `udp`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following bar chart is for the `land` feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00145.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The actual counts for each type in this feature look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00146.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It is quite hard to tell if we can deduce any meaningful insights from these
    outputs. Almost all samples in the dataset have a value of `0` for both the attack
    and normal groups. Let's take a look at one more feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following bar chart shows the distributions of the feature `flag` in attack
    and normal groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00147.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And the actual counts look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00148.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There are some noticeable distinctions in this feature, even though the most
    frequently appearing flag type for both attack and normal groups is `SF`. It seems
    the flag types `SF` and `REJ` take up the majority of the normal group. On the
    other hand, the flag types `SF`, `S0`, and `REJ` take up the majority of the attack
    group.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous variable distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we have looked at the distributions of categorical variables. Let''s
    now look at the distributions of continuous variables in our feature set. Similar
    to the previous chapters, we are going to look at the quartiles for each continuous
    variable. The code to compute quartiles for each continuous feature looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'And the variable, `continuousVars`, is defined as the following array of strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Similar to what we did for categorical variable analysis, we start iterating
    through the continuous variables in the preceding code. The string array, `continuousVars`,
    contains a list of all the continuous features we have in our dataset, and we
    iterate through this array to start computing the quartiles of each distribution.
    As in the previous chapters, we are using the `Accord.Statistics.Measures.Quantiles`
    method to compute quartiles, which are min, 25% percentile, median, 75% percentile,
    and max numbers. We do this twice, once for the attack group and another time
    for the normal group, so that we can see if there are any noticeable differences
    in the distributions. Let's take a look at a few features and their distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the following output is for the distribution of a feature called `duration`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00149.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From this output, we can see that the majority of the values for this feature
    are `0` for both attack and normal groups. As there is not so much variance in
    this variable, our model might not learn much information from this feature. Let's
    take a look at another feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following output is for the distribution of a feature called `dst_bytes`,
    which represents the number of data bytes from destination to source:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00150.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Here, we see some noticeable distinctions in the distributions between the attack
    and normal groups. Almost all the cyber attacks have a value of 0, while the values
    are distributed across a wide range for the normal network connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, the following output is for a feature called `wrong_fragment`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00151.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Similar to the case of the `duration` feature, the majority of the values are
    `0` for both the attack and normal group, which suggests that our model might
    not learn many insights from this feature. You can run the previous code to look
    at the distribution differences between the two groups for all the other features.
  prefs: []
  type: TYPE_NORMAL
- en: The full code to run this data analysis step can be found at this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/DataAnalyzer.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/DataAnalyzer.cs).
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering and PCA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have analyzed the distributions of the target variable `attack_category`,
    as well as the categorical and continuous variables in the cyber attack dataset.
    In this section, we are going to focus on encoding the target variable and categorical
    features, and creating PCA features for our future model-building step.
  prefs: []
  type: TYPE_NORMAL
- en: Target and categorical variables encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we will have to encode different classes in the target variable, `attack_category`.
    If you recall from the previous data analysis step, there are five different categories:
    normal, `dos`, `probe`, `r2l`, and `u2r`. We are going to encode each of these
    string values with a corresponding integer representation. Then, we are going
    to encode each of the categorical variables with one-hot encoding, where we encode
    with 1 if the given value appears in the example, and 0 if not. Let''s first load
    the cleaned-up data that we created in the previous data analysis step, using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we set `hasHeaders: true`, as the cleaned-up
    data now has correct headers associated with each of the columns. The following
    code shows how we went about encoding the target and categorical variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a deeper look at this code. We first created a string array variable, `categoricalVars`,
    which contains the column names of all the categorical variables, and a dictionary
    variable, `targetVarEncoding`, which maps each target class to an integer value.
    For example, we are encoding the `normal` class as `0`, the `dos` attack class
    as `1`, and so forth. Then, we iterate through all the columns in the `rawDF` data
    frame and start adding encoded data to the new and empty `featuresDF`. One thing
    to note here is that we use a helper function, `EncodeOneHot`, for encoding each
    of the categorical variables. Let''s take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: If you recall [Chapter 2](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470), *Spam
    Email Filtering* and [Chapter 3](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470), *Twitter
    Sentiment Analysis*, this code should look familiar. In this code, we iterate
    through each row, create a new variable that is a combination of the original
    column name and the value, and finally create a new Deedle data frame, `categoriesDF`.
    Once this step is done, this data frame output gets appended to the `featuresDF`
    in the previous code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we are done with encoding the target and categorical variables, we
    will need to export and store this new data frame, `featuresDF`. We are using
    the following code to store this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Fitting PCA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the encoded data we just created in the previous section, let's start building
    PCA features that we are going to use for the anomaly detection in the following
    model-building step.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing we need to do is separate our sample set into two separate sets—one
    with normal connection data and another with malicious connections. While we create
    these subsets, we need to create more realistic distributions between the two
    groups. If you recall from the previous data analysis step, we noticed that there
    are more malicious connections than normal connections, which is unrealistic,
    due to the fact that the KDD CUP 1999 Dataset is an artificial and hand-injected
    dataset. Aside from the purpose of creating a dataset with a more realistic number
    of normal and malicious connections, we need to create the two subsets so that
    we can apply PCA to the normal group only, and then apply it to the abnormal group.
  prefs: []
  type: TYPE_NORMAL
- en: This is because we want to learn and build principal components only from the
    normal connections group, and be able to flag any outliers as potential cyber
    attacks. We will discuss more in detail about how we are going to build an anomaly
    detection model using principal components.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following code for splitting our sample set into
    two groups—one for the normal group and another for the cyber attack group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are building arrays of indexes for the normal
    and cyber attack groups by filtering for whether the `attack_category` is `0`
    (normal) or greater than 0 (cyber attacks). Then, we randomly select 90,000 samples
    from the normal connections and 10,000 samples from the malicious connections.
    Now that we have the indexes for the normal and abnormal groups, we are going
    to use the following code to build the actual data for fitting PCA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, the `normalData` variable contains all the normal
    connection samples and the `wholeData` variable contains both the normal and cyber
    attack connection samples. We will be using `normalData` to fit PCA, and then
    apply this learned PCA to the `wholeData`, as you can see from the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As in [Chapter 8](part0097.html#2SG6I0-5ebdf09927b7492888e31e8436526470), *Handwritten
    Digit Recognition*, we are using the `PrincipalComponentAnalysis` class in the
    Accord.NET framework to fit PCA. Once we have trained PCA with the normal connections
    data, we apply it to the `wholeData` that contains both normal and cyber attack
    connections by using the `Transform` method of the `pca` object.
  prefs: []
  type: TYPE_NORMAL
- en: PCA features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have now built principal components using just the normal connections group.
    Let''s briefly inspect how well our target classes are separated on different
    combinations of principal components. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are building scatter plots between two principal
    components at a time, for the first six components. When you run this code, you
    will see plots similar to the following ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first plot is between the first and second principal components, and looks
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00152.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The blue dots represent the normal connections, and the other dots with different
    colors represent the cyber attacks. We can see some distinctions in the distributions
    among different classes, but the pattern does not seem so strong.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot is between the second and third components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00153.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Lastly, the following plot is between the third and fourth components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00154.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We cannot really see many distinctions among different classes in the last plot. Although
    the pattern does not seem very strong, previous scatter plots show some differences
    in the distributions. It is especially more difficult to visually see the distinctions
    on two-dimensional plots. If we take this to higher-dimensional space, which our
    anomaly detection model is going to be looking at, the differences in the patterns
    will become more noticeable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now look at the amount of variance explained from the principal components.
    The following code shows how we can get the cumulative proportion of variances
    explained, and display it in a line chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'If you look at this code more closely, the `Components` property in the `pca`
    object contains information about the proportion of variance explained. We can
    iterate through each component and get the cumulative proportion by using the
    `CumulativeProportion` property. Once we have extracted these values, we then
    use the `DataSeriesBox` class to display a line chart that shows the cumulative
    proportion of variance explained. The output looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00155.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we have successfully created PCA features and have full PCA-transformed
    data. You can use the following code to export this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The full code for the feature engineering step can be found at this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/FeatureEngineering.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/FeatureEngineering.cs).
  prefs: []
  type: TYPE_NORMAL
- en: Principal component classifier for anomaly detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have compiled everything and are now ready to start building an anomaly detection
    model for the cyber attack detection project. As mentioned previously, we are
    going to use the data of the distributions of principal components from the normal
    connections group, and take it as the normal ranges of principal components. For
    any records that deviate from these normal ranges of the principal component values,
    we are going to flag them as abnormal and potential cyber attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Preparation for training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let''s load the features data that we created from the feature engineering
    step. You can use the following code to load the PCA-transformed data and the
    labels data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s quickly look at the distributions of our target classes. The code to
    count by each target class is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you run this code, you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00156.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As expected, the majority of the samples belong to the 0 class, which is the
    normal group, and the rest combined are the minority (about 10%) in our sample
    set. This is a more realistic view of cyber attacks. Cyber attacks happen way
    less frequently than normal connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'For illustration purposes, we are going to use the first `27` principal components
    that explain about 70% of the overall variance in the dataset. You can experiment
    with different numbers of principal components and see how model performances
    change. The following code shows how we created a training set using the first
    `27` principal components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: If you look at this code closely, you will notice that we are creating `normalDF`
    and `normalData` variables with normal connection samples only. As mentioned previously,
    we want to learn only from the normal data, so that we can flag any outliers and
    extreme deviations from the normal ranges of principal components. We are going
    to use these variables to build a principal component classifier for the cyber
    attack detection in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Building a principal component classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to build a principal component classifier, which will flag those events
    that deviate from the normal connections, we need to calculate the distance between
    a record and the distributions of normal connections. We are going to use a distance
    metric, the **Mahalanobis distance**, which measures the distance between a point
    and a distribution. For the standardized principal components, like those here,
    the equation to compute the **Mahalanobis distance** is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00157.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*C[i]* in this equation represents the value of each principal component, and
    *var[i]* represents the variance of each principal component. Let''s take a look
    at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00158.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Assume you have 5 principal components with values as shown in this image and
    assume the variance for each principal is 1 for simplicity and demonstration purposes,
    then you can compute the **Mahalanobis distance** as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00159.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: And the computed **Mahalanobis distance** for this example is 0.64\. For a more
    detailed description of this distance metric, it is recommended that you review
    the following Wikipedia page: [https://en.wikipedia.org/wiki/Mahalanobis_distance](https://en.wikipedia.org/wiki/Mahalanobis_distance),
    or the following research paper: [https://users.cs.fiu.edu/~chens/PDF/ICDM03_WS.pdf](https://users.cs.fiu.edu/~chens/PDF/ICDM03_WS.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: 'We implemented the Mahalanobis distance equation as a helper function, `ComputeDistances`,
    and it looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have computed the distances of individual records, let''s analyze
    how the ranges for the normal connections look. We used the following code to
    calculate the mean and standard deviation of the distances, and a histogram to
    visualize the overall distance distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'When you run this code, you will see the following output for the mean and
    standard deviation of the distance metrics for normal connections:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00160.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And the histogram looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00161.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from these outputs, the majority of the distances are very small,
    which suggests that the non-attack and normal connections are typically clustered
    together closely. With this information about the distance distributions within
    the normal connections group, let's start looking to see if we can build a detection
    model by flagging certain network connections that go beyond the normal range
    of distances.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how we computed the distances of cyber attack connections
    from the distribution of normal network connections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we first created a variable, called `attackData`,
    which contains all the cyber attack connections from our training set. Then, we
    used the `ComputeDistances` method to calculate the distances of individual records
    in the cyber attack connections group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are ready to start flagging suspicious network connections based on
    the distance metrics that we just calculated. Let''s take a look at the following
    code first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we decide the threshold based on the distribution
    of distances within the normal connections group. For example, if our target is
    to have a 5% false alarm rate, we flag all the connections that have distances
    from the normal range greater than the 95% percentile of the distribution of distances
    within the normal connections group. More specifically, the 95% percentile of
    the normal connections' distance distribution in our case was 5.45\. So, in this
    case, we will flag all the connections that have distances from the normal range
    greater than 5.45 as cyber attacks. We repeat this process for the false alarm
    rates from 5% to 10%. We will discuss the performance of this anomaly detection
    model in more detail in the following model-evaluation step.
  prefs: []
  type: TYPE_NORMAL
- en: The full code for the model-building step can be found at this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/Modeling.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/Modeling.cs).
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating anomaly detection models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We built an anomaly detection model for cyber attacks in the previous model-building
    step. In the previous code, you might have noticed that we are using a function
    named `EvaluateResults`. It is a helper function that we wrote for evaluating
    model performances. Let''s take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are interested in two metrics: overall cyber
    attack detection rate and per-class detection rate. The evaluation results look
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00162.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The overall results look good with over 99% detection rates. At 5% false alarm
    rate, about 99.1% of the cyber attacks are detected. However, if we look closer
    at the per-class detection rates, we can see their weaknesses and strengths. At
    5% false alarm rate, our model does very well for detecting classes 1 and 2, which
    are `dos` and `probe` attacks. On the other hand, our model does poorly in detecting
    classes 3 and 4, which are `r2l` and `u2r` attacks. As you can see from this output,
    as we increase the target false alarm rates, the overall and per-class detection
    rates increase as well. In a real-world situation, you will have to evaluate the
    trade-offs between a higher detection rate and a higher false alarm rate, and
    make a decision on the target false alarm rate that meets your business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we built our very first anomaly detection model that can detect
    cyber attacks. At the beginning of this chapter, we discussed how this type of
    anomaly detection model can be used and applied to real-life situations, and how
    developing an anomaly detection model is different from other ML models that we
    have built so far. Then, we started analyzing the distributions of target classes
    and various features to understand the dataset better. While we were analyzing
    this dataset, we also noticed how there are more cyber attack samples than normal
    connection samples, which is unrealistic in real life. In order to simulate real-life
    situations, where abnormal malicious connections occur much less frequently than
    normal connections, we randomly sub-selected the normal and malicious connection
    samples so that 90% of the training set were normal connections and only 10% were
    cyber attack examples.
  prefs: []
  type: TYPE_NORMAL
- en: With this sub-selected training set, we applied PCA to the normal connections
    data to find out the normal ranges of principal components. Using the **Mahalanobis
    distance** metric, we computed the distances between individual records from the
    distributions of normal connections. During the model-building step, we experimented
    with different thresholds based on the target false alarm rates. Using 5% to 10%
    false alarm rates, we built cyber attack detection models and evaluated their
    performance. In our model-evaluation step, we noticed that the overall detection
    rates were over 99%, while a closer look at per-attack detection rates exposed
    the weaknesses and strengths of the models. We also noticed that as we sacrifice
    and increase the false alarm rates, the overall cyber attack detection rates improved.
    When applying this anomaly detection technique, it becomes necessary to understand
    this tradeoff between the false alarm rate and detection rate, and make a decision
    based on pertinent business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to expand our knowledge and experience in
    building anomaly detection models. We are going to work on a credit card fraud
    detection project with a credit card dataset. On top of the PCA-based anomaly
    detection model, we are going to discuss how to use a one-class support vector
    machine for anomaly detection.
  prefs: []
  type: TYPE_NORMAL
