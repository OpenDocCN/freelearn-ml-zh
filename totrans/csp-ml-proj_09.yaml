- en: Cyber Attack Detection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络攻击检测
- en: So far, we have been mainly developing **machine learning** (**ML**) models
    with well-balanced sample sets, where the target classes are distributed equally
    or almost equally across the sample records in the dataset. However, there are
    cases where a dataset has imbalanced class distributions. Class imbalance is especially
    common in anomaly and fraud detections. These kinds of class imbalance problems
    causes issues when training ML models, as most ML algorithms work best when the
    target classes are roughly equally distributed. In order to tackle this imbalanced
    class problem, we cannot approach it the same way we have been developing models
    for various classification and regression problems. We will need to approach it
    differently.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们主要开发的是具有平衡样本集的**机器学习**（**ML**）模型，其中目标类别在数据集中的样本记录中分布均匀或几乎均匀。然而，有些数据集存在类别分布不平衡的情况。类别不平衡在异常和欺诈检测中尤为常见。这类类别不平衡问题在训练ML模型时会引起问题，因为大多数ML算法在目标类别大致均匀分布时表现最佳。为了解决这个类别不平衡问题，我们不能像开发各种分类和回归问题的模型那样处理。我们需要采取不同的方法。
- en: In this chapter, we are going to discuss how we can build an anomaly detection
    model. We will be using a network intrusion dataset, **KDD Cup 1999 Data**, which
    has a large amount of network connection data where some of the connections are
    normal network connections, and some others are cyber attacks. We will first look
    at the structure of the data, types of cyber attacks present in the dataset, and
    distributions of various network features. Then, we will apply some of the feature-engineering
    techniques we have discussed in previous chapters, as the feature set contains
    both categorical and continuous variables. We are also going to apply the dimensionality
    reduction technique, **Principal Component Analysis** (**PCA**), that we discussed
    in the previous chapter. In addition to what we covered about PCA in the previous
    chapter, we are going to use PCA to build models for anomaly detection. With the
    models built using PCA, we are going to further discuss some of the ways to evaluate
    anomaly detection models, and what will work best for the cyber attack detection
    project.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何构建异常检测模型。我们将使用一个网络入侵数据集，即**KDD Cup 1999数据**，它包含大量网络连接数据，其中一些是正常网络连接，而另一些则是网络攻击。我们首先将查看数据的结构，数据集中存在的网络攻击类型，以及各种网络特征的分布。然后，我们将应用我们在前几章中讨论的一些特征工程技术，因为特征集包含分类变量和连续变量。我们还将应用我们在前一章中讨论的降维技术，即**主成分分析**（**PCA**）。除了我们在前一章中关于PCA的讨论外，我们还将使用PCA来构建异常检测模型。使用PCA构建的模型，我们将进一步讨论评估异常检测模型的一些方法，以及哪些最适合网络攻击检测项目。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Problem definition for the cyber attack detection project
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络攻击检测项目的定义问题
- en: Data analysis for the internet traffic dataset
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互联网流量数据集的数据分析
- en: Feature engineering and PCA
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程与PCA
- en: Principal component classifier for anomaly detection
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常检测的主成分分类器
- en: Evaluating anomaly detection models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估异常检测模型
- en: Problem definition
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题定义
- en: Datasets with imbalanced class distributions cause problems for most ML algorithms,
    as they typically perform well for well-balanced datasets. There are various ways
    to handle class imbalance problems in ML. Resampling the dataset to balance the
    target classes is one way. You can upsample the positive training samples, where
    you randomly select and duplicate the positive training samples, so that roughly
    50% of the dataset belongs to a positive class. You can also downsample the negative
    training samples so that the number of negative training examples matches with
    the number of positive training examples. In cases of extreme class imbalance,
    you can approach it as an anomaly detection problem, where the positive events
    are considered anomalies or outliers. Anomaly detection techniques have many applications
    in real-world problems. They are often used for network intrusion detection, credit
    card fraud detection, or even medical diagnosis.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 类别分布不平衡的数据集会给大多数机器学习算法带来问题，因为它们通常在平衡数据集上表现良好。在机器学习中处理类别不平衡问题有各种方法。对数据集进行重采样以平衡目标类别是一种方法。你可以通过随机选择并复制正样本训练样本来增加正样本的训练样本，这样大约50%的数据集属于正类别。你也可以减少负样本的训练样本，以便负样本的数量与正样本的数量相匹配。在极端类别不平衡的情况下，你可以将其视为一个异常检测问题，其中正事件被视为异常或离群值。异常检测技术在现实世界问题中有许多应用。它们通常用于网络入侵检测、信用卡欺诈检测，甚至医疗诊断。
- en: In this chapter, we are going to work on building an anomaly detection model
    for cyber attacks. In order to build a cyber attack detection model, we are going
    to use the **KDD Cup 1999 Data**, which has a large amount of artificial and hand-injected
    cyber attack data, along with normal network connection data. This data can be
    found at the following link: [http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).
    With this data, we are going to first look at the distributions of the cyber attack
    types and then the distributions of the network features. Since this is a simulated
    and artificial dataset, the majority of this dataset is made up of cyber attacks,
    which are abnormal and unrealistic in the real world. In order to simulate real-world
    examples of cyber attacks we are going to randomly sub-select the cyber attack
    events from the sample set and build a new training set that contains more normal
    network connections than malicious connections. With this sub-sampled dataset,
    we are going to build an anomaly detection model using PCA. Then, we are going
    to evaluate this model by looking at the cyber attack detection rate at various
    target false alarm rates.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将致力于构建一个用于网络攻击的异常检测模型。为了构建网络攻击检测模型，我们将使用**KDD Cup 1999数据**，该数据集包含大量的人工和手动注入的网络攻击数据，以及正常的网络连接数据。这些数据可以在以下链接找到：[http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)。有了这些数据，我们将首先查看网络攻击类型的分布，然后是网络特征的分布。由于这是一个模拟和人工数据集，这个数据集的大部分是由网络攻击组成的，这在现实世界中是不正常和不切实际的。为了模拟现实世界中的网络攻击实例，我们将从样本集中随机子选择网络攻击事件，并构建一个包含比恶意连接更多的正常网络连接的新训练集。使用这个子采样数据集，我们将使用PCA构建一个异常检测模型。然后，我们将通过查看不同目标误报率下的网络攻击检测率来评估这个模型。
- en: 'To summarize our problem definition for the cyber attack detection project:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结我们的网络攻击检测项目的问题定义：
- en: What is the problem? We need a cyber attack detection model that can identify
    potential malicious connections from large amounts of network connections so that
    we can avoid cyber attacks.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题是什么？我们需要一个能够从大量网络连接中识别潜在恶意连接的网络攻击检测模型，以便我们可以避免网络攻击。
- en: Why is it a problem? The number of cyber attacks increases every year and without
    being properly prepared for such attacks, our systems will become more vulnerable
    from various cyber attacks. With a cyber attack detection model, we can avoid
    becoming the victims of cyber attacks.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么这是一个问题？每年网络攻击的数量都在增加，如果没有为这种攻击做好准备，我们的系统将更容易受到各种网络攻击的侵害。有了网络攻击检测模型，我们可以避免成为网络攻击的受害者。
- en: What are some of the approaches to solving this problem? We are going to use
    publicly available data that has a large amount of artificial and simulated cyber
    attack data. We are going to sub-sample this data to replicate a real-life situation
    where there are more normal network connections than abnormal and malicious connections.
    Then, we are going to use PCA and its principal components to detect anomalies.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the success criteria? We want a high cyber attack detection rate, even
    if we need to sacrifice it for higher false alarm rate. This is because we are
    more concerned about allowing cyber attacks than false positive alerts.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analysis for internet traffic data
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start by taking a look into the internet traffic data. As mentioned previously,
    we are going to use the KDD Cup 1999 Data, which you can download from the following
    link: [http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).
    We will be using the `kddcup.data_10_percent.gz` data for this cyber attack detection
    project.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Data clean-up
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we need to do is clean up the data for future steps. If you
    open the data that you just downloaded, you will notice that there is no header
    in the dataset. However, for future data analysis and model building, it is always
    beneficial to have headers associated with each column. Based on the column description
    that can be found at [http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names](http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names),
    we are going to attach headers to the raw dataset. The code to attach column names
    to the data frame looks as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'As you can see from this code, we are loading this raw dataset without headers,
    by supplying the `hasHeaders: false` flag to the `ReadCsv` method of Deedle''s
    data frame. By supplying this flag, we are telling Deedle not to take the first
    row of the dataset as the header. Once this data is loaded into a data frame,
    we are using the `RenameColumns` method to attach the names of the columns to
    the data frame.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: 'The next clean-up task we are going to take is to group the cyber attack types
    together by corresponding categories. You can find the mapping between the attack
    type and the category at the following link: [http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types](http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types).
    Using this mapping, we are going to create a new column in the data frame that
    contains information about the attack category. Let''s look at the code first:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you look closely at this code, we created a `Dictionary` object that has
    mapping between an attack type and its category. For example, the attack type,
    `"back"`, is one of the **Denial-of-Service** (**DOS**) attacks and the attack
    type, `"rootkit"`, is one of the **User-to-Root** (**U2R**) attacks. Using this
    mapping, we created a new column, `"attack_category"`, and added it to the `featuresDF`.
    Now that we have cleaned the raw dataset with column names and attack categories,
    we need to export it and store it into our local drive for future use. You can
    use the following code to export this data:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Target variable distribution
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have clean data to work with, we will start digging into the data.
    Let''s first look at the distributions of cyber attack categories. The code to
    get the distribution of target variables looks as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Similar to the previous chapters, we are using the `AggregateRowsBy` method
    in Deedle''s data frame to group by the target variable, `attack_category`, and
    count the number of occurrences per category in the dataset. Then, we use the
    `DataBarBox` class to display a bar chart of this distribution. Once you run this
    code, the following bar chart will be displayed:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00141.jpeg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
- en: 'And the output that shows us the number of occurrences of each cyber attack
    category looks as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00142.jpeg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: There is one thing that is noticeable here. There are more DOS attack samples
    than normal samples in the dataset. As mentioned previously, the KDD Cup 1999
    dataset that we are using for this project is artificial and simulated data, and
    thus, it does not reflect a real-life situation, where the number of normal internet
    connections will outnumber the number of all the other cyber attacks combined.
    We will have to keep this in mind when building models in the following sections.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Categorical variable distribution
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The features that we have in this dataset are a mixture of categorical and continuous
    variables. For example, the feature named `duration`, which represents the length
    of the connection, is a continuous variable. However, the feature, named `protocol_type`,
    which represents the type of the protocol, such as `tcp`, `udp`, and so forth,
    is a categorical variable. For a complete set of feature descriptions, you can
    go to this link: [http://kdd.ics.uci.edu/databases/kddcup99/task.html](http://kdd.ics.uci.edu/databases/kddcup99/task.html).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we are going to take a look at the distribution differences
    in the categorical variables between the normal connections and the malicious
    connections. The following code shows how we separate the sample set into two
    subgroups, one for normal connections and another for abnormal connections:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now that we have these two subsets, let''s start comparing the distributions
    of categorical variables between normal and malicious connections. Let''s first
    take a look at the code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this code, we are iterating through an array of categorical variables: `protocol_type`,
    `service`, `flag`, and `land`. We will defer the feature descriptions to the description
    page that can be found at the following link: [http://kdd.ics.uci.edu/databases/kddcup99/task.html](http://kdd.ics.uci.edu/databases/kddcup99/task.html).
    For each categorical variable, we used the `AggregateRowsBy` method to group by
    each type of the variable and count the number of occurrences for each type. We
    do this aggregation once for the normal group and then once more for the attack
    group. Then, we use the `DataBarBox` class to display bar charts to visually show
    the differences in the distributions. Let''s take a look at a few plots and outputs.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'The following bar chart is for the `protocol_type` feature:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00143.jpeg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: 'The actual counts per type between the two groups look as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00144.jpeg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: As you can see from these outputs, there are some noticeable distinctions between
    the distributions of normal and cyber attack groups. For example, the majority
    of attacks happen on `icmp` and `tcp` protocols, while the majority of normal
    connections are on `tcp` and `udp`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'The following bar chart is for the `land` feature:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00145.jpeg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: 'The actual counts for each type in this feature look as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00146.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: It is quite hard to tell if we can deduce any meaningful insights from these
    outputs. Almost all samples in the dataset have a value of `0` for both the attack
    and normal groups. Let's take a look at one more feature.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'The following bar chart shows the distributions of the feature `flag` in attack
    and normal groups:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00147.jpeg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: 'And the actual counts look as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00148.jpeg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: There are some noticeable distinctions in this feature, even though the most
    frequently appearing flag type for both attack and normal groups is `SF`. It seems
    the flag types `SF` and `REJ` take up the majority of the normal group. On the
    other hand, the flag types `SF`, `S0`, and `REJ` take up the majority of the attack
    group.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Continuous variable distribution
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we have looked at the distributions of categorical variables. Let''s
    now look at the distributions of continuous variables in our feature set. Similar
    to the previous chapters, we are going to look at the quartiles for each continuous
    variable. The code to compute quartiles for each continuous feature looks as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And the variable, `continuousVars`, is defined as the following array of strings:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Similar to what we did for categorical variable analysis, we start iterating
    through the continuous variables in the preceding code. The string array, `continuousVars`,
    contains a list of all the continuous features we have in our dataset, and we
    iterate through this array to start computing the quartiles of each distribution.
    As in the previous chapters, we are using the `Accord.Statistics.Measures.Quantiles`
    method to compute quartiles, which are min, 25% percentile, median, 75% percentile,
    and max numbers. We do this twice, once for the attack group and another time
    for the normal group, so that we can see if there are any noticeable differences
    in the distributions. Let's take a look at a few features and their distributions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前进行分类变量分析所做的一样，我们开始遍历前述代码中的连续变量。字符串数组`continuousVars`包含了我们数据集中所有连续特征的列表，我们遍历这个数组以开始计算每个分布的四分位数。正如前几章所述，我们使用`Accord.Statistics.Measures.Quantiles`方法来计算四分位数，这些四分位数包括最小值、25%分位数、中位数、75%分位数和最大值。我们进行了两次计算，一次针对攻击组，另一次针对正常组，这样我们可以看到分布之间是否存在任何明显的差异。让我们看看一些特征及其分布。
- en: 'First, the following output is for the distribution of a feature called `duration`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，以下输出是针对一个名为`duration`的特征的分布：
- en: '![](img/00149.jpeg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00149.jpeg)'
- en: From this output, we can see that the majority of the values for this feature
    are `0` for both attack and normal groups. As there is not so much variance in
    this variable, our model might not learn much information from this feature. Let's
    take a look at another feature.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中，我们可以看到这个特征的攻击组和正常组的值大多数都是`0`。由于这个变量的方差不大，我们的模型可能不会从这个特征中学习到很多信息。让我们看看另一个特征。
- en: 'The following output is for the distribution of a feature called `dst_bytes`,
    which represents the number of data bytes from destination to source:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出是针对一个名为`dst_bytes`的特征的分布，它表示从目标到源的数据字节数：
- en: '![](img/00150.jpeg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00150.jpeg)'
- en: Here, we see some noticeable distinctions in the distributions between the attack
    and normal groups. Almost all the cyber attacks have a value of 0, while the values
    are distributed across a wide range for the normal network connections.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到攻击组和正常组之间分布的一些明显区别。几乎所有的网络攻击都有一个值为0，而正常网络连接的值分布在一个很宽的范围内。
- en: 'Lastly, the following output is for a feature called `wrong_fragment`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，以下输出是针对一个名为`wrong_fragment`的特征：
- en: '![](img/00151.jpeg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00151.jpeg)'
- en: Similar to the case of the `duration` feature, the majority of the values are
    `0` for both the attack and normal group, which suggests that our model might
    not learn many insights from this feature. You can run the previous code to look
    at the distribution differences between the two groups for all the other features.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 与`duration`特征的情况类似，攻击组和正常组的值大多数都是`0`，这表明我们的模型可能不会从这个特征中学习到很多见解。你可以运行之前的代码来查看其他所有特征的两组之间的分布差异。
- en: The full code to run this data analysis step can be found at this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/DataAnalyzer.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/DataAnalyzer.cs).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个数据分析步骤的完整代码可以在以下链接找到：[https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/DataAnalyzer.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/DataAnalyzer.cs)。
- en: Feature engineering and PCA
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程和PCA
- en: So far, we have analyzed the distributions of the target variable `attack_category`,
    as well as the categorical and continuous variables in the cyber attack dataset.
    In this section, we are going to focus on encoding the target variable and categorical
    features, and creating PCA features for our future model-building step.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经分析了目标变量`attack_category`的分布，以及网络攻击数据集中的分类和连续变量。在本节中，我们将专注于对目标变量和分类特征进行编码，并为我们的未来模型构建步骤创建PCA特征。
- en: Target and categorical variables encoding
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标和分类变量编码
- en: 'First, we will have to encode different classes in the target variable, `attack_category`.
    If you recall from the previous data analysis step, there are five different categories:
    normal, `dos`, `probe`, `r2l`, and `u2r`. We are going to encode each of these
    string values with a corresponding integer representation. Then, we are going
    to encode each of the categorical variables with one-hot encoding, where we encode
    with 1 if the given value appears in the example, and 0 if not. Let''s first load
    the cleaned-up data that we created in the previous data analysis step, using
    the following code:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须对目标变量`attack_category`中的不同类别进行编码。如果你还记得从上一个数据分析步骤，有五个不同的类别：normal、`dos`、`probe`、`r2l`和`u2r`。我们将用相应的整数表示来对这些字符串值进行编码。然后，我们将使用独热编码对每个分类变量进行编码，其中如果给定的值出现在示例中，我们用`1`进行编码，如果没有，则用`0`进行编码。让我们首先使用以下代码加载我们在上一个数据分析步骤中创建的清理后的数据：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'As you can see from this code, we set `hasHeaders: true`, as the cleaned-up
    data now has correct headers associated with each of the columns. The following
    code shows how we went about encoding the target and categorical variables:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '如此代码所示，我们设置了`hasHeaders: true`，因为清理后的数据现在与每个列都有正确的标题关联。以下代码显示了我们是如何对目标和分类变量进行编码的：'
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s take a deeper look at this code. We first created a string array variable, `categoricalVars`,
    which contains the column names of all the categorical variables, and a dictionary
    variable, `targetVarEncoding`, which maps each target class to an integer value.
    For example, we are encoding the `normal` class as `0`, the `dos` attack class
    as `1`, and so forth. Then, we iterate through all the columns in the `rawDF` data
    frame and start adding encoded data to the new and empty `featuresDF`. One thing
    to note here is that we use a helper function, `EncodeOneHot`, for encoding each
    of the categorical variables. Let''s take a look at the following code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地看看这段代码。我们首先创建了一个字符串数组变量`categoricalVars`，它包含所有分类变量的列名，以及一个字典变量`targetVarEncoding`，它将每个目标类别映射到一个整数值。例如，我们将`normal`类别编码为`0`，将`dos`攻击类别编码为`1`，依此类推。然后，我们遍历`rawDF`数据框中的所有列，并将编码后的数据添加到新的空`featuresDF`中。这里需要注意的是，我们使用了一个辅助函数`EncodeOneHot`来对每个分类变量进行编码。让我们看看以下代码：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you recall [Chapter 2](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470), *Spam
    Email Filtering* and [Chapter 3](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470), *Twitter
    Sentiment Analysis*, this code should look familiar. In this code, we iterate
    through each row, create a new variable that is a combination of the original
    column name and the value, and finally create a new Deedle data frame, `categoriesDF`.
    Once this step is done, this data frame output gets appended to the `featuresDF`
    in the previous code.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得[第2章](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470)，“垃圾邮件过滤”和[第3章](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470)，“Twitter情感分析”，这段代码应该看起来很熟悉。在这段代码中，我们遍历每一行，创建一个新的变量，它是原始列名和值的组合，最后创建一个新的Deedle数据框，`categoriesDF`。一旦完成这一步，这个数据框的输出就会被附加到前一个代码中的`featuresDF`。
- en: 'Now that we are done with encoding the target and categorical variables, we
    will need to export and store this new data frame, `featuresDF`. We are using
    the following code to store this data:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了目标和分类变量的编码，我们需要导出并存储这个新的数据框`featuresDF`。我们使用以下代码来存储这个数据：
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Fitting PCA
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 适配PCA
- en: With the encoded data we just created in the previous section, let's start building
    PCA features that we are going to use for the anomaly detection in the following
    model-building step.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们在上一节中创建的编码数据，让我们开始构建PCA特征，这些特征将在接下来的模型构建步骤中用于异常检测。
- en: The first thing we need to do is separate our sample set into two separate sets—one
    with normal connection data and another with malicious connections. While we create
    these subsets, we need to create more realistic distributions between the two
    groups. If you recall from the previous data analysis step, we noticed that there
    are more malicious connections than normal connections, which is unrealistic,
    due to the fact that the KDD CUP 1999 Dataset is an artificial and hand-injected
    dataset. Aside from the purpose of creating a dataset with a more realistic number
    of normal and malicious connections, we need to create the two subsets so that
    we can apply PCA to the normal group only, and then apply it to the abnormal group.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: This is because we want to learn and build principal components only from the
    normal connections group, and be able to flag any outliers as potential cyber
    attacks. We will discuss more in detail about how we are going to build an anomaly
    detection model using principal components.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following code for splitting our sample set into
    two groups—one for the normal group and another for the cyber attack group:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As you can see from this code, we are building arrays of indexes for the normal
    and cyber attack groups by filtering for whether the `attack_category` is `0`
    (normal) or greater than 0 (cyber attacks). Then, we randomly select 90,000 samples
    from the normal connections and 10,000 samples from the malicious connections.
    Now that we have the indexes for the normal and abnormal groups, we are going
    to use the following code to build the actual data for fitting PCA:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As you can see from this code, the `normalData` variable contains all the normal
    connection samples and the `wholeData` variable contains both the normal and cyber
    attack connection samples. We will be using `normalData` to fit PCA, and then
    apply this learned PCA to the `wholeData`, as you can see from the following code:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As in [Chapter 8](part0097.html#2SG6I0-5ebdf09927b7492888e31e8436526470), *Handwritten
    Digit Recognition*, we are using the `PrincipalComponentAnalysis` class in the
    Accord.NET framework to fit PCA. Once we have trained PCA with the normal connections
    data, we apply it to the `wholeData` that contains both normal and cyber attack
    connections by using the `Transform` method of the `pca` object.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: PCA features
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have now built principal components using just the normal connections group.
    Let''s briefly inspect how well our target classes are separated on different
    combinations of principal components. Take a look at the following code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see from this code, we are building scatter plots between two principal
    components at a time, for the first six components. When you run this code, you
    will see plots similar to the following ones.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'The first plot is between the first and second principal components, and looks
    as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00152.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: The blue dots represent the normal connections, and the other dots with different
    colors represent the cyber attacks. We can see some distinctions in the distributions
    among different classes, but the pattern does not seem so strong.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot is between the second and third components:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00153.jpeg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
- en: 'Lastly, the following plot is between the third and fourth components:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00154.jpeg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: We cannot really see many distinctions among different classes in the last plot. Although
    the pattern does not seem very strong, previous scatter plots show some differences
    in the distributions. It is especially more difficult to visually see the distinctions
    on two-dimensional plots. If we take this to higher-dimensional space, which our
    anomaly detection model is going to be looking at, the differences in the patterns
    will become more noticeable.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now look at the amount of variance explained from the principal components.
    The following code shows how we can get the cumulative proportion of variances
    explained, and display it in a line chart:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If you look at this code more closely, the `Components` property in the `pca`
    object contains information about the proportion of variance explained. We can
    iterate through each component and get the cumulative proportion by using the
    `CumulativeProportion` property. Once we have extracted these values, we then
    use the `DataSeriesBox` class to display a line chart that shows the cumulative
    proportion of variance explained. The output looks like the following:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00155.jpeg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: 'Now, we have successfully created PCA features and have full PCA-transformed
    data. You can use the following code to export this data:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The full code for the feature engineering step can be found at this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/FeatureEngineering.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/FeatureEngineering.cs).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Principal component classifier for anomaly detection
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have compiled everything and are now ready to start building an anomaly detection
    model for the cyber attack detection project. As mentioned previously, we are
    going to use the data of the distributions of principal components from the normal
    connections group, and take it as the normal ranges of principal components. For
    any records that deviate from these normal ranges of the principal component values,
    we are going to flag them as abnormal and potential cyber attacks.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Preparation for training
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let''s load the features data that we created from the feature engineering
    step. You can use the following code to load the PCA-transformed data and the
    labels data:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s quickly look at the distributions of our target classes. The code to
    count by each target class is as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Once you run this code, you will see the following output:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00156.jpeg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
- en: As expected, the majority of the samples belong to the 0 class, which is the
    normal group, and the rest combined are the minority (about 10%) in our sample
    set. This is a more realistic view of cyber attacks. Cyber attacks happen way
    less frequently than normal connections.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'For illustration purposes, we are going to use the first `27` principal components
    that explain about 70% of the overall variance in the dataset. You can experiment
    with different numbers of principal components and see how model performances
    change. The following code shows how we created a training set using the first
    `27` principal components:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: If you look at this code closely, you will notice that we are creating `normalDF`
    and `normalData` variables with normal connection samples only. As mentioned previously,
    we want to learn only from the normal data, so that we can flag any outliers and
    extreme deviations from the normal ranges of principal components. We are going
    to use these variables to build a principal component classifier for the cyber
    attack detection in the following section.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Building a principal component classifier
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to build a principal component classifier, which will flag those events
    that deviate from the normal connections, we need to calculate the distance between
    a record and the distributions of normal connections. We are going to use a distance
    metric, the **Mahalanobis distance**, which measures the distance between a point
    and a distribution. For the standardized principal components, like those here,
    the equation to compute the **Mahalanobis distance** is as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00157.jpeg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: '*C[i]* in this equation represents the value of each principal component, and
    *var[i]* represents the variance of each principal component. Let''s take a look
    at the following example:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00158.jpeg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: 'Assume you have 5 principal components with values as shown in this image and
    assume the variance for each principal is 1 for simplicity and demonstration purposes,
    then you can compute the **Mahalanobis distance** as the following:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00159.jpeg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
- en: And the computed **Mahalanobis distance** for this example is 0.64\. For a more
    detailed description of this distance metric, it is recommended that you review
    the following Wikipedia page: [https://en.wikipedia.org/wiki/Mahalanobis_distance](https://en.wikipedia.org/wiki/Mahalanobis_distance),
    or the following research paper: [https://users.cs.fiu.edu/~chens/PDF/ICDM03_WS.pdf](https://users.cs.fiu.edu/~chens/PDF/ICDM03_WS.pdf).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'We implemented the Mahalanobis distance equation as a helper function, `ComputeDistances`,
    and it looks as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now that we have computed the distances of individual records, let''s analyze
    how the ranges for the normal connections look. We used the following code to
    calculate the mean and standard deviation of the distances, and a histogram to
    visualize the overall distance distributions:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'When you run this code, you will see the following output for the mean and
    standard deviation of the distance metrics for normal connections:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00160.jpeg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: 'And the histogram looks as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00161.jpeg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
- en: As you can see from these outputs, the majority of the distances are very small,
    which suggests that the non-attack and normal connections are typically clustered
    together closely. With this information about the distance distributions within
    the normal connections group, let's start looking to see if we can build a detection
    model by flagging certain network connections that go beyond the normal range
    of distances.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how we computed the distances of cyber attack connections
    from the distribution of normal network connections:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As you can see from this code, we first created a variable, called `attackData`,
    which contains all the cyber attack connections from our training set. Then, we
    used the `ComputeDistances` method to calculate the distances of individual records
    in the cyber attack connections group.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are ready to start flagging suspicious network connections based on
    the distance metrics that we just calculated. Let''s take a look at the following
    code first:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As you can see from this code, we decide the threshold based on the distribution
    of distances within the normal connections group. For example, if our target is
    to have a 5% false alarm rate, we flag all the connections that have distances
    from the normal range greater than the 95% percentile of the distribution of distances
    within the normal connections group. More specifically, the 95% percentile of
    the normal connections' distance distribution in our case was 5.45\. So, in this
    case, we will flag all the connections that have distances from the normal range
    greater than 5.45 as cyber attacks. We repeat this process for the false alarm
    rates from 5% to 10%. We will discuss the performance of this anomaly detection
    model in more detail in the following model-evaluation step.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: The full code for the model-building step can be found at this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/Modeling.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.9/Modeling.cs).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating anomaly detection models
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We built an anomaly detection model for cyber attacks in the previous model-building
    step. In the previous code, you might have noticed that we are using a function
    named `EvaluateResults`. It is a helper function that we wrote for evaluating
    model performances. Let''s take a look at the following code:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'As you can see from this code, we are interested in two metrics: overall cyber
    attack detection rate and per-class detection rate. The evaluation results look
    as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00162.jpeg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
- en: The overall results look good with over 99% detection rates. At 5% false alarm
    rate, about 99.1% of the cyber attacks are detected. However, if we look closer
    at the per-class detection rates, we can see their weaknesses and strengths. At
    5% false alarm rate, our model does very well for detecting classes 1 and 2, which
    are `dos` and `probe` attacks. On the other hand, our model does poorly in detecting
    classes 3 and 4, which are `r2l` and `u2r` attacks. As you can see from this output,
    as we increase the target false alarm rates, the overall and per-class detection
    rates increase as well. In a real-world situation, you will have to evaluate the
    trade-offs between a higher detection rate and a higher false alarm rate, and
    make a decision on the target false alarm rate that meets your business requirements.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we built our very first anomaly detection model that can detect
    cyber attacks. At the beginning of this chapter, we discussed how this type of
    anomaly detection model can be used and applied to real-life situations, and how
    developing an anomaly detection model is different from other ML models that we
    have built so far. Then, we started analyzing the distributions of target classes
    and various features to understand the dataset better. While we were analyzing
    this dataset, we also noticed how there are more cyber attack samples than normal
    connection samples, which is unrealistic in real life. In order to simulate real-life
    situations, where abnormal malicious connections occur much less frequently than
    normal connections, we randomly sub-selected the normal and malicious connection
    samples so that 90% of the training set were normal connections and only 10% were
    cyber attack examples.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: With this sub-selected training set, we applied PCA to the normal connections
    data to find out the normal ranges of principal components. Using the **Mahalanobis
    distance** metric, we computed the distances between individual records from the
    distributions of normal connections. During the model-building step, we experimented
    with different thresholds based on the target false alarm rates. Using 5% to 10%
    false alarm rates, we built cyber attack detection models and evaluated their
    performance. In our model-evaluation step, we noticed that the overall detection
    rates were over 99%, while a closer look at per-attack detection rates exposed
    the weaknesses and strengths of the models. We also noticed that as we sacrifice
    and increase the false alarm rates, the overall cyber attack detection rates improved.
    When applying this anomaly detection technique, it becomes necessary to understand
    this tradeoff between the false alarm rate and detection rate, and make a decision
    based on pertinent business requirements.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to expand our knowledge and experience in
    building anomaly detection models. We are going to work on a credit card fraud
    detection project with a credit card dataset. On top of the PCA-based anomaly
    detection model, we are going to discuss how to use a one-class support vector
    machine for anomaly detection.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
