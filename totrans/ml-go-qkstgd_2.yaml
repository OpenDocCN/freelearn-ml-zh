- en: Setting Up the Development Environment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like traditional software development, ML application development requires
    the mastery of specialist boilerplate code and a development environment that
    allows the developer to proceed at a pace that has the lowest amount of friction
    and distraction. Software developers typically waste a lot of time with basic
    setup and data wrangling tasks. Being a productive and professional ML developer
    requires the ability to quickly prototype solutions; this means expending as little
    effort as possible on trivial tasks.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we outlined the main ML problems and a development
    process that you can follow to obtain a commercial solution. We also explained
    the advantages offered by Go as a programming language when creating ML applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will guide you through the steps that are required to set
    up a development environment for Go that is optimized for ML applications. Specifically,
    we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: How to install Go
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Go interactively using Jupyter and gophernotes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data wrangling with Gota
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data visualization with gonum/plot and gophernotes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preprocessing (formatting, cleaning, and sampling)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data transformation (normalization and encoding of categorical variables)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code examples that accompany this book are optimized for Debian-based Linux
    distributions. However, they can be adapted for other distributions (for example,
    by changing `apt` to `yum`) and Windows with Cygwin.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Once you have completed this chapter, you will be able to quickly explore, visualize,
    and process any dataset for subsequent use by an ML algorithm.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Installing Go
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Development environments are personal. Most developers will prefer one code
    editor or toolset over another. While we recommend the use of interactive tools
    such as Jupyter via gophernotes, the only prerequisite to running the code examples
    in this book is a working installation of Go 1.10 or higher. That is, the `go`
    command should be available and the `GOPATH` environment variable should be set
    up correctly.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: To install Go, download a binary release for your system from [https://golang.org/dl/](https://golang.org/dl/).
    Then, refer to the one of the following subsections that matches your operating
    system^([2]).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: If you only want to use gophernotes to run Go code and you intend to use Docker
    as the installation method, then you can skip this section and go straight to
    the *Running Go interactively with gophernotes* section.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Linux, macOS, and FreeBSD
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The binary releases are packaged as tarballs. Extract the binaries and add
    them to your `PATH`. Here''s an example:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To configure your `GOPATH` environment variable, you will need to decide where
    you will want your Go files, including any personal repositories, to live. One
    possible location is `$HOME/go`. Once you have decided on this, set the environment
    variable, for example as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To make this instruction permanent, you will need to add this line to `.bashrc`.
    For instructions if you're using other shells (such as `.zsh`), please refer to
    the official Go installation instructions at [https://github.com/golang/go/wiki/SettingGOPATH](https://github.com/golang/go/wiki/SettingGOPATH).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that your `GOPATH` is not in the same directory as your Go installation,
    otherwise this can cause issues.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Windows
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The binary releases are packaged either as a ZIP file or an MSI installer that
    automatically configures your environment variables. We recommend using the MSI
    installer. However, if you do not, then after extracting the contents of the ZIP
    file to a suitable location (such as `C:\Program Files\Go`), make sure that you
    add the `subdirectory` bin to your `PATH` environment variable using the control
    panel.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Once the binaries have been installed to a suitable location, you will need
    to configure your `GOPATH`. First, decide where you want your Go files, including
    any personal repositories, to live. One possible location is `C:\go`. Once you
    have decided, set the `GOPATH` environment variable to the path of this directory.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: If you are unsure how to set environment variables, refer to the official Go
    installation instructions at [https://github.com/golang/go/wiki/SettingGOPATH](https://github.com/golang/go/wiki/SettingGOPATH).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that your `GOPATH` is not in the same directory as your Go installation,
    otherwise this can cause issues.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Running Go interactively with gophernotes
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Project Jupyter is a not-for-profit organization that was created to develop
    language-agnostic interactive computing for data science^([3]). The result is
    a mature, well-supported environment to explore, visualize, and process data that
    can significantly accelerate development by providing immediate feedback and integrations
    with plotting libraries such as `gonum`/`plot`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: While its first iteration, called iPython, only supported Python-based handlers
    (called *kernels*) at first, the latest version of Jupyter has over 50 kernels
    that support dozens of languages, including three kernels for the Go language^([4]).
    GitHub has support for rendering Jupyter files (called *notebooks*)^([5]), and
    there are various specialized hubs for sharing notebooks online, including Google
    Research Colabs^([6]), Jupyter's community hub called NBViewer^([7]), and its
    enterprise offering, JupyterHub^([8]). Notebooks for presentation purposes can
    be converted into other file formats such as HTML using the nbconvert utility^([9]).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will be using Jupyter together with the gophernotes kernel
    for Go. The simplest way to get started with gophernotes on Linux and Windows
    is to use its Docker^([10]) image.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'For alternative installation methods, we recommend checking the README page
    of the gophernotes GitHub repository at:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/gopherdata/gophernotes](https://github.com/gopherdata/gophernotes).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps to begin a new gophernotes-based project are as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Create a new directory to hold the project files (this does not need to be in
    your `GOPATH`).
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Optional) Initialize a new git repository by running `git init` in the new
    directory.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the following command from the new directory (you may need to prefix it
    with `sudo`, depending on how you installed Docker):'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`docker run -it -p 8888:8888 -v $(pwd):/usr/share/notebooks gopherdata/gophernotes:latest-ds`'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the terminal, there will be a URL ending in `?token=[some combination of
    letters and numbers]`. Navigate to this URL in a modern web browser. The new directory
    you created will be mapped to `/usr/share/notebooks`, so navigate to this directory
    in the tree that presents itself.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On Windows, you may need to modify the preceding command by replacing `$(pwd)`
    with `%CD%`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have learned how to install Go and set up a basic development environment
    with gophernotes, it's time to learn about data preprocessing.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Example – the most common phrases in positive and negative reviews
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our first code example, we will use the multi-domain sentiment dataset (version
    2.0)^([11]). This dataset contains Amazon reviews from four different product
    categories. We will download it, preprocess it, and load it into Gota, a data
    wrangling library, to find the most common phrases in positive and negative reviews
    that do not co-occur in both. This is a basic example that involves no ML algorithms,
    but will serve as a hands-on introduction to Go, gophernotes, and Gota.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: You can find the full code example in the companion repository to this book
    at [https://github.com/PacktPublishing/Machine-Learning-with-Go-Quick-Start-Guide](https://github.com/PacktPublishing/Machine-Learning-with-Go-Quick-Start-Guide).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the example directory and downloading the dataset
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Following the process we implemented previously, create an empty directory
    to hold the code files. Before opening gophernotes, download the dataset from [http://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_acl.tar.gz](http://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_acl.tar.gz)
    and extract it to `datasets/words`. On most Linux distributions, you can do this
    with the following script:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, start gophernotes and navigate the tree to `/usr/share/notebooks`. Create
    a new Notebook by clicking on *New* | *Go*. You will see a blank Jupyter Notebook:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d688d626-95d1-4552-a14b-8d7287e0f1df.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: Input cells in Jupyter are marked with the `In` label. When you run the code
    in an input cell (*Shift* + *Enter*), a new output cell will be created with the
    result, marked as `Out`. Each cell is numbered with its execution order. For example,
    the `In [1]` cell is the first cell you ran within a given session.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'Try running some Go statements, like the following snippet:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In particular, note that the `a` variable is displayed in the output cell, even
    though there was no call to `fmt.Println()`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: All the imports, variables, and funcs you define within a session remain in
    memory, even if you delete the input cells. To clear the current scope, go to
    Kernel | Restart.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个会话中定义的所有导入、变量和函数都将保留在内存中，即使你删除了输入单元格。要清除当前作用域，请转到内核 | 重新启动。
- en: Loading the dataset files
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据集文件
- en: 'One of the basic tasks of data processing is to read the input file and load
    its contents. A simple way to do this is to use the `io/ioutil` utility func `ReadFile`.
    Unlike in a `.go` file, where you would need to place this code inside your `main` func,
    with gophernotes, you can run the following code without declaring any func at
    all:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理的基本任务之一是读取输入文件并加载其内容。完成此任务的一种简单方法是使用 `io/ioutil` 工具函数 `ReadFile`。与 `.go`
    文件不同，在 `.go` 文件中你需要将此代码放在你的 `main` 函数内部，使用 gophernotes，你可以运行以下代码而不需要声明任何函数：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The preceding code will load the contents of reviews of kitchen products with
    positive sentiments into a byte slice called `positives` and the ones with negative
    sentiments into the byte slice called `negatives`. If you have correctly downloaded
    the datasets and you run this code, it should not output anything because there
    are no errors. If any errors appear, check that the dataset files have been extracted
    to the correct folder.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将把具有积极情感的厨房产品评论内容加载到名为 `positives` 的字节切片中，将具有消极情感的评论内容加载到名为 `negatives`
    的字节切片中。如果你已正确下载数据集并运行此代码，它不应该输出任何内容，因为没有错误。如果有任何错误出现，请检查数据集文件是否已提取到正确的文件夹。
- en: 'If you have opened the `positive.review` or `negative.review` file in a text
    editor, you may have noticed that they are formatted as a space or newline separated
    list of pairs, that is, `phrase:frequency`. For example, the start of the positive
    review is as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经在文本编辑器中打开了 `positive.review` 或 `negative.review` 文件，你可能已经注意到它们是以空格或换行符分隔的对列表，即
    `phrase:frequency`。例如，积极评论的开始如下：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the next subsection, we will parse these pairs into a Go struct.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将解析这些对到 Go 结构体中。
- en: Parsing contents into a Struct
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将内容解析到结构体中
- en: 'We will use the `strings` package to parse the contents of the data files into
    slices of pairs. Each item in the slice of strings will contain a single pair,
    such as `them_it:1`. We will then further split this pair by the colon symbol
    and use the `strconv` package to parse the integer frequency into an `int`. Each
    `Pair` will be of the following type:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `strings` 包将数据文件的 内容解析成对数组的切片。字符串切片中的每个项目将包含一个对，例如 `them_it:1`。然后我们将进一步通过冒号符号分割这个对，并使用
    `strconv` 包将整数频率解析为 `int`。每个 `Pair` 将是以下类型：
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We will do this as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按以下方式操作：
- en: 'First, observe that the separation between the pairs can be either a new line
    (`\n`) or a space. We will use the `strings.Fields` func of the strings package,
    which will split the string by any consecutive whitespace characters:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，观察这些对之间的分隔可以是换行符 (`\n`) 或空格。我们将使用字符串包中的 `strings.Fields` 函数，该函数将字符串按任何连续的空白字符分割：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, we will iterate each pair, splitting by the colon separator and using
    the `strconv` package to parse the frequency to an integer:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将迭代每个对，通过冒号分隔符分割，并使用 `strconv` 包将频率解析为整数：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will also return a map of phrases so that we can later exclude phrases that
    are in the intersection between positive and negative reviews. The reason for
    doing this is that words that are common to both positive and negative reviews
    are less likely to be indicative of the positive or negative sentiment. This is
    done with the following function:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将返回一个短语映射，以便我们可以在以后排除正负评论交集中的短语。这样做的原因是，正负评论中共同出现的单词不太可能是积极或消极情感的特征。这是通过以下函数完成的：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we will apply this to our slices of pairs:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将此应用于我们的对数组切片：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The next step is to load the parsed pairs into Gota, the data wrangling library
    for Go.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将解析好的对加载到 Gota 中，这是 Go 的数据处理库。
- en: Loading the data into a Gota dataframe
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据加载到 Gota 数据框中
- en: The Gota library contains implementation of dataframes, series, and some general
    data wrangling algorithms^([12]). The concept of a dataframe is integral to a
    number of popular data science libraries and languages such as Python's pandas,
    R, and Julia. In a nutshell, a **dataframe** is a list of lists (called a **column**
    or **series**) that each have the same length. Every list has a name—the column
    name or series name, depending on the nomenclature favored by the library. This
    abstraction mimics a database table and makes an easy fundamental building block
    for mathematical and statistical tools.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Gota 库包含数据框、系列和一些通用数据处理算法的实现^([12])。数据框的概念对于许多流行的数据科学库和语言（如 Python 的 pandas、R
    和 Julia）至关重要。简而言之，**数据框**是一系列列表（称为**列**或**系列**），每个列表的长度都相同。每个列表都有一个名称——列名或系列名，具体取决于库所采用的命名法。这种抽象模仿了数据库表，并成为数学和统计工具的简单基本构建块。
- en: 'The Gota library has two packages: the `dataframe` and the `series` packages.
    The series package contains functions and structures to represent individual lists,
    whereas the `dataframe` package deals with the entire dataframe—that is, the table—as
    a whole. A Go developer may wish to use Gota to quickly sort, filter, aggregate,
    or perform relational operations, such as inner joins between two tables, saving
    on boilerplate code such as implementing a `sort` interface^([13]).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Gota 库包含两个包：`dataframe` 和 `series` 包。`series` 包包含表示单个列表的函数和结构，而 `dataframe`
    包处理整个数据框——即整个表格——作为一个整体。Go 开发者可能希望使用 Gota 来快速排序、过滤、聚合或执行关系操作，例如两个表之间的内连接，从而节省实现
    `sort` 接口等样板代码^([13])。
- en: 'There are several ways to create a new dataframe with Gota:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Gota 创建新的数据框有几种方法：
- en: '`dataframe.New(se ...series.Series)`: Accepts a slice of series (which can
    be created via the `series.New` func).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataframe.New(se ...series.Series)`: 接受一个系列切片（可以通过 `series.New` 函数创建）。'
- en: '`dataframe.LoadRecords(records [][]string, options ...LoadOption)`: Accepts
    a slice of slices. The first slice will be a slice of strings representing the
    column names.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataframe.LoadRecords(records [][]string, options ...LoadOption)`: 接受一个字符串切片的切片。第一个切片将是一个表示列名的字符串切片。'
- en: '`dataframe.LoadStructs(i interface{}, options ...LoadOption)`: Accepts a slice
    of structs. Gota will use reflection to determine the column names based on the
    struct field names.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataframe.LoadStructs(i interface{}, options ...LoadOption)`: 接受一个结构体的切片。Gota
    将使用反射根据结构体字段名称来确定列名。'
- en: '`dataframe.LoadMaps(maps []map[string][]interface{})`: Accepts a slice of maps
    of column names to slices.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataframe.LoadMaps(maps []map[string][]interface{})`: 接受一个列名到切片映射的切片。'
- en: '`dataframe.LoadMatrix(mat Matrix)`: Accepts a slice that is compatible with
    the mat64 matrix interface.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataframe.LoadMatrix(mat Matrix)`: 接受与 mat64 矩阵接口兼容的切片。'
- en: 'In our case, because we have parsed the data into structs, we will use the
    `LoadStructs` function, making one dataframe for positive reviews and one for
    negative reviews:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，因为我们已经将数据解析到结构体中，我们将使用 `LoadStructs` 函数，为正面评论和负面评论创建一个数据框：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If you want to inspect the content of a dataframe, that is, `df`, just use `fmt.Println(df)`.
    This will show you the first 10 rows of the dataframe, along with its column names
    and some useful metadata, such as the total number of rows.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想检查数据框的内容，即 `df`，只需使用 `fmt.Println(df)`。这将显示数据框的前 10 行，包括其列名和一些有用的元数据，例如总行数。
- en: Finding the most common phrases
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找最常见的短语
- en: 'Now that the data has been parsed, the co-occurring phrases have been filtered
    out, and the resulting phrase/frequency pairs have been loaded into dataframes,
    all that is remaining is to find the most common phrases for the positive and
    negative reviews and display them. One way of doing this without dataframes would
    be to create a `type ByFrequency []Pair` type that implements the `sort` interface,
    and then compose `sort.Reverse` and `sort.Sort` to order positive pairs and negative
    pairs by descending frequency. However, by using Gota, we can achieve this with
    one line per dataframe:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经被解析，共现短语已经被过滤，结果短语/频率对已经被加载到数据框中，接下来要做的就是找到正面和负面评论中最常见的短语并显示它们。在不使用数据框的情况下，可以通过创建一个实现
    `sort` 接口的 `type ByFrequency []Pair` 类型来完成这项工作，然后使用 `sort.Reverse` 和 `sort.Sort`
    来按频率降序排列正面和负面配对。然而，通过使用 Gota，我们可以每个数据框一行代码就实现这个功能：
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Printing the dataframes now gives the top 10 most common phrases for positive
    and negative reviews of kitchen items, respectively. For positive reviews, we
    have the following output:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'For negative reviews, we have the following output:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This completes this example. In the following section, we will cover the other
    transformation and processing features of Gota in more detail.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Example – exploring body mass index data with gonum/plot
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, we introduced gophernotes and Gota. In this section,
    we will explore a dataset containing 500 samples of gender, height, and BMI index.
    We will do this using the `gonum/plot` library. This library, which was originally
    a fork of the 2012 Plotinum library^([15]), contains several packages that make
    creating data visualizations in Go much easier^([16]):'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: The `plot` package contains a layout and formatting interface.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `plotter` package abstracts the layout and formatting for common plot types,
    such as bar charts, scatter plots, and so on.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `plotutil` package contains utility funcs for common plot types.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `vg` package exposes an API for vector graphics and is particularly useful
    when exporting plots to other software. We will not be covering this package.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing gonum and gonum/plot
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regardless of whether you are using the Docker image to run gophernotes as suggested
    previously or a different method, you will need to use `gonum/plot`. To do this,
    run the `go get gonum.org/v1/plot/...` command. If you do not have the `gonum`
    library installed, and you are not using the gophernotes Docker image, you will
    need to install this separately using the `go get github.com/gonum/...` command.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: To open a terminal from Jupyter, open up the web UI to the tree view (the default
    view) and then click on **New** | **Terminal**.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Note that, despite their names, gonum and gonum/plot are not part of the same
    repository, so you need to install both separately.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you have cloned the project repository, it will already contain the 500-person
    BMI dataset in the `datasets/bmi` folder. You can also download the dataset yourself
    from Kaggle^([14]). The dataset is a single CSV file with the following first
    few rows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Like in the previous section, we will use `io`/`ioutil` to read the file into
    a byte slice, but this time, we will take advantage of Gota''s ReadCSV method
    (which takes an `io.Reader` as an argument) to directly load the data into a dataframe
    with no preprocessing:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Inspect the dataframe to make sure that the data has been loaded correctly:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note that the data types of the series have been inferred automatically.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the distributions of the data series
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A good way to understand each series is to plot a histogram. This will give
    you an impression of how each series is distributed. Using `gonum`/`plot`, we
    will plot histograms for each series. However, before we plot anything, we can
    quickly access some summary statistics via Gota to gain a rudimentary understanding
    of the dataset:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This tells us that the heights of the sampled individuals lie between 140 cm
    and 199 cm, that their mean and median are 169 cm and 170 cm, respectively, and
    the fact that the mean and the median are so close suggests low skewness—that
    is, a symmetric distribution.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: 'An even quicker way to achieve this for all columns simultaneously is to use
    the `dataframe.Describe` function. This produces another dataframe that contains
    summary statistics of each column:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we will visualize the distributions using histograms. First, we will need
    to convert a column of a Gota dataframe into a plot-friendly `plotter.Values` slice.
    This can be accomplished with the following utility function:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The `dataframe.Col` func extracts just the required column from the given dataframe—in
    our case, a single column. You can also use `dataframe.Select`, which takes a
    slice of strings of column names to return a dataframe containing only the required
    columns. This can be useful for discarding unnecessary data.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can use gonum/plot to create a JPEG image of a histogram of a given
    column with a chosen title:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'To display the resulting plot using gophernotes, use the appropriate method
    of the display object. In this case, we are producing a JPEG image, so calling
    `display.JPEG` with the byte slice that was produced by the preceding code will
    display the plot in the output cell. The full code input cell would be as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In general, the steps to create a new plot from one of gonum''s built-in plotters
    are as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Create a new plot with `plot.New()` – this is like a canvas that the plot will
    live on.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set any plot attributes, such as its title.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new plotter based on one of the available types (`BarChart`, `BoxPlot`,
    `ColorBar`, `Contour`, `HeatMap`, `Histogram`, `Line`, `QuartPlot`, `Sankey`,
    or `Scatter`).
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set any plotter attributes and add the plotter to the plot by calling its `Add` method.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you wish to display the plot via gophernotes, use the `WriterTo` method and
    a byte buffer to output the plot data as a slice of bytes that can be passed to
    the built-in display object. Otherwise, use `p.Save` to save the image to a file.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If, instead of displaying the image in gophernotes, you wish to save it, you
    can do this with the plot's `Save` method. For example, `p.Save(5*vg.Inch, 4*vg.Inch,
    title + ".png")` will save the plot to a 5" x 4" PNG file.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting histograms for the 500-person weight/height/BMI dataset are as
    follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28d2f746-280a-4d9c-aaa8-c16831aaae93.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
- en: In the following example, we will not just load and visualize data, but also
    transform it to make it more suitable for use with an ML algorithm.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Example – preprocessing data with Gota
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The quality and speed of the ML algorithm training process depends on the quality
    of the input data. While many algorithms are robust to irrelevant columns and
    data that is not normalized, some are not. For example, many models requires data
    inputs to be normalized to lie between 0 and 1\. In this section, we will look
    at some quick and easy ways to preprocess data with Gota. For these examples,
    we will be using a dataset containing 1,035 records of the height (inch) and weight
    (lbs) of major league baseball players^([17]). The dataset, as described on the
    UCLA website, consists of the following features:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法训练过程的质量和速度取决于输入数据的质量。虽然许多算法对无关列和非规范化的数据具有鲁棒性，但有些则不是。例如，许多模型需要数据输入规范化，使其位于0到1之间。在本节中，我们将探讨使用Gota进行数据预处理的快速简单方法。对于这些示例，我们将使用包含1,035条记录的身高（英寸）和体重（磅）的主联赛棒球球员数据集^([17])。根据UCLA网站上的描述，数据集包含以下特征：
- en: '`Name`: Player name'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`姓名`: 球员姓名'
- en: '`Team`: The baseball team that the player was a member of'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`队伍`: 球员所属的棒球队'
- en: '`Position`: The player''s position'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`位置`: 球员的位置'
- en: '`Height (inches)`: Player height'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`身高（英寸）`: 球员身高'
- en: '`Weight (pounds)`: Player weight in pounds'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`体重（磅）`: 球员体重，单位为磅'
- en: '`Age`: Player age at the time of recording'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`年龄`: 记录时的球员年龄'
- en: 'For the purposes of this exercise, we will preprocess the data in the following
    manner:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了这个练习的目的，我们将以以下方式预处理数据：
- en: Remove the name and team column
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除姓名和队伍列
- en: Convert the height and weight columns into the float type
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将身高和体重列转换为浮点类型
- en: Filter out players with a weight greater than or equal to 260 pounds
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤掉体重大于或等于260磅的球员
- en: Normalize the height and weight columns
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化身高和体重列
- en: Divide the data into training and validation subsets with approximately 70%
    of rows in the training subset and 30% in the validation subset
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分为训练集和验证集，其中训练集大约包含70%的行，验证集包含30%
- en: Loading the data into Gota
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据加载到Gota中
- en: The dataset is supplied as an HTML table on the UCLA website^([17]). In the
    companion repository to this book, you will find a CSV version. To quickly convert
    the HTML table yourself into CSV format without needing to write any code, first
    highlight the table and copy and paste this into a spreadsheet program such as
    Microsoft Excel. Then, save the spreadsheet as a CSV file. Open this file in a
    text editor to ensure there are no artefacts or extraneous rows in the file.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集以HTML表格的形式提供在UCLA网站上^([17])。在本书的配套仓库中，你可以找到一个CSV版本。要快速将HTML表格转换为CSV格式，而无需编写任何代码，首先选中表格，然后将其复制并粘贴到电子表格程序，如Microsoft
    Excel中。然后，将电子表格保存为CSV文件。在文本编辑器中打开此文件，以确保文件中没有碎片或多余的行。
- en: 'Loading the dataset is done using the `dataframe.ReadCSV` method. Inspecting
    the dataframe produces the following output:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`dataframe.ReadCSV`方法加载数据集。检查dataframe会产生以下输出：
- en: '[PRE23]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Removing and renaming columns
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除和重命名列
- en: 'For this exercise, we have decided that we do not need the `Name` or the `Team`
    columns. We can use the dataframe''s `Select` method to specify a slice of strings
    of column names that we wish to keep:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习，我们决定我们不需要`姓名`或`队伍`列。我们可以使用dataframe的`Select`方法来指定我们希望保留的列名字符串的切片：
- en: '[PRE24]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'While we are at it, the `Height` and `Weight` columns should be renamed to
    remove the units from the column names. This can be achieved with the `Rename` method:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在此同时，`身高`和`体重`列应该重命名以去除单位。这可以通过`Rename`方法实现：
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The resulting dataset is as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的数据集如下：
- en: '[PRE26]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Converting a column into a different type
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将列转换为不同的类型
- en: Our dataframe now has the correct columns with more concise names. However,
    the height and weight columns are of the `int` type, whereas we need them to be
    of the `float` type so that we can correctly normalize their values. The easiest
    way to do this is to add this as a `LoadOption` when first loading the data into
    a dataframe. Namely, `func WithTypes(coltypes map[string]series.Type) LoadOption` accepts
    a map of column names to series types, and we can use this to perform the conversion
    at load time.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据框现在具有正确的列，且列名更简洁。然而，身高和体重列的类型为`int`，而我们需要它们为`float`类型，以便正确规范化它们的值。最容易的方法是在首次将数据加载到dataframe时添加此`LoadOption`。即`func
    WithTypes(coltypes map[string]series.Type) LoadOption`接受一个列名到系列类型的映射，我们可以使用它来在加载时执行转换。
- en: 'However, suppose that we have not done this. In that case, we convert the column
    type by replacing the column with a new series that has the correct type. To generate
    this series, we can use the `series.New` method, together with `df.Col` to isolate
    the column of interest. For example, to produce a series of floats from the current
    height series, we can use the following code:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To replace the column, we can use the `Mutate` method:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Doing this for both the `Height` and the `Weight` columns now produces the
    following output:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Filtering out unwanted data
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Suppose that, after exploring the data, we do not wish to keep samples where
    the player weight is greater than or equal to 260 pounds. This could be because
    there are not enough samples of heavier players, and so any analysis would not
    be representative of the player population as a whole. Such players could be called
    **outliers** in regards to the current dataset.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: You can find the reference (Godocs) for the Gota library at [https://godoc.org/github.com/kniren/gota](https://godoc.org/github.com/kniren/gota).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'Gota dataframes can be filtered using the `Filter` func. This accepts a `dataframe.F
    struct`, which consists of the target column, a comparator, and a value, such
    as `{"Column", series.Eq, 1}`, which would match only rows where `Column` was
    equal to `1`. The available comparators are as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '`series.Eq`: Keeps only rows that are equal to the given value'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.Neq`: Keeps only rows that are not equal to the given value'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.Greater`: Keeps only rows that are greater than the given value'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.GreaterEq`: Keeps only rows that are greater than or equal to the given
    value'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.Less`: Keeps only rows that are less than the given value'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.LessEq`: Keeps only rows that are less than or equal to the given value'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `series.Comparator` type is an alias for a string. These strings are the
    same as the ones that are used in the Go language itself. For example, `series.Neq`
    is equivalent to `"!="`.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, we will apply the series. We will use the `less` filter
    in order to remove rows where the weight is greater than or equal to 260 pounds:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Normalizing the Height, Weight, and Age columns
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data normalization, also known as feature scaling, is the process of transforming
    a group of independent variables to map them onto the same range. There are several
    methods to achieve this:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '**Rescaling** **(min/max normalization)**: This will linearly map the variable
    range onto the [0,1] range, where the minimum value of the series will map to
    0 and its maximum will map to 1\. This is achieved by applying the following formula:'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/f30229f7-b4a4-48b2-b81a-2e4b65e43a02.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
- en: '**Mean normalization**: This will map the variable range if we apply the following
    formula:'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/21ff6a5a-b923-4483-8996-bc613230a6f8.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
- en: '**Standardization** **(z-score normalization)**: This very common method of
    normalization for ML applications uses the mean and standard deviation to transform
    the series of values into their z-scores, that is, how many standard deviations
    from the mean the data point lies. This is done by computing the mean and standard
    deviation of the series and then applying the following formula:'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/6e6e18c2-e0bd-427e-853a-3a88497825f3.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
- en: Note that this is not guaranteed to map the variable onto a closed range.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'Rescaling can be implemented with the following utility func:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Mean normalization can be implemented with the following utility function:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Standardization can be implemented with the following utility func:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'For this example, we will apply rescaling to the `Height` and `Weight` columns
    with the following code:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The result is as follows. Note that the values of the `Height` and `Weight`
    columns now lie between 0 and 1, as intended:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Sampling to obtain training/validation subsets
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When training an ML algorithm, it is useful to reserve a portion of the dataset
    for validation. This is used to test the generalization of the model to previously
    unseen data and thus to ensure its usefulness when presented with real-life data
    that isn't part of the training set. Without the validation step, it is not possible
    to say whether a model will have good predictive power.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are no accepted conventions regarding how much of the dataset to
    reserve for validation, a fraction between 10% and 30% is common. Research that
    has been conducted into how much of the dataset to reserve for validation concluded
    that the more adjustable parameters a model has, the less the fraction of the
    data needs to be reserved for validation^([18]). For this exercise, we will divide
    our MLB dataset into two subsets: a training subset containing approximately 70%
    of samples, and a validation subset containing 30% of samples. There are two ways
    of doing this:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Select the first 70% of rows to form part of the training subset and the second
    30% to form part of the validation subset
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select a random 70% of samples to form part of the training subset and use the
    remainder for the validation subset
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In general, it is better to avoid deterministic sampling to ensure that both
    subsets are representative of the overall population. To implement random sampling,
    we will use the `math/rand` package to produce random indices and combine this
    with Gota''s `dataframe.Subset` method. The first step is to generate a random
    permutation of the indices of the dataframe:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now, we will take the first 70% of this slice for training and the remaining
    elements for validation, resulting in the following utility:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Applying this to our dataframe with `split(df, 0.7)` produces the following
    output. The first dataframe is the training subset, while the second is the validation
    subset:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Encoding data with categorical variables
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding dataframe, the `Position` column is a string. Suppose we want
    an ML algorithm to use this input, because, say, we are attempting to predict
    the weight of the player and players in certain positions tend to have different
    body composition. In this case, we need to **encode** the string to a numerical
    value that can be used by the algorithm.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: The naive solution is to determine the set of all player positions and assign
    an increasing integer to each member of the set. For example, we might end up
    with the `{Relief_Pitcher, Starting_Pitcher, Shortstop, Outfielder,...}` set,
    whereupon we would assign `0` to `Relief_Pitcher`, `1` to `Starting_Pitcher`,
    `2` to `Shortstop`, and so on. However, the flaw of this approach is in how the
    numbers are assigned, because it gives importance to the order of the categories
    where none exist. Suppose that a step of the ML algorithm computes a mean across
    categories. Therefore, it might conclude that `Starting_Pitcher` is the mean of
    `Relief_Pitcher` and `Shortstop`! Other types of algorithms might infer correlations
    where none exist.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: To solve this issue, we can use **one-hot encoding**. This type of encoding
    will split a categorical column with N possible values into N columns. Each of
    the columns, which correspond to one of the categories, will have the value `1`,
    where that input belongs to the given column, and `0` otherwise. This also allows
    for the scenario where an input sample may belong to multiple categories.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps to generate a one-hot encoding for a given column with Gota are as
    follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Enumerate the unique values of the categorical column
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new series for each unique value, mapping each row to `1` if it belongs
    to this category and `0` otherwise
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mutate the original dataframe by adding the series created in *step 2* and removing
    the original column
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enumerating the unique values can be done easily using a map:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Note that this makes use of the `series.Records` method to return the values
    of a given column as a slice of strings. Also, note that the order in which the
    values are returned will not necessarily be the same every time. Running this
    func on our dataframe with `UniqueValues(df, "Position")` yields the following
    unique values:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The second step is to iterate over the dataframe, creating new series as we
    go along:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This func will return one series for each unique value of the categorical variable.
    These series will have the names of the categories. In our case, we can call it
    with `OneHotSeries(df, "Position", UniqueValues(df, "Position"))`. Now, we will
    mutate our original dataframe and drop the `Position` column:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Printing `df` yields the following result:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: To conclude, just drop the `Position` column using `df = df.Drop("Position")`.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered how to set up a development environment for Go that
    is optimized for ML applications. We explained how to install an interactive environment,
    Jupyter, to accelerate data exploration and visualization using libraries such
    as Gota and gonum/plot.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'We also introduced some basic data processing steps, such as filtering outliers,
    removing unnecessary columns, and normalization. Finally, we covered sampling.
    This chapter took the first few steps in the ML life cycle: data acquisition,
    exploration, and preparation. Now that you have read this chapter, you have learned
    how to load data into a Gota dataframe, how to use the dataframe and series packages
    to process and prepare the data into a format that is required by your chosen
    algorithm, and how to visualize it with gonum''s plot package. You have also learned
    about different ways of normalizing the data, which is an important step for improving
    the accuracy and speed of many ML algorithms.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will introduce supervised learning algorithms and exemplify
    how to choose an ML algorithm, train it, and validate its predictive power on
    previously unseen data.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Further readings
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Software Development Waste*. Todd Sedano and Paul Ralph. ICSE ''17 Proceedings
    of the 39th International Conference on Software Engineering. Pages 130-140.'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: See the official Go installation instructions at [https://golang.org/doc/install](https://golang.org/doc/install).
    Retrieved February 19th, 2019.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://jupyter.org/about](https://jupyter.org/about). Retrieved February
    19th, 2019.'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/jupyter/jupyter/wiki/Jupyter-kernels](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels).
    Retrieved February 19th, 2019.'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For further instructions, see [https://help.github.com/articles/working-with-jupyter-notebook-files-on-github/](https://help.github.com/articles/working-with-jupyter-notebook-files-on-github/).
    Retrieved February 19th, 2019.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://colab.research.google.com](https://colab.research.google.com). Retrieved
    February 19th, 2019.'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://nbviewer.jupyter.org/](https://nbviewer.jupyter.org/). Retrieved February
    19th, 2019.'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://jupyter.org/hub](https://jupyter.org/hub). Retrieved February 19th,
    2019.'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/jupyter/nbconvert](https://github.com/jupyter/nbconvert).
    Retrieved February 19th, 2019.'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For Docker installation instructions, see [https://docs.docker.com/install/](https://docs.docker.com/install/)
    for Linux and [https://docs.docker.com/docker-for-windows/install/](https://docs.docker.com/docker-for-windows/install/)
    for Windows. Retrieved February 19th, 2019.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'John Blitzer, Mark Dredze, Fernando Pereira. Biographies, Bollywood, *Boom-boxes
    and Blenders: Domain Adaptation for Sentiment Classification.* Association of
    Computational Linguistics (ACL), 2007.'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/go-gota/gota](https://github.com/go-gota/gota). Retrieved
    February 19th, 2019.'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://godoc.org/sort#Interface](https://godoc.org/sort#Interface). Retrieved
    February 19th, 2019.'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/yersever/500-person-gender-height-weight-bodymassindex/version/2](https://www.kaggle.com/yersever/500-person-gender-height-weight-bodymassindex/version/2).
    Retrieved February 20th, 2019.'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://code.google.com/archive/p/plotinum/](https://code.google.com/archive/p/plotinum/).
    Retrieved February 20th, 2019.'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/gonum/plot](https://github.com/gonum/plot). Retrieved February
    20th, 2019.'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights).
    Retrieved February 20th, 2019.'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Guyon, Isabelle. 1996\. *A Scaling Law for the Validation-Set Training-Set Size
    Ratio*. AT&T Bell Lab. 1.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
