- en: Setting Up the Development Environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like traditional software development, ML application development requires
    the mastery of specialist boilerplate code and a development environment that
    allows the developer to proceed at a pace that has the lowest amount of friction
    and distraction. Software developers typically waste a lot of time with basic
    setup and data wrangling tasks. Being a productive and professional ML developer
    requires the ability to quickly prototype solutions; this means expending as little
    effort as possible on trivial tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we outlined the main ML problems and a development
    process that you can follow to obtain a commercial solution. We also explained
    the advantages offered by Go as a programming language when creating ML applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will guide you through the steps that are required to set
    up a development environment for Go that is optimized for ML applications. Specifically,
    we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: How to install Go
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Go interactively using Jupyter and gophernotes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data wrangling with Gota
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data visualization with gonum/plot and gophernotes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preprocessing (formatting, cleaning, and sampling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data transformation (normalization and encoding of categorical variables)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code examples that accompany this book are optimized for Debian-based Linux
    distributions. However, they can be adapted for other distributions (for example,
    by changing `apt` to `yum`) and Windows with Cygwin.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have completed this chapter, you will be able to quickly explore, visualize,
    and process any dataset for subsequent use by an ML algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Development environments are personal. Most developers will prefer one code
    editor or toolset over another. While we recommend the use of interactive tools
    such as Jupyter via gophernotes, the only prerequisite to running the code examples
    in this book is a working installation of Go 1.10 or higher. That is, the `go`
    command should be available and the `GOPATH` environment variable should be set
    up correctly.
  prefs: []
  type: TYPE_NORMAL
- en: To install Go, download a binary release for your system from [https://golang.org/dl/](https://golang.org/dl/).
    Then, refer to the one of the following subsections that matches your operating
    system^([2]).
  prefs: []
  type: TYPE_NORMAL
- en: If you only want to use gophernotes to run Go code and you intend to use Docker
    as the installation method, then you can skip this section and go straight to
    the *Running Go interactively with gophernotes* section.
  prefs: []
  type: TYPE_NORMAL
- en: Linux, macOS, and FreeBSD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The binary releases are packaged as tarballs. Extract the binaries and add
    them to your `PATH`. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To configure your `GOPATH` environment variable, you will need to decide where
    you will want your Go files, including any personal repositories, to live. One
    possible location is `$HOME/go`. Once you have decided on this, set the environment
    variable, for example as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To make this instruction permanent, you will need to add this line to `.bashrc`.
    For instructions if you're using other shells (such as `.zsh`), please refer to
    the official Go installation instructions at [https://github.com/golang/go/wiki/SettingGOPATH](https://github.com/golang/go/wiki/SettingGOPATH).
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that your `GOPATH` is not in the same directory as your Go installation,
    otherwise this can cause issues.
  prefs: []
  type: TYPE_NORMAL
- en: Windows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The binary releases are packaged either as a ZIP file or an MSI installer that
    automatically configures your environment variables. We recommend using the MSI
    installer. However, if you do not, then after extracting the contents of the ZIP
    file to a suitable location (such as `C:\Program Files\Go`), make sure that you
    add the `subdirectory` bin to your `PATH` environment variable using the control
    panel.
  prefs: []
  type: TYPE_NORMAL
- en: Once the binaries have been installed to a suitable location, you will need
    to configure your `GOPATH`. First, decide where you want your Go files, including
    any personal repositories, to live. One possible location is `C:\go`. Once you
    have decided, set the `GOPATH` environment variable to the path of this directory.
  prefs: []
  type: TYPE_NORMAL
- en: If you are unsure how to set environment variables, refer to the official Go
    installation instructions at [https://github.com/golang/go/wiki/SettingGOPATH](https://github.com/golang/go/wiki/SettingGOPATH).
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that your `GOPATH` is not in the same directory as your Go installation,
    otherwise this can cause issues.
  prefs: []
  type: TYPE_NORMAL
- en: Running Go interactively with gophernotes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Project Jupyter is a not-for-profit organization that was created to develop
    language-agnostic interactive computing for data science^([3]). The result is
    a mature, well-supported environment to explore, visualize, and process data that
    can significantly accelerate development by providing immediate feedback and integrations
    with plotting libraries such as `gonum`/`plot`.
  prefs: []
  type: TYPE_NORMAL
- en: While its first iteration, called iPython, only supported Python-based handlers
    (called *kernels*) at first, the latest version of Jupyter has over 50 kernels
    that support dozens of languages, including three kernels for the Go language^([4]).
    GitHub has support for rendering Jupyter files (called *notebooks*)^([5]), and
    there are various specialized hubs for sharing notebooks online, including Google
    Research Colabs^([6]), Jupyter's community hub called NBViewer^([7]), and its
    enterprise offering, JupyterHub^([8]). Notebooks for presentation purposes can
    be converted into other file formats such as HTML using the nbconvert utility^([9]).
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will be using Jupyter together with the gophernotes kernel
    for Go. The simplest way to get started with gophernotes on Linux and Windows
    is to use its Docker^([10]) image.
  prefs: []
  type: TYPE_NORMAL
- en: 'For alternative installation methods, we recommend checking the README page
    of the gophernotes GitHub repository at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/gopherdata/gophernotes](https://github.com/gopherdata/gophernotes).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps to begin a new gophernotes-based project are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new directory to hold the project files (this does not need to be in
    your `GOPATH`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Optional) Initialize a new git repository by running `git init` in the new
    directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the following command from the new directory (you may need to prefix it
    with `sudo`, depending on how you installed Docker):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`docker run -it -p 8888:8888 -v $(pwd):/usr/share/notebooks gopherdata/gophernotes:latest-ds`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the terminal, there will be a URL ending in `?token=[some combination of
    letters and numbers]`. Navigate to this URL in a modern web browser. The new directory
    you created will be mapped to `/usr/share/notebooks`, so navigate to this directory
    in the tree that presents itself.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On Windows, you may need to modify the preceding command by replacing `$(pwd)`
    with `%CD%`.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have learned how to install Go and set up a basic development environment
    with gophernotes, it's time to learn about data preprocessing.
  prefs: []
  type: TYPE_NORMAL
- en: Example – the most common phrases in positive and negative reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our first code example, we will use the multi-domain sentiment dataset (version
    2.0)^([11]). This dataset contains Amazon reviews from four different product
    categories. We will download it, preprocess it, and load it into Gota, a data
    wrangling library, to find the most common phrases in positive and negative reviews
    that do not co-occur in both. This is a basic example that involves no ML algorithms,
    but will serve as a hands-on introduction to Go, gophernotes, and Gota.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the full code example in the companion repository to this book
    at [https://github.com/PacktPublishing/Machine-Learning-with-Go-Quick-Start-Guide](https://github.com/PacktPublishing/Machine-Learning-with-Go-Quick-Start-Guide).
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the example directory and downloading the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Following the process we implemented previously, create an empty directory
    to hold the code files. Before opening gophernotes, download the dataset from [http://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_acl.tar.gz](http://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_acl.tar.gz)
    and extract it to `datasets/words`. On most Linux distributions, you can do this
    with the following script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, start gophernotes and navigate the tree to `/usr/share/notebooks`. Create
    a new Notebook by clicking on *New* | *Go*. You will see a blank Jupyter Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d688d626-95d1-4552-a14b-8d7287e0f1df.png)'
  prefs: []
  type: TYPE_IMG
- en: Input cells in Jupyter are marked with the `In` label. When you run the code
    in an input cell (*Shift* + *Enter*), a new output cell will be created with the
    result, marked as `Out`. Each cell is numbered with its execution order. For example,
    the `In [1]` cell is the first cell you ran within a given session.
  prefs: []
  type: TYPE_NORMAL
- en: 'Try running some Go statements, like the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In particular, note that the `a` variable is displayed in the output cell, even
    though there was no call to `fmt.Println()`.
  prefs: []
  type: TYPE_NORMAL
- en: All the imports, variables, and funcs you define within a session remain in
    memory, even if you delete the input cells. To clear the current scope, go to
    Kernel | Restart.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the dataset files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the basic tasks of data processing is to read the input file and load
    its contents. A simple way to do this is to use the `io/ioutil` utility func `ReadFile`.
    Unlike in a `.go` file, where you would need to place this code inside your `main` func,
    with gophernotes, you can run the following code without declaring any func at
    all:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will load the contents of reviews of kitchen products with
    positive sentiments into a byte slice called `positives` and the ones with negative
    sentiments into the byte slice called `negatives`. If you have correctly downloaded
    the datasets and you run this code, it should not output anything because there
    are no errors. If any errors appear, check that the dataset files have been extracted
    to the correct folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have opened the `positive.review` or `negative.review` file in a text
    editor, you may have noticed that they are formatted as a space or newline separated
    list of pairs, that is, `phrase:frequency`. For example, the start of the positive
    review is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the next subsection, we will parse these pairs into a Go struct.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing contents into a Struct
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use the `strings` package to parse the contents of the data files into
    slices of pairs. Each item in the slice of strings will contain a single pair,
    such as `them_it:1`. We will then further split this pair by the colon symbol
    and use the `strconv` package to parse the integer frequency into an `int`. Each
    `Pair` will be of the following type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We will do this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, observe that the separation between the pairs can be either a new line
    (`\n`) or a space. We will use the `strings.Fields` func of the strings package,
    which will split the string by any consecutive whitespace characters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will iterate each pair, splitting by the colon separator and using
    the `strconv` package to parse the frequency to an integer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also return a map of phrases so that we can later exclude phrases that
    are in the intersection between positive and negative reviews. The reason for
    doing this is that words that are common to both positive and negative reviews
    are less likely to be indicative of the positive or negative sentiment. This is
    done with the following function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will apply this to our slices of pairs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The next step is to load the parsed pairs into Gota, the data wrangling library
    for Go.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data into a Gota dataframe
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Gota library contains implementation of dataframes, series, and some general
    data wrangling algorithms^([12]). The concept of a dataframe is integral to a
    number of popular data science libraries and languages such as Python's pandas,
    R, and Julia. In a nutshell, a **dataframe** is a list of lists (called a **column**
    or **series**) that each have the same length. Every list has a name—the column
    name or series name, depending on the nomenclature favored by the library. This
    abstraction mimics a database table and makes an easy fundamental building block
    for mathematical and statistical tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Gota library has two packages: the `dataframe` and the `series` packages.
    The series package contains functions and structures to represent individual lists,
    whereas the `dataframe` package deals with the entire dataframe—that is, the table—as
    a whole. A Go developer may wish to use Gota to quickly sort, filter, aggregate,
    or perform relational operations, such as inner joins between two tables, saving
    on boilerplate code such as implementing a `sort` interface^([13]).'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several ways to create a new dataframe with Gota:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dataframe.New(se ...series.Series)`: Accepts a slice of series (which can
    be created via the `series.New` func).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dataframe.LoadRecords(records [][]string, options ...LoadOption)`: Accepts
    a slice of slices. The first slice will be a slice of strings representing the
    column names.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dataframe.LoadStructs(i interface{}, options ...LoadOption)`: Accepts a slice
    of structs. Gota will use reflection to determine the column names based on the
    struct field names.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dataframe.LoadMaps(maps []map[string][]interface{})`: Accepts a slice of maps
    of column names to slices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dataframe.LoadMatrix(mat Matrix)`: Accepts a slice that is compatible with
    the mat64 matrix interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In our case, because we have parsed the data into structs, we will use the
    `LoadStructs` function, making one dataframe for positive reviews and one for
    negative reviews:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If you want to inspect the content of a dataframe, that is, `df`, just use `fmt.Println(df)`.
    This will show you the first 10 rows of the dataframe, along with its column names
    and some useful metadata, such as the total number of rows.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the most common phrases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that the data has been parsed, the co-occurring phrases have been filtered
    out, and the resulting phrase/frequency pairs have been loaded into dataframes,
    all that is remaining is to find the most common phrases for the positive and
    negative reviews and display them. One way of doing this without dataframes would
    be to create a `type ByFrequency []Pair` type that implements the `sort` interface,
    and then compose `sort.Reverse` and `sort.Sort` to order positive pairs and negative
    pairs by descending frequency. However, by using Gota, we can achieve this with
    one line per dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Printing the dataframes now gives the top 10 most common phrases for positive
    and negative reviews of kitchen items, respectively. For positive reviews, we
    have the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'For negative reviews, we have the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This completes this example. In the following section, we will cover the other
    transformation and processing features of Gota in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Example – exploring body mass index data with gonum/plot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, we introduced gophernotes and Gota. In this section,
    we will explore a dataset containing 500 samples of gender, height, and BMI index.
    We will do this using the `gonum/plot` library. This library, which was originally
    a fork of the 2012 Plotinum library^([15]), contains several packages that make
    creating data visualizations in Go much easier^([16]):'
  prefs: []
  type: TYPE_NORMAL
- en: The `plot` package contains a layout and formatting interface.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `plotter` package abstracts the layout and formatting for common plot types,
    such as bar charts, scatter plots, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `plotutil` package contains utility funcs for common plot types.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `vg` package exposes an API for vector graphics and is particularly useful
    when exporting plots to other software. We will not be covering this package.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing gonum and gonum/plot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regardless of whether you are using the Docker image to run gophernotes as suggested
    previously or a different method, you will need to use `gonum/plot`. To do this,
    run the `go get gonum.org/v1/plot/...` command. If you do not have the `gonum`
    library installed, and you are not using the gophernotes Docker image, you will
    need to install this separately using the `go get github.com/gonum/...` command.
  prefs: []
  type: TYPE_NORMAL
- en: To open a terminal from Jupyter, open up the web UI to the tree view (the default
    view) and then click on **New** | **Terminal**.
  prefs: []
  type: TYPE_NORMAL
- en: Note that, despite their names, gonum and gonum/plot are not part of the same
    repository, so you need to install both separately.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you have cloned the project repository, it will already contain the 500-person
    BMI dataset in the `datasets/bmi` folder. You can also download the dataset yourself
    from Kaggle^([14]). The dataset is a single CSV file with the following first
    few rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Like in the previous section, we will use `io`/`ioutil` to read the file into
    a byte slice, but this time, we will take advantage of Gota''s ReadCSV method
    (which takes an `io.Reader` as an argument) to directly load the data into a dataframe
    with no preprocessing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Inspect the dataframe to make sure that the data has been loaded correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note that the data types of the series have been inferred automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the distributions of the data series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A good way to understand each series is to plot a histogram. This will give
    you an impression of how each series is distributed. Using `gonum`/`plot`, we
    will plot histograms for each series. However, before we plot anything, we can
    quickly access some summary statistics via Gota to gain a rudimentary understanding
    of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This tells us that the heights of the sampled individuals lie between 140 cm
    and 199 cm, that their mean and median are 169 cm and 170 cm, respectively, and
    the fact that the mean and the median are so close suggests low skewness—that
    is, a symmetric distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'An even quicker way to achieve this for all columns simultaneously is to use
    the `dataframe.Describe` function. This produces another dataframe that contains
    summary statistics of each column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will visualize the distributions using histograms. First, we will need
    to convert a column of a Gota dataframe into a plot-friendly `plotter.Values` slice.
    This can be accomplished with the following utility function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `dataframe.Col` func extracts just the required column from the given dataframe—in
    our case, a single column. You can also use `dataframe.Select`, which takes a
    slice of strings of column names to return a dataframe containing only the required
    columns. This can be useful for discarding unnecessary data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can use gonum/plot to create a JPEG image of a histogram of a given
    column with a chosen title:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'To display the resulting plot using gophernotes, use the appropriate method
    of the display object. In this case, we are producing a JPEG image, so calling
    `display.JPEG` with the byte slice that was produced by the preceding code will
    display the plot in the output cell. The full code input cell would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In general, the steps to create a new plot from one of gonum''s built-in plotters
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new plot with `plot.New()` – this is like a canvas that the plot will
    live on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set any plot attributes, such as its title.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new plotter based on one of the available types (`BarChart`, `BoxPlot`,
    `ColorBar`, `Contour`, `HeatMap`, `Histogram`, `Line`, `QuartPlot`, `Sankey`,
    or `Scatter`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set any plotter attributes and add the plotter to the plot by calling its `Add` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you wish to display the plot via gophernotes, use the `WriterTo` method and
    a byte buffer to output the plot data as a slice of bytes that can be passed to
    the built-in display object. Otherwise, use `p.Save` to save the image to a file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If, instead of displaying the image in gophernotes, you wish to save it, you
    can do this with the plot's `Save` method. For example, `p.Save(5*vg.Inch, 4*vg.Inch,
    title + ".png")` will save the plot to a 5" x 4" PNG file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting histograms for the 500-person weight/height/BMI dataset are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28d2f746-280a-4d9c-aaa8-c16831aaae93.png)'
  prefs: []
  type: TYPE_IMG
- en: In the following example, we will not just load and visualize data, but also
    transform it to make it more suitable for use with an ML algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Example – preprocessing data with Gota
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The quality and speed of the ML algorithm training process depends on the quality
    of the input data. While many algorithms are robust to irrelevant columns and
    data that is not normalized, some are not. For example, many models requires data
    inputs to be normalized to lie between 0 and 1\. In this section, we will look
    at some quick and easy ways to preprocess data with Gota. For these examples,
    we will be using a dataset containing 1,035 records of the height (inch) and weight
    (lbs) of major league baseball players^([17]). The dataset, as described on the
    UCLA website, consists of the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Name`: Player name'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Team`: The baseball team that the player was a member of'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Position`: The player''s position'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Height (inches)`: Player height'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Weight (pounds)`: Player weight in pounds'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Age`: Player age at the time of recording'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the purposes of this exercise, we will preprocess the data in the following
    manner:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove the name and team column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert the height and weight columns into the float type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filter out players with a weight greater than or equal to 260 pounds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalize the height and weight columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Divide the data into training and validation subsets with approximately 70%
    of rows in the training subset and 30% in the validation subset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading the data into Gota
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The dataset is supplied as an HTML table on the UCLA website^([17]). In the
    companion repository to this book, you will find a CSV version. To quickly convert
    the HTML table yourself into CSV format without needing to write any code, first
    highlight the table and copy and paste this into a spreadsheet program such as
    Microsoft Excel. Then, save the spreadsheet as a CSV file. Open this file in a
    text editor to ensure there are no artefacts or extraneous rows in the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Loading the dataset is done using the `dataframe.ReadCSV` method. Inspecting
    the dataframe produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Removing and renaming columns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this exercise, we have decided that we do not need the `Name` or the `Team`
    columns. We can use the dataframe''s `Select` method to specify a slice of strings
    of column names that we wish to keep:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'While we are at it, the `Height` and `Weight` columns should be renamed to
    remove the units from the column names. This can be achieved with the `Rename` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting dataset is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Converting a column into a different type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our dataframe now has the correct columns with more concise names. However,
    the height and weight columns are of the `int` type, whereas we need them to be
    of the `float` type so that we can correctly normalize their values. The easiest
    way to do this is to add this as a `LoadOption` when first loading the data into
    a dataframe. Namely, `func WithTypes(coltypes map[string]series.Type) LoadOption` accepts
    a map of column names to series types, and we can use this to perform the conversion
    at load time.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, suppose that we have not done this. In that case, we convert the column
    type by replacing the column with a new series that has the correct type. To generate
    this series, we can use the `series.New` method, together with `df.Col` to isolate
    the column of interest. For example, to produce a series of floats from the current
    height series, we can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'To replace the column, we can use the `Mutate` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Doing this for both the `Height` and the `Weight` columns now produces the
    following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Filtering out unwanted data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Suppose that, after exploring the data, we do not wish to keep samples where
    the player weight is greater than or equal to 260 pounds. This could be because
    there are not enough samples of heavier players, and so any analysis would not
    be representative of the player population as a whole. Such players could be called
    **outliers** in regards to the current dataset.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the reference (Godocs) for the Gota library at [https://godoc.org/github.com/kniren/gota](https://godoc.org/github.com/kniren/gota).
  prefs: []
  type: TYPE_NORMAL
- en: 'Gota dataframes can be filtered using the `Filter` func. This accepts a `dataframe.F
    struct`, which consists of the target column, a comparator, and a value, such
    as `{"Column", series.Eq, 1}`, which would match only rows where `Column` was
    equal to `1`. The available comparators are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`series.Eq`: Keeps only rows that are equal to the given value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.Neq`: Keeps only rows that are not equal to the given value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.Greater`: Keeps only rows that are greater than the given value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.GreaterEq`: Keeps only rows that are greater than or equal to the given
    value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.Less`: Keeps only rows that are less than the given value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`series.LessEq`: Keeps only rows that are less than or equal to the given value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `series.Comparator` type is an alias for a string. These strings are the
    same as the ones that are used in the Go language itself. For example, `series.Neq`
    is equivalent to `"!="`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, we will apply the series. We will use the `less` filter
    in order to remove rows where the weight is greater than or equal to 260 pounds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Normalizing the Height, Weight, and Age columns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data normalization, also known as feature scaling, is the process of transforming
    a group of independent variables to map them onto the same range. There are several
    methods to achieve this:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rescaling** **(min/max normalization)**: This will linearly map the variable
    range onto the [0,1] range, where the minimum value of the series will map to
    0 and its maximum will map to 1\. This is achieved by applying the following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/f30229f7-b4a4-48b2-b81a-2e4b65e43a02.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Mean normalization**: This will map the variable range if we apply the following
    formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/21ff6a5a-b923-4483-8996-bc613230a6f8.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Standardization** **(z-score normalization)**: This very common method of
    normalization for ML applications uses the mean and standard deviation to transform
    the series of values into their z-scores, that is, how many standard deviations
    from the mean the data point lies. This is done by computing the mean and standard
    deviation of the series and then applying the following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/6e6e18c2-e0bd-427e-853a-3a88497825f3.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that this is not guaranteed to map the variable onto a closed range.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rescaling can be implemented with the following utility func:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Mean normalization can be implemented with the following utility function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Standardization can be implemented with the following utility func:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'For this example, we will apply rescaling to the `Height` and `Weight` columns
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows. Note that the values of the `Height` and `Weight`
    columns now lie between 0 and 1, as intended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Sampling to obtain training/validation subsets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When training an ML algorithm, it is useful to reserve a portion of the dataset
    for validation. This is used to test the generalization of the model to previously
    unseen data and thus to ensure its usefulness when presented with real-life data
    that isn't part of the training set. Without the validation step, it is not possible
    to say whether a model will have good predictive power.
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are no accepted conventions regarding how much of the dataset to
    reserve for validation, a fraction between 10% and 30% is common. Research that
    has been conducted into how much of the dataset to reserve for validation concluded
    that the more adjustable parameters a model has, the less the fraction of the
    data needs to be reserved for validation^([18]). For this exercise, we will divide
    our MLB dataset into two subsets: a training subset containing approximately 70%
    of samples, and a validation subset containing 30% of samples. There are two ways
    of doing this:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the first 70% of rows to form part of the training subset and the second
    30% to form part of the validation subset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select a random 70% of samples to form part of the training subset and use the
    remainder for the validation subset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In general, it is better to avoid deterministic sampling to ensure that both
    subsets are representative of the overall population. To implement random sampling,
    we will use the `math/rand` package to produce random indices and combine this
    with Gota''s `dataframe.Subset` method. The first step is to generate a random
    permutation of the indices of the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will take the first 70% of this slice for training and the remaining
    elements for validation, resulting in the following utility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Applying this to our dataframe with `split(df, 0.7)` produces the following
    output. The first dataframe is the training subset, while the second is the validation
    subset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Encoding data with categorical variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding dataframe, the `Position` column is a string. Suppose we want
    an ML algorithm to use this input, because, say, we are attempting to predict
    the weight of the player and players in certain positions tend to have different
    body composition. In this case, we need to **encode** the string to a numerical
    value that can be used by the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The naive solution is to determine the set of all player positions and assign
    an increasing integer to each member of the set. For example, we might end up
    with the `{Relief_Pitcher, Starting_Pitcher, Shortstop, Outfielder,...}` set,
    whereupon we would assign `0` to `Relief_Pitcher`, `1` to `Starting_Pitcher`,
    `2` to `Shortstop`, and so on. However, the flaw of this approach is in how the
    numbers are assigned, because it gives importance to the order of the categories
    where none exist. Suppose that a step of the ML algorithm computes a mean across
    categories. Therefore, it might conclude that `Starting_Pitcher` is the mean of
    `Relief_Pitcher` and `Shortstop`! Other types of algorithms might infer correlations
    where none exist.
  prefs: []
  type: TYPE_NORMAL
- en: To solve this issue, we can use **one-hot encoding**. This type of encoding
    will split a categorical column with N possible values into N columns. Each of
    the columns, which correspond to one of the categories, will have the value `1`,
    where that input belongs to the given column, and `0` otherwise. This also allows
    for the scenario where an input sample may belong to multiple categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps to generate a one-hot encoding for a given column with Gota are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Enumerate the unique values of the categorical column
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new series for each unique value, mapping each row to `1` if it belongs
    to this category and `0` otherwise
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mutate the original dataframe by adding the series created in *step 2* and removing
    the original column
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enumerating the unique values can be done easily using a map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that this makes use of the `series.Records` method to return the values
    of a given column as a slice of strings. Also, note that the order in which the
    values are returned will not necessarily be the same every time. Running this
    func on our dataframe with `UniqueValues(df, "Position")` yields the following
    unique values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The second step is to iterate over the dataframe, creating new series as we
    go along:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This func will return one series for each unique value of the categorical variable.
    These series will have the names of the categories. In our case, we can call it
    with `OneHotSeries(df, "Position", UniqueValues(df, "Position"))`. Now, we will
    mutate our original dataframe and drop the `Position` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Printing `df` yields the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: To conclude, just drop the `Position` column using `df = df.Drop("Position")`.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered how to set up a development environment for Go that
    is optimized for ML applications. We explained how to install an interactive environment,
    Jupyter, to accelerate data exploration and visualization using libraries such
    as Gota and gonum/plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also introduced some basic data processing steps, such as filtering outliers,
    removing unnecessary columns, and normalization. Finally, we covered sampling.
    This chapter took the first few steps in the ML life cycle: data acquisition,
    exploration, and preparation. Now that you have read this chapter, you have learned
    how to load data into a Gota dataframe, how to use the dataframe and series packages
    to process and prepare the data into a format that is required by your chosen
    algorithm, and how to visualize it with gonum''s plot package. You have also learned
    about different ways of normalizing the data, which is an important step for improving
    the accuracy and speed of many ML algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will introduce supervised learning algorithms and exemplify
    how to choose an ML algorithm, train it, and validate its predictive power on
    previously unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: Further readings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Software Development Waste*. Todd Sedano and Paul Ralph. ICSE ''17 Proceedings
    of the 39th International Conference on Software Engineering. Pages 130-140.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: See the official Go installation instructions at [https://golang.org/doc/install](https://golang.org/doc/install).
    Retrieved February 19th, 2019.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://jupyter.org/about](https://jupyter.org/about). Retrieved February
    19th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/jupyter/jupyter/wiki/Jupyter-kernels](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels).
    Retrieved February 19th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For further instructions, see [https://help.github.com/articles/working-with-jupyter-notebook-files-on-github/](https://help.github.com/articles/working-with-jupyter-notebook-files-on-github/).
    Retrieved February 19th, 2019.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://colab.research.google.com](https://colab.research.google.com). Retrieved
    February 19th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://nbviewer.jupyter.org/](https://nbviewer.jupyter.org/). Retrieved February
    19th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://jupyter.org/hub](https://jupyter.org/hub). Retrieved February 19th,
    2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/jupyter/nbconvert](https://github.com/jupyter/nbconvert).
    Retrieved February 19th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For Docker installation instructions, see [https://docs.docker.com/install/](https://docs.docker.com/install/)
    for Linux and [https://docs.docker.com/docker-for-windows/install/](https://docs.docker.com/docker-for-windows/install/)
    for Windows. Retrieved February 19th, 2019.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'John Blitzer, Mark Dredze, Fernando Pereira. Biographies, Bollywood, *Boom-boxes
    and Blenders: Domain Adaptation for Sentiment Classification.* Association of
    Computational Linguistics (ACL), 2007.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/go-gota/gota](https://github.com/go-gota/gota). Retrieved
    February 19th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://godoc.org/sort#Interface](https://godoc.org/sort#Interface). Retrieved
    February 19th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/yersever/500-person-gender-height-weight-bodymassindex/version/2](https://www.kaggle.com/yersever/500-person-gender-height-weight-bodymassindex/version/2).
    Retrieved February 20th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://code.google.com/archive/p/plotinum/](https://code.google.com/archive/p/plotinum/).
    Retrieved February 20th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/gonum/plot](https://github.com/gonum/plot). Retrieved February
    20th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights).
    Retrieved February 20th, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Guyon, Isabelle. 1996\. *A Scaling Law for the Validation-Set Training-Set Size
    Ratio*. AT&T Bell Lab. 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
