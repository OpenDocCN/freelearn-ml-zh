["```py\npip install ultralytics && pip install pyyaml && pip install roboflow\n```", "```py\nimport torch\nfrom torch.utils.data import DataLoader, Subset\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nimport torchvision\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\nfrom roboflow import Roboflow\nimport glob\nimport os\nimport yaml\nimport cv2\n```", "```py\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n# First convolutional layer with 6 output channels, 5x5 kernel\n        self.conv1 = nn.Conv2d(3, 6, 5)\n# Max pooling layer with 2x2 window and default stride\n        self.pool = nn.MaxPool2d(2, 2)\n# Second convolutional layer with 16 output channels, 5x5 kernel\n        self.conv2 = nn.Conv2d(6, 16, 5)\n# First fully connected layer\n# Flattened input size determined by conv2 output shape\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n# Second fully connected layer with 84 nodes\n        self.fc2 = nn.Linear(120, 84)\n# Final fully connected output layer\n# 10 nodes for 10 image classes\n        self.fc3 = nn.Linear(84, 10)\n    def forward(self, x):\n# Pass input through first conv and activation\n        x = self.pool(F.relu(self.conv1(x)))\n# Second conv and activation, then pool\n        x = self.pool(F.relu(self.conv2(x)))\n# Flatten input for first fully connected layer\n        x = torch.flatten(x, 1)\n# Pass through all fully connected layers and activations\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n```", "```py\nfrom torchvision import models\nmodel = models.resnet18(pretrained=True)\nmodel = models.mobilenet_v2(pretrained=True)\n```", "```py\ntransform = transforms.Compose(\n[transforms.ToTensor(),\ntransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\nfull_dataset = torchvision.datasets.CIFAR10(\n    root='cifar10', train=True, download=True, transform=transform)\nprint(len(full_dataset))\n```", "```py\ninit_indices = list(range(2000)) # indices for initial our \"labeled\" set\nlabeled_set = Subset(full_dataset, init_indices)\n```", "```py\n# Data loaders\nlabeled_loader = DataLoader(labeled_set, batch_size=64, shuffle=True)\n```", "```py\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', \n    'horse', 'ship', 'truck')\nmodel = Net(n_classes=len(classes))\n```", "```py\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n# get some random training images\ndataiter = iter(labeled_loader)\nimages, labels = next(dataiter)\n# show images\nimshow(torchvision.utils.make_grid(images))\n```", "```py\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(5)))\n```", "```py\nfrog  truck truck deer  car\n```", "```py\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n```", "```py\ndef train(model, data_loader, epochs = 100):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n    for epoch in range(epochs):  # loop over the dataset multiple times\n        running_loss = 0.0\n        for i, data in enumerate(data_loader, 0):\n# get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n# zero the parameter gradients\n            optimizer.zero_grad()\n# forward + backward + optimize\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n# print statistics\n            running_loss += loss.item()\n            if i % 10 == 9:    # print every 10 mini-batches\n                print(f'[{epoch + 1}, {i + 1:5d}] loss: {\n                    running_loss / 2000:.3f}')\n                running_loss = 0.0\n    print('Finished Training')\n    return model\n```", "```py\nmodel = train(model, labeled_loader)\n```", "```py\ndef evaluate(model, test_dataset, batch_size=1):\n    # Testing\n    model.eval()\n    test_loader = torch.utils.data.DataLoader(test_dataset, \n        batch_size)\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(test_loader):\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    print('\\nAccuracy of the model on the test images: {} \n        %'.format(100 * correct / total))\n```", "```py\ntest_set = torchvision.datasets.CIFAR10(\n    root='data', train=False, transform=transform, download=True)\nprint(len(test_set))\n```", "```py\nevaluate(model, test_set)\n```", "```py\nAccuracy of the model on the test images: 40.08 %\n```", "```py\ndef least_confident_score(predicted_probs):\n    return 1 - predicted_probs[np.argmax(predicted_probs)]\n```", "```py\nunlabeled_loader = DataLoader(full_dataset, batch_size=1)\n```", "```py\nleast_confident_scores = []\nfor image, label in unlabeled_loader:\n    probs = F.softmax(model(image), dim=1)\n    score = least_confident_score(probs.detach().numpy()[0])\n    least_confident_scores.append(score)\nprint(least_confident_scores)\n```", "```py\n[0.637821763753891, 0.4338147044181824, 0.18698161840438843, 0.6028554439544678, 0.35655343532562256, 0.3845849633216858, 0.4887065887451172, ...]\n```", "```py\nnum_queries = 200\n```", "```py\nsorted_uncertainties, indices = torch.sort(\n    torch.tensor(least_confident_scores))\n```", "```py\nmost_uncertain_indices = indices[-num_queries:]\nprint(f\"sorted_uncertainties: {sorted_uncertainties} \\\n    nmost_uncertain_indices selected: {most_uncertain_indices}\")\n```", "```py\nsorted_uncertainties: tensor([0.0000, 0.0000, 0.0000,  ..., 0.7419, 0.7460, 0.7928], dtype=torch.float64)\nmost_uncertain_indices selected: tensor([45820, 36802, 15912,  8635, 32207, 11987, 39232,  6099, 18543, 29082, 42403, 21331,  5633, 29284, 29566, 23878, 47522, 17097, 15229, 11468, 18130, 45120, 25245, 19864, 45457, 20434, 34309, 10034, 45285, 25496, 40169, 31792, 22868, 35525, 31238, 24694, 48734, 18419, 45289, 16126, 31668, 45971, 26393, ... 44338, 19687, 18283, 23128, 20556, 26325])\n```", "```py\nfig, axs = plt.subplots(1, 5)\nfor i in range(5):\n    image, label = full_dataset[most_uncertain_indices[i]]\n    image = image.squeeze().permute(1, 2, 0) / 2 + 0.5\n    axs[i].imshow(image)\n    axs[i].axis('off')\nplt.show()\n```", "```py\ninit_indices.extend(most_uncertain_indices)\nlabeled_set_2 = Subset(full_dataset, init_indices)\nlabeled_loader_2 = DataLoader(labeled_set, batch_size=64)\nprint(len(labeled_set_2))\n```", "```py\nmodel_2 = Net(n_classes=len(classes))\nmodel_2 = train(model_2, labeled_loader_2)\n```", "```py\nevaluate(model_2, test_set)\n```", "```py\nAccuracy of the model on the test images: 41.54 %\n```", "```py\nmodel = train(model, labeled_loader_2)\nevaluate(model, test_set)\n```", "```py\nAccuracy of the model on the test images: 40.84 %\n```", "```py\nrf = Roboflow(api_key=\"your_key\")\nproject = rf.workspace(\"roboflow-100\").project(\"brain-tumor-m2pbp\")\ndataset = project.version(2).download(\"yolov8\")\n```", "```py\ndef rename_folders(current_folder_name, new_folder_name):\n    # Check if the folder exists\n    if os.path.exists(current_folder_name):\n        # Rename the folder\n        os.rename(current_folder_name, new_folder_name)\n    else:\n        print(f'The folder {current_folder_name} does not exist.')\n# Now let's run it on our three folders train, valid, and test:\nrename_folders(current_folder_name='/content/brain-tumor-2/train',\n    new_folder_name='/content/brain-tumor-2/unlabeled')\nrename_folders(current_folder_name='/content/brain-tumor-2/valid',\n    new_folder_name='/content/brain-tumor-2/testing')\nrename_folders(current_folder_name='/content/brain-tumor-2/test',\n    new_folder_name='/content/brain-tumor-2/labeled')\n```", "```py\npath_data_yaml = '/content/brain-tumor-2/data.yaml'\nwith open(path_data_yaml, 'r') as file:\n    data = yaml.safe_load(file)\ndata['train'] = 'labeled/images'\ndata['val'] = ''\ndata['test'] = 'testing/images'\nwith open(path_data_yaml, 'w') as file:\n    yaml.dump(data, file)\n```", "```py\nunlabeled_files = glob.glob('/content/brain-tumor-2/unlabeled/images/*.jpg')\nlabeled_files = glob.glob('/content/brain-tumor-2/labeled/images/*.jpg')\ntesting_files = glob.glob('/content/brain-tumor-2/testing/images/*.jpg')\nprint(f\"For our demo, we have {len(unlabeled_files)} unlabeled files,\n    {len(labeled_files)} labeled files, and {len(testing_files)} \n    testing files\")\n```", "```py\nFor our demo, we have 6930 unlabeled files, 990 labeled files, and 1980 testing files\n```", "```py\nfrom ultralytics import YOLO\nmodel = YOLO('yolov8s.pt')\nprint('Start training ')\nresults = model.train(data=path_data_yaml,\n    batch=32,\n    task='detect',\n    mode='train',\n    epochs=10\n    )\n```", "```py\nmetrics = model.val(data=path_data_yaml, split='test')\nprint(metrics.results_dict)\n```", "```py\n{'metrics/precision(B)': 0.6022637781613859,\n'metrics/recall(B)': 0.4763619681952341,\n'metrics/mAP50(B)': 0.4953616848732552,\n'metrics/mAP50-95(B)': 0.2252478418006819,\n'fitness': 0.25225922610793927}\n```", "```py\nresults = model(os.path.join('/content/brain-tumor-2/', \n    'unlabeled/images'), verbose=False, conf=0.15)\n```", "```py\nplt.figure(figsize=(12, 8))\nfor i in range(1, 33):\n    plt.subplot(4,8,i)\n    image = results[i].orig_img\n    for b in results[i].boxes.xywhn:\n        x, y, w, h = b.tolist()\n# Convert YOLO format coordinates to OpenCV format coordinates\n        dh, dw, _ = image.shape\n        l = int((x - w / 2) * dw)\n        r = int((x + w / 2) * dw)\n        t = int((y - h / 2) * dh)\n        b = int((y + h / 2) * dh)\n        cv2.rectangle(image, (l, t), (r, b), (0, 255, 0), 1)\n    plt.imshow(image)\nplt.show()\n```", "```py\nconfidences = []\nfor result in results:\n    confidences.append(result.boxes.conf)\n```", "```py\nconfidence_scores = []\nfor confidence in confidences:\n    if len(confidence) > 0:\n        confidence_scores.append(np.min(np.array(confidence.cpu())))\n    else:\n        confidence_scores.append(10)\nprint(confidence_scores)\n```", "```py\nnum_queries = 500\n# Sort by uncertainty\nsorted_uncertainties, indices = torch.sort(torch.tensor(confidence_scores))\n# Get original indices of most uncertain samples\nmost_uncertain_indices = indices[-num_queries:]\n print(f\"sorted_uncertainties: {sorted_uncertainties[0:num_queries]} \\\n    nmost_uncertain_indices selected: {most_uncertain_indices}\")\n```", "```py\nsorted_uncertainties: tensor([0.1500, 0.1500, 0.1501, 0.1501, 0.1501, 0.1501, ..., 0.1598, 0.1598, 0.1598, 0.1599, 0.1599, 0.1599, 0.1599, 0.1599, 0.1600])\nmost_uncertain_indices selected: tensor([4714, 4713, 4712, 4304, 4305, 4306,  ...., 5554, 5553, 5552, 5551, 5550, 5549, 5548, 5547, 3135, 5544, 5543])\n```", "```py\nimages_selected = np.array(\n    glob.glob(os.path.join('/content/brain-tumor-2/', \n        'unlabeled/images', '*.jpg'))\n)[np.array(most_uncertain_indices)]\n```", "```py\nimport shutil\nfor image_path in images_selected:\n    shutil.move(image_path, image_path.replace('unlabeled', \n        'labeled'))\n    label_file = image_path.replace('images', 'labels').replace('.jpg', '.txt')\n    shutil.move(label_file, label_file.replace('unlabeled', \n        'labeled'))\n```", "```py\nimages_labeled = glob.glob('/content/brain-tumor-2/labeled/images/*.jpg')\nlabels_labeled = glob.glob('/content/brain-tumor-2/labeled/labels/*.txt')\nprint(len(images_labeled))\nprint(len(labels_labeled))\n```", "```py\nmodel = YOLO('yolov8s.pt')\nprint('Start training ')\nresults = model.train(data=path_data_yaml,\n    batch=32,\n    task='detect',\n    mode='train',\n    epochs=10\n    )\n```", "```py\nmetrics = model.val(data=path_data_yaml, split='test')\nmetrics.results_dict\n```", "```py\n{'metrics/precision(B)': 0.6469528069030884,\n'metrics/recall(B)': 0.5106541285546612,\n'metrics/mAP50(B)': 0.543579045283473,\n'metrics/mAP50-95(B)': 0.26662268193511757,\n'fitness': 0.29431831826995314}\n```", "```py\nrf = Roboflow(api_key=\"your_key\")\nproject = rf.workspace(\"5060tanapoowapat-yumsarn\").project(\"strawberry-2vs5u\")\ndataset = project.version(2).download(\"yolov8\")\n```", "```py\nFor our demo, we have 3006 unlabeled files, 184 labeled files, and 659 testing files\n```", "```py\nmodel = YOLO('yolov8n-seg.pt')\nprint('Start training ')\nresults = model.train(data=path_data_yaml,\n    batch=16,\n    task='segment',\n    mode='train',\n    epochs=10\n    )\n```", "```py\n{'metrics/precision(B)': 0.673169825129636,\n'metrics/recall(B)': 0.7297833796885302,\n'metrics/mAP50(B)': 0.7664149988792639,\n'metrics/mAP50-95(B)': 0.533442993245899,\n'metrics/precision(M)': 0.7415224838967787,\n'metrics/recall(M)': 0.7482014388489209,\n'metrics/mAP50(M)': 0.8165979711704425,\n'metrics/mAP50-95(M)': 0.5967313838152124,\n'fitness': 1.175458236359971}\n```", "```py\nresults = model(os.path.join(f'/content/{dataset_name}/',\n    'unlabeled/images'), verbose=False, conf=0.25, task='segment')\n```", "```py\nplt.figure(figsize=(12, 8))\n# Generate a list of 32 random integers between 0 and 100\nrandom_integers = [random.randint(0, 100) for _ in range(32)]\nfor i, index in enumerate(random_integers):\n    plt.subplot(4,8,i+1)\n    image = results[index].orig_img\n    for b in results[index].boxes.xywhn:\n        x, y, w, h = b.tolist()\n        # Convert YOLO format coordinates to OpenCV format coordinates\n        dh, dw, _ = image.shape\n        l = int((x - w / 2) * dw)\n        r = int((x + w / 2) * dw)\n        t = int((y - h / 2) * dh)\n        b = int((y + h / 2) * dh)\n    cv2.rectangle(image, (l, t), (r, b), (0, 255, 0), 2)\n    if results[index].masks:\n        overlayed_image = image.copy()\n        for m in results[index].masks:\n            # Make sure both images are of data type uint8\n            mask = np.array(m.data.cpu()[0])\n            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n            image = image.astype(np.uint8)\n            mask = mask*255\n            mask = mask.astype(np.uint8)\n            # Overlay the mask on the RGB image\n            overlayed_image = cv2.addWeighted(overlayed_image, 1, \n                mask, 0.8, 0)\n    plt.imshow(cv2.cvtColor(overlayed_image, cv2.COLOR_BGR2RGB))\nplt.show()\n```", "```py\nsorted_uncertainties: tensor([0.2500, 0.2501, 0.2501, 0.2501, 0.2501, 0.2502, 0.2503, 0.2503, 0.2503, 0.2503, 0.2503,..., 0.2703, 0.2703, 0.2703, 0.2703, 0.2703, 0.2704, 0.2704, 0.2704, 0.2704, 0.2704])\nmost_uncertain_indices selected: tensor([2744,  806, 1822, 1025, 1486,  345,  743, 1374, 2329, 1381,  301, 2322, 2272, 1196, ..., 2127, 2004, 2119, 2118, 1401, 1402, 2666, 2105,  100,   47, 2093,   46, 2092, 2085,  970, 1422])\n```", "```py\n{'metrics/precision(B)': 0.7522007556106134,\n'metrics/recall(B)': 0.7570614064930203,\n'metrics/mAP50(B)': 0.800552933790843,\n'metrics/mAP50-95(B)': 0.6079730626509038,\n'metrics/precision(M)': 0.8061734224988162,\n'metrics/recall(M)': 0.8069544364508393,\n'metrics/mAP50(M)': 0.8511208111235853,\n'metrics/mAP50-95(M)': 0.6554160034789296,\n'fitness': 1.3022175340082929}\n```", "```py\n{'metrics/precision(B)': 0.673169825129636,\n'metrics/recall(B)': 0.7297833796885302,\n'metrics/mAP50(B)': 0.7664149988792639,\n'metrics/mAP50-95(B)': 0.533442993245899,\n'metrics/precision(M)': 0.7415224838967787,\n'metrics/recall(M)': 0.7482014388489209,\n'metrics/mAP50(M)': 0.8165979711704425,\n'metrics/mAP50-95(M)': 0.5967313838152124,\n'fitness': 1.175458236359971}\n```"]