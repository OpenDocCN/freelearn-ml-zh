<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer078">
			<h1 id="_idParaDest-35"><em class="italic"><a id="_idTextAnchor034"/>Chapter 2</em>: Choosing the Right Machine Learning Service in Azure</h1>
			<p>In the previous chapter, we learned about the end-to-end ML process and all the required steps, from data exploration to data preprocessing, training, optimization, deployment, and operation. Understanding the whole process will better help us in choosing the right service for building cloud-based ML services.</p>
			<p>In this chapter, we will help you navigate the different Azure AI services and show you how to select the right service for your ML task. First, we will classify the different services by service abstraction and application domain, and then look at the different trade-offs and benefits of the different services.</p>
			<p>In the next section, we will focus on managed services and jump right into Azure Cognitive Services, multiple pre-trained ML services for general tasks and domains. We will then cover customized Cognitive Services, which is a way to fine-tune a Cognitive Service for a specific task or domain, and end the section by looking into applied AI services.</p>
			<p>In the following section, we will discuss custom ML services in Azure, such as Azure Automated Machine Learning, Azure Machine Learning designer, and the Azure Machine Learning service – the service that we will use throughout this book.</p>
			<p>In the last section, we will look into custom compute services, such as Azure Databricks, Azure Batch, and Data Science Virtual Machines, for building custom ML solutions.</p>
			<p>At the end of this chapter, you will know how to navigate the Azure AI landscape and understand why Azure Machine Learning is the preferred service to build custom ML solutions.</p>
			<p>The following topics will be covered in this chapter:</p>
			<ul>
				<li>Choosing an Azure service for ML</li>
				<li>Managed ML services</li>
				<li>Custom ML services</li>
				<li>Custom compute services for ML</li>
			</ul>
			<h1 id="_idParaDest-36"><a id="_idTextAnchor035"/>Choosing an Azure service for ML</h1>
			<p>Azure provides more than 200 services, of <a id="_idIndexMarker174"/>which more than 30 services are targeted for building solutions for AI and ML. This vast number<a id="_idIndexMarker175"/> of services often makes it difficult for someone new to Azure to choose the right service for a specific task. Choosing the right service for your ML task is the most important decision you will have to make when starting with ML in Azure. In this section, we will provide clear guidance about how to choose the right ML and compute services in Azure.</p>
			<p>The right service with the right layer of abstraction could save you months if not years of time to market your ML-based product or feature. It could help you avoid tedious time-consuming tasks such as improving model performance through transfer learning, re-training, managing, and re-deploying ML models, or monitoring, scaling, and operating inference services and endpoints.</p>
			<p>Choosing the wrong service could mean that you start producing results quickly, but it might become impossible to improve model performance for a specific domain or extend a model for other tasks. Therefore, having a basic understanding of the different Azure AI and ML services will help you to make the right trade-offs and choose the right service for your use case. In the next section, we will help you navigate the many Azure services and Azure AI landscape to identify the right ML service for your use case.</p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor036"/>Navigating the Azure AI landscape</h2>
			<p>For many cloud-based<a id="_idIndexMarker176"/> services, such as<a id="_idIndexMarker177"/> compute, storage, database, or analytics, the most important choice is the service level abstraction – <strong class="bold">Infrastructure as a Service </strong>(<strong class="bold">IaaS</strong>), <strong class="bold">Platform as a Service</strong> (<strong class="bold">PaaS</strong>), or <strong class="bold">Software as a Service</strong> (<strong class="bold">SaaS</strong>). <em class="italic">Figure 2.1</em> shows the difference between the self-managed and managed parts of the application stack for cloud services:</p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B17928_02_01.jpg" alt="Figure 2.1 – An IaaS versus PaaS versus SaaS comparison for cloud services " width="1650" height="607"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1 – An IaaS versus PaaS versus SaaS comparison for cloud services</p>
			<p>Let's compare the different types<a id="_idIndexMarker178"/> of abstractions and responsibilities presented in the previous figure. The application stack is built from left to right, starting with a <em class="italic">data center</em> (building, cooling, power, and so on) that contains <em class="italic">hardware</em> (computers, disks, network cards, switches, and so on). Each machine is powered by an <em class="italic">operating system</em> (Linux or Windows) and runs specific <em class="italic">services</em> (web server, database, cache, and so on) and <em class="italic">applications</em> (for example, WordPress), which store and serve your <em class="italic">data</em> (for example, your custom website):</p>
			<ul>
				<li>With on-premises<a id="_idIndexMarker179"/> compute, you own and manage everything – from the building, cooling, power, physical servers, network connections, switches, and BIOS, up to the operating system, services, applications, and data. If a disk, network interface, or power connection fails, you need to get it changed.</li>
				<li>With <em class="italic">IaaS</em> services, you consume infrastructure from <a id="_idIndexMarker180"/>your cloud provider such as a <strong class="bold">Virtual Machine</strong> (<strong class="bold">VM</strong>). You choose the number of CPUs, memory, disks, network interfaces, and so on, which will all be managed for you, but you need to manage the OS as well as all the services, applications, and data yourself. If there is an important kernel security update, you need to get it installed. IaaS services are the fundamental building blocks for all other services.</li>
				<li><em class="italic">PaaS</em> services let you focus purely on your application. A typical example is so-called <em class="italic">serverless compute</em> such as Azure Functions. Here, you can choose your JVM version to deploy a Java-based application, but you don't need to worry about patching your operating system, your service runtime, or the underlying hardware. PaaS services often provide a good trade-off between ownership, customization, and cost. Most cloud services fall into this category.</li>
				<li>Lastly, <em class="italic">SaaS</em> services are whole applications that are designed, implemented, and managed by the cloud provider. You usually interact with these services through a website or API endpoint, without even knowing what operating system or service runtime is used or what the application code or data model looks like. SaaS services can be compared with popular web services that we use every day, such as Facebook, Netflix, Spotify, or YouTube. Cloud providers often build these services <a id="_idIndexMarker181"/>for specific use cases, such as IoT, genomics, computer vision, and others.</li>
			</ul>
			<p>In conclusion, all Azure services can be placed somewhere on the IaaS, PaaS, and SaaS scale based on the level of service abstraction. We can use this scale to categorize all Azure AI services into three groups:</p>
			<ul>
				<li>Managed ML services (SaaS)</li>
				<li>Custom ML services (PaaS)</li>
				<li>Custom compute services for ML (IaaS)</li>
			</ul>
			<p>Therefore, your first<a id="_idIndexMarker182"/> step in choosing an ML service in Azure is to determine the right service-level abstraction for your use case – by choosing the right trade-off between flexibility, ownership, skills, time, and cost.</p>
			<p>However, choosing an ML service is a bit more nuanced than differentiating only between managed and custom services. Especially for managed ML services, we also need to compare the different application domains and levels of customization and specialization.</p>
			<p>Azure provides many pre-trained domain-specific models and services, such as object detection, sentiment analysis, recommendation engines, and document parsing. Depending on your application domain, you could choose an ML service that includes a pre-trained model. For example, if you need a general face-recognition model, you could consume this as a managed service from Azure. This means that you don't need any training data at all for building such a feature. The decision of using a pre-trained model has a huge impact on your project timeline, as acquiring, cleaning, and labeling training data is one of the most tedious and time-consuming steps in the ML process.</p>
			<p>However, many ML applications are built for highly specialized domains such as medical data analysis, forensic analysis, and the legal profession. If you are building ML-based applications or features for<a id="_idIndexMarker183"/> such a domain, a pre-trained model without any customization for the application domain might not be the right fit. In this case, you can choose a managed ML service that provides customization capabilities – a way to use training data to fine-tune a pre-trained model for a custom domain. This process is also referred to as transfer learning and supported by some managed Azure Machine Learning services.</p>
			<p>Some domains or ML-based applications don't fit into this category and can't easily be fine-tuned for a different application domain. For example, it's not practical to pre-train a recommendation engine on someone else's ratings, transfer text-to-speech features to a generative <a id="_idIndexMarker184"/>model for classical music, or fine-tune a two-dimensional model with three-dimensional image data. In these cases, you have no other choice but to create your own models using your own training data.</p>
			<p>Using the preceding examples, we can sub-divide the managed and custom ML services by the amount of required training data and application domain into the following groups:</p>
			<ul>
				<li>No training data required</li>
				<li>Some training data required for customization</li>
				<li>Training data required</li>
			</ul>
			<p>Therefore, the second option to choose a managed or custom ML service is based on your application domain and requirements for training data and model specialization. Similar to service abstraction, the trade-off is between flexibility (customization), ownership, skills, time, and cost.</p>
			<p>Let's compare these requirements and look at a similar IaaS, PaaS, and SaaS comparison specifically for cloud-based ML services in <em class="italic">Figure 2.2</em>:</p>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/B17928_02_02.jpg" alt="Figure 2.2 – An IaaS versus PaaS versus SaaS comparison for ML services " width="1650" height="607"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2 – An IaaS versus PaaS versus SaaS comparison for ML services</p>
			<p>As you can see in the <a id="_idIndexMarker185"/>preceding figure, you can evaluate the preferred service abstraction for your ML service along similar dimensions as any other cloud service – depending on which part of the stack you want to manage yourself. The table contains a few adjustments specifically for ML applications, such as <em class="italic">libraries</em> (ML frameworks, tools, and runtimes) instead<a id="_idIndexMarker186"/> of services and a <em class="italic">model</em> instead of an application. SaaS services for ML can either allow customization, which means you can bring your own data, or don't allow customization, which means you don't have to provide any training data at all.</p>
			<p>Armed with this knowledge about service abstractions (IaaS versus PaaS versus SaaS) as well as application domain and required training data (no training data versus data for customization through transfer learning versus training data), we can start dissecting the Azure Machine Learning landscape.</p>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor037"/>Consuming a managed AI service</h2>
			<p>Consuming a <a id="_idIndexMarker187"/>managed AI service through an API is the easiest and quickest way to build ML-based features or applications. It's simple <a id="_idIndexMarker188"/>because you don't have to clean the training data and train the model, you don't have to manage compute clusters for training or inferencing, and you don't have to monitor and scale your model deployment for making batch predictions.</p>
			<p>For many managed AI services in Azure, all you need is to call a web service with your API key and your data, and the API will respond with the corresponding prediction, which is often a combination of multiple model scores. The Azure Cognitive Services API for understanding images, for example, will return predictions for object detection, image tagging, adult content classification, gory and racy classification, face detection, gender and age detection, image description, and more within a single API call.</p>
			<p>If you are dealing with a general ML problem and a general domain – such as image tagging, text extraction, speech-to-text, and translation – you are lucky enough to be able to choose such a managed AI service for your application. Image analysis for general image domains (such as photos), text analysis, text-to-speech and speech-to-text, language, and translation services are common ML problems that can take advantage of an off-the-shelf ML solution. We will explore the different APIs and services for managed pre-trained AI services later, in the <em class="italic">Azure Cognitive Services</em> section.</p>
			<p>A downside of managed AI <a id="_idIndexMarker189"/>services is that they all ship with pre-trained black-box models that we can't see, interpret, analyze, or optimize. This makes it infeasible to use these APIs for highly specific domains. If you work with MRI images for cancer detection, you won't find Azure's general object detection algorithm very useful.</p>
			<p>For these specific cases – general ML problems with custom application domains – Azure provides customizable managed AI services. One such example is the Azure Custom Vision service, which lets you fine-tune a pre-trained model for common image recognition tasks. What <a id="_idIndexMarker190"/>sets these services apart is that you can provide your own training data to fine-tune a model for a custom application domain, while benefiting from the advantages of using a managed service.</p>
			<p>Another such example is <strong class="bold">Azure Form Recognizer</strong>, a tool that<a id="_idIndexMarker191"/> allows you to extract printed and handwritten text from a structured document. It can be fine-tuned to detect custom text formats used in your application domain. We will take a look at all of these customizable managed services later, in the <em class="italic">Custom cognitive services</em> and <em class="italic">Azure applied services</em> sections.</p>
			<p>However, if you need the flexibility of choosing a specific model or algorithm that is not supported as a service (for example, image segmentation), then you don't have a choice but to implement your own model and build your own AI solution. We will dive deeper into this topic in the next section.</p>
			<p>Let's end this section with important advice for developing cloud- and ML-based features or applications – if possible, opt for a managed service with a pre-trained model over building a custom ML solution. Consuming a pre-trained model through an API is often magnitudes easier, faster, and cheaper than training, deploying, and operating your own ML service. Many practical applications can take advantage of generalized pre-trained <a id="_idIndexMarker192"/>models or fine-tuned customized models, and the list of provided models, services, and domains is constantly growing.</p>
			<p>Throughout this book, we <a id="_idIndexMarker193"/>will help you to master the skill of building custom ML applications in Azure, to cover all use cases where consuming a managed AI service is not possible.</p>
			<h2 id="_idParaDest-39"><a id="_idTextAnchor038"/>Building a custom AI service</h2>
			<p>If you can't consume a<a id="_idIndexMarker194"/> managed AI service either because there is no model or service available for your use case, or the fine-tuning <a id="_idIndexMarker195"/>capabilities are not sufficient for your application domain, you have no other choice but to build a custom AI solution.</p>
			<p>You can choose either PaaS or IaaS services to build a custom AI solution in Azure. Both types of services will give you a similar flexibility in choosing your own ML ingredients, such as picking your preferred programming language and libraries for implementing and training ML models, choosing your own data sources and formats as training data, and choosing specific deployment strategies, such as optimization for batch prediction or low-latency on-device inferencing.</p>
			<p>However, this flexibility comes at a cost, which is usually significantly higher than consuming a pre-trained or customized AI service. The higher costs are a result of the additional tasks, skills, and investments required for successfully building and operating an ML service. The most important differences for building a custom AI solution over consuming an AI service are the following:</p>
			<ul>
				<li>Collecting, preprocessing, and labeling training data</li>
				<li>Building infrastructure and automation for training and inferencing</li>
				<li>The modeling, training, and optimization of ML models</li>
				<li>Operating the ML service in production</li>
			</ul>
			<p>It's easy to see that the additional complexity doesn't only come from training a custom model but from many other tasks in the end-to-end ML process. The availability of a sufficient amount of training data, the quality of the data and the availability of people for labeling this data are the major blockers to build a high-performing custom AI solutions. Therefore, you need to make sure that training data is available before the start of the project or can be acquired during the project.</p>
			<p>The second most important additional cost and resources are related to infrastructure. Modeling, training, and optimizing is an ongoing iterative process for the lifetime of an ML service. After a deployment, we often collect more training data, record model metrics, measure the model drift, and repeat the whole process over and over. Therefore, even for smaller ML projects, investments in infrastructure are significant but essential for the long-term success of the project.</p>
			<p>Larger companies even<a id="_idIndexMarker196"/> split these responsibilities into different teams to address the need for different skillsets for both areas – one for building and maintaining the ML infrastructure and one for ML modeling, training, and optimization. This clearly shows that both infrastructure and modeling are equally important for developing successful ML projects.</p>
			<p>The best trade-off in<a id="_idIndexMarker197"/> terms of flexibility and ownership for building a cloud-based custom AI service is to choose a PaaS-based ML platform. Therefore, a great custom ML platform supports you with all these infrastructure setups and operations, facilitates your modeling and optimization tasks, provides abstractions to encapsulate repetitive workloads, and offers automation to minimize manual effort during the project life cycle. On top, a custom ML service provides you with the flexibility to choose any ML framework, any modeling technique and training algorithm, and any data source and format to build a fully custom AI solution.</p>
			<p>Azure Machine Learning is a great example of a PaaS-based service for building custom ML solutions and for optimizing the whole end-to-end life cycle of ML projects. We will take a closer look at Azure Machine Learning and compare its capabilities with other custom ML services later, in the <em class="italic">Custom ML services</em> section, and cover it in much more detail in the subsequent chapters.</p>
			<p>In this book, we will give you all the required skills to build your own custom ML service from start to finish, using Azure Machine Learning as your managed ML service of choice.</p>
			<p>However, it's worth noting that in order to build custom AI services, you don't necessarily need a platform to register your models, to define your datasets, or to track your training scores. You can simply pick your favorite compute service (for example, Azure Kubernetes Service), your favorite storage service (for example, Azure Data Lake Storage), and your favorite database service (for example, Azure Cosmos DB) and build your own custom solution. In fact, you can use any compute service to build your custom IaaS-based ML application in Azure.</p>
			<p>Choosing IaaS services to<a id="_idIndexMarker198"/> build your own ML applications gives you the most flexibility in terms of choosing any infrastructure component during your ML process. On the other hand, it also means that you need to manually set up, configure, and integrate these services as well as setting up identities, authentication, and access control, which results in a higher upfront investment, higher infrastructure development costs, and the need for a specific skillset.</p>
			<p>Azure provides excellent IaaS <a id="_idIndexMarker199"/>compute services to build custom ML solutions. You can choose from simple VMs, VMs with pre-installed ML images, batch computation services and services for scalable distributed computing. We will see a few service examples later, in the <em class="italic">Custom compute services for ML</em> section.</p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor039"/>What is the Azure Machine Learning service?</h2>
			<p>Before we start<a id="_idIndexMarker200"/> looking into the specific managed and custom ML services, we want to clear some confusion around the term <strong class="bold">Azure Machine Learning</strong>, which is not only prominent on the cover of this book but also a popular ML <a id="_idIndexMarker201"/>service in Azure, a workspace for other ML services, and a popular keyword across the internet, blogs, and books.</p>
			<p>First and foremost, the term <em class="italic">Azure Machine Learning</em> stands for a popular Azure service (<a href="https://docs.microsoft.com/en-us/azure/machine-learning/overview-what-is-azure-machine-learning">https://docs.microsoft.com/en-us/azure/machine-learning/overview-what-is-azure-machine-learning</a>) that provides capabilities for building custom ML solutions. The service contains different components to manage resources (such as compute clusters and data storage) and assets (such as datasets, experiments, models, pipelines, Docker environments, and endpoints), as well as access to these resources and assets, all within the same workspace.</p>
			<p>This is the service that we will use throughout this book to build an end-to-end pipeline for training, deploying, and operating custom ML models. You will start by creating your first Azure Machine Learning workspace in the next chapter.</p>
			<p>In order to build custom ML models, you will create training clusters, track experiments, register data as datasets, store trained models, manage Docker images for training and inferencing, and configure endpoints, all within Azure Machine Learning. </p>
			<p>Throughout this book, we will mostly use the Python APIs (<a href="https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py">https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py</a>) to interact with Azure Machine Learning. However, you can also use a UI portal to access and manage the resources and assets, create experiments, submit training jobs, visualize training results, create Docker environments, and deploy inference clusters.</p>
			<p>The UI to interact with Azure Machine<a id="_idIndexMarker202"/> Learning is called <strong class="bold">Azure Machine Learning studio</strong> (<a href="https://docs.microsoft.com/en-us/azure/machine-learning/overview-what-is-machine-learning-studio">https://docs.microsoft.com/en-us/azure/machine-learning/overview-what-is-machine-learning-studio</a>). This name is not to be confused with an older Azure service, Azure Machine Learning Studio – a GUI-based service to create and deploy ML services through a block-based drag-and-drop<a id="_idIndexMarker203"/> interface, which is now called <strong class="bold">Azure Machine Learning Studio (classic)</strong> (<a href="https://studio.azureml.net/">https://studio.azureml.net/</a>).</p>
			<p>The Azure Machine Learning <a id="_idIndexMarker204"/>service also provides access to other ML services that share the same resources and assets through the ML workspace. This includes services such as Azure Automated Machine Learner, the Azure Machine Learning designer – the new GUI-based experience for Azure Machine Learning, a data labeling tool, and an integrated notebook server for Azure Machine Learning (not to be confused with the discontinued <strong class="source-inline">https://notebooks.azure.com/experience</strong>), which all can be created within a workspace in Azure Machine Learning. Therefore, Azure Machine Learning is sometimes referred to<a id="_idIndexMarker205"/> as the Azure Machine Learning service or the Azure Machine Learning workspace (<a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace">https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace</a>).</p>
			<p>Knowing these subtle differences about the different terms and services for Azure Machine Learning, you are ready to learn more about the different managed and custom ML services in Azure.</p>
			<h1 id="_idParaDest-41"><a id="_idTextAnchor040"/>Managed ML services</h1>
			<p>If you are dealing <a id="_idIndexMarker206"/>with a well-defined general-purpose ML problem in the domain of text, image, video, language, or documents, then the chances are high that Azure already provides a managed ML service for this problem.</p>
			<p>Managed ML services are very easy to use, quick to embed into an application, and usually don't require any operational overhead. This makes them perfect for creating AI-based applications or features without the need for collecting training data, training models, and operating model deployments in production. Most importantly, managed ML services don't require any ML expertise to build ML-based applications.</p>
			<p>Some examples of well-defined ML problems are image classification, image tagging, object detection, face detection, handwriting recognition, speech-to-text and text-to-speech conversion, speaker recognition, translation, spell-checking, keywords and entity extraction, sentiment analysis, adult content filtering, and document parsing.</p>
			<p>Managed ML services are<a id="_idIndexMarker207"/> usually used with pre-trained models that sometimes can be trained or fine-tuned for a specific application domain. Using customized models in managed ML services combines the benefits of managed services with the flexibility of custom application domains.</p>
			<p>In this section, we will look into Azure Cognitive Services, customizable AI services, and Azure Applied AI Services.</p>
			<h2 id="_idParaDest-42"><a id="_idTextAnchor041"/>Azure Cognitive Services</h2>
			<p>Let's start <a id="_idIndexMarker208"/>with Azure's most popular service for managed AI capabilities, Azure Cognitive Services. <strong class="bold">Azure Cognitive Services</strong> is a collection of <a id="_idIndexMarker209"/>APIs containing multiple pre-trained ML models for well-defined common problems across the following categories – vision, language, speech, and decision.</p>
			<p>Azure Cognitive Services models are very easy to use and can be integrated by a single REST API call from within any programming language. This makes Cognitive Services a popular choice for adding ML capabilities to existing applications. Some examples of popular Cognitive Services are the following:</p>
			<ul>
				<li><em class="italic">Vision</em>: Computer Vision and Face API</li>
				<li><em class="italic">Language</em>: Text analytics and translator service</li>
				<li><em class="italic">Speech</em>: Text analytics, speech-to-text, text-to-speech, and speech translation</li>
				<li><em class="italic">Decision</em>: Anomaly detection and content moderation</li>
			</ul>
			<p>Most of the Cognitive Services APIs work very similarly. You first deploy a specific Cognitive Service (for example, Computer Vision and text analytics) or a Cognitive Services multi-service account in Azure. Once the service is deployed, you can retrieve the API endpoint and access key from the service and call the Cognitive Service API with your data and API key. This is all you have to do to enrich an existing application with AI capabilities.</p>
			<p>To give you a taste of how these services are used, we will walk you through an example of the Cognitive Service for Computer Vision. We will embed the functionality in a simple Python application. The following code is an example for calling the Cognitive Services API for computer<a id="_idIndexMarker210"/> vision. We will use the Analyze Image API with the free F0 tier to extract categories, tags, and a description from a sample image. Let's start <a id="_idIndexMarker211"/>with some setup code so that we can later use the <strong class="source-inline">requests</strong> library and fetch predictions from the Cognitive Services API:</p>
			<p class="source-code">import requests</p>
			<p class="source-code">region='eastus2'</p>
			<p class="source-code">language='en'</p>
			<p class="source-code">version='v3.1'</p>
			<p class="source-code">key = '&lt;insert access key&gt;'</p>
			<p class="source-code">url = f"https://{region}.api.cognitive.microsoft.com" \</p>
			<p class="source-code">    + f"/vision/{version}/analyze"</p>
			<p>In the previous code snippet, we defined the region, language, API version, and access key for the Cognitive Services API. You can find these details on the <strong class="bold">Service overview</strong> or <strong class="bold">Properties</strong> tab in the Azure portal. We will use these components to build the service endpoint. Next, let's define the parameters for the API call, including a URL to an image of the Eiffel Tower:</p>
			<p class="source-code">params = {</p>
			<p class="source-code">    'visualFeatures': 'Categories,Tags,Description',</p>
			<p class="source-code">    'language': language</p>
			<p class="source-code">}</p>
			<p class="source-code">headers = {</p>
			<p class="source-code">    'Content-Type': 'application/json',</p>
			<p class="source-code">    'Ocp-Apim-Subscription-Key': key</p>
			<p class="source-code">}</p>
			<p class="source-code">payload = {</p>
			<p class="source-code">    'url': 'https://../Eiffel_Tower.jpg'</p>
			<p class="source-code">}</p>
			<p>The only thing that is left is calling requests with all the parameters and the image URL. We get back a JSON response containing the scores of multiple models:</p>
			<p class="source-code">response = requests.post(url,</p>
			<p class="source-code">                         json=payload,</p>
			<p class="source-code">                         params=params,</p>
			<p class="source-code">                         headers=headers)</p>
			<p class="source-code">result = response.json()</p>
			<p class="source-code">print(result) </p>
			<p>As you can see in the preceding <a id="_idIndexMarker212"/>code example, using Cognitive Services boils down to sending an HTTP request. In Python, this is straightforward, using the <strong class="source-inline">requests</strong> library. The response body contains standard JSON<a id="_idIndexMarker213"/> and encodes the results of the Cognitive Services API. The resulting JSON output from the API will have the following structure:</p>
			<p class="source-code">{ </p>
			<p class="source-code">    "<strong class="bold">categories</strong>": [...], </p>
			<p class="source-code">    "<strong class="bold">tags</strong>": [...], </p>
			<p class="source-code">    "<strong class="bold">description</strong>": {...}, </p>
			<p class="source-code">    "requestId": "...", </p>
			<p class="source-code">    "metadata": { </p>
			<p class="source-code">        "width": 288, </p>
			<p class="source-code">        "height": 480, </p>
			<p class="source-code">        "format": "Jpeg" </p>
			<p class="source-code">    } </p>
			<p class="source-code">} </p>
			<p>The <strong class="source-inline">categories</strong> key contains object <a id="_idIndexMarker214"/>categories and derived classifications, such as a landmark detection result, including a confidence score. In the example of the Eiffel Tower image, the Cognitive Service detected a building with a score of almost 95% and identified it as a landmark with almost 100% confidence:</p>
			<p class="source-code">"categories": [ </p>
			<p class="source-code">    { </p>
			<p class="source-code">        "name": "<strong class="bold">building_</strong>", </p>
			<p class="source-code">        "score": <strong class="bold">0.9453125</strong>, </p>
			<p class="source-code">        "detail": { </p>
			<p class="source-code">            "landmarks": [ </p>
			<p class="source-code">                { </p>
			<p class="source-code">                    "name": "Eiffel Tower", </p>
			<p class="source-code">                    "confidence": 0.99992179870605469 </p>
			<p class="source-code">                } </p>
			<p class="source-code">            ] </p>
			<p class="source-code">       } </p>
			<p class="source-code">    } </p>
			<p class="source-code">] </p>
			<p>The <strong class="source-inline">tags</strong> key shows<a id="_idIndexMarker215"/> you multiple tags that are relevant for the whole image. In addition, each tag comes<a id="_idIndexMarker216"/> with a confidence score. As we can see in the response of the API, the model is confident that the picture was taken outdoors:</p>
			<p class="source-code">"tags": [ </p>
			<p class="source-code">   { </p>
			<p class="source-code">       "name": "outdoor", </p>
			<p class="source-code">        "confidence": 0.99838995933532715 </p>
			<p class="source-code">    }, </p>
			<p class="source-code">    { </p>
			<p class="source-code">       "name": "tower", </p>
			<p class="source-code">        "confidence": 0.63238395233132431 </p>
			<p class="source-code">    }, ... </p>
			<p class="source-code">] </p>
			<p>Finally, the <strong class="source-inline">description</strong> tag gives you more tags and an auto-generated image caption. This is cool, isn't it? Imagine<a id="_idIndexMarker217"/> how fast you could implement a tag-based image search by simply extracting image tags using Azure Cognitive Services and indexing the tags for each image URL:</p>
			<p class="source-code">"description": { </p>
			<p class="source-code">    "tags": [ </p>
			<p class="source-code">        "outdoor", "building", "tower", ... </p>
			<p class="source-code">    ], </p>
			<p class="source-code">    "captions": [ </p>
			<p class="source-code">        { </p>
			<p class="source-code">            "text": "a large clock tower in the background with Eiffel Tower in the background", </p>
			<p class="source-code">            "confidence": 0.74846089195278742 </p>
			<p class="source-code">        } </p>
			<p class="source-code">    ] </p>
			<p class="source-code">} </p>
			<p>The result of the Cognitive<a id="_idIndexMarker218"/> Services computer vision API is just one example of how this service can be used. We requested the image features of <a id="_idIndexMarker219"/>categories, tags, and description from the API, which are returned as keys of the JSON object. Each of the category and tag predictions returns the top results in combination with a confidence value. Some categories might trigger other detection models, such as faces, handwritten text recognition, and OCR. </p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">You can explore and test many of the other Azure Cognitive Services APIs by visiting the respective service websites. Here are a few examples:</p>
			<p class="callout"><a href="https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/">https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/</a></p>
			<p class="callout"><a href="https://azure.microsoft.com/en-us/services/cognitive-services/language-service/">https://azure.microsoft.com/en-us/services/cognitive-services/language-service/</a></p>
			<p class="callout"><a href="https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/">https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/</a></p>
			<p>Using the preceding example, calling Azure Cognitive Service with <strong class="source-inline">requests</strong>, you can implement a method that automatically adds image captions to your product images in a retail application by wrapping the preceding snippet in an <strong class="source-inline">analyze()</strong> method and applying it to all images in your dataset:</p>
			<p class="source-code">for url in product_image_urls: </p>
			<p class="source-code">    res = analyze(url, key, features=['Description']) </p>
			<p class="source-code">    caption = res['description']['captions'][0]['text'] </p>
			<p class="source-code">    print(caption) </p>
			<p>You can see that this is the <a id="_idIndexMarker220"/>quickest way to integrate a scalable deep learning-based image analysis service (such as creating a caption for an image) into your custom application. If you find this interesting, it is time to also<a id="_idIndexMarker221"/> experiment with the other Cognitive Services APIs.</p>
			<p>All Azure Cognitive Services have one thing in common – they use a pre-trained black-box ML model to perform predictions of the individual ML tasks. This is fine when we are dealing with faces or photos<a id="_idIndexMarker222"/> but can be problematic when dealing with a specific application domain, such as medical images. In this case, you will be delighted to hear that you can fine-tune some of the Cognitive Services for your custom application domain by providing custom training data. Let's take a closer look at these customizable services in the next section.</p>
			<h2 id="_idParaDest-43"><a id="_idTextAnchor042"/>Custom Cognitive Services</h2>
			<p>One major downside with<a id="_idIndexMarker223"/> Cognitive Services is that you can only use the functionalities that are provided by the API. This means you can't customize<a id="_idIndexMarker224"/> the labels or tags in the image classification API or, for example, use the model to classify different types of materials. To do so, you would need to customize the model in the Cognitive Services API – and this is exactly what some <strong class="bold">custom Cognitive Services</strong> allow you to do.</p>
			<p>Here is a list of popular customizable Cognitive Service APIs that can be fine-tuned to a specific application domain using your own training data:</p>
			<ul>
				<li><em class="italic">Vision</em>: Azure Custom Vision</li>
				<li><em class="italic">Language</em>: Language Understanding and QnA Maker</li>
				<li><em class="italic">Speech</em>: Custom speech-to-text</li>
				<li><em class="italic">Speech</em>: Custom text-to-speech </li>
				<li><em class="italic">Speech</em>: Speaker recognition</li>
				<li><em class="italic">Decision</em>: Azure Personalizer</li>
			</ul>
			<p>Each of the preceding services provides an interface to train or customize a built-in ML model with your own domain-specific training data. We won't go into details for each of these services in this book but rather look at two examples of these customizable Cognitive Services – Azure Personalizer and Custom Vision. Azure Personalizer is an interesting service that lets you optimize an online recommendation engine through reinforcement learning. We will take a closer look at Azure Personalizer in <a href="B17928_13_ePub.xhtml#_idTextAnchor202"><em class="italic">Chapter 13</em></a>, <em class="italic">Building a Recommendation Engine in Azure</em>, and compare it to other state-of-the-art recommendation systems.</p>
			<p>Let's look into the Azure Custom Vision service as an example of a customizable managed AI service in Azure in this chapter. Azure Custom Vision lets you fine-tune a pre-trained ML model on your own training data. This process is called transfer learning and is often used in ML to transfer previously learned feature extraction capabilities to a new objective or domain.</p>
			<p>Azure Custom Vision provides<a id="_idIndexMarker225"/> a UI to upload and classify your images (or tag your objects) and subsequently train the model, using a state-of-the-art computer vision model through the press of a button. <em class="italic">Figure 2.3</em> shows the finished training for an object detection model in the<a id="_idIndexMarker226"/> Azure Custom Vision service:</p>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/B17928_02_003.jpg" alt="Figure 2.3 – Azure Custom Vision training results " width="1256" height="771"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3 – Azure Custom Vision training results</p>
			<p>You can see in the preceding figure that training is as easy as clicking the <strong class="bold">Train</strong> button with the <strong class="bold">Quick Test</strong> option enabled at the top right, or customizing the training process using the advanced option. You don't have to write any code or select an error metric to be optimized; it's all <a id="_idIndexMarker227"/>managed for you. In the screenshot, you can see the result of training, with three metrics that are automatically computed on a validation set. By moving the classification probability threshold at the top left, you can even shift the weight toward higher precision or higher recall, depending on whether you want to avoid false positives or maximize true positives.</p>
			<p>This gives you the power of a pre-trained managed Cognitive Service with the flexibility of a custom application domain. Once the model is trained and published, it can be consumed using a<a id="_idIndexMarker228"/> REST API as we did with Cognitive Services. Click the <strong class="bold">Prediction URL</strong> button at the top to retrieve the prediction endpoint and parameters. The following code block is a sample snippet for Python using the <strong class="source-inline">requests</strong> library:</p>
			<p class="source-code">import requests </p>
			<p class="source-code">def score(img_url, key, project_id, iteration_name):</p>
			<p class="source-code">    endpoint = 'https://%s.api.cognitive.microsoft.com' \</p>
			<p class="source-code">      + '/customvision/v3.0/Prediction/%s' \</p>
			<p class="source-code">      + '/detect/iterations/%s/url' \ </p>
			<p class="source-code">      % (region, project_id, iteration_name) </p>
			<p class="source-code">    headers = {</p>
			<p class="source-code">        'Content-Type': 'application/json',</p>
			<p class="source-code">        'Prediction-Key': key</p>
			<p class="source-code">    } </p>
			<p class="source-code">    payload = { 'url': img_url } </p>
			<p class="source-code">    </p>
			<p class="source-code">    r = requests.post(url, json=payload, headers=headers) </p>
			<p class="source-code">    return r.json() </p>
			<p>In the preceding code, we<a id="_idIndexMarker229"/> implement a function that looks very similar to the one we used with Cognitive Services. In fact, only<a id="_idIndexMarker230"/> the endpoints and <strong class="source-inline">requests</strong> parameter have changed. We can now call the function as before: </p>
			<p class="source-code">url = 'https://../Material_Experiment_1.jpg' </p>
			<p class="source-code">key = '&lt;insert api key&gt;' </p>
			<p class="source-code">project_id = '&lt;insert project key&gt;' </p>
			<p class="source-code">iteration_name = 'Iteration2' </p>
			<p class="source-code">res = score(url, key, project_id, iteration_name) </p>
			<p class="source-code">print(res) </p>
			<p>The response is also a<a id="_idIndexMarker231"/> JSON object and now looks like the following: </p>
			<p class="source-code">{ </p>
			<p class="source-code">    "Id":"7796df8e-acbc-45fc-90b4-1b0c81b73639", </p>
			<p class="source-code">    "Project":"00ae2d88-a767-4ff6-ba5f-33cdf4817c44", </p>
			<p class="source-code">    "Iteration":"59ec199d-f3fb-443a-b708-4bca79e1b7f7", </p>
			<p class="source-code">    "Created":"2019-03-20T16:47:31.322Z", </p>
			<p class="source-code">    "Predictions":[ </p>
			<p class="source-code">        { </p>
			<p class="source-code">             "TagId":"d9cb3fa5-1ff3-4e98-8d47-2ef42d7fb373", </p>
			<p class="source-code">             "TagName":"defect", </p>
			<p class="source-code">             "Probability":1.0 </p>
			<p class="source-code">        }, </p>
			<p class="source-code">        { </p>
			<p class="source-code">             "TagId":"9a8d63fb-b6ed-4462-bcff-77ff72084d99", </p>
			<p class="source-code">             "TagName":"defect", </p>
			<p class="source-code">             "Probability":0.1087869 </p>
			<p class="source-code">        } </p>
			<p class="source-code">    ] </p>
			<p class="source-code">} </p>
			<p>The preceding response now contains a <strong class="source-inline">Predictions</strong> key with all the predicted categories and confidence<a id="_idIndexMarker232"/> values from Custom Vision. As you can see, the example looks very similar to the Cognitive Services example. However, we need to pass arguments to specify the project and published iteration of the trained model. Using this built-in serving API, we save ourselves a lot of effort in implementing and operating a deployment infrastructure. If we want to use the trained model somewhere else (for example, in an iPhone or Android application, or in a Kubernetes cluster), we can export the model in many different formats, such as<a id="_idIndexMarker233"/> TensorFlow, TensorFlow.js, Core ML, and ONNX.</p>
			<p>Custom Cognitive Services are a fantastic way to efficiently test or showcase an ML model for a custom <a id="_idIndexMarker234"/>application domain when dealing with a well-defined ML problem. You can use either the GUI or API to interact with these <a id="_idIndexMarker235"/>services and consume the models through a managed API or export them to any device platform. Another benefit is that you don't need deep ML expertise to apply the transfer learning algorithm and can simply use the predefined models and error metrics.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor043"/>Azure Applied AI Services</h2>
			<p>In the previous sections, we <a id="_idIndexMarker236"/>saw examples for Azure Cognitive Services for both fully pre-trained models and for customizable models. In this <a id="_idIndexMarker237"/>section, we will extend the list of customizable managed AI services to all services grouped under the name <strong class="bold">Azure Applied AI Services</strong>. These Applied AI Services are – like custom Cognitive Services – pre-trained customizable AI services loosely grouped under a common name to build specialized services.</p>
			<p>These Applied AI Services are all services that have been developed by Microsoft on top of Cognitive Services due to strong demand from large enterprise customers for these exact services. The following services are currently part of Applied AI Services, but unlike Cognitive Services, they don't fit neatly into categories. Here is a list of Applied AI Services that you can use to build your own custom models for specific applications:</p>
			<ul>
				<li><em class="italic">Conversations</em>: Azure Bot Service</li>
				<li><em class="italic">Documents</em>: Azure Form Recognizer</li>
				<li><em class="italic">Search</em>: Azure Cognitive Search</li>
				<li><em class="italic">Monitoring</em>: Azure Metrics Advisor</li>
				<li><em class="italic">Videos</em>: Azure Video Analyzer</li>
				<li><em class="italic">Accessibility</em>: Azure Immersive Reader</li>
			</ul>
			<p>We will not go into much detail about every service in this list, but we encourage you to look into them in more detail if some of them made you curious. You can find detailed information and examples in the Azure documentation (<a href="https://docs.microsoft.com/en-us/azure/applied-ai-services/">https://docs.microsoft.com/en-us/azure/applied-ai-services/</a>) or the Azure product page for Applied AI Services (<a href="https://azure.microsoft.com/en-us/product-categories/applied-ai-services">https://azure.microsoft.com/en-us/product-categories/applied-ai-services</a>). Both Azure Form Recognizer and Azure Cognitive Search use the Cognitive Service image APIs to extract text and handwritten notes from documents. While the former helps you to parse this data from structured documents, the latter creates a search index on all extracted data and provides a full-text search over unstructured documents, including handwritten documents.</p>
			<p>As you can see, if you<a id="_idIndexMarker238"/> have these exact same problems, then it is easy to use these Applied AI Services and integrate them into your application. While the application domain is limited, you <a id="_idIndexMarker239"/>can greatly accelerate any project that deals with these use cases.</p>
			<p>If you require full customization of the algorithms, models, and error metrics, you need to implement the model and ML pipeline on your own. In the following sections, we will discuss how this can be done in Azure using custom ML services. </p>
			<h1 id="_idParaDest-45"><a id="_idTextAnchor044"/>Custom ML services</h1>
			<p>Azure provides many <a id="_idIndexMarker240"/>PaaS services for different specialized domains. Platform services are built on top of IaaS services and implement useful abstractions and functionalities commonly used for the relevant domain. One such domain is ML, where you will find various services for building custom ML models. In this section, we will take a look at the most popular custom ML PaaS services.</p>
			<p>We will start first with the GUI-based solutions Azure Machine Learning Studio (classic) and Azure Machine Learning designer, and then switch to the GUI and API-based Azure Automated Machine Learning. Finally, we will take a look at Azure Machine Learning, the service that provides the workspaces for resources and assets for both previous services.</p>
			<p>Azure Machine Learning will help us to create notebook instances for authoring, train clusters for training, upload and register datasets, track experiments and trained models, as well as to track our Conda/PIP environments and Docker images.</p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor045"/>Azure Machine Learning Studio (classic)</h2>
			<p><strong class="bold">Azure Machine Learning Studio (classic)</strong> is a widely adopted tool in Azure to build, train, optimize, and <a id="_idIndexMarker241"/>deploy ML models using a GUI and drag and drop, block-based programming model. It's one of the <a id="_idIndexMarker242"/>oldest managed cloud services for ML in Azure and provides a robust and large number of features, algorithms, and extensions through R and Python support. The service provides built-in building blocks for clustering, regression, classification, anomaly detection, and recommendation, as well as data and statistical and text analysis. You can also extend the functionality of Azure Machine Learning Studio by using custom code blocks for Python or R.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Azure Machine Learning Studio (classic) will be retired by August 31, 2024, and customers will have to transition to Azure Machine Learning. Therefore, we strongly recommend starting any new projects in Azure Machine Learning.</p>
			<p><em class="italic">Figure 2.4</em> shows an overview of the main drag and drop GUI of Azure Machine Learning Studio (classic):</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer072" class="IMG---Figure">
					<img src="image/B17928_02_004.jpg" alt="Figure 2.4 – Azure Machine Learning Studio (classic)  " width="1041" height="685"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4 – Azure Machine Learning Studio (classic) </p>
			<p>Functional blocks <a id="_idIndexMarker243"/>can be chosen from the catalog on the left, dropped onto the canvas on the right, and connected to form a complex computational graph. Each block can define input and output data, which is passed along through the connections from other blocks.</p>
			<p>Azure Machine Learning Studio (classic) lets you import data from many different sources, such as CSV files from Azure Blob storage or direct imports from SQL Server, Azure Cosmos DB, or Apache Hive. It also provides many built-in blocks for the conversion of common data formats and data types, normalization, and cleaning.</p>
			<p>One of the reasons why Azure Machine Learning Studio (classic) was very popular lies in its deployment capabilities. If you have created a data pipeline and trained a model, you can save the trained model within Machine Learning Studio (classic). Now, within a few clicks, you can create a web service using the trained model to deploy a scoring service. The user input is defined<a id="_idIndexMarker244"/> through the very same data import block that was used for the training data. It can be connected to pipe user input to the pipeline or return the model predictions to the web service. With another click, you can deploy the pipeline to production using a web service plan.</p>
			<p>While Azure Machine <a id="_idIndexMarker245"/>Learning Studio was a very popular GUI-based tool for building ML pipelines – and to build simple web-based ML applications – it is not the tool of choice for writing custom ML applications. The workspace can get convoluted very <a id="_idIndexMarker246"/>quickly, which will make it difficult to follow the data flow through the pipeline. Another drawback is that the organization of custom code within blocks becomes difficult for larger pipelines, and that there are a limited number of integrations into other Azure services. And finally, after many years in service, Azure Machine Learning (classic) will be discontinued by 2024.</p>
			<p>If you are looking for a similar type of block-based programming, with better support for code organization and pipelines and better integration into Azure, then you should look into Azure Machine Learning designer.</p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor046"/>Azure Machine Learning designer</h2>
			<p>While Azure Machine<a id="_idIndexMarker247"/> Learning Studio (classic) was very popular and feature-rich, its integration into other Azure services has always<a id="_idIndexMarker248"/> been limited. Ingesting and pre processing data from different data sources is not easy, managing access and sharing datasets is difficult, and customizations are limited to Azure Machine Learning Studio (classic). However, with the creation of Azure Machine Learning, Microsoft also revamped the old Studio and created a new version inside Azure Machine Learning called the designer.</p>
			<p><strong class="bold">Azure Machine Learning designer</strong> is fully integrated with Azure Machine Learning and therefore has access to and can share all resources and assets within the workspace. It allows the GUI-based creation of ML pipelines while collaborating with other data engineers and data scientists in the same workspace. They all can share the same compute resources that automatically scale up and down to the needs of the developers.</p>
			<p><em class="italic">Figure 2.5</em> shows the UI of the designer, which is based on the same block-based, drag and drop UI as Azure Machine Learning Studio (classic):</p>
			<div>
				<div id="_idContainer073" class="IMG---Figure">
					<img src="image/B17928_02_005.jpg" alt="Figure 2.5 – The Azure Machine Learning designer UI " width="1281" height="771"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.5 – The Azure Machine Learning designer UI</p>
			<p>As you can see in the previous figure, creating ML processes through graphical dataflows still has the same <a id="_idIndexMarker249"/>disadvantages as discussed previously. However, we can at least share data ingestion, preprocessing, cleaning, and feature extraction stages with other users in the workspace and focus solely <a id="_idIndexMarker250"/>on ML tasks in the designer.</p>
			<p>GUIs to create block-based ML training pipelines are not for everyone. However, if you prefer a block-based, drag and drop environment, then Azure Machine Learning designer is the right choice for you. On top, all your work is stored in the Azure Machine Learning workspace, which means you can easily extend or migrate parts of your GUI-based pipeline to a code-based version and vice versa. Overall, it's a good choice to start your ML project in Azure Machine Learning using the designer. However, if you want to build a scalable ML project that <a id="_idIndexMarker251"/>allows the collaboration of multiple teams, it's recommended to use a non-GUI service such as the Azure Machine Learning workspace, which we will use throughout this book. </p>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor047"/>Azure Automated Machine Learning</h2>
			<p>Every user should be given<a id="_idIndexMarker252"/> the possibility to create<a id="_idIndexMarker253"/> predictive models and turn conforming datasets into ML models. This is the democratization of AI, where every user who can use a spreadsheet application has the possibility to <em class="italic">create</em> ML models out of data in spreadsheets without any ML expertise.</p>
			<p>This is where <strong class="bold">Azure Automated Machine Learning</strong> comes into play! Azure Automated Machine Learning is a no-code tool that lets you specify a dataset, a target column, and ML tasks to train an ML model from a spreadsheet. It is a great abstraction for a user who just wants to fit training data to a target variable without the knowledge about feature extraction, modeling, training, and optimization. Similar to Azure Machine Learning designer, Automated ML is a service that can be created from the Azure Machine Learning workspace and, therefore, has access to all resources and assets defined in the workspace.</p>
			<p>It's worth noting that the typical spreadsheet user is not the only target group for using Automated ML to automatically train, optimize, and stack ML models. Automated ML is a natural extension of hyperparameter tuning, where the model architecture and preprocessing itself become hyperparameters. We will take a closer look at this field of application and its Python API in <a href="B17928_11_ePub.xhtml#_idTextAnchor178"><em class="italic">Chapter 11</em></a>, <em class="italic">Hyperparameter Tuning and Automated Machine Learning</em>.</p>
			<p><em class="italic">Figure 2.6</em> shows the last step in the Automated ML interface, where the user needs to choose the ML task to be solved for the specified data: </p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/B17928_02_006.jpg" alt="Figure 2.6 – Automated ML " width="1157" height="685"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.6 – Automated ML</p>
			<p>As we can see in the<a id="_idIndexMarker254"/> previous figure, Automated Machine Learning currently supports classification, regression, and time-series forecasting tasks. Together with the informative explanations for each task, this is something we can put into the hands of Excel users and can help ML engineers to<a id="_idIndexMarker255"/> quickly build and deploy a great baseline model.</p>
			<p>In addition, Automated Machine Learning gives you access to all training runs, all trained models, and their training scores, as well as useful built-in metrics, visualization, and insights. In <em class="italic">Figure 2.7</em>, we can see the ROC curve as one example of many built-in visualizations of the training runs:</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B17928_02_007.jpg" alt="Figure 2.7 – The Receiver Operating Characteristic (ROC) curve for the Automated ML result " width="789" height="370"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.7 – The Receiver Operating Characteristic (ROC) curve for the Automated ML result</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Automated Machine Learning can also be accessed programmatically directly from your authoring environment through the Azure Machine Learning SDK. You can find more information about the Automated ML feature in the Azure Machine Learning Python SDK in the Microsoft documentation: <a href="https://docs.microsoft.com/en-us/python/api/azureml-automl-core/azureml.automl.core?view=azure-ml-py">https://docs.microsoft.com/en-us/python/api/azureml-automl-core/azureml.automl.core?view=azure-ml-py</a>.</p>
			<p>Automated Machine Learning is a<a id="_idIndexMarker256"/> great service, providing a true <a id="_idIndexMarker257"/>ML-as-a-service platform with a reasonable abstraction for non-experienced and highly skilled users. This service empowers every developer to take advantage of ML and will power the AI capabilities of future products.</p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor048"/>Azure Machine Learning workspace</h2>
			<p><strong class="bold">Azure Machine Learning</strong> is Azure's flagship ML service to implement and automize all steps of the end-to-end ML process for building custom ML applications. It was initially built to<a id="_idIndexMarker258"/> combine all other ML services under a single workspace and facilitate the sharing of resources, assets, and <a id="_idIndexMarker259"/>permissions – therefore, is also often referred to as the Azure Machine Learning workspace.</p>
			<p>Currently, Azure Machine Learning provides, combines, and abstracts many important ML infrastructure services and functionalities, such as tracking experiment runs and training jobs, a model registry, an environment and container registry based on conda/pip and Docker, a dataset registry, pipelines, and compute and storage infrastructure. It also implements a common set of identities and permissions to facilitate access to these individual components from within the Azure workspace.</p>
			<p>Besides all the infrastructure services, it also integrates Azure Automated Machine Learning, Azure Machine Learning designer (the new Azure Machine Learning Studio (classic)), and a data-labeling service in a single workspace. All the services in the workspace can access and share resources and assets. Azure Machine Learning provides many useful abstractions and functionalities to develop custom ML applications and has a great trade-off in flexibility, ease of use, and price. Therefore, it is also our service of choice for building custom ML solutions in Azure, and we will use it throughout this book.</p>
			<p><em class="italic">Figure 2.8</em> shows Azure Machine Learning Studio, the UI of Azure Machine Learning. As mentioned previously, the name is not to be confused with Azure Machine Learning Studio (classic), which is the old GUI- and block-based ML service.</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B17928_02_008.jpg" alt="Figure 2.8 – Azure Machine Learning Studio  " width="1107" height="662"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.8 – Azure Machine Learning Studio </p>
			<p>As you can see in the<a id="_idIndexMarker260"/> previous figure, we can manage different resources and assets in the Azure Machine Learning workspace. All these <a id="_idIndexMarker261"/>resources can not only be accessed through the UI but also through the SDK and the Azure Machine Learning CLI. Throughout this book, we will mostly use the Python SDK for Azure Machine Learning. You can find more information about the Azure Machine Learning Python SDK in the Microsoft documentation: <a href="https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py">https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py</a>.</p>
			<p>Throughout the book, we will use three types of compute resources for the different steps in the ML process. We can create these resources directly from within Azure Machine Learning with a couple of lines of code and the Azure Machine Learning SDK:</p>
			<ul>
				<li><strong class="bold">A compute instance for the authoring runtime and Jupyter</strong>: This is a compute instance with pre-installed and pre-configured ML libraries and the Azure Machine Learning SDK optimized for authoring and experimentation.</li>
				<li><strong class="bold">A training cluster for the ML execution runtime during training</strong>: This is an auto-scalable compute cluster with pre-installed and pre-configured ML libraries and the Azure Machine Learning SDK optimized for large- scale training and optimization.</li>
				<li><strong class="bold">An inferencing cluster for the execution runtime during scoring</strong>: This is a managed Kubernetes cluster using Azure Kubernetes Service.</li>
			</ul>
			<p>Besides compute, we <a id="_idIndexMarker262"/>will also use Azure Machine Learning to create storage resources that serve as storage for authoring and application code, job logs and output, visualization, trained models, dataset snapshots, and so on. We can use the ML SDK to manage Azure Blob storage containers in the ML workspace and to write the output and assets of jobs directly to the storage.</p>
			<p>Besides managing infrastructure, Azure Machine Learning can do a lot more for us. Most importantly, it can track our experiment runs and collect output files, graphs, artifacts, logs, and custom metrics, such as training loss. This is also by far the most powerful gateway to enter the Azure Machine Learning platform.</p>
			<p>By simply annotating your existing ML project, you can track all your model scores, stream your log output, collect all your output images, and store the best model for each iteration or run. All you need is a few simple lines of code to never lose track of a model for a particular training run ever again, or to keep track of your training scores, graphs, and artifacts. All this can be done without changing anything about your ML setup; your <a id="_idIndexMarker263"/>experiments can run on a local machine and your training runs can be scheduled on AWS.</p>
			<p>Besides tracking job artifacts, you can also track dataset versions, environments, and models in Azure Machine Learning using only a few lines of code. This gives you the benefit of being able to keep a predictable history of changes in your workspace. By doing this, you can create repeatable experiments that always read the same data snapshot for a training run, use the same specified Conda or PIP environment, and update the trained model in the<a id="_idIndexMarker264"/> model history and artifact store. This brings you on track toward a <strong class="bold">Continuous Integration/Continuous Deployment</strong> (<strong class="bold">CI/CD</strong>) approach for your training pipeline. We will discuss this approach in more detail in <a href="B17928_16_ePub.xhtml#_idTextAnchor252"><em class="italic">Chapter 16</em></a>, <em class="italic">Bringing Models into Production with MLOps</em>.</p>
			<p>Speaking of pipelines, Azure Machine Learning lets you abstract your authoring code into pipelines. A pipeline can trigger or run data preparation jobs in parallel, create and start training clusters, execute a training script on the cluster, or initiate and perform blue/green deployments. You can see how everything guides you toward a repeatable, versioned, end-to-end pipeline for your training process. The greatest part, however, is that you don't have to go all in to benefit from Azure Machine Learning.</p>
			<p>Instead, you can start little by little, adding more and more useful functionalities to your existing training process and then gradually move an existing or new ML project to the Azure Machine Learning workspace. You will get your feet wet and set up your Azure Machine Learning<a id="_idIndexMarker265"/> workspace in the next chapter. This will show you how easy it is to get started, to integrate with existing ML projects, and how to set up your authoring and training environment for new projects.</p>
			<p>Azure Machine Learning is the best <a id="_idIndexMarker266"/>PaaS service for building custom ML applications in Azure. However, if you prefer tinkering with VMs, debugging distributed job executions, and setting up MPI for distributed training jobs, you should take a closer look at the next section, where will learn more about custom compute services commonly used for ML.</p>
			<h1 id="_idParaDest-50"><a id="_idTextAnchor049"/>Custom compute services for ML</h1>
			<p>So far, we have had a look <a id="_idIndexMarker267"/>at services offering managed pre-trained ML models with and without some degree of customization, as well as custom ML services, including Azure Machine Learning. Azure Machine Learning is our service of choice for developing custom ML applications, due to the great trade-off between flexibility, functionality, and comfort.</p>
			<p>However, we understand that these trade-offs might not work for everyone and that some people want the highest flexibility for building custom ML applications using only IaaS services. These are the same services that build the foundation for any other PaaS service in Azure, including Azure Machine Learning. Hence, as a final step, we will delve into options where you can use custom compute services in Azure to build flexible ML solutions.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor050"/>Azure Databricks</h2>
			<p><strong class="bold">Azure Databricks</strong> is a <a id="_idIndexMarker268"/>managed service <a id="_idIndexMarker269"/>on Azure, offering the Databricks platform as a completely integrated solution. Azure Databricks is, therefore, a so-called first-class citizen in Azure. This means, compared to other third-party solutions, a user can deploy from the Azure Marketplace, and it is fully integrated with Azure Active Directory, allowing Azure administrators to treat this service the same way as any other Microsoft managed service on the platform.</p>
			<p>The Databricks platform itself is a big data analytics platform utilizing Apache Spark. The company behind this<a id="_idIndexMarker270"/> platform is also called Databricks (<a href="https://databricks.com/">https://databricks.com/</a>) and was founded<a id="_idIndexMarker271"/> by the original creators of Spark to offer this ever-changing open source technology as a ready-made product to customers.</p>
			<p>To understand how to <a id="_idIndexMarker272"/>perform ML in Azure Databricks, we will first have a look at the underlying technology for distributed computing that powers all computation and processing – Apache Spark.</p>
			<h3>Distributed computing using Apache Spark</h3>
			<p>Apache Spark is a<a id="_idIndexMarker273"/> distributed in-memory analytical engine, taking its roots from the Apache Hadoop framework. The main idea behind it is to distribute a graph of computations to the cluster's worker nodes. Think of these<a id="_idIndexMarker274"/> nodes as different independent servers, possibly even in different physical locations, that all together work on the same job, or – to be more precise – on their own part of the job. They are, in turn, controlled and orchestrated by a primary node that keeps an eye on scheduling, resource availability, and wiring up data streams.</p>
			<p><em class="italic">Figure 2.9</em> shows the most important components of Apache Spark. In the middle, we can see the main<a id="_idIndexMarker275"/> compute engine called Spark Core. Spark Core oversees job scheduling and monitoring, interaction with the underlying storage system, memory management on the nodes, and general fault tolerance for the overall cluster. For the scheduling, it either uses its own <a id="_idIndexMarker276"/>scheduler called <strong class="bold">Spark Scheduler</strong> or can run on other scheduling<a id="_idIndexMarker277"/> options, namely <strong class="bold">Apache YARN</strong> or <strong class="bold">Apache Mesos</strong>. When using <a id="_idIndexMarker278"/>Apache Spark in Azure Databricks, the job scheduling engine is part of the managed service and managed by Databricks:</p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B17928_02_09.jpg" alt="Figure 2.9 – The Apache Spark framework " width="1403" height="442"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.9 – The Apache Spark framework</p>
			<p>As a storage system, it <a id="_idIndexMarker279"/>supports a myriad of options, from standard local storage and the <strong class="bold">Hadoop Distributed File System</strong> (<strong class="bold">HDFS</strong>) to Azure Data Lake and Amazon S3 storage, and even has direct access to <strong class="bold">Relational Database Management Systems </strong>(<strong class="bold">RDBMS</strong>) and<a id="_idIndexMarker280"/> documents from NoSQL systems.</p>
			<p>Finally, to define <a id="_idIndexMarker281"/>and dispatch jobs, the end user can utilize <a id="_idIndexMarker282"/>different programming languages, such as Scala, Python and R, to define the computational graphs that will be executed via Apache Spark. In addition to all available libraries and frameworks, Apache Spark provides a few built-in libraries to facilitate both data access and manipulation via Spark SQL, as well as distributed computations via Spark Streaming, MLlib, and GraphX.</p>
			<h3>ML libraries for Azure Databricks</h3>
			<p>To train ML models on<a id="_idIndexMarker283"/> Spark and consequently on Azure Databricks, we require libraries that, on the one hand, implement the relevant ML algorithms and numerical functions and, on the other hand, understand the Spark framework to take advantage of the distributed computation primitives.</p>
			<p>Apache Spark comes with such a built-in <a id="_idIndexMarker284"/>ML library called MLlib. This library is designed to implement traditional ML algorithms, such as different clustering and embedding techniques, logistic regression, random forest, gradient boosting, and <strong class="bold">Alternating Least Squares</strong> (<strong class="bold">ALS</strong>) matrix <a id="_idIndexMarker285"/>factorization for recommendations, while taking advantage of the distributed computation capabilities of Apache Spark.</p>
			<p>Thanks to the supported languages, you can also use all other popular ML libraries in Apache Spark on Azure Databricks, such as TensorFlow, XGBoost, scikit-learn, PyTorch, Horovod, and many other well-known libraries (see <a href="https://databricks.com/product/machine-learning-runtime">https://databricks.com/product/machine-learning-runtime</a>).</p>
			<p>Azure Databricks also supports MLflow, an open source framework for automating the end-to-end ML process, which we will see in action in <a href="B17928_16_ePub.xhtml#_idTextAnchor252"><em class="italic">Chapter 16</em></a>, <em class="italic">Bringing Models into Production with MLOps</em>, as well as their own version of AutoML, and a notebook server.</p>
			<p>However, large-scale<a id="_idIndexMarker286"/> distributed compute engines usually don't come without any downsides, and the same is true for Apache Spark and Databricks. While Databricks did a great job of hiding most of the complexity and made it easy to get up and running with Spark, the complexity is not gone. Monitoring jobs and utilized cluster resources, debugging, and optimizing jobs, as well as reading and understanding logs becomes very complex without in-depth knowledge about Spark.</p>
			<p>Simply put, in addition to understanding machine learning processes and algorithms, the user also has to understand the internals of Spark and its distributed job scheduling and execution model. This adds another layer of complexity for running, debugging, and optimizing ML jobs, which makes the whole experience a lot more difficult.</p>
			<p>Moreover, not all ML libraries and algorithms are easily capable of distributing the workload to different nodes, which often leads to suboptimal utilization of the cluster resources. Why use a complex framework for distributed computing and pay a premium for primary orchestration nodes when the underlying algorithms are executed on a single worker node?</p>
			<p>Azure Databricks is a good choice when migrating on-premises Spark-based services to Azure, or building big data analytics, transformation, or recommendation services. However, it's complexity and premium price make it most often a poor choice for ML projects.</p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor051"/>Azure Batch</h2>
			<p>Azure Batch is a<a id="_idIndexMarker287"/> very mature and flexible batch-processing and scheduling framework for running massive parallel workloads in Azure. It lets you define custom applications and jobs that can be scheduled and executed on a pool of VMs. It processes data stored in Azure Storage and can dynamically scale the compute resources for you to up to tens of thousands of VMs. <strong class="bold">Azure Batch</strong> is the foundation for<a id="_idIndexMarker288"/> Azure Machine Learning training clusters and, hence, is a great solution if you want to build your own custom ML service.</p>
			<p>Azure Batch is usually used for <em class="italic">embarrassing parallel</em> workloads, namely work that can be easily parallelized across multiple machines without the need for any orchestration. This makes Azure Batch less flexible than Azure Databricks, which provides primitives for distributed coordination, but therefore is also less complicated for end users. Typical applications are computing 3D renderings, video and image processing, compute-intensive simulations, or general batch computations, such as computing recommendation results or batch-scoring ML models. </p>
			<p>Batch jobs will be executed on compute pools or custom VMs, which means Azure Batch supports many <em class="italic">exotic</em> compute instances, including high-performance compute instances, memory-optimized and GPU-enabled VMs, just to name a few. It also supports multi-instance<a id="_idIndexMarker289"/> workloads using a <strong class="bold">Message Passing Interface</strong> (<strong class="bold">MPI</strong>) and <strong class="bold">Remote Direct Memory Access</strong> (<strong class="bold">RDMA</strong>).</p>
			<p>If you are building your <a id="_idIndexMarker290"/>custom ML solution and want to avoid the comfort and flexibility of Azure Machine Learning, then Azure Batch is a great choice for you. It gives you all the flexibility to choose custom instances, frameworks, libraries, and data formats. However, Azure Machine Learning is – in almost every aspect – a better, easier, and more integrated solution, specifically for building ML applications.</p>
			<h2 id="_idParaDest-53"><a id="_idTextAnchor052"/>Data Science Virtual Machines</h2>
			<p>It doesn't require a <a id="_idIndexMarker291"/>separate section to explain that you can use traditional VMs in Azure for building a custom cloud-based ML service on top of IaaS services. This would be as low-level as it gets within a cloud service, where you have full control over every network interface, disk configuration, and user permission on the VM. You can use any instance type available in your region that fits any of your memory, compute, or graphics needs and requirements.</p>
			<p>However, if you are looking for a VM to be your cloud-based ML workstation – for example, to take advantage of flexible cloud compute, to run your ML experiments, or to perform on-demand<a id="_idIndexMarker292"/> GPU-accelerated training – there is a better choice than using a standard VM, namely <strong class="bold">Data Science Virtual Machines</strong> (<strong class="bold">DSVMs</strong>).</p>
			<p>A DSVM is a pre-built pre-configured VM optimized for data science and ML applications. It comes with many of the popular ML libraries pre-installed and supports Windows and Linux. Pre-installed libraries and services include CUDA and cuDNN, NVIDIA drivers and system management interfaces (<strong class="source-inline">nvidia-smi</strong>), CRAN-R, Julia, Python, Jupyter, TensorFlow, PyTorch, Horovod, XGBoost, LightGBM, OpenCV, and ONNX. You can start a DSVM on many different instance types, including GPU-accelerated instances.</p>
			<p>A DSVM is your <a id="_idIndexMarker293"/>service of choice whenever you need a carefree VM with your popular ML tools pre-installed and pre-configured. However, it is worth noting that you probably don't need a DSVM when working in an Azure Machine Learning workspace, as you can create compute instances and training clusters to run your ML experiments and training. Nevertheless, it's a great alternative ML experimentation environment.</p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/>Summary</h1>
			<p>In this chapter, you learned how to navigate the Azure AI landscape and choose the right ML service for your application and domain. While IaaS services give you great flexibility, PaaS services often provide useful abstractions and manage complex integrations for you. SaaS applications are great if they are designed for your application domain or can be customized.</p>
			<p>We investigated Azure services for building ML applications in each of the preceding categories, such as Azure Cognitive Services (SaaS), Azure Machine Learning (PaaS), and Azure Batch (IaaS). Azure Machine Learning is not only the most comprehensive and integrated ML service in Azure but also provides a good trade-off between flexibility, functionality, and comfort. Therefore, we will use Azure Machine Learning throughout this book to develop an end-to-end custom ML solution.</p>
			<p>If you really want to build your own ML infrastructure from scratch and not rely on any managed ML service, you should look into custom compute services that are optimized for large computational workloads, such as Azure Databricks or Azure Batch. If you simply need a VM ready for ML experiments without any pre-built service integrations or model and experiment tracking, you can choose a DSVM.</p>
			<p>In the next chapter, we will continue our journey by setting up an Azure Machine Learning workspace. In order to do this, we will first learn how to deploy resources in Azure programmatically; we will then have an in-depth look at the ML workspace itself, at how we can use notebooks and incorporate compute nodes for model training, and finally, we will run our first little experiment.</p>
		</div>
	</div>
</div>
</body></html>