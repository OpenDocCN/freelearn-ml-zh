- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Interpreting NLP Transformers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we learned about applying explanation methods to a specific
    type of deep learning model architecture, convolutional neural networks. In this
    chapter, we will provide some tools to do the same with the transformer model
    architecture. Transformer models are becoming increasingly popular, and their
    most common use case is **Natural Language Processing** (**NLP**). We broached
    the subject of NLP in *Chapter 5*, *Local Model-Agnostic Interpretation Methods*.
    In this chapter, we will do so too but with transformer-specific methods and tools.
    First, we will discuss how to visualize attention mechanisms, followed by interpreting
    integrated gradient attributions, and lastly, exploring the Swiss Army knife that
    is the **Learning Interpretability Tool** (**LIT**).
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the main topics we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing attention with BertViz
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpreting token attributions with integrated gradients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LIME, counterfactuals, and other possibilities with the LIT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter’s example uses the `mldatasets`, `pandas`, `numpy` , `torch`, `transformers`
    , `bertviz`, `captum`, and `lit-nlp` libraries. Instructions on how to install
    all these libraries are in the *Preface*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this chapter is located here: [https://packt.link/Yzf2L](https://packt.link/Yzf2L)'
  prefs: []
  type: TYPE_NORMAL
- en: The mission
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You are a data scientist working for a yet-to-launch startup in New York City.
    This startup aims to establish itself as the go-to place to find the best, newest,
    and most exciting culinary destinations in the city!
  prefs: []
  type: TYPE_NORMAL
- en: The aim is to move beyond the typical structured data about restaurants and
    delve deep into the vast array of textual data available online, from social media
    sites to directory websites. The startup believes that while ratings might provide
    a simplistic quantification of experiences, reviews contain richer details and
    can offer multidimensional insights into what makes a restaurant special.
  prefs: []
  type: TYPE_NORMAL
- en: Reviews express detailed sentiments that capture diverse user experiences, unlike
    ratings, which provide a singular, non-comparative perspective. By harnessing
    the granularity present in reviews, the startup can tailor its recommendations
    to cater to various audience segments with greater precision.
  prefs: []
  type: TYPE_NORMAL
- en: Your team has been discussing how to leverage sentiment analysis on reviews
    to determine how to best look for the feelings that exemplify the experience users
    look for in the recommender system. Binary sentiment analysis (positive/negative)
    does not offer the nuances required to distinguish between usual and unique experiences,
    or those catering to specific groups such as travelers, families, or couples.
    Also, the startup founders believe that the dining experience is multifaceted.
    An experience that might be seen as “positive” could range from “comforting and
    nostalgic” to “thrilling and adventurous.” Distinguishing these nuances will empower
    the recommender system to be more personalized and effective.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your manager encountered a sentiment classification model that has 27 categories
    trained with a dataset called GoEmotions, published by Google. GoEmotions offers
    a more detailed classification of sentiments, capturing the richness of human
    emotions more effectively than binary classification models. However, the lead
    strategist decided there were too many classifications and decided to group them
    into a different emotion taxonomy called Ekman (see *Figure 8.1*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.1: The Taxonomy of Emotions'
  prefs: []
  type: TYPE_NORMAL
- en: Ekman’s taxonomy of emotions is a classification system developed by psychologist
    Paul Ekman, which identifies six basic emotions that he believed to be universally
    experienced in all human cultures. These six emotions are joy, sadness, fear,
    anger, disgust, and surprise. Ekman suggested that these are fundamental emotions
    that are hard-wired into our brains and expressed in the same way by people all
    around the world, regardless of their culture. These emotions can be identified
    through specific facial expressions, and understanding them can help in fields
    like psychology, communication, and sociology. Ekman’s taxonomy offers a more
    concise set of emotion categories while still preserving the nuances. This makes
    the interpretation more manageable and actionable for the development team and
    other stakeholders. However, we’ve had to keep neutral, which cannot be classified
    into any Ekman category.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the next step is to interpret the GoEmotions Ekman classifier model with
    the Tripadvisor review dataset to understand what the model learned and uncover
    patterns that could be useful to the development of the recommender system. It’s
    an open-ended task. The general goal is to understand the patterns the model has
    identified in the reviews and how these correlate with Ekman’s categories. However,
    this path could lead to many findings or a dead-end. Leadership stressed that
    data scientists, like yourself, would have to use their judgment to find opportunities
    in data exploration and model interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: By uncovering these patterns, the startup can fine-tune its algorithm to look
    for reviews that resonate with these emotions. The insights can also guide restaurant
    partnerships, marketing strategies, and feature enhancements to the platform.
  prefs: []
  type: TYPE_NORMAL
- en: The approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You have decided to take a three-prong approach:'
  prefs: []
  type: TYPE_NORMAL
- en: You will look under the hood of the transformer model to visualize attention
    weights with BertViz to find relevant patterns in those mechanisms.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, you’ll produce saliency maps where attributions are color-coded for each
    token in reviews of interest, using the integrated gradients method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lastly, you’ll examine counterfactuals with the LIT.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You hope that you can deliver some actionable insights to the leadership team
    with these steps.
  prefs: []
  type: TYPE_NORMAL
- en: The preparations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will find the code for this example here: [https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/master/08/ReviewSentiment.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/master/08/ReviewSentiment.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: Loading the libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To run this example, you need to install the following libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mldatasets` to load the dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas` and `numpy` to manipulate it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`torch` (PyTorch) and `transformers` to load and configure the model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bertviz`, `captum`, and `lit-nlp` to generate and visualize the model interpretations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You should load all of them first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, we work on data understanding and preparations.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding and preparing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We load the data like this into a DataFrame we call `reviews_df`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'There should be over 380,000 records and 12 columns. We can verify this is
    the case with `info()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The output checks out. There are no missing values. However, there are only
    three numeric features, one date, and all the rest are object data types because
    they are mostly text. Given that this chapter focuses on NLP, this shouldn’t come
    as a surprise. Let’s examine the data dictionary to understand what we will use
    from this DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: The data dictionary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'These are the 12 columns in the DataFrame, most of which are there for reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '`review_id`: ID – a unique identifier for the review (only for reference)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`author_id`: ID – a unique identifier for the author (only for reference)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`restaurant_name`: text – the name of the restaurant (only for reference)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`url_restaurant`: **URL** – **Uniform Resource Identifier** to locate the web
    page where the restaurant review is located (only for reference)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_date`: date – the date when the review was made (only for reference)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_title`: text – the title the author wrote for the review'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_preview`: text – the preview generated for the review'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_full`: text – the full review written by the author'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rating`: ordinal – a rating given by the author to the establishment (a 1–5
    rating scale)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`positive_sentiment`: binary – whether the review has a positive sentiment
    according to a binary sentiment model (positive/negative)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`label`: categorical – the predicted emotion by the GoEmotions classifier (according
    to the Ekman seven-class classification: joy, neutral, sadness, disgust, fear,
    anger, and surprise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score`: continuous – the predicted probability that the review belongs to
    the predicted class'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It’s a multi-class model, so it predicted scores for each class. However, we
    only stored the `score` of the most probable class (`label`). Therefore, the last
    two columns represent the output of the model. As for the input, let’s examine
    the first three rows to illustrate it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18406_08_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.2: The first three reviews of the dataset'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s the first two columns in *Figure 8.2*, `review_title` and `review_full`,
    that represent the input for the model. It does so as a single piece of text,
    so when we discuss *the review*, we are referring to a string that concatenates
    both with a colon and space, separating them like this: *Disappointing: Food was
    mediocre at best. The lamb chops are an image they feature on the websites opening
    page*.'
  prefs: []
  type: TYPE_NORMAL
- en: But these are not the only columns that could matter in an analysis. We could,
    of course, analyze reviews by author, restaurant, date, and so on, and even connect
    restaurants to specific coordinates on a map to understand how sentiment varies
    geographically. This is all very interesting. However, we won’t go into any detail
    here because although it might be relevant to the general mission of sentiment
    analysis, it will divert from the technical topic of this chapter, which is interpreting
    transformer models.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, we will explore some features that are highly correlated with the
    model outcomes, which are the `rating` provided by the author and the outcome
    of the binary sentiment analysis model (`positive_sentiment`). You would definitely
    expect these to match because reviews are generally consistent with the ratings
    — that is, a positive review will have a higher rating than a negative one. Likewise,
    some emotions are more positive than negative.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand these correlations a bit better, let’s aggregate the reviews
    to get an average `rating` and `positive_sentiment` for each emotion like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The above code will produce the output in *Figure 8.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: A summary table of the emotions predicted for the review dataset'
  prefs: []
  type: TYPE_NORMAL
- en: As you can appreciate in *Figure 8.3*, the majority of the 380,000 reviews are
    placed in the joy label or class. Joy is a positive emotion, so it makes sense
    that our binary sentiment classifier classified over 90% of them as positive and
    that the average rating for joyous reviews is nearly 4.5\. The DataFrame is sorted
    by the average rating because it’s not a product of a model (which could be wrong),
    so it can perhaps give us the clearest indication of what predicted emotions the
    end users perceive to be the most positive. And as you go down in the list, you
    have positive emotions first, followed by neutral, and then the negative ones.
    Please note that the percentage of reviews that was deemed to be positive by the
    binary classifier is somewhat consistent with the same order provided by the average
    rating.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the average score for each label tells us how confident the
    predictions are on average that it belongs to said label. Joy, sadness, and surprise
    are the most confident. Since the multi-class predictions are seven numbers that
    add up to 1, an average score of 56.6% for anger is an indication that many predictions
    in which anger is the most probable emotion will have other emotions with a sizable
    probability – perhaps even emotions that may seem incompatible. We will put a
    pin on this because it would be interesting to explore this later.
  prefs: []
  type: TYPE_NORMAL
- en: Another fascinating interpretation you can make of *Figure 8.3* is that a large
    proportion of surprise is negative, despite it being supposedly perceived to be
    a positive emotion. Also, with an average rating lower than 4, there are probably
    quite a few negative ratings weighing them down. We won’t explore the data in
    this chapter, but indeed, there are plenty of negative reviews that embody a sentiment
    of surprise. In light of this finding and for the sake of adapting to the mission,
    let’s say you presented this to your bosses, and they decided it made sense to
    focus on surprise because market research shows that people love to find and be
    surprised by “hidden gems.” Therefore, it’s critical that a recommendation engine
    can help unearth any restaurants that are positively surprising, while suppressing
    any that are consistently negatively surprising.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Later on, we will be randomly selecting from our dataset, so in order to do
    that consistently, it’s best to set a random seed. It’s always good practice to
    initialize the seed in all the pertinent libraries, even though in this case it
    won’t make a difference for PyTorch inference operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s define a `device` variable because if you have a CUDA-enabled GPU,
    model inference will perform quicker. Then, we will load the tokenizer (`goemotions_tok`)
    and model (`goemotions_mdl`) from Hugging Face using the `from_pretrained` function.
    Lastly, we will move all the weights and biases to your device with the `model.to(device)`
    function and set the model to evaluation mode with `model.eval()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the model is loaded, we always inspect its architecture with `print(goemotions_mdl)`.
    However, architecturally, in broad terms, what may matter most when interpreting
    transformer models is how many layers and attention heads they have. We can inspect
    that easily with the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It should say that there are 12 layers and 12 attention heads. In the next section,
    we will dive into understanding how the attention mechanism works, and how to
    visualize the layers and heads with BertViz.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing attention with BertViz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is attention? Let’s imagine you’re reading a book and come across a sentence
    that mentions a character you’ve read about earlier, but you’ve forgotten some
    details about them. Instead of going back and reading everything from the start,
    you’d likely skim through previous pages, focusing specifically on the parts that
    talk about this character. Your mind gives “attention” to the relevant information
    while filtering out the less relevant parts.
  prefs: []
  type: TYPE_NORMAL
- en: The attention mechanism in models like transformers works in a similar way.
    When processing information, it doesn’t treat all pieces of data equally. Instead,
    it “pays attention” to the most relevant parts, giving them more importance in
    the context of the current task. This ability to selectively focus on specific
    parts helps the model understand complex patterns and relationships in the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Transformers are made up of two main components: the encoder and the decoder.
    Each component leverages attention mechanisms, but they do so differently:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Encoder**: The encoder’s job is to understand the input data. It does this
    by using an attention mechanism to figure out how each part of the input (like
    a word in a sentence) relates to all other parts. This allows the encoder to create
    a rich representation of the input that captures the relationships and context
    within it. It’s like reading a sentence and understanding what each word means
    in the context of that sentence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decoder**: Once the encoder has created this representation, the decoder
    uses it to produce the output. The decoder also uses an attention mechanism, but
    it uses it in two ways. First, it pays attention to the encoder’s representation
    to understand what the input was. Second, it pays attention to its own previous
    outputs to make sure the current output is consistent with what it has produced
    so far. It’s like writing a sentence that makes sense based on what you read and
    what you’ve already written.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, not all transformer models have both components. In essence, the use
    case determines which parts of the transformer are needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Encoder models** (like BERT): These models only use the encoder component
    of the transformer. They are typically used for tasks that involve understanding
    the input data, like sentiment analysis (determining whether a text is positive
    or negative), named entity recognition (identifying people, organizations, and
    locations in text), or other classification tasks. This is because the encoder’s
    job is to create a representation of the input data that captures the relationships
    and context within it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decoder models** (like GPT, LLaMa, etc.): These are used for tasks that involve
    generating new data, like text generation. The decoder part of the transformer
    ensures the generated output is consistent with what has been produced so far.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Encoder-decoder models** (like FLAN): These are used for tasks that involve
    transforming one piece of data into another, like translation. The encoder understands
    the input, and the decoder generates the output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have covered attention models, let’s dive into BERT.
  prefs: []
  type: TYPE_NORMAL
- en: '**BERT**, which stands for **Bidirectional Encoder Representations from Transformers**,
    is a type of transformer model developed by Google. It’s used to understand and
    analyze text data in a wide variety of languages. BERT is a transformer model
    that reads text bidirectionally to understand the context of words better. It
    only uses the encoder part of the transformer because its job is to understand
    text, not generate it. This makes BERT very effective for a wide range of tasks
    that involve understanding text.'
  prefs: []
  type: TYPE_NORMAL
- en: So, our BERT transformer model has 12 layers and 12 attention heads. But what
    do these do, and how do they work?
  prefs: []
  type: TYPE_NORMAL
- en: '**BERT layers**: The 12 hidden layers are BERT layers, and these are a stack
    of other layers that make up this encoder transformer. Much like with convolutional
    layers in a CNN, like the one we examined in *Chapter 7*, *Visualizing Convolutional
    Neural Networks*, BERT layers represent layers of abstraction. As the input data
    progresses through layers, the model learns increasingly abstract representations
    of the data. In the context of text, the lower layers might capture basic syntactic
    information, like the role of a word in a sentence. As you move up through the
    layers, they tend to capture higher-level semantics, such as overall sentence
    meaning or themes. The number of layers, called the depth of the model, often
    correlates with its ability to understand context and represent complex relationships.
    However, more layers also require more computational resources and might be more
    prone to overfitting if not enough data is available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Attention head**: The self-attention mechanism is the heart of any transformer
    model. The attention head has several self-attention mechanisms working in parallel.
    Inside the **multi-head self-attention mechanism**, there are multiple independent
    attention heads working in parallel. Each attention head learns to focus on different
    parts of the input data (like different relationships between tokens, which are
    usually the words). Having multiple attention heads allows the model to capture
    various types of relationships simultaneously. For example, one head might focus
    on the relationship between adjectives and nouns, while another might capture
    verb-subject relationships. After each head computes its own attention-weighted
    value representation, the outputs from all heads are concatenated and linearly
    transformed to produce the final value representation for the next layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s use some real reviews to examine the inner workings of the GoEmotions
    model. To that end, we will take four sample reviews and print out their details
    using the following code. While we are at it, we will save the sample reviews
    in a dictionary (`sample_reviews_dict`) so we can reference them later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18406_08_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.4: A few sample surprise reviews in the dataset'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in *Figure 8.4*, the commonality between all the review samples
    is surprise, both negative and positive.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will leverage BertViz, which, despite the name, can visualize attention
    for encoder-only transformer models (like BERT and all variants), decoder-only
    transformers (like GPT and all variants), and encoder-decoder transformers (like
    T5). It’s very flexible, but it’s important to note that it’s an interactive tool,
    so the print screens represented by the figures in this section won’t do it justice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will create a function that, with the tokenizer, model, and a tuple
    of sentences, can create two different kinds of BertViz visualizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: To visualize attention, we will need to take a pair of input `sentences` and
    encode them with our tokenizer (`inputs`). Then, we extract the token IDs for
    these inputs (`input_ids`) and values, which indicate what sentence each token
    belongs to (`token_type_ids`) – in other words, `0` for the first sentence and
    `1` for the second sentence. We then pass the inputs (`input_ids` and `token_type_ids`)
    to the model and extract the `attention` weights. Finally, there are two BertViz
    visualizers, `head_view` and `model_view`, and for them to work, all we need is
    the `attention` weights produced by our inputs, the token IDs converted to `tokens`,
    and the position for when the second sentence begins (`sentence_b_start`).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will visualize attention throughout the model with the *model view*.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting all attention with the model view
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding lines of code create a large plot, like the one portrayed in
    *Figure 8.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.5: The model view for the 1st sample review for 2nd Avenue Deli'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8.5* is a 12 x 12 grid with every attention head in the BERT model.
    We can click on any attention head to see both sentences in the BERT input, with
    lines drawn between them to represent the attention weights from one token (left)
    to another (right). We can select “Sentence A -> Sentence A”, “Sentence A -> Sentence
    B,” and every combination in between to view only a subset of all the attention
    weights. Lines for weights closest to one appear as very opaque, while weights
    close to zero show as transparent to the point of not being visible at all.'
  prefs: []
  type: TYPE_NORMAL
- en: 'At a glance, we can tell that some attention heads have more lines, thicker
    lines, or lines that seem to go more in one direction than another. We can click
    on individual attention heads to examine them individually – for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Layer 1 Head 11** is mostly attention, moving forward from one token to the
    following token in the same sentence. This is a very common pattern and makes
    complete logical sense because we read English left to right and understand it
    mostly in that order, although there are, of course, other patterns that are undoubtedly
    in the attention heads. We also see evidence of another common pattern, which
    is one or several tokens with attention weights toward the `[CLS]` token. The
    `[CLS]` token is a special token that is prepended to every input sequence when
    using BERT-like models for classification tasks. It’s often used to get the aggregate
    representation of the entire sequence for classification. This means that for
    this particular attention head, the token serves a purpose in the classification
    decision. This can be especially insightful when trying to understand which words
    in a sequence the model deems critical for classification decisions. When attention
    goes from a separator token `[SEP]` to the classification token `[CLS]`, it could
    be seen as the model recognizing the end of a context or sentence and reflecting
    its semantic conclusion, to perhaps influence the classification decision.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer 9 Head** seems to perform a more complicated task, which is to relate
    words to “great” and “surprised,” even across sentences. This is another common
    pattern where connecting words predict a word.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take note of patterns in the attention heads, and notice a few others, like
    attention moving backward in a sentence, or connecting synonyms. Then, change
    the zero in `sample_reviews_dict[0]` to one, two, or three to see if the attention
    heads show the same pattern. The samples are quite different, but if the attention
    heads are not doing the same thing, chances are they are doing something remarkably
    similar. However, for the bigger picture, it’s probably best to squint your eyes
    and see what kind of patterns are evident across different layers.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will make this task easier with the head view.
  prefs: []
  type: TYPE_NORMAL
- en: Diving into layer attention with the head view
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can start by choosing the first sample with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We can select any of the 12 layers (0–11). Line transparency means the same
    thing it did with the model view. However, the difference is we can isolate individual
    token attention weights by clicking on them, so when we select any token on the
    left, we’ll see lines connect with tokens on the right. Also, color-coded boxes
    will appear on the right, representing how much attention weight is in each of
    the 12 attention heads.
  prefs: []
  type: TYPE_NORMAL
- en: 'And if we happen to select any token on the right, we’ll get all the attention
    that is directed to it from the left tokens. In *Figure 8.6*, we can see examples
    of how several of the sample sentences would appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.6: The head view for samples 1, 2, and 4'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 8.6*, see how we can drill down on patterns just as we did with model
    view. For instance, we can examine different patterns of attention, from related
    words that are next to each other (“great sandwich” and “albeit quite expensive”)
    to those that have a relationship only in the context of the sentence (“sandwich”
    and “expensive”), or even across sentences (“bad” and “ignored,” “chef,” and “menu”).
  prefs: []
  type: TYPE_NORMAL
- en: By doing this, we can realize that visualizing attention heads is not just for
    curiosity’s sake but can also help us understand how a model connects the dots
    between words, thus accomplishing a downstream task like classification. Perhaps
    this can help us understand what to do next, whether it’s to fine-tune the model
    further with underrepresented words and situations, or prepare the data differently
    to stop the model from getting confused by a particular word or set of words.
    However, given the complexity of attention heads finding model issues, this can
    be like looking for a needle in a haystack. We only started with layers and attention
    heads in this chapter because it provides an intuitive way of understanding how
    transformers encode relationships between tokens.
  prefs: []
  type: TYPE_NORMAL
- en: A better way to start would be with attributions. An attribution method is a
    method that will compute how much a part of an input contributed to a model’s
    prediction for that input. In the case of images in *Chapter 7*, *Visualizing
    Convolutional Neural Networks*, the part of the input we compute attributions
    for is pixels. For text, the equivalent would be tokens, which in this case are
    made up of (mostly) words, so next, we will generate token attributions.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting token attributions with integrated gradients
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Integrated gradients is a popular method, and in *Chapter 7*, we explained
    and leveraged it to produce attributions for each pixel in an image. The method
    has the same steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Choose a baseline input**: The baseline represents no information. For images,
    it is usually a solid black image. For text, this could be a sentence with all
    words replaced by a placeholder like `[PAD]` or just an empty sentence.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Gradually change this baseline input** into your actual input sentence (e.g.,
    the review), step by step. At each step, you change a little bit of the baseline
    toward the actual input.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Compute output changes**: For each step, calculate how much the model’s prediction
    changes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Sum up all these changes** for each word in the sentence. This gives you
    a score for each word, indicating how much it contributed to the model’s final
    prediction.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'However, before we can use integrated gradients, it’s best that we define a
    transformer pipeline that tokenizes the input and performs inference on the model
    in one step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You can test the `goemotions` pipeline like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'It should output the following list of lists of dictionaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, in the first list, there are two predictions (one for each text),
    and each prediction has a list with seven dictionaries, with one that has the
    score for each class. Since the dictionaries are sorted from the highest score
    to the lowest, you can tell that the first restaurant review was mostly predicted
    as disgust and the second as joy at 66%, but there was also a sizable amount of
    surprise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will create a function that can take any DataFrame row with our review
    and our transformer, and generate and output attributions for every prediction
    with over 10% probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'It may seem complicated by the amount of code, but there are plenty of steps
    that are relatively straightforward when explained individually. We will start
    with model inference and work our way down:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Get predictions**: This is a very straightforward step. It just feeds the
    `text` into the pipeline (`pline`). It takes only the first item returned (`[0]`)
    because it only anticipates one prediction being inputted and, thus, returned
    by the pipeline. The next few lines show what the model does if the function **receives**
    a `sample_df`, which it only really needs to sort the predictions in the order
    of the best rating on average.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Process predictions**: Here, the code makes sure predictions are sorted and
    in tuples for easier iteration in the `for` loop that follows later.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Initialize integrated gradients**: A forward function is defined, which takes
    inputs and returns the model’s output for a given position, as well as a layer
    for which the attributions will be calculated, which in this case is the embedding
    layer. Then, an instance of `LayerIntegratedGradients` (`lig`) is initialized
    with the forward function and the specified layer.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Prepare tokens and baseline**: First, the text is tokenized and converted
    into a tensor, which is then moved to the specified device. Then, the token IDs
    are converted back to `tokens` for potential visualization or analysis. A `baseline`
    is created for the integrated gradients method. It consists of `[CLS][ token at
    the start, ]{custom-style="P - Code"}[SEP][ token at the end, and ]{custom-style="P
    - Code"}[PAD][ tokens in the middle matching the length of the input ]{custom-style="P
    - Code"}text`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Iterate over every prediction**: Here’s the `for` loop that iterates over
    every prediction as long as the probability is over 10%, as defined by `max_prob_threshold`.
    Within the `for` loop, we:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Set the target class**: Integrated gradients is a directed attribution method,
    so we need to know what `target` class to generate attributions for; therefore,
    we need the ID that was used internally by the model for the predicted class.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Get the attributions**: Using the very same Captum `attribute` method we
    used in *Chapter 7*, we generate the IG attributions for the tokenized version
    of our text (`inputs`), the `baselines`, the `target`, and decide whether to return
    a delta (a measure of approximation error) of the IG method (`return_convergence_delta`).'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Post-process the attributions**: the attributions returned by the IG method
    are of the shape (`num_inputs`, `sequence_length`, `embedding_dim`), where `embedding_dim=768`
    for this model, `sequence_length` corresponds to the number of tokens in the input,
    and `num_inputs=1` because we only perform one attribution at a time. So each
    token’s embedding has an attribution score, but what we need is one attribution
    per token. Therefore, these scores are summed across the embedding dimension to
    get a single attribution value for each token in the sequence. Then, the attributions
    are normalized, ensuring that the attributions have a magnitude between 0 and
    1 and are in a comparable scale. Finally, the attributions are detached from the
    computation graph, moved to the CPU, and converted to a `numpy` array for further
    processing or visualization.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Generate and append the Visualization Data Record**: Captum has a method
    called `VisualizationDataRecord`, which creates a record of each attribution for
    visualization purposes, so what we do in this step is create these records with
    the attributions, deltas, tokens, and metadata related to the prediction. It then
    appends this data record to a list.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Display the list of Visualization Data Records**: leverage `visualize_text`
    to display the list of records.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let’s create some samples to perform integrated gradient attributions
    on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In the above snippet, we take all surprise reviews with a probability over 90%,
    but to ensure that they are negative, we will select a negative sentiment and
    a rating below three. Then, we will take a random sample of 10 reviews from these.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will iterate across every review in this list and generate some visualizations.
    A few others are shown in the screenshot in *Figure 8.7:*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18406_08_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.7: IG visualizations for negative surprises'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in *Figure 8.7*, the surprise prediction is attributed to words
    like “shocked,” “realized,” and “mystery” and phrases like “not sure how.” These
    all make sense because they indicate that something is unknown. Naturally, there
    are also a few cases where the word “surprise” or “surprised” is all it takes
    to get a surprise prediction. However, sometimes it’s not that simple. In the
    last one, it’s not one word that appears to indicate surprise but many words,
    saying to the effect that something doesn’t add up. More specifically, these visitors
    from London were very surprised that a deli in New York City was so expensive.
    Please note that the color coding for “Negative” and “Positive” doesn’t mean that
    a word is negative or positive but, rather, it’s weighting against (negatively)
    or in favor (positively) of the attribution label.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are going to repeat code similar to what we ran to generate IG explanations
    for a sample of surprise negative reviews, but this time for positive reviews.
    To ensure that they are positive, we will use ratings above 4\. This time, we
    will make sure to remove any reviews with the word “surprise” from the samples
    just to make things interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will produce the visualizations in *Figure 8.8*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_08.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8\. IG visualizations for positive surprises
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8.8* shows how the words “perplexed” and “unbelievable,” as well as
    the phrase “couldn’t believe how” indicate surprise. There are also a few cases
    of tokens weighing negatively against the surprise prediction. For instance, for
    the last restaurant, having “something for everyone” doesn’t make it very surprising.
    Also, you’ll note the Japanese restaurant in the middle is predicted to embody
    both surprise and joy emotions. It’s interesting how some words correlate with
    one emotion but not so much with another, and sometimes they indicate the opposite,
    like the “hard” in “it’s very hard to find a place” indicating surprise but not
    joy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding reviews with mixed sentiments like the Japanese restaurant might hold
    some answers to why some reviews are hard to classify entirely with one sentiment.
    So, now, we will produce some positive and negative mixed review samples. We can
    easily do so by making sure that the score for the predicted label is never over
    50%:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will produce the IG visualization and polar line plot in
    *Figure 8.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.9: IG visualizations for mixed sentiment reviews'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8.9* portrays how this review for a sandwich shop appears to have joy,
    fear, and neutral emotions. The words “terrific” and “friendly” connect with joy,
    but they don’t with neutral. However, strangely, the word “terrific” also correlates
    with fear. Perhaps it has to do with the WordPiece tokenization performed on the
    word. Note that “terrific” appears as three subword tokens, te, ##rri, and ##fic.
    This probably happened because the original corpus used to train the model (the
    Reddit comments) didn’t have enough frequency for “terrific” to include it as
    a standalone word, but these subwords did. The downside to this technique is that
    it’s possible that the “te” and “rri” tokens are used often for words like “terrifying,”
    and “fic” in other scary words like “horrific” and “mortific.” On the other hand,
    “fic” appears in “magnificent” and “beneficial.” So what happens is that despite
    the contextual embeddings, the subword tokens can cause some ambiguities.'
  prefs: []
  type: TYPE_NORMAL
- en: We can now run the same code as before but for `neg_mixed_samp_df`, to examine
    other examples and make our own conclusions. Next, we can expand our XAI NLP-specific
    toolset with the LIT.
  prefs: []
  type: TYPE_NORMAL
- en: LIME, counterfactuals, and other possibilities with the LIT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The LIT is an open-source platform developed by the **People+AI Research** (**PAIR**)
    initiative to visualize and understand NLP models. PAIR developed the What-If
    Tool featured in *Chapter 6*, *Anchors and Counterfactual Explanations*.
  prefs: []
  type: TYPE_NORMAL
- en: 'LIT provides an interactive and visual interface to delve deep into NLP model
    behavior. With LIT, users can:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify types of examples where a model underperforms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine reasons behind specific model predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test the model’s consistency under textual variations, like style, verb tense,
    or pronoun gender.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LIT offers various built-in capabilities, including salience maps, attention
    visualization, metrics calculations, and counterfactual generation. However, it
    also supports customization, allowing the addition of specialized interpretability
    techniques, visualizations, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Although LIT’s primary focus is textual language data, it also supports models
    that operate on image and tabular data. It’s compatible with a range of machine
    learning frameworks, including TensorFlow and PyTorch. The tool can run both as
    a standalone server and within notebook environments like Colab, Jupyter, and
    Google Cloud Vertex AI notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to work with any custom dataset, LIT provides a `Dataset` subclass
    to create a LIT-compatible dataset loader. You must include an `__init__`, which
    loads the dataset, and a spec function, which specifies the data types returned
    in the dataset, while the `lit_nlp.api.types` provide a way to ensure that LIT
    recognizes each feature in your dataset. In this case, we provide the review (`TextSegment`),
    the label (`CategoryLabel`) with the seven labels, and two additional categories,
    which can be used for slicing and binning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'To make LIT flexible to accommodate any model, there is a `Model` subclass
    to make a LIT-compatible model loader. It also needs the `__init__` function to
    initialize the model, as well as a `predict_minibatch` function to predict with
    it. To this end, we also need to create specs for both the inputs (`input_spec`)
    and outputs (`output_spec`) of the `predict` function. In this case, we enter
    a review (of type `TextSegment`) and return probabilities of type `MulticlassPreds`.
    Remember that the output of the model is not always consistent, since each prediction
    is arranged from the highest to the lowest score. Note that in order to make the
    output of `predict_minibatch` comply with the `MulticlassPreds`, we have to arrange
    the probabilities as a list corresponding to the labels (`GE_LABELS`), in the
    same order provided to `vocab`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'OK, so now we have the two classes we need for LIT to function. The GoEmotions
    model initializer (`GEModel`) takes the model (`goemotions_mdl`) and tokenizer
    (`goemotions_tok`). We put these in a dictionary because LIT can take more than
    one model and more than one dataset to compare them. For the dataset, to make
    it load quickly, we will use 100 samples (`samples100_df`), made up of the four
    10-sample DataFrames we have created so far, plus 60 additional random samples
    from the entire reviews dataset. Then, we just input our 100-sample DataFrame
    into the GoEmotions dataset initializer (`GEDataset`) and place it into our datasets
    dictionary as `NYCRestaurants`. Lastly, we create the widget (`notebook.LitWidget`)
    by inputting our model and datasets dictionaries and `render` it. Please note
    that if you want to run this outside of a notebook environment, you can use the
    `Server` command to have it run on a LIT server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18406_08_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.10: Notebook view with the Predictions tab open'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can appreciate in *Figure 8.10*, LIT has:'
  prefs: []
  type: TYPE_NORMAL
- en: A top bar with a dropdown to select the model and dataset (but you can’t here
    because there’s only one of each) and three different views (**simple**, **default**,
    and **notebook**). **notebook** is selected by default.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A selection bar to select datapoints and see which ones are pinned.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A tab bar with three tabs (**Predictions**, **Explanations**, and **Analysis**).
    By default, **Predictions** is selected, and this tab has **Data Table** to the
    left, where you can select and pin individual datapoints, and the **Classification
    Results** pane to the right.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Even though the **notebook** view has much more going on than the **simple**
    view, it lacks many features available in the **default** view. From now on, we
    will examine the **default** view depicted in *Figure 8.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.11: The default view with the Predictions tab open'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in *Figure 8.11*, the default view has two permanent panes,
    with the **Data Table** and **Datapoint Editor** in the top pane and the tabs
    in the bottom pane. It’s not a great layout for a small notebook cell, but it
    can let you easily pin, select, and edit datapoints while also performing tasks
    on them in the tabs below. Note also that there are more than three tabs. We will
    briefly explain each one:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Predictions**: This lets you see classification results for selected and
    pinned datapoints. Note that it denotes the predicted label with a “P” and the
    ground truth with a “T.” However, since we didn’t train the model with this dataset,
    the label provided is no different than the one predicted, but this can prove
    very useful for examining misclassifications. To the right of the **Classification
    Results**, we have **Scalars**, which allows us to compare scores for the pinned
    and selected datapoints with all others in the dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explanations**: Here, we can use a number of explanation/attribution methods
    on our datapoints, such as LIME and integrated gradients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Salience Clustering**: We perform attributions on many datapoints and cluster
    the results to understand how tokens are clustered. We won’t go into details here,
    given that we only are using a dataset of 100.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics**: Had we been using a training dataset with ground truth labels,
    this tab would be very useful because it can slice and bin performance metrics
    in many ways.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Counterfactuals**: Much like with *Chapter 6*, the concept of counterfactuals
    is the same here, which is working out what feature (a token in this case) you
    can change in such a way that you modify the model outcome (the predicted label).
    There are several counterfactual finding methods provided.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, we will work our way down this list, excluding **Salience Clustering**
    and **Predictions** (which we already explained in *Figure 8.11*), so next, we
    will take a look at **Explanations**, as shown in *Figure 8.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.12: LIME explanation compared between pinned and selected reviews
    in the Explanations tab'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8.12* shows how LIME explanations vary between the pinned and selected
    datapoint. LIME was previously covered in *Chapter 5*, *Local Model-Agnostic Interpretation
    Methods*, and in the context of NLP no less. It’s the same here. Incidentally,
    although there are at least four methods available, including integrated gradients,
    only LIME will work with this model. The reason for this is that LIME is a model-agnostic
    permutation-based method that doesn’t need to access any of the intrinsic parameters
    of the model, but the rest of the methods aren’t model-agnostic. And if you recall,
    our `GEModel` doesn’t expose any of the intrinsic parameters. If we wanted to
    leverage gradient-based methods like IG within LIT, we would need to not use the
    pipeline and then specify the input and output in such a way that token embeddings
    are exposed. There are some examples on the LIT website that can help you accomplish
    this.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will take a look at the **Metrics** tab, as seen in *Figure 8.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.13: Confusion Matrix in the Metrics tab'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 8.13*, in the **Metrics** panel, there usually would be informative
    metrics for the entire dataset, the selection you have made, and any additional
    facets you may define. However, if you expand the tab, you’ll always see 100%
    accuracy for this dataset because there’s no ground truth. Perhaps the **Confusion**
    **Matrix** panel to the right is more informative in this case because we can
    see a cross tab between labels and rating, or labels and positive, since we defined
    both rating and positive as `CategoryLabel`s. Please note that, technically, it’s
    not a confusion matrix because it doesn’t compare a predicted sentiment label
    against the corresponding true label, but you can see how much agreement there
    is between the predicted label and the rating.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s examine the **Counterfactuals** tab, depicted in *Figure 8.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_08_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.14: Generating ablation flip counterfactuals in the Counterfactuals
    tab'
  prefs: []
  type: TYPE_NORMAL
- en: The **Counterfactuals** tab in *Figure 8.14* provides several methods to change
    the input in such a way that the predicted label is modified. Not all methods
    will work with `GEModel`, given how some counterfactual methods are model-agnostic
    and others require intrinsic parameters. Here, we use ablation flip, a model-agnostic
    method, to ablate (remove) tokens from the inputs. Ablation flip simply tries
    dropping tokens from the input to figure out which one changes the prediction.
    As you can see, the first one removed “Not” from “review,” and the second removed
    “impressed.”
  prefs: []
  type: TYPE_NORMAL
- en: 'With counterfactuals, you can test that the subword tokens in te ##rri ##fic
    (as depicted in *Figure 8.9*) indeed cause ambiguity when they are added and ablated
    in many different contexts. For instance, you can remove one token at a time from
    te ##rri ##fic from a review that is deemed to have a neutral or negative sentiment
    by the model, seeing if the prediction changes in a positive direction. You can
    also replace all three tokens with a synonym like “magnificent.”'
  prefs: []
  type: TYPE_NORMAL
- en: Mission accomplished
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It was pretty evident from the summary table (*Figure 8.3*), and confirmed with
    the integrated gradients and, to some degree, the attention visualization exercise,
    that many of the Ekman emotions are hard to discern from the reviews, with fear,
    disgust, anger, and sadness producing many mixed sentiment reviews. And these
    hard ones are all negative emotions.
  prefs: []
  type: TYPE_NORMAL
- en: Also, many emotions in both the GoEmotions and Ekman taxonomy don’t matter as
    much in the context of a recommendation engine, so it makes sense to consider
    consolidating some of the negative emotions and, given the ambiguity with the
    surprise category being sometimes positive and sometimes negative, splitting them
    to include curiosity and confusion.
  prefs: []
  type: TYPE_NORMAL
- en: Another important finding was that, given the many consistent patterns you found,
    surprise is not as hard to classify and yet a critical emotion to predict. However,
    there are good surprises and bad surprises. And given the right training data,
    a model can likely differentiate both with high precision. We can ensure that
    tokenization never separates words that convey emotions for the training corpus.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After reading this chapter, you should understand how to leverage BertViz to
    visualize transformer models, layers, and attention heads, and how to use Captum’s
    attribution methods, more specifically integrated gradients, and the Visualization
    Data Record to see what tokens are responsible for a predicted label. Finally,
    you should have a solid grasp of how to get started with the LIT. In the next
    chapter, we will look at interpreting multi-variate time-series models.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Vig, J., 2019, *A Multiscale Visualization of Attention in the Transformer
    Model*. ArXiv: [https://arxiv.org/abs/1906.05714](https://arxiv.org/abs/1906.05714)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kokhlikyan, N., Miglani, V., Martin, M., Wang, E., Alsallakh, B., Reynolds,
    J., Melnikov, A., Kliushkina, N., Araya, C., Yan, S., & Reblitz-Richardson, O.,
    2020, *Captum: A unified and generic model interpretability library for PyTorch*.
    ArXiv: [https://arxiv.org/abs/2009.07896](https://arxiv.org/abs/2009.07896)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tenney, I., Wexler, J., Bastings, J., Bolukbasi, T., Coenen, A., Gehrmann,
    S., Jiang, E., Pushkarna, M., Radebaugh, C., Reif, E., & Yuan, A., 2020, *The
    Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis
    for NLP Models.* Conference on Empirical Methods in Natural Language Processing:
    [https://arxiv.org/abs/2008.05122](https://arxiv.org/abs/2008.05122)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn more on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To join the Discord community for this book – where you can share feedback,
    ask the author questions, and learn about new releases – follow the QR code below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/inml](Chapter_8.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code107161072033138125.png)'
  prefs: []
  type: TYPE_IMG
