- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Achieving the GCP ML Certification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations! You have gone through all the chapters thus far and built a
    strong knowledge base and skillset for **Machine Learning** (**ML**) in Google
    Cloud. Now, it is time to integrate what you have learned so far and take the
    GCP ML certification exam – the last part of our learning roadmap.
  prefs: []
  type: TYPE_NORMAL
- en: The Google Professional Machine Learning Engineer certification exam is a very
    important part of your journey to becoming a Google Cloud Certified Machine Learning
    Engineer. To prepare for and pass the exam, you must review all the contents in
    this book and integrate them to deeply understand them and connect all the dots.
  prefs: []
  type: TYPE_NORMAL
- en: 'We recommend that you take the following steps to prepare for and achieve the
    Google Professional ML Engineer certification:'
  prefs: []
  type: TYPE_NORMAL
- en: Read the official Google ML certification exam guide.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read all the chapters in this book.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Complete all the hands-on labs in this book.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Practice and review all the practice questions in this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To get you prepared, we have provided some practice questions for the ML certification
    exam, along with the analysis of the questions in this chapter. Make sure you
    fully understand each question and all the answers to the questions, and why the
    right answer is right and the wrong answers are wrong. Keep in mind that the questions
    set here are just examples and we aim to provide a pilot sample for you to follow.
    You will need to do more research on the internet to reach a comprehensive level
    for the exam.
  prefs: []
  type: TYPE_NORMAL
- en: GCP ML exam practice questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please read each question carefully and thoroughly, and fully understand it.
    Please also review all the docs that are related to the question at the reference
    links provided:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 1**: Space Y is launching its hundredth satellite to build its StarSphere
    network. They have designed an accurate orbit (launching speed/time/and so on)
    for it based on the existing 99 satellite orbits to cover the Earth’s scope. What’s
    the best solution to forecast the position of the 100 satellites after the hundredth
    launch?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use ML algorithms and train ML models to forecast
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use neural networks to train the model to forecast
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use physical laws and actual environmental data to model and forecast
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a linear regression model to forecast
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: This is an ML problem framing question. To decide whether ML
    is the best method for a problem, we need to see whether traditional science modeling
    would be very difficult or impossible to solve the problem and whether plenty
    of data exists. When we start, science modeling will be our first choice since
    it builds the most accurate model based on science and natural laws. For example,
    given the initial position and speed of an object, as well as its mass and the
    forces acting on it, we can precisely predict its position at any time. For this
    case, the mathematical model works much better than any ML model!'
  prefs: []
  type: TYPE_NORMAL
- en: To forecast the hundredth satellite’s orbit, answer C is the best choice here.
  prefs: []
  type: TYPE_NORMAL
- en: '**Reference**: Section *Is ML the best solution?* in [*Chapter 3*](B18333_03.xhtml#_idTextAnchor072),
    *Preparing for ML Development*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 2**: A financial company is building an ML model to detect credit
    card fraud based on their historical dataset, which contains 20 positives and
    4,990 negatives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to the imbalanced classes, the model training is not working as desired.
    What’s the best way to resolve this issue?
  prefs: []
  type: TYPE_NORMAL
- en: Data augmentation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Early stopping
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Downsampling and upweighting
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Regularization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: This question is about class imbalance when preparing data for
    classification problems. When the data is imbalanced, it will be very difficult
    to train the ML model and get good forecasts. We need to use *downsampling and
    upweighting* to balance the classes, so the answer is C.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reference**: Section *Data sampling and balancing* in [*Chapter 3*](B18333_03.xhtml#_idTextAnchor072),
    *Preparing for ML Development*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 3**: A chemical manufacturer is using a GCP ML pipeline to detect
    real-time sensor anomalies by queuing the inputs and analyzing and visualizing
    the data. Which one will you choose for the pipeline?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataproc | AI Platform | BQ
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Dataflow | AutoML | Cloud SQL
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Dataflow | AI Platform | BQ
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Dataproc | AutoML | Bigtable
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: This is an ML pipeline question. We need to understand the difference
    between Dataflow and Dataproc, AI Platform and AutoML, as well as the various
    GCP databases: Cloud SQL, Bigtable, and BQ.'
  prefs: []
  type: TYPE_NORMAL
- en: Dataproc and Dataflow are GCP data processing services, and both can process
    batch or streaming data. However, Dataproc is designed to run on clusters for
    jobs that are compatible with MapReduce (Apache Hadoop, Hive, and Spark). Dataflow
    is based on parallel data processing and works better if your data has no implementation
    with Spark or Hadoop.
  prefs: []
  type: TYPE_NORMAL
- en: AI Platform involves “human-performed” ML training – using your own data and
    model. AutoML is “automated” ML training with Google’s model and your own data,
    with no coding.
  prefs: []
  type: TYPE_NORMAL
- en: Out of the GCP database/warehouse products, Cloud SQL is for relational data
    online transaction processing, Bigtable is more for NoSQL transaction processing,
    and BQ is great for analyzing and visualizing data (integrating with Data Studio).
  prefs: []
  type: TYPE_NORMAL
- en: Based on this, we will choose C as the answer.
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 4**: A real estate company, Zeellow, does great business buying
    and selling properties in the United States. Over the past few years, they have
    accumulated a big amount of historical data for US houses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeellow is using ML training to predict housing prices, and they retrain the
    models every month by integrating new data. The company does not want to write
    any code in the ML process. What method best suits their needs?
  prefs: []
  type: TYPE_NORMAL
- en: AutoML tables
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: BigQuery ML
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AI Platform
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AutoML classification
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: This question is also about the difference between AutoML and
    AI Platform, as well as between regression and classification. Since AutoML serves
    the purpose of no coding during the ML process, and this is a structured data
    ML problem, the correct answer is A.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 5**: The data scientist team is building a deep learning model for
    a customer support center of a big **Enterprise Resource Planning** (**ERP**)
    company, which has many ERP products and modules. The DL model will input customers’
    chat texts and categorize them into products before routing them to the corresponding
    team. The company wants to minimize the model development time and data preprocessing
    time. What strategy/platform should they choose?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI Platform
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Auto ML
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: NLP API
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Vertex AI Custom notebooks
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The key point here is that *the company wants to minimize the
    model development time and data preprocessing time.* AutoML is the best choice,
    so the correct answer is B.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 6**: A real estate company, Zeellow, does great business buying
    and selling properties in the United States. Over the past few years, they have
    accumulated a big amount of historical data for US houses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeellow wants to use ML to forecast future sales by leveraging their historical
    sales data. The historical data is stored in cloud storage. You want to rapidly
    experiment with all the available data. How should you build and train your model?
  prefs: []
  type: TYPE_NORMAL
- en: Load data into BigQuery and use BigQuery ML
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the data into CSV and use AutoML Tables
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the data into TFRecords and use TensorFlow
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert and refactor the data into CSV format and use the built-in XGBoost library
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The key point here is that we need to experiment quickly with
    all the structured datasets stored in cloud storage. BQ and BQML are the best
    options here since all the others will take a long time to build and train the
    model. Thus, the correct answer is A.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 7**: A real estate company, Zeellow, uses ML to forecast future
    sales by leveraging their historical data. New data is coming in every week, and
    Zeellow needs to make sure the model is continually retrained to reflect the marketing
    trend. What should they do with the historical data and new data?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Only use the new data for retraining
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the datasets weekly with new data
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the datasets with new data when model evaluation metrics do not meet
    the required criteria
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the datasets monthly with new data
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: Model retraining is the key term here. Since data changes over
    time and causes trained models to become obsolete, model retraining is the norm
    in the ML process. In this case, when do we need to retrain the model? The answer
    is when the performance metrics do not meet the requirements. How do we retrain
    the model? The answer is to use the integrated datasets, including existing and
    new data. Therefore, the correct answer is C.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 8**: A real estate company, Zeellow, uses ML to forecast future
    sales by leveraging their historical data. Their data science team trained and
    deployed a DL model in production half a year ago. Recently, the model is suffering
    from performance issues due to data distribution changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The team is working on a strategy for model retraining. What is your suggestion?
  prefs: []
  type: TYPE_NORMAL
- en: Monitor data skew and retrain the model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Retrain the model with fewer model features
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Retrain the model to fix overfitting
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Retrain the model with new data coming in every month
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: Model retraining is based on data value skews, which are significant
    changes in the statistical properties of data. When data skew is detected, this
    means that data patterns are changing, and we need to retrain the model to capture
    these changes. The question did not mention any overfitting issues, nor did it
    mention feature reduction. The retraining strategy will be monitoring data skew
    and retraining the model with the new inputs. Thus, the correct answer is A.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reference**: [https://developers.google.com/machine-learning/guides/rules-of-ml/#rule_37_measure_trainingserving_skew](https://developers.google.com/machine-learning/guides/rules-of-ml/#rule_37_measure_trainingserving_skew).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 9**: Recent research has indicated that when a certain kind of cancer,
    *X*, is developed in a human liver, there are usually other symptoms that can
    be identified as objects *Y* and *Z* from CT scan images. A hospital is using
    this research to train ML models with a label map of (*X*, *Y*, *Z*) on CT images.
    What cost functions should be used in this case?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary cross-entropy
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Categorical cross-entropy
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sparse categorical cross-entropy
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Dense categorical cross-entropy
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The correct answer is B.'
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 5*](B18333_05.xhtml#_idTextAnchor116), *Understanding Neural Networks
    and Deep Learning*, *in The cost function* section, we discussed the use cases
    for different cost functions. Binary cross-entropy is used for binary classification
    problems. Categorical entropy is better to use when you want to prevent the model
    from giving more importance to a certain class – the same as the one-hot encoding
    idea. Sparse categorical entropy is more optimal when your classes are mutually
    exclusive (for example, when each sample belongs exactly to one class).
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 10**: The data science team in your company has built a DNN model
    to forecast the sales value for an automobile company, based on historical data.
    As a Google ML Engineer, you need to verify that the features selected are good
    enough for the ML model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train the model with L1 regularization and verify that the loss is constant
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model with no regularization and verify that the loss is constant
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model with L2 regularization and verify that the loss is decreasing
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model with no regularization and verify that the loss is close to
    zero
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The correct answer is D.'
  prefs: []
  type: TYPE_NORMAL
- en: The loss function is the measurement for model prediction accuracy and is used
    as an index for the ML training process. To verify that the model that’s been
    built has enough features, we need to make sure that the loss function is close
    to zero when no regularizations are used.
  prefs: []
  type: TYPE_NORMAL
- en: '**Reference**: Section *Regularization* in [*Chapter 4*](B18333_04.xhtml#_idTextAnchor094),
    *Developing and Deploying ML Models*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 11**: The data science team in your company has built a DNN model
    to forecast the sales value for a real estate company, based on historical data.
    As a Google ML Engineer, you find that the model has over 300 features and that
    you wish to remove some features that are not contributing to the target. What
    will you do?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Explainable AI to understand the feature contributions and reduce the non-contributing
    ones.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use L1 regularization to reduce features.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use L2 regularization to reduce features.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Drop a feature at a time, train the model, and verify that it does not degrade
    the model. Remove these features.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The correct answer is A. This question is discussing feature
    selection, and Explainable AI is one of the ways to understand which features
    are contributing and which ones are not. It is important to understand that L1
    and L2 are methods for resolving model overfitting issues and not feature selection
    in data engineering.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 12**: The data science team in your company has built a DNN model
    to forecast the sales value for a real estate company, based on historical data.
    They found that the model fits the training dataset well, but not the validation
    dataset. What would you do to improve the model?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply a dropout parameter of 0.3 and decrease the learning rate by a factor
    of 10
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply an L2 regularization parameter of 0.3 and decrease the learning rate by
    a factor of 10
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply an L1 regularization parameter of 0.3 and increase the learning rate by
    a factor of 10
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Tune the hyperparameters to optimize the L2 regularization and dropout parameters
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The correct answer is D.'
  prefs: []
  type: TYPE_NORMAL
- en: This question is discussing techniques to avoid model overfitting. While L1/L2
    regularization, dropout parameters, and learning rate are all ways to help, we
    must tune the hyperparameters and find the optimized values. A hint here is that
    the correct answer would be fitting to the general case and thus will not have
    concrete numbers such as 0.3, 10, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 13**: You are building a DL model for a customer service center.
    The model will input customers’ chat text and analyze their sentiments. What algorithm
    should be used for the model?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MLP
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CNN
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: RNN
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The correct answer is D.'
  prefs: []
  type: TYPE_NORMAL
- en: This question tests the different algorithms used for ML/DL. Since text processing
    for sentiment analysis needs to process sequential data (time series), the best
    option is **Recurrent Neural Networks** (**RNNs**).
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 14**: A health insurance company scans customers'' hand-filled claim
    forms and stores them in Google Cloud Storage buckets in real time. They use ML
    models to recognize the handwritten texts. Since the claims may contain **Personally
    Identifiable Information** (**PII**), company policies require only authorized
    persons to access the information. What’s the best way to store and process this
    streaming data?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create two buckets and label them as sensitive and non-sensitive. Store data
    in the non-sensitive bucket first. Periodically scan it using the DLP API and
    move the sensitive data to the sensitive bucket.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Create one bucket to store the data. Only allow the ML service account access
    to it.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Create three buckets – quarantine, sensitive, and non-sensitive. Store all the
    data in the quarantine bucket first. Then, periodically scan it using the DLP
    API and move the data to either the sensitive or non-sensitive bucket.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Create three buckets – quarantine, sensitive, and non-sensitive. Store all the
    data in the quarantine bucket first. Then, once the file has been uploaded, trigger
    the DLP API to scan it, and move the data to either the sensitive or non-sensitive
    bucket.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The correct answer is D.'
  prefs: []
  type: TYPE_NORMAL
- en: This is a business use case for PII/private data storage and processing, and
    a typical solution is to create three buckets and utilize DLP to scan and then
    move the raw data into different buckets and control their access.
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 15**: A real estate company, Zeellow, uses ML to forecast future
    sales by leveraging their historical data. The recent model training was able
    to achieve the desired forecast accuracy objective, but it took the data science
    team a long time. They want to decrease the training time without affecting the
    achieved model accuracy. What hyperparameter should the team adjust?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning rate
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Epochs
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Scale tier
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Batch size
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The correct answer is C since changing the other three parameters
    will change the model’s prediction accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 16**: The data science team has built a DNN model to monitor and
    detect defective products using the images from the assembly line of an automobile
    manufacturing company. As a Google ML Engineer, you need to measure the performance
    of the ML model for the test dataset/images. Which of the following would you
    choose?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AUC value
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The recall value
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The precision value
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The TP value
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The correct answer is A because it measures how well the predictions
    are ranked rather than their absolute values. It is a classification threshold
    invariant and thus is the best way to measure the model’s performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 17**: The data science team has built a DL model to monitor and
    detect defective products using the images from the assembly line of an automobile
    manufacturing company. Over time, the team has built multiple model versions in
    AI Platform. As a Google ML Engineer, how will you compare the model versions?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compare the mean average precision for the model versions
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the model loss functions on the training dataset
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the model loss functions on the validation dataset
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the model loss functions on the testing dataset
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: The correct answer is A because it measures how well the different
    model versions perform over time: deploy your model as a model version and then
    create an evaluation job for that version. By comparing the mean average precision
    across the model versions, you can find the best performer.'
  prefs: []
  type: TYPE_NORMAL
- en: '**References**: [https://cloud.google.com/ai-platform/prediction/docs/continuous-evaluation/view-metrics#compare_mean_average_precision_across_models](https://cloud.google.com/ai-platform/prediction/docs/continuous-evaluation/view-metrics#compare_mean_average_precision_across_models).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 18**: The data science team is building a recommendation engine
    for an e-commerce website using ML models to increase its business revenue, based
    on users’ similarities. What model would you choose?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborative filtering
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Content-based filtering
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: For this recommendation engine question, the correct answer is
    A.'
  prefs: []
  type: TYPE_NORMAL
- en: Content-based filtering uses the similarity between items to recommend items
    that are similar to what the user likes. Collaborative filtering uses similarities
    between users to provide recommendations. The question specifies “based on users’
    similarities.”
  prefs: []
  type: TYPE_NORMAL
- en: '**References**: [https://developers.google.com/machine-learning/recommendation/overview/candidate-generation](https://developers.google.com/machine-learning/recommendation/overview/candidate-generation).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 19**: The data science team is building a fraud-detection model
    for a credit card company, whose objective is to detect as much fraud as possible
    and avoid as many false alarms as possible. What confusion matrix index would
    you maximize for this model performance evaluation?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precision
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Recall
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The area under the PR curve
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The area under the ROC curve
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: In this fraud-detection problem, it asks you to focus on detecting
    fraudulent transactions - maximize True Positive rate and minimize False Negative
    - maximize recall (*Recall = TruePositives / (TruePositives + FalseNegatives)*).
    It also asks you to minimize false alarms (false positives) - maximize precision
    (*Precision = TruePositives / (TruePositives + FalsePositives)*).'
  prefs: []
  type: TYPE_NORMAL
- en: So, since you want to maximize both precision and recall, the correct answer
    is C (maximize the area under the PR curve).
  prefs: []
  type: TYPE_NORMAL
- en: '**References**: [https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 20**: The data science team is building a data pipeline for an auto
    manufacturing company, whose objective is to integrate all the data sources that
    exist in their on-premise facilities, via a codeless data ETL interface. What
    GCP service will you use?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataproc
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Dataflow
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Dataprep
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Data Fusion
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: Since the question asks for data integration with a codeless
    interface, Data Fusion is the best choice here. Thus, the correct answer is D.'
  prefs: []
  type: TYPE_NORMAL
- en: '**References**: [https://cloud.google.com/data-fusion/docs/concepts/overview#using_the_code-free_web_ui](https://cloud.google.com/data-fusion/docs/concepts/overview#using_the_code-free_web_ui).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 21**: The data science team has built a TensorFlow model in BigQuery
    for a real estate company, whose objective is to integrate all their data models
    into the new Google Vertex AI platform. What’s the best strategy?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Export the model from BigQuery ML
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Register the BQML model to Vertex AI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Import the model into Vertex AI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use AI Platform as the middle stage
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: Since the question asks for model integration with Vertex AI,
    which allows you to register a BQML model in it, the correct answer is B.'
  prefs: []
  type: TYPE_NORMAL
- en: '**References**: https://cloud.google.com/bigquery-ml/docs/managing-models-vertex.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 22**: A real estate company, Zeellow, uses ML to forecast future
    house sale prices by leveraging their historical data. The data science team needs
    to build a model to predict US house sale prices based on the house location (US
    city-specific) and house type. What strategy is the best for feature engineering
    in this case?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One feature cross: [latitude X longitude X housetype]'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Two feature crosses: [binned latitude X binned housetype] and [binned longitude
    X binned housetype]'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Three separate binned features: [binned latitude], [binned longitude], [binned
    housetype]'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'One feature cross: [binned latitude X binned longitude X binned housetype]'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: Crossing binned latitude with binned longitude enables the model
    to learn city-specific effects on house types. It prevents a change in latitude
    from producing the same result as a change in longitude. Depending on the granularity
    of the bins, this feature cross could learn city-specific housing effects. So,
    the correct answer is D.'
  prefs: []
  type: TYPE_NORMAL
- en: '**References**: [https://developers.google.com/machine-learning/crash-course/feature-crosses/check-your-understanding](https://developers.google.com/machine-learning/crash-course/feature-crosses/check-your-understanding).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 23**: A health insurance company scans customer’s hand-filled claim
    forms and stores them in Google Cloud Storage buckets in real time. The data scientist
    team has developed an AI documentation model to digitize the images. By the end
    of each day, the submitted forms need to be processed automatically. The model
    is ready for deployment. What strategy should the team use to process the forms?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI batch prediction
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Vertex AI online prediction
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Vertex AI ML pipeline prediction
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Cloud Run to trigger prediction
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: As specified in the question, we need to run the process at the
    end of each day, which implies batch processing using AI Platform or Vertex AI.
    The correct answer is A.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 24**: A real estate company, Zeellow, uses GCP ML to forecast future
    house sale prices by leveraging their historical data. Their data science team
    has about 30 members and each member has developed multiple versions of models
    using Vertex AI customer notebooks. What’s the best strategy to manage these different
    models and different versions developed by the team members?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up IAM permissions to allow each member access to their notebooks, models,
    and versions
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a GCP project for each member for clean management
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a map from each member to their GCP resources using BQ
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply label/tags to the resources when they’re created for scalable inventory/cost/access
    management
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: Resource tagging/labeling is the best way to manage ML resources
    for medium/big data science teams. The best answer is D.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resource**: https://cloud.google.com/resource-manager/docs/tags/tags-creating-and-managing.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 25**: Starbucks is an international coffee shop selling multiple
    products A, B, C… at different stores (1, 2, 3… using one-hot encoding and location
    binning). They are building stores and want to leverage ML models to predict product
    sales based on historical data (A1 is the data for product A sales at store 1).
    Following the best practices of splitting data into a training subset, validation
    subset, and testing subset, how should the data be distributed into these subsets?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Distribute data randomly across the subsets:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Training set: [A1, B2, F1, E2, ...]'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Testing set: [A2, C3, D2, F4, ...]'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Validation set: [B1, C1, D9, C2...]'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Distribute products randomly across the subsets:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Training set: [A1, A2, A3, E1, E2, ...]'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Testing set: [B1, B2, C1, C2, C3, ...]'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Validation set: [D1, D2, F1, F2, F3, ...]'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Distribute stores randomly across subsets:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Training set: [A1, B1, C1, ...]'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Testing set: [A2, C2, F2, ...]'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Validation set: [D3, A3, C3, ...]'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregate the data groups by the cities where the stores are allocated and distribute
    cities randomly across subsets
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: This question is about dataset splitting to avoid data leakage.
    If we distribute the data randomly into the training, validation, and test sets,
    the model will be able to learn specific qualities about the products. If we divided
    things up at the product level so that the given products were only in the training
    subset, the validation subset, or the testing subset, the model would find it
    more difficult to get high accuracy on the validation since it would need to focus
    on the product characteristics/qualities. Therefore, the correct answer is B.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reference**: https://developers.google.com/machine-learning/crash-course/18th-century-literature.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 26**: You are building a DL model with Keras that looks as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How many trainable weights does this model have?
  prefs: []
  type: TYPE_NORMAL
- en: 200x128+128x4+4x2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 200x128+128x4+2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 200x128+129x4+5x2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 200x128x0.25+128x4x0.25+4x2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: This question is testing the concept of trainable weights in
    a Keras model. As you can see, the correct answer is D.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 27**: The data science team is building a DL model for a customer
    support center of a big ERP company, which has many ERP products and modules.
    The company receives over a million customer service calls every day and stores
    them in GCS. The call data must not leave the region in which the call originated
    and no PII can be stored/analyzed. The model will analyze calls for customer sentiments.
    How should you design a data pipeline for call processing, analyzing, and visualizing?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCS -> Speech2Text -> DLP -> BigQuery
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: GCS -> Pub/Sub -> Speech2Text -> DLP -> Datastore
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: GCS -> Speech2Text -> DLP -> BigTable
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: GCS -> Speech2Text -> DLP -> Cloud SQL
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: Since the question asks for a data pipeline to process, analyze,
    and visualize, the best answer is A. BigQuery is the best tool here to analyze
    and visualize.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 28**: The data science team is building an ML model to monitor and
    detect defective products using the images from the assembly line of an automobile
    manufacturing company, which does not have reliable Wi-Fi near the assembly line.
    As a Google ML Engineer, you need to reduce the amount of time spent by quality
    control inspectors utilizing the model’s fast defect detection. Your company wants
    to implement the new ML model as soon as possible. Which model should you use?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AutoML Vision
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AutoML Vision Edge mobile-versatile-1
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AutoML Vision Edge mobile-low-latency-1
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AutoML Vision Edge mobile-high-accuracy-1
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis:** Since the question asks for a quick inspection time and prioritizes
    latency reduction, the correct answer is C.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reference**: [https://cloud.google.com/vision/automl/docs/train-edge](https://cloud.google.com/vision/automl/docs/train-edge).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 29**: A national hospital is leveraging Google Cloud and a cell
    phone app to build an ML model to forecast heart attacks based on age, gender,
    exercise, heart rate, blood pressure, and more. Since the health data is highly
    sensitive personal information and cannot be stored in cloud databases, how should
    you train and deploy the ML model?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IoT with data encryption
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Federated learning
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Encrypted BQML
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: DLP API
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: Federated learning is the best choice here due to the restrictions.
    With federated learning, all the data is collected, and the model is trained with
    algorithms across multiple decentralized edge devices such as cell phones or websites,
    without exchanging them. Therefore, the best answer is B.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 30**: You are an ML engineer at a media company. You need to build
    an ML model to analyze video content frame by frame, identify objects, and alert
    users if there is inappropriate content. Which Google Cloud products should you
    use to build this project?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pub/Sub, Cloud Functions, and Cloud Vision API
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Pub/Sub, Cloud IoT, Dataflow, Cloud Vision API, and Cloud Logging
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Pub/Sub, Cloud Functions, Video Intelligence API, and Cloud Logging
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Pub/Sub, Cloud Functions, AutoML Video Intelligence, and Cloud Logging
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analysis**: Since this question involves video analysis, this will eliminate
    A and B. AutoML video intelligence is for cases where you wish to customize models
    with Google’s model and your data. Therefore, C is the correct answer since the
    Video Intelligence API can be used to meet the requirements.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the Google Cloud Professional Machine Learning
    Engineer certification exam and some practice questions. Since GCP ML is a changing
    domain, many new services have been developed and released by Google while this
    book was being written. By no means does this book cover all the exam topics in
    this domain. You will need to refer to the Google certification page for the certification
    exam guides and updates.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter concludes part four of this book. In part five of this book, in
    the appendices, we will provide some labs and demos for practicing your hands-on
    skills. It is recommended that you go through each appendix and practice the labs
    step-by-step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 5: Appendices'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, we provide hands-on practices for ML in Google Cloud, including
    the basic GCP services, the Python data science libraries, the scikit-learn library,
    the GCP Vertex AI suite, and the Google Cloud ML APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Appendix 1*](B18333_11.xhtml#_idTextAnchor184), Practicing with Basic GCP
    Services'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Appendix 2*](B18333_12.xhtml#_idTextAnchor195), Practicing with the Python
    Data Library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Appendix 3*](B18333_13.xhtml#_idTextAnchor209), Practicing with Scikit-Learn'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Appendix 4*](B18333_14.xhtml#_idTextAnchor218), Practicing with Google Vertex
    AI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Appendix 5*](B18333_15.xhtml#_idTextAnchor233), Practicing with Google Cloud
    ML API'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Practicing with Basic GCP Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this appendix, we will show some GCP resource provisioning examples, using
    the Google Cloud console and Cloud Shell. We will use the following architecture
    to practice using the Google Cloud console, as shown in *Figure 11.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A VPC network, VPC1, and two subnets in it: a public `subnet1` and a private
    `subnet2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `subnet1` that has an external IP address and can be accessed from the internet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A VM in the private `subnet2` that does not have an external IP address and
    thus can only be accessed from the console browser, or from VMs within the same
    VPC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Another VPC network, VPC2, and one subnet within VPC2: a private `subnet8`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A VM in the private `subnet8`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peering between VPC1 and VPC2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – A sample architecture for GCP console practice
  prefs: []
  type: TYPE_NORMAL
- en: In the GCP practice diagram in *Figure 11.1*, `public subnet1` is accessible
    from the internet. There is a Google Cloud Storage bucket called `B1`. If we want
    to have VM1, VM2, and VM8 access `B1`, what do we need to do? This is a great
    question to think about before reading further.
  prefs: []
  type: TYPE_NORMAL
- en: Practicing using GCP services with the Cloud console
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In GCP, a project is the basic unit for resource provision. You can use the
    following steps to begin a project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'After you log into the GCP console ([https://console.cloud.google.com](https://console.cloud.google.com))
    from your browser, you will see the following starting page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You can always create a new project by clicking the drop-down button next to
    **My First Project**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Within the **My First Project** project, we will now create the network VPCs,
    subnets, and VMs.
  prefs: []
  type: TYPE_NORMAL
- en: Creating network VPCs using the GCP console
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following steps to create a VPC in the GCP console:'
  prefs: []
  type: TYPE_NORMAL
- en: On the upper-left side of the window, there is the navigation drop-down menu
    that you will be able to use to choose the GCP services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From the navigation menu on the left side, go to **VPC network** and select
    **VPC networks** from the dropdown. It will prompt you to enable **Compute Engine
    API**. Go ahead and enable it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will be brought to the **VPC network** page, where you can create a VPC
    network.
  prefs: []
  type: TYPE_NORMAL
- en: Click **CREATE VPC NETWORK**.![](img/B18333_11_5.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, fill in the network details and create VPC1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`subnet1`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`10.10.1.0/24`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`us-east1`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subnet2`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`10.10.2.0/24`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asia-east1`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, `vpc1` is created with two subnets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_11_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Repeat *Steps 3* and *4* to create `vpc2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`subnet8`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`192.168.1.0/24`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`europe-central2`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You now have two VPCs created: `vpc1` with two subnets and `vpc2` with one
    subnet.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a public VM, vm1, within vpc1/subnet1 using the GCP console
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following steps to create a VM in the GCP console:'
  prefs: []
  type: TYPE_NORMAL
- en: From the navigation menu on the left side, go to **Compute Engine** and then
    **VM instances**. Click the **CREATE INSTANCE** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, fill in the VM instance details:'
  prefs: []
  type: TYPE_NORMAL
- en: '`vm1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`us-east1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`us-east1-b`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Machine configuration**: **GENERAL-PURPOSE**, **N1** series'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`f1-micro`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subnet1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_11_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Select the defaults for the other options, and then click on **NETWORKING, DISKS,
    SECURITY, MANAGEMENT, SOLE-TENANCY**.![](img/B18333_11_10.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand the **Networking** option, then go to **Network interfaces**.![](img/B18333_11_11.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `vpc1` for `subnet1 Ipv4 (10.10.1.0/24)` for **Subnetwork**, and leave
    everything else as the default.![](img/B18333_11_12.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **DONE** and then **CREATE**.![](img/B18333_11_13.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this time, VM1 is created in `vpc1` and `subnet1` (`10.10.1.0/24`), with
    the internal IP address of `10.10.1.2` and the external IP address of `34.148.1.115`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_11_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To allow **Secure Shell** (**SSH**) into this Linux VM, you need to create a
    firewall rule to allow inbound SSH traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Select **View network details** from the three dots drop-down menu.![](img/B18333_11_15.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Firewall** and then **CREATE FIREWALL RULE**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Fill in the firewall rule details:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`vpc1-firewall-rule2`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vpc1`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Select `0.0.0.0/0` for `22` as the port number (SSH uses port `22`). Then, click
    **CREATE**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: After the firewall rule is created successfully, go back to the **VM instances**
    page. Select **Open in browser window** from the **SSH** drop-down menu (make
    sure you allow pop-up windows from the browser).![](img/B18333_11_19.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now you are able to SSH into the VM instance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_11_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You now have a GCP VM, called `vm1`, created in `subnet1` of `vpc1`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a private VM, vm2, within vpc1/subnet2 using the GCP console
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Repeat the steps in *the previous section* to create a VM in `vpc1/subnet2`.
    The only changes are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose `asia-east1` as the region where `subnet2` sits.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose `subnet2` as the subnetwork.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose **None** for **External IPv4 address** since this is a private VM and
    no external IP address is assigned.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now, `vm2` is provisioned in `vpc1/subnet2` with the IP address of `10.10.2.2`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_11_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Repeat the steps in *Creating a public virtual machine vm1 within the vpc1/subnet1
    using GCP console* to create a firewall rule to allow `ping` within `vpc1` (`10.10.0.0/16`)
    so `vm1` and `vm2` can ping each other since they are in the same VPC.![](img/B18333_11_23.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ping `vm2` (`10.10.1.2`) from `vm1`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: At this time, you have a GCP VM, `vm2`, created in `subnet2` of `vpc1`, and
    `vm1` can ping `vm2`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a private VM, vm8, within vpc2/subnet8 using the GCP console
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Repeat the steps in *Creating a private virtual machine vm2 within the vpc1/subnet2
    using GCP console* to create a VM in `vpc2/subnet8` (`192.168.1.0/24`), with no
    public IP addresses. The only changes are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Choose `europe-central2` as the region where `subnet3` sits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose `subnet8` as the subnetwork.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notice that `vm1/vm2` cannot ping `vm8` even if you create firewall rules allowing
    pinging from `vpc1` to `vpc2`, since there are no routes between `vpc1` and `vpc2`.
    That’s why we need to create peering between `vpc1` and `vpc2`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating peering between vpc1 and vpc2 using the GCP console
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following steps to create VPC network peering between `vpc1` and `vpc2`:'
  prefs: []
  type: TYPE_NORMAL
- en: From the navigation menu, go to **VPC network** and then **VPC network peering**.![](img/B18333_11_25.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create `vpc12-peering` from `vpc1` to `vpc2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Do the same for `vpc2` to `vpc1` peering, so both peerings will now be active.![](img/B18333_11_27.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ping `vm8` (`192.168.1.2`) from `vm1`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You now have a GCP VM, `vm8`, created in `subnet8` of `vpc2`, and `vm1` can
    ping `vm8`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a GCS bucket from the GCP console
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following steps to create a GCS bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: From the navigation menu, go to **Cloud Storage** and then **Buckets**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From the new window, click **CREATE BUCKET**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_11_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Choose a globally unique name for the GCP bucket. Here, we use `bucket-08282022`.
    Select **Region** under **Choose where to store your data**, and select **us-east1**
    as the storage bucket region. Click the **CREATE** button.![](img/B18333_11_31.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It will bring you to the bucket page, where you can create a subfolder, upload
    files, or upload a folder under the previously created bucket.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_11_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So far, we have provisioned GCP resources (VPCs/subnets, VPC peering, VMs, and
    storage) from the console. All of this provisioning can be done using Cloud Shell.
    In the next section, we will provide the Cloud Shell commands/scripts for GCP
    resource provisioning.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning GCP resources using Google Cloud Shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instead of using the GCP console, we can use Google Cloud Shell to provision
    all the resources. In the following example, the GCP architecture is shown in
    *Figure 11.2*, and we use the Cloud Shell commands to provision GCP resources,
    including network VPCs/subnets, VMs, and VPC peering. Please practice using them
    in Cloud Shell, and make sure you understand each step.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_11_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 – A sample architecture for GCP Cloud Shell practice
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a project,VPC, and subnet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create VMs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'List all the VMs and write down their IP addresses:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Open the firewall for `VPC1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: SSH from the console to `myvm11`, and you should be able to ping `vm12` from
    `vm11`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'But how can we ping from `myvm11` to `myvm2`? You need to create VPC peering
    between `VPC1` and `VPC2` (they are in the same project):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Open a firewall for `vpc2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now you shall be able to ping `vm2` from `vm11`. But how can we ping from `myvm11`
    to `myvm3`? You need to create VPC peering between `vpc1` and `vpc3` (they are
    in different projects):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Open a firewall for `vpc3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now you shall be able to ping `vm3` from `vm11`.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this appendix, we have provided practice examples to provision GCP services/resources
    from the GCP console. We have also shown how to create these basic resources using
    Google Cloud Shell.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Practicing Using the Python Data Libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B18333_02.xhtml#_idTextAnchor054), *Mastering Python Programming*,
    we covered the Python data libraries, including NumPy, Pandas, Matpotlib, and
    Seaborn. In this appendix, we will continue learning these libraries by practicing
    using them on the Google Colab platform ([colab.research.google.com](http://colab.research.google.com)).
  prefs: []
  type: TYPE_NORMAL
- en: With a step-by-step approach, we will show how to use these libraries to manage
    and visualize data. For the NumPy library, we will discuss how to generate and
    operate NumPy arrays. For the Pandas library, we cover features including Series,
    DataFrames, missing data handling, GroupBy, and operations. For the Matpotlib
    and Seaborn libraries, we will show their features by exploring multiple data
    visualization examples.
  prefs: []
  type: TYPE_NORMAL
- en: Follow these examples and make sure you understand each of them. Practicing
    each example on Google Colab will yield the best results.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NumPy is a library for Python that adds support for large, multi-dimensional
    arrays and matrices, along with a large collection of high-level mathematical
    functions to operate on these arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will go over the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Generating NumPy arrays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating NumPy arrays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start with how to generate NumPy arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Generating NumPy arrays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will demonstrate various ways to create NumPy arrays. Arrays
    might be one-dimensional or two-dimensional.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s convert a list into a one-dimensional array by using the following code
    (the first line imports the NumPy library and and gives it the alias of `np`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s make our list a little complicated with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note that there are two sets of brackets that represent the two-dimensional
    array.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the basic functions in NumPy is `arange()`, where you can provide start
    and stop values. For example, with `0` as the start value and `10` as the stop
    value, `np.arange()` will generate a one-dimensional array with values from `0`
    to `10` (the last value provided in the function is not included):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s use the same function with some other values/arguments. In the following
    example, we add an additional argument called **step size** to create a one-dimensional
    array, with even numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The first argument in the `arange` function is the `start` value, the second
    is the `stop` value, and the last one is the step size.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other built-in function in NumPy is to generate an array with all zeros.
    We need to provide the argument with how many zeros we want to generate in the
    array, as shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also provide a tuple as an argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, if we need to generate an array with pure ones, we can use the `ones`
    function and provide a number as an argument, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Another useful built-in function is `linspace`, where we enter arguments as
    the first number and the last number, evenly spaced between specified intervals.
    Remember that the `arange` function returns all integers between the start and
    stop points, but `linspace` takes a third argument, the number of points we want:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous example, there is a one-dimensional array (specified with a
    single bracket), with 10 evenly spaced points between `0` and `5`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note that, using the same example with different space points (`25`), the array
    looks like a two-dimensional array, but it is one-dimensional, proven by there
    only being one bracket in front of the array.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are dealing with linear algebra problems, it is basically a two-dimensional
    square matrix (the same number of rows and columns), where we have a diagonal
    of ones and everything else is zero. That’s why it takes a single digit as an
    argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'One of the most used functions that will be used here generates an array with
    random numbers, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If we need to return from the standard normal distribution, instead of `rand`,
    we can use the `randn` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The other function is `randint`, which returns a random single integer between
    the lowest and highest integer values, provided as an argument (the lowest inclusive
    and the highest exclusive):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'If we need a particular number of random integers between the provided interval,
    we need to provide a third argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s do some conversion. In the following example, we have generated
    a one-dimensional array with 25 values, saved it in an `array` variable, and then
    reshaped it into a two-dimensional array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to get the maximum or minimum value in the randomly generated array,
    we can use the `array.max()` or `array.min()` function respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to pick a single value (or a set of values) from the array provided
    in the preceding example, we can specify this with brackets, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to replace a single value or a set of values in an array, we need
    to set those values as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, values that are in the `0`, `1`, and `2` indexes are replaced
    with values of `100`.
  prefs: []
  type: TYPE_NORMAL
- en: Operating NumPy arrays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we are going a little deeper and working with a two-dimensional array.
    In the following example, we generated an array with 25 random numbers and reshaped
    it into a two-dimensional array. It then shows a value, which is located on row
    1 and column 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a function to return a Boolean (`True` or `False`) of the
    array, based on a specific condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also apply some math, such as addition, subtraction, multiplication,
    and division operations, to an array, as well as applying some functions, such
    as `sin`, `cos`, and `log`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We have shown some examples using the NumPy library; for more information about
    the library, please refer to [https://numpy.org/](https://numpy.org/).
  prefs: []
  type: TYPE_NORMAL
- en: Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pandas is an open source library that is built on top of NumPy. Pandas allows
    for quick data analysis and data preparation. It excels in performance and productivity.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DataFrames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing data handling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GroupBy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Depending on the environment, you may need to install Pandas first by going
    to your command line or terminal and running the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We will start by looking at the Series data type.
  prefs: []
  type: TYPE_NORMAL
- en: Series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Series is the first main data type that we will be using with Pandas. Series
    is almost the same as the NumPy array. The difference is that with Series, a series
    of axis labels can be indexed by a label.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to make four different Python objects and form a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, if we do not specify the index values, it will assign `0, 1, 2,
    ….` Therefore, we can change those labels into labels we created earlier (`labels`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to provide a dictionary in a Series, you do not need to provide
    an index, since the dictionary already has its keys and values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'A Series can hold any data types, and we can provide labels too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: DataFrames
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A DataFrame is a two-dimensional labeled data structure with columns of different
    types. In this section, we will start building our first DataFrame using Pandas.
    In the following example, we have created a random number generated by NumPy and
    built a nice view with labels (rows and columns) with Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to display a specific row of a DataFrame, specify the name of the
    row in the brackets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the output is a Series, which we have covered before. If you want
    to check the type of the output, use the `type` syntax, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to display multiple columns from the DataFrame, you can specify
    them in brackets as a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Another feature of the DataFrame is being able to add new columns to it. When
    adding a new column, we need to specify the values of the new column. In the following
    example, we are creating a new column, `new`, and we will sum all the values from
    `x` and `y` and add them to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to delete a particular column or row, you can use the built-in
    `drop` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'If you need to get output from a specific row, you can use the `loc` syntax,
    which stands for `location`, and you need to specify a row name as an argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Conditional selection is also a feature of Pandas, where you can call data
    as a Boolean (`True` or `False`) in a DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Missing data handling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the DataFrame we created earlier, if we apply some conditions (such as greater
    than zero), data that is less than zero will be displayed as `NaN` (null data).
    If you need to display only rows and columns that do not have `null` data, use
    the `dropna` syntax, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are going to apply a condition and save a new DataFrame (`new_df`)
    with values that are greater than zero, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'For the cells that do not have any value (`NaN`), we are going to replace them
    with the mean (average) of all values in that column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Note that the value in the `x` column and `c` row is not null and is replaced
    with a value.
  prefs: []
  type: TYPE_NORMAL
- en: GroupBy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GroupBy allows you to group together rows based on columns and perform an aggregate
    function on them.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next example, we will create a new DataFrame using the dictionary, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are working with a large DataFrame and want to print the sum of the
    sales of each country, use the `groupby` built-in function, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will show some real-life data operations. In the next examples,
    we are going to use a CSV file, `Salaries.csv` (taken from [https://www.kaggle.com/kaggle/sf-salaries?select=Salaries.csv](https://www.kaggle.com/kaggle/sf-salaries?select=Salaries.csv)).
  prefs: []
  type: TYPE_NORMAL
- en: After downloading the file to a local computer and uploading it to Google Colab,
    you can visualize the DataFrame and explore the data using the Pandas library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `read_csv` function to read the CSV file, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding sections, we have shown the basic features of the Pandas library.
    For more information on Pandas features, please refer to [https://pandas.pydata.org](https://pandas.pydata.org).
  prefs: []
  type: TYPE_NORMAL
- en: Matplotlib
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Matplotlib is one of the essential libraries of data visualization in Python.
    It is an excellent two-dimensional and three-dimensional graphics library for
    generating scientific figures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the major pros of Matplotlib are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Generally easy to get started with simple plots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for custom labels and text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Great control of every element in a figure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-quality output in many formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Very customizable in general
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will start with simple data generated by the NumPy library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We have generated data using the `linspace` function in the NumPy library.
    We can also play with all our data (in our case, it is an array), such as taking
    each number in an array and squaring it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We can plot the data in a graph with a simple function in Matplotlib:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can rearrange the `x` and `y` axes with `a` and `b` values, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'So far, we have demonstrated how to plot using the `plot` and `subplot` methods.
    Now, we are going to dive into object-oriented methods, where we will break down
    all for a more formal introduction of the `matplotlib` object-oriented API method.
    In the following example, we run a built-in `figure` function, which builds an
    imaginary blank canvas, and later on, we will add a set to this canvas so that
    it will work more flexibly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The very first step is to add axes to the canvas using the `add_axes` function.
    The numbers in the brackets represent the left, the button, the width, and the
    height of the axes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each number should be between zero and one, representing a percentage, numbers
    representation:'
  prefs: []
  type: TYPE_NORMAL
- en: The first number (0.1) represents 10 percent from the left of the canvas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second number (0.1) represents 10 percent from the bottom.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third number (0.8) represents the percentage of axes from the canvas (width).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fourth number (0.8) represents the percentage of axes from the canvas (height).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the preceding example, we generated `a` and `b` values using NumPy and plotted
    them in our custom canvas/axes using object-oriented methods, which gives us more
    control. Using some other functions, we can set names for each axis and title,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let’s put two sets of figures on the same canvas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the next example, we have plotted two sets in the same figure and also added
    some labels, using the `label` and `legend` methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We have shown some examples using the Matplotlib library; for more detailed
    information, please refer to [https://matplotlib.org](https://matplotlib.org).
  prefs: []
  type: TYPE_NORMAL
- en: Seaborn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Seaborn is a statistical library built on top of the Matplotlib library, and
    all the Matplotlib knowledge that we have learned can be applied to Seaborn.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start with a simple importing library. One of the useful features of
    Seaborn is its built-in datasets. In our case, we are going to use the `tips`
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also check out some other details (such as the number of columns and
    rows, and data types) by using the `.info()` function, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The example here shows a very basic histogram, where we set the dataset name
    as `tips` and the `total_bill` data (one of the columns of our dataset):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The `displot` function described previously has different arguments that you
    can set to modify your graph/histogram. Note that we have entered two arguments,
    `kde` and `bins`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are going to explore different types of graphs using the `jointplot`
    function. You need to provide the `x` value, the `y` value, and the data name
    as arguments, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that the arguments we provided (`total_bill` and `tips`) are from data
    we imported, and they are the column names. It is a two-distribution plot, and
    in between, we have a scatter plot. As the bill value increases on the plot, the
    tip value also increases. `jointplot` also has other arguments that can help you
    to modify the graph (by default, it is a scatter plot, but you can also pass the
    hex argument), as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The next Seaborn features/functions we will introduce are box plots and violin
    plots. These types of plots are used to show the distribution of categorical data.
    They show the distribution of quantitative data in a way that facilitates comparison
    between variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The violin plot, unlike the box plot, allows you to actually plot all the components
    that correspond to actual data points, and it essentially shows the kernel density
    estimation of the underlying distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: By adding more arguments to the `violinplot` function, you can add different
    features and details to the graph, as shown here.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_12_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So far, we have shown the Seaborn library features via several examples. There
    are many different visual representations that use the Seaborn library in Python.
    Check out the Seaborn website ([https://seaborn.pydata.org/index.xhtml](https://seaborn.pydata.org/index.xhtml))
    for more details
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this appendix, we practices using the Python data libraries, including NumPy,
    Pandas, Matpotlib, and Seaborn. Thoroughly understanding these examples will help
    you to understand the data libraries and master Python programming skills.
  prefs: []
  type: TYPE_NORMAL
- en: 'Appendix 3: Practicing with Scikit-Learn'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 3*](B18333_03.xhtml#_idTextAnchor072), *Preparing for ML Development*,
    and [*Chapter 4*](B18333_04.xhtml#_idTextAnchor094), *Developing and Deploying
    ML Models*, we discussed the data preparation and ML model development process.
    In this appendix, we will continue learning about ML modeling skills by practicing
    using the scikit-learn package on the Google Colaboratory platform ([colab.research.google.com](http://colab.research.google.com)).
  prefs: []
  type: TYPE_NORMAL
- en: 'With a step-by-step approach, we will show you how to develop ML models leveraging
    the scikit-learn library. We will cover the following practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a best practice to follow these examples and make sure you understand
    each of them. Practicing each example on Google Colab will yield the best results.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapters, we discussed Python libraries such as NumPy, Pandas,
    Matplotlib, and Seaborn for processing and visualizing data. Let’s start with
    simply importing the libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: We will use a simple dataset that has only 4 columns and 10 rows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_13_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Notice that some of the columns are categorical and others are numerical, and
    some of them have missing values that we need to fix. The dataset `.csv` file
    is uploaded to Google Colab.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_13_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Using the `pandas` library and the `read_csv` function, we read the data and
    save it to a variable dataset, assign the first three columns (`X`, and assign
    the last column dataset to `y`, as the prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that it has some missing values. In the ML training process, we need to
    minimize the number of missing values, so you can either delete the rows containing
    missing data cells or replace the missing values with an input value, for example,
    the average of all values in that column. The following example is the filling
    of missing values with the mean/average of that particular column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to convert categorical values to numerical values. In our
    loaded dataset (`‘data.cvs’`), the name of the column is `Country` and it has
    three different values (`France`, `Spain`, and `Germany`). We are going to convert
    it to three columns with binary values using one-hot encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to encode the very last column of our dataset (where values are
    `Yes` or `No` only) to zeros and ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to split them into training and testing datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have practiced the basic data processing skills, let’s get into feature
    scaling before starting training ML models. There are two types of feature scaling:
    standardization and normalization. The goal is to have all values of the features
    in the same range. Let’s examine the train data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_13_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We find that the very first three rows were encoded previously, so we will
    apply feature scaling for rows 4 and 5 only:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Note that the outcome of `X_train` is between -2 and +2 (avery short range).
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we have split the datasets and transformed the data, we will show you how
    to use the scikit-learn library to build up ML models. We will start with regression
    and show you the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polynomial/non-linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple linear regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First things first, we need to prepare the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can start training our regression model. We need to import a class and
    feed our training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we are going to predict the results of the observation in the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s plot our prediction and real data to see how close they are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_13_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_13_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the simple linear regression model fits well with our datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple linear regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we are going to use another dataset, which has multiple columns
    as data features and one for the predictor:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_13_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'First, we perform the data preparation:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the necessary libraries and/or classes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split the dataset into `X` (features) and `y` (predictors).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Encode column index 3 (state names have been converted to binary values and
    saved as three additional columns).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Split the data into training and testing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'We can start training our model now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'And now is the time to validate/test our model. We cannot visualize as we did
    in the simple linear regression, since we have four different features and cannot
    plot them in a 5-dimensional graph. However, we can display two vectors: vectors
    of the *real profit* in the test set, and the *predicted profit*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: The left side of the output indicates the predicted profits, and the right side
    indicates the real profits.
  prefs: []
  type: TYPE_NORMAL
- en: Polynomial/non-linear regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will show examples of non-linear regression, where the relationship
    between the target and the feature(s) is not linear, that is, it is polynomial.
    We will use a linear model and a non-linear model, and compare how they fit to
    the real datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start with the data preparation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are going to train two models: linear regression and polynomial regression.
    The following example shows both regression models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will visualize both regressions.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the linear regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_13_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, this is the polynomial regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_13_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As we can see, polynomial regression (we used the power of `2`) yields accurate
    predictions. If we go with higher powers, we will harvest better results. In the
    following examples, we will change the power to `4` (see line 2), and the result
    will fit the dataset much better:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_13_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So far, we have covered the regression modeling process by practicing simple
    linear regression, multiple linear regression, and non-linear regression. In the
    next section, we will discuss classification models.
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike regression, where you predict a continuous number, you use classification
    to predict a category. We will cover logistic regression here.
  prefs: []
  type: TYPE_NORMAL
- en: We will use a dataset of historical data of iPhone purchases, based on the age
    and the salary of the buyers, to predict whether a new potential buyer will purchase
    an iPhone.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_13_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s do the preparation first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: Note that all values are between -3 and +3\.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we train the logistic regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Let’s predict a new result. Before running prediction scripts, let’s take a
    look into our original dataset and pick up a random feature set (in our case,
    the age of `30` and salary of `87000`), and the result is `0`.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the prediction function, the result is also the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'The following example demonstrates the comparison of the actual and predicted
    results for the testing dataset so we can compare the accuracy/efficiency of the
    trained model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'The output we have in the preceding code shows the comparison: the first column
    is the predicted value and the second column is the real value. To calculate the
    accuracy/efficiency of the model, we can divide the total of the correct number
    in the prediction by the total number of actual numbers in the testing dataset,
    and construct its confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'The output shows the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: The accuracy/efficiency of the model is 83%.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this appendix, we have shown examples of data preparation and model development
    (regression and classification) using the scikit-learn library. Going over these
    examples and understanding the process will help in your understanding of ML concepts
    and processes.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Practicing with Google Vertex AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [*Chapter 7*](B18333_07.xhtml#_idTextAnchor143), *Exploring Google Cloud
    Vertex AI*, we discussed Google Cloud Vertex AI. This appendix contains some hands-on
    tutorials for Google Vertex AI in the Google Cloud console, step by step. We will
    cover the following labs:'
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – enabling its API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI – datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI – labeling tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI – training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI – predictions (Vertex AI Endpoint)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI – predictions (Vertex AI Batch Prediction)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI – Workbench
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI – Feature Store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI – pipelines and metadata
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI – model monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are expected to follow these labs to practice Vertex AI and gain implementation
    skills.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – enabling its API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To start using Vertex AI in the Google Cloud console, you will need to set
    up a billing account and create a project. Once you have created a project (*Vertex
    AI – demo documentation*), you will be on the following project home dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Navigate through the top-left menu to launch Vertex AI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To launch Vertex AI for the first time, you need to enable the Vertex AI API.
    To do so, select a **Region** and click on the blue **ENABLE VERTEX AI API** button:'
  prefs: []
  type: TYPE_NORMAL
- en: f
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: After enabling the Vertex AI API, by default, you will land on the Vertex AI
    API dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The very first tool we will use in Vertex AI is **Datasets**. After clicking
    on **Datasets**, you will be taken to the respective page. Since we are working
    on a brand new project, there is no dataset to display. Click on **CREATE DATASET**
    to get started:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Enter the name of your dataset and select a dataset type to work with from
    the following four main categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image classification (Single-label)**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image classification (Multi-label)**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image object detection**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image segmentation**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tabular**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression/classification**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forecasting**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text classification (Single-label)**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text classification (Multi-label)**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text entity extraction**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text sentiment analysis**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Video**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Video action recognition**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Video classification**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Video object tracking**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After selecting a dataset type, a bucket will be created in Google Cloud Storage
    as the default dataset repository. Here, you can specify the region where your
    bucket will be created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the **CREATE** button. You will be brought to the next page, where
    you need to specify the import method. There are three options for importing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Upload images from your computer**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Upload import files from your computer**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Select import files from Cloud Storage**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To select a file(s) from your local computer, click on the **SELECT FILES**
    button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the page that appears, navigate to the folder that contains your pictures
    on your local computer and then select one or more pictures that you want to upload
    to your dataset. Note that you can upload up to 500 images per upload. The pictures
    that you upload should be in one of the following formats:'
  prefs: []
  type: TYPE_NORMAL
- en: JPEG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GIF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PNG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BMP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ICO
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you need to upload more pictures, you need to click on the **SELECT FILES**
    button and specify which Google Cloud bucket you want to use for your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the pictures have been uploaded, you can browse all the images in the
    dataset and check their status (they will be either **Labeled** or **Unlabeled**).
    As shown in the following screenshot, we have a total of 20 images and all of
    them are unlabeled (labeling tasks will be covered in the next section):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you wish to use the other two options for adding images to a dataset – **Upload
    import files from your computer** and **Select import files from Cloud Storage**
    – you can simply provide a link to Cloud Storage, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The other three categories (**Tabular**, **Text**, and **Video**) follow the
    same procedure in that you must create a dataset and upload files either from
    your local computer or from Google Cloud Storage. You must also enter a dataset
    name and select a region from the options provided.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – labeling tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, you will learn how to label data in Vertex AI. There are several
    ways to label data within a created dataset. If you use a small-size dataset,
    you can label each dataset manually. By default, the dataset only shows 10 images
    per page. If you want to see all your pictures on the same page, you can select
    a number from the **Items per page** option. There are three options – **10**,
    **50**, and **100**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since we haven’t created a label yet, we need to define/create a label name.
    Click on `Brain` and `Spine`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After creating/adding new labels, you can either select every single image
    and label it or make multiple selections and label them as a group (following
    each step from *Steps 1* to *4*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After labeling all the images, you can check if any of the images have been
    left unlabeled by going to the summary page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If you have a very large dataset, you can create a labeling task and assign
    it to a team to label the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have a labeled dataset, it is ready for model training. Vertex
    AI provides different methods for training your model:'
  prefs: []
  type: TYPE_NORMAL
- en: AutoML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom training (advanced)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To start AutoML training, in the Vertex AI console, click on **Training** and
    then the **CREATE** button, which is located at the top of the page (in our case,
    we are going to perform AutoML training using the dataset of MRI images that we
    created in the previous section):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the page that appears, you need to define some specifications for the model
    you are trying to train:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Select Dataset**: Here, you will be able to see all the datasets you created
    previously.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Annotation Set**: Labels are saved in collections called annotations. You
    can change annotation sets to apply a different group of labels to the same dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On the **Training method** page, select **AutoML** (this will be selected by
    default). Then, click **CONTINUE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Since we are working on training a new ML model, we need to select **Train new
    model**. But in case you already have a trained model and want to retrain *or*
    train a model as a version of an existing model, select **Train new version**.
  prefs: []
  type: TYPE_NORMAL
- en: Next, enter the name of the model and provide a description (the description
    is optional).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the **Advanced options** section, you will be given two options for data
    splitting: **Randomly assigned** and **Manual (Advanced)**. In terms of **Randomly
    assigned**, your dataset will be automatically randomized and split into training,
    validation, and testing sets using the following ratios:'
  prefs: []
  type: TYPE_NORMAL
- en: '`80%`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`10%`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`10%`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can change values as needed for your training mode. For more details, check
    out the Google documentation at [https://cloud.google.com/vertex-ai/docs/general/ml-use?_ga=2.140326960.-2030104523.1635276817&_gac=1.58794719.1650385127.CjwKCAjwu_mSBhAYEiwA5BBmf84zVxwFEpx-VaeJRusJFGq8rVNEovNnLhJ3vLYGMK3Eao6yJhRY5BoCdKgQAvD_BwE](https://cloud.google.com/vertex-ai/docs/general/ml-use?_ga=2.140326960.-2030104523.1635276817&_gac=1.58794719.1650385127.CjwKCAjwu_mSBhAYEiwA5BBmf84zVxwFEpx-VaeJRusJFGq8rVNEovNnLhJ3vLYGMK3Eao6yJhRY5BoCdKgQAvD_BwE):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Click **CONTINUE**.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next and last page, you will be prompted to enter an amount in the **Budget**
    section. Here, you need to specify the maximum amount of time that will be used
    to train a particular model. Click on the **START TRAINING** option:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When the training is done, you will receive an email confirming this and you
    will be able to see its status. Now, you can analyze the trained model from the
    training page (the same page where we trained our model) or click on **Models**
    from the left menu and click on the model you want to analyze:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When you click on the model you want to analyze, you will be prompted to select
    the version of the model. Since we have trained a brand new model, we only have
    one version. The following screenshot shows a summary of the training model for
    our tabular dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From this chart, you can see the performance of the trained model, as well as
    the confusion matrix of our classification model.
  prefs: []
  type: TYPE_NORMAL
- en: 'After model training, it is time to deploy the model for prediction. There
    are two ways to deploy the model:'
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Endpoint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI Batch Prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will discuss these in more detail in the next few sections.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – predictions (Vertex AI Endpoint)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are going to deploy our model via Vertex AI Endpoint. There
    are two ways to deploy a model:'
  prefs: []
  type: TYPE_NORMAL
- en: From **Models**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From **Endpoints**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s look at these options in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the model via Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Go to the **Models** section from the left menu, select the model you want
    to deploy, and select the version you want to deploy (remember, we have only one
    version since we have built/trained a brand-new model). Then, at the top of the
    page, click on **DEPLOY & TEST**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After clicking on **DEPLOY & TEST**, you will be taken to the next page. Here,
    click on the blue **DEPLOY TO ENDPOINT** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Deploying the model via Endpoints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Go to the **Endpoints** section from the left menu. By doing so, you will be
    navigated to a pop-up page where you need to define your endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the next page, you need to specify which model you want to deploy to the
    endpoint and select the version of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Specify the number of compute nodes and leave the other settings as-is. Then,
    click **DONE** and then **CREATE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Upon completing the deployment, you will receive an email specifying the status
    of the endpoint deployment. Now, we can start making predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to **Models**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the model you wish to use.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the model’s version.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At the top of the page, click on **DEPLOY & TEST**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will land on a page where you can start trying/testing your deployed model.
    Click on the blue **UPLOAD IMAGE** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Choose an image from your local drive. That image will be uploaded to the endpoint;
    on the right-hand side of the page, you will see the predicted result. In our
    case, we uploaded a random image (`spine MARI`) and the prediction was done with
    almost 99% accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you need to use your endpoint in mobile/web applications, you can request
    a sample API. From the same page, click on **Sample request**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'From the menu that appears, you can copy the script from the **REST** or **PYTHON**
    section based on your needs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After several attempts, the system will start generating graphs based on the
    logs that have been collected from the endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So far, we have deployed our model to Vertex AI Endpoint. Now, let’s learn how
    to use batch prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – predictions (Batch Prediction)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Batch prediction is used when you don’t require an immediate response and want
    to get predictions from the accumulated data via a single request. Follow these
    steps to perform batch prediction for the models we trained earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to **Models** from the left menu of the console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the model you want to work with.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the version of the model you want to work with.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the top menu, click on **BATCH PREDICT**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the blue **CREATE BATCH PREDICTION** button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_14_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After clicking on **CREATE BATCH PREDICTION**, you need to define some parameters,
    such as the batch prediction’s name, source, output, and so on. Let’s analyze
    each of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Batch prediction name**: Enter a name for the batch prediction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Select source**: Here, you need to specify the source of the value that will
    be used in batch prediction. You can source either the BigQuery table *or* the
    file in Cloud Storage. Remember that since we are using the tabular dataset, the
    format must be CSV, JSONL, or TFRecord.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Batch prediction output**: Select the format of output (BigQuery table, CSV,
    TFRecord, or JSONL) and provide the path (BigQuery *or* Cloud Storage).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explainability options**: Optionally, you may check **Enable feature attributions**
    for this model to get feature attributions as part of the output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using a BigQuery dataset and the table we have created, we can create a new
    batch prediction to predict the **Risk Level** column:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: After defining all the parameters, click on **CREATE**; the batch prediction
    will start processing. It will take some time to complete this process and you
    will receive an email upon completion.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – Workbench
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Vertex AI Workbench is a single development environment for the entire data
    science workflow. You can use Vertex AI Workbench’s notebook-based environment
    to query and explore data, develop and train a model, and run your code as part
    of a pipeline. Vertex AI workbench offers the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Managed notebooks** are Google-managed environments with integrations and
    features that help you set up and work in an end-to-end notebook-based production
    environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-managed notebooks** are deep learning VM image instances that are heavily
    customizable and are therefore ideal for users who need a lot of control over
    their environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To launch Vertex AI Workbench, navigate to the Vertex AI console and click
    on **Workbench**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you are using Vertex AI Workbench for the first time, you will need to enable
    Notebook API, which you will be prompted for after you click on **Workbench**.
    Click on **ENABLE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this lab, we are going to create a user-managed notebook. Vertex AI provides
    different types of Jupyter notebooks with various pre-installed libraries and
    dependencies. In this example, we will create a simple Python 3 notebook. Follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: From the left menu of the console, click on **Workbench**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **NEW NOTEBOOK** at the top of the page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the drop - down menu, click on **Python 3**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18333_14_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'From the popup menu, you need to identify the notebook by providing its **Notebook
    name**, **Region**, **Zone**, and so on. Then, click on **CREATE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let’s check and analyze the notebook we created earlier and what features
    are available in Vertex AI Notebook(s). Vertex AI provides a Jupyter notebook
    environment. Click on **OPEN JUPYTERLAB**, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You will be navigated to a new tab containing the JupyterLab environment. On
    the left-hand side of the page, you will see all your folders. By default, there
    are two folders, but you can create, upload, or clone a folder from different
    sources such as GitHub. On the right-hand side of the page, you have **Notebook**,
    **Console**, and **Other**, which includes options for **Terminal**, **Text File**,
    and so on. Click on **Python 3** under Notebook. You will be taken to a blank
    notebook where you can start programming using Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After clicking on `.ipynb` file (on the left) so that you can start inputting
    your scripts on the right:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: With that, you have created the training platform and are ready to start running
    Jupyter notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – Feature Store
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Feature Store in Vertex AI is where you can create entities and features and
    add values that can be used later as needed. In this demo, we are going to explore
    creating a Feature Store with entities and features in the Jupyter notebook by
    running some Python scripts. Before diving into the notebook, let’s create a Feature
    Store and entities via the Google Cloud console. From the left menu of the console,
    click on **Features**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since we haven’t created any Feature Store(s) yet, this section will be empty.
    To create a new entity, click on **CREATE ENTITY TYPE**, which is located at the
    top of the page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'From the popup menu, enter all the necessary information and click the **CREATE**
    button, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we are going to create a new notebook and clone a repository from GitHub
    ([https://github.com/GoogleCloudPlatform/vertex-ai-samples](https://github.com/GoogleCloudPlatform/vertex-ai-samples)).
    After creating a notebook and cloning the aforementioned repository, from the
    `cloned` folder, go to `Vertex-ai-samples` | `notebooks` | `official` | `feature_store`
    and click on `gapic-feature-store.ipynb`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Install all additional packages and enter your project ID, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Run all the scripts as you go through (in this demo document, we will not go
    over every single line, but we will highlight important points related to the
    Vertex AI Feature Store).
  prefs: []
  type: TYPE_NORMAL
- en: 'These scripts will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Prepare a dataset for output. It will create a dataset in BigQuery to host the
    output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import libraries and define constants.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the feature store, as well as its entities and features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After running all the scripts, you can check the created Feature Store (along
    with its entities and features) in the Google console. From the console, go to
    **Vertex AI** and click on **Features** from the left menu:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_43.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You will notice that we have created a Feature Store with two entities (`movies`
    and `users`). Each entity has three features. If you click on any entity provided,
    you will see some details about that particular entity (in our case, the entity
    is `movies`):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As a fully managed solution, Vertex AI Feature Store provides a centralized
    repository for you to organize, store, and serve ML features, and for your team
    to share, discover, and reuse ML features at scale. It greatly helps in developing
    and deploying new ML applications. For more detailed information about Feature
    Store, check out [https://cloud.google.com/vertex-ai/docs/featurestore](https://cloud.google.com/vertex-ai/docs/featurestore).
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – pipelines and metadata
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pipelines help you automate and reproduce your ML workflow. Vertex AI integrates
    its ML offerings across Google Cloud into a seamless development experience. Previously,
    models trained with AutoML and custom models were accessible via separate services.
    Vertex AI combines both into a single API, along with other new products. In this
    demo, we will create and run ML pipelines with Vertex Pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to use the Vertex AI SDK and create a Jupyter notebook. After
    creating a notebook, click on **OPEN JUPYTERLAB**, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_45.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The new notebook will open in a new tab. Clone the repository ([https://github.com/GoogleCloudPlatform/vertex-ai-samples](https://github.com/GoogleCloudPlatform/vertex-ai-samples)).
  prefs: []
  type: TYPE_NORMAL
- en: 'From the cloned folder, go to `Vertex-ai-samples` | `notebooks` | `official`
    | `pipelines`. After clicking on the `automl_tabular_classification_beans.ipynb`
    file, the notebook will open on the left-hand side, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_46.jpg)'
  prefs: []
  type: TYPE_IMG
- en: From the given notebook, read the overview and look at the dataset, objectives,
    and the cost of the particular demo. Run all commands as you go (we will not describe
    every single script but will focus on the main parts that are related to Vertex
    AI Pipeline).
  prefs: []
  type: TYPE_NORMAL
- en: 'The scripts you are going to run will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Set the project ID and bucket (where all the data will be stored).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import the necessary libraries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the constants and create the necessary components.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create an end-to-end ML pipeline. This process will take over 2 hours since
    it is going to perform the following tasks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a dataset in Vertex AI.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Train a tabular classification model with AutoML.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Get evaluation metrics on this model.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on the evaluation metrics, it will decide whether to deploy the model
    using conditional logic in Vertex Pipelines.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the model to an endpoint using Vertex prediction.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After creating a pipeline, to view and analyze it, from the left menu of Vertex
    AI, click on **Pipelines**, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_47.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After clicking on **Pipelines**, you will be taken to a page where you can
    select a pipeline you want to view. You will see the following diagram of the
    pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_48.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you click the `dataset` artifact, you’ll see details about the Vertex AI
    dataset that was created. You can click the link specified next to **URI** to
    go to the page for that dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_49.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To check the resulting metric visualizations from your custom evaluation component,
    click on the `metrics` artifact. On the right-hand side of your dashboard, you’ll
    be able to see the confusion matrix for this model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_50.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To check the model and endpoint that was created from this pipeline run, go
    to the `automl-beans` model. There, you should see this model deployed to an endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_51.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Remember that each section in the pipeline will produce output that will be
    used as input for the next section. Later, if those outputs/inputs need to be
    modified, click on the **Metadata** button from the left menu:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_52.jpg)'
  prefs: []
  type: TYPE_IMG
- en: With that, we have covered Vertex AI Pipelines and metadata. In the next section,
    we will discuss model monitoring for Vertex AI.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI – model monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After model deployment, we need to monitor it since the data and environment
    may change and cause the model to deteriorate over time. Two concepts of monitoring
    should be considered: **feature skew** and **drift detection**.'
  prefs: []
  type: TYPE_NORMAL
- en: In our demo documentation, we are going to build a brand-new tabular dataset
    and train the model. In this example, we will be using the *Women’s International
    Football Results* ([https://www.kaggle.com/datasets/martj42/womens-international-football-results](https://www.kaggle.com/datasets/martj42/womens-international-football-results))
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have created a tabular dataset where we have uploaded a CSV file that’s
    been downloaded from Kaggle. The following screenshot shows a summary of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_53.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We have also trained a model using the AutoML method, and as the target, we
    have used the `neutral` column, which has two values (either `False` or `True`).
    The following screenshot shows the summary of the trained model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_54.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'With Explainable AI, we can see that the `tournament` column has the most impact
    on our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_55.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we need to deploy our model to Endpoint. Click on the **DEPLOY TO ENDPOINT**
    button, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_56.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the popup menu that appears (on the right-hand side), fill out all the fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Monitoring job display name**: The name of the monitoring job.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring windows length**: How many hours the model will be monitored for.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alert emails**: Enter at least 1 email that is going to receive an alert
    (you can enter multiple email addresses).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sampling rate**: The percentage of the sampling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Leave the rest of the fields as-is and click **CONTINUE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_57.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the next and last section, you need to specify the monitoring objective
    (skew detection or drift detection). If you select the **Training-serving skew
    detection** option, you need to specify the training data source and target column.
    However, if you select the **Prediction drift detection** option, you need to
    specify alert thresholds. In our case, we will select **Prediction drift detection**.
    Next, click on the **DEPLOY** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_58.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'It will take a while to process the deployment to the endpoint. Once the deployment
    has finished, you will receive emails about the *notification and status of the
    deployment*, and the *monitoring job being created* (in two separate emails):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_14_59.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot shows the model monitoring job request email notification.
    Note that the request has been submitted and is based on the incoming prediction
    request. It will be sampled and logged for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this appendix, we looked at examples based on the Google Cloud Vertex AI
    suite, which provides end-to-end services for data scientists. We covered Vertex
    AI datasets, labeling tasks, training, prediction, Workbench, Feature Store, pipelines,
    metadata, and model monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: In the next appendix, we will discuss how to use various Google Cloud ML APIs,
    including the Vision API, NLP API, Speech-to-Text API, Text-to-Speech API, Translation
    API, and Dialogflow API.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Practicing with Google Cloud ML API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [*Chapter 8*](B18333_08.xhtml#_idTextAnchor159), *Discovering Google Cloud
    ML API*, we explored the Google Cloud ML API, which is the API interface provided
    by Google, based on pre-trained models. The Google Cloud ML API includes the following
    APIs, all of which will be covered as topics in this appendix:'
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Vision API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud NLP API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Speech-to-Text API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Text-to-Speech API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Translation API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Dialogflow API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this appendix, we will provide implementation examples for each of these
    APIs. Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Vision API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this appendix, we will show you how to use the Vision API via Google Cloud
    Shell and the Python SDK.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can start using the Vision API, we need to enable the Vision API
    from the Google console. From the left menu of the console, navigate to `Vision
    API`. After clicking on **Vision API**, you will be prompted to enable the API.
    In our case, the API is already enabled, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will start by using the Vision API via Google Cloud Shell. From the Google
    console, from the top-right corner, click on the Cloud Shell icon, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After clicking the Cloud Shell icon, the Shell Terminal will appear at the
    bottom of the console, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let’s look at some examples to show how the Vision API works in Google
    Cloud Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 1** is an image of a tree:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18333_15_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To upload a file to Google Cloud Shell, click on the three dots icon highlighted
    in the following screenshot and click **Upload**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the page that appears, you will be prompted to either upload a file or a
    folder. Navigate to your browser and select the image that you want to upload
    – in our case, `tree.jpeg`. Run the following command in Google Cloud Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_15_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot, we can see *X* and *Y* values. These represent
    the corners of the object, and the object was detected as a flower with a 78%
    confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 2** is an image of the Google logo:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18333_15_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we will try another option that’s available from the Vision API and detect
    a logo. Upload the image of the Google logo, and type the following command in
    Google Cloud Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_15_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also try using other options, such as detecting text on the *same*
    image. It will display the result, such as each character and the location of
    each character on the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_15_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that the preceding screenshot only displays part of the result since the
    output is long.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s interact with the Python SDK and the Vision API:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you must install Python’s Google Cloud Vision API. Use the following
    command in Google Cloud Shell:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will need some Python code. The following is a simple Python script
    where it detects the Google logo in the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we have imported all the necessary libraries, then defined an image name
    (the same logo image we used earlier), detected the logo using the Vision API,
    and printed the result and the score.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to upload the Python script to Cloud Shell. After uploading the
    Python script, we can execute it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: The result indicates that the logo is **Google** and the score is 0.98, which
    means it has a confidence level of about 98%.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud NLP API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Google Cloud NLP API uses models to analyze text. There are several ways
    to use the NLP API. Here, we will show you how to use the NLP API via Google Cloud
    Shell and the Python SDK.
  prefs: []
  type: TYPE_NORMAL
- en: Before you can use the NLP API, you will need to enable it. Simply navigate
    to the Natural Language API from the left menu of the console *or* type `Natural
    Language API` in the search bar at the top of the page. After landing on the NLP
    API web page, you will be asked to **Enable API** (if you have already done this,
    you can skip this).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s start using the NLP API with Google Cloud Shell. Click on the Cloud
    Shell icon to activate it and type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'As output, you will see the result of the classification based on the text
    provided:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding output shows that it successfully identified the text in `People
    & Society / Social Issues & Advocacy` with 98% confidence and `Sensitive Subjects`
    with 89% confidence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try another option – that is, `analyze-sentiment`. Here, we can provide
    some text to analyze the sentiment. For this example, we will use a restaurant
    review from Google Maps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Enter the following command in Google Cloud Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'The analysis will be displayed. The following screenshot shows part of the
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can scroll through the result to view its details. There are two main concepts
    we need to understand: magnitude (the overall strength of the emotion – that is,
    either positive or negative) and score (the overall emotional leaning of the text).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s investigate the NLP API with the Python SDK. There are a few other
    SDKs available as well, such as Java, PHP, Go, and others:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'First, we need to install the SDK. Type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: You need to have a credential to interact with Google Cloud. Therefore, create
    a service account, generate and upload the key, and activate it. We will skip
    this step here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will need some Python code. The following is a simple Python script
    that analyzes sentiment from the given text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'Save the script on your local computer and upload it to Google Cloud Shell
    with a filename of `analyze_sentiment.py`. When all the files have been uploaded,
    you can run the `.py` file to execute the script and start the analysis process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: Using the `analyze-sentiment` method, we can retrieve the value of the sentiment
    and magnitude. We will let you execute it and get the results.
  prefs: []
  type: TYPE_NORMAL
- en: The NLP API can also be used to integrate with other APIs, such as the **Speech-To-Text**
    (**STT**) API. By using the STT API, we can convert a sound/voice file into text
    and apply the NLP API, as well as various methods, to analyze the sentiment/entity/syntax
    of the text.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Speech-to-Text API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Google Cloud Speech-to-Text API is used to convert audio into text. The
    service is based on deep learning technology and supports 120 languages and variants.
    The service can be used to transcribe audio files as well as support voice-activated
    interfaces. Cloud Speech-to-Text automatically detects the language being spoken.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to enable the Speech-to-Text API. From the left menu, scroll
    down and click on `speech to text` in the search bar at the top of the page.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be taken to a page where you will be asked to enable the API. If you
    enabled it previously, you will see the following page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Since we are going to use `curl` to send a request to the Speech-To-Text API,
    we will need to generate an API key to pass in our request URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a request file named `request.json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, run the following command (note that we skipped the key creation step):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command calls the Speech-to-Text API, gets all the variables
    from the `request.json` file, uses the key we have generated, and sends/saves
    all the results to the `result.json` file. To view the `result.json` file, type
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B18333_15_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot shows the converted text from the given audio file,
    the confidence level (which is 98%), the time processed, and the language of the
    text.
  prefs: []
  type: TYPE_NORMAL
- en: Speech-to-Text supports different languages as well. Check out [https://cloud.google.com/speech-to-text/docs/languages](https://cloud.google.com/speech-to-text/docs/languages)
    for more details about supported languages.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Text-To-Speech API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Google Cloud Text-to-Speech API maps natural language texts to human-like
    speech. The initial step is to enable the Text-to-Speech API:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Go to Cloud Shell by clicking on the Shell icon. Before diving into the API,
    check the list of the supported voices and languages. You can check the available
    languages and voices via Google Cloud Shell using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command will list *all* possible languages and voices, along
    with their corresponding code. The following screenshot shows just a small part
    of the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we need to create a JSON file named `synthesize-text.json`, where we
    will specify the language and voice codes and provide some full text that we want
    to convert into audio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code to call the Text-to-Speech API using the `curl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: After running the preceding command, the result will be saved to a file called
    `synthesize-text.txt`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the `synthesize-text.txt` file. You’ll notice that the Text-to-Speech
    API provides the audio output in base64-encoded text and has been assigned to
    the `audioContent` field, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a Python file named `tts_decode.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, run the following command from Cloud Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: Now, our MP3 file is ready.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Translation API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Google’s Cloud Translation API allows you to translate text that’s in more
    than 100 languages. There are two ways to use the Translation API. From the main
    menu of the Google Cloud console, click on `Translation API` into the search bar
    (at the top of the page):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After clicking on the dashboard, you will be prompted to select one of three
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AutoML Translation**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Translation API**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Translation Hub**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since we are going to use `curl` to send a request to the Translation API, we
    will need to generate an API key to pass in our request URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s define our text. Type `TEXT=` and type any sentence. Remember
    that the space between words should *not* be left blank; instead, in each space,
    type `%20`. In our example, we will type `This is a demo documentation`, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we’ve defined our `TEXT` variable, type the following command, which
    is underlined in red:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: That is a `curl` call for the API where we specified a target language (in our
    case, it is `ru`, which stands for Russian). Check out [https://cloud.google.com/translate/docs/languages](https://cloud.google.com/translate/docs/languages)
    to view all the supported languages and ISO-639-1 codes.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the command provided, you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Google Cloud Translation API also has a feature that detects a language
    and translates it into *any* supported language.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we will provide two different texts in different languages,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: Instead of using a space between words, we need to type `%20`.
  prefs: []
  type: TYPE_NORMAL
- en: 'After defining `TEXT_ONE` and `TEXT_TWO`, run the following command to call
    the Translation API to detect the language(s):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return the language that was detected with a confidence level between
    zero and one (where zero stands for 0% and one stands for 100%):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, the language of `TEXT_ONE` is Turkish (`tr`) with a 100% confidence
    level and the language of `TEXT_TWO` is Russian (`ru`) with a 100% confidence
    level as well.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Dialogflow API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Dialogflow API is used for chatbots, **interactive voice response** (**IVR**),
    and other dialog-based interactions with human speech. First, we need to enable
    the Dialogflow API:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To start using the platform, open a new tab and type [https://dialogflow.cloud.google.com/#/logindialogflow.cloud.google.com](https://dialogflow.cloud.google.com/#/logindialogflow.cloud.google.com)
    into your browser. You might be asked to sign in with your Google account.
  prefs: []
  type: TYPE_NORMAL
- en: You will be taken to the Dialogflow platform. This is the Dialogflow ES (essential)
    version. Here, we will mainly be using its **user interface** (**UI**). There
    is a section where you can type scripts (such as Google Functions), which will
    be covered in this demo documentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s become familiar with the Dialogflow UI. The following screenshot
    shows the page you’ll see when you first start the Dialogflow platform:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In Dialogflow, you can have multiple agents. If you have already created agents
    before, you can check them by clicking on the down arrow shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, you can view a list of all created agents and/or create a new agent.
    To create a new agent, scroll down to the bottom and click on **Create new agent**,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You will be taken to the following page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In our case, we will name our new agent `Test-Chatbot` and leave all the other
    settings as-is. Now, click **CREATE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once your agent has been created, you will see **Intents** on the left:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This option helps you understand the intent of the user. Then, we have **Entities**,
    which allows you to grab useful information from users. For example, when someone
    says “I want a veggie pizza,” the chatbot can understand that they want a vegetarian
    pizza instead of a normal pizza.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, **Knowledge** is a beta feature. You can use this feature
    to create a knowledge base inside Dialogflow.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fulfillment** is where you can integrate Dialogflow with other systems such
    as your customer management system. The following screenshot shows an example
    script powered by Google Functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now, let’s learn how to use intents in Dialogflow. An intent is an action a
    user wants to perform or a question a user has. For example, let’s say that they
    want to order a pizza, book an appointment, or want more information about your
    company. In Dialogflow, we can create an agent that can understand the intent
    of the user and automatically reply to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you create a new agent (as we did here), Dialogflow creates two intents
    by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Default Welcome Intent**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Default Fallback Intent**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s see what’s inside **Default Welcome Intent**. To do so, click on **Default
    Welcome Intent**. This intent is for understanding greetings such as Hello, Hi,
    and others:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Each intent consists of two main parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Training phases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Response phases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training phases help Dialogflow understand the intent of the user, whereas
    the response phase involves Dialogflow understanding the greeting. If it does,
    it will respond with some text, which will be provided in the **Responses** section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The other default intent provided by Dialogflow is **Default Fallback Intent**.
    Here, when Dialogflow does not understand the user, it will respond with one of
    the pieces of text provided as a text response in **Default Fallback Intent**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now, let’s dive into creating an intent (as mentioned previously, we will build
    a chatbot where the user will order a pizza).
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a new intent, click **CREATE INTENT**, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will name our first intent `opening_times`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on **ADD TRAINING PHRASES**. This is where we will provide examples of
    how users can express their intent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s add a couple of training phrases, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we need to add some responses. Click on **ADD RESPONSE**, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will add just one response here, but remember you can add multiple responses
    for a particular intent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: When you’ve finished with the training phrases and responses, save them; they
    will automatically start training the agent. Dialogflow needs to train the agent
    to respond to the question. This will take a couple of seconds (or minutes if
    you have a long input); you will be notified when training has been completed.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s try our trained agent. On the right-hand side of the page, you will
    see a small section where you can try your trained agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s type a question for our agent. Let’s ask if they are open today and see
    what response we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In this agent, we can create multiple intents. Dialogflow will understand which
    intents to use and respond to the user’s question.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s create a new intent for ordering pizza. Click on **Intents** from
    the left menu and click on **CREATE INTENT**. The following screenshot shows some
    expressions you can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, provide a single response to the question (you can add more responses
    if you wish):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Upon saving your intent, your agent will be retrained. Let’s test our agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_43.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that the user’s phrase was different than it was in the training phases,
    but Dialogflow still understands the intent and gives the correct response.
  prefs: []
  type: TYPE_NORMAL
- en: If the user needs to provide more details, such as different toppings for the
    pizza, then Dialogflow will need to use entities that haven’t been created yet.
    So, we will need to create an entity.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the left menu, click on **Entities** and then **CREATE ENTITY**, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will use `topping` as the entity’s name. Check the `topping`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_45.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Click **SAVE**.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go back to our intent to order pizza and create a new training phrase
    with some details of ordering such as “I want to order cheese pizza.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some additional expressions for ordering a pizza:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_46.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that when we type `two`, it automatically detects the entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_47.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '`@sys.number` is a built-in entity in Dialogflow that captures/recognizes the
    numbers in the dialog. There are also other built-in entities that can recognize
    emails, addresses, phone numbers, and other details. Check out [https://cloud.google.com/dialogflow/es/docs/reference/system-entities](https://cloud.google.com/dialogflow/es/docs/reference/system-entities)
    for more built-in entities. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_48.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In our case, we are building entities, so we will need to map some words to
    an entity. This will allow us to see which part of the sentence is related to
    which entity. Simply select a word or a phrase from the expression that we used
    in the **Intents** section and assign it to the entity that’s been created, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_49.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After selecting the entity, you can select other words or phrases from the
    training expression and map them to that entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_50.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, we have two different entities – `@sys.number` and `@topping`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_51.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also change or modify the response with more dynamic answers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_52.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Click the **SAVE** button to train the agent and test/try the chatbot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_53.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If the user provides information about the topping for the pizza, we need to
    reinforce the extra question to gather that particular information. Click the
    checkbox next to **topping** in the **REQUIRED** section and click on **Define
    prompts**, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_54.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Add a question that the user will be asked, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_55.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Click **Close** and save the agent. Note that you can add more prompts as well.
    Now, let’s test the agent, which doesn’t know anything about the topping:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_56.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'With that, we have a very simple chatbot with basic functionality. But in real
    life, we would want to keep asking the user if they have any other questions *or*
    if they would like to add some other items to their current order. In our case,
    we have a chatbot where users order a pizza. In addition to asking about the pizza
    and its toppings, we can ask them if they want another pizza *or* if they want
    to add some drinks. This feature is called a **follow-up intent**. To enable this
    feature, click on **Add follow-up intent** next to the **order_pizza** intent,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_57.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'So, if a user wants to continue to add another pizza, they can simply answer
    **YES**. Click **YES** to add the follow-up intent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_58.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Click on the **order_pizza - yes** section; you will be taken to a page where
    you can modify the section’s content.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, we will change the name of the intent, leave all the training
    phrases as-is (they are good enough to use in our case), and add a response that
    states `Great! What topping do you want on your pizza?`. Then, click **SAVE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_59.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'But what happens if the user answers **NO** to this follow-up question (Do
    you want to add more pizza?)? In this case, we would like to ask if they want
    to add a drink to their order. As we did previously, from the follow-up intent,
    select **NO**, click on the sub-intent and change its title (optional), leave
    all the training phrases as-is, and type the answer, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18333_15_60.jpg)'
  prefs: []
  type: TYPE_IMG
- en: After saving the agent, you can try to chat with the bot. You can keep adding
    follow-up questions or new intents based on your designed conversation architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this appendix, we provided examples of how to use various Google Cloud ML
    APIs, including the Vision API, NLP API, Speech-To-Text API, Text-To-Speech API,
    Translation API, and Dialogflow API.
  prefs: []
  type: TYPE_NORMAL
