<html><head></head><body>
		<div id="_idContainer267">
			<h1 id="_idParaDest-228" class="chapter-number"><a id="_idTextAnchor227"/>14</h1>
			<h1 id="_idParaDest-229"><a id="_idTextAnchor228"/>Numerical Optimization</h1>
			<p>In our daily lives, while running errands and doing chores, the human mind is always carrying out some form of optimization. For example, the mind might be optimizing the route to take for single or multiple destinations that we need to visit. It can also be optimizing the cost of items that we need to buy on a trip to a grocery store, or, for example, budgeting our income and expenses on a weekly or monthly basis. Another example is to try to optimize the amount of sleep so that our mind is fresh the following day to work on our projects. In short, we are optimizing multiple tasks and schedules every single day without even knowing or thinking about it. Similarly, nature also optimizes its processes. For example, the Earth goes around the Sun in an optimal path to keep a balance between the various <span class="No-Break">gravitational forces.</span></p>
			<p><strong class="bold">Optimization</strong> also plays a<a id="_idIndexMarker984"/> big role in the technology industry. Several large-scale optimization problems are being solved by small and large corporations. For example, a courier delivering packages to our home follows the route and schedule assigned by an optimization problem that solved an equation (either numerically or analytically) under several constraints to come up with that optimal route. Similarly, stock trading is another example, where the action can be to sell, hold, or buy stocks of a particular company to maximize long-term or <span class="No-Break">short-term gains.</span></p>
			<p>In this chapter, we are going to discuss optimization in general while focusing more on numerical optimization, its examples, and use cases, along with its application in applied machine learning. The following topics will be covered in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Introduction <span class="No-Break">to optimization</span></li>
				<li>Common numerical <span class="No-Break">optimization algorithms</span></li>
				<li>Example use cases of large-scale numerical <span class="No-Break">optimization problems</span></li>
				<li>Numerical optimization using high-performance compute <span class="No-Break">on AWS</span></li>
				<li>Machine learning and <span class="No-Break">numerical optimization</span></li>
			</ul>
			<h1 id="_idParaDest-230"><a id="_idTextAnchor229"/>Introduction to optimization</h1>
			<p>As mentioned in the<a id="_idIndexMarker985"/> introduction to this chapter, optimization is an important tool for making decisions related to a large set of problems in our daily lives and various fields of science. There are various components to an optimization problem, as we are going to discuss in the <span class="No-Break">following subsections.</span></p>
			<h2 id="_idParaDest-231"><a id="_idTextAnchor230"/>Goal or objective function</h2>
			<p>The process of optimization starts with <a id="_idIndexMarker986"/>defining a goal or an objective, such as monetary gain, a route or path, a schedule, items, and so on. Selecting the goal or<a id="_idIndexMarker987"/> objective depends heavily on the problem domain, as well as the specific problem we are trying to solve. In addition to the objective function, we also need to know whether we are maximizing or minimizing the objective function. Again, this also depends on the specific problem domain, as well as the objective function. For an optimization problem with cost as the objective function, our goal will most likely be to minimize it, whereas if our objective function is revenue or profit, we would like to <span class="No-Break">maximize it.</span></p>
			<p>For our route optimization example, one organization might be focused on solving the problem to maximize the number of delivered items, while another organization might want to minimize fuel cost per delivery. So, even though the problem domain is the same for both problems, the objective is different. Many times, the objectives may be related or dependent on each other. For example, in the route optimization problem, the number of delivered items and the fuel cost per delivery seem to be dependent on each other. Trying to deliver the maximum number of items in a given amount of time also means that the route needs to be defined in such a way that the distance from one location to the next is short. This means the vehicle is going to travel short distances to deliver items and hence fuel cost per delivery will <span class="No-Break">be less.</span></p>
			<h2 id="_idParaDest-232"><a id="_idTextAnchor231"/>Variables</h2>
			<p>The objective function for <a id="_idIndexMarker988"/>any optimization problem is generally a function of <a id="_idIndexMarker989"/>several variables. By changing the values of these variables, the value of the objective function also changes. For example, for the route optimization problem, one of the variables can be the speed of the vehicle. If the vehicle speed is increased, the number of deliveries made by the vehicle will increase, thereby improving the objective functionâ€™s value. Numerical optimization problems vary the values of these variables in an attempt to arrive at the optimal value of the optimization function. Mathematically, we can define the objective function, <img src="image/f.png" alt=""/>, which maps some set of variables, <em class="italic">X</em>, to real <span class="No-Break">space, <img src="image/Formula_14.02.png" alt=""/>:</span></p>
			<div>
				<div id="_idContainer217" class="IMG---Figure">
					<img src="image/Formula_14.03.jpg" alt=""/>
				</div>
			</div>
			<p>Our objective or goal is to find the values, <em class="italic">X*</em>, of the <em class="italic">X</em> variable that minimize or maximize (depending on the problem) our objective function, <img src="image/f1.png" alt=""/>. So, for the maximization case, the <a id="_idIndexMarker990"/>optimization problem can be written <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer219" class="IMG---Figure">
					<img src="image/Formula_14.05.jpg" alt=""/>
				</div>
			</div>
			<p>For the minimization <a id="_idIndexMarker991"/>case, the optimization problem can be written <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer220" class="IMG---Figure">
					<img src="image/Formula_14.06.jpg" alt=""/>
				</div>
			</div>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor232"/>Constraints</h2>
			<p>In the route optimization problem discussed previously, there will be an upper limit on the speed of a vehicle based on the<a id="_idIndexMarker992"/> maximum speed allowed on a road. The vehicle should not exceed that speed limit. This will be a constraint on the optimization objective function. Any optimization problem will either have constraints (constrained optimization) or not (unconstrained <a id="_idIndexMarker993"/>optimization). Generally, a large-scale numerical optimization problem has several constraints. The goal of the optimization problem in the presence of constraints then becomes finding the best value of the objective function while satisfying all the constraints. A few example constraints are <span class="No-Break">defined here:</span></p>
			<ul>
				<li><strong class="bold">Linear constraints</strong>: The <img src="image/X1.png" alt=""/> and <img src="image/X2.png" alt=""/> variables<a id="_idIndexMarker994"/> are greater than or equal to zero and their sum is less <span class="No-Break">than 100:</span></li>
			</ul>
			<p class="IMG---Figure"><img src="image/Formula_14.09.png" alt=""/></p>
			<p class="IMG---Figure"><img src="image/Formula_14.10.png" alt=""/></p>
			<p class="IMG---Figure"><img src="image/Formula_14.11.png" alt=""/></p>
			<ul>
				<li><strong class="bold">Non-linear constraints</strong>: The square <a id="_idIndexMarker995"/>of the <img src="image/X1.png" alt=""/> variable is greater <span class="No-Break">than <img src="image/X2.png" alt=""/>:</span></li>
			</ul>
			<p class="IMG---Figure"><img src="image/Formula_14.14.png" alt=""/></p>
			<p>A real-world large-scale <a id="_idIndexMarker996"/>numerical optimization problem will generally have both linear as well as <span class="No-Break">non-linear constraints.</span></p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor233"/>Modeling an optimization problem</h2>
			<p>One of the hardest and <a id="_idIndexMarker997"/>most important tasks in any optimization problem is formulating or modeling the problem itself. This process involves identifying the variables, constraints, and objective function. Knowledge of the problem domain as well as a good understanding of the business problem that we are trying to solve are very important to have a good formulation of the optimization problem. Having a very simplistic formulation will not help us achieve good results with the problem, whereas having a too complicated formulation of the problem might result in giving us no solution or a bad solution while taking a very long time to numerically solve the problem, even on <span class="No-Break">modern-day machines.</span></p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor234"/>Optimization algorithm</h2>
			<p>After formulating the problem, the next step is to pick an optimization algorithm and then use a software tool to run it on the data containing our variables and constraints. No one algorithm solves all the<a id="_idIndexMarker998"/> optimization problems. Picking the right algorithm is a big factor in getting a good solution in a reasonable amount of time. Similarly, there are several open source as well as commercial tools with implementations of optimization algorithms. Depending on our budget and the resources available, we should pick the right software tool to solve the optimization problem. Once the algorithm has been executed and we have the results, the next step is to make sure that all the constraints, as well as optimality conditions, are satisfied. We can also carry out sensitivity analysis on the solution, if it is not an optimal solution, to improve <span class="No-Break">upon it.</span></p>
			<h2 id="_idParaDest-236"><a id="_idTextAnchor235"/>Local and global optima</h2>
			<p>The objective function that our optimization problem is attempting to solve usually has more than one optimum value. For example, if our optimization problem is a minimization problem and our objective function<a id="_idIndexMarker999"/> is convex, then it will have only one minimum value, called the <strong class="bold">global minimum</strong>, which can be found using methods based on calculus or well-known algorithms such as gradient descent, hill climbing, and <span class="No-Break">so on.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.1</em> shows the case of a convex objective function of one variable with a global minimum value, while <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.2</em> shows a convex objective function of <span class="No-Break">two variables:</span></p>
			<div>
				<div id="_idContainer229" class="IMG---Figure">
					<img src="image/B18493_14_001.jpg" alt="Figure 14.1 â€“ A convex objective function of one variable with a global minimum"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 â€“ A convex objective function of one variable with a global minimum</p>
			<div>
				<div id="_idContainer230" class="IMG---Figure">
					<img src="image/B18493_14_002.jpg" alt=" Figure 14.2 â€“ A convex objective function of two variables with a global minimum"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 14.2 â€“ A convex objective function of two variables with a global minimum</p>
			<p>Most of the optimization problems that we encounter and process in our daily lives have non-convex objective functions. These <a id="_idIndexMarker1000"/>objective functions have more than one optimum value, referred to as <strong class="bold">local optima</strong>. <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.3</em> and <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.4</em> show examples of objective functions with one variable with multiple <span class="No-Break">local minima:</span></p>
			<div>
				<div id="_idContainer231" class="IMG---Figure">
					<img src="image/B18493_14_003.jpg" alt="Figure 14.3 Â­â€“ Objective function with multiple local minima"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.3 Â­â€“ Objective function with multiple local minima</p>
			<div>
				<div id="_idContainer232" class="IMG---Figure">
					<img src="image/B18493_14_004.jpg" alt=" Figure 14.4 â€“ Objective function with multiple local minima"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 14.4 â€“ Objective function with multiple local minima</p>
			<p><span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.5</em> and <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.6</em> show <a id="_idIndexMarker1001"/>examples of objective functions with two variables with multiple <span class="No-Break">local minima:</span></p>
			<div>
				<div id="_idContainer233" class="IMG---Figure">
					<img src="image/B18493_14_005.jpg" alt="Figure 14.5 â€“ Non-convex objective function showing multiple local minima"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5 â€“ Non-convex objective function showing multiple local minima</p>
			<div>
				<div id="_idContainer234" class="IMG---Figure">
					<img src="image/B18493_14_006.jpg" alt="Figure 14.6 â€“ Another example of a non-convex objective function showing multiple local minima"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.6 â€“ Another example of a non-convex objective function showing multiple local minima</p>
			<p>For optimization problems with non-convex objective functions, it is not easy to find the global minimum. No<a id="_idIndexMarker1002"/> matter which algorithm we use, chances are that we will get a local minimum as the solution. There are, however, algorithms that perform iterative procedures to find good local minimum values. Random restart hill climbing and simulated annealing are examples of such algorithms. These iterative algorithms can be run on multiple machines or processors â€“ not only to find a good local optimum solution in a short amount of time but also to be able to search multiple locations in the search space for the objective <span class="No-Break">function concurrently.</span></p>
			<p>In the next section, we will discover some of the commonly used numerical <span class="No-Break">optimization algorithms.</span></p>
			<h1 id="_idParaDest-237"><a id="_idTextAnchor236"/>Common numerical optimization algorithms</h1>
			<p>Several numerical<a id="_idIndexMarker1003"/> optimization algorithms are implemented in open source and commercially sold optimization software tools. A lot of these algorithms are based on heuristic search, which is a technique based on solving problems quickly compared to classic methods. Heuristics-based algorithms attempt to find an approximate solution since the exact solution is very hard to find. The solutions provided by heuristics-based methods are considered good enough to solve the problem; however, it is generally not the best solution. In this section, we will briefly discuss a few of these algorithms. For detailed discussions on these algorithms and their mathematical formulation, you <a id="_idIndexMarker1004"/>can refer to the articles and texts cited in the <em class="italic">Further reading</em> section of <span class="No-Break">this chapter.</span></p>
			<h2 id="_idParaDest-238"><a id="_idTextAnchor237"/>Random restart hill climbing</h2>
			<p>In <strong class="bold">hill climbing</strong>, we start from a point, <img src="image/Formula_14.15.png" alt=""/>, and search in the neighborhood of <img src="image/X.png" alt=""/>. If the value of the objective<a id="_idIndexMarker1005"/> function, <img src="image/f2.png" alt=""/>, increases in any direction in the neighborhood of <img src="image/X.png" alt=""/>, then we move in the direction of the increment. We stop when the value of the objective function does not increase in any direction. This is the local optimum value of the objective function relative to our <a id="_idIndexMarker1006"/>starting point. This method is also called <strong class="bold">steepest ascent hill climbing</strong>. The algorithm is <span class="No-Break">very simple:</span></p>
			<p class="IMG---Figure"><img src="image/Formula_14.19.png" alt=""/></p>
			<p class="IMG---Figure"><img src="image/Image94631.png" alt=""/></p>
			<p class="IMG---Figure"><img src="image/Formula_14.21.png" alt=""/></p>
			<p><span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.7</em> shows an example of hill climbing to a local <span class="No-Break">maximum value:</span></p>
			<div>
				<div id="_idContainer242" class="IMG---Figure">
					<img src="image/B18493_14_007.jpg" alt="Figure 14.7 â€“ Example of hill climbing to a local optimum in the objective function"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.7 â€“ Example of hill climbing to a local optimum in the objective function</p>
			<p>For the case of minimization problems, the algorithm searches for a valley (or local minimum value) in the objective<a id="_idIndexMarker1007"/> function. Note that the optimum value found in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.7</em> is a local optimum value and it depends on where we started the <span class="No-Break">search from.</span></p>
			<p><strong class="bold">Random restart hill climbing</strong> is an <a id="_idIndexMarker1008"/>extension of the hill climbing method, in which, after finding an optimum value, the algorithm starts again at a different location in the variable space. This will often result in arriving at a different optimum value, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer243" class="IMG---Figure">
					<img src="image/B18493_14_008.jpg" alt="Figure 14.8 â€“ Random restart hill climbing starting at two different variable values and then using hill climbing to get to the optimum value in the vicinity"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.8 â€“ Random restart hill climbing starting at two different variable values and then using hill climbing to get to the optimum value in the vicinity</p>
			<p>Even though the algorithm arrives at the global optimum value in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.8</em>, this will not always be the<a id="_idIndexMarker1009"/> case. However, if we run random restart hill climbing several times, chances are that our resulting local optimum value at the end will be better than just trying hill climbing only once. Since random restart hill climbing starts with different values of the variables, which are chosen randomly each time, each iteration can be run on separate processors and threads to speed up <span class="No-Break">the algorithm.</span></p>
			<h2 id="_idParaDest-239"><a id="_idTextAnchor238"/>Simulated annealing</h2>
			<p>In random restart hill climbing, we<a id="_idIndexMarker1010"/> only move in one direction â€“ the direction toward a local maximum (or minimum, depending on the problem type). This means that the algorithm only exploits the information and is not exploring outside of its immediate neighborhood. By not exploring at all, there<a id="_idIndexMarker1011"/> is a good chance that the algorithm will get stuck in a local optimum value and will stay there. In <strong class="bold">simulated annealing</strong>, the algorithm also explores. It is not always trying to improve upon the current objective function value (to move in the direction of the local optimum), but it also sometimes moves in the direction where the objective function value gets worse (opposite to the direction of the local optimum). The<a id="_idIndexMarker1012"/> simulated annealing algorithm is described <span class="No-Break">as follows.</span></p>
			<p>For a finite set of iterations, do <span class="No-Break">the following:</span></p>
			<ol>
				<li>Sample the new point, <img src="image/Formula_14.22.png" alt=""/>, in the neighborhood, <img src="image/Formula_14.23.png" alt=""/> of the current <span class="No-Break">point, <img src="image/Formula_14.24.png" alt=""/></span></li>
				<li>Jump to the new point<a id="_idIndexMarker1013"/> with the probability given by an acceptance probability function, <img src="image/Formula_14.25.png" alt=""/>, where <em class="italic">T</em> is the temperature parameter that controls how often we jump, and <em class="italic">f</em> is the objective <span class="No-Break">function value:</span></li>
			</ol>
			<p class="IMG---Figure"><img src="image/Formula_14.26.png" alt=""/></p>
			<ol>
				<li value="3">Decrease <span class="No-Break">temperature, <img src="image/Formula_14.27.png" alt=""/></span></li>
			</ol>
			<p>In the preceding expression, if the objective function value for the new point is greater than the current value, then we make the jump to the new point. If the objective function value for the new point is less than the current value, we make the jump to the new point with the <span class="No-Break">following probability:</span></p>
			<p class="IMG---Figure"><img src="image/Formula_14.28.png" alt=""/></p>
			<p>Now, letâ€™s look at the effects of temperature on <span class="No-Break">simulated annealing.</span></p>
			<h3>Effects of temperature, T</h3>
			<p>The following are the effects of temperature, <em class="italic">T</em>, in <span class="No-Break">simulated annealing:</span></p>
			<ul>
				<li>If <em class="italic">T </em>is large, the<a id="_idIndexMarker1014"/> exponential will be close to 1, and we would make the jump with high probability, regardless of the objective function value at the new point, <img src="image/Formula_14.30.png" alt=""/>. This is very similar to random walk <span class="No-Break">when <img src="image/Formula_14.31.png" alt=""/>.</span></li>
				<li>If <em class="italic">T </em>is small, the exponential will be very small and we would rarely make the jump to the new point. This is very similar to hill climbing <span class="No-Break">when </span><span class="No-Break"><img src="image/Formula_14.33.png" alt=""/>.</span></li>
			</ul>
			<p>During the algorithm run, <em class="italic">T </em>is generally decreased slowly. When <em class="italic">T </em>is large, we jump around in the objective function space quite often and there is a good chance that we will end up somewhere close to the global optimum value or a good local optimum value for the objective function. By the time we have reduced <em class="italic">T </em>to a small value, we are probably very close to the global optimum and hence looking only in its vicinity. The probability of ending at a point, <img src="image/X.png" alt=""/>, is given <span class="No-Break">as follows:</span></p>
			<p class="IMG---Figure"><img src="image/Formula_14.38.png" alt=""/></p>
			<p>Here, <img src="image/Formula_14.39.png" alt=""/> scales the probabilities between 0 and 1. As we can see from this expression, the larger the value of the objective function (in the case of the global maximum), the larger the probability that we will end at that point, <img src="image/X.png" alt=""/>. The same holds for the case of <span class="No-Break">minimization tasks.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.9</em> demonstrates<a id="_idIndexMarker1015"/> the concept of simulated annealing, along with the probabilities of moving to the new point, depending on whether the newly selected points improve the objective function <span class="No-Break">or not:</span></p>
			<div>
				<div id="_idContainer258" class="IMG---Figure">
					<img src="image/B18493_14_009.jpg" alt="Figure 14.9 â€“ Probability of moving to a new point in simulated annealing when a neighboring point is selected to be the next point"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.9 â€“ Probability of moving to a new point in simulated annealing when a neighboring point is selected to be the next point</p>
			<p>Letâ€™s discuss Tabu <span class="No-Break">search next.</span></p>
			<h2 id="_idParaDest-240"><a id="_idTextAnchor239"/>Tabu search</h2>
			<p><strong class="bold">Tabu search</strong> is another heuristic-based<a id="_idIndexMarker1016"/> numerical optimization <a id="_idIndexMarker1017"/>method conceptually similar to simulated annealing. Just like simulated annealing, we are allowed to move to a solution where our objective function value worsens. In Tabu search, local search is carried out and it is prohibited to come back to previously visited solutions. A Tabu list is maintained that consists of rules<a id="_idIndexMarker1018"/> and solutions that are not allowed to be explored during the local search, giving this method the name <span class="No-Break">Tabu search.</span></p>
			<h2 id="_idParaDest-241"><a id="_idTextAnchor240"/>Evolutionary methods</h2>
			<p>Evolutionary algorithms are population-based algorithms that use candidate solutions along with some fitness<a id="_idIndexMarker1019"/> function to evolve/improve the solution using mutation and recombination. Evolutionary methods are used quite often in numerical optimization problems and can find a good local optimum generally within a few iterations. Genetic algorithms are a very well-known and used class of evolutionary algorithms. Genetic algorithms have several applications in the domain of numerical optimization, as well as machine learning. They can be used with binary as well as non-binary representations. Genetic algorithms generally use two solutions and apply a crossover operator to these solutions to arrive at a <span class="No-Break">better solution.</span></p>
			<p>In the next section, we will discuss the various applications and use cases of large-scale numerical <span class="No-Break">optimization problems.</span></p>
			<h1 id="_idParaDest-242"><a id="_idTextAnchor241"/>Example use cases of large-scale numerical optimization problems</h1>
			<p>In the previous section, we discussed a few of the commonly used numerical optimization methods. There are several others that we did not touch upon, and we recommend you check the <em class="italic">References</em> section for some great texts on several numerical optimization methods. Several very common large-scale optimization problems are implemented and <a id="_idIndexMarker1020"/>solved in verticals, such as logistics, manufacturing, telecommunications, health care and life sciences, financial services, and so on. In this section, we are going to discuss a few of the very common practical large-scale numerical optimization use cases and applications. We will discuss the following <span class="No-Break">use cases:</span></p>
			<ul>
				<li>The traveling salesperson problem of determining the best route for a salesperson going from one city to <span class="No-Break">the next</span></li>
				<li>A dispatch optimization problem for technicians traveling via vehicles and carrying out various jobs in a <span class="No-Break">geographic location</span></li>
				<li>Assembly line optimization to allocate the optimal type and number of parts to be manufactured on an <span class="No-Break">assembly line</span></li>
			</ul>
			<p>We will begin by<a id="_idIndexMarker1021"/> discussing one of the oldest and most commonly studied numerical optimization problems, known as the traveling <span class="No-Break">salesperson problem.</span></p>
			<h2 id="_idParaDest-243"><a id="_idTextAnchor242"/>Traveling salesperson optimization problem</h2>
			<p>The traveling salesperson <a id="_idIndexMarker1022"/>problem is one of the most studied combinational optimization problems, first formulated in 1930. It belongs to the class of NP-hard problems; the decision version of this problem belongs to the class of NP-complete problems. In the<a id="_idIndexMarker1023"/> traveling salesperson problem, we are given a set of cities (or locations), and we start from a city, travel to each city exactly once, and return to the origin city to find the shortest route to accomplish this task. For example, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.10</em>, in the US map, we want to start from city A, travel through all the cities marked, and then return to city A while following the shortest <span class="No-Break">possible route:</span></p>
			<div>
				<div id="_idContainer259" class="IMG---Figure">
					<img src="image/B18493_14_010.jpg" alt="Figure 14.10 â€“ A map of the US showing arbitrary cities A through O"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.10 â€“ A map of the US showing arbitrary cities A through O</p>
			<p>Even though this problem seems simple to solve, it is an NP-hard problem. There are several combinations that the traveling salesperson can take to visit each city exactly once, but there is generally only one solution that accomplishes this with the shortest possible route. The traveling salesperson problem can be formulated in a few different ways. It can be formulated as <a id="_idIndexMarker1024"/>an undirected weighted graph with cities being the vertices of the graph, the route connecting the cities being the edges, and weighted by the distance between the cities. It can then be solved as a minimization problem that starts and finishes at a given vertex, with each vertex being visited <span class="No-Break">exactly once.</span></p>
			<p>Another way to model the<a id="_idIndexMarker1025"/> traveling salesperson problem is as an integer linear program. Several formulations can be used, such as the Miller-Tucker-Zemlin formulation and the Dantzig-Fulkerson-Johnson formulation. When the number of cities is small and only a small set of paths exists between the cities, the exact solution can be found in a small amount of time. However, as the number of cities and routes between the cities become large, finding the exact solution in a reasonable amount of time becomes almost impossible. In such situations, numerical methods attempt to find approximate or suboptimal solutions for the problem. <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.11</em> shows one such example of a route found between the cities shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.10</em>. There may be possible shortest routes that exist for this problem, but the route shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.11</em> is reasonably<a id="_idIndexMarker1026"/> good and is quite possibly either the shortest possible route or very close to the shortest <span class="No-Break">possible route:</span></p>
			<div>
				<div id="_idContainer260" class="IMG---Figure">
					<img src="image/B18493_14_011.jpg" alt="Figure 14.11 â€“ Example of the traveling salesperson problem showing a very good route (possibly the shortest possible route) between the cities marked from A through O on the map"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.11 â€“ Example of the traveling salesperson problem showing a very good route (possibly the shortest possible route) between the cities marked from A through O on the map</p>
			<p>The traveling salesperson problem has several applications in various fields, such as planning, logistics, manufacturing, DNA sequencing, and so on. There are also several open source and <a id="_idIndexMarker1027"/>commercially sold software tools available for finding a solution for the traveling salesperson problem, as well as extending it to additional similar problems that exist in the industry. One of the most common practical extensions of the traveling salesperson problem is the vehicle routing problem. In the following section, we will discuss a more complex extension of the vehicle routing problem, called the worker dispatch <span class="No-Break">optimization problem.</span></p>
			<h2 id="_idParaDest-244"><a id="_idTextAnchor243"/>Worker dispatch optimization</h2>
			<p>The vehicle routing problem attempts to find the optimal set of routes for a fleet of vehicles to make deliveries to <a id="_idIndexMarker1028"/>customers. This is a very common problem in logistics where organizations such as the <strong class="bold">United States Postal Service</strong> (<strong class="bold">USPS</strong>), <strong class="bold">United Parcel Service</strong> (<strong class="bold">UPS</strong>), FedEx Corporation, and others, have to deliver several packages to a set of customers in various geographic locations daily. This problem can be formulated using various business objectives, such as delivering the packages promptly while maximizing the<a id="_idIndexMarker1029"/> number of deliveries assigned to a driver/vehicle and minimizing the total fuel cost. These organizations generally formulate this problem as an optimization problem and then solve it daily (and often multiple times a day) to make the delivery to customers while also maximizing their profitability within <span class="No-Break">certain constraints.</span></p>
			<p>Similar to the traveling person problem, finding a solution for the vehicle routing problem is also NP-hard. However, several numerical optimization software tools find a very good local optimum solution in a reasonable amount of time. Furthermore, using high-performance and distributed computing, the software can be written to start searching for various solutions at the same time on multiple processors and machines and then aggregate and find the best one out of the various local <span class="No-Break">optima found.</span></p>
			<p>Often, the vehicle routing problem is also extended with a few modifications to solve even more complex problems. One such example is the technician or worker dispatch optimization problem. In a worker dispatch optimization problem, the goal is to send technicians or workers to a customer location and carry out some task that requires time to complete. This is a very common problem for service-providing organizations such as electricity, gas, internet, telecommunication, and so on. These organizations have several worker/technician hubs or garages based on the home location of the worker. The jobs that arrive each day need to be assigned to these workers based on their schedules, as well as their skills and skill competency levels, since not all jobs are always the same. All workers have the same skill level for different types of jobs. Furthermore, in all such jobs, there is a committed time window to the customer that needs to be met for customer satisfaction. In addition, different jobs take a different amount of time to complete, and there is also the time required to travel a distance to the customer location, which may vary based on the time <span class="No-Break">of day.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.12</em> shows an <a id="_idIndexMarker1030"/>example where there is a worker hub in the center and several customer locations that need to be serviced by workers/technicians on a <span class="No-Break">given day:</span></p>
			<div>
				<div id="_idContainer261" class="IMG---Figure">
					<img src="image/B18493_14_012.jpg" alt="Figure 14.12 â€“ An example of the worker/technician optimization problem"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.12 â€“ An example of the worker/technician optimization problem</p>
			<p>We will now outline these<a id="_idIndexMarker1031"/> constraints formally and also discuss a few objective functions that can be used to solve <span class="No-Break">this problem.</span></p>
			<h3>Possible objective metrics for the worker optimization problem</h3>
			<p>The worker optimization<a id="_idIndexMarker1032"/> problem can have several objective functions/metrics based on the requirements of the business. We will list a few of <span class="No-Break">these here:</span></p>
			<ul>
				<li><strong class="bold">Minimize total fuel cost</strong>: With this objective function, the goal is to find a non-trivial solution that minimizes the total fuel cost per job of all the vehicles on any given day. Fuel costs will depend on the number of workers and vehicles, the number of jobs, the location of jobs, the routes that were taken to get to the jobs, the order of the jobs, and the workerâ€™s schedules. Often, minimizing fuel costs is an indirect consequence of finishing the maximum number of jobs on a given day, because if the algorithm can pack a large number of jobs for a given worker, then<a id="_idIndexMarker1033"/> the fuel cost per job for that particular vehicle will be low and hence the total fuel cost per job will be low as well for all <span class="No-Break">the workers.</span></li>
				<li><strong class="bold">Maximize the number of jobs done on a given day</strong>: To maximize profit and also to keep the customers happy, service organizations need to maximize the number of jobs completed on a given day with as few jobs as possible being carried over to the next day. This also depends on the number of workers available on a given day, worker skills, and the route taken to carry out <span class="No-Break">the jobs.</span></li>
				<li><strong class="bold">Maximize worker efficiency</strong>: This objective is dependent on maximizing the number of jobs done on a given day. The goal of this objective function is to maximize the number of jobs carried out by each worker on a given day, which also depends on the technicianâ€™s schedule, skills, level of competency, starting location, and the distance needed to travel by <span class="No-Break">the technician.</span></li>
				<li><strong class="bold">Composite objective function</strong>: In a composite objective function, the goal is to explicitly optimize a combination of objective functions, such as maximizing worker efficiency and minimizing distance or fuel cost. Sometimes, the various terms in a composite objective function may also be opposite to each other. For example, increasing one may result in decreasing the other, and so on. In such cases, we may have penalty terms associated with the different objective functions comprising the composite function and optimize the resulting combination of <span class="No-Break">penalized terms.</span></li>
			</ul>
			<p>Now, letâ€™s look at some of the constraints that can be important for formulating the worker dispatch <span class="No-Break">optimization problem.</span></p>
			<h3>Important constraints for the worker dispatch optimization problem</h3>
			<p>The following are some of the important constraints for the worker dispatch optimization problem. While constraints cover the most common ones, there can be additional constraints, depending on <a id="_idIndexMarker1034"/>the individual <span class="No-Break">use case:</span></p>
			<ul>
				<li><strong class="bold">The number of jobs</strong>: The total number of jobs for a given worker hub on any given day is important and affects the worker efficiency number, as well as the distance traveled, and hence the fuel cost. How many jobs can be feasibly completed on any given day is also heavily dependent on the number of jobs on a <span class="No-Break">given day.</span></li>
				<li><strong class="bold">The number of workers available on a given day</strong>: How many workers are available on a given day to carry out the jobs is another important constraint and it has a significant impact on worker efficiency, as well as distance traveled and <span class="No-Break">fuel cost.</span></li>
				<li><strong class="bold">Worker schedule</strong>: In addition to the number of workers available, the schedule of each worker is also an important constraint. Some workers may start their shift at 8 A.M. and some at 10 A.M., and so on. Similarly, the number of hours each worker may work each day might be different. Some may work for 8 hours, and others for 6 hours. In addition, generally, workers also have break times, such as lunch and other periodic breaks. These breaks may also be at different times, adding further schedule-related constraints to the <span class="No-Break">optimization problem.</span></li>
				<li><strong class="bold">Job types</strong>: There are generally several different job types. For example, for a telecommunication organization, there might be new service installations or old service repair jobs. In addition, several service-providing organizations offer multiple products and services. For example, a telecommunication organization generally offers internet, cable/TV services, and home phone services. These different job types add another dimension to the optimization problem, further <span class="No-Break">complicating it.</span></li>
				<li><strong class="bold">Worker skills and skills-related competency levels</strong>: Just like the different job types mentioned previously, different workers and technicians have different skill types as well as expertise levels in the skill. Using the same telecommunication use case example again, some workers might be dedicated to installing new services and others to repairing old services. In addition, some technicians can be experts in internet service installation and others in telephone service installation. This results in different workers taking different amounts of time to install the same service or debug and repair the same problem. This also <a id="_idIndexMarker1035"/>adds an interesting dilemma when formulating the problem from a business point <span class="No-Break">of view.</span></li>
			</ul>
			<p>The business may want to maximize the total number of jobs completed on a given day, which is generally accomplished if the algorithm matches the skill levels of workers with the jobs appropriately. On the other hand, if the business follows this approach, then the workers may not be able to learn new skills or get practical experience related to services and problems that they are not already an expert at. This parameter regarding skill level should be modeled appropriately in the formulation of the problem to achieve the <span class="No-Break">best results.</span></p>
			<ul>
				<li><strong class="bold">Job locations</strong>: Where each job is located in a geographical location is also important for deciding the route assigned by the optimization solution to <span class="No-Break">each worker.</span></li>
				<li><strong class="bold">Customer time windows</strong>: Service-providing companies also commit to a specific time window in which the worker should arrive at the customer/job location. These time windows may also vary based on the type of job, the number of workers available, as well as geographical locations. These time windows also have a significant effect on the final objective function value. For example, there might be a new service install job at a customer location with a committed time window of 8â€“10 A.M. on a particular day. At the same time, there might be another customer very close by with a repair request. Now, even though the jobs are physically very close to each other, because of the promised time window, the organization will probably need to dispatch multiple workers to adhere to the times committed to the customer. Due to this, several modernized organizations are also formulating the worker dispatch problem jointly with the scheduling problem; when there is a request for a repair or an installation, the scheduler should take into account all these constraints while committing to a time window with <span class="No-Break">the customer.</span></li>
				<li><strong class="bold">Job durations</strong>: Different jobs take different amounts of time to complete. There is generally an average time for a particular job for all the workers in a worker hub, and also<a id="_idIndexMarker1036"/>, individual times are taken by each worker to complete that job. All these are also modeled as constraints in the optimization problem to get the <span class="No-Break">best results.</span></li>
				<li><strong class="bold">Maximum travel time and distance</strong>: Generally, there is also a maximum limit on how much total distance or time a worker may travel on a given day, as well as the farthest a worker may travel from the <span class="No-Break">garage hub.</span></li>
			</ul>
			<p>In addition to these constraints, there may be additional constraints too (for example, the weather: rain, snow, storm, and so on), depending on the particular organization working on the use case. As we can imagine, all these constraints make the worker dispatch optimization problem very complicated. Generally, for any organization using this approach to assign jobs to its workers, this problem is solved on multiple higher-performance computation machines every morning in a distributed fashion. For example, for the same geographic location, the random restart approach for hill climbing and other similar algorithms can be used, with each restart iteration being executed on a different processor and/or machine. There are several open source and commercially available optimization software that formulate and solve this problem very efficiently in a reasonable amount <span class="No-Break">of time.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.13</em> shows an example of three worker hubs with three workers each following an optimized route to the job locations and back to the <span class="No-Break">worker hub:</span></p>
			<div>
				<div id="_idContainer262" class="IMG---Figure">
					<img src="image/B18493_14_013.jpg" alt="Figure 14.13 â€“ Example showing three worker hubs and nine workers ï»¿in totalï»¿, with three workers each starting from a worker hub and following an optimized route to the job locations"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.13 â€“ Example showing three worker hubs and nine workers in total, with three workers each starting from a worker hub and following an optimized route to the job locations</p>
			<p>By using numerical <a id="_idIndexMarker1037"/>optimization algorithms to solve this optimization problem, service companies can improve worker efficiency, cut down on fuel costs, and improve customer satisfaction significantly. Next, we will discuss another example of numerical optimization for allocating items to an assembly line to maximize the number of produced items on a <span class="No-Break">given day.</span></p>
			<h2 id="_idParaDest-245"><a id="_idTextAnchor244"/>Assembly line optimization</h2>
			<p>In manufacturing industries <a id="_idIndexMarker1038"/>such as electronics manufacturing, there are usually several assembly lines or belts on which<a id="_idIndexMarker1039"/> various items are being built and assembled to build a final product, such as a desktop/laptop computer, cell phone, tablet, and so on. On these assembly lines, human workers are manually working on assembling the items. Different assembly lines can assemble different products, with some overlap. Furthermore, the workers assembling the products also vary in some skills and skill levels, just like the worker dispatch optimization problem. Letâ€™s discuss the various optimization metrics <a id="_idIndexMarker1040"/>that can be used for this problem based on<a id="_idIndexMarker1041"/> the business <span class="No-Break">use case.</span></p>
			<h3>Objective metrics for assembly line optimization</h3>
			<p>The following objective<a id="_idIndexMarker1042"/> metrics are some of the common ones used for the assembly line <span class="No-Break">optimization problem:</span></p>
			<ul>
				<li><strong class="bold">Maximize the number of items produced on a given day</strong>: Using this metric, the goal is to maximize the total number of items assembled on any given day. Generally, it also depends on the number of orders, as well as the forecast for the number of items needed in <span class="No-Break">near future.</span></li>
				<li><strong class="bold">Minimize the number of items stored in storage</strong>: With this metric, the goal is to minimize the number of excessive items manufactured and stored in the storage for future sales. This metric also depends on the forecast of items to be manufactured, as well as the <span class="No-Break">storage capacity.</span></li>
			</ul>
			<p>In addition to these metrics, other metrics can be used based on the business use case and goals. Furthermore, like the worker dispatch optimization problem, objective metrics comprised of multiple metrics can also be used. Letâ€™s look at some of the constraints for <span class="No-Break">this problem.</span></p>
			<h3>Constraints for the assembly line optimization problem</h3>
			<p>The following constraints are<a id="_idIndexMarker1043"/> important for the assembly line <span class="No-Break">optimization problem:</span></p>
			<ul>
				<li>The number of different items needed to be assembled each day. This constraint depends on the sales forecast, as well as the number of <span class="No-Break">pre-ordered items.</span></li>
				<li>The number of workers available to work on a given day, as well as the schedule of <span class="No-Break">each worker.</span></li>
				<li>The skills of various individual workers, as well as the skill competency level of <span class="No-Break">each worker.</span></li>
				<li>Skills needed to assemble <span class="No-Break">various items.</span></li>
				<li>The capacity of each belt to assemble <span class="No-Break">different items.</span></li>
				<li>Storage capacity of the factory <span class="No-Break">and/or warehouse.</span></li>
				<li>The maximum number of items that can be stored (surplus) for a specific amount of time, such as a day, a week, or <span class="No-Break">a month.</span></li>
			</ul>
			<p>While these are some of the common constraints being considered while formulating the assembly line optimization problem, there can be additional constraints as well, depending on the specific business use case and various other conditions and requirements. By formulating this problem as an optimization problem and then solving it on a daily, weekly, monthly, or quarterly schedule, manufacturing companies generally improve their<a id="_idIndexMarker1044"/> yield, profit, and efficiency while reducing waste and the number of <span class="No-Break">surplus items.</span></p>
			<p>In this section, we discussed a few applications and use cases of numerical optimization being used in the industry. In the next section, we are going to discuss the high-performance compute options available on AWS for solving these numerical <span class="No-Break">optimization problems.</span></p>
			<h1 id="_idParaDest-246"><a id="_idTextAnchor245"/>Numerical optimization using high-performance compute on AWS</h1>
			<p>As discussed in the previous<a id="_idIndexMarker1045"/> sections, most of the numerical optimization problems are NP-hard and highly compute-intensive for finding a reasonable solution. The software tool employing these algorithms has to carry out a large-scale search over a very complicated multidimensional objective function in search of the global optimum. Because of the complexity, the number of dimensions, non-convexity, and sometimes discontinuities present in these objective functions, it is almost impossible to find the global optimum in a finite amount of time, even with todayâ€™s <span class="No-Break">compute resources.</span></p>
			<p>However, for most of these problems, several commercially available and open source software tools find a very good solution (local optimum) in a reasonable amount of time. These tools can be run on the infrastructure and compute resources provided by AWS. Letâ€™s discuss some of the common commercial and open source tools that can be installed and run on <a id="_idIndexMarker1046"/>various AWS resources to solve numerical optimization problems in almost every <span class="No-Break">industry domain.</span></p>
			<h2 id="_idParaDest-247"><a id="_idTextAnchor246"/>Commercial optimization solvers</h2>
			<p>The following<a id="_idIndexMarker1047"/> commercial solvers <a id="_idIndexMarker1048"/>are some of the most popular and common ones used on AWS <span class="No-Break">compute infrastructure:</span></p>
			<ul>
				<li>IBM ILOG CPLEX Optimization Studio (commonly known <span class="No-Break">as </span><span class="No-Break"><strong class="bold">CPLEX</strong></span><span class="No-Break">)</span></li>
				<li><span class="No-Break">Gurobi Optimization</span></li>
				<li>FICO <span class="No-Break">Xpress Optimization</span></li>
				<li><strong class="bold">A Mathematical Programming </strong><span class="No-Break"><strong class="bold">Language</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">AMPL</strong></span><span class="No-Break">)</span></li>
			</ul>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor247"/>Open source optimization solvers</h2>
			<p>In addition to the<a id="_idIndexMarker1049"/> commercially sold optimization solver tools, the following open source optimization solvers <a id="_idIndexMarker1050"/>can be easily run on AWS compute infrastructure <span class="No-Break">as well:</span></p>
			<ul>
				<li><strong class="bold">GNU Linear Programming </strong><span class="No-Break"><strong class="bold">Kit</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">GLPK</strong></span><span class="No-Break">)</span></li>
				<li><strong class="bold">Computational Infrastructure for Operations </strong><span class="No-Break"><strong class="bold">Research</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">COIN-OR</strong></span><span class="No-Break">)</span></li>
				<li><span class="No-Break">Pyomo</span></li>
				<li><strong class="bold">Convex Over and Under ENvelopes for Nonlinear </strong><span class="No-Break"><strong class="bold">Estimation</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">Couenne</strong></span><span class="No-Break">)</span></li>
				<li><span class="No-Break">PuLP</span></li>
				<li><span class="No-Break">Google OR-Tools</span></li>
				<li>SCIP <span class="No-Break">Optimization Suite</span></li>
			</ul>
			<p>These commercially available and open source software tools can be run on AWS infrastructure <a id="_idIndexMarker1051"/>using a variety of different architecture patterns, as outlined in the <span class="No-Break">following section.</span></p>
			<h2 id="_idParaDest-249"><a id="_idTextAnchor248"/>Numerical optimization patterns on AWS</h2>
			<p>Various <a id="_idIndexMarker1052"/>architecture patterns can be employed to run the previously mentioned optimization software tools on <span class="No-Break">AWS resources.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.14</em> shows various tools and resources from the AWS stack that can be used to help with solving numerical <span class="No-Break">optimization problems:</span></p>
			<div>
				<div id="_idContainer263" class="IMG---Figure">
					<img src="image/B18493_14_014.jpg" alt="Figure 14.14 Â­â€“ Various AWS resources and tools that can be used to solve numerical optimization problems"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.14 Â­â€“ Various AWS resources and tools that can be used to solve numerical optimization problems</p>
			<p>Letâ€™s discuss a few architecture patterns employing these AWS resources and tools and see how they can help with solving numerical <span class="No-Break">optimization problems.</span></p>
			<h3>EC2 instances</h3>
			<p>We can install and run <a id="_idIndexMarker1053"/>these optimization tools on Amazon EC2 instances in a container. The optimization software suite, along with all the required libraries, can be built into a container that can then utilize EC2 instances, which can also be used in a distributed manner to run several parallel searches at the same time (for example, random restart hill climbing). By running multiple iterations of these algorithms in parallel, there is a better chance of arriving at the global optimum <a id="_idIndexMarker1054"/>value or a very good local optimum. <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.15</em> shows the architecture for running these optimization tools on EC2 instances <span class="No-Break">using containers:</span></p>
			<div>
				<div id="_idContainer264" class="IMG---Figure">
					<img src="image/B18493_14_015.jpg" alt="Figure 14.15 â€“ Example architecture showing numerical optimization software running on a containeï»¿r on an Amazon EC2 compute instance"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.15 â€“ Example architecture showing numerical optimization software running on a containe<a id="_idTextAnchor249"/>r on an Amazon EC2 compute instance</p>
			<h3>Using a serverless architecture</h3>
			<p>In addition to using EC2 instances, we can also run the optimization software in a serverless manner on AWS. One example of using a serverless architecture is shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.16</em>, where AWS Lambda is <a id="_idIndexMarker1055"/>used to launch multiple optimization tasks on AWS Fargate. These tasks can be run in parallel and then aggregated to get the best solution for an optimization problem. These tasks can also be different optimization packages and libraries attempting to solve the same problem, with the best result being used at the end. The data consisting of constraints and variables can be read from Amazon S3, as also shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.16</em>. Amazon CloudWatch is also used in this pattern to output the necessary steps and <span class="No-Break">status messages:</span></p>
			<div>
				<div id="_idContainer265" class="IMG---Figure">
					<img src="image/B18493_14_016.jpg" alt="Figure 14.16 â€“ An example of a serverless architecture using AWS Lambda and AWS Fargate to run various optimization tasks in parallel"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.16 â€“ An example of a serverless architecture using AWS Lambda and AWS Fargate to run various optimization tasks in parallel</p>
			<p>The advantage of using this approach over that of EC2 instances is cost and scalability. We can start as many optimization tasks as needed without having to worry about managing EC2 instances. In addition, since we are using a serverless architecture, we only need to pay for the<a id="_idIndexMarker1056"/> compute for the duration that our optimization tasks are running. As an example, for our worker dispatch optimization problem, the job and worker-related data can arrive in an Amazon S3 bucket every morning. Then, using AWS Lambda, various optimization tasks can be launched on AWS Fargate, with each task for a particular worker hub attempting to find the optimal route and schedule for every worker in the <span class="No-Break">worker hub.</span></p>
			<h3>Using Amazon SageMaker processing</h3>
			<p>In addition to using dedicated <a id="_idIndexMarker1057"/>EC2 instances and a serverless architecture, we can also carry out numerical optimization on Amazon SageMaker using SageMaker processing jobs. <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.17</em> shows an example of this architecture pattern, where data consisting of constraints and various variables is residing in an Amazon S3 bucket. AWS Lambda and an AWS Step function are used to launch a SageMaker processing job that reads the data from the S3 bucket and runs the optimization task in a container with all the required packages and software needed to run the optimization job. This optimization job is run on an ephemeral EC2 instance; once the job is completed, the instance is released and no<a id="_idIndexMarker1058"/> more cost for the instance is incurred. The results are written in S3 and also in Amazon DynamoDB after some post-processing by an AWS Lambda function. A few other AWS resources are shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.17</em>, such as for authentication and caching, which may or may not be necessary, depending on the specific <span class="No-Break">use case:</span></p>
			<div>
				<div id="_idContainer266" class="IMG---Figure">
					<img src="image/B18493_14_017.jpg" alt="Figure 14.17 â€“ An example of running numerical optimization using Amazon SageMaker processing"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.17 â€“ An example of running numerical optimization using Amazon SageMaker processing</p>
			<p>In this section, we looked at a few ways numerical optimization problems can be solved using AWS high-performance compute resources and tools. While these are good examples of architectural patterns that can be employed for a variety of use cases, these can also be modified and extended, depending on the use case and <span class="No-Break">business requirements.</span></p>
			<p>In the next section, we are going to look at how numerical optimization is important for solving machine learning problems <span class="No-Break">as well.</span></p>
			<h1 id="_idParaDest-250"><a id="_idTextAnchor250"/>Machine learning and numerical optimization</h1>
			<p>So far, we have discussed numerical optimization and its use cases from an optimization problems perspective. Whereas numerical optimization has several standalone industry use cases and applications, it is also very commonly used in several machine learning algorithms and use cases. Whether itâ€™s supervised learning, unsupervised learning, or reinforcement, we are always solving <a id="_idIndexMarker1059"/>some form of optimization problem using iterative processes at the very core of a machine <span class="No-Break">learning algorithm.</span></p>
			<p>In supervised learning, for example, letâ€™s look at the case of linear regression. In linear regression, we are minimizing a cost function consisting generally of the mean squared error between the actual value of a target variable and the value predicted via <span class="No-Break">the model.</span></p>
			<p>Our algorithm arrives at the minimum value of the cost function (convex function with a global minimum if it is mean squared error, non-convex with local minima in most other cases) using an iterative algorithm, such as gradient descent. Gradient descent looks at the gradient of the cost<a id="_idIndexMarker1060"/> function and then modifies the linear regression parameters in the direction of the gradient. This way, after a certain number of iterations, the algorithm arrives at the global or local minimum value of the <span class="No-Break">objective function.</span></p>
			<p>Similarly, in logistic regression, we use an objective function consisting of logarithm terms. This objective function is again convex and we use gradient descent again to arrive at the minimum value of the objective function. Hence, once again, we are solving a numerical optimization problem at the core of the problem, with the higher-level goal of building a machine learning model for a <span class="No-Break">classification problem.</span></p>
			<p>In neural networks, including deep neural networks, we have several parameters for which we need to find the optimal value so that some error is minimized at the output layer. In the field of deep learning, we often have very large machine learning models consisting of millions or even billions of weights or parameters, especially for natural language processing and computer vision problems. Each neuron or unit in the neural network has some activation function, which is a function of a few of these parameters. To build a model that fits the data well and does good predictions on tests or new data, we need to find the optimal value of neural network parameters/weights. This, again, is achieved by using gradient descent or some other optimization algorithm to solve this numerical optimization problem consisting of a very large number <span class="No-Break">of parameters.</span></p>
			<p>Similar to supervised learning, numerical optimization is also used in unsupervised learning problems. For example, in clustering methods such as K-means clustering, we are trying to minimize the distance between the cluster center and associated points in the cluster. Similarly, in expectation maximization (a soft clustering method), we are maximizing the likelihood of each data point being generated by a Gaussian distribution, whose mean we are attempting <span class="No-Break">to find.</span></p>
			<p>In reinforcement learning, numerical optimization is <a id="_idIndexMarker1061"/>also quite often used. For example, in most reinforcement learning methods, the goal of the algorithm is to maximize some form of long-term reward using actions and rewards, while simulating the scenario repeatedly to learn the optimal policy that maximizes long-term reward. In deep reinforcement learning, we use the neural network weights to approximate the policy. These weights are, again, learned using numerical optimization algorithms such as gradient descent. In short, no matter which type of machine learning problem we are trying to solve, there is a strong connection with numerical optimization, and for most of these machine learning problems, we are solving some form of optimization problem to get the answer for our machine <span class="No-Break">learning problem.</span></p>
			<p>Letâ€™s summarize what weâ€™ve learned in <span class="No-Break">this chapter.</span></p>
			<h1 id="_idParaDest-251"><a id="_idTextAnchor251"/>Summary</h1>
			<p>In this chapter, we discussed numerical optimization and its applications. We started with a discussion about numerical optimization and its necessary ingredients. Next, we discussed a few of the common numerical optimization methods. We also discussed a few large-scale applications and use cases of numerical optimization. These use cases are very well known in academia as well as in the industry and are implemented by several organizations in their businesses. In addition, we talked about how AWS high-performance compute options and resources can be used to solve numerical optimization methods, and also discussed a few architectural patterns to <span class="No-Break">accomplish this.</span></p>
			<p>Finally, we ended with a short discussion about how various categories of machine learning algorithms employ numerical optimization at their core to build good models. The topics covered in this chapter will help you understand and formulate numerical optimization use cases, how numerical optimization is important for machine learning, and how high-performance computing can help with solving numerical optimization use cases. In addition, you should have an idea of the tools and software available for solving numerical <span class="No-Break">optimization problems.</span></p>
			<p>Overall, in this book, we have discussed the fundamentals of high-performance computing, followed by the data management, transfer, compute, networking, and storage aspects of high-performance computing. We also talked about applied modeling and its examples, such as data analysis, preprocessing, visualization, distributed training of machine learning models, optimizing models and their deployment, along with scaling machine learning models. Furthermore, we looked at various applications of high-performance computing, such as computational fluid dynamics, genomics, autonomous vehicles, and numerical optimization. The material presented in this text will introduce you to all these concepts and enable you to explore further and solve interesting use cases in high-performance computing and <span class="No-Break">associated fields.</span></p>
			<h1 id="_idParaDest-252"><a id="_idTextAnchor252"/>Further reading</h1>
			<p>To learn more about the topics that were covered in this chapter, take a look at the <span class="No-Break">following resources:</span></p>
			<ul>
				<li><em class="italic">An Interactive Tutorial on Numerical </em><span class="No-Break"><em class="italic">Optimization</em></span><span class="No-Break">: </span><a href="https://www.benfrederickson.com/numerical-optimization/"><span class="No-Break">https://www.benfrederickson.com/numerical-optimization/</span></a></li>
				<li>El-Ghazali Talbi. 2009. <em class="italic">Metaheuristics: From Design to Implementation</em>. <span class="No-Break">Wiley Publishing.</span></li>
				<li>Refs on NP-hard <span class="No-Break">and completeness:</span><ul><li>The traveling salesperson <span class="No-Break">problem: </span><a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem"><span class="No-Break">https://en.wikipedia.org/wiki/Travelling_salesman_problem</span></a></li><li>The vehicle routing <span class="No-Break">problem: </span><a href="https://www.sciencedirect.com/topics/economics-econometrics-and-finance/vehicle-routing-problem"><span class="No-Break">https://www.sciencedirect.com/topics/economics-econometrics-and-finance/vehicle-routing-problem</span></a></li><li>IBM ILOG CPLEX Optimization <span class="No-Break">Studio: </span><a href="https://www.ibm.com/analytics/cplex-optimizer"><span class="No-Break">https://www.ibm.com/analytics/cplex-optimizer</span></a></li><li>Gurobi <span class="No-Break">Optimization: </span><a href="http://www.gurobi.com"><span class="No-Break">www.gurobi.com</span></a></li><li>FICO Xpress <span class="No-Break">Optimization: </span><a href="https://www.fico.com/en/products/fico-xpress-optimization"><span class="No-Break">https://www.fico.com/en/products/fico-xpress-optimization</span></a></li><li><span class="No-Break">AMPL: </span><a href="https://ampl.com/"><span class="No-Break">https://ampl.com/</span></a></li><li>GNU Linear Programming <span class="No-Break">Kit: </span><a href="https://www.gnu.org/software/glpk/"><span class="No-Break">https://www.gnu.org/software/glpk/</span></a></li><li>Computational Infrastructure for Operations <span class="No-Break">Research: </span><a href="https://www.coin-or.org/"><span class="No-Break">https://www.coin-or.org/</span></a></li><li><span class="No-Break">Pyomo: </span><a href="http://www.pyomo.org/"><span class="No-Break">http://www.pyomo.org/</span></a></li><li>Convex Over and Under ENvelopes for Nonlinear <span class="No-Break">Estimation: </span><a href="https://github.com/coin-or/Couenne"><span class="No-Break">https://github.com/coin-or/Couenne</span></a></li><li><span class="No-Break">PuLP: </span><a href="https://pypi.org/project/PuLP/"><span class="No-Break">https://pypi.org/project/PuLP/</span></a></li><li>Google <span class="No-Break">OR-Tools: </span><a href="https://developers.google.com/optimization"><span class="No-Break">https://developers.google.com/optimization</span></a></li><li>SCIP Optimization <span class="No-Break">Suite: </span><a href="https://www.scipopt.org/"><span class="No-Break">https://www.scipopt.org/</span></a></li></ul></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer268" class="IMG---Figure">
			</div>
		</div>
	</body></html>