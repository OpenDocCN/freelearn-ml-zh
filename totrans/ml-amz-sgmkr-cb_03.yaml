- en: '*Chapter 2*: Machine Learning Basics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers some basic concepts of machine learning that will be used
    and referenced in this book. This is the bare minimum you need to know in order
    to use DataRobot effectively. Experienced data scientists can safely skip this
    chapter. It is not the intention of this chapter to give you a comprehensive understanding
    of statistics or machine learning, but just a refresher of some key ideas and
    concepts. Also, the focus is on practical aspects of what you need to know in
    order to understand the core ideas without going into too much detail. It might
    be tempting to jump in and let DataRobot automatically build the models, but doing
    that without a basic understanding could backfire. If you are leading a data science
    team, please make sure that you have experienced data scientists in your teams
    who are mentoring others and that there are other governance processes in place.
  prefs: []
  type: TYPE_NORMAL
- en: Some of these concepts will come up again during the hands-on examples, but
    we are covering many concepts here that might not come up during a specific example,
    but might come up in relation to your project at some point. The topics listed
    here can be used as a guide to determine some of the basic knowledge that you
    require in order to start using powerful tools such as DataRobot.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will have learned some of the core concepts
    you need to know to use DataRobot effectively. In this chapter, we''re going to
    cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before an algorithm can be applied to a dataset, the dataset needs to fit a
    certain pattern. The dataset also needs to be free of errors. Certain methods
    and techniques are used to ensure that the dataset is ready for the algorithms,
    and this will be the focus of this section.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since DataRobot mostly works with supervised learning problems, we will only
    focus on datasets for supervised machine learning (other types will be covered
    in a later section). In a supervised machine learning problem, we provide all
    the answers as part of the dataset. Imagine a table of data where each row represents
    a set of clues with their corresponding answers (*Figure 2.1*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Supervised learning dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.1_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – Supervised learning dataset
  prefs: []
  type: TYPE_NORMAL
- en: This dataset is made up of columns that contain clues (these are called **features**),
    and there is a column with the answers (this is called **target**). Given a dataset
    that looks like this, the algorithm learns how to produce the right answer given
    a set of clues. No matter what form your data is in, your task is to first transform
    it to make it look like the table in *Figure 2.1*. Note that the clues that you
    have might be spread across multiple databases or Excel files. You will have to
    compile all of that information into one table. If the datasets you have are complex,
    you will need to use languages such as SQL, tools such as **Python** **Pandas**,
    or **Excel**, or tools such as **Paxata**.
  prefs: []
  type: TYPE_NORMAL
- en: Time series datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Time series or forecasting problems have time as a key component of their datasets.
    They are similar to the supervised learning datasets, with slight differences,
    as shown in *Figure 2.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Time series dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.2_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.2 – Time series dataset
  prefs: []
  type: TYPE_NORMAL
- en: You need to make sure that your time series datasets appear as shown in the
    preceding diagram. It should have a date or time-based column, and a column with
    the series values you are trying to forecast, and a set of clues as needed. You
    can also add columns that help to categorize different series, if there are multiple
    time series that you need to forecast. For example, you might be interested in
    forecasting units sold for dates 5 and 6\. If your data is in some other form,
    it needs to be transformed to look like the preceding diagram.
  prefs: []
  type: TYPE_NORMAL
- en: Data cleansing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The data that comes to you will typically have errors in it. For example, you
    might have text in a field that is supposed to contain numbers. You might see
    a price column where the values may contain a $ sign on occasion, but no sign
    at other times. DataRobot can catch some of these, but there are times when an
    automated tool will not catch these, so you need to look and analyze the dataset
    carefully. It is useful to sometimes upload your data to DataRobot to see what
    it finds, and then use its analysis to determine the next steps. Some of this
    cleansing will need to be performed outside DataRobot, so be prepared to iterate
    a few times to get the data set up correctly. Common issues to watch out for include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Wrong data type in a column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mixed data types in a column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spaces or other characters in numeric columns that make them look like text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synonyms or misspelled words
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dates encoded as strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dates with differing formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data normalization and standardization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When different data features have varying scales and ranges, it becomes harder
    to compare their impacts on the target values. Also, many algorithms have difficulty
    in dealing with different scales of values, sometimes leading to stability issues.
    One method for avoiding these problems is to normalize (not to be confused with
    database normal forms) or standardize the values.
  prefs: []
  type: TYPE_NORMAL
- en: 'In normalization (also known as scaling), you scale the values such that they
    range from 0 to 1:'
  prefs: []
  type: TYPE_NORMAL
- en: Xnormalized = (X – Xmin) / (Xmax – Xmin)
  prefs: []
  type: TYPE_NORMAL
- en: 'Standardization, on the other hand, centers the data such that the mean becomes
    zero and scales it such that the standard deviation becomes 1\. This is also known
    as **z-scoring** the data:'
  prefs: []
  type: TYPE_NORMAL
- en: Xstandardized = (X – Xmean) / XSD
  prefs: []
  type: TYPE_NORMAL
- en: Here, Xmean is the mean of all X values, and XSD is the standard deviation of
    X values.
  prefs: []
  type: TYPE_NORMAL
- en: In general, you will not need to worry about this because DataRobot automatically
    does this for the datasets as required.
  prefs: []
  type: TYPE_NORMAL
- en: Outliers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Outliers are values that seem to be out of place compared to the rest of the
    dataset. These values can be very large or very small. In general, values that
    are more than three standard deviations from the mean are considered outliers,
    but this only applies to features where values are expected to be normally distributed.
    Outliers typically come from data quality issues or some unusual situations that
    are not considered relevant enough to be trained on. The data points deemed to
    be outliers are typically removed from the dataset to prevent them from overpowering
    your models. The rules of thumb are only for highlighting the candidates. You
    will have to use your judgment to determine whether any values are outliers and
    whether they need to be removed. Once again, DataRobot will highlight potential
    outliers, but you will have to review those data points and determine whether
    to remove them or leave them in.
  prefs: []
  type: TYPE_NORMAL
- en: Missing values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is a very common problem in datasets. Your dataset may contain many missing
    values, marked as **NULL** or **NaN**. In some cases, you will see a **?**, or
    you might see an unusual value, such as **-999**, that an organization might be
    using to represent a missing or unknown value. How you choose to handle such values
    depends a lot on the problem you are trying to solve and what the dataset represents.
    Many times, you might choose to remove the row of data that contains a missing
    value. Sometimes, that is not possible because you might not have enough data,
    and removing such rows might lead to the removal of a significant portion of your
    dataset. Sometimes, you will see a large number of values in a feature (or column)
    that might be missing. In those situations, you might want to remove that feature
    from the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Another possible way of dealing with this situation is to fill the missing values
    with a reasonable guess. This could take the form of a zero value, or the mean
    value for that feature, or a median value of that feature. For categorical data,
    missing values are typically treated as their own separate category.
  prefs: []
  type: TYPE_NORMAL
- en: More sophisticated methods use the k-nearest neighbor algorithm to compute missing
    values based on other similar data points. No one answer will be appropriate every
    time, so you will need to use your judgment and understanding of the problem to
    make a decision. One final option is to leave it as it is and let DataRobot figure
    out how to deal with the situation. DataRobot has many imputation strategies as
    well as algorithms to handle missing values. But you have to be careful, as that
    might not always lead to the best solution. Talk to an experienced data scientist
    and use your understanding of the business problem to plot a course of action.
  prefs: []
  type: TYPE_NORMAL
- en: Category encoding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many problems, you have to transform your features into numeric values. This
    is because many algorithms cannot handle categorical data. There are many ways
    to encode categorical values and DataRobot has many of these methods built in.
    Some of these techniques are one-hot encoding, leave one out encoding, and target
    encoding. We will not get into the details, as normally you would let DataRobot
    handle this for you, but there might be cases where you will want to encode it
    yourself in a specific way due to your understanding of the business problem.
    This feature of DataRobot is a great time saver and typically works very well
    for most problems.
  prefs: []
  type: TYPE_NORMAL
- en: Consolidate categories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, you have categorical data that contains a large number of categories.
    Although there are methods for dealing with large category counts (as discussed
    in the preceding section), many times, it is advisable to consolidate the categories.
    For example, you might have many categories that contain very few data points,
    but are very similar to one another. In this case, you can combine them into a
    single category. In other cases, it might just be that someone used a different
    spelling, a synonym, or an abbreviation. In such cases, it is better to combine
    them into a single category as well. Sometimes, you might want to split up a numerical
    feature into bins that have a business meaning for your users or stakeholders.
    This is an example of data preparation that you will need to do on your own based
    on your understanding of the problem. You should do this prior to uploading the
    data into DataRobot.
  prefs: []
  type: TYPE_NORMAL
- en: Target leakage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, the dataset contains features that are derived from the target itself.
    These are not known in advance or are not known at the time of prediction. Inadvertently
    using these features to build a model causes problems downstream. This issue is
    called target leakage. The dataset should be inspected carefully and such features
    should be removed from the training features. DataRobot will also analyze the
    features automatically and try to flag any features that might lead to target
    leakage.
  prefs: []
  type: TYPE_NORMAL
- en: Term-document matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your dataset may contain features that contain text or notes. These notes frequently
    contain important information that is useful for making decisions. Many of the
    algorithms, however, cannot make use of this text directly. This text has to be
    parsed into numeric values for it to become useful to modeling algorithms. There
    are several methods for doing that, with the most common one being the term-document
    matrices. Document here refers to a single text or notes entry. Each of these
    documents can be parsed to split it up into terms. Now you can count how many
    times a term showed up in a document. This result can be stored in a matrix called
    a **Term Frequency** (**TF**) matrix. Some of this information can also be visualized
    in word clouds. DataRobot will automatically build these word clouds for you.
    While TF is useful, it can be limiting because some terms might be very common
    in all the documents, hence they are not very useful in distinguishing between
    them. This leads to another idea, whereby perhaps we should look for terms that
    are somewhat unique to a document. This concept of giving more weight to a term
    that is present in some documents only is called **Inverse Document Frequency**
    (**IDF**). The combination of a term showing up multiple times in a document (TF)
    and it being somewhat rare (IDF) is called **TFIDF**. TFIDF is something that
    DataRobot will compute automatically for you and gets applied to features that
    contain text.
  prefs: []
  type: TYPE_NORMAL
- en: Data transformations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While DataRobot will do many data transformations for you (and it keeps adding
    more all the time), there are many transformations that will impact your model
    but that DataRobot will not be able to catch. You will have to do these on your
    own. Examples of these are mathematical transformations such as log, square, square
    root, absolute values, and differences. Some of the simple ones can be set up
    inside DataRobot, but for more complex ones, you will have to perform the operations
    outside of DataRobot or in tools such as Paxata. Sometimes, you will do a transformation
    to linearize your problem or to deal with features that have long-tailed data.
    Some of the transformations that DataRobot does automatically are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Computing aggregates such as counts, min, max, average, median, most frequent,
    and entropy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An extensive list of time-based features, such as change over time, max over
    time, and averages over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some text extraction features, such as word counts, extracted tokens, and term-document
    matrices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geospatial features from geospatial data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will discuss this topic again in more detail in [*Chapter 4*](B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087),
    *Preparing Data for DataRobot*.
  prefs: []
  type: TYPE_NORMAL
- en: Collinearity checks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In any given dataset, there will be features that are highly correlated to other
    features. In essence, they carry the same information as some other features.
    It is generally desirable to remove such features that are highly duplicative
    of some other features in the dataset. DataRobot performs these checks automatically
    for you and will flag these collinear features. This is especially critical for
    linear models, but some of the newer methods can deal with this issue better.
    What thresholds to use varies based on the modeling algorithms and your business
    problem. It is fairly easy in DataRobot to remove these features from your feature
    sets to be used for modeling.
  prefs: []
  type: TYPE_NORMAL
- en: DataRobot also produces a correlation matrix that shows how the different features
    are correlated to one another. This helps identify collinear features as well
    as key candidate features to be used in the model. You can gain a lot of insight
    into your data and the problem by analyzing the correlation matrix. In [*Chapter
    5*](B17159_05_Final_NM_ePub.xhtml#_idTextAnchor097), *Exploratory Data Analysis
    with DataRobot*, we will discuss examples of how this is done.
  prefs: []
  type: TYPE_NORMAL
- en: Data partitioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before you start building the models, you need to partition your dataset into
    three parts. These parts are called training, validation, and holdout. These three
    parts are used for different purposes during the model building process. It is
    common to split 10-20% of the dataset into the holdout set. The remaining portion
    is split up further, with 70-80% going to training and 20-30% going to the validation
    set. This splitting is done to make sure that the models are not overfitted and
    that the expected results in deployment are in line with results seen during model
    building.
  prefs: []
  type: TYPE_NORMAL
- en: Only the training dataset is used to train the model. The validation set is
    designed to tune the algorithms in order to optimize the results by performing
    multiple cross-validation tests. Finally, the holdout set is used after the models
    are built to test the model on data that it has never seen before. If the results
    on the holdout set are acceptable, then the model can be considered for deployment.
  prefs: []
  type: TYPE_NORMAL
- en: DataRobot automates most of this process, but it does allow the user to customize
    the split percentages, as well as how the partitioning should be done. It also
    performs a similar function for time series or forecasting problems by automatically
    splitting the data for time-based backtests.
  prefs: []
  type: TYPE_NORMAL
- en: Data visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most important tasks a data analyst or data scientist needs to do
    is to understand the dataset. Data visualization is key to this understanding.
    DataRobot provides various ways to visualize the datasets to help you understand
    the dataset. These visualizations are built automatically for you so that you
    can spend your time analyzing them instead of preparing them. Let's look at what
    these are and how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you go to the data page (*Figure 1.20*) for your project, you will see
    high-level profile information for your dataset. Inspect this information carefully
    to understand your dataset in totality. If you click on the **Feature Association**
    menu (top left), you will see how the features are related to one another (*Figure
    2.3*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Feature associations using mutual information'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.3_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.3 – Feature associations using mutual information
  prefs: []
  type: TYPE_NORMAL
- en: This diagram shows the interrelationships using the mutual information metric.
    **Mutual Information** (**MI**) uses information theory to determine the amount
    of information you obtain about one feature from the other feature. The benefit
    of using MI compared to the Pearson correlation coefficient is that it can be
    used for any type of feature. The value goes from 0 (the two features are independent)
    to 1 (they carry the same information). This is useful in determining which features
    will be good candidates for the model and which features will not provide any
    useful information or are redundant. This view is extremely important to understand
    and use before model building starts, even though DataRobot automatically uses
    this information to make modeling decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is another metric that is also used in a similar capacity. If you click
    on the metric dropdown at the bottom of the preceding screenshot, you can select
    the other metric called **Cramer''s V**. Once you select Cramer''s V, you will
    see a similar graphical view (*Figure 2.4*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Feature associations using Cramer''s V'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.4_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.4 – Feature associations using Cramer's V
  prefs: []
  type: TYPE_NORMAL
- en: Cramer's V is an alternative metric to MI, and it is used similarly. Its value
    also ranges from 0 (no relationship) to 1 (the features are highly correlated).
    Cramer's V is often used with categorical variables as an alternative to the Pearson
    correlation coefficient.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that DataRobot automatically found clusters of interrelated features.
    Each cluster is color-coded in a different color, and the features are sorted
    by clusters in *Figure 2.4*. You can zoom into specific clusters to inspect them
    further. This is an important feature of the DataRobot environment as very few
    data scientists know about this idea or make use of it. The clusters are important
    because they highlight groups of interrelated features. These complex interdependencies
    are typically very important for understanding the business problem. Normally,
    the only people who know about these complex interdependencies are people with
    a lot of domain experience. Most others will not even be aware of these complexities.
    If you are new to a domain, then understanding these will give you an equivalent
    of multiple years of experience. Study these carefully, discuss them with your
    business experts to fully understand what they are trying to highlight, and then
    use these insights to improve your models as well as your business processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, note that DataRobot provides a list of the top 10 strongest associations.
    It is important to note these associations and spend some time thinking about
    what they mean for your problem. Are these consistent with what you know about
    your domain, or are there some surprises? It is the surprises that often result
    in key insights that could prove to be valuable insights for your business. In
    the following list, you see a **View Feature Association Pairs** button. If you
    click on that button, you will see *Figure 2.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Feature association details'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.5_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.5 – Feature association details
  prefs: []
  type: TYPE_NORMAL
- en: This graphic shows the relationship between two selected features in detail.
    In this example, one feature is categorical while the other is numeric. The diagram
    shows how the two are related and could provide additional insights into the problem.
    Be sure to investigate the relationships, especially the ones that might be counterintuitive.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can click on the specific features to see how they are distributed
    (*Figure 2.6*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Feature details'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.6_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.6 – Feature details
  prefs: []
  type: TYPE_NORMAL
- en: This view shows a histogram of how the values are distributed and how they are
    related to the target values. Key things to focus on are ranges where you do not
    have enough data and where you have non-linearities. These could give you ideas
    about feature engineering. These are also areas where you ask the question why
    does the system exhibit this behavior?
  prefs: []
  type: TYPE_NORMAL
- en: With this background work done, you are now ready to dive into modeling algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are now hundreds of machine learning algorithms available to be used
    for a machine learning project, and more are being invented every day. DataRobot
    supports a wide array of open source machine learning algorithms, including several
    deep learning algorithms – Prophet, SparkML-based algorithms, and H2O algorithms.
    Let''s now take a look at what types of algorithms exist and what they are used
    for (*Figure 2.7*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – Machine learning algorithms'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.7_B17159-DESKTOP-C2VUV36.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.7 – Machine learning algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Our focus will mostly be on the algorithm types that DataRobot supports. These
    algorithm types are described in the following sub-sections.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Supervised learning algorithms are used when you can provide an answer (also
    called a label) as part of the training dataset. For supervised learning, you
    have to assign a feature of your dataset to be the answer, and the algorithm tries
    to learn to predict the answer by seeing multiple examples and learning from these
    examples. See *Figure 2.8* for the different types of answers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Targets for supervised learning algorithms'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.8_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.8 – Targets for supervised learning algorithms
  prefs: []
  type: TYPE_NORMAL
- en: 'DataRobot functionality is primarily focused on supervised learning algorithms.
    Included in the set are deep learning algorithms as well as big data algorithms
    from SparkML and H2O. DataRobot has built-in best practices to select the best-suited
    algorithms for your problem and dataset. There are four major types of supervised
    learning problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Regression problems are the ones where the answer (target) takes a numeric form
    (see *Figure 2.8*). Regression models try to fit a curve such that the error between
    the prediction and the actual value is minimized for the entire training dataset.
    Sometimes, even a classification problem can be set up as a numeric regression
    problem. In such cases, the answer is a number that can then be turned into a
    bin by using thresholds. Logistic regression is one such method that produces
    a value between zero and one. You can mark all answers below a certain threshold
    to be zero, and all above as ones. There are linear as well as non-linear regression
    algorithms that are used based on the problem. The models are assessed based on
    how well the regression line matches the data. Typical metrics used are **RMSE**,
    **MAPE**, **LogLoss**, and **Rsquared**. Typical algorithms used are **XGBoost**,
    **Elastic Net**, **Random Forest**, and **GA2M**.
  prefs: []
  type: TYPE_NORMAL
- en: Binary classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Binary classification problems have answers that can only take two distinct
    values (called classes). These could be in the form of 0 or 1, Yes or No, and
    so on. Please refer to *Figure 2.8* for an example of the target feature for binary
    classification. A typical issue that you commonly face is the problem of class
    imbalance. This happens when most of the dataset is biased toward one class. These
    are typically addressed by downsampling the overrepresented class when sufficient
    training data is present. When this is not possible, you can try oversampling
    the underrepresented class or use other methods. None of these methods is perfect,
    and sometimes you have to try different approaches to see what works best. DataRobot
    provides mechanisms to specify downsampling if needed. Some of the algorithms
    that are commonly used for binary classification are **logistic regression**,
    **k-nearest neighbors**, **tree-based algorithms**, **SVM**, and **Naïve Bayes**.
    In the case of classification problems, it is best to avoid using accuracy as
    a metric to assess results. The results are often shown in the form of a confusion
    matrix (described later in this chapter). DataRobot will automatically select
    an appropriate metric to use in such cases.
  prefs: []
  type: TYPE_NORMAL
- en: Multiclass classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Multiclass classification problems are the ones where you are trying to predict
    more than two classes or categories. For a simple example of what the target might
    look like, see *Figure 2.8*. Multiclass capability was added recently and many
    of the DataRobot features might not work with such problems. Since downsampling
    is not available, you might want to adjust your sampling prior to uploading your
    dataset into DataRobot. Also, note that you can frequently collapse your problem
    into a binary classification problem by collapsing the classes into two classes.
    That may or may not work for your use case, but it is an option if required. Also,
    not all algorithms are appropriate for multiclass problems. DataRobot will automatically
    select the appropriate algorithms to build the models for multiclass problems.
    Typical metrics to use are AUC, LogLoss, or Balanced Accuracy. The results are
    often shown in the form of a confusion matrix (described later in this chapter).
    Typical algorithms used are XGBoost, Random Forest, and TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: Time series/forecasting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Time series or forecasting models are also referred to as time-aware models
    in DataRobot. In these problems, you have data that is changing over time and
    you are interested in predicting/forecasting a target value in the future (*Figure
    2.2*). DataRobot not only supports the usual algorithms for time series such as
    ARIMA, but can also adapt these problems to machine learning regression problems
    and then apply algorithms such as XGBoost to solve them. These problems require
    that the series should be transformed into stationary series and require extensive
    feature engineering to create time-based features. The problems also require that
    you take into account important events in the past that may repeat (such as holidays
    or major shopping days). Time series models also require special ways of handling
    validation and testing via a method called backtests:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – Backtesting for time series problems'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.9_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.9 – Backtesting for time series problems
  prefs: []
  type: TYPE_NORMAL
- en: In backtesting, models are built using past data, and then tested using holdout
    data that is newer and has never been seen by the model. This time-based slicing
    of holdout data is also referred to as out-of-time validation. DataRobot automates
    many of these tasks for you, as we will see in more detail later.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s review some of the main algorithms used in DataRobot. Here, we only
    provide a high-level overview of these algorithms These algorithms can be tuned
    for a given problem by changing their hyperparameters. For a more detailed understanding
    of any specific algorithm, you can refer to a machine learning book or the DataRobot
    documentation. Some of the important algorithms are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Forest**. A random forest model is built by creating multiple decision
    tree models and then uses the mean of the output. This is done by creating bootstrap
    samples of the training data and building decision trees (*Figure 2.10*) on these
    samples:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.10 – Random forest'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.10_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 – Random forest
  prefs: []
  type: TYPE_NORMAL
- en: 'Random forest models handle missing data and non-linearities and have proven
    to work great in many situations. A random forest model can be used for regression
    as well as classification problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**XGBoost**: Also known as **eXtreme** gradient boosted trees, are decision
    tree-based algorithms that have become very popular because they tend to produce
    very effective predictions and can handle missing values. They can handle non-linear
    problems and interactions between features. XGBoost builds upon random forest
    models by creating a random forest and then creating trees on the residuals of
    the previous trees. This way, every new set of trees is able to produce a better
    result. XGBoost can be used for regression as well as classification problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rulefit**: Rulefit models are ensembles of simple rules. You can think of
    these rules as being chained together like a decision tree. Rulefit models are
    much easier to understand as most people can relate to a combination of rules
    being applied to solve a problem. DataRobot typically builds this model to help
    you understand a problem and provide insights. You can go to the insights section
    of your **Models** tab and see the insights generated from a Rulefit model and
    how effective a given rule is for the problem. They can be used for classification
    as well as regression problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ElasticNet**, **Ridge regressor**, **Lasso regressor**: These models use
    regularization to make sure that the models are not overfitting and are not unnecessarily
    complex. Regularization is done by adding a penalty for adding more features,
    which in turn forces the models to either drop some features or reduce their relative
    impact. Lasso regressor (also known as **L1 regressor**) uses penalty weights
    that are the absolute values of the coefficients. The effect of using Lasso is
    that it tries to reduce the coefficients to zero, thereby selecting important
    features and removing the ones that do not contribute much. Ridge regressor (also
    known as **L2 regressor**) uses penalty weights that are squared coefficients.
    The impact of this is to reduce the magnitude of coefficients. **ElasticNet**
    is used to refer to linear models that use both Lasso and Ridge regularization
    to produce models that are simpler as well as regularized. This comes in handy
    when you have a lot of features that are correlated with each other.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logistic Regression**: Logistic regression is a non-linear regression model
    that is used for binary classification. The output is in the form of a probability
    with a value ranging from 0 to 1\. This is then typically used with a threshold
    to assign the value to be a 0 or a 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SVM** (**Support Vector Machine**): This is a classification algorithm that
    tries to find a vector that best separates classes. It is easy to see what this
    looks like in a two-dimensional space (*Figure 2.11*), but the algorithm is known
    to work well in high dimension spaces. Another benefit of SVM is its ability to
    handle non-linearity by using non-linear kernel functions, which can be used to
    linearize the problem:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Targets for supervised learning algorithms'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.11_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.11 – Targets for supervised learning algorithms
  prefs: []
  type: TYPE_NORMAL
- en: '**GA2M** (**Generalized Additive Model**): This is one of those rare algorithms
    that offers understandability, while also offering high accuracy even in a non-linear
    problem. The number "2" in the name represents its ability to model interactions
    between features. GAM model output is a summation of outputs of the effects of
    individual features that have been binned. Since GAM allows these effects to be
    non-linear, it can capture the non-linear nature of the problem. The results of
    the model can be represented as a simple table that shows you the contribution
    of each feature to the overall answer. This type of table representation is easily
    understandable by most people. For industries or use cases where understandability
    and explainability are very important, this is perhaps one of the best options
    you can choose.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**K-Nearest Neighbors**: This is a very straightforward algorithm that finds
    the k closest data points (based on a specific way of computing distance). Now
    it finds the classification answers for these k points. It then determines the
    answer with the most votes and then assigns that as the answer. The default distance
    metric used is **Euclidian** distance, but DataRobot chooses the appropriate metric
    based on the dataset. A user can also specify a specific distance metric to be
    used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TensorFlow**. TensorFlow is a deep learning model that is based on deep neural
    networks. A deep neural network is one that has hidden deep layers made up of
    ensembles of artificial neurons. The neurons carry highly non-linear activation
    functions that allow them to fit highly non-linear problems. These models are
    very good at producing high accuracy without the need for feature engineering,
    but they do require a lot more training data as compared to other algorithms.
    These models are generally considered very opaque and are prone to overfitting
    and are therefore not suitable for some applications. They are especially successful
    for applications where the features and feature engineering are hard to extract,
    for example, image processing. These models can be used for regression as well
    as classification problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Keras Neural Network**: Keras is a high-level deep learning library built
    on top of TensorFlow that allows many types of deep learning models to be incorporated
    into DataRobot. Being a higher-level library, it makes building a TensorFlow model
    a lot easier. Everything described in the preceding section applies to Keras.
    The particular implementation in DataRobot is well suited for sparse datasets
    and is particularly useful for text processing and classification problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unsupervised learning problems are those where you are not provided with an
    answer or a label. Examples of such problems are clustering or anomaly detection.
    DataRobot does not offer much for these problems, but it does have some capability
    for anomaly or outlier detection. These are problems where you have data points
    that are unusual in a way that happens very rarely. Examples include fraud detection,
    cybersecurity breach detection, failure detection, and data outlier detection.
    DataRobot allows you to set up a project without a target and it will then attempt
    to identify anomalous data points. For any clustering problems, you should try
    to use Python or R to create clustering models.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reinforcement learning problems are where you want to learn a series of decisions
    to be taken by an agent such that you achieve a certain goal. This goal is associated
    with a reward that is given to the agent for achieving the goal either completely
    or partially. There is no dataset available for this training, so the agent must
    try multiple times (with different strategies) and learn something on each attempt.
    Over many attempts, the agent will learn the strategy or rules that produce the
    best reward. As you can now guess, these algorithms work best when you do not
    have data, but you can experiment repeatedly in the real world (or a synthetic
    world). As we discussed before, DataRobot is not a suitable tool for such problems.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble/blended models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensembling is a technique for creating a model that aggregates or blends predictions
    of other models. Different algorithms are sometimes able to exploit different
    aspects of the problem or dataset better. This means that many times, you can
    increase prediction accuracy by combining several good models. This, of course,
    comes with increasing complexity and cost. DataRobot offers many blending approaches
    and, in most circumstances, builds the blended model automatically for your project.
    You can then evaluate whether the increase in accuracy is enough to justify the
    additional complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Blueprints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In DataRobot, every model is associated with a blueprint. A blueprint is a
    step-by-step recipe used by DataRobot to train a specific model. See *Figure 2.12*
    for an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Model blueprint'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.12_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.12 – Model blueprint
  prefs: []
  type: TYPE_NORMAL
- en: The blueprint shows all the steps taken by DataRobot to build that specific
    model, including any data preparation and feature engineering done by DataRobot.
    Clicking on any specific box will show more details on the actions taken, parameters
    used, and documentation of the particular algorithm used. This also serves as
    great documentation for your modeling project that is automatically created for
    you.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's look at how to determine how well an algorithm did. For this, we
    will require some performance metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Performance metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DataRobot offers a wide range of performance metrics for the models. You have
    to specify the metric you want to use to optimize the models for your project.
    Typically, the best metric to use is the one recommended by DataRobot. DataRobot
    does compute the other metrics as well once the model is built, so you can review
    the results of your model across multiple metrics. Please keep in mind that no
    metric is perfect for every situation, and you should be careful in selecting
    the metric for evaluating your results. Listed here are some details regarding
    commonly used metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**RMSE** (**Root Mean Squared Error**): RMSE is a metric that first computes
    the square of errors (the difference between actual and predicted). These are
    then averaged over the entire dataset and then we compute a square root of that
    average. Given that this metric is dependent on the scale of the values, its interpretation
    is dependent on the problem. You cannot compare RMSE for two different datasets.
    This metric is frequently used for regression problems when the data is not highly
    skewed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MAPE** (**Mean Absolute Percentage Error**): MAPE is somewhat similar to
    RMSE in the sense that it first computes the absolute value of the percentage
    error. Then, these values are averaged over the dataset. Given that this metric
    is scaled in terms of percentage, it is easier to compare MAPE for different datasets.
    However, you have to be mindful of the fact that the percentage error for very
    small values (or zero values) tends to look very big.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SMAPE** (**Symmetric MAPE**): SMAPE is similar to MAPE, but addresses some
    of the shortcomings discussed above. SMAPE bounds the upper percentage value so
    that errors from small values do not overpower the metric. This makes SMAPE a
    good metric that you can easily compare across different problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accuracy**: Accuracy is one of the metrics used for classification problems.
    It can be represented as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Accuracy = number of correct predictions/number of total predictions*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It is essentially the ratio of the number of correct predictions and all predictions.
    For unbalanced problems, this metric can be misleading, hence it is never used
    by itself to determine how well a model did. It is typically used in combination
    with other metrics.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Balanced Accuracy**: Balanced accuracy overcomes the issues with accuracy
    by normalizing the accuracy across the two classes being predicted. Let''s say
    that the two classes are A and B:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (a) *Accuracy rate for A = number of correct A predictions/total number of As*
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (b) *Accuracy rate for B = number of correct B predictions/total number of Bs*
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (c) *Balanced accuracy = accuracy rate for A + accuracy rate for B/2*
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Balanced accuracy is essentially the average of the accuracy rate for A and
    the accuracy rate for B.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**AUC** (**Area Under the ROC Curve**): AUC is the area under the **ROC** (**Received
    Operator Characteristic**) curve. This metric is frequently used for classification
    problems as this also overcomes the deficiencies associated with the accuracy
    metric. The ROC curve represents the relationship between the true positive rate
    and the false positive rate. The AUC goes from 0 to 1 and it shows how well the
    model discriminates between the two classes. A value of 0.5 represents a random
    model, so you would want the AUC for your model to be greater than 0.5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gamma Deviance**: Gamma deviance is used for regression problems when the
    target values are gamma-distributed. For such targets, gamma deviance measures
    twice the average deviance (using the log-likelihood function) of the predictions
    from the actuals. A model that fits perfectly will have a deviance of zero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Poisson Deviance**: Poisson deviance is used for regression problems when
    the aim is to count data that is skewed. It works in a way that is very similar
    to gamma deviance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LogLoss**: LogLoss (also known as cross-entropy loss) is a measure of the
    inaccuracy of predicted probabilities for a classification problem. A value of
    0 indicates a perfect model, and as the model becomes worse, the logloss value
    increases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rsquared**: Rsquared is a metric used for regression problems that tells
    how well the fitted line represents the dataset. Its value ranges between 0 and
    1\. 0 indicates a poor model that explains none of the variation, while a value
    of 1 indicates a perfect model that explains 100% of the variation. It is one
    of the most commonly used metrics, but it can suffer from the problem that you
    can increase it by adding more variables without necessarily improving the model.
    It is also not suitable for non-linear problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have discussed some of the commonly used metrics, let's look at
    how to look at other results to assess the quality of your model, and the effects
    of different features on your model.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss various visualizations of metrics and other
    information to understand the results of the modeling exercise. These are important
    visualizations that need to be inspected carefully in addition to looking at the
    model metrics discussed in the previous section. These visualizations are generated
    automatically by DataRobot for any model that it trains.
  prefs: []
  type: TYPE_NORMAL
- en: Lift chart
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The lift chart shows how effective the model is at predicting the target values.
    As the number of data points is typically very large to show in one graphic, the
    lift chart sorts the output and aggregates the data into multiple bins. It then
    compares the averages of predictions and actuals in each bin (*Figure 2.13*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Lift chart'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.13_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.13 – Lift chart
  prefs: []
  type: TYPE_NORMAL
- en: The preceding lift chart shows how the predictions have been sorted from low
    to high and then binned (60 bins in this case). You can now see the average prediction
    and average actual value in each bin. This gives you a sense of how well the model
    is doing across the entire spectrum. You can see whether there are ranges where
    the model is doing worse. If the model is not doing well in a range that is important
    to your business, you can then investigate further to see how you can improve
    the model in that range. You can also inspect different models to see whether
    there is a model that does better in the region that is more important. Lift charts
    are more meaningful for regression problems.
  prefs: []
  type: TYPE_NORMAL
- en: Confusion matrix (binary and multiclass)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For classification problems, one of the best ways to assess model results is
    by looking at the confusion matrix and its associated metrics (*Figure 2.14*).
    This tab is available for multiclass problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14 – Confusion matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.14_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.14 – Confusion matrix
  prefs: []
  type: TYPE_NORMAL
- en: The confusion matrix maps predicted versus actual counts (frequency) for each
    class. Let's look at the sedan column. The big green circle indicates how many
    times we correctly classified a sedan as a sedan. In that column, you will also
    see red dots where the model predicted it to be a sedan, but it is a different
    type. You can see these for all classes. The relative scales should give you an
    idea of how well your model did and where it is having difficulty.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you select a specific class, you can look at the class-specific confusion
    matrix on the right. You can see two columns (+ for predicting a sedan, - for
    predicting something that isn''t a sedan). Similarly, you see two rows (+ where
    it is a sedan, and - for when it is not a sedan). You also see some critical definitions
    and metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Positives** (**TP**) = Where it is a sedan and is predicted as a sedan'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Positives** (**FP**) = Where it is not a sedan but is predicted as
    a sedan'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True Negatives** (**TN**) = Where it is not a sedan and is predicted as not
    being a sedan'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Negatives** (**FN**) = Where it is a sedan but is predicted as not
    being a sedan'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using these, we can now compute some specific metrics for this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Precision = correct fraction of predictions = TP/All Positive Predictions
    = TP/(TP+FP)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Recall = correct fraction of actuals = TP/All Positive Actuals = TP/(TP+FN)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*F1 Score = harmonic mean of precision and recall. So, 1/F1 = 1/Precision +
    1/Recall*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ROC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This tab is available for binary classification problems. The **ROC** (**Receiver
    Operator Characteristic**) curve is the relationship between the true positive
    rate and the false positive rate. The area under this curve is known as AUC. It
    goes from 0 to 1 and it shows how well the model discriminates between the two
    classes (*Figure 2.15*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15 – ROC curve and confusion matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.15_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.15 – ROC curve and confusion matrix
  prefs: []
  type: TYPE_NORMAL
- en: You can also see the confusion matrix (described earlier) and the associated
    metrics for the two classes. You can move the thresholds and assess the resulting
    trade-offs and cumulative gains. Since most problems are not symmetric in the
    sense that true positives have different business values compared to true negatives,
    you should select the threshold that makes sense for your business problem.
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy over time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This tab is available for time series problems (*Figure 2.16*) and compares
    the actual versus predicted values over time for a series:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – Model accuracy over time'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.16_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.16 – Model accuracy over time
  prefs: []
  type: TYPE_NORMAL
- en: You can view these values for the backtests or the holdout datasets. The diagram
    will clearly show where the model is not performing well and what you might want
    to focus on to improve your model.
  prefs: []
  type: TYPE_NORMAL
- en: Feature impacts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Besides model performance, one of the first things you want to understand is
    how impactful the features are in terms of your model''s performance. The **Feature
    Impacts** tab (*Figure 2.17*) is perhaps the most critical for understanding your
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Feature impacts'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.17_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.17 – Feature impacts
  prefs: []
  type: TYPE_NORMAL
- en: The graphic shows a sorted list of the most important features. For each feature,
    you can see the relative impact that a feature has on this model. You can see
    which features contribute very little; this can be used to create new feature
    lists by removing some of the features that have very little impact.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Fit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **Feature Fit** tab (*Figure 2.18*) shows an alternative view of the contribution
    of a feature. The graphic shows the features ranked by their importance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.18 – Feature Fit'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.18_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.18 – Feature Fit
  prefs: []
  type: TYPE_NORMAL
- en: For the selected feature, it shows how the predictions compare to actuals for
    the range of values of a feature. Reviewing these graphs for the key features
    can provide a lot of insight about how a feature impacts the results and range
    of values that perform better and ranges where it performs the worst. This could
    sometimes highlight the regions where you might need to collect more data to improve
    your model.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Effects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Feature Effects** show information that is very similar to **Feature Fit**
    (*Figure 2.19*). In this graphic, the features are sorted by **Feature Impacts**.
    Also, **Feature Effects** are focused on partial dependence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.19 – Feature Effects and Partial Dependence'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.19_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.19 – Feature Effects and Partial Dependence
  prefs: []
  type: TYPE_NORMAL
- en: Partial dependence plots are one of the most important plots that you want to
    study carefully. These plots tell you how a change in the value of a feature impacts
    the change in the average value of the target over a range of values for the other
    features. This insight is critical to understanding the business problem, understanding
    what the model is doing, and, more importantly, what aspects of the model are
    actionable and what range of values will produce the maximum impact.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction Explanations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Prediction Explanations** describe the reasons for a specific prediction
    in terms of feature values for the specific instance or row that is being scored
    (*Figure 2.20*). Note that this is different from **Feature Impacts**, which tell
    you the importance of a feature at a global level:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.20 – Prediction Explanations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.20_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.20 – Prediction Explanations
  prefs: []
  type: TYPE_NORMAL
- en: '**Prediction Explanations** can be generated for an entire dataset or a subset
    of data, as shown in the preceding screenshot. For example, it will provide the
    top three reasons why the model predicted a specific value. These explanations
    are sometimes required for regulatory reasons in certain use cases, but it is
    a good idea to produce these explanations as they do help in understanding why
    a model predicts a certain way and can be very useful in validating or catching
    errors in a model. DataRobot uses two algorithms for computing the explanations:
    **XEMP** (**exemplar-based explanations**) or **Shapley values**. XEMP is supported
    for a broader range of models and is selected by default. Shapley values are described
    in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Shapley values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Shapley** **values** (**SHAP**) are an alternative mechanism for producing
    prediction explanations (*Figure 2.21*). If you want to use SHAP for explanations,
    you have to specify this in the advanced options during the project setup before
    you press the **Start** button. Once DataRobot starts building the models, you
    cannot switch to SHAP. SHAP values are only available for linear or tree-based
    models and are not available for ensemble models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.21 – SHAP-based explanations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_2.21_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.21 – SHAP-based explanations
  prefs: []
  type: TYPE_NORMAL
- en: SHAP values are based on cooperative game theory, which tries to assign values
    to contributions of a team member in a collaborative project. In the context of
    machine learning, it tries to assign the value contribution of a specific feature
    when there is a team of features collaborating to make a prediction. SHAP values
    are additive and you can easily see how much of the final answer is due to a specific
    feature value.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered some of the basic machine learning concepts that
    will come in handy as we go through the remaining chapters, and they will also
    be useful in your data science journey. Please note that we have only covered
    concepts at a high level, and depending on your job role, you might want to explore
    some areas in more detail. We have also related this material to how DataRobot
    performs certain functions and where you need to pay closer attention.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hopefully, this has given you some insights into what DataRobot will be displaying
    and where to focus your attention in different stages of your project. Since DataRobot
    automates a good chunk of model building and prediction tasks, it might be tempting
    to ignore many of the outputs that DataRobot is automatically producing for you.
    Please resist that temptation. DataRobot software is taking considerable pains
    and resources to produce those outputs for a very good reason. It is also doing
    much of the grunt work for you, so please take advantage of those capabilities.
    Specifically, we have covered the following: What are the things to watch out
    for during data preparation? What data visualizations are important for gaining
    an understanding of your dataset? What are the key machine learning algorithms,
    and when do you use them? How do you measure the goodness of your model results?
    How do you assess model performance and understand what the model is telling you
    about your problem?'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know the basics, we will start our data science journey in the next
    chapter by learning how to understand the business problem and how to turn it
    into a specification that can be solved by using machine learning.
  prefs: []
  type: TYPE_NORMAL
