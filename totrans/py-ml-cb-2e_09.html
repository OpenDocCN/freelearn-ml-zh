<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Dissecting Time Series and Sequential Data</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Transforming data into a time series format</li>
<li>Slicing time series data</li>
<li>Operating on time series data</li>
<li>Extracting statistics from time series data</li>
<li>Building HMMs for sequential data</li>
<li>Building CRFs for sequential text data</li>
<li>Analyzing stock market data</li>
<li>Using RNNs to predict time series data</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>To address the recipes in this chapter, you need the following files (available on GitHub):</p>
<ul>
<li><kbd>convert_to_timeseries.py</kbd></li>
<li><kbd>data_timeseries.txt</kbd></li>
<li><kbd><span>slicing_data.py</span></kbd></li>
<li><kbd>operating_on_data.py</kbd></li>
<li><kbd><span>extract_stats.py</span></kbd></li>
<li><kbd><span>hmm.py</span></kbd></li>
<li><kbd><kbd>data_hmm.txt</kbd></kbd></li>
<li><kbd><span>crf.py</span></kbd></li>
<li><kbd>AmazonStock.py</kbd></li>
<li><kbd>AMZN.csv</kbd></li>
<li><kbd>LSTMstock.py</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing time series</h1>
                </header>
            
            <article>
                
<p>Time series data is basically a sequence of measurements that are collected over time. These measurements are taken with respect to a predetermined variable and at regular time intervals. One of the main characteristics of time series data is that the ordering matters!</p>
<p>The list of observations that we collect is ordered on a timeline, and the order in which they appear says a lot about underlying patterns. If you change the order, this would totally change the meaning of the data. Sequential data is a generalized notion that encompasses any data that comes in a sequential form, including time series data.</p>
<p>Our objective here is to build a model that describes the pattern of the time series or any sequence in general. Such models are used to describe important features of the time series pattern. We can use these models to explain how the past might affect the future. We can also use them to see how two datasets can be correlated, to forecast future values, or to control a given variable that is based on some metric.</p>
<p>To visualize time series data, we tend to plot it using line charts or bar graphs. Time series data analysis is frequently used in finance, signal processing, weather prediction, trajectory forecasting, predicting earthquakes, or any field where we have to deal with temporal data. The models that we build in time series and sequential data analysis should take into account the ordering of data and extract the relationships among neighbors. Let's go ahead and check out a few recipes to analyze time series and sequential data in Python.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Transforming data into a time series format</h1>
                </header>
            
            <article>
                
<p>A <strong>time series</strong> constitutes a sequence of observations of a phenomenon that's carried out in consecutive instants or time intervals that are usually, even if not necessarily, evenly spaced or of the same length. It follows that time is a fundamental parameter in the analysis of a time series. To start, we must therefore acquire a certain confidence in manipulating data that represents a long-term observation of a certain phenomenon.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p><span>We will start by understanding how to convert a sequence of observations into time series data and visualize it. We will use a library calle</span>d <kbd>pandas</kbd> to analy<span>ze time series data. Make sure that you install <kbd>pandas</kbd> before you proceed further. You can find the installation instructions for <kbd>pandas</kbd> at the following link: </span><span class="URLPACKT"><a href="http://pandas.pydata.org/pandas-docs/stable/install.html">http://pandas.pydata.org/pandas-docs/stable/install.html</a></span><span>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how we can transform data into a time series format:</p>
<ol>
<li>Create a new Python file (<span>the full code is given in the </span><kbd>convert_to_timeseries.py</kbd><span> file that is provided for you</span>) and import the following packages:</li>
</ol>
<pre style="padding-left: 60px">import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt </pre>
<ol start="2">
<li>Let's define a function that reads an input file and converts sequential observations into time-indexed data:</li>
</ol>
<pre style="padding-left: 60px">def convert_data_to_timeseries(input_file, column, verbose=False): </pre>
<ol start="3">
<li>We will use a text file consisting of four columns. The first column denotes the year, the second column denotes the month, and the third and fourth columns denote data. Let's load this into a NumPy array:</li>
</ol>
<pre>    # Load the input file 
    data = np.loadtxt(input_file, delimiter=',') </pre>
<ol start="4">
<li>As this is arranged chronologically, the first row contains the start date and the last row contains the end date. Let's extract the start and end dates of this dataset:</li>
</ol>
<pre>    # Extract the start and end dates 
    start_date = str(int(data[0,0])) + '-' + str(int(data[0,1])) 
    end_date = str(int(data[-1,0] + 1)) + '-' + str(int(data[-1,1] % 12 + 1)) </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="5">
<li>There is also a <kbd>verbose</kbd> mode for this function. So, if this is set to <kbd>true</kbd>, it will print a few things. Let's print out the start and end dates:</li>
</ol>
<pre>    if verbose: 
        print("Start date =", start_date)<br/>        print("End date =", end_date) </pre>
<ol start="6">
<li>Let's create a <kbd>pandas</kbd> variable, which contains the date sequence with monthly intervals:</li>
</ol>
<pre>    # Create a date sequence with monthly intervals 
    dates = pd.date_range(start_date, end_date, freq='M') </pre>
<ol start="7">
<li>Our next step is to convert the given column into time series data. You can access this data using the month and the year (as opposed to the index):</li>
</ol>
<pre>    # Convert the data into time series data 
    data_timeseries = pd.Series(data[:,column], index=dates) </pre>
<ol start="8">
<li>Use the <kbd>verbose</kbd> mode to print out the first 10 elements:</li>
</ol>
<pre>    if verbose: 
        print("Time series data:\n", data_timeseries[:10]) </pre>
<ol start="9">
<li>Return the time-indexed variable, as follows:</li>
</ol>
<pre>    return data_timeseries </pre>
<ol start="10">
<li>Define the main function, as follows:</li>
</ol>
<pre style="padding-left: 60px">if __name__=='__main__': </pre>
<ol start="11">
<li>We will use the <kbd>data_timeseries.txt</kbd> file that is already provided to you:</li>
</ol>
<pre>    # Input file containing data 
    input_file = 'data_timeseries.txt' </pre>
<ol start="12">
<li>Load the third column from this text file and convert it into time series data:</li>
</ol>
<pre>    # Load input data 
    column_num = 2 
    data_timeseries = convert_data_to_timeseries(input_file, column_num) </pre>
<ol start="13">
<li>The <kbd>pandas</kbd> library provides a nice plotting function that you can run directly on the variable:</li>
</ol>
<pre>    # Plot the time series data 
    data_timeseries.plot() 
    plt.title('Input data') 
 
    plt.show() </pre>
<p style="padding-left: 60px">If you run the code, you will see the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1036 image-border" src="assets/940ee777-eb54-4832-b1c5-f6c2fcdbbb17.png" style="width:34.33em;height:25.67em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>In this recipe, we learned how to convert a sequence of observations into time series data and display it. To do this, we first loaded the input file in a <kbd>.txt</kbd> format, so we extracted the start and end dates. Then, we created a sequence of dates with monthly intervals and converted the data into time series data. Finally, we plotted the time series data.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p>The <kbd>pandas</kbd> library is particularly suitable for working with time series data for all domains, thanks to the extensive capabilities and features it has. These features take advantage of the NumPy <kbd>datetime64</kbd> and <kbd>timedelta64</kbd> variables, and a large number of functionality from other Python libraries such as <kbd>scikits.timeseries.</kbd> These features have made <kbd>pandas</kbd> particularly efficient for manipulating time series data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the official documentation of the <kbd>pandas</kbd> time series and date functionality: <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html">https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html</a></li>
<li><em>Time Series Basics</em> (from The Pennsylvania State University): <a href="https://newonlinecourses.science.psu.edu/stat510/node/41/">https://newonlinecourses.science.psu.edu/stat510/node/41/</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Slicing time series data</h1>
                </header>
            
            <article>
                
<p><strong>Slice</strong> and <strong>dice</strong> are two terms that refer to a dataset meaning to divide a large DataFrame into smaller parts or examine them from different points of view to understand it better. The term comes from culinary jargon and describes two types of knife skills that every chef has to master. To slice means to cut, while to dice means to cut food into very small and uniform sections, and the two actions are often performed in sequence. In data analysis, the term <strong>slice and dice</strong> generally involves a systematic reduction of a large dataset into smaller parts to extract more information.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p><span>In this recipe, we will learn how to slice time series data. This will help you extract information from various intervals in the time series data. We will learn how to use dates to handle subsets of our data.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how we can perform slicing time series data:</p>
<ol>
<li>Create a new Python file and import the following packages (the full code is given in the <kbd><span>slicing_data.py</span></kbd> file that is provided for you):</li>
</ol>
<pre style="padding-left: 60px">import numpy as np 
from convert_to_timeseries import convert_data_to_timeseries </pre>
<p style="padding-left: 60px">Here, <kbd>convert_to_timeseries</kbd> is the function we defined in the previous recipe <em>Transforming data into a time series format</em>, that reads an input file and converts sequential observations into time-indexed data.</p>
<ol start="2">
<li>We will use the same text file that we used in the previous recipe (<kbd>data_timeseries.txt</kbd>) to slice and dice the data:</li>
</ol>
<pre style="padding-left: 60px"># Input file containing data 
input_file = 'data_timeseries.txt' </pre>
<ol start="3">
<li>We will extract only the third column:</li>
</ol>
<pre style="padding-left: 60px"># Load data 
column_num = 2 
data_timeseries = convert_data_to_timeseries(input_file, column_num) </pre>
<ol start="4">
<li>Let's assume that we want to extract the data between the given <kbd>start</kbd> and <kbd>end</kbd> years. Let's define these, as follows:</li>
</ol>
<pre style="padding-left: 60px"># Plot within a certain year range 
start = '2000' 
end = '2015' </pre>
<ol start="5">
<li>Plot the data between the given year range:</li>
</ol>
<pre style="padding-left: 60px">plt.figure() 
data_timeseries[start:end].plot() 
plt.title('Data from ' + start + ' to ' + end) </pre>
<ol start="6">
<li>We can also slice the data based on a certain range of months:</li>
</ol>
<pre style="padding-left: 60px"># Plot within a certain range of dates 
start = '2008-1' 
end = '2008-12' </pre>
<ol start="7">
<li>Plot the data, as follows:</li>
</ol>
<pre style="padding-left: 60px">plt.figure() 
data_timeseries[start:end].plot() 
plt.title('Data from ' + start + ' to ' + end) 
plt.show() </pre>
<p style="padding-left: 60px">If you run the code, you will see the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1037 image-border" src="assets/fb612a80-360f-4836-8904-92fa1215cb67.png" style="width:34.67em;height:26.92em;"/></p>
<p style="padding-left: 60px">The following screenshot displays a smaller time frame; hence, it looks as if we have zoomed into it:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1038 image-border" src="assets/99f7bdeb-2652-4ff9-b62a-c46bf625924d.png" style="width:33.58em;height:27.33em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>In this recipe, we learned how to break up time series data. First, we imported the data contained in a <kbd>.txt</kbd> file. This data was transformed into a time series format using a function that we defined in the previous recipe. Thus, we have plotted the data, first within a certain period of years, and then within a certain range of dates.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p>To transform data into a <span>time series format, the <kbd>pandas</kbd> library was used. This library is particularly efficient for manipulating time series data.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the official documentation of the pandas time series and date functionality:<span> </span><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html">https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html</a></li>
<li><em>Time Series</em> (by Prof Gesine Reinert, from the University of Oxford): <a href="http://www.stats.ox.ac.uk/~reinert/time/notesht10short.pdf">http://www.stats.ox.ac.uk/~reinert/time/notesht10short.pdf</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Operating on time series data</h1>
                </header>
            
            <article>
                
<p>Now that we know how to slice data and extract various subsets, let's discuss how to operate on time series data. You can filter the data in many different ways. The <kbd>pandas</kbd> library allows you to operate on time series data in any way that you want.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>In this recipe, we will use data contained in a <kbd>.txt</kbd> file and load it. Then, we will filter the data using a certain threshold to extract only a portion of the starting dataset that meets specific requirements.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how we can operate on time series data:</p>
<ol>
<li>Create a new Python file and import the following packages (the full code is given in the <kbd>operating_on_data.py</kbd> file that is provided for you):</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd 
import matplotlib.pyplot as plt 
from convert_to_timeseries import convert_data_to_timeseries </pre>
<p style="padding-left: 60px">Here, <kbd>convert_to_timeseries</kbd><span> is the function we defined in the previous recipe, </span><em>Transforming data into a time series format</em><span>, that read an input file and converted sequential observations into time-indexed data.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="2">
<li>We will use the same text file that we used in the previous recipes (<kbd>data_timeseries.txt</kbd>):</li>
</ol>
<pre style="padding-left: 60px"># Input file containing data 
input_file = 'data_timeseries.txt' </pre>
<ol start="3">
<li>We will use both the third and fourth columns in this <kbd>.txt</kbd> file (remember, Python lists the data starting from position 0, so the third and fourth columns have the indices 2 and 3):</li>
</ol>
<pre style="padding-left: 60px"># Load data 
data1 = convert_data_to_timeseries(input_file, 2) 
data2 = convert_data_to_timeseries(input_file, 3) </pre>
<ol start="4">
<li>Convert the data into a <kbd>pandas</kbd> DataFrame:</li>
</ol>
<pre style="padding-left: 60px">dataframe = pd.DataFrame({'first': data1, 'second': data2}) </pre>
<ol start="5">
<li>Plot the data in the given year range:</li>
</ol>
<pre style="padding-left: 60px"># Plot data 
dataframe['1952':'1955'].plot() 
plt.title('Data overlapped on top of each other') </pre>
<ol start="6">
<li>Let's assume that we want to plot the difference between the two columns that we just loaded in the given year range. We can do this using the following lines:</li>
</ol>
<pre style="padding-left: 60px"># Plot the difference 
plt.figure() 
difference = dataframe['1952':'1955']['first'] - dataframe['1952':'1955']['second'] 
difference.plot() 
plt.title('Difference (first - second)') </pre>
<ol start="7">
<li>If we want to filter the data based on different conditions for the first and second columns, we can just specify these conditions and plot this:</li>
</ol>
<pre style="padding-left: 60px"># When 'first' is greater than a certain threshold 
# and 'second' is smaller than a certain threshold 
dataframe[(dataframe['first'] &gt; 60) &amp; (dataframe['second'] &lt; 20)].plot(style='o') 
plt.title('first &gt; 60 and second &lt; 20') 
 
plt.show() </pre>
<p style="padding-left: 60px">If you run the preceding code, the first output will look as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1039 image-border" src="assets/95ef968f-8117-466e-83cc-bb02335bfc8f.png" style="width:30.33em;height:23.67em;"/></p>
<p style="padding-left: 60px">The second output screenshot denotes the difference, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1040 image-border" src="assets/2496b36b-19df-4b72-b296-917d135271f1.png" style="width:29.83em;height:23.17em;"/></p>
<p class="mce-root"/>
<p style="padding-left: 60px">The third output screenshot denotes the filtered data, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1041 image-border" src="assets/d7837dd2-957f-479c-a374-bae91b59aa16.png" style="width:31.25em;height:22.50em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>In this recipe, we learned how to filter the data contained in a time series. First, we plotted the data between two years (from 1952 to 1955). Then, we plotted the difference between the data contained in two columns for a specific time interval (from 1952 to 1955). Finally, we plotted data using a certain threshold to extract only a portion of the starting dataset that meets specific requirements—in particular, when the first column is greater than 60 and when the second column is smaller than 20.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p>To perform two-column filtering at the same time, the <kbd>&amp;</kbd> operator was used. The <kbd>&amp;</kbd> (and) operator is a logical operator (Boolean operator) of logical conjunction between two propositions. Given two propositions, A and B, the logical conjunction determines a third proposition, C<em>,</em> that manifests itself as true only when both propositions are true.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the <em>Fundamental concepts in Time Series Analysis</em> l<span>ecture, </span>(from the University of Lausanne): <a href="https://math.unice.fr/~frapetti/CorsoP/chapitre_1_part_1_IMEA_1.pdf">https://math.unice.fr/~frapetti/CorsoP/chapitre_1_part_1_IMEA_1.pdf</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Extracting statistics from time series data</h1>
                </header>
            
            <article>
                
<p>One of the main reasons that we want to analyze time series data is to extract interesting statistics from it. This provides a lot of information regarding the nature of the data. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p><span>In this recipe, we will take a look at how to extract some statistics.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how we can extract statistics from time series data:</p>
<ol>
<li>Create a new Python file and import the following packages (the full code is given in the <kbd>extract_stats.py</kbd> file that is provided for you):</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd 
import matplotlib.pyplot as plt 
from convert_to_timeseries import convert_data_to_timeseries </pre>
<p style="padding-left: 60px">The <kbd>convert_to_timeseries</kbd> function<span> is the function we defined in the previous recipe, </span><em>Transforming data into a time series format</em>,<span> that read an input file and converted sequential observations into time-indexed data.</span></p>
<ol start="2">
<li>We will use the same text file that we used in the previous recipes for analysis (<span><kbd>data_timeseries.txt</kbd>)</span>:</li>
</ol>
<pre style="padding-left: 60px"># Input file containing data 
input_file = 'data_timeseries.txt' </pre>
<ol start="3">
<li>Load both the data columns (third and fourth columns):</li>
</ol>
<pre style="padding-left: 60px"># Load data 
data1 = convert_data_to_timeseries(input_file, 2) 
data2 = convert_data_to_timeseries(input_file, 3) </pre>
<ol start="4">
<li>Create a <kbd>pandas</kbd> data structure to hold this data. This DataFrame is like a dictionary that has keys and values:</li>
</ol>
<pre style="padding-left: 60px">dataframe = pd.DataFrame({'first': data1, 'second': data2}) </pre>
<ol start="5">
<li>Let's start extracting some stats now. To extract the maximum and minimum values, use the following code:</li>
</ol>
<pre style="padding-left: 60px"># Print max and min 
print('Maximum:\n', dataframe.max())<br/>print('Minimum:\n', dataframe.min())</pre>
<ol start="6">
<li>To print the mean values of your data or just the row-wise mean, use the following code:</li>
</ol>
<pre style="padding-left: 60px"># Print mean 
print('Mean:\n', dataframe.mean())<br/>print('Mean row-wise:\n', dataframe.mean(1)[:10])</pre>
<ol start="7">
<li>The rolling mean is an important statistic that's used a lot in time series processing. One of the most famous applications is smoothing a signal to remove noise. <em>Rolling mean</em> refers to computing the mean of a signal in a window that keeps sliding on the time scale. Let's consider a window size of <kbd>24</kbd> and plot this, as follows:</li>
</ol>
<pre style="padding-left: 60px"># Plot rolling mean 
DFMean = dataframe.rolling(window=24).mean()<br/>plt.plot(DFMean) </pre>
<ol start="8">
<li>Correlation coefficients are useful in understanding the nature of the data, as follows:</li>
</ol>
<pre style="padding-left: 60px"># Print correlation coefficients 
print('Correlation coefficients:\n', dataframe.corr()) </pre>
<ol start="9">
<li>Let's plot this using a window size of <kbd>60</kbd>:</li>
</ol>
<pre style="padding-left: 60px"># Plot rolling correlation 
plt.figure()<br/>DFCorr= dataframe.rolling(window=60).corr(pairwise=False)<br/>plt.plot(DFCorr)<br/>plt.show()</pre>
<p style="padding-left: 60px">If you run the preceding code, the rolling mean will look as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1042 image-border" src="assets/ca055cc5-4cb0-4389-ac92-7b969f423cb1.png" style="width:87.92em;height:62.00em;"/></p>
<p style="padding-left: 60px">The second output indicates the rolling correlation (the following output is the result of a zoomed rectangle operation that was performed in the <kbd>matplotlib</kbd> window):</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1043 image-border" src="assets/40cb9669-d1a2-49a1-8a6d-df47979ae75b.png" style="width:89.67em;height:62.42em;"/></p>
<ol start="10">
<li>In the upper half of the Terminal, you will the see max, min, and mean values printed, as shown in the following output:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1044 image-border" src="assets/f5eab4b8-8343-4a9b-9dd6-a1c217637675.png" style="width:13.75em;height:15.58em;"/></p>
<ol start="11">
<li>In the lower half of the terminal, you will see the row-wise mean stats and correlation coefficients printed, as shown in the following output:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1045 image-border" src="assets/cf91ac64-c670-4527-aa2b-309b00cb6896.png" style="width:19.58em;height:18.83em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>In this recipe, we learned how to extract some statistics. We started by calculating the minimum, maximum, and mean of each of the two columns that were extracted from the dataset. Then, we calculated the mean for each row for the first 10 rows of the DataFrame. Finally, we performed a correlation analysis between the two features.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p>To perform a correlation analysis, the <kbd>pandas.DataFrame.corr</kbd> function was used. This function computes a pairwise correlation of columns, excluding N/A or null values. The following methods are available:</p>
<ul>
<li class="mce-root"><kbd>pearson</kbd>: This is the standard correlation coefficient</li>
<li class="mce-root"><kbd>kendall</kbd>: This is the <strong>Kendall Tau</strong> correlation coefficient</li>
<li class="mce-root"><kbd>spearman</kbd>: This is the <strong>Spearman rank</strong> correlation coefficient</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the official documentation of the <kbd>pandas.DataFrame.corr</kbd> function: <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html</a></li>
<li><em>Correlation</em> (from the SRM University): <a href="http://www.srmuniv.ac.in/sites/default/files/downloads/CORRELATION.pdf">http://www.srmuniv.ac.in/sites/default/files/downloads/CORRELATION.pdf</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building HMMs for sequential data</h1>
                </header>
            
            <article>
                
<p><strong>Hidden Markov models</strong><span> (<strong>HMMs</strong>)</span> are particularly suitable for sequential data analysis problems. They are widely used in fields such as speech analysis, finance, word sequencing, weather forecasting, and so on.</p>
<p>Any source of data that produces a sequence of outputs can produce patterns. Note that HMMs are generative models, which means that they can generate the data once they learn the underlying structure. HMMs cannot discriminate between classes in their base forms. This is in contrast to discriminative models that can learn to discriminate between classes but cannot generate data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Let's say that we want to predict whether the weather will be sunny, chilly, or rainy tomorrow. To do this, we look at all the parameters, such as temperature, pressure, and so on, whereas the underlying state is hidden. Here, the underlying state refers to the three available options: sunny, chilly, or rainy. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how we can build HMMs for sequential data:</p>
<ol>
<li>Create a new Python file and import the following packages (the full code is given in the <kbd>hmm.py</kbd> file that is provided for you):</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/>import matplotlib.pyplot as plt 
from hmmlearn.hmm import GaussianHMM </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="2">
<li>We will use the data from a file named <kbd>data_hmm.txt</kbd> that is already provided to you. This file contains comma-separated lines. Each line contains three values: a year, a month, and a piece of floating-point data. Let's load this into a NumPy array:</li>
</ol>
<pre style="padding-left: 60px"># Load data from input file 
input_file = 'data_hmm.txt' 
data = np.loadtxt(input_file, delimiter=',') </pre>
<ol start="3">
<li>Let's stack the data column-wise for analysis. We don't need to technically column-stack this because it's only one column. However, if you have more than one column to analyze, you can use the following structure:</li>
</ol>
<pre style="padding-left: 60px"># Arrange data for training  
X = np.column_stack([data[:,2]]) </pre>
<ol start="4">
<li>Create and train the HMM using four components. The number of components is a hyperparameter that we have to choose. Here, by selecting four, we say that the data is being generated using four underlying states. We will see how the performance varies with this parameter:</li>
</ol>
<pre style="padding-left: 60px"># Create and train Gaussian HMM  
print("Training HMM....") 
num_components = 4 
model = GaussianHMM(n_components=num_components, covariance_type="diag", n_iter=1000) 
model.fit(X) </pre>
<ol start="5">
<li>Run the predictor to get the hidden states:</li>
</ol>
<pre style="padding-left: 60px"># Predict the hidden states of HMM  
hidden_states = model.predict(X) </pre>
<ol start="6">
<li>Compute the mean and variance of the hidden states:</li>
</ol>
<pre style="padding-left: 60px">print("Means and variances of hidden states:")<br/>for i in range(model.n_components):<br/>    print("Hidden state", i+1)<br/>    print("Mean =", round(model.means_[i][0], 3))<br/>    print("Variance =", round(np.diag(model.covars_[i])[0], 3))</pre>
<ol start="7">
<li>As we discussed earlier, HMMs are generative models. So, let's generate, for example, <kbd>1000</kbd> samples and plot this:</li>
</ol>
<pre style="padding-left: 60px"># Generate data using model 
num_samples = 1000 
samples, _ = model.sample(num_samples)  
plt.plot(np.arange(num_samples), samples[:,0], c='black') 
plt.title('Number of components = ' + str(num_components)) 
plt.show() </pre>
<p style="padding-left: 60px">The full code is given in the <kbd>hmm.py</kbd> file that is already provided to you. If you run the preceding code, you will see the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1046 image-border" src="assets/3f7ca760-fe8a-4f2e-9775-42e56d237035.png" style="width:31.58em;height:24.83em;"/></p>
<ol start="8">
<li>You can experiment with the <kbd>n_components</kbd> parameter to see how the curve gets nicer as you increase it. You can basically give it more freedom to train and customize by allowing a larger number of hidden states. If you increase it to <kbd>8</kbd>, you will see the following output:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><span><img class="aligncenter size-full wp-image-1047 image-border" src="assets/f808d661-11ee-48ad-868b-cfbd6a10a5ac.png" style="width:28.67em;height:22.17em;"/></span></p>
<ol start="9">
<li>If you increase this to <kbd>12</kbd>, it will get even smoother:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1048 image-border" src="assets/6f68f940-7cb3-453f-9198-0ed5de91f93f.png" style="width:29.42em;height:23.50em;"/></p>
<p style="padding-left: 60px">In the terminal, you will get the following output:</p>
<pre style="padding-left: 60px" class="CDPAlignLeft CDPAlign"><strong>Training HMM....</strong><br/><strong>Means and variances of hidden states:</strong><br/><strong>Hidden state 1</strong><br/><strong>Mean = 5.592</strong><br/><strong>Variance = 0.253</strong><br/><strong>Hidden state 2</strong><br/><strong>Mean = 1.098</strong><br/><strong>Variance = 0.004</strong><br/><strong>Hidden state 3</strong><br/><strong>Mean = 7.102</strong><br/><strong>Variance = 0.003</strong><br/><strong>Hidden state 4</strong><br/><strong>Mean = 3.098</strong><br/><strong>Variance = 0.003</strong><br/><strong>Hidden state 5</strong><br/><strong>Mean = 4.104</strong><br/><strong>Variance = 0.003</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><span>HMM is a model in which the system being modeled is assumed to be a Markov process with unobserved states. A stochastic process is called Markovian when, having chosen a certain instance of <em>t</em> for observation, the evolution of the process, starting with <em>t</em>, depends only on <em>t</em> and does not depend in any way on the previous instances. Thus, a process is Markovian when, given the moment of observation, only this instance determines the future evolution of the process, while this evolution does not depend on the past. In this recipe, we learned how to use HMMs to generate a time series. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p><span>In this recipe, we used <kbd>hmmlearn</kbd> to build and train HMMs, which implements the HMMs. A HMM is a generative probabilistic model, wherein a sequence of observable variables is computed using a sequence of hidden internal states. Hidden states are not observed directly.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the official documentation of the <kbd>hmmlearn</kbd> library to find out more: <a href="https://hmmlearn.readthedocs.io/en/latest/">https://hmmlearn.readthedocs.io/en/latest/</a></li>
<li><em>A Tutorial on Hidden Markov Models</em> (by Lawrence R Rabiner from Oxford University): <a href="https://www.robots.ox.ac.uk/~vgg/rg/slides/hmm.pdf">https://www.robots.ox.ac.uk/~vgg/rg/slides/hmm.pdf</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building CRFs for sequential text data</h1>
                </header>
            
            <article>
                
<p><strong>Conditional random fields</strong> (<strong>CRFs</strong>) are probabilistic models that are used to analyze structured data. They are frequently used to label and segment sequential data. CRFs are discriminative models as opposed to HMMs, which are generative models. CRFs are used extensively to analyze sequences, stock, speech, words, and so on. In these models, given a particular labeled observation sequence, we define a conditional probability distribution over this sequence. This is in contrast to HMMs, where we define a joint distribution over the label and the observed sequence.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>In this recipe, we will use a library called <kbd>pystruct</kbd> to build and train CRFs. Make sure that you install this before you proceed. You can find the installation instructions at <a href="https://pystruct.github.io/installation.html"><span class="URLPACKT">https://pystruct.github.io/installation.html</span></a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how we can build CRFs for sequential text data:</p>
<ol>
<li>Create a new Python file and import the following packages (the full code is given in the <kbd>crf.py</kbd> file that is provided for you):</li>
</ol>
<pre style="padding-left: 60px">import argparse <br/>import numpy as np<br/>from pystruct.datasets import load_letters<br/>from pystruct.models import ChainCRF<br/>from pystruct.learners import FrankWolfeSSVM</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="2">
<li>Define an argument parser to take the <kbd>C</kbd> value as an input argument. Here, <kbd>C</kbd> is a hyperparameter that controls how specific you want your model to be without losing the power to generalize:</li>
</ol>
<pre style="padding-left: 60px">def build_arg_parser():<br/>    parser = argparse.ArgumentParser(description='Trains the CRF classifier')<br/>    parser.add_argument("--c-value", dest="c_value", required=False, type=float,<br/>            default=1.0, help="The C value that will be used for training")<br/>    return parser</pre>
<ol start="3">
<li>Define a <kbd>class</kbd> to handle all CRF-related processing:</li>
</ol>
<pre style="padding-left: 60px">class CRFTrainer(object): </pre>
<ol start="4">
<li>Define an <kbd>init</kbd> function to initialize the values:</li>
</ol>
<pre>    def __init__(self, c_value, classifier_name='ChainCRF'): 
        self.c_value = c_value 
        self.classifier_name = classifier_name </pre>
<ol start="5">
<li>We will use <kbd>ChainCRF</kbd> to analyze the data. We need to add an error check to this, as follows:</li>
</ol>
<pre>        if self.classifier_name == 'ChainCRF': 
            model = ChainCRF() </pre>
<ol start="6">
<li>Define the classifier that we will use with our CRF model. We will use a type of SVM to achieve this:</li>
</ol>
<pre>            self.clf = FrankWolfeSSVM(model=model, C=self.c_value, max_iter=50)  
        else: 
            raise TypeError('Invalid classifier type') </pre>
<ol start="7">
<li>Load the <kbd>letters</kbd> dataset. This dataset consists of segmented letters and their associated feature vectors. We will not analyze the images because we already have the feature vectors. The first letter from each word has been removed, so all we have are lowercase letters:</li>
</ol>
<pre>    def load_data(self): 
        letters = load_letters() </pre>
<p class="mce-root"/>
<ol start="8">
<li>Load the data and labels into their respective variables:</li>
</ol>
<pre>        X, y, folds = letters['data'], letters['labels'], letters['folds'] 
        X, y = np.array(X), np.array(y) 
        return X, y, folds </pre>
<ol start="9">
<li>Define a training method, as follows:</li>
</ol>
<pre>    # X is a numpy array of samples where each sample 
    # has the shape (n_letters, n_features)  
    def train(self, X_train, y_train): 
        self.clf.fit(X_train, y_train) </pre>
<ol start="10">
<li>Define a method to evaluate the performance of the model:</li>
</ol>
<pre>    def evaluate(self, X_test, y_test): 
        return self.clf.score(X_test, y_test) </pre>
<ol start="11">
<li>Define a method to classify new data:</li>
</ol>
<pre>    # Run the classifier on input data 
    def classify(self, input_data): 
        return self.clf.predict(input_data)[0] </pre>
<ol start="12">
<li>The letters are indexed in a numbered array. To check the output and make it readable, we need to transform these numbers into alphabets. Define a function to do this:</li>
</ol>
<pre style="padding-left: 60px">def decoder(arr): 
    alphabets = 'abcdefghijklmnopqrstuvwxyz' 
    output = '' 
    for i in arr: 
        output += alphabets[i]  
 
    return output </pre>
<ol start="13">
<li>Define the main function and parse the input arguments:</li>
</ol>
<pre style="padding-left: 60px">if __name__=='__main__': 
    args = build_arg_parser().parse_args() 
    c_value = args.c_value </pre>
<ol start="14">
<li>Initialize the variable with the class and the <kbd>C</kbd> value:</li>
</ol>
<pre>    crf = CRFTrainer(c_value) </pre>
<ol start="15">
<li>Load the <kbd>letters</kbd> data:</li>
</ol>
<pre>    X, y, folds = crf.load_data() </pre>
<ol start="16">
<li>Separate the data into training and testing datasets:</li>
</ol>
<pre>    X_train, X_test = X[folds == 1], X[folds != 1] 
    y_train, y_test = y[folds == 1], y[folds != 1] </pre>
<ol start="17">
<li>Train the CRF model, as follows:</li>
</ol>
<pre>    print("Training the CRF model...")
    crf.train(X_train, y_train) </pre>
<ol start="18">
<li>Evaluate the performance of the CRF model:</li>
</ol>
<pre>    score = crf.evaluate(X_test, y_test) 
    print("Accuracy score =", str(round(score*100, 2)) + '%') </pre>
<ol start="19">
<li>Let's take a random test vector and predict the output using the model:</li>
</ol>
<pre>    print("True label =", decoder(y_test[0]))<br/>    predicted_output = crf.classify([X_test[0]])<br/>    print("Predicted output =", decoder(predicted_output))</pre>
<ol start="20">
<li>If you run the preceding code, you will get the following output on your terminal. As we can see, the word is supposed to be <kbd>commanding</kbd>. The CRF does a pretty good job of predicting all the letters:</li>
</ol>
<pre style="padding-left: 60px" class="CDPAlignLeft CDPAlign"><strong>Training the CRF model...</strong><br/><strong>Accuracy score = 77.93%</strong><br/><strong>True label = ommanding</strong><br/><strong>Predicted output = ommanging</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p><span>HMMs assume that the current output is statistically independent of the previous outputs. This is needed by HMMs to ensure that the inference works in a robust way. However, this assumption doesn't always have to be true! The current output in a time series setup, more often than not, depends on previous outputs. One of the main advantages of CRFs over HMMs is that they are conditional by nature, which means that we are not assuming any independence between output observations. There are a few other advantages of using CRFs over HMMs. CRFs tend to outperform HMMs in a number of applications, such as linguistics, bioinformatics, speech analysis, and so on. In this recipe, we will learn how to use CRFs to analyze sequences of letters.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p>PyStruct is a structured library of easy-to-use machine learning algorithms. It implements the max-margin and perceptron methods. Examples of learning algorithms that are implemented in PyStruct are CRFs, <strong>maximum-margin Markov</strong> <strong>random fields</strong> (<strong>M3Ns</strong>), and structural SVMs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the official documentation of the <kbd>pystruct</kbd> library for more information: <a href="https://pystruct.github.io/">https://pystruct.github.io/</a></li>
<li>Look at the <em>Conditional Random Fields</em> lecture (from the University of Notre Dame): <a href="https://www3.nd.edu/~dchiang/teaching/nlp/2015/notes/chapter8v1.pdf">https://www3.nd.edu/~dchiang/teaching/nlp/2015/notes/chapter8v1.pdf</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Analyzing stock market data</h1>
                </header>
            
            <article>
                
<p>The stock market has always been a very popular topic; this is because stock market trends involve a truly impressive turnover. The interest that this topic arouses is clearly linked to the opportunity to get rich through good forecasting by a stock market title. A positive difference between the purchased stock price and that of the sold stock price entails a gain on the part of the investor. But, as we know, the performance of the stock market depends on multiple factors.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p><span>In this recipe, we'll look at how to analyze the stock price of a very popular company: I am referring to Amazon, the US e-commerce company, based in Seattle, Washington, which is the largest internet company in the world.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how we analyze stock market data:</p>
<ol>
<li>Create a new Python file and import the following packages (the full code is given in the <kbd><span>AmazonStock</span>.py</kbd> file that is provided for you):</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from random import seed</pre>
<ol start="2">
<li>Get the stock quotes from the <kbd>AMZN.csv</kbd> <span>file that is provided for you</span>:</li>
</ol>
<pre style="padding-left: 60px">seed(0)<br/>Data = pd.read_csv('AMZN.csv',header=0, usecols=['Date', 'Close'],parse_dates=True,index_col='Date')</pre>
<ol start="3">
<li>To extract preliminary information about the imported dataset, we can invoke the <kbd>info()</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">print(Data.info())</pre>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px"><strong>&lt;class 'pandas.core.frame.DataFrame'&gt;</strong><br/><strong>DatetimeIndex: 4529 entries, 2000-11-21 to 2018-11-21</strong><br/><strong>Data columns (total 1 columns):</strong><br/><strong>Close 4529 non-null float64</strong><br/><strong>dtypes: float64(1)</strong><br/><strong>memory usage: 70.8 KB</strong><br/><strong>None</strong></pre>
<p style="padding-left: 60px">This function prints information about a DataFrame, including the index and the <kbd>dtypes</kbd><span> column</span>, <kbd>non-null</kbd> values, and <kbd>memory usage</kbd>.</p>
<ol start="4">
<li>To display the first five rows of the imported DataFrame, we can use the <kbd>head()</kbd> function, as follows:</li>
</ol>
<pre style="padding-left: 60px">print(Data.head())</pre>
<p class="mce-root"/>
<p style="padding-left: 60px">This function returns the first <em>n</em> rows for the object based on position. It is useful for quickly testing whether your object has the right type of data in it. By default, (if <em>n</em> is omitted), the first five rows are displayed. The following results are returned:</p>
<pre style="padding-left: 60px"><strong>             Close</strong><br/><strong>Date </strong><br/><strong>2000-11-21 24.2500</strong><br/><strong>2000-11-22 25.1875</strong><br/><strong>2000-11-24 28.9375</strong><br/><strong>2000-11-27 28.0000</strong><br/><strong>2000-11-28 25.0312</strong></pre>
<ol start="5">
<li>To get a preview of the data contained in it, we can calculate a series of basic statistics. To do so, we will use the <kbd>describe()</kbd> function in the following way:</li>
</ol>
<pre style="padding-left: 60px">print(Data.describe())</pre>
<p style="padding-left: 60px">The <kbd>describe()</kbd> function generates descriptive statistics that summarize the central tendency, the dispersion, and the form of the distribution of a dataset, excluding the <kbd>NaN</kbd> values. This function analyzes both numerical and object series, as well as the DataFrame column sets of mixed data types. The following results are returned:</p>
<pre style="padding-left: 60px"><strong>                 Close</strong><br/><strong>count      4529.000000</strong><br/><strong>mean        290.353723</strong><br/><strong>std         407.211585</strong><br/><strong>min           5.970000</strong><br/><strong>25%          39.849998</strong><br/><strong>50%         117.889999</strong><br/><strong>75%         327.440002</strong><br/><strong>max        2039.510010</strong></pre>
<ol start="6">
<li>Now, we are going to perform an initial visual exploratory analysis of the time series:</li>
</ol>
<pre style="padding-left: 60px">plt.figure(figsize=(10,5))<br/>plt.plot(Data)<br/>plt.show()</pre>
<p class="mce-root"/>
<p style="padding-left: 60px">In the following graph, Amazon stock prices from 2000-11-21 to 2018-11-21 are shown:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1049 image-border" src="assets/7dd54eda-2970-4787-99af-3b14fa0b5bb3.png" style="width:108.92em;height:55.58em;"/></p>
<p style="padding-left: 60px">From the analysis of the previous graph, we can see that prices have increased considerably over time. In particular, starting from 2015, this increase has shown an exponential trend.</p>
<ol start="7">
<li>Now, let's try to obtain a deeper understanding of the change that Amazon stock has recorded over time. To calculate percentage changes in Python, we will use the <kbd>pct_change()</kbd> function. This function returns percentage changes over a given number of periods:</li>
</ol>
<pre style="padding-left: 60px">DataPCh = Data.pct_change()</pre>
<p style="padding-left: 60px">What we have just calculated coincides with the concept of return.</p>
<ol start="8">
<li>To calculate the logarithm of returns, we will use the <kbd>log()</kbd> function from <kbd>numpy</kbd>:</li>
</ol>
<pre style="padding-left: 60px">LogReturns = np.log(1 + DataPCh) <br/>print(LogReturns.tail(10))</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">The <kbd>tail()</kbd> function returns the last <em>n</em> rows from the object, based on position. It is useful for quickly verifying data—for example, after sorting or appending rows. The following values are returned (the last 10 rows of the <kbd>LogReturns</kbd> object):</p>
<pre style="padding-left: 60px"><strong>                  Close</strong><br/><strong>Date </strong><br/><strong>2018-11-08     -0.000330</strong><br/><strong>2018-11-09     -0.024504</strong><br/><strong>2018-11-12     -0.045140</strong><br/><strong>2018-11-13     -0.003476</strong><br/><strong>2018-11-14     -0.019913</strong><br/><strong>2018-11-15      0.012696</strong><br/><strong>2018-11-16     -0.016204</strong><br/><strong>2018-11-19     -0.052251</strong><br/><strong>2018-11-20     -0.011191</strong><br/><strong>2018-11-21      0.014123</strong></pre>
<ol start="9">
<li>Now, we will draw a diagram with the logarithm of the returns we have calculated:</li>
</ol>
<pre style="padding-left: 60px">plt.figure(figsize=(10,5))<br/>plt.plot(LogReturns)<br/>plt.show()</pre>
<p style="padding-left: 60px">As we have done previously, we first set the dimensions of the graph, then we will plot the graph, and finally we will visualize it. The following graph shows the logarithm of the returns:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1050 image-border" src="assets/067332e5-a62c-40f6-ab09-29ea44dd5d21.png" style="width:41.58em;height:21.17em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>To study the evolution of a phenomenon, a graph of its time series is not enough; we need to make comparisons between the intensity of the phenomenon at different times, that is, calculating the variations of intensity from one period to another. Furthermore, it can be interesting to analyze the trend of the variations of the phenomenon that occurred between adjoining periods of time. We indicate a time series with Y1,..., Yt,..., Yn. The time series is the chronological recording of experimental observations of a variable, such as price trends, stock market indices, spreads, and unemployment rates. It is therefore a succession of data that's been ordered over time from which we want to extract information for the characterization of the phenomenon under observation, and for the prediction of future values.</p>
<p>The variation that occurs between two different times (let's indicate them with <em>t</em> and <em>t + 1</em>) can be measured using the following ratio:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/6f1d5748-9875-4c3d-a708-3bfe00fa6cb2.png" style="width:5.33em;height:2.92em;"/></p>
<p>This index is a percentage ratio and is called a <strong>percentage change</strong>. In particular, this is the percentage rate of variation of the phenomenon <em>Y</em> of the time <em>t + 1</em>, with respect to the previous time, <em>t</em>. This method gives a more detailed explanation about how the data has changed over a period of time. With this technique, we can track the prices of individual stocks and large market indices, as well as compare the values of different currencies.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p>The advantage of using returns, compared to prices, lies in the normalization that allows us to measure all the variables in a comparable metric, thus allowing for the evaluation of analytical relationships between two or more variables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the official documentation of the <kbd>pandas.DataFrame.pct_change</kbd> function: <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pct_change.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pct_change.html</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using RNNs to predict time series data</h1>
                </header>
            
            <article>
                
<p><strong>Long short-term memory</strong> (<strong>LSTM</strong>) is a particular architecture of <strong>recurrent neural networks</strong><span> (</span><strong>RNNs</strong><span>)</span>. RNNs are based on the need to preserve the memory of past events; this behavior is not possible with normal networks, and that is why RNNs are used in areas where the classic networks do not produce results, such as the prediction of time series (weather, quotations, and so on) that refer to previous data.</p>
<p>An LSTM network consists of cells (LSTM blocks) that are linked together. Each cell is, in turn, composed of three types of ports: the input gate, output gate, and forget gate. They implement the write, read, and reset functions on the cell memory, respectively, so the LSTM modules are able to regulate what is stored and deleted. This is possible thanks to the presence of various elements called <strong>gates</strong>, which are composed of a sigmoid neural layer and a pointwise product. The output of each gate is in the range (0, 1), representing the percentage of information that flows inside it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p><span>In this recipe, we'll look at how the LSTM model can be applied to predict the future stock price of a very popular company: I refer to Amazon, the US e-commerce company, based in Seattle, Washington, which is the largest internet company in the world.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how we can use RNNs to predict time series data:</p>
<ol>
<li>Create a new Python file and import the following packages (the full code is given in the <kbd>LSTMstock.py</kbd> file that is provided for you). The first part of the file was tackled in the previous recipe, <em>Analyzing stock market data</em>. We report it only for the completeness of the algorithm:</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from random import seed<br/><br/>seed(0)<br/><br/>Data = pd.read_csv('AMZN.csv',header=0, usecols=['Date', 'Close'],parse_dates=True,index_col='Date')</pre>
<ol start="2">
<li>It is good practice to rescale the data before training an LSTM algorithm. With rescaling, data units are eliminated, allowing you to compare data from different locations easily. In this case, we will use the min-max method (usually called <strong>feature scaling</strong>) to get all the scaled data in the range [0, 1]. To perform feature scaling, we can use the preprocessing package that's available in the <kbd>sklearn</kbd> library:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.preprocessing import MinMaxScaler<br/>scaler = MinMaxScaler()<br/>DataScaled = scaler.fit_transform(Data)</pre>
<ol start="3">
<li>Now, let's split the data for the training and test model. Training and testing the model forms the basis for further usage of the model for prediction in predictive analytics. Given a dataset of 4,529 rows of data, we split it into a convenient ratio (say 70:30) and allocate 3,170 rows for training and 1,359 rows for testing:</li>
</ol>
<pre style="padding-left: 60px">np.random.seed(7)<br/>TrainLen = int(len(DataScaled) * 0.70)<br/>TestLen = len(DataScaled) - TrainLen<br/>TrainData = DataScaled[0:TrainLen,:] <br/>TestData = DataScaled[TrainLen:len(DataScaled),:]<br/><br/>print(len(TrainData), len(TestData))</pre>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px"><strong>3170 1359</strong></pre>
<ol start="4">
<li>Now, we need input and output to train and test our network. It is clear that the input is represented by the data that's present in the dataset. Therefore, we must construct our output; we will do so by supposing we want to predict the Amazon stock price at time <em>t + 1</em> with respect to the value stored at time <em>t</em>. A recurrent network has memory, and this is maintained by fixing the so-called time step. The time step is all about how many steps back in time backpropagation uses when calculating gradients for weight updates during training. In this way, we set <kbd>TimeStep=1</kbd>. Then, we define a function that gives a dataset and a time step, which then returns the input and output data:</li>
</ol>
<pre style="padding-left: 60px">def DatasetCreation(dataset, TimeStep=1):<br/>  DataX, DataY = [], []<br/>  for i in range(len(dataset)-TimeStep-1):<br/>    a = dataset[i:(i+TimeStep), 0]<br/>    DataX.append(a)<br/>    DataY.append(dataset[i + TimeStep, 0])<br/>  return np.array(DataX), np.array(DataY)</pre>
<p style="padding-left: 60px">In this function, <kbd>dataX =Input= data(t)</kbd> is the input variable and <kbd>DataY=output= data(t + 1)</kbd> is the predicted value at the next time period.</p>
<ol start="5">
<li>Let's use this function to set the train and test datasets that we will use in the next phase (network modeling):</li>
</ol>
<pre style="padding-left: 60px">TimeStep = 1<br/>TrainX, TrainY = DatasetCreation(TrainData, TimeStep)<br/>TestX, TestY = DatasetCreation(TestData, TimeStep)</pre>
<p style="padding-left: 60px">In an LSTM/RNN network, the input for each LSTM layer must contain the following information:</p>
<ul>
<li><strong>Observations</strong>: Number of observations collected</li>
<li><strong>Time steps</strong>: A time step is an observation point in the sample</li>
<li><strong>Features</strong>: One feature for each step</li>
</ul>
<p style="padding-left: 60px">Therefore, it is necessary to add a temporal dimension to those foreseen for a classical network. Thus, the input shape is as follows:</p>
<p style="padding-left: 60px" class="CDPAlignCenter CDPAlign">(<em>Number of observations, number of time steps, number of features per steps</em>)</p>
<p style="padding-left: 60px" class="CDPAlignLeft CDPAlign">In this way, the input for each LSTM layer becomes three-dimensional.</p>
<ol start="6">
<li>To transform the input datasets into 3D form, we will use the <kbd>np.reshape()</kbd> function, as follows:</li>
</ol>
<pre style="padding-left: 60px">TrainX = np.reshape(TrainX, (TrainX.shape[0], 1, TrainX.shape[1]))<br/>TestX = np.reshape(TestX, (TestX.shape[0], 1, TestX.shape[1]))</pre>
<ol start="7">
<li>Now that the data is in the right format, it's time to create the model. Let's start by importing the libraries:</li>
</ol>
<pre style="padding-left: 60px">from keras.models import Sequential<br/>from keras.layers import LSTM<br/>from keras.layers import Dense</pre>
<ol start="8">
<li>We will use a <kbd>Sequential</kbd> model, that is, a linear stack of layers. To create a sequential model, we have to pass a list of layer instances to the constructor. We can also simply add layers via the <kbd>add()</kbd> method:</li>
</ol>
<pre style="padding-left: 60px">model = Sequential()<br/>model.add(LSTM(256, input_shape=(1, TimeStep)))<br/>model.add(Dense(1, activation='sigmoid'))<br/>model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])<br/>model.fit(TrainX, TrainY, epochs=100, batch_size=1, verbose=1)<br/>model.summary()</pre>
<p style="padding-left: 60px">The following result is printed:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1051 image-border" src="assets/b0198263-2a08-40c5-a32f-5ba727792200.png" style="width:39.42em;height:13.33em;"/></p>
<ol start="9">
<li>To evaluate the performance of the model we have just adapted, we can use the <kbd>evaluate()</kbd> function, as follows:</li>
</ol>
<pre style="padding-left: 60px">score = model.evaluate(TrainX, TrainY, verbose=0)<br/>print('Keras Model Loss = ',score[0])<br/>print('Keras Model Accuracy = ',score[1])</pre>
<p style="padding-left: 60px">The preceding function displays the loss value and metrics values for the model in the test mode. This is computed in batches. The following results are returned:</p>
<pre style="padding-left: 60px"><strong>Keras Model Loss = 2.4628453362992094e-06</strong><br/><strong>Keras Model Accuracy = 0.0003156565656565657</strong></pre>
<ol start="10">
<li>The model is now ready for use. We can therefore use it to execute our predictions:</li>
</ol>
<pre style="padding-left: 60px">TrainPred = model.predict(TrainX)<br/>TestPred = model.predict(TestX)</pre>
<ol start="11">
<li>The predictions must be reported in their original form so that they can be compared to the actual values:</li>
</ol>
<pre style="padding-left: 60px">TrainPred = scaler.inverse_transform(TrainPred)<br/>TrainY = scaler.inverse_transform([TrainY])<br/>TestPred = scaler.inverse_transform(TestPred)<br/>TestY = scaler.inverse_transform([TestY])</pre>
<ol start="12">
<li>To verify the correct prediction of data, we can now visualize the results by drawing an appropriate graph. To display the time series correctly, a prediction shift is required. This operation must be carried out both on the train set and the test set:</li>
</ol>
<pre style="padding-left: 60px">TrainPredictPlot = np.empty_like(DataScaled)<br/>TrainPredictPlot[:, :] = np.nan<br/>TrainPredictPlot[1:len(TrainPred)+1, :] = TrainPred</pre>
<ol start="13">
<li>As we stated previously, the same operation must then be performed on the test set:</li>
</ol>
<pre style="padding-left: 60px">TestPredictPlot = np.empty_like(DataScaled)<br/>TestPredictPlot[:, :] = np.nan<br/>TestPredictPlot[len(TrainPred)+(1*2)+1:len(DataScaled)-1, :] = TestPred</pre>
<ol start="14">
<li>Finally, we have to plot the actual data and the predictions:</li>
</ol>
<pre style="padding-left: 60px">plt.figure(figsize=(10,5))<br/>plt.plot(scaler.inverse_transform(DataScaled))<br/>plt.plot(TrainPredictPlot)<br/>plt.plot(TestPredictPlot)<br/>plt.show()</pre>
<p class="CDPAlignLeft CDPAlign">The following screenshot shows the actual data and the predictions:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1052 image-border" src="assets/b0a827d7-3058-4be1-a038-b0b715dd7d6b.png" style="width:46.50em;height:23.17em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>At the beginning of this recipe, we said that the LSTM modules are able to regulate what is stored and deleted. This is possible thanks to the presence of various elements called gates, which are composed of a sigmoid neural layer and a pointwise product. The first part of the LSTM module decides what information is deleted from the cell. The gate takes the inputs and returns a value between 0 and 1 for each state of the cell. The gate output can take two values:</p>
<ul>
<li><kbd>0</kbd>: Complete reset of the cell status</li>
<li><kbd>1</kbd>: Total storage of the cell value</li>
</ul>
<p>Data storage is divided into two phases:</p>
<ul>
<li>The first is entrusted to one sigmoid layer called the <strong>input gate layer</strong>; it carries out an operation that establishes which values will need to be updated.</li>
<li>The second phase is instead entrusted to a <kbd>tanh</kbd> layer that creates a vector of values, intended to be updated. To create an updated set of values, the outputs of the two layers are combined.</li>
</ul>
<p>Finally, the result will be given by a <kbd>sigmoid</kbd> layer, which determines which parts of the cell will contribute to the output and from the current state of the cell, filtered through a <kbd>tanh</kbd> function to obtain a range from -1 to 1. The result of this operation is multiplied by the value of the <kbd>sigmoid</kbd> layer so that only the desired outputs are given.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p class="mce-root">A RNN is a neural model in which a bidirectional flow of information is present. In other words, while the propagation of signals in feedforward networks takes place only in a continuous manner in one direction, from inputs to outputs, recurrent networks are different. In recurrent networks, this propagation can also occur from a neural layer following a previous one, between neurons belonging to the same layer, or even between a neuron and itself.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the official documentation of the Keras library: <a href="https://keras.io/">https://keras.io/</a></li>
<li>Refer to <em>Recurrent Neural Networks</em> (from Yale University): <a href="http://euler.stat.yale.edu/~tba3/stat665/lectures/lec21/lecture21.pdf">http://euler.stat.yale.edu/~tba3/stat665/lectures/lec21/lecture21.pdf</a></li>
<li>Refer to <em>Long Short-Term Memory</em> (from the University of Wisconsin, Madison): <a href="http://pages.cs.wisc.edu/~shavlik/cs638/lectureNotes/Long%20Short-Term%20Memory%20Networks.pdf">http://pages.cs.wisc.edu/~shavlik/cs638/lectureNotes/Long%20Short-Term%20Memory%20Networks.pdf</a>                                       </li>
</ul>


            </article>

            
        </section>
    </body></html>