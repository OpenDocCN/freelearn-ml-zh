- en: Music Genre Recommendation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to go back to supervised learning. We have built
    numerous supervised learning algorithms for both classification and regression
    problems using learning algorithms such as logistic regression, Naive Bayes, random
    forest, and **Support Vector Machine** (**SVM**). However, the number of outputs
    from these models we have built has always been one. In our Twitter sentiment
    analysis project, the output could only be one of positive, negative, or neutral.
    On the other hand, in our housing price prediction project, the output was a log
    of house prices predicted. Unlike our previous projects, there are cases where
    we want our **machine learning** (**ML**) models to output multiple values. A
    recommendation system is one example of where we need ML models that can produce
    rank-ordered predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to use a dataset that contains various audio features,
    compiled from numerous music recordings. With this data, we are going to explore
    how the values of audio features, such as kurtosis and skewness of the sound spectrum,
    are distributed across different genres of songs. Then, we are going to start
    building multiple ML models that output the predicted probabilities of the given
    song belonging to each music genre, instead of producing just one prediction output
    of the most likely genre for a given song. Once we have these models built, we
    are going to take it a step further and ensemble the prediction results of these
    base models to build a meta model for the final recommendations of song music
    genres. We are going to use a different model validation metric, **Mean Reciprocal
    Rank** (**MRR**), to evaluate our ranking models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Problem definition for the Music Genre Recommendation project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analysis for the audio features dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML models for music genre classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensembling base learning models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating recommendation/rank-ordering models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problem definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's get into greater detail and properly define what problems we are going
    to solve and what machine learning models we are going to build for this project.
    Music streaming services, such as Pandora and Spotify, require music recommendation
    systems, with which they can recommend and play songs that their listeners might
    like. There is more than one way to build a music recommendation system. One way
    is to look at what other similar users listened to, and the way to define similar
    users is to look at the history of songs that they listened to. However, this
    approach will not work well if the user is new to the platform and/or if we do
    not have enough of a history of songs he or she listened to. In this case, we
    cannot rely on the historical data. Instead, it will be better to use the attributes
    of the songs that the user is currently listening to recommend other music. One
    song attribute that can play an important role in music recommendation is the
    genre. It is highly likely that a user who is currently listening to music on
    the platform will like to continue listening to the same or similar music. Imagine
    you were listening to instrumental music and the music streaming application then
    suddenly played rock music. It would not be a smooth transition and it would not
    be a good user experience, as you most likely would have wanted to continue listening
    to instrumental music. By correctly identifying the genre of the songs and recommending
    the right song type to play, you can avoid disturbing the user experience of your
    music streaming service.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to build a music genre recommendation model, we are going to use **FMA:
    A Dataset For Music Analysis**, which contains a large amount of data for over
    100,000 tracks. The dataset contains information about the album, title, audio
    attributes, and so forth, and the full dataset can be found and downloaded from
    this link: [https://github.com/mdeff/fma](https://github.com/mdeff/fma). With
    this data, we are going to sub-select the features that are of interest and build
    numerous ML models that output the probability of each song belonging to different
    music genres. Then, we are going to rank-order the genres by probability. We will
    be experimenting with various learning algorithms, such as logistic regression,
    Naive Bayes, and SVM. We are going to take it a step further by using the ensembling
    technique to take the output of these models as an input to another ML model that
    produces the final prediction and recommendation output. We are going to use MRR as
    the metric to evaluate our music genre recommendation models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize our problem definition for the music genre recommendation project:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the problem? We need a recommendation model that rank-orders music genres
    by how likely it is that a song belongs to each genre, so that we can properly
    identify the genre of a song and recommend what song to play next.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is it a problem?Use of historical data for music recommendation is not reliable
    for those users who are new to the platform, as they will not have enough historical
    data for good music recommendations. In this case, we will have to use audio and
    other features to identify what music to play next. Correctly identifying and
    recommending the genre of music is the first step to figuring out what song to
    play next.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are some approaches to solving this problem? We are going to use publicly
    available music data, which not only contains information about the album, title,
    and artist of the song, but also contains information about numerous audio features.
    Then, we are going to build ML models that output the probabilities and use this
    probability output to rank-order genres for given song.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the success criteria? We want the correct music genre to come up as
    one of the top predicted genres. We will use MRR as the metric to evaluate ranking
    models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analysis for the audio features dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start looking into the audio features dataset. In order to focus on
    building recommendation models for music genres, we trimmed down the original
    dataset from **FMA: A Dataset For Music Analysis**. You can download this data
    from this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.7/sample.csv](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.7/sample.csv).'
  prefs: []
  type: TYPE_NORMAL
- en: Target variable distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Similar to previous chapters, we used the `AggregateRowsBy` method in the Deedle
    data frame to count the number of records per genre. Then, we used the `DataBarBox`
    class to create a bar chart that shows the distribution of the target variable
    visually. As you can see from this code snippet (in line 10), we are using the
    first three letters of each genre as a label for each genre in the bar chart.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you run this code, you will see the following output for the distribution
    of the target variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00097.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'The following plot shows the bar chart for the distribution of the target variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00098.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this chart, we have the largest number for Instrumental (**Ins**)
    music in our sample set and Electronic (**Ele**) and Rock (**Roc**) follow as
    the second and third. Although this sample set contains some songs in certain
    genres more so than others, this is a relatively well balanced set, where one
    or two genres do not take up the majority of the sample records. Now, let's look
    at the distributions of some of our features.
  prefs: []
  type: TYPE_NORMAL
- en: Audio features – MFCC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this project, we are going to focus on a subset of features that the full
    dataset has. We are going to use **Mel Frequency Cepstral Coefficients** (**MFCCs**)
    and their statistical distributions as the features to our ML models. Simply put,
    **MFCC** is a representation of the sound spectrum and we will use its statistical
    distributions, kurtosis, skewness, min, max, mean, median, and standard deviation.
    If you look at the sample set you have downloaded from the previous step, you
    will see the columns are named according to the corresponding statistical distribution.
    We are going to first look at the distributions of each of these features. The
    following code snippet shows how we computed the quartiles for each feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Similar to previous chapters, we are using the `Quantiles` method in the `Accord.Statistics.Measures`
    class to compute quartiles, which are the three numbers that separate the values
    into four subsets—the middle number between the min and median (25^(th) percentile),
    median (50^(th) percentile), and the middle number between the median and max
    (75^(th) percentile). As you can see in line 6 of this code snippet, we are only
    showing the first four coefficients' statistical distributions. For your further
    experiments, you can look at the distributions of all the MFCC features, not limited
    to only these four. Let's quickly take a look at just a couple of the distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The distribution for the kurtosis of the first four coefficients looks like
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00099.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this output, the majority of the kurtosis values fall between
    -2 and 5, but there are cases where the kurtosis can take large values. Let''s
    now look at the skewness distributions for the first four coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00100.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Skewness varies between narrower ranges. Typically, the skewness values seem
    to fall between -15 and 5\. Lastly, let''s look at the distributions of the mean
    of the first four coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00101.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this output, the mean values seem to vary and have wide
    ranges. It can take any values between -1,000 and 300.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a rough idea of how the audio features' distributions look,
    let's see if we can find any discrepancies in the feature distributions among
    different genres. We are going to plot a scatter plot where the *x* axis is the
    index of each feature and the *y* axis is the values for the given feature. Let's
    look at these plots first, as it will be easier to understand with some visuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plots show the distributions of kurtosis for four different genres:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00102.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As briefly mentioned previously, the *x* axis refers to the index of each feature.
    Since we have 20 individual features for kurtosis of MFCCs, the x-values span
    from 1 to 20\. On the other hand, the *y* axis shows the distributions of the
    given feature. As you can see from this chart, there are some differences in the
    feature distributions among different genres, which will help our ML models to
    learn how to correctly predict the genre of a given song.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plots show the distributions of skewness for four different genres:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00103.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Lastly, the following plots show the mean distributions for four different
    genres:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00104.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The distributions of the mean values for each feature seem more similar among
    different genres, when compared to the kurtosis and skewness.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to create these charts, we have used the `ScatterplotBox` class. The
    following code shows how we created the previous charts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we start iterating through different statistical
    distributions (`kurtosis`, `min`, `max`, and so on) from line 2 and, for each
    of those statistical distributions, we sub-select the columns that we are interested
    in from `featuresDF` in line 7\. Then, we wrote and used a helper function that
    builds an array of x-y pairs for the scatter plot and display it using the `Show`
    method of the `ScatterplotBox` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for the helper function that builds x-y pairs for scatter plots is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, this method takes the index of the feature as
    an x value and takes the value of the feature as a y value.
  prefs: []
  type: TYPE_NORMAL
- en: The full code for this data analysis step can be found at this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.7/DataAnalyzer.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.7/DataAnalyzer.cs).
  prefs: []
  type: TYPE_NORMAL
- en: ML models for music genre classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now start building ML models for music genre classification. In this
    project, the output of our ML models will take a slightly different form. Unlike
    other supervised learning models that we have built, we want our models to output
    the likelihoods or probabilities for each genre for a given song. So, instead
    of the model output being one value, we would like our models to output eight
    values, where each value will represent the probability of the given song belonging
    to each of the eight genres—electronic, experimental, folk, hip-hop, instrumental,
    international, pop, and rock. In order to achieve this, we will be using the `Probabilities`
    method from each of the model classes, on top of the `Decide` method that we have
    been using so far.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first model we are going to experiment with is logistic regression. The
    following code shows how we built a logistic regression classifier with an 80/20
    split for training and testing sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As you should be familiar with it already, we used `SplitSetValidation` to split
    our sample set into train and test sets. We are using 80% of our sample set for
    training and the other 20% for testing and evaluating our models. We are using `MultinomialLogisticRegression`
    as our model for the multi-class classifier and `MultinomialLogisticLearning`
    with `GradientDescent` as our learning algorithm. Similar to the previous chapters,
    we are using `ZeroOneLoss` for our `Loss` function for the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see at the base of this code, we are storing the trained logistic
    regression classifier model into a separate variable, `logitTrainedModel`, and
    also the indexes of the train and test sets for use in training and testing other
    learning algorithms. We do this so that we can do head-to-head comparisons of
    model performance among different ML models.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code to do in-sample and out-of-sample predictions using this trained logistic
    regression model is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As briefly mentioned before, we are using the `Probabilities` method from the `MultinomialLogisticRegression`
    model, which outputs an array of probabilities, and each index represents the
    probability of the given song being the corresponding music genre. The following
    code shows how we encoded each of the genres:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Let's try training another ML model using the same indexes for train and test
    sets that we used for the logistic regression model.
  prefs: []
  type: TYPE_NORMAL
- en: SVM with the Gaussian kernel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using the following code, you can train a multi-class SVM model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, there is one minor difference between the SVM
    model that we built previously. We are using `MulticlassSupportVectorLearning` instead
    of `LinearRegressionNewtonMethod` or `FanChenLinSupportVectorRegression`, which
    we used in [Chapter 5](part0056.html#1LCVG0-5ebdf09927b7492888e31e8436526470),
    *Fair Value of House and Property*. This is because we now have a multi-class
    classification problem and need to use a different learning algorithm for such
    SVM models. As we discussed in another chapter previously, the hyper-parameters,
    such as `Epsilon`, `Tolerance`, and `Complexity`, can be tuned and you should
    experiment with other values for better-performing models.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to note here is that when we are training our SVM model, we use the
    same train set that we used for building the logistic regression model. As you
    can see at the base of the code, we sub-select records with the same indexes in
    the train set that we used previously for the logistic regression model. This
    is to make sure that we can correctly do a head-to-head comparison of the performance
    of this SVM model against that of the logistic regression model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the case of the previous logistic regression model, we are using
    the following code for in-sample and out-of-sample predictions, using the trained
    SVM model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `MulticlassSupportVectorMachine` class also provides the `Probabilities`
    method, with which we can get the likelihoods of a song belonging to each of the
    eight genres. We store these probability outputs into separate variables, `svmTrainProbabilities`
    and `svmTestProbabilities`, for our future model evaluation and for ensembling
    the models.
  prefs: []
  type: TYPE_NORMAL
- en: Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to build one more machine learning model for music genre classification.
    We are going to train a Naive Bayes classifier. The following code shows how you
    can build a Naive Bayes classifier for input with continuous values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are using `NormalDistribution` as a distribution
    for `NaiveBayesLearning`. Unlike in the previous chapters, where we had word counts
    as features of our Naive Bayes classifiers, we have continuous values for our
    audio features. In this case, we need to build a Gaussian Naive Bayes classifier. Similar
    to when we were building an SVM model, we are training our Naive Bayes classifier
    with the same train set that we used for the logistic regression model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how we can get the probability output for in-sample
    and out-of-sample predictions using the trained Naive Bayes classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Similar to the `MulticlassSupportVectorMachine` and `MultinomialLogisticRegression`
    classes, the `NaiveBayes` model also provides the `Probabilities` method.  As
    you can see from the code, we store the predicted probabilities for both in-sample
    and out-of-sample records into two separate variables, `nbTrainProbabilities`
    and `nbTestProbabilities`.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will take a look at how we can combine and ensemble
    these models we have built so far. The full code for building ML models can be
    found at this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.7/Modeling.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.7/Modeling.cs).
  prefs: []
  type: TYPE_NORMAL
- en: Ensembling base learning models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensemble learning is where you combine trained models together in order to improve
    their predictive power. The random forest classifier that we built in previous
    chapters is an example of ensemble learning. It builds a forest of decision trees,
    where the individual trees are trained with a portion of the samples and features
    in the sample set. This method of ensemble learning is called **bagging**. The
    ensemble method that we are going to use in this chapter is **stacking**. Stacking
    is when you build a new ML model using the outputs of the other models, which
    are called **base learning models**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this project, we are going to built a new Naive Bayes classifier model on
    top of the predicted probability output from those logistic regression, SVM, and
    Naive Bayes models that we built in the previous section. The first thing we need
    to do to build a new model with the probability output of the base models is to
    build the training input. The following code shows how we combined all the outputs
    from the base models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are concatenating the predicted probabilities
    from all three models that we built so far. Using this probability output data
    as input, we are going to build a new meta-model, using the Naive Bayes learning
    algorithm. The following code is how we trained this meta-model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'From this code, you can see that we are still using `NormalDistribution`, as
    the input is a set of continuous values. Then, we train this new Naive Bayes classifier
    with the combined probability output of the base learning models that we trained
    before. Similar to the previous steps, we get the prediction output from this
    meta-model by using the `Probabilities` method and store these results into separate
    variables. The code to get the prediction output for the train and test sets using
    this new meta-model is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have all the models built, let's start looking at the performances
    of these models. In the following section, we will evaluate the performance of
    base models as well as the meta-model we just built.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating recommendation/rank-ordering models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Evaluating recommendation models that rank-order the outcomes is quite different
    from evaluating classification models. Aside from whether the model prediction
    is right or wrong, we also care about in which rank the correct outcome comes
    in the recommendation models. In other words, a model that predicted the correct
    outcome to be the second from the top is a better model than a model that predicted
    the correct outcome to be fourth or fifth from the top. For example, when you
    search for something on a search engine, getting the most appropriate document
    on the top of the first page is great, but it is still OK to have that document
    as the second or third link on the first page, as long as it does not appear at
    the bottom of the first page or the next page. We are going to discuss some ways
    to evaluate such recommendation and ranking models in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction accuracy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first and the simplest metric to look at is accuracy. For the first logistic
    regression model we built, we can use the following code to get the accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'For the following models, SVM and Naive Bayes classifiers, we can use the following
    code to compute the accuracy for the train and test set predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We used the `SplitSetValidation` class for the first logistic regression model,
    so it computes the accuracy while the model is being fit. However, for the subsequent
    models, we trained SVM and Naive Bayes models individually, so we need to use
    the `ZeroOneLoss` class to compute accuracies.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you run this code, you will see the accuracy output for the logistic regression
    model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00105.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'For the Naive Bayes model, the accuracy results look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00106.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'And for the SVM model, the output looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00107.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Lastly, the accuracy results for the meta-model look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00108.gif)'
  prefs: []
  type: TYPE_IMG
- en: From these results, we can see that the Naive Bayes classifier performed the
    best by predicting the correct genre for about 42% of the time. The logistic regression
    model comes in as the second best model with the second highest accuracy and the
    SVM model comes in as the worst model in terms of prediction accuracy. Interestingly,
    the meta-model that we built with the output from the other three models did not
    perform so well. It did better than the SVM model, but performed worse than the
    Naive Bayes and logistic regression classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: Confusion matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next thing we are going to look at is confusion matrices. In the case of
    binary classification in [Chapter 2](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470), *Spam
    Email Filtering*, we explored a case where the confusion matrix was a 2 x 2 matrix.
    However, in this project, our models have `8` outcomes and the shape of the confusion
    matrix will be 8 x 8\. Let''s first look at how we can build such a confusion
    matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The code for the helper function, `BuildConfusionMatrix`, looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you run this code, you are going to get an 8 x 8 matrix, where the rows
    are the actual and observed genres and the columns are the predicted genres from
    the models. The following is the confusion matrix for our logistic regression
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00109.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'The numbers in bold represent the number of records that the model predicted
    correctly. For example, this logistic regression model predicted **79** songs
    correctly as **Electronic** and **33** songs were predicted as **Electronic**,
    where they were actually **Experimental**. One thing noticeable here is that this
    logistic regression model did not do so well for predicting Pop songs. It only
    had one prediction for Pop, but that prediction was wrong and the song was actually
    a **Hip-Hop** song. Let''s now look at the confusion matrix of the Naive Bayes
    classifier''s predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00110.gif)'
  prefs: []
  type: TYPE_IMG
- en: As expected from the accuracy results, the confusion matrix looks better than
    that for logistic regression. A higher proportion of predictions in each category
    were right, when compared to the logistic regression classifier. The Naive Bayes
    classifier seemed to do much better for **Pop** songs as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the confusion matrix for the SVM classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00111.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'As expected, the prediction results are not good. The SVM model predicted 100%
    of the records as **Electronic**. Lastly, let''s look at how the meta-model did:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00112.gif)'
  prefs: []
  type: TYPE_IMG
- en: This confusion matrix looks slightly better than that of the SVM model. However,
    the majority of the predictions were either **Instrumental** or **International**
    and only a handful of records were predicted as other genres.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the confusion matrix is a good way to check misclassifications by
    models and find out the weaknesses and strengths of the models. These results
    are well aligned with the accuracy results, where the Naive Bayes classifier outperformed
    all the other models and the meta-model did not do so well, although it is not
    the worst among the four models that we have built.
  prefs: []
  type: TYPE_NORMAL
- en: Mean Reciprocal Rank
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next evaluation metric we are going to look at is MRR. MRR can be used
    where a model produces a list of outcomes and it measures the overall quality
    of the rankings. Let''s first look at the equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00113.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, it is an average of the sum of the inverse of the ranks. Consider
    the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00114.gif)'
  prefs: []
  type: TYPE_IMG
- en: In the first example, the correct genre was the second in rank, so the reciprocal
    rank is **1/2**.  The second example's correct genre was the first in rank, so
    the reciprocal rank is **1/1**, which is **1**. Following this process, we can
    get the reciprocal ranks for all the records and the final MRR value is simply
    the average of those reciprocal ranks. This tells us the general quality of the
    rankings. In this example, the **MRR** is **0.57**, which is above 1/2\. So, this
    MRR number suggests that, on average, the correct genres come up within the top
    two predicted genres by the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to compute the MRR for our models, we first need to transform the
    probability output into rankings and then compute the MRR from this transformed
    model output. The following code snippet shows how we computed the MRR for our
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This code uses two helper functions, `GetPredictionRanks` and `ComputeMeanReciprocalRank`.
    The `GetPredictionRanks` method transforms the probability output of a model into
    rankings and the `ComputeMeanReciprocalRank` method calculates the MRR from the
    rankings. The helper function, `GetPredictionRanks`, looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We are using the `Matrix.ArgSort` method from the `Accord.Math` package to rank-order
    the genres for each record. `Matrix.ArgSort` returns the indexes of the genres
    after sorting them by probability in ascending order. However, we want them to
    be sorted in descending order so that the most likely genre comes up as the first
    in rank. This is why we reverse the order of the sorted indexes using the `Reversed`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The helper function, `ComputeMeanReciprocalRank`, looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This is our implementation of the equation for the MRR calculation that we discussed
    previously. This method iterates through each record and gets the rank of the
    correct genre.  Then, it reciprocates the rank, sums all of the reciprocals, and
    finally divides this sum by the number of records to get the MRR number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start looking at the MRR scores for the models that we have built so
    far. The following output shows the MRR scores for the `Logistic Regression Classifier`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00115.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'The in-sample and out-of-sample MRR scores for the Naive Bayes classifier look
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00116.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'And the results for the SVM classifier are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00117.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Lastly, the MRR scores for the meta-model look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00118.gif)'
  prefs: []
  type: TYPE_IMG
- en: From these outputs, we can see that the Naive Bayes classifier has the best
    MRR scores at around `0.61`, while the SVM classifier has the worst MRR scores
    at around `0.33`. The meta-model has MRR scores at around `0.4`. This is aligned
    with the results we have found from looking at the prediction accuracy and confusion
    matrix in the previous steps.  From these MRR scores, we can see that the correct
    genres generally fall within the top two ranks for the Naive Bayes classifier.
    On the other hand, the correct genres typically come up as the third from the
    top for the SVM classifier and within the top three for the meta-model. As you
    can see from these cases, we can understand the overall quality of the rankings
    by looking at the MRR measures.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we built our first recommendation model to rank-order the likelihood
    of each of the outcomes. We started this chapter by defining the problems that
    we were going to solve and the modeling and the evaluation approaches that we
    were going to use. Then, we looked at the distributions of the variables in our
    sample set. First, we looked at how well the target variables were distributed
    among different classes or genres and noticed that it was a well-balanced sample
    set with no one genre taking up the majority of the samples in our dataset. Then,
    we looked at the distributions of the audio features. In this project, we focused
    mainly on MFCCs and their statistical distributions, such as kurtosis, skewness,
    min, and max. By looking at the quartiles and the scatter plots of these features,
    we confirmed that the feature distributions differed among the music genres.
  prefs: []
  type: TYPE_NORMAL
- en: 'During our model-building step, we experimented with three learning algorithms:
    logistic regression, SVM, and Naive Bayes. Since we were building multi-class
    classification models, we had to use different learning algorithms from previous
    chapters. We learned how to use the `MultinomialLogisticRegression` and `MulticlassSupportVectorMachine`
    classes in the Accord.NET framework, as well as when to use `NormalDistribution`
    for `NaiveBayesLearning`. We then discussed how we could build a meta-model that
    ensembled the prediction results from the base learning models to improve the
    predictive power of the ML models. Lastly, we discussed how evaluating ranking
    models differed from other classification models and looked at the accuracy, confusion
    matrix, and MRR metrics to evaluate our ML models.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to use a hand-written digit image dataset
    to build a classifier that classifies each image into the corresponding digit.
    We are going to discuss some techniques to reduce the dimensions of the feature
    set and how to apply them to the image dataset. We will also discuss how to build
    a neural network in C# using the Accord.NET framework, which is the backbone of
    deep learning.
  prefs: []
  type: TYPE_NORMAL
