["```py\nDataSource source = new DataSource(\"data/zoo.arff\"); \nInstances data = source.getDataSet(); \nSystem.out.println(data.numInstances() + \" instances loaded.\"); \nSystem.out.println(data.toString()); \n```", "```py\n101 instances loaded.\n```", "```py\nRemove remove = new Remove(); \nString[] opts = new String[]{ \"-R\", \"1\"}; \n```", "```py\nremove.setOptions(opts); \nremove.setInputFormat(data); \ndata = Filter.useFilter(data, remove); \nSystem.out.println(data.toString()); \n```", "```py\nInfoGainAttributeEval eval = new InfoGainAttributeEval(); \nRanker search = new Ranker(); \n```", "```py\nAttributeSelection attSelect = new AttributeSelection(); \nattSelect.setEvaluator(eval); \nattSelect.setSearch(search); \nattSelect.SelectAttributes(data); \n```", "```py\nint[] indices = attSelect.selectedAttributes(); \nSystem.out.println(Utils.arrayToString(indices)); \n```", "```py\n12,3,7,2,0,1,8,9,13,4,11,5,15,10,6,14,16 \n```", "```py\nJ48 tree = new J48(); \nString[] options = new String[1]; \noptions[0] = \"-U\"; \n\ntree.setOptions(options); \n```", "```py\ntree.buildClassifier(data); \n```", "```py\nSystem.out.println(tree); \n```", "```py\n    J48 unpruned tree\n    ------------------\n\n    feathers = false\n    |   milk = false\n    |   |   backbone = false\n    |   |   |   airborne = false\n    |   |   |   |   predator = false\n    |   |   |   |   |   legs <= 2: invertebrate (2.0)\n    |   |   |   |   |   legs > 2: insect (2.0)\n    |   |   |   |   predator = true: invertebrate (8.0)\n    |   |   |   airborne = true: insect (6.0)\n    |   |   backbone = true\n    |   |   |   fins = false\n    |   |   |   |   tail = false: amphibian (3.0)\n    |   |   |   |   tail = true: reptile (6.0/1.0)\n    |   |   |   fins = true: fish (13.0)\n    |   milk = true: mammal (41.0)\n    feathers = true: bird (20.0)\n\n    Number of Leaves  : 9\n\n    Size of the tree : 17\n\n```", "```py\nTreeVisualizer tv = new TreeVisualizer(null, tree.graph(), new PlaceNode2()); \nJFrame frame = new javax.swing.JFrame(\"Tree Visualizer\"); \nframe.setSize(800, 500); \nframe.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); \nframe.getContentPane().add(tv); \nframe.setVisible(true); \ntv.fitToScreen(); \n```", "```py\ndouble[] vals = new double[data.numAttributes()]; \nvals[0] = 1.0; //hair {false, true} \nvals[1] = 0.0;  //feathers {false, true} \nvals[2] = 0.0;  //eggs {false, true} \nvals[3] = 1.0;  //milk {false, true} \nvals[4] = 0.0;  //airborne {false, true} \nvals[5] = 0.0;  //aquatic {false, true} \nvals[6] = 0.0;  //predator {false, true} \nvals[7] = 1.0;  //toothed {false, true} \nvals[8] = 1.0;  //backbone {false, true} \nvals[9] = 1.0;  //breathes {false, true} \nvals[10] = 1.0;  //venomous {false, true} \nvals[11] = 0.0;  //fins {false, true} \nvals[12] = 4.0;  //legs INTEGER [0,9] \nvals[13] = 1.0;  //tail {false, true} \nvals[14] = 1.0;  //domestic {false, true} \nvals[15] = 0.0;  //catsize {false, true} \nDenseInstance myUnicorn = new DenseInstance(1.0, vals);\nmyUnicorn.setDataset(data); \n```", "```py\ndouble result = tree.classifyInstance(myUnicorn); \nSystem.out.println(data.classAttribute().value((int) result)); \n```", "```py\nClassifier cl = new J48(); \nEvaluation eval_roc = new Evaluation(data); \neval_roc.crossValidateModel(cl, data, 10, new Random(1), new Object[] {}); \nSystem.out.println(eval_roc.toSummaryString()); \n```", "```py\n    Correctly Classified Instances          93               92.0792 %\n    Incorrectly Classified Instances         8                7.9208 %\n    Kappa statistic                          0.8955\n    Mean absolute error                      0.0225\n    Root mean squared error                  0.14  \n    Relative absolute error                 10.2478 %\n    Root relative squared error             42.4398 %\n    Coverage of cases (0.95 level)          96.0396 %\n    Mean rel. region size (0.95 level)      15.4173 %\n    Total Number of Instances              101  \n\n```", "```py\ndouble[][] confusionMatrix = eval_roc.confusionMatrix(); \nSystem.out.println(eval_roc.toMatrixString()); \n```", "```py\n    === Confusion Matrix ===\n\n      a  b  c  d  e  f  g   <-- classified as\n     41  0  0  0  0  0  0 |  a = mammal\n      0 20  0  0  0  0  0 |  b = bird\n      0  0  3  1  0  1  0 |  c = reptile\n      0  0  0 13  0  0  0 |  d = fish\n      0  0  1  0  3  0  0 |  e = amphibian\n      0  0  0  0  0  5  3 |  f = insect\n      0  0  0  0  0  2  8 |  g = invertebrate\n\n```", "```py\nFile irisFile = new File(\"data/iris.data.csv\");\nVersatileDataSource source = new CSVDataSource(irisFile, false, CSVFormat.DECIMAL_POINT);\n\nVersatileMLDataSet data = new VersatileMLDataSet(source); \ndata.defineSourceColumn(\"sepal-length\", 0, ColumnType.continuous); \ndata.defineSourceColumn(\"sepal-width\", 1, ColumnType.continuous); \ndata.defineSourceColumn(\"petal-length\", 2, ColumnType.continuous); \ndata.defineSourceColumn(\"petal-width\", 3, ColumnType.continuous); \n\nColumnDefinition outputColumn = data.defineSourceColumn(\"species\", 4, ColumnType.nominal);\ndata.analyze(); \n```", "```py\ndata.defineSingleOutputOthersInput(outputColumn); \n\nEncogModel model = new EncogModel(data); \nmodel.selectMethod(data, MLMethodFactory.TYPE_FEEDFORWARD);\n\nmodel.setReport(new ConsoleStatusReportable()); \ndata.normalize(); \n```", "```py\nmodel.holdBackValidation(0.3, true, 1001);\n```", "```py\nmodel.selectTrainingType(data); \nMLRegression bestMethod = (MLRegression)model.crossvalidate(5, true); \n```", "```py\nSystem.out.println( \"Training error: \" + EncogUtility.calculateRegressionError(bestMethod, model.getTrainingDataset())); \nSystem.out.println( \"Validation error: \" + EncogUtility.calculateRegressionError(bestMethod, model.getValidationDataset())); \n```", "```py\nwhile(csv.next()) { \n            StringBuilder result = new StringBuilder(); \n            line[0] = csv.get(0); \n            line[1] = csv.get(1); \n            line[2] = csv.get(2); \n            line[3] = csv.get(3); \n            String correct = csv.get(4); \n            helper.normalizeInputVector(line,input.getData(),false); \n            MLData output = bestMethod.compute(input); \n            String irisChosen = helper.denormalizeOutputVectorToString(output)[0]; \n\n            result.append(Arrays.toString(line)); \n            result.append(\" -> predicted: \"); \n            result.append(irisChosen); \n            result.append(\"(correct: \"); \n            result.append(correct); \n            result.append(\")\"); \n\n            System.out.println(result.toString()); \n        } \n```", "```py\n$ java -cp moa.jar -javaagent:sizeofag.jar moa.gui.GUI\n```", "```py\nX1;X2;X3;X4;X5;X6;X7;X8;Y1;Y2;; \n0,98;514,50;294,00;110,25;7,00;2;0,00;0;15,55;21,33;; \n0,98;514,50;294,00;110,25;7,00;3;0,00;0;15,55;21,33;; \n```", "```py\n0,62;808,50;367,50;220,50;3,50;5;0,40;5;16,64;16,03;; \n;;;;;;;;;;; \n;;;;;;;;;;; \n```", "```py\nimport weka.core.Instances; \nimport weka.core.converters.CSVLoader; \nimport java.io.File; \nimport java.io.IOException; \n\npublic class EnergyLoad { \n\n  public static void main(String[] args) throws IOException { \n\n    // load CSV \n    CSVLoader loader = new CSVLoader();\n    loader.setFieldSeparator(\",\"); \n    loader.setSource(new File(\"data/ENB2012_data.csv\")); \n    Instances data = loader.getDataSet(); \n\n    System.out.println(data); \n  } \n} \n```", "```py\ndata.setClassIndex(data.numAttributes() - 2); \n```", "```py\n//remove last attribute Y2 \nRemove remove = new Remove(); \nremove.setOptions(new String[]{\"-R\", data.numAttributes()+\"\"}); \nremove.setInputFormat(data);\ndata = Filter.useFilter(data, remove); \n```", "```py\nimport weka.classifiers.functions.LinearRegression; \n... \ndata.setClassIndex(data.numAttributes() - 2);\nLinearRegression model = new LinearRegression(); \nmodel.buildClassifier(data); \nSystem.out.println(model);\n```", "```py\n    Y1 =\n\n        -64.774  * X1 +\n         -0.0428 * X2 +\n          0.0163 * X3 +\n         -0.089  * X4 +\n          4.1699 * X5 +\n         19.9327 * X7 +\n          0.2038 * X8 +\n         83.9329\n\n```", "```py\nEvaluation eval = new Evaluation(data); \neval.crossValidateModel(model, data, 10, new Random(1), new String[]{}); \nSystem.out.println(eval.toSummaryString()); \n```", "```py\nCorrelation coefficient                  0.956  \nMean absolute error                      2.0923 \nRoot mean squared error                  2.9569 \nRelative absolute error                 22.8555 % \nRoot relative squared error             29.282  % \nTotal Number of Instances              768      \n```", "```py\nFile datafile = new File(\"data/ENB2012_data.csv\");\nVersatileDataSource source = new CSVDataSource(datafile, true, CSVFormat.DECIMAL_POINT);\nVersatileMLDataSet data = new VersatileMLDataSet(source); \ndata.defineSourceColumn(\"X1\", 0, ColumnType.continuous); \ndata.defineSourceColumn(\"X2\", 1, ColumnType.continuous); \ndata.defineSourceColumn(\"X3\", 2, ColumnType.continuous); \ndata.defineSourceColumn(\"X4\", 3, ColumnType.continuous);\ndata.defineSourceColumn(\"X5\", 4, ColumnType.continuous);\ndata.defineSourceColumn(\"X6\", 5, ColumnType.continuous);\ndata.defineSourceColumn(\"X7\", 6, ColumnType.continuous);\ndata.defineSourceColumn(\"X8\", 7, ColumnType.continuous);\n```", "```py\nColumnDefinition outputColumn1 = data.defineSourceColumn(\"Y1\", 8,    ColumnType.continuous);\nColumnDefinition outputColumn2 = data.defineSourceColumn(\"Y2\", 9,  ColumnType.continuous);\nColumnDefinition outputscol [] = {outputColumn1, outputColumn2};\ndata.analyze();\n\ndata.defineMultipleOutputsOthersInput(outputscol);\n```", "```py\nEncogModel model = new EncogModel(data); \nmodel.selectMethod(data, MLMethodFactory.TYPE_FEEDFORWARD);\nmodel.setReport(new ConsoleStatusReportable());\n\ndata.normalize();\nmodel.holdBackValidation(0.3, true, 1001);\nmodel.selectTrainingType(data);\nMLRegression bestMethod = (MLRegression)model.crossvalidate(5, true);            \nNormalizationHelper helper = data.getNormHelper(); \n\nSystem.out.println(helper.toString()); \nSystem.out.println(\"Final model: \" + bestMethod); \n```", "```py\n$ java -cp moa.jar -javaagent:sizeofag-1.0.4.jar moa.gui.GUI\n```", "```py\nimport weka.classifiers.trees.M5P; \n... \nM5P md5 = new M5P(); \nmd5.setOptions(new String[]{\"\"}); \nmd5.buildClassifier(data);  \nSystem.out.println(md5); \n```", "```py\n    M5 pruned model tree:\n    (using smoothed linear models)\n\n    X1 <= 0.75 : \n    |   X7 <= 0.175 : \n    |   |   X1 <= 0.65 : LM1 (48/12.841%)\n    |   |   X1 >  0.65 : LM2 (96/3.201%)\n    |   X7 >  0.175 : \n    |   |   X1 <= 0.65 : LM3 (80/3.652%)\n    |   |   X1 >  0.65 : LM4 (160/3.502%)\n    X1 >  0.75 : \n    |   X1 <= 0.805 : LM5 (128/13.302%)\n    |   X1 >  0.805 : \n    |   |   X7 <= 0.175 : \n    |   |   |   X8 <= 1.5 : LM6 (32/20.992%)\n    |   |   |   X8 >  1.5 : \n    |   |   |   |   X1 <= 0.94 : LM7 (48/5.693%)\n    |   |   |   |   X1 >  0.94 : LM8 (16/1.119%)\n    |   |   X7 >  0.175 : \n    |   |   |   X1 <= 0.84 : \n    |   |   |   |   X7 <= 0.325 : LM9 (20/5.451%)\n    |   |   |   |   X7 >  0.325 : LM10 (20/5.632%)\n    |   |   |   X1 >  0.84 : \n    |   |   |   |   X7 <= 0.325 : LM11 (60/4.548%)\n    |   |   |   |   X7 >  0.325 : \n    |   |   |   |   |   X3 <= 306.25 : LM12 (40/4.504%)\n    |   |   |   |   |   X3 >  306.25 : LM13 (20/6.934%)\n\n    LM num: 1\n    Y1 = \n      72.2602 * X1 \n      + 0.0053 * X3 \n      + 11.1924 * X7 \n      + 0.429 * X8 \n      - 36.2224\n\n    ...\n\n    LM num: 13\n    Y1 = \n      5.8829 * X1 \n      + 0.0761 * X3 \n      + 9.5464 * X7 \n      - 0.0805 * X8 \n      + 2.1492\n\n    Number of Rules : 13\n\n```", "```py\n    Correlation coefficient                  0.9943\n    Mean absolute error                      0.7446\n    Root mean squared error                  1.0804\n    Relative absolute error                  8.1342 %\n    Root relative squared error             10.6995 %\n    Total Number of Instances              768     \n```", "```py\nimport java.io.BufferedReader; \nimport java.io.FileReader; \n\nimport weka.core.Instances; \nimport weka.clusterers.EM; \n\npublic class Clustering { \n\n  public static void main(String args[]) throws Exception{ \n\n    //load data \n    Instances data = new Instances(new BufferedReader\n       (new FileReader(\"data/bank-data.arff\"))); \n\n    // new instance of clusterer \n    EM model = new EM(); \n    // build the clusterer \n    model.buildClusterer(data); \n    System.out.println(model); \n\n  } \n} \n```", "```py\n    EM\n    ==\n\n    Number of clusters selected by cross validation: 6\n\n                     Cluster\n    Attribute              0        1        2        3        4        5\n                       (0.1)   (0.13)   (0.26)   (0.25)   (0.12)   (0.14)\n    ======================================================================\n    age\n      0_34            10.0535  51.8472 122.2815  12.6207   3.1023   1.0948\n      35_51           38.6282  24.4056  29.6252  89.4447  34.5208   3.3755\n      52_max          13.4293    6.693   6.3459  50.8984   37.861  81.7724\n      [total]         62.1111  82.9457 158.2526 152.9638  75.4841  86.2428\n    sex\n      FEMALE          27.1812  32.2338  77.9304  83.5129  40.3199  44.8218\n      MALE            33.9299  49.7119  79.3222  68.4509  34.1642   40.421\n      [total]         61.1111  81.9457 157.2526 151.9638  74.4841  85.2428\n    region\n      INNER_CITY      26.1651  46.7431   73.874  60.1973  33.3759  34.6445\n      TOWN            24.6991  13.0716  48.4446  53.1731   21.617  17.9946\n    ...\n\n```", "```py\ndouble logLikelihood = ClusterEvaluation.crossValidateModel(model, data, 10, new Random(1));\nSystem.out.println(logLikelihood);  \n```", "```py\n-8.773410259774291 \n```", "```py\nDATA = { { 28, 15, 22 }, { 16, 15, 32 }, { 32, 20, 44 }, { 1, 2, 3 }, { 3, 2, 1 } };\n```", "```py\nBasicMLDataSet set = new BasicMLDataSet();\n\nfor (final double[] element : DATA) {\n    set.add(new BasicMLData(element));\n}\n```", "```py\nKMeansClustering kmeans = new KMeansClustering(2, set);\n\nkmeans.iteration(100);\n\n// Display the cluster\nint i = 1;\nfor (MLCluster cluster : kmeans.getClusters()) {\n    System.out.println(\"*** Cluster \" + (i++) + \" ***\");\n    final MLDataSet ds = cluster.createDataSet();\n    final MLDataPair pair = BasicMLDataPair.createPair(ds.getInputSize(), ds.getIdealSize());\n    for (int j = 0; j < ds.getRecordCount(); j++) {\n        ds.getRecord(j, pair);\n        System.out.println(Arrays.toString(pair.getInputArray()));\n        }\n    }\n```", "```py\n*** Cluster 1 ***\n[16.0, 15.0, 32.0]\n[1.0, 2.0, 3.0]\n[3.0, 2.0, 1.0]\n*** Cluster 2 ***\n[28.0, 15.0, 22.0]\n*** Cluster 3 ***\n[32.0, 20.0, 44.0]\n```", "```py\n$ java -jar elki-bundle-0.7.1.jar \n```"]