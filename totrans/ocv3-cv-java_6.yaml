- en: Chapter 6. Detecting Foreground and Background Regions and Depth with a Kinect
    Device
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 使用Kinect设备检测前景和背景区域及深度
- en: In the field of video security applications, one often needs to notice the differences
    between frames because that's where the action happens. In other fields, it is
    also very important to isolate the objects from the background. This chapter shows
    several techniques to achieve this goal, comparing their strengths and weaknesses.
    Another completely different approach for detecting foreground or background regions
    is using a depth device like a **Kinect**. This chapter also deals with how to
    accomplish this goal with this device.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在视频安全应用领域，人们常常需要注意到帧之间的差异，因为那里是动作发生的地方。在其他领域，将对象从背景中分离出来也非常重要。本章展示了实现这一目标的一些技术，并比较了它们的优缺点。检测前景或背景区域的一种完全不同的方法是使用深度设备，如**Kinect**。本章还讨论了如何使用该设备实现这一目标。
- en: 'In this chapter, we will be covering:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Background subtraction
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 背景减法
- en: Frame differencing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帧差分
- en: Averaging background method
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均背景法
- en: Mixture of Gaussian's method
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高斯混合法
- en: Contour finding
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等高线查找
- en: Kinect depth maps
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kinect深度图
- en: By the end of this chapter, you will have several approaches solving the problem
    of finding foreground/background regions, either through direct image processing
    or using a depth-compatible device such as a Kinect.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将拥有几种解决查找前景/背景区域问题的方法，无论是通过直接图像处理还是使用与深度兼容的设备，如Kinect。
- en: Background subtraction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景减法
- en: When working with surveillance cameras, it's easy to see that most of the frame
    keeps still, while the moving objects, the ones we are interested in, are the
    areas that vary most over time. Background subtraction is defined as the approach
    used to detect moving objects from static cameras, also known as **foreground
    detection**, since we're mostly interested in the foreground objects.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当与监控摄像头一起工作时，很容易看出大多数帧保持静止，而移动的对象，即我们感兴趣的对象，是随时间变化最大的区域。背景减法被定义为从静态摄像头检测移动对象的方法，也称为**前景检测**，因为我们主要对前景对象感兴趣。
- en: In order to perform some valuable background subtraction, it is important to
    account for varying luminance conditions, taking care always to update our background
    model. Although some techniques extend the idea of background subtraction beyond
    its literal meaning, such as the mixture of Gaussian approach, they are still
    named like this.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行一些有价值的背景减法，重要的是要考虑到变化的亮度条件，并始终注意更新我们的背景模型。尽管一些技术将背景减法的概念扩展到其字面意义之外，例如高斯混合方法，但它们仍然被这样命名。
- en: 'In order to compare all the solutions in the following sections, we will come
    up with a useful interface, which is called **VideoProcessor**. This interface
    is made of a simple method called **process**. The whole interface is given in
    the following piece of code:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较以下章节中的所有解决方案，我们将提出一个有用的接口，称为**VideoProcessor**。此接口由一个简单的名为**process**的方法组成。整个接口在以下代码片段中给出：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that we will implement this interface in the following background processors
    so that we can easily change them and compare their results. In this context,
    `Mat inputImage` refers to the current frame in the video sequence being processed.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们将在以下背景处理器中实现此接口，这样我们可以轻松地更改它们并比较它们的结果。在此上下文中，`Mat inputImage`指的是正在处理的视频序列中的当前帧。
- en: All the code related to background subtraction can be found in the `background`
    project, available in the `chapter6` reference code.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所有与背景减法相关的代码都可以在`background`项目中找到，该项目位于`chapter6`参考代码中。
- en: 'Our main application consists of two windows. One of them simply plays back
    the input video or the webcam stream, while the other one shows the output of
    applying a background subtractor that implements the `VideoProcessor` interface.
    This way, our main loop looks pretty much like the following code:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要应用由两个窗口组成。其中一个简单地回放输入视频或网络摄像头流，而另一个显示应用了实现`VideoProcessor`接口的背景减法器的输出。这样，我们的主循环看起来大致如下代码：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that upon successful image retrieval, we pass it to our `VideoProcessor`
    and update our windows. We also sleep for 10 ms so that the video playback will
    not look like a fast forward. This 10 ms delay is not the recorded frame delay
    and it is used because the focus here is not to play back at the same speed as
    the original file. In order to try the different subtraction approaches, we simply
    change the instantiation of our `VideoProcessor` class.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在成功检索图像后，我们将其传递给我们的 `VideoProcessor` 并更新我们的窗口。我们还暂停了 10 毫秒，以便视频播放不会看起来像快进。这个
    10 毫秒的延迟不是记录的帧延迟，它被使用是因为这里的重点不是以原始文件相同的速度播放。为了尝试不同的减法方法，我们只需更改我们的 `VideoProcessor`
    类的实例化。
- en: Frame differencing
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 帧差分
- en: 'It should be straightforward to think of a simple background subtraction in
    order to retrieve foreground objects. A simple solution could look similar to
    the following line of code:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检索前景对象，简单地考虑一个简单的背景减法应该是直截了当的。一个简单的解决方案可能看起来像以下代码行：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This function simply subtracts each pixel of `backgroundImage` from `inputImage`
    and writes its absolute value in `foregroundImage`. As long as we have initialized
    the background to `backgroundImage` and we have that clear from objects, this
    could work as a simple solution.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数简单地从 `backgroundImage` 中减去 `inputImage` 的每个像素，并将绝对值写入 `foregroundImage`。只要我们初始化了背景为
    `backgroundImage`，并且我们清楚地从对象中分离出来，这就可以作为一个简单的解决方案。
- en: 'Here follows the background subtraction video processor code:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是背景减法视频处理器代码：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The main method, `process`, is really simple. It only applies the absolute difference
    method. The only detail to remember is to initialize the background image in the
    constructor, which should correspond to the whole background being free from the
    foreground objects.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 主要方法，`process`，实际上非常简单。它仅应用绝对差分方法。唯一需要记住的细节是在构造函数中初始化背景图像，它应该对应整个背景没有前景对象。
- en: 'We can see the output of applying ordinary background subtraction in the following
    image; it is important to check that the moving leaves in the background are not
    correctly removed since this is a weak background modeling. Also, remember to
    move the **Video Playback Example** window as it might be covering the **Background
    Removal Example** window:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下图像中看到应用普通背景减法的结果；重要的是要检查背景中的移动树叶是否被正确移除，因为这是一个弱背景建模。此外，记得移动**视频播放示例**窗口，因为它可能会覆盖**背景移除示例**窗口：
- en: '![Frame differencing](img/3972OS_06_01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![帧差分](img/3972OS_06_01.jpg)'
- en: Averaging a background method
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景平均方法
- en: The problem with the background subtractor from the previous section is that
    the background will generally change due to illumination and other effects. Another
    fact is that the background may not be readily available, or the concept of background
    can change, for instance, when someone leaves a luggage in a video surveillance
    application. The luggage might be a foreground object for the first frames, but
    afterwards, it should be forgotten.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节中背景减法器的问题在于背景通常会因为光照和其他效果而改变。另一个事实是背景可能不容易获得，或者背景的概念可能改变，例如，当有人在视频监控应用中留下行李时。行李可能是第一帧的前景对象，但之后，它应该被遗忘。
- en: 'An interesting algorithm to deal with these problems uses the running average
    concept. Instead of always using the first frame as a clear background, it will
    update it constantly by calculating a moving average of it. Consider the following
    equation, which will be executed, updating each pixel from the old average and
    considering each pixel from the recently acquired image:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的算法用于处理这些问题，它使用了运行平均的概念。它不是总是使用第一帧作为清晰的背景，而是通过计算其移动平均来不断更新它。考虑以下方程，它将被执行，更新每个像素从旧的平均值，并考虑从最近获取的图像中的每个像素：
- en: '![Averaging a background method](img/3972OS_06_11.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![背景平均方法](img/3972OS_06_11.jpg)'
- en: Note that ![Averaging a background method](img/3972OS_06_12.jpg) is the new
    pixel value; ![Averaging a background method](img/3972OS_06_13.jpg) is the value
    of the average background at time `t-1`, which would be the last frame; ![Averaging
    a background method](img/3972OS_06_14.jpg) is the new value for the background;
    and ![Averaging a background method](img/3972OS_06_15.jpg) is the learning rate.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，![背景平均方法](img/3972OS_06_12.jpg) 是新的像素值；![背景平均方法](img/3972OS_06_13.jpg) 是时间
    `t-1` 的平均背景值，这将是最后一帧；![背景平均方法](img/3972OS_06_14.jpg) 是背景的新值；而 ![背景平均方法](img/3972OS_06_15.jpg)
    是学习率。
- en: 'Fortunately, OpenCV already has the `accumulateWeighted` function, which performs
    the last equation for us. Now let''s see how the average background process is
    implemented in the `RunningAverageBackground` class as we check its `process`
    method as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，OpenCV 已经有了 `accumulateWeighted` 函数，它为我们执行最后一个方程。现在让我们看看在检查 `RunningAverageBackground`
    类的 `process` 方法时，平均背景过程是如何在 `RunningAverageBackground` 类中实现的：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: First, we convert the input image to gray level since we will store the average
    background like this, although we could make it with three channels. Then, if
    the accumulated background hasn't been started, we will have to set it to the
    first input image in the floating point format. Then we subtract the recently
    acquired frame from the accumulated background, which yields our foreground image,
    which we later threshold in order to remove small illumination or noisy changes.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将输入图像转换为灰度级别，因为我们将以这种方式存储平均背景，尽管我们也可以使用三个通道来实现。然后，如果累积背景尚未开始，我们必须将其设置为第一个输入图像的浮点格式。然后我们从累积背景中减去最近获取的帧，从而得到我们的前景图像，我们稍后会对其进行阈值处理以去除小的光照变化或噪声。
- en: Note that this time we use `Imgproc.THRESH_BINARY_INV`, which turns every pixel
    above the given threshold black, yielding black pixels for the foreground objects
    and white pixels for the background.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这次我们使用的是 `Imgproc.THRESH_BINARY_INV`，它将所有高于给定阈值的像素转换为黑色，从而为前景对象生成黑色像素，为背景生成白色像素。
- en: This way, we can use this image as a mask for updating only background pixels
    when using the `acccumulateWeighted` method later. On the following line, we only
    convert `inputImage` to `inputFloating` so that we can have it in the floating
    point format. We then use `accumulateWeighted` to apply our commented equation
    for the running average. Finally, we invert the image and return our foreground
    objects as white pixels.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就可以使用这张图像作为掩模，在以后使用 `accumulateWeighted` 方法时只更新背景像素。在下一行，我们只转换 `inputImage`
    为 `inputFloating`，这样我们就可以以浮点格式拥有它。然后我们使用 `accumulateWeighted` 应用我们的注释方程进行运行平均值。最后，我们反转图像并返回作为白色像素的前景对象。
- en: 'We can see a better modeling of the moving leaves on the background in the
    following image. Although thresholding makes it harder to compare these results
    with simple background subtraction, it is clear that lots of moving leaves have
    been removed. Besides, a good part of the hand has also been swept away. A careful
    tuning of the threshold parameter can be used for better results as shown in the
    following screenshot:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图像中，我们可以看到对背景中移动的叶子的更好建模。尽管阈值处理使得将这些结果与简单的背景减法进行比较变得困难，但很明显，许多移动的叶子已经被移除。此外，大部分手也被清除。可以通过调整阈值参数来获得更好的结果，如下面的截图所示：
- en: '![Averaging a background method](img/3972OS_06_02.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![平均背景方法](img/3972OS_06_02.jpg)'
- en: The mixture of Gaussians method
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高斯混合方法
- en: Although we can get very good results with the previous idea, some more advanced
    methods have been proposed in literature. A great approach, proposed by Grimson
    in 1999, is to use not just one running average, but more averages so that if
    a pixel fluctuates between the two orbit points, these two running averages are
    calculated. If it does not fit any of them, it is considered foreground.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们可以通过前面的想法获得非常好的结果，但文献中已经提出了更多先进的方法。1999 年，Grimson 提出的一种伟大方法是使用不止一个运行平均值，而是更多平均值，这样如果像素在两个轨道点之间波动，这两个运行平均值都会被计算。如果它不符合任何一个，则被认为是前景。
- en: Besides, Grimson's approach also keeps the variance of the pixels, which is
    a measure of how far a set of numbers is spread out, taken from statistics. With
    a mean and a variance, a Gaussian model can be calculated and a probability can
    be measured to be taken into consideration, yielding a **Mixture of Gaussians
    model** (**MOG**). This can be very useful when branches and leaves are moving
    in the background.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Grimson 的方法还保留了像素的方差，这是衡量一组数字分布程度的统计量。有了平均值和方差，我们可以计算出高斯模型，并测量一个概率以供考虑，从而得到一个**高斯混合模型**（**MOG**）。当背景中的树枝和叶子移动时，这可以非常有用。
- en: Unfortunately, Grimson's method suffers from slow learning in the beginning
    and it can not distinguish between the moving shadows and moving objects. Therefore,
    an improved technique has been published by KaewTraKulPong and Bowden to tackle
    these problems. This one is implemented in OpenCV and it is quite straightforward
    to use it by means of the `BackgroundSubtractorMOG2` class.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Grimson的方法在开始时学习速度较慢，并且无法区分移动的阴影和移动的对象。因此，KaewTraKulPong和Bowden发布了一种改进技术来解决这些问题。这个技术已经在OpenCV中实现，并且通过`BackgroundSubtractorMOG2`类使用它非常简单。
- en: 'In order to show how effective is the mixture of Gaussians approach, we have
    implemented a `BackgroundSubtractorMOG2`-based `VideoProcessor`. Its entire code
    is as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示高斯混合方法的有效性，我们实现了一个基于`BackgroundSubtractorMOG2`的`VideoProcessor`。其完整代码如下：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Note that we only need to instantiate the `BackgroundSubtractorMOG2` class
    and use the `apply` method, passing the input frame, the output image, and a learning
    rate that will tell how fast it should learn the new background. Besides the factory
    method without parameters, another one exists with the following signature:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们只需要实例化`BackgroundSubtractorMOG2`类并使用`apply`方法，传递输入帧、输出图像以及一个学习率，这个学习率将告诉算法以多快的速度学习新的背景。除了无参数的工厂方法外，还有一个具有以下签名的工厂方法：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here, `history` is the length of the history, `varThreshold` is the threshold
    on the squared Mahalanobis distance between the pixel and the model to decide
    whether a pixel is well described by the background model, and if `detectShadows`
    is `true`, the algorithm will detect and mark the shadows. If we do not set parameters
    by using the empty constructor, the following values are used by default:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`history`是历史长度，`varThreshold`是像素与模型之间的平方马氏距离的阈值，用于决定像素是否被背景模型很好地描述，如果`detectShadows`为`true`，则算法将检测并标记阴影。如果我们不使用空构造函数设置参数，则默认使用以下值：
- en: '`defaultHistory = 500;`'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`defaultHistory = 500;`'
- en: '`varThreshold = 16;`'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`varThreshold = 16;`'
- en: '`detectShadows = true;`'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detectShadows = true;`'
- en: Try playing with these values in order to look for better results when making
    background subtraction.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试调整这些值以在执行背景减法时寻找更好的结果。
- en: '![The mixture of Gaussians method](img/3972OS_06_03.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![高斯混合方法](img/3972OS_06_03.jpg)'
- en: 'In the preceding screenshot, we can clearly see a great background removal
    result with very little customization. Although some leaves still account for
    noise in the removed background result, we can see a good amount of the hand being
    correctly identified as foreground. A simple open morphological operator can be
    applied to remove some of the noise, as seen in the following screenshot:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，我们可以清楚地看到一个非常出色的背景去除结果，且几乎无需任何定制。尽管一些叶子仍然在去除的背景结果中造成噪声，但我们仍可以看到大量手部被正确地识别为前景。可以应用一个简单的开形态算子来去除一些噪声，如下面的截图所示：
- en: '![The mixture of Gaussians method](img/3972OS_06_04.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![高斯混合方法](img/3972OS_06_04.jpg)'
- en: Contour finding
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 轮廓查找
- en: When dealing with the binary images removed from the background, it is important
    to transform pixels into useful information, such as by grouping them into an
    object or making it very clear for the user to see. In this context, it is important
    to know the concept of connected components, which are a set of connected pixels
    in a binary image, and OpenCV's function used to find its contours.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理从背景中去除的二值图像时，将像素转换为有用的信息非常重要，例如通过将它们组合成一个对象或让用户非常清楚地看到。在这种情况下，了解连通组件的概念非常重要，连通组件是在二值图像中连接的像素集，以及OpenCV用于找到其轮廓的函数。
- en: In this section, we will examine the `findContours` function, which extracts
    contours of connected components in an image as well as a helper function that
    will draw contours in an image, which is `drawContours`. The `findContours` function
    is generally applied over an image that has gone through a threshold procedure
    as well as some canny image transformation. In our example, a threshold is used.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将检查`findContours`函数，该函数提取图像中连通组件的轮廓以及一个辅助函数，该函数将在图像中绘制轮廓，即`drawContours`。`findContours`函数通常应用于经过阈值处理以及一些Canny图像变换的图像。在我们的例子中，使用了阈值。
- en: 'The `findContours` function has the following signature:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`findContours`函数具有以下签名：'
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It is implemented using Suzuki's algorithm described in his paper *Topological
    structural analysis of digitized binary images by border following*. The first
    parameter is the input image. Make sure you work on a copy of your target image
    since this function alters the image. Also, beware that the 1 pixel border of
    the image is not considered. The contours that are found are stored in the list
    of `MatOfPoints`. This is simply a structure that stores points in a matrix.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 它使用Suzuki在其论文《通过边界跟踪对数字化二值图像进行拓扑结构分析》中描述的算法实现。第一个参数是输入图像。确保您在目标图像的副本上工作，因为此函数会更改图像。此外，请注意，图像的1像素边界不被考虑。找到的轮廓存储在`MatOfPoints`列表中。这是一个简单地以矩阵形式存储点的结构。
- en: '`Mat hierarchy` is an optional output vector that is set for each contour found.
    They represent 0-based indices of the next and previous contours at the same hierarchical
    level, the first child contour, and the parent contour, represented in the `hierarcy[i][0]`,
    `hierarcy[i][1]`, `hierarcy[i][2]`, and `hierarcy[i][3]` elements, respectively
    for a given `i` contour. If there aren''t contours corresponding to those values,
    they will be negative.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`Mat hierarchy`是一个可选的输出向量，为每个找到的轮廓设置。它们代表同一层次级别中下一个和前一个轮廓的0基于索引，第一个子轮廓和父轮廓，分别用`hierarcy[i][0]`、`hierarcy[i][1]`、`hierarcy[i][2]`和`hierarcy[i][3]`元素表示，对于给定的`i`轮廓。如果没有与这些值对应的轮廓，它们将是负数。'
- en: The `mode` parameter deals with how the hierarchical relationships are established.
    If this is not interesting to you, you can set it as `Imgproc.RETR_LIST`. When
    retrieving the contours, the `method` parameter controls how they are approximated.
    If `Imgproc.CHAIN_APPROX_NONE` is set, all the contour points are stored. On the
    other hand, when using `Imgproc.CHAIN_APPROX_SIMPLE` for this value, horizontal,
    vertical, and diagonal lines are compressed by using only their endpoints. Other
    approximations are available as well.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`mode`参数处理层次关系是如何建立的。如果您对此不感兴趣，可以将其设置为`Imgproc.RETR_LIST`。在检索轮廓时，`method`参数控制它们是如何近似的。如果将`Imgproc.CHAIN_APPROX_NONE`设置为，则存储所有轮廓点。另一方面，当使用`Imgproc.CHAIN_APPROX_SIMPLE`为此值时，通过仅使用它们的端点压缩水平、垂直和对角线线。还有其他近似方法可用。'
- en: 'In order to draw the obtained contours outline or fill them, Imgproc''s `drawContours`
    is used. This function has the following signature:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了绘制获取到的轮廓轮廓或填充它们，使用Imgproc的`drawContours`函数。此函数具有以下签名：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`Mat image` is simply the destination image, while the list of `MatOfPoint`
    contours is the one obtained while calling `findContours`. The `contourIdx` property
    is the one intended to be drawn, while `color` is the desired color for drawing.
    Overloaded functions are also available in which the user can choose the thickness,
    line type, hierarchy max level, and an offset.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`Mat image`是目标图像，而`MatOfPoint`轮廓列表是在调用`findContours`时获得的。`contourIdx`属性是要绘制的属性，而`color`是绘制所需的颜色。还有重载函数，用户可以选择厚度、线型、层次结构最大级别和偏移量。'
- en: 'When deciding on which contours are interesting, a useful function to help
    in that decision is to find the contour area. OpenCV implements this function
    through `Imgproc.contourArea`. This function can be found in the `chapter6` source
    code''s sample `connected` project. This application takes an image as input,
    runs a threshold over it and then uses it for finding the contours. Several options
    are available for testing the functions discussed in this section, such as whether
    it is filling the contour or painting the contour according to the area found.
    The following is a screenshot of this application:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定哪些轮廓有趣时，一个有用的函数可以帮助做出这个决定，那就是找到轮廓面积。OpenCV通过`Imgproc.contourArea`实现此功能。此函数可以在`chapter6`源代码的示例`connected`项目中找到。此应用程序接受一个图像作为输入，对其运行阈值，然后使用它来查找轮廓。本节讨论的函数有几个测试选项，例如是否填充轮廓或根据找到的面积绘制轮廓。以下是此应用程序的屏幕截图：
- en: '![Contour finding](img/3972OS_06_05.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![轮廓查找](img/3972OS_06_05.jpg)'
- en: 'When dealing with contours, it is also important to draw shapes around them
    in order to make measures or highlight what is found. The sample application also
    offers some code with instructions on how to draw a bounding box, circle, or convex
    hull around the contour. Let''s take a look at the main `drawContours()` function,
    which is called upon pressing the button:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理轮廓时，围绕它们绘制形状也很重要，以便进行测量或突出显示找到的内容。示例应用程序还提供了一些代码，说明如何围绕轮廓绘制边界框、圆形或凸包。让我们看看主要的`drawContours()`函数，该函数在按下按钮时被调用：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We firstly clone our target binary image, so we won''t change it. Then, we
    initialize the `MatOfPoint` structure and define the thickness flag. We then run
    `findContours`, ignoring the output hierarchy matrix. It is time to iterate the
    contours in the `for` loop. We use the `Imgproc.contourArea` helper function for
    an area estimate. Based on that, if it is the previous `areaThreshold` defined
    by the slider, it is drawn as green using the `drawContours` function or else
    it is drawn as red. An interesting part of the code are the shape drawing functions,
    which are described as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先克隆我们的目标二进制镜像，这样我们就不会改变它。然后，我们初始化`MatOfPoint`结构并定义厚度标志。接下来，我们运行`findContours`，忽略输出层次矩阵。现在是时候在`for`循环中迭代轮廓了。我们使用`Imgproc.contourArea`辅助函数进行面积估计。基于此，如果它是之前通过滑块定义的`areaThreshold`，则使用`drawContours`函数将其绘制为绿色；否则，将其绘制为红色。代码中一个有趣的部分是形状绘制函数，具体描述如下：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Drawing a bounding box is simple; it is just a matter of calling `Imgproc.boundingRect()`
    in order to identify the shape's surrounding rectangle. Then, the Imgproc's `rectangle`
    function method is called to draw the rectangle itself.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制边界框很简单；只需调用`Imgproc.boundingRect()`以识别形状周围的矩形。然后，调用Imgproc的`rectangle`函数方法来绘制矩形本身。
- en: Drawing the enclosing circle is also easy due to the existence of the `minEnclosingCircle`
    function. The only caveat is converting `MatOfPoint` to `MatOfPoint2f`, which
    is accomplished by calling Contour's `convertTo`. The Imgproc's `circle` function
    deals with drawing it.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于存在`minEnclosingCircle`函数，绘制包围圆也很容易。唯一的注意事项是将`MatOfPoint`转换为`MatOfPoint2f`，这可以通过调用Contour的`convertTo`方法实现。Imgproc的`circle`函数负责绘制它。
- en: Finding the convex hull is a rather important problem from a computational geometry
    perspective. It can be seen as putting an elastic band around a set of points
    and checking the final shape it takes. Fortunately, OpenCV also deals with this
    problem through the Imgproc's `convexHull` function. Note that in the first and
    the second line of `drawConvexHull` in the preceding code, `MatOfInt` is created,
    and `convexHull` is called, passing the current contour and this matrix as parameters.
    This function will return convex hull indexes in `MatOfInt`. We can draw lines
    ourselves, based on the coordinates of these indexes from the original contour.
    Another idea is to use the OpenCV's `drawContour` function. In order to do this,
    you need to build a new contour. This is done in the following lines in the code
    until `drawContour` is called.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 从计算几何的角度来看，找到凸包是一个相当重要的问题。它可以看作是在一组点周围放置一个橡皮筋并检查它最终形成的形状。幸运的是，OpenCV也通过Imgproc的`convexHull`函数处理这个问题。注意，在前面的代码中`drawConvexHull`的第一行和第二行，创建了`MatOfInt`，并调用`convexHull`，将当前轮廓和这个矩阵作为参数传递。这个函数将返回凸包索引在`MatOfInt`中。我们可以根据这些索引的坐标从原始轮廓绘制线条。另一个想法是使用OpenCV的`drawContour`函数。为了做到这一点，你需要构建一个新的轮廓。这是在代码中的以下行中完成的，直到调用`drawContour`。
- en: Kinect depth maps
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kinect深度图
- en: From the beginning of this chapter until now, we have focused on the background
    subtraction approaches that try to model the background of the scene using ordinary
    cameras and then on applying frame differencing.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 从本章的开头到现在，我们一直专注于尝试使用普通摄像头对场景背景进行建模的背景减法方法，然后是应用帧差分。
- en: Note
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Although the Kinect is reported to work with Linux and OSX, this section deals
    only with Windows setup on OpenCV 2.4.7 version.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然据报道Kinect与Linux和OSX兼容，但本节仅涉及在OpenCV 2.4.7版本上对Windows的设置。
- en: 'In this section, we will take a different approach. We will set how far we
    want our objects to be considered foreground and background, which means removing
    the background by selecting a depth parameter. Unfortunately, this can not be
    done using a single ordinary camera in a single shot, so we will need a sensor
    that tells us the depth of objects or try to determine depth from stereo, which
    is not in the scope of this chapter. Thanks to both gamers and several efforts
    from all around the world, this device has become a commodity and it is called
    a **Kinect**. Some attempts can be made to use two cameras and try to get depth
    from stereo, but the results might not be as great as the ones with the Kinect
    sensor. Here is how it looks:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将采用不同的方法。我们将设置我们希望我们的物体被认为是前景和背景的距离，这意味着通过选择一个深度参数来移除背景。不幸的是，这不能通过一次拍摄使用单个普通相机来完成，因此我们需要一个能够告诉我们物体深度的传感器，或者尝试从立体视觉中确定深度，但这超出了本章的范围。多亏了游戏玩家和来自世界各地的许多努力，这种设备已经变成了商品，它被称为**Kinect**。可以尝试使用两个相机并尝试从立体视觉中获得深度，但结果可能不如使用Kinect传感器的结果那么好。以下是它的样子：
- en: '![Kinect depth maps](img/3972OS_06_06.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![Kinect深度图](img/3972OS_06_06.jpg)'
- en: 'What makes the Kinect really different from an average camera is that it includes
    an infrared emitter and an infrared sensor that are able to project and sense
    a structured light pattern. It also contains an ordinary VGA camera so that the
    depth data can be merged into it. The idea behind the structured light is that
    when projecting a known pattern of pixels on to the objects, the deformation of
    this pattern allows the computer vision systems to calculate the depth and surface
    information from them. If a camera capable of registering infrared is used to
    record the emitted Kinect pattern, an image similar to the following can be seen:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使Kinect真正区别于普通相机的是，它包括一个红外发射器和红外传感器，能够投影和感应结构光模式。它还包含一个普通的VGA相机，以便将深度数据合并到其中。结构光背后的想法是，当将已知的像素模式投影到物体上时，该模式的变形允许计算机视觉系统从这些模式中计算深度和表面信息。如果使用能够注册红外线的相机来记录发射的Kinect模式，可以看到类似以下图像：
- en: '![Kinect depth maps](img/3972OS_06_07.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![Kinect深度图](img/3972OS_06_07.jpg)'
- en: Although it might look like a random set of points, they are actually pseudo-random
    patterns that have been previously generated. These patterns can be identified
    and a disparity to depth relationship can be calculated, inferring the depth.
    More information can be acquired when studying structured light concepts if it
    is required.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它可能看起来像一组随机的点，但实际上它们是先前生成的伪随机模式。这些模式可以被识别，并且可以计算出深度与视差的关系，从而推断深度。如果需要，可以通过研究结构光概念来获取更多信息。
- en: One should be aware of the implications this method has. As it relies on active
    infrared projection, some outdoor effects, such as direct sunlight will confuse
    the sensors, so outdoor use is not recommended. Users should also be aware that
    the depth range is from 0.8 meters to 4.0 meters (roughly from 2.6 feet to 13.1
    feet). Some shadows related to the IR projection can also make the results not
    look as great as they should, and cause some noise in the images. Despite all
    these issues, it is one of the best results available for the near field background
    removal.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 应该意识到这种方法的影响。因为它依赖于主动红外投影，一些户外效果，如直射日光，会混淆传感器，因此不建议户外使用。用户还应该意识到深度范围是从0.8米到4.0米（大约从2.6英尺到13.1英尺）。与红外投影相关的某些阴影也可能使结果看起来不如应有的好，并在图像中产生一些噪声。尽管存在所有这些问题，但它是在近场背景移除方面最好的结果之一。
- en: The Kinect setup
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kinect设置
- en: Using a Kinect should be straightforward, but we need to consider two important
    aspects. First we need to be sure that all the device driver softwares are correctly
    installed for using them. Then we need to check whether OpenCV has been compiled
    with Kinect support. Unfortunately, if you have downloaded precompiled binaries
    of version 2.4.7 from [http://sourceforge.net/projects/opencvlibrary/files/](http://sourceforge.net/projects/opencvlibrary/files/),
    as described in the beginning of [Chapter 1](ch01.html "Chapter 1. Setting Up
    OpenCV for Java"), *Setting Up OpenCV for Java* the out-of-the-box support is
    not included. We will briefly describe the setup instructions in the upcoming
    sections.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kinect应该是直接的，但我们需要考虑两个重要方面。首先，我们需要确保所有设备驱动软件都已正确安装以便使用。然后，我们需要检查OpenCV是否已编译为支持Kinect。不幸的是，如果你已经从[http://sourceforge.net/projects/opencvlibrary/files/](http://sourceforge.net/projects/opencvlibrary/files/)下载了2.4.7版本的预编译二进制文件，如[第1章](ch01.html
    "第1章。为Java设置OpenCV")开头所述，*为Java设置OpenCV*，开箱即用的支持不包括在内。我们将在接下来的章节中简要描述设置说明。
- en: It is important to note that not only the Xbox 360 Kinect device is commercialized,
    but also the Kinect for Windows. Currently, if you are creating commercial applications
    with the Kinect, you should go with the Kinect for Windows, although the Xbox
    360 Kinect works with the provided drivers.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，不仅Xbox 360 Kinect设备是商业化的，而且Windows Kinect也是。目前，如果你正在创建使用Kinect的商业应用程序，你应该选择Windows
    Kinect，尽管Xbox 360 Kinect可以与提供的驱动程序一起使用。
- en: The driver setup
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 驱动程序设置
- en: OpenCV Kinect support relies on OpenNI and PrimeSensor Module for OpenNI. An
    OpenNI framework is an open source SDK used for the development of 3D sensing
    middleware libraries and applications. Unfortunately, [OpenNI.org](http://OpenNI.org)
    site was available only until April 23rd, 2014, but the OpenNI source code is
    available on Github at [https://github.com/OpenNI/OpenNI](https://github.com/OpenNI/OpenNI)
    and [https://github.com/OpenNI/OpenNI2](https://github.com/OpenNI/OpenNI2). We
    will focus on using version 1.5.7.10 in this section.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV对Kinect的支持依赖于OpenNI和PrimeSensor Module for OpenNI。OpenNI框架是一个开源SDK，用于开发3D感知中间件库和应用。不幸的是，[OpenNI.org](http://OpenNI.org)网站仅在2014年4月23日之前可用，但OpenNI源代码可在Github上找到，地址为[https://github.com/OpenNI/OpenNI](https://github.com/OpenNI/OpenNI)和[https://github.com/OpenNI/OpenNI2](https://github.com/OpenNI/OpenNI2)。在本节中，我们将重点关注使用版本1.5.7.10。
- en: Although instructions for building the binaries are readily available, we can
    use installers provided in the code repository of this book.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然构建二进制的说明 readily available，但我们可以使用本书代码库中提供的安装程序。
- en: After installing the OpenNI library, we will need to install the Kinect drivers.
    These are available at [https://github.com/avin2/SensorKinect/](https://github.com/avin2/SensorKinect/),
    and installers are specifically at [https://github.com/avin2/SensorKinect/tree/unstable/Bin](https://github.com/avin2/SensorKinect/tree/unstable/Bin).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装OpenNI库之后，我们还需要安装Kinect驱动程序。这些驱动程序可在[https://github.com/avin2/SensorKinect/](https://github.com/avin2/SensorKinect/)找到，安装程序位于[https://github.com/avin2/SensorKinect/tree/unstable/Bin](https://github.com/avin2/SensorKinect/tree/unstable/Bin)。
- en: 'When plugging your Xbox 360 Kinect device into Windows, you should see the
    following screenshot in your Device Manager:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当将你的Xbox 360 Kinect设备插入Windows时，你应该在你的设备管理器中看到以下截图：
- en: '![The driver setup](img/3972OS_06_08.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![驱动程序设置](img/3972OS_06_08.jpg)'
- en: Make sure all of the three Kinect devices—**Audio**, **Camera**, and **Motor**—show
    appropriately.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 确保所有三个Kinect设备——**音频**、**摄像头**和**电机**——都显示正确。
- en: Note
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: One caveat that can happen is that if users forget to plug the power supply
    for the XBox 360 Kinect device, only **Kinect Motor** might show up since there
    isn't enough energy for the all three of them. Also, you won't be able to retrieve
    frames in your OpenCV application. Remember to plugin your power supply, and you
    should be fine.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 可能发生的一个注意事项是，如果用户忘记为XBox 360 Kinect设备连接电源，则可能只有**Kinect电机**会显示，因为它们没有足够的能量。此外，你将无法在OpenCV应用程序中检索帧。请记住连接电源，你应该会没事的。
- en: The OpenCV Kinect support
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCV Kinect支持
- en: 'After ensuring that the OpenNI and Kinect drivers have been correctly installed,
    you need to check for the OpenCV Kinect support. Fortunately, OpenCV offers quite
    a useful function to check that. It is called `Core.getBuildInformation()`. This
    function shows important information about which options have been enabled during
    the OpenCV compilation. In order to check for Kinect support, simply output the
    result of calling this function to the console by using `System.out.println(Core.getBuildInformation());`
    and look for the video I/O section which looks like the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在确保OpenNI和Kinect驱动程序已经正确安装后，你需要检查OpenCV的Kinect支持。幸运的是，OpenCV提供了一个非常有用的函数来检查这一点。它被称为`Core.getBuildInformation()`。这个函数显示了在OpenCV编译期间启用的哪些选项的重要信息。为了检查Kinect支持，只需使用`System.out.println(Core.getBuildInformation());`将此函数的输出打印到控制台，并查找类似于以下内容的视频I/O部分：
- en: '![The OpenCV Kinect support](img/3972OS_06_output.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![OpenCV Kinect支持](img/3972OS_06_output.jpg)'
- en: It means OpenNI and Kinect support has not been enabled.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着OpenNI和Kinect支持尚未启用。
- en: 'Now, according to [Chapter 1](ch01.html "Chapter 1. Setting Up OpenCV for Java"),
    *Setting Up OpenCV for Java*, instead of typing:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，根据[第1章](ch01.html "第1章. 为Java设置OpenCV") *为Java设置OpenCV*，而不是输入：
- en: '[PRE11]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Remember to add the `WITH_OPENNI` flag, as given in the following line of code:'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 记得添加`WITH_OPENNI`标志，如下代码行所示：
- en: '[PRE12]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Instead of the preceding code, make sure you tick this option when using CMake''s
    GUI. Check for an output similar to the following screenshot:'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用CMake的GUI时，不要使用前面的代码，确保勾选这个选项。检查输出是否类似于以下截图：
- en: '![The OpenCV Kinect support](img/3972OS_06_09.jpg)'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![OpenCV Kinect支持](img/3972OS_06_09.jpg)'
- en: Make sure you point the OPENNI paths to your OpenNI correct installation folder.
    Rebuild the library, and now your `opencv_java247.dll` will be built with Kinect
    support.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保将OPENNI路径指向你的OpenNI正确安装文件夹。重新构建库，现在你的`opencv_java247.dll`将带有Kinect支持构建。
- en: 'Now try checking your `Core.getBuildInformation()` again. The availability
    of OpenNI will be demonstrated in your Java console, as given in the following
    lines:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在再次尝试检查你的`Core.getBuildInformation()`。OpenNI的可用性将在你的Java控制台中显示，如下所示：
- en: '[PRE13]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'An alternative approach is using our configured Maven repository. We have added
    a runtime dependency to the book Maven repository, only available for Windows
    x86, which is very easy to configure. Simply follow the Java OpenCV Maven configuration
    section from [Chapter 1](ch01.html "Chapter 1. Setting Up OpenCV for Java"), *Setting
    Up OpenCV for Java*, and then, instead of adding the ordinary OpenCV dependency,
    `opencvjar-runtime`, use the following dependency:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是使用我们配置的Maven仓库。我们已经将运行时依赖项添加到本书的Maven仓库中，仅适用于Windows x86，配置非常简单。只需遵循[第1章](ch01.html
    "第1章. 为Java设置OpenCV") *为Java设置OpenCV* 中的Java OpenCV Maven配置部分，然后，在添加普通OpenCV依赖项`opencvjar-runtime`而不是添加依赖项时，使用以下依赖项：
- en: '[PRE14]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The complete POM file can be accessed in this chapter's Kinect project source
    code.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的POM文件可以在本章的Kinect项目源代码中找到。
- en: Be sure you check for some caveats, such as not mixing 32 bit and 64 bit drivers
    and libraries as well as Java runtime. If this is the case, you might receive
    **Can't load IA 32-bit .dll on a AMD 64-bit platform**, for instance. Another
    source of problems is forgetting to plugin the power supply for Kinect XBox 360,
    which will cause it to load only Kinect Motor.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你检查了一些注意事项，例如不要混合32位和64位的驱动程序和库，以及Java运行时。如果是这种情况，你可能收到“**在AMD 64位平台上无法加载IA
    32位.dll**”的错误信息，例如。另一个问题来源是忘记为Kinect XBox 360连接电源，这将导致它只能加载Kinect电机。
- en: Now that we are sure that the OpenNI and Kinect Drivers have been correctly
    installed as well as the OpenCV's OpenNI support, we are ready to move on to the
    next section.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们确认OpenNI和Kinect驱动程序已经正确安装，以及OpenCV的OpenNI支持，我们就可以继续到下一节了。
- en: The Kinect depth application
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kinect深度应用
- en: The application focuses on the depth-sensing information from the Kinect as
    well as on the OpenCV API for OpenNI depth sensor, which means it won't cover
    some well-known Kinect features such as skeletal tracking (which puts nodes in
    important body parts like head, heap center, shoulder, wrists, hands, knees, feet,
    and others), gesture tracking, microphone recording, or tilting the device. Although
    we will just cover depth sensing, it is one of the most fantastic features of
    the Kinect.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序专注于Kinect的深度感应信息以及OpenCV API的OpenNI深度传感器，这意味着它不会涵盖一些知名的Kinect功能，如骨骼追踪（在头部、脊椎中心、肩膀、手腕、手、膝盖、脚等重要身体部位放置节点）、手势追踪、麦克风录音或倾斜设备。尽管我们只涉及深度感应，但这却是Kinect最神奇的功能之一。
- en: 'The basic idea behind this application is to segment an image from its depth
    information and combine it with a background image. We will capture an RGB frame
    from the Kinect device and retrieve its depth map. From a slider, you can choose
    how much depth you want for the segmentation. Based on that, a mask is generated
    through simple thresholding. The combined RGB frame and depth are now used to
    overlay a background image, resulting in an effect similar to chroma key compositing,
    but without the need for a green screen background, of course. This process can
    be seen in the following screenshot:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序背后的基本思想是从深度信息中分割图像，并将其与背景图像结合。我们将从Kinect设备捕获RGB帧并检索其深度图。通过滑块，你可以选择你想要的分割深度。基于此，通过简单的阈值生成掩码。现在，结合RGB帧和深度用于叠加背景图像，产生类似于色键合成的效果，当然，不需要绿色屏幕背景。这个过程可以在以下屏幕截图中看到：
- en: '![The Kinect depth application](img/3972OS_06_10.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![Kinect深度应用](img/3972OS_06_10.jpg)'
- en: We should notice that in OpenCV version 2.4.7, the Java API does not support
    the Kinect depth sensing, but this is built on top of `VideoCapture`, so just
    some minor modifications related to constants will be required. For the sake of
    simplicity, these constants are in the main `App` class, but they should be refactored
    to a class that only deals with the OpenNI constants. Please look for the project
    `kinect` from this chapter in order to check for source code.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该注意到，在OpenCV 2.4.7版本中，Java API不支持Kinect深度感应，但这建立在`VideoCapture`之上，因此只需要对常量进行一些小的修改。为了简单起见，这些常量位于主`App`类中，但它们应该重构为一个只处理OpenNI常量的类。请查找本章中的项目`kinect`以检查源代码。
- en: 'In order to work with depth-sensing images, we will need to follow these simple
    guidelines:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理深度感应图像，我们需要遵循以下简单指南：
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We will use the same `VideoCapture` class as the one used in [Chapter 2](ch02.html
    "Chapter 2. Handling Matrices, Files, Cameras, and GUIs"), *Handling Matrices,
    Files, Cameras, and GUIs*, for webcam input, with the same interface, passing
    the constant `CV_CAP_OPENNI` for telling it to retrieve frames from the Kinect.
    The difference here is that instead of using the `read` method,we will break this
    step in grabbing the frame and then retrieving either the depth image or the captured
    frame. Note that this is done by firstly calling the `grab` method and then the
    `retrieve` method, passing `CV_CAP_OPENNI_DEPTH_MAP` and `CV_CAP_OPENNI_BGR_IMAGE`
    as parameters. Make sure you send it to different matrices. Note that all these
    constants are extracted from the `highgui_c.h` file, which is located in the `opencv\modules\highgui\include\opencv2\highgui`
    path from OpenCV's source code tree. We will only work with the disparity map
    and RGB images from the Kinect, but one can also use the `CV_CAP_OPENNI_DEPTH_MAP`
    constant for receiving the depth values in mm as a `CV_16UC1` matrix, or `CV_CAP_OPENNI_POINT_CLOUD_MAP`
    for a point cloud map in a `CV_32FC3` matrix in which the values are XYZ coordinates
    in meters.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与[第2章](ch02.html "第2章. 处理矩阵、文件、摄像头和GUI")中相同，即*处理矩阵、文件、摄像头和GUI*所使用的`VideoCapture`类，用于摄像头输入，具有相同的接口，传递常量`CV_CAP_OPENNI`来告诉它从Kinect检索帧。这里的区别在于，我们不会使用`read`方法，而是将获取帧的步骤拆分，然后分别检索深度图像或捕获的帧。请注意，这是通过首先调用`grab`方法，然后调用`retrieve`方法来完成的，参数为`CV_CAP_OPENNI_DEPTH_MAP`和`CV_CAP_OPENNI_BGR_IMAGE`。确保将它们发送到不同的矩阵中。请注意，所有这些常量都是从OpenCV源代码树中的`opencv\modules\highgui\include\opencv2\highgui`路径下的`highgui_c.h`文件中提取的。我们只将与Kinect的视差图和RGB图像一起工作，但也可以使用`CV_CAP_OPENNI_DEPTH_MAP`常量以毫米为单位接收深度值作为`CV_16UC1`矩阵，或者使用`CV_CAP_OPENNI_POINT_CLOUD_MAP`以`CV_32FC3`矩阵的形式接收点云图，其中值是米为单位的XYZ坐标。
- en: 'Our main loop consists of the following code:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要循环由以下代码组成：
- en: '[PRE16]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: First, we invoke the `grab` method to get the next frame from the Kinect. Then,
    we retrieve depth map and color images. As we have previously loaded our background
    in `resizedBackground`, we just clone it to `workingBackground`. Following this,
    we threshold our disparity image according to our slider level. This will make
    pixels farther away from our desired depth go black, while the ones we still want
    become white. It is time to clear our mask and combine it with the colored image.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们调用`grab`方法从Kinect获取下一帧。然后，我们检索深度图和彩色图像。因为我们之前已经在`resizedBackground`中加载了我们的背景，所以我们只需将其克隆到`workingBackground`。随后，我们根据滑块级别对差异图像进行阈值处理。这将使远离我们期望深度的像素变黑，而我们仍然想要的像素变白。现在是时候清除我们的掩码并将其与彩色图像组合了。
- en: Summary
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter has really covered several areas that deal with background removal
    as well as some details that arise from this problem, such as the need to use
    connected components to find their contours. Firstly, the problem of background
    removal itself was established. Then, a simple algorithm such as frame differencing
    was analyzed. After that, more interesting algorithms, such as averaging background
    and **mixture of Gaussian** (**MOG**) were covered.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 本章真正涵盖了处理背景去除的几个领域以及由此问题产生的某些细节，例如需要使用连通组件来找到它们的轮廓。首先，确立了背景去除本身的问题。然后，分析了如帧差分这样的简单算法。之后，介绍了更有趣的算法，例如平均背景和**高斯混合**（**MOG**）。
- en: After using algorithms to deal with background removal problems, an insight
    about connected components was explored. Core OpenCV algorithms such as `findContours`
    and `drawContours` were explained. Some properties of contours were also analyzed,
    such as their area as well as convex hulls.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用算法处理背景去除问题后，探索了关于连通组件的见解。解释了核心OpenCV算法，如`findContours`和`drawContours`。还分析了轮廓的一些属性，例如它们的面积以及凸包。
- en: The chapter finished with complete explanations of how to use the Kinect's depth
    sensor device as a background removal tool, for OpenCV 2.4.7\. After depth instructions
    on the device setup, a complete application was developed, making it clear to
    deal with the depth sensing sensors API.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本章以如何使用Kinect的深度传感器设备作为背景去除工具的完整解释结束，针对OpenCV 2.4.7。在设备设置上的深度指令之后，开发了一个完整的应用程序，使处理深度感应传感器API变得清晰。
- en: Well, now it's time to jump from desktop applications to web apps in the next
    chapter. There, we'll cover details on how to set up an OpenCV-based web application,
    deal with image uploads, and create a nice augmented reality application based
    on the Tomcat web server. It is going to be fun, just watch out for Einstein's
    screenshots.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，现在到了下一章从桌面应用程序跳转到Web应用程序的时候了。在那里，我们将介绍如何设置基于OpenCV的Web应用程序的细节，处理图像上传，并基于Tomcat
    Web服务器创建一个不错的增强现实应用程序。这将很有趣，只是要注意看Einstein的截图。
