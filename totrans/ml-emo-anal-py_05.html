<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer077">
<h1 class="chapter-number" id="_idParaDest-82"><a id="_idTextAnchor116"/>5</h1>
<h1 id="_idParaDest-83"><a id="_idTextAnchor117"/>Sentiment Lexicons and Vector-Space Models</h1>
<p>We now have the machinery that we need to make systems that find emotions in texts – <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) algorithms for converting raw texts into feature sets and <a id="_idIndexMarker494"/>machine learning algorithms for extracting patterns from feature sets. Over the next few chapters, we will develop a series of emotion mining algorithms, very simple ones to start with, leading up to sophisticated algorithms that use a variety of <span class="No-Break">advanced techniques.</span></p>
<p>While doing so, we will use a collection of datasets and a variety of measures to test each algorithm and compare the effectiveness of the various preprocessing steps. So, this chapter will start by considering the datasets and metrics that we will be using as we develop the various algorithms. Once we have the datasets and metrics in place, we will consider very simple classifiers based purely on sentiment lexicons, and we will look at ways of calculating how strongly an individual word expresses a sentiment. This will provide us with a baseline for looking at the performance of more sophisticated algorithms in <span class="No-Break">later chapters.</span></p>
<p>In this chapter, we will cover the <span class="No-Break">following topics:</span></p>
<ul>
<li>Datasets <span class="No-Break">and metrics</span></li>
<li><span class="No-Break">Sentiment lexicons</span></li>
<li>Extracting a sentiment lexicon from <span class="No-Break">a corpus</span></li>
<li><span class="No-Break">Vector-space models</span></li>
</ul>
<h1 id="_idParaDest-84"><a id="_idTextAnchor118"/>Datasets and metrics</h1>
<p>Over the <a id="_idIndexMarker495"/>next few chapters, we will <a id="_idIndexMarker496"/>look at several emotion-mining algorithms. Before we do so, we need to consider exactly what these algorithms are designed to do. There are several slightly different tasks for emotion mining algorithms, and we need to be clear about which of these tasks a given algorithm is <span class="No-Break">aimed at:</span></p>
<ul>
<li>You might just want to know whether the texts you are looking at are positive or negative, or you might want a <span class="No-Break">finer-grained classification.</span></li>
<li>You might assume that each text expresses exactly one emotion, or at most one emotion, or that a text can express several (or <span class="No-Break">no) emotions.</span></li>
<li>You might want to know how strongly a text expresses an emotion. For example, <em class="italic">I’m a bit irritated by that</em> and <em class="italic">That makes me absolutely furious</em> both express anger, but the second clearly expresses it much <span class="No-Break">more strongly.</span></li>
</ul>
<p>We will concentrate <a id="_idIndexMarker497"/>on algorithms that aim to assign multiple (or no) labels to each tweet, with the labels drawn from some collection of candidate emotions, ranging from <a id="_idIndexMarker498"/>just positive and negative to larger sets drawn from Plutchik’s wheel. We will refer to datasets where a single tweet can have zero or more labels as <strong class="bold">multi-label</strong> datasets. This <a id="_idIndexMarker499"/>is to be distinguished from <strong class="bold">multi-class</strong> datasets, where <a id="_idIndexMarker500"/>there are several labels available but exactly one is assigned to each tweet. Multi-label datasets are significantly more difficult than simple multi-class ones, and the task also gets harder as the set of labels gets larger (it may, for instance, be difficult to distinguish between anger and disgust, but they are both negative); and it also gets harder if we don’t have a preconception about how many emotions are expressed. Since most of the learning algorithms depend on comparing some score obtained from the text with a threshold, we can usually use this score to assess how strongly a text expresses an emotion rather than just whether it expresses it or not. We will mainly concentrate on deciding whether a text expresses an emotion rather than <span class="No-Break">how strongly.</span></p>
<p>We will <a id="_idIndexMarker501"/>use a selection of the datasets listed in <a href="B18714_02.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Building and Using a Dataset</em>, to train and test the various models that we <span class="No-Break">will develop:</span></p>
<ul>
<li>The <strong class="bold">Workshop on Computational Approaches to Subjectivity, Sentiment &amp; Social Media Analysis</strong> (<strong class="bold">WASSA</strong>) dataset, which contains 3.9K English tweets, each labeled with one of anger, fear, joy, <span class="No-Break">and sadness.</span></li>
<li>The Semeval 2018 Task E_c dataset, which contains a moderate number of tweets in English, Arabic, and Spanish, where a fairly high percentage of tweets contain emojis, with each tweet labeled with 0 or more emotions from a standard set of 11 emotions. This dataset contains 7.7K English tweets, 2.9K Arabic tweets, and 4.2K Spanish tweets. We will refer to this as the <span class="No-Break">SEM-11 set.</span></li>
<li>The Semeval 2016 Task El-reg and El-oc dataset, where the El-reg dataset has tweets labeled with a score from 0 to 1 for each of a set of four emotions, and the El-oc dataset has tweets ranked in terms of which emotion they express. The combinations of these datasets, which we will refer to as the SEM4 set, contain 7.6K English tweets, 2.8K Arabic, and <span class="No-Break">2.6K Spanish.</span></li>
<li>The CARER dataset is large (slightly over 400K tweets) and has labels for six emotions (anger, fear, joy, love, sadness, and surprise). Each tweet is assigned exactly <span class="No-Break">one emotion.</span></li>
<li>The IMDb dataset <a id="_idIndexMarker502"/>contains 50K negative and positive film reviews and provides an interesting test of the robustness of the various algorithms since <a id="_idIndexMarker503"/>it is split into just two categories (positive and negative), which makes the task of learning to classify documents easier. The reviews contain anything from 100 to 1,000 words, which is much longer than a tweet and poses a different set <span class="No-Break">of problems.</span></li>
<li>A collection of Kuwaiti tweets, annotated either by assigning a label if all three annotators unanimously assigned that label (KWT.U) or if at least two of them did (KWT.M). This set is particularly interesting because, in a large number of cases, the annotators agreed that a tweet expressed no emotions and in some, it expressed several, which poses a substantial challenge for classifiers that assign a single label to <span class="No-Break">every observation.</span></li>
</ul>
<p>These datasets provide enough variation to help us verify that a given approach to the task of finding emotions is robust across <span class="No-Break">different conditions:</span></p>
<ul>
<li>The WASSA, SEM4, and SEM11 datasets contain emojis, which makes the task of emotion mining slightly easier because the main (sole?) point of using emojis is to express emotions, though they are sometimes used in slightly <span class="No-Break">surprising ways.</span></li>
<li>The SEM4 and SEM11 datasets are multilingual, with data supplied in English, Arabic, and Spanish. This helps when trying out approaches that are intended to be language-independent since the methodology for collecting the three languages is <span class="No-Break">the same.</span></li>
<li>The SEM11 set contains tweets with differing numbers of emotions, including none, which can make the task of assigning emotions <span class="No-Break">considerably harder.</span></li>
<li>The CARER dataset is very large, though it does not contain any emojis or hashtags: this makes it possible to carry out investigations into how performance varies with the size of the <span class="No-Break">training data.</span></li>
<li>The IMDb set has just two labels, but very <span class="No-Break">long texts.</span></li>
<li>The KWT sets have tweets with zero, one, or more emotions, but this time, a very large proportion <span class="No-Break">have zero.</span></li>
</ul>
<p>Given that these <a id="_idIndexMarker504"/>datasets are supplied in different formats, we need, as usual, a common format for <a id="_idIndexMarker505"/>representing them. We will use two <span class="No-Break">basic classes:</span></p>
<ul>
<li>A tweet is an object with a sequence of tokens, a term frequency table, and possibly a Gold Standard set of labels, along with several <span class="No-Break">bookkeeping properties:</span><pre class="source-code">
class TWEET:</pre><pre class="source-code">    def __init__(self, id=False, src=False,</pre><pre class="source-code">                 text=False, tf=False,</pre><pre class="source-code">                 scores=False, tokens=False,</pre><pre class="source-code">                 args=False):</pre><pre class="source-code">        self.id = id</pre><pre class="source-code">        self.src = src</pre><pre class="source-code">        self.text = text</pre><pre class="source-code">        self.GS = scores</pre><pre class="source-code">        self.tokens = tokens</pre><pre class="source-code">        self.tf = ormalize(tf)</pre><pre class="source-code">        self.ARGS = args</pre><pre class="source-code">    def __repr__(self):</pre><pre class="source-code">        return self.text</pre></li> <li>A dataset is a set containing a set of tweets, a list of emotion names, the Gold Standard labels for the tweets, and, again, some bookkeeping properties. The most useful of these is an index that assigns each word in the dataset a unique index. We will frequently <a id="_idIndexMarker506"/>use this in later sections, so it is worth looking at how <a id="_idIndexMarker507"/>we do it here. The basic idea is that we read the dataset word by word. If the word we have just read is already in the index, there is nothing to be done. If it is not, then we assign it the current length of the index: this ensures that every word gets assigned a unique identifier; once we have added the current word, the length of the index will be incremented by one, so the next new word will get a <span class="No-Break">new index:</span><pre class="source-code">
    def makeIndex(self):</pre><pre class="source-code">        index = {}</pre><pre class="source-code">        for tweet in self.tweets:</pre><pre class="source-code">            for token in tweet.tokens:</pre><pre class="source-code">                if not token in index</pre><pre class="source-code">                    index[token] = len(index)</pre><pre class="source-code">        return index</pre></li> </ul>
<p>This will generate an index, as shown here, where each word has a <span class="No-Break">unique identifier:</span></p>
<pre class="source-code">
<strong class="bold">{..., 'days': 6, 'sober': 7, 'do': 8, "n't": 9, 'wanna': 10,</strong><strong class="bold">  …}</strong></pre> <p>Given <strong class="source-inline">makeIndex</strong>, we can construct a <strong class="source-inline">DATASET</strong> class <span class="No-Break">as follows:</span></p>
<pre class="source-code">
class DATASET:    def __init__(self, emotions, tweets, idf, ARGS, N=sys.maxsize):
        self.emotions = sorted(emotions)
        self.tweets = tweets
        self.GS = [tweet.GS for tweet in self.tweets][:N]
        self.idf = idf
        self.words = [w[0] for w in reversed(sortTable(idf))]
        self.makeIndex()
        self.ARGS = ARGS</pre>
<p>We will need to convert the format of a given dataset into these representations, but once that has <a id="_idIndexMarker508"/>been done, we will use them throughout this and the following chapters. We will do this <span class="No-Break">in stages.</span></p>
<p>First, we will convert <a id="_idIndexMarker509"/>the dataset so that it looks like the SEM11 dataset – that is, a tab-separated file with a header that specifies that the first and second fields as the ID and the tweet itself, with the remaining columns as the various emotions, followed by a line per tweet with 0s and 1s in the appropriate columns (the following example has the tweet and the columns for emotions truncated, so it will fit on <span class="No-Break">the page).</span></p>
<p>This format is a variant of the standard <strong class="bold">one-hot</strong> representation used in neural networks, where a choice from several discrete labels is represented by a vector where each position in the vector represents a possible option. Suppose, for instance, that the possible labels were <strong class="bold">{angry, sad, happy, love}</strong>. In this case, we could represent <strong class="bold">angry</strong> with the vector &lt;1, 0, 0, 0&gt;, <strong class="bold">sad</strong> with &lt;0, 1, 0, 0&gt;, <strong class="bold">happy</strong> with &lt;0, 0, 1, 0&gt;, and <strong class="bold">love</strong> with &lt;0, 0, <span class="No-Break">0, 1&gt;.</span></p>
<p>The advantage of the SEM11 version of this format is that it makes it easy to allow tweets to have an arbitrary number of labels, thus allowing us to treat multi-label datasets and single-label <span class="No-Break">datasets uniformly:</span></p>
<pre class="source-code">
ID     Tweet                    anger  disgust  fear21441  Worry is a down payment    0      1        0
1535   it makes you #happy.       0      0        0</pre>
<p>Exactly how we convert a given dataset into this format depends on how the dataset is supplied. The following <a id="_idIndexMarker510"/>code shows how we do it for the CARER dataset – the others <a id="_idIndexMarker511"/>are similar, but because their original format is slightly different, the code for converting it into the SEM11 format will be <span class="No-Break">slightly different</span></p>
<p>The CARER dataset comes as two files: a file called <strong class="source-inline">dataset_infos.json</strong> containing information about the dataset and another called <strong class="source-inline">data.jsonl</strong> containing the actual data. We convert this into SEM11 format by finding the names of the labels in  <strong class="source-inline">dataset_infos.json</strong> and then converting the entries in <strong class="source-inline">data.jsonl</strong> so that they have a 1 in the appropriate column and a 0 in <span class="No-Break">the others.</span></p>
<p><strong class="source-inline">data.jsonl</strong> looks <span class="No-Break">as follows:</span></p>
<pre class="source-code">
{"text":"i feel awful about it","label":0}{"text":"i really do feel proud of myself","label":1}
...</pre>
<p>We want to convert this into <span class="No-Break">the following:</span></p>
<table class="No-Table-Style" id="table001-5">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">ID</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">text</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">sadness</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">joy</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">love</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">anger</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">fear</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">surprise</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>i feel awful <span class="No-Break">about it</span></p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>i really do feel proud <span class="No-Break">of myself</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
</tbody>
</table>
<p>We do this by using the set of labels provided in <strong class="source-inline">dataset_infos.json</strong> as the header line, and then <a id="_idIndexMarker512"/>writing each entry in <strong class="source-inline">data.jsonl</strong> with a 1 in the column specified by <a id="_idIndexMarker513"/>its label (for example, in the first (sadness) column for tweet 1 and the second (joy) column for <span class="No-Break">tweet 2):</span></p>
<pre class="source-code">
def convert(self):    # extract the labels from dataset_infos.json
    with open(os.path.join(self.DOWNLOAD,
                           "dataset_infos.json")) as jsfile:
        infos = json.load(jsfile)
        self.labels = infos["default"]["features"]\
                                       ["label"]["names"]
    # read the data line by line from data.jsonl
    with open(os.path.join(self.PATH, "data.jsonl"))\
              as input:
        d = [json.loads(line) for line in input]
    # initialise the output with a header line
    csv = "ID\ttext\t%s\n"%("\t".join(self.labels))
    # Go through the data writing each line as the ID,
    # the text itself and an appropriate set of 0s and 1s
    for i, x in enumerate(d):
        cols = ["1" if x['label'] == i else "0"\
                        for i in range(len(self.labels))]
        csv += "%s\t%s\t%s\n"%(i, x['text'],"\t".join(cols))
    # Save this as wholething.csv inside CARER/EN
    with open(os.path.join(self.PATH, "wholething.csv"), "w") as out:
        out.write(csv)</pre>
<p>Once we have the data in SEM11 format, we can read it as a dataset. We read the data line by line, using the <a id="_idIndexMarker514"/>first line as a header where the first two items are <strong class="source-inline">ID</strong> and <strong class="source-inline">tweet</strong> and the remainder are the emotions, and then use <strong class="source-inline">makeTweet</strong> to convert subsequent <a id="_idIndexMarker515"/>lines into <strong class="source-inline">tweets</strong>. We then remove duplicates and shuffle the data, construct document frequency and inverse document frequency tables, and wrap the whole thing up as <span class="No-Break">a </span><span class="No-Break"><strong class="source-inline">dataset</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
def makeDATASET(src, N=sys.maxsize, args=None):    dataset = [line.strip() for line in open(src)][:N]
    emotions = None
    tweets = []
    for tweet in dataset:
        if emotions is None:
            emotions = tweet.split()[2:]
        else:
            tweets.append(makeTweet(tweet, args=args))
    pruned = prune(tweets)
    random.seed(0); random.shuffle(pruned)
    df = counter()
    index = {}
    for i, tweet in enumerate(tweets):
        for w in tweet.tokens:
            df.add(w)
    """
    remove singletons from the idf count
    """
    idf = {}
    for w in list(df.keys()):
        idf[w] = 1.0/float(df[w]+1)
    return DATASET(emotions, tweets, df, idf, args=args)</pre>
<p><strong class="source-inline">makeTweet</strong> does quite a lot of work. It splits the line that was read from the file (which is, at this point, still just a tab-separated string) into its component parts and converts the 0s and 1s into a <a id="_idIndexMarker516"/>NumPy array; does tokenization and stemming as required (for example, for Arabic, the default is to convert the text into a form using Latin characters, tokenize it by <a id="_idIndexMarker517"/>just splitting it at white space, and then use the stemmer described in <em class="italic">wwww, Preprocessing – Stemming, Tagging, and Parsing</em> to find roots and affixes, with similar steps for other languages); and then finally make a term frequency table for the tweet and wrap everything up in <strong class="source-inline">tweet</strong>. All of these functions have an argument called <strong class="source-inline">args</strong> that contains a set of parameters that are supplied at the top level and that control what happens – for example, what language we are using, which tokenizer and stemmer we want to use, and <span class="No-Break">so on:</span></p>
<pre class="source-code">
def makeTweet(tweet, args):    tweet = tweet.strip().split("\t")
    scores = numpy.array([int(score) for score in tweet[2:]])
    tweet, text tweet[0], tweet[1]
    if args["language"] == "AR":
        tokens = a2bw.convert(text, a2bw.a2bwtable).split()
        if args["stemmer"] == "standard":
            tokens = stemmer.stemAll(tokens, stemmer.TWEETGROUPS)
    elif args["language"] == "ES":
    elif args["language"] == "EN":
    tf = counter()
    for w in tokens:
        tf.add(word)
    return TWEET(id=tweet,tf=tf,scores=scores,tokens=tokens,args=args)</pre>
<p>We must also <a id="_idIndexMarker518"/>define an abstract class <span class="No-Break">for classifiers:</span></p>
<pre class="source-code">
class BASECLASSIFIER():    def applyToTweets(self, dataset):
        return [self.applyToTweet(tweet) for tweet in dataset.tweets]</pre>
<p>As we continue, we will define <a id="_idIndexMarker519"/>several concrete types of classifiers. These all need a method so that they can be applied to sets of tweets, though how they are applied to individual tweets will vary. Therefore, we will provide this abstract class, which says that to apply any classifier to a set of tweets, you just apply its <strong class="source-inline">applyToTweet</strong> method to each tweet in the dataset. <strong class="source-inline">BASECLASSIFIER</strong> lets us capture this in an abstract class: we will never actually make a <strong class="source-inline">BASECLASSIFIER</strong>, and indeed it does not have a constructor, but all our concrete classifiers will be subclasses of <strong class="source-inline">BASECLASSIFIER</strong> and hence will have <span class="No-Break">this method.</span></p>
<p>The abstract class has no constructor and just one method, which simply says that to apply a classifier to a dataset, you must use its <strong class="source-inline">applyToTweet</strong> method on each tweet in the dataset, but it will prove useful as we continue. Different concrete subclasses of this class will each define a version of <strong class="source-inline">applyToTweet</strong>, but it is useful to have a generic method for applying a classifier to an <span class="No-Break">entire dataset.</span></p>
<p>We will use the Jaccard score, macro-F1, and micro-F1 as performance measures. As noted in <a href="B18714_02.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Building and Using a Dataset</em>, micro-F1 tends to be very forgiving in situations where there is one class that predominates and the learning algorithm performs well on this class but less so on the smaller classes. This is a useful measure if you want to know <a id="_idIndexMarker520"/>how well the algorithm performs overall, but if you wish to make sure <a id="_idIndexMarker521"/>that it performs well on all the classes, then macro-F1 is more reliable (and is typically lower). Again, from <a href="B18714_02.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Building and Using a Dataset</em> Jaccard and micro-F1 are monotonically linked – if the micro-F1 for one experiment is higher than the micro-F1 for another, then the Jaccard measure will also be higher. So, these two measures will always provide the same ranking for sets of classifiers, but since some papers report one and some the other, it makes sense to include both when comparing a new classifier with others in <span class="No-Break">the literature.</span></p>
<h1 id="_idParaDest-85"><a id="_idTextAnchor119"/>Sentiment lexicons</h1>
<p>Now that we have all the machinery for reading and managing datasets, it is time to start trying to develop classifiers. The first one we will look at is based on the simple observation that <a id="_idIndexMarker522"/>individual words carry emotional weight. It may be, as we will see later, that exactly how they contribute to the overall content of the message depends on their relationships with other words in the text, but simply looking at the presence of emotionally laden words (and emojis and suchlike) will give you a pretty <span class="No-Break">good idea:</span></p>
<p><em class="italic">I feel like she is a really sweet person as well</em> (from the <span class="No-Break">CARER dataset)</span></p>
<p><em class="italic">I feel like she is a really horrible person as well</em> (one <span class="No-Break">word changed)</span></p>
<p><em class="italic">I feel gracious as he hands me across a rough patch</em> (from the <span class="No-Break">CARER dataset)</span></p>
<p><em class="italic">I feel irritated as he hands me across a rough patch</em> (one <span class="No-Break">word changed)</span></p>
<p>So, the simplest imaginable emotion-mining algorithm would simply involve labeling words with sentiments and seeing which sentiment scored the most highly for each text. Nothing could be simpler to implement, so long as you have a lexicon that has been labeled <span class="No-Break">with emotions.</span></p>
<p>How could you get such a lexicon? You could make one by hand (or find one that someone else has made by hand), or you could try to extract one from a <span class="No-Break">labeled corpus.</span></p>
<p>Both these approaches involve a large amount of work. You either have to go through a long list of words and assign a set of emotion labels to each, possibly with a score (for example, <em class="italic">sweet</em> and <em class="italic">love</em> both express joy, but <em class="italic">love</em> probably expresses it more strongly than <em class="italic">sweet</em>, and quantifying just how much more strongly it does so would be very difficult); or you have to go through a long list of tweets and assign a set of emotion labels to them, again possibly with a score. Both of these require a considerable amount of work, which you can <a id="_idIndexMarker523"/>either do yourself or get someone else to do (for example, by crowdsourcing it via a platform such as Amazon’s Mechanical Turk). If someone else has already done it and made the results available, then so much the better. We will start by considering a well-known resource, namely the NRC Word-Emotion <a id="_idIndexMarker524"/>Association Lexicon (also know<a id="_idTextAnchor120"/>n as <strong class="bold">EMOLEX</strong>) (Mohammad &amp; Turney, 2013). This consists of a list of English forms, each labeled with zero or more labels from a set of eight emotions (<strong class="bold">anger</strong>, <strong class="bold">anticipation</strong>, <strong class="bold">disgust</strong>, <strong class="bold">fear</strong>, <strong class="bold">joy</strong>, <strong class="bold">sadness</strong>, <strong class="bold">surprise</strong>, and <strong class="bold">trust</strong>) plus two polarities (<strong class="bold">negative</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="bold">positive</strong></span><span class="No-Break">):</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table002-2">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">anger</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">anticipation</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">disgust</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">fear</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">joy</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">negative</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">positive</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">sadness</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">surprise</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">trust</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">aback</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">abacus</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">abandon</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">abandoned</span></p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">abandonment</span></p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">abate</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">abatement</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">abba</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">abbot</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
<td class="No-Table-Style">
<p>...</p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – EMOLEX labels</p>
<p>To use this with a given dataset, we have to match the emotions in the lexicon with the labels in the dataset – we cannot use the lexicon for any emotions that it does not contain, and emotions that are in the lexicon but not in some dataset cannot be used for extracting emotions from <span class="No-Break">that dataset.</span></p>
<p>We will start by reading the lexicon and converting it into a Python dictionary. This is very straightforward – read the lexicon line by line, where the first item on a line is a word and the remainder are the scores for the 11 emotions. The only complications are that the dataset <a id="_idIndexMarker525"/>we want to use it with may have a different set of emotions from the eleven in the lexicon; and that we might want to use a stemmer to get the root form of a word – for example, to treat <em class="italic">abandon</em> and <em class="italic">abandoned</em> as a single item. This may make little difference for English, but it can be important when using the non-English equivalents that are provided for <span class="No-Break">several languages.</span></p>
<p>EMOLEX comes in various forms. We are using the one where the first column is an English word, the next 11 are the values for each emotion, and the last is a translation of the given English word into some other language. The default is the one where the other language is Arabic, but we have done some experiments with a Spanish corpus, for which we need a Spanish stemmer. The way to extend this to other languages should <span class="No-Break">be obvious.</span></p>
<p><strong class="source-inline">ARGS</strong> is a set of parameters for applying the algorithm in different settings – for example, for specifying which language we are using. The two major issues here are <span class="No-Break">as follows:</span></p>
<ul>
<li>EMOLEX contains inflected forms of words, but our classifiers typically require the <span class="No-Break">root forms</span></li>
<li>The emotions in EMOLEX are not necessarily the same as the ones used in <span class="No-Break">the datasets</span></li>
</ul>
<p>To deal with the first of these, we have to use a stemmer – that is, one of the ones from <a href="B18714_04.xhtml#_idTextAnchor093"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Preprocessing – Stemming, Tagging, and Parsing</em>. For the second, we have to find <a id="_idIndexMarker526"/>the emotions that are shared between EMOLEX and the dataset and restrict our attention <span class="No-Break">to those:</span></p>
<pre class="source-code">
EMOLEX="CORPORA/NRC-Emotion-Lexicon/Arabic-NRC-EMOLEX.txt"def readNRC(ifile=EMOLEX, targets=None, ARGS=False):
    lines = list(open(ifile))
    # emotions is the list of emotions in the EMOLEX file
    # targets is the list of emotions in the dataset that
    # the classifieris going to be applied to.
    emotions = lines[0].strip().split("\t")[1:-1]
    emotionIndex = [True if e in targets else False for e in emotions]
    targetIndex = [True if e in emotions else False for e in targets]
    lex = {}
    # add entries line by line
    for line in lines[1:]:
        line = line.split("\t")
        # if we're doing it for English
        if ARGS.Language == "EN":
            form = line[0]
            if ARGS.Stemmer.startswith("justRoot"):
                form = justroot(form)
            elif ARGS.Stemmer.startswith("morphyroot"):
                form = morphyroot(form)
        ...
        else:
            raise Exception("Unknown language: %s"%(ARGS.Language))
        # The line we just read is a string, so the values
        # for the emotions are "0" and "1". We want them as
        # ints, and we also only want the ones that appear
        # in emotionIndex, i.e. ones that are present in
        # the lexicon and in the target dataset
        lex[form] \
              = [int(x) for (x, y) in zip(line[1:-1], emotionIndex) if y]
    return lex, emotionIndex, targetIndex</pre>
<p>The following <a id="_idIndexMarker527"/>table shows what happens when we use this lexicon with our English datasets (SEM4, SEM11, WASSA, CARER), simply tokenizing the text by splitting it at <span class="No-Break">white space:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table003-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.418</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.683</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.519</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.489</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.350</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.368</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.401</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.383</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.333</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.237</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.435</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.738</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.547</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.524</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.376</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.229</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.524</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.318</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.287</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.189</strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – EMOLEX-based classifiers, no stemming</p>
<p>These scores provide a baseline for comparing the more sophisticated models to be developed later. It is worth observing that the scores for SEM4 are better than those for SEM11 – this is unsurprising given that SEM4 only has four fairly basic emotions (<strong class="bold">anger</strong>, <strong class="bold">fear</strong>, <strong class="bold">joy</strong>, and <strong class="bold">sadness</strong>), whereas SEM11 adds several more challenging ones (<strong class="bold">surprise</strong>, <strong class="bold">trust</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="bold">anticipation</strong></span><span class="No-Break">).</span></p>
<p>Some of the classifiers that we will look at later can take a long time to train, and it may be that losing a bit of accuracy is worth it if training the more accurate classifiers takes an infeasible amount of time. What matters is whether the classifier is any good at the task we want <a id="_idIndexMarker528"/>it to carry out. A classifier that takes a second to train but gets almost everything wrong is no use. Nonetheless, if two algorithms have very similar results but one is much faster to train than the other, it may make sense to choose the faster one. It is hard to imagine anything much faster than the EMOLEX-based one – less than a thousandth of a second to process a single tweet, so that’s a tenth of a second to train on our largest (411K) <span class="No-Break">training set.</span></p>
<p>The basic EMOLEX-based classifier, then, is very fast but produces fairly poor results. Are there things we can do to improve <span class="No-Break">its scores?</span></p>
<p>The first extension involves using the tokenizer and stemmer described in <a href="B18714_04.xhtml#_idTextAnchor093"><span class="No-Break"><em class="italic">Chapter 4</em></span></a><em class="italic">, Preprocessing – Stemming, Tagging, and Parsing</em>. This has a fairly substantial effect in that it improves the scores, as shown here (we will mark the highest score that we have seen to date in bold; since all the scores in the table that use stemming are better than the ones without, they are all marked in <span class="No-Break">bold here):</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table004-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.461</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.622</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.530</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.538</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.360</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.411</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.430</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.420</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.363</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.266</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.465</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.666</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.547</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.545</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.377</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.378</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.510</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.434</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.378</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.278</strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – EMOLEX-based classifiers with stemming</p>
<p>EMOLEX also <a id="_idIndexMarker529"/>provides a route into other languages by including a target language equivalent for each <span class="No-Break">English word:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table005-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">anger</strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">…</strong></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">negative</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">positive</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">sadness</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">surprise</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">trust</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Spanish</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Aback</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">detrás</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Abacus</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">ábaco</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Abandon</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">abandonar</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Abandoned</span></p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">abandonado</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
<td class="No-Table-Style">
<p>…</p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – EMOLEX entries with Spanish translations</p>
<p>In some cases, this can be leveraged to provide a classifier for the target language: the missing section from the previous definition of readNRC is given here – the key changes are that we use the last item in the line as the form and that we use the appropriate stemmer for the <span class="No-Break">given language:</span></p>
<pre class="source-code">
        elif ARGS.Language == "AR":            form = line[-1].strip()
            form = a2bw.convert(form, a2bw.a2bwtable)
            if ARGS.Stemmer == "SEM":
                form = stemArabic(form)
        elif ARGS.Language == "ES":
            form = line[-1].strip()
            if ARGS.Stemmer.startswith("stemSpanish"):
                form = stemSpanish(form)</pre>
<p>By trying this on the SEM4 and SEM11 Spanish and Arabic datasets, we obtain the <span class="No-Break">following results:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table006-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.356</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.100</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.156</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.144</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.085</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.272</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.070</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.111</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.096</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.059</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.409</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.362</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.384</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.372</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.238</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.267</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.259</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.263</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.232</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.151</strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5 – EMOLEX-based classifiers for Spanish and Arabic, no stemming</p>
<p>The recall for <a id="_idIndexMarker530"/>the Spanish sets is very poor, but apart from that, the scores are surprisingly good considering that we just have the English dataset with one translation of each English word, where the translation is in the canonical form (that is, Spanish verbs are in the infinitive, Arabic nouns are singular, and where a noun has both masculine and feminine forms, then the masculine is used). If we simply use the Spanish and Arabic stemmers from <a href="B18714_04.xhtml#_idTextAnchor093"><span class="No-Break"><em class="italic">Chapter 4</em></span></a><em class="italic"> , Preprocessing – Stemming, Tagging, and Parsing</em> (which do not, remember, make use of any lexicon), we get <span class="No-Break">the following:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table007">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.406</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.164</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.234</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.224</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.132</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.255</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.105</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.149</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.121</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.080</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.452</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.536</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.490</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.469</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.325</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.284</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.348</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.313</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.276</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.185</strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.6 – EMOLEX-based classifiers for Spanish and Arabic, stemmed</p>
<p>Using the stemmed forms improves the recall in every case, and generally improves the precision. The key here is that by using stemmed forms, things that look different but have the same underlying form get matched – for example, if the lexicon contains قدرة (<em class="italic">qdrp</em>, using the Buckwalter transliteration scheme <a id="_idTextAnchor121"/>(Buckwalter, T, 2007)) and some tweet contains القدرات (<em class="italic">AlqdrAt</em>, the plural form of the same word with a definite article added) – then whatever emotions قدرة is associated with will be found for القدرات. This will improve the recall since more words in the lexicon will be retrieved. It is more surprising that it generally improves the precision: to see why this happens, consider a case where the unstemmed form retrieves one word that is linked with <strong class="bold">anger</strong> and <strong class="bold">surprise</strong> but the stemmed form retrieves that word plus one that is just linked with <strong class="bold">anger</strong>. In the first case, the tweet will be labeled overall as <strong class="bold">anger+surprise</strong>, while in the second, it will be linked with <span class="No-Break">just </span><span class="No-Break"><strong class="bold">anger</strong></span><span class="No-Break">.</span></p>
<p>Using a better <a id="_idIndexMarker531"/>stemmer will improve the performance of the non-English versions of this approach, but the performance of the English version provides an upper limit – after all, there will be cases where the English word expresses some emotion that the translation doesn’t, and in those cases, any inferences based on the translation will be wrong. Suppose, for instance, that the English word <em class="italic">sick</em> was marked as being positive (which it often is in informal texts, though EMOLEX doesn’t recognize this); it is very unlikely that the French word <em class="italic">malade</em>, which is given as a translation, has the same informal interpretation. However, using EMOLEX, as described previously, would lead to the same emotions being ascribed to a French text that contains <em class="italic">malade</em> as those ascribed to an English one <span class="No-Break">containing </span><span class="No-Break"><em class="italic">sick</em></span><span class="No-Break">.</span></p>
<p>The EMOLEX lexicon for English is fairly large (14K words) and has been constructed following fairly strict guidelines, so it gives a reasonable indication of what can be achieved using a manually constructed lexicon. Can we do any better by extracting a lexicon from a <span class="No-Break">training corpus?</span></p>
<h2 id="_idParaDest-86"><a id="_idTextAnchor122"/>Extracting a sentiment lexicon from a corpus</h2>
<p>Extracting a lexicon <a id="_idIndexMarker532"/>from a corpus marked up for emotions is easy (once you have a corpus that has been marked up for emotions, which can be an extremely time-consuming and laborious thing to get). Just look at each tweet in the corpus: if it is annotated as contributing to some emotion, increment the number of times it has voted for that emotion, and at the end find out which emotion it has voted for most often. The corpus is used to make an instance of a class called <strong class="source-inline">SIMPLELEXCLASSIFIER</strong>, which is a realization of the <strong class="source-inline">BASECLASSIFIER</strong> class introduced previously. The key methods of this class are <strong class="source-inline">calculateScores</strong>, which iterates <a id="_idIndexMarker533"/>the training data (embodied as <strong class="source-inline">DATASET</strong>) to create the lexicon, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">applyToTweet</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
    def calculateScores(self):        for word, cols in self.dataset.index.items():
            # set up a list of zeros to correspond to the
            # emotions in the dataset
            self.scoredict[word] = [0]*len(self.emotions)
            # count the non-zero emotions for this word
            s = sum(len(col) for col in cols.values())
            if s &gt; 0:
                for col in cols:
                    # use s to rebalance the scores for
                    # emotions for this word so they add up
                    # to 1
                    self.scoredict[word][self.colindex[col]]
                                                   = len(cols[col])/s</pre>
<p>This gives a range of scores for each word for each emotion – <em class="italic">sorry</em>, for instance, scores <strong class="bold">anger</strong>:0.62, <strong class="bold">fear</strong>:0.10, <strong class="bold">joy</strong>:0.00, <strong class="bold">sadness</strong>:0.29 – that is, it expresses mainly anger (most tweets containing it have been labeled as <strong class="bold">anger</strong>) but also sadness and, to a slight <span class="No-Break">extent, fear.</span></p>
<p>Given this range <a id="_idIndexMarker534"/>of scores for individual words, we can expect complete tweets to contain a mixture of scores. So, we need to choose a threshold at which we say a tweet expresses an emotion. Thus, the definition of <strong class="source-inline">applyToTweet</strong> is <span class="No-Break">as follows:</span></p>
<pre class="source-code">
    def applyToTweet(self, tweet):        scores = [0]*len(self.emotions)
        for token in tweet.tokens:
            if token and token in self.scoredict:
                for i, x in enumerate(
                self.scoredict[token]):
                    scores[i] += x
        m = max(scores)
        return [1 if x &gt;= m*self.threshold else 0 for x in scores]</pre>
<p>The choice of threshold is crucial. As we increase the threshold, the precision will go up (by definition, as the threshold goes up, fewer tweets will meet it; however, the ones that do meet or exceed it are more likely to be correct, so the proportion that is correctly assigned an emotion will increase) and the recall will go down (because fewer tweets will meet it and some of the ones that do not will be ones that should have been included). The following tables show what happens with different thresholds for our datasets (we have added the aclIMDB and KWT.M-AR sets at this point – neither of these worked at all with the EMOLEX-based classifier). The following table shows the scores we get for the various datasets using a threshold of 1 and no stemming. Note the extremely high score we obtain for aclIMDB: this is due largely to the fact that this dataset only contains two emotions, so if we simply made random guesses, we would expect to obtain a score of 0.5, whereas since <a id="_idIndexMarker535"/>the SEM11 datasets have 11 emotions, random guessing would have an expected score <span class="No-Break">of 0.09:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table008">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.664</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.664</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.664</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.664</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.497</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.614</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.258</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.363</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.365</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.222</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.601</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.601</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.601</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.601</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.430</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.503</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.503</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.503</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.503</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.336</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">aclImdb-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.839</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.839</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.839</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.839</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.722</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.672</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.672</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.672</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.672</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.506</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.647</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.283</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.394</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.413</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.245</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">KWT.M-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.768</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.757</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.762</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.768</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.616</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.541</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.664</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.596</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.542</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.425</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.486</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.293</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.365</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.367</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.224</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7 – Simple lexicon-based classifier, threshold=1, no stemming</p>
<p>This contrasts with the results we get when we lower the threshold to 0.5, as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">.</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table009">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.281</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.997</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.438</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.465</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.281</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM11-EN</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.365</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.767</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.494</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.487</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.328</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.287</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.989</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.444</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.471</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.286</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.365</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.803</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.502</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.508</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.335</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">aclImdb-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.500</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">1.000</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.667</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.667</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.500</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.454</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.858</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.594</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.654</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.422</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM11-AR</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.430</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.728</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.541</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.546</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.371</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">KWT.M-AR</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.795</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.785</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.790</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.795</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.652</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.311</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.879</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.460</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.516</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.299</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM11-ES</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.315</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.625</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.419</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.421</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.265</strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8 – Simple lexicon-based classifier, threshold=0.5, no stemming</p>
<p>As expected, the precision decreases and the recall increases as we lower the threshold. The size of this <a id="_idIndexMarker536"/>effect varies from dataset to dataset, with different thresholds producing different Jaccard and macro-F1 scores – the Jaccard score for SEM4-EN at threshold 1 is better than the score for this dataset at threshold 0.5, whereas, for SEM-11-EN, the Jaccard score is better at 0.5 than at 1. Note that the scores for the SEM-11 and KWT.M cases are all better at the lower threshold: this happens because these cases all allow multiple emotions to be assigned to a single tweet. Lowering the threshold lets the classifier find more emotions, which is helpful if large numbers of tweets have multiple emotions. We will return to this issue in <a href="B18714_10.xhtml#_idTextAnchor193"><span class="No-Break"><em class="italic">Chapter </em></span><span class="No-Break"><em class="italic">10</em></span></a><span class="No-Break">, </span><span class="No-Break"><em class="italic">Multiclassifiers</em></span><span class="No-Break">.</span></p>
<p>We can attempt to find the best threshold automatically: find the lowest and highest scores that any tweet has and then try a range of thresholds between these two values. We apply this algorithm to a small section of the training data – we cannot apply it to the test data, but experimentation shows that we do not need the full training set to arrive at good values for <span class="No-Break">the threshold:</span></p>
<pre class="source-code">
    def bestThreshold(self, test=None, show=False):        if test is None:
            test = self.test.tweets
        # Apply this classifier to the tweets we are
        # interested in: setting probs=True forces it to
        # return the values actually calculated by the
        # classifier rather than the 0/1 version obtained
        # by using the threshold
        train = self.train.tweets[:len(test)]
        l = self.applyToTweets(train, threshold=0,
                               probs=True)
        # The optimal threshold must lie somewhere between
        # the smallest and largest scores for any tweet
        start = threshold = min(min(tweet.predicted) for tweet in train)
        end = max(max(tweet.predicted) for tweet in train)
        best = []
        # Go from start to end in small steps using
        # increasing values for threshold
        while threshold &lt;= end:
            l = self.applyToTweets(train,
                                   threshold=threshold)
            # getmetrics returns macro F1, true positives,
            # false positives, false negatives
            (macroF, tp, fp, fn)
                    = metrics.getmetrics([tweet.GS for tweet in test], l)
            # Jaccard
            j = tp/(tp+fp+fn)
            best = max(best, [j, threshold])
            threshold += (end-start)/20
        return round(best[1], 5)</pre>
<p>Using this to <a id="_idIndexMarker537"/>find the optimal threshold, we find that in every case, automatically extracting the lexicon produces a better score than the original scores <span class="No-Break">with EMOLEX:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table010">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.617</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.732</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.670</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.683</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.503</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.475</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.564</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.515</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.515</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.347</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.571</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.669</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.616</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.623</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.445</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.487</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.554</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.518</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.522</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.350</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">aclImdb-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.839</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.839</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.839</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.839</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.722</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.672</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.672</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.672</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.672</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.506</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.485</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.632</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.549</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.549</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.378</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">KWT.M-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.816</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.812</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.814</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.817</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.687</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.541</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.664</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.596</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.542</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.425</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.372</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.493</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.424</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.429</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.269</strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.9 – Standard datasets, optimal thresholds, no stemming</p>
<p>Unsurprisingly, the scores here are as good as or better than the scores obtained with 1.0 or 0.5 as thresholds since we have tried a range of thresholds and chosen the best – if the best is indeed 1.0 or 0.5, then the score will be as in those tables, but if not, it must be better (or we would not have <span class="No-Break">chosen it!).</span></p>
<p>Using the optimal <a id="_idIndexMarker538"/>thresholds with stemming produces worse results in several cases. In the English cases, the performance is, at best, fractionally better than when we do not do stemming, though it does help with some of the <span class="No-Break">non-English cases:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table011">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.610</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.729</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.664</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.677</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.497</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM11-EN</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.478</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.562</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.516</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.518</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.348</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.566</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.658</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.609</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.615</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.437</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">CARER-EN</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.477</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.569</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.519</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.522</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.350</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">aclImdb-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.684</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.964</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.800</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.827</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.667</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM4-AR</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.651</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.701</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.675</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.683</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.509</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM11-AR</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.497</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.635</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.557</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.554</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.386</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">KWT.M-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.802</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.793</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.797</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.801</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.663</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.516</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.692</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.591</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.531</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.420</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM11-ES</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.376</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.493</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.427</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.431</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.271</strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.10 – Standard datasets, optimal thresholds, stemmed</p>
<p>It is less surprising that we get the greatest improvement from the EMOLEX-based classifiers with the large dataset: EMOLEX contains 24.9K words,  the lexicons extracted from the SEM4-EN, SEM11-EN, and WASSA datasets contain 10.8K, 17.5K, and 10.9K words, respectively, and the lexicon extracted from CARER contains 53.4K words. In other words, the increase in the size of the extracted lexicon is much greater for the large dataset, which is why the improvement over the hand-coded one is <span class="No-Break">also greater.</span></p>
<p>The various <a id="_idIndexMarker539"/>lexicons all link emotionally loaded words with the emotions they express. Using the CARER dataset, we can see that we get sensible associations for some common words that would be used to <span class="No-Break">express emotions:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table012">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">anger</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">fear</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">joy</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">love</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">sadness</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">surprise</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">adores</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.11</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.44</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.33</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.11</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">happy</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.08</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.05</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.62</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.05</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.17</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.03</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">hate</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.22</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.13</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.16</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.06</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.42</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.02</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">joy</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.07</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.05</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.53</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.12</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.21</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">love</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.09</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.07</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.42</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.19</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.21</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.03</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">sad</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.14</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.08</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.11</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.03</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.61</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.03</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">scared</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.71</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.07</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.01</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.14</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.02</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">sorrow</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.15</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.24</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.13</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.41</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">terrified</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.01</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.90</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.03</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.01</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.01</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.11 – Emotions associated with significant words, the CARER dataset</p>
<p>If we look at other words that would not be expected to have any emotional significance, however, we will find <span class="No-Break">something surprising:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table013">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">anger</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">fear</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">joy</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">love</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">sadness</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">surprise</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>a</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.13</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.12</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.35</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.10</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.27</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">and</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.13</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.11</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.35</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.09</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.28</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">the</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.13</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.11</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.37</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.10</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.26</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.12 – Emotions associated with common words, the CARER dataset</p>
<p>The word <em class="italic">a</em> occurs in almost every text in this dataset – every text that expresses anger, every text that expresses fear, and so on. So, it contains scores that reflect the distribution of emotions in the dataset: <em class="italic">a</em>, <em class="italic">and</em>, and <em class="italic">the</em> all get scores of around 0.13 for anger, which simply <a id="_idIndexMarker540"/>reflects the fact that about 13% of the tweets express this emotion; they each get scores of about 0.11 for fear because about 11% of the tweets express fear, and <span class="No-Break">so on.</span></p>
<p>There are three obvious things we can do to try to solve <span class="No-Break">this problem:</span></p>
<ul>
<li>We can manually produce a list of stop words. This tends to be a poor way to proceed since it relies very heavily on intuitions, which are often unreliable when people are thinking about words <span class="No-Break">in isolation.</span></li>
<li>We can try to weed out words that do not contribute to the distinctive meaning of the text we are <span class="No-Break">looking at.</span></li>
<li>We can adjust the degree to which a word votes more strongly for one emotion than <span class="No-Break">for others.</span></li>
</ul>
<p>Let’s discuss the last two <span class="No-Break">in detail.</span></p>
<p><em class="italic">Weeding out words that do not contribute much to the distinctive meaning of a text</em>: If a word occurs extremely frequently across a corpus, then it cannot be used as a good indicator of whether one text in the corpus is similar to another. This notion is widely used when computing similarity between texts, so it is worth looking at whether it can help us with the problem of common words voting <span class="No-Break">for emotions.</span></p>
<p>The most commonly used measure for assessing the contribution that a word makes to the distinctiveness <a id="_idIndexMarker541"/>of a text is <strong class="bold">term frequency/inverse document frequency</strong> (<strong class="bold">TF-IDF<a id="_idTextAnchor123"/></strong>) (Sparck Jones, 1972). Term frequency is the number of times the word in question occurs in a given document, whereas document frequency is the number of documents that it occurs in. So, if a word occurs frequently in a document, then it may be important for that document, but if it occurs in every single document, then it probably is not. It is customary to take the log <a id="_idIndexMarker542"/>of the document frequency to smooth out the effect of very common words, and it is essential to add 1 to the document frequency to make sure that we are not trying to take the log <span class="No-Break">of 0:</span></p>
<p><img alt="&lt;math  display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" height="91" src="image/14.png" style="vertical-align:-0.852em;height:2.185em;width:27.069em" width="1128"/></p>
<p>Using this measure to weight the contributions of individual words produces <span class="No-Break">the following:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table014">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.546</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.546</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.546</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.546</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.375</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.554</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.232</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.327</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.328</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.195</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.492</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.492</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.492</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.492</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.326</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.518</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.518</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.518</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.518</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.350</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">aclImdb-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.815</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.815</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.815</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.815</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.687</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.638</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.638</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.638</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.638</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.468</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.592</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.261</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.362</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.378</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.221</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">KWT.M-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.804</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.789</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.797</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.802</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.662</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.503</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.661</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.571</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.510</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.400</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.439</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.279</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.341</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.348</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.206</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.13 – Using TF-IDF to adjust the weights</p>
<p>These scores are not an improvement on the originals: using TF-IDF does not help with our task, at least not in isolation. We will find that it can be useful when used in combination with other measures, but by itself, it is <span class="No-Break">not useful.</span></p>
<p><em class="italic">Adjusting the degree to which a word votes more strongly for one emotion than for others</em>: Revisiting the tables of weights for individual words, we can see that the weights for <em class="italic">a</em> are very <a id="_idIndexMarker543"/>evenly distributed, whereas the scores for <em class="italic">terrified</em> scores highly for <strong class="bold">fear</strong> and very low for <span class="No-Break">anything else:</span></p>
<table class="No-Table-Style" id="table015">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">anger</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">fear</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">joy</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">love</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">sadness</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">surprise</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>a</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.13</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.12</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.35</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.10</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.27</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">terrified</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.01</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.90</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.03</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.01</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.01</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.14 – Emotions associated with “a” and “terrified,” the CARER dataset</p>
<p>If we subtract the average for a score from the individual scores, we end up with a much more sensible set of scores: a conditional probability classifier, <strong class="source-inline">CPCLASSIFIER</strong>, is a subclass of <strong class="source-inline">SIMPLELEXCLASSIFIER</strong>, which simply has the definition of <strong class="source-inline">calculateScores</strong> changed to <span class="No-Break">the following:</span></p>
<pre class="source-code">
    def calculateScores(self):        for word, cols in self.dataset.index.items():
            best = False
            bestscore = -1
            self.scoredict[word] = [0]*len(self.emotions)
            for col in cols:
                self.scoredict[word][self.colindex[col]]
                                         = len(cols[col])
            s = sum(self.scoredict[word])
            for i, x in enumerate(self.scoredict[word]):
                if s &gt; 0:
                   x = x/s-1/len(self.emotions))
                  self.scoredict[word][i] = max(0, x)</pre>
<p>In other words, the only change is that we subtract the average score for emotions for a given word <a id="_idIndexMarker544"/>from the original, so long as the result of doing that is greater than 0. This changes the values for a common word and an emotionally laden word, as <span class="No-Break">shown here:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table016">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">anger</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">fear</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">joy</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">love</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">sadness</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">surprise</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>a</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.18</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.10</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">terrified</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.73</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.00</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.15 – Emotions associated with “a” and “terrified,” the CARER dataset, bias emphasized</p>
<p>Here, the scores for <em class="italic">a</em> have been greatly flattened out, while <em class="italic">terrified</em> only votes <span class="No-Break">for </span><span class="No-Break"><strong class="bold">fear</strong></span><span class="No-Break">:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table017">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM4-EN</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.714</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.779</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.745</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.752</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.593</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM11-EN</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.471</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.582</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.521</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.518</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.352</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">WASSA-EN</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.604</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.769</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.677</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.692</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.512</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.539</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.640</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.585</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.589</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.414</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">aclImdb-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.798</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.883</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.838</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.847</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.721</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.592</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.747</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.661</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.684</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.493</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.476</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.624</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.540</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.540</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.370</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">KWT.M-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.814</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.811</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.813</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.816</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.684</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.194</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.948</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.321</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.310</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.191</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.400</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.471</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.433</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.435</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.276</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.16 – Increased bias lexicon-based classifier, optimal thresholds, no stemming</p>
<p>Changing the <a id="_idIndexMarker545"/>weights in this way without stemming improves or has very little effect on the scores for nearly all the <span class="No-Break">English cases:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table018">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM4-EN</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.718</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.772</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.744</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.750</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.593</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM11-EN</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.479</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.573</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.522</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.520</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.353</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.641</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.703</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.671</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.675</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.505</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.512</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.633</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.566</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.570</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.395</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">aclImdb-EN</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.799</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.882</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.839</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.848</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.722</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM4-AR</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.651</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.709</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.679</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.686</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.513</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.501</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.616</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.553</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.552</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.382</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">KWT.M-AR</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.801</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.797</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.799</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.803</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.666</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-ES</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.189</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.733</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.301</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.284</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.177</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">SEM11-ES</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.397</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.481</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.435</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.439</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.278</strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.17 – Increased bias lexicon-based classifier, optimal thresholds, stemmed</p>
<p>As ever, stemming sometimes helps with non-English examples and sometimes <span class="No-Break">it doesn’t.</span></p>
<p>So far in this chapter, we have looked at several ways of extracting a lexicon from a corpus that has <a id="_idIndexMarker546"/>been marked up with emotion labels and used this to assign emotions to unseen texts. The main lessons to be learned from these experiments are <span class="No-Break">as follows:</span></p>
<ul>
<li>Lexicon-based classifiers can provide reasonable performance for very little computational cost, though the effort involved in making lexicons, either directly or by extracting them from annotated texts, <span class="No-Break">is considerable.</span></li>
<li>Refinements such as stemming and varying the weights associated with individual words can sometimes be useful, but what works for one corpus may not work for another. For this reason, it is sensible to divide your training data into training and development sets so that you can try out different combinations to see what works with your data, on the assumption that the data you are using for training is indeed similar to the data that you will be applying it on for real. For this reason, competition data is often split into training and development sets when it <span class="No-Break">is distributed.</span></li>
<li>Having a large amount of data can be useful but after a certain point, the improvements in performance tail off. It makes sense to plot data size against accuracy for subsets of your full dataset since this allows you to fit a curve of the relationship between the two. Given such a curve, it is possible to estimate what the accuracy would be if you were able to obtain more data, and hence to decide whether it is worth trying to do so. Such an estimate will only be an approximation, but if, for instance, it is clear that the curve has already flattened out, then it is unlikely that getting more data will make <span class="No-Break">a difference.</span></li>
</ul>
<p>One of the problems with this kind of approach is that the training data may not contain every emotion-bearing word. In the next section, we will try to extend lexicons of the kind we extracted previously by looking for “similar” words to fill in <span class="No-Break">the gap.</span></p>
<h1 id="_idParaDest-87"><a id="_idTextAnchor124"/>Similarity measures and vector-space models</h1>
<p>One of the problems that any lexicon-based classifier faces is that the lexicon may not contain all <a id="_idIndexMarker547"/>the words in the test set. For the English <a id="_idIndexMarker548"/>datasets we have been looking at, EMOLEX and the lexicon extracted from the training data contain the following percentages of the words in the <span class="No-Break">development sets:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table019">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><strong class="bold">% of words in the </strong><span class="No-Break"><strong class="bold">extracted dictionary</strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">% of words </strong><span class="No-Break"><strong class="bold">in EMOLEX</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.46</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.20</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.47</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.19</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.55</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.21</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.95</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.44</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.18 – Words in the test sets that are in one of the lexicons</p>
<p>Many of the words that are missing from EMOLEX will be function words (<em class="italic">a</em>, <em class="italic">the</em>, <em class="italic">in</em>, <em class="italic">and</em>, and so on) and words that carry no emotion, but it seems likely that adding more words to the lexicon will be helpful. If we knew that <em class="italic">adore</em> was very similar to <em class="italic">love</em>, but <em class="italic">adore</em> was not in the lexicon, then it would be very helpful if we could use the emotional weight of <em class="italic">love</em> when a text contained <em class="italic">adore</em>. The number of words that are missing from the extracted lexicons is more worrying. As the training data increases, the number of missing words goes down – 54% of the words in the test sets for SEM4-EN are missing in the training data, whereas only 5% are missing from CARER, but virtually none of the missing words in these cases are function words, so many are likely to <span class="No-Break">be emotion-bearing.</span></p>
<p>There are numerous ways of estimating whether two words are similar. Nearly all are based on the notion that two words are similar if they occur in similar contexts, usually using sentences or local windows as contexts, and they nearly all make use of vector-space models. In this section, we will explore these two ideas before looking at how they may be used to supplement the lexicons being used for <span class="No-Break">emotion detection.</span></p>
<h2 id="_idParaDest-88"><a id="_idTextAnchor125"/>Vector spaces</h2>
<p>It is often useful to represent things as vectors in some high-dimensional space. An obvious example <a id="_idIndexMarker549"/>is the representation of a sentence as a point in a space where each word of the language is a dimension. Recall that <strong class="source-inline">makeIndex</strong> lets us make an index linking each word to a unique identifier; <span class="No-Break">for example:</span></p>
<pre class="source-code">
{..., 'days': 6, 'sober': 7, 'do': 8, "n't": 9, 'wanna': 10,  …}</pre> <p>We can then use <strong class="source-inline">sentence2vector</strong> to convert a string of words into a vector. We make a vector full of zeros that is large enough to accommodate every word in the index. Then, we can scan the sentence and add 1 to the appropriate position in the vector for each word that <span class="No-Break">we see:</span></p>
<pre class="source-code">
def sentence2vector(sentence, index):    vector = numpy.zeros(len(index))
    for word in sentence:
        vector[index[word]] += 1
    return vector</pre>
<p>Given the preceding index, this would produce the following for the sentence <em class="italic">I don’t want to </em><span class="No-Break"><em class="italic">be sober</em></span><span class="No-Break">:</span></p>
<pre class="source-code">
&gt;&gt;&gt; list(sentence2vector("I do n't want to be sober".split(), index))[0., 0., 1., 0., 0., 0., 0., 1., 1., 1., ...]</pre>
<p>Such vectors tend to be very sparse. The index we used for constructing this vector contained 18,263 words and the sentence contained 7 distinct words, so 18,256 entries in the vector are 0. This means that a lot of space is wasted, but also that calculations involving such vectors <a id="_idIndexMarker550"/>can be very slow. Python provides tools for handling such vectors: <strong class="bold">sparse arrays</strong>. The key to the way Python does this is that instead of keeping an array that contains a place for every value, you keep three arrays: the first contains the non-zero values, and the second and third contain the row and column where a value is to be found. For our example, we would have the following (we only need the column values because our array is just <span class="No-Break">a vector):</span></p>
<pre class="source-code">
&gt;&gt;&gt; # v is the vector we just made; convert it to a sparse matrix&gt;&gt;&gt; s = sparse.csr_matrix(v)
&gt;&gt;&gt; # it contains seven 1s
&gt;&gt;&gt; list(s.data)
[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
&gt;&gt;&gt; # These are at positions 2, 7, 8, ...
&gt;&gt;&gt; list(s.indices)
[2, 7, 8, 9, 119, 227, 321]</pre>
<p>In other words, we have <a id="_idIndexMarker551"/>the value 1 at positions 2 (which was the index entry for <em class="italic">I</em>), 7 (<em class="italic">sober</em>), 8 (<em class="italic">do</em>), and <span class="No-Break">so on.</span></p>
<h2 id="_idParaDest-89"><a id="_idTextAnchor126"/>Calculating similarity</h2>
<p>The commonest use of vector representations is for calculating the similarity between two objects. We will illustrate this, and explore it a bit further, by considering it as a way of comparing <a id="_idIndexMarker552"/>sentences, but given the number of things that can be represented as vectors, the technique has a very wide range <span class="No-Break">of applications.</span></p>
<p>Consider two vectors in a simple 2D space. There are two ways of assessing how similar they are: you can see how far apart their endpoints are, or you can calculate the angle between them. In the following diagram, it is clear that the angle between the two vectors &lt;(0,0), (2.5, 2.5)&gt; and &lt;(0, 0), (4.6, 4.9)&gt; is very small, but the distance between their endpoints is quite large. It is common practice when using vector-space representations to carry out normalization, by dividing the value in each dimension by the length of <span class="No-Break">the vector:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer075">
<img alt="Figure 5.19 – Vectors to (2.5, 2.5) and (4.6, 4.9)" height="308" src="image/B18714_05_19.jpg" width="303"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.19 – Vectors to (2.5, 2.5) and (4.6, 4.9)</p>
<p>If we normalize <a id="_idIndexMarker553"/>these two vectors, we get <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.20</em>, where the angle between the vectors and the distance between their endpoints are both <span class="No-Break">very small:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer076">
<img alt="Figure 5.20 – Normalized versions of (2.5, 2.5) and (4.6, 4.9)" height="440" src="image/B18714_05_20.jpg" width="439"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.20 – Normalized versions of (2.5, 2.5) and (4.6, 4.9)</p>
<p>Most applications use the (<em class="italic">N</em>-dimensional) cosine of the angle between the vectors, but it is worth noting that for <strong class="bold">normalized</strong> vectors, the angle between V0 and V1 will be greater than that between V0 and V2 if and only if the Euclidean distance between the endpoints of V0 and V1 is greater than the distance between the endpoints of V0 and V2; so, the two measures will rank the similarity between sets of vectors identically. Calculating the cosine of the angle between two vectors in a high dimensional space is slightly confusing, but fortunately, the Python <strong class="source-inline">sklearn.metrics.pairwise</strong> library provides <strong class="source-inline">cosine_similarity</strong> for <span class="No-Break">this task.</span></p>
<p>If we apply <strong class="source-inline">sentence2vector</strong> to the sentences <em class="italic">John ate some pasta</em>, <em class="italic">John ate the pasta</em>, <em class="italic">John ate some potatoes</em>, and <em class="italic">Mary drank some beer</em>, we get <span class="No-Break">the following:</span></p>
<pre class="source-code">
S0: John ate the pasta[63, 2306, 3304, 7616]
S1: John ate some pasta
[229, 2306, 3304, 7616]
S2: John ate the potatoes
[63, 3304, 4162, 7616]
S3: Mary drank some beer
[229, 5040, 5176, 10372]</pre>
<p>This means <em class="italic">John ate some pasta</em> is represented by a vector that has 1 as the value in the 63rd, 2,306th, 3,304th, and 7,616th dimensions and zero everywhere else, and similarly for the <a id="_idIndexMarker554"/>other sentences. If we compute the cosine similarity of each pair, we get <span class="No-Break">the following:</span></p>
<pre class="source-code">
      S0      S1      S2      S3S0    1.00    0.75    0.75    0.25
S1    0.75    1.00    0.50    0.00
S2    0.75    0.50    1.00    0.25
S3    0.25    0.00    0.25    1.00</pre>
<p>In other words, every sentence is identical to itself, <strong class="source-inline">S0</strong>, <strong class="source-inline">S1</strong>, and <strong class="source-inline">S2</strong> are quite similar to one another, and <strong class="source-inline">S3</strong> is fairly different from the others. This all seems fairly sensible, save that <strong class="source-inline">S0</strong>, <strong class="source-inline">S1</strong>, and <strong class="source-inline">S2</strong> all have <strong class="bold">identical</strong> similarity scores. That doesn’t seem quite as reasonable – surely <em class="italic">John ate some pasta</em> and <em class="italic">John ate the pasta</em> are more similar than <em class="italic">John ate some pasta</em> and <em class="italic">John ate </em><span class="No-Break"><em class="italic">some potatoes</em></span><span class="No-Break">.</span></p>
<p>The key here is that some words seem to be more important than others <em class="italic">when you are trying to calculate how similar two sentences are</em>. This is not to say that words such as <em class="italic">some</em> and <em class="italic">the</em> are not important when you are trying to work out what a sentence means, but if, for instance, you want to see whether two sentences are about the same general topic, then maybe these closed class items are <span class="No-Break">less significant.</span></p>
<p>You could try to deal with this by providing a list of <strong class="bold">stop words</strong>, which should be ignored when you are turning a sentence into a vector. However, there are two problems with <span class="No-Break">this approach:</span></p>
<ul>
<li>It is very hard to work out which words should be ignored and which <span class="No-Break">ones shouldn’t</span></li>
<li>It’s a very blunt instrument – some words seem to make very little difference when you are comparing sentences, some make a bit of difference but not much, and some are <span class="No-Break">highly significant</span></li>
</ul>
<p>What we want <a id="_idIndexMarker555"/>is a number that we can use to weight different words for <span class="No-Break">their significance.</span></p>
<p>We will use TF-IDF to assign weights to words. There are several minor variations on how to calculate TF-IDF, with some working better with long documents and some with shorter ones (for example, when a document is just a single sentence), but the following is a reasonably <a id="_idIndexMarker556"/>standard version. We start by calculating an <strong class="bold">inverse document frequency</strong> table. We walk through the set of documents, getting the set of words in each document, and then increment a counter for each word in the set. This gives us a count of the number of documents each word appears in. We then make the inverse table by getting the reciprocal of the log of each entry – we need the reciprocal because we are going to want to divide by these values. We may as well do that now so that we can replace division with multiplication later on. It is standard practice to use the log at this point, though there is no very strong theoretical reason for doing so and there are cases (particularly with very short documents) where the raw value <span class="No-Break">works better:</span></p>
<pre class="source-code">
def getDF(documents, uselog=numpy.log):    # adding something to df either sets or increments a counter
    df = counter()
    for document in enumerate(documents):
        # for each unique word in the document increment df
        for w in set(document.split()):
            df.add(w)
    idf = {}
    for w in df:
        idf[w] = 1.0/float(uselog(df[w])+1)
    return df, idf</pre>
<p>This produces a pair of tables, <strong class="source-inline">df</strong> and <strong class="source-inline">idf</strong>, as follows when applied to the tweets in SEM4-EN, where <em class="italic">a</em> and <em class="italic">the</em> appear in large numbers of documents and <em class="italic">man</em>, <em class="italic">cat</em>, and <em class="italic">loves</em> appear in <a id="_idIndexMarker557"/>a fairly small set, so <strong class="source-inline">df</strong> for <em class="italic">a</em> and <em class="italic">the</em> is high and their <strong class="source-inline">idf</strong> (which is the measure of how important they are in this document) <span class="No-Break">is low:</span></p>
<pre class="source-code">
       DF    IDFa      1521  0.001
the    1842  0.001
cat    5     0.167
loves  11    0.083
man    85    0.012</pre>
<p>We can use this to change <strong class="source-inline">sentence2vector</strong> so that it increments the scores by the IDF value for each word, rather than always incrementing by 1 (this is the same as multiplying the sum of a series of increments by the <span class="No-Break">IDF value):</span></p>
<pre class="source-code">
def sentence2vector(sentence, index, idf={}):    vector = numpy.zeros(len(index))
    for word in sentence:
        inc = idf[word] if word in idf else 1
        vector[index[word]] += inc
    return vector</pre>
<p><em class="italic">John ate the pasta</em> is now represented by a vector with values that represent how common the words in question are, and hence how much importance they should be given when <span class="No-Break">comparing vectors:</span></p>
<pre class="source-code">
&gt;&gt;&gt; list(S1.data)[0.008, 0.3333333333333333, 0.1, 0.5]
&gt;&gt;&gt; list(S1.indices)
[229, 2306, 3304, 7616]</pre>
<p>Using this weighted <a id="_idIndexMarker558"/>version of the various vectors, our similarity table for the four sentences becomes <span class="No-Break">as follows:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table020">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">S0</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">S1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">S2</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">S3</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">S0</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">1.0000</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.9999</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.5976</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.0000</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">S1</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.9999</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">1.0000</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.5976</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.0003</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">S2</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.5976</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.5976</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">1.0000</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.0000</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">S3</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.0000</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.0003</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.0000</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">1.0000</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.21 – Similarity table</p>
<p><strong class="source-inline">S0</strong> and <strong class="source-inline">S1</strong> are now very similar (so similar that we have had to print them to four decimal places for any difference to show up) because the weights for <em class="italic">some</em> and <em class="italic">the</em> are very low; <strong class="source-inline">S1 and S2</strong> are fairly similar to one another, and <strong class="source-inline">S3</strong> is different. By treating <em class="italic">the</em> and <em class="italic">some</em> as being less significant than <em class="italic">pasta</em> and <em class="italic">potatoes</em> for comparing similarity, we get a better measure <span class="No-Break">of similarity.</span></p>
<p>We can use cosine similarity and TF-IDF weights to compare any items that can be represented as sequences of words. We will use this to calculate how similar two words are. We can represent a word using a <strong class="bold">cooccurrence table</strong> – that is, the set of words that occur in the same context, where a context could be an article, a sentence, a tweet, or a window around the word’s position in a text – it could also be defined by requiring the two words to be syntactically related (for example, <em class="italic">eat</em> and <em class="italic">cake</em> could be seen as occurring in the same context in <em class="italic">he ate some very rich cake</em> because <em class="italic">cake</em> is the object of <em class="italic">ate</em>, even though they are some way apart in the text). We can either simply count the cooccurrences or we can weigh them using an IDF table if we <span class="No-Break">have one.</span></p>
<p>Let’s assume that <strong class="source-inline">getPairs</strong> returns a cooccurrence table of words that have occurred in the <span class="No-Break">same context:</span></p>
<pre class="source-code">
king  {'king': 144, 'new': 88, 'queen': 84, 'royal': 69, 'made': 68,...}queen  {'mother': 123, 'speech': 86, 'king': 84, 'royal': 62, ...}</pre>
<p>There are various ways of obtaining such a table. For the next few examples, we will use the fact that the BNC is already tagged to collect open class words (nouns, verbs, adjectives, and adverbs) that occur inside a window of three words on either side of the target word – for example, from the sentence, <em class="italic">It</em>-PN <em class="italic">is</em>-VB <em class="italic">often</em>-AV <em class="italic">said</em>-VV <em class="italic">that</em>-CJ <em class="italic">you</em>-PN <em class="italic">can</em>-VM <em class="italic">discover</em>-VV <em class="italic">a</em>-AT <em class="italic">great</em>-AJ <em class="italic">deal</em>-NN, we would get <strong class="source-inline">{'often': {'said': 1}, 'said': {'often': 1}, 'discover': {'great': 1, 'deal': 1}, 'great': {'discover': 1, 'deal': 1}, 'deal': {'discover': 1, 'great': 1}}</strong> because <em class="italic">often</em> and <em class="italic">said</em> are within a window of three positions of each other and so are <em class="italic">discover</em>, <em class="italic">great</em>, and <em class="italic">deal</em>. We save this table <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">pairs0</strong></span><span class="No-Break">.</span></p>
<p>We then make a <a id="_idIndexMarker559"/>document frequency table and reduce this so that it only contains the top <em class="italic">N</em> words (we do this by sorting it, getting the <em class="italic">N</em> highest-scoring cases, and then reconstructing it as a table), and we use the reduced table to get a cooccurrence table (<strong class="source-inline">pairs1</strong>) that only contains the top <em class="italic">N</em> words. If we only consider the top 10,000 words, we will get comparisons between most words that we are likely to be interested in and we will reduce the amount of computation to be carried out when constructing the similarity table. We weight the scores in this table by the document frequency for the words that it contains (we use a version of TF-IDF in which we do not take logs since this seems to work better in this case), storing this in <strong class="source-inline">pairs2</strong>. Finally, we convert <strong class="source-inline">pairs2</strong> into a sparse matrix and use <strong class="source-inline">cosine_similarity</strong> to calculate the similarity scores for every word in <span class="No-Break">the matrix:</span></p>
<pre class="source-code">
class TF-IDFMODE():    def __init__(self, uselog=log, corpus=corpora.BNC, N=10000):
        self.pairs0 = getPairs(corpus)
        self.df = sortTable(getDF(self.pairs0))[:N]
        self.df = {x[0]:x[1] for x in self.df}
        self.pairs1 = {}
        for word in self.pairs0:
            if word in self.df:
                self.pairs1[word] = {}
                for other in self.pairs0[word]:
                    if other in self.df:
                        self.pairs1[word][other]\
                                 = self.pairs0[word][other]
        self.pairs2 = applyIDF(self.pairs1, df=self.df, uselog=uselog)
        self.dimensions, self.invdimensions, self.matrices\
            = pairs2matrix(self.pairs2)
        self.similarities = cosine_similarity(
            self.matrices)</pre>
<p>Applying this to the entire BNC (approximately 100 million words), we get an initial DF table and set <a id="_idIndexMarker560"/>of cooccurring pairs with just over 393K entries each, which means that if we do not reduce them to the commonest 10K words, the cooccurrence table would potentially have 393,000**2 entries – that is, about 15G entries. Reducing this so that only the top 10K words are included reduces the potential size of the cooccurrence table to 100M entries, but this table is fairly sparse, with the sparse representation containing just under <span class="No-Break">500K entries.</span></p>
<p>Typical entries in the cooccurrence table look as follows (just showing the highest scoring co-occurring entries for each word). These all look reasonable enough – they are all words that you can imagine cooccurring with the <span class="No-Break">given targets:</span></p>
<pre class="source-code">
cat:  mouse:0.03, litter:0.02, ginger:0.02, stray:0.02, pet:0.02dog:  stray:0.05, bark:0.03, pet:0.03, shepherd:0.03, vet:0.02
eat:  sandwiches:0.03, foods:0.03, bite:0.03, meat:0.02, cake:0.02
drink: sipped:0.08, alcoholic:0.03, pints:0.03, merry:0.02, relaxing:0.02</pre>
<p>Calculating the pairwise similarities between rows in this table is remarkably quick, taking about 1.3 seconds on a standard MacBook with a 2.8 GHz processor. To make use of the similarity table, we have to map words to their indices to get into the matrix and then map indices <a id="_idIndexMarker561"/>back to words to interpret the results, but apart from that, finding the “most similar” words to a given target is <span class="No-Break">very simple:</span></p>
<pre class="source-code">
    def nearest(self, word, N=6):        similarwords = self.similarities[self.dimensions[word]]
        matches = list(reversed(sorted([x, i]\
                       for i, x in enumerate(similarwords)))[1:N]
        return [(self.invdimensions[i], s) for [s, i] in matches]</pre>
<p>Looking at a set of common words, we can see that the most similar ones have quite a lot in common with the targets, so it seems plausible that calculating word similarity based on whether two words occur in the same contexts may be useful for a range <span class="No-Break">of tasks:</span></p>
<pre class="source-code">
Best matches for cat:dog:0.39,cats:0.25,keyboard:0.23,bin:0.23,embryo:0.22
Best matches for dog:
dogs:0.42,cat:0.39,cats:0.35,hairs:0.26,bullet:0.24
Best matches for eat:
ate:0.35,eaten:0.35,cakes:0.28,eating:0.28,buffet:0.27
Best matches for drink:
brandy:0.41,beer:0.41,coffee:0.38,lager:0.38,drinks:0.36</pre>
<p>Some of these are just the inflected forms of the originals, which shouldn’t be too surprising – <em class="italic">eat</em>,  <em class="italic">ate</em>, <em class="italic">eaten</em>, and <em class="italic">eating</em> are all very similar words! The ones that are not just inflected forms <a id="_idIndexMarker562"/>of the targets contain some plausible-looking pairs (<em class="italic">cat</em> and <em class="italic">dog</em> are returned as being very similar and the matches for <em class="italic">drink</em> are all things you can drink), along with some oddities. We will return to the question of whether this is useful for our <span class="No-Break">task shortly.</span></p>
<h2 id="_idParaDest-90"><a id="_idTextAnchor127"/>Latent semantic analysis</h2>
<p>Using TF-IDF weights makes it possible to discount items that occur in large numbers of contexts, and which <a id="_idIndexMarker563"/>therefore are unlikely to be useful when distinguishing between contexts. An alternative strategy is to try to find combinations of weights that produce <strong class="bold">fixed points</strong> – that is, those that can be used to recreate the original data. If you remove the least significant parts of such combinations, you can approximate the essence of the original data and use that to <span class="No-Break">calculate similarities.</span></p>
<p>We will learn how to use neural networks for this purpose later. For now, we will consider an approach known as <strong class="bold">latent semantic analysis</strong> (<a id="_idTextAnchor128"/><strong class="bold">LSA</strong>) (Deerwester et al., 1990), which uses matrix algebra to produce lower-dimensional approximations of the original data. The key here is that given any MxN matrix, A, you can find an MxM matrix, U, a vector, S, of length M where the elements of U are given in decreasing order, and an NxM matrix, V, such that A = (U * S) dot V. U, S,  and V provide a fixed point of the original data. If S’ is obtained from S by setting some of the lower values of S to 0, then (U * S’) dot V becomes an approximation of A, where S’ is of a lower dimension <span class="No-Break">than S.</span></p>
<p>As an example, we will start with a 6x8 array of <span class="No-Break">random integers:</span></p>
<pre class="source-code">
61.0    26.0    54.0    90.0    9.0    19.034.0    53.0    73.0    21.0    17.0    67.0
59.0    75.0    33.0    96.0    59.0    24.0
72.0    90.0    79.0    88.0    48.0    45.0
77.0    24.0    88.0    65.0    33.0    94.0
44.0    0.00    55.0    61.0    71.0    92.0</pre>
<p>U, S, and V are <a id="_idIndexMarker564"/><span class="No-Break">as follows:</span></p>
<pre class="source-code">
-0.4    0.1    0.3    0.3    0.3   -0.8-0.4   -0.5   -0.5    0.6    0.1    0.2
-0.3    0.3    0.5    0.2    0.4    0.6
-0.5    0.7   -0.5   -0.2   -0.1    0.0
-0.4   -0.5    0.1   -0.7    0.2    0.0
-0.4   -0.1    0.3    0.1   -0.8    0.0
356.95    103.09    90.57    61.44    53.85    14.53
-0.4   -0.4   -0.3   -0.4   -0.3   -0.3   -0.3   -0.4
-0.4   -0.1    0.7   -0.4   -0.0    0.2   -0.2    0.4
 0.2   -0.5    0.0   -0.1    0.0   -0.5    0.4    0.5
 0.1   -0.2   -0.0    0.3   -0.8    0.3   -0.1    0.3
 0.7   -0.4    0.1   -0.3    0.2    0.2   -0.5   -0.1
-0.3   -0.5   -0.4    0.1    0.4    0.6    0.2    0.1</pre>
<p>If we set the last element of S to 0 and calculate (U * S) dot V, we get <span class="No-Break">the following:</span></p>
<pre class="source-code">
76.8    42.8    51.1    46.5    35.2    45.4    40.1    78.972.8    76.4     2.0    78.6    10.9    65.3    16.4    19.8
59.7    13.3    52.3    22.7    27.5    25.6    36.2    79.2
26.2    98.3    93.2    36.9    60.7    84.6    19.9    69.9
92.2    74.3    14.2    57.9    85.8    22.6    52.9    35.9
44.1    64.1    29.1    69.0    31.9    17.9    76.0    78.0</pre>
<p>This is a reasonable approximation to <span class="No-Break">the original.</span></p>
<p>LSA works by applying this notion to cooccurrence matrices of the kind we have been looking at. Given the <a id="_idIndexMarker565"/>size of such matrices, it can be difficult to calculate S in full. So, we must restrict the number of entries that we want on S, rather than calculating the full set and then zeroing <span class="No-Break">some out.</span></p>
<p>By restricting the length of S to 1,000, we get the following nearest neighbors for <em class="italic">cat</em>, <em class="italic">dog</em>, <em class="italic">drink</em>, <span class="No-Break">and </span><span class="No-Break"><em class="italic">eat</em></span><span class="No-Break">:</span></p>
<pre class="source-code">
Best matches for cat:cats:0.66,hairs:0.62,dog:0.61,dogs:0.60,hair:0.54
Best matches for dog:
dogs:0.72,cats:0.68,cat:0.61,pet:0.54,bull:0.46
Best matches for eat:
meat:0.77,sweets:0.75,ate:0.75,chicken:0.73,delicious:0.72
Best matches for drink:
pint:0.84,sherry:0.83,brandy:0.83,beer:0.81,drank:0.79</pre>
<p>The changes from the original set are not dramatic – the inflected forms of <em class="italic">eat</em> have been demoted with various things that you can eat appearing high in the list, but apart from that, the changes are not all <span class="No-Break">that significant.</span></p>
<p>However, calculating the SVD of a cooccurrence matrix, particularly if we allow less common words to appear as columns, becomes infeasible as the matrix gets larger, and hence alternative solutions are required if we want to handle gigabytes of training data, rather than the 100 million words of the BNC. The<a id="_idTextAnchor129"/> <strong class="bold">GLoVe</strong> (Pennington et al., 2014) model of word similarity essentially calculates the SVD of the matrix using an algorithm that is not as badly affected by the size of the cooccurrence matrix, while the <strong class="bold">word2vec</strong> alg<a id="_idTextAnchor130"/>orithm (Mikolov et al., 2013) works <a id="_idIndexMarker566"/>by using a deep neural network to learn to predict a word from the context, and then uses the excitation levels in the penultimate layer in the network when a word is input as the vector-space model of that word (we will discuss neural networks in <a href="B18714_08.xhtml#_idTextAnchor157"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Neural Networks and Deep Neural Nets</em>; in the following examples, we will use the <strong class="source-inline">gensim</strong> (<a href="https://radimrehurek.com/gensim/intro.xhtml">https://radimrehurek.com/gensim/intro.xhtml</a>) version <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">word2vec</strong></span><span class="No-Break">).</span></p>
<p>Returning to our task, the problem we were considering was that the training data may not contain all the words that appear in the test data. If a word in the test data should contribute to the emotional tag assigned to a sentence but is missing from the training data, then we cannot <a id="_idIndexMarker567"/>calculate its contribution to the emotion of that sentence. We can try to use these notions of similarity to fill in the gaps in our lexicons: if we have a word in the target text that does not appear in the emotion lexicon, we could substitute it with the nearest word according to our similarity metric that does. If the similarity lexicon returns words that have similar emotional associations, then that should improve the recall, and possibly the precision, of our emotion <span class="No-Break">mining algorithms.</span></p>
<p>We can extend the method for calculating the scores for a given tweet like so. The key is that if some word is not in the sentiment lexicon, we use <strong class="source-inline">chooseother</strong> to select the nearest word according to the <span class="No-Break">similarity metric:</span></p>
<pre class="source-code">
    def chooseother(self, token):        # If the classifier has a model, use that to find
        # the 5 most similar words to the target and go
        # through these looking for one that is in the
        # sentiment lexicon
        if self.model:
            try:
                for other in self.model.nearest(token, topn=5):
                    other = other[0]
                    if other in self.scoredict:
                        return other
            except:
                pass
        return False
    def applyToTweet(self, tweet):
        scores = [0]*len(self.emotions)
        for token in tweet.tokens:
            if not token in self.scoredict:
                token = self.chooseother(token)
            if token in self.scoredict:
                for i, x in enumerate(self.scoredict[token]):
                    scores[i] += x
        m = max(scores)
        return [1 if x &gt;= m*self.threshold else 0 for x in scores]</pre>
<p>The following <a id="_idIndexMarker568"/>results show what happens when we combine a <strong class="source-inline">word2vec</strong> model derived from the entire BNC with the classification algorithm that we get by extracting a lexicon from the training data without stemming. The first table is just the one we had earlier for the English datasets (the <strong class="source-inline">word2vec</strong> model trained on the BNC will only work with the English datasets) with optimal thresholds, repeated here for ease <span class="No-Break">of comparison:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table021">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.718</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.772</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.744</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.750</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.593</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.474</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.579</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.521</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.520</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.353</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.641</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.703</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.671</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.675</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.505</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.512</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.633</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.566</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.570</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">0.395</strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.22 – Lexicon-based classifier, basic English datasets, optimal thresholds, no stemming, no model</p>
<p>When we try <a id="_idIndexMarker569"/>to use a <strong class="source-inline">word2vec</strong> model trained on the entire BNC, we get <span class="No-Break">the following:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table022">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Micro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Macro-F1</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Jaccard</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM4-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.699</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.753</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.725</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.731</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.569</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">SEM11-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.471</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.574</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.518</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.515</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.349</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">WASSA-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.618</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.682</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.648</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.654</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.480</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">CARER-EN</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.510</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.631</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.564</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.568</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.393</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.23 – Lexicon-based classifier, basic English datasets, optimal thresholds, no stemming, word2vec as the model</p>
<p>In every case, using the <strong class="source-inline">word2vec</strong> model makes things worse. Why? We can look at the words that are substituted for missing words and the emotions that <span class="No-Break">they carry:</span></p>
<pre class="source-code">
…cat chosen for kitten: anger:0.05, fear:0.10, joy:0.00, sadness:0.00
fall chosen for plummet: anger:0.00, fear:0.04, joy:0.04, sadness:0.02
restrain chosen for evict: anger:0.72, fear:0.00, joy:0.00, sadness:0.00
arrogance chosen for cynicism: anger:0.72, fear:0.00, joy:0.00, sadness:0.00
overweight chosen for obese: anger:0.00, fear:0.72, joy:0.00, sadness:0.00, neutral:0.00
greedy chosen for downtrodden: anger:0.72, fear:0.00, joy:0.00, sadness:0.00
sacred chosen for ancient: anger:0.00, fear:0.72, joy:0.00, sadness:0.00
...</pre>
<p>Most of the substitutions seem reasonable – <em class="italic">cat</em> is like <em class="italic">kitten</em>, <em class="italic">fall</em> is like <em class="italic">plummet</em>, and <em class="italic">overweight</em> is like <em class="italic">obese</em>. The trouble is that while the emotion associated with the substitution is often appropriate for the substitution, it cannot be relied on to be appropriate for the target. It is conceivable that cats are linked to <strong class="bold">fear</strong>, but kittens are surely more likely to be linked to <strong class="bold">joy</strong>, and while sacred objects might invoke <strong class="bold">fear</strong>, ancient ones <span class="No-Break">surely don’t.</span></p>
<p>The problem is <a id="_idIndexMarker570"/>that two words that are classified as being similar by one of these algorithms may not have similar emotional associations. The words that co-occur with a verb tend to be the kinds of things that can be involved when the action denoted by that verb is performed, the words that cooccur with a noun tend to be the kinds of actions it can be involved in, and the words that cooccur with an adjective tend to be the kinds of things that can have the property denoted by that adjective. If we look at the performance of our 100M-word <strong class="source-inline">word2vec</strong> model on a collection of emotionally laden words, the results are <span class="No-Break">somewhat surprising:</span></p>
<pre class="source-code">
love ['hate', 'kindness', 'joy', 'passion', 'dread']hate ['adore', 'loathe', 'despise', 'hated', 'dislike']
adore ['loathe', 'hate', 'despise', 'detest', 'daresay']
happy ['pleased', 'nice', 'glad', 'lucky', 'unhappy']
sad ['funny', 'pathetic', 'miserable', 'depressing', 'strange']
furious ['stunned', 'angry', 'annoyed', 'shocked', 'horrified']
happiness ['sorrow', 'joy', 'fulfilment', 'enjoyment', 'dignity']</pre>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.24 – Most similar words to common emotionally-laden words, 100M-word word2vec model</p>
<p>In five out of the seven cases, the most similar word carries exactly the opposite emotions from the target. The problem is that the kinds of things that you can love or hate are very similar, and the kinds of things that are sad or funny are very similar. Because the training corpus contains no information about emotions, its notion of similarity pays no attention <span class="No-Break">to emotions.</span></p>
<p>This is not just <a id="_idIndexMarker571"/>an artifact of the way that <strong class="source-inline">word2vec</strong> calculates similarity or of the training set we used. We get very similar results with other algorithms and other training corpora. The following table shows the most similar words for a set of common words and for a set of emotionally-laden words with four algorithms – a simple TF-IDF model trained on the 110 million words in the BNC using a window of three words before and after the target as the “document” in which it appears; the same model after latent semantic analysis using 100 elements of the diagonal; <strong class="source-inline">word2vec</strong> trained on the same corpus; and a version of GloVe trained on a corpus of 6 <span class="No-Break">billion words:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table023">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">man</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">woman</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">king</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">queen</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">eat</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">drink</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">GLOVEMODEL</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">woman</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">girl</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">prince</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">princess</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">consume</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">beer</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">W2VMODEL</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">woman</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">girl</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">duke</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">bride</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">cook</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">coffee</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">TF-IDFMODEL</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">woman</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">wise</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">emperor</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">grandmother</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">hungry</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">pour</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">LSAMODEL</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">priest</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">wise</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">bishop</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">bride</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">forget</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">bath</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.25 – Nearest neighbors for common words, various models</p>
<p>The words that are returned as the nearest neighbors of the targets by the various algorithms are all reasonable enough (you do have to weed out cases where the nearest neighbor is an inflected form of the target: GLoVe is particularly prone to this, with <em class="italic">eats</em> and <em class="italic">ate</em>, for instance, being the words that are found to be most similar to <em class="italic">eat</em>). For nouns, the words that are returned are things that can do, or have done to them, the same kinds of things; for verbs, they are largely actions that can be performed on the same kinds of things (GLoVe and <strong class="source-inline">word2vec</strong> both return things that you can drink <span class="No-Break">for </span><span class="No-Break"><em class="italic">drink</em></span><span class="No-Break">).</span></p>
<p>If similar words <a id="_idIndexMarker572"/>tend to involve, or are involved in, the same kinds of actions, what happens when we look at emotionally <span class="No-Break">laden words?</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table024">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">love</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">like</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">hate</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">detest</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">joy</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">sorrow</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">GLOVEMODEL</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">me</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">even</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">hatred</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">despise</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">sadness</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">sadness</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">W2VMODEL</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">envy</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">crush</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">despise</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">daresay</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">sorrow</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">sadness</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">TF-IDFMODEL</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">hate</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">think</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">love</span></p>
</td>
<td class="No-Table-Style">
<p>--</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">pleasure</span></p>
</td>
<td class="No-Table-Style">
<p>--</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">LSAMODEL</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">passion</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">want</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">imagine</span></p>
</td>
<td class="No-Table-Style">
<p>--</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">pleasure</span></p>
</td>
<td class="No-Table-Style">
<p>--</p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.26 – Nearest neighbors for emotionally laden words</p>
<p>A number of the nearest neighbors simply carry no emotional weight – <em class="italic">me</em>, <em class="italic">even</em>, <em class="italic">think</em>, and <em class="italic">daresay</em>. In such cases, the strategy of looking for the nearest word that does carry such a weight would move on to the next case, but since this will produce different results with different lexicons, the effect is unpredictable until we choose a lexicon. In the remaining cases, we see the same phenomenon as before – some of the nearest neighbors carry the same emotions as the target (<strong class="bold">hate</strong>: <em class="italic">hatred</em> (GLoVe), <em class="italic">despise</em> (<strong class="source-inline">word2vec</strong>), <strong class="bold">joy</strong>: <em class="italic">pleasure</em> (TF-IDF, LSA), <strong class="bold">sorrow</strong>: <em class="italic">sadness</em> (GLoVe, word2vec)) and as many carry exactly the opposite weight (<strong class="bold">love</strong>: <em class="italic">envy</em> (<strong class="source-inline">word2vec</strong>), <em class="italic">hate</em> (TF-IDF), <strong class="bold">hate</strong>: <em class="italic">love</em> (TF-IDF), <strong class="bold">joy</strong>: <em class="italic">sadness</em> (GLoVe), <em class="italic">sorrow</em> (<strong class="source-inline">word2vec</strong>)). GLoVe trained on 6 billion words gives two words that carry the correct emotions, two that carry exactly the wrong ones, and two that carry none; <strong class="source-inline">word2vec</strong> trained on 100 million words gives two that carry the right emotions, two that carry the wrong ones and two that carry none; and TF-IDF and LSA do much the same. Using word similarity models that are trained on corpora that are not marked up for emotions can give very misleading information about emotions, and should only be used with <span class="No-Break">extreme care.</span></p>
<h1 id="_idParaDest-91"><a id="_idTextAnchor131"/>Summary</h1>
<p>What does all this add up to? You can make an emotion mining algorithm by making a lexicon with words marked up for emotions. Doing so by extracting the information from a corpus where texts, rather than words, have been marked will probably do better on target texts of the same kind than by using a lexicon where individual words have been marked. They are both time-consuming, labor-intensive activities, but you are going to have to do something like this because any machine learning algorithm is going to require training data. There are numerous minor variants that you can try – stemming, changing the bias, varying the threshold, or using a similarity metric for filling in gaps. They all produce improvements <em class="italic">under some circumstances</em>, depending on the nature of the corpus and the task, so it is worth trying combinations of techniques, but they do not produce large improvements. Lexicon-based algorithms form a good starting point, and they have the great advantage of being very easy to implement. To get substantially better performance, we will investigate more sophisticated machine learning algorithms in the <span class="No-Break">following chapters.</span></p>
<h1 id="_idParaDest-92"><a id="_idTextAnchor132"/>References</h1>
<p>To learn more about the topics that were covered in this chapter, take a look at the <span class="No-Break">following resources:</span></p>
<ul>
<li><a id="_idTextAnchor133"/>Buckwalter, T. (2007). <em class="italic">Issues in Arabic morphological analysis</em>. Arabic Computational <span class="No-Break">Morphology, 23–42.</span></li>
<li>Deerwester, S. C., Dumais, S. T., Landauer, T. K., Furnas, G. W., &amp; Harshman, R. A. (1990). <em class="italic">Indexing by Latent Semantic Analysis</em>. Journal of the American Society of Information Science, <span class="No-Break">41(6), 391–407.</span></li>
<li>Mikolov, T., Chen, K., Carrado, G., &amp; Dean, J. (2013). <em class="italic">Efficient Estimation of Word Representations in Vector Space (1st </em><span class="No-Break"><em class="italic">ed.)</em></span><span class="No-Break">. </span><a href="http://arxiv.org/pdf/1301.3781.pdf"><span class="No-Break">http://arxiv.org/pdf/1301.3781.pdf</span></a><span class="No-Break">.</span></li>
<li>Mohammad, S. M., &amp; Turney, P. D. (2013). <em class="italic">Crowdsourcing a Word-Emotion Association Lexicon</em>. Computational Intelligence, 29 (<span class="No-Break">3), 436–465.</span></li>
<li>Pennington, J., Socher, R., &amp; Manning, C. (2014). <em class="italic">GLoVe: Global Vectors for Word Representation</em>. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), <span class="No-Break">1,532–1,543. </span><a href="https://doi.org/10.3115/v1/D14-1162"><span class="No-Break">https://doi.org/10.3115/v1/D14-1162</span></a><span class="No-Break">.</span></li>
<li>Sparck Jones, K. (1972). <em class="italic">A statistical interpretation of term specificity and its application in retrieval</em>. Journal of Documentation, <span class="No-Break">28(1), 11–21.</span></li>
</ul>
</div>
</div></body></html>