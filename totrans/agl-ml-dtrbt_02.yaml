- en: '*Chapter 1*: What Is DataRobot and Why You Need It?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第一章*：什么是DataRobot以及为什么你需要它？'
- en: '**Machine learning** (**ML**) and AI are all the rage these days, and it is
    clear that these technologies will play a critical role in the success and competitiveness
    of most organizations. This will create considerable demand for people with data
    science skills.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）和人工智能现在是热门话题，很明显，这些技术将在大多数组织的成功和竞争力中发挥关键作用。这将产生对具有数据科学技能的人的巨大需求。'
- en: This chapter describes the current practices and processes of building and deploying
    ML models and some of the challenges in scaling these approaches to meet the expected
    demand. The chapter then describes what **DataRobot** is and how **DataRobot**
    addresses many of these challenges, thus allowing analysts and data scientists
    to quickly add value to their organizations. This chapter also helps executives
    understand how they can use DataRobot to efficiently scale their data science
    practice without the need to hire a large staff with hard-to-find skills, and
    how DataRobot can be leveraged to increase the effectiveness of your existing
    data science team. This chapter covers various components of DataRobot, how it
    is architected, how it integrates with other tools, and different options to set
    it up on-premises or in the cloud. It also describes, at a high level, various
    user interface components and what they signify.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了构建和部署机器学习模型当前的做法和流程，以及将这些方法扩展以满足预期需求的一些挑战。然后，本章描述了**DataRobot**是什么以及**DataRobot**如何解决许多这些挑战，从而使得分析师和数据科学家能够快速为他们的组织增加价值。本章还帮助高管了解他们如何使用DataRobot高效地扩展他们的数据科学实践，而无需雇佣大量难以找到技能的员工，以及如何利用DataRobot提高现有数据科学团队的有效性。本章涵盖了DataRobot的各个组成部分、其架构、如何与其他工具集成以及不同选项在本地或云中设置。它还从高层次上描述了各种用户界面组件及其含义。
- en: By the end of this chapter, you will have learned about the core functions and
    architecture of DataRobot and why it is a great enabler for data analysts as well
    as experienced data scientists for solving the most critical challenges facing
    organizations as they try to extract value from data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将了解DataRobot的核心功能和架构，以及为什么它是数据分析师以及经验丰富的数据科学家解决组织在从数据中提取价值时面临的最关键挑战的强大推动者。
- en: 'In this chapter, we''re going to cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Data science practices and processes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学实践和流程
- en: Challenges associated with data science
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与数据科学相关联的挑战
- en: DataRobot architecture
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataRobot架构
- en: DataRobot features and how to use them
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataRobot功能和如何使用它们
- en: How DataRobot addresses data science challenges
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataRobot如何解决数据科学挑战
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This book requires that you have access to DataRobot. DataRobot is a commercial
    piece of software, and you will need to purchase a license for it. Most likely
    your organization has already purchased DataRobot licenses, and your administrator
    can set up your account on a DataRobot instance and provide you with the appropriate
    URL to access DataRobot.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书要求您能够访问DataRobot。DataRobot是一款商业软件，您需要为其购买许可证。很可能是您的组织已经购买了DataRobot许可证，您的管理员可以在DataRobot实例上为您设置账户，并提供访问DataRobot的适当URL。
- en: 'A trial version is available, at the time of the writing of this book, that
    you can access from DataRobot''s website: [https://www.datarobot.com/trial/](https://www.datarobot.com/trial/).
    Please be aware that the trial version does not provide all of the functionality
    of the commercial version, and what it provides may change over time.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书编写时，DataRobot网站上提供了一个试用版，您可以从[https://www.datarobot.com/trial/](https://www.datarobot.com/trial/)访问。请注意，试用版并不提供商业版的所有功能，并且它提供的内容可能会随时间变化。
- en: Data science processes for generating business value
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成商业价值的数据科学流程
- en: 'Data science is an emerging practice that has seen a lot of hype. Much of what
    it means is under debate and the practice is evolving rapidly. Regardless of these
    debates, there is no doubt that data science methods can provide business benefits
    if used properly. While following a process is no guarantee of success, it can
    certainly improve the odds of success and allow for improvement. Data science
    processes are inherently iterative, and it is important to not get stuck in a
    specific step for too long. People looking for predictable and predetermined timelines
    and results are bound to be disappointed. By all means, create a plan, but be
    ready to be nimble and agile as you proceed. A data science project is also a
    discovery project: you are never sure of what you will find. Your expectations
    or your hypotheses might turn out to be false and you might uncover interesting
    insights from unexpected sources.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学是一种新兴实践，已经引起了大量的炒作。其中很多含义仍在争论中，实践也在快速发展。尽管存在这些争论，但毫无疑问，如果使用得当，数据科学方法可以为企业带来好处。遵循流程并不能保证成功，但它确实可以提高成功的几率，并允许进行改进。数据科学流程本质上是迭代的，因此不要在一个特定步骤上停留太久是很重要的。寻找可预测和预定时间表和结果的人注定会失望。无论如何，制定一个计划，但也要准备好在前进过程中保持灵活和敏捷。数据科学项目也是一个发现项目：你永远不知道你会发现什么。你的期望或假设可能最终是错误的，你也可能从意想不到的来源发现有趣的见解。
- en: 'There are many known applications of data science and new ones are being discovered
    every day. Some example applications are listed here:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学有许多已知的应用，每天都有新的应用被发现。以下是一些示例应用：
- en: Predicting which customer is most likely to buy a product
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测哪位客户最有可能购买产品
- en: Predicting which customer will come back
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测哪位客户会回来
- en: Predicting what a customer will want next
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测客户接下来会想要什么
- en: Predicting which customer might default on a loan
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测哪位客户可能会违约
- en: Predicting which customer is likely to have an accident
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测哪位客户可能发生事故
- en: Predicting which component of a machine might fail
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测机器的哪个部件可能会故障
- en: Forecasting how many items will be sold in a store
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测商店将卖出多少商品
- en: Forecasting how many calls the call center will receive tomorrow
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测呼叫中心明天将接收多少个电话
- en: Forecasting how much energy will be consumed next month
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测下个月将消耗多少能源
- en: '*Figure 1.1* shows a high-level process that describes how a data science project
    might go from concept to value generation:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.1* 展示了一个高层次的过程，描述了数据科学项目可能从概念到价值生成的过程：'
- en: '![Figure 1.1 – Typical process steps with details about what happens during
    each step'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.1 – 每个步骤的典型流程及其详细信息'
- en: '](img/b17159_01_01_new_2.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/b17159_01_01_new_2.jpg](img/b17159_01_01_new_2.jpg)'
- en: Figure 1.1 – Typical process steps with details about what happens during each
    step
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 每个步骤的典型流程及其详细信息
- en: Following these steps is critical for a successful machine learning project.
    Sometimes these steps get skipped due to deadlines or issues that inevitably surface
    during development and debugging. We will show how using DataRobot helps you avoid
    some of the problems and ensure that your teams are following best practices.
    These steps will be covered in great detail, with examples, in other chapters
    of this book, but let's get familiar with them at a high level.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循这些步骤对于成功进行机器学习项目至关重要。有时，由于截止日期或开发调试过程中不可避免地出现的问题，这些步骤会被跳过。我们将展示如何使用DataRobot帮助您避免一些问题，并确保您的团队能够遵循最佳实践。这些步骤将在本书的其他章节中详细阐述，并附有示例，但让我们先从高层次上熟悉它们。
- en: Problem understanding
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题理解
- en: 'This is perhaps the most important step and also the step that is given the
    least attention. Most data science projects fail because this step is rushed.
    This is also the task where you have the least methods and tools available from
    the data science disciplines. This step involves the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是最重要的步骤，同时也是最不受重视的步骤。大多数数据科学项目失败是因为这一步骤被仓促完成。这也是数据科学学科中可用的方法和工具最少的任务。这一步骤包括以下内容：
- en: Understanding the business problem from a systemic perspective
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从系统角度理解业务问题
- en: Understanding what it is that the end users or consumers of the model's results
    expect
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解最终用户或模型结果消费者期望的是什么
- en: Understanding what the stakeholders will do with the results
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解利益相关者将如何使用这些结果
- en: Understanding what the potential sources of data are and how the data is captured
    and modified before it reaches you
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解潜在的数据来源以及数据在到达你之前是如何被捕获和修改的
- en: Assessing whether there are any legal concerns regarding the use of data and
    data sources
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估使用数据和数据源是否存在任何法律问题
- en: Developing a detailed understanding of what various features of the datasets
    mean
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入理解数据集的各种特征含义
- en: Data preparation
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: This step is well known in the data science community as data science teams
    typically spend most of their time in this step. This is a task where DataRobot's
    capabilities start coming into play, but not completely. There is still a lot
    of work that the data science or data engineering teams have to do using SQL,
    Python, or R. There are also many tasks in this step that require a data scientist's
    skill and experience (for example, feature engineering), even though DataRobot
    is beginning to provide capabilities in this area. For example, DataRobot provides
    a lot of useful data visualizations and notifications about data quality, but
    it is up to the analyst to make sense out of them and take appropriate actions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学社区中，此步骤广为人知，因为数据科学团队通常将大部分时间花在这一步骤上。这是一个DataRobot能力开始发挥作用但并非完全发挥的任务。数据科学或数据工程团队仍需使用SQL、Python或R完成大量工作。此步骤中也有许多任务需要数据科学家的技能和经验（例如，特征工程），尽管DataRobot开始在这一领域提供能力。例如，DataRobot提供了大量有用的数据可视化和关于数据质量的通知，但分析师需要从中理解并采取适当的行动。
- en: This step also involves defining the expected result (such as predicting how
    many items will be sold next week or determining the probability of default on
    a loan) of the model and how the quality of results will be measured during model
    development, validation, and testing stages.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤还涉及定义模型的预期结果（例如预测下周将售出多少商品或确定贷款违约的概率）以及如何在模型开发、验证和测试阶段衡量结果的质量。
- en: Model development
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型开发
- en: This step involves the development of several models using different algorithms
    and optimizing or tuning hyperparameters of the algorithms. Results produced by
    the models are then evaluated to narrow down the model list, potentially drop
    some of the features, and fine-tune the hyperparameters.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤涉及使用不同的算法开发多个模型，并优化或调整算法的超参数。然后评估模型产生的结果，以缩小模型列表，可能删除一些特征，并微调超参数。
- en: It is also common to look at feature effects, feature importance, and partial
    dependence plots to engineer additional features. Once you are satisfied with
    the results, you start thinking about how to turn the predictions and explanations
    into useable and actionable information.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通常还会查看特征效应、特征重要性和部分依赖图来构建额外的特征。一旦对结果满意，您就开始思考如何将预测和解释转化为可用和可操作的信息。
- en: Model deployment
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署
- en: Upon completion of model development, the model results are reviewed with users
    and stakeholders. This is the point at which you should carefully assess how the
    results will be turned into actions. What will the consequences of those actions
    be, and are there any unintended consequences that could emerge? This is also
    the time to assess any fairness or bias issues resulting from the models. Make
    sure to discuss any concerns with the users and business leaders.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发完成后，与用户和利益相关者审查模型结果。这是您应该仔细评估结果将如何转化为行动的时候。这些行动的后果是什么，是否存在可能出现的意外后果？这也是评估模型产生的任何公平性或偏差问题的时机。务必与用户和业务领导者讨论任何担忧。
- en: DataRobot provides several mechanisms to rapidly deploy the models as REST APIs
    or executable Java objects that can be deployed anywhere in the organization's
    infrastructure or in the cloud. Once the model is operational as an API, the hard
    part of change management starts. Here you have to make sure that the organization
    is ready for the change associated with the new way of doing business. This is
    typically hard on people who are used to doing things a certain way. Communicating
    why this is necessary, why it is better, and how to perform new functions are
    important aspects that frequently get missed.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: DataRobot提供几种机制，可以快速将模型作为REST API或可执行的Java对象部署到组织的任何基础设施或云中。一旦模型作为API运行，变更管理的困难部分就开始了。您必须确保组织为与新的业务方式相关的变化做好准备。这对习惯于以某种方式做事的人来说通常很困难。沟通为什么这是必要的，为什么它更好，以及如何执行新功能是经常被忽视的重要方面。
- en: Model maintenance
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型维护
- en: Once the model is successfully deployed and operating, the focus shifts to managing
    the model operations and maintenance. This includes identifying data gaps and
    other recommendations to improve the model over time as well as refining and retraining
    the models as needed. Monitoring involves evaluating incoming data to see whether
    the data has drifted and whether the drift requires action, monitoring the health
    of the prediction services, and monitoring the results and accuracy of the model
    outputs. It is also important to periodically meet with users to understand what
    the model does well and where it can be improved. It is also common to sometimes
    employ champion and challenger models to see whether a different model is able
    to perform better in the production setting.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型成功部署并运行，重点就转向管理模型的操作和维护。这包括确定数据差距和其他建议，以随着时间的推移改进模型，以及根据需要改进和重新训练模型。监控包括评估传入的数据以查看数据是否发生了漂移以及漂移是否需要采取行动，监控预测服务的健康状况，以及监控模型输出的结果和准确性。定期与用户会面，了解模型做得好的地方以及可以改进的地方也很重要。有时也常见到使用冠军模型和挑战者模型来查看是否有一个不同的模型能够在生产环境中表现更好。
- en: As we outlined before, although these steps are presented in a linear fashion,
    in practice these steps do not occur in this exact sequence and there is typically
    plenty of iteration before you get to the final result. ML model development is
    a challenging process, and we will now discuss what some of the challenges are
    and how to address them.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前概述的，尽管这些步骤以线性方式呈现，但在实践中，这些步骤并不按照这种精确的顺序发生，通常在得到最终结果之前会有大量的迭代。机器学习模型开发是一个具有挑战性的过程，我们现在将讨论一些挑战以及如何应对它们。
- en: Challenges associated with data science
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与数据科学相关的挑战
- en: 'It is no secret that getting value from data science projects is hard, and
    many projects end in failure. While some of the reasons are common to any type
    of project, there are some unique challenges associated with data science projects.
    Data science is still a relatively young and immature discipline and therefore
    suffers from problems that any emerging discipline encounters. Data science practitioners
    can learn from other mature disciplines to avoid some of the mistakes that others
    have learned to avoid. Let''s review some of the key issues that make data science
    projects challenging:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据科学项目中获得价值并不容易，许多项目以失败告终。虽然一些原因与任何类型的项目都普遍存在，但数据科学项目有一些独特的挑战。数据科学仍然是一个相对年轻和不成熟的学科，因此会遭遇任何新兴学科都会遇到的问题。数据科学从业者可以从其他成熟的学科中学习，以避免一些别人已经学会避免的错误。让我们回顾一下使数据科学项目具有挑战性的关键问题：
- en: '**Lack of good-quality data**: This is a common refrain, but this is a problem
    that is not likely to go away anytime soon. The key reason is that most organizations
    are used to collecting data for reporting. This tends to be aggregate, success-oriented
    information. Data needed for building models, on the other hand, needs to be detailed
    and should capture all outcomes. Many organizations invest heavily in data and
    data warehouses in response to the need for data; the mistake they make is collecting
    it from the perspective of reporting rather than modeling. Hence, even after all
    the time and costs spent, they end up in a place where enough useable data is
    not available. This leads to frustration in senior leadership as to why their
    teams cannot make use of these large data warehouses built at enormous expense.
    Taking some time in developing a systemic understanding of the business can help
    mitigate this problem, as discussed in the following chapters.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏高质量的数据**：这是一个常见的说法，但这个问题不太可能在不久的将来消失。关键原因在于，大多数组织习惯于收集数据用于报告。这通常是汇总的、以成功为导向的信息。而用于构建模型所需的数据则需要详细，并且应该捕捉到所有结果。许多组织为了满足数据需求，在数据和数据仓库上投入了大量资金；他们犯的错误是从报告的角度而不是从模型的角度收集数据。因此，尽管花费了大量的时间和成本，他们最终发现自己处于一个可用数据不足的地方。这导致高层领导对为什么他们的团队能够利用这些花费巨大的大型数据仓库感到沮丧。花一些时间在发展对业务的系统性理解上可以帮助缓解这个问题，正如以下章节所讨论的。'
- en: '**Explosion of data**: Data is being generated and collected on an exponential
    scale. As more data is collected, the scale of the data makes it harder to be
    analyzed and understood through traditional reporting methods. New data also spawns
    new use cases that were previously not possible. The scaling of data also increases
    noise. This makes it increasingly difficult to extract meaningful insights with
    traditional methods.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据爆炸**：数据正在以指数级规模生成和收集。随着收集到的数据越来越多，数据的规模使得通过传统的报告方法进行分析和理解变得更加困难。新的数据也催生了之前不可能实现的新用例。数据的扩展也增加了噪声。这使得使用传统方法提取有意义的见解变得越来越困难。'
- en: '**Shortage of experienced data scientists**: This is another topic that gets
    a lot of press. The reason for the shortage is that it is a relatively new field
    where techniques and methods are still rapidly evolving. Another factor is that
    data science is a multi-disciplinary field that requires expertise in multiple
    areas, such as statistics, computer science, and business, as well as knowledge
    of the domain where it is to be applied. Most of the talent pool today is relatively
    inexperienced and therefore most data scientists have not had a chance to work
    on a variety of use cases with a broad range of methods and data types. Best practices
    are still evolving and are not in widespread use. As more and more jobs become
    data-driven, it will also become important for a broad range of employees to become
    data-savvy.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**经验丰富的数据科学家短缺**：这也是一个受到很多关注的主题。短缺的原因是这是一个相对较新的领域，技术和方法仍在迅速发展。另一个因素是数据科学是一个多学科领域，需要多个领域的专业知识，如统计学、计算机科学和商业，以及对其应用领域的了解。今天的大多数人才库相对缺乏经验，因此大多数数据科学家还没有机会使用广泛的方法和数据类型在各种用例上工作。最佳实践仍在不断发展，并未得到广泛应用。随着越来越多的工作变得数据驱动，对于广泛的员工来说，具备数据意识也将变得重要。'
- en: '**Immature tools and environments**: Most of the tools and environments being
    used are relatively immature, and that makes it difficult to efficiently build
    and deploy models. Most of a data scientist''s time is spent wrestling with data
    and infrastructure issues, which limits the time spent understanding the business
    problem and evaluating the business and ethical implications of models. This in
    turn increases the odds of failure to produce lasting business value.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工具和环境不成熟**：目前使用的工具和环境相对不成熟，这使得高效构建和部署模型变得困难。数据科学家的大部分时间都花在与数据和基础设施问题作斗争上，这限制了他们理解业务问题和评估模型商业和伦理影响的时间。这反过来又增加了无法产生持久商业价值的风险。'
- en: '**Black box models**: As the complexity of models rises, our ability to understand
    what they are doing goes down. This lack of transparency creates many problems
    and can lead to models producing nonsensical results or, at worst, dangerous results.
    To make matters worse, these models tend to have better accuracy on training and
    validation datasets. Black box models tend to be difficult to explain to stakeholders
    and are therefore less likely to be adopted by users.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑盒模型**：随着模型复杂性的增加，我们理解它们所做事情的能力下降。这种缺乏透明度造成了许多问题，可能导致模型产生无意义的或最糟糕的情况下的危险结果。更糟糕的是，这些模型在训练和验证数据集上往往具有更好的准确性。黑盒模型往往难以向利益相关者解释，因此不太可能被用户采用。'
- en: '**Bias and fairness**: The issue of ML models being biased and unfair has been
    raised recently and it is a key concern for anyone looking to develop and deploy
    ML models. The biases can creep into the models via biased data, biased processes,
    or even biased decision-making using model results. The use of black box models
    makes this problem much harder to track and manage. Bias and fairness are hard
    to detect but will be increasingly important not only for an organization''s reputation
    but also with regard to the regulatory or legal problems that they can create.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏差和公平性**：机器学习模型存在偏差和不公平的问题最近被提出，并且对于任何希望开发和部署机器学习模型的人来说，这是一个关键的关注点。偏差可以通过有偏差的数据、有偏差的过程，甚至使用模型结果进行有偏差的决策而渗透到模型中。使用黑盒模型使得这个问题更加难以追踪和管理。偏差和公平性难以检测，但将越来越重要，不仅对组织的声誉至关重要，而且与它们可能引发的监管或法律问题也密切相关。'
- en: Before we discuss how to address these challenges, we need to introduce you
    to DataRobot because, as you might have guessed, DataRobot helps in addressing
    many of these challenges.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论如何解决这些挑战之前，我们需要向您介绍DataRobot，因为正如您可能已经猜到的，DataRobot有助于解决许多这些挑战。
- en: DataRobot architecture
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DataRobot架构
- en: 'DataRobot is one of the most well-known commercial tools for **automated ML**
    (**AutoML**). It only seems appropriate that the technology meant to automate
    everything should itself benefit from automation. As you go through the data science
    process, you will realize that there are many tasks that are repetitive in nature
    and standardized enough to warrant automation. DataRobot has done an excellent
    job of capturing such tasks to increase the speed, scale, and efficiency of building
    and deploying ML models. We will cover these aspects in great detail in this book.
    Having said that, there are still many tasks and aspects of this process that
    still require decisions, actions, and tradeoffs to be done by data scientists
    and data analysts. We will highlight these as well. The following figure shows
    a high-level view of the DataRobot architecture:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: DataRobot是**自动化机器学习**（**AutoML**）最知名的商业工具之一。似乎只有让旨在自动化的技术本身也受益于自动化才是合适的。随着您通过数据科学过程，您将意识到有许多任务在性质上是重复的，并且标准化到足以值得自动化的程度。DataRobot在捕捉此类任务以增加构建和部署机器学习模型的速度、规模和效率方面做得非常出色。我们将在本书中详细讨论这些方面。话虽如此，仍有许多任务和此过程中的方面仍需要数据科学家和数据分析师做出决策、采取行动和权衡。我们也将突出这些内容。以下图显示了DataRobot架构的高级视图：
- en: '![Figure 1.2 – Key components of the DataRobot architecture'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.2 – DataRobot架构的关键组件'
- en: '](img/b17159_01_02.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/b17159_01_02.jpg)'
- en: Figure 1.2 – Key components of the DataRobot architecture
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – DataRobot架构的关键组件
- en: The figure shows five key layers of the architecture and the corresponding components.
    In the following sections, we will describe each layer and how it enables a data
    science project.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该图显示了架构的五个关键层及其相应的组件。在接下来的章节中，我们将描述每一层以及它是如何使数据科学项目得以实现的。
- en: Hosting platform
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 托管平台
- en: 'The DataRobot environment is accessed via a web browser. The environment itself
    can be hosted on an organization''s servers, or within an organization''s server
    instances on a cloud platform, such as AWS or DataRobot''s cloud. There are pros
    and cons to each hosting option and which option you should choose depends on
    your organization''s needs. Some of these are discussed at a high level in *Table
    1.1*:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 数据机器人环境可以通过网页浏览器访问。该环境本身可以托管在组织的服务器上，或者托管在云平台（如AWS或DataRobot的云）上的组织服务器实例中。每种托管选项都有其优缺点，您应该选择的选项取决于您组织的需要。其中一些在*表1.1*中进行了高层次讨论：
- en: '![Figure 1.3 – Pros and cons of various hosting options'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.3 – 各种托管选项的优缺点'
- en: '](img/b17159_01_03_new.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/b17159_01_03_new.jpg)'
- en: Figure 1.3 – Pros and cons of various hosting options
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – 各种托管选项的优缺点
- en: As you can gather from this table, DataRobot offers you a lot of choices, and
    you can pick the option that suits your environment the best. It is important
    to get your IT, information security, and legal teams involved in this conversation.
    Let's now look at how data comes into DataRobot.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从这张表中可以看出，DataRobot为您提供了很多选择，您可以选择最适合您环境的选项。重要的是让您的IT、信息安全和法律团队参与这次对话。现在让我们看看数据是如何进入DataRobot的。
- en: Data sources
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据来源
- en: Datasets can be brought into DataRobot via local files (`csv`, `xlsx`, and more),
    by connecting to a relational database, from a URL, or from **Hadoop Distributed File
    System** (**HDFS**) (if it is set up for your environment). The datasets can be
    brought directly into a project or can be placed into an AI catalog. The datasets
    in the catalog can be shared across multiple projects. DataRobot has integrations
    and technology alliances with several data management system providers.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以通过本地文件（`csv`、`xlsx`等）、连接到关系数据库、从URL或从**Hadoop分布式文件系统**（**HDFS**）（如果为您的环境设置了）导入到DataRobot中。数据集可以直接导入到项目中，也可以放入AI目录中。目录中的数据集可以在多个项目中共享。DataRobot与多个数据管理系统提供商建立了集成和技术联盟。
- en: Core functions
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核心功能
- en: DataRobot provides a fairly comprehensive set of capabilities to support the
    entire ML process, either through the core product or through add-on components
    such as Paxata, which provides easy-to-use data preparation and **Exploratory
    Data Analysis** (**EDA**) capabilities. Discussion of Paxata is beyond the scope
    of this book, so we will provide details of the capabilities of the core product.
    DataRobot automatically performs several EDA analyses that are presented to the
    user for gaining insights into the datasets and catching any data quality issues
    that may need to be fixed.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: The automated modeling functions are the most critical capability offered by
    DataRobot. This includes determining the algorithms to be tried on the selected
    problem, performing basic feature engineering, automatically building models,
    tuning hyperparameters, building ensemble models, and presenting results. It must
    be noted that DataRobot mostly supports supervised ML algorithms and time series
    algorithms. Although there are capabilities to perform **Natural Language Processing**
    (**NLP**) and image processing, these functions are not comprehensive. DataRobot
    has also been adding to MLOps capabilities recently by providing functions for
    rapidly deploying models as REST APIs, monitoring data drift and service health,
    and tracking model performance. DataRobot continues to add capabilities such as
    support for geospatial data and bias detection.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: These tasks are normally done by using programming languages such as R and Python
    and can be fairly time-consuming. The time spent coding up data analysis, model
    building, output analysis, and deployment can be significant. Typically, a lot
    of time is also spent debugging and fixing errors and making the code robust.
    Depending on the size and complexity of the model, this can take anywhere from
    weeks to months. DataRobot can reduce this time to days. This time can in turn
    be used to deliver projects faster, build more robust models, and better understand
    the problem being solved.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: External interactions
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DataRobot functions can be accessed via a comprehensive user interface (which
    we will describe in the next section), a client library that can be used in a
    Python or R framework to programmatically access DataRobot capabilities via an
    API, and a REST API for use by external applications. DataRobot also provides
    the ability to create applications that can be used by business users to enable
    them to make data-driven decisions.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Users
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While most people believe that DataRobot is for data analysts and data scientists
    who do not like to code, it offers significant capabilities for data scientists
    who can code and can significantly increase the productivity of any data science
    team. There is also some support for business users for some specific use cases.
    Other systems can integrate with DataRobot models via the API, and this can be
    used to add intelligence to external systems or to store predictions in external
    databases. Several tool integrations exist through their partners program.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Navigating and using DataRobot features
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have some familiarity with the core functions, let''s take a quick
    tour of what DataRobot looks like and how you navigate the various functions.
    This section will introduce DataRobot at a high level, but don''t worry: we will
    get into details in subsequent chapters. This section is only meant to familiarize
    you with DataRobot functionality.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Your DataRobot administrator will provide you with the appropriate URL and a
    username and password to access your DataRobot instance. In my experience, Google
    Chrome seems to work best with DataRobot, but you can certainly try other browsers
    as you see fit.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the screens and options you see depend on the products you
    have the license for and the privileges granted to you by your admin. For most
    part, it will not affect the flow of this book. Since we will be focusing on the
    ML development core of DataRobot, you should be able to follow along.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s go ahead and launch the browser and go to your DataRobot URL. You
    will see a login screen as shown in the following figure:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4 – DataRobot login screen'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_04.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.4 – DataRobot login screen
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'Go ahead and log in using your credentials. Once you have logged in, you will
    be presented with a welcome screen (*Figure 1.4*) that prompts you to select what
    you want to do next. It is also possible that (depending on your setup) you will
    be directly taken to the data input screen (*Figure 1.5*):'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5 – Welcome screen'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_05.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.5 – Welcome screen
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we will select the **ML Development** option and click the **Continue**
    button. This prompts you to provide the dataset that you wish to build models
    with (*Figure 1.5*):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6 – New project/drag dataset screen'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_06.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.6 – New project/drag dataset screen
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you can drag a dataset file from your local machine onto the
    screen (or select one of the other choices) and DataRobot will start the process
    of analyzing your data. You can click on the **View dataset** requirements link
    to see the file format options available (*Figure 1.6*). The file size requirements
    for your instance might be different from what you see here:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7 – Dataset requirements'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_07.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.7 – Dataset requirements
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you can upload any test dataset from your local drive. DataRobot
    will immediately start evaluating your data (*Figure 1.7*):'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.8 – EDA'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_08.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.8 – EDA
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the process of building the project and associated models in
    later chapters; for now, let''s cover what other options we have. If you click
    on the **?** icon in the top right, you will see the **DOCUMENTATION** drop-down
    menu (*Figure 1.8*):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.9 – DOCUMENTATION drop-down menu'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_09.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.9 – DOCUMENTATION drop-down menu
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'Here you see various options to learn more about different functions, contact
    customer support, or interact with the DataRobot community. I highly recommend
    joining the community to interact with and learn from other community members.
    You can reach the community via [https://community.datarobot.com](https://community.datarobot.com).
    If you select **Platform Documentation** from the dropdown, you will see extensive
    documentation on DataRobot functions (*Figure 1.9*):'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.10 – DataRobot platform documentation'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_10.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.10 – DataRobot platform documentation
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'You can review the various topics at your leisure or come back to a specific
    topic as needed according to the task you are working on. Let''s click on the
    **?** icon in the top right again and this time select **API Documentation** from
    the dropdown. You will now see the documentation for the DataRobot API (*Figure
    1.10*):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.11 – DataRobot API Documentation'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_11.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.11 – DataRobot API Documentation
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: We will cover the API in the advanced topics in later chapters. If you are not
    familiar with programming or are relatively new to programming, you can ignore
    this part for now. If you are an experienced data scientist with expertise in
    Python or R, you can start reviewing the various functions available to you to
    automate your model-building tasks even further.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go back to the main DataRobot page and this time select the folder icon
    in the top right of the page (*Figure 1.11*):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.12 – Project drop-down menu'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_12.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.12 – Project drop-down menu
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: If you do not see the folder icon, it simply means that you do not have any
    projects defined. We will describe creating projects in more detail later. For
    now, just familiarize yourself with different options and what they look like.
    Here you will see options to create a new project or manage existing projects.
    In here, you will also see some details about the currently active project as
    well as a list of recent projects.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Create New Project** option takes you back to the new project page that
    we saw before in *Figure 1.5*. If you select the **Manage Projects** menu, it
    will show all of your projects listed by create date (*Figure 1.12*). Here you
    are able to select a project to see more details, clone a project, share the project
    with other users, or delete a project as needed, as shown in the following figure:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.13 – Manage projects page'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_13.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.13 – Manage projects page
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'If you click on the very last menu item in the top right of the page that looks
    like a person, you will see a dropdown (*Figure 1.13*):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.14 – User account management dropdown'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_14.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.14 – User account management dropdown
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: From here you can manage your profile and adjust your account settings. If you
    have admin privileges, you can view and manage other users and groups. You can
    also sign out of DataRobot if needed.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'If you select the **Profile** menu, you will see details of your account (*Figure
    1.14*):'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.15 – User profile page'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_15.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.15 – User profile page
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 'Here you can update some of your information. You will also see some new menu
    choices on the second menu row at the top. This allows you to change settings
    or access some developer options, and so on. If you select the **Settings** menu,
    you will see the following (*Figure 1.15*):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.16 – User Settings'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_16.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.16 – User Settings
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: On this page, you can change your password, set up two-factor authentication,
    change the theme, and set up notifications (you will see different options available
    to you based on how your account was set up by your administrator).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'If you select **Developer Tools**, you will see the following (*Figure 1.16*):'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.17 – Developer Tools screen'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_17.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.17 – Developer Tools screen
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Here you can create an API key associated with your account. This key is useful
    for authentication if you will be using the DataRobot API. You can also download
    the API package to set up a portable prediction server to deploy models within
    your organization's infrastructure.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'If you click on the **AI Catalog** menu at the top, you will see a catalog
    of shareable datasets available within DataRobot (*Figure 1.17*):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.18 – AI Catalog'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_18.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.18 – AI Catalog
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'This page shows you a list of datasets available. If you do not see any datasets,
    you can upload a test dataset here by clicking on the **Add new data** button
    (*Figure 1.18*). You can also click on a dataset to explore the data available.
    You can search and sort by sources, user-defined tags, or owner/creator:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.19 – Dataset information page'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_19.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.19 – Dataset information page
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Normally a dataset is only available within a project. If you want to share
    datasets across projects or iterations of projects, you can create the dataset
    within this catalog. This allows you to share these datasets across projects and
    users. The datasets can be static, or they can be dynamically created using a
    SQL query as needed. Datasets can also be modified or blended via Spark SQL if
    you need data from multiple tables or sources for a project.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'If you click on the **Profile** button, you will see profile-level information
    about the dataset (*Figure 1.19*). This information is automatically compiled
    for you. We will describe these capabilities and how to use them in more detail
    later:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.20 – Dataset information page'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_20.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.20 – Dataset information page
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: This page shows details of the dataset that is part of the project that is active
    at that time. This page is one of the key components of the DataRobot capability.
    The page shows summary information as well as any data quality issues that DataRobot
    has detected. Below that, it shows summaries of data features as well as a feature's
    importance relative to the target feature. We will cover these capabilities in
    more detail in subsequent chapters.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now click on the **Data** menu at the top left of the page. This page
    (*Figure 1.20*) shows a detailed analysis of the dataset for your currently active
    project:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.21 – Project data page'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_21.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.21 – Project data page
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: This page shows the results of the analysis of your datasets, provides any warnings,
    relative importance of the features, and the feature lists for use in your project.
    We will review the functionality of this page in great detail in later chapters.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now click on the **Models** menu item at the top. This shows the model
    leaderboard for the active project (*Figure 1.21*):'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.22 – Model leaderboard'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_22.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.22 – Model leaderboard
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: This is another critical page where you will spend a lot of your time during
    the modeling process. Here you can see the top-performing models that DataRobot
    has built and their performance metrics for validation, cross-validation, and
    holdout samples. You can drill down into the details of any selected model. It
    is important to note that DataRobot mostly works with supervised learning problems;
    currently, it does not have support for unsupervised learning (except for some
    anomaly detection) or reinforcement learning. Also, support for NLP and image
    processing problems is limited. Similarly, there are situations where either due
    to data limitations or extreme scales, you will find that the automation adds
    a level of overhead that makes it impractical to use DataRobot. If your project
    requires advanced capabilities in these areas, you will need to work in Python
    or R directly. More on this in subsequent chapters.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now move to the next menu item, **MLOps**. When you click on **MLOps**,
    you will see the screen shown in *Figure 1.22*:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.23 – MLOps page'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_23.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.23 – MLOps page
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: The **MLOps** page shows you your active deployments and their health. You can
    set up alerts relating to data drift or model accuracy as needed for your use
    cases.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: The next menu item is **Model Registry**. Now, **Model registry** is the mechanism
    by which you can bring externally developed models into DataRobot. This capability
    is an add-on that your organization may or may not have purchased. This aspect
    is an advanced topic that is beyond the scope of this book.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s click on the next menu item, **Applications**. You will now see what''s
    shown in *Figure 1.23*:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.24 – Applications page'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '](img/b17159_01_24.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.24 – Applications page
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '**Applications** is a relatively new functionality in DataRobot that is meant
    to allow business users to easily access model results without needing to get
    DataRobot user licenses.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our quick tour of what DataRobot is and what it looks like. We
    will revisit many of these components in great detail and see examples of how
    these are used to take a data science project from start to finish.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Addressing data science challenges with DataRobot
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you know what DataRobot offers, let's revisit the data science process
    and challenges to see how DataRobot helps in addressing these challenges and why
    this is a valuable tool in your toolkit.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Lack of good-quality data
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While DataRobot cannot do much to address this challenge, it does offer some
    capabilities to handle data with quality problems:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Automatically highlights data quality problems.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated EDA and data visualization expose issues that could be missed.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handles and imputes missing values.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detection of data drift.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explosion of data
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While it is unlikely that the increase in the volume and variety will slow
    down any time soon, DataRobot offers several capabilities to address these challenges:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Support for SparkSQL enables the efficient pre-processing of large datasets.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatically handles categorical data encodings and selects appropriate model
    blueprints.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatically handles geospatial features, text features, and image features.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shortage of experienced data scientists
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is a key challenge for most organizations and data science teams, and
    DataRobot is well positioned to address this challenge:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Provides capabilities that cover most of the data science process steps.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Significant automation of several routine tasks by providing pre-built blueprints
    encoded with best practices.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experienced data scientists can build and deploy models much faster.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analysts or data scientists who are not very comfortable coding can utilize
    DataRobot capabilities without having to write a lot of code.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experienced data scientists who are comfortable with coding can utilize the
    APIs to automatically build and deploy an order of magnitude more models than
    otherwise feasible without the support of other data engineering or IT staff.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even experienced data scientists do not know all the possible algorithms and
    typically do not have the time to try out many of the combinations and build analysis
    visualizations and explanations for all models. DataRobot takes care of many of
    these tasks for them, enabling them to focus more time on understanding the problem
    and analyzing results.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immature tools and environments
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is a key barrier to the productivity and effectiveness of any data science
    organization. DataRobot clearly addresses this key challenge by offering the following:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Ease of deployment of any model as a REST API.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ease of use in developing multiple competing models and selecting the best ones
    without worrying about the underlying infrastructure, installation of compatible
    versions, and without coding and debugging. These tasks can take up a lot of time
    that would be better spent on understanding and solving the business problem.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DataRobot encodes many of the best practices into their development process
    so as to prevent mistakes. DataRobot automatically takes care of many small details
    that can be overlooked even by experienced data scientists, leading to flawed
    models or rework.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DataRobot provides automated documentation of models and modeling steps that
    could otherwise be glossed over or forgotten. This becomes valuable at a later
    time when a data scientist has to revisit an old model built by them or someone
    else.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Black box models
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is a key challenge that DataRobot has done extensive work on to provide
    methods to help make models more explainable, such as the following:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Automated generation of feature importance (using Shapley values and other methods)
    and partial dependence plots for models
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated generation of explanations for specific predictions
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated generation of simpler models that could be used to explain the complex
    models
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ability to create models that inherently more explainable such as **Generalized
    Additive Models** (**GAMs**)
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bias and fairness
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recently, DataRobot has added capabilities to help detect bias and fairness
    issues in models. This is no guarantee of a complete lack of bias, but it''s a
    good starting point to ensure positive movement in this direction. Some of the
    capabilities added are listed here:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Specify protected features that need to be checked for bias.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specify bias metrics that you want to use to check for fairness.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate your models using metrics for protected features.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use of model explanations to investigate whether there is potential for unfairness.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While many people believe that with these automated tools, you no longer need
    data scientists, nothing could be further from the truth. It is, however, obvious
    that such tools will make data science teams a lot more valuable to their organizations
    by unlocking more value faster and by making these organizations more competitive.
    It is therefore likely that tools such as DataRobot will become increasingly commonplace
    and see widespread use.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most data scientists today are bogged down in the implementation details or
    are implementing suboptimal algorithms. This leaves them with less time to understand
    the problem and to search for optimal algorithms or their hyperparameters. This
    book will show you how to take your game to the next level and let the software
    do the repetitive work.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we covered what a typical data science process is and how DataRobot
    supports this process. We discussed steps in the process where DataRobot offers
    a lot of capability and we also highlighted areas where a data scientist's expertise
    and domain understanding is critical (areas such as problem understanding and
    analyzing the impacts of deploying a model on the overall system). This highlights
    an important point in that success comes from the combination of skilled data
    scientists and analysts and appropriate tools (such as DataRobot). By themselves,
    they cannot be as effective as the combination. DataRobot enables relatively new
    data scientists to quickly develop and deploy robust models. At the same time,
    experienced data scientists can use DataRobot to rapidly explore and build a broader
    range of models than they would be able to build on their own.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: We covered some of the key data science challenges and how DataRobot helps you
    overcome some of the specific challenges. This should help guide leaders on how
    to craft the right combination of data scientists and the tools and infrastructure
    they need. We also covered the DataRobot architecture, its components, and what
    DataRobot looks like. You got a taste of what you will see when you start using
    it and where to go to find specific functions and help.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, this chapter has shown you why DataRobot could be an important tool
    in your toolbox regardless of your experience or how comfortable you are with
    coding. In the following chapters, we will use hands-on examples to show how to
    use DataRobot in detail and how to move your projects into a higher gear. But
    before we do that, we need to cover some ML basics in the next chapter.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
