["```py\ndef confusion(gs, p):    c = {}\n    for x, y in zip(gs, p):\n        if not x in c:\n            c[x] = counter()\n        c[x].add(y)\n```", "```py\ndef proportions(clsfs, emotions, which=lambda x: x.predicted, ignore=[\"neutral\", \"--\"]):    conf = numpy.zeros(len(emotions))\n    for clsf in clsfs:\n        for t in clsf.test.tweets:\n            for i, k in enumerate(which(t)):\n                if not emotions[i] in ignore:\n                    if k == 1:\n                        conf[i] += 1\n    return conf/sum(conf)\n```", "```py\ndef scoreproportions(clsfs):    ignore = [\"neutral\", \"--\"]\n    emotions = clsfs[0].train.emotions\n    predictedproportions = proportions(clsfs, emotions, ignore)\n    gsproportions = proportions(clsfs, emotions, ignore,\n                                which=lambda x: x.GS)\n    return cosine_similarity(predictedproportions.reshape(1, -1),\n                             gsproportions.reshape(1, -1))[0][0]\n```", "```py\n        def bestThreshold(self, bestthreshold, start=0, end=sys.maxsize):\n    ```", "```py\n            train = self.train.tweets[:len(self.test.tweets)]\n    ```", "```py\n            self.applyToTweets(train, threshold=0, probs=True)\n    ```", "```py\n            if bestthreshold == \"global\":\n    ```", "```py\n                predicted = [t.predicted for t in train]\n    ```", "```py\n                # select the required columns from the prediction\n    ```", "```py\n                predicted = numpy.array(predicted)[start:end, :]\n    ```", "```py\n                lowest = threshold = numpy.min(predicted)\n    ```", "```py\n                highest = numpy.max(predicted)\n    ```", "```py\n                step = (highest-lowest)/20\n    ```", "```py\n                best = []\n    ```", "```py\n                GS = numpy.array([t.GS for t in train])[:, start:end]\n    ```", "```py\n                for i in range(20):\n    ```", "```py\n                    l = self.applyToTweets(train, threshold=threshold)\n    ```", "```py\n                    l = numpy.array(l)[:, start:end]\n    ```", "```py\n                    m = metrics.getmetrics(GS, l, show=False)\n    ```", "```py\n                    (macroF, tp, tn, fp, fn) = m\n    ```", "```py\n                    j = tp/(tp+fp+fn)\n    ```", "```py\n                    best = max(best, [j, threshold])\n    ```", "```py\n                    if show:\n    ```", "```py\n                        print(\"%.2f %.3f\"%(threshold, j))\n    ```", "```py\n                    threshold += step\n    ```", "```py\n                return best[1]\n    ```", "```py\n            elif bestthreshold == \"local\":\n    ```", "```py\n                # do the global version, but just for each column in turn\n    ```", "```py\n                localthresholds = []\n    ```", "```py\n                for i in range(len(self.train.emotions)):\n    ```", "```py\n                    localthreshold = self.bestThreshold(\"global\",\n    ```", "```py\n                                                        start=i, end=i+1)\n    ```", "```py\n                    localthresholds.append(localthreshold)\n    ```", "```py\n                return localthresholds\n    ```", "```py\n            else:\n    ```", "```py\n                raise Exception(\"%s unexpected value for bestthreshold\"%(bestthreshold))\n    ```", "```py\n    def __init__(self, train, showprogress=True, args={}):        self.train = train\n        T = time.time()\n        self.datasets = {}\n        self.classifiers = {}\n        self.args = args\n        # Find what kind of classifier to use for the individual emotions\n        subclassifier = args[\"subclassifiers\"]\n        for i in range(len(self.train.emotions)):\n            squeezed = self.squeeze(i)\n            if squeezed:\n                self.datasets[i] = squeezed\n                self.classifiers[i] = subclassifier(self.datasets[i], args=args)\n```"]