<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer052">
			<h1 id="_idParaDest-39"><em class="italic"><a id="_idTextAnchor039"/>Chapter 2</em>: Machine Learning Basics</h1>
			<p>This chapter covers some basic concepts of machine learning that will be used and referenced in this book. This is the bare minimum you need to know in order to use DataRobot effectively. Experienced data scientists can safely skip this chapter. It is not the intention of this chapter to give you a comprehensive understanding of statistics or machine learning, but just a refresher of some key ideas and concepts. Also, the focus is on practical aspects of what you need to know in order to understand the core ideas without going into too much detail. It might be tempting to jump in and let DataRobot automatically build the models, but doing that without a basic understanding could backfire. If you are leading a data science team, please make sure that you have experienced data scientists in your teams who are mentoring others and that there are other governance processes in place.</p>
			<p>Some of these concepts will come up again during the hands-on examples, but we are covering many concepts here that might not come up during a specific example, but might come up in relation to your project at some point. The topics listed here can be used as a guide to determine some of the basic knowledge that you require in order to start using powerful tools such as DataRobot.</p>
			<p>By the end of this chapter, you will have learned some of the core concepts you need to know to use DataRobot effectively. In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Data preparation</li>
				<li>Data visualization</li>
				<li>Machine learning algorithms</li>
				<li>Performance metrics</li>
				<li>Understanding the results</li>
			</ul>
			<h1 id="_idParaDest-40"><a id="_idTextAnchor040"/>Data preparation</h1>
			<p>Before an algorithm can be applied to a <a id="_idIndexMarker074"/>dataset, the dataset needs to fit a certain pattern. The dataset also needs to be free of errors. Certain methods and techniques are used to ensure that the dataset is ready for the algorithms, and this will be the focus of this section.</p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor041"/>Supervised learning dataset</h2>
			<p>Since DataRobot mostly works with supervised learning problems, we will only focus on datasets for supervised machine learning (other types will be covered in a later section). In a supervised machine learning problem, we provide all the answers as part of the dataset. Imagine a table of data where each row represents a set of clues with their corresponding answers (<em class="italic">Figure 2.1</em>):</p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="Images/Figure_2.1_B17159.jpg" alt="Figure 2.1 – Supervised learning dataset&#13;&#10;" width="1544" height="460"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1 – Supervised learning dataset</p>
			<p>This dataset is made up of <a id="_idIndexMarker075"/>columns that contain clues (these are called <strong class="bold">features</strong>), and there is a column with the answers (this is called <strong class="bold">target</strong>). Given a dataset that looks like this, the algorithm learns how to produce the right answer given a set of clues. No matter what form your data is in, your task is to first transform it to make it look like the table in <em class="italic">Figure 2.1</em>. Note that the clues that you have might be spread across multiple databases or Excel files. You will have to compile all of that information into one table. If the datasets you have are complex, you will need to use languages such as SQL, tools such as <strong class="bold">Python</strong> <strong class="bold">Pandas</strong>, or <strong class="bold">Excel</strong>, or tools such as <strong class="bold">Paxata</strong>.</p>
			<h2 id="_idParaDest-42"><a id="_idTextAnchor042"/>Time series datasets</h2>
			<p>Time series or forecasting problems have time as a key component of their datasets. They are similar to the supervised learning datasets, with slight differences, as shown in <em class="italic">Figure 2.2</em>:</p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="Images/Figure_2.2_B17159.jpg" alt="Figure 2.2 – Time series dataset&#13;&#10;" width="1443" height="504"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2 – Time series dataset</p>
			<p>You need to make sure that your time series datasets appear as shown in the preceding diagram. It should have a date or time-based column, and a column with the series values you are trying to forecast, and a set of clues as needed. You can also add columns that help to categorize different series, if there are multiple time series that you need to forecast. For example, you might be interested in forecasting units sold for dates 5 and 6. If your data is in some other form, it needs to be transformed to look like the preceding diagram.</p>
			<h2 id="_idParaDest-43"><a id="_idTextAnchor043"/>Data cleansing</h2>
			<p>The data that comes to you will typically have errors in it. For example, you might have text in a field that is supposed to contain numbers. You might see a price column where the values may contain a $ sign on occasion, but no sign at other times. DataRobot can catch some of these, but there are times when an automated tool will not catch these, so you need to look and analyze the dataset carefully. It is useful to sometimes upload your data to DataRobot to see what it finds, and then use its analysis to determine the next steps. Some of this cleansing will need to be performed outside DataRobot, so be prepared to iterate a few times to get the data set up correctly. Common issues to watch out for include the following:</p>
			<ul>
				<li>Wrong data type in a column</li>
				<li>Mixed data types in a column</li>
				<li>Spaces or other characters in numeric columns that make them look like text</li>
				<li>Synonyms or misspelled words</li>
				<li>Dates encoded as strings</li>
				<li>Dates with differing formats</li>
			</ul>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor044"/>Data normalization and standardization</h2>
			<p>When different data features have varying scales and ranges, it becomes harder to compare their impacts on the target values. Also, many algorithms have difficulty in dealing with different scales of values, sometimes leading to stability issues. One method for avoiding these problems is to normalize (not to be confused with database normal forms) or standardize the values.</p>
			<p>In normalization (also known as scaling), you scale the values such that they range from 0 to 1:</p>
			<p>X<span class="subscript">normalized</span> = (X – X<span class="subscript">min</span>) / (X<span class="subscript">max</span> – X<span class="subscript">min</span>)</p>
			<p>Standardization, on the other hand, centers the data such that the mean becomes zero and scales it such that the standard deviation becomes 1. This is also known as <strong class="bold">z-scoring</strong> the data:</p>
			<p><a id="_idTextAnchor045"/>X<span class="subscript">standardized</span> = (X – X<span class="subscript">mean</span>) / X<span class="subscript">SD</span></p>
			<p>Here, X<span class="subscript">mean</span> is the mean of all X values, and X<span class="subscript">SD</span> is the standard deviation of X values.</p>
			<p>In general, you will not need to worry about this because DataRobot automatically does this for the datasets as required.</p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor046"/>Outliers</h2>
			<p>Outliers<a id="_idIndexMarker076"/> are values that seem to be out of place compared to the rest of the dataset. These values can be very large or very small. In general, values that are more than three standard deviations from the mean are considered outliers, but this only applies to features where values are expected to be normally distributed. Outliers typically come from data quality issues or some unusual situations that are not considered relevant enough to be trained on. The data points deemed to be outliers are typically removed from the dataset to prevent them from overpowering your models. The rules of thumb are only for highlighting the candidates. You will have to use your judgment to determine whether any values are outliers and whether they need to be removed. Once again, DataRobot will highlight potential outliers, but you will have to review those data points and determine whether to remove them or leave them in.</p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor047"/>Missing values</h2>
			<p>This is a<a id="_idIndexMarker077"/> very common problem in datasets. Your dataset may contain many missing values, marked as <strong class="bold">NULL</strong> or <strong class="bold">NaN</strong>. In some cases, you will see a <strong class="bold">?</strong>, or you might see an unusual value, such as <strong class="bold">-999</strong>, that an organization might be using to represent a missing or unknown value. How you choose to handle such values depends a lot on the problem you are trying to solve and what the dataset represents. Many times, you might choose to remove the row of data that contains a missing value. Sometimes, that is not possible because you might not have enough data, and removing such rows might lead to the removal of a significant portion of your dataset. Sometimes, you will see a large number of values in a feature (or column) that might be missing. In those situations, you might want to remove that feature from the dataset.</p>
			<p>Another possible way of dealing with this situation is to fill the missing values with a reasonable guess. This could take the form of a zero value, or the mean value for that feature, or a median value of that feature. For categorical data, missing values are typically treated as their own separate category.</p>
			<p>More sophisticated methods use the k-nearest neighbor algorithm to compute missing values based on other similar data points. No one answer will be appropriate every time, so you will need to use your judgment and understanding of the problem to make a decision. One final option is to leave it as it is and let DataRobot figure out how to deal with the situation. DataRobot has many imputation strategies as well as algorithms to handle missing values. But you have to be careful, as that might not always lead to the best<a id="_idIndexMarker078"/> solution. Talk to an experienced data scientist and use your understanding of the business problem to plot a course of action.</p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor048"/>Category encoding</h2>
			<p>In many <a id="_idIndexMarker079"/>problems, you have to transform your features into numeric values. This is because many algorithms cannot handle categorical data. There are many ways to encode categorical values and DataRobot has many of these methods built in. Some of these techniques are one-hot encoding, leave one out encoding, and target encoding. We will not get into the details, as normally you would let DataRobot handle this for you, but there might be cases where you will want to encode it yourself in a specific way due to your understanding of the business problem. This feature of DataRobot is a great time saver and typically works very well for most problems.</p>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor049"/>Consolidate categories</h2>
			<p>Sometimes, you<a id="_idIndexMarker080"/> have categorical data that contains a large number of categories. Although there are methods for dealing with large category counts (as discussed in the preceding section), many times, it is advisable to consolidate the categories. For example, you might have many categories that contain very few data points, but are very similar to one another. In this case, you can combine them into a single category. In other cases, it might just be that someone used a different spelling, a synonym, or an abbreviation. In such cases, it is better to combine them into a single category as well. Sometimes, you might want to split up a numerical feature into bins that have a business meaning for your users or stakeholders. This is an example of data preparation that you will need to do on your own based on your understanding of the problem. You should do this prior to uploading the data into DataRobot.</p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor050"/>Target leakage</h2>
			<p>Sometimes, the<a id="_idIndexMarker081"/> dataset contains features that are derived from the target itself. These are not known in advance or are not known at the time of prediction. Inadvertently using these features to build a model causes problems downstream. This issue is called target leakage. The dataset should be inspected carefully and such features should be removed from the training features. DataRobot will also analyze the features automatically and try to flag any features that might lead to target leakage.</p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor051"/>Term-document matrix</h2>
			<p>Your <a id="_idIndexMarker082"/>dataset may contain features that contain text or notes. These notes frequently contain important information that is useful for making decisions. Many of the algorithms, however, cannot make use of this text directly. This text has to be parsed into numeric values for it to become useful to modeling algorithms. There are several methods for doing that, with the most common one being the term-document matrices. Document here refers to a single text or notes entry. Each of these documents can be parsed to split it up into terms. Now you can count how many times a term showed up in a document. This result can be stored in a <a id="_idIndexMarker083"/>matrix called a <strong class="bold">Term Frequency</strong> (<strong class="bold">TF</strong>) matrix. Some of this information can also be visualized in word clouds. DataRobot will automatically build these word clouds for you. While TF is useful, it can be limiting because some terms might be very common in all the documents, hence they are not very useful in distinguishing between them. This leads to another idea, whereby perhaps we should look for terms that are somewhat unique to a document. This concept of giving more weight to a term that is present in some documents only is<a id="_idIndexMarker084"/> called <strong class="bold">Inverse Document Frequency</strong> (<strong class="bold">IDF</strong>). The combination of a term showing up multiple times in a document (TF) and it being somewhat rare (IDF) is <a id="_idIndexMarker085"/>called <strong class="bold">TFIDF</strong>. TFIDF is something that DataRobot will compute automatically for you and gets applied to features that contain text.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor052"/>Data transformations</h2>
			<p>While <a id="_idIndexMarker086"/>DataRobot will do many data transformations for you (and it keeps adding more all the time), there are many transformations that will impact your model but that DataRobot will not be able to catch. You will have to do these on your own. Examples of these are mathematical transformations such as log, square, square root, absolute values, and differences. Some of the simple ones can be set up inside DataRobot, but for more complex ones, you will have to perform the operations outside of DataRobot or in tools such as Paxata. Sometimes, you will do a transformation to linearize your problem or to deal with features that have long-tailed data. Some of the transformations that DataRobot does automatically are as follows:</p>
			<ul>
				<li>Computing aggregates such as counts, min, max, average, median, most frequent, and entropy</li>
				<li>An extensive list of time-based features, such as change over time, max over time, and averages over time</li>
				<li>Some text extraction features, such as word counts, extracted tokens, and term-document matrices</li>
				<li>Geospatial <a id="_idIndexMarker087"/>features from geospatial data</li>
			</ul>
			<p>We will discuss this topic again in more detail in <a href="B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087"><em class="italic">Chapter 4</em></a>, <em class="italic">Preparing Data for DataRobot</em>.</p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor053"/>Collinearity checks</h2>
			<p>In any given<a id="_idIndexMarker088"/> dataset, there will be features that are highly correlated to other features. In essence, they carry the same information as some other features. It is generally desirable to remove such features that are highly duplicative of some other features in the dataset. DataRobot performs these checks automatically for you and will flag these collinear features. This is especially critical for linear models, but some of the newer methods can deal with this issue better. What thresholds to use varies based on the modeling algorithms and your business problem. It is fairly easy in DataRobot to remove these features from your feature sets to be used for modeling.</p>
			<p>DataRobot also produces a correlation matrix that shows how the different features are correlated to one another. This helps identify collinear features as well as key candidate features to be used in the model. You can gain a lot of insight into your data and the problem by analyzing the correlation matrix. In <a href="B17159_05_Final_NM_ePub.xhtml#_idTextAnchor097"><em class="italic">Chapter 5</em></a>, <em class="italic">Exploratory Data Analysis with DataRobot</em>, we will discuss examples of how this is done.</p>
			<h2 id="_idParaDest-53"><a id="_idTextAnchor054"/>Data partitioning</h2>
			<p>Before you <a id="_idIndexMarker089"/>start building the models, you need to partition your dataset into three parts. These parts are called training, validation, and holdout. These three parts are used for different purposes during the model building process. It is common to split 10-20% of the dataset into the holdout set. The remaining portion is split up further, with 70-80% going to training and 20-30% going to the validation set. This splitting is done to make sure that the models are not overfitted and that the expected results in deployment are in line with results seen during model building.</p>
			<p>Only the training dataset is used to train the model. The validation set is designed to tune the algorithms in order to optimize the results by performing multiple cross-validation tests. Finally, the holdout set is used after the models are built to test the model on data that it has never seen before. If the results on the holdout set are acceptable, then the model can be considered for deployment.</p>
			<p>DataRobot automates most of this process, but it does allow the user to customize the split percentages, as well as how the partitioning should be done. It also performs a similar function for time series or forecasting problems by automatically splitting the data for time-based backtests.</p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor055"/>Data visualization</h1>
			<p>One of the <a id="_idIndexMarker090"/>most important tasks a data analyst or data scientist needs to do is to understand the dataset. Data visualization is key to this understanding. DataRobot provides various ways to visualize the datasets to help you understand the dataset. These visualizations are built automatically for you so that you can spend your time analyzing them instead of preparing them. Let's look at what these are and how to use them.</p>
			<p>When you go to the data page (<em class="italic">Figure 1.20</em>) for your project, you will see high-level profile information for your dataset. Inspect this information carefully to understand your dataset in totality. If you click on the <strong class="bold">Feature Association</strong> menu (top left), you will see how the features are related to one another (<em class="italic">Figure 2.3</em>):</p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="Images/Figure_2.3_B17159.jpg" alt="Figure 2.3 – Feature associations using mutual information&#13;&#10;" width="968" height="781"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3 – Feature associations using mutual information</p>
			<p>This diagram <a id="_idIndexMarker091"/>shows the interrelationships using the <a id="_idIndexMarker092"/>mutual information metric. <strong class="bold">Mutual Information</strong> (<strong class="bold">MI</strong>) uses information theory to determine the amount of information you obtain about one feature from the other feature. The benefit of using MI compared to the Pearson correlation coefficient is that it can be used for any type of feature. The value goes from 0 (the two features are independent) to 1 (they carry the same information). This is useful in determining which features will be good candidates for the model and which features will not provide any useful information or are redundant. This view is extremely important to understand and use before model building starts, even though DataRobot automatically uses this information to make modeling decisions.</p>
			<p>There is another metric that is also used in a similar capacity. If you click on the metric dropdown at the bottom of the preceding screenshot, you can select the other metric called <strong class="bold">Cramer's V</strong>. Once<a id="_idIndexMarker093"/> you select Cramer's V, you will see a similar graphical view (<em class="italic">Figure 2.4</em>):</p>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="Images/Figure_2.4_B17159.jpg" alt="Figure 2.4 – Feature associations using Cramer's V&#13;&#10;" width="1001" height="789"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4 – Feature associations using Cramer's V</p>
			<p>Cramer's V is<a id="_idIndexMarker094"/> an alternative metric to MI, and it is used similarly. Its value also ranges from 0 (no relationship) to 1 (the features are highly correlated). Cramer's V is often used with categorical variables as an alternative to the Pearson correlation coefficient.</p>
			<p>Notice that DataRobot automatically found clusters of interrelated features. Each cluster is color-coded in a different color, and the features are sorted by clusters in <em class="italic">Figure 2.4</em>. You can zoom into specific clusters to inspect them further. This is an important feature of the DataRobot environment as very few data scientists know about this idea or make use of it. The clusters are important because they highlight groups of interrelated features. These complex interdependencies are typically very important for understanding the business problem. Normally, the only people who know about these complex interdependencies are people with a lot of domain experience. Most others will not even be aware of these complexities. If you are new to a domain, then understanding these will give you an equivalent of multiple years of experience. Study these carefully, discuss them with your business experts to fully understand what they are trying to highlight, and then use these insights to improve your models as well as your business processes.</p>
			<p>Also, note that DataRobot provides a list of the top 10 strongest associations. It is important to note these associations and spend some time thinking about what they mean for your problem. Are these consistent with what you know about your domain, or are there some surprises? It is the surprises that often result in key insights that could prove to be valuable insights for <a id="_idIndexMarker095"/>your business. In the following list, you see a <strong class="bold">View Feature Association Pairs</strong> button. If you click on that button, you will see <em class="italic">Figure 2.5</em>:</p>
			<div>
				<div id="_idContainer035" class="IMG---Figure">
					<img src="Images/Figure_2.5_B17159.jpg" alt="Figure 2.5 – Feature association details&#13;&#10;" width="1224" height="591"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.5 – Feature association details</p>
			<p>This graphic shows the relationship between two selected features in detail. In this example, one feature is categorical while the other is numeric. The diagram shows how the two are related and could provide additional insights into the problem. Be sure to investigate the relationships, especially the ones that might be counterintuitive. </p>
			<p>Now you can click on the specific features to see how they are distributed (<em class="italic">Figure 2.6</em>):</p>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="Images/Figure_2.6_B17159.jpg" alt="Figure 2.6 – Feature details&#13;&#10;" width="1181" height="686"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.6 – Feature details</p>
			<p>This view shows <a id="_idIndexMarker096"/>a histogram of how the values are distributed and how they are related to the target values. Key things to focus on are ranges where you do not have enough data and where you have non-linearities. These could give you ideas about feature engineering. These are also areas where you ask the question why does the system exhibit this behavior?</p>
			<p>With this background work done, you are now ready to dive into modeling algorithms.</p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor056"/>Machine learning algorithms</h1>
			<p>There are <a id="_idIndexMarker097"/>now hundreds of machine learning algorithms available to be used for a machine learning project, and more are being invented every day. DataRobot supports a wide array of open source machine learning algorithms, including several deep learning algorithms – Prophet, SparkML-based algorithms, and H2O algorithms. Let's now take a look at what types of algorithms exist and what they are used for (<em class="italic">Figure 2.7</em>):</p>
			<div>
				<div id="_idContainer037" class="IMG---Figure">
					<img src="Images/Figure_2.7_B17159-DESKTOP-C2VUV36.jpg" alt="Figure 2.7 – Machine learning algorithms&#13;&#10;" width="1524" height="633"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.7 – Machine learning algorithms</p>
			<p>Our focus<a id="_idIndexMarker098"/> will mostly be on the algorithm types that<a id="_idIndexMarker099"/> DataRobot supports. These algorithm types are described in the following sub-sections.</p>
			<h3>Supervised learning</h3>
			<p>Supervised<a id="_idIndexMarker100"/> learning algorithms <a id="_idIndexMarker101"/>are used when you can provide an answer (also called a label) as part of the training dataset. For supervised learning, you have to assign a feature of your dataset to be the answer, and the algorithm tries to learn to predict the answer by seeing multiple examples and learning from these examples. See <em class="italic">Figure 2.8</em> for the different types of answers:</p>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="Images/Figure_2.8_B17159.jpg" alt="Figure 2.8 – Targets for supervised learning algorithms&#13;&#10;" width="1650" height="553"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.8 – Targets for supervised learning algorithms</p>
			<p>DataRobot functionality is primarily focused on supervised learning algorithms. Included in the set<a id="_idIndexMarker102"/> are deep learning <a id="_idIndexMarker103"/>algorithms as well as big data algorithms from SparkML and H2O. DataRobot has built-in best practices to select the best-suited algorithms for your problem and dataset. There are four major types of supervised learning <a id="_idIndexMarker104"/>problems:</p>
			<h3>Regression</h3>
			<p>Regression<a id="_idIndexMarker105"/> problems are the ones where the answer (target) takes a numeric form (see <em class="italic">Figure 2.8</em>). Regression models try to fit a curve such that the error between the prediction and the actual value is minimized for the entire training dataset. Sometimes, even a classification problem can be set up as a numeric regression problem. In such cases, the answer is a number that can then be turned into a bin by using thresholds. Logistic regression is one such method that produces a value between zero and one. You can mark all answers below a certain threshold to be zero, and all above as ones. There are linear as well as non-linear regression algorithms that are used based on the problem. The models are assessed based on how well the regression line matches the data. Typical metrics used are <strong class="bold">RMSE</strong>, <strong class="bold">MAPE</strong>, <strong class="bold">LogLoss</strong>, and <strong class="bold">Rsquared</strong>. Typical algorithms used are <strong class="bold">XGBoost</strong>, <strong class="bold">Elastic Net</strong>, <strong class="bold">Random Forest</strong>, and <strong class="bold">GA2M</strong>.</p>
			<h3>Binary classification</h3>
			<p>Binary <a id="_idIndexMarker106"/>classification problems have answers that can only take two distinct values (called classes). These could be in the form of 0 or 1, Yes or No, and so on. Please refer to <em class="italic">Figure 2.8</em> for an example of the target feature for binary classification. A typical issue that you commonly face is the problem of class imbalance. This happens when most of the dataset is biased toward one class. These are typically addressed by downsampling the overrepresented class when sufficient training data is present. When this is not possible, you can try oversampling the underrepresented class or use other methods. None of these methods is perfect, and sometimes you have to try different approaches to see what works best. DataRobot <a id="_idIndexMarker107"/>provides <a id="_idIndexMarker108"/>mechanisms to specify<a id="_idIndexMarker109"/> downsampling <a id="_idIndexMarker110"/>if needed. Some of the algorithms<a id="_idIndexMarker111"/> that are commonly used for binary classification are <strong class="bold">logistic regression</strong>, <strong class="bold">k-nearest neighbors</strong>, <strong class="bold">tree-based algorithms</strong>, <strong class="bold">SVM</strong>, and <strong class="bold">Naïve Bayes</strong>. In the case of classification problems, it is best to avoid using accuracy as a metric to assess results. The results are often shown in the form of a confusion matrix (described later in this chapter). DataRobot will automatically select an appropriate metric to use in such cases.</p>
			<h3>Multiclass classification</h3>
			<p>Multiclass <a id="_idIndexMarker112"/>classification problems are the ones where you are trying to predict more than two classes or categories. For a simple example of what the target might look like, see <em class="italic">Figure 2.8</em>. Multiclass capability was added recently and many of the DataRobot features might not work with such problems. Since downsampling is not available, you might want to adjust your sampling prior to uploading your dataset into DataRobot. Also, note that you can frequently collapse your problem into a binary classification problem by collapsing the classes into two classes. That may or may not work for your use case, but it is an option if required. Also, not all algorithms are appropriate for multiclass problems. DataRobot will automatically select the appropriate algorithms to build the models for multiclass problems. Typical metrics to use are AUC, LogLoss, or Balanced Accuracy. The results are often shown in the form of a confusion matrix (described later in this chapter). Typical algorithms used are XGBoost, Random Forest, and TensorFlow.</p>
			<h3>Time series/forecasting</h3>
			<p>Time series or<a id="_idIndexMarker113"/> forecasting models are also referred to as time-aware models in DataRobot. In these problems, you have data that is changing over time and you are interested in predicting/forecasting a target value in the future (<em class="italic">Figure 2.2</em>). DataRobot not only supports the usual algorithms for time series such as ARIMA, but can also adapt these problems to machine learning regression problems and then apply algorithms such as XGBoost to solve them. These problems require that the series should be transformed into stationary series and require extensive feature engineering to create time-based features. The problems also require that you take into account important events in the past that may repeat (such as holidays or major shopping days). Time series models also require special ways of handling validation and testing via a method called backtests:</p>
			<div>
				<div id="_idContainer039" class="IMG---Figure">
					<img src="Images/Figure_2.9_B17159.jpg" alt="Figure 2.9 – Backtesting for time series problems&#13;&#10;" width="870" height="789"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.9 – Backtesting for time series problems</p>
			<p>In backtesting, models are built using past data, and then tested using holdout data that is newer and has never been seen by the model. This time-based slicing of holdout data is also referred to as out-of-time validation. DataRobot automates many of these tasks for <a id="_idIndexMarker114"/>you, as we will see in more detail later.</p>
			<h3>Algorithms</h3>
			<p>Let's review some <a id="_idIndexMarker115"/>of the main algorithms used in DataRobot. Here, we only provide a high-level overview of these algorithms These algorithms can be tuned for a given problem by changing their hyperparameters. For a more detailed understanding of any specific algorithm, you can refer to a machine learning book or the DataRobot documentation. Some of the important algorithms are as follows:</p>
			<ul>
				<li><strong class="bold">Random Forest</strong>. A random forest model is built by creating multiple decision tree models and then uses the mean of the output. This is done by creating bootstrap samples of the training data and building decision trees (<em class="italic">Figure 2.10</em>) on these samples:</li>
			</ul>
			<div>
				<div id="_idContainer040" class="IMG---Figure">
					<img src="Images/Figure_2.10_B17159.jpg" alt="Figure 2.10 – Random forest&#13;&#10;" width="1650" height="538"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.10 – Random forest</p>
			<p>Random forest models handle missing data and non-linearities and have proven to work great in many situations. A random forest model can be used for regression as well as classification problems:</p>
			<ul>
				<li><strong class="bold">XGBoost</strong>: Also known as <strong class="bold">eXtreme</strong> gradient<a id="_idIndexMarker116"/> boosted trees, are decision tree-based algorithms that have become very popular because they tend to produce very effective predictions and can handle missing values. They can handle non-linear problems and interactions between features. XGBoost builds upon random forest models by creating a random forest and then creating trees on the residuals of the previous trees. This way, every new set of trees is able to produce a better result. XGBoost can be used for regression as well as classification problems.</li>
				<li><strong class="bold">Rulefit</strong>: Rulefit models are ensembles of simple rules. You can think of these rules as being chained together like a decision tree. Rulefit models are much easier to understand as most people can relate to a combination of rules being applied to solve a problem. DataRobot typically builds this model to help you understand a problem and provide insights. You can go to the insights section of your <strong class="bold">Models</strong> tab <a id="_idIndexMarker117"/>and see the insights generated from a Rulefit model and how effective a given rule is for the problem. They can be used for classification as well as regression problems.</li>
				<li><strong class="bold">ElasticNet</strong>, <strong class="bold">Ridge regressor</strong>, <strong class="bold">Lasso regressor</strong>: These models use regularization to make sure that the models are not overfitting and are not unnecessarily complex. Regularization is done by adding a penalty for adding more features, which in turn forces the models to either drop some features or reduce their relative impact. Lasso regressor (also known as <strong class="bold">L1 regressor</strong>) uses penalty weights that are the absolute values of the coefficients. The effect of using Lasso is that it tries to reduce the coefficients to zero, thereby selecting important features and removing the ones that do not contribute much. Ridge regressor (also known as <strong class="bold">L2 regressor</strong>) uses penalty weights that are squared coefficients. The impact of this is to reduce the magnitude of coefficients. <strong class="bold">ElasticNet</strong> is used to refer to linear models that use both Lasso and Ridge regularization to produce models that are simpler as well as regularized. This comes in handy when you have a lot of features that are correlated with each other.</li>
				<li><strong class="bold">Logistic Regression</strong>: Logistic regression is a non-linear regression model that is used for binary classification. The output is in the form of a probability with a value ranging from 0 to 1. This is then typically used with a threshold to assign the value to be a 0 or a 1.</li>
				<li><strong class="bold">SVM</strong> (<strong class="bold">Support Vector Machine</strong>): This<a id="_idIndexMarker118"/> is a classification algorithm that tries to find a vector that best separates classes. It is easy to see what this looks like in a two-dimensional space (<em class="italic">Figure 2.11</em>), but the algorithm is known to work well in high dimension spaces. Another benefit of SVM is its ability to handle non-linearity by <a id="_idIndexMarker119"/>using non-linear kernel functions, which can be used to linearize the problem:</li>
			</ul>
			<div>
				<div id="_idContainer041" class="IMG---Figure">
					<img src="Images/Figure_2.11_B17159.jpg" alt="Figure 2.11 – Targets for supervised learning algorithms&#13;&#10;" width="1130" height="346"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.11 – Targets for supervised learning algorithms</p>
			<ul>
				<li><strong class="bold">GA2M</strong> (<strong class="bold">Generalized Additive Model</strong>): This is one of those rare algorithms that offers understandability, while also offering high accuracy even in a non-linear problem. The number "2" in the name represents its ability to model interactions between features. GAM model output is a summation of outputs of the effects of individual features that have been binned. Since GAM allows these effects to be non-linear, it can capture the non-linear nature of the problem. The results of the model can be represented as a simple table that shows you the contribution of each feature to the overall answer. This type of table representation is easily understandable by most people. For industries or use cases where understandability and explainability are very important, this is perhaps one of the best options you can choose.</li>
				<li><strong class="bold">K-Nearest Neighbors</strong>: This is a very straightforward algorithm that finds the k closest data points (based on a specific way of computing distance). Now it finds the classification answers for these k points. It then determines the answer with the most votes and then assigns that as the answer. The default distance metric used is <strong class="bold">Euclidian</strong> distance, but<a id="_idIndexMarker120"/> DataRobot chooses the appropriate metric based on the dataset. A user can also specify a specific distance metric to be used.</li>
				<li><strong class="bold">TensorFlow</strong>. TensorFlow is a deep learning model that is based on deep neural networks. A <a id="_idIndexMarker121"/>deep neural network is one that has hidden deep layers made up of ensembles of artificial neurons. The neurons carry highly non-linear activation functions that allow them to fit highly non-linear problems. These models are very good at producing high accuracy without the need for feature engineering, but they do require a lot more training data as compared to other algorithms. These models are generally considered very opaque and are prone to overfitting and are therefore not suitable for some applications. They are especially successful for applications where the features and feature engineering are hard to extract, for example, image processing. These models can be used for regression as well as classification problems.</li>
				<li><strong class="bold">Keras Neural Network</strong>: Keras is a high-level deep learning library built on top of TensorFlow that allows many types of deep learning models to be incorporated into DataRobot. Being a higher-level library, it makes building a TensorFlow model a lot easier. Everything described in the preceding section applies to Keras. The particular implementation in DataRobot is well suited for sparse datasets and is particularly useful for text processing and classification problems.</li>
			</ul>
			<h2 id="_idParaDest-56"><a id="_idTextAnchor057"/>Unsupervised learning</h2>
			<p>Unsupervised<a id="_idIndexMarker122"/> learning problems <a id="_idIndexMarker123"/>are those where you are not provided with an answer or a label. Examples of such problems are clustering or anomaly detection. DataRobot does not offer much for these problems, but it does have some capability for anomaly or outlier detection. These are problems where you have data points that are unusual in a way that happens very rarely. Examples include fraud detection, cybersecurity breach detection, failure detection, and data outlier detection. DataRobot allows you to set up a project without a target and it will then attempt to identify anomalous data points. For any clustering problems, you should try to use Python or R to create clustering models.</p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor058"/>Reinforcement learning</h2>
			<p>Reinforcement<a id="_idIndexMarker124"/> learning <a id="_idIndexMarker125"/>problems are where you want to learn a series of decisions to be taken by an agent such that you achieve a certain goal. This goal is associated with a reward that is given to the agent for achieving the goal either completely or partially. There is no dataset available for this training, so the agent must try multiple times (with different strategies) and learn something on each attempt. Over many attempts, the agent will learn the strategy or rules that produce the best reward. As you can now guess, these algorithms work best when you do not have data, but you can experiment repeatedly in the real world (or a synthetic world). As we discussed before, DataRobot is not a suitable tool for such problems.</p>
			<h2 id="_idParaDest-58"><a id="_idTextAnchor059"/>Ensemble/blended models</h2>
			<p>Ensembling<a id="_idIndexMarker126"/> is a technique <a id="_idIndexMarker127"/>for creating a model that aggregates or blends predictions of other models. Different algorithms are sometimes able to exploit different aspects of the problem or dataset better. This means that many times, you can increase prediction accuracy by combining several good models. This, of course, comes with increasing complexity and cost. DataRobot offers many blending approaches and, in most circumstances, builds the blended model automatically for your project. You can then evaluate whether the increase in accuracy is enough to justify the additional complexity.</p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor060"/>Blueprints</h2>
			<p>In<a id="_idIndexMarker128"/> DataRobot, every<a id="_idIndexMarker129"/> model is associated with a blueprint. A blueprint is a step-by-step recipe used by DataRobot to train a specific model. See <em class="italic">Figure 2.12</em> for an example:</p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="Images/Figure_2.12_B17159.jpg" alt="Figure 2.12 – Model blueprint&#13;&#10;" width="1115" height="659"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.12 – Model blueprint</p>
			<p>The blueprint shows all the steps taken by DataRobot to build that specific model, including any data preparation and feature engineering done by DataRobot. Clicking on any specific<a id="_idIndexMarker130"/> box <a id="_idIndexMarker131"/>will show more details on the actions taken, parameters used, and documentation of the particular algorithm used. This also serves as great documentation for your modeling project that is automatically created for you.</p>
			<p>Now, let's look at how to determine how well an algorithm did. For this, we will require some performance metrics.</p>
			<h1 id="_idParaDest-60"><a id="_idTextAnchor061"/>Performance metrics</h1>
			<p>DataRobot <a id="_idIndexMarker132"/>offers a wide range of performance metrics for the models. You have to specify the metric you want to use to optimize the models for your project. Typically, the best metric to use is the one recommended by DataRobot. DataRobot does compute the other metrics as well once the model is built, so you can review the results of your model across multiple metrics. Please keep in mind that no metric is perfect for every situation, and you should be careful in selecting the metric for evaluating your results. Listed here are some details regarding commonly used metrics:</p>
			<ul>
				<li><strong class="bold">RMSE</strong> (<strong class="bold">Root Mean Squared Error</strong>): RMSE is a metric that first computes the square of<a id="_idIndexMarker133"/> errors (the difference between actual and predicted). These are then averaged over the entire dataset and then we compute a square root of that average. Given that this metric is dependent on the scale of the values, its interpretation is dependent on the problem. You cannot compare RMSE for two different datasets. This metric is frequently used for regression problems when the data is not highly skewed.</li>
				<li><strong class="bold">MAPE</strong> (<strong class="bold">Mean Absolute Percentage Error</strong>): MAPE is somewhat similar to RMSE in<a id="_idIndexMarker134"/> the sense that it first computes the absolute value of the percentage error. Then, these values are averaged over the dataset. Given that this metric is scaled in terms of<a id="_idIndexMarker135"/> percentage, it is easier to compare MAPE for different datasets. However, you have to be mindful of the fact that the percentage error for very small values (or zero values) tends to look very big.</li>
				<li><strong class="bold">SMAPE</strong> (<strong class="bold">Symmetric MAPE</strong>): SMAPE<a id="_idIndexMarker136"/> is similar to MAPE, but addresses some of the shortcomings discussed above. SMAPE bounds the upper percentage value so that errors from small values do not overpower the metric. This makes SMAPE a good metric that you can easily compare across different problems.</li>
				<li><strong class="bold">Accuracy</strong>: Accuracy is one of the metrics used for classification problems. It can be represented as follows:<p><em class="italic">Accuracy = number of correct predictions/number of total predictions</em></p><p>It is essentially the ratio of the number of correct predictions and all predictions. For unbalanced problems, this metric can be misleading, hence it is never used by itself to determine how well a model did. It is typically used in combination with other metrics.</p></li>
				<li><strong class="bold">Balanced Accuracy</strong>: Balanced accuracy overcomes the issues with accuracy by normalizing the accuracy across the two classes being predicted. Let's say that the two classes are A and B:<p>(a) <em class="italic">Accuracy rate for A = number of correct A predictions/total number of As</em></p><p>(b) <em class="italic">Accuracy rate for B = number of correct B predictions/total number of Bs</em></p><p>(c) <em class="italic">Balanced accuracy = accuracy rate for A + accuracy rate for B/2</em></p><p>Balanced <a id="_idIndexMarker137"/>accuracy is essentially the average of the accuracy rate for A and the accuracy rate for B.</p></li>
				<li><strong class="bold">AUC</strong> (<strong class="bold">Area Under the ROC Curve</strong>): AUC <a id="_idIndexMarker138"/>is the<a id="_idIndexMarker139"/> area under the <strong class="bold">ROC</strong> (<strong class="bold">Received Operator Characteristic</strong>) curve. This metric is frequently used for classification problems as this also overcomes the deficiencies associated with the accuracy metric. The ROC curve represents the relationship between the true positive rate and the false positive rate. The AUC goes from 0 to 1 and it shows how well the model discriminates between the two classes. A value of 0.5 represents a random model, so you would want the AUC for your model to be greater than 0.5.</li>
				<li><strong class="bold">Gamma Deviance</strong>: Gamma <a id="_idIndexMarker140"/>deviance is used for regression problems when the target values are gamma-distributed. For such targets, gamma deviance measures twice the average deviance (using the log-likelihood function) of the predictions from the actuals. A model that fits perfectly will have a deviance of zero.</li>
				<li><strong class="bold">Poisson Deviance</strong>: Poisson deviance is used for regression problems when the aim is to count data that is skewed. It works in a way that is very similar to gamma deviance.</li>
				<li><strong class="bold">LogLoss</strong>: LogLoss (also known <a id="_idIndexMarker141"/>as cross-entropy loss) is a measure of the inaccuracy of predicted probabilities for a classification problem. A value of 0 indicates a perfect model, and as the model becomes worse, the logloss value increases.</li>
				<li><strong class="bold">Rsquared</strong>: Rsquared is a metric used for regression problems that tells how well the fitted line represents the dataset. Its value ranges between 0 and 1. 0 indicates a poor model that explains none of the variation, while a value of 1 indicates a perfect model that explains 100% of the variation. It is one of the most commonly used metrics, but it can suffer from the problem that you can increase it by adding more variables without necessarily improving the model. It is also not suitable for non-linear problems.</li>
			</ul>
			<p>Now that we have <a id="_idIndexMarker142"/>discussed some of the commonly used metrics, let's look at how to look at other results to assess the quality of your model, and the effects of different features on your model.</p>
			<h1 id="_idParaDest-61"><a id="_idTextAnchor062"/>Understanding the results</h1>
			<p>In this section, we <a id="_idIndexMarker143"/>will discuss various visualizations of metrics and other information to understand the results of the modeling exercise. These are important visualizations that need to be inspected carefully in addition to looking at the model metrics discussed in the previous section. These visualizations are generated automatically by DataRobot for any model that it trains.</p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor063"/>Lift chart </h2>
			<p>The lift <a id="_idIndexMarker144"/>chart shows how effective the model is at predicting the target values. As the number of data points is typically very large to show in one graphic, the lift chart sorts the output and aggregates the data into multiple bins. It then compares the averages of predictions and actuals in each bin (<em class="italic">Figure 2.13</em>):</p>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="Images/Figure_2.13_B17159.jpg" alt="Figure 2.13 – Lift chart&#13;&#10;" width="1002" height="657"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.13 – Lift chart</p>
			<p>The preceding<a id="_idIndexMarker145"/> lift chart shows how the predictions have been sorted from low to high and then binned (60 bins in this case). You can now see the average prediction and average actual value in each bin. This gives you a sense of how well the model is doing across the entire spectrum. You can see whether there are ranges where the model is doing worse. If the model is not doing well in a range that is important to your business, you can then investigate further to see how you can improve the model in that range. You can also inspect different models to see whether there is a model that does better in the region that is more important. Lift charts are more meaningful for regression problems.</p>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor064"/>Confusion matrix (binary and multiclass)</h2>
			<p>For<a id="_idIndexMarker146"/> classification problems, one of the best ways to assess model results is by looking at the confusion matrix and its associated metrics (<em class="italic">Figure 2.14</em>). This tab is available for multiclass problems:</p>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="Images/Figure_2.14_B17159.jpg" alt="Figure 2.14 – Confusion matrix&#13;&#10;" width="1165" height="717"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.14 – Confusion matrix</p>
			<p>The confusion matrix maps predicted versus actual counts (frequency) for each class. Let's look at the sedan column. The big green circle indicates how many times we correctly classified a sedan as a sedan. In that column, you will also see red dots where the model predicted it to be a sedan, but it is a different type. You can see these for all classes. The relative scales should give you an idea of how well your model did and where it is having difficulty.</p>
			<p>If you select a specific class, you can look at the class-specific confusion matrix on the right. You can see two columns (+ for predicting a sedan, - for predicting something that isn't a sedan). Similarly, you see two rows (+ where it is a sedan, and - for when it is not a sedan). You also see some critical definitions and metrics:</p>
			<ul>
				<li><strong class="bold">True Positives</strong> (<strong class="bold">TP</strong>) = Where<a id="_idIndexMarker147"/> it is a sedan and is predicted as a sedan</li>
				<li><strong class="bold">False Positives</strong> (<strong class="bold">FP</strong>) = Where <a id="_idIndexMarker148"/>it is not a sedan but is predicted as a sedan</li>
				<li><strong class="bold">True Negatives</strong> (<strong class="bold">TN</strong>) = Where <a id="_idIndexMarker149"/>it is not a sedan and is predicted as not being a sedan </li>
				<li><strong class="bold">False Negatives</strong> (<strong class="bold">FN</strong>) = Where<a id="_idIndexMarker150"/> it is a sedan but is predicted as not being a sedan</li>
			</ul>
			<p>Using these, we<a id="_idIndexMarker151"/> can now compute some specific metrics for this class:</p>
			<ul>
				<li><em class="italic">Precision = correct fraction of predictions = TP/All Positive Predictions = TP/(TP+FP)</em></li>
				<li><em class="italic">Recall = correct fraction of actuals = TP/All Positive Actuals = TP/(TP+FN)</em></li>
				<li><em class="italic">F1 Score = harmonic mean of precision and recall. So, 1/F1 = 1/Precision + 1/Recall</em></li>
			</ul>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor065"/>ROC</h2>
			<p>This tab<a id="_idIndexMarker152"/> is available<a id="_idIndexMarker153"/> for binary classification problems. The <strong class="bold">ROC</strong> (<strong class="bold">Receiver Operator Characteristic</strong>) curve is the relationship between the true positive rate and the false positive rate. The area under this curve is known as AUC. It goes from 0 to 1 and it shows how well the model discriminates between the two classes (<em class="italic">Figure 2.15</em>):</p>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="Images/Figure_2.15_B17159.jpg" alt="Figure 2.15 – ROC curve and confusion matrix&#13;&#10;" width="1118" height="707"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.15 – ROC curve and confusion matrix</p>
			<p>You can also see the confusion matrix (described earlier) and the associated metrics for the two<a id="_idIndexMarker154"/> classes. You can <a id="_idIndexMarker155"/>move the thresholds and assess the resulting trade-offs and cumulative gains. Since most problems are not symmetric in the sense that true positives have different business values compared to true negatives, you should select the threshold that makes sense for your business problem.</p>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor066"/>Accuracy over time</h2>
			<p>This tab is <a id="_idIndexMarker156"/>available for time series problems (<em class="italic">Figure 2.16</em>) and compares the actual versus predicted values over time for a series:</p>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="Images/Figure_2.16_B17159.jpg" alt="Figure 2.16 – Model accuracy over time&#13;&#10;" width="1129" height="587"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.16 – Model accuracy over time</p>
			<p>You can view these values for the backtests or the holdout datasets. The diagram will clearly show <a id="_idIndexMarker157"/>where the model is not performing well and what you might want to focus on to improve your model.</p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor067"/>Feature impacts</h2>
			<p>Besides <a id="_idIndexMarker158"/>model performance, one of the first things you want to understand is how impactful the features are in terms of your model's performance. The <strong class="bold">Feature Impacts</strong> tab (<em class="italic">Figure 2.17</em>) is perhaps the most critical for understanding your model:</p>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="Images/Figure_2.17_B17159.jpg" alt="Figure 2.17 – Feature impacts&#13;&#10;" width="1181" height="628"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.17 – Feature impacts</p>
			<p>The graphic shows a sorted list of the most important features. For each feature, you can see the <a id="_idIndexMarker159"/>relative impact that a feature has on this model. You can see which features contribute very little; this can be used to create new feature lists by removing some of the features that have very little impact.</p>
			<h2 id="_idParaDest-67"><a id="_idTextAnchor068"/>Feature Fit</h2>
			<p>The <strong class="bold">Feature Fit</strong> tab (<em class="italic">Figure 2.18</em>) shows <a id="_idIndexMarker160"/>an alternative view of the contribution of a feature. The graphic shows the features ranked by their importance:</p>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="Images/Figure_2.18_B17159.jpg" alt="Figure 2.18 – Feature Fit&#13;&#10;" width="1171" height="555"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.18 – Feature Fit</p>
			<p>For the selected feature, it shows how the predictions compare to actuals for the range of values of a feature. Reviewing these graphs for the key features can provide a lot of insight about how a feature impacts the results and range of values that perform better and ranges<a id="_idIndexMarker161"/> where it performs the worst. This could sometimes highlight the regions where you might need to collect more data to improve your model.</p>
			<h2 id="_idParaDest-68"><a id="_idTextAnchor069"/>Feature Effects</h2>
			<p><strong class="bold">Feature Effects</strong> show <a id="_idIndexMarker162"/>information that is very similar to <strong class="bold">Feature Fit</strong> (<em class="italic">Figure 2.19</em>). In this graphic, the features are sorted by <strong class="bold">Feature Impacts</strong>. Also, <strong class="bold">Feature Effects</strong> are focused on partial dependence:</p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="Images/Figure_2.19_B17159.jpg" alt="Figure 2.19 – Feature Effects and Partial Dependence&#13;&#10;" width="1173" height="547"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.19 – Feature Effects and Partial Dependence</p>
			<p>Partial dependence plots are one of the most important plots that you want to study carefully. These plots tell you how a change in the value of a feature impacts the change in the average <a id="_idIndexMarker163"/>value of the target over a range of values for the other features. This insight is critical to understanding the business problem, understanding what the model is doing, and, more importantly, what aspects of the model are actionable and what range of values will produce the maximum impact.</p>
			<h2 id="_idParaDest-69"><a id="_idTextAnchor070"/>Prediction Explanations</h2>
			<p><strong class="bold">Prediction Explanations</strong> describe<a id="_idIndexMarker164"/> the reasons for a specific prediction in terms of feature values for the specific instance or row that is being scored (<em class="italic">Figure 2.20</em>). Note that this is different from <strong class="bold">Feature Impacts</strong>, which tell you the importance of a feature at a global level:</p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="Images/Figure_2.20_B17159.jpg" alt="Figure 2.20 – Prediction Explanations&#13;&#10;" width="1134" height="601"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.20 – Prediction Explanations</p>
			<p><strong class="bold">Prediction Explanations</strong> can be generated for an entire dataset or a subset of data, as shown in the preceding screenshot. For example, it will provide the top three reasons why the model predicted a specific value. These explanations are sometimes required for regulatory reasons in certain use cases, but it is a good idea to produce these explanations as they do help in understanding why a model predicts a certain way and can be very useful in validating or catching errors in a model. DataRobot uses two algorithms<a id="_idIndexMarker165"/> for computing<a id="_idIndexMarker166"/> the explanations: <strong class="bold">XEMP</strong> (<strong class="bold">exemplar-based explanations</strong>) or <strong class="bold">Shapley values</strong>. XEMP is supported for a broader range of models and is selected by default. Shapley values are described in the next section.</p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor071"/>Shapley values</h2>
			<p><strong class="bold">Shapley</strong><strong class="bold"><a id="_idIndexMarker167"/></strong><strong class="bold"> values</strong> (<strong class="bold">SHAP</strong>) are an alternative<a id="_idIndexMarker168"/> mechanism for producing prediction explanations (<em class="italic">Figure 2.21</em>). If you want to use SHAP for explanations, you have to specify this in the advanced options during the project setup before you press the <strong class="bold">Start</strong> button. Once DataRobot starts building the models, you cannot switch to SHAP. SHAP values are only available for linear or tree-based models and are not available for ensemble models:</p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="Images/Figure_2.21_B17159.jpg" alt="Figure 2.21 – SHAP-based explanations&#13;&#10;" width="1092" height="518"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.21 – SHAP-based explanations</p>
			<p>SHAP values are based on cooperative game theory, which tries to assign values to contributions of a team member in a collaborative project. In the context of machine learning, it <a id="_idIndexMarker169"/>tries to assign the value <a id="_idIndexMarker170"/>contribution of a specific feature when there is a team of features collaborating to make a prediction. SHAP values are additive and you can easily see how much of the final answer is due to a specific feature value.</p>
			<h1 id="_idParaDest-71"><a id="_idTextAnchor072"/>Summary</h1>
			<p>In this chapter, we covered some of the basic machine learning concepts that will come in handy as we go through the remaining chapters, and they will also be useful in your data science journey. Please note that we have only covered concepts at a high level, and depending on your job role, you might want to explore some areas in more detail. We have also related this material to how DataRobot performs certain functions and where you need to pay closer attention.</p>
			<p>Hopefully, this has given you some insights into what DataRobot will be displaying and where to focus your attention in different stages of your project. Since DataRobot automates a good chunk of model building and prediction tasks, it might be tempting to ignore many of the outputs that DataRobot is automatically producing for you. Please resist that temptation. DataRobot software is taking considerable pains and resources to produce those outputs for a very good reason. It is also doing much of the grunt work for you, so please take advantage of those capabilities. Specifically, we have covered the following: What are the things to watch out for during data preparation? What data visualizations are important for gaining an understanding of your dataset? What are the key machine learning algorithms, and when do you use them? How do you measure the goodness of your model results? How do you assess model performance and understand what the model is telling you about your problem?</p>
			<p>Now that we know the basics, we will start our data science journey in the next chapter by learning how to understand the business problem and how to turn it into a specification that can be solved by using machine learning.</p>
		</div>
	</div></body></html>