<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Learning the Graphical User Interface and Basic Filtering</h1></div></div></div><p>In the previous chapter, we learned the basic classes and structures of OpenCV and the most important class called <code class="literal">Mat</code>.</p><p>We learned how to read and save images, videos, and the internal structure in the memory of images.</p><p>We are ready to work now, but we need to show our results and have some basic interaction with our images. OpenCV provides us with a few basic user interfaces to work with and help create our applications and prototypes.</p><p>To better understand how the user interface works, we are going to create a small application called <a id="id108" class="indexterm"/>
<strong>PhotoTool</strong> at the end of this chapter. In this application, we will learn how to use filters and color conversions.</p><p>In this chapter, we will cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The basic OpenCV user interface</li><li class="listitem" style="list-style-type: disc">The OpenCV QT interface</li><li class="listitem" style="list-style-type: disc">Sliders and buttons</li><li class="listitem" style="list-style-type: disc">An advanced user interface—OpenGL</li><li class="listitem" style="list-style-type: disc">Color conversion</li><li class="listitem" style="list-style-type: disc">Basic filters</li></ul></div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec24"/>Introducing the OpenCV user interface</h1></div></div></div><p>OpenCV has<a id="id109" class="indexterm"/> its own cross-operating system user interface that allows developers to create their own applications without the need to learn complex libraries for the user interface.</p><p>The OpenCV user interface is basic, but it gives Computer Vision developers the basic functions to create and manage their software developments. All of them are native and optimized for real-time use.</p><p>OpenCV provides<a id="id110" class="indexterm"/> two options for the user interface:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A basic interface based on native user interfaces, such as Cocoa or Carbon for OS X and GTK for Linux or Windows user interfaces, that are selected by default when you compile OpenCV.</li><li class="listitem" style="list-style-type: disc">A slightly more advanced interface based on the QT library that is cross-platform. You have to enable the QT option manually in CMake before you compile OpenCV.<div><img src="img/B04283_03_01.jpg" alt="Introducing the OpenCV user interface"/></div></li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec25"/>A basic graphical user interface with OpenCV</h1></div></div></div><p>We are <a id="id111" class="indexterm"/>going to create a basic user interface with OpenCV. The OpenCV user interface allows us to create windows, add images to it, move it, resize it, and destroy it.</p><p>The user interface <a id="id112" class="indexterm"/>is in the OpenCV's module called <code class="literal">highui</code>:</p><div><pre class="programlisting">#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;sstream&gt;
using namespace std;

// OpenCV includes
#include "opencv2/core.hpp"
#include "opencv2/highgui.hpp"
using namespace cv;

const int CV_GUI_NORMAL= 0x10;

int main( int argc, const char** argv )
{
  // Read images
  Mat lena= imread("../lena.jpg");
  Mat photo= imread("../photo.jpg");
  
  // Create windows
  namedWindow("Lena", CV_GUI_NORMAL);
  namedWindow("Photo", WINDOW_AUTOSIZE);

  // Move window
  moveWindow("Lena", 10, 10);
  moveWindow("Photo", 520, 10);
  
  // show images
  imshow("Lena", lena);
  imshow("Photo", photo); 

  // Resize window, only non autosize
  resizeWindow("Lena", 512, 512); 

  // wait for any key press
  waitKey(0);

  // Destroy the windows
  destroyWindow("Lena");
  destroyWindow("Photo");

  // Create 10 windows
  for(int i =0; i&lt; 10; i++)
  {
    ostringstream ss;
    ss &lt;&lt; "Photo " &lt;&lt; i;
    namedWindow(ss.str());
    moveWindow(ss.str(), 20*i, 20*i);
    imshow(ss.str(), photo);
  }

  waitKey(0);
  // Destroy all windows
  destroyAllWindows();
  return 0;
}</pre></div><p>Let's understand the code.</p><p>The first task that <a id="id113" class="indexterm"/>we need to perform in order to enable a Graphical User Interface is import the OpenCV's module <code class="literal">highui</code>:</p><div><pre class="programlisting">#include "opencv2/highgui.hpp"</pre></div><p>Now, we are prepared to create our new windows, and then we need to load some images that are to be shown:</p><div><pre class="programlisting">// Read images
Mat lena= imread("../lena.jpg");
Mat photo= imread("../photo.jpg");</pre></div><p>To create the windows, we use the <code class="literal">namedWindow</code> function. This function has two parameters: the first parameter is a constant string with the window's name, and the second parameter is the flags that we require, which is optional:</p><div><pre class="programlisting">namedWindow("Lena", CV_GUI_NORMAL);
namedWindow("Photo", WINDOW_AUTOSIZE);</pre></div><p>In our case, we create two windows: the first window is called <code class="literal">Lena</code> and the second is called <code class="literal">Photo</code>.</p><p>By default, there are the three flags for QT and native interfaces:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">WINDOW_NORMAL</code>: This <a id="id114" class="indexterm"/>flag allows the user to resize the window</li><li class="listitem" style="list-style-type: disc"><code class="literal">WINDOW_AUTOSIZE</code>: If this<a id="id115" class="indexterm"/> flag is set, the window size is automatically adjusted to fit the display image and it is not possible to resize the window</li><li class="listitem" style="list-style-type: disc"><code class="literal">WINDOW_OPENGL</code>: This<a id="id116" class="indexterm"/> flag enables OpenGL support</li></ul></div><p>QT has some more flags, which are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">WINDOW_FREERATIO</code> or <code class="literal">WINDOW_KEEPRATIO</code>: If set <a id="id117" class="indexterm"/>to <code class="literal">WINDOW_FREERATIO</code>, then the image<a id="id118" class="indexterm"/> is adjusted with no respect to its ratio. If set to <code class="literal">WINDOW_FREERATIO</code>, then the image is adjusted with respect to its ratio.</li><li class="listitem" style="list-style-type: disc"><code class="literal">CV_GUI_NORMAL </code>or <code class="literal">CV_GUI_EXPANDED</code>: The <a id="id119" class="indexterm"/>first flag enables the basic interface <a id="id120" class="indexterm"/>without the status bar and toolbar. The second flag enables the most advanced graphical user interface with the status bar and toolbar.</li></ul></div><div><div><h3 class="title"><a id="note15"/>Note</h3><p>If we compile OpenCV with QT, all the windows that we create are, by default, in the expanded interface, but we can use native and more basic interfaces by adding the <code class="literal">CV_GUI_NORMAL</code> flag.</p><p>By default, the flags are <code class="literal">WINDOW_AUTOSIZE</code>, <code class="literal">WINDOW_KEEPRATIO</code>, and <code class="literal">CV_GUI_EXPANDED</code>.</p></div></div><p>When we create <a id="id121" class="indexterm"/>multiple windows, they are superimposed one above the other, but we can move the windows to any area of our desktop with the <code class="literal">moveWindow</code> function:</p><div><pre class="programlisting">// Move window
moveWindow("Lena", 10, 10);
moveWindow("Photo", 520, 10);</pre></div><p>In our code, we move the <code class="literal">Lena</code> window to the left 10 pixels 10 pixels to the top; and the <code class="literal">Photo</code> window to the left 520 pixels and 10 pixels to the top:</p><div><pre class="programlisting">// show images
imshow("Lena", lena);
imshow("Photo", photo); 
// Resize window, only non autosize
resizeWindow("Lena", 512, 512); </pre></div><p>After showing the images that we loaded previously with the <code class="literal">imshow</code> function, we resize the <code class="literal">Lena</code> window to 512 pixels, calling the <code class="literal">resizeWindow</code> function. This function has three parameters: <code class="literal">window name</code>, <code class="literal">width</code>, and <code class="literal">height</code>.</p><div><div><h3 class="title"><a id="note16"/>Note</h3><p>The specific window size is for the image area. Toolbars are not counted. Only windows without the enabled<code class="literal"> WINDOW_AUTOSIZE</code> flag can be resized.</p></div></div><p>After waiting for a <a id="id122" class="indexterm"/>key press with the <code class="literal">waitKey</code> function, we will remove or delete our windows with the <code class="literal">destroyWindow</code> function in which the name of the window is the only parameter that is required:</p><div><pre class="programlisting">waitKey(0);

// Destroy the windows
destroyWindow("Lena");
destroyWindow("Photo");</pre></div><p>OpenCV has a function that is used to remove all the windows that we create in only one call. The function is called <code class="literal">destroyAllWindows</code>. To show how this function works, in our sample we create 10 windows and wait for a key press. When the user presses any key, we destroy all the windows. Anyway, OpenCV automatically handles the destruction of all the windows when the application is terminated, and it is not necessary to call this function at the end of our application:</p><div><pre class="programlisting">// Create 10 windows
for(int i =0; i&lt; 10; i++)
{
  ostringstream ss;
  ss &lt;&lt; "Photo " &lt;&lt; i;
  namedWindow(ss.str());
  moveWindow(ss.str(), 20*i, 20*i);
  imshow(ss.str(), photo);
}

waitKey(0);
// Destroy all windows
destroyAllWindows();</pre></div><p>The result of this code can be seen in the following images in two steps. The first image shows two windows:</p><div><img src="img/B04283_03_02.jpg" alt="A basic graphical user interface with OpenCV"/></div><p>After pressing any key, the <a id="id123" class="indexterm"/>application continues and draws several windows by changing their positions:</p><div><img src="img/B04283_03_03.jpg" alt="A basic graphical user interface with OpenCV"/></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec26"/>The graphical user interface with QT</h1></div></div></div><p>The <a id="id124" class="indexterm"/>QT user interface gives us more control and options to work with our images.</p><p>The interface is divided into three main areas:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The toolbar</li><li class="listitem" style="list-style-type: disc">The image area</li><li class="listitem" style="list-style-type: disc">The status bar<div><img src="img/B04283_03_04.jpg" alt="The graphical user interface with QT"/></div></li></ul></div><p>The toolbar has the following buttons from left to right:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Four buttons for panning</li><li class="listitem" style="list-style-type: disc">Zoom x1</li><li class="listitem" style="list-style-type: disc">Zoom x30 and show labels</li><li class="listitem" style="list-style-type: disc">Zoom in</li><li class="listitem" style="list-style-type: disc">Zoom out</li><li class="listitem" style="list-style-type: disc">Save the current image</li><li class="listitem" style="list-style-type: disc">Show the properties windows</li></ul></div><p>These options can be seen more clearly in the following screenshot:</p><div><img src="img/B04283_03_05.jpg" alt="The graphical user interface with QT"/></div><p>The image <a id="id125" class="indexterm"/>area shows an image and a contextual menu when we push the right mouse button over the image. This area can show an overlay message at the top of the area using the <code class="literal">displayOverlay</code> function. This function accepts three parameters: the window name, the text that we want to show, and the period in milliseconds when the overlay text is displayed. If the time is set to <code class="literal">0</code>, the text never disappears:</p><div><pre class="programlisting">// Display Overlay
displayOverlay("Lena", "Overlay 5secs", 5000);</pre></div><div><img src="img/B04283_03_06.jpg" alt="The graphical user interface with QT"/></div><p>Finally, the <a id="id126" class="indexterm"/>status bar shows the bottom part of the window, the pixel value, and the position of the coordinates in the image:</p><div><img src="img/B04283_03_07.jpg" alt="The graphical user interface with QT"/></div><p>We can use<a id="id127" class="indexterm"/> the status bar to show messages, such as an overlay. The function that can change the status bar message is <code class="literal">displayStatusBar</code>. This function has the same parameters as overlay functions: the window name, the text to show, and the period of time to show it:</p><div><img src="img/B04283_03_08.jpg" alt="The graphical user interface with QT"/></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec27"/>Adding slider and mouse events to our interfaces</h1></div></div></div><p>Mouse events and slider controls <a id="id128" class="indexterm"/>are very useful in Computer Vision and OpenCV. Using these controls, users can interact directly with the interface and change the properties of their input images or variables.</p><p>In this section, we <a id="id129" class="indexterm"/>are going to introduce you to the concepts of adding slider and mouse events for basic interactions. To understand this correctly, we will create a small project, where we paint green circles in the image using the mouse events and blur the image with the slider:</p><div><pre class="programlisting">// Create a variable to save the position value in track
int blurAmount=15;

// Trackbar call back function
static void onChange(int pos, void* userInput);

//Mouse callback
static void onMouse( int event, int x, int y, int, void* userInput );

int main( int argc, const char** argv )
{
  // Read images
  Mat lena= imread("../lena.jpg");
  
  // Create windows
  namedWindow("Lena");
  
  // create a trackbark
  createTrackbar("Lena", "Lena", &amp;blurAmount, 30, onChange, &amp;lena);
  
  setMouseCallback("Lena", onMouse, &amp;lena);

  // Call to onChange to init
  onChange(blurAmount, &amp;lena);
    
  // wait app for a key to exit
  waitKey(0);
  
  // Destroy the windows
  destroyWindow("Lena");
  
  return 0;
}</pre></div><p>Let's understand the code!</p><p>First, we create <a id="id130" class="indexterm"/>a variable to save the slider position, and then we need to save the slider position for access from other functions:</p><div><pre class="programlisting">// Create a variable to save the position value in track
int blurAmount=15;</pre></div><p>Now, we define our callbacks for our slider and mouse events that are required for the OpenCV <code class="literal">setMouseCallbac</code> and <code class="literal">createTrackbar</code> functions:</p><div><pre class="programlisting">// Trackbar call back function
static void onChange(int pos, void* userInput);

//Mouse callback
static void onMouse( int event, int x, int y, int, void* userInput );</pre></div><p>In the main function, we load an image and create a new window called <code class="literal">Lena</code>:</p><div><pre class="programlisting">int main( int argc, const char** argv )
{
  // Read images
  Mat lena= imread("../lena.jpg");
  
  // Create windows
  namedWindow("Lena");</pre></div><p>It is time to create the slider. OpenCV has the <code class="literal">createTrackbar</code> function that is used to generate a slider with the following parameters in order:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The track bar name.</li><li class="listitem" style="list-style-type: disc">The window name.</li><li class="listitem" style="list-style-type: disc">An integer pointer to be used as a value; this parameter is optional. If the pointer value is set, the slider gets this position during its creation.</li><li class="listitem" style="list-style-type: disc">The maximal position on the slider.</li><li class="listitem" style="list-style-type: disc">The callback function when the position slider changes.</li><li class="listitem" style="list-style-type: disc">The user data to be sent to the callback. It can be used to send data to callbacks without using global variables:<div><pre class="programlisting">  // create a trackbark
  createTrackbar("Lena", "Lena", &amp;blurAmount, 30, onChange, &amp;lena);</pre></div></li></ul></div><p>After creating <a id="id131" class="indexterm"/>the slider, we add the mouse events that allow you to paint circles when the user pushes the left mouse button. OpenCV has the <code class="literal">setMouseCallback</code> function. This function has three parameters, which are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The window name where we get the mouse events</li><li class="listitem" style="list-style-type: disc">The <code class="literal">callback</code> function to be called when there are mouse interactions</li><li class="listitem" style="list-style-type: disc">User data refers to any data that will be sent to the callback function when it's fired. In our example, we'll send the entire <code class="literal">Lena</code> image:<div><pre class="programlisting">setMouseCallback("Lena", onMouse, &amp;lena);</pre></div></li></ul></div><p>To finalize the <code class="literal">main</code> function, we only need to initialize the image with the same parameter as the slider. To perform the initialization, we only need to call the <code class="literal">callback</code> function manually and wait for events before we close the windows:</p><div><pre class="programlisting">  // Call to onChange to init
  onChange(blurAmount, &amp;lena);
    
  // wait app for a key to exit
  waitKey(0);
  
  // Destroy the windows
  destroyWindow("Lena");</pre></div><p>The slider callback applies a basic blur filter to the image using the slider value as a blur quantity:</p><div><pre class="programlisting">// Trackbar call back function
static void onChange(int pos, void* userData)
{
  if(pos &lt;= 0)
    return;
  // Aux variable for result
  Mat imgBlur;

  // Get the pointer input image
  Mat* img= (Mat*)userInput;

  // Apply a blur filter
  blur(*img, imgBlur, Size(pos, pos));  

  // Show the result
  imshow("Lena", imgBlur);
}</pre></div><p>This function <a id="id132" class="indexterm"/>checks whether the slider value is 0 using the <code class="literal">pos</code> variable; in this case, we do not apply the filter because it generates a bad execution. We cannot apply a 0 pixels blur.</p><p>After checking the slider value, we create an empty matrix called <code class="literal">imgBlur</code> to store the blur result.</p><p>To retrieve the image sent via the user data in the <code class="literal">callback</code> function, we have to cast the <code class="literal">void* userData</code> to correct the <code class="literal">pointer Mat*</code> image type.</p><p>Now, we have the correct variables to be applied to the blur filter. The blur function applies a basic median filter to an input image, <code class="literal">*img</code> in our case, to an output image. The last parameter is the size of a blur kernel (a kernel is a small matrix used to calculate the means of convolution between the kernel and image) that we want to apply. In our case, we are using a squared kernel of the <code class="literal">pos</code> size.</p><p>Finally, we only need to update the image interface using the <code class="literal">imshow</code> function.</p><p>The mouse events callback has five input parameters: the first parameter defines the event type, the second and third parameters define the mouse position, the fourth parameter defines the wheel movement, and the fifth parameter defines the user input data.</p><p>The mouse event types are shown in the following table:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Event type</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_MOUSEMOVE</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user moves the mouse</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_LBUTTONDOWN</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user pushes the left mouse button</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_RBUTTONDOWN</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user pushes the right mouse button</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_MBUTTONDOWN</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user pushes the middle mouse button</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_LBUTTONUP</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user releases the left mouse button</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_RBUTTONUP</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user releases the right mouse button</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_MBUTTONUP</code> </p>
</td><td style="text-align: left" valign="top">
<p>When the user releases the middle mouse button</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_LBUTTONDBLCLK</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user double-clicks with the left mouse button</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_RBUTTONDBLCLK</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user double-clicks with the right mouse button</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_MBUTTONDBLCLK</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user double-clicks with the middle mouse button</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENTMOUSEWHEEL</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user does a vertical scroll with the mouse wheel</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">EVENT_MOUSEHWHEEL</code>
</p>
</td><td style="text-align: left" valign="top">
<p>When the user does a horizontal scroll with the mouse wheel</p>
</td></tr></tbody></table></div><p>In our sample, we only go to manage events that come from a left-push mouse button, and then any other<a id="id133" class="indexterm"/> event different from <code class="literal">EVENT_LBUTTONDOWN</code> is discarded. After discarding other events, we get the input image, such as a slider callback, and draw a circle in the image with the circle OpenCV function:</p><div><pre class="programlisting">//Mouse callback
static void onMouse( int event, int x, int y, int, void* userInput )
{
  if( event != EVENT_LBUTTONDOWN )
          return;

  // Get the pointer input image
  Mat* img= (Mat*)userInput;
  
  // Draw circle
  circle(*img, Point(x, y), 10, Scalar(0,255,0), 3);

  // Call on change to get blurred image
  onChange(blurAmount, img);

}</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec28"/>Adding buttons to a user interface</h1></div></div></div><p>In the <a id="id134" class="indexterm"/>previous chapter, we learned how to create normal or QT interfaces and interact with them with a mouse and slider, but we can create different types of buttons as well.</p><div><div><h3 class="title"><a id="note17"/>Note</h3><p>Buttons are only supported in QT Windows.</p></div></div><p>The types of buttons supported are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <code class="literal">push</code> button</li><li class="listitem" style="list-style-type: disc">The <code class="literal">checkbox</code></li><li class="listitem" style="list-style-type: disc">The <code class="literal">radiobox</code></li></ul></div><p>The buttons <a id="id135" class="indexterm"/>only appear in the control panel. The control panel is an independent window per program, where we can attach buttons and track bars.</p><p>To show the control panel, we can push the last toolbar button, right-click on any part of the QT window, and select the <strong>Display properties</strong> window or the <em>Ctrl</em> + <em>P</em> shortcut.</p><p>Let's see how to create a basic sample with buttons. The code is large, and we will first explain the main function and later explain each callback separately to understand each one of them:</p><div><pre class="programlisting">Mat img;
bool applyGray=false;
bool applyBlur=false;
bool applySobel=false;
…
int main( int argc, const char** argv )
{
  // Read images
  img= imread("../lena.jpg");
  
  // Create windows
  namedWindow("Lena");
  
  // create Buttons
  createButton("Blur", blurCallback, NULL, QT_CHECKBOX, 0);

  createButton("Gray",grayCallback,NULL,QT_RADIOBOX, 0);
  createButton("RGB",bgrCallback,NULL,QT_RADIOBOX, 1);

  createButton("Sobel",sobelCallback,NULL,QT_PUSH_BUTTON, 0);
  
  // wait app for a key to exit
  waitKey(0);
  
  // Destroy the windows
  destroyWindow("Lena");
  
  return 0;
}</pre></div><p>We are going <a id="id136" class="indexterm"/>to apply three types of blur fiters, a sobel fiter, and a color conversion to gray. All these filters are optional and the user can choose each one of them using the buttons that we are going to create. Then, in order to get the status of each filter, we create three global Boolean variables:</p><div><pre class="programlisting">bool applyGray=false;
bool applyBlur=false;
bool applySobel=false;</pre></div><p>In the main function after we load the image and create the window, we have to use the <code class="literal">createButton</code> function to create each button.</p><p>There are three button types defined in OpenCV, which are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">QT_CHECKBOX</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">QT_RADIOBOX</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">QT_PUSH_BUTTON</code></li></ul></div><p>Each button has five parameters with the following order:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The button name</li><li class="listitem" style="list-style-type: disc">The callback function</li><li class="listitem" style="list-style-type: disc">A pointer to user variable data passed to callback</li><li class="listitem" style="list-style-type: disc">The button type</li><li class="listitem" style="list-style-type: disc">The default initialized state used for the <code class="literal">checkbox</code> and <code class="literal">radiobox</code> button types</li><li class="listitem" style="list-style-type: disc">Then, we create a blur checkbox button, two radio buttons for color conversion, and a push button for the Sobel filter:<div><pre class="programlisting">  // create Buttons
  createButton("Blur", blurCallback, NULL, QT_CHECKBOX, 0);

  createButton("Gray",grayCallback,NULL,QT_RADIOBOX, 0);
  createButton("RGB",bgrCallback,NULL,QT_RADIOBOX, 1);

  createButton("Sobel",sobelCallback,NULL,QT_PUSH_BUTTON, 0);</pre></div></li><li class="listitem" style="list-style-type: disc">This is the most important part of the main function. We are going to explore the callback <a id="id137" class="indexterm"/>functions. Each callback changes its status variable to call another function called <code class="literal">applyFilters</code> and adds the filters activated by the input image:<div><pre class="programlisting">void grayCallback(int state, void* userData)
{
  applyGray= true;
  applyFilters();
}
void bgrCallback(int state, void* userData)
{
  applyGray= false;
  applyFilters();
}

void blurCallback(int state, void* userData)
{
  applyBlur= (bool)state;
  applyFilters();
}

void sobelCallback(int state, void* userData)
{
  applySobel= !applySobel;
  applyFilters();
}</pre></div></li><li class="listitem" style="list-style-type: disc">The <code class="literal">applyFilters</code> function checks the status variable for each filter:<div><pre class="programlisting">void applyFilters(){
  Mat result;
  img.copyTo(result);
  if(applyGray){
    cvtColor(result, result, COLOR_BGR2GRAY);
  }
  if(applyBlur){
    blur(result, result, Size(5,5));  
  }
  if(applySobel){
    Sobel(result, result, CV_8U, 1, 1);  
  }
  imshow("Lena", result);
}</pre></div></li></ul></div><p>To change the color to gray, we use the <code class="literal">cvtColor</code> function that accepts three parameters: an input image, an <a id="id138" class="indexterm"/>output image, and the color conversion type.</p><p>The most useful color spaces conversions are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">RGB or BGR to gray (<code class="literal">COLOR_RGB2GRAY, COLOR_BGR2GRAY</code>)</li><li class="listitem" style="list-style-type: disc">RGB or BGR to YcrCb (or YCC) (<code class="literal">COLOR_RGB2YCrCb, COLOR_BGR2YCrCb</code>)</li><li class="listitem" style="list-style-type: disc">RGB or BGR to HSV (<code class="literal">COLOR_RGB2HSV, COLOR_BGR2HSV</code>)</li><li class="listitem" style="list-style-type: disc">RGB or BGR to Luv (<code class="literal">COLOR_RGB2Luv, COLOR_BGR2Luv</code>)</li><li class="listitem" style="list-style-type: disc">Gray to RGB or BGR (<code class="literal">COLOR_GRAY2RGB, COLOR_GRAY2BGR</code>)</li></ul></div><p>We can see that the code is easy to memorize.</p><div><div><h3 class="title"><a id="note18"/>Note</h3><p>Remember that OpenCV works, by default, with the BGR format, and the color conversion is different for RGB and BGR, when converting to gray. Some developers think that gray equals <em>R+G+B/3</em>, but the optimal gray value is called <strong>luminosity</strong> and has the formula <em>0.21*R + 0.72*G + 0.07*B</em>.</p></div></div><p>The blur filter was described in the previous section. Finally, if the <code class="literal">applySobel</code> variable is <code class="literal">true</code>, we apply the sobel filter.</p><p>The sobel filter is an image derivatives that uses the sobel operator, commonly used to detect edges. OpenCV allow us to generate different derivatives with different kernel sizes, but the most common is a 3x3 kernel used to calculate the <code class="literal">x</code> derivatives or <code class="literal">y</code> derivatives.</p><p>The most important sobel parameters are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">An input image</li><li class="listitem" style="list-style-type: disc">An output image</li><li class="listitem" style="list-style-type: disc">An output image depth (<code class="literal">CV_8U</code>, <code class="literal">CV_16U</code>, <code class="literal">CV_32F</code>, <code class="literal">CV_64F</code>)</li><li class="listitem" style="list-style-type: disc">The order of the derivatives x</li><li class="listitem" style="list-style-type: disc">The order of the derivatives y</li><li class="listitem" style="list-style-type: disc">The kernel size (3 value by default)</li><li class="listitem" style="list-style-type: disc">To generate a 3x3 kernel and first <code class="literal">x</code> order derivatives, we have to use the following parameters:<div><pre class="programlisting">Sobel(input, output, CV_8U, 1, 0);</pre></div></li><li class="listitem" style="list-style-type: disc">To generate the <code class="literal">y</code> order derivatives, we use the following parameters:<div><pre class="programlisting">Sobel(input, output, CV_8U, 0, 1);</pre></div></li></ul></div><p>In our example, we <a id="id139" class="indexterm"/>use the <code class="literal">x</code> and <code class="literal">y</code> derivatives simultaneously to overwrite the input:</p><div><pre class="programlisting">Sobel(result, result, CV_8U, 1, 1);</pre></div><p>The output of the <code class="literal">x</code> and <code class="literal">y</code> derivatives is as shown:</p><div><img src="img/B04283_03_09.jpg" alt="Adding buttons to a user interface"/></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec29"/>OpenGL support</h1></div></div></div><p>OpenCV includes <a id="id140" class="indexterm"/>OpenGL support. OpenGL is a graphical library that is integrated in graphic cards as a standard. OpenGL allow us to draw from 2D to complex 3D scenes.</p><p>OpenCV includes OpenGL support due to the importance of representing 3D spaces in some tasks. To allow a window support in OpenGL, we have to set up the <code class="literal">WINDOW_OPENGL</code> flag when we create the window with the <code class="literal">namedWindow</code> call.</p><p>The following code creates a window with OpenGL support and draws a rotated plane that shows the web camera frames:</p><div><pre class="programlisting">Mat frame;
GLfloat angle= 0.0;
GLuint texture; 
VideoCapture camera;

int loadTexture() {

    if (frame.data==NULL) return -1;
glGenTextures(1, &amp;texture);
   glBindTexture( GL_TEXTURE_2D, texture ); 
   glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MAG_FILTER,GL_LINEAR);
   glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MIN_FILTER,GL_LINEAR);
   glPixelStorei(GL_UNPACK_ALIGNMENT, 1);

   glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, frame.cols, frame.rows,0, GL_BGR, GL_UNSIGNED_BYTE, frame.data);
   return 0;

}

void on_opengl(void* param)
{
    glLoadIdentity();  
    // Load frame Texture
    glBindTexture( GL_TEXTURE_2D, texture ); 
    // Rotate plane before draw
    glRotatef( angle, 1.0f, 1.0f, 1.0f );
    // Create the plane and set the texture coordinates
    glBegin (GL_QUADS);
        // first point and coordinate texture
     glTexCoord2d(0.0,0.0); 
     glVertex2d(-1.0,-1.0); 
        // seccond point and coordinate texture
     glTexCoord2d(1.0,0.0); 
     glVertex2d(+1.0,-1.0); 
        // third point and coordinate texture
     glTexCoord2d(1.0,1.0); 
     glVertex2d(+1.0,+1.0);
        // last point and coordinate texture
     glTexCoord2d(0.0,1.0); 
     glVertex2d(-1.0,+1.0);
    glEnd();

}

int main( int argc, const char** argv )
{
    // Open WebCam
    camera.open(0);
    if(!camera.isOpened())
        return -1;

    // Create new windows
    namedWindow("OpenGL Camera", WINDOW_OPENGL);
    
    // Enable texture
    glEnable( GL_TEXTURE_2D );  

    setOpenGlDrawCallback("OpenGL Camera", on_opengl);

    while(waitKey(30)!='q'){
        camera &gt;&gt; frame;
        // Create first texture
        loadTexture();
        updateWindow("OpenGL Camera");
        angle =angle+4;
    }
    
  
  // Destroy the windows
  destroyWindow("OpenGL Camera");
  
  return 0;
}</pre></div><p>Let's understand the code.</p><p>The first task <a id="id141" class="indexterm"/>is to create the required global variables where we store the video capture, save the frames, control the animation angle plane, and the OpenGL texture:</p><div><pre class="programlisting">Mat frame;
GLfloat angle= 0.0;
GLuint texture; 
VideoCapture camera;</pre></div><p>In our main function, we have to create the video camera capture to retrieve the camera frames:</p><div><pre class="programlisting">camera.open(0);
    if(!camera.isOpened())
        return -1;</pre></div><p>If the camera is opened correctly, then we have to create our window with OpenGL support using the <code class="literal">WINDOW_OPENGL</code> flag:</p><div><pre class="programlisting">// Create new windows
namedWindow("OpenGL Camera", WINDOW_OPENGL);</pre></div><p>In our example, we want to draw the images in a plane that come from the web camera, and then we need to enable the OpenGL textures:</p><div><pre class="programlisting">// Enable texture
glEnable( GL_TEXTURE_2D );</pre></div><p>Now, we are ready to draw with OpenGL in our window, but we need set up a draw OpenGL callback such as a typical OpenGL application. OpenCV give us the <code class="literal">setOpenGLDrawCallback</code> function that has two parameters: the window name and the callback function:</p><div><pre class="programlisting">setOpenGlDrawCallback("OpenGL Camera", on_opengl);</pre></div><p>With the OpenCV window and callback function defined, we need to create a loop to load the texture and update the window content by calling the OpenGL draw callback; finally, we need to update the angle position.</p><p>To update the window content, we use the OpenCV function update window with the window name as the parameter:</p><div><pre class="programlisting">while(waitKey(30)!='q'){
        camera &gt;&gt; frame;
        // Create first texture
        loadTexture();
        updateWindow("OpenGL Camera");
        angle =angle+4;
    }</pre></div><p>We are in the <a id="id142" class="indexterm"/>loop while the user press the <em>q</em> key.</p><p>Before we compile our application sample, we need to define the <code class="literal">loadTexture</code> function and our <code class="literal">on_opengl</code> callback draw function.</p><p>The <code class="literal">loadTexture</code> function converts our <code class="literal">Mat</code> frame to an OpenGL texture image that is ready to be loaded and used in each callback drawing. Before we load the image as a texture, we need to ensure that we have data in our frame matrix to check whether the data variable object is not empty:</p><div><pre class="programlisting">if (frame.data==NULL) return -1;</pre></div><p>If we have data in our matrix frame, then we can create the OpenGL texture binding and set the OpenGL texture parameters as a linear interpolation:</p><div><pre class="programlisting">glGenTextures(1, &amp;texture);

glBindTexture( GL_TEXTURE_2D, texture );
    glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MAG_FILTER,GL_LINEAR);
    glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MIN_FILTER,GL_LINEAR);</pre></div><p>Now, we need to define how the pixels are stored in our matrix and how to generate the pixels with the OpenGL's <code class="literal">glTexImage2D</code> function. It's very important to note that OpenGL uses the RGB format and OpenCV has the BGR format by default, and we need to set it up correctly in this function:</p><div><pre class="programlisting">glPixelStorei(GL_UNPACK_ALIGNMENT, 1);
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, frame.cols, frame.rows,0, GL_BGR, GL_UNSIGNED_BYTE, frame.data);
    return 0;</pre></div><p>Now, we only need to finish drawing our plane for every callback when we call the <code class="literal">updateWindow</code> in the main loop. We use the common OpenGL functions, and then we load the identity OpenGL matrix to reset all our previous changes:</p><div><pre class="programlisting">glLoadIdentity();</pre></div><p>Load the frame texture into the memory:</p><div><pre class="programlisting">    // Load Texture
    glBindTexture( GL_TEXTURE_2D, texture ); </pre></div><p>Before we draw our plane, we apply all the transformations to our scene; in our case, we are going to rotate our plane in the (1, 1, 1) axis:</p><div><pre class="programlisting">    // Rotate plane
    glRotatef( angle, 1.0f, 1.0f, 1.0f );</pre></div><p>Now, we have <a id="id143" class="indexterm"/>the scene set correctly to draw our plane, so we will draw quads faces and use <code class="literal">glBegin(GL_QUADS)</code>for this purpose:</p><div><pre class="programlisting">// Create the plane and set the texture coordinates
    glBegin (GL_QUADS);</pre></div><p>We draw a plane centered at the (0, 0) position with a two units of size. Then, we have to define the texture coordinate to be used and the vertex position using the <code class="literal">glTextCoord2D</code> and <code class="literal">glVertex2D</code> functions:</p><div><pre class="programlisting">    // first point and coordinate texture
 glTexCoord2d(0.0,0.0); 
 glVertex2d(-1.0,-1.0); 
    // seccond point and coordinate texture
 glTexCoord2d(1.0,0.0); 
 glVertex2d(+1.0,-1.0); 
    // third point and coordinate texture
 glTexCoord2d(1.0,1.0); 
 glVertex2d(+1.0,+1.0);
    // last point and coordinate texture
 glTexCoord2d(0.0,1.0); 
 glVertex2d(-1.0,+1.0);
    glEnd();</pre></div><div><div><h3 class="title"><a id="note19"/>Note</h3><p>This OpenGL code is becoming obsolete, but it is important to better understand the OpenCV and OpenGL integration without the complex OpenGL code. To introduce you to modern OpenGL, read <em>Introduction to Modern OpenGL</em>, <em>Pack Publishing</em>.</p></div></div><p>We can see the result in the following image:</p><div><img src="img/B04283_03_10.jpg" alt="OpenGL support"/></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec30"/>Summary</h1></div></div></div><p>In this chapter, we learned how to create different types of user interface to show images or 3D interfaces using OpenGL. We learned how to create sliders and buttons and draw in 3D. We learned some basic image processing filters as well.</p><p>In the next chapter, we will learn how to construct a complete photo tool application using all that we learned using the graphical user interface. We will also learn how to apply multiple filters to an input image.</p></div></body></html>