["```py\nface_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n```", "```py\nfaces = face_cascade.detectMultiScale(gray)\n```", "```py\nimport numpy as np\nimport cv2\n\n# create cascaded classifier with pre-learned weights\n# For other objects, change the file here\nface_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n\ncap = cv2.VideoCapture(0)\n\nwhile(True):\n ret, frame = cap.read()\n if not ret:\n print(\"No frame captured\")\n\n # frame = cv2.resize(frame, (640, 480))\n gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n # detect face\n faces = face_cascade.detectMultiScale(gray)\n\n # plot results\n for (x,y,w,h) in faces:\n cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n\n cv2.imshow('img',frame)\n if cv2.waitKey(1) & 0xFF == ord('q'):\n break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\ngit clone https://github.com/tensorflow/models.git\ncd models/research\n```", "```py\ncurl -O http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2017_11_08.tar.gz\ntar -xvf faster_rcnn_resnet101_coco_2017_11_08.tar.gz\n```", "```py\nwget http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2017_11_08.gz\ntar -xvf faster_rcnn_resnet101_coco_2017_11_08.tar.gz\n```", "```py\nprotoc object_detection/protos/*.proto --python_out=.\n```", "```py\nexport PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim \n```", "```py\nimport numpy as np\nimport os\nimport sys\nimport tensorflow as tf\nimport cv2\nfrom matplotlib import pyplot as plt\n# inside jupyter uncomment next line \n# %matplotlib inline\nimport random\nimport time\nfrom utils import label_map_util \n```", "```py\n# load graph \ndef load_and_create_graph(path_to_pb):\n    \"\"\"\n    Loads pre-trained graph from .pb file. \n    path_to_pb: path to saved .pb file\n    Tensorflow keeps graph global so nothing is returned\n    \"\"\"\n    with tf.gfile.FastGFile(path_to_pb, 'rb') as f:\n        # initialize graph definition\n        graph_def = tf.GraphDef()\n        # reads file \n        graph_def.ParseFromString(f.read())\n        # imports as tf.graph\n        _ = tf.import_graph_def(graph_def, name='')\n```", "```py\nload_and_create_graph('faster_rcnn_resnet101_coco_2017_11_08/frozen_inference_graph.pb')\n```", "```py\n# load labels for classes output\npath_to_labels = os.path.join('data', 'mscoco_label_map.pbtxt')\n# pre-training was done on 90 categories\nnb_classes = 90\nlabel_map = label_map_util.load_labelmap(path_to_labels)\ncategories = label_map_util.convert_label_map_to_categories(label_map,\n                   max_num_classes=nb_classes, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)\n```", "```py\ndef read_cv_image(filename):\n    \"\"\"\n    Reads an input color image and converts to RGB order\n    Returns image as an array\n    \"\"\"\n    img = cv2.imread(filename)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n```", "```py\n\ndef show_mpl_img_with_detections(img, dets, scores, \n                                 classes, category_index, \n                                 thres=0.6):\n    \"\"\"\n    Applies thresholding to each box score and \n    plot bbox results on image. \n    img: input image as numpy array\n    dets: list of K detection outputs for given image.(size:[1,K])\n    scores: list of detection score for each detection output(size: [1,K]).\n    classes: list of predicted class index(size: [1,K]) \n    category_index: dictionary containing mapping from class index to class name. \n    thres: threshold to filter detection boxes:(default: 0.6)\n    By default K:100 detections\n    \"\"\"\n    # plotting utilities from matplotlib\n    plt.figure(figsize=(12,8))\n    plt.imshow(img)\n    height = img.shape[0]\n    width = img.shape[1]\n    # To use common color of one class and different for different classes\n    colors = dict() \n    # iterate over all proposed bbox \n    # choose whichever is more than a threshold\n    for i in range(dets.shape[0]):\n        cls_id = int(classes[i])\n        # in case of any wrong prediction for class index\n        if cls_id >= 0:\n\n            score = scores[i]\n            # score for a detection is more than a threshold\n            if score > thres:\n                if cls_id not in colors:\n                    colors[cls_id] = (random.random(), \n                                      random.random(), \n                                      random.random())\n                xmin = int(dets[i, 1] * width)\n                ymin = int(dets[i, 0] * height)\n                xmax = int(dets[i, 3] * width)\n                ymax = int(dets[i, 2] * height)\n                rect = plt.Rectangle((xmin, ymin), xmax - xmin,\n                                     ymax - ymin, fill=False,\n                                     edgecolor=colors[cls_id],\n                                     linewidth=2.5)\n                plt.gca().add_patch(rect)\n                # to plot class name and score around each detection box\n                class_name = str(category_index[cls_id]['name'])\n\n                plt.gca().text(xmin, ymin - 2,\n                           '{:s} {:.3f}'.format(class_name, score),\n                           bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n                           fontsize=8, color='white')\n    plt.axis('off')\n    plt.show()\n\n    return\n```", "```py\nimage_dir = 'test_images/'\n# create graph object from previously loaded graph\n# tensorflow previously loaded graph as default \ngraph=tf.get_default_graph()\n\n# launch a session to run this graph \nwith tf.Session(graph=graph) as sess:\n    # get input node\n    image_tensor = graph.get_tensor_by_name('image_tensor:0')\n\n    # get output nodes\n    detection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n    detection_scores = graph.get_tensor_by_name('detection_scores:0')\n    detection_classes = graph.get_tensor_by_name('detection_classes:0')\n    num_detections = graph.get_tensor_by_name('num_detections:0')\n\n    # read image from file and pre-process it for input.\n    # Note: we can do this outside session scope too. \n    image = read_cv_image(os.path.join(image_dir, 'cars2.png'))\n    input_img = image[np.newaxis, :, :, :]\n\n    # To compute prediction time \n    start = time.time()\n    # Run prediction and get 4 outputs\n    (boxes, scores, classes, num) = sess.run(\n          [detection_boxes, detection_scores, detection_classes, num_detections],\n          feed_dict={image_tensor: input_img})\n    end = time.time()\n    print(\"Prediction time:\",end-start,\"secs for \", num[0], \"detections\")\n    # display results\n    show_mpl_img_with_detections(image, boxes[0],scores[0], classes[0],category_index, thres=0.6)\n\n```", "```py\ngit clone https://github.com/tensorflow/models.git\ncd models/research\n```", "```py\ncurl -O http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz\ntar -xvf ssd_inception_v2_coco_2017_11_17.tar.gz\n```", "```py\nwget http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz\ntar -xvf ssd_inception_v2_coco_2017_11_17.tar.gz\n```", "```py\nprotoc object_detection/protos/*.proto --python_out=.\n```", "```py\nexport PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim \n```", "```py\nimport numpy as np\nimport os\nimport sys\nimport tensorflow as tf\nimport cv2\nfrom matplotlib import pyplot as plt\n# inside jupyter uncomment next line \n# %matplotlib inline\nimport random\nimport time\nfrom utils import label_map_util \n```", "```py\ndef load_and_create_graph(path_to_pb):\n \"\"\"\n Loads pre-trained graph from .pb file. \n path_to_pb: path to saved .pb file\n Tensorflow keeps graph global so nothing is returned\n \"\"\"\n with tf.gfile.FastGFile(path_to_pb, 'rb') as f:\n # initialize graph definition\n graph_def = tf.GraphDef()\n # reads file \n graph_def.ParseFromString(f.read())\n # imports as tf.graph\n _ = tf.import_graph_def(graph_def, name='')\n```", "```py\ndef read_cv_image(filename):\n \"\"\"\n Reads an input color image and converts to RGB order\n Returns image as an array\n \"\"\"\n img = cv2.imread(filename)\n img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n return img\n```", "```py\ndef show_mpl_img_with_detections(img, dets, scores, \n classes, category_index, \n thres=0.6):\n \"\"\"\n Applies thresholding to each box score and \n plot bbox results on image. \n img: input image as numpy array\n dets: list of K detection outputs for given image. (size:[1,K] )\n scores: list of detection score for each detection output(size: [1,K]).\n classes: list of predicted class index(size: [1,K]) \n category_index: dictionary containing mapping from class index to class name. \n thres: threshold to filter detection boxes:(default: 0.6)\n By default K:100 detections\n \"\"\"\n # plotting utilities from matplotlib\n plt.figure(figsize=(12,8))\n plt.imshow(img)\n height = img.shape[0]\n width = img.shape[1]\n # To use common color of one class and different for different classes\n colors = dict() \n # iterate over all proposed bbox \n # choose whichever is more than a threshold\n for i in range(dets.shape[0]):\n cls_id = int(classes[i])\n # in case of any wrong prediction for class index\n if cls_id >= 0:\n\n score = scores[i]\n # score for a detection is more than a threshold\n if score > thres:\n if cls_id not in colors:\n colors[cls_id] = (random.random(), \n random.random(), \n random.random())\n xmin = int(dets[i, 1] * width)\n ymin = int(dets[i, 0] * height)\n xmax = int(dets[i, 3] * width)\n ymax = int(dets[i, 2] * height)\n rect = plt.Rectangle((xmin, ymin), xmax - xmin,\n ymax - ymin, fill=False,\n edgecolor=colors[cls_id],\n linewidth=2.5)\n plt.gca().add_patch(rect)\n # to plot class name and score around each detection box\n class_name = str(category_index[cls_id]['name'])\n\n plt.gca().text(xmin, ymin - 2,\n '{:s} {:.3f}'.format(class_name, score),\n bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n fontsize=8, color='white')\n plt.axis('off')\n plt.show()\n\n return \n```", "```py\n# load pre-trained model\nload_and_create_graph('ssd_inception_v2_coco_2017_11_17/frozen_inference_graph.pb')\n```", "```py\n# load labels for classes output\npath_to_labels = os.path.join('data', 'mscoco_label_map.pbtxt')\nnb_classes = 90\nlabel_map = label_map_util.load_labelmap(path_to_labels)\ncategories = label_map_util.convert_label_map_to_categories(label_map,\n max_num_classes=nb_classes, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)\n```", "```py\nimage_dir = 'test_images/'\n# create graph object from previously loaded graph\n# tensorflow previously loaded graph as default \ngraph=tf.get_default_graph()\n\n# launch a session to run this graph \nwith tf.Session(graph=graph) as sess:\n # get input node\n image_tensor = graph.get_tensor_by_name('image_tensor:0')\n\n # get output nodes\n detection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n detection_scores = graph.get_tensor_by_name('detection_scores:0')\n detection_classes = graph.get_tensor_by_name('detection_classes:0')\n num_detections = graph.get_tensor_by_name('num_detections:0')\n\n # read image from file and pre-process it for input.\n # Note: we can do this outside session scope too. \n image = read_cv_image(os.path.join(image_dir, 'person1.png'))\n # Input Shape : [N, Width,Height,Channels], \n # where N=1, batch size\n input_img = image[np.newaxis, :, :, :] \n\n # To compute prediction time \n start = time.time()\n # Run prediction and get 4 outputs\n (boxes, scores, classes, num) = sess.run(\n [detection_boxes, detection_scores, detection_classes, num_detections],\n feed_dict={image_tensor: input_img})\n end = time.time()\n print(\"Prediction time:\",end-start,\"secs for \", num, \"detections\")\n\n # display results with score threshold of 0.6\n # Since only one image is used , hence we use 0 index for outputs\n show_mpl_img_with_detections(image, boxes[0],scores[0], classes[0], thres=0.6)\n```", "```py\nfor i in range(nb_inputs):\n show_mpl_img_with_detections(images[i], boxes[i],scores[i], classes[i], thres=0.6)\n```"]