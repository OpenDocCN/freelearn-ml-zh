<html><head></head><body>
		<div class="Content" id="_idContainer046">
			<p class="hidden">2</p>
		</div>
		<div class="Content" id="_idContainer047">
			<h1 id="_idParaDest-36"><a id="_idTextAnchor037"/>Summarizing <br/>Text Documents Using NLP</h1>
		</div>
		<div class="Content" id="_idContainer048">
			<h2>Learning Objectives</h2>
			<p>By the end of this chapter, you will able to:</p>
			<ul>
				<li class="bullets">Use Amazon Comprehend to examine text, in order to determine its primary language</li>
				<li class="bullets">Extract information such as entities (people or places), key phrases (noun phrases that are indicative of the content), emotional sentiments, and topics in a set of documents</li>
				<li class="bullets">Set up a Lambda function to process and analyze the imported text using Comprehend</li>
			</ul>
			<p>This chapter describes the use of Amazon Comprehend to summarize the text documents and creating Lambda function to analyze the text.</p>
		</div>
		<div class="Content" id="_idContainer086">
			<h2 id="_idParaDest-37"><a id="_idTextAnchor038"/>Introduction</h2>
			<p>The Amazon Comprehend service continually learns from new data from Amazon.com product descriptions and consumer reviews, and thus, it perpetually improves its ability to understand a variety of topics from <em class="italics">Government</em>, <em class="italics">Health</em>, <em class="italics">Media</em>, <em class="italics">Education</em>, <em class="italics">Advertising</em>, and so on. Overall, Amazon Comprehend can analyze a collection of text documents and can organize the articles by topic, identify the most frequently mentioned features, and group articles by subject matter, to enable personalized recommendations to website visitors. </p>
			<p>In the first part of this chapter, you learned how to use Amazon Comprehend to extract insights through using <strong class="bold">Natural Language Processing (NLP)</strong> from the contents of documents. Now, you will learn how to use the Amazon Comprehend API to produce insights by recognizing the language, entities, key phrases, sentiments, and topics in a document. This will allow you to understand deep learning-based NLP to build more complex applications, which we will do on Day 2. </p>
			<p>In the second part of this chapter, you will learn about AWS Lambda, and how to integrate this service with Amazon Comprehend. You will also integrate a database to provide the foundation to build scalable NLP processing applications. </p>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor039"/>What is Natural Language Processing?</h2>
			<p>Amazon Comprehend is a Natural Language Processing (NLP) service. The overall goal of an NLP service is to make machines understand our spoken and written language. Virtual Assistants, such as Alexa or Siri, use NLP to produce insights from input data. The input data is structured by a language, which has a unique grammar, syntax, and vocabulary. Thus, processing text data requires identifying the language first, to apply subsequent rules to identify the document's information. NLP's general task is to capture this information as a numeral representation. The general task is further specified into specific tasks, such as identifying languages, entities, key phrases, emotional sentiments, and topics. </p>
			<p>Amazon Comprehend processes any text file in UTF-8 format. It uses a pre-trained model to examine a document or set of documents, in order to gather insights about the document set. Amazon continuously trains the model so that there is no need to provide training data. </p>
			<h2 id="_idParaDest-39"><a id="_idTextAnchor040"/>Using Amazon Comprehend to Inspect Text and Determine the Primary Language</h2>
			<p>Amazon Comprehend is used to gather insights from a variety of topics (Health, Media, Telecom, Education, Government, and so on) and languages in text data. Thus, the first step to analyze text data and utilize more complex features (such as topic, entity, and sentiment analysis) is to determine the dominant language. Determining the dominant language ensures the accuracy of more in-depth analysis.</p>
			<p>To examine the text in order to determine the primary language, there are two operations (<strong class="inline">DetectDominantLanguage</strong> and <strong class="inline">BatchDetectDominantLanguage</strong>).</p>
			<p><strong class="inline">DetectDominantLanguage</strong> accepts a <strong class="inline">UTF-8</strong> text string that is at least 20 characters in length and must contain fewer than 5,000 bytes of UTF-8 encoded characters. <strong class="inline">BatchDetectDominantLanguage</strong> accepts an array of strings as a list. The list can contain a maximum of 25 documents. Each document should have at least 20 characters, and must contain fewer than 5,000 bytes of UTF-8 encoded characters.</p>
			<p>The response includes what language was identified using a two-letter code. The following table shows the language codes for different countries: </p>
			<h4>Note</h4>
			<p class="callout">Check out <a href="">https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html</a> for an updated list of supported languages.</p>
			<div>
				<div class="IMG---Figure" id="_idContainer049">
					<img alt="Figure 2.1: Amazon Comprehend – supported languages&#13;&#10;" src="image/image0011.jpg"/>
				</div>
			</div>
			<h6>Figure 2.1: Amazon Comprehend supported languages</h6>
			<p>The reaction also includes a score that indicates the certainty level that Amazon Comprehend has that a specific language is the dominant language in the document (see the following screenshot). The language scores are independent of other scores, and so reaction does not provide the percentage of the document that is represented by a particular language:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer050">
					<img alt="Figure 2.2: Dominant language score confidence output&#13;&#10;" src="image/image002.jpg"/>
				</div>
			</div>
			<h6>Figure 2.2: Dominant language score confidence output</h6>
			<h3 id="_idParaDest-40"><a id="_idTextAnchor041"/>Exercise 5: Detecting the Dominant Language Using the Command-Line Interface in a text document</h3>
			<p>In this exercise, you will learn how to detect Comprehend's using <strong class="inline">detectDominantLanguage</strong> function. The following steps describe how to detect the dominant language:</p>
			<h4>Note</h4>
			<p class="callout">The source code is available via GitHub in the repository at: <a href="">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_a/detect_dominant_languages.py</a>.</p>
			<ol>
				<li>First, we must import the AWS SDK for Python (boto3) <a href="">http://boto3.readthedocs.io/en/latest/</a>: <p class="snippet">import boto3 	</p></li>
				<li>Then, import the JSON module to serialize the JSON <a href="">https://docs.python.org/3.6/library/json.html</a> :<p class="snippet">import json 	</p></li>
				<li>Replace &lt;<strong class="inline">input region</strong>&gt; with your unique region (for example, <strong class="inline">us-east-1</strong>). The following instantiates a new Comprehend client:<p class="snippet">comprehend = boto3.client(service_name='comprehend', region_name='&lt;input region&gt;')	</p></li>
				<li>Next, we assign English and Spanish strings to be analyzed by Comprehend:<p class="snippet">english_string = 'Machine Learning is fascinating.'</p><p class="snippet">spanish_string = 'El aprendizaje automático es fascinante.'</p></li>
				<li>Next, we print a string to indicate the respective variable that our script is about to execute: <p class="snippet">print('Calling DetectDominantLanguage')</p><p class="snippet">print('english_string result:')</p></li>
				<li>Lastly, call Comprehend's <strong class="inline">detect_dominant_language</strong> method with the <strong class="inline">engligh_string</strong> and <strong class="inline">spanish_string</strong> variables <a href="">https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html</a> . <strong class="inline">json.dumps()</strong> writes the JSON data to a Python string in the terminal:<p class="snippet">print(json.dumps(comprehend.detect_dominant_language(Text = english_string), sort_keys=True, indent=4))</p></li>
				<li>Save the changes to the file. Open a command prompt, if you haven't already, and activate your virtual environment.</li>
				<li>Navigate to the <strong class="inline">detect_dominant_languages.py</strong> location. Type <strong class="inline">python detect_dominant_languages.py</strong> in the command prompt. Executing this command will produce the following output (see the following screenshot):<p>As expected, the <strong class="inline">english_text</strong> string is identified as English (with the "<strong class="inline">en</strong>" language code) with a ~0.99 confidence score (see the following output).</p><p>Also as expected, the <strong class="inline">spanish_text</strong> string is identified Spanish (with the "<strong class="inline">es</strong>" language code) with a ~0.99 confidence score (see the following output):</p></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer051">
					<img alt="Figure 2.3: Detecting the dominant language output – English and Spanish&#13;&#10;" src="image/image0031.jpg"/>
				</div>
			</div>
			<h6>Figure 2.3: Detecting the dominant language output – English and Spanish</h6>
			<h3 id="_idParaDest-41"><a id="_idTextAnchor042"/>Exercise 6: Detecting the Dominant Language in Multiple Documents by Using the Command-Line Interface (CLI) </h3>
			<p>In this exercise, you will learn how to detect Comprehend's <strong class="inline">detectDominantLanguage</strong> operation for multiple documents. The following steps describe how to detect the dominant language:</p>
			<h4>Note</h4>
			<p class="callout">The source code is available via GitHub in the repository at: <a href="">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_a/batch_detect_dominant_languages.py</a>.</p>
			<ol>
				<li value="1">First, we import the AWS SDK for Python (boto3) <a href="">http://boto3.readthedocs.io/en/latest/</a>: <p class="snippet">import boto3 	</p></li>
				<li>Then, we import the JSON module to serialize the JSON <a href="">https://docs.python.org/3.6/library/json.html</a> :<p class="snippet">import json 	</p></li>
				<li>Replace &lt;<strong class="inline">input region</strong>&gt; with your unique region (for example, 'us-east-1'). The following instantiates a new Comprehend client:<p class="snippet">comprehend = boto3.client(service_name='comprehend', region_name='&lt;input region&gt;')	</p></li>
				<li>Next, assign a list of English and Spanish strings to be analyzed by Comprehend:<p><strong class="inline">english_string_list</strong> = ['Machine Learning is fascinating.', 'Studying Artificial Intelligence is my passion.']</p><p><strong class="inline">spanish_string_list</strong> = ['El aprendizaje automático es fascinante.', 'Estudiar Inteligencia Artificial es mi pasión.']</p></li>
				<li>Lastly, we call Comprehend's "<strong class="inline">batch_detect_dominant_language</strong>" method with the <strong class="inline">engligh_string_list</strong> and <strong class="inline">spanish_string_list</strong> variables <a href="">https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html</a>. Then, <strong class="inline">json.dumps()</strong> writes the JSON data to a Python string to the terminal:<p class="snippet">print(json.dumps(comprehend.batch_detect_dominant_language(Text = english_string_list), sort_keys=True, indent=4))</p></li>
			</ol>
			<p>The important concepts to remember are that Comprehend has the ability to detect different languages and can take text input as a single string or in batch format as <br/>a list of strings. </p>
			<p>In this chapter, we reviewed how Comprehend's <strong class="inline">DetectDominantLanguage</strong> method is structured, and how to pass in both strings and a list of strings. Next, we will extract entities, phrases, and sentiments from a set of documents.</p>
			<h2 id="_idParaDest-42"><a id="_idTextAnchor043"/>Extracting Information in a Set of Documents</h2>
			<p>At a business level, knowing if and why a customer is angry or happy when they text a Virtual assistant is extremely important, in order to retain the customer. At an NLP level, this requires more information to extract and a more complex algorithm. The additional information to extract, and quantify are <strong class="inline">entities</strong>, <strong class="inline">key phrases</strong>, <strong class="inline">emotional sentiment</strong>, and <strong class="inline">topics</strong>. </p>
			<h3 id="_idParaDest-43"><a id="_idTextAnchor044"/>Detecting Named Entities – AWS SDK for Python (boto3)</h3>
			<p>An entity is a textual reference to the unique name of a real-world object, such as people, places, commercial items, and precise references to measurements such as dates and quantities. For example, in the text "Martin lives at 27 Broadway St.", <strong class="bold">Martin</strong> might be detected as a <strong class="bold">PERSON</strong>, while <strong class="bold">27 Broadway St</strong> might be detected as a <strong class="bold">LOCATION</strong>.</p>
			<p>Entities also have a score to indicate the confidence level that the entity type was detected correctly. The following table shows a complete list of entity types and descriptions:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer052">
					<img alt="Figure 2.4: AWS Comprehend - entity types and descriptions&#13;&#10;" src="image/image004.jpg"/>
				</div>
			</div>
			<h6>Figure 2.4: AWS Comprehend entity types and descriptions</h6>
			<h3 id="_idParaDest-44"><a id="_idTextAnchor045"/>DetectEntites – Input and Output</h3>
			<p>DetectEntites takes a <strong class="inline">LanguageCode</strong> and string of text as an input, and then provides the following information about each entity within the input text: <strong class="inline">BeginOffset</strong>, <strong class="inline">EndOffset</strong>, <strong class="inline">Score</strong>, <strong class="inline">Text</strong>, and <strong class="inline">Type</strong>. The following table shows a complete list of AWS Comprehend DetectEntities, types, and descriptions:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer053">
					<img alt="Figure 2.5: AWS Comprehend - entity types and descriptions&#13;&#10;" src="image/image0051.jpg"/>
				</div>
			</div>
			<h6>Figure 2.5: AWS Comprehend entity types and descriptions</h6>
			<h3 id="_idParaDest-45"><a id="_idTextAnchor046"/>Exercise 7: Determining the Named Entities in a Document </h3>
			<p>In this exercise, we will determine the named entities in a document. For this, we will use Amazon Comprehend's <strong class="inline">DetectEntities</strong> operation. The following are the steps for detecting the Named Entities:</p>
			<h4>Note</h4>
			<p class="callout">The source code is available via GitHub in the repository at: <a href="">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_b/detect_entities.py</a>.</p>
			<ol>
				<li value="1">Navigate to the <strong class="inline">detect_entities.py</strong> location, replace &lt;<strong class="inline">input region</strong>&gt; with your specific region, and save the file.<p>Now, import the AWS SDK for python (boto3) <a href="">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a> by using the following command:</p><p class="snippet">import boto3</p></li>
				<li>Now, import the <strong class="inline">JSON</strong> module to serialize <strong class="inline">JSON</strong> from <a href="">https://docs.python.org/3.6/library/json.html</a> by using the following command: <p class="snippet">import json</p></li>
				<li>Now, instantiate a new Comprehend client:<p class="snippet">comprehend = boto3.client(service_name='comprehend', region_name='&lt;input region&gt;')</p></li>
				<li>Now, after instantiating a new Comprehend, provide <strong class="bold">English</strong> text to analyze <strong class="inline">english_string = "I study Machine Learning in Seattle on Thursday.":</strong><p class="snippet">print('Calling DetectEntities')</p></li>
				<li>Now, <strong class="inline">json.dumps()</strong> writes JSON data to a Python string: <p class="snippet">print(json.dumps(comprehend.detect_entities(Text = english_string, LanguageCode='en'), sort_keys=True, indent=4))</p><p class="snippet">print('End of DetectEntities\n')</p></li>
				<li>Run the code by executing the <strong class="inline">detect_entities.py</strong> command with <strong class="inline">python</strong>. The output of the preceding code is shown in the following screenshot:</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer054">
					<img alt="Figure 2.6: AWS Comprehend – DetectEntities output&#13;&#10;" src="image/image006.jpg"/>
				</div>
			</div>
			<h6>Figure 2.6: AWS Comprehend DetectEntities output</h6>
			<p>The confidence scores were both ~0.99, as the inputs were simple examples. As expected, <strong class="bold">Seattle</strong> was detected as a <strong class="bold">LOCATION</strong>, and <strong class="bold">Thursday</strong> was detected as the <strong class="bold">DATE</strong>:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer055">
					<img alt="Figure 2.7: AWS Comprehend - BeginOffset and EndOffset review&#13;&#10;" src="image/image0071.jpg"/>
				</div>
			</div>
			<h6>Figure 2.7: AWS Comprehend BeginOffset and EndOffset review</h6>
			<h3 id="_idParaDest-46"><a id="_idTextAnchor047"/>DetectEntities in a Set of Documents (Text Files)</h3>
			<p>We are now going to extract entities from a set of documents (text files). Navigate to the <a href="">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_b/detect_entities_from_documents.py</a> location, replace '&lt;<strong class="inline">input region</strong>&gt;' with your specific region, and save the file. Run the code by executing the command with <strong class="inline">python detect_key_phrases.py</strong>:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer056">
					<img alt="Figure 2.8: detectKeyPhrases output&#13;&#10;" src="image/image008.jpg"/>
				</div>
			</div>
			<h6>Figure 2.8: DetectKeyPhrases output</h6>
			<h3 id="_idParaDest-47"><a id="_idTextAnchor048"/>Detecting Key Phrases </h3>
			<p>A key phrase for AWS is analogous to a noun phrase, which represents an actual thing. In English when we put together different words that represent one concrete idea we call it a noun phrase. For example, "<strong class="bold">A fast machine</strong>" is a noun phrase because it consists of "<strong class="bold">A</strong>", the article, "<strong class="bold">fast</strong>", an adjective, and "<strong class="bold">machine</strong>" which is a noun. AWS looks for appropriate word combinations and gives scores that indicates the confidence that a string is actually a noun phrase. </p>
			<h3 id="_idParaDest-48"><a id="_idTextAnchor049"/>Exercise 8: Determining the Key Phrase Detection. </h3>
			<p>In this exercise, we will determine the key phrase detection. To do so we will use Amazon Comprehend's <strong class="inline">DetectKeyPhrase</strong> operation. The following are the steps for detecting the Named Entities:</p>
			<h4>Note</h4>
			<p class="callout">The source code is available via GitHub in the repository at: <a href="">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_b/detect_key_phrases.py</a>.</p>
			<ol>
				<li value="1">Navigate to the <strong class="inline">detect_key_phrases.py</strong> location, replace <strong class="inline">&lt;input region&gt;</strong> with your specific region, and save the file. Import the AWS SDK for python (boto3) <a href="">http://boto3.readthedocs.io/en/latest/</a> by using the following command:<p class="snippet">import boto3</p></li>
				<li>Now, import the JSON module to serialize the JSON from <a href="">https://docs.python.org/3.6/library/json.html</a> by using the following command:<p class="snippet">import json</p></li>
				<li>Now, instantiate a new Comprehend client by using the following code:<p class="snippet">comprehend = boto3.client(service_name='comprehend', region_name='&lt;input region&gt;')</p></li>
				<li>Now, provide <strong class="bold">English</strong> text to analyze, using the following code:<p class="snippet">english_string = 'I study Machine Learning in Seattle on Thursday.'</p><p class="snippet">print('Calling DetectKeyPhrases')</p><p class="snippet"># json.dumps() writes JSON data to a Python string</p><p class="snippet">print(json.dumps(comprehend.detect_entities(Text = english_string, LanguageCode='en'), sort_keys=True, indent=4))</p><p class="snippet">print('End of DetectKeyPhrases\n')</p></li>
				<li>Run the code by executing the command with <strong class="inline">python detect_key_phrases.py</strong>. You will see the following output:</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer057">
					<img alt="Figure 2.9: AWS Comprehend – DetectKeyPhrases output&#13;&#10;" src="image/image0081.jpg"/>
				</div>
			</div>
			<h6>Figure 2.9: AWS Comprehend DetectKeyPhrases output</h6>
			<h3 id="_idParaDest-49"><a id="_idTextAnchor050"/>Detecting Sentiments </h3>
			<p>Amazon Comprehend can be used to determine the sentiment of a document. You can determine whether the sentiment is positive, negative, neutral, or mixed. For example, you can use sentiment analysis to determine the sentiments of comments on a blog post, to determine whether your readers liked the post.</p>
			<h3 id="_idParaDest-50"><a id="_idTextAnchor051"/>Exercise 9: Detecting Sentiment Analysis</h3>
			<p>In this exercise, We will determine the sentiment analysis. To do so, we will use Amazon Comprehend's <strong class="inline">DetectSentiment</strong> operation. The following are the steps for detecting Sentiment Analysis:</p>
			<h4>Note</h4>
			<p class="callout">The source code is available via Github in the repository at: <a href="">https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_b/detect_sentiment.py</a>.</p>
			<ol>
				<li value="1">Navigate to the <strong class="inline">detect_sentiment.py</strong> location, replace '&lt;<strong class="inline">input region</strong>&gt;' with your specific region, and save the file. Import the <strong class="inline">AWS SDK</strong> for Python (boto3) from <a href="">http://boto3.readthedocs.io/en/latest/</a> by using the following command:<p class="snippet">import boto3</p></li>
				<li>Now, import the <strong class="inline">JSON</strong> module to serialize JSON from <a href="">https://docs.python.org/3.6/library/json.html</a> by using the following command:<p class="snippet">import json</p></li>
				<li>Now, instantiate a new comprehend client, using the following code:<p class="snippet">comprehend = boto3.client(service_name='comprehend', region_name='&lt;input region&gt;')</p></li>
				<li>Then, provide a text string to analyze, using the following code:<p class="snippet">english_string = 'Today is my birthday, I am so happy.'</p><p class="snippet">print('Calling DetectSentiment')</p><p class="snippet">json.dumps() writes JSON data to a Python string</p><p class="snippet">print('english_string results:')</p><p class="snippet">print(json.dumps(comprehend.detect_sentiment(Text = english_string,                                          LanguageCode='en'), </p><p class="snippet">sort_keys=True, </p><p class="snippet">	indent=4))</p><p class="snippet">print('End of DetectSentiment\n')</p><p>Run the code by executing the command with: <strong class="inline">python detect_seniment.py</strong>. The output is shown as follows:</p></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer058">
					<img alt="Figure 2.10: AWS Comprehend – DetectSentiment output&#13;&#10;" src="image/image0091.jpg"/>
				</div>
			</div>
			<h6>Figure 2.10: AWS Comprehend – DetectSentiment output</h6>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor052"/>Setting up a Lambda function and Analyzing Imported Text Using Comprehend </h2>
			<p>In this topic, we will be integrating AWS Lambda functions to Comprehend, which provides a more powerful, scalable infrastructure. You can use AWS Lambda to run your code in response to events, such as changes to data in an Amazon S3 Bucket.</p>
			<p>Executing code in response to events provides a real-world solution for developing scalable software architecture. Overall, this increases our data pipeline and provides the ability to handle more complex Big Data volumes and NLP operations.</p>
			<h3 id="_idParaDest-52"><a id="_idTextAnchor053"/>What is AWS Lambda?</h3>
			<p>AWS Lambda is a compute service that runs code without provisioning or managing servers. AWS Lambda executes the code only when needed, and scales automatically. AWS Lambda runs your code on high availability compute infrastructure, which performs the administration of the compute service. More specifically, AWS Lambda performs the following: server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring, and logging. </p>
			<p>Overall, the goal of a Lambda is to make short, simple, modular code segments that you can tie together into a larger processing infrastructure.</p>
			<h3 id="_idParaDest-53"><a id="_idTextAnchor054"/>What does AWS Lambda do?</h3>
			<p>Lambda allows users to run small segments of code (Java, Node, or Python) to complete a specific task. These specific tasks can be storing and then executing changes to your AWS setup, or responding to events in S3 (we will explore the latter later on in this topic). Before Lambda, you would typically need a separate EC2 server to run your entire code; however, Lambda allows small segments of the code to run without the need for EC2.</p>
			<h3 id="_idParaDest-54"><a id="_idTextAnchor055"/>Lambda Function Anatomy </h3>
			<p>AWS Lambda provides two options for implementing Python code. First, you can upload a complete Python code file. Second, you can use the Lambda function editor entirely in-line, which means that you can enter and modify the code directly, without having to upload any files to AWS. The code that you enter will be executed when the Lambda function is invoked. The second option will allow for easier testing, so we will use it. </p>
			<p>Let's examine the structure of the Lambda function:</p>
			<ul>
				<li>When you create a function (for example, <strong class="inline">s3_trigger</strong>), AWS creates a folder named the same, with a Python file named <strong class="inline">Lambda_function.py</strong> within the <strong class="bold">folder</strong>. This file contains a stub for the <strong class="inline">Lambda_handler</strong> function, which is the entry point of our Lambda function. The entry point takes two parameters as arguments:</li>
				<li>The event argument provides the value of the payload, which is sent to the function from the <strong class="inline">calling</strong> process. It typically takes the form of a Python <strong class="inline">dict</strong> type, although it could also be one of list, <strong class="inline">str</strong>, <strong class="inline">int</strong>, <strong class="inline">float</strong>, or <strong class="inline">NoneType</strong>.</li>
				<li>The context argument is of the type <strong class="keyword">LambdaContext</strong> and contains runtime information. You will be using this parameter for an exercise in a later section. The return value of the function can be any type that is JSON serializable. This value gets returned to the calling application, after serializing.</li>
			</ul>
			<p>We will incorporate Lambda, S3, and Amazon Comprehend, in order to automatically perform document analysis when a text document is uploaded to S3. The architecture of a Lambda function is as follows:</p>
			<div>
				<div class="IMG---Figure" id="_idContainer059">
					<img alt=" Figure 2.11: Architecture diagram&#13;&#10;" src="image/image010.jpg"/>
				</div>
			</div>
			<h6> Figure 2.11: Architecture diagram</h6>
			<h3 id="_idParaDest-55"><a id="_idTextAnchor056"/>Exercise 10: Setting up a Lambda function for S3</h3>
			<p>In this exercise, we will integrate the following AWS services: S3, Lambda, and Amazon Comprehend. For performing this exercise, the architecture should be recollected. Upload a file (<strong class="inline">test_s3trigger_configured.txt</strong>) to S3 and view the results from Comprehend's analysis. The following are the steps for setting up a Lambda function.</p>
			<p><strong class="bold">Creating the S3 Bucket</strong></p>
			<ol>
				<li value="1">First, navigate to the Amazon S3 service, <a href="">https://console.aws.amazon.com/s3/</a>, and click on <strong class="bold">Create bucket</strong>:<div class="IMG---Figure" id="_idContainer060"><img alt="Figure 2.12: S3 Bucket creation for the Lambda trigger&#13;&#10;" src="image/image0111.jpg"/></div><h6>Figure 2.12: S3 Bucket creation for the Lambda trigger</h6></li>
				<li>For the Bucket name, type <strong class="inline">aws-ml-s3-trigger</strong>, and then click<strong class="bold"> </strong>on <strong class="bold">Create</strong>:<div class="IMG---Figure" id="_idContainer061"><img alt="Figure 2.13: Creating an S3 Bucket&#13;&#10;" src="image/image012.jpg"/></div><h6>Figure 2.13: Creating an S3 Bucket</h6></li>
				<li>Your <strong class="inline">Bucket</strong> will be created, and you will be redirected to the <strong class="bold">Bucket list</strong>:<div class="IMG---Figure" id="_idContainer062"><img alt="Figure 2.14: S3 Bucket list screen&#13;&#10;" src="image/image0131.jpg"/></div><h6>Figure 2.14: S3 Bucket list screen</h6></li>
				<li>Next, navigate to <a href="">https://console.aws.amazon.com/Lambda/</a> and click on <strong class="bold">Create a function</strong>:<div class="IMG---Figure" id="_idContainer063"><img alt="Figure 2.15: AWS Lambda home screen.&#13;&#10;" src="image/image014.jpg"/></div><h6>Figure 2.15: AWS Lambda home screen.</h6></li>
				<li>Choose Author from scratch from the options. For Name, <strong class="inline">type s3_trigger</strong>:<div class="IMG---Figure" id="_idContainer064"><img alt="Figure 2.16: AWS Lambda – Creating a function with the “author from scratch” selection&#13;&#10;" src="image/image0151.jpg"/></div><h6>Figure 2.16: AWS Lambda – Creating a function with the "author from scratch" selection</h6></li>
				<li>For the runtime options, choose <strong class="inline">Python 3.6</strong> from the list:<div class="IMG---Figure" id="_idContainer065"><img alt="Figure 2.17: AWS Lambda – Python 3.6 selection&#13;&#10;" src="image/image016.jpg"/></div><h6>Figure 2.17: AWS Lambda – Python 3.6 selection</h6></li>
				<li>For the Role field, choose <strong class="bold">Create new role from template(s)</strong> from the drop-down menu, and enter the name <strong class="inline">s3TriggerRole</strong> in the Role name field. Then, click on the <strong class="bold">Create</strong> <strong class="bold">function</strong> button to create the <strong class="inline">Lambda function</strong> in AWS:<div class="IMG---Figure" id="_idContainer066"><img alt="Figure 2.18: AWS Lambda – Create function screen&#13;&#10;" src="image/image0171.jpg"/></div><h6>Figure 2.18: AWS Lambda – Create function screen</h6></li>
				<li>Then, click on the drop-down menu under <strong class="bold">Policy templates</strong>:<div class="IMG---Figure" id="_idContainer067"><img alt="Figure 2.19: Policy template selection dropdown&#13;&#10;" src="image/image018.jpg"/></div><h6>Figure 2.19: Policy template selection drop-down menu</h6></li>
				<li>Select <strong class="bold">Amazon S3</strong> object read-only permissions:<div class="IMG---Figure" id="_idContainer068"><img alt="Figure 2.20: Amazon S3 object read-only permissions selection&#13;&#10;" src="image/image0191.jpg"/></div><h6>Figure 2.20: Amazon S3 object read-only permissions selection</h6></li>
				<li>Then, click on the <strong class="bold">Create function</strong> button to create the <strong class="inline">Lambda function</strong>:<div class="IMG---Figure" id="_idContainer069"><img alt="Figure 2.21: Clicking on Create function&#13;&#10;" src="image/image020.jpg"/></div><h6>Figure 2.21: Clicking on Create function</h6><h4>Note</h4><p class="callout">If you receive a <strong class="inline">NoSuchEntity</strong> error, this is a temporary warning that occurs when Amazon creates the service role for the <strong class="inline">s3_trigger</strong>. AWS has a reference to the possible temporary issues under the Roles heading. This will not affect your ability to continue with the chapter. Refresh your screen, and in a few minutes the warning message should disappear.</p></li>
				<li>You will know that the issues have been resolved when the <strong class="bold">Amazon CloudWatch</strong><strong class="inline"> Logs</strong> service becomes available as a resource for the function's role:<div class="IMG---Figure" id="_idContainer070"><img alt="Figure 2.22: Amazon CloudWatch Logs&#13;&#10;" src="image/image0211.jpg"/></div><h6>Figure 2.22: Amazon CloudWatch Logs</h6></li>
				<li>You should see a configuration screen, as follows:<div class="IMG---Figure" id="_idContainer071"><img alt="Figure 2.23: AWS Lambda - Successful s3_trigger created verification screen&#13;&#10;" src="image/image022.jpg"/></div><h6>Figure 2.23: AWS Lambda successful s3_trigger verification screen</h6></li>
				<li>Now, let's add S3 as a trigger. Under <strong class="bold">Add triggers</strong>, scroll to S3:<div class="IMG---Figure" id="_idContainer072"><img alt="Figure 2.24: AWS Lambda – Adding S3 as a trigger selection screen&#13;&#10;" src="image/image0231.jpg"/></div><h6>Figure 2.24: AWS Lambda – Adding S3 as a trigger selection screen</h6></li>
				<li>Click <strong class="inline">S3,</strong> and it will auto-populate under the <strong class="inline">s3_trigger</strong>. After clicking <strong class="inline">S3</strong>, your screen will look as follows:</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer073">
					<img alt="Figure 2.25: Aws Lambda – S3 trigger selection, configuration required&#13;&#10;" src="image/image024.jpg"/>
				</div>
			</div>
			<h6>Figure 2.25: AWS Lambda – S3 trigger selection, configuration required</h6>
			<h3 id="_idParaDest-56"><a id="_idTextAnchor057"/>Exercise 11: Configuring the Trigger for an S3 Bucket</h3>
			<p>In this exercise, we will configure the trigger for the <strong class="inline">Bucket</strong> created in the preceding exercise. To configure the trigger, follow these steps:</p>
			<ol>
				<li value="1">Scroll down the screen to the configure triggers section from <strong class="bold">Bucket</strong> and choose the Bucket that you created, that is, <strong class="inline">aws-ml-s3-trigger</strong>.:<div class="IMG---Figure" id="_idContainer074"><img alt="Figure 2.26: AWS Lambda – Configuring S3 trigger, S3 Bucket selection&#13;&#10;" src="image/image0251.jpg"/></div><h6>Figure 2.26: AWS Lambda – Configuring S3 trigger, S3 Bucket selection</h6></li>
				<li>Leave the remaining default settings. Next, scroll down the screen and click on <strong class="bold">Add</strong>:<div class="IMG---Figure" id="_idContainer075"><img alt="Figure 2.27: AWS Lambda – Adding the S3 Bucket as a trigger&#13;&#10;" src="image/image0271.jpg"/></div><h6>Figure 2.27: AWS Lambda – Adding the S3 Bucket as a trigger</h6></li>
				<li>The next step is to click on the <strong class="bold">Save</strong> button:<div class="IMG---Figure" id="_idContainer076"><img alt="AWS Lambda – Saving the S3 trigger&#13;&#10;" src="image/image0272.jpg"/></div><h6>AWS Lambda – Saving the S3 trigger</h6></li>
				<li>Next, scroll down the screen to the <strong class="bold">Function code</strong> section. The default code will be the same as or similar to, the following:<div class="IMG---Figure" id="_idContainer077"><img alt="Figure 2.28: AWS Lambda – the default Lambda_function screen&#13;&#10;" src="image/image028.jpg"/></div><h6>Figure 2.28: AWS Lambda The default Lambda_function screen</h6><p>Here, we can enter and edit our code entirely within the Lambda function screen (as long as the Code entry type is set to Edit code inline, which is the default value in the  drop-down menu).</p><h4>Note</h4><p class="callout">For this step, you may either follow along and type in the code, or obtain it from the source code folder at https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_c/s3_trigger.py file.</p></li>
				<li>First, we import the <strong class="bold">AWS SDK</strong> for Python (boto3) <a href="">http://boto3.readthedocs.io/en/latest/</a>: <p class="snippet">import boto3</p></li>
				<li>Next, create a function that takes two parameters-event and context:<p class="snippet">def Lambda_handler(event, context):</p></li>
				<li>Next, create the s3 client object:<p class="snippet">s3 = boto3.client("s3")</p></li>
				<li>Add an <strong class="inline">if</strong> event to check whether an event occurs.</li>
				<li>Next, replace <strong class="inline">&lt;input Bucket name&gt;</strong> with the Bucket you created (<strong class="inline">aws-ml-s3-trigger</strong>, in my example):<p class="snippet">Bucket = "&lt;input Bucket name&gt;"</p></li>
				<li>Next, access the event <strong class="inline">Records</strong> first index to obtain the text file object:<p class="snippet">text_file_obj = event["Records"][0]</p></li>
				<li>Next, assign the text <strong class="inline">filename</strong> to a variable, and print the filename:<p class="snippet">filename = str(text_file_obj['s3']['object']['key'])</p><p class="snippet">print("filename: ", filename)</p></li>
				<li>Next, create the file object by getting the Bucket and key:<p class="snippet">file_obj = s3.get_object(Bucket = Bucket, Key = filename)</p></li>
				<li>Assign the text to the <strong class="inline">body_str_obj</strong> variable:<p class="snippet">body_str_obj = str(file_obj['Body'].read())</p></li>
				<li>Replace &lt;<strong class="inline">input region name</strong>&gt; with your specific region. In addition, create the comprehend variable (us-east-1, in my example):<p class="snippet">comprehend = boto3.client(service_name="comprehend", region_name='&lt;input region_name&gt;') </p></li>
				<li>The next three lines of code call the respective comprehend functions to detect the sentiment, entities, and key phrases from the text document. Then, the output is printed to the console:<p class="snippet">sentiment_response = comprehend.detect_sentiment(Text = body_str_obj, LanguageCode = "en")</p><p class="snippet">print("sentiment_response: \n", sentiment_response)</p><p class="snippet">entity_response = comprehend.detect_entities(Text = body_str_obj, LanguageCode = "en")</p><p class="snippet">print("\n\nentity_response: \n", entity_response)</p><p class="snippet">key_phases_response = comprehend.detect_key_phrases(Text = body_str_obj, LanguageCode = "en") </p><p class="snippet">print("\n\nkey_phases_response: \n", key_phases_response)</p></li>
				<li>The final statement returns the string 'Hello from Lambda', like so:<p class="snippet">return 'Hello from Lambda'</p></li>
				<li>Now, click on the <strong class="bold">Save</strong> button:</li>
				<li><div class="IMG---Figure" id="_idContainer078"><img alt="Figure 2.29: AWS Lambda – Save screen&#13;&#10;" src="image/image0291.jpg"/></div></li>
			</ol>
			<h6>Figure 2.29: AWS Lambda – Save screen</h6>
			<p>From this exercise, the <strong class="inline">s3_trigger</strong> function has access to S3, but not Amazon Comprehend. We need to attach a policy to the <strong class="inline">s3_trigger</strong> function to allow it to access Amazon Comprehend to execute the text analysis functions (<strong class="inline">detect_sentiment</strong>, <strong class="inline">detect_entities</strong>, and <strong class="inline">detect_key_phrases</strong>).</p>
			<h3 id="_idParaDest-57"><a id="_idTextAnchor058"/>Exercise 12: Assigning Policies to S3_trigger to Access Comprehend </h3>
			<p>In this exercise, we will attach the policies to the <strong class="inline">S3_trigger</strong> function, in order to allow it to access comprehend. The steps for completion for assigning the policies are as follows:</p>
			<ol>
				<li value="1">Navigate to the Identity and Access Management dashboard at <a href="">https://console.aws.amazon.com/iam</a>:<div class="IMG---Figure" id="_idContainer079"><img alt="Figure 2.30: IAM dashboard" src="image/image030.jpg"/></div><h6>Figure 2.30: IAM dashboard</h6></li>
				<li>Now, once you get to the IAM dashboard, click on <strong class="bold">Roles</strong>:<div class="IMG---Figure" id="_idContainer080"><img alt="Figure 2.31: Left-hand side of the IAM dashboard&#13;&#10;" src="image/image0311.jpg"/></div><h6>Figure 2.31: Left-hand side of the IAM dashboard</h6></li>
				<li>Now, the screen will be populated with the Role list. Click on <strong class="inline">s3TriggerRole</strong> in the Role list:<div class="IMG---Figure" id="_idContainer081"><img alt="Figure 2.32: Role list – selecting s3TriggerRole&#13;&#10;" src="image/image032.jpg"/></div><h6>Figure 2.32: Role list Selecting s3TriggerRole</h6></li>
				<li>The option of <strong class="inline">s3TriggerRole</strong> will be enabled. Then, click on <strong class="bold">Attach policies</strong>:<div class="IMG---Figure" id="_idContainer082"><img alt="Figure 2.33: Permissions tab for s3TriggerRole&#13;&#10;" src="image/image0331.jpg"/></div><h6>Figure 2.33: Permissions tab for s3TriggerRole</h6></li>
				<li>Type <strong class="inline">Comprehend</strong> to filter the policies. Then, click the checkbox next to <strong class="inline">ComprehendFullAccess</strong>:<div class="IMG---Figure" id="_idContainer083"><img alt="Figure 2.34: ComprehendFullAccess policy selection&#13;&#10;" src="image/image034.jpg"/></div><h6>Figure 2.34: ComprehendFullAccess policy selection</h6></li>
				<li>Once you have selected the checkbox, click on <strong class="bold">Attach policy</strong> (located in the lower right-hand side of the screen):<div class="IMG---Figure" id="_idContainer084"><img alt="Figure 2.35: Attaching the selected policies&#13;&#10;" src="image/image0351.jpg"/></div><h6>Figure 2.35: Attaching the selected policies</h6></li>
				<li>You will be redirected to the <strong class="inline">s3TriggerRole</strong> screen, and you will receive the following message:</li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer085">
					<img alt="Figure 2.36: Successfully attached polices message&#13;&#10;" src="image/image036.jpg"/>
				</div>
			</div>
			<h6>Figure 2.36: Successfully attached polices message</h6>
			<h3 id="_idParaDest-58"><a id="_idTextAnchor059"/>Activity 3: Integrating Lambda with Amazon Comprehend to Perform Text Analysis</h3>
			<p>In this activity, we will integrate the Lambd<a id="_idTextAnchor060"/>a function with Comprehend to perform text analysis (<strong class="inline">detect_sentiment</strong>, <strong class="inline">detect_entities</strong>, and <strong class="inline">detect_key_phrases</strong>) when a document is uploaded to S3.</p>
			<p>Suppose that you are an entrepreneur creating a chatbot. You have identified a business topic and the corresponding text documents, with content that will allow the chatbot to make your business successful. Your next step is to integrate the Lambda function with Comprehend, for sentiment, key phrases, and entities. To ensure that this happens correctly, you will need to have <strong class="inline">test_s3trigger_configured.txt</strong>. Before you execute the <strong class="inline">s3_trigger</strong>, consider the output, based on the following aspects of the text: sentiment (positive, negative, or neutral), entities (quantity, person, place, and so on), and key phrases:</p>
			<ol>
				<li value="1">First, navigate to the <strong class="inline">S3_trigger</strong> Lambda function.</li>
				<li>Add <strong class="inline">test_s3trigger_configured.txt</strong> to the S3 Bucket, in order to verify the Lambda <strong class="inline">S3_trigger</strong> function.</li>
				<li>Now, upload the file into the Bucket and monitor the file.</li>
				<li>Next, click on View logs in the <strong class="inline">CloudWatch</strong> by using the log stream. </li>
				<li>Now, expand the output in a text format.</li>
				<li>The following will be the output:<p><strong class="inline">Sentiment_response</strong> -&gt; Classified as 60.0% likely to be a Positive</p><p><strong class="inline">Sentiment_response:</strong> </p></li>
			</ol>
			<p class="snippet">{'Sentiment': 'POSITIVE','SentimentScore':{'Positive': 0.6005121469497681,'Negative': 0.029164031147956848, 'Neutral': 0.3588017225265503, 'Mixed': 0.01152205839753151}, </p>
			<p><strong class="inline">entity_response</strong> --&gt; Classified as 70.5% likely to be a Quantity</p>
			<p><strong class="inline">entity_response: </strong></p>
			<p class="snippet">{Entities':[{'Score':0.7053232192993164, 'Type': 'QUANTITY','Text': '3 trigger', 'BeginOffset': 35, 'EndOffset': 44}], </p>
			<p><strong class="inline">key_phases_response</strong> -&gt; Classified as 89.9% likely "a test file" and 98.5% likely 'the s3 trigger" are the key phrases:</p>
			<p><strong class="inline">key_phases_response: </strong></p>
			<p class="snippet"> {'KeyPhrases': [{'Score': 0.8986637592315674, 'Text': 'a test file', 'BeginOffset': 8, 'EndOffset': 19}, {'Score': 0.9852105975151062, 'Text': 'the s3 trigger', 'BeginOffset': 30, 'EndOffset': 44}],</p>
			<h4>Note</h4>
			<p class="callout">To refer to the detailed steps, go to the <em class="italics">Appendix A</em> at the end of this book on Page no.198</p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor061"/>Summary </h2>
			<p>In this chapter, you learned how Comprehend's <strong class="inline">DetectDominantLanguage</strong> method is structured, and how to pass in both strings and a list of strings. You learned how to extract entities, sentiments, key phrases, and topics, which provide the data for complex NLP processing. This allows Amazon Comprehend to become more efficient, by automating text analysis upon a text document that's been uploaded to S3.</p>
			<p>Overall, the culmination of these independent functions provides the foundation for building complex machine learning-based NLP applications (for example, Siri, Alexa, and so on). Knowing how and why the individual functions operate will allow you to build your own AWS-based NLP applications.</p>
			<p>In the next chapter, we will explore Topic Modeling and perform theme extraction. </p>
		</div>
	</body></html>