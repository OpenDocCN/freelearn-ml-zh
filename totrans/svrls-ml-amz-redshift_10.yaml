- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Creating a Custom ML Model with XGBoost
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用XGBoost创建自定义ML模型
- en: So far, all of the supervised learning models we have explored have utilized
    the **Amazon Redshift Auto ML** feature, which uses **Amazon SageMaker Autopilot**
    behind the scenes. In this chapter, we will explore how to create custom **machine
    learning** (**ML**) models. Training a custom model gives you the flexibility
    to choose the model type and the hyperparameters to use. This chapter will provide
    examples of this modeling technique. By the end of this chapter, you will know
    how to create a custom XGBoost model and how to prepare the data to train your
    model using Redshift SQL.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们探索的所有监督学习模型都使用了**Amazon Redshift Auto ML**功能，该功能在幕后使用**Amazon SageMaker
    Autopilot**。在本章中，我们将探讨如何创建自定义**机器学习**（**ML**）模型。训练自定义模型让你有选择模型类型和使用超参数的灵活性。本章将提供这种建模技术的示例。到本章结束时，你将知道如何创建自定义XGBoost模型以及如何使用Redshift
    SQL准备训练模型的数据。
- en: 'In this chapter, we will go through the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主要主题：
- en: Introducing XGBoost
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍XGBoost
- en: Introducing an XGBoost use case
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍XGBoost用例
- en: XGBoost model with Auto off feature
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有自动关闭功能的XGBoost模型
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires a web browser and access to the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要网络浏览器以及访问以下内容：
- en: An AWS account
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个AWS账户
- en: An Amazon Redshift Serverless endpoint
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Redshift无服务器端点
- en: Amazon Redshift Query Editor v2
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Redshift查询编辑器v2
- en: 'You can find the code used in this chapter here:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此处找到本章使用的代码：
- en: '[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter10/chapter10.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter10/chapter10.sql)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter10/chapter10.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter10/chapter10.sql)'
- en: Introducing XGBoost
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍XGBoost
- en: '**XGBoost** gets its name because it is built on the **Gradient Boosting**
    framework. Using a tree-boosting technique provides a fast method for solving
    ML problems. As you have seen in previous chapters, you can specify the model
    type, which can help speed up model training since **SageMaker Autopilot** does
    not have to determine which model type to use.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**XGBoost**之所以得名，是因为它是建立在**梯度提升**框架之上的。使用树提升技术为解决ML问题提供了一种快速方法。正如你在前面的章节中看到的，你可以指定模型类型，这有助于加快模型训练，因为**SageMaker
    Autopilot**不需要确定使用哪种模型类型。'
- en: 'You can learn more about XGBoost here: [https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此处了解更多关于XGBoost的信息：[https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html)。
- en: When you create a model with Redshift ML and specify XGBoost as the model type,
    and optionally specify AUTO OFF, this turns off SageMaker Autopilot and you have
    more control of model tuning. For example, you can specify the hyperparameters
    you wish to use. You will see an example of this in the *Creating a binary classification
    model using* *XGBoost* section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用Redshift ML创建一个模型，并指定XGBoost作为模型类型，并且可选地指定AUTO OFF时，这将关闭SageMaker Autopilot，并让你对模型调优有更多的控制。例如，你可以指定你希望使用的超参数。你将在*使用XGBoost创建二元分类模型*部分看到这个示例。
- en: You will have to perform preprocessing when you set **AUTO** to **OFF**. Carrying
    out the preprocessing ensures we will get the best possible model and is also
    necessary since all inputs must be numeric when you set **AUTO** to **OFF**, for
    example, by making sure data is cleansed, categorical variables are encoded, and
    numeric variables are standardized. You will also need to identify the type of
    problem that you have and select an appropriate model to train. You will be able
    to create train and test datasets and evaluate models yourself. You also have
    the ability to tune the hyperparameters. In summary, you get total control of
    the end-to-end ML model training and building.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将**AUTO**设置为**OFF**时，你将需要进行预处理。执行预处理确保我们将获得最佳模型，并且由于当你将**AUTO**设置为**OFF**时，所有输入都必须是数值型的，这也是必要的，例如，确保数据被清理，分类变量被编码，数值变量被标准化。你还需要确定你遇到的问题类型，并选择一个合适的模型进行训练。你将能够创建训练和测试数据集，并自行评估模型。你还有能力调整超参数。总之，你将获得对端到端ML模型训练和构建的完全控制。
- en: By using XGBoost with Amazon Redshift ML, you can solve both regression and
    classification problems. You also can specify the learning objective of your model.
    For example, if you are solving a binary classification problem, you would choose
    `binary:logistic` as your objective or use `multi:softmax` for multi-class classification
    problems.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用Amazon Redshift ML的XGBoost，你可以解决回归和分类问题。你还可以指定你模型的训练目标。例如，如果你正在解决一个二元分类问题，你会选择`binary:logistic`作为你的目标，或者对于多类分类问题使用`multi:softmax`。
- en: At the time of writing this book, the supported learning objectives are `reg:squarederror`,
    `reg:squaredlogerror`, `reg:logistic`, `reg:pseudohubererror`, `reg:tweedie`,
    `binary:logistic`, `binary:hinge`, and `multi:softmax`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，支持的训练目标包括`reg:squarederror`、`reg:squaredlogerror`、`reg:logistic`、`reg:pseudohubererror`、`reg:tweedie`、`binary:logistic`、`binary:hinge`和`multi:softmax`。
- en: 'For more information about these objectives, see the *Learning Task Parameters*
    section of the XGBoost documentation here: [https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters](https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有关这些目标的更多信息，请参阅XGBoost文档中的*学习任务参数*部分：[https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters](https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters)。
- en: Now that you have learned what XGBoost is, we will take a look at a use case
    where we can apply XGBoost and solve a common business problem using binary classification.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了XGBoost是什么，我们将看看一个用例，其中我们可以应用XGBoost并使用二元分类解决一个常见的业务问题。
- en: Introducing an XGBoost use case
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍XGBoost用例
- en: 'In this section, we will be discussing a use case where we want to predict
    whether credit card transactions are fraudulent. We will be going through the
    following steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一个用例，其中我们想要预测信用卡交易是否为欺诈。我们将进行以下步骤：
- en: Defining the business problem
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义业务问题
- en: Uploading, analyzing, and preparing data for training
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上传、分析和准备训练数据
- en: Splitting data into training and testing datasets
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集
- en: Preprocessing the input variables
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理输入变量
- en: Defining the business problem
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义业务问题
- en: In this section, we will use a credit card payment transaction dataset to build
    a binary classification model using XGBoost in Redshift ML. This dataset contains
    customer and terminal information along with the date and amount related to the
    transaction. This dataset also has some derived fields based on **recency**, **frequency**,
    and **monetary** numeric features, along with a few categorical variables, such
    as whether a transaction occurred during the weekend or at night. Our goal is
    to identify whether a transaction is fraudulent or non-fraudulent. This use case
    is taken from [https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook](https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook).
    Please refer to the GitHub repository to learn more about this data generation
    process.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用信用卡支付交易数据集，在Redshift ML中使用XGBoost构建一个二元分类模型。此数据集包含客户和终端信息，以及与交易相关的日期和金额。此数据集还有一些基于**最近性**、**频率**和**货币**数值特征的派生字段，以及一些分类变量，例如交易是否发生在周末或夜间。我们的目标是识别交易是否为欺诈或非欺诈。此用例来自[https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook](https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook)。请参阅GitHub存储库以了解更多关于此数据生成过程的信息。
- en: Dataset citation
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: '*Reproducible Machine Learning for Credit Card Fraud Detection - Practical
    Handbook*, Le Borgne, Yann-Aël and Siblini, Wissam and Lebichot, Bertrand and
    Bontempi, Gianluca, [https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook](https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook),
    2022, Université Libre de Bruxelles'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*可重复的机器学习用于信用卡欺诈检测 - 实用手册*，Le Borgne, Yann-Aël 和 Siblini, Wissam 以及 Lebichot,
    Bertrand 和 Bontempi, Gianluca，[https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook](https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook)，2022，布鲁塞尔自由大学'
- en: Now, we will load our dataset into Amazon Redshift ML and prepare it for model
    training.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将我们的数据集加载到Amazon Redshift ML中，并为其模型训练做准备。
- en: Uploading, analyzing, and preparing data for training
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传、分析和准备训练数据
- en: Before we begin, let’s first connect to Redshift as an admin or database developer
    and then load data into Amazon Redshift.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们首先以管理员或数据库开发者的身份连接到Redshift，然后将数据加载到Amazon Redshift中。
- en: In the following steps, you will create a schema for all of the tables and objects
    needed for this exercise, which involves creating all the needed tables, loading
    data, and creating the views used for data transformations.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下步骤中，您将创建所有需要的表和对象的模式，这包括创建所有需要的表、加载数据以及创建用于数据转换的视图。
- en: 'Navigate to Query Editor v2, connect to the serverless endpoint, and then connect
    to the **dev** database, as shown in the following screenshot:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到查询编辑器 v2，连接到无服务器端点，然后连接到 **dev** 数据库，如下截图所示：
- en: '![Figure 10.1 – Connect to Query Editor v2](img/B19071_10_01.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.1 – 连接到查询编辑器 v2](img/B19071_10_01.jpg)'
- en: Figure 10.1 – Connect to Query Editor v2
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 连接到查询编辑器 v2
- en: 'Execute the following step to create the schema. This schema will be used for
    all objects and models created in this chapter:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下步骤以创建模式。此模式将用于本章中创建的所有对象和模型：
- en: '[PRE0]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, copy the following SQL statement into Query Editor v2 to create the table
    for hosting the customer payment transaction history, which we will load in the
    subsequent step:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将以下 SQL 语句复制到查询编辑器 v2 中以创建用于托管客户支付交易历史的表，我们将在后续步骤中加载数据：
- en: '[PRE1]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now that you have created the table, you can execute the following command
    in Query Editor v2 to load the table:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您已经创建了表，您可以在查询编辑器 v2 中执行以下命令来加载数据表：
- en: '[PRE28]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now that you have loaded the data, it’s a good practice to sample some data
    to make sure our data is loaded properly. Run the following query to sample 10
    records:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您已经加载数据，一个好的做法是采样一些数据以确保我们的数据加载正确。运行以下查询以采样 10 条记录：
- en: '[PRE33]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In the following screenshot, we can see that we have loaded the data correctly
    with a sampling of different transaction IDs:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下截图中，我们可以看到我们已经正确加载了数据，并采样了不同的交易 ID：
- en: '![Figure 10.2 – Data sample](img/B19071_10_02.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – 数据样本](img/B19071_10_02.jpg)'
- en: Figure 10.2 – Data sample
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 数据样本
- en: As discussed in earlier chapters, the target variable is the value that we are
    trying to predict in our model. In our use case, we are trying to predict whether
    a transaction is fraudulent. In our dataset, this is the `tx_fraud` attribute,
    which is our target. Let us check our table to see how many transactions were
    flagged as fraudulent.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如前几章所述，目标变量是我们试图在模型中预测的值。在我们的用例中，我们试图预测交易是否为欺诈。在我们的数据集中，这是 `tx_fraud` 属性，即我们的目标。让我们检查我们的表以查看有多少笔交易被标记为欺诈。
- en: 'Run the following command in Query Editor v2:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询编辑器 v2 中运行以下命令：
- en: '[PRE36]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We identify fraudulent transactions in our dataset as those with a `tx_fraud`
    value of `1`. We have identified 14,681 transactions as fraudulent in our dataset.
    Conversely, a `tx_fraud` value of `0` indicates that a transaction is not fraudulent:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据集中的欺诈交易识别为 `tx_fraud` 值为 `1` 的交易。我们在数据集中已识别出 14,681 笔欺诈交易。相反，`tx_fraud`
    值为 `0` 表示交易不是欺诈：
- en: '![Figure 10.3 – Fraudulent transactions](img/B19071_10_03.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.3 – 欺诈交易](img/B19071_10_03.jpg)'
- en: Figure 10.3 – Fraudulent transactions
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – 欺诈交易
- en: Let us look at the trend of fraudulent and non-fraudulent transactions over
    the months. We want to analyze whether there are any unusual spikes in fraudulent
    transactions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看欺诈和非欺诈交易在几个月内的趋势。我们想要分析是否存在任何欺诈交易的不寻常峰值。
- en: 'Run the following SQL command in Query Editor v2:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询编辑器 v2 中运行以下 SQL 命令：
- en: '[PRE37]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Notice that fraudulent transactions increased by nearly 8 percent in 202207
    over 202206:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到欺诈交易在 202207 相比 202206 增加了近 8%：
- en: '![Figure 10.4 – Fraudulent transaction trends](img/B19071_10_04.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.4 – 欺诈交易趋势](img/B19071_10_04.jpg)'
- en: Figure 10.4 – Fraudulent transaction trends
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – 欺诈交易趋势
- en: Now that we have loaded our data, let’s get our data prepared for model training
    by splitting the data into train and test datasets. The training data is used
    to train the model and the testing data is used to run our prediction queries.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经加载数据，让我们通过将数据分割成训练集和测试集来准备我们的数据以供模型训练。训练数据用于训练模型，测试数据用于运行我们的预测查询。
- en: Splitting data into train and test datasets
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据分割成训练集和测试集
- en: To train the model, we will have transactions that are older than `2022-10-01`,
    which is ~ 80 percent of the transactions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练模型，我们将使用 `2022-10-01` 之前的交易，这大约占交易总数的 80%。
- en: To test the model, we will use transactions from after `2022-09-30`, which is
    20 percent of the transactions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试模型，我们将使用 `2022-09-30` 之后的交易数据，这占交易总数的 20%。
- en: Preprocessing the input variables
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理输入变量
- en: We have a combination of numeric and categorical variables in our input fields.
    We need to preprocess the categorical variables into one-hot-encoded values and
    standardize the numeric variables. Since we will be using **AUTO OFF**, SageMaker
    does not automatically preprocess the data. Hence, it is important to transform
    various numeric, datetime, and categorical features.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的输入字段中，我们有数值和分类变量的组合。我们需要将分类变量预处理为独热编码值并标准化数值变量。由于我们将使用 **自动关闭**，SageMaker
    不会自动预处理数据。因此，转换各种数值、日期和时间特征非常重要。
- en: '**Categorical features** (also referred to as nominal) have distinct categories
    or levels. These can be categories without an order to them, such as country or
    gender. Or they can have an order such as level of education (also referred to
    as ordinal).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类特征**（也称为名义变量）具有不同的类别或级别。这些可以是没有任何顺序的类别，例如国家或性别。或者它们可以有顺序，例如教育水平（也称为有序变量）。'
- en: Since ML models need to operate on **numeric variables**, we need to apply ordinal
    encoding or one-hot encoding.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器学习模型需要在 **数值变量** 上操作，我们需要应用有序编码或独热编码。
- en: 'To make things easier, we have created the following view to take care of the
    transformation logic. This view is somewhat lengthy, but actually, what the view
    is doing is quite simple:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使事情更简单，我们创建了一个视图来处理转换逻辑。这个视图有点长，但实际上，视图所做的是相当简单的：
- en: Calculating the transaction time in seconds and days
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算交易时间（以秒和天为单位）
- en: Applying one-hot encoding by assigning `0` or `1` to classify transactions as
    weekday, weekend, daytime, or nighttime (such as `TX_DURING_WEEKEND` or `TX_DURING_NIGHT`)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过分配 `0` 或 `1` 来进行独热编码，以将交易分类为工作日、周末、白天或夜间（例如 `TX_DURING_WEEKEND` 或 `TX_DURING_NIGHT`）
- en: Applying window functions to transactions so that we make it easy to visualize
    the data in 1-day, 7-day, and 30-day intervals
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对交易应用窗口函数，以便我们可以在1天、7天和30天的时间间隔内轻松可视化数据
- en: 'Execute the following SQL command in Query Editor v2 to create the view by
    applying the transformation logic:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在Query Editor v2中执行以下SQL命令以通过应用转换逻辑创建视图：
- en: '[PRE38]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Now that the view is created, let’s sample 10 records.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在视图已创建，让我们采样10条记录。
- en: 'Execute the following command in Query Editor v2:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在Query Editor v2中执行以下命令：
- en: '[PRE39]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can see some of our transformed values, such as `tx_time_seconds` and `txn_time_days`,
    in the following screenshot:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下屏幕截图中看到一些我们的转换值，例如 `tx_time_seconds` 和 `txn_time_days`：
- en: '![Figure 10.5 – Transformed data](img/B19071_10_05.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图10.5 – 转换后的数据](img/B19071_10_05.jpg)'
- en: Figure 10.5 – Transformed data
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 – 转换后的数据
- en: 'Now, let’s quickly review why we needed to create this view:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们快速回顾一下为什么我们需要创建这个视图：
- en: Since we are using XGBoost with Auto OFF, we must do our own data preprocessing
    and feature engineering
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于我们使用XGBoost与自动关闭，我们必须自己进行数据预处理和特征工程
- en: We applied one-hot encoding to our categorical variables
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们对分类变量应用了独热编码
- en: We scaled our numeric variables
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们对数值变量进行了缩放
- en: 'Here is a summary of the view logic:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是视图逻辑的摘要：
- en: The target variable we used is `TX_FRAUD`
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用的目标变量是 `TX_FRAUD`
- en: The categorical variables we used are `TX_DURING_WEEKEND_IND`, `TX_DURING_WEEKDAY_IND`,
    `TX_DURING_NIGHT_IND`, and `TX_DURING_DAY_IND`
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用的分类变量是 `TX_DURING_WEEKEND_IND`, `TX_DURING_WEEKDAY_IND`, `TX_DURING_NIGHT_IND`,
    和 `TX_DURING_DAY_IND`
- en: The scaled numeric variables are `s_customer_id_nb_tx_1day_window`, `s_customer_id_avg_amount_1day_window`,
    `s_customer_id_nb_tx_7day_window`, `s_customer_id_avg_amount_7day_window,s_customer_id_nb_tx_30day_window`,
    `s_customer_id_avg_amount_30day_window`, `s_terminal_id_nb_tx_1day_window`, `s_terminal_id_risk_1day_window`,
    `s_terminal_id_nb_tx_7day_window`, `s_terminal_id_risk_7day_window`, `s_terminal_id_nb_tx_30day_window`,
    and `s_terminal_id_risk_30day_window`
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放后的数值变量是 `s_customer_id_nb_tx_1day_window`, `s_customer_id_avg_amount_1day_window`,
    `s_customer_id_nb_tx_7day_window`, `s_customer_id_avg_amount_7day_window`, `s_customer_id_nb_tx_30day_window`,
    `s_customer_id_avg_amount_30day_window`, `s_terminal_id_nb_tx_1day_window`, `s_terminal_id_risk_1day_window`,
    `s_terminal_id_nb_tx_7day_window`, `s_terminal_id_risk_7day_window`, `s_terminal_id_nb_tx_30day_window`,
    和 `s_terminal_id_risk_30day_window`
- en: You have now completed data preparation and are ready to create your model!
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经完成了数据准备，并准备好创建你的模型！
- en: Creating a model using XGBoost with Auto Off
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用XGBoost自动关闭创建模型
- en: 'In this exercise, we are going to create a custom binary classification model
    using the XGBoost algorithm. You can achieve this by setting **AUTO off**. Here
    are the parameters that are available:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用XGBoost算法创建一个自定义的二进制分类模型。你可以通过设置 **自动关闭** 来实现这一点。以下是可用的参数：
- en: '**AUTO OFF**'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动关闭**'
- en: '**MODEL_TYPE**'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型类型**'
- en: '**OBJECTIVE**'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标**'
- en: '**HYPERPARAMETERS**'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超参数**'
- en: 'For the complete list of hyperparameter values that are available and their
    defaults, please read the documentation found here:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 关于可用的超参数值及其默认值的完整列表，请阅读以下文档：
- en: '[https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_auto_off_create_model](https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_auto_off_create_model)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_auto_off_create_model](https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_auto_off_create_model)'
- en: Now that you have a basic understanding of the parameters available with XGBoost,
    you can create the model.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了XGBoost提供的参数，你可以创建模型。
- en: Creating a binary classification model using XGBoost
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用XGBoost创建二元分类模型
- en: Let’s create a model to predict whether a transaction is fraudulent or non-fraudulent.
    As you learned in the previous chapters, creating models with Amazon Redshift
    ML is simply done by running a SQL command that creates a function. As inputs
    (or features), you will be using the attributes from the view that you created
    in the previous section. You will specify `tx_fraud` as the target and give the
    function name, which you will use later in your prediction queries. Additionally,
    you will specify hyperparameters to do your own model tuning. Let’s begin!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个模型来预测交易是欺诈还是非欺诈。正如你在前面的章节中学到的，使用Amazon Redshift ML创建模型只需运行一个创建函数的SQL命令。作为输入（或特征），你将使用你在上一节中创建的视图中的属性。你将指定`tx_fraud`作为目标，并给出函数名称，你将在后续的预测查询中使用它。此外，你将指定超参数以进行自己的模型调优。让我们开始吧！
- en: 'Execute the following commands in Query Editor v2\. The following is a code
    snippet; you may retrieve the full code from the following URL:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询编辑器v2中执行以下命令。以下是一个代码片段；你可以从以下URL获取完整的代码：
- en: '[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/chapter10.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/chapter10.sql)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/chapter10.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/chapter10.sql)'
- en: '[PRE40]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The `CREATE MODEL` function is going to invoke the XGBoost algorithm and train
    a binary classification model. We have set `num_round` hyperparameter value to
    `100`, which is the number of rounds to run the training.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`CREATE MODEL`函数将调用XGBoost算法并训练一个二元分类模型。我们将`num_round`超参数值设置为`100`，这是训练运行的轮数。'
- en: 'Now, let’s run `SHOW MODEL` to see whether model training is completed. Run
    the following command in Query Editor v2:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们运行 `SHOW MODEL` 来查看模型训练是否完成。在查询编辑器v2中运行以下命令：
- en: '[PRE41]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Note **Model State** in the following screenshot, which shows your model is
    still training:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 注意以下截图中的**模型状态**，它显示你的模型仍在训练中：
- en: '![Figure 10.6 – Show model output](img/B19071_10_06.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图10.6 – 显示模型输出](img/B19071_10_06.jpg)'
- en: Figure 10.6 – Show model output
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 – 显示模型输出
- en: From the preceding screenshot, we notice that the value of `CREATE MODEL` statement
    – **Model Type** is set to **xgboost**. **objective** is set to **binary:logistic**
    and the **num_round** parameter is set to **100**.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的截图，我们注意到`CREATE MODEL`语句的值**模型类型**设置为**xgboost**。**objective**设置为**binary:logistic**，而**num_round**参数设置为**100**。
- en: When you have a custom model with **AUTO OFF** and specify the hyperparameters,
    the model can be trained much faster. This model will usually finish in under
    10 minutes.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有一个**自动关闭**的自定义模型并指定超参数时，模型可以训练得更快。这个模型通常在10分钟内完成。
- en: 'Run the `SHOW MODEL` command again after 10 minutes to check whether model
    training is complete or not. As you can see from the following screenshot, model
    training has completed and the **train:error** field reports the error rate. Most
    datasets have a threshold of *.5*, so our value of **0.051870** is very good,
    as seen in the following screenshot:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 10分钟后再次运行`SHOW MODEL`命令来检查模型训练是否完成。如以下截图所示，模型训练已完成，**train:error**字段报告了错误率。大多数数据集的阈值是*.5*，所以我们的**0.051870**值非常好，如以下截图所示：
- en: '![Figure 10.7 – SHOW MODEL output](img/B19071_10_07.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图10.7 – SHOW MODEL输出](img/B19071_10_07.jpg)'
- en: Figure 10.7 – SHOW MODEL output
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 – SHOW MODEL输出
- en: Now, your model is complete and has a good score based on `score – train_error`,
    which is `0.051870`. You are now ready to use it for predictions.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你的模型已经完成，并且基于`score – train_error`的得分很好，为`0.051870`。你现在可以使用它进行预测。
- en: Generating predictions and evaluating model performance
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成预测和评估模型性能
- en: 'Run the following query in Query Editor v2, which will compare the actual `tx_fraud`
    value with the `predicted_tx_fraud` value:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询编辑器 v2 中运行以下查询，该查询将比较实际的 `tx_fraud` 值与 `predicted_tx_fraud` 值：
- en: '[PRE42]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The following screenshot shows the sample output. In this screenshot, our predicted
    values are the same as the actual values:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了样本输出。在此截图中，我们的预测值与实际值相同：
- en: '![Figure 10.8 – Inference query output](img/B19071_10_08.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.8 – 推理查询输出](img/B19071_10_08.jpg)'
- en: Figure 10.8 – Inference query output
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 – 推理查询输出
- en: 'Since we did not get the F1 value for our model from Redshift ML, let’s calculate
    it. We will create a view that contains the logic to accomplish this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有从 Redshift ML 获取我们模型的 F1 值，让我们来计算它。我们将创建一个包含完成此逻辑的视图：
- en: '[PRE43]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Run the following SQL command in Query Editor v2 to check the F1 score that
    we calculated in the view:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询编辑器 v2 中运行以下 SQL 命令以检查我们在视图中计算的 F1 分数：
- en: '[PRE44]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'You can see our accuracy is 90 percent and our F1 score is 87 percent, which
    are both very good. Additionally, our confusion matrix values tell us how many
    times we correctly predicted `True` and correctly predicted `False`:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们的准确率是 90%，F1 分数是 87%，这两个指标都非常出色。此外，我们的混淆矩阵值告诉我们我们正确预测 `True` 和正确预测 `False`
    的次数：
- en: '![Figure 10.9 – F1 score](img/B19071_10_09.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.9 – F1 分数](img/B19071_10_09.jpg)'
- en: Figure 10.9 – F1 score
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 – F1 分数
- en: 'Now, let’s check actual versus prediction counts. Run the following query in
    Query Editor v2:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查实际与预测计数。在查询编辑器 v2 中运行以下查询：
- en: '[PRE45]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output in the following screenshot shows, for a given value, what our prediction
    was compared to the actual value and the count of those records. Our model incorrectly
    predicted a fraudulent transaction 178 times and incorrectly predicted a non-fraudulent
    transaction 1,081 times:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图的输出显示了对于给定值，我们的预测值与实际值以及这些记录的数量相比。我们的模型错误地预测了 178 次欺诈交易，错误地预测了 1,081 次非欺诈交易：
- en: '![Figure 10.10 – Confusion matrix](img/B19071_10_10.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.10 – 混淆矩阵](img/B19071_10_10.jpg)'
- en: Figure 10.10 – Confusion matrix
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10 – 混淆矩阵
- en: This demonstrates how Redshift ML can help you confidently predict whether a
    transaction is fraudulent.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了 Redshift ML 如何帮助你自信地预测一笔交易是否为欺诈。
- en: Summary
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned what XGBoost is and how to apply it to a business
    problem. You learned how to specify your own hyperparameters when using the **Auto
    Off** option and how to specify the objective for a binary classification problem.
    Additionally, you learned how to do your own data preprocessing and calculate
    the F1 score to validate the model performance.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了 XGBoost 是什么以及如何将其应用于商业问题。你学习了在使用 **Auto Off** 选项时如何指定自己的超参数，以及如何为二分类问题指定目标。此外，你还学习了如何进行自己的数据预处理并计算
    F1 分数以验证模型性能。
- en: In the next chapter, you will learn how to bring your own models from Amazon
    SageMaker for in-database or remote inference.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何将你的模型从 Amazon SageMaker 带入数据库或远程推理。
