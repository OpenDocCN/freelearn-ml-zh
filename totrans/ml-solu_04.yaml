- en: Chapter 4. Recommendation Systems for E-Commerce
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous three chapters, we have covered a lot of tips and tricks that
    can be used to build various types of analytics products. In this chapter, we
    are going to build a recommendation engine for the e-commerce domain. Let's go
    over some background of recommendation systems. Then, we will discuss the problem
    statement that we are trying to solve in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a relatable example from real life. We surf videos on YouTube almost
    every day, right? Suppose you saw some videos related to rock music on YouTube
    last night. This morning, when you open your YouTube, you may find that there
    are a couple of suggested YouTube channels with good videos on rock music. YouTube
    actually changes its suggestions based on your watching habits. Do you want to
    know how that algorithm works? Let''s take another example that might be useful
    to us in this chapter. Most of us buy stuff from various e-commerce sites. Suppose
    you are trying to purchase a book from Amazon. When you search for a book there
    is a section that suggests other books in the same genre. The title of this section
    is *Customers who bought this item also bought*; you may find these suggestions
    useful and buy another book as well. Take a look at the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendation Systems for E-Commerce](img/B08394_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1: Book suggestions on Amazon'
  prefs: []
  type: TYPE_NORMAL
- en: All these suggestions you find on e-commerce websites use a specific algorithm,
    and this algorithm is referred to as the recommendation algorithm. This chapter
    is all about how to build the recommendation system using different types of Machine
    Learning (ML) algorithms. Other than e-commerce, there are many domains in which
    the recommendation system has been used; for example, Netflix and YouTube use
    the recommendation algorithm to suggest videos we may like, Airbnb provides a
    recommendation based on our activities on their website. The retail banking domain
    too uses the logic of the recommendation engine to offer various types of credit
    cards and offers to their customers. The list is never-ending, so now let's learn
    how to build a recommendation system.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the problem statement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Building the baseline approach:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the basic concepts
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the baseline approach
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the testing matrix
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the result of the baseline approach
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Problems with the baseline approach
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing the baseline approach
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Building the revised approach:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the revised approach
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the revised approach
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Problems with the revised approach
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding how to improve the revised approach
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The best approach:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the key concepts
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the best approach
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So let's discuss the problem statement as well as start with the basic concepts
    of the recommendation system.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the problem statement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you know, in this chapter, we are trying to build a recommendation system.
    A domain that mainly uses the recommendation system is e-commerce. So, in our
    basic version of the recommendation engine specifically, we will be building an
    algorithm that can suggest the name of the products based on the category of the
    product. Once we know the basic concepts of the recommendation engine, we will
    build a recommendation engine that can suggest books in the same way as the Amazon
    website.
  prefs: []
  type: TYPE_NORMAL
- en: We will be building three versions of the recommendation algorithm. The baseline
    approach is simple but intuitive so that readers can learn what exactly the recommendation
    algorithm is capable of doing. Baseline is easy to implement. In the second and
    third approach, we will be building the book recommendation engine using ML algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the basic methods or approaches that are used to build the recommendation
    system. There are two main approaches, which you can find in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Introducing the problem statement](img/B08394_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: Approaches for the recommendation engine'
  prefs: []
  type: TYPE_NORMAL
- en: We will be using these two approaches although there are other approaches as
    well, such as a knowledge-based approach or a hybrid approach. But in this chapter,
    we will be focusing on the given two approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's look at the dataset that we are going to use.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we are using two datasets, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: E-commerce item data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Book-Crossing dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: e-commerce Item Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This dataset contains data items taken from actual stock keeping units (SKUs).
    It is from an outdoor apparel brand''s product catalog. We are building the recommendation
    engine for this outdoor apparel brand''s product catalog. You can access the dataset
    by using this link: [https://www.kaggle.com/cclark/product-item-data/data](https://www.kaggle.com/cclark/product-item-data/data).'
  prefs: []
  type: TYPE_NORMAL
- en: This dataset contains 500 data items. There are two columns in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**ID**: This column indicates the indexing of the data item. In layman''s terms,
    it is the serial number of the dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Description**: This column has all the necessary descriptions about the products,
    and we need to use this data to build the recommendation engine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can refer to the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![e-commerce Item Data](img/B08394_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3: Snippet of the e-commerce item data'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the description column has textual data, and we need to process
    this textual dataset in order to build the recommendation engine. Now let's move
    to the next dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The Book-Crossing dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Book-Crossing dataset is widely used to build recommendation systems. You
    can access it at [http://www2.informatik.uni-freiburg.de/~cziegler/BX/](http://www2.informatik.uni-freiburg.de/~cziegler/BX/).
    This dataset is available in two formats, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: SQL dump
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CSV dump
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We are using the CSV dump of the dataset. Both formats have three tables with
    different data attributes. The names of these three files are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`BX-Book-Ratings.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BX-Books.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BX-Users.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's explore the data given in each of the data tables.
  prefs: []
  type: TYPE_NORMAL
- en: BX-Book-Ratings.csv
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This CSV file contains data related to the rating of the book. This table contains
    three data attributes, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User-ID**: This data attribute indicates the unique user ID. This column
    has a numeric value. The length of the user ID is six.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ISBN**: The full form of ISBN is International Standard Book Number. This
    data attribute indicates the unique identification number of the book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Book rating**: This data attribute indicates the user rating for the book.
    The rating of the book varies from 0 to 10\. 0, with 0 indicating less appreciation
    and 10.0 indicating the highest appreciation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BX-Books.csv
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This file contains all the details regarding the books. The table contains
    the following data attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ISBN**: The ISBN is provided to identify the book. All invalid ISBNs have
    already been deleted. This data table contains only valid ISBNs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Book-Title**: This data attribute contains the name of the book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Book-Author**: This data attribute contains the name of the author of the
    book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Year-Of-Publication**: This indicates the year of publication of the book
    and is in the YYYY format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Publisher**: This data column has the name of the publisher who has published
    the book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image-URL-S**: This data attribute has the URL for the image of the book''s
    cover page. S indicates a small size of cover page image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image-URL-M**: This data attribute has the URL for the image of the book''s
    cover page. M indicates a medium size of cover image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image-URL-L**: This data attribute has the URL for the image of the book''s
    cover page. L indicates a large size of cover image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let's look at the details of the previous data table.
  prefs: []
  type: TYPE_NORMAL
- en: BX-Users.csv
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the third data table of the Book-Crossing dataset. This file contains
    information about the users.
  prefs: []
  type: TYPE_NORMAL
- en: 'This particular data file contains the following data attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User-ID**: This data column indicates the user ID, which is a six-digit integer
    number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Location**: This data is the part of the demographic details regarding the
    user. The location indicates the name and abbreviation of the city. The location
    details for all users are not available, so you will find the `null` value for
    those users whose locations haven''t been found.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Age**: This is also a demographic data point. If the user''s age is tracked,
    then it is present in the dataset; if not, then the value of the age is `null`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have gathered basic information about the two datasets. We will be moving
    toward building the basic version of the recommendation engine.
  prefs: []
  type: TYPE_NORMAL
- en: Building the baseline approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From this section onward, we will focus on how to build the basic version of
    the recommendation engine (which means the recommendation system in the context
    of this chapter). In order to develop the baseline approach, we will be using
    the content-based approach. These are the topics that we will be covering:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the basic concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the baseline approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the testing matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the result of the baseline approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problems with the baseline approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning optimization tricks for the baseline approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Without wasting any time, let's look at how the content-based approach has been
    used to build the recommendation engine.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the basic concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As I've specified earlier, we are using the content-based approach. You must
    be wondering what this approach is and how I have decided to use it. In order
    to find the answers to these questions, we need to understand the approach first,
    and then we can discuss why I chose it.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the content-based approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The intuition behind this algorithm is simple. If you are buying or are interested
    in one type of item, then you will probably like a similar product(s) as well.
    Let's take an example. If you are buying a pair of jeans, then there is a high
    chance that you will also like to buy t-shirts or tops, as well as formal trousers
    or other types of trousers. Basically, the recommendation for the products is
    based on the content that you have explored, bought, or are interested in. This
    approach works well when the context and properties of each of the item can be
    determined easily. This kind of recommendation system is used to recommend video
    and audio content to users.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you watch a comedy video on YouTube you might notice there are suggestions
    for other funny clips and comedy videos. This is because there is a high chance
    that you will like similar kinds of content based on your watching and browsing
    history. You can understand this example with the help of the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding the content-based approach](img/B08394_04_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.4: Pictorial representation of the idea of the content-based approach'
  prefs: []
  type: TYPE_NORMAL
- en: So, when we need to build a system that can recommend items or products that
    are similar to the user's buying pattern or browsing pattern, we use this approach.
    The reason for choosing this approach is that this type of recommendation is not
    influenced by choices of other users. This will provide a personalized experience
    for users. A recommendation is totally based on the items and its features that
    users like. This approach helps the e-commerce company increase their sales with
    less effort. It needs less manual work, which is a good point to note here. We
    can also use products that have been newly introduced by e-commerce platforms.
  prefs: []
  type: TYPE_NORMAL
- en: In order to implement this approach, we need to focus on the architecture part
    of it as well as look at basic concepts, such as TF-IDF and cosine similarity.
    We will explore all these topics in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the baseline approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will be designing the architecture of the content-based
    recommendation system. After that, we will look at how we can build a simple recommendation
    system. So, there are two subtopics that we will be covering here:'
  prefs: []
  type: TYPE_NORMAL
- en: Architecture of the recommendation system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Steps for implementing the baseline approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecture of the recommendation system
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will cover the basic architecture for the content-based
    recommendation system. Refer to the following figure, which explains the components
    in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Architecture of the recommendation system](img/B08394_04_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.5: Architecture of the content-based recommendation system'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there are a number of components that we need to use in order
    to build the recommendation system. We are using the data source or the information
    source to store details about the items or products. The content analyzer converts
    the item description into a certain format so that the recommendation engine can
    consume this information. We have all the products or item-related information
    with us. Now we need to know what the user is browsing, buying, or searching for
    on the e-commerce platform. This user-related information is used as a training
    example for the recommendation system. These training examples are the input of
    the profile learning module that actual analyzes the age, gender, time spent on
    website, as well as other demographics and user-activity-based information.
  prefs: []
  type: TYPE_NORMAL
- en: This collective information will be passed on to the filtering component. Based
    on the information of the products available on the e-commerce platform and user's
    activities, we will recommend the list of items to the customer.
  prefs: []
  type: TYPE_NORMAL
- en: The logic of the recommendation engine comes into picture here. We will push
    the recommendations to the active users of the e-commerce platform. Here, active
    users are those who have bought the product in last month or who have browsed
    the platform more frequently. We need to track the activity of the users, which
    acts as the feedback for our recommendation engine.
  prefs: []
  type: TYPE_NORMAL
- en: In the feedback, we can track the number of items the user clicked on from the
    list of recommendations. Did they buy any items that were a part of the recommendation
    list? This kind of feedback is useful because based on this feedback, we can fine-tune
    the logic of the recommendation engine. We will send the feedback to the profile
    learner, and using that, we will update the interest area for each user so that
    in future we can give them more suggestions regarding sport clothes, if the person
    previously browsed sport shoes. Now that you understand the components and their
    workings, let's take a look at the step-by-step implementation of the baseline
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: Steps for implementing the baseline approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will cover the coding of the basic recommendation engine.
    You can refer to the code by using this GitHub link: [https://github.com/jalajthanaki/Basic_Ecommerce_Recomendation_System](https://github.com/jalajthanaki/Basic_Ecommerce_Recomendation_System)'
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the steps that we need to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: Loading the dataset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generating the feature using TF-IDF the cosine similarity matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generating the prediction
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Loading the dataset
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We are using the e-commerce item dataset here. In this dataset, there is an
    item description that we need to use. We will use the `pandas` library to load
    the dataset. You can refer to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Loading the dataset](img/B08394_04_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.6: Code snippet for loading the dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Generating features using TF-IDF
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We will be using the concept of TF-IDF, which is a simple but effective statistical
    feature technique. TF-IDF stands for Term Frequency-Inverse Document Frequency.
    I will explain this briefly.
  prefs: []
  type: TYPE_NORMAL
- en: 'TF-IDF has two parts: Term Frequency and Inverse Document Frequency. Let''s
    begin with term frequency. The term is self-explanatory, but we will walk through
    the concept anyway. Term frequency indicates the frequency of each of the words
    present in the document or dataset. The equation for TF is given in the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating features using TF-IDF](img/B08394_04_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.7: Equation for TF'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s talk about inverse document frequency. IDF indicates how important
    the word is to the document. This is because when we calculate TF, we give equal
    importance to every single word. If the word *the* appears in the dataset more
    frequently, then its term frequency (TF) value is high but that word does not
    carry much importance for the document. If the word *the* appears in the document
    100 times, then it means that it does not carry that much information compared
    to words that are less frequent in the dataset. Thus, we need to define some weighing
    down of frequent terms while scaling up the rare ones, which is what decides the
    importance of each word. We will achieve this by using the equation given in the
    following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating features using TF-IDF](img/B08394_04_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.8: Equation for IDF'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the final equation to calculate TF-IDF is given in the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating features using TF-IDF](img/B08394_04_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.9: Equation for TF-IDF'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to read this in detail, then I would recommend that you read this
    topic from this book: [Chapter 5](ch05.xhtml "Chapter 5. Sentiment Analysis"),
    *Python Natural Language Processing*. For that, you can refer to this link: [https://www.packtpub.com/big-data-and-business-intelligence/python-natural-language-processing](https://www.packtpub.com/big-data-and-business-intelligence/python-natural-language-processing)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The practical implementation of this concept is quite easy. We use the scikit-learn
    library to code this up. You can refer to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating features using TF-IDF](img/B08394_04_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.10: Code snippet for generating features using TF-IDF'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have used the `TfidfVectorizer` API and generated the TF-IDF vectors
    for the item description. We have removed the English stop words using the `stop_words`
    parameter. Here, we have provided `ngram_range` from 1 to 3\. Now let's build
    the cosine similarity matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Building the cosine similarity matrix
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we will build the cosine similarity matrix, which is actually
    the main step required in order to build the content-based recommendation engine.
    This matrix indicates how similar the description of one product is to the other
    product. Here, we will check the cosine similarity between the TF-IDF vectors
    of all the products. We need to find the angle between two TF-IDF vectors. This
    angle represents how close or how far apart the TF-IDF vectors are. For that,
    we need to obtain the dot product between TF-IDF vectors by using the following
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building the cosine similarity matrix](img/B08394_04_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.11: Equation for the dot product'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, with the help of the given cosine equation, we can generate the angle
    between these vectors. You can refer to the equations in the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building the cosine similarity matrix](img/B08394_04_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.12: Equation for cosine similarity and norm for vectors'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s look at a basic example so that you can understand the basic math
    behind it. For that, you need to refer to the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building the cosine similarity matrix](img/B08394_04_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.13: Basic cosine similarity example'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the preceding figure, there are two vectors; each of them
    has three elements. First, we calculated their norms and then we performed the
    dot product on them. After that, we used the cosine similarity formula and found
    the angle between these vectors. Note that we can measure the cosine similarity
    for two nonzero vectors. The interval for the cosine angle is *[0,2π)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The coding implementation for this is pretty easy. You can refer to the code
    snippet shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building the cosine similarity matrix](img/B08394_04_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.14: Code snippet for generating the cosine similarity'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have stored all the recommendations in a dictionary, where each item
    and its corresponding recommendation have been stored. There are 500 items in
    our dataset, and for each and every item, we have generated a list of items that
    can be recommended to the users. Now it's time to generate the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Generating the prediction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we will be generating the recommendation list for the given
    `item_id`. We need to pass any `item_id` from 1 to 500\. The system will obtain
    five different suggestions, which are referred to as recommended items. These
    recommended items are similar to the item whose `item_id` we have passed to the
    algorithm. You can see the code snippet in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating the prediction](img/B08394_04_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.15: Code snippet for generating prediction'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we retrieve the results from the dictionary. We have printed
    the value of cos θ as our scoring values. If the score is close to one, then it
    can be said that these items are more similar and there is a higher chance that
    the user will like the recommendation. If the score is closer to 0 or –1, then
    items appear less attractive to the users. So just note that here, the score indicates
    the value of cos θ and not the angle directly.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's look at the testing matrix, which can help us evaluate this approach
    as well as other approaches that we will be implementing in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the testing matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will be exploring the testing or evolution matrix for the
    content-based recommendation engine. Here, the cosine similarity score is the
    biggest testing score for us. That is because with the help of that score, we
    can easily come to learn whether the algorithm can suggest the items whose cosine
    similarity score is close to 1 close to 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'For some items, we will obtain a score that is close to 1, and for other items,
    we obtain a score that is close to 0\. So, we need to focus on this cosine score
    in order to get an idea of how well or badly the recommendation engine is doing.
    You can refer to the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding the testing matrix](img/B08394_04_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.16: Understanding of the cosine similarity score and angle'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the preceding figure, we need to use the cosine score in order
    to test this approach. We can perform the following steps for testing. We need
    to count the number of items with more than a certain score, which means that
    we can decide the threshold value for the cosine similarity score and count how
    many items the recommendation engine is suggesting above that threshold value.
    Let me give you an example. Suppose we decide a cut-off score of 0.15\. In this
    case, all items whose cosine score is above 0.15 are considered a good recommendation.
    Here, the trick is that you need to experiment with this threshold value because
    based on the user's activity, you may change it later on. This parameter will
    be a tunable parameter for us. In the next section, we will look at the code for
    the testing.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the result of the baseline approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will see how we can implement the logic of the threshold
    value. After that, we will compare the results for different items. You can refer
    to the code snippet shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Testing the result of the baseline approach](img/B08394_04_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.17: Code snippet for testing'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can see the results for different `item_ids`. You can find the result
    of the three items. I have picked up `item_id` randomly. Take a look at the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Testing the result of the baseline approach](img/B08394_04_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.18: Result of items'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Testing the result of the baseline approach](img/B08394_04_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.19: Analysis based on useful recommendations'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the preceding figure, this approach gives us useful recommendations
    69.8% of the time, and it provides four useful suggestions 7.2% of the time. After
    looking at the analysis of the result, we can say that the baseline approach is
    doing well, and we can definitely improve the results with the help of the other
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discuss the problems this baseline approach has
    and how we can solve them.
  prefs: []
  type: TYPE_NORMAL
- en: Problems with the baseline approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will be discussing the problems that are a part of the
    baseline approach. We need to understand the problems so that we can take care
    of them in the revised approach. The problems with this approach are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Limited content analysis**: If we do not have enough information in order
    to differentiate the items more accurately, then the recommendation engine won''t
    be giving useful or more precise suggestions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Over-specialization**: Content-based systems are based on the user profile
    and the items they are browsing, so the user will get the same kind of suggestion
    if they are browsing the same thing again and again. There is no different or
    novel item that the user can find. This is bad because if we provide the same
    recommendation more often, then there is no element of surprise for the user and
    they won''t be motivated to buy things. This problem is called over-specialization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**New-user**: If there is a new user who is exploring the e-commerce platform
    and we have a very limited amount of information about the user, then we cannot
    give them a good recommendation initially. This situation occurs due to the lack
    of a solid profile.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the preceding problems are well known for their content-based recommendation
    engine. In order to solve these problems, we can try out some other approach.
    The details related to this are given in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the baseline approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, we will have an overview of how we can resolve the problems that we encountered
    in the previous section. In the baseline approach, we are basically dependent
    on the user profile and the item description, but this approach did not turn out
    well. In order to improve that we will be using two approaches. In the revised
    approach, we will be using the correction-based approach. After that, we will
    try the collaborative-filtering-based approach.
  prefs: []
  type: TYPE_NORMAL
- en: This correlation-based approach depends on the users' activities and is not
    dependent on the content or the description of the item. This helps us resolve
    the issues of new users, over-specialization, and limited content analysis. We
    are using a correlation coefficient to build the recommendation engine. This is
    a simple statistical technique that can be quite helpful. The basic concepts that
    are important for implementation will be described as and when we start building
    the revised approach.
  prefs: []
  type: TYPE_NORMAL
- en: So let's build the revised approach.
  prefs: []
  type: TYPE_NORMAL
- en: Building the revised approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this iteration, we will be building the recommendation engine using a statistical
    concept called correlation. We will be looking at how users' activities and choices
    are correlated to one another. We try to find out the pattern from the users'
    activities and behavior on the e-commerce platform.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will be using the Book-Crossing dataset. One of the critical parameters
    for building the recommendation system is the book rating attribute. I will explain
    the concepts along with the implementation part, so it will be easy for you to
    understand.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the revised approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to implement the revised approach, we will need to perform the following
    steps. You can refer to the code on GitHub at: [https://github.com/jalajthanaki/Book_recommendation_system/blob/master/correlation_based_recommendation_system.ipynb](https://github.com/jalajthanaki/Book_recommendation_system/blob/master/correlation_based_recommendation_system.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: Loading the dataset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Exploratory Data Analysis** (**EDA**) of book-rating datafile'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exploring the book datafile
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: EDA of user datafile
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implementing the logic of correlation for the recommendation engine
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Loading dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As a first step, we will use the `pandas` library to load our Book-Crossing
    dataset. As you already know, this dataset has three datafiles. We are loading
    all of them. You can refer to the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Loading dataset](img/B08394_04_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.20: Code snippet for loading the data'
  prefs: []
  type: TYPE_NORMAL
- en: Our data separator is a semicolon, and we are using latin-1 as encoding. We
    have defined three `pandas` dataframes.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's jump to the next step, which is the EDA step for all three datafiles.
  prefs: []
  type: TYPE_NORMAL
- en: EDA of the book-rating datafile
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For this datafile, we have generated the ratings dataframe. We need to know
    what kind of data distribution this datafile has. That means we need to check
    how many books are getting a 10 out of 10 score, how many books are getting a
    5 out of 10 score, and how many books do not have any rating at all. Refer to
    the following code snippet to generate this information for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '![EDA of the book-rating datafile](img/B08394_04_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.21: Code snippet for EDA of book-rating datafile'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the bar chart for this in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![EDA of the book-rating datafile](img/B08394_04_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.22: Bar chart for book-rating score distribution'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, there are 7,16,109 books with a zero rating, whereas 1,03,736
    books have a rating of eight. Based on this analysis, we can deduce that there
    are many books whose rating is zero, so the data distribution is biased here.
    We need to keep this point in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the book datafile
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will perform the EDA of the book datafile. We also need
    to check the data attributes and format the data. No other trick needs to be applied
    for this datafile. Take a look at the code snippet shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploring the book datafile](img/B08394_04_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.23: Code snippet for exploring the book datafile'
  prefs: []
  type: TYPE_NORMAL
- en: You can see that we have checked the shape and columns list for the book datafile.
    There is nothing that critical we need to consider in order to build the recommendation
    engine.
  prefs: []
  type: TYPE_NORMAL
- en: EDA of the user datafile
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here, we need to perform an analysis of the users'' datafile. This datafile
    is important as we will be using it often to derive some important facts for this
    approach. First, we need to obtain the age distribution. The age distribution
    is one of the critical data points when we are building a recommendation system
    because users of a similar age group have similar reading patterns, and if we
    obtain this pattern, then we can generate more effective recommendations for our
    users. You can refer to the code snippet shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![EDA of the user datafile](img/B08394_04_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.24: Code snippet for generating the age distribution'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can refer to the box chart, which indicates the age distribution shown
    in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![EDA of the user datafile](img/B08394_04_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.25: Box graph for the age distribution'
  prefs: []
  type: TYPE_NORMAL
- en: Based on the distribution, we can derive the fact that we have a majority of
    the users whose age falls between 20 and 40\. So if we focus on their reading
    and browsing pattern, then our work will get easier.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the logic of correlation for the recommendation engine
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will cover the core logic of the recommendation engine.
    The logic can be divided into two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Recommendations based on the rating of the books
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendations based on correlations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So let's start!
  prefs: []
  type: TYPE_NORMAL
- en: Recommendations based on the rating of the books
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In order to build a book recommendation system that is based on the rating
    of the book, all the ratings are provided by the readers. So, for the implementation
    of this approach, we will be extracting the top five books with the highest ratings,
    which means we need to obtain a list of the books with the most ratings from the
    reader. The code snippet for that is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendations based on the rating of the books](img/B08394_04_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.26: Code snippet for generating the top five books based on book rating'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have generated the ISBN of the top five books on the book rating count,
    but we also need to check what those books'' names are and what the average rating
    for each of them is. You can find the name of the books by merging the book and
    book-rating data frame. You can see the code for this in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendations based on the rating of the books](img/B08394_04_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.27: Code snippet for generating the names of the top 5 books'
  prefs: []
  type: TYPE_NORMAL
- en: Now, you may wonder what the benefit of this approach is. Let me tell you, we
    have a list of the books in descending order based on the book rating. If a user
    buys the book based on the rating of the book, then we can suggest other books
    that have the same rating. This way, users get suggestions that are more accurate
    than the previous approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look at the results of the top five books, then you will learn that
    the maximum rating is for Rich Shapero''s book `Wild Animus`. All five books are
    novels. If someone wants to buy `Wild Animus`, then the user may also buy `The
    Lovely Bones: A Novel`. That is the reason this approach makes sense.'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's see the correlation-based recommendation engine.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendations based on correlations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We are using the bivariant correlation and the **Pearson correlation coefficient**
    (**PCC**). This is also referred to as `Person''s r`. This correlation provides
    a measure of the linear correction between the two variables `a and b`. Here,
    we are considering the rating of two books and applying the PCC technique to them.
    The value of Person''s `r` is in the range of `+1` to `–1`. The interpretation
    for this correlation value is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**+1**: This value indicates the total positive linear correlation. This means
    that if there is an increment in the value of the variable 1, then variable 2
    is incremented as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**0**: This value indicates that there is no linear correlation. This means
    that the two variables are not related.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**-1**: This value indicates that there is a total negative linear correlation.
    This means that if there is an increment in the value of variable 1, then variable
    2 is decremented.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The equation for the PCC is shown in the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendations based on correlations](img/B08394_04_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.28: Equation for PCC or Person''s r'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider a simple math example so you know how we have calculated Person''s
    r. Take a look at the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendations based on correlations](img/B08394_04_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.29: Math example for Person''s r'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note: we are considering the ratings of the two books in order to find the
    correlation between them.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we need to obtain the average rating for all books. The code
    snippet is given in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendations based on correlations](img/B08394_04_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.30: Code snippet for generating an average book rating'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the books that received the most rating counts are not the ones that
    are highly rated. This means there are some books for which readers share their
    feedback more often, but that doesn't mean those books are highly rated. Maybe
    some books were rated by 100 users but the score for the book is 4.3\. This is
    the most important point that I need to highlight because this is where mistakes
    can happen. For making a better system, we need to consider the book-rating count
    and the book-rating score.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will be excluding users who have provided less than 200 ratings as
    well as books that have received less than 100 ratings. This means we are setting
    up a threshold so that we can make a better system. We can achieve this by using
    the code snippet given in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendations based on correlations](img/B08394_04_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.31: Code snippet for setting up threshold for considering users and
    books'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are converting the ratings dataframe into a 2D matrix. This matrix is
    a sparse matrix because not every user has provided a rating for every book. You
    can see the code in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendations based on correlations](img/B08394_04_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.32: Code snippet for generating a sparse matrix for rating'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have completed some basic work, now it''s time to find out about books that
    correlate with the second most-rated book, *The Lovely Bones: A Novel.* I want
    to quote the summary of this book, which is taken from Wikipedia: [https://en.wikipedia.org/wiki/The_Lovely_Bones](https://en.wikipedia.org/wiki/The_Lovely_Bones)'
  prefs: []
  type: TYPE_NORMAL
- en: '"It is the story of a teenage girl who, after being raped and murdered, watches
    from her personal Heaven as her family and friends struggle to move on with their
    lives while she comes to terms with her own death".'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now we need to obtain a book that can be recommended to a user if they are
    trying to buy this book. The code that can help us get the recommendation is given
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendations based on correlations](img/B08394_04_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.33: Code snippet for generating a correlation-based recommendation'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you can see that we are using a sparse matrix and have applied the `corrwith`
    API to generate a correlation. There may be some runtime warnings. They are related
    to the float data type. Apart from that, we have coded the condition we need in
    order to recommend books that have received more than or equal to 300 user-rating
    counts. We have obtained the ISBN using the preceding code. So, we need to obtain
    the names of the books as well. For that, we need to use the code snippet given
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendations based on correlations](img/B08394_04_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.34: Code snippet for generating the name of the book'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s select the top three recommendations for the book, which are, *The Nanny
    Diaries: A Novel*, *The Pilot''s Wife: A Novel*, *and 1st to Die: A Novel*. The
    Nanny Diaries criticizes the upper-class society of Manhattan as seen through
    the eyes of their children''s caregivers. The Pilot''s Wife: A Novel is written
    by the same author who wrote The Lovely Bones. 1st to Die is the first book of
    a women''s murder club series.'
  prefs: []
  type: TYPE_NORMAL
- en: If you actually look at the content of these three books, then we can see that
    all these recommendations make sense.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the revised approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already obtained the recommendation, and if we check the suggested books
    using this revised approach, then we see that this simple correlation-based approach
    works rather well. We performed manual testing and evaluated the quality of the
    recommendations and the suggestions were surprisingly more sensible and useful
    for the users.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will be discussing the problems with this approach and
    how we can improvise the approach further. Before implementing optimization, we
    need to discuss the points on which we will be focusing. So, let's list down all
    the problems or areas of improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Problems with the revised approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we need to list down the problems or areas of improvement
    so that we can improve the revised approach. Here are the points for areas of
    improvement:'
  prefs: []
  type: TYPE_NORMAL
- en: The correlation-based approach is not generalized for all kinds of situations,
    so we need a more sophisticated approach. Basically, the correlation-based approach
    performs really well if the model has seen a similar kind of data example during
    training. For unseen data examples, it may not generate good results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can't always do manual testing, so we need a recommendation engine that is
    easy to develop, build, and test. The new approach can also adopt future changes,
    which means new approaches should be easy for us to change or modify as and when
    required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let's see how we can improve this revised approach.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how to improve the revised approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to improve the revised approach, we will be using the well-known recommendation
    algorithm, collaborative filtering (CF). We will be using the Machine Learning
    (ML) algorithm K-nearest neighbors (KNN). This is a basic outline for how we can
    improve the revised approach.
  prefs: []
  type: TYPE_NORMAL
- en: With the help of the CF algorithm and the ML algorithm, it will be easy for
    us to test the algorithm as well as modify the algorithm based on our requirements.
    You may know how KNN works, so we are not going to dive into the KNN algorithm
    in detail, but we will definitely try to understand the intuition behind the KNN
    algorithm. We will also understand how the CF-based recommendation engine works
    in detail so that all your concepts are clear during the implementation. With
    the help of these algorithms, we will build the best possible book recommendation
    system. We will compare the results of our algorithm with Amazon.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will cover the algorithms first and then start implementing
    our approach.
  prefs: []
  type: TYPE_NORMAL
- en: The best approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are trying to build the best possible recommendation engine.
    There are two parts to this section:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the key concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the best approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our first part covers the basic concepts, such as how the CF and KNN algorithms
    work, what kind of features we need to choose, and so on. In the second part,
    we will be implementing the recommendation engine using the KNN and CF algorithm.
    We will generate the accuracy score as well as the recommendation for books. So
    let's begin!
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the key concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will understand the concepts of collaborative filtering.
    This covers a lot of aspects of the recommendation system. So, let's explore CF.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two main types of collaborative filtering, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Memory-based CF:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-user collaborative filtering
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Item-item collaborative filtering
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Model-based CF:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix-factorization-based algorithms
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We will begin with memory-based CF and then move on to the model-based CF.
  prefs: []
  type: TYPE_NORMAL
- en: Memory-based CF
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Memory-based CF is further divided into two sections. I have defined these sections
    earlier. Refer to the *Introducing the problem statement* section. Here, we need
    to understand the concepts. We will begin with user-user CF and then look into
    item-item CF.
  prefs: []
  type: TYPE_NORMAL
- en: User-user collaborative filtering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In user-user CF, we consider a particular user. Now we need to find users that
    are similar to our particular user. We find similar users by observing their buying
    pattern and rating pattern for the items. Based on the similarity in the ratings
    and buying patterns, we recommend products to similar types of users. In order
    to understand user-user CF, you can refer to the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![User-user collaborative filtering](img/B08394_04_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.35: Pictorial representation of user-user CF'
  prefs: []
  type: TYPE_NORMAL
- en: Item-item CF works differently, however.
  prefs: []
  type: TYPE_NORMAL
- en: Item-item collaborative filtering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In item-item CF, we consider items. We find users who like a particular item
    and other items that the user or similar users also liked and bought. So, we recommend
    the item along with the particular item the user is looking for. Here, we need
    to take items as the input and generate the list of items as a recommendation.
    You can refer to the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Item-item collaborative filtering](img/B08394_04_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.36: Image representing item-item CF'
  prefs: []
  type: TYPE_NORMAL
- en: 'These two approaches can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Item-item CF**: We consider users who have liked x item as well as y'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-user CF**: We consider users who, similar to you, also liked x and y
    items'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory-based models use similarity-based techniques. In this approach, there
    are no optimization techniques, such as a gradient descent, involved so it will
    be easy to implement. We can use the KNN ML algorithm as it doesn't use a gradient
    descent-based optimization strategy. So, during the implementation, we will be
    using the KNN algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea behind the KNN algorithm is simple. We need to obtain the weight for
    each user or item. We can generate this weight by a cosine similarity or a person''s
    correlation coefficient. We use the similarity values, but we need to limit the
    number of similar users because we cannot consider all users to be similar. This
    number is denoted by K. Here, K indicates the number of similar neighbors or users
    we need to consider. This is the reason why the algorithm is called K-nearest
    neighbors (KNN). If you want more details on the KNN algorithm, then you can refer
    to this article: [https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/)'
  prefs: []
  type: TYPE_NORMAL
- en: Model-based CF
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this approach, we will be using ML-based techniques to predict the recommendation
    for users, especially for those items that are unrated. For that, we can use the
    matrix factorization method or the Deep-Learning-based approach. We will focus
    on the matrix factorization method here.
  prefs: []
  type: TYPE_NORMAL
- en: So, let's look at matrix factorization.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix-factorization-based algorithms
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The main idea behind the matrix-factorization-based algorithm is that preferences
    of the user can be determined by the matrix operation. We need to define the small
    number of hidden or latent factors. We can refer to this matrix as factors or
    embeddings. Let's take an example to understand it better.
  prefs: []
  type: TYPE_NORMAL
- en: We need to define the embedding matrix. Here, the values are randomly initialized
    and then we perform a dot product of this embedding matrix and the book embedding
    matrix. The resultant matrix is generated in such a way that we can predict which
    book can be recommended to which user. For matrix factorization, we need nonnegative
    elements in our resultant matrix. We will use singular value decomposition (SVD)
    models to identify latent factors. There are some other techniques that can be
    used as well, such as probabilistic matrix factorization, nonnegative matrix factorization,
    and so on. We will implement this matrix factorization technique.
  prefs: []
  type: TYPE_NORMAL
- en: Difference between memory-based CF and model-based CF
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The main difference between memory-based CF and model-based CF is that in the
    memory-based approach, there are no optimization techniques involved, whereas
    in the model-based approach, there is an optimization strategy and other optimization
    functions involved that improve accuracy of the model over a period of time. Now
    we will implement the CF-based approach.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the best approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will be implementing this approach by using the following steps. You can
    refer to the code on GitHub at: [https://github.com/jalajthanaki/Book_recommendation_system/blob/master/KNN_based_recommendation_system.ipynb](https://github.com/jalajthanaki/Book_recommendation_system/blob/master/KNN_based_recommendation_system.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: Loading the aset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Merging the data frames
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: EDA for the merged data frame
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Filtering data based on geolocation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applying the KNN algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Recommendation using the KNN algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applying matrix factorization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Recommendation using matrix factorization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Loading the dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Just like we loaded the dataset in the revised approach, we need to implement
    it here as well. Take a look at the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Loading the dataset](img/B08394_04_37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.37: Code snippet for loading the dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Merging the data frames
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We need to merge the books and ratings data frames. We will be generating the
    total rating each book has received to date. The code snippet for this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Merging the data frames](img/B08394_04_38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.38: Code snippet for generating the rating count'
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, we will be generating the book-rating score as well. Refer to the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Merging the data frames](img/B08394_04_39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.39: Code snippet for generating the book-rating score'
  prefs: []
  type: TYPE_NORMAL
- en: EDA for the merged data frames
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here, we will perform data analysis for the total rating count. After that,
    we need to obtain the quantile value for the rating of the book. That quantile
    value gives us a good idea about the data distribution. You can refer to the code
    snippet shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![EDA for the merged data frames](img/B08394_04_40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.40: Code snippet for EDA on total-book-rating'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, only 1% of the books received a user rating of 50 or more. There
    are many books in this dataset, but we will consider only 1% of these books. The
    total number of unique books is 2,713.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering data based on geolocation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will limit our user data to the USA and Canada regions. This filter speeds
    up the computation. We need to combine the user data and the total book-rating
    count data. For that, the code is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Filtering data based on geolocation](img/B08394_04_41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.41: Code snippet for geolocation-based filtering'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, now we have users that are from the USA and Canada.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the KNN algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It''s time to apply the main logic. We will be applying the KNN algorithm using
    the `sklearn` library. Our main goal is to determine the closeness of the data
    instances. You can take a look at the code snippet shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Applying the KNN algorithm](img/B08394_04_42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.42: Code snippet for implementing the KNN algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: We have used cosine similarity as the KNN matric parameter and we are considering
    the five nearest neighbors. This means that the value for K=5\. After the model
    is trained, we need to obtain the recommendation using them.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation using the KNN algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here, we need to obtain the recommendation using the KNN algorithm that has
    been trained just now. The code is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendation using the KNN algorithm](img/B08394_04_43.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.43: Code snippet for obtaining a recommendation using KNN'
  prefs: []
  type: TYPE_NORMAL
- en: For recommendation purposes, we have chosen the value of K = 6, which means
    we are considering the six nearest neighbors to recommend the book to any user.
    Here, we have chosen the book randomly from the `us_canada_user_rating_pivot`
    data frame.
  prefs: []
  type: TYPE_NORMAL
- en: The suggestions look great. All of The Green Mile series books are recommended
    here.
  prefs: []
  type: TYPE_NORMAL
- en: Applying matrix factorization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now let''s implement the matrix factorization method. We will convert the USA
    and Canada user rating data frame into a 2D matrix. This matrix is also referred
    to as a utility matrix. We have replaced the missing value with 0\. You can refer
    to the code given in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Applying matrix factorization](img/B08394_04_44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.44: Code snippet for generating the utility matrix'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need to transpose the utility matrix. The `bookTitles` become rows and
    `userID` is converted into columns. After that, we will apply `TruncatedSVD` for
    dimensionality reduction. This operation is performed on columns—on `userID`—because
    we need to use the book''s title afterward. You can refer to the code shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Applying matrix factorization](img/B08394_04_45.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.45: Code snippet for SVD dimensionality reduction'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have chosen the value of `n_components` as 12\. So as you can see,
    the dimensionality of our data frame has reduced a lot. Earlier, the dimensions
    of the data frame were 40017 x 2442, which has now become 2442 x 12.
  prefs: []
  type: TYPE_NORMAL
- en: Now we perform Pearson's correlation coefficient for every book pair in our
    final matrix. We will compare the results with the KNN algorithm. Basically, we
    should get the suggestion we got previously using the KNN algorithm for this approach
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation using matrix factorization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here, we need to generate a recommendation using the matrix factorization technique.
    We will list down all the recommendations for The Green Mile: Night Journey (Green
    Mile Series). The algorithm should suggest highly correlated books. We have applied
    a threshold for the correlation. Only those books that have a correlation score
    of more than 0.9 to less than 1 are listed using this approach. You can refer
    to the code snippet given in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendation using matrix factorization](img/B08394_04_46.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.46: Code snippet for generating a recommendation using matrix factorization'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the recommendation for all the books that have been recommended
    using the KNN-based approach appear here as well. So, this CF-based recommendation
    system works in the best manner. You can find the same kind of recommendations
    on Amazon as well. Refer to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recommendation using matrix factorization](img/B08394_04_47.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.47: Recommendation on Amazon'
  prefs: []
  type: TYPE_NORMAL
- en: We can confirm that our recommendation engine works well.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the last chapter of the analytics domain. So far, you have learned a
    lot of concepts that can help us build amazing analytics applications. In this
    chapter, you learned how to make a recommendation engine for an e-commerce product.
    In the baseline approach, we used the concept of TF-IDF and cosine similarity.
    In the revised approach, we built a book recommendation system that used the concept
    of correlation. In the best approach, we used the KNN algorithm to build a recommendation
    engine that used a collaborative-filtering-based approach. We looked at the advantages
    and disadvantages of all the approaches. You also learned about the architecture
    of the recommendation system. All these topics will help you understand and build
    your own recommendation system. You can also build a computer vision-based recommendation
    engine. This kind of recommendation engine really changes the way content is recommended
    to the users. So don't hesitate to build new types of recommendation systems.
  prefs: []
  type: TYPE_NORMAL
- en: From the next chapter onward, we will be addressing the applications that belong
    to the natural language processing domain or the natural language generation domain.
    The next chapter is all about sentiment analysis, which is a well-known and simple
    NLP application. We will be using a variety of Machine Learning algorithms to
    achieve the best possible result.
  prefs: []
  type: TYPE_NORMAL
