- en: 'Chapter 11: Monitoring Production Models with Amazon SageMaker Model Monitor
    and Clarify'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitoring production **machine learning** (**ML**) models is a critical step
    to ensure that the models continue to meet business needs. Besides the infrastructure
    hosting the model, there are other important aspects of ML models that should
    be monitored regularly. As models age over a period of time, the real-world inference
    data distribution may change as compared to the data used for training the model.
    For example, consumer purchase patterns may change in the retail industry and
    economic conditions such as mortgage rates may change in the financial industry.
  prefs: []
  type: TYPE_NORMAL
- en: This gradual misalignment between the training and the live inference datasets
    can have a big impact on model predictions. Model quality metrics such as accuracy
    may degrade over time as well. Degraded model quality has a negative impact on
    business outcomes. Regulatory requirements, such as ensuring that ML models are
    unbiased and explainable, add another angle to model monitoring. Comprehensive
    monitoring of production models for these aspects allows you to proactively identify
    if and when a production model needs to be updated. Updating a production model
    needs both retraining and deployment resources. The costs involved in updating
    a production model should be weighed against the opportunity costs of effectively
    serving the model consumers.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter addresses the challenge of monitoring production models using two
    managed services – **Amazon SageMaker Model Monitor** and **Amazon SageMaker Clarify**.
    These managed services eliminate the need to build custom tooling to monitor models
    and detect when corrective actions need to be taken. By the end of this chapter,
    you will be able to monitor production models for data drift, model quality, model
    bias, and model explainability. You will further learn how to automate remediation
    actions for the issues detected during monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic concepts of Amazon SageMaker Model Monitor and Amazon SageMaker Clarify
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: End-to-end architectures for monitoring ML models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practices for monitoring ML models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need an AWS account to run the examples included in this chapter. If
    you have not set up the data science environment yet, please refer to [*Chapter
    2*](B17249_02_Final_JM_ePub.xhtml#_idTextAnchor039), *Data Science Environments*,
    which walks you through the setup process.
  prefs: []
  type: TYPE_NORMAL
- en: The code examples included in the book are available on GitHub at [https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter11](https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter11).
    You will need to install a Git client to access them ([https://git-scm.com/](https://git-scm.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: Basic concepts of Amazon SageMaker Model Monitor and Amazon SageMaker Clarify
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, let''s review the capabilities provided by two SageMaker features:
    Model Monitor and Clarify.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon SageMaker Model Monitor provides capabilities to monitor data drift
    and the model quality of models deployed as SageMaker real-time endpoints. Amazon
    SageMaker Clarify provides capabilities to monitor the deployed model for bias
    and feature attribution drift. Using a combination of these two features, you
    can monitor the following four different aspects of ML models deployed on SageMaker:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data drift**: If the live inference traffic data served by the deployed model
    is statistically different from the training data the model was trained on, the
    model prediction accuracy will start to deteriorate. Using a combination of a
    training data baseline and periodic monitoring to compare the incoming inference
    requests with the baseline data, SageMaker Model Monitor detects data drift. Model
    Monitor further generates data drift metrics that are integrated with Amazon CloudWatch.
    Using these CloudWatch alerts, you can generate data drift detection alerts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model quality**: Monitoring model quality involves comparing labels predicted
    by a model to the actual labels, also called the ground truth inference labels.
    Model Monitor periodically merges data captured from real-time inferences with
    the ground truth labels to compare model quality drift against a baseline generated
    with training data. Similar to data drift metrics, model quality metrics are integrated
    with CloudWatch, so alerts can be generated if the model quality falls below a
    threshold.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bias drift**: Statistically, significant drift between the live inference
    traffic data and the training data could also result in bias in the model over
    a period of time. This could happen even after detecting and addressing bias in
    the training data before training and deploying the model. SageMaker Clarify continuously
    monitors a deployed model for bias and generates bias metrics that are integrated
    with CloudWatch metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature attribution drift**: Along with introducing bias in deployed models,
    drift in live inference data distribution can also cause drift in feature attribution
    values. Feature attribution ranks the individual features of a dataset according
    to their relative importance to a model trained using that dataset using an importance
    score. The feature importance score provides one way of explaining the model predictions
    by providing insight into which features played a role in making predictions.
    SageMaker Clarify compares the feature attribution or feature rankings in the
    training data to the feature attribution or feature rankings in live inference
    traffic data. Similar to other types of monitoring, feature attribution drift
    metrics are generated and integrated with CloudWatch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Monitoring an ML model with SageMaker Model Monitor or SageMaker Clarify involves
    four high-level steps, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – High-level steps for model monitoring'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_11_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.1 – High-level steps for model monitoring
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what is involved in each of these steps in a bit more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enable data capture**: The first step is to enable data capture on the real-time
    endpoint. On enabling data capture, input to and output from the SageMaker endpoint
    is captured and saved in Amazon **Simple Storage Service** (**S3**). Input captured
    includes the live inference traffic requests and output captured includes predictions
    from the deployed model. This is a common step for all four types of monitoring:
    data drift, model quality, bias drift, and feature attribution drift monitoring.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Generate baseline**: In this step, the training or validation data is analyzed
    to generate a baseline. The baseline generated will be further used in the next
    step to compare against the live inference traffic. The baseline generation process
    computes metrics about the data analyzed and suggests constraints for the metrics.
    The baseline generated is unique to the type of monitoring.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Schedule and execute monitoring job**: To continuously monitor the real-time
    endpoint, the next step is to create a monitoring schedule to execute at a predefined
    interval. Once the monitoring schedule is in place, SageMaker Processing jobs
    are automatically kicked off to analyze the data captured from the endpoint in
    a specific interval. For each execution of the monitoring job, the processing
    job compares live traffic data captured with the baseline. If the metrics generated
    on the live traffic data captured in a period are outside the range of constraints
    suggested by the baseline, a violation is generated. The scheduled monitoring
    jobs also generate monitoring reports for each execution, which are saved in an
    S3 bucket. Additionally, CloudWatch metrics are also generated, the exact metrics
    being unique to the type of monitoring.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analyze and act on results**: Reports generated by the monitoring job can
    either be downloaded directly from S3 or visualized in a SageMaker Studio environment.
    In the Studio environment, you can also visualize the details of the monitoring
    jobs and create charts that compare the baseline metrics with the metrics calculated
    by the monitoring job.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To remediate issues discovered, you can use the CloudWatch metrics emitted from
    the monitoring job. The specific metrics depend on the type of the monitoring
    job. You can configure CloudWatch alerts for these metrics, based on the threshold
    values suggested by the baseline job. CloudWatch alerts allow you to automate
    responses to violations and metrics generated by monitoring jobs.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know what aspects of an ML model can be monitored, what the steps
    involved in monitoring are, and how you can respond to the issues discovered,
    you can build a monitoring solution that meets your business needs. In the next
    section, you will learn how to build end-to-end model monitoring architectures
    for the different types of monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end architectures for monitoring ML models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will put together the four high-level steps of monitoring
    to build end-to-end architectures for **data drift**, **model quality**, **bias
    drift**, and **feature attribution drift monitoring**. Along with the architecture,
    you will dive into the unique aspects of the individual steps as applicable to
    each type of monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: For all four types of monitoring, the first and last steps – enabling data capture
    and analyzing monitoring results – remain the same. We will discuss these two
    steps in detail for the first type of monitoring – data drift monitoring. For
    the other three types of monitoring, we will only briefly mention them.
  prefs: []
  type: TYPE_NORMAL
- en: Data drift monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You monitor a production model for data drift to ensure that the distribution
    of the live inference traffic the deployed model is serving does not drift away
    from the distribution of the dataset used for training the model. The end-to-end
    architecture for the monitoring model for data drift is shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Data drift monitoring: end-to-end architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_11_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.2 – Data drift monitoring: end-to-end architecture'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s dive into the four high-level steps involved in this end-to-end architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enable data capture for the deployed endpoint**: The first step is to deploy
    a SageMaker endpoint with data capture enabled. As you can see from the following
    sample code, configuring data capture includes specifying the percentage of inference
    traffic to capture and the S3 location to save the captured traffic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To deploy the model, create the endpoint by passing in the data capture configuration
    as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following code shows a sample of the data captured. As you can see, both
    the request to and response from the endpoint along with event metadata are captured:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`DefaultModelMonitor` to configure the infrastructure to execute the processing
    job on and the maximum runtime. Sample code is shown as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `suggest_baseline` method on `DefaultModelMonitor` to configure and
    kick off the baseline job. To configure the baseline job, specify where the baseline
    data is and where you want the baseline results to be saved in S3, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The baseline job results in two files – `statistics.json` and `constraints.json`
    – saved in the S3 location you specified. The `statistics.json` file includes
    metadata analysis of the training data – such as sum, mean, min, and max values
    for numerical features and distinct counts for text features.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This baseline job uses a SageMaker-provided container called `sagemaker-model-monitor-analyzer`
    to analyze the training dataset. This Spark-based container uses the open source
    `constraints.json` file captures the thresholds for the statistics for monitoring
    purposes. The constraints also include conditions such as whether a particular
    feature should be considered a string, not an integer or whether a specific field
    should be not-null. The following screenshot shows a sample of constraints generated
    by the baseline job, which indicates that the `value` feature should always be
    treated as a string:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Constraints generated by the data drift baseline job'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B17249_11_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 11.5 – Constraints generated by the data drift baseline job
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The generated constraints also suggest completeness for each feature, which
    represents the percentage of values that can be non-null in the inference traffic.
    In this example, since completeness for all features is at `1.0`, there cannot
    be any null values of these features in the inference traffic. Additionally, as
    suggested by `num_constraints.is_non_negative`, none of the integral and fractional
    features can be null.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The constraints generated are suggestions provided by the baseline job after
    analyzing the training data. You can choose to override the constraint file based
    on the domain knowledge you have about your specific use case. You can override
    the suggested constraint at the individual field level or override the entire
    file. In the `constraints.json` file, you will also see an `emit_metrics : Enabled`
    entry. This suggests that CloudWatch metrics will be emitted during monitoring.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`Completeness` and `BaselineDrift`. The `Completeness` metric indicates the
    percentage of values that can be null for a given feature in a specific interval.
    The `BaselineDrift` metric indicates how much a feature has drifted in a specific
    interval from the baseline. Additionally, for numerical features, a few other
    metrics emitted are `Max`, `Min`, `Sum`, `SampleCount`, and `AverageCount`, as
    observed during the interval.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For any of these metrics, you can configure a CloudWatch alert to be triggered
    based on threshold values suggested in the constraints file. If the feature values
    in the inference traffic observed during a given interval violate the threshold
    values, an alert is raised.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Analyze and act on results**: The final step is to analyze and act on the
    monitoring results. As mentioned in the high-level monitoring steps discussion
    earlier, you can download the monitoring reports from S3 and analyze them in your
    notebook environment or use Studio to view the monitoring details. For example,
    downloading the violation report to a notebook environment and viewing the report
    contents shows results similar to the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Violations generated by the data drift monitoring job'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_11_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.7 – Violations generated by the data drift monitoring job
  prefs: []
  type: TYPE_NORMAL
- en: You can decide what actions you want to take on these alerts according to your
    business and operational requirements. You can automate actions such as updating
    the model, updating your training data, and retraining and updating the model
    as a response to the CloudWatch alert triggered.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: An example notebook that provides a complete walk-through of using SageMaker
    Model Monitor for data drift monitoring is provided in the GitHub repo [https://gitlab.com/randydefauw/packt_book/-/blob/main/CH10/data_drift_monitoring/WeatherPredictionDataDriftModelMonitoring.ipynb](https://gitlab.com/randydefauw/packt_book/-/blob/main/CH10/data_drift_monitoring/WeatherPredictionDataDriftModelMonitoring.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: Model quality drift monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You monitor the quality of a production model to ensure that the performance
    of the production model continues to meet your requirements. Model quality is
    measured by different metrics depending on the type of the underlying ML problem.
    For example, for classification problems, accuracy or recall are good metrics
    and **root mean square error** (**RMSE**) is a metric to use with regression problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The end-to-end architecture for monitoring a model for model quality drift
    is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Model quality monitoring: end-to-end architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_11_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.8 – Model quality monitoring: end-to-end architecture'
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture is very similar to data drift monitoring with an additional
    step for merging the actual inference ground truth labels in an S3 bucket with
    the model predictions. Let''s dive into the four high-level steps involved in
    this end-to-end architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enable data capture for the deployed endpoint**: The first step is to deploy
    a SageMaker endpoint with data capture enabled and capture predictions made by
    the model in an S3 bucket.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`probability`, `prediction`, and `label`. While `probability` is the values
    returned by the model, `prediction` is inferred from the probability based on
    a threshold value. `label` represents the ground truth label from the validation
    set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For model quality monitoring, you use `ModelQualityMonitor` to configure the
    infrastructure to execute the processing jobs and the maximum runtime, as shown
    in the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `suggest_baseline` method to configure and kick off the baseline job.
    To configure the baseline job, specify where the baseline data is and where you
    want the baseline results to be saved in S3, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The baseline job results in two files – `statistics.json` and `constraints.json`
    – saved in the S3 location you specified.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following figure shows the statistics generated by the baseline job:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Statistics generated by the model quality baseline job'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B17249_11_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 11.9 – Statistics generated by the model quality baseline job
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Similarly, the following figure also shows the statistics generated by the
    baseline job:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Constraints generated by the model quality baseline job'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B17249_11_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 11.10 – Constraints generated by the model quality baseline job
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As you can see in *Figure 11.10*, one of the constraints generated is for the
    `rmse` model. It suggests that if the `rmse` value of the production model is
    greater than `3.87145` in any interval, it is an indication that the model quality
    is degrading. If any of the constraints suggested by the baseline job are either
    too restrictive or too lenient for your requirements, you can modify the constraints
    file.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`confusion_matrix`, `recall`, and `precision`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For a complete list of metrics generated, please review the SageMaker documentation
    at [https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For any of these metrics, you can configure a CloudWatch alert to be triggered
    based on threshold values suggested in the constraints file. If model predictions
    for the inference traffic observed during a given interval violate the threshold
    values, a CloudWatch alert is raised.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Analyze and act on results**: Finally, to analyze and act on the monitoring
    results, similar to the draft drift monitoring results, you can access the monitoring
    reports directly from S3, visualize them in your notebook or Studio environment,
    and finally, automate responses to the CloudWatch alerts raised.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An example notebook that provides a complete walk-through of using SageMaker
    Model Monitor for quality model monitoring is provided in the GitHub repo [https://gitlab.com/randydefauw/packt_book/-/blob/master/CH10/model_quality_monitoring/WeatherPredictionModelQualityMonitoring.ipynb](https://gitlab.com/randydefauw/packt_book/-/blob/master/CH10/model_quality_monitoring/WeatherPredictionModelQualityMonitoring.ipynb).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Bias drift monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The concept of bias relates to the individual features of a dataset. Bias is
    typically measured for sensitive features called facets to identify whether any
    particular feature or a set of feature values are disproportionately represented
    in the dataset. Amazon Clarify provides capabilities to detect and monitor bias
    in a pre-training dataset and deployed models. The end-to-end architecture to
    monitor deployed models for bias drift is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – Bias drift and feature attribution monitoring: end-to-end
    architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_11_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.11 – Bias drift and feature attribution monitoring: end-to-end architecture'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s dive into the four high-level steps involved in this end-to-end architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enable data capture for the deployed endpoint**: The first step for bias
    drift monitoring remains the same as other types of monitoring – enabling data
    capture while deploying a SageMaker endpoint.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`DataConfig`. Sample code is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Details of sensitive features along with threshold values considered as bias
    are captured by `BiasConfig`. In the following code, we are monitoring for bias
    drift in the `"City"` feature:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To calculate the bias metrics, a deployed model to execute inferences is necessary.
    `ModelConfig` captures this model''s related information as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, `ModelPredictedLabelConfig` indicates how to extract a predicted label
    from the model output. For example, the following sample code indicates a prediction
    of `1` if the probability returned by the model is above `0.8`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With `DataConfig`, `BiasConfig`, `ModelConfig`, and `ModelPredictedLabelConfig`
    in hand, you are ready to create and kick off a baseline job. Sample code is as
    follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: During the baseline job execution, SageMaker creates a temporary endpoint called
    a **shadow endpoint**. A baselining job runs predictions on the validation dataset,
    calculates bias metrics, and suggests constraints on these metrics. Once the bias
    metrics are computed, the shadow endpoint is deleted.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Baseline job execution results in a constraints file that shows the bias metric
    values computed along with the suggested thresholds. A sample of the constraints
    generated is shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Schedule and execute a model quality monitoring job**: The next step is to
    schedule a bias drift monitoring job. In this step, the monitored bias of the
    model will be compared against the baseline generated in the previous step. SageMaker
    executes the bias drift monitoring job using SageMaker Processing periodically
    according to the schedule you specify. The bias drift monitoring job generates
    a monitoring report and constraint violations along with CloudWatch metrics.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analyze and act on results**: Finally, analyzing the monitoring results and
    taking remedial actions is similar to the previous monitoring types.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implementation of the end-to-end flow of this architecture is provided in the
    notebook. Review the notebook and the results of the execution to view the bias
    metrics generated.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: An example notebook that provides a complete walk-through of using SageMaker
    Model Monitor for quality model monitoring is provided in the GitHub repo [https://gitlab.com/randydefauw/packt_book/-/blob/master/CH10/bias_drift_monitoring/WeatherPredictionBiasDriftMonitoring.ipynb](https://gitlab.com/randydefauw/packt_book/-/blob/master/CH10/bias_drift_monitoring/WeatherPredictionBiasDriftMonitoring.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: Feature attribution drift monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Feature attribution ranks the individual features of a dataset according to
    their relative importance to a model trained using that dataset using an importance
    score. The feature importance score provides one way of explaining the model predictions
    by providing insight into which features played a role in making predictions.
    With continuous monitoring of the model, you can identify when the feature attribution
    of the live inference traffic starts to drift away from the feature attribution
    of the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The end-to-end flow for monitoring feature attribution drift is the same as
    the flow for bias drift monitoring as previously shown in *Figure 11.11*. Let''s
    dive into the four high-level steps involved in this end-to-end architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enable data capture for the deployed endpoint**: The first step for feature
    attribution drift monitoring remains the same as other types of monitoring – enabling
    data capture while deploying a SageMaker endpoint.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`DataConfig` and `ModelConfig`, which capture the data and model details, are
    the same as for bias drift monitoring.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'However, instead of using `BiasConfig` to capture sensitive features, you will
    need to configure `SHAPConfig`, which captures a baseline dataset to use, a number
    of samples to use in the Kernel SHAP algorithm, and a method for determining global
    SHAP values. Sample code is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For feature attribution drift monitoring, you use `ModelExplainabilityMonitor`
    to configure the infrastructure to execute the processing jobs and the maximum
    runtime, as shown in the following code. `ModelExplainabilityMonitor` explains
    model predictions using the feature importance score and detects feature attribution
    drift:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the different config objects in hand, you can now kick off the baseline
    job as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Baseline job execution results in a constraints file that shows the feature
    importance values computed along with the suggested thresholds. A sample of the
    constraints generated is shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Schedule and execute the model quality monitoring job**: The next step to
    schedule a feature attribution monitoring job is similar to scheduling the bias
    drift monitoring job.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`https://gitlab.com/randydefauw/packt_book/-/blob/master/CH10/bias_drift_monitoring/WeatherPredictionFeatureAttributionDriftMonitoring
    .ipynb`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s now summarize the details of the four different monitoring types. The
    following table shows a summary of the monitoring types discussed so far and brings
    focus to the unique aspects of each monitoring type:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12 – Summary of model monitoring'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_Table-02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.12 – Summary of model monitoring
  prefs: []
  type: TYPE_NORMAL
- en: Now that you can put together end-to-end architecture for monitoring different
    aspects of deployed models using SageMaker Clarify and Model Monitor, in the next
    section, you will learn the best practices of using these capabilities along with
    some limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for monitoring ML models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section discusses best practices for monitoring models using SageMaker
    Model Monitor and SageMaker Clarify, taking into consideration the under-the-hood
    operation of these features and a few limitations as they stand at the time of
    publication of this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Choosing the correct data format**: Model Monitor and Clarify can only monitor
    for drift in tabular data. Therefore, ensure that your training data is in tabular
    format. For other data formats, you will have to build custom monitoring containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Choosing real-time endpoints as the mode of model deployment**: Model Monitor
    and Clarify support monitoring for a single-model real-time endpoint. Monitoring
    a model used with batch transform or multi-model endpoints is not supported. So,
    ensure that the model you want to monitor is deployed as a single-model real-time
    endpoint. Additionally, if the model is part of an inference pipeline, the entire
    pipeline is monitored, not the individual models that make up the pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Choosing sampling data capture – sampling percentage**: When you enable data
    capture on a real-time endpoint, a configuration parameter to pay attention to
    is **sampling percentage**, which indicates what percentage of the live traffic
    is captured. Choosing the values for this metric depends on your use case. It
    is a trade-off between the amount of inference traffic saved and the effectiveness
    of the model monitoring. If the value of this parameter is close to 100, you have
    more information stored, leading to more storage costs, and more data for the
    monitoring job to analyze, leading to a long execution time. On the other hand,
    a higher sampling percentage leads to capturing more inference traffic patterns
    to compare against the baseline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your production model is operating in dynamic environments such as retail
    or financial services, where the consumer behavior or environment factors often
    change, impacting the model predictions, the best practice is to use a sampling
    percentage of 100.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Choosing a dataset for baseline generation**: For generating the baseline,
    the training dataset is typically a good dataset to use. For baseline generation,
    keep in mind that the first column in the training dataset is considered to be
    the label. Besides the label, ensure that the number and order of the features
    in the inference traffic match the training dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, for bias drift and feature attribution drift, the baseline generation
    process stands up a shadow endpoint to collect predictions from. So, consider
    the limit of the number of active endpoints in your AWS account when executing
    a baseline job.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Choosing the monitoring schedule execution frequency**: Monitoring jobs,
    as you have seen so far, are executed on a periodic basis where the minimum interval
    length is 1 hour. This minimum interval is necessary because enough inference
    traffic needs to be collected to be compared against the baseline. When determining
    the monitoring execution frequency, you should select this interval based on the
    inference traffic your model is serving. For example, a model deployed as part
    of a busy e-commerce website may serve higher traffic volumes, so running a monitoring
    job every few hours will give you the chance to detect data and model quality
    issues quickly. However, every time a monitoring job is executed, it adds to your
    model monitoring costs. The monitoring job schedule should therefore consider
    the trade-off between the ability to robustly detect model issues and monitoring
    costs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: There could be a delay of 0-20 minutes between the scheduled time and execution
    of the monitoring job.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`StartOffset` and `EndOffset` fields of the `ModelQualityJobInput` parameter.
    `StartOffset` specifies the time subtracted from the start time and `EndOffset`
    specifies the time subtracted from the end time of the monitoring job. Offsets
    are in the format of `-P#D`, `-P#M`, or `-P#H`, where `D`, `M`, and `H` represent
    days, minutes, and hours, respectively, and `#` is the number. For example, a
    `-P7H` value of `StartOffset` will cause the monitoring job to start 7 hours after
    the scheduled time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, ensure that the monitoring schedule cadence is such that any given
    execution should be completed before the subsequent execution starts, allowing
    both the ground truth merge job and the monitoring job to complete for each interval.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Automating remediation actions**: While a monitoring solution proactively
    detects the data and model issues, without a proper plan to act on the issues,
    you cannot ensure the model''s continued ability to meet your business needs.
    To reap the benefits of the model monitoring alerts generated, as much as possible,
    automate actions that you need to perform as a result. For example, automate notifications
    sent to operations and data science teams about possible data and model issues.
    Similarly, automate collecting or importing new training data and triggering re-training
    and testing of the models in non-production environments such as dev/QA and staging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sagemaker-model-monitor-analyzer` that provides the capabilities we have reviewed
    in this chapter so far. This Spark-based container built on the open source Deequ
    framework provides a range of capabilities, such as generating statistics, suggesting
    constraints, validating constraints against a baseline, and emitting CloudWatch
    metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whenever possible, choose to use this built-in container since SageMaker takes
    on the burden of securing, managing, and updating this container with new capabilities.
    You can extend the capabilities of this container by providing your own preprocessing
    and postprocessing scripts. For example, you can use a custom preprocessing script
    to make small changes to data, such as converting from an array to flattened JSON
    as required by the baseline job. Similarly, you can perform postprocessing to
    make changes to monitoring results.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In addition to using the SageMaker-provided container, you can also use your
    own containers for custom monitoring. Custom containers allow you to build your
    own monitoring schedules as well as your own logic for generating custom statistics,
    constraints, and violations, along with custom CloudWatch metrics. When creating
    a custom container, you should follow the input and output contracts published
    by SageMaker. Additionally, you will be responsible for registering, managing,
    and updating this custom container.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Including human reviews in the monitoring workflow**: For some critical ML
    applications, say, for example, a financial loan approval application, it will
    often be necessary to include human reviewers in the monitoring loop. Especially
    when the ML model returns predictions with low confidence, human experts need
    to ensure that the predictions are valid. Amazon A2I allows you to configure custom
    monitoring workflows to include human experts to review predictions from SageMaker
    models. Please see the *References* section for a link to a detailed blog on configuring
    custom human-in-the-loop workflows using SageMaker and Amazon A2I.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the best practices discussed in this section to create model monitoring
    configurations that best meet your business and organizational requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned the importance of monitoring ML models deployed
    in production and the different aspects of models to monitor. You dove deep into
    multiple end-to-end architectures to build continuous monitoring, automate responses
    to detected data, and model issues using SageMaker Model Monitor and SageMaker
    Clarify. You learned how to use the various metrics and reports generated to gain
    insight into your data and model.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we concluded with a discussion on the best practices for configuring
    model monitoring. Using the concepts discussed in this chapter, you can build
    a comprehensive monitoring solution to meet your performance and regulatory requirements,
    without having to use various different third-party tools for monitoring various
    aspects of your model.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will introduce end-to-end ML workflows that stitch all
    the individual steps involved in the ML process together.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For additional reading material, please review the following reference:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Automated monitoring of your ML models with Amazon SageMaker Model Monitor
    and sending predictions to human review workflows using Amazon A2I:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/blogs/machine-learning/automated-monitoring-of-your-machine-learning-models-with-amazon-sagemaker-model-monitor-and-sending-predictions-to-human-review-workflows-using-amazon-a2i](https://aws.amazon.com/blogs/machine-learning/automated-monitoring-of-your-machine-learning-models-with-amazon-sagemaker-model-monitor-and-sending-predictions-to-human-review-workflows-using-amazon-a2i)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
