- en: 'Chapter 8: Understanding Deep Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we have examined the many tools and methods within the
    fields of supervised and unsupervised machine learning. Within the field of unsupervised
    learning, we explored **clustering** and **dimensionality reduction**, while within
    the field of supervised learning, we explored **classification** and **regression**.
    Within all of these fields, we explored many of the most popular algorithms for
    developing powerful predictive models for our datasets. However, as we have seen
    with some of the data we have worked with, there are numerous limitations when
    it comes to these models' performance that cannot be overcome by additional tuning
    and hyperparameter optimization. In cases such as these, data scientists often
    turn to the field of **deep learning**.
  prefs: []
  type: TYPE_NORMAL
- en: If you recall our overarching diagram of the artificial intelligence space that
    we saw in *Chapter 5*, *Introduction to Machine Learning*, we noted that the overall
    space is known as **Artificial Intelligence** (**AI**). Within the AI space, we
    defined machine learning as the ability to develop models to learn or generalize
    from data and make predictions. We will now explore a subset of machine learning
    known as **deep learning**, which focuses on developing models and extracting
    patterns within data using deep neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout this chapter, we will explore the ideas of neural networks and deep
    learning as they relate to the field of biotechnology. In particular, we will
    be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the field of deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the types of deep learning models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting an activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring progress with loss
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing models with the Keras library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tutorial – protein sequence classification via LSTMs using Keras and MLflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tutorial – anomaly detection using AWS Lookout for Vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these sections in mind, let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the field of deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned in the introduction, deep learning is a subset or branch of
    the machine learning space that focuses on developing models using neural networks.
    The idea behind using neural networks for deep learning derives from neural networks
    found in the human brain. Let's learn more about this.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Similar to machine learning, the idea behind developing deep learning models
    is not to explicitly define the steps in which a decision or prediction is made.
    The main idea here is to generalize from the data. Deep learning makes this possible
    by drawing a parallel between the dendrites, cell body, and synapses of the human
    brain, which, within the context of deep learning, act as inputs, nodes, and outputs
    for a given model, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Comparison between the human brain and a neural network ](img/B17761_08_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Comparison between the human brain and a neural network
  prefs: []
  type: TYPE_NORMAL
- en: Some of the biggest benefits behind such an implementation revolve around the
    idea of feature engineering. Earlier in this book, we saw how features can be
    created or summarized using various methods such as basic mathematical operations
    (x2) or through complex algorithms such as **Principal Component Analysis** (**PCA**).
    Manually engineered features can be very time-consuming and not feasible in practice,
    which is where the field of deep learning can come in, with the ability to learn
    the many underlying features in a given dataset directly from the data.
  prefs: []
  type: TYPE_NORMAL
- en: Within the field of **biotechnology**, most applications, ranging from the early
    stages of therapeutic discovery all the way downstream to manufacturing, are generally
    data-rich processes. However, much of the data that's been collected will have
    little to no use on its own, or perhaps the data that's been collected is for
    different batches of a particular molecule. Perhaps the data is extensive for
    some molecules and less extensive for others. In many of these cases, using deep
    learning models can come to your aid when it comes to features that are relative
    to the traditional machine learning models we have discussed so far.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can think of features at three different levels:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Low-level features**, such as individual amino acids, a protein, or the elements
    of a small molecule.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mid-level features**, such as the amino acid sequences of a protein and the
    functional groups of a small molecule.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High-level features**, such as the overall structure or the classification
    of a protein or the geometric shape of a small molecule.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows a graphical representation of these features:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – The three types of features and some associated examples ](img/B17761_08_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – The three types of features and some associated examples
  prefs: []
  type: TYPE_NORMAL
- en: 'In many instances, architecting a robust deep learning model can unlock a more
    powerful predictive model relative to its machine learning counterpart. In many
    of the machine learning models we have explored, we attempted to improve the model''s
    performance not only by tuning and adjusting the hyperparameters but also by making
    a conscious decision to use datasets with a sufficient amount of data. Increasing
    the size of the datasets will likely not lead to any significant improvement in
    our machine learning models. However, this is not always the case with deep learning
    models, which tend to improve in performance when more data is made available.
    We can see a visual depiction of this in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – A graphical representation of machine learning versus deep learning
    ](img/B17761_08_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – A graphical representation of machine learning versus deep learning
  prefs: []
  type: TYPE_NORMAL
- en: Using neural networks within the context of machine learning has seen a major
    surge in recent years, which can be attributed to the increased use of big data
    within most industries, the decreased expense of computational hardware such as
    CPUs and GPUs, and the growing community that supports much of the open source
    software and packages that are available today. Two of the most common packages
    out there for developing deep learning models are TensorFlow and Keras – we will
    explore these two later in this chapter. Before we do, let's go ahead and talk
    about the architecture behind a deep learning model.
  prefs: []
  type: TYPE_NORMAL
- en: The perceptron
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the most important building blocks of any deep learning model is the
    perceptron. A perceptron is an algorithm that''s used for developing supervised
    binary classifiers, first invented in 1958 by Frank Rosenblatt, who is sometimes
    called the father of deep learning. A perceptron generally consists of four major
    parts:'
  prefs: []
  type: TYPE_NORMAL
- en: The **input** values, which are generally taken from a given dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **weights**, which are values by which the input values are multiplied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **net sum**, which is the sum of all the values from each of the inputs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **activation function**, which maps a resulting value to an output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows a graphical representation of these four parts
    of a perceptron:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – A graphical representation of a perceptron ](img/B17761_08_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – A graphical representation of a perceptron
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three main steps that a perceptron takes to arrive at a predicted
    output from a given set of input values:'
  prefs: []
  type: TYPE_NORMAL
- en: The **input values** (x1, x2, and so on) are multiplied by their respective
    weights (w1, w2, and so on). These weights are determined in the training process
    for this model so that a different weight is assigned to each of the input values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All the values from each of the calculations are summed together in a value
    known as the **weighted sum**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The weighted sum is then applied to the **activation function** to map the value
    to a given output. The specific activation function that's used is dependent on
    the given situation. For example, within the context of a unit step activation
    function, values would either be mapped to 0 or 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When viewed from a mathematical perspective, we can define the output value,
    ![](img/Formula_B17761__08_016.png), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B17761__08_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this equation, *g* is the activation function, *w*o is the bias, and the
    final components are the sum of the **linear combination** of input values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B17761__08_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So, in this equation, ![](img/Formula_B17761__08_003.png) and ![](img/Formula_B17761__08_004.png)
    account for the final output value.
  prefs: []
  type: TYPE_NORMAL
- en: A perceptron is one of the simplest deep learning building blocks out there
    and can be expanded quite drastically by increasing the number of **hidden layers**.
    Hidden layers are the layers that lay in-between the input and output layers.
    Models with very few hidden layers are generally referred to as **neural networks**
    or multilayer perceptrons, whereas models with many hidden layers are referred
    to as **deep neural networks**.
  prefs: []
  type: TYPE_NORMAL
- en: Each of these layers consists of several **nodes**, and the flow of data is
    similar to that of the perceptron we saw previously. The number of input nodes
    (*x*1*, x*2*, x*3) generally corresponds to the number of **features** in a given
    dataset, whereas the number of output nodes generally corresponds to the number
    of outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram is a graphical representation of the difference between
    neural networks and deep learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Difference between neural networks and deep learning ](img/B17761_08_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – Difference between neural networks and deep learning
  prefs: []
  type: TYPE_NORMAL
- en: In the previous diagram, we can see the neural network or multilayer perceptron
    (on the left) consisting of an input layer, a single hidden layer with four nodes,
    and an output layer with four nodes. Similar to the single perceptron we saw earlier,
    the idea here is that each of the nodes within the hidden layer will intake the
    input nodes, multiplied by some value, and then pass them through an **activation
    function** to yield output. On the right, we can see a similar model, but the
    values are passed through several hidden layers before determining a final output
    value.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the different types of deep learning models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many different types of neural networks and deep learning architectures
    out there that differ in function, shape, data flow, and much more. There are
    three types of neural networks that have gained a great deal of popularity in
    recent years, given their promise and robustness with various types of data. First,
    we will explore the simplest of these architectures, known as a multilayer perceptron.
  prefs: []
  type: TYPE_NORMAL
- en: Multilayer perceptron
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A **Multilayer Perceptron** (**MLP**) is one of the most basic types of **Artificial
    Neural Networks** (**ANNs**). This type of network is simply composed of layers
    in which data flows in a forward manner, as shown in the previous diagram. Data
    flows from the input layer to one or more hidden layers, and then finally to an
    output layer in which a prediction is produced. In essence, each layer attempts
    to learn and calculate certain weights. ANNs and MLPs come in many different shapes
    and sizes: they can have a different number of nodes in each layer, a different
    number of inputs, or even a different number of outputs. We can see a visual depiction
    of this in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Two examples of MLPs ](img/B17761_08_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – Two examples of MLPs
  prefs: []
  type: TYPE_NORMAL
- en: MLP models are generally very versatile but are most commonly used for structured
    tabular data, such as the structured protein classification dataset we have been
    working with. In addition, they can be used for image data or even text data.
    MLPs, however, generally tend to suffer when it comes to sequential data such
    as protein sequences and time-series datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Convolutional Neural Networks** (**CNNs**) are deep learning algorithms that
    are commonly used for processing and analyzing image data. CNNs can take in images
    as input data and restructure them to determine the importance through weights
    and biases, allowing it to distinguish between the features of one image relative
    to another. Similar to our earlier discussion of how deep learning is similar
    to neurons in the brain, CNNs are also analogous to the connectivity of neurons
    in the human brain and the visual cortex when it comes to the sensitivity of regions,
    similar to the concept of receptive fields. One of the biggest areas of success
    for CNN models is their ability to capture spatial dependencies, as well as temporal
    dependencies, in images through the use of filters. We can see a visual representation
    of this in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – A representation of a CNN ](img/B17761_08_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – A representation of a CNN
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take, for example, the idea of creating an image classification model.
    We could use an ANN and convert a 2D image of pixels by flattening it. An image
    with a 4x4 matrix of pixels would now become a 1x16 vector instead. This change
    would cause two main drawbacks:'
  prefs: []
  type: TYPE_NORMAL
- en: The spatial features of the image would be lost, and thereby reduce the robustness
    of any trained model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of input features would increase quite drastically as the image size
    grows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CNNs can overcome this by extracting high-level features from the images, allowing
    them to be quite effective with image-based datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent neural networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Recurrent Neural Networks** (**RNNs**) are commonly used algorithms that
    are generally applied to sequence-based datasets. They are quite similar in architecture
    to the ANNs we discussed earlier, but RNNs can remember their input using internal
    memory, making them quite effective with sequential datasets in which previous
    data is of great importance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take, for example, a protein sequence consisting of various amino acids. To
    predict the class of the protein, or its general structure, the model would not
    only need to know which amino acids were used but the order in which they were
    used as well. RNNs and their many derivatives have been central to the many advances
    in deep learning within the field of biology and biotechnology. We can see a visual
    representation of this in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – A representation of an ANN node versus an RNN node ](img/B17761_08_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 – A representation of an ANN node versus an RNN node
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several advantages when it comes to using RNNs as predictor models,
    with the main benefits being as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Their ability to capture the dependency between data points such as words in
    a sentence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Their ability to share parameters across time steps, thus decreasing the overall
    computational cost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because of this, RNNs have become increasingly popular architectures for developing
    models that solve problems related to scientific sequence data such as proteins
    and DNA, as well as text and time-series data.
  prefs: []
  type: TYPE_NORMAL
- en: Long short-term memory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Long Short-Term Memory** (**LSTM**) models are a type of RNN designed with
    the capability of learning long-term dependencies when handling sequence-based
    problems. Commonly used with text-based data for classification, translation,
    and recognition, LSTMs have gained an unprecedented surge in popularity over the
    years. We can depict the structure of a standard RNN as we did previously, but
    structured slightly differently:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – The inner workings of an RNN versus an LSTM ](img/B17761_08_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 – The inner workings of an RNN versus an LSTM
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, *X*t is an input vector, *h*tis a hidden layer vector,
    and *o*t is an output vector. On the other hand, and using some of the same elements,
    an LSTM can be structured quite similarly. Without diving into too much detail,
    the core idea behind an LSTM is the cell state (the top horizontal line). This
    state operates similarly to a conveyor belt in which data flows linearly through
    it. Gates within the cell are methods that optionally allow information to be
    added to the state. An LSTM has three gates, all leading to the cell state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although LSTM models and their associated diagrams can be quite intimidating
    at first, they have proven their worth time and time again in various areas. Most
    recently, LSTM models have been used as generative models for antibody design,
    as well as classification models for protein sequence-structure classification.
    Now that we have explored several common deep learning architectures, let''s go
    ahead and explore their main components: activation functions.'
  prefs: []
  type: TYPE_NORMAL
- en: Selecting an activation function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recall that, in the previous section, we used an activation function to map
    a value to a particular output, depending on the value. We will define an activation
    function as a mathematical function that defines the output of an individual node
    using an input value. Using the analogy of the human brain, these functions simply
    act as gatekeepers, deciding what will be *fired off* to the next neuron. There
    are several features that an activation function should have to allow the model
    to learn most effectively from it:'
  prefs: []
  type: TYPE_NORMAL
- en: The avoidance of a vanishing gradient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A low computational expense
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Artificial neural networks are trained using a process known as gradient descent.
    For this example, let''s assume that there is a two-layer neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B17761__08_005.jpg)![](img/Formula_B17761__08_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The overall network can be represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B17761__08_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When the weights are calculated in a step known as a backward pass, the result
    becomes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B17761__08_008.jpg)![](img/Formula_B17761__08_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Upon determining the derivative, the function becomes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B17761__08_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If this process were to continue through many layers during the backpropagation
    step, there would be a considerable reduction in the value of the gradient for
    the initial layers, thus halting the model's ability to learn. This is the concept
    of **vanishing gradients**.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, **computational expense** is also a feature that must be
    considered before designing and deploying any given model. The activation functions
    that are applied from one layer to another must be calculated many times, so the
    expense of the calculation should be kept to a minimum to avoid longer training
    periods. The flow of information from an input layer to an output layer is called
    **forward propagation**.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many different types of activation functions out there that are commonly
    used for various purposes. Although this is not a hard rule, some activation functions
    are generally used with specific deep learning layers. For example, `sigmoid`
    and **Tanh** activation functions are commonly used with **RNNs**. Let''s take
    a moment and look at the three most common activation functions you will likely
    encounter in your journey:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10 – Various types of activation functions by model type ](img/B17761_08_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 – Various types of activation functions by model type
  prefs: []
  type: TYPE_NORMAL
- en: 'With some of these types now in mind, let''s go ahead and explore them in a
    little more detail. `sigmoid` functions are probably some of the most commonly
    used functions within the field of deep learning. It is a non-linear activation
    function that is also sometimes referred to as a logistic function (remember logistic
    regression? Hint hint). `sigmoid` functions are unique in the sense that they
    can map values to either a 0 or a 1\. Using the `numpy` library, we can easily
    put together a `Python` function to calculate it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this function alongside the `numpy` library, we can generate some data
    and plot our `sigmoid` function accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In return, we yield the following diagram, showing the curved nature of a `sigmoid`
    function. Notice how the upper and lower ranges are 1 and 0, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11 – A simple sigmoid function ](img/B17761_08_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.11 – A simple sigmoid function
  prefs: []
  type: TYPE_NORMAL
- en: One of the biggest issues with a `sigmoid` activation function is that the outputs
    can **saturate** in the sense that values greater than 1.0 are mapped to one,
    and values that are smaller than 0 are mapped to 0\. This can cause some models
    to fail to generalize or learn from the data and is related to the vanishing gradients
    issue we discussed earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, another common activation function is `sigmoid` function.
    The Tanh function is symmetric in the sense that it passes through the point (0,
    0) and it ranges to the values of 1 and -1, unlike its `sigmoid` counterpart,
    making it a slightly better function. Instead of defining our functions in Python,
    as we did previously, we can take advantage of the optimized functions in the
    `numpy` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon executing this code, we retrieve the following diagram. Notice how the
    center of the diagram is the point (0, 0), while the upper and lower values are
    1.00 and -1.00, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12 – A simple Tanh function ](img/B17761_08_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.12 – A simple Tanh function
  prefs: []
  type: TYPE_NORMAL
- en: Similar to its `sigmoid` counterpart, the `sigmoid`, making it a slightly better
    function to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, yet another commonly used activation function is the **Rectified Linear
    Unit** (**ReLU**). **ReLU** activation functions were specifically developed to
    avoid saturation when handling larger numbers. The non-linear nature of this function
    allows it to learn the patterns within the data, whereas the linear nature of
    the function allows it to be easily interpretable relative to the other functions
    we have seen so far. Let''s go ahead and explore this in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing this code yields the following diagram. Notice how the **ReLU** function
    takes advantage of both the linear and non-linear nature of activation functions,
    giving it the best of both worlds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13 – A simple ReLU function ](img/B17761_08_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.13 – A simple ReLU function
  prefs: []
  type: TYPE_NORMAL
- en: The **ReLU** activation function has become one of the most popular, if not
    **the** most popular, activation function among data scientists because of its
    ease of implementation, and its robust speed within the model development and
    training process. **ReLU** activation functions do, however, have their downsides.
    For example, the function cannot be differentiable when x = 0 (at point 0, 0),
    so **gradient descent** cannot be computed for that value.
  prefs: []
  type: TYPE_NORMAL
- en: Yet another activation function worth mentioning is known as **Softmax**. **Softmax**
    is very different from the other activation functions we have looked at so far
    because it computes a probability distribution for a list of values that are proportional
    to the relative scale of each of the values in the vector, the sum of which always
    equals 1\.
  prefs: []
  type: TYPE_NORMAL
- en: 'Commonly used for `numpy` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon printing the values, we retrieve the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.14 – Results of a Softmax function ](img/B17761_08_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.14 – Results of a Softmax function
  prefs: []
  type: TYPE_NORMAL
- en: The two main advantages that come from using **Softmax** as an activation function
    are that the output values range between 0 and 1 and that they always sum to a
    value of 1.0\. In return, this allows the function to be used to understand cross-entropy
    when it comes to the idea of divergence. We will visit this topic in more detail
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The various activation functions we have visited so far each have their pros
    and cons when it comes to using them in various applications. For example, `sigmoid`
    functions are commonly used for binary and multilabel classification applications,
    whereas **Softmax** functions are generally used for multiclass classification.
    This is not a hard rule, but simply a guide to help you match a function with
    the highest chance of success with its respective application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.15 – Activation functions by problem type ](img/B17761_08_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.15 – Activation functions by problem type
  prefs: []
  type: TYPE_NORMAL
- en: Activation functions are a vital part of any deep learning model and are often
    regarded as *game changers* since simply changing one function for another can
    boost the performance of a model quite drastically. We will take a closer look
    at how model performance can be quantified within the scope of deep learning in
    the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring progress with loss
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we discussed the areas of classification and regression, we outlined a
    few measures to measure and quantify the performance of our models relative to
    one another. When it came to classification, we used **precision** and **accuracy**,
    whereas, in regression, we used **MAE** and **MSE**. Within the confines of deep
    learning, we will use a metric known as **loss**. The **loss** of a neural network
    is simply a measure of the cost that''s incurred from making an incorrect prediction.
    Take, for example, a simple neural network with three input values and a single
    output value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.16 – A neural network showing input and output values ](img/B17761_08_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.16 – A neural network showing input and output values
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we have the values *[2.3, 3.3, 1.2]* being used as input values
    to the model, with a predicted value of 0.2 relative to the actual value of 1.0\.
    We can demonstrate the loss as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B17761__08_011.jpg)![](img/Formula_B17761__08_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In this function, ![](img/Formula_B17761__08_013.png)is the predicted value,
    while ![](img/Formula_B17761__08_014.png) is the actual value.
  prefs: []
  type: TYPE_NORMAL
- en: '**Empirical loss**, on the other hand, is a measure of the total loss for the
    entirety of the dataset. We can represent empirical loss as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B17761__08_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In this function, we sum the total losses for all calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout the model training process, our main objective will be to minimize
    this loss in a process known as **loss optimization**. The main idea behind loss
    optimization is to identify a set of weights that help achieve the lowest loss
    possible. We can visualize the idea of gradient descent as the process of moving
    from an initial starting value with a high loss, to a final value with a low loss.
    Our objective will be to ensure that converge in a global minimum rather than
    a local minimum, as depicted in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.17 – The process of loss optimization ](img/B17761_08_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.17 – The process of loss optimization
  prefs: []
  type: TYPE_NORMAL
- en: Each step we take to get closer to the minimum value is known as a **learning
    step**, the **learning rate** of which is generally determined by the user. This
    parameter is just one of many that we can specify using Keras, which we will learn
    about in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning with Keras
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Within the realm of data science, the availability and use of various **frameworks**
    will always be crucial to standardizing the methods we use to develop and deploy
    models. So far, we have focused our machine learning efforts on using the scikit-learn
    framework. Throughout this section, we will learn about three new frameworks specifically
    focused on deep learning: **Keras**, **TensorFlow**, and **PyTorch**. These two
    frameworks are the two most popular amongst data scientists when it comes to developing
    various deep learning models as they offer a comprehensive list of APIs for numerous
    problems and use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the differences between Keras and TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Although these two platforms allow users to develop deep learning models, there
    are a few differences to know about. TensorFlow is known as an end-to-end machine
    learning platform that offers a comprehensive list of libraries, tools, and numerous
    resources. Users can manage data, develop models, and deploy solutions. Unlike
    most other libraries, **TensorFlow** offers both low and high levels of abstractions
    through their APIs, giving users lots of flexibility when it comes to developing
    models. On the other hand, **Keras** offers high-level APIs for developing neural
    networks, which run using **TensorFlow**. The high-level nature of this library
    allows users to begin developing and training complex neural networks with only
    a few lines of Python code. Keras is generally regarded as user-friendly, modular,
    and extendable. A third library exists that is commonly used in the deep learning
    space known as **PyTorch**. **PyTorch** is a low-level API known for its remarkable
    speed and optimization in the model training process. The architectures within
    this library are generally complex and not appropriate for introductory material,
    so they are not within the scope of this book. However, it is worth mentioning
    as it is one of the most common libraries in the machine learning space that you
    will likely encounter. Let''s take a closer look at all three:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.18 – A comparison between three of the most common deep learning
    frameworks ](img/013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.18 – A comparison between three of the most common deep learning frameworks
  prefs: []
  type: TYPE_NORMAL
- en: There are pros and cons for each of these libraries and you should select one
    of these libraries based on the task you set out to accomplish. Given that we
    are exploring the development of deep learning models for the first time, we will
    focus on using the Keras library.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Keras and ANNs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we move on to a full tutorial, let''s look at an example of using the
    `Keras` library since we have not explored its functionality and code:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we will need some sample data to use. Let's take advantage of the `make_blobs`
    class in `sklearn` to create a `classification` dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will specify the need for two classes (binary classification) and a cluster
    standard deviation of `5` to ensure that the two clusters overlap, making it a
    more difficult dataset to work with:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we can scale the data using the `MinMaxScaler()` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Following this transformation, we can split the data into training and testing
    sets, similar to how we have done previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s go ahead and convert the array into a DataFrame to check the first few
    rows of data beforehand:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will render the following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.19 – An example of the data within the DataFrame of features ](img/B17761_08_019.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 8.19 – An example of the data within the DataFrame of features
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can check the overlap of the two clusters by using the `seaborn` library
    to plot the first two of the four features of the training dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following diagram shows the preceding code''s output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.20 – A scatterplot of the dataset showing the overlapping nature
    of the two classes ](img/B17761_08_020.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 8.20 – A scatterplot of the dataset showing the overlapping nature of
    the two classes
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here, we can see that the data is quite well blended, making it difficult for
    some of the machine learning models we have explored to be able to separate the
    two classes with a high degree of **accuracy**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With the data ready, we can go ahead and use the Keras library. One of the
    most popular methods for setting up a model is using the `Sequential()` class
    from `Keras`. Let''s go ahead and import the class and instantiate a new model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the model now instantiated, we can add a new layer to our model using
    the `Dense` class. We can also specify the number of `nodes` (`4`), `input_shape`
    (`4` for the four features), `activation` (`relu`), and a unique `name` for the
    layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To review the model we have built so far, we can use the `summary()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will give us some information and details about the model so far:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.21 – The sample output of the model''s summary ](img/B17761_08_021.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 8.21 – The sample output of the model's summary
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can add a few more layers to our model by simply using the `model.add()`
    function again after the fact, perhaps even with a different number of nodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Since we are developing a `0` and `1`, we can only have a single output value
    come from the model. Therefore, we will need to add one more layer that reduces
    the number of nodes from 8 to 1\. In addition, we will change the activation to
    `sigmoid`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that our model''s general architecture has been set up, we will need to
    use the compile function and specify our loss. Since we are creating a binary
    classifier, we can use the `binary_crossentropy` loss and specify accuracy as
    our main metric of interest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the model ready, let''s use the summary function to check it once more:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.22 – The sample output of the model''s summary ](img/B17761_08_022.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 8.22 – The sample output of the model's summary
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: So far, the model is quite simple. It will intake a dataset with four features
    in the first layer, expand that to eight nodes in the second layer, and then reduce
    it down to a single output in the third layer. With the model all set, we can
    go ahead and train it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can train a model by using the `model.fit()` function and by specifying the
    `X_train` and `y_train` sets. In addition, we will specify 50 `epochs` to train
    over. **Epochs** are simply the number of passes or iterations. We can also control
    the verbosity of the model, allowing us to control the amount of output data we
    want to see in the training process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Recall that, in our earlier machine learning models, we only used the training
    data to train the model and kept the testing data to test the model after the
    training was completed. We will use the same methodology here as well; however,
    we will take advantage of the high-level nature of `validation split` to be used
    in the training process. Deep learning models will almost always overfit your
    data. Using a validation split in the training process can help mitigate this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As the model begins the training process, it will begin to produce the following
    output. You can monitor the performance here by looking at the number of **epochs**
    on the left and the **metrics** on the right. When training a model, our objective
    is to ensure that the **loss** metric is constantly decreasing, whereas the accuracy
    is increasing. We can see an example of this in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.23 – A sample of a model''s output ](img/B17761_08_023.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 8.23 – A sample of a model's output
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With the model trained, let''s quickly examine the classification metrics,
    as we did previously, to get a sense of the performance. We can begin by making
    predictions using the testing data and using the `classification_report` to calculate
    our metric. Note that the `predict()` method does not return a class but a probability
    that needs to be rounded to either `0` or `1`, given that this is a **binary classification**
    problem:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upon printing the report, we will get the following results:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.24 – The results of the model ](img/B17761_08_024.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 8.24 – The results of the model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can see that the `history` variable, which contains the model''s training
    history:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upon executing this code, we will receive the following diagram, which shows
    the change in accuracy and loss over the course of the model training process:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.25 – The accuracy and loss of the model ](img/B17761_08_025.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.25 – The accuracy and loss of the model
  prefs: []
  type: TYPE_NORMAL
- en: When training a model, recall that the main objective is to ensure that the
    loss is decreasing, and never increasing over time. In addition, our secondary
    objective is to ensure that the accuracy of our model slowly and steadily increases.
    When trying to diagnose a model that is not performing well, the first step is
    to generate graphs such as these to get a sense of any potential problems before
    altering the model in an attempt to improve the metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we worked with most of the machine learning models in the previous chapters,
    we learned that we could alter these metrics by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Improving our data preprocessing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuning our hyperparameters or changing the model. Within the confines of deep
    learning, in addition to the options mentioned previously, there are a few more
    tools we have to change to suit our needs. For instance, we can change the overall
    architecture by adding or removing layers and nodes. In addition, we can change
    the activation functions within each of the layers to whatever would complement
    our problem statement the most. We can also change the optimizer or the learning
    rate of our optimizer (Adam, in this model).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With so many changes that can be made that could have high impacts on any given
    model, we will need to organize our work. We could either create numerous models
    and record our metrics manually in a spreadsheet, or we could take advantage of
    a library specifically designed to handle use cases such as these: **MLflow**.
    We will take a closer look at **MLflow** in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Tutorial – protein sequence classification via LSTMs using Keras and MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning has gained a surge of popularity in recent years, prompting many
    scientists to turn to the field as a new means for solving and optimizing scientific
    problems. One of the most popular applications for deep learning within the biotechnology
    space involves **protein sequence** data. So far within this book, we have focused
    our efforts on developing predictive models when it comes to **structured** data.
    We will now turn our attention to data that's **sequential** in the sense that
    the elements within a sequence bear some relation to their previous element. Within
    this tutorial, we will attempt to develop a protein **sequence classification**
    model in which we will classify protein sequences based on their known family
    accession using the **Pfam** ([https://pfam.xfam.org/](https://pfam.xfam.org/))
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '`Pfam` dataset: Pfam: The protein families database in 2021 J. Mistry, S. Chuguransky,
    L. Williams, M. Qureshi, G.A. Salazar, E.L.L. Sonnhammer, S.C.E. Tosatto, L. Paladin,
    S. Raj, L.J. Richardson, R.D. Finn, A. BatemanNucleic Acids Research (2020) doi:
    10.1093/nar/gkaa913 (`Pfam: The protein families database in 2021`).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Pfam` dataset consists of several columns, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Family_id`: The name of the family that the sequence belongs to (for example,
    filamin)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Family Accession`: The class or output that our model will aim to predict'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Sequence`: The amino acid sequence we will use as input for our model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughout this tutorial, we will use the sequence data to develop several predictive
    models to determine each sequence's associated family accession. The sequences
    are in their raw state with different lengths and sizes. We will need to pre-process
    the data and structure it in such a way as to prepare it for sequence classification.
    When it comes to the labels, we will develop a model using a **balanced** set
    of different labels to ensure the model does not learn any particular bias.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we begin to develop our ideal classification model, we will need to alter
    the many possible parameters to maximize the performance. To keep track of these
    changes, we will make use of the MLflow ([https://mlflow.org](https://mlflow.org))
    library. There are four main components within **MLflow**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**MLflow Tracking**: Allows users to record and query experiments'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MLflow Projects**: Packages data science code'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MLflow Models**: Deploys trained machine learning models'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MLflow Registry**: Stores and manages your models'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Within this tutorial, we will explore how to use MLflow tracking to track and
    manage the development of a protein sequence classification model. With these
    items in mind, let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: Importing the necessary libraries and datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will begin with the standard set of library imports, followed by the dataset
    in the format of a CSV document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'With the libraries now imported, we can import the dataset as well. We will
    begin by specifying the path, and then concatenate the dataset using a `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon importing the dataset, we immediately notice that it contains five columns
    and ~1.3 million rows of data – slightly larger than what we have worked with
    so far. We can take a quick glimpse at the dataset using the `.head()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.26 – A sample of the data from the protein sequence dataset ](img/B17761_08_026.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.26 – A sample of the data from the protein sequence dataset
  prefs: []
  type: TYPE_NORMAL
- en: With the dataset successfully imported, let's go ahead and explore the dataset
    in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can confirm the completeness of the data in this DataFrame using the `isna()`
    function, followed by the `sum()` function to summarize by column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s take a closer look at the `family_accession` column (our model''s
    output) of this dataset. We can check the total number of instances by grouping
    the column and using the `value_counts()` function, followed by the `n_largest()`
    function, to get the top 10 most common entries in this column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Grouping the data will yield the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.27 – A summary of the classes in the dataset with value counts higher
    than 1,200 ](img/B17761_08_027.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.27 – A summary of the classes in the dataset with value counts higher
    than 1,200
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that 1,500 entries seems to be the cutoff point for the top
    10 values. We can also take a closer look at the sequence column (our model''s
    input) by getting a sense of the average lengths of the sequences. We can plot
    the count of each sequence length using the `displot()` function from the `seaborn`
    library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing this code will yield the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.28 – A histogram of the counts of the sequence lengths in the dataset
    ](img/B17761_08_028.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.28 – A histogram of the counts of the sequence lengths in the dataset
  prefs: []
  type: TYPE_NORMAL
- en: From this graph, as well as by using the `mean()` and `median()` functions,
    we can see that the average and most common lengths are approximately 155 and
    100 amino acids. We will use these numbers later when determining what the cutoff
    should be for the input sequences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have gained a better sense of the data, it is time to prepare the
    dataset for our classification models. We could theoretically train the model
    on the dataset as a whole without limits – however, the models would require a
    much longer duration to train. In addition, by training across all the data without
    accounting for balance, we may introduce bias within the model. To mitigate both
    of these situations, let''s reduce this dataset by filtering for the classifications
    with at least 1,200 **observations**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Given that some classes have significantly more than 1,200 observations, we
    can randomly select exactly 1,200 observations using the `sample()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now check the filtered and balanced dataset using the `head()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `head()` function will yield the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.29 – A sample of the data in the form of a DataFrame ](img/B17761_08_029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.29 – A sample of the data in the form of a DataFrame
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check the number of classes we will have in this dataset by checking
    the length of the `value_counts()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If we check the `num_classes` variable, we will see that we have 28 possible
    classes in total.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the data prepared, our next step will be to split the dataset into training,
    testing, and validation sets. We will once again make use of the `train_test_split`
    function from `sklearn` to accomplish this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: With the data now split, let's go ahead and preprocess it.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the data split up, we need to preprocess the datasets to use on our neural
    network models. First, we will need to reduce the sequences down to the 20 most
    common amino acids and convert the sequences into integers. This will speed up
    the training process. First, we will create a dictionary of amino acids that contains
    their corresponding values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can iterate over the sequences and convert the string values into
    their corresponding integers. Note that we will complete this for the training,
    testing, and validation sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will need to pad the sequences to ensure they are all of an equal
    length. To accomplish this, we can use the `pad_sequences` function from `keras`.
    We will specify `max_length` for each of the sequences as 100, given that it approximates
    the median value we saw earlier. In addition, we will pad the sequences with `''post''`
    to ensure that we pad them at the end instead of the front:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We can take a quick glance of the changes we have made using one of the sequences.
    First, we have the raw sequence as a `string`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can encode the sequence to remove uncommon amino acids and convert
    the string to a list of integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can limit the lengths of the sequences to either truncate them
    at 100 elements or **pad** them with zeros to reach 100 elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have preprocessed the input data, we will need to preprocess the
    output values as well. We can do so using the `LabelEncoder` class from `sklearn`.
    Our main objective here will be to transform the values from a list of labels
    in a dataframe column into an encoded list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can use the `to_categorical` function from `sklearn` to transform
    a class vector into a binary class matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'To review the changes we''ve made here, we can use a single column in a `DataFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the results of this in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.30 – A list of the classes ](img/B17761_08_030.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.30 – A list of the classes
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we must encode the classes into a list of numerical values, with each
    value representing a specific class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we must convert the structure into a **binary class matrix** so that
    each row consists of a list of 27 values of zero, and one value of 1, representing
    the class it belongs to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: With that, our datasets have been fully preprocessed and ready to be used in
    the model development phase of the tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: Developing models with Keras and MLflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Similar to our previous example of developing models with the `Keras` library,
    we will once again be using the `Sequential` class:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by importing the layers and other items we will need from Keras:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can create a new instance of a model using the sequential class and
    begin populating it by adding a few layers of interest. We will start by adding
    an embedding layer to convert positive integers into dense vectors. We will specify
    an `input_dim` of `21` to represent the size of the amino acid index + 1, and
    an `output_dim` of 32\. In addition, we will assign an `input_length` equal to
    that of `max_length` – the length of the sequences:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will add an LSTM layer, wrapped in a `Bidirectional` layer, to run
    inputs in both directions – from past to future and from future to past:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will add a `Dropout` layer to help prevent the model from overfitting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we will end with a `Dense` layer and set the number of nodes to `28`
    so that this corresponds with the shape of the outputs. Notice that we use a Softmax
    activation here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the model''s architecture prepared, we can assign an optimizer (Adam),
    compile the model, and check the summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s go ahead and train our model using the `fit()` function and assign
    30 epochs. Notice from our previous tutorial that training deep learning models
    can be very time-consuming and expensive, so training a model that is not learning
    can be a major waste of time. To mitigate situations such as these, we can implement
    what is known as a callback in the sense that Keras can end the training period
    when a model is no longer learning (that is, the loss is no longer decreasing):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can go ahead and log our new run in MLflow by calling the `autolog()`
    function and fitting the model, as we did previously. MLflow offers many different
    methods to log both parameters and metrics, and you are not limited to using just
    `autolog()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assuming you followed these steps correctly, the model will print a note stating
    that MLflow is being used, and you should see a new directory appear next to your
    current notebook. Upon completing the training process, you can plot the results,
    as we did previously, to arrive at the following diagram:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.31 – The accuracy and results of the first iteration of this model
    ](img/B17761_08_031.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.31 – The accuracy and results of the first iteration of this model
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that the accuracy seems to remain stagnant at around 80-85%,
    while the loss remains stagnant at 0.6 to 0.8\. We can see that the model is not
    learning. Perhaps a change of parameters is needed? Let''s go ahead and change
    the number of nodes from `8` to `12` and the learning rate from `0.1` to `0.01`.
    Upon compiling the new model, calling the `autolog()` function, and training the
    new dataset, we will arrive at a new diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.32 – The accuracy and results of the next iteration of this model
    ](img/B17761_08_032.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.32 – The accuracy and results of the next iteration of this model
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that the model''s loss, both for training and validation,
    decreased quite nicely until the callback stopped the training at around 30 epochs
    in. Alternatively, the accuracy shows a sharp increase at the beginning, followed
    by a stable increase toward the end, also stopping at 30 epochs into the process.
    We can keep making our changes and calling the `autolog()` function over and over,
    allowing the system to log the changes and the resulting metrics on our behalf.
    After several iterations, we can review the performance of our models using `mlflow
    ui`. Within the notebook itself, enter the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, navigate to `http://localhost:5000/`. There, you will be able to see
    the `MLflow` UI, where you will be able to view the models, their parameters,
    and their associated metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.33 – An example of the MLflow UI ](img/B17761_08_033.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.33 – An example of the MLflow UI
  prefs: []
  type: TYPE_NORMAL
- en: With that, you can select the best model and move forward with your project.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the model's performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that the best-performing model has been selected, let''s get a better sense
    of its associated `classification_report`, as we did previously, showing almost
    99% for both precision and recall. Alternatively, we can use a confusion matrix
    to get a better sense of the data, given that we have 28 classes in total:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'With the confusion matrix calculated, we can use a heatmap to visualize the
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon executing this, we will get the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.34 – A confusion matrix of the results of the model ](img/B17761_08_034.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.34 – A confusion matrix of the results of the model
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the performance of the model is quite robust as it is
    giving us great results! Keras, TensorFlow, and PyTorch are great packages that
    can help us develop robust and high-impact models to solve specific solutions.
    Often, we will find that there may be a model (or set of models) that already
    exists through AWS that can solve our complex problem with little to no code.
    We will explore an example of this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Tutorial – anomaly detection in manufacturing using AWS Lookout for Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we prepared and trained a deep learning model to classify
    proteins in their given categories. We went through the process of preprocessing
    our data, developing a model, testing the parameters, editing the architecture,
    and selecting a combination that maximized our metrics of interest. While this
    process can generally produce good results, we can sometimes utilize platform
    architectures such as those from AWS to automatically develop models on our behalf.
    Within this tutorial, we will take advantage of a tool known **AWS Lookout for
    Vision** ([https://aws.amazon.com/lookout-for-vision/](https://aws.amazon.com/lookout-for-vision/))
    to help us prepare a model capable of detecting anomalies within a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout this tutorial, we will be working with a dataset consisting of images
    concerned with manufacturing a of **Drug Product** (**DP**). Each of the images
    consists of a vial whose image was captured at the end of the manufacturing cycle.
    Most of the vials are clean and don''t have any impurities. However, some of the
    vials contain minor impurities, as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.35 – An example of an accepted vial versus a damaged vial ](img/B17761_08_035.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.35 – An example of an accepted vial versus a damaged vial
  prefs: []
  type: TYPE_NORMAL
- en: The process of rejecting damaged or impure vials is often done manually and
    can be quite time-consuming. We have been tasked with implementing an automated
    solution to this problem and we only have a few days to do so. Rather than developing
    our own custom deep learning model for detecting anomalies in images, we can utilize
    **Amazon Lookout for Vision**. In this tutorial, we will begin by uploading our
    dataset of images to S3, importing the images into the framework, and begin training
    our model. With that in mind, let's go ahead and get started!
  prefs: []
  type: TYPE_NORMAL
- en: 'Within this book''s GitHub repository, you can find a directory called `vials_input_dataset_s3`,
    which contains a collection of both normal and damaged vials. If we take a closer
    look at our dataset, we will notice that it is constructed using a directory hierarchy,
    as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.36 – An example of an accepted vial versus a damaged vial ](img/B17761_08_036.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.36 – An example of an accepted vial versus a damaged vial
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by importing the images into the same S3 bucket we have been
    working with throughout this book:'
  prefs: []
  type: TYPE_NORMAL
- en: First, navigate to S3 from within the AWS console and select the bucket of interest.
    In this case, I will select **biotech-machine-learning**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, click the orange **Upload** button, select the **vials_input_dataset_s3**
    folder, and click **Upload**. This process may take a few moments, depending on
    your internet connection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, click on the **Copy S3 URI** button at the top right-hand side of the page.
    We will need this URI in a few moments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, our data is available for use to use in our S3 bucket. Next, we can focus
    on getting the data imported with the model and start the model training process:'
  prefs: []
  type: TYPE_NORMAL
- en: To begin, navigate to Amazon Lookout for Vision, which is located in the AWS
    console. Then, click the **Get started** button:![Figure 8.37 – The front page
    of Amazon Lookout for Vision ](img/B17761_08_037.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 8.37 – The front page of Amazon Lookout for Vision
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **Create project** button on the right-hand side of the page and
    give your project a name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the project has been created, go ahead and click the **Create dataset**
    button on the left-hand side of the page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the second option to **Create a training dataset and test dataset**:![Figure
    8.38 – Creating a dataset in AWS Lookout for Vision ](img/B17761_08_038.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 8.38 – Creating a dataset in AWS Lookout for Vision
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, within the `training` to the path, as shown in the following screenshot:![Figure
    8.39 – Creating a dataset in AWS Lookout for Vision ](img/B17761_08_039.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 8.39 – Creating a dataset in AWS Lookout for Vision
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In addition, be sure to select the **Automatic labeling** option to ensure our
    labels are taken in by AWS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat this same process for the test dataset but be sure to add the word `validation`
    instead of training in the S3 URI path. Then, click on **Create dataset**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the dataset has been created, you will be taken to a new page where you
    can visually inspect the dataset''s readiness. Then, you can click the **Train
    model** button located in the top right-hand corner of the page to begin the model
    training process. This process can be time-consuming and may take a few hours:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.40 – The dataset before training the model ](img/B17761_08_040.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.40 – The dataset before training the model
  prefs: []
  type: TYPE_NORMAL
- en: 'By doing this, you will be presented with the final results for the model,
    which will show you the precision, recall, and F1 score, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.41 – The Model performance metrics page ](img/B17761_08_041.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.41 – The Model performance metrics page
  prefs: []
  type: TYPE_NORMAL
- en: With that final step completed, we have successfully developed a robust model
    capable of detecting anomalies in the manufacturing process! Not only were we
    able to create the models in just a few hours, but we managed to do so without
    any code!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Throughout this chapter, we made a major stride to cover a respectable portion
    of the *must-know* elements of deep learning and neural networks. First, we investigated
    the roots of neural networks and how they came about and then dove into the idea
    of a perceptron and its basic form of functionality. We then embarked on a journey
    to explore four of the most common neural networks out there: MLP, CNN, RNN, and
    LSTM. We gained a better sense of how to select activation functions, measure
    loss, and implement our understandings using the Keras library.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we took a less theoretical and much more hands-on approach as we tackled
    our first dataset that was sequential nature. We spent a considerable amount of
    time preprocessing our data, developing our model, getting our model development
    organized with MLflow, and reviewing its performance. Following these steps allowed
    us to create a custom and well-suited model for the problem at hand. Finally,
    we took a no-code approach by using AWS Lookout for Vision to train a model capable
    of detecting anomalies in images of vials.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning and the application of neural networks have most certainly seen
    a major surge over the last few years, and in the next chapter, we will see an
    application of deep learning as it relates to natural language processing.
  prefs: []
  type: TYPE_NORMAL
