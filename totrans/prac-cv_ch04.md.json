["```py\n# load image and convert to grayscale\nimg = cv2.imread('../figures/flower.png')\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# harris corner parameters\nblock_size = 4 # Covariance matrix size\nkernel_size = 3 # neighbourhood kernel\nk = 0.01 # parameter for harris corner score\n\n# compute harris corner\ncorners = cv2.cornerHarris(gray, block_size, kernel_size, k)\n\n# create corner image\ndisplay_corner = np.ones(gray.shape[:2])\ndisplay_corner = 255*display_corner\n# apply thresholding to the corner score\nthres = 0.01 # more than 1% of max value\ndisplay_corner[corners>thres*corners.max()] = 10 #display pixel value\n\n# set up display\nplt.figure(figsize=(12,8))\nplt.imshow(display_corner, cmap='gray')\nplt.axis('off')\n```", "```py\ndef compute_fast_det(filename, is_nms=True, thresh = 10):\n \"\"\"\n Reads image from filename and computes FAST keypoints.\n Returns image with keypoints\n filename: input filename\n is_nms: flag to use Non-maximal suppression\n thresh: Thresholding value\n \"\"\"\n img = cv2.imread(filename)\n\n # Initiate FAST object with default values\n fast = cv2.FastFeatureDetector_create() \n\n # find and draw the keypoints\n if not is_nms:\n fast.setNonmaxSuppression(0)\n\n fast.setThreshold(thresh)\n\n kp = fast.detect(img,None)\n cv2.drawKeypoints(img, kp, img, color=(255,0,0))\n\n return img\n```", "```py\norb = cv2.ORB_create()\n# set parameters orb.setScoreType(cv2.FAST_FEATURE_DETECTOR_TYPE_9_16)\n```", "```py\n# detect keypoints\nkp = orb.detect(img,None)\n```", "```py\n# for detected keypoints compute descriptors. \nkp, des = orb.compute(img, kp)\n```", "```py\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport cv2 \n# With jupyter notebook uncomment below line \n# %matplotlib inline \n# This plots figures inside the notebook\n\ndef compute_orb_keypoints(filename):\n \"\"\"\n Reads image from filename and computes ORB keypoints\n Returns image, keypoints and descriptors. \n \"\"\"\n # load image\n img = cv2.imread(filename)\n\n # create orb object\n orb = cv2.ORB_create()\n\n # set parameters \n # FAST feature type\n orb.setScoreType(cv2.FAST_FEATURE_DETECTOR_TYPE_9_16)\n\n # detect keypoints\n kp = orb.detect(img,None)\n\n # for detected keypoints compute descriptors. \n kp, des = orb.compute(img, kp)\n return img, kp, des\n```", "```py\ndef draw_keyp(img, kp):\n \"\"\"\n Takes image and keypoints and plots on the same images\n Does not display it. \n \"\"\"\n cv2.drawKeypoints(img,kp,img, color=(255,0,0), flags=2) \n return img\n\ndef plot_img(img, figsize=(12,8)):\n \"\"\"\n Plots image using matplotlib for the given figsize\n \"\"\"\n fig = plt.figure(figsize=figsize)\n ax = fig.add_subplot(1,1,1)\n\n # image need to be converted to RGB format for plotting\n ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n plt.axis('off')\n plt.show()\n\ndef main():\n # read an image \n filename = '../figures/flower.png'\n # compute ORB keypoints\n img1,kp1, des1 = compute_orb_keypoints(filename)\n # draw keypoints on image \n img1 = draw_keyp(img1, kp1)\n # plot image with keypoints\n plot_img(img1)\n\nif __name__ == '__main__':\n main()\n```", "```py\ndef compute_orb_keypoints(filename):\n \"\"\"\n Takes in filename to read and computes ORB keypoints\n Returns image, keypoints and descriptors \n \"\"\"\n\n img = cv2.imread(filename)\n # create orb object\n orb = cv2.ORB_create()\n\n # set parameters \n orb.setScoreType(cv2.FAST_FEATURE_DETECTOR_TYPE_9_16)\n\n # detect keypoints\n kp = orb.detect(img,None)\n\n # using keypoints, compute descriptor\n kp, des = orb.compute(img, kp)\n return img, kp, des\n```", "```py\nbf = cv2.BFMatcher(cv2.NORM_HAMMING2, crossCheck=True)\n```", "```py\nmatches = bf.match(des1,des2)\n```", "```py\ndef brute_force_matcher(des1, des2):\n \"\"\"\n Brute force matcher to match ORB feature descriptors\n des1, des2: descriptors computed using ORB method for 2 images\n returns matches \n \"\"\"\n # create BFMatcher object\n bf = cv2.BFMatcher(cv2.NORM_HAMMING2, crossCheck=True)\n # Match descriptors.\n matches = bf.match(des1,des2)\n\n # Sort them in the order of their distance.\n matches = sorted(matches, key = lambda x:x.distance)\n\n return matches\n```", "```py\n\ndef compute_img_matches(filename1, filename2, thres=10):\n \"\"\"\n Extracts ORB features from given filenames\n Computes ORB matches and plot them side by side \n \"\"\"\n img1, kp1, des1 = compute_orb_keypoints(filename1)\n img2, kp2, des2 = compute_orb_keypoints(filename2)\n\n matches = brute_force_matcher(des1, des2)\n draw_matches(img1, img2, kp1, kp2, matches, thres)\n\ndef draw_matches(img1, img2, kp1, kp2, matches, thres=10):\n \"\"\"\n Utility function to draw lines connecting matches between two images.\n \"\"\"\n draw_params = dict(matchColor = (0,255,0),\n singlePointColor = (255,0,0),\n flags = 0)\n\n # Draw first thres matches.\n img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:thres],None, **draw_params)\n plot_img(img3)\n\ndef main():\n # read an image \n filename1 = '../figures/building_crop.jpg'\n filename2 = '../figures/building.jpg'\n\n compute_img_matches(filename1, filename2)\n\nif __name__ == '__main__':\n main()\n```", "```py\ndef compute_orb_keypoints(filename):\n \"\"\"\n Takes in filename to read and computes ORB keypoints\n Returns image, keypoints and descriptors \n \"\"\"\n\n img = cv2.imread(filename)\n\n # downsample image 4x\n img = cv2.pyrDown(img) # downsample 2x\n img = cv2.pyrDown(img) # downsample 4x\n\n # create orb object\n orb = cv2.ORB_create()\n\n # set parameters \n orb.setScoreType(cv2.FAST_FEATURE_DETECTOR_TYPE_9_16)\n\n # detect keypoints\n kp = orb.detect(img,None)\n\n kp, des = orb.compute(img, kp)\n return img, kp,  des\n```", "```py\ndef compute_img_matches(filename1, filename2, thres=10):\n \"\"\"\n Extracts ORB features from given filenames\n Computes ORB matches and plot them side by side \n \"\"\"\n img1, kp1, des1 = compute_orb_keypoints(filename1)\n img2, kp2, des2 = compute_orb_keypoints(filename2)\n\n matches = brute_force_matcher(des1, des2)\n draw_matches(img1, img2, kp1, kp2, matches, thres)\n\ndef brute_force_matcher(des1, des2):\n \"\"\"\n Brute force matcher to match ORB feature descriptors\n \"\"\"\n # create BFMatcher object\n bf = cv2.BFMatcher(cv2.NORM_HAMMING2, crossCheck=True)\n # Match descriptors.\n matches = bf.match(des1,des2)\n\n # Sort them in the order of their distance.\n matches = sorted(matches, key = lambda x:x.distance)\n\n return matches\n\ndef draw_matches(img1, img2, kp1, kp2, matches, thres=10):\n \"\"\"\n Utility function to draw lines connecting matches between two images.\n \"\"\"\n draw_params = dict(matchColor = (0,255,0),\n singlePointColor = (255,0,0),\n flags = 0)\n\n # Draw first thres matches.\n img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:thres],None, **draw_params)\n plot_img(img3)\n\ndef main():\n # read an image \n filename2 = '../figures/building_7.JPG'\n filename1 = '../figures/building_crop.jpg'\n compute_img_matches(filename1, filename2, thres=20)\n\nif __name__ == '__main__':\n main()\n```"]