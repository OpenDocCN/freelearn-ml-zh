["```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n    from sklearn.impute import SimpleImputer\n    from sklearn.pipeline import make_pipeline\n    from sklearn.compose import ColumnTransformer\n    from sklearn.feature_selection import RFE\n    from sklearn.naive_bayes import GaussianNB\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.model_selection import cross_validate, \\\n      RandomizedSearchCV, RepeatedStratifiedKFold\n    import sklearn.metrics as skmet\n    import os\n    import sys\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    from preprocfunc import OutlierTrans\n    ```", "```py\n    nbagames = pd.read_csv(\"data/nbagames2017plus.csv\", parse_dates=['GAME_DATE'])\n    nbagames = nbagames.loc[nbagames.WL_HOME.isin(['W','L'])]\n    nbagames.shape\n    (4568, 149)\n    nbagames['WL_HOME'] = \\\n      np.where(nbagames.WL_HOME=='L',0,1).astype('int')\n    nbagames.WL_HOME.value_counts(dropna=False)\n    1    2586\n    0    1982\n    Name: WL_HOME, dtype: int64\n    ```", "```py\n    num_cols = ['FG_PCT_HOME','FTA_HOME','FG3_PCT_HOME',\n      'FTM_HOME','FT_PCT_HOME','OREB_HOME','DREB_HOME',\n      'REB_HOME','AST_HOME','STL_HOME','BLK_HOME',\n      'TOV_HOME', 'FG_PCT_AWAY','FTA_AWAY','FG3_PCT_AWAY',\n      'FT_PCT_AWAY','OREB_AWAY','DREB_AWAY','REB_AWAY',\n      'AST_AWAY','STL_AWAY','BLK_AWAY','TOV_AWAY']\n    cat_cols = ['TEAM_ABBREVIATION_HOME','SEASON']\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(nbagames[num_cols + cat_cols],\\\n      nbagames[['WL_HOME']], test_size=0.2,random_state=0)\n    ```", "```py\n    ohe = OneHotEncoder(drop='first', sparse=False)\n    cattrans = make_pipeline(ohe)\n    standtrans = make_pipeline(OutlierTrans(2),\n      SimpleImputer(strategy=\"median\"), StandardScaler())\n    coltrans = ColumnTransformer(\n      transformers=[\n        (\"cat\", cattrans, cat_cols),\n        (\"stand\", standtrans, num_cols)\n      ]\n    )\n    ```", "```py\n    nb = GaussianNB()\n    rfe = RFE(estimator=LogisticRegression(),\n      n_features_to_select=15)\n    pipe1 = make_pipeline(coltrans, rfe, nb)\n    ```", "```py\n    kf = RepeatedStratifiedKFold(n_splits=7,n_repeats=10,\\\n      random_state=0)\n    scores = cross_validate(pipe1, X_train, \\\n      y_train.values.ravel(), \\\n      scoring=['accuracy','precision','recall','f1'], \\\n      cv=kf, n_jobs=-1)\n    print(\"accuracy: %.2f, precision: %.2f, \n      sensitivity: %.2f, f1: %.2f\"  %\n      (np.mean(scores['test_accuracy']),\\\n       np.mean(scores['test_precision']),\\\n       np.mean(scores['test_recall']),\\\n       np.mean(scores['test_f1'])))\n    accuracy: 0.81, precision: 0.84, sensitivity: 0.83, f1: 0.83\n    ```", "```py\nnb_params = {\n    'gaussiannb__var_smoothing': np.logspace(0,-9, num=100)\n}\nrs = RandomizedSearchCV(pipe1, nb_params, cv=kf, \\\n  scoring='accuracy')\nrs.fit(X_train, y_train.values.ravel())\n```", "```py\n    rs.best_params_\n    {'gaussiannb__var_smoothing': 0.657933224657568}\n    rs.best_score_\n    0.8608648056923919\n    ```", "```py\n    results = \\\n      pd.DataFrame(rs.cv_results_['mean_test_score'], \\\n        columns=['meanscore']).\\\n      join(pd.DataFrame(rs.cv_results_['params'])).\\\n      sort_values(['meanscore'], ascending=False)\n    results\n             meanscore     gaussiannb__var_smoothing\n    2        0.86086        0.65793\n    1        0.85118        0.03511\n    9        0.81341        0.00152\n    5        0.81212        0.00043\n    7        0.81180        0.00019\n    8        0.81169        0.00002\n    3        0.81152        0.00000\n    6        0.81152        0.00000\n    0        0.81149        0.00000\n    4        0.81149        0.00000\n    ```", "```py\n    print(\"fit time: %.3f, score time: %.3f\"  %\n      (np.mean(rs.cv_results_['mean_fit_time']),\\\n      np.mean(rs.cv_results_['mean_score_time'])))\n    fit time: 0.660, score time: 0.029\n    ```", "```py\n    pred = rs.predict(X_test)\n    print(\"accuracy: %.2f, sensitivity: %.2f, \\\n      specificity: %.2f, precision: %.2f\"  %\n      (skmet.accuracy_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred, \\\n         pos_label=0),\n      skmet.precision_score(y_test.values.ravel(), pred)))\n    accuracy: 0.86, sensitivity: 0.92, specificity: 0.79, precision: 0.83\n    ```", "```py\n    cm = skmet.confusion_matrix(y_test, pred)\n    cmplot = skmet.ConfusionMatrixDisplay(\n      confusion_matrix=cm, display_labels=['Loss', 'Won'])\n    cmplot.plot()\n    cmplot.ax_.set(title='Home Team Win Confusion Matrix', \n      xlabel='Predicted Value', ylabel='Actual Value')\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from imblearn.pipeline import make_pipeline\n    from imblearn.over_sampling import SMOTE\n    from sklearn.naive_bayes import MultinomialNB\n    from sklearn.feature_extraction.text import CountVectorizer\n    import sklearn.metrics as skmet\n    ```", "```py\n    spamtext = pd.read_csv(\"data/spamtext.csv\")\n    spamtext['spam'] = np.where(spamtext.category=='spam',1,0)\n    spamtext.groupby(['spam','category']).size()\n    spam  category\n    0     ham         4824\n    1     spam         747\n    dtype: int64\n    spamtext.head()\n     category  message                                spam\n    0  ham     Go until jurong point, crazy..         0\n    1  ham     Ok lar... Joking wif u oni...          0\n    2  spam    Free entry in 2 a wkly comp to win...  1\n    3  ham     U dun say so early hor... U c already..0\n    4  ham     Nah I don't think he goes to usf, ..   0\n    ```", "```py\nX_train, X_test, y_train, y_test =  \\\n  train_test_split(spamtext[['message']],\\\n  spamtext[['spam']], test_size=0.2,\\\n  stratify=spamtext[['spam']], random_state=0)\ncountvectorizer = CountVectorizer(analyzer='word', \\\n  stop_words='english')\n```", "```py\nsmallsample = \\\n  X_train.loc[X_train.message.str.len()<50].\\\n    sample(2, random_state=35)\nsmallsample\n                                        message\n2079                I can take you at like noon\n5393  I dont know exactly could you ask chechi.\nourvec = \\\n    pd.DataFrame(countvectorizer.\\\n    fit_transform(smallsample.values.ravel()).\\\n    toarray(),\\\n    columns=countvectorizer.get_feature_names())\nourvec\n    ask   chechi  dont   exactly  know  like  noon\n0    0    0       0      0        0     1     1\n1    1    1       1      1        1     0     0\n```", "```py\n    nb = MultinomialNB()\n    smote = SMOTE(random_state=0)\n    pipe1 = make_pipeline(countvectorizer, smote, nb)\n    pipe1.fit(X_train.values.ravel(), \n      y_train.values.ravel())\n    ```", "```py\n    pred = pipe1.predict(X_test.values.ravel())\n    print(\"accuracy: %.2f, sensitivity: %.2f, specificity: %.2f, precision: %.2f\"  %\n      (skmet.accuracy_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred, pos_label=0),\n      skmet.precision_score(y_test.values.ravel(), pred)))\n    accuracy: 0.97, sensitivity: 0.87, specificity: 0.98, precision: 0.87\n    ```", "```py\n    cm = skmet.confusion_matrix(y_test, pred)\n    cmplot = skmet.ConfusionMatrixDisplay(\n      confusion_matrix=cm, \\\n      display_labels=['Not Spam', 'Spam'])\n    cmplot.plot()\n    cmplot.ax_.set(\n      title='Spam Prediction Confusion Matrix', \n      xlabel='Predicted Value', ylabel='Actual Value')\n    ```"]