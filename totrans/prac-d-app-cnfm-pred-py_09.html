<html><head></head><body>
<div id="_idContainer064">
<h1 class="chapter-number" id="_idParaDest-113"><a id="_idTextAnchor111"/><span class="koboSpan" id="kobo.1.1">9</span></h1>
<h1 id="_idParaDest-114"><a id="_idTextAnchor112"/><span class="koboSpan" id="kobo.2.1">Conformal Prediction for Computer Vision</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In today’s fast-paced world, computer vision has grown beyond mere image recognition to be a fundamental cornerstone in numerous real-world applications. </span><span class="koboSpan" id="kobo.3.2">From self-driving cars navigating bustling streets to medical imaging systems that detect early signs of diseases, the demand for reliable and accurate computer vision models has never been higher. </span><span class="koboSpan" id="kobo.3.3">However, with the increasing complexity of these systems and their applications, a critical need arises for the ability to quantify the uncertainty associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">their predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">Enter </span><strong class="bold"><span class="koboSpan" id="kobo.6.1">conformal prediction</span></strong><span class="koboSpan" id="kobo.7.1">, a ground-breaking framework that offers a robust means to encapsulate the uncertainty inherent in machine learning models. </span><span class="koboSpan" id="kobo.7.2">While traditional computer vision models often produce a singular prediction, the true power of conformal prediction lies in its ability to provide a set of possible outcomes, each backed by a confidence level. </span><span class="koboSpan" id="kobo.7.3">This offers practitioners a more informed, nuanced view of the model’s predictions, enabling safer and more reliable deployments in </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">critical applications.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">This chapter dives deep into the marriage of conformal prediction and computer vision. </span><span class="koboSpan" id="kobo.9.2">We begin by illuminating the necessity of uncertainty quantification in computer vision, highlighting its significance in real-world scenarios including </span><strong class="bold"><span class="koboSpan" id="kobo.10.1">autonomous driving</span></strong><span class="koboSpan" id="kobo.11.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.12.1">healthcare diagnostics</span></strong><span class="koboSpan" id="kobo.13.1">. </span><span class="koboSpan" id="kobo.13.2">As we navigate deeper, we’ll explore the Achilles’ heel of modern deep learning models: </span><em class="italic"><span class="koboSpan" id="kobo.14.1">their tendency to produce </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.15.1">miscalibrated predictions</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.17.1">By the journey’s end, you’ll gain hands-on experience building state-of-the-art computer vision classifiers imbued with the power of conformal prediction. </span><span class="koboSpan" id="kobo.17.2">We’ll introduce and guide you through the best open source conformal prediction libraries in computer vision applications to ensure you have all the tools necessary to embark on </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">this journey.</span></span></p>
<p><span class="koboSpan" id="kobo.19.1">In this chapter, we’re going to cover the following </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">main topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.21.1">Uncertainty quantification for </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">computer vision</span></span></li>
<li><span class="koboSpan" id="kobo.23.1">Why deep learning produces </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">miscalibrated predictions</span></span></li>
<li><span class="koboSpan" id="kobo.25.1">Various approaches to quantify uncertainty in computer </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">vision problems</span></span></li>
<li><span class="koboSpan" id="kobo.27.1">Conformal prediction for </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">computer vision</span></span></li>
<li><span class="koboSpan" id="kobo.29.1">Building computer vision classifiers using </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">Conformal prediction</span></span></li>
</ul>
<h1 id="_idParaDest-115"><a id="_idTextAnchor113"/><span class="koboSpan" id="kobo.31.1">Uncertainty quantification for computer vision</span></h1>
<p><span class="koboSpan" id="kobo.32.1">As a domain, computer vision has transformed many sectors by automating complex tasks that were once reserved for human eyes and cognition. </span><span class="koboSpan" id="kobo.32.2">Computer vision models have become an integral part of modern technology, whether it’s detecting pedestrians on the road, identifying potential</span><a id="_idIndexMarker453"/><span class="koboSpan" id="kobo.33.1"> tumours in medical scans, or even analyzing satellite images for environmental studies. </span><span class="koboSpan" id="kobo.33.2">However, as the reliance on these models grows, so does the need to understand and quantify the uncertainty associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">their predictions.</span></span></p>
<h2 id="_idParaDest-116"><a id="_idTextAnchor114"/><span class="koboSpan" id="kobo.35.1">Why does uncertainty matter?</span></h2>
<p><span class="koboSpan" id="kobo.36.1">Before deep-diving into the mechanics, it’s essential to understand why we need </span><strong class="bold"><span class="koboSpan" id="kobo.37.1">uncertainty quantification</span></strong><span class="koboSpan" id="kobo.38.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.39.1">UQ</span></strong><span class="koboSpan" id="kobo.40.1">) in the first</span><a id="_idIndexMarker454"/><span class="koboSpan" id="kobo.41.1"> place. </span><span class="koboSpan" id="kobo.41.2">Let’s go through some of the reasons </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">as follows:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.43.1">Safety and reliability</span></strong><span class="koboSpan" id="kobo.44.1">: A wrong prediction can have severe consequences in critical applications, such as medical imaging or autonomous driving. </span><span class="koboSpan" id="kobo.44.2">Knowing the confidence level in a prediction can aid in decision-making, such as whether to trust the model’s prediction or seek </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">human intervention.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.46.1">Model improvements</span></strong><span class="koboSpan" id="kobo.47.1">: Uncertainty measurements can provide insights into areas where the model might be lacking, helping to guide data collection and </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">training enhancements.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.49.1">Trustworthiness</span></strong><span class="koboSpan" id="kobo.50.1">: Knowing that a system acknowledges its limitations and can provide confidence intervals or uncertainty metrics for end users and stakeholders makes it </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">more trustworthy.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.52.1">Navigating the world of computer vision, one inevitably encounters uncertainties that can influence the accuracy of model predictions. </span><span class="koboSpan" id="kobo.52.2">But what are the sources of these uncertainties, and can they be managed? </span><span class="koboSpan" id="kobo.52.3">Let’s delve into the two primary types of uncertainty in </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">computer vision.</span></span></p>
<h2 id="_idParaDest-117"><a id="_idTextAnchor115"/><span class="koboSpan" id="kobo.54.1">Types of uncertainty in computer vision</span></h2>
<p><span class="koboSpan" id="kobo.55.1">Uncertainty in computer vision can be broadly classified into </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">two categories:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.57.1">Aleatoric uncertainty</span></strong><span class="koboSpan" id="kobo.58.1">: This type of </span><a id="_idIndexMarker455"/><span class="koboSpan" id="kobo.59.1">uncertainty arises from the inherent noise in the data. </span><span class="koboSpan" id="kobo.59.2">For instance, low-light images, blurry images, or images taken from varying angles introduce </span><a id="_idIndexMarker456"/><span class="koboSpan" id="kobo.60.1">variability that the model might find challenging to handle. </span><span class="koboSpan" id="kobo.60.2">Aleatoric uncertainty is often irreducible, meaning no matter how good the model becomes, this uncertainty will always exist due to the inherent noise in </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">the observations.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.62.1">Epistemic uncertainty</span></strong><span class="koboSpan" id="kobo.63.1">: This type of uncertainty stems from the model itself. </span><span class="koboSpan" id="kobo.63.2">It could be due to incomplete training </span><a id="_idIndexMarker457"/><span class="koboSpan" id="kobo.64.1">data, model architecture choices, or the optimization process. </span><span class="koboSpan" id="kobo.64.2">Given enough </span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.65.1">data or improvements in model design, epistemic uncertainty can </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">be reduced.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.67.1">In the realm of computer vision, it’s not enough to simply get a prediction. </span><span class="koboSpan" id="kobo.67.2">As advanced as our models are, they can sometimes be overly confident, potentially leading to misinformed decisions. </span><span class="koboSpan" id="kobo.67.3">How do we gauge the reliability of these predictions? </span><span class="koboSpan" id="kobo.67.4">Enter the world of </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1">uncertainty quantification.</span></span></p>
<h2 id="_idParaDest-118"><a id="_idTextAnchor116"/><span class="koboSpan" id="kobo.69.1">Quantifying uncertainty</span></h2>
<p><span class="koboSpan" id="kobo.70.1">Modern computer vision models, especially </span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.71.1">deep learning architectures, produce predictions that are often overconfident. </span><span class="koboSpan" id="kobo.71.2">This miscalibration can be misleading, especially in critical applications. </span><span class="koboSpan" id="kobo.71.3">The need, therefore, is not just to produce a prediction but also to accompany it with a measure of confidence </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">or uncertainty.</span></span></p>
<p><span class="koboSpan" id="kobo.73.1">Various methods have been proposed to quantify uncertainty, ranging from Bayesian neural networks, which provide a distribution over model parameters, to ensemble methods, which rely on the variability of predictions across </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">different models.</span></span></p>
<p><span class="koboSpan" id="kobo.75.1">However, as we’ll see in the subsequent sections, Conformal prediction offers a fresh and rigorous perspective on uncertainty quantification tailored to the needs of computer </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">vision applications.</span></span></p>
<p><span class="koboSpan" id="kobo.77.1">Uncertainty </span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.78.1">quantification for computer vision is not a theoretical exercise but a crucial aspect of building reliable, safe, and trustworthy models. </span><span class="koboSpan" id="kobo.78.2">Understanding and accounting for their inherent uncertainties will be paramount as computer vision systems continue to permeate </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1">every sector.</span></span></p>
<h1 id="_idParaDest-119"><a id="_idTextAnchor117"/><span class="koboSpan" id="kobo.80.1">Why does deep learning produce miscalibrated predictions?</span></h1>
<p><span class="koboSpan" id="kobo.81.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.82.1">ImageNet Large Scale Visual Recognition Challenge</span></strong><span class="koboSpan" id="kobo.83.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.84.1">ILSVRC</span></strong><span class="koboSpan" id="kobo.85.1">) is an annual competition where research teams </span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.86.1">evaluate their algorithms on a given dataset, aiming to push the boundaries of computer vision. </span><span class="koboSpan" id="kobo.86.2">2012</span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.87.1"> was a watershed moment for the field, marking a significant shift towards the dominance of deep learning in computer </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">vision (</span></span><a href="https://www.image-net.org/challenges/LSVRC/2012/"><span class="No-Break"><span class="koboSpan" id="kobo.89.1">https://www.image-net.org/challenges/LSVRC/2012/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.90.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.91.1">Before the advent of deep learning, computer vision primarily relied on hand-engineered features and</span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.92.1"> traditional machine learning techniques. </span><span class="koboSpan" id="kobo.92.2">Algorithms such as </span><strong class="bold"><span class="koboSpan" id="kobo.93.1">Scale-Invariant Feature Transform </span></strong><span class="koboSpan" id="kobo.94.1">(</span><strong class="bold"><span class="koboSpan" id="kobo.95.1">SIFT</span></strong><span class="koboSpan" id="kobo.96.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.97.1">Histogram of Oriented Gradients </span></strong><span class="koboSpan" id="kobo.98.1">(</span><strong class="bold"><span class="koboSpan" id="kobo.99.1">HOG</span></strong><span class="koboSpan" id="kobo.100.1">), and </span><strong class="bold"><span class="koboSpan" id="kobo.101.1">Speeded-Up Robust Features </span></strong><span class="koboSpan" id="kobo.102.1">(</span><strong class="bold"><span class="koboSpan" id="kobo.103.1">SURF</span></strong><span class="koboSpan" id="kobo.104.1">) were</span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.105.1"> commonly used to extract </span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.106.1">features from images. </span><span class="koboSpan" id="kobo.106.2">These features would then be fed into machine learning classifiers such as </span><strong class="bold"><span class="koboSpan" id="kobo.107.1">Support Vector Machines</span></strong><span class="koboSpan" id="kobo.108.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.109.1">SVM</span></strong><span class="koboSpan" id="kobo.110.1">) to make</span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.111.1"> predictions. </span><span class="koboSpan" id="kobo.111.2">While these methods had their successes, they had significant limitations regarding scalability and performance on more </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">complex datasets.</span></span></p>
<p><span class="koboSpan" id="kobo.113.1">In 2012, a deep convolutional neural network named AlexNet (</span><a href="https://en.wikipedia.org/wiki/AlexNet"><span class="koboSpan" id="kobo.114.1">https://en.wikipedia.org/wiki/AlexNet</span></a><span class="koboSpan" id="kobo.115.1">), developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, was entered into the ILSVRC. </span><span class="koboSpan" id="kobo.115.2">It achieved a top-5 error rate of 15.3%, a staggering 10.8 percentage points lower than the second-place finisher. </span><span class="koboSpan" id="kobo.115.3">This dramatic improvement was an incremental step and a quantum leap </span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">in performance.</span></span></p>
<p><span class="koboSpan" id="kobo.117.1">Why was </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">AlexNet revolutionary?</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.119.1">Deep architecture</span></strong><span class="koboSpan" id="kobo.120.1">: AlexNet was </span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.121.1">considerably deeper than other networks of its time. </span><span class="koboSpan" id="kobo.121.2">It had five convolutional layers followed by three fully connected layers. </span><span class="koboSpan" id="kobo.121.3">This depth allowed it to learn more complex and hierarchical features from the </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">ImageNet dataset.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.123.1">GPU training</span></strong><span class="koboSpan" id="kobo.124.1">: The team utilized </span><strong class="bold"><span class="koboSpan" id="kobo.125.1">graphics processing units</span></strong><span class="koboSpan" id="kobo.126.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.127.1">GPUs</span></strong><span class="koboSpan" id="kobo.128.1">) to train the network, which</span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.129.1"> made it feasible to process the massive amount of data in the ImageNet dataset and efficiently train the </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">deep architecture.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.131.1">ReLU activation</span></strong><span class="koboSpan" id="kobo.132.1">: Instead of traditional tanh or sigmoid activation functions, AlexNet </span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.133.1">employed the </span><strong class="bold"><span class="koboSpan" id="kobo.134.1">Rectified Linear Unit</span></strong><span class="koboSpan" id="kobo.135.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.136.1">ReLU</span></strong><span class="koboSpan" id="kobo.137.1">) activation. </span><span class="koboSpan" id="kobo.137.2">This choice helped combat the vanishing gradient problem, enabling the training of </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">deeper networks.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.139.1">Dropout</span></strong><span class="koboSpan" id="kobo.140.1">: To prevent</span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.141.1"> overfitting, AlexNet introduced the dropout technique, where random subsets of neurons were “dropped out” during</span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.142.1"> training, forcing the network to learn </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">redundant representations.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.144.1">The dawn of 2012 marked a transformative moment in the realm of computer vision. </span><span class="koboSpan" id="kobo.144.2">Propelled by the unprecedented achievements of AlexNet in the ImageNet competition, the entire industry pivoted towards deep </span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.145.1">learning, especially </span><strong class="bold"><span class="koboSpan" id="kobo.146.1">convolutional</span></strong> <strong class="bold"><span class="koboSpan" id="kobo.147.1">neural networks</span></strong><span class="koboSpan" id="kobo.148.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.149.1">CNNs</span></strong><span class="koboSpan" id="kobo.150.1">). </span><span class="koboSpan" id="kobo.150.2">As we journey through the aftermath of this revolution, we’ll witness the exponential growth in research, widespread industry adoption, and the relentless quest for more data and </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">computational power.</span></span></p>
<h2 id="_idParaDest-120"><a id="_idTextAnchor118"/><span class="koboSpan" id="kobo.152.1">Post-2012 – the deep learning surge</span></h2>
<p><span class="koboSpan" id="kobo.153.1">The 2012 ImageNet competition, marked by the triumph of AlexNet, became a watershed moment in the field of computer vision. </span><span class="koboSpan" id="kobo.153.2">This victory underscored the profound potential of deep learning, especially </span><strong class="bold"><span class="koboSpan" id="kobo.154.1">convolutional neural networks</span></strong><span class="koboSpan" id="kobo.155.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.156.1">CNNs</span></strong><span class="koboSpan" id="kobo.157.1">). </span><span class="koboSpan" id="kobo.157.2">As a result, the </span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">following happened:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.159.1">Research boom</span></strong><span class="koboSpan" id="kobo.160.1">: After 2012, there was an explosion of research into deep learning for computer vision. </span><span class="koboSpan" id="kobo.160.2">Variants and improvements upon AlexNet, such as VGG, GoogLeNet, and ResNet, were rapidly developed, pushing the </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">envelope further.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.162.1">Industry adoption</span></strong><span class="koboSpan" id="kobo.163.1">: Tech giants and start-ups began investing heavily in deep learning research and applications, from facial recognition systems to </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">augmented reality.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.165.1">Datasets and compute</span></strong><span class="koboSpan" id="kobo.166.1">: The success of deep learning fueled the creation of even larger datasets and a race for more powerful computation infrastructure, further accelerating the </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">innovation cycle.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.168.1">The 2012 ImageNet competition was</span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.169.1"> a turning point, heralding the era of deep learning in computer vision. </span><span class="koboSpan" id="kobo.169.2">The principles and breakthroughs of AlexNet laid the foundation for the subsequent advancements we see today, from self-driving cars to real-time </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">video analytics.</span></span></p>
<h2 id="_idParaDest-121"><a id="_idTextAnchor119"/><span class="koboSpan" id="kobo.171.1">The "calibration crisis" in deep learning – a turning point in 2017</span></h2>
<p><span class="koboSpan" id="kobo.172.1">Since its triumphant ascendance</span><a id="_idIndexMarker474"/><span class="koboSpan" id="kobo.173.1"> following the 2012 ImageNet competition, deep learning experienced rapid advancements and widespread adoption across many domains. </span><span class="koboSpan" id="kobo.173.2">The community was engrossed in developing architectures, optimization techniques, and applications for five consecutive years. </span><span class="koboSpan" id="kobo.173.3">Yet, amidst this whirlwind of innovation, a significant concern remained largely overlooked: </span><em class="italic"><span class="koboSpan" id="kobo.174.1">the miscalibration of predictions produced by deep </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.175.1">learning systems</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.177.1">In real-world applications where automated systems drive decisions, it’s not enough for classification networks to merely provide accurate results. </span><span class="koboSpan" id="kobo.177.2">These systems play an integral role in various critical sectors, from healthcare to finance, and a misjudgment can have significant consequences. </span><span class="koboSpan" id="kobo.177.3">Therefore, it’s crucial that these classification networks not only deliver precise outcomes but also possess the self-awareness to flag potential uncertainties or errors in </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">their predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.179.1">For instance, in a medical diagnostic tool, beyond correctly identifying a disease, the system should also indicate its confidence level in that diagnosis. </span><span class="koboSpan" id="kobo.179.2">Medical professionals can take appropriate precautions if uncertain, perhaps seeking additional tests or </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">expert opinions.</span></span></p>
<p><span class="koboSpan" id="kobo.181.1">Take another example: a self-driving car equipped with a neural network designed to identify pedestrians and various obstacles on the road. </span><span class="koboSpan" id="kobo.181.2">In such a scenario, the car’s system doesn’t just need to recognize people or obstructions; it must do so accurately and in real time. </span><span class="koboSpan" id="kobo.181.3">Any delay or misidentification could lead to potentially </span><span class="No-Break"><span class="koboSpan" id="kobo.182.1">dangerous situations.</span></span></p>
<p><span class="koboSpan" id="kobo.183.1">Furthermore, it’s not only about detecting obstacles but also understanding the level of certainty in that detection. </span><span class="koboSpan" id="kobo.183.2">Imagine a scenario where a self-driving car’s detection network struggles to determine whether there’s an obstruction ahead confidently. </span><span class="koboSpan" id="kobo.183.3">If the car’s system is uncertain about an object—perhaps due to poor lighting conditions or an obscured view—it</span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.184.1"> should be programmed to lean more heavily on data from its other sensors, such as lidar or radar, to decide whether braking is necessary and to proceed cautiously, slow down, or even halt. </span><span class="koboSpan" id="kobo.184.2">This dual requirement of precise detection and self-awareness of its own certainty levels ensures safer navigation and decision-making, especially in dynamic and unpredictable road environments. </span><span class="koboSpan" id="kobo.184.3">See the article </span><em class="italic"><span class="koboSpan" id="kobo.185.1">Risk-Sensitive Decision-Making for Autonomous-Driving</span></em><span class="koboSpan" id="kobo.186.1"> (</span><a href="https://uu.diva-portal.org/smash/get/diva2:1698692/FULLTEXT01.pdf"><span class="koboSpan" id="kobo.187.1">https://uu.diva-portal.org/smash/get/diva2:1698692/FULLTEXT01.pdf</span></a><span class="koboSpan" id="kobo.188.1">) if you are interested in more details on </span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">the subject.</span></span></p>
<p><span class="koboSpan" id="kobo.190.1">Accurate confidence estimates play a pivotal role in enhancing model interpretability. </span><span class="koboSpan" id="kobo.190.2">Humans inherently understand and relate to probabilities, making it an intuitive measure to </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">gauge predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.192.1">When a model provides well-calibrated confidence levels, it offers an additional layer of information that bolsters its credibility to the user. </span><span class="koboSpan" id="kobo.192.2">This is especially crucial for neural networks, as their decision-making processes can be complex and challenging to decipher. </span><span class="koboSpan" id="kobo.192.3">Moreover, reliable probability assessments can be integrated into broader probabilistic models, further expanding their utility </span><span class="No-Break"><span class="koboSpan" id="kobo.193.1">and application.</span></span></p>
<p><span class="koboSpan" id="kobo.194.1">This combination of accuracy and introspection ensures that automated decision-making systems are trustworthy and reliable, fostering confidence in their integration into </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">critical applications.</span></span></p>
<p><span class="koboSpan" id="kobo.196.1">Miscalibration refers to the disparity between a model’s stated confidence in its predictions and the actual accuracy of those predictions. </span><span class="koboSpan" id="kobo.196.2">For instance, if a model claims 90% confidence for a set of predictions, one expects approximately 90% of those predictions to be correct. </span><span class="koboSpan" id="kobo.196.3">However, despite their high accuracy, deep learning models often needed to catch up on their expressed confidence and </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">actual correctness.</span></span></p>
<p><span class="koboSpan" id="kobo.198.1">Fast forward to the present, and while contemporary neural networks have seen significant advancements in accuracy compared to those from a decade ago, it’s intriguing to note that they no longer </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">maintain calibration.</span></span></p>
<p><span class="koboSpan" id="kobo.200.1">It wasn’t until 2017 that the magnitude of this issue was brought to the forefront of the AI community’s attention. </span><span class="koboSpan" id="kobo.200.2">A pivotal paper, </span><em class="italic"><span class="koboSpan" id="kobo.201.1">On Calibration of Modern Neural Networks (Guo, 2017)</span></em><span class="koboSpan" id="kobo.202.1">, (</span><a href="https://proceedings.mlr.press/v70/guo17a.html"><span class="koboSpan" id="kobo.203.1">https://proceedings.mlr.press/v70/guo17a.html</span></a><span class="koboSpan" id="kobo.204.1">) discovered that deep neural networks are poorly calibrated, spotlighting the calibration conundrum inherent in deep </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">learning systems.</span></span></p>
<p><span class="koboSpan" id="kobo.206.1">This research not only</span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.207.1"> underscored the severe miscalibration of these systems but also brought to light a startling revelation: several of the </span><em class="italic"><span class="koboSpan" id="kobo.208.1">state-of-the-art</span></em><span class="koboSpan" id="kobo.209.1"> techniques that had been hailed as breakthroughs, such as dropout, weight decay, and batch normalization, were paradoxically exacerbating the </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">miscalibration issue.</span></span></p>
<p><span class="koboSpan" id="kobo.211.1">This seminal paper served as a wake-up call. </span><span class="koboSpan" id="kobo.211.2">It prompted introspection within the community, urging researchers to question and revisit the techniques they had championed. </span><span class="koboSpan" id="kobo.211.3">The paper was a critique and an invitation to explore and rectify the issue. </span><span class="koboSpan" id="kobo.211.4">Its lucid exposition and profound insights made it a must-read for anyone in </span><span class="No-Break"><span class="koboSpan" id="kobo.212.1">the field.</span></span></p>
<p><span class="koboSpan" id="kobo.213.1">While the years following the 2012 ImageNet competition were characterized by rapid progress and unbridled optimism, the 2017 paper served as a moment of reckoning. </span><span class="koboSpan" id="kobo.213.2">It underscored the importance of introspection in science and the continuous need to refine, recalibrate, and, if necessary, rethink our approaches, ensuring that the AI systems we build are accurate and </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">reliably calibrated.</span></span></p>
<p><span class="koboSpan" id="kobo.215.1">Confidence calibration is the problem of predicting probability estimates that represent the actual outcome. </span><span class="koboSpan" id="kobo.215.2">It is crucial for classification models in many applications because good confidence estimates provide valuable information to establish trustworthiness with the user. </span><span class="koboSpan" id="kobo.215.3">Good probability estimates can be used for model interpretability, as humans have a natural cognitive intuition </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">for probabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.217.1">The authors of the paper </span><em class="italic"><span class="koboSpan" id="kobo.218.1">On Calibration of Modern Neural Networks</span></em><span class="koboSpan" id="kobo.219.1"> found that increased model capacity and lack of regularization are closely related to the miscalibration phenomenon observed in deep neural networks. </span><span class="koboSpan" id="kobo.219.2">Model capacity has increased dramatically over the past few years, with networks having hundreds or thousands of layers and hundreds of convolutional filters per layer. </span><span class="koboSpan" id="kobo.219.3">Recent work shows that very deep or wide models can generalize better than smaller ones while exhibiting the capacity to fit the training set easily. </span><span class="koboSpan" id="kobo.219.4">However, this increased capacity can lead to overfitting </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">and miscalibration.</span></span></p>
<p><span class="koboSpan" id="kobo.221.1">Regarding shallow classical neural networks, the paper </span><em class="italic"><span class="koboSpan" id="kobo.222.1">On Calibration of Modern Neural Networks</span></em><span class="koboSpan" id="kobo.223.1"> posited that traditional (or shallow) neural networks were well calibrated. </span><span class="koboSpan" id="kobo.223.2">This belief stemmed from a highly cited 2005 paper by Niculescu-Mizil and R. </span><span class="koboSpan" id="kobo.223.3">Caruana, titled </span><em class="italic"><span class="koboSpan" id="kobo.224.1">Predicting good probabilities with supervised learning</span></em><span class="koboSpan" id="kobo.225.1"> (</span><a href="https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf"><span class="koboSpan" id="kobo.226.1">https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf</span></a><span class="koboSpan" id="kobo.227.1">). </span><span class="koboSpan" id="kobo.227.2">Presented at the prestigious ICML conference, this paper has amassed over 1,570 citations since its </span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.228.1">publication. </span><span class="koboSpan" id="kobo.228.2">One of the conclusions reached was that shallow (classical) neural networks were “</span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">well calibrated.”</span></span></p>
<p><span class="koboSpan" id="kobo.230.1">However, this conclusion about the calibration of shallow neural networks was upended later. </span><span class="koboSpan" id="kobo.230.2">In a 2020 study titled </span><em class="italic"><span class="koboSpan" id="kobo.231.1">Are Traditional Neural Networks Well-Calibrated?</span></em><span class="koboSpan" id="kobo.232.1"> (</span><a href="https://ieeexplore.ieee.org/document/8851962"><span class="koboSpan" id="kobo.233.1">https://ieeexplore.ieee.org/document/8851962</span></a><span class="koboSpan" id="kobo.234.1">), the authors debunked the widely held belief that shallow neural networks are well-calibrated. </span><span class="koboSpan" id="kobo.234.2">Their findings revealed that traditional shallow networks are poorly calibrated, and their ensembles exhibit the same issue. </span><span class="koboSpan" id="kobo.234.3">Fortunately, the researchers also highlighted that the calibration of these networks can be significantly enhanced using the Venn-ABERS conformal prediction method we learned about in </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">previous chapters.</span></span></p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor120"/><span class="koboSpan" id="kobo.236.1">Overconfidence in modern deep learning computer vision models</span></h2>
<p><span class="koboSpan" id="kobo.237.1">Many deep learning models designed for computer vision predominantly utilize convolution-based architectures. </span><span class="koboSpan" id="kobo.237.2">These architectures have propelled the field forward, achieving unprecedented predictive </span><a id="_idIndexMarker478"/><span class="koboSpan" id="kobo.238.1">accuracy. </span><span class="koboSpan" id="kobo.238.2">However, there’s an unintended side effect: </span><em class="italic"><span class="koboSpan" id="kobo.239.1">these models often produce </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.240.1">overconfident predictions</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.241.1">:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.242.1">Accuracy versus quality</span></strong><span class="koboSpan" id="kobo.243.1">: The relentless pursuit of accuracy in deep learning has led to models that can correctly classify images with remarkable precision. </span><span class="koboSpan" id="kobo.243.2">However, accuracy is just one facet of a model’s performance. </span><span class="koboSpan" id="kobo.243.3">Predictive quality, which encompasses aspects such as the reliability and calibration of predictions, is </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">equally vital.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.245.1">The overconfidence issue</span></strong><span class="koboSpan" id="kobo.246.1">: Even as these models achieve higher accuracy rates, they tend to be excessively confident in their predictions. </span><span class="koboSpan" id="kobo.246.2">This means they do so with high confidence when they make an error, indicating they believe strongly in the </span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">incorrect prediction.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.248.1">Implications in critical applications</span></strong><span class="koboSpan" id="kobo.249.1">: This overconfidence poses considerable risks, especially in sectors where the stakes are high. </span><span class="koboSpan" id="kobo.249.2">Consider healthcare: a misdiagnosis by a computer vision system analyzing medical scans might lead medical professionals to pursue incorrect treatments if made with high confidence. </span><span class="koboSpan" id="kobo.249.3">Similarly, an overconfident misinterpretation of a road scene in autonomous vehicles</span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.250.1"> could result in </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">dangerous manoeuvres.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.252.1">In essence, as the deep learning community pushes the boundaries of accuracy, it’s imperative also to address the calibration of these models. </span><span class="koboSpan" id="kobo.252.2">Ensuring that they not only make accurate predictions but also gauge the confidence of those predictions appropriately is crucial, especially when these models are employed in </span><span class="No-Break"><span class="koboSpan" id="kobo.253.1">life-critical applications.</span></span></p>
<h1 id="_idParaDest-123"><a id="_idTextAnchor121"/><span class="koboSpan" id="kobo.254.1">Various approaches to quantify uncertainty in computer vision problems</span></h1>
<p><span class="koboSpan" id="kobo.255.1">Uncertainty quantification in computer vision is crucial for ensuring vision-based systems’ reliability and safety, especially</span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.256.1"> when deployed in critical applications. </span><span class="koboSpan" id="kobo.256.2">Over the years, various approaches have been developed to address and quantify this uncertainty. </span><span class="koboSpan" id="kobo.256.3">Here’s a look at some of the most </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">prominent methods:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.258.1">Bayesian Neural Networks </span></strong><span class="koboSpan" id="kobo.259.1">(</span><strong class="bold"><span class="koboSpan" id="kobo.260.1">BNNs</span></strong><span class="koboSpan" id="kobo.261.1">): These neural networks treat weights as probability distributions rather than </span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.262.1">fixed values. </span><span class="koboSpan" id="kobo.262.2">By doing so, they can provide a measure of uncertainty for their predictions. </span><span class="koboSpan" id="kobo.262.3">During inference, multiple forward passes are made with different weight samples, producing a distribution of outputs that capture the </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">model’s uncertainty.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.264.1">Monte Carlo dropout</span></strong><span class="koboSpan" id="kobo.265.1">: Monte </span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.266.1">Carlo dropout involves performing dropout during inference. </span><span class="koboSpan" id="kobo.266.2">By running the network multiple times with dropout and averaging the results, a distribution over the outputs is obtained, which can be used to </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">gauge uncertainty.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.268.1">Ensemble methods</span></strong><span class="koboSpan" id="kobo.269.1">: Ensemble methods involve training multiple models and aggregating their predictions. </span><span class="koboSpan" id="kobo.269.2">The </span><a id="_idIndexMarker483"/><span class="koboSpan" id="kobo.270.1">variance in predictions across models can be used as a proxy for uncertainty. </span><span class="koboSpan" id="kobo.270.2">This approach is computationally expensive but often leads to more robust </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">uncertainty estimates.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.272.1">Deep Gaussian processes</span></strong><span class="koboSpan" id="kobo.273.1">: Deep Gaussian processes combine deep learning with Gaussian processes to provide a </span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.274.1">non-parametric way to estimate uncertainty. </span><span class="koboSpan" id="kobo.274.2">They offer a rich way to capture complex uncertainties but can be computationally challenging</span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.275.1"> for </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">large datasets.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.277.1">Conformal prediction</span></strong><span class="koboSpan" id="kobo.278.1">: Conformal prediction </span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.279.1">provides a set of possible outcomes for a prediction, each with a confidence level. </span><span class="koboSpan" id="kobo.279.2">This set-based prediction approach is designed to guarantee coverage, meaning that the actual outcome will fall within the predicted set with a probability equal to the </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">confidence level.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.281.1">Calibration techniques</span></strong><span class="koboSpan" id="kobo.282.1">: While not directly measuring uncertainty, calibration techniques such as Platt scaling or</span><a id="_idIndexMarker487"/><span class="koboSpan" id="kobo.283.1"> temperature scaling ensure that the predicted confidence scores reflect the true likelihood of correctness. </span><span class="koboSpan" id="kobo.283.2">A well-calibrated model’s predicted probabilities are more interpretable and can be used as a measure </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">of uncertainty.</span></span></li>
</ul>
<h1 id="_idParaDest-124"><a id="_idTextAnchor122"/><span class="koboSpan" id="kobo.285.1">The superiority of conformal prediction in uncertainty quantification</span></h1>
<p><span class="koboSpan" id="kobo.286.1">Quantifying uncertainty is fundamental to building robust and reliable machine learning models. </span><span class="koboSpan" id="kobo.286.2">Several methodologies have emerged over the years, each with its own merits. </span><span class="koboSpan" id="kobo.286.3">However, conformal prediction stands out as </span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.287.1">a particularly compelling framework. </span><span class="koboSpan" id="kobo.287.2">Let’s </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">explain why:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.289.1">Distribution-free framework</span></strong><span class="koboSpan" id="kobo.290.1">: One of the most notable features of conformal prediction is that it doesn’t make any assumptions about the distribution of the data. </span><span class="koboSpan" id="kobo.290.2">Many uncertainty quantification</span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.291.1"> methods are based on certain probabilistic assumptions or rely on specific data distributions to function effectively. </span><span class="koboSpan" id="kobo.291.2">In contrast, conformal prediction remains agnostic to these considerations, making it versatile and widely applicable across </span><span class="No-Break"><span class="koboSpan" id="kobo.292.1">diverse datasets.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.293.1">Theoretical guarantees</span></strong><span class="koboSpan" id="kobo.294.1">: conformal prediction offers robust theoretical guarantees for its predictions. </span><span class="koboSpan" id="kobo.294.2">Specifically, it provides a set of potential outcomes for a prediction, and each outcome is associated with a confidence level. </span><span class="koboSpan" id="kobo.294.3">The framework ensures that the actual outcome will fall within the predicted set with a probability corresponding to the confidence level. </span><span class="koboSpan" id="kobo.294.4">This is a powerful assurance, especially in critical applications where understanding the bounds of a prediction </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">is essential.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.296.1">Model independence</span></strong><span class="koboSpan" id="kobo.297.1">: Another significant advantage of conformal prediction is its independence from the underlying model. </span><span class="koboSpan" id="kobo.297.2">Whether you’re working with a simple linear regression, a complex </span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.298.1">deep learning architecture, or any other model, conformal prediction </span><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.299.1">can be applied seamlessly. </span><span class="koboSpan" id="kobo.299.2">This flexibility ensures that practitioners are open in their choice of model when seeking to </span><span class="No-Break"><span class="koboSpan" id="kobo.300.1">quantify uncertainty.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.301.1">Scalability with dataset size</span></strong><span class="koboSpan" id="kobo.302.1">: conformal prediction is not sensitive to the size of the dataset. </span><span class="koboSpan" id="kobo.302.2">Whether dealing with a small dataset with limited entries or a massive one with millions of data points, the framework remains effective and reliable. </span><span class="koboSpan" id="kobo.302.3">This scalability is especially beneficial in modern applications where data can range from scarce to </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">overwhelmingly abundant.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.304.1">While numerous approaches exist for uncertainty quantification, conformal prediction emerges as a frontrunner due to its distribution-free nature, robust theoretical underpinnings, model independence, and scalability. </span><span class="koboSpan" id="kobo.304.2">For practitioners seeking a robust and reliable method to gauge the uncertainty of their machine learning models, conformal prediction presents a </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">compelling choice.</span></span></p>
<h1 id="_idParaDest-125"><a id="_idTextAnchor123"/><span class="koboSpan" id="kobo.306.1">Conformal prediction for computer vision</span></h1>
<p><span class="koboSpan" id="kobo.307.1">In this section, we will dive deeper into</span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.308.1"> the diverse applications of conformal prediction in computer vision. </span><span class="koboSpan" id="kobo.308.2">With its broad range of problems, from image classification to object detection, computer vision presents challenges that require precise and reliable machine learning models. </span><span class="koboSpan" id="kobo.308.3">As we navigate these applications, we will demonstrate how conformal prediction is a robust tool to quantify the uncertainty associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">these models.</span></span></p>
<p><span class="koboSpan" id="kobo.310.1">By exploring these practical examples, we aim to underscore the importance of understanding the model’s confidence in its predictions. </span><span class="koboSpan" id="kobo.310.2">Understanding is crucial, especially when decisions based on these predictions could have significant consequences. </span><span class="koboSpan" id="kobo.310.3">Conformal prediction, with its ability to provide a measure of uncertainty, can greatly aid researchers and practitioners in making informed decisions based on the outputs of their models. </span><span class="koboSpan" id="kobo.310.4">This improves the system’s reliability and paves the way for more transparent and</span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.311.1"> trustworthy AI implementations in </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">computer vision.</span></span></p>
<h2 id="_idParaDest-126"><a id="_idTextAnchor124"/><span class="koboSpan" id="kobo.313.1">Uncertainty sets for image classifiers using conformal prediction</span></h2>
<p><span class="koboSpan" id="kobo.314.1">In 2020, researchers from the University </span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.315.1">of California, Berkeley, published a paper titled </span><em class="italic"><span class="koboSpan" id="kobo.316.1">Uncertainty sets for image classifiers using Conformal </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.317.1">Prediction</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.318.1"> (</span></span><a href="https://arxiv.org/abs/2009.14193"><span class="No-Break"><span class="koboSpan" id="kobo.319.1">https://arxiv.org/abs/2009.14193</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.320.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.321.1">This was the first time that computer vision researchers applied conformal prediction to the computer vision problem. </span><span class="koboSpan" id="kobo.321.2">The paper described the first conformal prediction method explicitly developed for computer vision, RAPS, which is the current state of the art for </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">image classification.</span></span></p>
<p><span class="koboSpan" id="kobo.323.1">Here are the key points from </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">the paper:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.325.1">The paper proposes a </span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.326.1">new method called </span><strong class="bold"><span class="koboSpan" id="kobo.327.1">regularized adaptive predictive sets</span></strong><span class="koboSpan" id="kobo.328.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.329.1">RAPS</span></strong><span class="koboSpan" id="kobo.330.1">) for generating stable prediction sets with neural network classifiers guaranteed to achieve a desired </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">coverage level.</span></span></li>
<li><span class="koboSpan" id="kobo.332.1">RAPS modifies an existing conformal prediction algorithm to produce smaller, more stable prediction sets by regularizing the influence of noisy probability estimates for </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1">unlikely classes.</span></span></li>
<li><span class="koboSpan" id="kobo.334.1">RAPS is evaluated on ImageNet classification using ResNet and other CNN models. </span><span class="koboSpan" id="kobo.334.2">It achieves the desired coverage levels while producing prediction sets that are substantially smaller (5 to 10 times smaller) than a standalone Platt </span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">scaling baseline.</span></span></li>
<li><span class="koboSpan" id="kobo.336.1">The method satisfies theoretical guarantees on coverage and is proven to provide the best performance for selecting </span><span class="No-Break"><span class="koboSpan" id="kobo.337.1">fixed-size sets.</span></span></li>
<li><span class="koboSpan" id="kobo.338.1">RAPS provides a practical way to obtain prediction sets from any image classifier that can reliably quantify uncertainty and identify complex test examples. </span><span class="koboSpan" id="kobo.338.2">The authors suggest applications in areas such as medical imaging and </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">active learning.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.340.1">Here is a summary of how the</span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.341.1"> RAPS </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">algorithm works:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.343.1">It uses a pre-trained image classifier to compute class probability estimates for images in the calibration set and class probability estimates for a new </span><span class="No-Break"><span class="koboSpan" id="kobo.344.1">test image.</span></span></li>
<li><span class="koboSpan" id="kobo.345.1">For every image within the </span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.346.1">calibration set, RAPS calculates conformity scores, denoted as </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.347.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.348.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.349.1">j</span></span><span class="koboSpan" id="kobo.350.1"> as follows: </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.351.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.352.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.353.1">j</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.354.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.355.1">∑</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.356.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.357.1">i</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.358.1">=</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.359.1">1</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.360.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.361.1">k</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.362.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.363.1">′</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.364.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.365.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.366.1"> </span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.367.1">(</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.368.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.369.1">ˆ</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.370.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.371.1">π</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.372.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.373.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.374.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.375.1">i</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.376.1">)</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.377.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.378.1">x</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.379.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.380.1">j</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.381.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.382.1">+</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.383.1">λ</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.384.1">1</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.385.1">[</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.386.1">i</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.387.1">&gt;</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.388.1">k</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.389.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.390.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.391.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.392.1">g</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.393.1">]</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.394.1">)</span></span><span class="koboSpan" id="kobo.395.1">. </span><span class="koboSpan" id="kobo.395.2">This is achieved by arranging the probability estimates in a descending sequence. </span><span class="koboSpan" id="kobo.395.3">The scores are then computed by accumulating these probability estimates, starting from the highest and continuing down to (and including) the probability estimate of the image’s actual class. </span><span class="koboSpan" id="kobo.395.4">The calculation is illustrated in the following </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.396.1">Figure 9</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.397.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.399.1">A high value of </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.400.1">λ</span></span><span class="koboSpan" id="kobo.401.1"> acts as a deterrent against creating sets that are larger than </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.402.1">k</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.403.1"> </span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.404.1">r</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.405.1">e</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.406.1">g</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.407.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.408.1">As is standard in inductive conformal prediction, the model then computes the 1-alpha quantile of the conformity scores computed on the </span><span class="No-Break"><span class="koboSpan" id="kobo.409.1">calibration set.</span></span></li>
<li><span class="koboSpan" id="kobo.410.1">Outputs the k* highest-score classes where the conformity score </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.411.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.412.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.413.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.414.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.415.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.416.1">t</span></span><span class="koboSpan" id="kobo.417.1"> for the test point is greater or equal the </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">1-alpha quantile.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.419.1">The following figure illustrates</span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.420.1"> the RAPS method. </span><span class="koboSpan" id="kobo.420.2">The figure is from Anastasios N. </span><span class="koboSpan" id="kobo.420.3">Angelopoulos’ blog </span><em class="italic"><span class="koboSpan" id="kobo.421.1">Uncertainty Sets for Image Classifiers using Conformal </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.422.1">Prediction</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.423.1">: (</span></span><a href="https://people.eecs.berkeley.edu/~angelopoulos/blog/posts/conformal-classification/"><span class="No-Break"><span class="koboSpan" id="kobo.424.1">https://people.eecs.berkeley.edu/~angelopoulos/blog/posts/conformal-classification/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.425.1">).</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer057">
<span class="koboSpan" id="kobo.426.1"><img alt="Figure 9.1 – An illustration of the RAPS method (the red line is drawn to achieve exact coverage)" src="image/B19925_09_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.427.1">Figure 9.1 – An illustration of the RAPS method (the red line is drawn to achieve exact coverage)</span></p>
<p><span class="koboSpan" id="kobo.428.1">The parameters </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.429.1">λ</span></span><span class="koboSpan" id="kobo.430.1"> and </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.431.1">k</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.432.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.433.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.434.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.435.1">g</span></span><span class="koboSpan" id="kobo.436.1"> are estimated by the RAPS model on the calibration set. </span><span class="koboSpan" id="kobo.436.2">The intuition behind parameters is that a high </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.437.1">λ</span></span><span class="koboSpan" id="kobo.438.1"> discourages sets larger than </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.439.1">k</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.440.1"> </span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.441.1">r</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.442.1">e</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.443.1">g</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.444.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.445.1">By construction, this </span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.446.1">prediction set provably contains the true class with probability of at least 1-α, where α is the desired error level. </span><span class="koboSpan" id="kobo.446.2">The regularization penalty allows RAPS to produce smaller, more stable sets than previous methods such as Platt scaling or the unregularized </span><span class="No-Break"><span class="koboSpan" id="kobo.447.1">adaptive method.</span></span></p>
<p><span class="koboSpan" id="kobo.448.1">This approach allows researchers to use any underlying classifier and produce predictive sets that are assured to meet a designated error rate, such as 90%, all while maintaining a minimal average size. </span><span class="koboSpan" id="kobo.448.2">Its ease of deployment makes it a compelling, automated method to gauge the uncertainty of image classifiers, which is crucial in areas including medical diagnostics, autonomous vehicles, and screening hazardous </span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">online content.</span></span></p>
<p><span class="koboSpan" id="kobo.450.1">In summary, RAPS</span><a id="_idIndexMarker500"/><span class="koboSpan" id="kobo.451.1"> leverages conformal prediction ideas to guarantee coverage, modifies the conformal score to enable smaller sets, and calibrates the procedure correctly using </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">held-out data.</span></span></p>
<h1 id="_idParaDest-127"><a id="_idTextAnchor125"/><span class="koboSpan" id="kobo.453.1">Building computer vision classifiers using conformal prediction</span></h1>
<p><span class="koboSpan" id="kobo.454.1">Let’s illustrate the application of </span><a id="_idIndexMarker501"/><span class="koboSpan" id="kobo.455.1">conformal prediction to computer vision in practice. </span><span class="koboSpan" id="kobo.455.2">We will use a notebook from the book repository available at </span><strong class="source-inline"><span class="koboSpan" id="kobo.456.1">https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_09.ipynb</span></strong><span class="koboSpan" id="kobo.457.1">. </span><span class="koboSpan" id="kobo.457.2">This notebook extensively uses notebooks from Anastasios Angelopolous’ </span><em class="italic"><span class="koboSpan" id="kobo.458.1">Conformal Prediction</span></em><span class="koboSpan" id="kobo.459.1"> repo </span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">at </span></span><a href="https://github.com/aangelopoulos/conformal-prediction"><span class="No-Break"><span class="koboSpan" id="kobo.461.1">https://github.com/aangelopoulos/conformal-prediction</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.462.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.463.1">After loading the data, set up the problem and define the desired coverage and the number of points in the </span><span class="No-Break"><span class="koboSpan" id="kobo.464.1">calibration set:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.465.1">n_cal = 1000</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.466.1">alpha = 0.1</span></pre>
<p><span class="koboSpan" id="kobo.467.1">The softmax scores were split into the calibration and test datasets, obtaining calibration and </span><span class="No-Break"><span class="koboSpan" id="kobo.468.1">test labels:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.469.1">idx = np.array([1] * n_cal + [0] * (smx.shape[0]-n_cal)) &gt; 0</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.470.1">np.random.seed(42)</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.471.1">np.random.shuffle(idx)</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.472.1">cal_smx, test_smx = smx[idx,:], smx[~idx,:]</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.473.1">cal_labels, test_labels = labels[idx], labels[~idx]</span></pre>
<p><span class="koboSpan" id="kobo.474.1">The test dataset contains 49,000 points, and the calibration dataset contains 1,000 points. </span><span class="koboSpan" id="kobo.474.2">Both datasets include images and human-readable labels from the </span><span class="No-Break"><span class="koboSpan" id="kobo.475.1">ImageNet dataset.</span></span></p>
<h2 id="_idParaDest-128"><a id="_idTextAnchor126"/><span class="koboSpan" id="kobo.476.1">Naïve Conformal prediction</span></h2>
<p><span class="koboSpan" id="kobo.477.1">We'll first look at a naïve way to produce </span><a id="_idIndexMarker502"/><span class="koboSpan" id="kobo.478.1">prediction sets using </span><span class="No-Break"><span class="koboSpan" id="kobo.479.1">conformal prediction:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.480.1">Compute a non-conformity </span><a id="_idIndexMarker503"/><span class="koboSpan" id="kobo.481.1">score for each </span><span class="No-Break"><span class="koboSpan" id="kobo.482.1">calibration point</span></span></li>
<li><span class="koboSpan" id="kobo.483.1"> Then, an empirical quantile of the calibration scores will </span><span class="No-Break"><span class="koboSpan" id="kobo.484.1">be evaluated</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.485.1">This closely resembles what we observed with inductive conformal prediction in earlier chapters. </span><span class="koboSpan" id="kobo.485.2">We determine non-conformity scores through hinge loss, and then use the distribution of these scores to calculate the quantile based on the desired coverage. </span><span class="koboSpan" id="kobo.485.3">This process, including the final sample correction formula, parallels our approach for inductive </span><span class="No-Break"><span class="koboSpan" id="kobo.486.1">conformal prediction:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.487.1">cal_scores = 1-cal_smx[np.arange(n_cal),cal_labels]</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.488.1">q_level = np.ceil((n_cal+1)*(1-alpha))/n_cal</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.489.1">qhat = np.quantile(cal_scores, q_level, method='higher')</span></pre>
<p><span class="koboSpan" id="kobo.490.1">We can form the prediction sets for test set objects using the computed get adjusted quantile on </span><span class="No-Break"><span class="koboSpan" id="kobo.491.1">nonconformity scores:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.492.1">prediction_sets = test_smx &gt;= (1-qhat)</span></pre>
<p><span class="koboSpan" id="kobo.493.1">The result is an array showcasing sets of predictions. </span><span class="koboSpan" id="kobo.493.2">This Boolean array signifies ImageNet classes according to the Boolean values it holds. </span><span class="koboSpan" id="kobo.493.3">The Boolean values indicate the classes chosen by the model, with </span><strong class="source-inline"><span class="koboSpan" id="kobo.494.1">True</span></strong><span class="koboSpan" id="kobo.495.1"> signifying a class is selected and </span><strong class="source-inline"><span class="koboSpan" id="kobo.496.1">False</span></strong><span class="koboSpan" id="kobo.497.1"> meaning the class is not included in the </span><span class="No-Break"><span class="koboSpan" id="kobo.498.1">prediction set.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer058">
<span class="koboSpan" id="kobo.499.1"><img alt="Figure 9.2 – An illustration of the prediction sets for the test set" src="image/B19925_09_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.500.1">Figure 9.2 – An illustration of the prediction sets for the test set</span></p>
<p><span class="koboSpan" id="kobo.501.1">We can calculate the </span><a id="_idIndexMarker504"/><span class="koboSpan" id="kobo.502.1">empirical coverage, which comes very close to the specified confidence level </span><span class="No-Break"><span class="koboSpan" id="kobo.503.1">of 90%:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.504.1">empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),test_labels].mean()</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.505.1">print(f"The empirical coverage is: {empirical_coverage}")</span></pre>
<p><span class="koboSpan" id="kobo.506.1">We can look at some of the objects and </span><span class="No-Break"><span class="koboSpan" id="kobo.507.1">prediction sets.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<span class="koboSpan" id="kobo.508.1"><img alt="Figure 9.3 – An object from the test set, the prediction set produced by the naïve variant of conformal prediction was the label &quot;palace&quot;" src="image/B19925_09_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.509.1">Figure 9.3 – An object from the test set, the prediction set produced by the naïve variant of conformal prediction was the label "palace"</span></p>
<p><span class="koboSpan" id="kobo.510.1">For objects</span><a id="_idIndexMarker505"/><span class="koboSpan" id="kobo.511.1"> with higher</span><a id="_idIndexMarker506"/><span class="koboSpan" id="kobo.512.1"> levels of uncertainty, prediction sets contain more than </span><span class="No-Break"><span class="koboSpan" id="kobo.513.1">one element.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer060">
<span class="koboSpan" id="kobo.514.1"><img alt="Figure 9.4 – An object from the test set, the prediction set produced by the naïve variant of conformal prediction was [‘Crock Pot’, ‘digital clock’]" src="image/B19925_09_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.515.1">Figure 9.4 – An object from the test set, the prediction set produced by the naïve variant of conformal prediction was [‘Crock Pot’, ‘digital clock’]</span></p>
<p><span class="koboSpan" id="kobo.516.1">The naïve method presents two </span><span class="No-Break"><span class="koboSpan" id="kobo.517.1">significant issues:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.518.1">Firstly, the </span><a id="_idIndexMarker507"/><span class="koboSpan" id="kobo.519.1">probabilities produced by CNNs often need to be more accurate, resulting in sets that don’t achieve the </span><span class="No-Break"><span class="koboSpan" id="kobo.520.1">intended coverage</span></span></li>
<li><span class="koboSpan" id="kobo.521.1">Secondly, for instances where the model lacks confidence, the naive method must include </span><a id="_idIndexMarker508"/><span class="koboSpan" id="kobo.522.1">numerous classes to attain the desired confidence threshold, leading to an excessively </span><span class="No-Break"><span class="koboSpan" id="kobo.523.1">large set</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.524.1">Temperature scaling isn’t a remedy, as it only adjusts the score of the primary class, and calibrating the remaining scores is an overwhelming task. </span><span class="koboSpan" id="kobo.524.2">Interestingly, even with the perfect calibration of all scores, the naive approach would still fall short of </span><span class="No-Break"><span class="koboSpan" id="kobo.525.1">achieving coverage.</span></span></p>
<p><span class="koboSpan" id="kobo.526.1">Alternative ways of constructing prediction sets were developed to address these issues, namely </span><strong class="bold"><span class="koboSpan" id="kobo.527.1">Adaptive Prediction Sets</span></strong><span class="koboSpan" id="kobo.528.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.529.1">APS</span></strong><span class="koboSpan" id="kobo.530.1">) and </span><strong class="bold"><span class="koboSpan" id="kobo.531.1">Regularized</span></strong> <strong class="bold"><span class="koboSpan" id="kobo.532.1">Adaptive Prediction </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.533.1">Sets</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.534.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.535.1">RAPS</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.536.1">).</span></span></p>
<h2 id="_idParaDest-129"><a id="_idTextAnchor127"/><span class="koboSpan" id="kobo.537.1">Adaptive Prediction Sets (APS)</span></h2>
<p><span class="koboSpan" id="kobo.538.1">Next, we'll look at APS, described in the </span><a id="_idIndexMarker509"/><span class="koboSpan" id="kobo.539.1">NeurIPS spotlight paper, </span><em class="italic"><span class="koboSpan" id="kobo.540.1">Classification with Valid and Adaptive Coverage</span></em><span class="koboSpan" id="kobo.541.1"> (</span><span class="No-Break"><span class="koboSpan" id="kobo.542.1">2000) (</span></span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">https://proceedings.neurips.cc/paper/2020/file/244edd7e85dc81602b7615cd705545f5-Paper.pdf</span></span><span class="No-Break"><span class="koboSpan" id="kobo.544.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.545.1">In essence, APS presents a simple approach. </span><span class="koboSpan" id="kobo.545.2">Instead of directly using the softmax scores, a new threshold is determined based on a calibration dataset. </span><span class="koboSpan" id="kobo.545.3">For example, if sets with a projected probability of 93% yield a 90% coverage on the calibration set, then a 93% threshold would be adopted. </span><span class="koboSpan" id="kobo.545.4">APS is a particular implementation of RAPS, and unlike the naïve approach, it aims to achieve </span><span class="No-Break"><span class="koboSpan" id="kobo.546.1">precise coverage.</span></span></p>
<p><span class="koboSpan" id="kobo.547.1">However, APS does face a practical hurdle: the average size of its sets is significantly large. </span><span class="koboSpan" id="kobo.547.2">Deep learning classifiers </span><a id="_idIndexMarker510"/><span class="koboSpan" id="kobo.548.1">grapple with a permutation dilemma: their scores for less certain classes, such as those ranked from 10 to 1,000, don’t reflect accurate probability estimates. </span><span class="koboSpan" id="kobo.548.2">The arrangement of these classes is largely swayed by noise, prompting APS to opt for vast sets, especially for </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">complex images.</span></span></p>
<p><span class="koboSpan" id="kobo.550.1">The code describing APS is </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.552.1"># Get scores. </span><span class="koboSpan" id="kobo.552.2">calib_X.shape[0] == calib_Y.shape[0] == n</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.553.1">cal_pi = cal_smx.argsort(1)[:, ::-1]</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.554.1">cal_srt = np.take_along_axis(cal_smx, cal_pi, axis=1).cumsum(axis=1)</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.555.1">cal_scores = np.take_along_axis(cal_srt, cal_pi.argsort(axis=1), axis=1)[</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.556.1">    range(n_cal), cal_labels</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.557.1">]</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.558.1"># Get the score quantile</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.559.1">qhat = np.quantile(</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.560.1">    cal_scores, np.ceil((n_cal + 1) * (1 - alpha)) / n_cal, method="higher"</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.561.1">)</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.562.1">test_pi = test_smx.argsort(1)[:, ::-1]</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.563.1">test_srt = np.take_along_axis(test_smx, test_pi, axis=1).cumsum(axis=1)</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.564.1">prediction_sets = np.take_along_axis(test_srt &lt;= qhat, test_pi.argsort(axis=1), axis=1)</span></pre>
<p><span class="koboSpan" id="kobo.565.1">Let’s look at the code in </span><a id="_idIndexMarker511"/><span class="koboSpan" id="kobo.566.1">more detail. </span><span class="koboSpan" id="kobo.566.2">It uses APS to generate prediction sets based on a specified </span><span class="No-Break"><span class="koboSpan" id="kobo.567.1">quantile threshold:</span></span></p>
<ol>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.568.1">Calibration phase</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.569.1">:</span></span><ol><li class="upper-roman"> <strong class="source-inline"><span class="koboSpan" id="kobo.570.1">cal_pi = cal_smx.argsort(1)[:, ::-1]</span></strong><span class="koboSpan" id="kobo.571.1">: This sorts the softmax scores `</span><strong class="source-inline"><span class="koboSpan" id="kobo.572.1">cal_smx</span></strong><span class="koboSpan" id="kobo.573.1"> for each</span><a id="_idIndexMarker512"/><span class="koboSpan" id="kobo.574.1"> instance score from </span><strong class="source-inline"><span class="koboSpan" id="kobo.575.1">cal_smx</span></strong><span class="koboSpan" id="kobo.576.1"> in descending order and returns the indices of the </span><span class="No-Break"><span class="koboSpan" id="kobo.577.1">sorted values.</span></span></li><li class="upper-roman"><strong class="source-inline"><span class="koboSpan" id="kobo.578.1">cal_srt = np.take_along_axis(cal_smx, cal_pi, axis=1).cumsum(axis=1)</span></strong><span class="koboSpan" id="kobo.579.1">: For each row, it rearranges the scores based on the indices from </span><strong class="source-inline"><span class="koboSpan" id="kobo.580.1">cal_pi</span></strong><span class="koboSpan" id="kobo.581.1">, then computes the cumulative sum along </span><span class="No-Break"><span class="koboSpan" id="kobo.582.1">the columns.</span></span></li><li class="upper-roman"><strong class="source-inline"><span class="koboSpan" id="kobo.583.1">cal_scores = np.take_along_axis(cal_srt, cal_pi.argsort(axis=1), axis=1)[range(n_cal), cal_labels]</span></strong><span class="koboSpan" id="kobo.584.1">: This step retrieves the specific scores corresponding to the true labels </span><strong class="source-inline"><span class="koboSpan" id="kobo.585.1">(cal_labels)</span></strong><span class="koboSpan" id="kobo.586.1">. </span><span class="koboSpan" id="kobo.586.2">It first reverts the sorted order of </span><strong class="source-inline"><span class="koboSpan" id="kobo.587.1">cal_pi</span></strong><span class="koboSpan" id="kobo.588.1"> to get the original </span><a id="_idIndexMarker513"/><span class="koboSpan" id="kobo.589.1">ordering and then picks the scores associated with the true labels for </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">each instance.</span></span></li></ol></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.591.1">Determine </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.592.1">quantile threshold</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.593.1">:</span></span><ol><li class="upper-roman"><strong class="source-inline"><span class="koboSpan" id="kobo.594.1">qhat = np.quantile(cal_scores, np.ceil((n_cal + 1) * (1 - alpha)) / n_cal, method="higher")</span></strong><span class="koboSpan" id="kobo.595.1">: Calculates the quantile value based on the provided </span><strong class="source-inline"><span class="koboSpan" id="kobo.596.1">alpha</span></strong><span class="koboSpan" id="kobo.597.1">. </span><span class="koboSpan" id="kobo.597.2">This value will serve as the threshold for the </span><a id="_idIndexMarker514"/><span class="No-Break"><span class="koboSpan" id="kobo.598.1">prediction phase.</span></span></li></ol></li>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.599.1">Prediction phase</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.600.1">:</span></span><ol><li class="upper-roman"><strong class="source-inline"><span class="koboSpan" id="kobo.601.1">test_pi = test_smx.argsort(1)[:, ::-1]</span></strong><span class="koboSpan" id="kobo.602.1">: Similarly, for the test set, it sorts the</span><a id="_idIndexMarker515"/><span class="koboSpan" id="kobo.603.1"> scores from </span><strong class="source-inline"><span class="koboSpan" id="kobo.604.1">test_smx</span></strong><span class="koboSpan" id="kobo.605.1"> in descending order and returns the indices of the </span><a id="_idIndexMarker516"/><span class="No-Break"><span class="koboSpan" id="kobo.606.1">sorted values.</span></span></li><li class="upper-roman"><strong class="source-inline"><span class="koboSpan" id="kobo.607.1">test_srt= np.take_along_axis(test_smx, test_pi, axis=1).cumsum(axis=1)</span></strong><span class="koboSpan" id="kobo.608.1">: Rearranges the test set scores based on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.609.1">test_pi</span></strong><span class="koboSpan" id="kobo.610.1"> sorted indices and computes the </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">cumulative sum.</span></span></li><li class="upper-roman"><strong class="source-inline"><span class="koboSpan" id="kobo.612.1">prediction_sets= np.take_along_axis(test_srt &lt;= qhat, test_pi.argsort(axis=1), axis=1)</span></strong><span class="koboSpan" id="kobo.613.1">: For each instance in the test set, it determines which scores are below the quantile threshold </span><strong class="source-inline"><span class="koboSpan" id="kobo.614.1">qhat</span></strong><span class="koboSpan" id="kobo.615.1">. </span><span class="koboSpan" id="kobo.615.2">This Boolean array (</span><strong class="source-inline"><span class="koboSpan" id="kobo.616.1">test_srt &lt;= qhat</span></strong><span class="koboSpan" id="kobo.617.1">) is then rearranged into its original order using </span><strong class="source-inline"><span class="koboSpan" id="kobo.618.1">test_pi.argsort(axis=1)</span></strong><span class="koboSpan" id="kobo.619.1">, resulting in the final prediction sets </span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.620.1">where </span><strong class="source-inline"><span class="koboSpan" id="kobo.621.1">True</span></strong><span class="koboSpan" id="kobo.622.1"> entries indicate inclusion in </span><span class="No-Break"><span class="koboSpan" id="kobo.623.1">the set.</span></span></li></ol></li>
</ol>
<p><span class="koboSpan" id="kobo.624.1">In essence, this code is used to calibrate model scores to define a threshold and then uses this threshold to generate prediction sets for a new (</span><span class="No-Break"><span class="koboSpan" id="kobo.625.1">test) dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.626.1">We can look at some objects and prediction sets generated </span><span class="No-Break"><span class="koboSpan" id="kobo.627.1">by APS.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer061">
<span class="koboSpan" id="kobo.628.1"><img alt="Figure 9.5 – An object from the test set" src="image/B19925_09_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.629.1">Figure 9.5 – An object from the test set</span></p>
<p><span class="koboSpan" id="kobo.630.1">Unfortunately, as</span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.631.1"> already mentioned and demonstrated in this example, the prediction sets produced by APS </span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.632.1">can be vast. </span><span class="koboSpan" id="kobo.632.2">The preceding example produced a prediction </span><span class="No-Break"><span class="koboSpan" id="kobo.633.1">set of:</span></span></p>
<p><span class="koboSpan" id="kobo.634.1">['King Charles Spaniel', 'Rhodesian Ridgeback', 'Afghan Hound', 'Basset Hound', 'Bloodhound', 'Redbone Coonhound', 'Otterhound', 'Weimaraner', 'Irish Terrier', 'Norfolk Terrier', 'Norwich Terrier', 'Australian Terrier', 'Dandie Dinmont Terrier', 'Tibetan Terrier', 'Soft-coated Wheaten Terrier', 'Flat-Coated Retriever', 'Golden Retriever', 'Labrador Retriever', 'Vizsla', 'English Setter', 'Irish Setter', 'Gordon Setter', 'Clumber Spaniel', 'English Springer Spaniel', 'Welsh Springer Spaniel', 'Cocker Spaniels', 'Sussex Spaniel', 'Irish Water Spaniel', 'Briard', 'Bullmastiff', 'Leonberger', 'Newfoundland', 'Chow Chow', 'Miniature Poodle', 'Standard Poodle', 'lion', 'brown bear', 'grasshopper', 'leafhopper', 'doormat', 'handkerchief', 'maze', 'prayer rug', 'tennis </span><span class="No-Break"><span class="koboSpan" id="kobo.635.1">ball', 'acorn'].</span></span></p>
<h2 id="_idParaDest-130"><a id="_idTextAnchor128"/><span class="koboSpan" id="kobo.636.1">Regularized Adaptive Prediction Sets (RAPS)</span></h2>
<p><span class="koboSpan" id="kobo.637.1">We now get hands-on with RAPS, which </span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.638.1">was briefly introduced in the </span><em class="italic"><span class="koboSpan" id="kobo.639.1">Uncertainty sets for image classifiers using conformal prediction</span></em><span class="koboSpan" id="kobo.640.1"> section earlier in </span><span class="No-Break"><span class="koboSpan" id="kobo.641.1">this chapter.</span></span></p>
<p><span class="koboSpan" id="kobo.642.1">We set the RAPS regularization parameters (a larger </span><strong class="source-inline"><span class="koboSpan" id="kobo.643.1">lam_reg</span></strong><span class="koboSpan" id="kobo.644.1"> value and smaller </span><strong class="source-inline"><span class="koboSpan" id="kobo.645.1">k_reg</span></strong><span class="koboSpan" id="kobo.646.1"> value leads to smaller sets) and regularization vector in the following </span><span class="No-Break"><span class="koboSpan" id="kobo.647.1">code block:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.648.1">lam_reg = 0.01</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.649.1">k_reg = 5</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.650.1">disallow_zero_sets = False</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.651.1">rand = True</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.652.1">reg_vec = np.array(k_reg*[0,] + (smx.shape[1]-k_reg)*[lam_reg,])[None,:]</span></pre>
<p><span class="koboSpan" id="kobo.653.1">As previously, we </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.654.1">compute non-conformity scores and obtain </span><span class="No-Break"><span class="koboSpan" id="kobo.655.1">score quantiles:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.656.1">cal_pi = cal_smx.argsort(1)[:,::-1];</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.657.1">cal_srt = np.take_along_axis(cal_smx,cal_pi,axis=1)</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.658.1">cal_srt_reg = cal_srt + reg_vec</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.659.1">cal_L = np.where(cal_pi == cal_labels[:,None])[1]</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.660.1">cal_scores = cal_srt_reg.cumsum(axis=1)[np.arange(n_cal),cal_L] - np.random.rand(n_cal)*cal_srt_reg[np.arange(n_cal),cal_L]</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.661.1">qhat = np.quantile(cal_scores, np.ceil((n_cal+1)*(1-alpha))/n_cal, method='higher')</span></pre>
<p><span class="koboSpan" id="kobo.662.1">We can deploy predictions on the test set using the </span><span class="No-Break"><span class="koboSpan" id="kobo.663.1">following code:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.664.1">n_test = test_smx.shape[0]</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.665.1">test_pi = test_smx.argsort(1)[:,::-1]</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.666.1">test_srt = np.take_along_axis(test_smx,test_pi,axis=1)</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.667.1">test_srt_reg = test_srt + reg_vec</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.668.1">test_srt_reg_cumsum = test_srt_reg.cumsum(axis=1)</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.669.1">indicators = (test_srt_reg.cumsum(axis=1) - np.random.rand(n_test,1)*test_srt_reg) &lt;= qhat if rand else test_srt_reg.cumsum(axis=1) -test_srt_reg &lt;= qhat</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.670.1">if disallow_zero_sets: indicators[:,0] = True</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.671.1">prediction_sets = np.take_along_axis(indicators,test_pi.argsort(axis=1),axis=1)</span></pre>
<p><span class="koboSpan" id="kobo.672.1">Let’s look at some</span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.673.1"> objects and prediction sets </span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.674.1">generated </span><span class="No-Break"><span class="koboSpan" id="kobo.675.1">by RAPS.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer062">
<span class="koboSpan" id="kobo.676.1"><img alt="Figure 9.6 – An object from the test set﻿; the prediction set produced by RAPS was [‘electric ray’]" src="image/B19925_09_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.677.1">Figure 9.6 – An object from the test set; the prediction set produced by RAPS was [‘electric ray’]</span></p>
<p><span class="koboSpan" id="kobo.678.1">We can see that for objects with little uncertainty, RAPS produces one-element prediction sets. </span><span class="koboSpan" id="kobo.678.2">Unlike </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.679.1">APS, RAPS still produces rather parsimonious prediction sets for objects involving </span><span class="No-Break"><span class="koboSpan" id="kobo.680.1">more uncertainty.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer063">
<span class="koboSpan" id="kobo.681.1"><img alt="Figure 9﻿.7 – An object from the test set﻿; the prediction set produced by RAPS was [‘red wolf’, ‘coyote’, ‘dhole’, ‘gray fox’]" src="image/B19925_09_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.682.1">Figure 9.7 – An object from the test set; the prediction set produced by RAPS was [‘red wolf’, ‘coyote’, ‘dhole’, ‘gray fox’]</span></p>
<p><span class="koboSpan" id="kobo.683.1">Let’s summarize the</span><a id="_idIndexMarker525"/> <span class="No-Break"><span class="koboSpan" id="kobo.684.1">chapter next.</span></span></p>
<h1 id="_idParaDest-131"><a id="_idTextAnchor129"/><span class="koboSpan" id="kobo.685.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.686.1">In the rapidly evolving realm of technology, computer vision has transformed from mere image recognition into an integral component of countless real-world applications. </span><span class="koboSpan" id="kobo.686.2">As these applications span diverse fields such as autonomous vehicles and medical diagnostics, the pressure on computer vision models to deliver accurate and reliable predictions intensifies. </span><span class="koboSpan" id="kobo.686.3">With the growing sophistication of these models comes a dire need: quantifying </span><span class="No-Break"><span class="koboSpan" id="kobo.687.1">prediction uncertainties.</span></span></p>
<p><span class="koboSpan" id="kobo.688.1">This is where conformal prediction shines. </span><span class="koboSpan" id="kobo.688.2">Unlike traditional models that typically output a singular prediction, conformal prediction offers a range of potential outcomes, each coupled with a confidence measure. </span><span class="koboSpan" id="kobo.688.3">This novel approach grants users a detailed perspective on model predictions, which is invaluable for applications where precision </span><span class="No-Break"><span class="koboSpan" id="kobo.689.1">is paramount.</span></span></p>
<p><span class="koboSpan" id="kobo.690.1">This chapter delved into the symbiotic relationship between conformal prediction and computer vision. </span><span class="koboSpan" id="kobo.690.2">We started by emphasizing the importance of uncertainty quantification in computer vision, citing its pivotal role in areas including autonomous transportation and medical imaging. </span><span class="koboSpan" id="kobo.690.3">Further, we shed light on a major area for improvement in contemporary deep learning models: their tendency to deliver </span><span class="No-Break"><span class="koboSpan" id="kobo.691.1">miscalibrated predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.692.1">By working through this chapter, you have acquired the expertise to craft cutting-edge computer vision classifiers infused with the capabilities of conformal prediction. </span><span class="koboSpan" id="kobo.692.2">Additionally, you got experience of the top-tier open source conformal prediction tools tailored for computer vision, ensuring you’re well equipped for </span><span class="No-Break"><span class="koboSpan" id="kobo.693.1">future endeavors.</span></span></p>
<p><span class="koboSpan" id="kobo.694.1">The key achievements in this chapter are to grasp the role of uncertainty quantification in computer vision, unravel the reasons behind deep learning’s miscalibrated predictions, explore diverse strategies to measure uncertainty in computer vision tasks, comprehend the fundamentals and applications of conformal prediction in computer vision, and attain mastery of constructing computer vision classifiers powered by </span><span class="No-Break"><span class="koboSpan" id="kobo.695.1">conformal prediction.</span></span></p>
<p><span class="koboSpan" id="kobo.696.1">In the next chapter, we will navigate the world of conformal prediction in NLP, understand its significance, and learn how to harness its power for more reliable and </span><span class="No-Break"><span class="koboSpan" id="kobo.697.1">confident predictions.</span></span></p>
</div>
</body></html>