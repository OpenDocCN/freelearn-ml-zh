- en: Credit Card Fraud Detection Using Autoencoders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fraud management has been known to be a very painful problem for banking and
    finance firms. Card-related frauds have proven to be especially difficult for
    firms to combat. Technologies such as chip and PIN are available and are already
    used by most credit card system vendors, such as Visa and MasterCard. However,
    the available technology is unable to curtail 100% of credit card fraud. Unfortunately,
    scammers come up with newer ways of phishing to obtain passwords from credit card
    users. Also, devices such as skimmers make stealing credit card data a cake walk!
  prefs: []
  type: TYPE_NORMAL
- en: Despite the availability of some technical abilities to combat credit card fraud,
    *The Nilson Report*, a leading publication covering payment systems worldwide,
    estimated that credit card fraud is going to soar to $32 billion in 2020 ([https://nilsonreport.com/upload/content_promo/The_Nilson_Report_10-17-2017.pdf](https://nilsonreport.com/upload/content_promo/The_Nilson_Report_10-17-2017.pdf)).
    To get a perspective on the estimated loss, it is more than the recent profits
    posted by companies such as Coca-Cola ($2 billion), Warren Buffet’s Berkshire
    Hathaway ($24 billion), and JP Morgan Chase ($23.5 billion)!
  prefs: []
  type: TYPE_NORMAL
- en: 'While credit card chip technology-providing companies have been investing hugely
    to advance the technology to counter credit card fraud, in this chapter, we are
    going to examine whether and how far machine learning can help deal with the credit
    card fraud problem. We will cover the following topics as we progress through
    this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning in credit card fraud detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoencoders and the various types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The credit card fraud dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building AEs with the H2O library in R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of auto encoder for credit card fraud detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning in credit card fraud detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The task of fraud detection often boils down to outlier detection, in which
    a dataset is verified to find potential anomalies in the data. Traditionally,
    this task was deemed a manual task, where risk experts checked all transactions
    manually. Even though there is a technical layer, it is purely based on a rules
    base that scans through each transaction, and then those shortlisted as suspicious
    are sent through for a manual review to make a final decision on the transaction.
    However, there are some major drawbacks to this system:'
  prefs: []
  type: TYPE_NORMAL
- en: Organizations need substantial fraud management budgets for manual review staff.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extensive training is required to train the employees working as manual review
    staff.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training the personnel to manually review transactions is time consuming and
    expensive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even the most highly trained manual review staff carry certain biases, therefore
    making the whole review system inaccurate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual reviews increase the time required to fulfill a transaction. The customers
    might get frustrated with the long wait times required to pass a credit card transaction.
    This may impact the loyalty of customers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual reviews may yield false positives. A false positive not only affects
    the sale in the process but also lifetime value generated from the customer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fortunately, with the rise of **machine learning** (**ML**), **artificial intelligence**
    (**AI**), and deep learning, it became feasible to automate the manual credit
    card transaction review process to a large extent. This not only saves an intensive
    amount of labor but also yields better detection of credit card fraud, which otherwise
    is impacted due to biases that human reviewers carry.
  prefs: []
  type: TYPE_NORMAL
- en: ML-based fraud detection strategies generally can be accomplished using both
    supervised ML and unsupervised ML techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised ML models are generally used when large amounts of transaction data
    tagged as **genuine **or **fraud **are available. A model is trained on the labeled
    dataset and the resultant model is then used for classifying any new credit card
    transactions into one of the two possible classes.
  prefs: []
  type: TYPE_NORMAL
- en: With most organizations, the problem is that labeled data is unavailable, or
    very little labeled data is available. This makes supervised learning models less
    feasible. This is where unsupervised models come into play. They are designed
    to spot anomalous behavior in transactions and they do not need explicit pre-labeled
    data to identify the anomalous behavior. The general idea in unsupervised fraud
    detection is to detect behavior anomalies by identifying transactions that do
    not conform to the majority.
  prefs: []
  type: TYPE_NORMAL
- en: Another thing to keep in mind is that fraud events are rare, and are not as
    common as genuine transactions. Due to the rarity of fraud, severe class imbalance
    problem may be seen in datasets related to credit card fraud. In other words,
    one would observe that 95% or more of the data in the dataset is of genuine transactions,
    and less than 5% of the data belongs to fraudulent transactions. Also, even if
    you learn about a fraudulent transaction today, the model is likely to face an
    anomaly tomorrow with different features. So, the problem space of genuine transactions
    is well known and it is pretty much stagnant; however, the problem space for fraudulent
    transactions is not well known and it is not constant. Due to these reasons, it
    make sense to deal with the fraud detection problem with unsupervised learning
    rather than supervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anomaly detection is an unsupervised learning algorithm that is also termed
    a **one-class classification** algorithm. It distinguishes between **normal** and
    **anomalous** observations. The key principle on which the algorithm is built
    is that anomalous observations do not conform to the expected pattern of other
    common observations in a dataset. It is called a one-class classification as it
    learns the pattern of genuine transactions, and anything that shows non-conformance
    to this pattern is termed as an **anomaly**, and therefore as a fraudulent **transaction**.
    The following figure is an illustration showing anomaly detection in a two-dimensional
    space:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a74dd4da-4def-42ae-aa44-3d2cf811cb62.png)'
  prefs: []
  type: TYPE_IMG
- en: Anomaly detection illustrated in 2D space
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple example of an anomaly is the identification of data points that are
    too far from the mean (standard deviation) in a time series. The following figure
    is an illustration displaying the data points that are identified as anomalies
    in a time series:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9a73590b-e9ae-403e-86b8-b13ce39d2a66.png)'
  prefs: []
  type: TYPE_IMG
- en: Anomaly in time series—identified through standard deviation
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will focus our efforts on a type of unsupervised deep learning
    application known as **AEs**.
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Autoencoders** (**AEs**) are neural networks that are of a feedforward and
    non-recurrent type. They aim to copy the given inputs to the outputs. An AE works
    by compressing the input into a lower dimensional summary. This summary is often
    referred as latent space representation. An AE attempts to reconstruct the output
    from the latent space representation. An **Encoder**, a **Latent Space Representation**,
    and a **Decoder** are the three parts that make up the AEs. The following figure
    is an illustration showing the application of an AE on a sample picked from the MNIST
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ec6a118-78cf-4d2c-9747-e56c5f0a31fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Application of AE on MNIST dataset sample
  prefs: []
  type: TYPE_NORMAL
- en: 'The encoder and decoder components of AEs are fully-connected feedforward networks.
    The number of neurons in a latent space representation is a hyperparameter that
    needs to be passed as part of building the AE. The number of neurons or nodes
    that is decided in the latent semantic space dictates the amount of compression
    that is attained while compressing the actual input image into a latent space
    representation. The general architecture of an AE is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bfd126a4-2ff5-4855-860e-3fbf58cf59e0.png)'
  prefs: []
  type: TYPE_IMG
- en: General architecture of a AE
  prefs: []
  type: TYPE_NORMAL
- en: The given input first passes through an **Encoder**, which is a fully-connected
    **artificial neural network** (**ANN**). The **Encoder** acts upon the **Input**
    and reduces its dimensions, as specified in the hyperparameter. The **Decoder**
    is another fully-connected ANN that picks up this reduced **Input** (latent space
    representation) and then reconstructs the **Output**. The goal is to get the **Output**
    identical to that of the **Input**. In general, the architectures of the **Encoder**
    and the **Decoder** are mirror images. Although there is no such requirement that
    mandates that the **Encoder** and **Decoder** architectures should be the same,
    it is generally practiced that way. In fact, the only requirement of the AE is
    to obtain identical output from that of the given input. Anything in between can
    be customized to the whims and fancies of the individual building the AE.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, the encoder can be represented as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/f0867ffa-839a-4d32-b873-572ef7961eb2.png)]'
  prefs: []
  type: TYPE_NORMAL
- en: 'where *x* is the input and *h* is the function that acts on the input to represent
    it in a concise summary format. A decoder, on the other hand, can be represented
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/f8c2a45f-0bf3-4960-bc5b-5d66df7ad3a2.png).]'
  prefs: []
  type: TYPE_NORMAL
- en: While the expectation is to obtain ![](img/7eed3d3e-b794-4999-a444-e13c99a809a8.png),
    this is not always the case as the reconstruction is done from a compact summary
    representation; therefore, there is occurrence of certain error. The error *e*
    is computed from the original input *x* and reconstructed output *r*, ![](img/71b0ef36-ab8e-44a8-9243-cfb52997e5e1.png)
    .
  prefs: []
  type: TYPE_NORMAL
- en: The AE network then learns by reducing the **Mean Squared Error** (**MSE**),
    and the error is propagated back to the hidden layers for adjustment. The weights
    of the decoder and encoder are transposes of each other, which makes it faster
    to learn training parameters. The mirrored architectures of the encoder and decoder
    make it possible to learn the training parameters faster. In different architectures,
    the weights cannot be simply transposed; therefore, the computation time will
    increase. This is the reason for keeping the mirrored architectures for the encoder
    and decoder.
  prefs: []
  type: TYPE_NORMAL
- en: Types of AEs based on hidden layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Based on the size of the hidden layer, AEs can be classified into two types, **undercomplete
    AEs** and **overcomplete AEs**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Undercomplete AE**: If the AE simply learns to copy the input to the output,
    then it is not useful. The idea is to produce a concise representation as the
    output of the encoder, and this concise representation should consist of the most
    useful features of the input. The amount of conciseness achieved by the input
    layer is governed by the number of neurons or nodes that we use in the latent
    space representation. This can be set as a parameter while building the AE. If
    the number of neurons is set to fewer dimensions than that of the input features,
    then the AE is forced to learn most of the key features of the input data. The
    architecture where the number of neurons in latent space is less than that of
    input dimensions is called an undercomplete AE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overcomplete AE**: It is possible to represent the number of neurons in latent
    space as equal to or more than that of the input dimensions. This kind of architecture
    is termed an overcomplete AE.  In this case, the AE does not learn anything and
    simply copies the input to the latent space, which in turn is propagated through
    to the decoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apart from the number of neurons in the latent space, the following are some
    of the other parameters that can be used in an AE architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Number of layers in the encoder and decoder**: The depth of the encoder and
    decoder can be set to any number. Generally, in a mirrored architecture of encoder
    and decoder, the number of layers is set as the same number. The last figure is
    an illustration showing the AE with two layers, excluding the input and output,
    in both the encoder and decoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of neurons per layer in encoder and decoder**: The number of neurons
    decreases with each layer in an encoder and it increases with each layer in a
    decoder. The neurons in layers of encoders and decoders are symmetric.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Loss function**: Loss functions such as MSE or cross-entropy are used by
    AEs to learn the weights during backpropagation. If the input is in the range
    of (0,1), then cross-entropy is used as metric, otherwise MSE is used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of AEs based on restrictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Based on the restrictions imposed on the loss, AEs can be grouped into the
    following types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Plain Vanilla AEs**: This is the simplest AE architecture possible, with
    a fully-connected neural layer as the encoder and decoder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sparse AEs**: Sparse AEs are an alternative method for introducing an information
    bottleneck, without requiring a reduction in the number of nodes in our hidden
    layers. Rather than preferring an undercomplete AE, the loss function is constructed
    in a way that it penalizes the activations within a layer. For any given observation,
    the network is encouraged to learn encoding and decoding, which only relies on
    activating a small number of neurons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Denoising AEs**: This is a type of overcomplete AE that experiences the risk
    of learning the **identity function** or **null function**. Essentially, the AE
    learns the output that is equal to the input, therefore making the AE useless. Denoising
    AEs avoid this problem of learning the identity function by randomly initializing
    some of the inputs to 0\. During the computation of the loss function, the noise-induced
    input is not considered; therefore, the network still learns the correct weights
    without the risk of learning the identity function. At the same time, the AE is
    trained to learn to reconstruct the output, even from the corrupted input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure is a example of denoising AEs on sample images from the MNIST
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d7a07b41-c689-4e55-a083-f06fe8654b83.png)'
  prefs: []
  type: TYPE_IMG
- en: Application of denoising AEs on MNIST samples
  prefs: []
  type: TYPE_NORMAL
- en: '**Convolutional AEs**: When dealing with images as inputs, one can use convolutional
    layers as part of the encoder and decoder networks. Such kinds of AEs that use
    convolutional layers are termed **convolutional AEs**. The following figure is
    an illustration showing the use of convolutions in AEs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/cad4e496-083e-4442-9e06-9dfba7e17d0c.png)'
  prefs: []
  type: TYPE_IMG
- en: Convolutional AEs
  prefs: []
  type: TYPE_NORMAL
- en: '**Stacked AEs**: Stacked AEs are ones that have multiple layers in the encoder
    as well as the decoder. You can refer to the general architecture of an AE as
    an example illustration of a stacked AE architecture, with the encoder and decoder
    having two layers (excluding the input and output layers).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variational AEs**: A **variational AE** (**VAE**), rather than building an
    encoder that outputs a singl'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'e value to describe each latent state attribute, describes a probability distribution
    for each latent attribute. This makes it possible to design complex generative
    models of data and also generate fictional celebrity images and digital artwork.
    The following figure is an illustration depicting the representation of data in
    VAEs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/f0cf2cf0-7185-44d1-a669-4a7522e025b3.png)'
  prefs: []
  type: TYPE_IMG
- en: In a VAE, the encoder model is sometimes referred to as the recognition model,
    whereas the decoder model is sometimes referred to as the generative model. The
    encoder outputs a range of statistical distributions for the latent features.
    These features are randomly sampled and used by the decoder to reconstruct the
    input. For any sampling of the latent distributions, the decoder is expected to
    be able to accurately reconstruct the input. Thus, values that are nearby to one
    another in latent space should correspond with very similar reconstructions.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of AEs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are some of the practical applications where AEs may be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image coloring**: Given a grayscale image as input, AEs can auto color the
    image and return the colored image as output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Noise removal**: Denoising AEs are able to remove noise from images and reconstruct
    images without noise. Tasks such as watermark removal from videos and images can
    be accomplished.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dimensionality reduction**: AEs represent the input data in a compressed
    form, but with a focus on key features alone. Therefore, things like images can
    be represented with reduced pixels, without much loss of information during image
    reconstruction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image search**: This is used to identify similar images based on a given
    input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Information retrieval**: When retrieving information from a corpus, AEs may
    be used to group together all the documents that belong to a given input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Topic modeling**: Variational AEs are used to approximate the posterior distribution,
    and it has become a promising alternative for inferring latent topic distributions
    of text documents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have covered the fundamentals that are needed for us to understand AEs and
    their applications. Let us understand, at a high level, the solution we are going
    to employ using AEs on the credit card fraud detection problem.
  prefs: []
  type: TYPE_NORMAL
- en: The credit card fraud dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generally in a fraud dataset, we have sufficient data for the negative class
    (non-fraud/genuine transactions) and very few or no data for the positive class
    (fraudulent transactions). This is termed a **class imbalance problem** in the ML
    world. We train an AE on the non-fraud data and learn features using the encoder.
    The decoder is then used to compute the reconstruction error on the training set
    to find a threshold. This threshold will be used on the unseen data (test dataset
    or otherwise). We use the threshold to identify those test instances whose values
    are greater than the threshold as fraud instances.
  prefs: []
  type: TYPE_NORMAL
- en: For the project in this chapter, we will be using a dataset that is sourced
    from this URL: [https://essentials.togaware.com/data/](https://essentials.togaware.com/data/).
    This is a public dataset of credit card transactions. This dataset is originally
    made available through the research paper *Calibrating Probability with Undersampling
    for Unbalanced Classification*, A. Dal Pozzolo, O. Caelen, R. A Johnson and G.
    Bontempi, IEEE **Symposium Series on Computational Intelligence** (**SSCI**),
    Cape Town, South Africa, 2015\. The dataset is also available at this URL: [http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.Rdata](http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.Rdata).
    The dataset was collected and analyzed during a research collaboration of Worldline
    and the Machine Learning Group ([http://mlg.ulb.ac.be](http://mlg.ulb.ac.be/))
    of ULB (Université Libre de Bruxelles) on big data mining and fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the characteristics of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: The paper made the dataset available as an Rdata file. There is a CSV converted
    version of this dataset available on Kaggle as well as other sites.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It contains transactions made by credit cards in September 2013 by European
    cardholders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The transactions occurred on two days are recorded and is presented as the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a total of 284,807 transactions in the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dataset suffers from a severe class imbalance problem. Only 0.172% of all
    transactions are fraudulent transactions (492 fraudulent transactions).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a total thirty features in the dataset, namely `V1`, `V2`, ...,`V28`,
    `Time`, and `Amount`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The variables `V1`, `V2`, ...,`V28` are the principal components obtained with
    PCA from the original set of variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to confidentiality, the original set of variables that yielded the principal
    components are not revealed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Time` feature contains the seconds elapsed between each transaction and
    the first transaction in the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Amount` feature is the transaction amount.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dependent variable is named `Class`. The fraudulent transactions are represented
    as 1 in the class and genuine transactions are represented as 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will now jump into using AEs for the credit card fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: Building AEs with the H2O library in R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be using the AE implementation available in H2O for our project. H2O
    is a fully open source, distributed, in-memory ML platform with linear scalability.
    It offers parallelized implementations of some of the most widely used ML algorithms.
    It supports an easy to use, unsupervised, and non-linear AE as part of its deep
    learning model. The DL AE of H2O is based on the multilayer neural net architecture,
    where the entire network is trained together, instead of being stacked layer by
    layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `h2o` package can be installed in R with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Additional details on the installation and dependencies of H2O in R are available
    at this URL: [https://cran.r-project.org/web/packages/h2o/index.html](https://cran.r-project.org/web/packages/h2o/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the package is installed successfully, the functions offered by the `h2o`
    package, including the AE, can simply be used by including the following line
    in R code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This is all we need to do prior to coding our credit card fraud detection system
    with the AE. Without waiting any longer, let's start building our code to explore
    and prepare our dataset, as well as to implement the AE that captures fraudulent
    credit card transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoder code implementation for credit card fraud detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As usual, like all other projects, let''s first load the data into an R dataframe
    and then perform EDA to understand the dataset better. Please note the inclusion
    of `h2o` as well as the `doParallel` library in the code. These inclusions enable
    us to use the AE that is part of the `h2o` library, as well as to utilize the
    multiple CPU cores that are present in the laptop/desktop as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Initializing the H2O cluster in localhost under the port `54321`. The `nthreads`
    defines the number of thread pools to be used, this is close to the number of
    cpus to be used. In our case, we are saying use all CPUs, we are also specifying
    the maximum memory to use by H2O cluster as `8G`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get a similar output to that shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to set the working directory of the data file location, load Rdata and
    read it into the dataframe, and view the dataframe using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3e302731-40c7-43f1-9350-8c3cb93e9608.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s now print the dataframe structure using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to view the class distribution, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'To view the relationship between the `V1` and `Class` variables, use the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/75981835-0fdf-4ffd-807e-6cceab13ec32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To visualize the distribution of transaction amounts with respect to class,
    use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95ac410b-3790-435f-a980-d0f89f27af11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To visualize the distribution of transaction times with respect to class, use
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cc9a994e-1e30-440c-9f0e-80c79e7ae4ba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the following code to visualize the `V2` variable with respect to `Class`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get the following as the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c891040-a5e6-4568-a669-bfa9307f150e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the following code to visualize `V3` with respect to `Class`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph is the resultant output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/084bee5f-c39d-4cd7-a4ef-f3654ca44992.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To visualize the `V3` variable with respect to `Class`, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph is the resultant output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/312d60a0-e11b-4ec9-ac1a-5b5a2fb77cc3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the following code to visualize the `V6` variable with respect to `Class`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph is the resultant output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ec1dc19-0116-4bae-b1f4-72f520de15f8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the following code to visualize the `V7` variable with respect to `Class`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph is the resultant output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9b97b5a5-1b06-4151-adde-1b85b632f657.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the following code to visualize the `V8` variable with respect to `Class`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph is the resultant output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c471bfc-a6ff-4867-96cc-30da7a810d47.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To visualize the `V9` variable with respect to `Class`, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph is the resultant output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b82a52f6-7fe5-4983-b56f-9c9d92dfeed7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To visualize the `V10` variable with respect to `Class`, use the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph is the resultant output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aeee5f93-f562-4bd6-944f-e2cfb1936b0c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From all the visualizations related to variables with respect to class, we
    can infer that most of the principal components are centered on `0`. Now, to plot
    the distribution of classes in the data, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following bar graph is the resultant output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ab03c79-8eea-4c65-94a7-ba90deedae22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We observe that the distribution of classes is very imbalanced. The representation
    of the major class (non-fraudulent transactions, represented by `0`) in the dataset
    is too heavy when compared to the minority class (fraudulent transactions: `1`).
    In the traditional supervised ML way of dealing with this kind of problem, we
    would have treated the class imbalance problem with techniques such as **Synthetic
    Minority Over-Sampling Technique** (**SMORT**). However, with AEs, we do not treat
    the class imbalance during data preprocessing; rather, we feed the data as is
    to the AE for learning. In fact, the AE is learning the thresholds and the characteristics
    of the data from the majority class; this is the reason we call it a one-class
    classification problem.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will need to do some feature engineering prior to training our AE. Let''s
    first focus on the `Time` variable in the data. Currently, it is in the seconds
    format, but we may better represent it as days. Run the following code to see
    the current form of time in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We know that there are 86,400 seconds in a given day (60 seconds per minute
    * 60 minutes per hour * 24 hours per day). We will convert the `Time` variable
    into `Day` by considering the value in `Time` and representing it as `day1` if
    the number of seconds is less than or equal to 86,400, and anything over 86,400
    becomes `day2.` There are only two days possible, as we can see from the summary
    that the maximum value represented by the time variable is `172792` seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the resultant output of the first six rows after the conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a810fdad-2a9b-4045-a5ba-92635cd881ac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, use the following code to view the last six rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the resultant output of the last six rows after the conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5506a84a-a119-421a-be3c-1284e371c32a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s print the distribution of transactions by the day in which the
    transaction falls, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get the following as the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create a new variable, `Time_day`, based on the seconds represented
    in the `Time` variable, and summarize the `Time_day` variable with respect to
    `Day` using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following as the resultant output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code the convert all character variables in the dataset to
    factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We can further fine-tune the `Time_day` variable by converting the variable
    into a factor. The factors represents the time of day at which the transaction
    happened, for example, `morning`, `afternoon`, `evening`, and `night`. We can
    create a new variable called `Time_Group`, based on the various buckets of the
    day, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the resultant output of the first six rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/26eb4e24-39aa-4069-8b8b-b62b16d185af.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the following code to view and confirm the last six rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give the following output, and we see that we have successfully converted
    the data which represent the various time of the day:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4bf537f3-165f-47c8-a6b2-b04cd963ba4e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c44ad84-e7fe-4871-a9b6-b0a84d54b8d1.png)'
  prefs: []
  type: TYPE_IMG
- en: We can infer from the visualization that there is no difference in the count
    of transactions that happened on day 1 and day 2\. Both remain close to 150,000
    transactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we will convert the `Class` variable as a factor and then visualize the
    data by `Time_Group` variable using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e186689d-e77c-4cde-b52d-5ed9c1d5707c.png)'
  prefs: []
  type: TYPE_IMG
- en: The inference obtained from this visualization is that the number of non-fraudulent
    transactions remains almost the same across all time periods of the day, whereas
    we see a huge rise in the number of fraudulent transactions during the morning
    `Time` group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do a last bit of exploration of the transaction amount with respect
    to class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: One interesting insight from the summary is that the mean amount in fraudulent
    transactions is higher compared to genuine transactions. However, the maximum
    transaction amount that we see in fraudulent transactions is much lower than the
    genuine transactions. It can also be seen that genuine transactions have a higher
    median amount.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s convert our R dataframe to an H2O dataframe to apply the AE to
    it. This is a requirement in order to use the functions from the `h2o` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The `tanh` activation function is a rescaled and shifted logistic function.
    Other functions, such as ReLu and Maxout, are also provided by the `h2o` library
    and they can also be used.  In the first AE model, let's use the `tanh` activation
    function. This choice is arbitrary and other activation functions may also be
    tried as desired.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `h2o.deeplearning` function has a parameter AE and this should be set to
    `TRUE` to train a AE model. Let''s build our AE model now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We will save the model so we do not have to retrain t again and again. Then
    load the model that is persisted on the disk and print the model to verify the
    AE learning using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now make predictions on test dataset using the AE model that is built,
    using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'It is possible to visualize the encoder representing the data in a conscious
    manner in the inner layers through the `h2o.deepfeatures` function. Let''s try
    visualizing the reduced data in a second layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us now plot the data of `DF.L2.C1` with respect to `DF.L2.C2` to verify
    if the encoder has detected the fraudulent transactions, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1d57f16e-1bf6-47eb-94e4-83557dbb69eb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Again we plot the data of `DF.L2.C3` with respect to `DF.L2.C4` to verify the
    if the encoder have detected any fraud transaction, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3bcd6f63-b386-415a-a650-87cf67b96e22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We see from the two visualizations that the fraudulent transactions are indeed
    detected by the dimensionality reduction approach with our AE model. Those few
    scattered dots (represented by `1`) depicts the fraud transactions that are detected.
    We can also train a new model with the other hidden layers, using our first model.
    This results in 10 columns, since the third layer has 10 nodes. We are just attempting
    to slice out one layer where some level of reduction was done and use that to
    build a new model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the training models and data are successfully created. We will
    now go ahead and train the new model, save it and the print it. First, we will
    get the feature names from the sliced encoder layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we will training a new model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then save the model to avoid retraining again, then retrieve the model
    and print it using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'For measuring model performance on test data, we need to convert the test data
    to the same reduced dimensions as the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We see, the data has been converted successfully. Now, to make predictions
    on the test dataset with `model_two`, we will use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, from the output, predictions has been successfully completed
    and now let us visualize the predictions using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We see that our AE is able to correctly predict non-fraudulent transactions
    with 98% accuracy, which is good. However, it is yielding only 58% accuracy when
    predicting fraudulent transactions. This is definitely something to focus on.
    Our model needs some improvement, and this can be accomplished through the following
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: Using other layers' latent space representations as input to build `model_two`
    (recollect that we currently use the layer 3 representation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using ReLu or Maxout activation functions instead of `Tanh`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking the misclassified instances through the `h2o.anomaly` function and
    increasing or decreasing the cutoff threshold MSE values, which separates the
    fraudulent transactions from non-fraudulent transactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trying out a more complex architecture in the encoder and decoder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are not going to be attempting these options in this chapter as they are
    experimental in nature. However, interested readers may try and improve the accuracy
    of the model by trying these options.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, one best practice is to explicitly shut down the `h2o` cluster. This
    can be accomplished with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about an unsupervised deep learning technique called
    AEs. We covered the definition, working principle, types, and applications of
    AEs. H2O, an open source library that enables us to create deep learning models,
    including AEs, was explored. We then discussed a credit card fraud open dataset
    and implemented a project with an AE to detect fraudulent credit card transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Can deep neural networks help with creative tasks such as prose generation,
    story writing, caption generation for images, and poem writing? Not sure?! Let's
    explore RNNs, in the next chapter, a special type of deep neural network that
    enables us to accomplish creative tasks. Turn the page to explore the world of
    RNNs for prose generation.
  prefs: []
  type: TYPE_NORMAL
