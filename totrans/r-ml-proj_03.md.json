["```py\n# including the required libraries\nlibrary(data.table)\nlibrary(recommenderlab)\n# setting the seed so as to reproduce the results\nset.seed(54)\n# reading the data to a variable\nlibrary(recommenderlab)\ndata(Jester5k)\nstr(Jester5k)\n```", "```py\nFormal class 'realRatingMatrix' [package \"recommenderlab\"] with 2 slots\n  ..@ data     :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n  .. .. ..@ i       : int [1:362106] 0 1 2 3 4 5 6 7 8 9 ...\n  .. .. ..@ p       : int [1:101] 0 3314 6962 10300 13442 18440 22513 27512 32512 35685 ...\n  .. .. ..@ Dim     : int [1:2] 5000 100\n  .. .. ..@ Dimnames:List of 2\n  .. .. .. ..$ : chr [1:5000] \"u2841\" \"u15547\" \"u15221\" \"u15573\" ...\n  .. .. .. ..$ : chr [1:100] \"j1\" \"j2\" \"j3\" \"j4\" ...\n  .. .. ..@ x       : num [1:362106] 7.91 -3.2 -1.7 -7.38 0.1 0.83 2.91 -2.77 -3.35 -1.99 ...\n  .. .. ..@ factors : list()\n  ..@ normalize: NULL\n```", "```py\n# Viewing the first 5 records in the dataset\nhead(getRatingMatrix(Jester5k),5)\n```", "```py\n2.5 x 100 sparse Matrix of class \"dgCMatrix\"\n   [[ suppressing 100 column names ‘j1’, ‘j2’, ‘j3’ ... ]]                                                                                                           \nu2841   7.91  9.17  5.34  8.16 -8.74  7.14  8.88 -8.25  5.87  6.21  7.72  6.12 -0.73  7.77 -5.83 -8.88  8.98\nu15547 -3.20 -3.50 -9.56 -8.74 -6.36 -3.30  0.78  2.18 -8.40 -8.79 -7.04 -6.02  3.35 -4.61  3.64 -6.41 -4.13\nu15221 -1.70  1.21  1.55  2.77  5.58  3.06  2.72 -4.66  4.51 -3.06  2.33  3.93  0.05  2.38 -3.64 -7.72  0.97\nu15573 -7.38 -8.93 -3.88 -7.23 -4.90  4.13  2.57  3.83  4.37  3.16 -4.90 -5.78 -5.83  2.52 -5.24  4.51  4.37\nu21505  0.10  4.17  4.90  1.55  5.53  1.50 -3.79  1.94  3.59  4.81 -0.68 -0.97 -6.46 -0.34 -2.14 -2.04 -2.57                                \nu2841  -9.32 -9.08 -9.13 7.77  8.59  5.29  8.25  6.02  5.24  7.82  7.96 -8.88  8.25  3.64 -0.73  8.25  5.34 -7.77\nu15547 -0.15 -1.84 -1.84 1.84 -1.21 -8.59 -5.19 -2.18  0.19  2.57 -5.78  1.07 -8.79  3.01  2.67 -9.22 -9.32  3.69\nu15221  2.04  1.94  4.42 1.17  0.10 -5.10 -3.25  3.35  3.30 -1.70  3.16 -0.29  1.36  3.54  6.17 -2.72  3.11  4.81\nu15573  4.95  5.49 -0.49 3.40 -2.14  5.29 -3.11 -4.56 -5.44 -6.89 -0.24 -5.15 -3.59 -8.20  2.18  0.39 -1.21 -2.62\nu21505 -0.15  2.43  3.16 1.50  4.37 -0.10 -2.14  3.98  2.38  6.84 -0.68  0.87  3.30  6.21  5.78 -6.21 -0.78 -1.36\n## number of ratings\nprint(nratings(Jester5k))\n```", "```py\n362106## number of ratings per user\n```", "```py\nprint(summary(rowCounts(Jester5k)))\n```", "```py\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.\n  36.00   53.00   72.00   72.42  100.00  100.00\n```", "```py\n## rating distribution\nhist(getRatings(Jester5k), main=\"Distribution of ratings\")\n```", "```py\nhead(JesterJokes,5)\n```", "```py\nj1 \"A man visits the doctor. The doctor says \\\"I have bad news for you.You have cancer and Alzheimer's disease\\\". The man replies \\\"Well,thank God I don't have cancer!\\\"\"\nj2 \"This couple had an excellent relationship going until one day he came home from work to find his girlfriend packing. He asked her why she was leaving him and she told him that she had heard awful things about him. \\\"What could they possibly have said to make you move out?\\\" \\\"They told me that you were a pedophile.\\\" He replied, \\\"That's an awfully big word for a ten year old.\\\"\"\nj3  \"Q. What's 200 feet long and has 4 teeth? A. The front row at a Willie Nelson Concert.\"\nj4 \"Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\"\nj5 \"Q. What's O. J. Simpson's Internet address? A. Slash, slash, backslash, slash, slash, escape.\"\n```", "```py\n## 'best' joke with highest average rating\nbest <- which.max(colMeans(Jester5k))\ncat(JesterJokes[best])\n```", "```py\nA guy goes into confession and says to the priest, \"Father, I'm 80 years old, widower, with 11 grandchildren. Last night I met two beautiful flight attendants. They took me home and I made love to both of them. Twice.\" The priest said: \"Well, my son, when was the last time you were in confession?\" \"Never Father, I'm Jewish.\" \"So then, why are you telling me?\" \"I'm telling everybody.\"\n```", "```py\n# convert the df dataframe to a matrix\nr_mat <- as.matrix(df)\n```", "```py\n# convert r_mat matrix to a recommenderlab realRatingMatrix\nr_real_mat <- as(r_mat,\"realRatingMatrix\")\n```", "```py\n# split the data into the training and the test set\nJester5k_es <- evaluationScheme(Jester5k, method=\"split\", train=0.8, given=20, goodRating=0)\n# verifying if the train - test was done successfully\nprint(Jester5k_es)\n```", "```py\nEvaluation scheme with 20 items given\nMethod: ‘split’ with 1 run(s).\nTraining set proportion: 0.800\nGood ratings: >=0.000000\nData set: 5000 x 100 rating matrix of class ‘realRatingMatrix’ with 362106 ratings.\n```", "```py\ntype = \"IBCF\"\n##train ITCF cosine similarity models\n# non-normalized\nITCF_N_C <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = NULL, method=\"Cosine\"))\n# centered\nITCF_C_C <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"center\",method=\"Cosine\"))\n# Z-score normalization\nITCF_Z_C <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"Z-score\",method=\"Cosine\"))\n##train ITCF Euclidean Distance models\n# non-normalized\nITCF_N_E <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = NULL, method=\"Euclidean\"))\n# centered\nITCF_C_E <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"center\",method=\"Euclidean\"))\n# Z-score normalization\nITCF_Z_E <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"Z-score\",method=\"Euclidean\"))\n#train ITCF pearson correlation models\n# non-normalized\nITCF_N_P <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = NULL, method=\"pearson\"))\n# centered\nITCF_C_P <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"center\",method=\"pearson\"))\n# Z-score normalization\nITCF_Z_P <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"Z-score\",method=\"pearson\"))\n```", "```py\n# compute predicted ratings from each of the 9 models on the test dataset\npred1 <- predict(ITCF_N_C, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred2 <- predict(ITCF_C_C, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred3 <- predict(ITCF_Z_C, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred4 <- predict(ITCF_N_E, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred5 <- predict(ITCF_C_E, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred6 <- predict(ITCF_Z_E, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred7 <- predict(ITCF_N_P, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred8 <- predict(ITCF_C_P, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred9 <- predict(ITCF_Z_P, getData(Jester5k_es, \"known\"), type=\"ratings\")\n# set all predictions that fall outside the valid range to the boundary values\npred1@data@x[pred1@data@x[] < -10] <- -10\npred1@data@x[pred1@data@x[] > 10] <- 10\npred2@data@x[pred2@data@x[] < -10] <- -10\npred2@data@x[pred2@data@x[] > 10] <- 10\npred3@data@x[pred3@data@x[] < -10] <- -10\npred3@data@x[pred3@data@x[] > 10] <- 10\npred4@data@x[pred4@data@x[] < -10] <- -10\npred4@data@x[pred4@data@x[] > 10] <- 10\npred5@data@x[pred5@data@x[] < -10] <- -10\npred5@data@x[pred5@data@x[] > 10] <- 10\npred6@data@x[pred6@data@x[] < -10] <- -10\npred6@data@x[pred6@data@x[] > 10] <- 10\npred7@data@x[pred7@data@x[] < -10] <- -10\npred7@data@x[pred7@data@x[] > 10] <- 10\npred8@data@x[pred8@data@x[] < -10] <- -10\npred8@data@x[pred8@data@x[] > 10] <- 10\npred9@data@x[pred9@data@x[] < -10] <- -10\npred9@data@x[pred9@data@x[] > 10] <- 10\n# aggregate the performance measurements obtained from all the models\nerror_ITCF <- rbind(\n  ITCF_N_C = calcPredictionAccuracy(pred1, getData(Jester5k_es, \"unknown\")),\n  ITCF_C_C = calcPredictionAccuracy(pred2, getData(Jester5k_es, \"unknown\")),\n  ITCF_Z_C = calcPredictionAccuracy(pred3, getData(Jester5k_es, \"unknown\")),\n  ITCF_N_E = calcPredictionAccuracy(pred4, getData(Jester5k_es, \"unknown\")),\n  ITCF_C_E = calcPredictionAccuracy(pred5, getData(Jester5k_es, \"unknown\")),\n  ITCF_Z_E = calcPredictionAccuracy(pred6, getData(Jester5k_es, \"unknown\")),\n  ITCF_N_P = calcPredictionAccuracy(pred7, getData(Jester5k_es, \"unknown\")),\n  ITCF_C_P = calcPredictionAccuracy(pred8, getData(Jester5k_es, \"unknown\")),\n  ITCF_Z_P = calcPredictionAccuracy(pred9, getData(Jester5k_es, \"unknown\"))\n)\nlibrary(knitr)\nkable(error_ITCF)\n```", "```py\n|         |     RMSE|      MSE|      MAE|\n|:--------|--------:|--------:|--------:|\n|ITCF_N_C | 4.533455| 20.55221| 3.460860|\n|ITCF_C_C | 5.082643| 25.83326| 4.012391|\n|ITCF_Z_C | 5.089552| 25.90354| 4.021435|\n|ITCF_N_E | 4.520893| 20.43848| 3.462490|\n|ITCF_C_E | 4.519783| 20.42844| 3.462271|\n|ITCF_Z_E | 4.527953| 20.50236| 3.472080|\n|ITCF_N_P | 4.582121| 20.99583| 3.522113|\n|ITCF_C_P | 4.545966| 20.66581| 3.510830|\n|ITCF_Z_P | 4.569294| 20.87845| 3.536400|\n```", "```py\nlibrary(recommenderlab)\ndata(Jester5k)\n# split the data into the training and the test set\nJester5k_es <- evaluationScheme(Jester5k, method=\"split\", train=0.8, given=20, goodRating=0)\nprint(Jester5k_es)\ntype = \"UBCF\"\n#train UBCF cosine similarity models\n# non-normalized\nUBCF_N_C <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = NULL, method=\"Cosine\"))\n# centered\nUBCF_C_C <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"center\",method=\"Cosine\"))\n# Z-score normalization\nUBCF_Z_C <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"Z-score\",method=\"Cosine\"))\n#train UBCF Euclidean Distance models\n# non-normalized\nUBCF_N_E <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = NULL, method=\"Euclidean\"))\n# centered\nUBCF_C_E <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"center\",method=\"Euclidean\"))\n# Z-score normalization\nUBCF_Z_E <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"Z-score\",method=\"Euclidean\"))\n#train UBCF pearson correlation models\n# non-normalized\nUBCF_N_P <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = NULL, method=\"pearson\"))\n# centered\nUBCF_C_P <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"center\",method=\"pearson\"))\n# Z-score normalization\nUBCF_Z_P <- Recommender(getData(Jester5k_es, \"train\"), type,\n                        param=list(normalize = \"Z-score\",method=\"pearson\"))\n# compute predicted ratings from each of the 9 models on the test dataset\npred1 <- predict(UBCF_N_C, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred2 <- predict(UBCF_C_C, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred3 <- predict(UBCF_Z_C, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred4 <- predict(UBCF_N_E, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred5 <- predict(UBCF_C_E, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred6 <- predict(UBCF_Z_E, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred7 <- predict(UBCF_N_P, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred8 <- predict(UBCF_C_P, getData(Jester5k_es, \"known\"), type=\"ratings\")\npred9 <- predict(UBCF_Z_P, getData(Jester5k_es, \"known\"), type=\"ratings\")\n# set all predictions that fall outside the valid range to the boundary values\npred1@data@x[pred1@data@x[] < -10] <- -10\npred1@data@x[pred1@data@x[] > 10] <- 10\npred2@data@x[pred2@data@x[] < -10] <- -10\npred2@data@x[pred2@data@x[] > 10] <- 10\npred3@data@x[pred3@data@x[] < -10] <- -10\npred3@data@x[pred3@data@x[] > 10] <- 10\npred4@data@x[pred4@data@x[] < -10] <- -10\npred4@data@x[pred4@data@x[] > 10] <- 10\npred5@data@x[pred5@data@x[] < -10] <- -10\npred5@data@x[pred5@data@x[] > 10] <- 10\npred6@data@x[pred6@data@x[] < -10] <- -10\npred6@data@x[pred6@data@x[] > 10] <- 10\npred7@data@x[pred7@data@x[] < -10] <- -10\npred7@data@x[pred7@data@x[] > 10] <- 10\npred8@data@x[pred8@data@x[] < -10] <- -10\npred8@data@x[pred8@data@x[] > 10] <- 10\npred9@data@x[pred9@data@x[] < -10] <- -10\npred9@data@x[pred9@data@x[] > 10] <- 10\n# aggregate the performance statistics\nerror_UBCF <- rbind(\n  UBCF_N_C = calcPredictionAccuracy(pred1, getData(Jester5k_es, \"unknown\")),\n  UBCF_C_C = calcPredictionAccuracy(pred2, getData(Jester5k_es, \"unknown\")),\n  UBCF_Z_C = calcPredictionAccuracy(pred3, getData(Jester5k_es, \"unknown\")),\n  UBCF_N_E = calcPredictionAccuracy(pred4, getData(Jester5k_es, \"unknown\")),\n  UBCF_C_E = calcPredictionAccuracy(pred5, getData(Jester5k_es, \"unknown\")),\n  UBCF_Z_E = calcPredictionAccuracy(pred6, getData(Jester5k_es, \"unknown\")),\n  UBCF_N_P = calcPredictionAccuracy(pred7, getData(Jester5k_es, \"unknown\")),\n  UBCF_C_P = calcPredictionAccuracy(pred8, getData(Jester5k_es, \"unknown\")),\n  UBCF_Z_P = calcPredictionAccuracy(pred9, getData(Jester5k_es, \"unknown\"))\n)\nlibrary(knitr)\nprint(kable(error_UBCF))\n```", "```py\n|         |     RMSE|      MSE|      MAE|\n|:--------|--------:|--------:|--------:|\n|UBCF_N_C | 4.877935| 23.79425| 3.986170|\n|UBCF_C_C | 4.518210| 20.41422| 3.578551|\n|UBCF_Z_C | 4.517669| 20.40933| 3.552120|\n|UBCF_N_E | 4.644877| 21.57488| 3.778046|\n|UBCF_C_E | 4.489157| 20.15253| 3.552543|\n|UBCF_Z_E | 4.496185| 20.21568| 3.528534|\n|UBCF_N_P | 4.927442| 24.27968| 4.074879|\n|UBCF_C_P | 4.487073| 20.13382| 3.553429|\n|UBCF_Z_P | 4.484986| 20.11510| 3.525356|\n```", "```py\n# load the required libraries\nlibrary(data.table)\nlibrary(arules)\nlibrary(recommenderlab)\n# set the seed so that the results are replicable\nset.seed(42)\n# reading the Jester5k data\ndata(Jester5k)\nclass(Jester5k)\n```", "```py\n[1] \"realRatingMatrix\"\nattr(,\"package\")\n[1] \"recommenderlab\"\n```", "```py\n# binarizing the Jester ratings\nJester5k_bin <- binarize(Jester5k, minRating=1)\n# let us verify the binarized object\nclass(Jester5k_bin)\n```", "```py\n[1] \"binaryRatingMatrix\"\nattr(,\"package\")\n[1] \"recommenderlab\"\n```", "```py\n# converting the binaryratingsmatrix to matrix format\nJester5k_bin_mat <- as(Jester5k_bin,\"matrix\")\n# visualizing the matrix object\nView(Jester5k_bin_mat)\n```", "```py\n# converting the cell values to 1 and 0\nJester5k_bin_mat_num <- 1*Jester5k_bin_mat\n# viewing the matrix\nView(Jester5k_bin_mat_num)\n```", "```py\nrules <- apriori(data = Jester5k_bin_mat_num, parameter = list(supp = 0.005, conf = 0.8))\n```", "```py\nApriori\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support minlen maxlen target   ext\n        0.8    0.1    1 none FALSE            TRUE       5     0.5      1     10  rules FALSE\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\nAbsolute minimum support count: 2500\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[100 item(s), 5000 transaction(s)] done [0.02s].\nsorting and recoding items ... [29 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 done [0.01s].\nwriting ... [78 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n```", "```py\ninspect(rules)\n```", "```py\n     lhs          rhs   support confidence lift     count\n[1]  {j48}     => {j50} 0.5068  0.8376860  1.084523 2534\n[2]  {j56}     => {j36} 0.5036  0.8310231  1.105672 2518\n[3]  {j56}     => {j50} 0.5246  0.8656766  1.120762 2623\n[4]  {j42}     => {j50} 0.5150  0.8475971  1.097355 2575\n[5]  {j31}     => {j27} 0.5196  0.8255481  1.146276 2598\n```", "```py\n# converting the rules object into a dataframe\nrulesdf <- as(rules, \"data.frame\")\n# employing quick sort on the rules dataframe. lift and confidence are\n# used as keys to sort the dataframe. - in the command indicates that we\n# want lift and confidence to be sorted in descending order\nrulesdf[order(-rulesdf$lift, -rulesdf$confidence), ]\n```", "```py\n# including the required libraries\nlibrary(recommenderlab)\n# accessing the Jester5k dataset that is a part of recommenderlab library\ndata(Jester5k)\n# split the data into the training and the test set\nJester5k_es <- evaluationScheme(Jester5k, method=\"split\", train=0.8, given=20, goodRating=0)\n```", "```py\n#train a hybrid recommender model\nhybrid_recom <- HybridRecommender(\n  Recommender(getData(Jester5k_es, \"train\"), method = \"POPULAR\"),\n  Recommender(getData(Jester5k_es, \"train\"), method=\"IBCF\",\n              param=list(normalize = NULL, method=\"Cosine\")),\n  Recommender(getData(Jester5k_es, \"train\"), method=\"UBCF\",\n                          param=list(normalize = \"Z-score\",method=\"Euclidean\")),\n  Recommender(getData(Jester5k_es, \"train\"), method = \"RANDOM\"),\n  weights = c(.2, .3, .3,.2)\n)\n# Observe the model that is built\nprint (getModel(hybrid_recom)\n```", "```py\n$recommender\n$recommender[[1]]\nRecommender of type ‘POPULAR’ for ‘realRatingMatrix’\nlearned using 4000 users.\n$recommender[[2]]\nRecommender of type ‘IBCF’ for ‘realRatingMatrix’\nlearned using 4000 users.\n$recommender[[3]]\nRecommender of type ‘UBCF’ for ‘realRatingMatrix’\nlearned using 4000 users.\n$recommender[[4]]\nRecommender of type ‘RANDOM’ for ‘realRatingMatrix’\nlearned using 4000 users.\n$weights\n[1] 0.2 0.3 0.3 0.2\n```", "```py\n# making predictions\npred <- predict(hybrid_recom, getData(Jester5k_es, \"known\"), type=\"ratings\")\n# # set the predictions that fall outside the valid range to the boundary values\npred@data@x[pred@data@x[] < -10] <- -10\npred@data@x[pred@data@x[] > 10] <- 10\n# calculating performance measurements\nhybrid_recom_pred = calcPredictionAccuracy(pred, getData(Jester5k_es, \"unknown\"))\n# printing the performance measurements\nlibrary(knitr)\nprint(kable(hybrid_recom_pred))\n```", "```py\n|     |         x|\n|:----|---------:|\n|RMSE |  4.468849|\n|MSE  | 19.970611|\n|MAE  |  3.493577|\n```"]