["```py\n    > install.packages(\"glmnet\")\n    > install.packages(\"dplyr\")\n    > install.packages(\"tidyr\")\n    > install.packages(\"ggplot2\")\n    > install.packages(\"caret\")\n    > install.packages(\"boot\")\n    > install.packages(\"RColorBrewer\")\n    > install.packages(\"Metrics\")\n    > library(dplyr)\n    > library(tidyr)\n    > library(ggplot2)\n    > library(caret)\n    > library(glmnet)\n    > library(boot)\n    > library(RColorBrewer)\n    > library(Metrics)\n\n```", "```py\n> fitbit_details <- read.csv(\"https://raw.githubusercontent.com/ellisp/ellisp.github.io/source/data/fitbit_export_20160806.csv\", \n    + skip = 1, stringsAsFactors = FALSE) %>%\n    + mutate(\n    + Calories.Burned = as.numeric(gsub(\",\", \"\", Calories.Burned)),\n    + Steps = as.numeric(gsub(\",\", \"\", Steps)),\n    + Activity.Calories = as.numeric(gsub(\",\", \"\", Activity.Calories)),\n    + Date = as.Date(Date, format = \"%d/%m/%Y\")\n    + )\n\n```", "```py\n> fitbit <- fitbit_details\n\n```", "```py\n > head(fitbit)\n\n```", "```py\n> fitbit$Activity.Calories <- NULL\n\n```", "```py\n> fitbit$Date <- NULL\n\n```", "```py\n> fitbit$Steps <- fitbit$Steps / 1000\n\n```", "```py\n> fitbit$Steps\n\n```", "```py\n    > panel_correlations <- function(x, y, digits = 2, prefix = \"\", cex.cor, ...){\n    # combining multiple plots into one overall graph\n    + usr <- par(\"usr\")\n    + on.exit(par(usr))\n    + par(usr = c(0, 1, 0, 1))\n    # computing the absolute value\n    + r <- abs(cor(x, y))\n# Formatting object \n    + txt <- format(c(r, 0.123456789), digits = digits)[1]\n    + txt <- paste0(prefix, txt)\n    + if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\n    + text(0.5, 0.5, txt, cex = cex.cor * r)\n    + }\n\n```", "```py\n> pairs(fitbit[ , -1], lower.panel = panel_correlations, main = \"Pairwise Relationship - Fitbit's Measured Activities\")\n\n```", "```py\n> ggplot(fitbit, aes(x = Distance / Steps)) + geom_rug() + geom_density() +ggtitle(\"Stride Length Reverse- Engineered from Fitbit Data\", subtitle = \"Not all strides identical, due to rounding or other jitter\")\n\n```", "```py\n> moderate <- lm(Calories.Burned ~ Steps, data = fitbit)\n\n```", "```py\n> moderate\n\n```", "```py\n> round(coef(moderate))\n\n```", "```py\n> plot(moderate, which = 1, bty = \"l\", main = \"Predicted Calories compared with Residuals\")\n\n```", "```py\n> pacf(resid(moderate), main = \"Partial Autocorrelation of residuals from single variable regression\")\n\n```", "```py\n> grid()\n\n```", "```py\n > X <- as.matrix(fitbit[ , -1])\n\n```", "```py\n> head(X)\n\n```", "```py\n> Y <- fitbit$Calories.Burned\n\n```", "```py\n> Y\n\n```", "```py\n> set.seed(123)\n\n```", "```py\n > alphas <- seq(from = 0, to  = 1, length.out = 10)\n > res <- matrix(0, nrow = length(alphas), ncol = 6)\n\n```", "```py\n    > for(i in 1:length(alphas)){\n    + for(j in 2:6){\n    # k-fold cross-validation for glmnet\n    + cvmod <- cv.glmnet(X, Y, alpha = alphas[i])\n    + res[i, c(1, j)] <- c(alphas[i], sqrt(min(cvmod$cvm)))\n    + }\n    + }\n\n```", "```py\n> res <- data.frame(res)\n\n```", "```py\n> res\n\n```", "```py\n> res$average_rmse <- apply(res[ , 2:6], 1, mean)\n\n```", "```py\n> res$average_rmse\n\n```", "```py\n> res <- res[order(res$average_rmse), ]\n\n```", "```py\n> res\n\n```", "```py\n    > names(res)[1] <- \"alpha\"\n    > res %>%\n    + select(-average_rmse) %>%\n    + gather(trial, rmse, -alpha) %>%\n    + ggplot(aes(x = alpha, y = rmse)) +\n    + geom_point() +\n    + geom_smooth(se = FALSE) +\n    + labs(y = \"Root Mean Square Error\") +\n    + ggtitle(\"Cross Validation best RMSE for differing values of alpha\")\n\n```", "```py\n> bestalpha <- res[1, 1]\n\n```", "```py\n> bestalpha\n\n```", "```py\n> crossvalidated <- cv.glmnet(X, Y, alpha = bestalpha)\n\n```", "```py\n> moderate1 <- glmnet(X, Y, alpha = bestalpha)\n\n```", "```py\n> OLSmodel <- lm(Calories.Burned ~ ., data = fitbit)\n\n```", "```py\n> OLSmodel\n\n```", "```py\n > coeffs <- data.frame(original = coef(OLSmodel), \n + shrunk = as.vector(coef(moderate1, s = crossvalidated$lambda.min)),\n + very.shrunk = as.vector(coef(moderate1, s = crossvalidated$lambda.1se)))\n\n```", "```py\n> coeffs\n\n```", "```py\n> round(coeffs, 3)\n\n```", "```py\n> moderate2 <- glmnet(X, Y, lambda = 0)\n\n```", "```py\n> moderate2\n\n```", "```py\n> round(data.frame(\"elastic, lambda = 0\" = as.vector(coef(moderate2)), \"lm\" = coef(OLSmodel), check.names = FALSE), 3)\n\n```", "```py\n> moderate3 <- glmnet(X[ , -2], Y, lambda = 0)\n\n```", "```py\n> moderate3\n\n```", "```py\n> moderate4 <- lm(Y ~ X[ , -2])\n\n```", "```py\n> moderate4\n\n```", "```py\n> round(data.frame(\"elastic, lambda = 0\" = as.vector(coef(moderate3)), \"lm\" = coef(moderate4), check.names = FALSE), 3)\n\n```", "```py\n    > modellingfucn1 <- function(data, i){\n    + X <- as.matrix(data[i , -1])\n    + Y <- data[i , 1]\n    # k-fold cross-validation for glmnet\n    + crossvalidated <- cv.glmnet(X, Y, alpha = 1, nfolds = 30)\n    # Fitting a generalized linear model via penalized maximum likelihood\n    + moderate1 <- glmnet(X, Y, alpha = 1)\n    # Computing the root mean squared error\n    + rmse(predict(moderate1, newx = as.matrix(data[ , -1]), s =     crossvalidated$lambda.min), data[ , 1])\n    + }\n\n```", "```py\n> elastic_boot <- boot(fitbit, statistic = modellingfucn1, R = 99)\n\n```", "```py\n > elastic_boot\n\n```", "```py\n    > modellingOLS <- function(data, i){\n    + mod0 <- lm(Calories.Burned ~ Steps, data = data[i, ])\n    + rmse(predict(moderate, newdata = data), data[ , 1])\n    + }\n\n```", "```py\n> lmOLS_boot <- boot(fitbit, statistic = modellingOLS, R = 99)\n\n```", "```py\n> lmOLS_boot\n\n```", "```py\n> lm_boot <- boot(fitbit, statistic = modellingfucn2, R = 99)\n\n```", "```py\n> lm_boot\n\n```", "```py\n > round(c(\"elastic modelling\" = mean(elastic_boot$t), \n + \"OLS modelling\" = mean(lm_boot$t),\n + \"OLS modelling, only one explanatory variable\" = mean(lmOLS_boot$t)), 1)\n\n```", "```py\n > ordering <- c(7,5,6,2,1,3,4)\n > par(mar = c(5.1, 4.1, 6.5, 1), bg = \"grey90\")\n > model_scaled <- glmnet(scale(X), Y, alpha = bestalpha)\n > the_palette <- brewer.pal(7, \"Set1\")\n > plot(model_scaled, xvar = \"dev\", label = TRUE, col = the_pallete, lwd = 2, main = \"Increasing contribution of different explanatory variablesnas penalty for including them is relaxed\")\n > legend(\"topleft\", legend = colnames(X)[ordering], text.col = the_palette[ordering], lwd = 2, bty = \"n\", col = the_palette[ordering])\n\n```", "```py\n    > install.packages(\"rgl\")\n    > install.packages(\"RColorBrewer\")\n    > install.packages(\"scales\")\n    > library(rgl)\n    > library(RColorBrewer)\n    > library(scales)\n\n```", "```py\n > delta <- read.csv(file=\"d:/delta.csv\", header=T, sep=\",\", row.names=1)\n\n```", "```py\n> str(delta)\n\n```", "```py\n> plot(delta[,16:22], main = \"Aircraft Physical Characteristics\", col = \"red\")\n\n```", "```py\n> principal_comp_analysis <- princomp(delta)\n\n```", "```py\n> principal_comp_analysis\n\n```", "```py\n> plot(principal_comp_analysis, main =\"Principal Components Analysis of Raw Data\", col =\"blue\")\n\n```", "```py\n> loadings(principal_comp_analysis)\n\n```", "```py\n > mar <- par()$mar\n > par(mar=mar+c(0,5,0,0))\n > barplot(sapply(delta, var), horiz=T, las=1, cex.names=0.8, main = \"Regular Scaling of Variance\", col = \"Red\", xlab = \"Variance\")\n\n```", "```py\n> barplot(sapply(delta, var), horiz=T, las=1, cex.names=0.8, log='x', main = \"Logarithmic  Scaling of Variance\", col = \"Blue\", xlab = \"Variance\")\n\n```", "```py\n> par(mar=mar)\n\n```", "```py\n> delta2 <- data.frame(scale(delta))\n\n```", "```py\n> plot(sapply(delta2, var), main = \"Variances Across Different Variables\", ylab = \"Variances\")\n\n```", "```py\n> principal_comp_analysis <- princomp(delta2)\n\n```", "```py\n> plot(principal_comp_analysis, main =\"Principal Components Analysis of Scaled Data\", col =\"red\")\n\n```", "```py\n> plot(principal_comp_analysis, type='l', main =\"Principal Components Analysis of Scaled Data\")\n\n```", "```py\n> summary(principal_comp_analysis)\n\n```", "```py\n> principal_comp_vectors <- prcomp(delta2)\n\n```", "```py\n> comp <- data.frame(principal_comp_vectors$x[,1:4])\n\n```", "```py\n> k_means <- kmeans(comp, 4, nstart=25, iter.max=1000)\n\n```", "```py\n> palette(alpha(brewer.pal(9,'Set1'), 0.5))\n\n```", "```py\n> plot(comp, col=k_means$clust, pch=16)\n\n```", "```py\n> plot3d(comp$PC1, comp$PC2, comp$PC3, col=k_means$clust) \n\n```", "```py\n> plot3d(comp$PC1, comp$PC3, comp$PC4, col=k_means$clust)\n\n```", "```py\n> sort(table(k_means$clust))\n\n```", "```py\n> clust <- names(sort(table(k_means$clust)))\n\n```", "```py\n> row.names(delta[k_means$clust==clust[1],])\n\n```", "```py\n> row.names(delta[k_means$clust==clust[2],])\n\n```", "```py\n> row.names(delta[k_means$clust==clust[3],])\n\n```", "```py\n> row.names(delta[k_means$clust==clust[4],])\n\n```", "```py\n> install.packages(\"glmnet\") \n    > library(ggplot2)\n    > library(glmnet)\n\n```", "```py\n> datafile <- file.path(\"d:\",\"epic_recipes.txt\")\n\n```", "```py\n> recipes_data <- read.table(datafile, fill=TRUE, col.names=1:max(count.fields(datafile)), na.strings=c(\"\", \"NA\"), stringsAsFactors = FALSE)\n\n```", "```py\n> agg <- aggregate(recipes_data[,-1], by=list(recipes_data[,1]), paste, collapse=\",\")\n\n```", "```py\n> agg$combined <- apply(agg[,2:ncol(agg)], 1, paste, collapse=\",\")\n\n```", "```py\n> agg$combined <- gsub(\",NA\",\"\",agg$combined)\n\n```", "```py\n> cuisines <- as.data.frame(table(recipes_data[,1]))\n\n```", "```py\n> cuisines\n\n```", "```py\n > ingredients_freq <- lapply(lapply(strsplit(a$combined,\",\"), table), as.data.frame) \n > names(ingredients_freq) <- agg[,1]\n\n```", "```py\n > proportion <- lapply(seq_along(ingredients_freq), function(i) {\n + colnames(ingredients_freq[[i]])[2] <- names(ingredients_freq)[i]\n + ingredients_freq[[i]][,2] <- ingredients_freq[[i]][,2]/cuisines[i,2] \n + ingredients_freq[[i]]}\n + )\n\n```", "```py\n    > names(proportion) <- a[,1]\n    > final <- Reduce(function(...) merge(..., all=TRUE, by=\"Var1\"), proportion)\n    > row.names(final) <- final[,1]\n    > final <- final[,-1]\n    > final[is.na(final)] <- 0\n    > prop_matrix <- t(final)\n    > s <- sort(apply(prop_matrix, 2, sd), decreasing=TRUE)\n\n```", "```py\n > final_imp <- scale(subset(prop_matrix, select=names(which(s > 0.1))))\n\n```", "```py\n> heatmap.2(final_imp, trace=\"none\", margins = c(6,11), col=topo.colors(7), key=TRUE, key.title=NA, keysize=1.2, density.info=\"none\")\n\n```", "```py\n> pca_computation <- princomp(final_imp) \n\n```", "```py\n> pca_computation\n\n```", "```py\n> biplot(pca_computation, pc.biplot=TRUE, col=c(\"black\",\"red\"), cex=c(0.9,0.8), xlim=c(-2.5,2.5), xlab=\"PC1, 39.7%\", ylab=\"PC2, 24.5%\")\n\n```"]