<html><head></head><body><div class="chapter" title="Chapter&#xA0;5.&#xA0;Recommendation Systems">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05"/>&#13;
 Chapter 5. Recommendation Systems</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>Recommendation systems find their natural application whenever a user is exposed to a wide choice of products or services that they cannot evaluate in a reasonable timeframe. These engines are an important part of an e-commerce business because they assist the clients on the web to facilitate the task of deciding the appropriate items to buy or choose over a large number of candidates not relevant to the end user. Typical examples are Amazon, Netflix, eBay, and Google Play stores that suggest each user the items they may like to buy using the historical data they have collected. Different techniques have been developed in the past 20 years and we will focus on the most important (and employed) methods used in the industry to date, specifying the advantages and <a id="id414" class="indexterm"/>&#13;
 disadvantages that characterize each of these methods. The recommendation systems are classified in <span class="strong">&#13;
<strong>Content-based Filtering</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>CBF</strong>&#13;
</span>&#13;
 ) and <span class="strong">&#13;
<strong>Collaborative Filtering</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>CF</strong>&#13;
</span>&#13;
 ) techniques <a id="id415" class="indexterm"/>&#13;
 and other different approaches (association rules, the log-likelihood method, and hybrid methods) will be discussed together with different ways to evaluate their accuracy. The methods <a id="id416" class="indexterm"/>&#13;
 will be tested on the MovieLens database (from <a class="ulink" href="http://grouplens.org/datasets/movielens/">http://grouplens.org/datasets/movielens/</a>&#13;
 ) consisting of 100,000 movie ratings (1 to 5 values) from 943 users on 1,682 movies. Each user has at least 20 ratings and each movie has a list of genres that it belongs to. All the codes shown in this chapter are available, as usual, at <a class="ulink" href="https://github.com/ai2010/machine_learning_for_the_web/tree/master/chapter_5">https://github.com/ai2010/machine_learning_for_the_web/tree/master/chapter_5</a>&#13;
 in the <code class="literal">rec_sys_methods.ipynb</code>&#13;
 file.</p>&#13;
<p>We will start by introducing the main matrix used to arrange the dataset employed by the recommendation system and the metric measures typically used before starting to discuss the algorithms in the following sections.</p>&#13;
<div class="section" title="Utility matrix">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05lvl1sec30"/>&#13;
 Utility matrix</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>The data <a id="id417" class="indexterm"/>&#13;
 used in a recommendation system is divided in two categories: the users and the items. Each user likes certain items, and the rating value <span class="emphasis">&#13;
<em>r<sub>ij</sub>&#13;
</em>&#13;
</span>&#13;
 (from 1 to 5) is the data associated with each user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and item <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 and represents how much the user appreciates the item. These rating values are collected in matrix, called utility matrix <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 , in which each row <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 represents the list of rated items for user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 while each column <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 lists all <a id="id418" class="indexterm"/>&#13;
 the users who have rated item <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 . In our case, the data folder <code class="literal">ml-100k</code>&#13;
 contains a file called <code class="literal">u.data</code>&#13;
 (and also <code class="literal">u.item</code>&#13;
 with the list of movie titles) that has been converted into a Pandas DataFrame (and saved into a <code class="literal">csv, utilitymatrix.csv</code>&#13;
 ) by the following script:</p>&#13;
<div class="mediaobject"><img src="Image00452.jpg" alt="Utility matrix"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The output of the first two lines is as follows:</p>&#13;
<div class="mediaobject"><img src="Image00453.jpg" alt="Utility matrix"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Each column name, apart from the first (which is the user id), defines the name of the movie <a id="id419" class="indexterm"/>&#13;
 and the ID of the movie in the MovieLens database (separated by a semicolon). The <code class="literal">0</code>&#13;
 values represent the missing values and we expect to have a large number of them because the users evaluated far fewer than 1,600 movies. Note that the movies with less than 50 ratings have been removed from the utility matrix, so the number of columns is 604 (603 movies rated more than 50 times). The goal of the recommendation system is to predict these values, but for some techniques to work properly it will be necessary for us to initially set these values (imputation). Usually, two imputation approaches are used: ratings average per user or ratings average per item, and both of them are implemented in the following function:</p>&#13;
<div class="mediaobject"><img src="Image00454.jpg" alt="Utility matrix"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>This function will be called by many of the algorithms implemented in this chapter, so we decided to discuss it here as a reference for future use. Furthermore, in this chapter the utility matrix <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 will have dimensions <span class="emphasis">&#13;
<em>N</em>&#13;
</span>&#13;
 ×<span class="emphasis">&#13;
<em>M</em>&#13;
</span>&#13;
 with <span class="emphasis">&#13;
<em>N</em>&#13;
</span>&#13;
 number of users and <span class="emphasis">&#13;
<em>M</em>&#13;
</span>&#13;
 number of items. Due to the recurrent use of the similarity measures by different algorithms, we will define the most commonly used definitions hereafter.</p>&#13;
</div>&#13;
</div>&#13;

<div class="section" title="Similarities measures">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05lvl1sec31"/>&#13;
 Similarities measures</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>In order <a id="id420" class="indexterm"/>&#13;
 to compute similarity <span class="emphasis">&#13;
<em>s</em>&#13;
</span>&#13;
 between two different <a id="id421" class="indexterm"/>&#13;
 vectors <span class="emphasis">&#13;
<em>x</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>y</em>&#13;
</span>&#13;
 , which can be users (rows of utility matrix) or items (columns of utility matrix), two measures are typically used:</p>&#13;
<div class="itemizedlist">&#13;
<ul class="itemizedlist">&#13;
<li class="listitem">Cosine similarity: <span class="inlinemediaobject"><img src="Image00455.jpg" alt="Similarities measures"/>&#13;
</span>&#13;
</li>&#13;
<li class="listitem">Pearson correlation: <span class="inlinemediaobject"><img src="Image00456.jpg" alt="Similarities measures"/>&#13;
</span>&#13;
 , where <span class="emphasis">&#13;
<em>x</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>y</em>&#13;
</span>&#13;
 are the <a id="id422" class="indexterm"/>&#13;
 averages of the two vectors.</li>&#13;
</ul>&#13;
</div>&#13;
<p>Note that <a id="id423" class="indexterm"/>&#13;
 the two measures coincide if the average is 0. We can now start discussing the different algorithms, starting from the CF category. The following <code class="literal">sim()</code>&#13;
 function will be used to evaluate the similarity between two vectors:</p>&#13;
<div class="mediaobject"><img src="Image00457.jpg" alt="Similarities measures"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The <code class="literal">SciPy</code>&#13;
 library has been used to compute both similarities (note that the cosine scipy definition is the opposite of what has been defined previously, so the value is subtracted from 1).</p>&#13;
</div>&#13;

<div class="section" title="Collaborative Filtering methods">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05lvl1sec32"/>&#13;
 Collaborative Filtering methods</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This class <a id="id424" class="indexterm"/>&#13;
 of methods is based on the idea that any user will like items appreciated by other users similar to them. In simple terms, the fundamental hypothesis is that a user <span class="emphasis">&#13;
<em>A</em>&#13;
</span>&#13;
 , who is similar to user <span class="emphasis">&#13;
<em>B</em>&#13;
</span>&#13;
 , will likely rate an item as <span class="emphasis">&#13;
<em>B</em>&#13;
</span>&#13;
 did rather than in another way. In practice, this concept is implemented by either comparing the taste of different user's and inferring the future rating for a given user using the most similar users taste (memory-based) or by extracting some rating patterns from what the users like (model-based) and trying to predict the future rating following these patterns. All these methods require a large amount of data to work because the recommendations to a given user rely on how many similar users can be found in the data. This problem <a id="id425" class="indexterm"/>&#13;
 is called <span class="strong">&#13;
<strong>cold start</strong>&#13;
</span>&#13;
 and it is very well studied in literature, which usually suggests using some hybrid method between CF and CBF to overcome the issue. In our MovieLens database example we assume we have enough data to avoid the cold start problem. Other common problems of CF algorithms are the scalability, because the computation grows with the number of users and products (it may be necessary some parallelization technique), and <a id="id426" class="indexterm"/>&#13;
 the sparsity of the utility matrix due to small number of items that any user usually rates (imputation is usually an attempt to handle the problem).</p>&#13;
<div class="section" title="Memory-based Collaborative Filtering">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h2 class="title"><a id="ch05lvl2sec32"/>&#13;
 Memory-based Collaborative Filtering</h2>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This <a id="id427" class="indexterm"/>&#13;
 subclass <a id="id428" class="indexterm"/>&#13;
 employs the utility matrix to calculate either the similarity between users or items. The methods suffer from scalability and cold start issues, but when they are applied to a large or too small utility matrix, they are currently used in many commercial systems today. We are going to discuss user-based Collaborative Filtering and iteFiased Collaborative Filtering hereafter.</p>&#13;
<div class="section" title="User-based Collaborative Filtering">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h3 class="title"><a id="ch05lvl3sec28"/>&#13;
 User-based Collaborative Filtering</h3>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>The <a id="id429" class="indexterm"/>&#13;
 approach uses a <code class="literal">k-NN</code>&#13;
 method (see <a class="link" title="Chapter 3. Supervised Machine Learning" href="text00024.html#page">Chapter 3</a>&#13;
 , <span class="emphasis">&#13;
<em>Supervised Machine Learning</em>&#13;
</span>&#13;
 ) to find the users whose past ratings are similar to the ratings of the chosen user so that their ratings can be combined in a weighted average to return the current user's missing ratings.</p>&#13;
<p>The algorithm is as follows:</p>&#13;
<p>For any given user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and item not yet rated <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 :</p>&#13;
<div class="orderedlist">&#13;
<ol class="orderedlist arabic">&#13;
<li class="listitem" value="1">Find the <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 that is most similar users that have rate <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 using a similarity metric <span class="emphasis">&#13;
<em>s</em>&#13;
</span>&#13;
 .</li>&#13;
<li class="listitem" value="2">Calculate the predicted rating for each item <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 not yet rated by <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 as a weighted average over the ratings of the users <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 :<div class="mediaobject"><img src="Image00458.jpg" alt="User-based Collaborative Filtering"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
</li>&#13;
</ol>&#13;
<div style="height:10px; width: 1px"/>&#13;
</div>&#13;
<p>Here <span class="inlinemediaobject"><img src="Image00459.jpg" alt="User-based Collaborative Filtering"/>&#13;
</span>&#13;
 are the average ratings for users <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>k</em>&#13;
</span>&#13;
 to compensate for subjective judgment (some users are generous and some are picky) and <span class="emphasis">&#13;
<em>s(i</em>&#13;
</span>&#13;
 , <span class="emphasis">&#13;
<em>k)</em>&#13;
</span>&#13;
 is the similarity metric, as seen in the previous paragraph. Note that we can even normalize by the spread of the ratings per user to compare more homogeneous ratings:</p>&#13;
<div class="mediaobject"><img src="Image00460.jpg" alt="User-based Collaborative Filtering"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, σ<sub>i</sub>&#13;
 and σ<sub>k</sub>&#13;
 are the standard deviations of ratings of users <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>k</em>&#13;
</span>&#13;
 .</p>&#13;
<p>This algorithm has as an input parameter, the number of neighbors, <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 but usually a value between <code class="literal">20</code>&#13;
 and <code class="literal">50</code>&#13;
 is <a id="id430" class="indexterm"/>&#13;
 sufficient in most applications. The Pearson correlation has been found <a id="id431" class="indexterm"/>&#13;
 to return <a id="id432" class="indexterm"/>&#13;
 better results than cosine similarity, probably because the subtraction of the user ratings means that the correlation formula makes the users more comparable. The following code is used to predict the missing ratings of each user.</p>&#13;
<p>The <code class="literal">u_vec</code>&#13;
 represents the user ratings values from which the most similar other users <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 are found by the function <code class="literal">FindKNeighbours</code>&#13;
 . <code class="literal">CalcRating</code>&#13;
 just computes the predicted rating using the formula discussed earlier (without the spreading correction). Note that in case the utility matrix is so sparse that no neighbors are found, the mean rating of the user is predicted. It may happen that the predicted rating is beyond <code class="literal">5</code>&#13;
 or below <code class="literal">1</code>&#13;
 , so in such situations the predicted rating is set to <code class="literal">5</code>&#13;
 or <code class="literal">1</code>&#13;
 respectively.</p>&#13;
<div class="mediaobject"><img src="Image00461.jpg" alt="User-based Collaborative Filtering"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
</div>&#13;
<div class="section" title="Item-based Collaborative Filtering">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h3 class="title"><a id="ch05lvl3sec29"/>&#13;
 Item-based Collaborative Filtering</h3>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This <a id="id433" class="indexterm"/>&#13;
 approach is conceptually the same as user-based CF except that the similarity is calculated on the items rather than the users. Since most of the time the number of users can become much larger than the number of items, this method offers a more scalable recommendation system because the items' similarities can be precomputed and they will not change much when new users arrive (if the number of users <span class="emphasis">&#13;
<em>N</em>&#13;
</span>&#13;
 is significantly large).</p>&#13;
<p>The algorithm for each user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and item <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 is as follows:</p>&#13;
<div class="orderedlist">&#13;
<ol class="orderedlist arabic">&#13;
<li class="listitem" value="1">Find the <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 most similar items using a similarity metric <span class="emphasis">&#13;
<em>s</em>&#13;
</span>&#13;
 that <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 has already rated.</li>&#13;
<li class="listitem" value="2">Calculate the predicted rating as a weighted average of the ratings of the <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 items:<div class="mediaobject"><img src="Image00462.jpg" alt="Item-based Collaborative Filtering"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
</li>&#13;
</ol>&#13;
<div style="height:10px; width: 1px"/>&#13;
</div>&#13;
<p>Note <a id="id434" class="indexterm"/>&#13;
 that the similarity metric may have a negative value, so we need to restrict the summation to only positive similarities in order to have meaningful (that is, positive) <span class="emphasis">&#13;
<em>P<sub>ij</sub>&#13;
</em>&#13;
</span>&#13;
 (the relative ordering of items will be correct anyway if we are only interested in the best item to recommend instead of the ratings). Even in this case, a <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 value between <code class="literal">20</code>&#13;
 and <code class="literal">50</code>&#13;
 is usually fine in most applications.</p>&#13;
<p>The algorithm is implemented using a class, as follows:</p>&#13;
<div class="mediaobject"><img src="Image00463.jpg" alt="Item-based Collaborative Filtering"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The constructor of the class <code class="literal">CF_itembased</code>&#13;
 calculates the item similarity matrix <code class="literal">simmatrix</code>&#13;
 <a id="id435" class="indexterm"/>&#13;
 to use any time we want to evaluate missing ratings for a user through the function <code class="literal">CalcRatings</code>&#13;
 . The function <code class="literal">GetKSimItemsperUser</code>&#13;
 finds <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 : most similar users to the chosen user (given by <code class="literal">u_vec</code>&#13;
 ) and <code class="literal">CalcRating</code>&#13;
 just implements the weighted average rating calculations discussed previously. Note that in case no neighbors are found, the rating is set to the average or the item's ratings.</p>&#13;
</div>&#13;
<div class="section" title="Simplest item-based Collaborative Filtering – slope one">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h3 class="title"><a id="ch05lvl3sec30"/>&#13;
 Simplest item-based Collaborative Filtering – slope one</h3>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>Instead <a id="id436" class="indexterm"/>&#13;
 of computing the similarity using the metric discussed previously, a very simple but effective method can be used. We can compute a matrix <span class="emphasis">&#13;
<em>D</em>&#13;
</span>&#13;
 in which each entry <span class="emphasis">&#13;
<em>d<sub>ij</sub>&#13;
</em>&#13;
</span>&#13;
 is the average difference between the ratings of items <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 :</p>&#13;
<div class="mediaobject"><img src="Image00464.jpg" alt="Simplest item-based Collaborative Filtering – slope one"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, <span class="inlinemediaobject"><img src="Image00465.jpg" alt="Simplest item-based Collaborative Filtering – slope one"/>&#13;
</span>&#13;
 is a variable that counts if the user <span class="emphasis">&#13;
<em>k</em>&#13;
</span>&#13;
 has rated both <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 items, so <span class="inlinemediaobject"><img src="Image00466.jpg" alt="Simplest item-based Collaborative Filtering – slope one"/>&#13;
</span>&#13;
 is the number of users who have rated both <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 items.</p>&#13;
<p>Then the algorithm is as explained in the <span class="emphasis">&#13;
<em>Item-based Collaborative Filtering</em>&#13;
</span>&#13;
 section. For each user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and item <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 :</p>&#13;
<div class="orderedlist">&#13;
<ol class="orderedlist arabic">&#13;
<li class="listitem" value="1">Find the <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 items with the smallest differences from <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 , <span class="inlinemediaobject"><img src="Image00467.jpg" alt="Simplest item-based Collaborative Filtering – slope one"/>&#13;
</span>&#13;
 (the <code class="literal">*</code>&#13;
 indicates the possible index values, but for simplicity we relabel them from <code class="literal">1</code>&#13;
 to <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 ).</li>&#13;
<li class="listitem" value="2">Compute the predicted rating as a weighted average:<div class="mediaobject"><img src="Image00468.jpg" alt="Simplest item-based Collaborative Filtering – slope one"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
</li>&#13;
</ol>&#13;
<div style="height:10px; width: 1px"/>&#13;
</div>&#13;
<p>Although this algorithm is much simpler than the other CF algorithms, it often matches their <a id="id437" class="indexterm"/>&#13;
 accuracy, is computationally less expensive, and is easy to implement. The implementation is very similar to the class used for item-based CF:</p>&#13;
<div class="mediaobject"><img src="Image00469.jpg" alt="Simplest item-based Collaborative Filtering – slope one"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The only difference is the matrix: now <code class="literal">difmatrix</code>&#13;
 is used to calculate the differences <span class="emphasis">&#13;
<em>d(i</em>&#13;
</span>&#13;
 , <span class="emphasis">&#13;
<em>j)</em>&#13;
</span>&#13;
 between <a id="id438" class="indexterm"/>&#13;
 items <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 , <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 , as explained earlier, and the function <code class="literal">GetKSimItemsperUser</code>&#13;
 now looks for the smallest <code class="literal">difmatrix</code>&#13;
 values to determine the <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 nearest neighbors. Since it is possible (although unlikely) that two items have not been rated by at least one user, <code class="literal">difmatrix</code>&#13;
 can have undefined values that are set to <code class="literal">1000</code>&#13;
 by default. Note that it is also possible that the predicted rating is beyond <code class="literal">5</code>&#13;
 or below <code class="literal">1</code>&#13;
 , so in such situations the predicted rating must be set to <code class="literal">5</code>&#13;
 or <code class="literal">1</code>&#13;
 appropriately.</p>&#13;
</div>&#13;
</div>&#13;
<div class="section" title="Model-based Collaborative Filtering">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h2 class="title"><a id="ch05lvl2sec33"/>&#13;
 Model-based Collaborative Filtering</h2>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This <a id="id439" class="indexterm"/>&#13;
 class of methods uses the utility matrix to generate a model to extract the pattern of how the users rate the items. The pattern model returns the predicted ratings, filling or approximating the original matrix (matrix factorization).Various models have been studied <a id="id440" class="indexterm"/>&#13;
 in the literature and we will discuss particular <span class="emphasis">&#13;
<em>matrix factorization</em>&#13;
</span>&#13;
 algorithms—the <span class="strong">&#13;
<strong>Singular Value Decomposition</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>SVD</strong>&#13;
</span>&#13;
 , also with expectation maximization), the <span class="strong">&#13;
<strong>Alternating Least Square</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>ALS</strong>&#13;
</span>&#13;
 ), the <span class="strong">&#13;
<strong>Stochastic Gradient Descent</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>SGD</strong>&#13;
</span>&#13;
 ), and the general <span class="strong">&#13;
<strong>Non-negative matrix factorization</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>NMF</strong>&#13;
</span>&#13;
 ) class of algorithms.</p>&#13;
<div class="section" title="Alternative least square (ALS)">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h3 class="title"><a id="ch05lvl3sec31"/>&#13;
 Alternative least square (ALS)</h3>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This is <a id="id441" class="indexterm"/>&#13;
 the simplest <a id="id442" class="indexterm"/>&#13;
 method to factorize the matrix <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 . Each user and each item can be represented in a feature space of dimension <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 so that:</p>&#13;
<div class="mediaobject"><img src="Image00470.jpg" alt="Alternative least square (ALS)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, <span class="emphasis">&#13;
<em>P N×K</em>&#13;
</span>&#13;
 is the new matrix of users in the feature space, and <span class="emphasis">&#13;
<em>Q M×K</em>&#13;
</span>&#13;
 is the projection of the items in the same space. So the problem is reduced to minimize a regularized cost function <span class="emphasis">&#13;
<em>J</em>&#13;
</span>&#13;
 :</p>&#13;
<div class="mediaobject"><img src="Image00471.jpg" alt="Alternative least square (ALS)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, λ is the regularization parameter, which is useful to avoid overfitting by penalizing the learned parameters and ensuring that the magnitudes of the vectors <span class="emphasis">&#13;
<em>p<sub>i</sub>&#13;
</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>&#13;
<sub>q</sub>&#13;
 <sup>T</sup>&#13;
 <sub>j</sub>&#13;
</em>&#13;
</span>&#13;
 are not too large. The <a id="id443" class="indexterm"/>&#13;
 matrix entries <span class="emphasis">&#13;
<em>Mc<sub>ij</sub>&#13;
</em>&#13;
</span>&#13;
 are <a id="id444" class="indexterm"/>&#13;
 needed to check that the pair of user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and item <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 are actually rated, so <span class="emphasis">&#13;
<em>Mc<sub>ij</sub>&#13;
</em>&#13;
</span>&#13;
 is <code class="literal">1</code>&#13;
 if <span class="emphasis">&#13;
<em>r<sub>ij</sub>&#13;
 &gt;0</em>&#13;
</span>&#13;
 , and it's <code class="literal">0</code>&#13;
 otherwise. Setting the derivatives of <span class="emphasis">&#13;
<em>J</em>&#13;
</span>&#13;
 to <code class="literal">0</code>&#13;
 for each user vector <span class="emphasis">&#13;
<em>p<sub>i</sub>&#13;
</em>&#13;
</span>&#13;
 and item vector <span class="emphasis">&#13;
<em>q<sub>j</sub>&#13;
</em>&#13;
</span>&#13;
 , we obtain the following two equations:</p>&#13;
<div class="mediaobject"><img src="Image00472.jpg" alt="Alternative least square (ALS)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<div class="mediaobject"><img src="Image00473.jpg" alt="Alternative least square (ALS)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here <span class="emphasis">&#13;
<em>R<sub>i</sub>&#13;
</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>Mc<sub>i</sub>&#13;
</em>&#13;
</span>&#13;
 refer to the row <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 of the matrices <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>Mc</em>&#13;
</span>&#13;
 , and <span class="emphasis">&#13;
<em>R<sub>j</sub>&#13;
</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>Mc<sub>j</sub>&#13;
</em>&#13;
</span>&#13;
 refer to the column <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 of the matrices <span class="emphasis">&#13;
<em>Mc</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 . Alternating the fixing of the matrix <span class="emphasis">&#13;
<em>P</em>&#13;
</span>&#13;
 , <span class="emphasis">&#13;
<em>Q</em>&#13;
</span>&#13;
 , the previous equations can be solved directly using a least square algorithm and the following function implements the ALS algorithm in Python:</p>&#13;
<div class="mediaobject"><img src="Image00474.jpg" alt="Alternative least square (ALS)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The matrix <span class="emphasis">&#13;
<em>Mc</em>&#13;
</span>&#13;
 is called <code class="literal">mask</code>&#13;
 , the variable <code class="literal">l</code>&#13;
 represents the regularization parameter lambda and is set to <code class="literal">0.001</code>&#13;
 by default, and the least square problem has been solved using the <code class="literal">linalg.solve</code>&#13;
 function of the <code class="literal">Numpy</code>&#13;
 library. This method usually is less precise than both <span class="strong">&#13;
<strong>Stochastic Gradient Descent</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>SGD</strong>&#13;
</span>&#13;
 ) and <span class="strong">&#13;
<strong>Singular Value Decomposition</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>SVD</strong>&#13;
</span>&#13;
 ) (see the following sections) but it is very easy to implement and easy to parallelize (so it can be fast).</p>&#13;
</div>&#13;
<div class="section" title="Stochastic gradient descent (SGD)">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h3 class="title"><a id="ch05lvl3sec32"/>&#13;
 Stochastic gradient descent (SGD)</h3>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This <a id="id445" class="indexterm"/>&#13;
 method <a id="id446" class="indexterm"/>&#13;
 also belongs to the matrix factorization subclass because it relies on the approximation of the utility matrix <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 as:</p>&#13;
<div class="mediaobject"><img src="Image00475.jpg" alt="Stochastic gradient descent (SGD)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, the matrices <span class="emphasis">&#13;
<em>P(N×K)</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>Q(M×K)</em>&#13;
</span>&#13;
 represent the users and the items in a latent feature space of <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 dimensions. Each approximated rating <span class="inlinemediaobject"><img src="Image00476.jpg" alt="Stochastic gradient descent (SGD)"/>&#13;
</span>&#13;
 can be expressed as follows:</p>&#13;
<div class="mediaobject"><img src="Image00477.jpg" alt="Stochastic gradient descent (SGD)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The matrix <span class="inlinemediaobject"><img src="Image00478.jpg" alt="Stochastic gradient descent (SGD)"/>&#13;
</span>&#13;
 is found, solving the minimization problem of the regularized squared errors <span class="emphasis">&#13;
<em>e<sup>2</sup>&#13;
 <sub>ij</sub>&#13;
</em>&#13;
</span>&#13;
 as with the ALS method (cost function <span class="emphasis">&#13;
<em>J</em>&#13;
</span>&#13;
 as in <a class="link" title="Chapter 3. Supervised Machine Learning" href="text00024.html#page">Chapter 3</a>&#13;
 , <span class="emphasis">&#13;
<em>Supervised Machine Learning</em>&#13;
</span>&#13;
 ):</p>&#13;
<div class="mediaobject"><img src="Image00479.jpg" alt="Stochastic gradient descent (SGD)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>This minimization problem is solved using the gradient descent (see <a class="link" title="Chapter 3. Supervised Machine Learning" href="text00024.html#page">Chapter 3</a>&#13;
 , <span class="emphasis">&#13;
<em>Supervised Machine Learning</em>&#13;
</span>&#13;
 ):</p>&#13;
<div class="mediaobject"><img src="Image00480.jpg" alt="Stochastic gradient descent (SGD)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<div class="mediaobject"><img src="Image00481.jpg" alt="Stochastic gradient descent (SGD)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, α is the learning rate (see <a class="link" title="Chapter 3. Supervised Machine Learning" href="text00024.html#page">Chapter 3</a>&#13;
 , <span class="emphasis">&#13;
<em>Supervised Machine Learning</em>&#13;
</span>&#13;
 ) and <span class="inlinemediaobject"><img src="Image00482.jpg" alt="Stochastic gradient descent (SGD)"/>&#13;
</span>&#13;
 . The technique finds <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 alternating between the two previous equations (fixing <span class="emphasis">&#13;
<em>q<sub>kj</sub>&#13;
</em>&#13;
</span>&#13;
 and solving <span class="emphasis">&#13;
<em>P<sub>ik</sub>&#13;
</em>&#13;
</span>&#13;
 , and vice versa) until convergence. SGD is usually easier to parallelize (so it can be faster) than SVD (see the following section) but is less precise at finding <a id="id447" class="indexterm"/>&#13;
 good <a id="id448" class="indexterm"/>&#13;
 ratings. The implementation in Python of this method is given by the following script:</p>&#13;
<div class="mediaobject"><img src="Image00483.jpg" alt="Stochastic gradient descent (SGD)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>This SGD function has default parameters that are learning rate <span class="emphasis">&#13;
<em>α = 0.0001</em>&#13;
</span>&#13;
 , regularization parameter <span class="emphasis">&#13;
<em>λ = l =0.001</em>&#13;
</span>&#13;
 , maximum number of iterations <code class="literal">1000</code>&#13;
 , and convergence tolerance <code class="literal">tol = 0.001</code>&#13;
 . Note also that the items not rated (<code class="literal">0</code>&#13;
 rating values) are not considered in the computation, so an initial filling (imputation) is not necessary when using this method.</p>&#13;
</div>&#13;
<div class="section" title="Non-negative matrix factorization (NMF)">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h3 class="title"><a id="ch05lvl3sec33"/>&#13;
 Non-negative matrix factorization (NMF)</h3>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This <a id="id449" class="indexterm"/>&#13;
 is a group of methods that finds the decomposition of the matrix <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 again as a product of two matrices <span class="emphasis">&#13;
<em>P</em>&#13;
</span>&#13;
 (<span class="emphasis">&#13;
<em>N</em>&#13;
</span>&#13;
 ×<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 ) and <span class="emphasis">&#13;
<em>Q</em>&#13;
</span>&#13;
 (<span class="emphasis">&#13;
<em>M</em>&#13;
</span>&#13;
 ×<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 ) (where <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 is a dimension of the feature space), but <a id="id450" class="indexterm"/>&#13;
 their elements are required to be non-negative. The general minimization problem is as follows:</p>&#13;
<div class="mediaobject"><img src="Image00484.jpg" alt="Non-negative matrix factorization (NMF)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, α is a parameter that defines which regularization term to use (<code class="literal">0</code>&#13;
 squared, <code class="literal">1</code>&#13;
 a lasso regularization, or a mixture of them) and λ is the regularization parameter. Several techniques have been developed to solve this problem, such as projected gradient, coordinate descent, and non-negativity constrained least squares. It is beyond the scope of this book to discuss the details of these techniques, but we are going to use the coordinate descent method implemented in <code class="literal">sklearn NFM</code>&#13;
 wrapped in the following function:</p>&#13;
<div class="mediaobject"><img src="Image00485.jpg" alt="Non-negative matrix factorization (NMF)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Note that an imputation may be performed before the actual factorization takes place and that the function <code class="literal">fit_transform</code>&#13;
 returns the <span class="emphasis">&#13;
<em>P</em>&#13;
</span>&#13;
 matrix while the <span class="emphasis">&#13;
<em>Q<sup>T</sup>&#13;
</em>&#13;
</span>&#13;
 matrix is stored in the <code class="literal">nmf.components_</code>&#13;
 object. The <span class="emphasis">&#13;
<em>α</em>&#13;
</span>&#13;
 value is assumed to be <code class="literal">0</code>&#13;
 (squared regularization) and <span class="emphasis">&#13;
<em>λ = l =0.01</em>&#13;
</span>&#13;
 by default. Since the utility matrix has positive values (ratings), this class of methods is certainly a good fit to predict these values.</p>&#13;
</div>&#13;
<div class="section" title="Singular value decomposition (SVD)">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h3 class="title"><a id="ch05lvl3sec34"/>&#13;
 Singular value decomposition (SVD)</h3>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>We have <a id="id451" class="indexterm"/>&#13;
 already <a id="id452" class="indexterm"/>&#13;
 discussed this algorithm in <a class="link" title="Chapter 2. Unsupervised Machine Learning" href="text00020.html#ch02">Chapter 2</a>&#13;
 , <span class="emphasis">&#13;
<em>Unsupervised Machine Learning</em>&#13;
</span>&#13;
 , as a dimensionality reduction technique to approximate a matrix by decomposition into matrices <span class="emphasis">&#13;
<em>U</em>&#13;
</span>&#13;
 , Σ, <span class="emphasis">&#13;
<em>V</em>&#13;
</span>&#13;
 (you should read the related section in <a class="link" title="Chapter 2. Unsupervised Machine Learning" href="text00020.html#ch02">Chapter 2</a>&#13;
 , <span class="emphasis">&#13;
<em>Unsupervised Machine Learning</em>&#13;
</span>&#13;
 , for further technical details). In this case, SVD is used <a id="id453" class="indexterm"/>&#13;
 as a matrix factorization technique, but an imputation method is required to initially estimate <a id="id454" class="indexterm"/>&#13;
 the missing data for each user; typically, the average of each utility matrix row (or column) or a combination of both (instead of leaving the zero values) is used. Apart from directly applying the SVD to the utility matrix, another algorithm that exploits an expectation-maximization (see <a class="link" title="Chapter 2. Unsupervised Machine Learning" href="text00020.html#ch02">Chapter 2</a>&#13;
 , <span class="emphasis">&#13;
<em>Unsupervised Machine Learning</em>&#13;
</span>&#13;
 ) can be used as follows, starting from the matrix <span class="inlinemediaobject"><img src="Image00486.jpg" alt="Singular value decomposition (SVD)"/>&#13;
</span>&#13;
 :</p>&#13;
<div class="orderedlist">&#13;
<ol class="orderedlist arabic">&#13;
<li class="listitem" value="1">&#13;
<span class="strong">&#13;
<strong>m-step</strong>&#13;
</span>&#13;
 : Perform <span class="inlinemediaobject"><img src="Image00487.jpg" alt="Singular value decomposition (SVD)"/>&#13;
</span>&#13;
</li>&#13;
<li class="listitem" value="2">&#13;
<span class="strong">&#13;
<strong>e-step</strong>&#13;
</span>&#13;
 : <span class="inlinemediaobject"><img src="Image00488.jpg" alt="Singular value decomposition (SVD)"/>&#13;
</span>&#13;
</li>&#13;
</ol>&#13;
<div style="height:10px; width: 1px"/>&#13;
</div>&#13;
<p>This procedure is repeated until the sum of squared errors <span class="inlinemediaobject"><img src="Image00489.jpg" alt="Singular value decomposition (SVD)"/>&#13;
</span>&#13;
 is less than a chosen tolerance. The code that implements this algorithm and the simple SVD factorization is as follows:</p>&#13;
<div class="mediaobject"><img src="Image00490.jpg" alt="Singular value decomposition (SVD)"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Note that the SVD is given by the <code class="literal">sklearn</code>&#13;
 library and both imputation average methods (user ratings' average and item ratings' average) have been implemented, although the function <a id="id455" class="indexterm"/>&#13;
 default <a id="id456" class="indexterm"/>&#13;
 is <span class="emphasis">&#13;
<em>none</em>&#13;
</span>&#13;
 , which means that the zero values are left as initial values. For the expect-maximization SVD, the other default parameters are the convergence tolerance (0.0001) and the maximum number of iterations (10,000). This method (especially with expectation-maximization) is slower than the ALS, but the accuracy is generally higher. Also note that the SVD method decomposes the utility matrix subtracted by the user ratings' mean since this approach usually performs better (the user ratings' mean is then added after the SVD matrix has been computed).</p>&#13;
<p>We finish remarking that SVD factorization can also be used in memory-based CF to compare users or items in the reduced space (matrix <span class="emphasis">&#13;
<em>U</em>&#13;
</span>&#13;
 or <span class="emphasis">&#13;
<em>V<sup>T</sup>&#13;
</em>&#13;
</span>&#13;
 ) and then the ratings are taken from the original utility matrix (SVD with k-NN approach).</p>&#13;
</div>&#13;
</div>&#13;
</div>&#13;

<div class="section" title="CBF methods">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05lvl1sec33"/>&#13;
 CBF methods</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This <a id="id457" class="indexterm"/>&#13;
 class of method relies on the data that describes the items, which is then used to extract the features of the users. In our MovieLens example, each movie <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 has a set of <span class="emphasis">&#13;
<em>G</em>&#13;
</span>&#13;
 binary fields to indicate if it belongs to one of the following genres: unknown, action, adventure, animation, children's, comedy, crime, documentary, drama, fantasy, film noir, horror, musical, mystery, romance, sci-fi, thriller, war, or western.</p>&#13;
<p>Based on these features (genres), each movie is described by a binary vector <span class="emphasis">&#13;
<em>m<sub>j</sub>&#13;
</em>&#13;
</span>&#13;
 with <span class="emphasis">&#13;
<em>G</em>&#13;
</span>&#13;
 dimensions (number of movie genres) with entries equal to <code class="literal">1</code>&#13;
 for all the genres contained in movie <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 , or <code class="literal">0</code>&#13;
 otherwise. Given the <code class="literal">dataframe</code>&#13;
 that stores the utility matrix called <code class="literal">dfout</code>&#13;
 in the <span class="emphasis">&#13;
<em>Utility matrix</em>&#13;
</span>&#13;
 section mentioned earlier, these binary vectors <span class="emphasis">&#13;
<em>m<sub>j</sub>&#13;
</em>&#13;
</span>&#13;
 are collected from the MoviesLens <code class="literal">database</code>&#13;
 into a dataframe using the following script:</p>&#13;
<div class="mediaobject"><img src="Image00491.jpg" alt="CBF methods"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The movies content matrix has been saved in the <code class="literal">movies_content.csv</code>&#13;
 file ready to be used by the CBF methods.</p>&#13;
<p>The goal of the content-based recommendation system is to generate the user's profile with the same fields to indicate how much the user likes each genre. The problem with this method is that the content description of the item is not always available, so it is not always possible to employ this technique in the e-commerce environment. The advantage is that the recommendations to a specific user are independent of the other users' ratings, so it does not suffer from cold start problems due to an insufficient number of users' ratings for particular items. Two approaches are going to be discussed to find the best recommendation methodologies. The first methodology simply generates the user's profile associated with the average ratings of the movies seen by each user to each genre and the cosine similarity is used to find the movies most similar to the user preferences. The second methodology is a regularized linear regression model to generate the user's profile features from the ratings and the movie features so that the ratings of the movies not yet seen by each user can be predicted using these users' profiles.</p>&#13;
<div class="section" title="Item features average method">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h2 class="title"><a id="ch05lvl2sec34"/>&#13;
 Item features average method</h2>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>The <a id="id458" class="indexterm"/>&#13;
 approach is really simple and we are going to explain it using the features that describe the movies in the MovieLens example, as discussed previously. The objective of the method is to generate the movie genres' preferences vector <span class="inlinemediaobject"><img src="Image00492.jpg" alt="Item features average method"/>&#13;
</span>&#13;
 for each user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 (length equal to <span class="emphasis">&#13;
<em>G</em>&#13;
</span>&#13;
 ). This is done by calculating the average rating <span class="inlinemediaobject"><img src="Image00493.jpg" alt="Item features average method"/>&#13;
</span>&#13;
 and each genre entry <span class="emphasis">&#13;
<em>g</em>&#13;
</span>&#13;
 ; <span class="inlinemediaobject"><img src="Image00494.jpg" alt="Item features average method"/>&#13;
</span>&#13;
 is given by the sum of ratings of the movies seen by user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 (<span class="emphasis">&#13;
<em>Mi</em>&#13;
</span>&#13;
 ) containing the genre <span class="emphasis">&#13;
<em>g</em>&#13;
</span>&#13;
 , minus the average <span class="inlinemediaobject"><img src="Image00493.jpg" alt="Item features average method"/>&#13;
</span>&#13;
 and divided by the number of movies containing genre <span class="emphasis">&#13;
<em>g</em>&#13;
</span>&#13;
 :</p>&#13;
<div class="mediaobject"><img src="Image00495.jpg" alt="Item features average method"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, <span class="emphasis">&#13;
<em>I<sub>kg</sub>&#13;
</em>&#13;
</span>&#13;
 is 1 if the movie <span class="emphasis">&#13;
<em>k</em>&#13;
</span>&#13;
 contains genre <span class="emphasis">&#13;
<em>g</em>&#13;
</span>&#13;
 ; otherwise it is <code class="literal">0</code>&#13;
 .</p>&#13;
<p>The vectors <span class="inlinemediaobject"><img src="Image00496.jpg" alt="Item features average method"/>&#13;
</span>&#13;
 are then compared to the binary vectors m<span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 using the cosine similarity and the movies with the highest similarity values are recommended to the user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 . The implementation of the method is given by the following Python class:</p>&#13;
<div class="mediaobject"><img src="Image00497.jpg" alt="Item features average method"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The <a id="id459" class="indexterm"/>&#13;
 constructor stores the list of the movie titles in <code class="literal">Movieslist</code>&#13;
 and the movie features in the <code class="literal">Movies</code>&#13;
 vector, and the <code class="literal">GetRecMovies</code>&#13;
 function generates the user genres' preferences vector, that is, <span class="inlinemediaobject"><img src="Image00496.jpg" alt="Item features average method"/>&#13;
</span>&#13;
 (applying the preceding formula) called <code class="literal">features_u</code>&#13;
 , and returns the most similar items to this vector.</p>&#13;
</div>&#13;
<div class="section" title="Regularized linear regression method">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h2 class="title"><a id="ch05lvl2sec35"/>&#13;
 Regularized linear regression method</h2>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>The method <a id="id460" class="indexterm"/>&#13;
 learns the movie preferences of the users as parameters <span class="inlinemediaobject"><img src="Image00498.jpg" alt="Regularized linear regression method"/>&#13;
</span>&#13;
 of a linear model, with <span class="inlinemediaobject"><img src="Image00499.jpg" alt="Regularized linear regression method"/>&#13;
</span>&#13;
 , where <span class="emphasis">&#13;
<em>N</em>&#13;
</span>&#13;
 is the number of users and <span class="emphasis">&#13;
<em>G</em>&#13;
</span>&#13;
 is the number of features (movie genres) of each item. We add an intercept value on the user parameters <span class="emphasis">&#13;
<em>θ<sub>i</sub>&#13;
 (θ<sub>i0</sub>&#13;
 = 1</em>&#13;
</span>&#13;
 ) and also the movie vector <span class="emphasis">&#13;
<em>m<sub>j</sub>&#13;
</em>&#13;
</span>&#13;
 that has the same value <span class="emphasis">&#13;
<em>m<sub>j0</sub>&#13;
 =1</em>&#13;
</span>&#13;
 , and so <span class="inlinemediaobject"><img src="Image00500.jpg" alt="Regularized linear regression method"/>&#13;
</span>&#13;
 . To learn the vectors of parameters q<span class="emphasis">&#13;
<em>&#13;
<sub>i</sub>&#13;
</em>&#13;
</span>&#13;
 , we solve the following regularized minimization problem:</p>&#13;
<div class="mediaobject"><img src="Image00501.jpg" alt="Regularized linear regression method"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, <span class="emphasis">&#13;
<em>I<sub>ij</sub>&#13;
</em>&#13;
</span>&#13;
 is <code class="literal">1</code>&#13;
 ; that is, user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 watched the movie, otherwise <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 is <code class="literal">0</code>&#13;
 and λ is the regularization parameter (see <a class="link" title="Chapter 3. Supervised Machine Learning" href="text00024.html#page">Chapter 3</a>&#13;
 , <span class="emphasis">&#13;
<em>Supervised Machine Learning</em>&#13;
</span>&#13;
 ).</p>&#13;
<p>The <a id="id461" class="indexterm"/>&#13;
 solution is given by applying gradient descent (see <a class="link" title="Chapter 3. Supervised Machine Learning" href="text00024.html#page">Chapter 3</a>&#13;
 , <span class="emphasis">&#13;
<em>Supervised Machine Learning</em>&#13;
</span>&#13;
 ). For each user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 :</p>&#13;
<div class="itemizedlist">&#13;
<ul class="itemizedlist">&#13;
<li class="listitem">&#13;
<span class="inlinemediaobject"><img src="Image00502.jpg" alt="Regularized linear regression method"/>&#13;
</span>&#13;
 (k=0)</li>&#13;
<li class="listitem">&#13;
<span class="inlinemediaobject"><img src="Image00503.jpg" alt="Regularized linear regression method"/>&#13;
</span>&#13;
 (k&gt;0)</li>&#13;
</ul>&#13;
</div>&#13;
<p>Since we are adding <code class="literal">1</code>&#13;
 entry to the movie and user vectors respectively, the distinction between learning the intercept parameter (<span class="emphasis">&#13;
<em>k=0</em>&#13;
</span>&#13;
 ) and the others is necessary (there is no possibility of overfitting on the intercept, so no need to regularize on it). After the parameters q<span class="emphasis">&#13;
<em>&#13;
<sub>i</sub>&#13;
</em>&#13;
</span>&#13;
 are learned, the recommendation is performed by simply applying for any missing rating <span class="emphasis">&#13;
<em>r<sub>ij</sub>&#13;
</em>&#13;
</span>&#13;
 in the formula <span class="inlinemediaobject"><img src="Image00504.jpg" alt="Regularized linear regression method"/>&#13;
</span>&#13;
 .</p>&#13;
<p>The method is implemented by the following code:</p>&#13;
<div class="mediaobject"><img src="Image00505.jpg" alt="Regularized linear regression method"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The constructor of the class <code class="literal">CBF_regression</code>&#13;
 just performs the gradient descent to find the <a id="id462" class="indexterm"/>&#13;
 parameters <span class="emphasis">&#13;
<em>θ<sub>i</sub>&#13;
</em>&#13;
</span>&#13;
 (called <code class="literal">Pmatrix</code>&#13;
 ) while the function <code class="literal">CalcRatings</code>&#13;
 finds the most similar rating vector in the stored utility matrix <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 (in case the user is not present in the utility matrix) and then it uses the corresponding parameters' vector to predict the missing ratings.</p>&#13;
</div>&#13;
</div>&#13;

<div class="section" title="Association rules for learning recommendation system">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05lvl1sec34"/>&#13;
 Association rules for learning recommendation system</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>Although <a id="id463" class="indexterm"/>&#13;
 this method is not used often in many commercial recommendation systems, association rules learning is certainly a method worth knowing about because of historical data reasons, and it can be employed to solve a wide range of problems in real-world examples. The main concept of this method is to find relationships among items based on some statistical measure of the occurrences of the items in the database of transactions <span class="emphasis">&#13;
<em>T</em>&#13;
</span>&#13;
 (for example, a transaction could be the movies seen by a user <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 or the products bought by <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 ). More formally, a rule could be <span class="emphasis">&#13;
<em>{item1,item2} =&gt; {item3}</em>&#13;
</span>&#13;
 , that is, a set of items <span class="emphasis">&#13;
<em>({item1,item2})</em>&#13;
</span>&#13;
 implies the presence of another set <span class="emphasis">&#13;
<em>({item3})</em>&#13;
</span>&#13;
 . Two definitions are used to characterize each <span class="emphasis">&#13;
<em>X=&gt;Y</em>&#13;
</span>&#13;
 rule:</p>&#13;
<div class="itemizedlist">&#13;
<ul class="itemizedlist">&#13;
<li class="listitem">&#13;
<span class="strong">&#13;
<strong>Support</strong>&#13;
</span>&#13;
 : Given a <a id="id464" class="indexterm"/>&#13;
 set of items <span class="emphasis">&#13;
<em>X</em>&#13;
</span>&#13;
 , the support <span class="emphasis">&#13;
<em>supp(X)</em>&#13;
</span>&#13;
 is the portion of transactions that contains the set <span class="emphasis">&#13;
<em>X</em>&#13;
</span>&#13;
 over the total transactions.</li>&#13;
<li class="listitem">&#13;
<span class="strong">&#13;
<strong>Confidence</strong>&#13;
</span>&#13;
 : It is <a id="id465" class="indexterm"/>&#13;
 the fraction of transactions that contains the set <span class="emphasis">&#13;
<em>X</em>&#13;
</span>&#13;
 that also contains the set <span class="emphasis">&#13;
<em>Y: conf(X=&gt;Y)=supp(X U Y)/supp(X)</em>&#13;
</span>&#13;
 . Note that the confidence <span class="emphasis">&#13;
<em>conf(X=&gt;Y)</em>&#13;
</span>&#13;
 can have a very different value than <span class="emphasis">&#13;
<em>conf(Y=&gt;X)</em>&#13;
</span>&#13;
 .</li>&#13;
</ul>&#13;
</div>&#13;
<p>Support represents the frequency of a certain rule on the transaction database, while the confidence indicates the probability that set <span class="emphasis">&#13;
<em>Y</em>&#13;
</span>&#13;
 will occur if set <span class="emphasis">&#13;
<em>X</em>&#13;
</span>&#13;
 is present. In other words, the support value is chosen to filter the number of rules we want to mine from the database (the higher the support, the fewer rules will satisfy the condition), while the confidence can be thought of as a <span class="emphasis">&#13;
<em>similarity</em>&#13;
</span>&#13;
 metric between sets <span class="emphasis">&#13;
<em>X</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>Y</em>&#13;
</span>&#13;
 . In the case of the movie recommendation system, the transaction database can be generated from the utility matrix <span class="emphasis">&#13;
<em>R</em>&#13;
</span>&#13;
 considering the movies each user likes, and we look for rules composed by sets <span class="emphasis">&#13;
<em>X</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>Y</em>&#13;
</span>&#13;
 that contain only one item (movie). These rules are collected in a matrix, <code class="literal">ass_matrix</code>&#13;
 , in which each entry <span class="emphasis">&#13;
<em>ass_matrixij</em>&#13;
</span>&#13;
 represents the confidence of the rule <span class="emphasis">&#13;
<em>i =&gt;j</em>&#13;
</span>&#13;
 . The recommendations for the given user are obtained by simply multiplying the <code class="literal">ass_matrix</code>&#13;
 by his ratings <code class="literal">u_vec</code>&#13;
 : <span class="inlinemediaobject"><img src="Image00506.jpg" alt="Association rules for learning recommendation system"/>&#13;
</span>&#13;
 , and sorting all the values <span class="inlinemediaobject"><img src="Image00507.jpg" alt="Association rules for learning recommendation system"/>&#13;
</span>&#13;
 by the largest value corresponding to the most recommended movie to the least. Therefore, this method does not predict the ratings, but the list of movie recommendations; however, it is fast and it also works well with a sparse utility matrix. Note that to find all the possible combinations of items to form sets X and Y as fast as possible, two algorithms have been developed in the literature: <span class="emphasis">&#13;
<em>apriori</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>fp-growth</em>&#13;
</span>&#13;
 (not discussed here since we only require rules with one item per set <span class="emphasis">&#13;
<em>X</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>Y</em>&#13;
</span>&#13;
 ).</p>&#13;
<p>The class that implements the method is as follows:</p>&#13;
<div class="mediaobject"><img src="Image00508.jpg" alt="Association rules for learning recommendation system"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The class constructor takes as input parameters the utility matrix <code class="literal">Umatrix</code>&#13;
 , the movie titles <a id="id466" class="indexterm"/>&#13;
 list <code class="literal">Movieslist</code>&#13;
 , the support <code class="literal">min_support</code>&#13;
 , confidence <code class="literal">min_confidence</code>&#13;
 thresholds (default <code class="literal">0.1</code>&#13;
 ), and the <code class="literal">likethreshold</code>&#13;
 , which is the minimum rating value to consider a movie in a transaction (default <code class="literal">3</code>&#13;
 ). The function <code class="literal">combine_lists</code>&#13;
 finds all the possible rules, while <code class="literal">filterSet</code>&#13;
 just reduces the rules to the subset that satisfies the minimum support threshold. <code class="literal">calc_confidence_matrix</code>&#13;
 fills the <code class="literal">ass_matrix</code>&#13;
 with the confidence value that satisfies the minimum threshold (otherwise <code class="literal">0</code>&#13;
 is set by default) and <code class="literal">GetRecItems</code>&#13;
 returns the list of recommended movies given the user ratings <code class="literal">u_vec</code>&#13;
 .</p>&#13;
</div>&#13;

<div class="section" title="Log-likelihood ratios recommendation system method">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05lvl1sec35"/>&#13;
 Log-likelihood ratios recommendation system method</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>The <span class="strong">&#13;
<strong>log-likelihood ratio</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>LLR</strong>&#13;
</span>&#13;
 ) is a measure of how two events <span class="emphasis">&#13;
<em>A</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>B</em>&#13;
</span>&#13;
 are unlikely to be <a id="id467" class="indexterm"/>&#13;
 independent but occur together <a id="id468" class="indexterm"/>&#13;
 more than by chance (more than the single event frequency). In other words, the LLR indicates where a significant co-occurrence might exist between two events <span class="emphasis">&#13;
<em>A</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>B</em>&#13;
</span>&#13;
 with a frequency higher than a normal distribution (over the two events variables) would predict.</p>&#13;
<p>It has been shown by Ted Dunning (<a class="ulink" href="http://tdunning.blogspot.it/2008/03/surprise-and-coincidence.html">http://tdunning.blogspot.it/2008/03/surprise-and-coincidence.html</a>&#13;
 ) that the LLR can be expressed based on binomial distributions for events A and B using a matrix <span class="emphasis">&#13;
<em>k</em>&#13;
</span>&#13;
 with the following entries:</p>&#13;
<div class="informaltable">&#13;
<table border="1">&#13;
<colgroup><col/>&#13;
<col/>&#13;
<col/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th valign="bottom"> </th>&#13;
<th valign="bottom">&#13;
<p>A</p>&#13;
</th>&#13;
<th valign="bottom">&#13;
<p>Not A</p>&#13;
</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="strong">&#13;
<strong>B</strong>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="emphasis">&#13;
<em>k11</em>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="emphasis">&#13;
<em>k12</em>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="strong">&#13;
<strong>Not B</strong>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="emphasis">&#13;
<em>k21</em>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="emphasis">&#13;
<em>k22</em>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div>&#13;
<div class="mediaobject"><img src="Image00509.jpg" alt="Log-likelihood ratios recommendation system method"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, <span class="inlinemediaobject"><img src="Image00510.jpg" alt="Log-likelihood ratios recommendation system method"/>&#13;
</span>&#13;
 and <span class="inlinemediaobject"><img src="Image00511.jpg" alt="Log-likelihood ratios recommendation system method"/>&#13;
</span>&#13;
 is the <span class="strong">&#13;
<strong>Shannon</strong>&#13;
</span>&#13;
 entropy that measures the information contained in the vector <span class="emphasis">&#13;
<em>p</em>&#13;
</span>&#13;
 .</p>&#13;
<p>Note: <span class="inlinemediaobject"><img src="Image00512.jpg" alt="Log-likelihood ratios recommendation system method"/>&#13;
</span>&#13;
 is also called <a id="id469" class="indexterm"/>&#13;
 the <span class="strong">&#13;
<strong>Mutual Information</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>MI</strong>&#13;
</span>&#13;
 ) of the <a id="id470" class="indexterm"/>&#13;
 two event variables <span class="emphasis">&#13;
<em>A</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>B</em>&#13;
</span>&#13;
 , measuring how the occurrence of the two events depend on each other.</p>&#13;
<p>This test is also called <span class="emphasis">&#13;
<em>G2</em>&#13;
</span>&#13;
 , and it has been proven effective to detect co-occurrence of rare events (especially in text analysis), so it's useful with sparse databases (or a utility matrix, in our case).</p>&#13;
<p>In our case, the events <span class="emphasis">&#13;
<em>A</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>B</em>&#13;
</span>&#13;
 are the like or dislike of two movies <span class="emphasis">&#13;
<em>A</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>B</em>&#13;
</span>&#13;
 by a user, where the event of <span class="emphasis">&#13;
<em>like a movie</em>&#13;
</span>&#13;
 is defined when the rating is greater than <code class="literal">3</code>&#13;
 (and vice versa for dislike). Therefore, the implementation of the algorithm is given by the following class:</p>&#13;
<div class="mediaobject"><img src="Image00513.jpg" alt="Log-likelihood ratios recommendation system method"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The constructor takes as input the utility matrix, the movie titles list, and the <code class="literal">likethreshold</code>&#13;
 that <a id="id471" class="indexterm"/>&#13;
 is used to define if a user likes a movie or not (default <code class="literal">3</code>&#13;
 ). The function <code class="literal">loglikelihood_ratio</code>&#13;
 generates the matrix with all the LLR values for each pair of movies <span class="emphasis">&#13;
<em>i</em>&#13;
</span>&#13;
 and <span class="emphasis">&#13;
<em>j</em>&#13;
</span>&#13;
 calculating the matrix <span class="emphasis">&#13;
<em>k</em>&#13;
</span>&#13;
 (<code class="literal">calc_k</code>&#13;
 ) and the corresponding LLR (<code class="literal">calc_llr</code>&#13;
 ). The function <code class="literal">GetRecItems</code>&#13;
 returns the recommended movie list for the user with ratings given by <code class="literal">u_vec</code>&#13;
 (the method does not predict the rating values).</p>&#13;
</div>&#13;

<div class="section" title="Hybrid recommendation systems">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05lvl1sec36"/>&#13;
 Hybrid recommendation systems</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This is a <a id="id472" class="indexterm"/>&#13;
 class of methods that combine both CBF and CF in a single recommender to achieve better results. Several approaches have been tried and can be summarized in the following categories:</p>&#13;
<div class="itemizedlist">&#13;
<ul class="itemizedlist">&#13;
<li class="listitem">&#13;
<span class="strong">&#13;
<strong>Weighted</strong>&#13;
</span>&#13;
 : The <a id="id473" class="indexterm"/>&#13;
 CBF and CF predicted ratings are combined in to some weighted mean.</li>&#13;
<li class="listitem">&#13;
<span class="strong">&#13;
<strong>Mixed</strong>&#13;
</span>&#13;
 : CF <a id="id474" class="indexterm"/>&#13;
 and CBF predicted movies are found separately and then merged in to a single list.</li>&#13;
<li class="listitem">&#13;
<span class="strong">&#13;
<strong>Switched</strong>&#13;
</span>&#13;
 : Based <a id="id475" class="indexterm"/>&#13;
 on certain criteria, the CF predictions or CBF predictions are used.</li>&#13;
<li class="listitem">&#13;
<span class="strong">&#13;
<strong>Feature combination</strong>&#13;
</span>&#13;
 : CF <a id="id476" class="indexterm"/>&#13;
 and CBF features are considered together to find the most similar users or items.</li>&#13;
<li class="listitem">&#13;
<span class="strong">&#13;
<strong>Feature augmentation</strong>&#13;
</span>&#13;
 : Similar <a id="id477" class="indexterm"/>&#13;
 to feature combination, but the additional features are used to predict some ratings and then the main recommender uses these ratings to produce the recommendation list. For example, Content-Boosted Collaborative Filtering learns the ratings of unrated movies by a content-based model and then a collaborative approach is employed to define the recommendations.</li>&#13;
</ul>&#13;
</div>&#13;
<p>As an example, we implement two hybrid feature combination methods merging an item's features CBF method with a user-based CF method. The first method employs a user-based CF to the expanded utility matrix that now also contains the average rating per genre per user. The Python class is as follows:</p>&#13;
<div class="mediaobject"><img src="Image00514.jpg" alt="Hybrid recommendation systems"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<div class="mediaobject"><img src="Image00515.jpg" alt="Hybrid recommendation systems"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The constructor generates the expanded utility matrix with the movies' genres average rating <a id="id478" class="indexterm"/>&#13;
 features associated to each user, <code class="literal">Umatrix_mfeats</code>&#13;
 . The function <code class="literal">CalcRatings</code>&#13;
 finds the K-NN using the Pearson correlation comparing the expanded feature vectors of the users. The second method applies and SVD factorization to the expanded utility matrix that contains the genre preferences for each user.</p>&#13;
<div class="mediaobject"><img src="Image00516.jpg" alt="Hybrid recommendation systems"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>As <a id="id479" class="indexterm"/>&#13;
 the SVD method, the ratings are subtracted with the user rating's average, and genre preferences are subtracted from the same user rating's average.</p>&#13;
</div>&#13;

<div class="section" title="Evaluation of the recommendation systems">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05lvl1sec37"/>&#13;
 Evaluation of the recommendation systems</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>We have <a id="id480" class="indexterm"/>&#13;
 discussed all of the most relevant methods used in the commercial environment to date. The evaluation of a recommendation system can be executed offline (using only the data in the utility matrix) or online (using the utility matrix data and the new data provided in real time by each user using the website). The online evaluation procedures are discussed in <a class="link" title="Chapter 7. Movie Recommendation System Web Application" href="text00050.html#page">Chapter 7</a>&#13;
 , <span class="emphasis">&#13;
<em>Movie Recommendation System Web Application</em>&#13;
</span>&#13;
 , together with a proper online movie recommendation system website. In this section, we will evaluate the performances of the methods using two offline tests often used to evaluate recommendation systems: root mean square error on ratings and ranking accuracy. For all the evaluations in which k-fold cross-validation (see <a class="link" title="Chapter 3. Supervised Machine Learning" href="text00024.html#page">Chapter 3</a>&#13;
 , <span class="emphasis">&#13;
<em>Supervised Machine Learning</em>&#13;
</span>&#13;
 ) is applicable, a 5-fold cross-validation has been performed to obtain more objective results. The utility matrix has been divided in to 5 folds using the following function:</p>&#13;
<div class="mediaobject"><img src="Image00517.jpg" alt="Evaluation of the recommendation systems"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here <code class="literal">df</code>&#13;
 is <a id="id481" class="indexterm"/>&#13;
 a data frame object that stores the utility matrix and <span class="emphasis">&#13;
<em>k</em>&#13;
</span>&#13;
 is the number of folds. In the validation set, for each user ratings' vector <code class="literal">u_vec</code>&#13;
 , half of the ratings have been hidden so that the real value can be predicted.</p>&#13;
<div class="mediaobject"><img src="Image00518.jpg" alt="Evaluation of the recommendation systems"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>&#13;
<code class="literal">u_vals</code>&#13;
 stores the values to predict while <code class="literal">u_test</code>&#13;
 contains the ratings for testing the algorithms. Before we start to compare the different algorithms with the different measures, we load the utility matrix and the movie content matrix into data frames and split the data into 5 folds for cross-validation.</p>&#13;
<div class="mediaobject"><img src="Image00519.jpg" alt="Evaluation of the recommendation systems"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>&#13;
<code class="literal">df_vals</code>&#13;
 contains the validation sets so the <code class="literal">HideRandomRatings</code>&#13;
 function presented in this section needs to be applied.</p>&#13;
<div class="mediaobject"><img src="Image00520.jpg" alt="Evaluation of the recommendation systems"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The <a id="id482" class="indexterm"/>&#13;
 data available in the <code class="literal">movies</code>&#13;
 matrix, the <code class="literal">movieslist</code>&#13;
 list, and the data frames <code class="literal">df_trains</code>&#13;
 , <code class="literal">vals_vecs_folds</code>&#13;
 , <code class="literal">tests_vecs_folds</code>&#13;
 are now ready to be used for training and validating all the methods discussed in the previous sections. We can start evaluating the <span class="strong">&#13;
<strong>root mean square error</strong>&#13;
</span>&#13;
 (<span class="strong">&#13;
<strong>RMSE</strong>&#13;
</span>&#13;
 ).</p>&#13;
<div class="section" title="Root mean square error (RMSE) evaluation">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h2 class="title"><a id="ch05lvl2sec36"/>&#13;
 Root mean square error (RMSE) evaluation</h2>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>This <a id="id483" class="indexterm"/>&#13;
 validation technique is applicable only on CF methods and linear regression CBF since the predicted ratings are generated only by these algorithms. Given each rating <span class="emphasis">&#13;
<em>rij</em>&#13;
</span>&#13;
 in <code class="literal">u_vals</code>&#13;
 in the validation sets, the predicted rating <span class="inlinemediaobject"><img src="Image00521.jpg" alt="Root mean square error (RMSE) evaluation"/>&#13;
</span>&#13;
 is calculated using each method and the root mean square error is obtained:</p>&#13;
<p>RMSE = <span class="inlinemediaobject"><img src="Image00522.jpg" alt="Root mean square error (RMSE) evaluation"/>&#13;
</span>&#13;
</p>&#13;
<p>Here, <span class="emphasis">&#13;
<em>Nval</em>&#13;
</span>&#13;
 is the number of ratings in the <code class="literal">u_vals</code>&#13;
 vectors. The presence of the square factor in this formula highly penalizes the large errors, so the methods with low RMSE (best values) are characterized by small errors spread over all the predicted ratings instead of large errors on few ratings, like the mean absolute error MAE=<span class="inlinemediaobject"><img src="Image00523.jpg" alt="Root mean square error (RMSE) evaluation"/>&#13;
</span>&#13;
 would prefer.</p>&#13;
<p>The code <a id="id484" class="indexterm"/>&#13;
 to calculate the RMSE for the memory-based CF user-based and item-based methods is as follows:</p>&#13;
<div class="mediaobject"><img src="Image00524.jpg" alt="Root mean square error (RMSE) evaluation"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<div class="mediaobject"><img src="Image00525.jpg" alt="Root mean square error (RMSE) evaluation"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>For each <a id="id485" class="indexterm"/>&#13;
 method, the SE function is called to compute the error for each fold and then the total RMSE of the folds is obtained.</p>&#13;
<p>Using 5 nearest-neighbors for item-based CF with slope one and 20 for user-based CF, the methods have the following errors:</p>&#13;
<div class="informaltable">&#13;
<table border="1">&#13;
<colgroup><col/>&#13;
<col/>&#13;
<col/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th valign="bottom">&#13;
<p>Method</p>&#13;
</th>&#13;
<th valign="bottom">&#13;
<p>RMSE</p>&#13;
</th>&#13;
<th valign="bottom">&#13;
<p>Number of Predicted Ratings</p>&#13;
</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="strong">&#13;
<strong>CF user-based</strong>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>1.01</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="strong">&#13;
<strong>CF item-based</strong>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>1.03</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="strong">&#13;
<strong>Slope one</strong>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>1.08</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>&#13;
<span class="strong">&#13;
<strong>CF-CBF user-based</strong>&#13;
</span>&#13;
</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>1.01</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div>&#13;
<p>All have similar RMSE values but the best method is item-based Collaborative Filtering.</p>&#13;
<p>For the <a id="id486" class="indexterm"/>&#13;
 model-based methods, instead of not hidden validation ratings, <code class="literal">u_test</code>&#13;
 are included in the utility matrix for training and then the RMSE is calculated using the following script:</p>&#13;
<div class="mediaobject"><img src="Image00526.jpg" alt="Root mean square error (RMSE) evaluation"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>The code calculates the RMSE only for CBF regression and SVD, and the reader can easily <a id="id487" class="indexterm"/>&#13;
 replicate the code to calculate the error for the other algorithms since most of the required code is just commented (SVD expect-maximization, SGD, ALS, and NMF). The results are shown in the following table (<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 dimension feature space):</p>&#13;
<div class="informaltable">&#13;
<table border="1">&#13;
<colgroup><col/>&#13;
<col/>&#13;
<col/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th valign="bottom">&#13;
<p>Method</p>&#13;
</th>&#13;
<th valign="bottom">&#13;
<p>RMSE</p>&#13;
</th>&#13;
<th valign="bottom">&#13;
<p>Number Predicted Ratings</p>&#13;
</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>CBF linear regression</p>&#13;
<p>(a= 0.01, l =0.0001, its=50)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>1.09</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>SGD ( K=20, 50 its, a =0.00001, l=0.001)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>1.35</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>ALS ( K=20, 50 its, l =0.001)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>2.58</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>SVD (<code class="literal">imputation</code>&#13;
 =<code class="literal">useraverage</code>&#13;
 , <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 =20)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>1.02</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>SVD EM (<code class="literal">imputation</code>&#13;
 =<code class="literal">itemaverage</code>&#13;
 , iterations=30,<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 =20)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>1.03</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>HYBRID SVD (<code class="literal">imputation</code>&#13;
 =<code class="literal">useraverage</code>&#13;
 , <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 =20)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>1.01</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>NMF (<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 =20 <code class="literal">imputation</code>&#13;
 =<code class="literal">useraverage</code>&#13;
 )</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.97</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,972</p>&#13;
</td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div>&#13;
<p>As expected, the ALS and SGD are the worst methods but they are discussed because they are instructive from a didactic point of view (they are also slow because the implementation is not as optimized as the methods from <code class="literal">sklearn</code>&#13;
 library).</p>&#13;
<p>All the others have similar results. However, just note that the hybrid methods have slightly better results than the corresponding SVD and CF user-based algorithms. Note that the movies to predict are chosen randomly so the results may vary.</p>&#13;
</div>&#13;
<div class="section" title="Classification metrics">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h2 class="title"><a id="ch05lvl2sec37"/>&#13;
 Classification metrics</h2>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>The rating <a id="id488" class="indexterm"/>&#13;
 error RMSE does not really indicate the quality of a method but is an academic measure that is not really used in a commercial environment. The goal of a website is to present content that is relevant to the user regardless of the exact rating the user gives. In order to evaluate the relevance of the recommended items, the <code class="literal">precision</code>&#13;
 , <code class="literal">recall</code>&#13;
 , and <code class="literal">f1</code>&#13;
 (see <a class="link" title="Chapter 2. Unsupervised Machine Learning" href="text00020.html#ch02">Chapter 2</a>&#13;
 , <span class="emphasis">&#13;
<em>Unsupervised Machine Learning</em>&#13;
</span>&#13;
 ) measures are used where the correct predictions are the items with ratings greater than 3. These measures are calculated on the first 50 items returned by each algorithm (if the algorithm return a recommended list or the 50 items with the highest predicted ratings for the other methods). The function that calculates the measures is as follows:</p>&#13;
<div class="mediaobject"><img src="Image00527.jpg" alt="Classification metrics"/>&#13;
</div>&#13;
<p style="clear:both; height: 1em;"/>&#13;
<p>Here, Boolean <code class="literal">ratingsval</code>&#13;
 indicates if the method returns ratings or recommended list. We use the function <code class="literal">ClassificationMetrics</code>&#13;
 in the same way we compute the RMSE for all the methods, so the actual code to evaluate the measures is not shown (you can write it as an exercise). The following table summarizes the results for all the methods (<span class="emphasis">&#13;
<em>neighs</em>&#13;
</span>&#13;
 is number of nearest-neighbors, <span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 dimension feature space):</p>&#13;
<div class="informaltable">&#13;
<table border="1">&#13;
<colgroup><col/>&#13;
<col/>&#13;
<col/>&#13;
<col/>&#13;
<col/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th valign="bottom">&#13;
<p>Method</p>&#13;
</th>&#13;
<th valign="bottom">&#13;
<p>Precision</p>&#13;
</th>&#13;
<th valign="bottom">&#13;
<p>Recall</p>&#13;
</th>&#13;
<th valign="bottom">&#13;
<p>f1</p>&#13;
</th>&#13;
<th valign="bottom">&#13;
<p>Number of Predicted Ratings</p>&#13;
</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>CF user-based (<span class="emphasis">&#13;
<em>neighs</em>&#13;
</span>&#13;
 =20)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.6</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.18</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.26</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>CBFCF user-based (<span class="emphasis">&#13;
<em>neighs</em>&#13;
</span>&#13;
 =20)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.6</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.18</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.26</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>HYBRID SVD (<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 =20, <code class="literal">imputation</code>&#13;
 =<code class="literal">useraverage</code>&#13;
 )</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.54</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.12</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.18</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>CF item-based (<span class="emphasis">&#13;
<em>neighs</em>&#13;
</span>&#13;
 =5)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.57</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.15</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.22</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>Slope one (<span class="emphasis">&#13;
<em>neighs</em>&#13;
</span>&#13;
 =5)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.57</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.17</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.24</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>SVD EM (<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 =20, iterations=30, <code class="literal">imputation</code>&#13;
 =<code class="literal">useraverage</code>&#13;
 )</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.58</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.16</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.24</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>SVD (<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 =20, <code class="literal">imputation</code>&#13;
 =<code class="literal">itemaverage</code>&#13;
 )</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.53</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.12</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.18</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>CBF regression (a = 0.01, l =0.0001, iterations=50)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.54</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.13</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.2</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>SGD (K=20, a =0.00001, l =0.001)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.52</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.12</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.18</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>ALS (<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 =20, λ =0.001, iterations=50)</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.57</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.15</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.23</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>CBF average</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.56</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.12</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.19</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>LLR</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.63</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.3</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.39</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>NMF (<span class="emphasis">&#13;
<em>K</em>&#13;
</span>&#13;
 =20, λ =0.001, <code class="literal">imputation</code>&#13;
 =<code class="literal">ssss</code>&#13;
 )</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.53</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.13</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.19</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td valign="top">&#13;
<p>Association rules</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.68</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.31</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>0.4</p>&#13;
</td>&#13;
<td valign="top">&#13;
<p>39,786</p>&#13;
</td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div>&#13;
<p>From <a id="id489" class="indexterm"/>&#13;
 the results you can see that the best method is association rules, and there is good precision also for the LLR, hybrid CBFCF user-based, and CF user-based methods. Note that the results may vary since the movies to predict have been randomly chosen.</p>&#13;
</div>&#13;
</div>&#13;

<div class="section" title="Summary">&#13;
<div class="titlepage">&#13;
<div>&#13;
<div>&#13;
<h1 class="title"><a id="ch05lvl1sec38"/>&#13;
 Summary</h1>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
<p>In this chapter, we discussed the most commonly used recommendation system methods from Collaborative Filtering and content-based filtering to two simple hybrid algorithms. Note also that in the literature are present <span class="emphasis">&#13;
<em>modal</em>&#13;
</span>&#13;
 recommendation systems in which different data (user gender, demographics, views, locations, devices, and so on) are incorporated in to the same algorithm. These methods are more advanced and more different data is needed to use them.</p>&#13;
<p>In <a class="link" title="Chapter 7. Movie Recommendation System Web Application" href="text00050.html#page">Chapter 7</a>&#13;
 , <span class="emphasis">&#13;
<em>Movie Recommendation System Web Application</em>&#13;
</span>&#13;
 , we will implement a web recommendation system using the methods discussed in this chapter, but before that we will present the Django framework to build web applications in <a class="link" title="Chapter 6. Getting Started with Django" href="text00046.html#ch06">Chapter 6</a>&#13;
 , <span class="emphasis">&#13;
<em>Getting Started with Django</em>&#13;
</span>&#13;
 .</p>&#13;
</div>&#13;

<h1>读累了记得休息一会哦~</h1>
<p> </p>
<p><strong>公众号：古德猫宁李</strong></p>
<ul>
<li>电子书搜索下载</li>
<li>书单分享</li>
<li>书友学习交流</li>

<p> </p>
</ul>
<p><strong>网站：</strong><a href="https://www.chenjin5.com">沉金书屋 https://www.chenjin5.com</a></p>
<ul>
<li>电子书搜索下载</li>
<li>电子书打包资源分享</li>
<li>学习资源分享</li>

</ul>
</body></html>