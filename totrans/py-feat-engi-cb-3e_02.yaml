- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Encoding Categorical Variables
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对分类变量进行编码
- en: '`Home owner` variable with the values of `owner` and `non-owner` is categorical,
    and so is the `Marital status` variable with the values of `never married`, `married`,
    `divorced`, and `widowed`. In some categorical variables, the labels have an intrinsic
    order; for example, in the `Student''s grade` variable, the values of `A`, `B`,
    `C`, and `Fail` are ordered, with `A` being the highest grade and `Fail` being
    the lowest. These are called `City` variable, with the values of `London`, `Manchester`,
    `Bristol`, and so on.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '`Home owner`变量具有`owner`和`non-owner`的值，是分类变量，同样`Marital status`变量具有`never married`、`married`、`divorced`和`widowed`的值，也是分类变量。在一些分类变量中，标签具有内在顺序；例如，在`Student''s
    grade`变量中，`A`、`B`、`C`和`Fail`的值是有序的，其中`A`是最高等级，`Fail`是最低等级。这些被称为`City`变量，具有`London`、`Manchester`、`Bristol`等值。'
- en: The values of categorical variables are often encoded as strings. To train most
    machine learning models, we need to transform those strings into numbers. The
    act of replacing strings with numbers is called **categorical encoding**. In this
    chapter, we will discuss multiple categorical encoding methods.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 分类变量的值通常编码为字符串。为了训练大多数机器学习模型，我们需要将这些字符串转换为数字。用数字替换字符串的行为称为**分类编码**。在本章中，我们将讨论多种分类编码方法。
- en: 'This chapter will cover the following recipes:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下食谱：
- en: Creating binary variables through one-hot encoding
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过单热编码创建二进制变量
- en: Performing one-hot encoding of frequent categories
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对频繁类别执行单热编码
- en: Replacing categories with counts or the frequency of observations
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将类别替换为计数或观察频率
- en: Replacing categories with ordinal numbers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将类别替换为序数
- en: Performing ordinal encoding based on the target value
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于目标值进行序数编码
- en: Implementing target mean encoding
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现目标均值编码
- en: Encoding with the Weight of Evidence
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用证据权重进行编码
- en: Grouping rare or infrequent categories
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对稀有或罕见类别进行分组
- en: Performing binary encoding
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行二进制编码
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will use the `Matplotlib`, `pandas`, `NumPy`, `scikit-learn`,
    `feature-engine`, and Category Encoders Python libraries. If you need to install
    Python, the free Anaconda Python distribution ([https://www.anaconda.com/](https://www.anaconda.com/))
    includes most numerical computing libraries.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用`Matplotlib`、`pandas`、`NumPy`、`scikit-learn`、`feature-engine`和Category
    Encoders Python库。如果您需要安装Python，免费的Anaconda Python发行版（[https://www.anaconda.com/](https://www.anaconda.com/））包括大多数数值计算库。
- en: '`feature-engine` can be installed with `pip`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`pip`安装`feature-engine`：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you use Anaconda, you can install `feature-engine` with `conda`:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用Anaconda，可以使用`conda`安装`feature-engine`：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To install Category Encoders, use `pip` as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装Category Encoders，请使用以下`pip`命令：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will use the **Credit Approval** dataset from the *UCI Machine Learning
    Repository* ([https://archive.ics.uci.edu/](https://archive.ics.uci.edu/)), licensed
    under the CC BY 4.0 creative commons attribution: [https://creativecommons.org/licenses/by/4.0/legalcode](https://creativecommons.org/licenses/by/4.0/legalcode).
    You’ll find the dataset at this link: [http://archive.ics.uci.edu/dataset/27/credit+approval](http://archive.ics.uci.edu/dataset/27/credit+approval).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用来自*UCI机器学习仓库*的**Credit Approval**数据集（[https://archive.ics.uci.edu/](https://archive.ics.uci.edu/)），该数据集根据CC
    BY 4.0创意共享许可：[https://creativecommons.org/licenses/by/4.0/legalcode](https://creativecommons.org/licenses/by/4.0/legalcode)。您可以在以下链接找到数据集：[http://archive.ics.uci.edu/dataset/27/credit+approval](http://archive.ics.uci.edu/dataset/27/credit+approval)。
- en: 'I downloaded and modified the data as shown in this notebook: [https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/credit-approval-dataset.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/credit-approval-dataset.ipynb).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我已下载并修改了如本笔记本所示的数据：[https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/credit-approval-dataset.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/credit-approval-dataset.ipynb)。
- en: 'You’ll find a copy of the modified data set in the accompanying GitHub repository:
    [https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在附带的GitHub仓库中找到修改后的数据集副本：[https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/)。
- en: Note
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Before encoding categorical variables, you might want to impute their missing
    data. Check out the imputation methods for categorical variables in [*Chapter
    1*](B22396_01.xhtml#_idTextAnchor020), *Imputing* *Missing Data*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在对分类变量进行编码之前，你可能想要填充它们的缺失数据。查看[*第1章*](B22396_01.xhtml#_idTextAnchor020)，*填充*
    *缺失数据*的方法。
- en: Creating binary variables through one-hot encoding
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过单热编码创建二进制变量
- en: '`1` if the category is present, or `0` otherwise.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果类别存在，则为`1`，否则为`0`。
- en: 'The following table shows the one-hot encoded representation of the `Smoker`
    variable with the categories of `Smoker` and `Non-Smoker`:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了`Smoker`变量的单热编码表示，其中包含`Smoker`和`Non-Smoker`类别：
- en: '![Figure 2.1 – One-hot encoded representation of the Smoker variable](img/B22396_02_01.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1 – Smoker变量的单热编码表示](img/B22396_02_01.jpg)'
- en: Figure 2.1 – One-hot encoded representation of the Smoker variable
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – Smoker变量的单热编码表示
- en: As shown in *Figure 2**.1*, from the `Smoker` variable, we can derive a binary
    variable for `Smoker`, which shows the value of `1` for smokers, or the binary
    variable for `Non-Smoker`, which takes the value of `1` for those who do not smoke.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图2**.1所示，从`Smoker`变量中，我们可以推导出一个二进制变量`Smoker`，对于吸烟者显示值为`1`，或者推导出一个`Non-Smoker`的二进制变量，对于不吸烟者显示值为`1`。
- en: For the `Color` categorical variable with the values of `red`, `blue`, and `green`,
    we can create three variables called `red`, `blue`, and `green`. These variables
    will be assigned a value of `1` if the observation corresponds to the respective
    color, and `0` if it does not.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有`red`，`blue`和`green`值的`Color`分类变量，我们可以创建三个变量，分别称为`red`，`blue`和`green`。如果观察结果对应相应的颜色，这些变量将被分配值为`1`，如果不对应，则为`0`。
- en: 'A categorical variable with *k* unique categories can be encoded using *k-1*
    binary variables. For `Smoker`, *k* is *2* as it contains two labels (`Smoker`
    and `Non-Smoker`), so we only need one binary variable (*k - 1 = 1*) to capture
    all the information. For the `Color` variable, which has 3 categories (*k = 3*;
    `red`, `blue`, and `green`), we need 2 (*k - 1 = 2*) binary variables to capture
    all the information so that the following occurs:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一个具有*k*个唯一类别的分类变量可以使用*k-1*个二进制变量进行编码。对于`Smoker`变量，*k*是*2*，因为它包含两个标签（`Smoker`和`Non-Smoker`），所以我们只需要一个二进制变量（*k
    - 1 = 1*）来捕捉所有信息。对于`Color`变量，它有3个类别（*k = 3*；`red`，`blue`和`green`），我们需要2个（*k -
    1 = 2*）二进制变量来捕捉所有信息，以便以下发生：
- en: If the observation is red, it will be captured by the `red` variable (`red`
    = `1`, `blue` = `0`)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果观察结果是红色，它将被`red`变量捕获（`red` = `1`，`blue` = `0`）
- en: If the observation is blue, it will be captured by the `blue` variable (`red`
    = `0`, `blue` = `1`)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果观察结果是蓝色，它将被`blue`变量捕获（`red` = `0`，`blue` = `1`）
- en: If the observation is green, it will be captured by the combination of `red`
    and `blue` (`red` = `0`, `blue` = `0`)
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果观察结果是绿色，它将被`red`和`blue`的组合捕获（`red` = `0`，`blue` = `0`）
- en: 'Encoding into *k-1* binary variables is well suited for linear models. There
    are a few occasions in which we may prefer to encode the categorical variables
    with *k* binary variables:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将编码到*k-1*个二进制变量非常适合线性模型。在某些情况下，我们可能更喜欢使用*k*个二进制变量对分类变量进行编码：
- en: When training decision trees, since they do not evaluate the entire feature
    space at the same time
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练决策树时，因为它们不会同时评估整个特征空间
- en: When selecting features recursively
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在递归选择特征时
- en: When determining the importance of each category within a variable
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在确定变量中每个类别的相对重要性时
- en: In this recipe, we will compare the one-hot encoding implementations of `pandas`,
    `scikit-learn`, and `feature-engine`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将比较`pandas`，`scikit-learn`和`feature-engine`的单热编码实现。
- en: How to do it...
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'First, let’s make a few imports and get the data ready:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们进行一些导入并准备好数据：
- en: 'Import `pandas` and the `train_test_split` function from `scikit-learn`:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`scikit-learn`导入`pandas`和`train_test_split`函数：
- en: '[PRE3]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let’s load the Credit Approval dataset:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载Credit Approval数据集：
- en: '[PRE4]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s separate the data into train and test sets:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将数据分为训练集和测试集：
- en: '[PRE5]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s inspect the unique categories of the `A4` variable:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查`A4`变量的唯一类别：
- en: '[PRE6]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can see the unique values of `A4` in the following output:'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以在以下输出中看到`A4`的独特值：
- en: '[PRE7]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: dummies = pd.get_dummies(
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: dummies = pd.get_dummies(
- en: X_train["A4"], drop_first=True)
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_train["A4"], drop_first=True)
- en: dummies.head()
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: dummies.head()
- en: '[PRE8]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: With `pandas`’ `get_dummies()`, we can either ignore or encode missing data
    through the `dummy_na` parameter. By setting `dummy_na=True`, missing data will
    be encoded in a new binary variable. To encode the variable into *k* dummies,
    use `drop_first=False` instead.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pandas`的`get_dummies()`，我们可以通过`dummy_na`参数忽略或编码缺失数据。通过将`dummy_na=True`设置，缺失数据将编码在一个新的二进制变量中。要将变量编码为*k*个虚拟变量，请使用`drop_first=False`。
- en: 'Here, we can see the output of *Step 5*, where each label is now a binary variable:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们可以看到*步骤5*的输出，其中每个标签现在都是一个二进制变量：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, let’s encode all the categorical variables into *k-1* binaries:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将所有分类变量编码为*k-1*个二进制变量：
- en: '[PRE10]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: '`pandas`’ `get_dummies()`will encode all variables of the object, string, or
    category type by default. To encode a subset of the variables, pass the variable
    names in a list to the `columns` parameter.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`的`get_dummies()`默认情况下将对象、字符串或类别类型的所有变量编码。要编码变量子集，请将变量名列表传递给`columns`参数。'
- en: 'Let’s inspect the first five rows of the resulting DataFrame:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查结果DataFrame的前五行：
- en: '[PRE11]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: When encoding more than one variable, `get_dummies()` captures the variable
    name – say, `A1` – and places an underscore followed by the category name to identify
    the resulting binary variables.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当编码多个变量时，`get_dummies()`捕获变量名 – 比如，`A1` – 并在类别名前放置一个下划线来标识结果二进制变量。
- en: 'We can see the binary variables in the following output:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下输出中看到二进制变量：
- en: '![Figure 2.2 – A transformed DataFrame showing the numerical variables followed
    by the one-hot encoded representation of the categorical variables](img/B22396_02_02.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 – 一个转换后的DataFrame，显示了数值变量随后是分类变量的独热编码表示](img/B22396_02_02.jpg)'
- en: Figure 2.2 – A transformed DataFrame showing the numerical variables followed
    by the one-hot encoded representation of the categorical variables
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 一个转换后的DataFrame，显示了数值变量随后是分类变量的独热编码表示
- en: Note
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: '`pandas`’ `get_dummies()`will create one binary variable per category seen
    in a DataFrame. Hence, if there are more categories in the train set than in the
    test set, `get_dummies()` will return more columns in the transformed train set
    than in the transformed test set, and vice versa. To avoid this, it is better
    to carry out one-hot encoding with `scikit-learn` or `feature-engine`.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`的`get_dummies()`将为DataFrame中看到的每个类别创建一个二进制变量。因此，如果训练集中的类别比测试集中的多，`get_dummies()`将在转换后的训练集中返回比测试集更多的列，反之亦然。为了避免这种情况，最好使用`scikit-learn`或`feature-engine`进行独热编码。'
- en: Let’s do one-hot encoding using `scikit-learn` instead.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`scikit-learn`进行独热编码。
- en: 'Let’s import the encoder and `ColumnTransformer` from `scikit-learn`:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入`scikit-learn`中的编码器和`ColumnTransformer`：
- en: '[PRE12]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let’s create a list with the names of the categorical variables:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个包含分类变量名的列表：
- en: '[PRE13]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let’s set up the encoder to create *k-1* binary variables:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置编码器以创建*k-1*个二进制变量：
- en: '[PRE14]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: To encode variables into *k* dummies, set the `drop` parameter to `None`. To
    encode only binary variables into *k-1*, set the `drop` parameter to `if_binary`.
    The latter is useful because encoding binary variables into *k* dummies is redundant.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要将变量编码为*k*个虚拟变量，将`drop`参数设置为`None`。要将仅二进制变量编码为*k-1*，将`drop`参数设置为`if_binary`。后者很有用，因为将二进制变量编码为*k*个虚拟变量是多余的。
- en: 'Let’s restrict the encoding to the categorical variables:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将编码限制在分类变量上：
- en: '[PRE15]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let’s fit the encoder so that it identifies the categories to encode:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们调整编码器，使其能够识别要编码的类别：
- en: '[PRE16]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let’s inspect the categories that will be represented with binary variables:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查将被二进制变量表示的类别：
- en: '[PRE17]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The transformer will add binary variables for the following categories:'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 变换器将为以下类别添加二进制变量：
- en: '![Figure 2.3 – Arrays with the categories that will be encoded into binary
    variables (one array per variable)](img/B22396_02_03.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图2.3 – 将被编码为二进制变量的类别数组（每个变量一个数组）](img/B22396_02_03.jpg)'
- en: Figure 2.3 – Arrays with the categories that will be encoded into binary variables
    (one array per variable)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – 将被编码为二进制变量的类别数组（每个变量一个数组）
- en: Note
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: '`scikit-learn`’s `OneHotEncoder()` will only encode the categories learned
    from the train set. If there are new categories in the test set, we can instruct
    the encoder to ignore them, return an error, or replace them with an infrequent
    category, by setting the `handle_unknown` parameter to `ignore`, `error`, or `infrequent_if_exists`.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn`的`OneHotEncoder()`只会对从训练集中学习到的类别进行编码。如果测试集中有新的类别，我们可以通过设置`handle_unknown`参数为`ignore`、`error`或`infrequent_if_exists`来指示编码器忽略它们、返回错误或用不常见的类别替换它们。'
- en: 'Let’s encode the categorical variables:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编码分类变量：
- en: '[PRE18]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Make sure to inspect the result by executing `X_test_enc.head()`.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保通过执行`X_test_enc.head()`来检查结果。
- en: 'To get familiar with the output, let’s print the variable names of the resulting
    DataFrame:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了熟悉输出，让我们打印结果DataFrame的变量名称：
- en: '[PRE19]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the following image, we see the names of the variables in the transformed
    DataFrame:'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下图像中，我们可以看到转换后的DataFrame中的变量名称：
- en: '![Figure 2.4 – Arrays with the names of the variables in the resulting DataFrame](img/B22396_02_04.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图2.4 – 结果DataFrame中变量的名称数组](img/B22396_02_04.jpg)'
- en: Figure 2.4 – Arrays with the names of the variables in the resulting DataFrame
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 – 结果DataFrame中变量的名称数组
- en: Note
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`ColumnTransformer()` changes the name and order of the variables during the
    transformation. If the variable was encoded, it will append the `encoder` prefix
    and if the variable was not modified, it will append the `remainder` prefix.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`ColumnTransformer()`在转换过程中会更改变量的名称和顺序。如果变量被编码，它将附加`encoder`前缀；如果变量未被修改，它将附加`remainder`前缀。'
- en: To wrap up the recipe, let’s perform one-hot encoding with `feature-engine`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结这个菜谱，让我们使用`feature-engine`进行one-hot编码。
- en: 'Let’s import the encoder from `f``eature-engine`:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从`f``eature-engine`导入编码器：
- en: '[PRE20]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let’s set up the encoder so that it returns *k-1* binary variables:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置编码器，使其返回*k-1*个二进制变量：
- en: '[PRE21]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`feature-engine`’s `OneHotEncoder()` encodes all categorical variables by default.
    To encode a subset of the variables, pass the variable names in a list: `OneHotEncoder(variables=["A1",
    "A4"]`). To encode numerical variables, set the `ignore_format` parameter to `True`
    or cast the variables as objects.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature-engine`的`OneHotEncoder()`默认编码所有分类变量。要编码变量的子集，请传递变量名称列表：`OneHotEncoder(variables=["A1",
    "A4"])`。要编码数值变量，将`ignore_format`参数设置为`True`或将变量转换为对象类型。'
- en: 'Let’s fit the encoder to the train set so that it learns the categories and
    variables to encode:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将编码器拟合到训练集中，以便它学习要编码的类别和变量：
- en: '[PRE22]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To encode binary variables into *k-1*, and other categorical variables into
    *k* dummies, set the `drop_last_binary` parameter to `True`.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要将二进制变量编码为*k-1*，并将其他分类变量编码为*k*个虚拟变量，将`drop_last_binary`参数设置为`True`。
- en: 'Let’s explore the variables that will be encoded:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们探索将要编码的变量：
- en: '[PRE23]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The transformer found and stored the variables of the object or categorical
    type, as shown in the following output:'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 转换器找到了并存储了对象或分类类型的变量，如下面的输出所示：
- en: '[PRE24]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s explore the categories for which dummy variables will be created:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们探索将创建虚拟变量的类别：
- en: '[PRE25]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following dictionary contains the categories that will be encoded in each
    variable:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下字典包含将编码到每个变量中的类别：
- en: '[PRE26]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let’s encode the categorical variables in train and test sets:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在训练集和测试集中编码分类变量：
- en: '[PRE27]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'If we execute `X_train_enc.head()`, we will see the following DataFrame:'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们执行`X_train_enc.head()`，我们将看到以下DataFrame：
- en: '![Figure 2.5 – Transformed DataFrame with numerical variables followed by the
    one-hot encoded representation of the categorical variables](img/B22396_02_05.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图2.5 – 转换后的DataFrame，其中包含数值变量，后面跟着分类变量的one-hot编码表示](img/B22396_02_05.jpg)'
- en: Figure 2.5 – Transformed DataFrame with numerical variables followed by the
    one-hot encoded representation of the categorical variables
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 – 转换后的DataFrame，其中包含数值变量，后面跟着分类变量的one-hot编码表示
- en: Note how the `A4` categorical variable was replaced with `A4_u`, `A4_y`, and
    so on.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到`A4`分类变量被替换为`A4_u`、`A4_y`等等。
- en: Note
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We can get the names of all the variables in the transformed dataset by executing
    `ohe_enc.get_feature_names_out()`.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行`ohe_enc.get_feature_names_out()`来获取转换数据集中所有变量的名称。
- en: How it works...
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we performed a one-hot encoding of categorical variables using
    `pandas`, `scikit-learn`, and `feature-engine`.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用`pandas`、`scikit-learn`和`feature-engine`对分类变量进行了one-hot编码。
- en: '`pandas`’ `get_dummies()` replaced the categorical variables with a set of
    binary variables representing each of the categories. When used on the entire
    dataset, it returned the numerical variables, followed by the one-hot encoded
    representation of each seen category in every variable of type object, string,
    or categorical.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas` 的 `get_dummies()` 将类别变量替换为表示每个类别的二进制变量集合。当在整个数据集上使用时，它返回数值变量，随后是每个变量类型为对象、字符串或类别的每个变量中看到的每个类别的独热编码表示。'
- en: Note
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`pandas` will return binary variables for every category seen in a dataset.
    In practice, to avoid data leakage and anticipate deployment eventualities, we
    want to return dummy variables for categories seen in a training set only. So,
    it is safer to use `scikit-learn` and `feature-engine`.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas` 会为数据集中出现的每个类别返回二进制变量。在实际应用中，为了避免数据泄露并预测部署情况，我们只想为训练集中出现的类别返回虚拟变量。因此，使用
    `scikit-learn` 和 `feature-engine` 更为安全。'
- en: '`OneHotEncoder()` from `scikit-learn` or `feature-engine` learned the categories
    that should be represented by binary variables from the train set when we applied
    `fit()`. With `transform()`, `scikit-learn` returned just the binary variables,
    whereas `feature-engine` returned the numerical variables followed by the one-hot
    encoded representation of the categorical ones.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`OneHotEncoder()` 从 `scikit-learn` 或 `feature-engine` 中学习，在应用 `fit()` 时从训练集中识别出应该用二进制变量表示的类别。使用
    `transform()`，`scikit-learn` 仅返回二进制变量，而 `feature-engine` 则返回数值变量，随后是类别变量的独热编码表示。'
- en: '`scikit-learn`’s `OneHotEncoder()` encodes all variables by default. To restrict
    the encoding to categorical variables, we used `ColumnTransformer()`. We set the
    output of `transform()`to `pandas` to obtain the resulting data as a DataFrame.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn` 的 `OneHotEncoder()` 默认对所有变量进行编码。为了限制编码只针对类别变量，我们使用了 `ColumnTransformer()`。我们将
    `transform()` 的输出设置为 `pandas`，以获得结果数据作为 DataFrame。'
- en: Note
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: One-hot encoding is suitable for linear models. It also expands the feature
    space. If your dataset contains many categorical variables or highly cardinal
    variables, you can restrict the number of binary variables by encoding the most
    frequent categories only. You can do this automatically with both `scikit-learn`
    and `feature-engine` as we describe in the *Performing one-hot encoding of frequent*
    *categories* recipe.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 独热编码适用于线性模型。它还会扩展特征空间。如果你的数据集中包含许多类别变量或高度基数变量，你可以通过仅编码最频繁的类别来限制二进制变量的数量。你可以像我们在
    *对频繁类别进行独热编码* 食谱中描述的那样，使用 `scikit-learn` 和 `feature-engine` 自动完成此操作。
- en: There’s more...
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We can also perform one-hot encoding using the Category Encoders Python library:
    [https://contrib.scikit-learn.org/category_encoders/onehot.html](https://contrib.scikit-learn.org/category_encoders/onehot.html).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 Category Encoders Python 库进行独热编码：[https://contrib.scikit-learn.org/category_encoders/onehot.html](https://contrib.scikit-learn.org/category_encoders/onehot.html)。
- en: 'To limit the number of binary variables, we can choose which categories to
    encode and which to ignore; check out a Python demo in the following article:
    https://www.blog.trainindata.com/one-hot-encoding-categorical-variables/.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了限制二进制变量的数量，我们可以选择要编码的类别和要忽略的类别；查看以下文章中的 Python 示例：https://www.blog.trainindata.com/one-hot-encoding-categorical-variables/。
- en: Performing one-hot encoding of frequent categories
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对频繁类别进行独热编码
- en: One-hot encoding represents each variable’s category with a binary variable.
    Hence, one-hot encoding of highly cardinal variables or datasets with multiple
    categorical features can expand the feature space dramatically. This, in turn,
    may increase the computational cost of using machine learning models or deteriorate
    their performance. To reduce the number of binary variables, we can perform one-hot
    encoding of the most frequent categories. One-hot encoding the top categories
    is equivalent to treating the remaining, less frequent categories as a single,
    unique category.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 独热编码使用二进制变量表示每个变量的类别。因此，对高度基数变量或具有多个类别特征的集合进行独热编码可以显著扩展特征空间。这反过来可能会增加使用机器学习模型的计算成本或降低其性能。为了减少二进制变量的数量，我们可以对最频繁的类别进行独热编码。对顶级类别进行独热编码相当于将剩余的、较少出现的类别视为一个唯一的类别。
- en: In this recipe, we will implement one-hot encoding of the most popular categories
    using `pandas`, `Scikit-learn`, and `feature-engine`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将使用 `pandas`、`Scikit-learn` 和 `feature-engine` 实现对最流行类别的独热编码。
- en: How to do it...
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'First, let’s import the necessary Python libraries and get the dataset ready:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入必要的 Python 库并准备好数据集：
- en: 'Import the required Python libraries, functions, and classes:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的Python库、函数和类：
- en: '[PRE28]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let’s load the Credit Approval dataset and divide it into train and test sets:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载信用审批数据集并将其分为训练集和测试集：
- en: '[PRE29]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Note
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: The most frequent categories need to be determined in the train set. This is
    to avoid data leakage.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练集中需要确定最频繁的类别。这是为了避免数据泄露。
- en: 'Let’s inspect the unique categories of the `A6` variable:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查`A6`变量的唯一类别：
- en: '[PRE30]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The unique values of `A6` are displayed in the following output:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`A6`的唯一值显示在以下输出中：'
- en: '[PRE31]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: X_train["A6"].value_counts().sort_values(
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_train["A6"].value_counts().sort_values(
- en: ascending=False).head(5)
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ascending=False).head(5)
- en: '[PRE32]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: A6
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A6
- en: c      93
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c      93
- en: q      56
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: q      56
- en: w      48
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: w      48
- en: i      41
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: i      41
- en: ff     38
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ff     38
- en: 'A6 in a list by using the code in *Step 4* inside a list comprehension:'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用*步骤4*中的代码通过列表推导式将A6放入一个列表中：
- en: '[PRE33]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let’s add a binary variable per top category to a copy of the train and test
    sets:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在训练集和测试集的副本中为每个顶级类别添加一个二元变量：
- en: '[PRE35]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let’s display the top `10` rows of the original and encoded variable, `A6`,
    in the train set:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在训练集中显示原始变量和编码变量`A6`的前`10`行：
- en: '[PRE36]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'In the output of *Step 7*, we can see the `A6` variable, followed by the binary
    variables:'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第7步的输出中，我们可以看到`A6`变量，随后是二元变量：
- en: '[PRE37]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let’s import the encoder:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入编码器：
- en: '[PRE38]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let’s set up the encoder to encode categories shown in at least `39` observations
    and limit the number of categories to encode to `5`:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置编码器，以编码至少有`39`个观察值的类别，并将编码的类别数量限制为`5`：
- en: '[PRE39]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Finally, let’s fit the transformer to the two high cardinal variables and then
    transform the data:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们将转换器拟合到两个高基数变量，然后转换数据：
- en: '[PRE40]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'If you execute `X_train_enc.head()` you’ll see the resulting DataFrame:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您执行`X_train_enc.head()`，您将看到生成的DataFrame：
- en: '![Figure 2.6 – Transformed DataFrame containing binary variables for those
    categories with at least 39 observations and an additional binary representing
    all remaining categories](img/B22396_02_06.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6 – 包含至少有39个观察值的类别二元变量以及表示所有剩余类别的额外二元变量的转换DataFrame](img/B22396_02_06.jpg)'
- en: Figure 2.6 – Transformed DataFrame containing binary variables for those categories
    with at least 39 observations and an additional binary representing all remaining
    categories
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6 – 包含至少有39个观察值的类别二元变量以及表示所有剩余类别的额外二元变量的转换DataFrame
- en: To wrap up the recipe, let’s encode the most frequent categories with `feature-engine`.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结这个配方，让我们使用`feature-engine`对最频繁的类别进行编码。
- en: 'Let’s set up the one-hot encoder to encode the five most frequent categories
    of the `A6` and `A7` variables:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置一热编码器来编码`A6`和`A7`变量中最频繁的五个类别：
- en: '[PRE41]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Note
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: The number of frequent categories to encode is arbitrarily determined by the
    user.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 要编码的频繁类别数量由用户任意确定。
- en: 'Let’s fit the encoder to the train set so that it learns and stores the most
    frequent categories of `A6` and `A7`:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将编码器拟合到训练集，以便它学习并存储`A6`和`A7`变量的最频繁类别：
- en: '[PRE42]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Finally, let’s encode `A6` and `A7` in the train and test sets:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们在训练集和测试集中对`A6`和`A7`进行编码：
- en: '[PRE43]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: You can view the new binary variables in the transformed DataFrame by executing
    `X_train_enc.head()`. You can also find the top five categories learned by the
    encoder by executing `ohe_enc.encoder_dict_`.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以通过执行`X_train_enc.head()`来查看转换DataFrame中的新二元变量。您还可以通过执行`ohe_enc.encoder_dict_`来找到编码器学习到的前五个类别。
- en: How it works...
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the first part of this recipe, we worked with the `A6` categorical variable.
    We inspected its unique categories with `pandas`’ `unique()`. Next, we counted
    the number of observations per category using `pandas`’ `value_counts()`, which
    returned a `pandas` series with the categories as the index and the number of
    observations as values. Next, we sorted the categories from the one with the most
    to the one with the least observations using `pandas`’ `sort_values()`. We then
    reduced the series to the five most popular categories by using `pandas`’ `head()`.
    We used this series in a list comprehension to capture the names of the most frequent
    categories. After that, we looped over each category, and with NumPy’s `where()`,
    we created binary variables by placing a value of `1` if the observation showed
    the category, or `0` otherwise.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方的第一部分，我们处理了`A6`分类变量。我们使用`pandas`的`unique()`检查其唯一类别。接下来，我们使用`pandas`的`value_counts()`计算每个类别的观测值数量，它返回一个以类别为索引、观测值数量为值的`pandas`系列。然后，我们使用`pandas`的`sort_values()`将类别从观测值最多到最少的顺序排序。我们然后使用`pandas`的`head()`将系列缩减到最流行的五个类别。我们使用这个系列在一个列表推导式中捕获最频繁类别的名称。之后，我们遍历每个类别，并使用NumPy的`where()`，如果观测值显示了该类别，则创建值为`1`的二元变量，否则为`0`。
- en: We discussed how to use `OneHotEncoder()` from `scikit-learn` and `feature-engine`
    in the *Creating binary variables through one-hot encoding* recipe. Here, I will
    only highlight the parameters needed to encode the most frequent categories.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在“通过独热编码创建二元变量”的配方中讨论了如何使用`scikit-learn`和`feature-engine`。在这里，我将只强调编码最频繁类别所需的参数。
- en: To encode frequent categories with `scikit-learn`, we set the `min_frequency`
    parameter to `39`. Hence, categories shown in less than `39` observations were
    grouped into an additional binary variable called `infrequent_sklearn`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`scikit-learn`编码频繁类别，我们将`min_frequency`参数设置为`39`。因此，在少于`39`个观测值中出现的类别将被组合成一个额外的二元变量，称为`infrequent_sklearn`。
- en: To encode frequent categories with `feature-engine`, we set the `top_categories`
    parameter to `5`. Hence, the transformer created binary variables for the 5 most
    frequent categories only. Less frequent categories will show a `0` in all the
    binary variables.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`feature-engine`编码频繁类别，我们将`top_categories`参数设置为`5`。因此，创建的转换器只为5个最频繁的类别创建二元变量。较少见的类别将在所有二元变量中显示为`0`。
- en: There’s more...
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: This recipe is based on the winning solution of the **Knowledge Discovery and
    Data** (**KDD**) 2009 mining cup, *Winning the KDD Cup Orange Challenge with Ensemble
    Selection* (http://proceedings.mlr.press/v7/niculescu09/niculescu09.pdf), where
    the author's limited one-hot encoding to the 10 most frequent categories of each
    variable.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方基于2009年知识发现与数据（**KDD**）挖掘杯的获胜方案，*使用集成选择赢得KDD Cup Orange挑战*（http://proceedings.mlr.press/v7/niculescu09/niculescu09.pdf），其中作者将独热编码限制为每个变量的10个最频繁类别。
- en: Replacing categories with counts or the frequency of observations
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用观测值的计数或频率替换类别
- en: In count with counts or frequency of observations” or frequency encoding, we
    replace the categories with the count or the fraction of observations showing
    that category. That is, if 10 out of 100 observations show the `blue` category
    for the `Color` variable, we would replace `blue` with `10` when doing count encoding,
    or with `0.1` if performing frequency encoding. These encoding methods are useful
    when there is a relationship between the category frequency and the target. For
    example, in sales, the frequency of a product may indicate its popularity.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在“计数与观测值的计数或频率”或频率编码中，我们将类别替换为显示该类别的观测值的计数或分数。也就是说，如果有10个观测值中的100个显示`Color`变量的`blue`类别，我们在进行计数编码时将`blue`替换为`10`，或者在执行频率编码时替换为`0.1`。这些编码方法在类别频率与目标之间存在关系时很有用。例如，在销售中，产品的频率可能表明其受欢迎程度。
- en: Note
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If two different categories are present in the same number of observations,
    they will be replaced by the same value, which may lead to information loss.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个不同的类别在相同数量的观测值中出现，它们将被相同的值替换，这可能会导致信息丢失。
- en: In this recipe, we will perform count and frequency encoding using `pandas`
    and `feature-engine`.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用`pandas`和`feature-engine`执行计数和频率编码。
- en: How to do it...
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We’ll start by encoding one variable with `pandas` and then we’ll automate
    the process with `feature-engine`:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用`pandas`编码一个变量，然后我们将使用`feature-engine`自动化这个过程：
- en: 'Let’s start with the imports:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从导入开始：
- en: '[PRE44]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let’s load the Credit Approval dataset and divide it into train and test sets:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载信用批准数据集并将其分为训练集和测试集：
- en: '[PRE45]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Let’s with counts or frequency of observations” capture the number of observations
    per category of the `A7` variable in a dictionary:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过计数或观察频率来捕获 `A7` 变量每个类别的观察数量，并将其存储在一个字典中：
- en: '[PRE46]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Note
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To find the frequency instead, execute `X_train["A7"].value_counts(normalize=True).to_dict()`.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到频率，请执行 `X_train["A7"].value_counts(normalize=True).to_dict()`。
- en: 'If we execute `print(counts)`, we’ll see the count of observations per category
    of `A7`:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们执行 `print(counts)`，我们将看到 `A7` 每个类别的观察计数：
- en: '[PRE47]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Let’s replace the categories in `A7` with the counts in a copy of the data
    sets:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在数据集的副本中将 `A7` 中的类别替换为计数：
- en: '[PRE48]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Go ahead and inspect the data by executing `X_train_enc.head()` to corroborate
    that the categories have been replaced by the counts.
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 继续执行 `X_train_enc.head()` 来检查类别是否已被替换为计数。
- en: To apply this procedure to multiple variables, we can use `feature-engine`.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要将此过程应用于多个变量，我们可以使用 `feature-engine`。
- en: 'Let’s set up the encoder so that it encodes all categorical variables with
    the count of observations:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置编码器，使其使用观察计数来编码所有分类变量：
- en: '[PRE49]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Note
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`CountFrequencyEncoder()` will automatically find and encode all categorical
    variables in the train set. To encode only a subset of the variables, pass the
    variable names in a list to the `variables` argument. To encode with the frequency
    instead, use `encoding_method="frequency"`.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '`CountFrequencyEncoder()` 将自动找到并编码训练集中的所有分类变量。要仅编码变量子集，请将变量名称列表传递给 `variables`
    参数。要使用频率进行编码，请使用 `encoding_method="frequency"`。'
- en: 'Let’s fit the encoder to the train set so that it stores the number of observations
    per category per variable:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将编码器拟合到训练集，以便它存储每个变量每个类别的观察数量：
- en: '[PRE50]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The encoder found the categorical variables automatically. Let’s check them
    out:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码器自动找到了分类变量。让我们来看看：
- en: '[PRE51]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The previous command returns the names of the categorical variables in the
    train set:'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 之前的命令返回训练集中分类变量的名称：
- en: '[PRE52]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Let’s print the count of observations per category per variable:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打印每个变量每个类别的观察计数：
- en: '[PRE53]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The previous attribute stores the mappings that will be used to replace the
    categories:'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 之前的属性存储了将用于替换类别的映射：
- en: '![Figure 2.7 – Dictionary containing the number of observations per category,
    for each variable; these values will be used to encode the categorical variables](img/B22396_02_07.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![图2.7 – 包含每个变量每个类别的观察数量的字典；这些值将用于编码分类变量](img/B22396_02_07.jpg)'
- en: Figure 2.7 – Dictionary containing the number of observations per category,
    for each variable; these values will be used to encode the categorical variables
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 – 包含每个变量每个类别的观察数量的字典；这些值将用于编码分类变量
- en: 'Finally, let’s with counts or frequency of observations” replace the categories
    with counts in the train and test sets:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们在训练和测试集中使用“计数或观察频率”将类别替换为计数：
- en: '[PRE54]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Check out the result by executing `X_train_enc.head()`. The encoder returns
    `pandas` DataFrames with the strings of the categorical variables replaced with
    the counts of observations, leaving the variables ready to use in machine learning
    models.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行 `X_train_enc.head()` 来检查结果。编码器返回 `pandas` DataFrame，其中分类变量的字符串被观察计数替换，使变量准备好在机器学习模型中使用。
- en: How it works...
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we replaced categories with the count of observations using
    `pandas` and `feature-engine`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用 `pandas` 和 `feature-engine` 将类别替换为观察计数。
- en: Using `pandas`’ `value_counts()`, we determined the number of observations per
    category of the `A7` variable, and with `pandas`’ `to_dict()`, we captured these
    values in a with counts or frequency of observations” dictionary, where each key
    was a unique category, and each value the number of observations for that category.
    With `pandas`’ `map()` and using this dictionary, we replaced the categories with
    the observation counts in both the train and test sets.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `pandas` 的 `value_counts()`，我们确定了 `A7` 变量每个类别的观察数量，并通过 `pandas` 的 `to_dict()`，将这些值捕获在“计数或观察频率”字典中，其中每个键是一个唯一的类别，每个值是该类别的观察数量。通过
    `pandas` 的 `map()` 和使用此字典，我们在训练和测试集中将类别替换为观察计数。
- en: Note
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The count of observations for the encoding should be obtained from the train
    set to avoid data leakage. Note that new categories in the test set will not have
    a corresponding mapping and hence will be replaced by `nan`. To avoid this, use
    f`eature-engine`. Alternatively, you can replace the `nan` with `0`.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 编码的观测值数量应从训练集中获取，以避免数据泄露。请注意，测试集中的新类别将没有对应的映射，因此将被替换为`nan`。为了避免这种情况，请使用`feature-engine`。或者，您可以将`nan`替换为`0`。
- en: To perform count encoding with `feature-engine`, we used `CountFrequencyEncoder()`
    and set `encoding_method` to `'count'`. We left the `variables` argument set to
    `None` so that the encoder automatically finds all the categorical variables in
    the dataset. With `fit()`, the transformer found the categorical variables and
    stored the observation counts per category in the `encoder_dict_` attribute. With
    `transform()`, the transformer replaced the categories with the counts, returning
    a `pandas` DataFrame.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`feature-engine`执行计数编码，我们使用了`CountFrequencyEncoder()`并将`encoding_method`设置为`'count'`。我们将`variables`参数设置为`None`，以便编码器自动找到数据集中的所有分类变量。使用`fit()`，转换器找到了分类变量，并将每个类别的观测值计数存储在`encoder_dict_`属性中。使用`transform()`，转换器用计数替换了类别，返回一个`pandas`
    DataFrame。
- en: Note
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If there are categories in the test set that were not present in the train set,
    the encoder will raise an error by default. You can make it ignore them, in which
    case they will appear as `nan`, or encode them as `0`.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试集中有训练集中不存在的类别，编码器将默认引发错误。您可以使其忽略它们，在这种情况下，它们将显示为`nan`，或者将它们编码为`0`。
- en: See also
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'You can also carry out count and frequency encoding with the Python library
    Category Encoders: [https://contrib.scikit-learn.org/category_encoders/count.html](https://contrib.scikit-learn.org/category_encoders/count.html).'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用Python库Category Encoders执行计数和频率编码：[https://contrib.scikit-learn.org/category_encoders/count.html](https://contrib.scikit-learn.org/category_encoders/count.html)。
- en: 'For some useful applications of count encoding, check out this article: [https://letsdatascience.com/frequency-encoding/](https://letsdatascience.com/frequency-encoding/).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看计数编码的一些有用应用，请参阅这篇文章：[https://letsdatascience.com/frequency-encoding/](https://letsdatascience.com/frequency-encoding/)。
- en: Replacing categories with ordinal numbers
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用序数替换类别
- en: Ordinal encoding consists of replacing the categories with digits from *1* to
    *k* (or *0* to *k-1*, depending on the implementation), where *k* is the number
    of distinct categories of the variable. The numbers are assigned arbitrarily.
    Ordinal encoding is better suited for non-linear machine learning models, which
    can navigate through arbitrarily assigned numbers to find patterns that relate
    to the target.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 序数编码包括用从`1`到`k`（或根据实现从`0`到`k-1`）的数字替换类别，其中`k`是变量的不同类别的数量。这些数字是任意分配的。序数编码更适合非线性机器学习模型，这些模型可以通过任意分配的数字来寻找与目标相关的模式。
- en: In this recipe, we will perform ordinal encoding using `pandas`, `scikit-learn`,
    and `feature-engine`.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用`pandas`、`scikit-learn`和`feature-engine`执行序数编码。
- en: How to do it...
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'First, let’s make the import and prepare the dataset:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们进行导入并准备数据集：
- en: 'Import `pandas` and the data split function:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`和数据拆分函数：
- en: '[PRE55]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Let’s load the Credit Approval dataset and divide it into train and test sets:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载Credit Approval数据集并将其分为训练集和测试集：
- en: '[PRE56]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'To encode the `A7` variable, let’s make a dictionary of category-to-integer
    pairs:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要编码`A7`变量，让我们创建一个类别到整数的字典：
- en: '[PRE57]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'If we execute `print(ordinal_mapping)`, we will see the digits that will replace
    each category:'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们执行`print(ordinal_mapping)`，我们将看到将替换每个类别的数字：
- en: '[PRE58]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Now, let’s replace the categories in a copy of the DataFrames:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们在DataFrame的副本中替换类别：
- en: '[PRE59]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Go ahead and execute `print(X_train["A7"].head())` to see the result of the
    previous operation.
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 执行`print(X_train["A7"].head())`以查看上一操作的结果。
- en: Next, we’ll carry out ordinal encoding using `scikit-learn`.
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们将使用`scikit-learn`执行序数编码。
- en: 'Let’s import the required classes:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入所需的类：
- en: '[PRE60]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Note
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Do not confuse `OrdinalEncoder()` with `LabelEncoder()` from `scikit-learn`.
    The former is intended to encode predictive features, whereas the latter is intended
    to modify the target variable.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 不要混淆`OrdinalEncoder()`和来自`scikit-learn`的`LabelEncoder()`。前者旨在编码预测特征，而后者旨在修改目标变量。
- en: 'Let’s set up the encoder:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置编码器：
- en: '[PRE61]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Let’s make a list containing the categorical variables to encode:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个包含需要编码的分类变量的列表：
- en: '[PRE62]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Let’s restrict the encoding to the categorical variables:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将编码限制在分类变量上：
- en: '[PRE63]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Note
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Remember to set `remainder` to `"passthrough"` to make the `ColumnTransformer()`
    return the un-transformed variables as well.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 记得将`remainder`设置为`"passthrough"`，以便`ColumnTransformer()`返回未转换的变量。
- en: 'Let’s fit the encoder to the train set so that it creates and stores representations
    of categories to digits:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将编码器拟合到训练集，以便它创建并存储类别到数字的表示：
- en: '[PRE64]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Note
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: By executing `ct.named_transformers_["encoder"].categories_`, you can visualize
    the unique categories per variable.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行`ct.named_transformers_["encoder"].categories_`，您可以可视化每个变量的唯一类别。
- en: 'Now, let’s encode the categorical variables in the train and test sets:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们对训练集和测试集中的分类变量进行编码：
- en: '[PRE65]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Go ahead and execute `X_train_enc.head()` to check out the resulting DataFrame.
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 执行`X_train_enc.head()`来查看生成的DataFrame。
- en: Note
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`ColumnTransformer()` will mark the encoded variables by appending `encoder`
    to the variable name. The variables that were not modified show the `remainder`
    prefix.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '`ColumnTransformer()`将通过在变量名后附加`encoder`来标记已编码的变量。未修改的变量显示`remainder`前缀。'
- en: Now, let’s do ordinal encoding with `feature-engine`.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`feature-engine`进行顺序编码。
- en: 'Let’s import the encoder:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入编码器：
- en: '[PRE66]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Let’s set up the encoder so that it replaces categories with arbitrary integers
    in the categorical variables specified in *Step 7*:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置编码器，使其在*步骤7*中指定的分类变量中将类别替换为任意整数：
- en: '[PRE67]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Note
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`feature-engine`’s `OrdinalEncoder()` automatically finds and encodes all categorical
    variables if the `variables` parameter is `None`. Alternatively, it will encode
    the variables indicated in the list. In addition, it can assign the integers according
    to the target mean value (see the *Performing ordinal encoding based on the target*
    *value* recipe).'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`variables`参数为`None`，`feature-engine`的`OrdinalEncoder()`将自动查找并编码所有分类变量。或者，它将编码列表中指示的变量。此外，它可以根据目标平均值分配整数（参见*基于目标*
    *值* 进行顺序编码的配方）。
- en: 'Let’s fit the encoder to the train set so that it learns and stores the category-to-integer
    mappings:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将编码器拟合到训练集，以便它学习并存储类别到整数的映射：
- en: '[PRE68]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Note
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The category to integer mappings are stored in the `encoder_dict_` attribute
    and can be accessed by executing `enc.encoder_dict_`.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 类别到整数的映射存储在`encoder_dict_`属性中，可以通过执行`enc.encoder_dict_`来访问。
- en: 'Finally, let’s encode the categorical variables in the train and test sets:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们将训练集和测试集中的分类变量进行编码：
- en: '[PRE69]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '`feature-engine` returns `pandas` DataFrames where the values of the original
    variables are replaced with numbers, leaving the DataFrame ready to use in machine
    learning models.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature-engine`返回`pandas` DataFrame，其中原始变量的值被数字替换，使DataFrame准备好在机器学习模型中使用。'
- en: How it works...
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we replaced categories with integers assigned arbitrarily.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将类别替换为任意分配的整数。
- en: We used `pandas`’ `unique()` to find the unique categories of the `A7` variable.
    Next, we created a dictionary of category-to-integer and passed it to `pandas`’
    `map()` to replace the strings in `A7` with the integers.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`pandas`的`unique()`找到`A7`变量的唯一类别。接下来，我们创建了一个类别到整数的字典，并将其传递给`pandas`的`map()`，以将`A7`中的字符串替换为整数。
- en: Next, we carried out ordinal encoding using `scikit-learn`’s `OrdinalEncoder()`
    and used `ColumnTransformer()` to restrict the encoding to categorical variables.
    With `fit()`, the transformer created the category-to-integer mappings based on
    the categories in the train set. With `transform()`, the categories were replaced
    with integers. By setting the `remainder` parameter to `passthrough`, we made
    `ColumnTransformer()` concatenate the variables that are not encoded at the back
    of the encoded features.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`scikit-learn`的`OrdinalEncoder()`进行了顺序编码，并使用`ColumnTransformer()`将编码限制在分类变量上。通过`fit()`，转换器根据训练集中的类别创建了类别到整数的映射。通过`transform()`，类别被替换为整数。通过将`remainder`参数设置为`passthrough`，我们使`ColumnTransformer()`将未编码的变量连接到编码特征之后。
- en: To perform ordinal encoding with `feature-engine`, we used `OrdinalEncoder()`,
    indicating that the integers should be assigned arbitrarily through `encoding_method`,
    and passed a list with the variables to encode in the `variables` argument. With
    `fit()`, the encoder assigned integers to each variable’s categories, which were
    stored in the `encoder_dict_` attribute. These mappings were then used by the
    `transform()` method to replace the categories in the train and test sets, returning
    DataFrames.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`feature-engine`进行有序编码时，我们使用了`OrdinalEncoder()`，表示整数应通过`encoding_method`任意分配，并通过`variables`参数传递了一个包含要编码的变量的列表。使用`fit()`，编码器将整数分配给每个变量的类别，这些类别存储在`encoder_dict_`属性中。然后，这些映射被`transform()`方法用于替换训练集和测试集中的类别，返回DataFrames。
- en: Note
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When a category in the test set is not present in the training set, it will
    not have a mapping to a digit. `OrdinalEncoder()` from `scikit-learn` and `feature-engine`
    will raise an error by default. However, they have the option to replace unseen
    categories with a user-defined value or `-``1`, respectively.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 当测试集中的类别不在训练集中时，它将没有映射到数字。`scikit-learn`的`OrdinalEncoder()`和`feature-engine`默认会引发错误。然而，它们都有选项用用户定义的值或`-1`替换未看到的类别。
- en: '`scikit-learn`’s `OrdinalEncoder()` can restrict the encoding to those categories
    with a minimum frequency. `feature-engine`’s `OrdinalEncoder()` can assign the
    numbers based on the target mean value, as we will see in the following recipe.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn`的`OrdinalEncoder()`可以限制编码到具有最小频率的类别。`feature-engine`的`OrdinalEncoder()`可以根据目标平均值分配数字，正如我们将在下一个配方中看到的。'
- en: There’s more...
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多...
- en: You can also carry out ordinal encoding with `OrdinalEncoder()` from Category
    Encoders. Check it out at [http://contrib.scikit-learn.org/category_encoders/ordinal.html](http://contrib.scikit-learn.org/category_encoders/ordinal.html).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用`OrdinalEncoder()`从`Category Encoders`进行有序编码。请查看[http://contrib.scikit-learn.org/category_encoders/ordinal.html](http://contrib.scikit-learn.org/category_encoders/ordinal.html)。
- en: Performing ordinal encoding based on the target value
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于目标值进行有序编码
- en: In the previous recipe, we replaced categories with integers, which were assigned
    arbitrarily. We can also assign integers to the categories given the target values.
    To do this, first, we calculate the mean value of the target per category. Next,
    we order the categories from the one with the lowest to the one with the highest
    target mean value. Finally, we assign digits to the ordered categories, starting
    with *0* to the first category up to *k-1* to the last category, where *k* is
    the number of distinct categories.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的配方中，我们用整数替换了类别，这些整数是任意分配的。我们也可以根据目标值给类别分配整数。为此，首先，我们计算每个类别的目标值的平均值。接下来，我们按目标平均值从低到高对类别进行排序。最后，我们将数字分配给有序的类别，从第一个类别开始的*0*到最后一个类别的*k-1*。
- en: This encoding method creates a monotonic relationship between the categorical
    variable and the response and therefore makes the variables more adequate for
    use in linear models.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这种编码方法在分类变量和响应变量之间创建了一个单调关系，因此使得变量更适合用于线性模型。
- en: In this recipe, we will encode categories while following the target value using
    `pandas` and `feature-engine`.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用`pandas`和`feature-engine`在遵循目标值的同时对类别进行编码。
- en: How to do it...
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'First, let’s import the necessary Python libraries and get the dataset ready:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入必要的Python库并准备好数据集：
- en: 'Import the required Python libraries, functions, and classes:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的Python库、函数和类：
- en: '[PRE70]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Let’s load the Credit Approval dataset and divide it into train and test sets:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载Credit Approval数据集并将其分为训练集和测试集：
- en: '[PRE71]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Let’s determine the mean target value per category in `A7`, then sort the categories
    from that with the lowest to that with the highest target value:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在`A7`中确定每个类别的平均目标值，然后按目标值从低到高排序类别：
- en: '[PRE72]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The following is the output of the preceding command:'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是在前面的命令中的输出：
- en: '[PRE73]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Now, let’s repeat the computation in *Step 3*, but this time, let’s retain
    the ordered category names:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们重复第3步的计算，但这次，让我们保留有序的类别名称：
- en: '[PRE74]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'To display the output of the preceding command, we can execute `print(ordered_labels)`:
    `Index([''o'', ''ff'', ''j'', ''dd'', ''v'', ''bb'', ''h'', ''n'', ''z'', ''Missing''],`
    `dtype=''object'', name=''A7'')`.'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要显示前面命令的输出，我们可以执行`print(ordered_labels)`：`Index(['o', 'ff', 'j', 'dd', 'v',
    'bb', 'h', 'n', 'z', 'Missing'], dtype='object', name='A7')`。
- en: 'Let’s create a dictionary of category-to-integer pairs, using the ordered list
    we created in *Step 4*:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个类别到整数的字典，使用我们在 *步骤4* 中创建的有序列表：
- en: '[PRE75]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We can visualize the result of the preceding code by executing `print(ordinal_mapping)`:'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过执行 `print(ordinal_mapping)` 来可视化前面代码的结果：
- en: '[PRE76]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: X_train_enc = X_train.copy()
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_train_enc = X_train.copy()
- en: X_test_enc = X_test.copy()
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_test_enc = X_test.copy()
- en: X_train_enc["A7"] = X_train_enc["A7"].map(
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_train_enc["A7"] = X_train_enc["A7"].map(
- en: ordinal_mapping)
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ordinal_mapping)
- en: X_test_enc["A7"] = X_test_enc["A7"].map(
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_test_enc["A7"] = X_test_enc["A7"].map(
- en: ordinal_mapping)
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ordinal_mapping)
- en: '[PRE77]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Note
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If the test set contains a category that is not present in the train set, the
    preceding code will introduce `np.nan`.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试集包含训练集中不存在的类别，前面的代码将引入 `np.nan`。
- en: To visualize the effect of this encoding, let’s plot the relationship of the
    categories of the `A7` variable with the target before and after the encoding.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化这种编码的效果，让我们绘制编码前后 `A7` 变量的类别与目标之间的关系。
- en: 'Let’s plot the mean target response per category of the `A7` variable:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制 `A7` 变量每个类别的目标响应平均值：
- en: '[PRE78]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'We can see the non-monotonic relationship between categories of `A7` and the
    target in the following plot:'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以在以下图表中看到 `A7` 类别和目标之间的非单调关系：
- en: '![Figure 2.8 – Mean target value per category of A7 before the encoding](img/B22396_02_08.jpg)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8 – 编码前A7每个类别的目标值平均值](img/B22396_02_08.jpg)'
- en: Figure 2.8 – Mean target value per category of A7 before the encoding
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 – 编码前A7每个类别的目标值平均值
- en: 'Let’s plot the mean target value per category in the encoded variable:'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制编码变量中每个类别的目标值平均值：
- en: '[PRE79]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The encoded variable shows a monotonic relationship with the target – the higher
    the mean target value, the higher the digit assigned to the category:'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码后的变量与目标之间存在单调关系 – 目标值平均值越高，分配给类别的数字就越高：
- en: '![Figure 2.9 – Mean target value per category of A7 after the encoding.](img/B22396_02_09.jpg)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9 – 编码后A7每个类别的目标值平均值](img/B22396_02_09.jpg)'
- en: Figure 2.9 – Mean target value per category of A7 after the encoding.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 – 编码后A7每个类别的目标值平均值
- en: Now, let’s perform ordered ordinal encoding using `feature-engine`.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `feature-engine` 执行有序顺序编码。
- en: 'Let’s import the encoder:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入编码器：
- en: '[PRE80]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Next, let’s set up the encoder so that it assigns integers based on the target
    mean value to all categorical variables in the dataset:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们设置编码器，使其根据目标平均值将整数分配给数据集中的所有分类变量：
- en: '[PRE81]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Note
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`OrdinalEncoder()` will find and encode all categorical variables automatically.
    To restrict the encoding to a subset of variables, pass their names in a list
    to the `variables` argument. To encode numerical variables, set `ignore_format=True`.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '`OrdinalEncoder()` 将自动查找并编码所有分类变量。要限制编码到变量的子集，将它们的名称作为列表传递给 `variables` 参数。要编码数值变量，设置
    `ignore_format=True`。'
- en: 'Let’s fit the encoder to the train set so that it finds the categorical variables,
    and then stores the category and integer mappings:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将编码器拟合到训练集，以便它找到分类变量，然后存储类别和整数映射：
- en: '[PRE82]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Finally, let’s replace the categories with numbers in the train and test sets:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们在训练集和测试集中将类别替换为数字：
- en: '[PRE83]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Note
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You’ll find the digits that will replace each category in the `encoder_dict_`
    attribute.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在 `encoder_dict_` 属性中找到替换每个类别的数字。
- en: Check out the output of the transformation by executing `X_train_enc.head()`.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行 `X_train_enc.head()` 来查看转换的输出。
- en: How it works...
  id: totrans-371
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we replaced the categories with integers according to the target
    mean.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们根据目标平均值将类别替换为整数。
- en: In the first part of this recipe, we worked with the `A7` categorical variable.
    With `pandas`’ `groupby()`, we grouped the data based on the categories of `A7`,
    and with `pandas`’ `mean()`, we determined the mean value of the target for each
    of those categories. Next, we ordered the categories with `pandas`’ `sort_values()`
    from the ones with the lowest to the ones with the highest target mean response.
    The output of this operation was a `pandas` series, with the categories as indices
    and the target mean as values. With `pandas`’ `index`, we captured the ordered
    categories in an array; then, with Python dictionary comprehension, we created
    a dictionary of category-to-integer pairs. Finally, we used this dictionary to
    replace the category with integers using `pandas`’ `map()`.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱的第一部分，我们处理了`A7`分类变量。使用`pandas`的`groupby()`函数，我们根据`A7`的分类对数据进行分组，并使用`pandas`的`mean()`函数确定每个分类的目标均值。接下来，我们使用`pandas`的`sort_values()`函数按目标均值响应从低到高对分类进行排序。这个操作的输出是一个`pandas`系列，其中分类作为索引，目标均值作为值。使用`pandas`的`index`，我们将排序后的分类存储在一个数组中；然后，使用Python字典推导式创建了一个分类到整数的字典对。最后，我们使用这个字典通过`pandas`的`map()`函数将分类替换为整数。
- en: Note
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To avoid data leakage, we determine the category-to-integer mappings from the
    train set.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免数据泄露，我们从训练集中确定分类到整数的映射。
- en: To perform the encoding with `feature-engine`, we used `OrdinalEncoder()`, setting
    the `encoding_method` to `ordered`. We left the argument variables set to `None`
    so that the encoder automatically detects all categorical variables in the dataset.
    With `fit()`, the encoder found the categorical variables and assigned digits
    to their categories according to the target mean value. The categorical variables’
    names and dictionaries with category-to-digit pairs were stored in the `variables_`
    and `encoder_dict_` attributes, respectively. Finally, using `transform()`, we
    replaced the categories with digits in the train and test sets, returning `pandas`
    DataFrames.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`feature-engine`执行编码，我们使用了`OrdinalEncoder()`，将`encoding_method`设置为`ordered`。我们将变量参数设置为`None`，以便编码器自动检测数据集中的所有分类变量。使用`fit()`，编码器找到了分类变量，并根据目标均值值分配数字给它们的分类。分类变量的名称和分类到数字对的字典分别存储在`variables_`和`encoder_dict_`属性中。最后，使用`transform()`，我们在训练集和测试集中用数字替换了分类，返回`pandas`数据框。
- en: See also
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'For an implementation of this recipe with Category Encoders, visit this book’s
    GitHub repository: [https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-05-Ordered-ordinal-encoding.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-05-Ordered-ordinal-encoding.ipynb).'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看使用分类编码器的本食谱的实现，请访问本书的GitHub仓库：[https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-05-Ordered-ordinal-encoding.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-05-Ordered-ordinal-encoding.ipynb)。
- en: Implementing target mean encoding
  id: totrans-379
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现目标均值编码
- en: '**Mean encoding** or **target encoding** maps each category to the probability
    estimate of the target attribute. If the target is binary, the numerical mapping
    is the posterior probability of the target conditioned to the value of the category.
    If the target is continuous, the numerical representation is given by the expected
    value of the target given the value of the category.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '**均值编码**或**目标编码**将每个分类映射到目标属性的预测概率。如果目标是二元的，数值映射是目标在给定分类值条件下的后验概率。如果目标是连续的，数值表示是给定分类值的目标的期望值。'
- en: In its simplest form, the numerical representation for each category is given
    by the mean value of the target variable for a particular category group. For
    example, if we have a `City` variable, with the categories of `London`, `Manchester`,
    and `Bristol`, and we want to predict the default rate (the target takes values
    of `0` and `1`); if the default rate for `London` is 30%, we replace `London`
    with `0.3`; if the default rate for `Manchester` is 20%, we replace `Manchester`
    with `0.2`; and so on. If the target is continuous – say we want to predict income
    – then we would replace `London`, `Manchester`, and `Bristol` with the mean income
    earned in each city.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在其最简单形式中，每个类别的数值表示由特定类别组的目标变量的平均值给出。例如，如果我们有一个`City`变量，类别为`London`、`Manchester`和`Bristol`，我们想要预测违约率（目标取值为`0`和`1`）；如果`London`的违约率是30%，我们将`London`替换为`0.3`；如果`Manchester`的违约率是20%，我们将`Manchester`替换为`0.2`；依此类推。如果目标是连续的——比如说我们想要预测收入——那么我们将`London`、`Manchester`和`Bristol`替换为每个城市所赚取的平均收入。
- en: 'In mathematical terms, if the target is binary, the replacement value, *S*,
    is determined like so:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学的角度来看，如果目标是二元的，替换值*S*的确定如下：
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1.png)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/1.png)'
- en: Here, the numerator is the number of observations with a target value of *1*
    for category *i* and the denominator is the number of observations with a category
    value of *i*.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，分子是类别*i*中具有目标值*1*的观测值的数量，分母是具有类别值*i*的观测值的数量。
- en: 'If the target is continuous, *S*, this is determined by the following formula:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 如果目标是连续的，*S*，则由以下公式确定：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mo>∑</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><msub><mi>n</mi><mi>i</mi></msub></mfrac></mrow></mrow></math>](img/2.png)'
  id: totrans-386
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mo>∑</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><msub><mi>n</mi><mi>i</mi></msub></mfrac></mrow></mrow></math>](img/2.png)'
- en: Here, the numerator is the sum of the target across observations in category
    *i* and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/3.png)
    is the total number of observations in category *i*.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，分子是类别*i*中观测值的总和，而![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/3.png)是类别*i*中的观测值总数。
- en: These formulas provide a good approximation of the target estimate if there
    is a sufficiently large number of observations with each category value – in other
    words, if ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4.png)
    is large. However, in many datasets, there will be categories present in a few
    observations. In these cases, target estimates derived from the precedent formulas
    can be unreliable.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 这些公式在存在足够多的每个类别值的观测值时提供了对目标估计的良好近似——换句话说，如果![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/4.png)很大。然而，在许多数据集中，将存在一些观测值中包含的类别。在这些情况下，从先前的公式中得出的目标估计可能不可靠。
- en: 'To mitigate poor estimates returned for rare categories, the target estimates
    can be determined as a mixture of two probabilities: those returned by the preceding
    formulas and the prior probability of the target based on the entire training.
    The two probabilities are *blended* using a weighting factor, which is a function
    of the category group size:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻对罕见类别返回的估计不佳，目标估计可以确定为两种概率的混合：前一个公式返回的概率和基于整个训练的目标先验概率。这两个概率通过一个权重因子进行混合，该权重因子是类别组大小的函数：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mi>λ</mi><mfrac><msub><mi>n</mi><mrow><mi>i</mi><mo>(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>)</mo></mrow></msub><msub><mi>n</mi><mi>i</mi></msub></mfrac><mo>+</mo><mo>(</mo><mn>1</mn><mo>−</mo><msub><mi>λ</mi><mi>i</mi></msub><mo>)</mo><mfrac><msub><mi>n</mi><mi>λ</mi></msub><mi>N</mi></mfrac></mrow></mrow></mrow></math>](img/5.png)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mi>λ</mi><mfrac><msub><mi>n</mi><mrow><mi>i</mi><mo>(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>)</mo></mrow></msub><msub><mi>n</mi><mi>i</mi></msub></mfrac><mo>+</mo><mo>(</mo><mn>1</mn><mo>−</mo><msub><mi>λ</mi><mi>i</mi></msub><mo>)</mo><mfrac><msub><mi>n</mi><mi>λ</mi></msub><mi>N</mi></mfrac></mrow></mrow></mrow></math>](img/5.png)'
- en: In this formula, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">λ</mml:mi></mml:mrow></mml:msub></mml:math>](img/6.png) is
    the total number of cases where the target takes a value of *1*, *N* is the size
    of the train set, and *𝜆* is the weighting factor.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">λ</mml:mi></mml:mrow></mml:msub></mml:math>](img/6.png) 是目标取值为
    *1* 的总案例数，*N* 是训练集的大小，而 *𝜆* 是权重因子。
- en: When the category group is large, *𝜆* tends to *1*, so more weight is given
    to the first term of the equation. When the category group size is small, then
    *𝜆* tends to *0*, so the estimate is mostly driven by the second term of the equation
    – that is, the target’s prior probability. In other words, if the group size is
    small, knowing the value of the category does not tell us anything about the value
    of the target.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 当类别组较大时，*𝜆* 趋向于 *1*，因此方程的第一项被赋予更多的权重。当类别组较小时，*𝜆* 趋向于 *0*，因此估计主要由方程的第二项驱动——即目标的先验概率。换句话说，如果组大小较小，知道类别值并不能告诉我们关于目标值的信息。
- en: 'The weighting factor, *𝜆*, is determined differently in different open-source
    implementations. In Category Encoders, *𝜆* is a function of the group size, *k*,
    and a smoothing parameter, *f*, which controls the rate of transition between
    the first and second term of the preceding equation:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 权重因子，*𝜆*，在不同的开源实现中确定方式不同。在 Category Encoders 中，*𝜆* 是组大小，*k*，以及平滑参数，*f* 的函数，它控制着前一个方程中第一项和第二项之间的转换速率：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>λ</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mrow><mrow><mo>−</mo><mo>(</mo><mi>n</mi><mo>−</mo><mi>k</mi><mo>)</mo></mrow></mrow><mo>/</mo><mi>f</mi></mrow></msup></mrow></mfrac></mrow></mrow></math>](img/7.png)'
  id: totrans-394
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="normal">λ</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mrow><mrow><mo>−</mo><mo>(</mo><mi>n</mi><mo>−</mo><mi>k</mi><mo>)</mo></mrow></mrow><mo>/</mo><mi>f</mi></mrow></msup></mrow></mfrac></mrow></mrow></math>](img/7.png)'
- en: Here, *k* is half of the minimal size for which we *fully trust* the first term
    of the equation. The *f* parameter is selected by the user either arbitrarily
    or with optimization.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*k* 是我们完全信任方程第一项的最小大小的一半。*f* 参数由用户任意选择或通过优化选择。
- en: 'In `scikit-learn` and `feature-engine`, *𝜆* is a function of the target variance
    for the entire dataset and within the category, and is determined as follows:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `scikit-learn` 和 `feature-engine` 中，*𝜆* 是整个数据集和类别内的目标方差的函数，并按以下方式确定：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="normal">λ</mi><mo>=</mo><mfrac><mrow><mi>n</mi><mi>i</mi><mo>×</mo><mi>t</mi></mrow><mrow><mi>s</mi><mo>+</mo><mi>n</mi><mi>i</mi><mo>×</mo><mi>t</mi></mrow></mfrac></mrow></mrow></math>](img/8.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="normal">λ</mi><mo>=</mo><mfrac><mrow><mi>n</mi><mi>i</mi><mo>×</mo><mi>t</mi></mrow><mrow><mi>s</mi><mo>+</mo><mi>n</mi><mi>i</mi><mo>×</mo><mi>t</mi></mrow></mfrac></mrow></mrow></math>](img/8.png)'
- en: Here, *t* is the target variance in the entire dataset and *s* is the target
    variance within the category. Both implementations are equivalent, but it is important
    to know the equations because they will help you set up the parameters in the
    transformers.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*t* 是整个数据集的目标方差，而 *s* 是类别内的目标方差。两种实现方式是等效的，但了解这些方程式很重要，因为它们将帮助你在变压器中设置参数。
- en: Note
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Mean encoding was designed to encode highly cardinal categorical variables
    without expanding the feature space. For more details, check out the following
    article: Micci-Barreca D. A., *Preprocessing Scheme for High-Cardinality Categorical
    Attributes in Classification and Prediction Problems*. ACM SIGKDD Explorations
    Newsletter, 2001.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 平均编码旨在在不扩展特征空间的情况下编码高度基数分类变量。更多详情，请参阅以下文章：Micci-Barreca D. A.，《用于分类和预测问题中高基数分类属性的前处理方案》。ACM
    SIGKDD Explorations Newsletter，2001。
- en: In this recipe, we will perform mean encoding using `scikit-learn` and `feature-engine`.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用 `scikit-learn` 和 `feature-engine` 执行平均编码。
- en: How to do it...
  id: totrans-402
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let’s begin with this recipe:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从这个配方开始：
- en: 'Import `pandas` and the data split function:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas` 和数据拆分函数：
- en: '[PRE84]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Let’s load the Credit Approval dataset and divide it into train and test sets:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载 Credit Approval 数据集并将其分为训练集和测试集：
- en: '[PRE85]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Let’s import the transformers from `scikit-learn`:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入 `scikit-learn` 中的变压器：
- en: '[PRE86]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Let’s make a list with the names of the categorical variables:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个包含分类变量名称的列表：
- en: '[PRE87]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Let’s set up the encoder to use the target variance to determine the weighting
    factor, as described at the beginning of the recipe:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将编码器设置为使用目标方差来确定权重因子，正如配方开头所述：
- en: '[PRE88]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Let’s restrict the imputation to categorical variables:'
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将插补限制为分类变量：
- en: '[PRE89]'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Let’s fit the encoder and transform the datasets:'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们拟合编码器并转换数据集：
- en: '[PRE90]'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Check out the result by executing `X_train_enc.head()`.
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过执行 `X_train_enc.head()` 检查结果。
- en: Note
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The `fit_transform()` method of `scikit-learn`’s `TargetEncoder()` is not equivalent
    to applying `fit().transform()`. With `fit_transform()`, the resulting dataset
    is encoded based on partial fits over the training folds of a cross-validation
    scheme. This functionality was intentionally designed to prevent overfitting the
    machine learning model to the train set.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn` 的 `TargetEncoder()` 的 `fit_transform()` 方法与 `fit().transform()`
    的应用不等价。使用 `fit_transform()`，生成的数据集基于交叉验证方案训练折的局部拟合进行编码。这个功能是故意设计的，以防止机器学习模型过度拟合训练集。'
- en: 'Now, let’s perform target encoding with `feature-engine`:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `feature-engine` 执行目标编码：
- en: 'Let’s import the encoder:'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入编码器：
- en: '[PRE91]'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Let’s set up the target mean encoder to encode all categorical variables while
    applying smoothing:'
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置目标平均编码器，在应用平滑的同时编码所有分类变量：
- en: '[PRE92]'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: Note
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`MeanEncoder()` does not apply smoothing by default. Make sure you set it to
    `auto` or to an integer to control the blend between prior and posterior target
    estimates.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '`MeanEncoder()` 默认不应用平滑。确保将其设置为 `auto` 或整数以控制先验和后验目标估计之间的混合。'
- en: 'Let’s fit the transformer to the train set so that it learns and stores the
    mean target value per category per variable:'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将变压器拟合到训练集，以便它学习并存储每个变量每个类别的平均目标值：
- en: '[PRE93]'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Finally, let’s encode the train and test sets:'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们对训练集和测试集进行编码：
- en: '[PRE94]'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Note
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The category-to-number pairs are stored as a dictionary of dictionaries in the
    `encoder_dict_` attribute. To display the stored parameters, execute `mean_enc.encoder_dict_.`
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 类别到数字对存储在 `encoder_dict_` 属性中的字典字典中。要显示存储的参数，执行 `mean_enc.encoder_dict_`。
- en: How it works…
  id: totrans-434
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we replaced the categories with the mean target value using
    `scikit-learn` and `feature-engine`.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们使用 `scikit-learn` 和 `feature-engine` 将类别替换为平均目标值。
- en: To encode with `scikit-learn`, we used `TargetEncoder()`, leaving the `smooth`
    parameter to its default value of `auto`. Like this, the transformer used the
    target variance to determine the weighting factor for the blend of probabilities.
    With `fit()`, the transformer learned the value it should use to replace the categories,
    and with `transform()`, it replaced the categories.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 `scikit-learn` 进行编码，我们使用了 `TargetEncoder()`，将 `smooth` 参数保留为其默认值 `auto`。这样，变压器使用目标方差来确定概率混合的权重因子。使用
    `fit()`，变压器学习它应该用来替换类别的值，而使用 `transform()`，它替换了类别。
- en: Note that for `TargetEncoder()`, the `fit()` method followed by `transform()`
    do not return the same dataset as the `fit_transform()`method. The latter encodes
    the training set based on mappings found with cross-validation. The idea is to
    use `fit_transform()` within a pipeline, so the machine learning model does not
    overfit. However, and here is where it gets confusing, the mappings stored in
    the `encodings_` attribute are the same after `fit()` and `fit_transform()`, and
    this is done intentionally so that when we apply `transform()` to a new dataset,
    we obtain the same result regardless of whether we apply `fit()` or `fit_transform()`to
    the training set.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于`TargetEncoder()`，`fit()`方法后面跟`transform()`方法并不返回与`fit_transform()`方法相同的数据集。后者基于交叉验证找到的映射来编码训练集。想法是在管道中使用`fit_transform()`，这样机器学习模型就不会过拟合。然而，这里变得有些复杂，存储在`encodings_`属性中的映射在`fit()`和`fit_transform()`之后是相同的，这是故意为之，以便当我们将`transform()`应用于新数据集时，无论我们是否将`fit()`或`fit_transform()`应用于训练集，我们都会获得相同的结果。
- en: Note
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Unseen categories are encoded with the target mean by `scikit-learn`’s `TargetEncoder()`.
    `feature-engine`’s `MeanEncoder()` can either return an error, replace the unseen
    categories with `nan`, or with the target mean.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 未见过类别由`scikit-learn`的`TargetEncoder()`用目标均值进行编码。`feature-engine`的`MeanEncoder()`可以返回错误，用`nan`替换未见过类别，或者用目标均值替换。
- en: To perform the target encoding with `feature-engine`, we used `MeanEncoder(),`
    setting the `smoothing` parameter to `auto`. With `fit()`, the transformer found
    and stored the categorical variables and the values to encode each category. With
    `transform()`, it replaced the categories with numbers, returning `pandas` DataFrames.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`feature-engine`进行目标编码时，我们使用了`MeanEncoder()`，并将`smoothing`参数设置为`auto`。通过`fit()`方法，转换器找到了并存储了分类变量以及编码每个类别的值。通过`transform()`方法，它用数字替换了类别，返回`pandas`数据框。
- en: There’s more…
  id: totrans-441
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'If you want to implement target encoding with `pandas` or Category Encoders,
    check out the notebook in the accompanying GitHub repository: [https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-06-Target-mean-encoding.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-06-Target-mean-encoding.ipynb).'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用`pandas`或类别编码器实现目标编码，请查看随附GitHub仓库中的笔记本：[https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-06-Target-mean-encoding.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-06-Target-mean-encoding.ipynb)。
- en: 'There is an alternative way to return *better* target estimates when the category
    groups are small. The replacement value for each category is determined as follows:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 当类别组较小时，有一种替代方法可以返回*更好的*目标估计。每个类别的替换值确定如下：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mi>n</mi><mrow><mi>i</mi><mfenced
    open="(" close=")"><mrow><mi>Y</mi><mo>=</mo><mn>1</mn></mrow></mfenced></mrow></msub><mo>+</mo><mi>p</mi><mi>Y</mi><mi>x</mi><mi>m</mi></mrow><mrow><msub><mi>n</mi><mi>i</mi></msub><mo>+</mo><mi>m</mi></mrow></mfrac></mrow></mrow></math>](img/9.png)'
  id: totrans-444
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mi>n</mi><mrow><mi>i</mi><mfenced
    open="(" close=")"><mrow><mi>Y</mi><mo>=</mo><mn>1</mn></mrow></mfenced></mrow></msub><mo>+</mo><mi>p</mi><mi>Y</mi><mi>x</mi><mi>m</mi></mrow><mrow><msub><mi>n</mi><mi>i</mi></msub><mo>+</mo><mi>m</mi></mrow></mfrac></mrow></mrow></math>](img/9.png)'
- en: Here, ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>n</mi><mrow><mi>i</mi><mo>(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>)</mo></mrow></msub></mrow></math>](img/10.png)is
    the target mean for category *i* and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/11.png)
    is the number of observations with category *i*. The target prior is given by
    *pY* and *m* is the weighting factor. With this adjustment, the only parameter
    that we have to set is the weight, *m*. If *m* is large, then more importance
    is given to the target’s prior probability. This adjustment affects target estimates
    for all categories but mostly for those with fewer observations because, in such
    cases, *m* could be much larger than ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/12.png)
    in the formula’s denominator.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: This method is a good alternative to Category Encoders’ `TargetEncoder()` because,
    in Category Encoders’ implementation of target encoding, we need to optimize two
    parameters instead of one (as we did with `feature-engine` and `scikit-learn`)
    to control the smoothing.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: 'For an implementation of this encoding method using `MEstimateEncoder()`, visit
    this book’s GitHub repository: [https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-06-Target-mean-encoding.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-06-Target-mean-encoding.ipynb).'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: Encoding with Weight of Evidence
  id: totrans-449
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Weight of Evidence** (**WoE**) was developed primarily for credit and financial
    industries to facilitate variable screening and exploratory analysis and to build
    more predictive linear models to evaluate the risk of loan defaults.'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: 'The WoE is computed from the basic odds ratio:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>WoE</mi><mo>=</mo><mi>log</mi><mrow><mrow><mo>(</mo><mfrac><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>p</mi><mi>o</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>s</mi><mi>e</mi><mi>s</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>p</mi><mi>o</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>n</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>s</mi><mi>e</mi><mi>s</mi></mrow></mfrac><mo>)</mo></mrow></mrow></mrow></mrow></math>](img/13.png)'
  id: totrans-452
  prefs: []
  type: TYPE_IMG
- en: Here, positive and negative refer to the values of the target being *1* or *0*,
    respectively. The proportion of positive cases per category is determined as the
    sum of positive cases per category group divided by the total positive cases in
    the training set. The proportion of negative cases per category is determined
    as the sum of negative cases per category group divided by the total number of
    negative observations in the training set.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，正负分别指目标值的*1*或*0*，每个类别的正例比例是每个类别组正例总和除以训练集中正例总数。每个类别的负例比例是每个类别组负例总和除以训练集中负观察值的总数。
- en: 'WoE has the following characteristics:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: WOE具有以下特点：
- en: WoE = *0* if *p(positive)* / *p(negative)* = *1*; that is, if the outcome is
    random
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当*p(正面)* / *p(负面)* = *1*时，WOE = *0*；也就是说，如果结果是随机的。
- en: WoE > *0* if *p(positive)* > *p(negative)*
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当*p(正面)* > *p(负面)*时，WOE > *0*。
- en: WoE < *0* if *p(negative)* > *p(positive)*
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当*p(负面)* > *p(正面)*时，WOE < *0*。
- en: 'This allows us to directly visualize the predictive power of the category in
    the variable: the higher the WoE, the more likely the event will occur. If the
    WoE is positive, the event is likely to occur.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够直接可视化变量中类别的预测能力：WOE越高，事件发生的可能性越大。如果WOE为正，则事件很可能发生。
- en: 'Logistic regression models a binary response, *Y*, based on *X* predictor variables,
    assuming that there is a linear relationship between *X* and the log of odds of
    *Y*:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型基于预测变量*X*的二进制响应*Y*，假设*X*与*Y*的对数优势之间存在线性关系：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>log</mi><mfenced
    open="(" close=")"><mfrac><mrow><mi>p</mi><mfenced open="(" close=")"><mrow><mi>Y</mi><mo>=</mo><mn>1</mn></mrow></mfenced></mrow><mrow><mi>p</mi><mfenced
    open="(" close=")"><mrow><mi>Y</mi><mo>=</mo><mn>0</mn></mrow></mfenced></mrow></mfrac></mfenced><mo>=</mo><msub><mi>b</mi><mn>0</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><msub><mi>X</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub><msub><mi>X</mi><mn>2</mn></msub><mo>+</mo><mo>…</mo><mo>+</mo><msub><mi>b</mi><mi>n</mi></msub><msub><mi>X</mi><mi>n</mi></msub></mrow></mrow></math>](img/14.png)'
  id: totrans-460
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>log</mi><mfenced
    open="(" close=")"><mfrac><mrow><mi>p</mi><mfenced open="(" close=")"><mrow><mi>Y</mi><mo>=</mo><mn>1</mn></mrow></mfenced></mrow><mrow><mi>p</mi><mfenced
    open="(" close=")"><mrow><mi>Y</mi><mo>=</mo><mn>0</mn></mrow></mfenced></mrow></mfrac></mfenced><mo>=</mo><msub><mi>b</mi><mn>0</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><msub><mi>X</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub><msub><mi>X</mi><mn>2</mn></msub><mo>+</mo><mo>…</mo><mo>+</mo><msub><mi>b</mi><mi>n</mi></msub><msub><mi>X</mi><mi>n</mi></msub></mrow></mrow></math>](img/14.png)'
- en: Here, *log (p(Y=1)/p(Y=0))* is the log of odds. As you can see, the WoE encodes
    the categories in the same scale – that is, the log of odds – as the outcome of
    the logistic regression.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*log (p(Y=1)/p(Y=0))* 是优势比的对数。正如你所见，WOE将类别编码在相同的尺度上——即优势比的对数——与逻辑回归的结果相同。
- en: Therefore, by using WoE, the predictors are prepared and coded on the same scale,
    and the parameters in the logistic regression model – that is, the coefficients
    – can be directly compared.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过使用WOE，预测因子被准备并编码在同一尺度上，逻辑回归模型中的参数——即系数——可以直接比较。
- en: In this recipe, we will perform WoE encoding using `pandas` and `feature-engine`.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用`pandas`和`feature-engine`执行WOE编码。
- en: How to do it...
  id: totrans-464
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let’s begin by making some imports and preparing the data:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先进行一些导入和准备数据：
- en: 'Import the required libraries and functions:'
  id: totrans-466
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库和函数：
- en: '[PRE95]'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Let’s load the Credit Approval dataset and divide it into train and test sets:'
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载Credit Approval数据集并将其分为训练集和测试集：
- en: '[PRE96]'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Let’s get the inverse of the target values to be able to calculate the negative
    cases:'
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们获取目标值的逆，以便能够计算负例：
- en: '[PRE97]'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Let’s determine the number of observations where the target variable takes
    a value of `1` or `0`:'
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们确定目标变量取值为`1`或`0`的观测数：
- en: '[PRE98]'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Now, let’s calculate the numerator and denominator of the WoE’s formula, which
    we discussed earlier in this recipe:'
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们计算我们之前在本菜谱中讨论的WOE公式的分子和分母：
- en: '[PRE99]'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Now, let’s calculate the WoE per category:'
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们计算每个类别的WOE值：
- en: '[PRE100]'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'We can display the series with the category to WoE pairs by executing `print(woe)`:'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过执行`print(woe)`来显示具有类别到WOE对的序列：
- en: '[PRE101]'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: X_train_enc = X_train.copy()
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_train_enc = X_train.copy()
- en: X_test_enc = X_test.copy()
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_test_enc = X_test.copy()
- en: X_train_enc["A1"] = X_train_enc["A1"].map(woe)
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_train_enc["A1"] = X_train_enc["A1"].map(woe)
- en: X_test_enc["A1"] = X_test_enc["A1"].map(woe)
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: X_test_enc["A1"] = X_test_enc["A1"].map(woe)
- en: '[PRE102]'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Let’s import the encoder:'
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入编码器：
- en: '[PRE103]'
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'Next, let’s set up the encoder to encode three categorical variables:'
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们设置编码器以编码三个分类变量：
- en: '[PRE104]'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: Note
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For rare categories, it might happen that `p(0)=0` or `p(1)=0`, and then the
    division or the logarithm is not defined. To avoid this, group infrequent categories
    as shown in the *Grouping rare or infrequent* *categories* recipe.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 对于稀少类别，可能会发生`p(0)=0`或`p(1)=0`的情况，这时除法或对数没有定义。为了避免这种情况，请按照*分组稀少或不常见类别*食谱中的方法将不常见的类别分组。
- en: 'Let’s fit the transformer to the train set so that it learns and stores the
    WoE of the different categories:'
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将转换器拟合到训练集，以便它学习并存储不同类别的WoE：
- en: '[PRE105]'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: Note
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We can display the dictionaries with the categories to WoE pairs by executing
    `woe_enc.encoder_dict_`.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行`woe_enc.encoder_dict_`来显示具有类别到WoE对的字典。
- en: 'Finally, let’s encode the three categorical variables in the train and test
    sets:'
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们将训练集和测试集中的三个分类变量进行编码：
- en: '[PRE106]'
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '`feature-engine` returns `pandas` DataFrames, which contain the encoded categorical
    variables ready to use in machine learning models.'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature-engine`返回包含编码好的分类变量的`pandas` DataFrame，这些变量可以用于机器学习模型。'
- en: How it works...
  id: totrans-498
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we encoded categorical variables using the WoE with `pandas`
    and `feature-engine`.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们使用`pandas`和`feature-engine`对分类变量进行了WoE编码。
- en: We combined the use of `pandas`’ `sum()` and `groupby()` and `numpy`’s `log()`
    to determine the WoE as we described at the beginning of this recipe.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 我们结合了`pandas`的`sum()`和`groupby()`以及`numpy`的`log()`，正如我们在本食谱开头所描述的那样，来确定WoE。
- en: Next, we automated the procedure with `feature-engine`. We used the `WoEEncoder()`,
    which learned the WoE per category with the `fit()` method, and then used `transform()`
    to replace the categories with the corresponding numbers.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`feature-engine`自动化了该过程。我们使用了`WoEEncoder()`，它使用`fit()`方法学习每个类别的WoE，然后使用`transform()`将类别替换为相应的数字。
- en: See also
  id: totrans-502
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'For an implementation of WoE with Category Encoders, visit this book’s GitHub
    repository: [https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-07-Weight-of-evidence.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-07-Weight-of-evidence.ipynb).'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看使用类别编码器的WoE的实现，请访问本书的GitHub仓库：[https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-07-Weight-of-evidence.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch02-categorical-encoding/Recipe-07-Weight-of-evidence.ipynb)。
- en: Grouping rare or infrequent categories
  id: totrans-504
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分组稀少或不常见的类别
- en: Rare categories are those present only in a small fraction of the observations.
    There is no rule of thumb to determine how small a small fraction is, but typically,
    any value below 5% can be considered rare.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 稀少类别是指只存在于观测中一小部分的类别。没有规则可以确定多小可以被认为是小的，但通常，任何低于5%的值都可以被认为是稀少的。
- en: Infrequent labels often appear only on the train set or only on the test set,
    thus making the algorithms prone to overfitting or being unable to score an observation.
    In addition, when encoding categories to numbers, we only create mappings for
    those categories observed in the train set, so we won’t know how to encode new
    labels. To avoid these complications, we can group infrequent categories into
    a single category called `Rare` or `Other`.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 不常见的标签通常只出现在训练集或测试集中，这使得算法容易过拟合或无法评分观测。此外，当将类别编码为数字时，我们只为在训练集中观察到的类别创建映射，因此我们不知道如何编码新的标签。为了避免这些复杂性，我们可以将不常见的类别组合成一个称为`Rare`或`Other`的单个类别。
- en: In this recipe, we will group infrequent categories using `pandas` and `feature-engine`.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用`pandas`和`feature-engine`对不常见的类别进行分组。
- en: How to do it...
  id: totrans-508
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'First, let’s import the necessary Python libraries and get the dataset ready:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入必要的Python库并准备好数据集：
- en: 'Import the necessary Python libraries, functions, and classes:'
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的Python库、函数和类：
- en: '[PRE107]'
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'Let’s load the Credit Approval dataset and divide it into train and test sets:'
  id: totrans-512
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载Credit Approval数据集并将其分为训练集和测试集：
- en: '[PRE108]'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'Let’s capture the fraction of observations per category in `A7` in a variable:'
  id: totrans-514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在变量`A7`中捕获每个类别的观测比例：
- en: '[PRE109]'
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'We can see the percentage of observations per category of `A7`, expressed as
    decimals, in the following output after executing `print(freqs)`:'
  id: totrans-516
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在执行`print(freqs)`后，我们可以看到以下输出中`A7`每个类别的观测百分比，以小数表示：
- en: '[PRE110]'
  id: totrans-517
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'Let’s create a list containing the names of the categories present in more
    than 5% of the observations:'
  id: totrans-518
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个包含在超过5%的观测中存在的类别名称的列表：
- en: '[PRE111]'
  id: totrans-519
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'If we execute `print(frequent_cat)`, we will see the frequent categories of
    `A7`:'
  id: totrans-520
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE112]'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: X_train_enc = X_train.copy()
  id: totrans-522
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_test_enc = X_test.copy()
  id: totrans-523
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_train_enc["A7"] = np.where(X_train["A7"].isin(
  id: totrans-524
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: frequent_cat), X_train["A7"], "Rare")
  id: totrans-525
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: X_test_enc["A7"] = np.where(X_test["A7"].isin(
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: frequent_cat), X_test["A7"], "Rare")
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE113]'
  id: totrans-528
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Let’s determine the percentage of observations in the encoded variable:'
  id: totrans-529
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  id: totrans-530
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'We can see that the infrequent labels have now been re-grouped into the `Rare`
    category:'
  id: totrans-531
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE115]'
  id: totrans-532
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'Let’s create a rare label encoder that groups categories present in less than
    5% of the observations, provided that the categorical variable has more than four
    distinct values:'
  id: totrans-533
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  id: totrans-534
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'Let’s fit the encoder so that it finds the categorical variables and then learns
    their most frequent categories:'
  id: totrans-535
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  id: totrans-536
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: Note
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
- en: Upon fitting, the transformer will raise warnings, indicating that many categorical
    variables have less than four categories, thus their values will not be grouped.
    The transformer just lets you know that this is happening.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
- en: We can display the frequent categories per variable by executing `rare_encoder.encoder_dict_`,
    as well as the variables that will be encoded by executing `rare_encoder.variables_`.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s group rare labels in the train and test sets:'
  id: totrans-540
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  id: totrans-541
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: Now that we have grouped rare labels, we are ready to encode the categorical
    variables, as we’ve done in the previous recipes in this chapter.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-543
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we grouped infrequent categories using `pandas` and `feature-engine`.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
- en: We determined the fraction of observations per category of the `A7` variable
    using `pandas`’ `value_counts()` by setting the `normalize` parameter to `True`.
    Using list comprehension, we captured the names of the variables present in more
    than 5% of the observations. Finally, using NumPy’s `where()`, we searched each
    row of `A7`, and if the observation was one of the frequent categories in the
    list, which we checked using `pandas`’ `isin()`, its value was kept; otherwise,
    it was replaced with `Rare`.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
- en: We automated the preceding steps for multiple categorical variables using `feature-engine`’s
    `RareLabelEncoder()`. By setting `tol` to `0.05`, we retained categories present
    in more than 5% of the observations. By setting `n_categories` to `4`, we only
    grouped categories in variables with more than four unique values. With `fit()`,
    the transformer identified the categorical variables and then learned and stored
    their frequent categories. With `transform()`, the transformer replaced infrequent
    categories with the `Rare` string.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
- en: Performing binary encoding
  id: totrans-547
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`1` can be represented with the sequence of `1-0`, integer `2` with `0-1`,
    integer `3` with `1-1`, and integer `0` with `0-0`. The digits in the two positions
    of the binary string become the columns, which are the encoded representations
    of the original variable:'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – Table showing the steps required for binary encoding the color
    variable](img/B22396_02_10.jpg)'
  id: totrans-549
  prefs: []
  type: TYPE_IMG
- en: Figure 2.10 – Table showing the steps required for binary encoding the color
    variable
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
- en: Binary encoding encodes the data in fewer dimensions than one-hot encoding.
    In our example, the `Color` variable would be encoded into *k-1* categories by
    one-hot encoding – that is, three variables – but with binary encoding, we can
    represent the variable with only two features. More generally, we determine the
    number of binary features needed to encode a variable as *log2(number of distinct
    categories)*; in our example, *log2(4) = 2* binary features.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
- en: Binary encoding is an alternative method to one-hot encoding where we do not
    lose information about the variable, yet we obtain fewer features after the encoding.
    This is particularly useful when we have highly cardinal variables. For example,
    if a variable contains 128 unique categories, with one-hot encoding, we would
    need 127 features to encode the variable, whereas with binary encoding, we will
    only need *7 (log2(128)=7)*. Thus, this encoding prevents the feature space from
    exploding. In addition, binary-encoded features are also suitable for linear models.
    On the downside, the derived binary features lack human interpretability, so if
    we need to interpret the decisions made by our models, this encoding method may
    not be a suitable option.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to perform binary encoding using Category
    Encoders.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-554
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let’s import the necessary Python libraries and get the dataset ready:'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required Python libraries, functions, and classes:'
  id: totrans-556
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  id: totrans-557
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'Let’s load the Credit Approval dataset and divide it into train and test sets:'
  id: totrans-558
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'Let’s inspect the unique categories in `A7`:'
  id: totrans-560
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  id: totrans-561
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'In the following output, we can see that `A7` has 10 different categories:'
  id: totrans-562
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE122]'
  id: totrans-563
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: encoder = BinaryEncoder(cols=["A7"],
  id: totrans-564
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: drop_invariant=True)
  id: totrans-565
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE123]'
  id: totrans-566
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: Note
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
- en: '`BinaryEncoder()`, as well as other encoders from the Category Encoders package,
    allow us to select the variables to encode. We simply pass the column names in
    a list to the `cols` argument.'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s fit the transformer to the train set so that it calculates how many binary
    variables it needs and creates the variable-to-binary code representations:'
  id: totrans-569
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  id: totrans-570
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: 'Finally, let’s encode `A7` in the train and test sets:'
  id: totrans-571
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  id: totrans-572
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: 'We can display the top rows of the transformed train set by executing `print(X_train_enc.head())`,
    which returns the following output:'
  id: totrans-573
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.11 – DataFrame with the variables after binary encoding](img/B22396_02_11.jpg)'
  id: totrans-574
  prefs: []
  type: TYPE_IMG
- en: Figure 2.11 – DataFrame with the variables after binary encoding
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
- en: Binary encoding returned four binary variables for `A7`, which are `A7_0`, `A7_1`,
    `A7_2`, and `A7_3`, instead of the nine that would have been returned by one-hot
    encoding.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-577
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we performed binary encoding using the Category Encoders package.
    We used `BinaryEncoder()` to encode the `A7` variable. With the `fit()` method,
    `BinaryEncoder()` created a mapping from a category to a set of binary columns,
    and with the `transform()` method, the encoder encoded the `A7` variable in both
    the train and test sets.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们使用了Category Encoders包进行二进制编码。我们用`BinaryEncoder()`来编码`A7`变量。通过`fit()`方法，`BinaryEncoder()`创建了一个从类别到一组二进制列的映射，而通过`transform()`方法，编码器在训练集和测试集中对`A7`变量进行了编码。
