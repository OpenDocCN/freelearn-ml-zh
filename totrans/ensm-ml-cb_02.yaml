- en: Getting Started with Ensemble Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Max-voting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Averaging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weighted averaging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to ensemble machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Simply speaking, ensemble machine learning refers to a technique that integrates
    output from multiple learners and is applied to a dataset to make a prediction.
    These multiple learners are usually referred to as base learners. When multiple
    base models are used to extract predictions that are combined into one single
    prediction, that prediction is likely to provide better accuracy than individual
    base learners.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble models are known for providing an advantage over single models in terms
    of performance. They can be applied to both regression and classification problems.
    You can either decide to build ensemble models with algorithms from the same family
    or opt to pick them from different families. If multiple models are built on the
    same dataset using neural networks only, then that ensemble would be called a
    **homogeneous ensemble model**. If multiple models are built using different algorithms,
    such as **support vector machines** (**SVMs**), neural networks, and random forests,
    then the ensemble model would be called a **heterogeneous ensemble model**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The construction of an ensemble model requires two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Base learners are learners that are designed and fit on training data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The base learners are combined to form a single prediction model by using specific
    ensembling techniques such as max-voting, averaging, and weighted averaging
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following diagram shows the structure of the ensemble model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f805ffc2-b5f2-44a0-a330-a1e09b822eac.png)'
  prefs: []
  type: TYPE_IMG
- en: However, to get an ensemble model that performs well, the base learners themselves
    should be as accurate as possible. A common way to measure the performance of
    a model is to evaluate its generalization error. A generalization error is a term
    to measure how accurately a model is able to make a prediction, based on a new
    dataset that the model hasn't seen.
  prefs: []
  type: TYPE_NORMAL
- en: To perform well, the ensemble models require a sufficient amount of data. Ensemble
    techniques prove to be more useful when you have large and non-linear datasets.
  prefs: []
  type: TYPE_NORMAL
- en: An ensemble model may overfit if too many models are included, although this
    isn't very common.
  prefs: []
  type: TYPE_NORMAL
- en: Irrespective of how well you fine-tune your models, there's always the risk
    of high bias or high variance. Even the best model can fail if the bias and variance
    aren't taken into account while training the model. Both bias and variance represent
    a kind of error in the predictions. In fact, the total error is comprised of bias-related
    error, variance-related error, and unavoidable noise-related error (or irreducible
    error). The noise-related error is mainly due to noise in the training data and
    can't be removed. However, the errors due to bias and variance can be reduced.
  prefs: []
  type: TYPE_NORMAL
- en: 'The total error can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'A measure such as **mean square error** (**MSE**) captures all of these errors
    for a continuous target variable and can be represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/89f95d7f-2f1e-4f9e-b2c4-3eda6906ffb2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this formula, *E* stands for the expected mean, *Y* represents the actual
    target values and ![](img/9e4b0739-22af-4cc1-816a-a36dd771abf2.png) is the predicted
    values for the target variable. It can be broken down into its components such
    as bias, variance and noise as shown in the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/21b41a6e-ac17-4354-ae2b-daea48ef913e.png)'
  prefs: []
  type: TYPE_IMG
- en: While bias refers to how close is the ground truth to the expected value of
    our estimate, the variance, on the other hand, measures the deviation from the
    expected estimator value. Estimators with small MSE is what is desirable. In order
    to minimize the MSE error, we would like to be centered (0-bias) at ground truth
    and have a low deviation (low variance) from the ground truth (correct) value.
    In other words, we'd like to be confident (low variance, low uncertainty, more
    peaked distribution) about the value of our estimate. High bias degrades the performance
    of the algorithm on the training dataset and leads to underfitting. High variance,
    on the other hand, is characterized by low training errors and high validation
    errors. Having high variance reduces the performance of the learners on unseen
    data, leading to overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble models can reduce bias and/or variance in the models.
  prefs: []
  type: TYPE_NORMAL
- en: Max-voting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Max-voting, which is generally used for classification problems, is one of the
    simplest ways of combining predictions from multiple machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: In max-voting, each base model makes a prediction and votes for each sample.
    Only the sample class with the highest votes is included in the final predictive
    class.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's say we have an online survey, in which consumers answer a
    question in a five-level Likert scale. We can assume that a few consumers will
    provide a rating of five, while others will provide a rating of four, and so on.
    If a majority, say more than 50% of the consumers, provide a rating of four, then
    the final rating is taken as four. In this example, taking the final rating as
    four is similar to taking a mode for all of the ratings.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps we will download the following packages:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, import the `os` and `pandas` packages and set your working directory
    according to your requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Download the `Cryotherapy.csv` dataset from GitHub and copy it to your working
    directory. Read the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the data with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the data has been read properly and has the `Result_of_Treatment` class
    variable. We then move on to creating models with `Result_of_Treatment` as the
    response variable.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can create a voting ensemble model for a classification problem using the
    `VotingClassifier` class from Python''s `scikit-learn` library. The following
    steps showcase an example of how to combine the predictions of the decision tree,
    SVMs, and logistic regression models for a classification problem:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required libraries for building the decision tree, SVM, and logistic
    regression models. We also import `VotingClassifier` for max-voting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We then move on to building our feature set and creating our train and test
    datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We build our models with the decision tree, SVM, and logistic regression algorithms:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We build individual models with each of the classifiers we''ve chosen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then see the accuracy score of each of the individual base learners:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8525dd2f-69c0-494d-b766-f40177dc16d2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We proceed to ensemble our models and use `VotingClassifier` to score the accuracy
    of the ensemble model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the accuracy score of the ensemble model using `Hard Voting`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7cfc6f63-ea79-42d0-93f7-ae8601618f96.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`VotingClassifier` implements two types of voting—**hard** and **soft** voting.
    In hard voting, the final class label is predicted as the class label that has
    been predicted most frequently by the classification models. In other words, the
    predictions from all classifiers are aggregated to predict the class that gets
    the most votes. In simple terms, it takes the mode of the predicted class labels.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In hard voting for the class labels, ![](img/cdcf3a61-7859-4677-ae40-0ad28f93b20b.png) is
    the prediction based on the majority voting of each classifier ![](img/14f699f6-50a7-48d2-9954-00f6f3b93265.png),
    where *i=1.....n* observations, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06173c0a-41c4-4350-b2ec-d5bcfa423a2d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As shown in the previous section, we have three models, one from the decision tree,
    one from the SVMs, and one from logistic regression. Let''s say that the models
    classify a training observation as class 1, class 0, and class 1 respectively.
    Then with majority voting, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9957aac7-8217-431a-8822-5a4e87bea84c.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, we would classify the observation as class 1.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding section, in* Step 1*, we imported the required libraries to
    build our models. In *Step 2*, we created our feature set. We also split our data
    to create the training and testing samples. In *Step 3*, we trained three models
    with the decision tree, SVMs, and logistic regression respectively. In *Step 4*,
    we looked at the accuracy score of each of the base learners, while in *Step 5*,
    we ensembled the models using `VotingClassifier()` and looked at the accuracy
    score of the ensemble model.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many classifiers can estimate class probabilities. In this case, the class labels
    are predicted by averaging the class probabilities. This is called **soft voting** and is
    recommended for an ensemble of well-tuned classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: In the `scikit-learn` library, many classification algorithms have the `predict_proba()`
    method to predict the class probabilities. To perform the ensemble with soft voting,
    simply replace `voting='hard'` with `voting='soft'` in `VotingClassifier()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code creates an ensemble using soft voting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We get to see the accuracy from individual learners and the ensemble learner
    using soft voting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e5c04d3c-702b-4e19-9e34-631718d46d9e.png)'
  prefs: []
  type: TYPE_IMG
- en: The `SVC` class can't estimate class probabilities by default, so we've set
    its probability hyper-parameter to `True` in the preceding code. With `probability=True`,
    `SVC` will be able to estimate class probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Averaging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Averaging is usually used for regression problems or can be used while estimating
    the probabilities in classification tasks. Predictions are extracted from multiple
    models and an average of the predictions are used to make the final prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let us get ready to build multiple learners and see how to implement averaging:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the `whitewines.csv` dataset from GitHub and copy it to your working
    directory, and let''s read the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at the data with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following screenshot, we can see that the data has been read properly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f3e9bfa0-d5c9-4605-b4bd-133db9ca6cc4.png)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have a dataset that is based on the properties of wines. Using this dataset,
    we''ll build multiple regression models with the quality as our response variable.
    With multiple learners, we extract multiple predictions. The averaging technique
    would take the average of all of the predicted values for each training sample:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the response and feature sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Split the data into training and testing sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the base regression learners using linear regression, `SVR`, and a decision
    tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the base learners to make a prediction based on the test data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the predictions and divide by the number of base learners:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Step 1*, we imported the required packages. In *Step 2*, we separated the
    feature set and the response variable from our dataset. We split our dataset into
    training and testing samples in *Step 3*.
  prefs: []
  type: TYPE_NORMAL
- en: Note that our response variable is continuous in nature. For this reason, we
    built our regression base learners in *Step 4* using linear regression, `SVR`,
    and a decision tree. In *Step 5*, we passed our test dataset to the `predict()`
    function to predict our response variable. And finally, in *Step 6*, we added
    all of the predictions together and divided them by the number of base learners,
    which is three in our example.
  prefs: []
  type: TYPE_NORMAL
- en: Weighted averaging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like averaging, weighted averaging is also used for regression tasks. Alternatively,
    it can be used while estimating probabilities in classification problems. Base
    learners are assigned different weights, which represent the importance of each
    model in the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: A weight-averaged model should always be at least as good as your best model.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Download the `wisc_bc_data.csv` dataset from GitHub and copy it to your working
    directory. Let''s read the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the data with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that the data has been read properly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2cc3ae34-687d-4175-a392-89311304bed7.png)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we have a dataset based on the properties of cancerous tumors. Using this
    dataset, we'll build multiple classification models with `diagnosis` as our response
    variable. The diagnosis variable has the values, `B` and `M`, which indicate whether
    the tumor is benign or malignant. With multiple learners, we extract multiple
    predictions. The weighted averaging technique takes the average of all of the
    predicted values for each training sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we consider the predicted probabilities as the output and
    use the `predict_proba()` function of the scikit-learn algorithms to predict the
    class probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the response and feature sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We retrieved the feature columns using the `iloc()` function of the `pandas`
    DataFrame, which is purely integer-location based indexing for selection by position. The
    `iloc()` function takes row and column selection as its parameter, in the form: `data.iloc(<row
    selection>, <column selection>)`. The row and column selection can either be an
    integer list or a slice of rows and columns. For example, it might look as follows:
    `df_cancerdata.iloc(2:100, 2:30)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll then split our data into training and testing sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the base classifier models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Fit the models on the test data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `predict_proba()` function to predict the class probabilities:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Assign different weights to each of the models to get our final predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Step **1*, we imported the libraries that are required to build our models.
    In *Step 2*, we created the response and feature sets. We retrieved our feature
    set using the `iloc()` function of the `pandas` DataFrame. In *Step 3*, we split
    our dataset into training and testing sets. In *Step 4*, we built our base classifiers.
    Kindly note that we passed `probability=True` to our `SVC` function to allow `SVC()`
    to return class probabilities. In the `SVC` class, the default is `probability=False`.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 5*, we fitted our model to the training data. We used the `predict_proba()`
    function in *Step 6* to predict the class probabilities for our test observations.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in *Step 7*, we assigned different weights to each of our models to
    estimate the weighted average predictions. The question that comes up is how to
    choose the weights. One way is to sample the weights uniformly and to make sure
    they normalize to one and validate on the test set and repeat keeping track of
    weights that provide the highest accuracy. This is an example of a random search.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the scikit reference links:'
  prefs: []
  type: TYPE_NORMAL
- en: Scikit guide to ensemble methods [(https://bit.ly/2oVNogs)](https://bit.ly/2oVNogs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scikit guide to `VotingClassifier` [(https://bit.ly/2oW0avo)](https://bit.ly/2oW0avo)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
