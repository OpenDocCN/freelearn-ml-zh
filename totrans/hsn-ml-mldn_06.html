<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Classification Model</h1>
                </header>
            
            <article>
                
<p><span>With regression models behind us, it is now time to dive into classification models. In this chapter, we will examine the math behind classification models, as well as the various applications of classification models. In addition, we will build two new ML.NET classification applications: the first, a binary classification example that will predict if a car's price is a good deal or not, akin to what you would find on a car purchase website; the other application, a multi-class classification application that categorizes emails. Finally, we will explore how to evaluate a classification model with the properties ML.NET exposes in classification models.</span></p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Breaking down classification models</li>
<li>Creating a binary classification application</li>
<li>Creating a multi-class classification application</li>
<li>Evaluating a classification model</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Breaking down classification models</h1>
                </header>
            
            <article>
                
<p>As mentioned in <a href="b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml">Chapter 1</a>, <em>Getting Started with Machine Learning and ML.NET</em>, classification is broken down into two main categories—two-class and multi-class. In a two-class classifier, also known as a binary classifier, the prediction simply returns 0 or 1. In a multi-class problem, a pre-selected range of return labels, such as virus types or car types, is returned.  </p>
<p>There are several binary classification model types available in the machine learning ecosystem to choose from, as follows:</p>
<ul>
<li><kbd>AveragedPerceptronTrainer</kbd></li>
<li><kbd>SdcaLogisticRegressionBinaryTrainer</kbd></li>
<li><kbd>SdcaNonCalibratedBinaryTrainer</kbd></li>
</ul>
<ul>
<li><kbd>SymbolicSgdLogisticRegressionBinaryTrainer</kbd></li>
<li><kbd>LbfgsLogisticRegressionBinaryTrainer</kbd></li>
<li><kbd>LightGbmBinaryTrainer</kbd></li>
<li><kbd>FastTreeBinaryTrainer</kbd></li>
<li><kbd>FastForestBinaryTrainer</kbd></li>
<li><kbd>GamBinaryTrainer</kbd></li>
<li><kbd>FieldAwareFactorizationMachineTrainer</kbd></li>
<li><kbd>PriorTrainer</kbd></li>
<li><kbd>LinearSvmTrainer</kbd></li>
</ul>
<p>The car-value application we will be creating later in this chapter utilizes the <kbd>FastTreeBinaryTrainer</kbd> model.</p>
<p>ML.NET also provides the following multi-class classifiers:</p>
<ul>
<li><kbd>LightGbmMulticlassTrainer</kbd></li>
<li><kbd>SdcaMaximumEntropyMulticlassTrainer</kbd></li>
<li><kbd>SdcaNonCalibratedMulticlassTrainer</kbd></li>
<li><kbd>LbfgsMaximumEntropyMulticlassTrainer</kbd></li>
<li><kbd>NaiveBayesMulticlassTrainer</kbd></li>
<li><kbd>OneVersusAllTrainer</kbd></li>
<li><kbd>PairwiseCouplingTrainer</kbd></li>
</ul>
<p>For the multi-class classifier example application, we will be using the <kbd>SdcaMaximumEntropyMulticlassTrainer</kbd> model. The reason for this is that <strong>Stochastic Dual Coordinate Ascents</strong> (<strong>SDCAs</strong>) can provide a good default performance without tuning.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Choosing a classification trainer</h1>
                </header>
            
            <article>
                
<p>Given the two types of classification, which should you choose? As stated earlier in this chapter, compared to regression models, your prediction output type will decide between binary and multi-class classification. Does your problem simply predict a value of true or false, or does it provide a more varied output based on a pre-defined value set? If your answer is the former, you need to use a binary classification. If the latter, you will need to use a multi-class classification. In this chapter, we will demonstrate both model prediction types.</p>
<p>For specific binary classification trainers, SDCA, LightGBM, and FastTree are the most popular options, as well as the most documented.</p>
<p>For specific multi-class classification trainers, LightGBM and SDCA are the most popular and best-documented options. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a binary classification application</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, the application we will be creating is a car-value predictor. Given a set of attributes tied to a car, one can predict if the price is a good deal or not. The attributes included in this example aren't a definitive list of attributes, nor should they be used as-is in a production environment. However, one could use this as a starting point for predicting a simple true-or-false answer based on several attributes.</p>
<p>As with previous chapters, the complete project code, sample dataset, and project files can be downloaded here: <a href="https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter04">https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter04</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Diving into the trainer</h1>
                </header>
            
            <article>
                
<p>As previously mentioned, for this binary classification application, we will be using the FastTree trainer.   </p>
<p>FastTree is based on the <strong>Multiple Additive Regression Trees</strong> (<strong>MART</strong>) gradient boosting algorithm. Gradient boosting is a very popular technique, in which a series of trees are built in a step-wise manner before ultimately selecting the best tree. MART takes this approach a step further by learning an ensemble of regression trees that use scalar values in their leaves.</p>
<p>The FastTree trainer doesn't require normalization but does require all of the feature columns to use a <kbd>float</kbd> variable type and the label column to be a <kbd>bool</kbd> variable type.</p>
<div class="packt_tip">If you are curious about MART, Cornell University has a paper from 2015 on the subject: <a href="https://arxiv.org/abs/1505.01866.">https://arxiv.org/abs/1505.01866</a>.<a href="https://arxiv.org/abs/1505.01866."/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring the project architecture</h1>
                </header>
            
            <article>
                
<p>Building on the project architecture and code we created in <a href="8bcfc000-9adc-4eda-a91a-e09f676eac85.xhtml">Chapter 3</a>, <em>Regression Model</em>, the major change architecturally in this example is the mechanism for input. For this application, since we are using the FastTree algorithm, this requires referencing the <kbd>Microsoft.ML.FastTree</kbd> NuGet package (version 1.3.1 is the latest at the time of this writing).<strong> </strong>If you are building this project from scratch and do not remember how to add a NuGet reference, please refer back to <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter <span><span>2</span></span></a>, <em>Setting Up the ML.NET Environment</em>. </p>
<p>In the following screenshot, you will find the Visual Studio Solution Explorer view of the project. The new addition to the solution is the <kbd>testdata.csv</kbd> file, which we will review here:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/68e93a35-367b-4d5d-a63d-6e0dad029632.png" style="width:22.00em;height:30.58em;"/></p>
<p>The <kbd>sampledata.csv</kbd> file contains 18 rows of random data. Feel free to adjust the data to fit your own observations or to adjust the trained model. Here is a snippet of the data:</p>
<div>
<pre>0,0,0,4000,0<br/>1,1,1,4500,1<br/>0,1,0,5000,0<br/>0,0,1,4500,0<br/>0,0,0,3000,1<br/>0,1,0,3100,1<br/>0,1,1,3500,1<br/>1,1,1,5500,0<br/>1,1,1,4200,1</pre></div>
<p>Each of these rows contains the value for the properties in the newly created <kbd>CarInventory</kbd> class that we will review later on in this chapter.</p>
<p>In addition, in this chapter, we added the <kbd>testdata.csv</kbd> file that contains additional data points to test the newly trained model against and evaluate. Here is a snippet of the data inside of <kbd>testdata.csv</kbd>:</p>
<pre>0,0,0,2010,1<br/>1,0,0,2600,1<br/>1,0,0,3700,0<br/>1,1,0,3100,1<br/>1,1,0,3600,0<br/>0,1,0,3500,0<br/>0,0,1,3400,1<br/>0,0,1,5100,0</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Diving into the code</h1>
                </header>
            
            <article>
                
<p>For this application, as noted in the previous section, we are building on top of the work completed in <a href="8bcfc000-9adc-4eda-a91a-e09f676eac85.xhtml">Chapter 3</a>, <em>Regression Model</em>. For this deep dive, we are going to focus solely on the code that was changed for this application.</p>
<p>Classes that were changed or added are as follows:</p>
<ul>
<li><kbd>CarInventory</kbd></li>
<li><kbd>CarInventoryPrediction</kbd></li>
<li><kbd>Predictor</kbd></li>
<li><kbd>Trainer</kbd></li>
<li><kbd>Program</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The CarInventory class</h1>
                </header>
            
            <article>
                
<p>The <kbd>CarInventory</kbd> class is the container class that contains the data to both predict and train our model. These columns map in order of the sample data reviewed previously. If you begin experimenting with new features and add to the following class, ensure you increment the array index appropriately, as follows:</p>
<div>
<pre>using Microsoft.ML.Data;<br/><br/>namespace chapter04.ML.Objects<br/>{<br/>    public class CarInventory<br/>    {<br/>        [LoadColumn(0)]<br/>        public float HasSunroof { get; set; }<br/><br/>        [LoadColumn(1)]<br/>        public float HasAC { get; set; }<br/><br/>        [LoadColumn(2)]<br/>        public float HasAutomaticTransmission { get; set; }<br/><br/>        [LoadColumn(3)]<br/>        public float Amount { get; set; }<br/><br/>        [LoadColumn(4)]<br/>        public bool Label { get; set; }<br/>    }<br/>}</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The CarInventoryPrediction class</h1>
                </header>
            
            <article>
                
<p>The <kbd>CarInventoryPrediction</kbd> class contains the properties mapped to our prediction output, in addition to the <kbd>Score</kbd> and <kbd>Probability</kbd> properties used for model evaluation. The <kbd>PredictedLabel</kbd> property contains our classification result, not the label as in previous chapters, as shown in the following code block:</p>
<div>
<pre>namespace chapter04.ML.Objects<br/>{<br/>    public class CarInventoryPrediction<br/>    {<br/>        public bool Label { get; set; }<br/><br/>        public bool PredictedLabel { get; set; }<br/><br/>        public float Score { get; set; }<br/><br/>        public float Probability { get; set; }<br/>    }<br/>}</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Predictor class</h1>
                </header>
            
            <article>
                
<p>There are a couple of changes in this class to handle the employment-prediction scenario, as follows:</p>
<ol>
<li>The first <span>change is in the prediction call itself. As you probably guessed, the <kbd>TSrc</kbd> and <kbd>TDst</kbd> arguments need to be adjusted to utilize both of the new classes we created, <kbd>CarInventory</kbd> and <kbd>CarInventoryPrediction</kbd></span>, like this:</li>
</ol>
<div>
<pre style="padding-left: 60px">var predictionEngine = MlContext.Model.CreatePredictionEngine&lt;CarInventory, CarInventoryPrediction&gt;(mlModel);            </pre></div>
<ol start="2">
<li>Given that we are no longer simply passing in the string and building an object on the fly, we need to first read in the file as text. We then deserialize the JSON into our <kbd>CarInventory</kbd><strong> </strong>object, as follows:</li>
</ol>
<div>
<pre style="padding-left: 60px">var prediction = predictionEngine.Predict(JsonConvert.DeserializeObject&lt;CarInventory&gt;(json));</pre></div>
<ol start="3">
<li>L<span>astly, we need to adjust the output of our prediction to match our new </span><kbd>CarInventoryPrediction</kbd><strong> </strong><span>properties, like this:</span></li>
</ol>
<div>
<pre style="padding-left: 60px">Console.WriteLine(<br/>    $"Based on input json:{System.Environment.NewLine}" +<br/>    $"{json}{System.Environment.NewLine}" + <br/>    $"The car price is a {(prediction.PredictedLabel ? "good" : "bad")} deal, with a {prediction.Probability:P0} confidence");</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Trainer class</h1>
                </header>
            
            <article>
                
<p>Inside the <kbd>Trainer</kbd> class, several modifications need to be made to support binary classification, as follows:</p>
<ol>
<li>The first change is the check to ensure the test filename exists, shown in the following code block:</li>
</ol>
<div>
<pre style="padding-left: 60px">if (!File.Exists(testFileName))<br/>{<br/>    Console.WriteLine($"Failed to find test data file ({testFileName}");<br/>    <br/>    return;<br/>}</pre></div>
<ol start="2">
<li>We then build the data process pipeline using the <kbd>NormalizeMeanVariance</kbd> transform method we used in <a href="8bcfc000-9adc-4eda-a91a-e09f676eac85.xhtml">Chapter 3</a>, <em>Regression Model</em>,<strong> </strong>on the inputted values, like this:</li>
</ol>
<div>
<pre style="padding-left: 60px">IEstimator&lt;ITransformer&gt; dataProcessPipeline = MlContext.Transforms.Concatenate("Features",<br/> typeof(CarInventory).ToPropertyList&lt;CarInventory&gt;(nameof(CarInventory.Label)))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(inputColumnName: "Features",<br/> outputColumnName: "FeaturesNormalizedByMeanVar"));</pre></div>
<ol start="3">
<li>We can then create the <kbd>FastTree</kbd> trainer with the label from the <kbd>CarInventory</kbd> class and the normalized mean variance, as follows:</li>
</ol>
<div>
<pre style="padding-left: 60px">var trainer = MlContext.BinaryClassification.Trainers.FastTree(<br/>    labelColumnName: nameof(CarInventory.Label),<br/>    featureColumnName: "FeaturesNormalizedByMeanVar",<br/>    numberOfLeaves: 2,<br/>    numberOfTrees: 1000,<br/>    minimumExampleCountPerLeaf: 1,<br/>    learningRate: 0.2);</pre></div>
<div class="packt_tip">Later on, after you have run the application, consider tweaking the number of leaves and the number of trees to see how both the model metrics and your prediction probability percentage change.</div>
<ol start="4">
<li>Lastly, we call the <kbd>Regression.Evaluate</kbd> method to provide regression-specific metrics, followed by a <kbd>Console.WriteLine</kbd> call to provide these metrics to your console output. We will go into detail about what each of these means in the last section of the chapter, but for now, the code can be seen here:</li>
</ol>
<pre style="padding-left: 60px">var trainingPipeline = dataProcessPipeline.Append(trainer);<br/><br/>var trainedModel = trainingPipeline.Fit(trainingDataView);<br/><br/>MlContext.Model.Save(trainedModel, trainingDataView.Schema, ModelPath);</pre>
<p style="padding-left: 60px">Now, we evaluate the model we just trained, like this:</p>
<pre style="padding-left: 60px">var evaluationPipeline = trainedModel.Append(MlContext.Transforms<br/> .CalculateFeatureContribution(trainedModel.LastTransformer)<br/> .Fit(dataProcessPipeline.Fit(trainingDataView).Transform(trainingDataView)));<br/><br/>var testDataView = MlContext.Data.LoadFromTextFile&lt;CarInventory&gt;(testFileName, ',', hasHeader: false);<br/><br/>var testSetTransform = evaluationPipeline.Transform(testDataView);<br/><br/>var modelMetrics = MlContext.BinaryClassification.Evaluate(data: testSetTransform,<br/> labelColumnName: nameof(CarInventory.Label),<br/> scoreColumnName: "Score");</pre>
<p style="padding-left: 60px">Finally, we output all of the classification metrics. We will detail each of these in the next section, but for now, the code can be seen here:</p>
<pre style="padding-left: 60px">Console.WriteLine($"Accuracy: {modelMetrics.Accuracy:P2}");<br/>Console.WriteLine($"Area Under Curve: {modelMetrics.AreaUnderRocCurve:P2}");<br/>Console.WriteLine($"Area under Precision recall Curve: {modelMetrics.AreaUnderPrecisionRecallCurve:P2}");<br/>Console.WriteLine($"F1Score: {modelMetrics.F1Score:P2}");<br/>Console.WriteLine($"LogLoss: {modelMetrics.LogLoss:#.##}");<br/>Console.WriteLine($"LogLossReduction: {modelMetrics.LogLossReduction:#.##}");<br/>Console.WriteLine($"PositivePrecision: {modelMetrics.PositivePrecision:#.##}");<br/>Console.WriteLine($"PositiveRecall: {modelMetrics.PositiveRecall:#.##}");<br/>Console.WriteLine($"NegativePrecision: {modelMetrics.NegativePrecision:#.##}");<br/>Console.WriteLine($"NegativeRecall: {modelMetrics.NegativeRecall:P2}");</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Program class</h1>
                </header>
            
            <article>
                
<p>The only change in the <kbd>Program</kbd> class is the help text to indicate usage for the trainer to accept the test file, shown in the following code block:</p>
<pre>if (args.Length &lt; 2)<br/>{<br/>    Console.WriteLine($"Invalid arguments passed in, exiting.{Environment.NewLine}        {Environment.NewLine}Usage:{Environment.NewLine}" +<br/> $"predict &lt;path to input json file&gt;{Environment.NewLine}" +<br/> $"or {Environment.NewLine}" +<br/> $"train &lt;path to training data file&gt; &lt;path to test data file&gt;{Environment.NewLine}");<br/><br/>    return;<br/>}</pre>
<p>Finally, we modify the <kbd>switch</kbd>/<kbd>case</kbd> statement to support the additional parameter to the <kbd>Train</kbd> method, as follows:</p>
<pre>switch (args[0])<br/>{<br/>    case "predict":<br/>        new Predictor().Predict(args[1]);<br/>        break;<br/>    case "train":<br/>        new Trainer().Train(args[1], args[2]);<br/>        break;<br/>    default:<br/>        Console.WriteLine($"{args[0]} is an invalid option");<br/>        break;<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the application</h1>
                </header>
            
            <article>
                
<p><span>To run the application, the process is nearly identical to the sample application in <a href="8bcfc000-9adc-4eda-a91a-e09f676eac85.xhtml">Chapter 3</a>, <em>Regression Model</em>, with the addition of passing in the test dataset when training, described as follows:</span></p>
<ol>
<li>To run the training on the command line, as we did in <a href="b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml">Chapter 1</a>, <em>Getting Started with Machine Learning and ML.NET</em>, we simply pass in the following command (assuming you are using the included sample dataset and test dataset):</li>
</ol>
<div>
<pre style="padding-left: 60px"><strong>PS chapter04\bin\Debug\netcoreapp3.0&gt; .\chapter04.exe train ..\..\..\Data\sampledata.csv ..\..\..\Data\testdata.csv</strong><br/>Accuracy: 88.89%<br/>Area Under Curve: 100.00%<br/>Area under Precision recall Curve: 100.00%<br/>F1Score: 87.50%<br/>LogLoss: 2.19<br/>LogLossReduction: -1.19<br/>PositivePrecision: 1<br/>PositiveRecall: .78<br/>NegativePrecision: .82<br/>NegativeRecall: 100.00%</pre></div>
<p style="padding-left: 60px">Note the expanded output to include several metric data points—we will go through what each one of these means at the end of this chapter.</p>
<ol start="2">
<li>After training the model, build a sample JSON file and save it as <kbd>input.json</kbd>, as follows:</li>
</ol>
<div>
<pre style="padding-left: 60px">{<br/>    "HasSunroof":0,<br/>    "HasAC":0,<br/>    "HasAutomaticTransmission":0,<br/>    "Amount":1300<br/>}</pre></div>
<ol start="3">
<li>To run the model with this file, simply pass in the filename to the built application, and the predicted output will appear, as follows:</li>
</ol>
<div>
<pre style="padding-left: 60px"><strong>PS chapter04\bin\Debug\netcoreapp3.0&gt; .\chapter04.exe predict .\input.json</strong><br/>Based on input json:<br/>{<br/>"HasSunroof":0,"HasAC":0,"HasAutomaticTransmission":0,"Amount":1300<br/>}<br/>The car price is a good deal, with a 100% confidence</pre></div>
<p style="padding-left: 60px">Feel free to modify the values and see how the prediction changes based on the dataset on which the model was trained. A few areas of experimentation from this point might be as follows:</p>
<ul>
<li style="padding-left: 60px">Add some additional features based on your own car-buying experiences</li>
<li style="padding-left: 60px">Modify the <kbd>sampledata.csv</kbd> file to include your own car-buying experiences</li>
<li style="padding-left: 60px">Modify the sample application to have a <strong>graphical user interface</strong> (<strong>GUI</strong>) to make running predictions easier</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a multi-class classification application</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, we will now create a multi-class classification application, categorizing email into one of three categories:</p>
<ul>
<li>Orders</li>
<li>Spam</li>
<li>Friend</li>
</ul>
<p>Flushing out this example for a production application would more than likely include significantly more categories in addition to more features. However, this is a good starting point to demonstrate a multi-class classification use case.</p>
<p><span>As with other examples</span><span>, the complete project code, sample dataset, and project files can be downloaded here: </span><a href="https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter04-multiclass">https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter04-multiclass</a><span>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Diving into the trainer</h1>
                </header>
            
            <article>
                
<p>As previously mentioned, for this multi-class classification application we will be using the <kbd>SdcaMaximumEntropy</kbd> trainer.   </p>
<p>The <span><kbd>SdcaMaximumEntropy</kbd> class, as the name implies, is based on the SDCA we deep dove into in</span> <a href="8bcfc000-9adc-4eda-a91a-e09f676eac85.xhtml">Chapter 3</a>, <em>Regression Model</em>, <span>and uses empirical risk minimization, which optimizes based on the training data. This does leave a potential for outliers or anomalies to greatly affect the predict performance. Therefore, when using this trainer, provide the trainer with ample sampling of expected data, to avoid both overfitting and potential errors when predicting data.</span></p>
<p>The <span><kbd>SdcaMaximumEntropy</kbd> </span>trainer, unlike the previous binary classification example, does require normalization. In addition, caching is not required; however, we do utilize caching when building the pipeline.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring the project architecture</h1>
                </header>
            
            <article>
                
<p>Building on the project architecture and code created earlier in this chapter, there are no new NuGet packages to include in this project, as SDCA trainers are considered core trainers. The major change is in the <kbd>Training</kbd> pipeline, which we will go into in further detail later on in this section. </p>
<p>In the following screenshot, you will find the Visual Studio Solution Explorer view of the project:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7df2ac8b-d10d-460b-9d8a-5cfde49e58b6.png" style="width:19.42em;height:24.83em;"/></p>
<p>The <kbd>sampledata.csv</kbd> file contains six rows of random data. Feel free to adjust the data to fit your own observations or to adjust the trained model. Here is a snippet of the data:</p>
<div>
<pre>"Order #1234","Thank you for ordering a new CPU","order@cpulandia.com","orders"<br/>"Get Free Free","Click here for everything free","freefree@asasdasd.com","spam"<br/>"Checking in","How is it going?","johndough@gmail.com","friend"<br/>"Order 4444","Thank you for ordering a pizza","order@pizzalandia.com","orders"<br/>"Unlock Free","Click here to unlock your spam","spammer@asasdasd.com","spam"<br/>"Hello","Did you see my last message?","janedough@gmail.com","friend"</pre></div>
<p>Each of these rows contains the value for the properties in the newly created <kbd>Email</kbd> class that we will review later on in this chapter.</p>
<p>In addition, in this chapter, we added the <kbd>testdata.csv</kbd> file that contains additional data points to test the newly trained model against. Here is a snippet of the data:</p>
<pre>"Order 955","Thank you for ordering a new gpu","order@gpulandia.com","orders"<br/>"Win Free Money","Lottery winner, click here","nowfree@asasdasd.com","spam"<br/>"Yo","Hey man?","john@gmail.com","friend"</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Diving into the code</h1>
                </header>
            
            <article>
                
<p>For this application, as noted earlier, we are building on top of the work completed in <a href="8bcfc000-9adc-4eda-a91a-e09f676eac85.xhtml">Chapter 3</a>, <em>Regression Model</em>. For this deep dive, we are going to focus solely on the code that was changed for this application.</p>
<p>Classes that were changed or added are as follows:</p>
<ul>
<li><kbd>Email</kbd></li>
<li><kbd>EmailPrediction</kbd></li>
<li><kbd>Predictor</kbd></li>
<li><kbd>Trainer</kbd></li>
<li><kbd>Program</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Email class</h1>
                </header>
            
            <article>
                
<p>The<span> </span><kbd>Email</kbd><span> </span>class is the container class that contains the data to both predict and train our model. These columns map in order to the sample data reviewed previously. If you begin experimenting with new features and add to this list, ensure you increment the array index appropriately, as shown in the following code block:</p>
<div>
<pre>using Microsoft.ML.Data;<br/><br/>namespace chapter04_multiclass.ML.Objects<br/>{<br/>    public class Email<br/>    {<br/>        [LoadColumn(0)]<br/>        public string Subject { get; set; }<br/><br/>        [LoadColumn(1)]<br/>        public string Body { get; set; }<br/><br/>        [LoadColumn(2)]<br/>        public string Sender { get; set; }<br/><br/>        [LoadColumn(3)]<br/>        public string Category { get; set; }<br/>    }<br/>}</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The EmailPrediction class</h1>
                </header>
            
            <article>
                
<p>The<span> </span><kbd>EmailPrediction</kbd><span> </span>class contains the property mapped to our prediction output used for model evaluation. In the following code block, we are returning the <kbd>Category</kbd> value (string value):</p>
<div>
<pre>using Microsoft.ML.Data;<br/><br/>namespace chapter04_multiclass.ML.Objects<br/>{<br/>    public class EmalPrediction<br/>    {<br/>        [ColumnName("PredictedLabel")]<br/>        public string Category;<br/>    }<br/>}</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Predictor class</h1>
                </header>
            
            <article>
                
<p>There are a couple of changes in this class to handle the email categorization prediction scenario, as follows:</p>
<ol>
<li>The first change is in the prediction call itself. As you probably guessed, the <kbd>TSrc</kbd> and <kbd>TDst</kbd> arguments need to be adjusted to utilize both of the new classes we created, <kbd>Email</kbd> and <kbd>EmailPrediction</kbd>, as follows:</li>
</ol>
<div>
<pre style="padding-left: 60px">var predictionEngine = MlContext.Model.CreatePredictionEngine&lt;Email, EmailPrediction&gt;(mlModel);            </pre></div>
<ol start="2">
<li>Given that we are no longer simply passing in the string and building an object on the fly, we need to first read in the file as text. We then deserialize the JSON into our <kbd>Email</kbd><strong> </strong>object, like this:</li>
</ol>
<div>
<pre style="padding-left: 60px">var prediction = predictionEngine.Predict(JsonConvert.DeserializeObject&lt;Email&gt;(json));</pre></div>
<ol start="3">
<li>L<span>astly, we need to adjust the output of our prediction to match our new <kbd>EmailPrediction</kbd><strong> </strong></span><span>properties, as follows:</span></li>
</ol>
<div>
<pre style="padding-left: 60px">Console.WriteLine(<br/>    $"Based on input json:{System.Environment.NewLine}" +<br/>    $"{json}{System.Environment.NewLine}" + <br/>    $"The email is predicted to be a {prediction.Category}");</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Trainer class</h1>
                </header>
            
            <article>
                
<p>There are a couple of changes in this class to handle the email categorization prediction scenario, as follows:</p>
<ol>
<li>First, we read in the <kbd>trainingFileName</kbd> string and typecast it to an <kbd>Email</kbd> object, like this:</li>
</ol>
<div>
<pre>var trainingDataView = MlContext.Data.LoadFromTextFile&lt;Email&gt;(trainingFileName, ',', hasHeader: false);           </pre></div>
<ol start="2">
<li>Next, we will create our pipeline mapping our input properties to <kbd>FeaturizeText</kbd> transformations before appending our SDCA trainer, as follows:</li>
</ol>
<div>
<pre style="padding-left: 60px">var dataProcessPipeline = MlContext.Transforms.Conversion.MapValueToKey(inputColumnName: nameof(Email.Category), outputColumnName: "Label")<br/>    .Append(MlContext.Transforms.Text.FeaturizeText(inputColumnName: nameof(Email.Subject), outputColumnName: "SubjectFeaturized"))<br/>    .Append(MlContext.Transforms.Text.FeaturizeText(inputColumnName: nameof(Email.Body), outputColumnName: "BodyFeaturized"))<br/>    .Append(MlContext.Transforms.Text.FeaturizeText(inputColumnName: nameof(Email.Sender), outputColumnName: "SenderFeaturized"))<br/>    .Append(MlContext.Transforms.Concatenate("Features", "SubjectFeaturized", "BodyFeaturized", "SenderFeaturized"))<br/>    .AppendCacheCheckpoint(MlContext);<br/><br/>var trainingPipeline = dataProcessPipeline<br/>    .Append(MlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy("Label", "Features"))<br/>    .Append(MlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel"));</pre></div>
<ol start="3">
<li>L<span>astly, we load in our test data, run the <kbd>MultiClassClassification</kbd> evaluation, and then output the four model evaluation properties, like this</span><span>:</span></li>
</ol>
<div>
<pre style="padding-left: 60px">var testDataView = MlContext.Data.LoadFromTextFile&lt;Email&gt;(testFileName, ',', hasHeader: false);<br/><br/>var modelMetrics = MlContext.MulticlassClassification.Evaluate(trainedModel.Transform(testDataView));<br/><br/>Console.WriteLine($"MicroAccuracy: {modelMetrics.MicroAccuracy:0.###}");<br/>Console.WriteLine($"MacroAccuracy: {modelMetrics.MacroAccuracy:0.###}");<br/>Console.WriteLine($"LogLoss: {modelMetrics.LogLoss:#.###}");<br/>Console.WriteLine($"LogLossReduction: {modelMetrics.LogLossReduction:#.###}");</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the application</h1>
                </header>
            
            <article>
                
<div>
<p>To run the application, the process is nearly identical to <span><span>the</span></span> sample application in <a href="8bcfc000-9adc-4eda-a91a-e09f676eac85.xhtml">Chapter 3</a>, <em>Regression Model</em>, with the addition of passing in the test dataset when training:</p>
</div>
<ol>
<li>To run the training on the command line as we did in <a href="b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml">Chapter 1</a>, <em>Getting Started with Machine Learning and ML.NET</em>, simply pass in the following command (assuming you are using the included sample dataset and test dataset):</li>
</ol>
<pre style="padding-left: 60px"><strong>PS chapter04-multiclass\bin\Debug\netcoreapp3.0&gt; .\chapter04-multiclass.exe train ..\..\..\Data\sampledata.csv ..\..\..\Data\testdata.csv</strong><br/>MicroAccuracy: 1<br/>MacroAccuracy: 1<br/>LogLoss: .1<br/>LogLossReduction: .856</pre>
<p style="padding-left: 60px">Note the expanded output to include several metric data points—we will go through what each one of these means at the end of this chapter.</p>
<ol start="2">
<li>After training the model, build a sample JSON file and save it as <kbd>input.json</kbd>, as follows:</li>
</ol>
<pre style="padding-left: 60px">{<br/>    "Subject":"hello",<br/>    "Body":"how is it?",<br/>    "Sender":"joe@gmail.com"<br/>}</pre>
<ol start="3">
<li>To run the model with this file, simply pass in the filename to the built application, and the predicted output will show, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>PS chapter04-multiclass\bin\Debug\netcoreapp3.0&gt; .\chapter04-multiclass.exe predict .\input.json</strong><br/>Based on input json:<br/>{<br/>"Subject":"hello",<br/>"Body":"how is it?",<br/>"Sender":"joe@gmail.com"<br/>}<br/>The email is predicted to be a "friend"</pre>
<p style="padding-left: 60px">Feel free to modify the values and see how the prediction changes based on the dataset on which the model was trained. A few areas of experimentation from this point might be to:</p>
<ul>
<li style="padding-left: 60px">Add more sample and test data based on your own emails.</li>
<li style="padding-left: 60px">Add more categories based on your own emails.</li>
<li style="padding-left: 60px">Expand the features, such as the date of sending, and the IP address of the sender.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Evaluating a classification model</h1>
                </header>
            
            <article>
                
<p>As discussed in previous chapters, evaluating a model is a critical part of the overall model-building process. A poorly trained model will only provide inaccurate predictions. Fortunately, ML.NET provides many popular attributes to calculate model accuracy, based on a test set at the time of training, to give you an idea of how well your model will perform in a production environment. </p>
<p>In ML.NET, as noted earlier in the sample applications, there are several properties that comprise the <kbd>CalibratedBinaryClassificationMetrics</kbd> class object. In <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter 2</a>, <em>Setting Up the ML.NET Environment</em>, we reviewed some of these properties. However, now that we have a more complex example and have learned how to evaluate regression models, let us dive into the following properties:</p>
<ul>
<li>Accuracy</li>
<li>Area Under ROC Curve</li>
<li>F1 Score</li>
<li>Area Under Precision-Recall Curve</li>
</ul>
<p>In addition, we will also look at the following four metrics returned by the <kbd>MulticlassClassificationMetrics</kbd> object used in the multi-class classification application:</p>
<ul>
<li>Micro Accuracy</li>
<li>Macro Accuracy</li>
<li>Log Loss</li>
<li>Log-Loss Reduction</li>
</ul>
<p>In the next sections, we will break down how these values are calculated, and detail the ideal values to look for.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Accuracy</h1>
                </header>
            
            <article>
                
<p>Accuracy is the proportion of correct predictions to incorrect predictions in the test dataset.</p>
<p>You will want to be as close to a value of 100%, but not exactly 100%. As seen in our binary classification example, we received 88.89%—close to 100%, but not quite. If you see a 100% score when experimenting, you are more than likely seeing a case of overfitting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Area Under ROC Curve</h1>
                </header>
            
            <article>
                
<p>Area Under ROC Curve, also commonly referred to as AUC, is the measurement of the area under the curve.</p>
<p>As with Accuracy, a value close to 100% is ideal. If you are seeing values of less than 50%, your model either needs more features and/or more training data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">F1 Score</h1>
                </header>
            
            <article>
                
<p>F1 Score is the harmonic mean of both precision and recall.</p>
<p>A value close to or equal to 100% is preferred. A value of 0 indicates your precision is completely inaccurate. As shown in our binary classification example, we received 87.50%.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Area Under Precision-Recall Curve</h1>
                </header>
            
            <article>
                
<p>Area Under Precision-Recall Curve, also commonly referred to as AUPRC, is the measure of successful prediction. This value should be inspected when your dataset is imbalanced into one classification.</p>
<p>As with AUC and Accuracy, a value close to 100% is preferred, as this indicates you have a high recall. As shown in our binary classification example, we received a 100% AUPRC value. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Micro Accuracy</h1>
                </header>
            
            <article>
                
<p>Micro Accuracy evaluates if every sample-class pair contributes equally to the accuracy metric.</p>
<p>A value close to or equal to 1 is preferred. As shown in our example application with the sample and test datasets, a value of 1 was achieved.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Macro Accuracy</h1>
                </header>
            
            <article>
                
<p>Macro Accuracy evaluates if every class pair contributes equally to the accuracy metric.</p>
<p>A value close to or equal to 1 is preferred. As shown in our example application with the sample and test datasets, a value of 1 was achieved.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Log Loss</h1>
                </header>
            
            <article>
                
<p>Log Loss <span>is an evaluation metric describing the accuracy of the classifier. Log Loss takes into account the difference between the model's prediction and the actual classification.</span></p>
<p>A value close to 0 is preferred, as a value of 0 indicates the model's prediction on the test set is perfect. As shown in our example application with the sample and test datasets, a value of .1 was achieved.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Log-Loss Reduction</h1>
                </header>
            
            <article>
                
<p>Log-Loss Reduction is simply an evaluation metric describing the accuracy of the classifier as compared to a random prediction.</p>
<p>A value close to or equal to 1 is preferred, as the model's relative accuracy improves as the value approaches 1. As shown in our example application with the sample and test datasets, a value of .856 was achieved, meaning the probability of guessing the correct answer is 85.6%.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Over the course of this chapter, we have deep-dived into classification models. We have also created and trained our first binary classification application, using FastTree and ML.NET, to predict how good a car's price is. We also created our first multi-class classification application using an SDCA trainer to categorize emails. Lastly, we also dove into how to evaluate a classification model and the various properties that ML.NET exposes to achieve a proper evaluation of your classification models.</p>
<p>In the next chapter, we will deep dive into clustering algorithms with ML.NET and creating a file-type classifier.</p>


            </article>

            
        </section>
    </body></html>