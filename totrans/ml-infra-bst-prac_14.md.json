["```py\nfrom tokenizers import ByteLevelBPETokenizer\npaths = ['source_code_wolf_ssl.txt']\nprint(f'Found {len(paths)} files')\nprint(f'First file: {paths[0]}')\n```", "```py\n# Initialize a tokenizer\ntokenizer = ByteLevelBPETokenizer()\nprint('Training tokenizer...')\n# Customize training\n# we use a large vocabulary size, but we could also do with ca. 10_000\ntokenizer.train(files=paths,\n                vocab_size=52_000,\n                min_frequency=2,\n                special_tokens=[\"<s>\",\"<pad>\",\"</s>\",\"<unk>\",\"<mask>\",])\n```", "```py\nimport os\n# we give this model a catchy name - wolfBERTa\n# because it is a RoBERTa model trained on the WolfSSL source code\ntoken_dir = './wolfBERTa'\nif not os.path.exists(token_dir):\n  os.makedirs(token_dir)\ntokenizer.save_model('wolfBERTa')\n```", "```py\nfrom tokenizers.processors import BertProcessing\n# let's make sure that the tokenizer does not provide more tokens than we expect\n# we expect 512 tokens, because we will use the BERT model\ntokenizer._tokenizer.post_processor = BertProcessing(\n    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n)\ntokenizer.enable_truncation(max_length=512)\n```", "```py\nimport the RoBERTa configuration\nfrom transformers import RobertaConfig\n# initialize the configuration\n# please note that the vocab size is the same as the one in the tokenizer.\n# if it is not, we could get exceptions that the model and the tokenizer are not compatible\nconfig = RobertaConfig(\n    vocab_size=52_000,\n    max_position_embeddings=514,\n    num_attention_heads=12,\n    num_hidden_layers=6,\n    type_vocab_size=1,\n)\n```", "```py\n# Initializing a Model From Scratch\nfrom transformers import RobertaForMaskedLM\n# initialize the model\nmodel = RobertaForMaskedLM(config=config)\n# let's print the number of parameters in the model\nprint(model.num_parameters())\n# let's print the model\nprint(model)\n```", "```py\nfrom transformers import RobertaTokenizer\n# initialize the tokenizer from the file\ntokenizer = RobertaTokenizer.from_pretrained(\"./wolfBERTa\", max_length=512)\n```", "```py\nfrom datasets import load_dataset\nnew_dataset = load_dataset(\"text\", data_files='./source_code_wolf_ssl.txt')\n```", "```py\ntokenized_dataset = new_dataset.map(lambda x: tokenizer(x[\"text\"]), num_proc=8)\n```", "```py\nfrom transformers import DataCollatorForLanguageModeling\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)\n```", "```py\nfrom transformers import Trainer, TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir=\"./wolfBERTa\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,\n    per_device_train_batch_size=32,\n    save_steps=10_000,\n    save_total_limit=2,\n)\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=tokenized_dataset['train'],\n)\n```", "```py\n# Transforms images to a PyTorch Tensor\ntensor_transform = transforms.ToTensor()\n# Download the Fashion MNIST Dataset\ndataset = datasets.FashionMNIST(root = \"./data\",\n                         train = True,\n                         download = True,\n                         transform = tensor_transform)\n# DataLoader is used to load the dataset\n# for training\nloader = torch.utils.data.DataLoader(dataset = dataset,\n                                     batch_size = 32,\n                                     shuffle = True)\n```", "```py\n# Creating a PyTorch class\n# 28*28 ==> 9 ==> 28*28\nclass AE(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Building an linear encoder with Linear\n        # layer followed by Relu activation function\n        # 784 ==> 9\n        self.encoder = torch.nn.Sequential(\n            torch.nn.Linear(28 * 28, 128),\n            torch.nn.ReLU(),\n            torch.nn.Linear(128, 64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64, 36),\n            torch.nn.ReLU(),\n            torch.nn.Linear(36, 18),\n            torch.nn.ReLU(),\n            torch.nn.Linear(18, 9)\n        )\n        # Building an linear decoder with Linear\n        # layer followed by Relu activation function\n        # The Sigmoid activation function\n        # outputs the value between 0 and 1\n        # 9 ==> 784\n        self.decoder = torch.nn.Sequential(\n            torch.nn.Linear(9, 18),\n            torch.nn.ReLU(),\n            torch.nn.Linear(18, 36),\n            torch.nn.ReLU(),\n            torch.nn.Linear(36, 64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64, 128),\n            torch.nn.ReLU(),\n            torch.nn.Linear(128, 28 * 28),\n            torch.nn.Sigmoid()\n        )\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n```", "```py\n# Model Initialization\nmodel = AE()\n# Validation using MSE Loss function\nloss_function = torch.nn.MSELoss()\n# Using an Adam Optimizer with lr = 0.1\noptimizer = torch.optim.Adam(model.parameters(),\n                             lr = 1e-1,\n                             weight_decay = 1e-8)\n```", "```py\nepochs = 10\noutputs = []\nlosses = []\nfor epoch in range(epochs):\n    for (image, _) in loader:\n      # Reshaping the image to (-1, 784)\n      image = image.reshape(-1, 28*28)\n      # Output of Autoencoder\n      reconstructed = model(image)\n      # Calculating the loss function\n      loss = loss_function(reconstructed, image)\n      # The gradients are set to zero,\n      # the gradient is computed and stored.\n      # .step() performs parameter update\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n      # Storing the losses in a list for plotting\n      losses.append(loss)\n    outputs.append((epochs, image, reconstructed))\n```", "```py\n# Defining the Plot Style\nplt.style.use('seaborn')\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\n# Convert the list to a PyTorch tensor\nlosses_tensor = torch.tensor(losses)\nplt.plot(losses_tensor.detach().numpy()[::-1])\n```", "```py\nfor i, item in enumerate(image):\n  # Reshape the array for plotting\n  item = item.reshape(-1, 28, 28)\n  plt.imshow(item[0])\n```", "```py\nyhat = model(image[0])\nmake_dot(yhat,\n         params=dict(list(model.named_parameters())),\n         show_attrs=True,\n         show_saved=True)\n```", "```py\nfrom torchsummary import summary\nsummary(model, (1, 28 * 28))\n```", "```py\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Linear-1               [-1, 1, 128]         100,480\n              ReLU-2               [-1, 1, 128]               0\n            Linear-3                [-1, 1, 64]           8,256\n              ReLU-4                [-1, 1, 64]               0\n            Linear-5                [-1, 1, 36]           2,340\n              ReLU-6                [-1, 1, 36]               0\n            Linear-7                [-1, 1, 18]             666\n              ReLU-8                [-1, 1, 18]               0\n            Linear-9                 [-1, 1, 9]             171\n           Linear-10                [-1, 1, 18]             180\n             ReLU-11                [-1, 1, 18]               0\n           Linear-12                [-1, 1, 36]             684\n             ReLU-13                [-1, 1, 36]               0\n           Linear-14                [-1, 1, 64]           2,368\n             ReLU-15                [-1, 1, 64]               0\n           Linear-16               [-1, 1, 128]           8,320\n             ReLU-17               [-1, 1, 128]               0\n           Linear-18               [-1, 1, 784]         101,136\n          Sigmoid-19               [-1, 1, 784]               0\n================================================================\nTotal params: 224,601\nTrainable params: 224,601\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.02\nParams size (MB): 0.86\nEstimated Total Size (MB): 0.88\n----------------------------------------------------------------\n```"]