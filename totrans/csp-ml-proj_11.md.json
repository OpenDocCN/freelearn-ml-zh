["```py\nvar learner = new IterativeReweightedLeastSquares<LogisticRegression>()\n{\n    MaxIterations = 100\n};\nvar model = learner.Learn(inputs, outputs);\n```", "```py\nvar learner = new MultinomialLogisticLearning<GradientDescent>()\n{\n    MiniBatchSize = 500\n};\nvar model = learner.Learn(inputs, outputs);\n```", "```py\nvar learner = new NaiveBayesLearning<NormalDistribution>();\nvar model = learner.Learn(inputs, outputs);\n```", "```py\nvar learner = new RandomForestLearning()\n{\n    NumberOfTrees = 100,\n\n    CoverageRatio = 0.5,\n\n    SampleRatio = 0.7\n\n};\nvar model = learner.Learn(inputs, outputs);\n```", "```py\nvar learner = new SequentialMinimalOptimization<Gaussian>();\nvar model = learner.Learn(inputs, outputs);\n```", "```py\nvar network = new ActivationNetwork(\n    new BipolarSigmoidFunction(2), \n    91, \n    20,\n    10\n);\n\nvar teacher = new LevenbergMarquardtLearning(network);\n\nConsole.WriteLine(\"\\n-- Training Neural Network\");\nint numEpoch = 10;\ndouble error = Double.PositiveInfinity;\nfor (int i = 0; i < numEpoch; i++)\n{\n    error = teacher.RunEpoch(trainInput, outputs);\n    Console.WriteLine(\"* Epoch {0} - error: {1:0.0000}\", i + 1, error);\n}\n```", "```py\nvar learner = new OrdinaryLeastSquares()\n{\n    UseIntercept = true\n};\nvar model = learner.Learn(inputs, outputs);\n```", "```py\nvar learner = new LinearRegressionNewtonMethod()\n{\n    Epsilon = 2.1,\n    Tolerance = 1e-5,\n    UseComplexityHeuristic = true\n};\nvar model = learner.Learn(inputs, outputs);\n```", "```py\nvar learner = new FanChenLinSupportVectorRegression<Polynomial>()\n{\n    Kernel = new Polynomial(3)\n};\nvar model = learner.Learn(inputs, outputs);\n```", "```py\nvar learner = new FanChenLinSupportVectorRegression<Gaussian>()\n{\n    Kernel = new Gaussian()\n};\nvar model = learner.Learn(inputs, outputs);\n```", "```py\nKMeans kmeans = new KMeans(numClusters);\nKMeansClusterCollection clusters = kmeans.Learn(sampleSet);\n```"]