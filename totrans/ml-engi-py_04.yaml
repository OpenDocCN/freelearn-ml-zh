- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Packaging Up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we introduced a lot of the tools and techniques you will
    need to use to successfully build working **machine learning** (**ML**) products.
    We also introduced a lot of example pieces of code that helped us to understand
    how to implement these tools and techniques. So far, this has all been about *what*
    we need to program, but this chapter will focus on *how* to program. In particular,
    we will introduce and work with a lot of the techniques, methodologies, and standards
    that are prevalent in the wider Python software development community and apply
    them to ML use cases. The conversation will be centered around the concept of
    developing *user-defined libraries and packages*, reusable pieces of code that
    you can use to deploy your ML solutions or develop new ones. It is important to
    note that everything we discuss here can be applied to all of your Python development
    activities across your ML project development life cycle. If you are working on
    some exploratory data analysis in a notebook or some modeling scripts for the
    research portion of your project, your work will still benefit immensely from
    the concepts we are about to introduce.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will recap some of the basic points of programming in Python,
    before discussing the concept of coding standards and some pointers for writing
    high-quality Python code. We will also touch upon the difference between **object-oriented**
    and **functional** programming in Python, and where this has strengths and points
    of synergy with other tools that you may want to use in your solution. We will
    discuss some good use cases for writing your own ML packages and go through the
    options for packaging up. Next will be a discussion on testing, logging, and error
    handling in your code, which are important concepts for building code that can
    be trusted not just to work but also to be diagnosable when it doesn’t. This will
    be followed by a deep dive into the logical flow of our package. Finally, we will
    perform an exploration of how we ensure we do not reinvent the wheel and use functionality
    that already exists elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Writing good Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a style
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Packaging your code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building your package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing, logging, and error handling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not reinventing the wheel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IMPORTANT NOTE
  prefs: []
  type: TYPE_NORMAL
- en: There isn’t a clearly defined difference between a package and a library in
    Python. The general consensus seems to be that *library* often refers to any collection
    of code you want to reuse in other projects, whereas *package* refers to a collection
    of Python modules (covered in this chapter). We will often use the two interchangeably
    here with the understanding that when we say library, we are usually referring
    to a bunch of code that is cleanly put together and contains at least one package.
    This means that we won’t count single scripts with some code you reuse later as
    a library for our purposes here.
  prefs: []
  type: TYPE_NORMAL
- en: Who doesn’t want to write more robust, clean, readable, testable, and performant
    code that can be used by our colleagues, the ML community, or even our customers?
    Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As with the other chapters, the dependencies required to run the examples in
    this chapter can be installed by navigating to the `Chapter 04` folder of the
    book repository and creating a new Conda environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You should note that this chapter mainly focuses on Python fundamentals around
    packaging, so the requirements are a bit lighter than usual!
  prefs: []
  type: TYPE_NORMAL
- en: Writing good Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed throughout this book, Python is an extremely popular and very versatile
    programming language. Some of the most widely used software products in the world,
    and some of the most widely used ML engineering solutions in the world, use Python
    as a core language.
  prefs: []
  type: TYPE_NORMAL
- en: Given this scope and scale, it is clear that if we are to write similarly amazing
    pieces of ML-driven software, we should once again follow the best practices and
    standards already adopted by these solutions. In the following sections, we will
    explore what packaging up means in practice, and start to really level up our
    ML code in terms of quality and consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Recapping the basics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we get stuck into some more advanced concepts, let’s make sure we are
    all on the same page and go over some of the basic terminology of the Python world.
    If you feel quite confident in the fundamentals of Python, then you can skip this
    section and carry on with the rest of the chapter. However, going over these fundamentals
    if you are a bit newer to Python or have not revised them in a while will ensure
    that you apply the right thought processes to the right things and that you can
    feel confident when writing your code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, we have the following objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Variable**: An object that stores data of one of a variety of types. In Python,
    variables can be created through **assignment** without specifying the type, for
    example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Function**: A unit of code that is self-contained and performs logical steps
    on variables (or another object). Defined by the `def` keyword in Python and can
    return any Python object. Functions are *first-class citizens* in Python, which
    means you can reference them using their object name (and re-reference them),
    and that functions can pass and return functions. So, for example, if we create
    a function that calculates some simple statistics from a pandas DataFrame, we
    can do the following. First, define it:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then run it using the original name and a DataFrame called `X_train`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then you can re-assign the function using a new name and similarly call it:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can then pass the function around even more. For example, if you pass the
    function into a new function that takes the result and returns a JSON object,
    then you can call that!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This can help build up some simple pieces of code into something relatively
    complex quite quickly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Module**: This is a file containing definitions and statements of functions,
    variables, and other objects where the contents can be imported into other Python
    code. For example, if we put the functions defined in the previous example into
    a file called `module.py`, we can then type the following in another Python program
    (or the Python interpreter) in order to use the functionality contained within
    it:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Class**: We will discuss classes in detail in the *Object-oriented programming*
    section, but for now, just know that these are the basic units of object-oriented
    programming, and act as a nice way of containing logically related functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Package**: This is a collection of modules that are coupled together via
    their directory structure and is built such that modules in the package are accessed
    through the `dot` syntax. For example, if we have a package called `feature` that
    contains modules to help us to do feature engineering, it could be organized as
    follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, if we wanted to use the functionality contained within the `numerical`
    or `categorical` sub-modules, we would use the `dot` syntax like so:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now let’s move on to discuss some general Python tips and tricks.
  prefs: []
  type: TYPE_NORMAL
- en: Tips and tricks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s now discuss some tips and tricks for using Python that can often be overlooked,
    even by those quite familiar with the language. The following concepts can help
    you write more compact and performant code, so it’s good to have them to hand.
    Note that this list is definitely not exhaustive:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Generators**: These are convenience functions for helping us create a syntax
    that iterates in some sense. They save us from writing a lot of boilerplate code,
    are memory efficient, and have very useful properties, such as the ability to
    pause execution and save the internal state automatically. Then you can resume
    iterating with it later in your program. Generators are created in Python whenever
    we define a function that uses the `yield` statement. For example, here we can
    define a generator that will filter a given list of values based on a predicate
    called `condition`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In action, we could apply this to a simple list of the integers from zero to
    ninety-nine called `data_vals` and filter out values below a certain threshold:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will return the integers from fifty to ninety-nine.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The other way to define a generator expression is by using an iterative statement
    in round brackets. For example, here we can define a generator that iterates over
    the squares from zero to nine:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that you can only execute your generators once; after that, they are *empty*.
    This is because they only store what they need in memory for each step of the
    iteration, so once it is complete, nothing is stored!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Generators are really powerful ways of creating data manipulation steps that
    are memory efficient and can be used to define custom pipelines in frameworks
    such as Apache Beam. We will not cover this here, but it is definitely worth checking
    out. As an example, take a look at the article at [https://medium.com/analytics-vidhya/building-a-data-pipeline-with-python-generators-a80a4d19019e](https://medium.com/analytics-vidhya/building-a-data-pipeline-with-python-generators-a80a4d19019e).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**List comprehension**: This is a syntax that allows us to take any iterable
    we have to hand (a `dict`, a `list`, a `tuple`, and a `str` are all examples)
    and build a list from it in an extremely compact way. This can save you from writing
    long, clunky loops and can help create some more elegant code. List comprehensions
    create the entire list in memory, so they are not as efficient as generators.
    So use them wisely, and only create small lists if you can. You perform list comprehension
    by writing your iteration logic in square brackets, as opposed to the round brackets
    of generators. As an example, we can create the data used in the first generator
    example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Containers and collections**: Python has a useful set of built-in types that
    are known as **containers**, these being `dict`, `set`, `list`, and `tuple`. Beginners
    in Python learn how to use these from their first time playing with the language,
    but what we can often forget is their augmented counterparts: **collections**.
    These allow for additional behavior on top of the standard containers, which can
    be useful. The table shown in *Figure 4.1* summarizes some useful containers mentioned
    in the Python 3 documentation on *python.org* at [https://docs.python.org/3/library/collections.xhtml](https://docs.python.org/3/library/collections.xhtml).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These are useful to have to hand when you are working through some data manipulations
    and can often save you a couple of lines of code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| **Container** | **Description** |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| deque | This is a double-ended queue and allows you to add and remove elements
    to either end of the object in a scalable way. It’s useful if you want to add
    to the beginning or end of large data lists or if you want to search for the last
    occurrences of X in your data. |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Counter | Counters take in iterables such as dicts or lists and return the
    count of each of the elements. They’re really useful to get quick summaries of
    the content of these objects. |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| OrderedDict | The standard dict object does not maintain order, so OrderedDict
    introduces this functionality. This can be really useful if you need to loop back
    over a dictionary you have created in the same order as it was created for new
    processing. |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: 'Table 4.1: Some useful types in the collections module in Python 3.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '***args** and ****kwargs**: When we want to call a function in Python, we often
    supply it with arguments. We have seen plenty of examples of this in this book
    already. But what happens if you define a function for which you would like to
    apply to a varying number of arguments? This is where the ***args** and ****kwargs**
    patterns come in. For example, imagine we want to initialize a class called `Address`
    that uses information gathered from an online web form to create a single string
    giving an address.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We may not know how many elements are going to be in each text box used by
    the user for the address ahead of time. We could then use the ***args** pattern
    (you don’t have to call it **args**, so here we’ve called it `address`). Here’s
    the class:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then your code will work absolutely fine in both of these cases, even though
    there are a variable number of arguments to the constructor:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Then `address1.address` will be given by `'62 Lochview Crescent'` and `address2.address`
    will be given by `'The Palm 1283 Royston Road'`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '****kwargs** extends this idea to allow a variable number of keyword arguments.
    This is particularly useful if you have functions where you may want to define
    a variable number of parameters, but you need names attached to those parameters.
    For example, we may want to define a class for containing ML model hyperparameter
    values, the number and names of which will vary by algorithm. We can therefore
    do something like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then the code will allow us to define instances such as the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And then `hyp1.hyperparams` will be given by `{''eps'': 3, ''distance'': ''euclidean''}`
    and `hyp2.hyperparams` by `{''n_clusters'': 4, ''max_iter'': 100}`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: There are many more concepts that are important to understand for a detailed
    understanding of how Python works. For now, these pointers will be enough for
    us to build upon throughout the chapter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now we will consider how to define and organize these elements in a way that
    makes your code readable and consistent.
  prefs: []
  type: TYPE_NORMAL
- en: Adhering to standards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you say something like *adhering to standards*, in most contexts, you would
    be forgiven for half-expecting a sigh and a gigantic eye roll from whoever you
    were talking to. Standards sound boring and tedious, but they are in fact an extremely
    important part of making sure that your work is consistent and high quality.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, the *de facto* standard for coding style is **Python Enhancement
    Proposal 8** (**PEP-8**), written by Guido Van Rossum (the creator of Python),
    Barry Warsaw, and Nick Coghlan ([https://www.python.org/dev/peps/pep-0008/](https://www.python.org/dev/peps/pep-0008/)).
    It is essentially a collection of guidelines, tips, tricks, and suggestions for
    making code that is consistent and readable. Some of the benefits of adhering
    to the PEP-8 style guide in your Python projects are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Greater consistency**: This will help you write code that is less likely
    to break once you have deployed it, as it is much easier to follow the flow of
    your programs and identify errors and bugs. Consistency also helps simplify the
    design of extensions and interfaces to your code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved readability**: This begets efficiency, as colleagues and even users
    of your solutions can understand what is being done and how to use it more effectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, what is in the PEP-8 style guide? And how should you think about applying
    it to your ML project? For the full details, I recommend you read the PEP-8 documentation
    given earlier. But in the next few paragraphs, we will go into some of the details
    that will give you the greatest improvement to your code for the least effort.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s cover **naming conventions**. When you write a piece of code, you
    will have to create several variables, files, and other objects, such as classes,
    and these all have to have a name. Making sure that these names are readable and
    consistent is the first part of making your code of a very high standard.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the key pointers from PEP-8 are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Variables and function names**: It is recommended that these consist of all
    lowercase words, separated by underscores. They should also help us understand
    what they are for. As an example, if you are building a regression model and you
    want to put some of your feature engineering steps inside a function to simplify
    reuse and readability elsewhere in the code, you may call it something like `Makemydata()`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calling your function `Makemydata()` is not a great idea, whereas naming it
    something like `transform_features` is better:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This function name is compliant with PEP-8.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Modules and packages**: The recommendation is that these have all short lowercase
    names. Some great examples are ones you are familiar with, such as `pandas`, `numpy`,
    and `scipy`. **Scikit-learn** may seem like it breaks this rule, but it actually
    doesn’t as the package name is `sklearn`. The style guide mentions that modules
    can have underscores to improve readability, but packages should not. If we had
    a module in a package called `transform_helpers`, then this is acceptable, but
    an entire package called `marketing_outlier_detection` would be terrible!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classes**: Classes should have names such as `OutlierDetector`, `Transformer`,
    or `PipelineGenerator`, which clearly specify what they do and also follow the
    upper CamelCase or PascalCase (both mean the same thing) style.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are some of the most commonly used naming conventions you should be aware
    of. The PEP-8 document also covers a lot of good points on whitespace and the
    formatting of lines that we will not go into here. We will finish this section
    with a discussion on some of the author’s favorite suggestions from the *programming
    recommendations* of PEP-8\. These are often overlooked and, if forgotten, can
    make for some code that is both horrible to read and likely to break, so take
    heed!
  prefs: []
  type: TYPE_NORMAL
- en: A good point to remember in all of this talk about style is that at the top
    of the PEP-8 document, which states that *Foolish Consistency is the Hobgoblin
    of Little Minds* and that there are good reasons to ignore these style suggestions
    in certain circumstances. Again, read the PEP-8 document for the full works, but
    if you follow these points, then in general, you will write clean and readable
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will cover how some of these rules do not really apply when we are
    using the Python API for Apache Spark.
  prefs: []
  type: TYPE_NORMAL
- en: Writing good PySpark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we draw attention to one particular flavor of Python that is
    very important in the world of data science and ML. PySpark code has already been
    used in examples throughout this book since it is the go-to tool for distributing
    your data workloads, including your ML models. In *Chapter 6*, *Scaling Up*, we
    will learn more about PySpark, but here we will just briefly mention some points
    on coding style.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned in the section on *Spark ML pipelines* in *Chapter 3*, *From Model
    to Model Factory*, since Spark is written in Scala, the syntax of PySpark (which
    is just the Python API for Spark) has inherited a lot of the syntactical style
    from that underlying language. This means in practice that many of the methods
    you use will be written in CamelCase, meaning that it also makes sense to define
    your variables using CamelCase rather than the standard Python PEP-8 naming convention
    of words separated by underscores. This is behavior that we should encourage as
    it helps people reading our code to clearly see which sections are PySpark code
    and which are (more) vanilla Python. To emphasize this, when we used the `StringIndexer`
    object from the `pyspark.ml` package before, we used `StringIndexer` instead of
    the more idiomatic Python, `string_indexer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Another important point about PySpark code is that because Spark is written
    in a functional paradigm, it also makes sense that your code also follows this
    style. We will understand a bit more about what this means in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a style
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will provide a summary of two coding styles or paradigms, which
    make use of different organizational principles and capabilities of Python. Whether
    you write your code in an object-oriented or functional style could just be an
    aesthetic choice.
  prefs: []
  type: TYPE_NORMAL
- en: This choice, however, can also provide other benefits, such as code that is
    more aligned with the logical elements of your problem, code that is easier to
    understand, or even more performant code.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will outline the main principles of each paradigm
    and allow you to choose for yourself based on your use case.
  prefs: []
  type: TYPE_NORMAL
- en: Object-oriented programming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Object-oriented programming** (**OOP**) is a style where the code is organized
    around, you guessed it, abstract objects with relevant attributes and data instead
    of around the logical flow of your solution. The subject of OOP is worth a book
    (or several books!) in itself, so we will focus on the key points that are relevant
    to our ML engineering journey.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, in OOP, you have to define your `objects`. This is done in Python through
    the core OOP principle of classes, which are definitions of structures in your
    program that keep together related data and logical elements. A class is a template
    for defining the objects in OOP. As an example, consider a very simple class that
    groups together some methods for calculating numerical outliers on a dataset.
    For example, if we consider the pipelines that we looked into in *Chapter 3*,
    *From Model to Model Factory*, we may want to have something that makes this even
    easier to apply in a production setting. We may therefore want to wrap up some
    of the functionality provided by tools such as Scikit-Learn into a class of its
    own that could have bespoke steps specific to our problem. In the simplest case,
    if we wanted a class to wrap the standardization of our data and then apply a
    generic outlier detection model, it could look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: All this example does is allow a user to skip writing out some of the steps
    that they may have to otherwise write to get the job done. The code doesn’t disappear;
    it just gets placed inside a handy object with a clear logical definition. In
    this case, the pipeline shown is extremely simple, but we can imagine extending
    this to something very complex and containing logic that’s specific to our use
    case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, if we have already defined an outlier detection model (or retrieved
    it from a model store, such as MLflow, as discussed in *Chapter 3*, *From Model
    to Model Factory*), we can then feed this into this class and run quite complex
    pipelines just with a single line of code, no matter the complexity contained
    within the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the example, this pattern of implementation seems familiar,
    and it should! **Scikit-learn** has a lot of OOP in it, and you use this paradigm
    every time you create a model. The act of creating a model is a case of you instantiating
    a class object, and the process of you calling `fit` or `predict` on your data
    are examples of calling class methods. So, the reason the preceding code may not
    seem alien is that it shouldn’t! We’ve already been using OOP when working with
    ML with Scikit-Learn.
  prefs: []
  type: TYPE_NORMAL
- en: Despite what we have just said, using objects and understanding how to build
    them are obviously two different challenges. So, let’s go through the core concepts
    of building your own classes. This will set us up later for building more classes
    of relevance for our own ML solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Next, you can see that the functionality we want to group together is defined
    inside the class. Functions that live inside a class are called methods. You can
    see that `OutlierDetector` has only one method, called `detect`, but you are not
    limited in how many methods your class can have.
  prefs: []
  type: TYPE_NORMAL
- en: Methods contain your class’s abilities to interact with data and other objects,
    so their definition is where most of the work of building up your class goes.
  prefs: []
  type: TYPE_NORMAL
- en: You might think we have missed a method, the one called `__init__()`. This is
    in fact not a method (or you can think of it as a very special method) and is
    called the *constructor*. The constructor does what it says—it constructs! Its
    job is to perform all of the relevant setup tasks (some of which occur in the
    background, such as memory allocation) for your class when it gets initialized
    as an object. When the example defines `detector`, the constructor is called.
    As you can see, you can pass variables and then these variables can be used within
    the class. Classes in Python can be created without defining an explicit constructor,
    but one will be created in the background. The final point we will make on constructors
    is that they are not allowed to return anything other than `None`, so it’s common
    to leave the `return` statement unwritten.
  prefs: []
  type: TYPE_NORMAL
- en: You will also have seen in the example that there are variables inside the class
    and there is a somewhat mysterious `self` keyword. This allows methods and operations
    inside the class to refer to the particular instance of the class. So, if you
    define two or a hundred instances of the `OutlierDetector` object, it is possible
    for them all to have different values for their internal attributes but still
    have the same functionality.
  prefs: []
  type: TYPE_NORMAL
- en: We will create some more involved OOP styles for your ML solution later, but
    for now, let’s discuss the other programming paradigm that we may want to use
    – functional programming.
  prefs: []
  type: TYPE_NORMAL
- en: Functional programming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Functional programming** is based on the concept of, you guessed it, functions.
    At its core, this programming paradigm is about trying to write pieces of code
    that only take in data and output data, doing so without creating any internal
    state that can be changed. One of the goals of functional programming is to write
    code that has no unintended side effects due to mismanagement of state. It also
    has the benefit of making sure that the data flow in your programs can be understood
    completely by looking at the `return` statements of the functions you have written.'
  prefs: []
  type: TYPE_NORMAL
- en: It uses the idea of the data in your program not being allowed to change in
    place. This concept is known as **immutability**. If your data (or any object)
    is immutable, it means that there is no internal state to modify, and if you want
    to do something with the data, you actually have to create new data. For example,
    in the section on *Object-oriented programming*, we again revisited the concept
    of standardizing data. In a functional program, standardized data cannot overwrite
    unstandardized data; you would need to store this new data somewhere, for example,
    in a new column in the same data structure.
  prefs: []
  type: TYPE_NORMAL
- en: Some programming languages are designed with functional principles at their
    core, such as F# and Haskell, but Python is a general-purpose language that can
    accommodate both paradigms quite nicely.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will likely have seen some other functional programming concepts in other
    Python code. For example, if you have ever used a lambda function, then this can
    be a powerful aspect of a functionally programmed piece of code as it is how you
    define *anonymous functions* (those without a specified name). So, you may have
    seen code that looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, `df` is a pandas DataFrame and `data` is just a
    column of numbers. This is one of the tools that help make functional programming
    in Python easier. Other such tools are the built-in functions `map()`, `reduce()`,
    and `filter()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, imagine that we have some address data similar to that in the
    *Recapping the basics* section, where we discussed the concepts of **args** and
    ****kwargs**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we might want to write some code that returns a list of lists with the
    same shape as this data, but every entry now contains the number of characters
    in each string. This could be a stage in a data preparation step in one of our
    ML pipelines. If we wanted to write some code to do this functionally, we could
    define a function that takes a list and returns a new list with the string lengths
    for the entries like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This embodies functional programming because the data is immutable (there is
    no change of internal state) and the function is pure (it only uses data within
    the scope of the function). We can then use another concept from functional programming
    called higher-order functions, where you supply functions as the arguments of
    other functions. For example, we may want to define a function that can apply
    any list-based function but to a list of lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that this is completely generic; as long as the `list_func()` can be applied
    to a list, this will work on a list of lists. We can therefore get the original
    result we wanted by calling the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns the desired result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Spark, a tool that’s already been used multiple times in this book, is written
    in the Scala language, which is also general-purpose and can accommodate both
    object-oriented and functional programming. Spark is predominantly written in
    a functional style; its aim of distributing computation is more easily accommodated
    if principles such as immutability are respected. This means that when we have
    been typing PySpark code through this book, we have subtly been picking up some
    functional programming practices (did you notice?).
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, in *Chapter 3*, *From Model to Model Factory*, the example PySpark
    pipeline we built had code like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This is functional since the `data` object we create is actually a new DataFrame
    with the new column added—we can’t just add a column in place. There was also
    code that formed part of our pipelines from the Spark ML library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This is defining how to take a series of columns in a DataFrame and perform
    a scaling transformation on them. Note how you define input columns and output
    columns, and *these cannot be the same*. That’s immutability in action—you have
    to create new data rather than transform it in place.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, this gives you a taste of functional programming in Python. This
    is not the main paradigm we will use in this book, but it will be used for some
    pieces of code, and, in particular, remember that when we use PySpark, we are
    often implicitly using functional programming.
  prefs: []
  type: TYPE_NORMAL
- en: We will now discuss ways of packaging the code that you have written.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging your code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In some ways, it is interesting that Python has taken the world by storm. It
    is dynamically typed and non-compiled, so it can be quite different to work with
    compared to Java or C++. This particularly comes to the fore when we think about
    packaging our Python solutions. For a compiled language, the main target is to
    produce a compiled artifact that can run on the chosen environment – a Java `jar`,
    for example. Python requires that the environment you run in has an appropriate
    Python interpreter and the ability to install the libraries and packages you need.
    There is also no single compiled artifact created, so you often need to deploy
    your whole code base as is.
  prefs: []
  type: TYPE_NORMAL
- en: Despite this, Python has indeed taken the world by storm, especially for ML.
    As we are ML engineers thinking about taking models to production, we would be
    remiss to not understand how to package and share Python code in a way that helps
    others to avoid repetition, trust in the solution, and be able to easily integrate
    it with other projects.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we are first going to discuss what we mean by a user-defined
    library and some of the advantages of packaging your code this way. We are then
    going to define the main ways you can do this so that you can run your ML code
    in production.
  prefs: []
  type: TYPE_NORMAL
- en: Why package?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we discuss in detail exactly what a package or library is in Python,
    we can articulate the advantages by using a working definition of *a collection
    of Python code that can be run without detailed knowledge of its implementation*.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will have already picked up from this definition the nature of the first
    reason to do this: **abstraction**.'
  prefs: []
  type: TYPE_NORMAL
- en: Bringing together your code into a library or package that can be reused by
    other developers and data scientists in your team, organization, or the wider
    community allows these user groups to solve problems more quickly. Since the details
    of the work are abstracted away, anyone using your code can focus on implementing
    the capabilities of your solution, rather than trying to understand and dissect
    every line. This will lead to reduced development and deployment time in projects,
    as well as encourage the usage of your code in the first place!
  prefs: []
  type: TYPE_NORMAL
- en: The second advantage is that, by consolidating the functionality you need into
    a library or package, you bring all of the implementation details to one place
    and therefore *improvements scale*. What we mean by this is if 40 projects are
    using your library and someone discovers a minor bug, you only need to patch it
    *once* and then redeploy or update the package in those 40 implementations.
  prefs: []
  type: TYPE_NORMAL
- en: This is way more scalable than explaining the issue to the relevant teams and
    getting 40 different fixes at the implementation end. This consolidation also
    means that once you have thoroughly tested all the components, you can more confidently
    assume that this solution will be running smoothly in those 40 different projects,
    without knowing anything about the details under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 4.1* helps to show how packages helpfully allow a *write once, use
    many* philosophy for your code, which is incredibly important if you want to engineer
    ML solutions that can solve multiple problems in a scalable fashion:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Developing packages for your ML solutions allows you to write
    the code once but use it many times in different environments ](img/B19525_04_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1: Developing packages for your ML solutions allows you to write the
    code once but use it many times in different environments.'
  prefs: []
  type: TYPE_NORMAL
- en: The next section will build on these main ideas about packaging to discuss specified
    use cases in which packaging our code can be beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting use cases for packaging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First things first, not all of your solutions should be libraries. If you have
    an extremely simple use case, you may only need one simple script to run on a
    schedule for the core of your ML solution. You can still write a well-engineered
    system and performant code in this case, but it’s not a library. Similarly, if
    your problem is best solved by a web app, then although there will be lots of
    components, it will not naturally be a library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some good reasons you may want to write up your solution as a library or package
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The problem your code solves is a common one that may come up in multiple projects
    or environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to abstract away implementation details so that execution and development
    are decoupled, making it easier for others to use your code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To minimize the number of places and the number of times you need to change
    code to implement bug fixes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To make testing simpler.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To simplify your **continuous integration/continuous deployment** (**CI/CD**)
    pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will now dive into how we might go about designing our packages.
  prefs: []
  type: TYPE_NORMAL
- en: Designing your package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The layout of your code base is far more than just a stylistic consideration.
    It is something that will determine how your code is used in every instance of
    the project – no pressure!
  prefs: []
  type: TYPE_NORMAL
- en: This means that it is important to put some thought into how you want to lay
    out your code and how this influences usage patterns. You need to ensure that
    all of the main components you need have a presence in the code base and are easy
    to find.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s work this through with an example based on the outlier detection case
    we worked through in the previous sections.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to decide what kind of solution we want to create. Are we building
    something that will run a web application or a standalone executable with lots
    of functionality, or are we building a library for others to use in their ML projects?
    In fact, we can choose to do more than one thing! For this case, let’s build a
    package that can be imported for use in other projects but can also run in a standalone
    execution mode.
  prefs: []
  type: TYPE_NORMAL
- en: To set the context for the development of our package, imagine we have been
    asked to start building a solution that can run a set of selected unsupervised
    outlier detection models. The data scientists have found that, for the problem
    at hand, `Isolation` `Forest` models are the most performant, but they must be
    retrained on every run and the users of the package should be able to edit the
    configuration of the models through a config file. Only `sklearn` models have
    been studied so far, but the business and users of the package would like this
    functionality to be extensible to other modeling tools if needed. The technical
    requirements for this project mean we cannot use MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Don’t worry; in later chapters when we build more examples, we will relax this
    constraint to show how it all fits together:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The package we are going to build is all about outliers, so let’s call it `outliers`
    (I know, inventive, right?). Just to make it clear how everything hangs together,
    we will start to build the `outliers` package in a folder called `outlier_package`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Our package design will be based on the functionality we want the solution
    to have; in this case, we want something that detects outliers, so let’s create
    a sub-package called `detectors`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Within this, we will put some code that wraps (more on this later) around some
    basic models from external libraries. We will also want some code that gets data
    for us to analyze, so we will add a sub-package for that too:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can already see our package taking shape. Finally, we will want to have
    somewhere to store configuration information and somewhere to store helper functions
    that may be used across the package, so let’s add a directory and sub-package
    for those too:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, this layout is not sacrosanct or dictated in any way. We can create the
    layout however we want and do whatever we think makes sense.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It is important when doing this, though, to always remember the principles of
    **Don’t Repeat Yourself** (**DRY**), **Keep It Simple, Stupid** (**KISS**), and
    the Python mantra of *there should preferably be only one way to do something*.
    If you stick to these principles, you will be fine. For more information on these
    principles, see [https://code.tutsplus.com/tutorials/3-key-software-principles-you-must-understand--net-25161](https://code.tutsplus.com/tutorials/3-key-software-principles-you-must-understand--net-25161)
    and [https://www.python.org/dev/peps/pep-0020/](https://www.python.org/dev/peps/pep-0020/).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: So, what actually goes in each of these sub-packages? Well, the underlying code
    of course!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In this case, we will want something to provide an interface between our detector
    implementations and the syntax for creating a pipeline and calling them, so we
    will build a simple class and keep it in `pipelines.py`. The `pipelines.py` file
    contains the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then also need something to define the models we want to interface with.
    In this case, we will create code that uses information stored in a configuration
    file to decide which of a select few models to instantiate. We put all this functionality
    in a class called `DetectionModels`. For brevity, we omit the details of each
    of the functions in the class in this first instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The initialization method is expanded here. Notice that we wrote this code
    so that we could define a series of models in the `config` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then the `create_model` method is able to instantiate the model based on parameter
    and model name information. We have also built this so that we can actually pull
    in configuration information for models from different libraries if we wanted
    to; we would just need to add the appropriate implementation logic in this `create_model`
    function, checking that `sklearn` or another model was defined and running the
    appropriate syntax in each case. We would also have to make sure the pipeline
    generated in `OutlierDetector` was appropriate in each case as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we bring the preceding methods together through the `get_models` method,
    which returns a list of all models defined in the appropriate config file, instantiated
    as a `sklearn` object via the `create_model` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You may be thinking *why not just read in the appropriate model and apply it,
    no matter what it is?* That could be a viable solution, but what we have done
    here means that only model types and algorithms that have been approved by the
    team working on the project can make it through to production, as well as permitting
    the use of heterogeneous model implementations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To see how this could all work in practice, let’s define a script called `__main__.py`
    at the uppermost level of the package, which can act as the main entry point for
    the execution of modeling runs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `model_config.json` file referred to here is given by the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `definitions.py` file is a file that holds relevant paths and other variables
    that we want to make globally accessible in the package without polluting the
    namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see that we don’t really do anything with the results; we just print
    them to show that output is produced. But in reality, you will either push these
    results elsewhere or calculate statistics on them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This script can be run by typing this in your terminal:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Alternatively, you could type the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: And that is how you can package functionality into classes, modules, and packages.
    The example given was relatively constrained, but it does give us an awareness
    of how the different pieces can be brought together and executed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: IMPORTANT NOTE
  prefs: []
  type: TYPE_NORMAL
- en: The example given here has been built up to show you how to hang your code together
    by using some of the techniques discussed in this chapter. It is not necessarily
    the only way to bring all of these bits together, but it does act as a good illustration
    of how to create your own package. So, just remember that if you see a way to
    improve this implementation or adapt it to your own purposes, then brilliant!
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore how to build distributions of this code
    and how to allow ourselves and users to install the `outliers` package as a normal
    Python package that we can use in other projects.
  prefs: []
  type: TYPE_NORMAL
- en: Building your package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our example, we can package up our solution using the `setuptools` library.
    In order to do this, you must create a file called `setup.py` that contains the
    important metadata for your solution, including the location of the relevant packages
    it requires. An example of `setup.py` is shown in the following code block. This
    shows how to do this for a simple package that wraps some of the outlier detection
    functionality we have been mentioning in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that `setuptools` allows you to supply metadata such as the name
    of the package, the version number, and the software license. Once you have this
    file in the root directory of your project, you can then do a few things:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you can install the package locally as an executable. This will mean
    you can import your library like any other Python library in the code you want
    to run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can create a source distribution of the package so that all of the code
    is bundled together efficiently. For example, if you run the following command
    at the root of your project, a `gzipped tarball` is created in a folder called
    `dist`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can create a built distribution of the package, which is an object that
    can be unpacked and used immediately by the user without them having to run the
    `setup.py` script as in a source distribution. The most appropriate built distribution
    is what is known as a Python `wheel`. Running the following command in the root
    directory of your project creates the `wheel` and puts it in the `dist` folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you are going to distribute your code using pip, then it makes sense to
    package both a `source` distribution and a `wheel` and let the user decide what
    to do. So, you can build both and then use a package called `twine` to upload
    both distributions to PyPI. If you want to do this, then you need to register
    for a PyPI account at [https://pypi.org/account/register/](https://pypi.org/account/register/).
    Just run the previous two commands together in the root directory of your project
    and use the `twine upload` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For a lot more information on packaging, you can read through the information
    and tutorials at [https://www.pypa.io/en/latest/](https://www.pypa.io/en/latest/),
    provided by the **Python Packaging Authority** (**PyPA**).
  prefs: []
  type: TYPE_NORMAL
- en: The next section touches briefly on how we can automate a few of the steps around
    building and testing our packages using Makefiles.
  prefs: []
  type: TYPE_NORMAL
- en: Managing your environment with Makefiles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we are on a UNIX system and we have the `make` utility installed, then we
    can further automate a lot of the steps we want to run for our solution in different
    scenarios using Makefiles. For example, in the following code block, we have a
    Makefile that allows us to run our module’s main entry point, run our test suite,
    or clean up any artifacts using the `run`, `test`, and `clean` targets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a very simple Makefile, but we can make it as complex as needed by
    layering more and more commands. If we want to `run` a specific target set of
    commands, we simply call `make`, then the target name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This is a powerful way to abstract out a lot of terminal commands you would
    otherwise have to manually enter in each case. It also acts as documentation for
    other users of the solution!
  prefs: []
  type: TYPE_NORMAL
- en: The example we have just gone through is quite simple; let’s now make things
    more sophisticated. We can actually use Makefiles to manage our environments and
    help streamline our development process so that it does not require lots of cognitive
    effort just to keep track of the state of our environment.
  prefs: []
  type: TYPE_NORMAL
- en: The following examples leverage a lot of great work by Kjell Wooding, or *hackalog*
    on GitHub, specifically his repository [https://github.com/hackalog/make_better_defaults](https://github.com/hackalog/make_better_defaults).
  prefs: []
  type: TYPE_NORMAL
- en: 'This repository formed the basis of his talk at the 2021 PyData Global conference
    titled “Makefiles: One Great Trick for Making Your Conda Environments More Manageable.”'
  prefs: []
  type: TYPE_NORMAL
- en: First, the inclusion of a `Makefile.help` file allows for customizable help
    prompts when using the `make` command. If we run `make` in the terminal, assuming
    we are still in the main project directory, you will see the output in *Figure
    4.2*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: The help presented from the Makefile example.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This help message has been customized by using the `PROJECT_NAME` variable
    in the main Makefile, which has been set as `mlewp-ed2-ch4-outliers`. In fact,
    the top of the Makefile has several variables set for this project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The `MODULE` variable is referring to the name of the package as before. `PYTHON_INTERPRETER`,
    `CONDA_EXE`, and `VIRTUALENV` are hopefully self-explanatory. `ARCH` is grabbing
    architecture information from the local system. `EASYDATA_LOCKFILE` refers to
    a file that will be created as we work that helps us track the full list of dependencies
    in our project.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see that the help message clearly refers to different targets for the
    Makefile, so let’s explore each of these in turn. First, in order to standardize
    the creation of a new Conda environment for the project, if one is required, there
    are a few steps that can be brought together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Walking through this step by step, this code states that if `conda` is the virtual
    environment, then proceed to create or update a Conda environment with the project
    name and then export the environment into the `environment.yml` file; then after
    that, export the environment configuration into the lock file. It works this way
    because `$<` refers to the first prerequisite (in this case, the `environment.yml`
    file), and `$@` refers to the name of the target (in this case, the `EASYDATA_LOCKFILE`
    variable). After this is triggered, the second block is checking if `conda` is
    the virtual env manager before removing the lock file and then providing some
    guides to the user in the terminal. Note that `@` here is referring to terminal
    commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next important block in the Makefile is the one that handles updating the
    environment for you if required, which will often be the case during the “Develop”
    phase of your project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'This block ensures that if you run the following command in your terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Then you will create a new `lockfile.yml` with all of the details of the latest
    version of the environment. There is also a `delete_environment` target that will
    clear out the lockfiles and remove the Conda environment, as well as some other
    helper targets that need not concern us here, but that you can explore in the
    book repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bringing this all together, the workflow using this Makefile-based approach
    would be:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a starter `environment.yml` file for the project. This could be very
    simple; as an example, for the `outliers` package that we are building in the
    chapter, I started with an `environment.yml` file that looked something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the environment with:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Update the environment, which will create the first lockfile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you develop your solution, if you need a new package, go into the `environment.yml`
    file and add the dependency you require before running `make update_environment`.
    The idea here is that by not installing the packages manually but by mandating
    them in the `environment.yml` file, you are creating a more repeatable and robust
    workflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It becomes impossible for you to forget what you installed and what you haven’t!
    For example, if I wanted to add the `bandit` package to this environment, I would
    go into the `environment.yml` file using my text editor or IDE and would simply
    add that dependency in either the `conda` or `pip` dependency:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And that’s it! This is how you can use Makefiles to manage your Conda environments
    in a far more repeatable way. As mentioned above, if you wanted to start again,
    you can delete the environment by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: That covers this particular method for managing your Python development environment
    when developing your packages. We will now move on to discuss one of the most
    popular tools for Python dependency management and packaging in use today, **Poetry**.
  prefs: []
  type: TYPE_NORMAL
- en: Getting all poetic with Poetry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python package management is one of the things about the language that definitely
    does not have people screaming praise from the rooftops. It has been widely admitted
    by even the most ardent supporters of the language (myself included) that Python’s
    package management is, to put it bluntly, a bit of a mess. The examples we have
    walked through using `setup.py` and the production of wheels are some of the most
    accepted ways and, as mentioned, recommended by the PyPA. But they are still not
    the simplest or most intuitive approaches you would expect from a language that
    otherwise holds these as key design principles.
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, over the past few years, there have been a few major developments,
    one of which we will cover in detail here. This is the creation of the Python
    packaging and dependency management tool, Poetry. Poetry’s benefits include its
    ease of use and its drastic simplification of the packaging up and dependency
    management of your solution. Most visibly, it does this by requiring only one
    configuration file, the `pyproject.toml` file, rather than a potential setup including
    `setup.py`, `setup.cfg`, `MANIFEST.in`, or `Pipfile` configuration files. There
    is also a big advantage in the fact that the dependency file is locked so that
    auto-updates do not occur, which means the admin (you) has to explicitly call
    out changes in dependencies. This helps to make the project more stable.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, this sounds great, but how do we get started? Well, no surprise, we first
    install the tool using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, if you wanted to start a new project that leveraged Poetry, you would
    go into the appropriate directory where you want your package to be and run the
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'This would then create a sub-directory structure like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The `tests` folder will be where we place our unit tests, as covered in the
    *Testing* section of this chapter. `pyproject.toml` is the most important file
    in the directory. It specifies the main metadata concerning the project and is
    organized into blocks covering package dependencies for production and for development
    and testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The file generated when I ran the previous commands was the one shown in *Figure
    4.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3: The pyproject.toml file created by Poetry when we create a new
    project.'
  prefs: []
  type: TYPE_NORMAL
- en: In the first case, this is given in a block under `[tool.poetry]`, which covers
    high-level information about the package. Then there is `[tool.poetry.dependencies]`,
    which currently only contains Python version 3.10 and nothing else, as I have
    not used it to install anything else yet. The `[build-system]` section contains
    details of the build-time dependencies, here only listing `poetry-core`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we then want to add a new dependency, such as `pytest`, we can run a command
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: This will output in the terminal something like that shown in *Figure 4.4*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.4: Output from adding a new package to a Poetry-managed project.'
  prefs: []
  type: TYPE_NORMAL
- en: This will also update the `pyproject.toml` file with the new dependency, as
    shown in *Figure 4.5*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.5: Updated pyproject.toml file after adding a new dependency.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, the `[tool.poetry.dependencies]` section is the place where you should
    define all of the packages you need to be installed at runtime for your package,
    so you do not necessarily want to bloat this with lots of testing packages.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, Poetry allows you to define a block that lists your development dependencies
    by specifying a `[tool.poetry.group.dev.dependencies]` block, like that shown
    in *Figure 4.6*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.6: The pyproject.toml file with a set of development dependencies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When you install Poetry, it creates its own virtual environment in order to
    create appropriate isolation from the rest of your system. You can activate this
    environment if you are on a Linux system by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Or you can also run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: If you already have a Python virtual environment running through Conda, `venv`,
    or some other tool, then Poetry is actually aware of this and works within it.
    This can be very helpful as you can use Poetry to manage that virtual environment,
    rather than starting completely from scratch. In this case, you may get some output
    in the terminal like that shown in *Figure 4.7*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.7: Output from poetry shell command if you are already working in
    a Python virtual environment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To close down this environment but not the shell you are running, you can use
    the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to close the environment and the shell (be warned, this will likely
    close your terminal), you can type the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'To install the dependencies you have been adding in the `pyproject.toml` file,
    you can run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: This will either download and install all the dependencies listed in your `pyproject.toml`
    file, grabbing the latest versions from `pip`, or it will grab and install the
    versions of these packages as they are listed in the `.lock` file. This is to
    ensure that even if multiple people have been working in the environment and running
    `poetry install` commands, the environment is kept stable with consistent package
    versions. This is exactly the same reason for using a `.lock` file in the section
    on Makefiles earlier in this chapter. When the `install` command was run for this
    `my-ml-package` project, for example, the output was that shown in *Figure 4.8*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.8: Poetry installing packages from the .lock file in order to maintain
    environment stability.'
  prefs: []
  type: TYPE_NORMAL
- en: 'All of the preceding commands are around the basic management of the environment,
    but what about when we want to do something with this environment? Well, if you
    have a script called `main.py`, you can run this using the Poetry-configured environment
    via the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'We do not have anything like this in the `my-ml-package`. Instead, since we
    are building a library, we can package and deploy the package by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: This gives the output shown in *Figure 4.9*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.9: The output when Poetry builds our simple package.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to publish to PyPI, which only works if you are a registered user
    with the correct credentials configured, you can just run the command `poetry
    publish`. If you want to publish to some other private repository, you can run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: After all of this, you can probably see how Poetry can make things a lot clearer
    when it comes to package development. We have been able to manage stable development
    and production (like Python environments that can be worked on by multiple developers
    without fear of corruption), build and publish our package, as well as run any
    scripts and processes we want to – all in a few commands!
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s cover some of the steps we can take to ensure that our packages
    are robust and can be trusted to work or fail gracefully and be diagnosable if
    there is an issue.
  prefs: []
  type: TYPE_NORMAL
- en: Testing, logging, securing, and error handling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building code that performs an ML task may seem like the end goal, but it is
    only one piece of the puzzle. We also want to be confident that this code will
    work, and if it doesn’t, we will be able to fix it. This is where the concepts
    of testing, logging, and error handling come in, which the next few sections cover
    at a high level.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most important features that sets your ML-engineered code apart from
    typical research scripts is the presence of robust testing. It is critical that
    any system you are designing for deployment can be trusted not to fall down all
    the time and that you can catch issues during the development process.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, since Python is a general-purpose programming language, it is replete
    with tools for performing tests on your software. In this chapter, we will use
    **pytest**, which is one of the most popular, powerful, and easy-to-use testing
    toolsets for Python code available. pytest is particularly useful if you are new
    to testing because it focuses on building tests as standalone Python functions
    that are quite readable, whereas other packages can sometimes lead to the creation
    of clunky testing classes and complex `assert` statements. Let’s dive into an
    example.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s start by writing tests for some pieces of code defined in the
    rest of this chapter from our `outliers` package. We can define a simple test
    to ensure that our data helper function actually creates some numerical data that
    can be used for modeling. To run this sort of test in pytest, we first create
    a file with `test_` or `_test` in the name somewhere in our test’s directory—pytest
    will automatically find files that have this in their name. So, for example, we
    may write a test script called `test_create_data.py` that contains the logic we
    need to test all of the functions that refer to creating data within our solution.
    Let’s make this explicit with an example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the relevant modules we will need from the package and anything else
    we need for testing. Here, we import `pytest` because we will use some functionality
    from it in later steps but, in general, you don’t need to import this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, since we want to test the function for creating data, it would be good
    to only generate the data once, then test its attributes in a variety of ways.
    To do this, we employ the `fixture` decorator from pytest, which allows us to
    define an object that can be read into several of our tests. Here, we use this
    so that we can apply our tests using `dummy_data`, which is just the output of
    the `create_data` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can actually write the tests. Here are two examples that test if
    the dataset created by the function is a `numpy` array and if it has more than
    `100` rows of data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can write as many of these tests and as many of these types of test modules
    as we like. This allows us to create a high degree of **test coverage** across
    our package.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can then enter the following command in the terminal at the top level of
    your project in order to run all the tests in the package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Then you will see a message like this, telling us what tests have run and which
    have passed and failed:![Figure 4.3 – The output of a successful unit test in
    PyTest ](img/B19525_04_10.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.10: The output of a successful unit test in pytest.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The previous example showed how to write and execute some basic tests on our
    data utilities. We can now expand on this by testing some of the more sophisticated
    functionality in the package – namely, the model creation process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Similarly to the previous case, we create a script for holding our tests in
    `tests/test_detectors.py`. Since we are testing more complex functionality, we
    will have to import more pieces of the package into the script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will have the same fixture for dummy data created as in *Step 2*, but now
    we also have a fixture for creating some example models to use in tests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Our final fixture creates an example detector instance for us to use, based
    on the previous model’s fixture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And now we are ready to test some of the model creation functionality. First,
    we can test that the models we created are not empty `objects`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can then test that we can successfully retrieve models using the instance
    of `DetectionModels` created in *Step 6*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can test that the results found by applying the model pass some
    simple tests. This shows that the main pieces of our package are working for an
    end-to-end application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As in *Step 4*, we can run the full test suite from the command line. We add
    a verbosity flag to return more information and show the individual tests that
    pass. This helps confirm that both our data utility and our model tests are being
    triggered:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The output is shown in the following screenshot:![Figure 4.4 – Output of successful
    tests on both data and model functionality ](img/B19525_04_11.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 4.11: Output of successful tests on both data and model functionality.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The running of these tests can be automated either via the inclusion of `githooks`
    in our repository or through the use of other tools, such as the `Makefile` used
    for the project.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll now move on to consider how we can log information about our code as it
    runs, which can help with debugging and general monitoring of your solution.
  prefs: []
  type: TYPE_NORMAL
- en: Securing your solutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As software engineers of any kind, we should always be very cognizant of the
    fact that there is a flip-side to the joy of building products that people use.
    This flip-side is that it is then your job to make sure the solution is secure
    and safe for those users. In the words of Uncle Ben, “*With great power comes
    great responsibility*.”
  prefs: []
  type: TYPE_NORMAL
- en: Now, cybersecurity is a huge discipline in its own right, so we cannot do it
    justice here. The following sections will simply aim to introduce some useful
    tools and explain the basics of using them in order to make your solutions more
    secure and trustworthy.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to understand the different ways we can create secure solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: Testing the application and code itself for internal bugs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Screening packages and scanning other code used for security vulnerabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing for data leaks and data exposure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing robust monitoring techniques, specifically with respect to the above
    points and less so about the monitoring of your ML models, which has been covered
    elsewhere in this book.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first case, this refers mostly to things like our unit-testing approaches,
    which, again, we have covered elsewhere, but in brief, this refers to the act
    of testing the functionality of the code you write in order to ensure it works
    as expected. In the section on model monitoring, it was mentioned that performing
    standard tests for the expected performance of a machine learning model can be
    difficult and so requires specific techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we are focused more on the general application code and the solution wrapping
    the main model.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of screening packages and code, this is a very pertinent and, thankfully,
    easy-to-implement challenge. The reader may recall that in 2022, there was a wave
    of activity across the world as organizations and software engineers tried to
    deal with the discovery of a bug in the Java-based Log4j library. Bugs and security
    flaws will always happen and not always be detected, but this point is all about
    having some system in place to automatically scan the code and packages you are
    using in your solution to find these proactively, saving major headaches (and
    far worse) for the users of your code.
  prefs: []
  type: TYPE_NORMAL
- en: Data leakage is an incredibly important topic now. Regulations like the **General
    Data Protection Regulation** (**GDPR**) in the European Union have placed a massive
    emphasis on the management and curation of customers’ data. Since machine learning
    systems are fundamentally data-driven applications, this means that concerns around
    privacy, usage, storage, and many other points become extremely important to consider
    in designs and implementations. It is important to note that what we are discussing
    here goes far beyond the “garbage in, garbage out” question of data quality, and
    really is about how securely you are holding and transferring the data required
    to make your machine learning system work.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing your own code for security issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you will have noticed throughout this book, the Python open-source community
    has almost every challenge you can think of covered in at least some way, and
    when it comes to security, this is no different. To perform static analysis of
    your own code and check for vulnerabilities that may have been introduced during
    development, you can use the open-source Bandit package, [https://bandit.readthedocs.io/en/latest/](https://bandit.readthedocs.io/en/latest/).
    This is a linter that is focused on finding security issues in source code, and
    it is extremely easy to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, as always, we need to install Bandit. We can now do this using the Makefile
    magic we learned about in the earlier section on *Building your package*, so we
    add the Bandit package to the `pip` dependencies in the `environment.yml` file
    and run the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, to run Bandit on your source code, you simply run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'As we mentioned in *Chapter 2*, *The Machine Learning Development Process*,
    it is always useful to automate any development steps that you will want to run
    again and again. We can do this with Bandit by adding the following to our `.pre-commit-config.yaml`
    in our Git directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: This means that after every commit, we will run the `bandit` command as outlined
    in the previous two steps.
  prefs: []
  type: TYPE_NORMAL
- en: The output from running Bandit on some example code is given by a series of
    blocks like the following in *Figure 4.12*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.12: Bandit output on a typical piece of code.'
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by a small summary report at the end of the output, shown in
    *Figure 4.13.*
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.13: The Bandit tool provides a high-level summary at the end of its
    output for diagnosing the state of your code base.'
  prefs: []
  type: TYPE_NORMAL
- en: There are many more features of Bandit but this shows how easy it is to get
    started and start analyzing the potential issues in your Python code base.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing dependencies for security issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we have outlined, we don’t just want to scan the code we have written for
    security vulnerabilities; it is also important that we try and find any issues
    in the packages that we are using in our solution. This can be done using something
    like the Python `safety` tool, [https://pypi.org/project/safety/](https://pypi.org/project/safety/).
    Safety uses a standardized database containing known Python security issues and
    then compares any packages found in your solution against this database. Please
    note that, as the documentation for safety calls out:'
  prefs: []
  type: TYPE_NORMAL
- en: By default it uses the open Python vulnerability database Safety DB, which is
    licensed for non-commercial use only.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For all commercial projects, Safety must be upgraded to use a PyUp API using
    the key option.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Below is an example of using this on the same source code tree as in the example
    for using Bandit:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you do not have safety installed, install it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You then need to change into the top folder of your source code tree before
    running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When I ran this on the folder containing the `outlier_package` we have been
    building, I got the terminal output shown in *Figure 4.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.14: The output of safety on the outliers package.'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from *Figure 4.15*, we are being warned that the current version
    cannot be used for scanning commercial software and that if this was needed, you
    should get an API key. For the project here, this is fine. One vulnerability has
    been found by the tool relating to the version of the `wheel` package. Upon inspection
    of the `environment.yml` file in the project, we see that we can update this to
    version 0.38.1 as the advisory note suggests. This is shown in *Figure 4.15*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.15: Updating the environment.yml file in order to avoid the error
    produced by the safety tool.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the Conda channels used in this `environment.yml` file did not have
    the `wheel` package in version 0.38.1 or greater so this was added to the `pip`
    dependencies instead, as shown in *Figure 4.16*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.16: Updating the pip dependencies of the environment.yml file in the
    outliers package.'
  prefs: []
  type: TYPE_NORMAL
- en: 'After doing this and re-running the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: The solution is given a clean bill of health, as shown in the report in *Figure
    4.17*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19525_04_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.17: The safety tool returns zero security vulnerabilities after updating
    the identified package.'
  prefs: []
  type: TYPE_NORMAL
- en: Although safety does require a commercial license in order to get the full set
    of features, it can still be extremely helpful for sniffing out issues in your
    dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, it is important to ensure that as your code is running, the status of
    the different operations is reported, as well as any errors that occur. This helps
    make your code more maintainable and helps you debug when there is an issue. For
    this, you can use the Python `logging` library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Loggers can be instantiated in your code via logic like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'This code defines our format for the logging messages and specifies that logging
    messages of level `DEBUG` or higher will go to the `outliers.log` file. We can
    then log output and information relevant to our code’s running status using the
    very easy-to-use syntax that comes with the `logging` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: What we have shown so far is really the basics of logging and it so far assumes
    that, although things may not be going perfectly, nothing has errored. This is
    obviously not always the case! So, what if we want to log an exception or error
    to our logging file?
  prefs: []
  type: TYPE_NORMAL
- en: Well, this is typically done with the `logging.error` syntax but with an important
    point we must consider, which is that it is often not enough to just log the fact
    we’ve raised an error; we would also like to log the details of the error. So,
    as discussed in the *Error handling* section, we know that we can execute a `try`
    `except` clause on some code and then raise an exception. What we want to do in
    this case is log the details of that exception to our logging target. To do this
    we need to know that the `logging.error` method (and the `logging.debug` method)
    have some important keyword arguments we can use. For more on keyword arguments,
    see the section on *Tips and tricks* in this chapter. According to the logging
    documentation, [https://docs.python.org/3/library/logging.xhtml#logging.debug](https://docs.python.org/3/library/logging.xhtml#logging.debug),
    the keyword arguments `exc_info` and `stack_info` are given as Booleans, and `extra`
    is a dictionary. The keyword argument `exc_info = True` specifies that we wish
    to return exception information in the logging call, `stack_info = True` will
    return far more detailed stack trace information for the exception (including
    the logger call), and `extra` can be set equal to a dictionary with extra information
    that the developer has defined.
  prefs: []
  type: TYPE_NORMAL
- en: The extra information in this case is then provided with the initial part of
    the record, as part of the identifier of the event. This is a good way to provide
    some bespoke information to your logging calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let us consider a bespoke feature transformation function, which,
    in this case, will actually not do anything useful, just return the original DataFrame
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to raise an exception when this function failed and log details
    about the error, we could write something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run this code on a simple dummy pandas DataFrame like the one below,
    the code will execute without issue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'If, however, we do the same, but this time, we run the code on something that
    does not have the pandas DataFrame `mean()` syntax, like a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B19525_04_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.18: The output to the log file when we use the exc_info = True flag.'
  prefs: []
  type: TYPE_NORMAL
- en: Error handling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The last piece of *housekeeping* to cover in this section is error handling.
    It is important to remember that when you are an ML engineer, your aim is to build
    products and services that work, but an important part of this is recognizing
    that things do not always work! It is therefore important that you build in patterns
    that allow for the escalation of (inevitable) errors during runtime. In Python,
    this is typically done via the concept of *exceptions*. Exceptions can be raised
    by the core Python functions and methods you are using. For example, imagine you
    ran the following code without defining the variable `x`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'The following exception would be raised:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'The important point for us as engineers is that we should build solutions in
    which we can confidently control the flow of errors. We may not always want our
    code to break when an error occurs, or we may want to ensure that very specific
    messages and logging occur upon certain expected edge cases. The simplest technique
    for doing this is via `try except` blocks, as seen in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: In this case, `do_something_else()` is executed if `do_something()` runs into
    an error.
  prefs: []
  type: TYPE_NORMAL
- en: We will now finish with a comment on how to be efficient when building your
    solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Error handling in Python is often built around the idea of “exceptions,” which
    are just events that disrupt the expected functioning of the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'The full list of exceptions in Python contains around 50 different types. Below
    is an excerpt taken from the Python documentation, with ellipses highlighting
    where I have not shown the full details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see from the exception list that these are organized in a hierarchy.
    This means that raising an exception at a lower level is simply a more specific
    instance of an exception at a higher level, so you can actually raise it at a
    higher level of the hierarchy and everything still works correctly. As a quick
    example, we can see from the `ArithmeticError` sub-hierarchy that there are three
    exceptions at a lower level in the hierarchy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'This then means that if we were to raise an exception for a piece of code we
    think may divide a number by zero, we can legally use `ZeroDivisionError` or `ArithmeticError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'In general, when you catch an exception, there are a few different routes you
    can go down to handle it. First, you could handle the exception and continue the
    program flow. You should do this when it is clear what will be causing the error
    and it can be handled within the logic of the code. Second, you could raise the
    exception again. You may want to do this for a few reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You want to log the error but still allow the exception to propagate up the
    call stack. This can be useful for debugging purposes, as it allows you to log
    the error message and other details about the exception, while still allowing
    the calling code to handle the exception as appropriate. An example may look something
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this example, the `process_data` function tries to process some data and
    returns the result. If an exception occurs while processing the data, the exception
    is logged using the `logging.exception` function, which logs the exception along
    with a stack trace. The exception is then re-raised using the `raise` statement,
    which allows the calling code to handle the exception as appropriate.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You want to add additional context to the exception. For example, you might
    want to add information about the state of your application when the exception
    occurred, or about the input that led to the exception being raised. Adapting
    the previous example, we may then have something like:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this example, if an exception occurs while processing the data, the exception
    message is modified to include the data that was being processed. A new exception
    is then raised using the modified message and the original exception as the cause
    (using the `from e` syntax).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You want to handle an exception in a higher level of your code but still allow
    lower-level code to handle the exception if it is not appropriate to handle it
    at the higher level. This is a bit more complex, so we will try and walk through
    another adapted example step by step. First, this time, when we raise the exception,
    we call a function that handles the exception in a bespoke way, called `handle_exception`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The code for `handle_exception` would look something like the following, where
    we have to determine if we want to handle the exception at this level of abstraction
    or pass it up the call stack, using another function called `should_handle`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `should_handle` function would then be where we define our bespoke logic
    for deciding if we handle the exception at the current level or use the raise
    syntax to escalate up the call stack. For example, if we want to handle an `ArithmeticError`
    at this level and otherwise we want to raise up the call stack, the logic would
    look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, you may raise a different exception, perhaps because you need to bring
    together a few different exceptions and deal with them together at a higher level
    of abstraction. Once again, adapting the previous examples, this may mean that
    you write some code that looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this example, if a `ValueError` exception occurs while processing the data,
    it is caught and a new `MyCustomException` is raised with the same message. If
    a `MyCustomException` exception occurs, it is caught and a new `MyCustomException`
    is raised with a modified message that includes the `data` that was being processed.
    This allows you to deal with different types of exceptions together at a higher
    level of abstraction, by raising a single, custom exception type that can be handled
    in a consistent way.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A third program flow that we can use is that we can raise a new exception from
    within the original exception. This can be helpful because we can provide more
    detailed information about the type of error that has occurred, and we can give
    more contextual information that will help us debug any issues down the line.
    To make this clearer, let’s define an example function to stand in for the function
    we’ve been using in the previous examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'We will call this in the same function as we had in the first example of the
    list above but now we will add a new piece of syntax to raise an exception from
    the original exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'The raising from the original exception now ensures that we have logged the
    fact that this was specifically a `ValueError` related to the input data, and
    it allows us to log a higher-level message that can give additional context in
    the stack trace. For example, if you use the above functions and run this function
    call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'We get an error, as expected, since we are supplying a string and then trying
    to add an integer to it. A snippet from the stack trace I got when I ran this
    is given below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'The above exception was the direct cause of the following exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: You can see how the exception we raised from the original exception calls out
    where in the `process_data` function the error has occurred, and it has also given
    us the information that this issue relates to the processing of the data. Both
    pieces of information help provide context and can help us debug. The more technical
    original exception, the `TypeError` referring to the operand types, is still useful
    but could be hard to digest and fully debug on its own.
  prefs: []
  type: TYPE_NORMAL
- en: This only scratches the surface of what is possible when it comes to logging,
    but this will allow you to get started.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we move on to what we need to do in our code to handle scenarios where
    things go wrong!
  prefs: []
  type: TYPE_NORMAL
- en: Not reinventing the wheel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will already have noticed through this chapter (or I hope you have!) that
    a lot of the functionality that you need for your ML and Python project has already
    been built. One of the most important things you can learn as an ML engineer is
    that you are not supposed to build everything from scratch. You can ensure you
    do not do this in a variety of ways, the most obvious of which is to use other
    packages in your own solution and then build a functionality that enriches what
    is already there. As an example, you do not need to build basic regression modeling
    capabilities since they exist in a variety of packages, but you might have to
    add a new type of regressor or use some specific domain knowledge or trick you
    have developed. In this case, you would be justified in writing your own code
    on top of the existing solution. You can also use a variety of concepts from Python,
    such as wrapper classes or decorators. The key message is that although there
    is a lot of work for you to do when building your ML solutions, it is important
    that you do not feel the need to build everything from scratch. It is far more
    efficient to focus on where you can create added value and build on what has gone
    before!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has been all about best practices for when you write your own Python
    packages for your ML solutions. We went over some of the basic concepts of Python
    programming as a refresher before covering some tips and tricks and good techniques
    to bear in mind. We covered the importance of coding standards in Python and PySpark.
    We then performed a comparison between object-oriented and functional programming
    paradigms for writing your code. We moved on to the details of taking the high-quality
    code you have written and packaging it up into something you can distribute across
    multiple platforms and use cases. To do this, we looked into different tools,
    designs, and setups you could use to make this a reality, including the use of
    Makefiles and Poetry. We continued with a summary of some housekeeping tips for
    your code, including how to test, log, and monitor your solution. This also included
    some detailed examples of exception handling and how you can develop more sophisticated
    control flows in your programs and packages. We finished with a brief *philosophical*
    point on the importance of not reinventing the wheel.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a deep dive into the world of deployment.
    This will be all about how you take scripts, packages, libraries, and apps that
    you have written and run them on appropriate infrastructure and tools.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussion with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/mle](https://packt.link/mle)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code102810325355484.png)'
  prefs: []
  type: TYPE_IMG
