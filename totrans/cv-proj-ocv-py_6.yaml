- en: Facial Feature Tracking and Classification with dlib
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用dlib进行面部特征追踪和分类
- en: In this chapter, we'll learn about dlib and how to locate faces from images
    and videos with the help of some examples. We will also learn about facial recognition
    using dlib.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习dlib及其如何通过一些示例从图像和视频中定位人脸，同时也会学习使用dlib进行面部识别。
- en: 'We are going to cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Introducing dlib
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍dlib
- en: Facial landmarks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部特征点
- en: Finding 68 facial landmarks in images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像中找到68个面部特征点
- en: Faces in videos
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频中的面部
- en: Facial recognition
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部识别
- en: Introducing dlib
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍dlib
- en: dlib is a general-purpose, cross-platform software library written in the programming
    language C++. We are going to learn dlib and understand how to find and use human
    facial features from images and videos. According to their own website, [dlib.net](http://dlib.net/),
    dlib is a modern C++ tool containing machine learning algorithms and tools for
    creating complex software in C++ to solve real-world problems. It is a C++ toolkit
    and, just like OpenCV, it contains a very nice set of Python bindings that will
    work very well for our applications.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: dlib是一个通用、跨平台的软件库，使用C++编程语言编写。我们将学习dlib，并理解如何从图像和视频中找到和使用人类面部特征。根据其官方网站[dlib.net](http://dlib.net/)，dlib是一个现代的C++工具，包含机器学习算法和用于在C++中创建复杂软件的工具，以解决现实世界的问题。它是一个C++工具包，就像OpenCV一样，它包含了一套非常优秀的Python绑定，这将非常适合我们的应用。
- en: dlib is a very rich library and contains a whole lot of algorithms and features,
    which are very well documented on their website. This makes it easy to learn from,
    and it has a whole lot of examples similar to what we're going to do in this chapter
    and for your customized projects. It is recommended that you check their website
    if you're interested in dlib and want to learn how to use it for your applications.
    The *High Quality Portable Code* section on the [http://dlib.net/](http://dlib.net/) website
    has efficient code for Microsoft Windows, Linux, and macOS, and just like Python,
    contains a very rich set of machine learning algorithms, including state-of-the-art
    deep learning, which we are using in this chapter, although we're going to use
    TensorFlow for our purposes. It also has **Support Vector Machines** (**SVMs**),
    which we saw in Chapter 5, *Handwritten Digit Recognition with scikit-learn and
    TensorFlow* on handwritten digit recognition, and a wide variety of other things
    for object detection and clustering, K-means, and so forth. It also has a rich
    set of numerical algorithms, linear algebra, **singular value decomposition**
    (**SVD**), and a whole lot optimization algorithms, as well as graphical model
    inference algorithms, and image processing (which is very useful for us). It has
    routines for reading and writing common image formats (although we won't use them
    as we're going to use the tools that we've already seen for reading and writing
    images) and **Speeded-Up Robust Features** (**SURF**), **Histogram of Oriented
    Gradient** (**HOG**), and FHOG, which are useful for image detection and recognition.
    What's interesting for now are the tools for detecting objects, including frontal
    face detection, pose estimation, and facial feature recognition. So, we'll talk
    about that in this chapter. There are some other features of dlib, such as threading,
    networking, **Graphical User Interface** (**GUI**) development, data compression,
    and a bunch of other utilities. [http://dlib.net/](http://dlib.net/) includes
    examples in C++ and examples in Python. What we're going to be interested in is
    face detection, facial landmark detection, and recognition. So, we're going to
    go through similar examples to see what we have here.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: dlib是一个非常丰富的库，包含大量算法和功能，这些内容在他们的网站上都有很好的文档说明。这使得学习起来变得容易，并且它提供了许多与我们在本章将要做的以及为您的定制项目相似的示例。如果您对dlib感兴趣并想了解如何将其用于您的应用程序，建议您查看他们的网站。在[http://dlib.net/](http://dlib.net/)网站的*高质量便携代码*部分，有针对Microsoft
    Windows、Linux和macOS的高效代码，就像Python一样，包含了一个非常丰富的机器学习算法集，包括我们在本章使用的最先进的深度学习，尽管我们将使用TensorFlow来完成我们的目的。它还包括**支持向量机**（**SVMs**），我们在第5章“使用scikit-learn和TensorFlow进行手写数字识别”中看到过，以及用于目标检测和聚类的广泛其他功能，如K-means等。它还包含丰富的数值算法、线性代数、**奇异值分解**（**SVD**）以及大量的优化算法，以及图形模型推理算法和图像处理（这对我们非常有用）。它有读取和写入常见图像格式的例程（尽管我们不会使用它们，因为我们将使用我们之前看到的工具来读取和写入图像）以及**加速鲁棒特征**（**SURF**）、**方向梯度直方图**（**HOG**）和FHOG，这些对图像检测和识别很有用。目前有趣的是检测对象的各种工具，包括正面人脸检测、姿态估计和面部特征识别。因此，我们将在本章中讨论这些内容。dlib还有一些其他功能，如多线程、网络、**图形用户界面**（**GUI**）开发、数据压缩以及许多其他实用工具。[http://dlib.net/](http://dlib.net/)提供了C++和Python的示例。我们将对人脸检测、面部特征点检测和识别感兴趣。因此，我们将通过类似的示例来查看我们这里有什么。
- en: Facial landmarks
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部特征点
- en: We're going to learn all about facial landmarks in dlib. Before we can run any
    code, we need to grab some data that's used for facial features themselves. We'll
    see what these facial features are and exactly what details we're looking for.
    This is not included with Python dlib distributions, so you will have to download
    this. We'll go to the [dlib.net/files/](http://dlib.net/files) site, where you
    can see all the source code files; scroll to the bottom and you can see the `shape_predictor_68_face_landmarks.dat.bz2`
    file. Click on it and then save it wherever you keep your Jupyter Notebooks for
    this book.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习dlib中关于面部特征点的所有内容。在我们能够运行任何代码之前，我们需要获取一些用于面部特征本身的数据。我们将了解这些面部特征是什么以及我们具体在寻找哪些细节。这些内容不包括在Python
    dlib发行版中，因此您将需要下载这些内容。我们将访问[dlib.net/files/](http://dlib.net/files)网站，在那里您可以查看所有源代码文件；滚动到页面底部，您可以看到`shape_predictor_68_face_landmarks.dat.bz2`文件。点击它，然后将其保存到您为这本书的Jupyter
    Notebooks保留的位置。
- en: Okay, so, what exactly is that? What are these 68 landmarks? Well, these landmarks
    are a common feature set that was generated by training alpha datasets from something
    called iBUG ([https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/](https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/)),
    the intelligent behavior understanding group. So, this is a pre-trained model,
    a database of a whole bunch of human faces of people from all over the world,
    male/female, different age groups, and so forth.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那么，这究竟是什么？这68个标记点是什么？嗯，这些标记点是通过对称为iBUG（[https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/](https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/））的智能行为理解小组从alpha数据集进行训练生成的常见特征集。所以，这是一个预训练模型，一个包含来自世界各地、各种年龄、男性和女性等人群的大量人脸数据库。
- en: 'So, we''ll work on a variety of cases, and what we''re looking for is a bunch
    of points around the outline of the face, as you can see in the following diagram:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将处理各种情况，我们寻找的是围绕面部轮廓的一组点，正如您可以在以下图中看到：
- en: '![](img/03f332b3-640a-46e9-a413-1d8ef79dca42.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/03f332b3-640a-46e9-a413-1d8ef79dca42.png)'
- en: Points **1** through **17** are the outline of the face, points **18** through
    **22** are the right eyebrow, **23** to **27** the left eyebrow, **28** to **31**
    the ridge of the nose, **30** to **36** the base of the nose, **37** to **42**
    forms the right eye, and **43** to **48** outlines the left eye, and then there
    are a whole bunch of points for the mouth, including both sides of the upper lip
    and both sides of the lower lip.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 点**1**至**17**是面部轮廓，点**18**至**22**是右眉毛，**23**至**27**是左眉毛，**28**至**31**是鼻梁，**30**至**36**是鼻底，**37**至**42**形成右眼，**43**至**48**勾勒出左眼，然后还有许多关于嘴巴的点，包括上唇两侧和下唇两侧。
- en: So, these are common features that all human faces will have, and this will
    allow us to do a whole lot of things like facial recognition and identification,
    pose estimation, possibly age estimation, gender estimation, and even neat things
    like facial stitching and facial blending. A lot of very interesting things can
    be done just with this information, and these are just based on pure intensity
    values on the face. So, there are no SURF features, **Scale Invariant Feature
    Transform** (**SIFT**) features, HOG features, or anything like that. These are
    just detectable from pixel values. So, effectively you can convert from RGB to
    black and white to monochrome, and you can run this model if it's an ensemble
    of regression trees.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这些是所有人类面孔都会有的常见特征，这将使我们能够做很多事情，如人脸识别和身份验证、姿态估计、可能年龄估计、性别估计，甚至像面部缝合和面部混合这样的有趣事情。仅凭这些信息就可以做很多非常有趣的事情，这些都是基于面部纯强度值。所以，这里没有SURF特征、**尺度不变特征变换**（**SIFT**）特征、HOG特征或任何类似的东西。这些只是从像素值中可检测到的。所以，实际上您可以将RGB转换为黑白到单色，并且如果这是一个回归树的集成，您可以运行这个模型。
- en: You can download the iBUG dataset and train your own model, and you can actually
    vary the number of features. There are datasets with more features than this,
    but this is more than adequate for our purposes. You can train it if you want
    to run it on a variety of faces or particular faces, but you'll find that this
    pre-trained dataset is going to work in a wide variety of cases. So, iBUG is powerful
    in and of itself. We're going to use it here, and we're going to see how to run
    the code that will find all these features for some images and for some videos.
    Then, we're going to apply that to the facial recognition problem, where we differentiate
    between faces in a given set. After you have downloaded the `shape_predictor_68_face_landmarks.dat.bz2`
    file, you can put the file in your directory where you have your Jupyter Notebook
    and with that, we can get started with our code.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以下载iBUG数据集并训练您自己的模型，并且您实际上可以调整特征的数量。有比这更多特征的数据集，但这对我们的目的来说已经足够了。如果您想对各种面孔或特定面孔运行它，您可以训练它，但您会发现这个预训练数据集在许多情况下都会有效。因此，iBUG本身就很强大。我们将在这里使用它，并展示如何运行代码来为一些图像和视频找到所有这些特征。然后，我们将将其应用于人脸识别问题，其中我们在给定集合中区分面孔。在您下载了`shape_predictor_68_face_landmarks.dat.bz2`文件后，您可以将该文件放入您拥有Jupyter
    Notebook的目录中，然后我们可以开始编写代码。
- en: Finding 68 facial landmarks in images
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在图像中寻找68个面部标记点
- en: 'In this section, we''re going to see our first example, where we find 68 facial
    landmarks and images with single people and with multiple people. So, let''s open
    our Jupyter Notebook for this section. Take a look at this first cell:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到我们的第一个示例，其中找到68个面部地标和单人图像以及多个人图像。所以，让我们打开本节的Jupyter Notebook。看看这个第一个单元格：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We've got to do some basic setup, as we did in the previous chapters. We're
    going to initialize `%pylab notebook`. Again, that will load NumPy and PyPlot
    and some other stuff, and we're going to perform `notebook` for now, which will
    be good for close-up views of images, though we're going to switch it to `inline`
    for the second example because we'll need that for looking at videos. Then, we
    have to import our other libraries. dlib is the focus of this section, of course.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做一些基本的设置，就像我们在前面的章节中所做的那样。我们将初始化`%pylab notebook`。再次强调，这将加载NumPy和PyPlot以及其他一些东西，我们现在将执行`notebook`，这对于图像的近距离观察很有用，尽管我们将它切换到`inline`用于第二个示例，因为我们需要它来查看视频。然后，我们必须导入我们的其他库。dlib当然是本节的重点。
- en: We're going to use a few utilities from OpenCV, but it's just additional annotation
    and working with videos. We're going to use `tkinter` so we have a nice file dialog
    display. So, rather than hardcoding the filename into our code, we'll just prompt
    the user for the file that we want to analyze. We'll import `display` from `IPython`
    in order to watch the movie for the second example, and we have to set up `tkinter`;
    we want to make sure that we're in the working directory with all our files. You
    might not need this, but you can do it just to be sure.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用OpenCV的一些实用工具，但这只是额外的注释和视频处理。我们将使用`tkinter`来有一个漂亮的文件对话框显示。所以，而不是将文件名硬编码到我们的代码中，我们将提示用户输入我们想要分析的文件。我们将从`IPython`导入`display`以便在第二个示例中观看电影，我们必须设置`tkinter`；我们想要确保我们处于包含所有文件的工作目录中。你可能不需要这样做，但你可以这样做以确保。
- en: 'So, we''re going to select the cell, hit *Ctrl* + *Enter*, and then, if everything
    worked correctly, you should see the following output:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将选择单元格，按*Ctrl* + *Enter*，然后，如果一切正常，你应该看到以下输出：
- en: '![](img/b8e2d5f1-8a71-4a80-9fa6-856e48514edb.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b8e2d5f1-8a71-4a80-9fa6-856e48514edb.png)'
- en: You can see `Populating the interactive namespace` and your current working
    directory.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到`Populating the interactive namespace`和你的当前工作目录。
- en: 'Okay, so let''s see the first example now that we''re set up, and we''ll actually
    use those 68 features from that file that we downloaded; we''ll see how easy it
    is to do this within dlib. Now, we''re going to see that this is only just a little
    bit of code, but it does something really cool:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们已经设置好了，让我们看看第一个示例，我们将实际使用我们下载的文件中的68个特征；我们将看到在dlib中这样做是多么简单。现在，我们将看到这只是一点点的代码，但它确实做了些非常酷的事情：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'First, we''re going to ask the user for the filename. So, this is using `tkinter`
    and we''re going to open a filename; it''ll start searching in the current working
    directory using the `initialdir=os.getcwd()` function:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将要求用户输入文件名。所以，这是使用`tkinter`，我们将打开一个文件名；它将使用`initialdir=os.getcwd()`函数在当前工作目录中开始搜索：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We''ll read that in using the following line:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下行来读取：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `img.flags['WRITEABLE']=True` line is kind of a quirk of dlib, not really
    a big deal but, depending on how you loaded the file, `flags` for a `WRITEABLE`
    might be set `False`. That happens with `imread`. It depends on how you load it,
    but just to be sure, `WRITEABLE` needs to be set to `True`. Otherwise, dlib will
    throw an error. Depending on how you load, this might not be necessary.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`img.flags[''WRITEABLE'']=True`这一行是dlib的一个小特性，并不是什么大问题，但是，根据你如何加载文件，`WRITEABLE`的`flags`可能被设置为`False`。这种情况发生在使用`imread`时。这取决于你如何加载它，但为了确保，`WRITEABLE`需要被设置为`True`。否则，dlib会抛出一个错误。根据你的加载方式，这可能不是必要的。'
- en: 'We want to create an image that we can write on, where we can actually display
    where the landmarks were found, so we''re going to create a copy of our image
    that we loaded earlier, the image that has the face in it, so we can write to
    it without clobbering the original image:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要创建一个可以写入的图像，实际上可以显示地标的位置，所以我们将创建我们之前加载的图像的副本，即包含人脸的图像，这样我们就可以写入它而不会覆盖原始图像：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, we will load the data from the file we downloaded. `shape_predictor_68_face_landmarks.dat.bz2` comes
    in `.bz2` format; if you have not already unzipped it, you can unzip it to the
    `.dat` format. If you're on Windows, then it is recommend to use 7-zip. If you're
    on Linux or macOS, there should be a built-in utility you can just double-click
    on and it should be pretty straightforward to extract that.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将从我们下载的文件中加载数据。`shape_predictor_68_face_landmarks.dat.bz2`以`.bz2`格式提供；如果你还没有解压它，你可以将其解压为`.dat`格式。如果你在Windows上，建议使用7-zip。如果你在Linux或macOS上，应该有一个内置的实用程序，你可以双击它，提取应该相当直接。
- en: 'So, we''ll set the path and keep it in the current directory, and we need to
    initialize our objects:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将设置路径并将其保持在当前目录中，并且我们需要初始化我们的对象：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, there are two stages here. First, you need to detect where the faces are.
    This is similar to what Haar cascades would do if you''ve used OpenCV and those
    examples before, but we use `dlib.get_frontal_face_detector`, which is just built-in:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这里有两个阶段。首先，你需要检测人脸的位置。这类似于如果你之前使用过OpenCV和那些示例，Haar级联会做什么，但我们使用`dlib.get_frontal_face_detector`，它只是内置的：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'So, we create the `detector` object, get it from `dlib.get_frontal_face_detector`,
    initialize that, and then there''s the `predictor`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们创建`detector`对象，从`dlib.get_frontal_face_detector`获取它，初始化它，然后是`predictor`：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Once we've detected where the face is, we know how many faces there are, and
    there can be more than one. dlib works fine for multiple faces, as we'll see.
    Once you know where the faces are, then you can run the `predictor`, which actually
    finds where those 68 landmarks previously mentioned are. So, we create our `detector`
    object and our `predictor` object, again making sure `predictor_path` is set up
    correctly.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们检测到人脸的位置，我们就知道有多少张人脸，可能会有多张。dlib对于多张人脸也能很好地工作，我们将会看到。一旦你知道人脸在哪里，然后你可以运行`predictor`，它实际上会找到之前提到的68个地标的位置。所以，我们再次创建我们的`detector`对象和`predictor`对象，同时确保`predictor_path`设置正确。
- en: 'Then, we''ll set our `font` here:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将设置我们的`font`：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`font` is just displaying landmark data on the annotated image. So, you can
    change that if you want. Okay, now we get to the fun part of the code. First,
    do the detection, and find where exactly the faces are. Here''s one really simple
    line of code:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`font`只是将地标数据显示在注释图像上。所以，如果你想改变它，可以。好的，现在我们来到了代码的有趣部分。首先，进行检测，并找到人脸的确切位置。这里有一行非常简单的代码：'
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We''re going to just print out the number of faces detected:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将只打印出检测到的人脸数量：
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This can be useful for debugging purposes, although we'll see the output image
    where it actually detected the faces.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于调试目的可能很有用，尽管我们将在实际检测到人脸的地方看到输出图像。
- en: 'Now, we''re going to do a `for` loop here, and this will handle the case where
    we could have more than one face:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将在这里进行一个`for`循环，这将处理可能有多张人脸的情况：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: So, we're going to iterate over each one. The length of `dets` could be one,
    more than one, or zero, but we're not going to do that in this case. If you're
    not sure, then you might want to put this in a `try...catch` block, but we're
    only going to deal with images that have visible faces here.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将遍历每一个。`dets`的长度可能是一个，多个，或者零，但在这个例子中我们不会这么做。如果你不确定，你可能想把它放在`try...catch`块中，但在这里我们只处理有可见人脸的图像。
- en: 'So, we''ll iterate over the faces, and display where exactly the bounding box
    is for each face on the `Left`, `Top`, `Right`, and `Bottom`; where exactly did
    those go? Note the following code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将遍历人脸，并在`Left`、`Top`、`Right`和`Bottom`上显示每个脸的确切边界框；它们确切地在哪里？注意以下代码：
- en: '[PRE12]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This is where the magic happens:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是魔法发生的地方：
- en: '[PRE13]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We''re going to find the shape, then we''re going to find those 68 landmarks,
    and just do a sanity check by printing out the first couple of landmarks just
    to make sure that it''s working:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将找到形状，然后找到那68个地标，并通过打印出前几个地标来做一个简单的检查，以确保它正在工作：
- en: '[PRE14]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Okay, so, we have our landmarks for the face, and now we want to actually display
    it to understand what exactly we have here. We want to scale the `font` to make
    sure that fits the image because, depending on the size of the image, you could
    have a high resolution such as a 4,000 × 2,000 image, or you could have a low
    resolution such as a 300 × 200 (or something similar) and the heads could be very
    large in the image, as if the subject is close to the camera, or the reverse,
    small if it's far away.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，所以我们有了脸部地标，现在我们实际上想要显示它，以便了解我们到底有什么。我们想要调整`font`的大小，以确保它适合图像，因为，根据图像的大小，你可能有一个高分辨率的图像，比如4,000×2,000像素，或者你可能有一个低分辨率的图像，比如300×200像素（或者类似的大小），图像中的头部可能非常大，就像主题靠近相机一样，或者相反，如果它远离相机，则可能很小。
- en: 'So, we want to scale our `font` to the size of the head in the image:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们想要将`font`缩放到图像中头部的大小：
- en: '[PRE15]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: So, here we're just computing `head_width`. `shape` is a predictor object that
    has a `part` method, and you pass in the index of the landmark that you want to
    find and each landmark is going to have an `x` and a `y` part. So, `head_width`
    is `16` here, which is dependent on your perspective. `head_width` is just width
    in terms of pixels of the head. Then, we're going to scale the font size based
    on `head_width`, and `650` is just a nice factor that works well.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这里我们只是在计算`head_width`。`shape`是一个预测对象，它有一个`part`方法，你传入你想要找到的地标点的索引，每个地标都将有一个`x`和`y`部分。所以，`head_width`在这里是`16`，这取决于你的视角。`head_width`只是头部在像素意义上的宽度。然后，我们将根据`head_width`调整字体大小，`650`是一个很好的因子，效果很好。
- en: 'Now, we have all the data, we''re going to iterate over each of the points:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了所有数据，我们将遍历每个点：
- en: '[PRE16]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'So, we''ll hardcode `68`, because we know that we have `68` points, but if
    you were using another kind of shape finder, such as a pre-trained shape finder,
    then you might want to change this number. We iterate over the points and then
    we get the `x` and the `y` coordinates for each of the landmarks that were shown
    before. We extract the `x` and `y` coordinates using `shape.part` and update the
    annotated image. We need `cv2` to put the text into the image. dlib does have
    something similar to this, but `cv2` is better, and we can have just one interface
    for that anyway. So, we''re going to use OpenCV here and then we''re going to
    create a figure and display it:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将硬编码`68`，因为我们知道我们有`68`个点，但如果你使用另一种形状检测器，比如预训练的形状检测器，你可能想改变这个数字。我们遍历这些点，然后我们得到之前显示的每个地标点的`x`和`y`坐标。我们使用`shape.part`提取`x`和`y`坐标并更新注释图像。我们需要`cv2`将文本放入图像。dlib确实有类似的功能，但`cv2`更好，我们无论如何都可以有一个统一的接口。所以，我们将在这里使用OpenCV，然后我们将创建一个图形并显示它：
- en: '[PRE17]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'So, that''s all regarding the code, and hopefully that seems pretty straightforward
    to you. Read it at your leisure. When we execute the code, we can see a dialog
    box of stock photos. We can select any photo among those; for instance, here is
    the photo of a man wearing a hat. So, it''ll take just a little bit to compute
    that, and here you go:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这就是关于代码的所有内容，希望这对你来说看起来相当简单。随意阅读。当我们执行代码时，我们可以看到一个股票照片的对话框。我们可以从这些照片中选择任何一张；例如，这里是一位戴帽子的男士的照片。所以，计算这个只需要一点时间，看这里：
- en: '![](img/8131ab8a-d1ba-4a20-a662-b96e70e491fe.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8131ab8a-d1ba-4a20-a662-b96e70e491fe.png)'
- en: 'We see this guy with all 68 points. We have labeled it from 0 to **67**, because
    of Python''s index from 0 convention, but we can see that, just like before, we
    have all of the points; so, you can see point 0 on the left side, point 16 on
    the right side, depending on your perspective, and then it continues all the way
    around. Here''s a zoomed view for clarity:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这个人有所有的68个点。我们将其标记为从0到**67**，因为这是Python从0开始的索引惯例，但我们可以看到，就像之前一样，我们有了所有的点；所以，你可以看到左侧的点0，右侧的点16，这取决于你的视角，然后它继续围绕整个头部。这里有一个放大的视图以增加清晰度：
- en: '![](img/e2c13edd-8383-479c-8956-52562790372c.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e2c13edd-8383-479c-8956-52562790372c.png)'
- en: As we can see, some of the points are close together, but you can get the idea
    here of what's what. It looks pretty clear. So, this is pretty cool, and there's
    a whole lot you can do with this, as mentioned before. This guy is looking straight
    into the camera, so you might be asking what happens if somebody has their head
    tilted? Alright, we're going to run this again.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，有些点彼此很近，但你可以在这里了解每个点代表什么。看起来相当清晰。所以，这相当酷，正如之前提到的，你可以用这个做很多事情。这个人正直视镜头，所以你可能想知道如果有人头部倾斜会发生什么？好吧，我们将再次运行这个程序。
- en: 'Let''s select the stock photo woman here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里选择一位股票照片中的女士：
- en: '![](img/234d6149-587a-4198-b328-933943ad6e4a.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/234d6149-587a-4198-b328-933943ad6e4a.png)'
- en: You can see her head is turned, and yet this still works fine. It won't always
    work in extreme cases; if somebody's head is turned so much that landmarks aren't
    there, then this can fail for reasonable cases, you can see that this actually
    works very nicely.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到她的头转过去了，但这仍然可以正常工作。在极端情况下，这并不总是可行的；如果某人的头转得太多以至于地标不见了，那么在合理的情况下，这可能会失败，你可以看到这实际上工作得非常好。
- en: 'Okay, so what about multiple faces? Does this work for that? Let''s have a
    look at another group photo:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那么关于多个人脸呢？这对那个有效吗？让我们看看另一张团体照片：
- en: '![](img/98189d50-d116-461c-aee8-f01e2699f76d.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/98189d50-d116-461c-aee8-f01e2699f76d.png)'
- en: We can see we have six people here in various poses. Given the resolution here,
    it's not possible to read those annotations, but that's perfectly okay because
    you have seen where they are, and we can see that we actually detected all six
    faces very nicely. So, hopefully you can get some ideas here of how you can use
    this in your own code, and just how easy dlib makes it for you in terms of detection
    phases.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这里有六个人，他们以不同的姿势站立。鉴于这里的分辨率，你无法阅读这些注释，但这完全没问题，因为你已经看到了它们的位置，我们可以看到我们实际上非常准确地检测到了所有六个面部。所以，希望你能在这里得到一些想法，了解你如何在自己的代码中使用它，以及
    dlib 在检测阶段为你提供了多么简单的操作。
- en: Faces in videos
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视频中的人脸
- en: 'We''re going to see our second example from what we learned in the last section
    on faces in photos. The still image example was neat, but you might be asking
    about videos. Okay, let''s look at that for our next example:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到上一节关于照片中人脸的第二个示例。静态图像示例很简洁，但你可能想知道关于视频的情况。好的，让我们看看下一个示例：
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We change to `%pylab inline` because having all those widgets can actually cause
    a problem with Jupyter when you want to display a video sequence. We'll need the
    same code to get started with as shown in the previous example, and only replace
    `notebook` with `inline`. Then, we run the same code again.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将代码更改为`%pylab inline`，因为所有这些小部件实际上可能会在你想显示视频序列时与 Jupyter 发生问题。我们将需要与之前示例中相同的代码来开始，只需将`notebook`替换为`inline`。然后，我们再次运行相同的代码。
- en: 'After its execution, we move on with the next part. This is actually very close
    to the same thing because all you have to do is iterate over each frame, and it
    will work just the same:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 执行完毕后，我们继续下一部分。这实际上非常相似，因为你只需要遍历每一帧，它就会以同样的方式工作：
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'So, you see this code is pretty much the same as the previous example. If you
    want, you can do this with your webcam. It''s actually pretty neat to watch. We''ll
    not be using a webcam here, but for your custom project, if you want to use a
    webcam you can add the following line:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你看，这段代码基本上与之前的示例相同。如果你想，你可以用你的摄像头来做这个。实际上，这非常有趣。我们这里不会使用摄像头，但如果你想在自定义项目中使用摄像头，你可以添加以下行：
- en: '[PRE20]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We''re assuming here that you only have one webcam. If you have more than one
    camera and you don''t want to use the first one, then you might need to change
    that `0` to something else. If you don''t want to use your webcam, add the following
    line:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设你只有一个摄像头。如果你有多个摄像头并且不想使用第一个，那么你可能需要将那个`0`改为其他值。如果你不想使用你的摄像头，请添加以下行：
- en: '[PRE21]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here, we are not using a webcam. We want to create a figure that we''re going
    to display, and we''ll name it `100` to make sure it has its own unique ID. We''ll
    use the same `font` as in the previous example:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们不会使用摄像头。我们想要创建一个我们将要显示的图形，我们将它命名为`100`以确保它有一个唯一的 ID。我们将使用与之前示例中相同的`font`：
- en: '[PRE22]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'It sounds really complicated, but it''s just an ordinary font. We''re going
    to create a `while` loop, which is going to go over each and every frame:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来很复杂，但实际上它只是一个普通的字体。我们将创建一个`while`循环，它将遍历每一帧：
- en: '[PRE23]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: So, we have `cap` as our video capture object from OpenCV, and then all we have
    to do to read the frames is `cap.read()`. `ret` is just code that makes sure that
    we actually read a frame. Then, `img` is the actual image that is returned, and
    again make sure that the `WRITEABLE` flag is set, otherwise dlib could produce
    an error.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用`cap`作为 OpenCV 的视频捕获对象，然后我们只需要执行`cap.read()`来读取帧。`ret`只是确保我们实际上读取了一个帧的代码。然后，`img`是返回的实际图像，再次确保设置了`WRITEABLE`标志，否则
    dlib 可能会产生错误。
- en: 'We''re going to try to find a face and, if the face is not found, then we''re
    going to release and break out of our loop:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试找到一个人脸，如果找不到人脸，那么我们将释放并跳出我们的循环：
- en: '[PRE24]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: You might not want this for your application, but one neat thing here is if
    you're using a webcam, an easy way to just stop this loop from running indefinitely
    is to just put your hand in front of the face. You put your hand in front of the
    camera, or turn your head, or whatever, and that will automatically stop it, hands-free.
    Otherwise, you can send a kernel interrupt and just make sure you do `cap.release()`,
    otherwise the video source will stay open and you might get an error later.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不希望你的应用程序有这个功能，但这里的一个很酷的事情是，如果你使用的是摄像头，一个简单的方法来停止这个循环无限期地运行就是将你的手放在脸部前面。你将手放在摄像头前，或者转动你的头，或者随便什么，这会自动停止它，无需手动操作。否则，你可以发送内核中断，并确保你执行
    `cap.release()`，否则视频源将保持打开状态，你可能会稍后遇到错误。
- en: According to the preceding code block, we grab the image, detect the faces,
    and take the shape. For this code, we'll assume that there's only one face, but
    you can see from the previous example how to deal with multiple faces.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的代码块，我们抓取图像，检测人脸，并获取形状。对于这段代码，我们假设只有一个脸，但你可以从之前的例子中看到如何处理多个脸。
- en: 'Then, we create the blank image or the image that''s a copy of the original,
    which we can write without distorting the original. Set the `head_width` and `fontsize`,
    and then just do exactly what we did before. Find the `x` and `y` points, and
    then write to them:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建一个空白图像或一个与原始图像相同的图像，我们可以写入它而不会扭曲原始图像。设置 `head_width` 和 `fontsize`，然后做与我们之前完全一样的事情。找到
    `x` 和 `y` 点，然后写入它们：
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We are going to display our results, as shown in the following code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将展示我们的结果，如下面的代码所示：
- en: '[PRE26]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note the color, `BGR2RGB`. That's because OpenCV uses **blue green red** (**BGR**)
    by default, and the colors will look really funny if you don't change that for
    the display. Then, there's some stuff here that will make sure that our window
    is updating while the script is still running. Otherwise, it will actually just
    run the entire script and you won't see what's happening in real time.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 注意颜色，`BGR2RGB`。这是因为 OpenCV 默认使用 **蓝绿红** （**BGR**），如果你不改变这个设置来显示颜色，颜色看起来会很奇怪。然后，这里有一些东西可以确保在脚本仍在运行时我们的窗口正在更新。否则，它实际上会运行整个脚本，你将看不到实时发生的事情。
- en: 'We then hit *Shift* + *Enter*. It might take a second to load and then it''ll
    run pretty slowly, largely because it''s part of Jupyter Notebook. You can take
    the code out and run it as an independent program, and probably you''ll want to
    create a `cv2` named window, but this will do for our purposes. When you execute
    the cell, you''ll see two women:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们然后按下 *Shift* + *Enter*。可能需要一秒钟来加载，然后它会运行得相当慢，主要是因为它是 Jupyter Notebook 的一部分。你可以将代码提取出来作为一个独立的程序运行，你可能还想创建一个名为
    `cv2` 的窗口，但这对我们的目的来说已经足够了。当你执行单元格时，你会看到两位女士：
- en: '![](img/9a43cb3c-24ab-4896-ba42-1162aeaa7572.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9a43cb3c-24ab-4896-ba42-1162aeaa7572.png)'
- en: One face is kind of obscured, so it's not going to detect her, but for the one
    who's in the foreground, as you can see, her face is being tracked pretty nicely
    and the landmarks are being found. This can work in real time depending on your
    hardware, and this isn't the kind of thing that you want to run in a Jupyter Notebook.
    You can watch this as long as you want to, but you get the idea.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一张脸有点模糊，所以它不会检测到她，但对于前景中的那位女士，正如你所看到的，她的脸被很好地追踪，并且找到了地标。这可以根据你的硬件实时工作，这不是你希望在
    Jupyter Notebook 中运行的那种类型的东西。你可以看多久就多久，但你会明白这个意思。
- en: 'So, that''s how easy it is to work with video. Switch to the other woman in
    the background, and the first one''s face is turned:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这就是与视频一起工作的简单方法。切换到背景中的另一位女士，第一位女士的脸转过去了：
- en: '![](img/80e7597f-ba7f-449f-957a-977d6f6f3974.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/80e7597f-ba7f-449f-957a-977d6f6f3974.png)'
- en: That's how easy it is to work with video, and you can detect multiple faces
    and do whatever you want with this information.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是与视频一起工作的简单方法，你可以检测多个脸，并使用这些信息做任何你想做的事情。
- en: Facial recognition
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部识别
- en: We're going to see how we can perform facial recognition with dlib with a relatively
    small amount of code. Facial recognition here means that we're going to look at
    an image and see whether or not this person is the same as the person in a different
    image. We're going to keep it simple here and just compare two faces to see whether
    they're the same, but this can easily be generalized, as we'll see later.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看看如何使用 dlib 和相对较少的代码执行面部识别。在这里，面部识别意味着我们将查看一张图片，看看这个人是否与另一张图片中的人相同。我们将保持简单，只比较两张脸以查看它们是否相同，但这一点可以很容易地推广，就像我们稍后看到的。
- en: Here, we're going to do something similar to the first example, where we're
    going to prompt the user to open two files, each with a face that is going to
    be compared to another. For this, we are going to use some faces from **Labeled
    Faces in the Wild** (**LFW**). It's a nice database that has thousands of faces
    from various celebrities. You can download the entire set from [http://vis-www.cs.umass.edu/lfw/](http://vis-www.cs.umass.edu/lfw/)
    and get a whole lot of examples that you can play with. So, we are just going
    to use a small subset of examples from the dataset to do our example here.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将进行与第一个示例类似的操作，我们将提示用户打开两个文件，每个文件中都有一个面部图像将被与另一个进行比较。为此，我们将使用来自 **Labeled
    Faces in the Wild** (**LFW**) 的某些面部图像。这是一个很好的数据库，包含来自各种名人的数千张面部图像。您可以从 [http://vis-www.cs.umass.edu/lfw/](http://vis-www.cs.umass.edu/lfw/)
    下载整个集合，并获得大量可以使用的示例。因此，我们只是将从数据集的一个小子集中使用一些示例来进行我们的示例。
- en: 'We prompt a user to select two different facial images. We''re going to start
    the initial directory in the `faces` subdirectory of the project folder:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提示用户选择两个不同的面部图像。我们将从项目文件夹的 `faces` 子目录开始初始目录：
- en: '[PRE27]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: There are two additional files that you're going to need from [dlib.net/files](http://dlib.net/files),
    and they are the `shape_predictor_5_face_landmarks.dat` file and the `dlib_face_recognition_resnet_model_v1.dat`
    file. Again, they're going to be in `bz2` format. So, interestingly, we're only
    using five facial landmarks for this, but combined with the descriptors that's
    actually very adequate for describing a human face. Hence, we are not using 68
    face landmarks, but just 5\. We'll see just how nicely that works. Download those
    files and unzip `bz2`, just as we did in the first example.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要从 [dlib.net/files](http://dlib.net/files) 下载两个额外的文件，它们是 `shape_predictor_5_face_landmarks.dat`
    文件和 `dlib_face_recognition_resnet_model_v1.dat` 文件。再次强调，这些文件将以 `bz2` 格式存在。有趣的是，我们只使用了五个面部特征点，但结合描述符，实际上非常适用于描述人脸。因此，我们没有使用
    68 个面部特征点，而是只用了 5 个。我们将看到这会多么顺利。下载这些文件，并像第一个示例中那样解压 `bz2` 文件。
- en: 'Now, we set the path to the proper file locations:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们设置正确的文件路径：
- en: '[PRE28]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `predictor` works similarly to the 68 face landmarks, but again a link comes
    up with five results, and we're going to use a pre-trained recognition model.
    It works on a variety of faces; you won't have to retrain it now. Here, we don't
    have to do any complicated deep learning modeling for this. There are ways to
    train your own models, but you'll see that this will actually work very nicely
    for a wide variety of applications.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`predictor` 的工作方式与 68 个面部特征点相似，但同样会提供五个结果，我们将使用一个预训练的识别模型。它适用于各种面部；您现在不需要重新训练它。在这里，我们不需要进行任何复杂的深度学习建模。有方法可以训练自己的模型，但您会看到这实际上非常适合广泛的多种应用。'
- en: 'So, we create our `detector`, as before. That doesn''t require any additional
    data:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们创建我们的 `detector`，就像之前一样。这不需要任何额外的数据：
- en: '[PRE29]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We''re going to create our shape finder, similar to the previous example, and
    again we''re using the five facial landmarks detector. We''re going to create
    a new `facerec` object that comes from `dlib.face_recognition_model_v1`, passing
    in the path as `face_rec_model_path`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建我们的形状查找器，类似于之前的示例，并且再次使用五个面部特征点检测器。我们将创建一个新的 `facerec` 对象，来自 `dlib.face_recognition_model_v1`，将路径作为
    `face_rec_model_path` 传入：
- en: '[PRE30]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Now, what `facerec` does is it takes a mapping, given our detected face and
    given the shapes and the location of where those landmarks are, and it's going
    to create a 128-length float vector, called a descriptor, that's going describe
    the face. So, it actually creates something that will be a description of a face,
    and is something that will capture the essence of a face. If you have the same
    person in two different pictures, where in one picture the person is far away
    from the camera and in another their face might be turned, it could be as many
    pictures and there could be different lighting conditions and so forth. The descriptor
    should be pretty much invariant to that. The descriptor is never exactly the same,
    but the same person should get a similar enough face descriptor, regardless of
    their orientation, the lighting conditions, and so forth. Even if they change
    their hair or they're wearing a hat, you should get a similar descriptor, and
    `facerec` actually does a good job of that.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`facerec`所做的是，它接受一个映射，给定我们检测到的面部以及那些地标的位置和形状，然后它将创建一个128长度的浮点向量，称为描述符，用来描述面部。因此，它实际上创建了一个将描述面部特征的东西，并且能够捕捉到面部的本质。如果你有同一个人在两张不同的照片中，其中一张照片中的人离相机较远，而在另一张照片中他们的脸可能转向，可能有更多张照片，并且可能有不同的光照条件等等。描述符应该对那些条件相当不变。描述符永远不会完全相同，但同一个人应该得到足够相似的面部描述符，无论他们的方向、光照条件等等。即使他们改变发型或戴帽子，你也应该得到一个相似的描述符，而`facerec`实际上在这方面做得很好。
- en: 'The following code just performs the detection and the shape finding:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码仅执行检测和形状查找：
- en: '[PRE31]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Then, we''re going to perform the operation that we described previously: given
    the detection, spatial features, and the landmarks, we''re going to compute the
    128-point vector, and we can inspect it a little bit. Then, we''re going to look
    at the faces side by side:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将执行之前描述的操作：给定检测、空间特征和地标，我们将计算128点的向量，我们可以稍作检查。然后，我们将并排查看面部：
- en: '[PRE32]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, we want to know how similar the faces are, so we''re going to compute
    the Euclidean distance:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想知道面部有多相似，所以我们将计算欧几里得距离：
- en: '[PRE33]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: What that means is you take each point, 1 through 128, and you subtract the
    second one from the first one, you square each one, you sum them together, and
    take the square root, and that's going to give you a single number. That number
    is going to be used to determine whether or not these two images are of the same
    person's face.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你取每个点，从1到128，从第二个点减去第一个点，对每个点进行平方，将它们相加，然后开平方，这将给出一个单一的数字。这个数字将用来确定这两张图像是否是同一个人的面部。
- en: 'There''s a magic number, `0.6`, which we''re going to use here, and which has
    been determined empirically to work very well. If the 128-dimensional distance
    is less than `0.6`, we say that these two images are of the same person. If it''s
    more than `0.6`, or equal to `0.6` as in this case, we''re going to say that these
    are different people. So, we look at the two images, compute all those metrics,
    and then we''re going to say if it is `<0.6`, the faces match, and if it is `>0.6`,
    the faces are different:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个神奇的数字`0.6`，我们将在这里使用它，并且它已经被经验证明非常有效。如果128维的距离小于`0.6`，我们说这两张图像是同一个人的。如果它大于`0.6`，或者等于`0.6`，就像这个例子一样，我们将说这些是不同的人。因此，我们查看这两张图像，计算所有这些指标，然后我们将说如果它是`<0.6`，面部匹配，如果是`>0.6`，面部不同：
- en: '[PRE34]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, let''s run the code. You''ll see a dialog of celebrity photos from the
    LFW. We''ll pick one of Alec Baldwin and one of Sylvester Stallone:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们运行代码。你会看到一个来自LFW的名人照片对话框。我们将选择亚历克·鲍德温和西尔维斯特·史泰龙中的一张：
- en: '![](img/cc0a96d9-6198-4055-9983-9231eeee5be9.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc0a96d9-6198-4055-9983-9231eeee5be9.png)'
- en: 'Baldwin and Sylvester Stallone are classified as two different people. That
    is exactly as we expected, as the faces are different. Now, let''s do it for another
    pair. Let''s compare Alec Baldwin to Alec Baldwin:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 巴德温和西尔维斯特·史泰龙被归类为两个不同的人。这正是我们所预期的，因为他们的脸是不同的。现在，让我们为另一对进行比较。让我们比较亚历克·鲍德温与亚历克·鲍德温：
- en: '![](img/a8b1916d-cc5f-4b2b-8de4-fba8bed71416.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a8b1916d-cc5f-4b2b-8de4-fba8bed71416.png)'
- en: 'Here, you can see that their faces match. Let''s do a few more comparisons
    for fun. So, Yao Ming and Winona Ryder look different from each other:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到他们的面部匹配。让我们为了乐趣再进行一些比较。所以，姚明和温莎·瑞德看起来彼此不同：
- en: '![](img/befb8a98-2baf-4d94-a90f-d9b7f9e57314.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/befb8a98-2baf-4d94-a90f-d9b7f9e57314.png)'
- en: 'Then, we take two different pictures of Winona Ryder, and the faces match:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们取温莎·瑞德的两个不同照片，面部匹配：
- en: '![](img/677b9fbb-8d52-4b3a-bffb-d7eafceb104d.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/677b9fbb-8d52-4b3a-bffb-d7eafceb104d.png)'
- en: 'You can do all kinds of combinations of this. Okay, so this is pretty easy.
    It might be useful to take a look at the facial descriptor; you can just hit *Shift*
    + *Tab,* and you can see what the vectors look like, which is something like this:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以做各种各样的组合。好吧，所以这很简单。看看面部描述符可能很有用；你只需按*Shift* + *Tab*，你就可以看到向量看起来像这样：
- en: '![](img/520480df-9d83-4c50-b02f-2b4f8351549a.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/520480df-9d83-4c50-b02f-2b4f8351549a.png)'
- en: It's not very human-understandable, but is available just in case you're curious
    about it. That is enough to capture the essence of a human face, and just using
    a simple comparison, we can actually do a pretty good job of telling whether the
    two pictures are of the same face. This actually has a greater than 99% accuracy
    on the LFW dataset. So, you'll actually have a difficult time finding two faces
    that get bad results, whether two faces of the same person that are said not to
    match, or two of different people that are said to match.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不非常易于人类理解，但如果你对此好奇，它仍然可用。这足以捕捉到人脸的本质，仅仅通过简单的比较，我们实际上可以相当好地判断两张图片是否为同一张人脸。这在LFW数据集上实际上有超过99%的准确率。所以，你实际上很难找到两张人脸结果不佳的情况，无论是同一人的两张人脸声称不匹配，还是不同人的两张人脸声称匹配。
- en: Therefore, if you wanted to adapt this to your own needs, what you can do is
    get your own database, just your own directory of faces of people that you want
    to recognize, and then when you have a new face, just go through each of the faces
    in your database. Just do a `for` loop and compare your new face to each one.
    For the Euclidean distance, computed here simply by using the NumPy linear algebra
    norm (`np.linalg.norm`), if that distance is less than 0.6, then you can say that
    you have a match. If you are concerned with false positives, you can have multiple
    faces of a person and compare to each one, then do a majority rule.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你想根据自己的需求进行适配，你可以做的是获取自己的数据库，仅限于你想要识别的人的面部图像目录，然后当你有新的人脸时，只需遍历数据库中的每一张人脸。只需进行一个`for`循环，并将新的人脸与每一张进行比较。对于这里通过使用NumPy线性代数范数（`np.linalg.norm`）计算出的欧几里得距离，如果这个距离小于0.6，那么你可以说你找到了一个匹配。如果你担心误判，你可以有一个人多张人脸，并与每一张进行比较，然后执行多数规则。
- en: Otherwise, suppose you have ten faces and you want to make sure that all ten
    of them match. If you really want to make sure that you did not get a false positive,
    you can just get ten really good images and then compare your new test image to
    all ten. But in any case, you can see from this example that it does not take
    a whole lot of code, and this method can be adapted to a wide variety of applications.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，假设你有十张人脸，你想要确保这十张人脸都匹配。如果你真的想确保没有出现误判，你可以获取十张非常好的图像，然后将你的新测试图像与这十张图像进行比较。但无论如何，从这个例子中你可以看出，这并不需要很多代码，并且这种方法可以适应各种不同的应用。
- en: Summary
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we had a brief introduction to the dlib library and learned
    how to use it for facial recognition. We then learned how to generate the outline
    for a face using the 68 facial landmarks pre-trained model. Later, we learned
    how to find the facial landmarks for a single person, multiple people, and for
    people in videos.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们简要介绍了dlib库，并学习了如何使用它进行人脸识别。然后，我们学习了如何使用预训练的68个面部特征点模型生成人脸轮廓。之后，我们学习了如何为单个人、多个人以及视频中的人找到面部特征点。
- en: In the next chapter, [Chapter 7](ffda7469-1745-4a0a-8375-43426248af4d.xhtml), *Deep
    Learning Image Classification with TensorFlow*, we'll learn how to classify images
    with TensorFlow using a pre-trained model, and later we'll use our own custom
    images.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，[第7章](ffda7469-1745-4a0a-8375-43426248af4d.xhtml)，*使用TensorFlow进行深度学习图像分类*，我们将学习如何使用预训练模型通过TensorFlow对图像进行分类，然后我们将使用我们自己的自定义图像。
