- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploratory Data Analysis
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter covered the basic plotting principles using `ggplot2`,
    including the use of various geometries and themes layers. It turns out that cleaning
    and massaging the raw data (covered in [*Chapter 2*](B18680_02.xhtml#_idTextAnchor032)
    and [*Chapter 3*](B18680_03.xhtml#_idTextAnchor050)) and visualizing the data
    (covered in [*Chapter 4*](B18680_04.xhtml#_idTextAnchor077)) belong to the first
    stage of a typical data science project workflow – that is, **exploratory data
    analysis** (**EDA**). We will cover this using a few case studies in this chapter.
    We will learn how to apply the coding techniques we covered earlier in this book
    and focus on analyzing the data through the lens of EDA.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will know how to uncover the structures of data
    using numerical and graphical techniques, discover interesting relationships among
    variables, and spot unusual observations.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: EDA fundamentals
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EDA in practice
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To complete the exercises in this chapter, you will need to have the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: The latest version of the `yfR` package, which is 1.0.0 at the time of writing
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of the `corrplot` package, which is 0.92 at the time of writing
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code and data for this chapter are available at [https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_5/chapter_5.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_5/chapter_5.R).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: EDA fundamentals
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When facing a new dataset in the form of a table (a DataFrame) in Excel or a
    dataset, EDA helps us gain insight into the underlying pattern and irregularities
    of variables in the dataset. This is an important first-step exercise before building
    any predictive model. As the saying goes, *garbage in, garbage out*. When the
    input variables used for model development suffer from problems, such as missing
    values or different scales, the resulting model will either perform poorly, converge
    slowly, or even hit an error in the training stage. Therefore, understanding your
    data and ensuring the raw materials are in check are critical steps in warrantying
    a good-performing model later on.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: This is where EAD comes in. Instead of being a rigid statistical procedure,
    EAD is a set of exploratory analyses that enables you to develop a better understanding
    of the features and potential relationships in the data. It serves as a transitional
    analysis to guide modeling later on, involving both the data manipulation and
    visualization techniques we learned earlier. It helps summarize salient characteristics
    of the data through various forms of visual aids, facilitating the extraction
    of important features.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two broad types of EDA: descriptive statistics such as the mean,
    median, mode, and inter-quantile range, and graphical descriptions such as density
    plots, histograms, box plots, and so on.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: A typical EAD process includes analyzing categorical and numerical variables,
    both standalone in univariate analysis and in combination via bivariate and multivariate
    analysis. Common practices include analyzing the distribution of a given set of
    variables and examining missing values and outliers. In the following sections,
    we will start by analyzing different types of data, including categorical and
    numerical variables. We will then go through a case study to apply and reinforce
    the techniques covered in previous chapters using `dplyr` and `ggplot2`.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing categorical data
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will look at how to analyze two categorical variables via
    graphical and numerical summaries. We will use a dataset on comic characters from
    the Marvel comics universe, which should not be unfamiliar to you if you are a
    fan of Marvel superheroes. The dataset is published by `read_csv()` function from
    the `readr` package, the data loading arm of the `tidyverse` universe, as shown
    in the following code snippet:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Printing out the DataFrame shows that this dataset contains `16,376` rows and
    `13` columns, including the character names, IDs, and so on.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at summarizing two categorical variables using
    the count statistic.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing categorical variables using counts
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will cover different ways to analyze two categorical variables,
    including using a contingency table and a bar chart. A contingency table is a
    useful way to show the total counts of observations that fall into each unique
    combination of the two categorical variables. Let’s go through an exercise on
    how to achieve this.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.1 – summarizing two categorical variables
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will focus on two categorical variables: `ALIGN` (indicating
    whether the character is good, neutral, or bad) and `SEX` (indicating the gender
    of the character). First, we will look at the unique values of each variable,
    followed by summarizing the respective total counts when combined:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspect the unique values of `ALIGN` and `SEX`:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The results show that both variables contain `NA` values. Let’s remove the observations
    with `NA` values in either `ALIGN` or `SEX`.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Remove observations with `NA` values in either `ALIGN` or `SEX` in `df` using
    the `filter` verb function:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can verify whether the rows with `NA` values have been successfully removed
    by checking the dimension of the resulting DataFrame and the count of `NA` values
    in `ALIGN` and `SEX`:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Next, we must create a contingency table to summarize the frequency of each
    unique combination of values.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a contingency table between `ALIGN` and `SEX`:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We can see that most characters are male and bad. Among all male characters,
    the majority are bad, whereas good or neutral characters are dominant in female
    characters. Let’s visually present and analyze the proportions using a bar chart.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a bar chart between these two variables using `ggplot2`:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Figure 5.1 – Bar chart of ALIGN and SEX](img/B18680_05_001.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Bar chart of ALIGN and SEX
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the total count of `Agender Characters` and `Genderfluid Characters`
    is very limited, we can remove these two combinations when plotting the bar chart:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Running this command generates *Figure 5**.2*:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Removing low-count combinations from the bar chart](img/B18680_05_002.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Removing low-count combinations from the bar chart
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Using counts may not be as intuitive when comparing different combinations.
    In this case, converting counts into proportions will help present the information
    on a relative scale.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Converting counts into proportions
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will go over an exercise that covers conditional proportions
    in a contingency table. Unlike the previous unconditional contingency table, conditioning
    along either dimension of a two-way contingency table results in a different distribution
    of proportions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.2 – summarizing two categorical variables
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will learn how to express the previous contingency table
    using proportions and convert it into a conditional distribution based on a specified
    dimension:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'Express the previous contingency table using proportions. Avoid scientific
    notation (for example, e+10) and keep three decimal places:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The values in the contingency table are now expressed as proportions. Since
    the proportions are derived by dividing the previous absolute counts by the total
    sum, we can verify whether the total sum of proportions is equal to one by summing
    all the values in the table:'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Obtain the contingency table as proportions after conditioning on rows (here,
    the `ALIGN` variable):'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can verify the conditioning by calculating the row-wise summations:'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In this code, setting `margin=1` means row-level conditioning. We can also exercise
    column-level conditioning by setting `margin=2`.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Obtain the contingency table as proportions after conditioning on columns (for
    instance, the `SEX` variable):'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Similarly, we can verify the conditioning by calculating the column-wise summations:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Plot the unconditional proportions in a bar chart after applying the same filtering
    condition to `SEX`. Change the label of the *y* axis to `proportion`:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Running this command generates *Figure 5**.3*, where it is obvious that bad
    characters are predominantly male characters:'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Visualizing the unconditional proportions in a bar chart](img/B18680_05_003.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Visualizing the unconditional proportions in a bar chart
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also obtain a similar result from a different angle by switching the
    two variables in the bar chart:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Running this command generates *Figure 5**.4*, where `ALIGN` is used as the
    *x* axis and `SEX` is used as the grouping variable:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Switching variables in the bar chart.](img/B18680_05_004.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Switching variables in the bar chart.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look at describing one categorical variable using a marginal distribution
    and faceted bar chart.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Marginal distribution and faceted bar charts
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Marginal distribution refers to the distribution of one variable after integrating
    other variables. This means that we are interested in the distribution of one
    specific variable, no matter how the other variables are distributed.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of our previous two-way contingency table stored in `count_df`,
    we can derive the marginal distribution of `SEX` in the form of a frequency count
    by summing over all possible values of `ALIGN`. That is, we can perform column-wise
    summation to get the marginal count of `SEX`, as shown in the following code snippet:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This has the same effect as directly obtaining the count of different categories
    in `SEX`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, what if we would like to obtain the marginal distribution of one variable
    for each category of another variable? This can be achieved via `ggplot2`, as
    shown in the following code snippet:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Running this code generates *Figure 5**.5*, which contains three side-by-side
    bar charts for bad, good, and neutral characters, respectively. This is essentially
    rearranging the stacked bar chart in *Figure 5**.4*. Note that faceting can be
    added by using the `facet_wrap` function, where `~ALIGN` indicates that the faceting
    is to be performed using the `ALIGN` variable. Note that we used the `strip.text.x`
    attribute to adjust the text size of the facet grid labels:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Faceted bar chart](img/B18680_05_005.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Faceted bar chart
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, we can adjust the sequence of the individual bar facets by overriding
    the levels of `ALIGN` after converting it into a factor:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Running the same faceting codes again will now generate *Figure 5**.6*, where
    the sequence of facets is determined according to the levels in `ALIGN`:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Arranging the sequence of facets in a faceted bar chart](img/B18680_05_006.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – Arranging the sequence of facets in a faceted bar chart
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at different ways to explore numerical variables.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing numerical data
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will look at summarizing numerical data using different
    types of plots for the Marvel dataset. Since there’s an infinite amount of values
    that a numerical/continuous variable can assume, the frequency table used earlier
    no longer applies. Instead, we often group the values into pre-specified bins,
    allowing us to work with ranges instead of single values.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.3 – exploring numerical variables
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will describe a numerical variable using a dot plot, histogram,
    density plot, and box plot for the `Year` variable:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'Get a summary of the `Year` variable using the `summary()` function:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Generate a dotted plot of the `Year` variable:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Running this command generates *Figure 5**.7*, where each dot represents an
    observation at the corresponding location on the *x* axis. Similar observations
    are then stacked together on top of each top. It should be noted that using a
    dot plot is not the best option when the number of observations becomes large,
    with the *y* axis becoming meaningless due to technical limitations in `ggplot2`:'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Summarizing the Year variable using a dot plot](img/B18680_05_007.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – Summarizing the Year variable using a dot plot
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a histogram of the `Year` variable:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Running this command generates *Figure 5**.8*, where each value of `Year` is
    grouped into bins and then the number of observations in each bin is counted to
    represent the height of each bin. Note that the default number of bins is 30,
    although this can be overwritten using the `bins` argument. The histogram thus
    presents the general shape of the distribution of the underlying variable. We
    can also convert it into a density plot to smooth out the steps between bins:'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Summarizing the Year variable using a histogram](img/B18680_05_008.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – Summarizing the Year variable using a histogram
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a density plot of the `Year` variable:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Running this command generates *Figure 5**.9*, where the distribution is represented
    as a smooth line. Note that a density plot is recommended only when there are
    many observations in the dataset:'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Summarizing the Year variable using a density plot](img/B18680_05_009.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – Summarizing the Year variable using a density plot
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a box plot of the `Year` variable:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![Figure 5.10 – Summarizing the Year variable using a box plot](img/B18680_05_010.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – Summarizing the Year variable using a box plot
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Running this command generates *Figure 5**.10*, where the central box represents
    the majority (25th to 75th percentile) of the observations, the middle line in
    the box denotes the median (50th percentile), and the outreaching whiskers include
    almost all “normal” observations. The outlier observation, which is none in this
    case, would be represented as dots outside the reach of the whiskers.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: We can also add a faceting layer by `SEX` and observe the change in box plots
    across different genders.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a faceting layer to the previous box plot using the `SEX` variable:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Running this command generates *Figure 5**.11*. As we can see, most female
    characters are introduced later than many of the male characters, and recent years
    feature more female characters than male ones:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Faceting the box plot based on SEX](img/B18680_05_011.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – Faceting the box plot based on SEX
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how to visualize data with higher dimensions.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Visualization in higher dimensions
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The previous example used facets to present the distribution of a numerical
    variable in each unique value of a categorical variable. When there is more than
    one categorical variable, we can apply the same technique and expand the facets
    accordingly. This allows us to visualize the same numerical variable in higher
    dimensions that contain more than one categorical variable. Let’s go through an
    exercise on visualizing the distribution of `Year` by `ALIGN` and `SEX`.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.4 – visualizing Year by ALIGN and SEX
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `facet_grid()` function from `ggplot2` to
    visualize the distribution of `Year` in each unique combination of `ALIGN` and
    `SEX` using both a density plot and a histogram:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a density plot of `Year` by `ALIGN` and `SEX` after applying the same
    filtering condition to `SEX`:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Running this command generates *Figure 5**.12*, where we used the `facet_grid()`
    function to create six histograms, with the columns split by the first argument,
    `ALIGN`, and the rows split by the second argument, `SEX`. The result shows an
    increasing trend (more movies were produced) for all different combinations of
    `ALIGN` and `SEX`. However, since the *y* axis shows the relative density only,
    we would need to switch to a histogram to assess the absolute frequency of occurrence.
    Note that we used the `strip.text.y` attribute to adjust the text size of the
    facet grid labels along the *y* axis:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.12 – Density plot of Year by ALIGN and SEX](img/B18680_05_012.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – Density plot of Year by ALIGN and SEX
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Build the same plots using a histogram:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Running this command generates *Figure 5**.13*, where we can see that good
    female and male characters are steadily increasing in recent years:'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Histogram of Year by ALIGN and SEX](img/B18680_05_013.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – Histogram of Year by ALIGN and SEX
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will try different ways to measure the central concentration
    of a numerical variable.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the central concentration
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are different ways to measure the central concentration, or central tendency,
    of a numerical variable. Depending on the context and purpose, the measure of
    center is often used to represent a typical observation out of a numerical variable
    of interest.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: The most popular measure of center is the mean, which is calculated as the average
    value of a list of numbers. In other words, we can obtain the mean value by summing
    all observations divided by the number of observations. This can be achieved using
    the `mean()` function in R.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Another measure of center is the median, which is the middle value after sorting
    the list of numbers from the smallest to the largest. This can be achieved using
    the `median()` function in R.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: The third measure of center is the mode, which represents the most common observation
    in the list of numbers. Since there is no built-in function for calculating the
    mode, we must write a customized function to obtain the most frequent observation
    based on the count of occurrences using the `table()` function.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种中心度量是众数，它代表数字列表中最常见的观测值。由于没有内置的函数来计算众数，我们必须编写一个自定义函数，根据出现次数使用`table()`函数来获取最频繁的观测值。
- en: It is important to look at the shape of the distribution before deciding on
    the measure of center. For a start, note that the mean value is often drawn toward
    the long tail of a skewed distribution, a continuous distribution inferred from
    the list of numbers such as the density plot from earlier. In other words, the
    mean value is sensitive to the extreme values in the observations. On the other
    hand, the median will not suffer from such sensitivity since it is simply a measure
    that divides the ordered observations by half. Therefore, the median is a better
    and more sensible candidate measure of center when working with a skewed continuous
    distribution, unless additional treatment on the extreme values, often treated
    as outliers, is in place.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定中心度量之前，观察分布的形状是很重要的。首先，请注意，平均值通常会被拉向偏斜分布的长尾，这是一个从数字列表（如之前的密度图）推断出的连续分布。换句话说，平均值对观测中的极端值很敏感。另一方面，中位数不会受到这种敏感性的影响，因为它只是将有序观测值分成两半的度量。因此，当处理偏斜的连续分布时，中位数是一个更好、更合理的中心度量候选者，除非对极端值（通常被视为异常值）进行了额外的处理。
- en: Let’s look at how to obtain the three measures of center via an exercise.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个练习来看看如何获得三个中心度量。
- en: Exercise 5.5 – calculating the measure of center
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习5.5 – 计算中心度量
- en: 'In this exercise, we will calculate the mean, median, and mode of `APPEARANCES`,
    which denotes the number of appearances for each character:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将计算`APPEARANCES`的平均值、中位数和众数，它表示每个角色的出现次数：
- en: 'Calculate the mean of `APPEARANCES`:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`APPEARANCES`的平均值：
- en: '[PRE27]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The `NA` result suggests that there are `NA` values in the observations of
    `APPEARANCES`. To verify this, we can look at the summary of this continuous variable:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`NA`结果表明，`APPEARANCES`的观测值中存在`NA`值。为了验证这一点，我们可以查看这个连续变量的摘要：'
- en: '[PRE28]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Indeed, there are quite a few `NA` values. To calculate the mean value after
    removing these `NA` observations, we can enable the `na.rm` argument in the `mean()`
    function:'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 的确，存在相当多的`NA`值。为了在移除这些`NA`观测值后计算平均值，我们可以在`mean()`函数中启用`na.rm`参数：
- en: '[PRE29]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Calculate the mean of `APPEARANCES`:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`APPEARANCES`的平均值：
- en: '[PRE30]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: When the mean and median values deviate a lot from each other, this is an obvious
    sign that we are working with a skewed distribution. In this case, the `APPEARANCES`
    variable is quite skewed, with the median character appearing three times and
    the most popular character appearing up to 4,043 times.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当平均值和中位数差异很大时，这是一个明显的迹象，表明我们正在处理一个偏斜分布。在这种情况下，`APPEARANCES`变量非常偏斜，中位数角色出现三次，最受欢迎的角色出现高达4,043次。
- en: 'Calculate the mode of `APPEARANCES`:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`APPEARANCES`的众数：
- en: '[PRE31]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here, we created a customized function called `mode()` to calculate the mode
    of a numerical variable, where we first extract a list of the unique values using
    the `unique()` function, then count the number of times each unique value appears
    using the `tabulate()` and `match()` functions, and lastly obtain the index of
    the maximal value using the `which.max()` function. The result shows that the
    majority of characters only appear once in the entire history of Marvel comics.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个名为`mode()`的自定义函数来计算数值变量的众数，其中我们首先使用`unique()`函数提取一个唯一值的列表，然后使用`tabulate()`和`match()`函数计算每个唯一值出现的次数，最后使用`which.max()`函数获取最大值的索引。结果显示，大多数角色在整个漫威漫画的历史中只出现了一次。
- en: Now, let’s look at a detailed breakdown of mean and median appearances by `ALIGN`.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，让我们详细分析通过`ALIGN`的平均值和众数。
- en: 'Calculate the mean and median values of `APPEARANCES` by each level of `ALIGN`:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过每个`ALIGN`级别计算`APPEARANCES`的平均值和众数：
- en: '[PRE32]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The result shows that good characters appear more often than bad ones.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示，好人角色比坏人角色出现得更频繁。
- en: Next, we will look at how to measure the variability of a continuous variable.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨如何测量连续变量的变异性。
- en: Measuring variability
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量变异性
- en: As with central concentration, several metrics can be used to measure the variability
    or dispersion of a continuous variable. Some are sensitive to outliers, such as
    variance and standard deviation, while others are robust to outliers, such as
    **inter-quantile range** (**IQR**). Let’s go through an exercise on how to calculate
    these metrics.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Note that robust measures such as median and IQR are used in box plots, although
    more details are hidden compared to the full density of a given variable.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.6 – calculating the variability of a continuous variable
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will calculate different metrics on variability both manually
    and using built-in functions. We will start with variance, which is calculated
    as the average squared difference between each raw value and the mean value. Note
    that this is how population variance is calculated. To calculate the sample variance,
    we need to adjust the averaging operation by subtracting 1 from the total number
    of observations used in the variance calculation.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, variance is a squared version of the original unit and is thus
    not easily interpretable. To measure the variability of the data at the same original
    scale, we can use standard deviation, which is calculated by taking the square
    root of the variance. Let’s look at how to achieve this in practice:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the population variance of `APPEARANCES` after removing `NA` values.
    Keep two decimal points:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here, we first remove `NA` values from `APPEARANCES` and save the result in
    `tmp`. Next, we subtract the mean value of `tmp` from each original value, square
    the result, sum all values, and then divide by the number of observations in `tmp`.
    This essentially follows the definition of variance, which measures the average
    variability of each observation to the central tendency – in other words, the
    mean value.
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can also calculate the sample variance.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the sample variance of `APPEARANCES`:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The result is now slightly different from the population variance. Note that
    to calculate the sample mean, we simply use one less observation in the denominator.
    Such adjustment is necessary, especially when we are working with limited sample
    data, although the difference becomes small as the sample size grows.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can also calculate sample variance by calling the `var()` function.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate sample variance using `var()`:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The result is aligned with our previous manual calculation of the sample variance.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To obtain the measure of variability at the same unit as the original observations,
    we can calculate the standard deviation. This can be achieved using the `sd()`
    function.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the standard deviation using `sd()`:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Another measure of variability is IQR, which is the difference between the third
    and first quantiles and quantifies the range of the majority values.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the IQR using `IQR()`:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We can also verify the result by calling the `summary()` function, which returns
    the different quantile values:'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: As discussed earlier, measures such as variance and standard deviation are sensitive
    to extreme values in the data, while IQR is a robust measure of outliers. We can
    assess the change to these measures after removing the maximal value from `tmp`.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the standard deviation and IQR after removing the maximum from `tmp`:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The result shows that IQR stays the same after removing the maximum, thus being
    a more robust measure compared to standard deviation.
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can also calculate these measures by different levels of another categorical
    variable.
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the standard deviation, IQR, and count of `APPEARANCES` for each
    level of `ALIGN`:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Next, we will dive deeper into the skewness in the distribution of a continuous
    variable.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Working with skewed distributions
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Besides the mean and standard deviation, we can also characterize the distribution
    of a continuous variable using modality and skewness. Modality refers to the number
    of humps that exist in the continuous distribution. For example, a unimodal distribution,
    the most popular distribution we have seen so far in the form of a bell curve,
    has one peak across the whole distribution. It can grow into a bimodal distribution
    when there are two humps and multimodal distribution when there are three humps
    or more. If there is no discernable mode and the distribution appears flat across
    the whole support region (the range of the continuous variable), it is referred
    to as a uniform distribution. *Figure 5**.14* summarizes the distributions of
    different modalities:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14 – Different types of modalities in a distribution](img/B18680_05_014.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 – Different types of modalities in a distribution
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, a continuous variable may be skewed toward the left or the
    right or appear symmetric around the central tendency. A right-skewed distribution
    contains more extreme values on the right tail of the distribution, while a left-skewed
    distribution has a long tail on the left-hand side. *Figure 5**.15* illustrates
    the different types of skewness in a distribution:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15 – Different types of skewness in a distribution](img/B18680_05_015.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: Figure 5.15 – Different types of skewness in a distribution
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Distribution can also attribute its skewness to outliers in a continuous variable.
    When there are multiple outliers in the data, sensitive measures such as mean
    and variance will become distorted, causing a shift in distribution toward the
    outliers. Let’s go through an exercise to understand how to deal with skewness
    and outliers in a distribution.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.7 – working with skewness and outliers
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will look at how to work with a skewed distribution that
    contains many extreme values, especially outliers in the data:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'Visualize the density plot of `APPEARANCES` by `ALIGN` for observations since
    the year `2000`. Set the transparency level to `0.2`:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Running this command generates *Figure 5**.16*, where all three distributions
    are quite skewed toward the right, an obvious sign of many outliers in the data:'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.16 – Density plot of APPEARANCES by ALIGN](img/B18680_05_016.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
- en: Figure 5.16 – Density plot of APPEARANCES by ALIGN
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'Remove observations whose `APPEARANCES` are above the 90th percentile and generate
    the same plot:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Running this command generates *Figure 5**.17*, where all three distributions
    are much less right-skewed than before. Removing outliers is one way to work around
    extreme values, although the information contained in the removed observations
    is lost. To control the effect of outliers and retain their presence at the same
    time, we can transform the continuous variable using the `log()` function, which
    brings it to the logarithmic scale. Let’s see how this works in practice:'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.17 – Density plot of APPEARANCES by ALIGN after removing outliers](img/B18680_05_017.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
- en: Figure 5.17 – Density plot of APPEARANCES by ALIGN after removing outliers
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply log transformation to `APPEARANCES` and re-generate the same plot:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Running this command generates *Figure 5**.18*, where the three density plots
    appear as a bimodal distribution and not as right-skewed as before. Transforming
    the continuous variable using the logarithmic function could thus bring the original
    value to a more controlled scale:'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.18 – Density plot of APPEARANCES by ALIGN after applying log transformation](img/B18680_05_018.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
- en: Figure 5.18 – Density plot of APPEARANCES by ALIGN after applying log transformation
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will go through a case study to enhance our skills when
    conducting EDA on a new dataset.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: EDA in practice
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will analyze a dataset that consists of the stock prices
    of the top five companies in 2021\. First, we will look at how to download and
    process these stock indexes, followed by performing univariate analysis and bivariate
    analysis in terms of correlation.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining the stock price data
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To obtain the daily stock prices of a particular ticker, we can use the `yfR`
    package to download the data from Yahoo! Finance, a vast repository of financial
    data that covers a large number of markets and assets and has been widely used
    in both academia and industry. The following exercise illustrates how to download
    the stock data using `yfR`.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.8 – downloading stock prices
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will look at how to specify the different parameters so
    that we can download stock prices from Yahoo! Finance, including the ticker name
    and date range:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'Install and load the `yfR` package:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Note that we would need to wrap the package name inside a pair of double quotes
    in the `install.packages()` function.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Specify the starting and end date parameters, as well as the ticker names so
    that they cover Facebook (now `META`), Netflix (`NFLX`), Google (`GOOG`), Amazon
    (`AMZN`), and Microsoft (`MSFT`):'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Here, the start and end dates are formatted as the `Date` type, and the ticker
    names are concatenated in a vector.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Download the stock prices using the `yf_get()` function and store the result
    in `df`:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Running this command generates the following message, which shows that the
    data for all five stocks has been downloaded successfully. Each ticker has 252
    rows in 2021 since there are 252 trading days in a year:'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Let’s examine the structure of the dataset:'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The data that’s been downloaded includes information such as the daily opening,
    closing, highest, and closet prices for each ticker.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the following sections, we will use the adjusted price field, `price_adjusted`,
    which is adjusted for corporate events such as splits, dividends, and others.
    This is usually what we would use when analyzing stocks as it represents the actual
    financial performance of the stockholders.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Univariate analysis of individual stock prices
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will perform a graphical analysis based on the stock prices.
    Since the stock prices are time series data that are numerical, we will use plots
    such as histograms, density plots, and box plots for visualization purposes.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.9 – downloading stock prices
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will start with the time series plots for the five stocks,
    followed by generating other types of plots suitable for continuous variables:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate the time series plots for the five plots:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Running this command generates *Figure 5**.19*, where Netflix takes the lead
    in terms of stock value. However, it also suffers from a huge fluctuation, especially
    around November 2021:'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.19 – Time series plots of the five stocks](img/B18680_05_019.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
- en: Figure 5.19 – Time series plots of the five stocks
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a histogram for each of the five stocks, with 100 bins for each histogram:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Running this command generates *Figure 5**.20*, which shows that Netflix has
    the biggest mean and variance in terms of stock value. Google and Amazon seem
    to share a similar spread, and the same goes for Facebook and Microsoft:'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.20 – Histograms of the five stocks](img/B18680_05_020.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
- en: Figure 5.20 – Histograms of the five stocks
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a density plot for each of the five stocks. Set the transparency level
    to `0.2`:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Running this command generates *Figure 5**.21*, where the plots are now visually
    clearer compared to the histograms:'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.21 – Density plots of the five stocks](img/B18680_05_021.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
- en: Figure 5.21 – Density plots of the five stocks
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a box plot for each of the five stocks:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Running this command generates *Figure 5**.22*. Box plots are good at indicating
    the central tendency and variation of each stock. For example, Netflix has the
    biggest mean and variance across all five stocks:'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.22 – Box plots of the five stocks](img/B18680_05_022.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
- en: Figure 5.22 – Box plots of the five stocks
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: 'Obtain the mean, standard deviation, IQR, and count of each stock:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: In the next section, we will look at the pairwise correlation between each pair
    of stocks.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Correlation analysis
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Correlation measures the strength of covariation between two variables. There
    are several ways to calculate the specific value of correlation, with Pearson
    correlation being the most widely used. Pearson correlation is a value that ranges
    from -1 to 1, with 1 indicating two perfectly and positively correlated variables
    and -1 denoting perfect negative correlation. Perfect correlation means that the
    change in the value of one variable is always proportional to the change in the
    value of another variable. For example, when y = 2x, the correlation between variable
    x and y is 1 since y always changes positively in proportion to x.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Instead of manually calculating the pairwise correlation between all variables,
    we can use the `corrplot` package to calculate and visualize pairwise correlations
    automatically. Let’s go through an exercise on how this can be achieved.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.10 – downloading stock prices
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will first convert the previous DataFrame from long into
    wide format so that each stock has a separate column indicating the adjusted price
    across different days/rows. The wide-format dataset will then be used to generate
    the pairwise correlation plot:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: 'Convert the previous dataset into a wide format using the `spread()` function
    in the `tidyr` package. Save the result in `wide_df`:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Here, we first select three variables, with `ref_date` as the row-level date
    index, `ticker`, whose unique values serve as the columns to be spread across
    the DataFrame, and `price_adjusted`, to be used to fill in the cells of the wide
    DataFrame. With this, we can examine the first few rows of the new dataset:'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Now, the DataFrame has been converted from a long format into a wide format,
    which will facilitate the creation of correlation plots later on.
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate a correlation plot using the `corrplot()` function from the `corrplot`
    package (to be installed if you have not done so already):'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Running these commands generates *Figure 5**.23*. Each circle represents the
    strength of correlation between the corresponding stocks, where a bigger and darker
    circle denotes a stronger correlation:'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.23 – Correlation plot between each pair of stocks](img/B18680_05_023.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
- en: Figure 5.23 – Correlation plot between each pair of stocks
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the correlation plot relies on the `cor_table` variable, which stores
    the pairwise correlation as a table, as shown here:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: A high correlation between variables may or may not be a good thing. When the
    dependent variable (also called the target outcome) to be predicted is highly
    correlated with an independent variable (also called a predictor, feature, or
    covariate), we would prefer to include this feature in the prediction model due
    to its high covariation with the target variable. On the other hand, when two
    features are highly correlated, we tend to ignore one and choose the other or
    apply some sort of regularization and feature selection approach to downsize the
    impact of correlated features.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced basic techniques to conduct EDA. We started by
    going over the common approaches to analyzing and summarizing categorical data,
    including frequency count and bar charts. We then introduced marginal distribution
    and faceted bar charts when working with multiple categorical variables.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: Next, we switched to analyzing numerical variables and covered sensitive measures
    such as central tendency (mean) and variation (variance), as well as robust measures
    such as median and IQR. Several types of charts are available for visualizing
    a numerical variable, including histograms, density plots, and box plots, all
    of which can be combined with another categorical variable.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we went through a case study using the stock price data. We started
    by downloading the real data from Yahoo! Finance and applying all the EDA techniques
    to analyze the data, followed by creating a correlation plot to indicate the strength
    of covariation between each pair of variables. This allows us to develop a helpful
    understanding of the relationship between variables and jump-start the predictive
    modeling stage.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover r markdown, a widely used package to generate
    interactive reports in R.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
