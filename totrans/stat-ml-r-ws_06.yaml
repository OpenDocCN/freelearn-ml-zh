- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploratory Data Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter covered the basic plotting principles using `ggplot2`,
    including the use of various geometries and themes layers. It turns out that cleaning
    and massaging the raw data (covered in [*Chapter 2*](B18680_02.xhtml#_idTextAnchor032)
    and [*Chapter 3*](B18680_03.xhtml#_idTextAnchor050)) and visualizing the data
    (covered in [*Chapter 4*](B18680_04.xhtml#_idTextAnchor077)) belong to the first
    stage of a typical data science project workflow – that is, **exploratory data
    analysis** (**EDA**). We will cover this using a few case studies in this chapter.
    We will learn how to apply the coding techniques we covered earlier in this book
    and focus on analyzing the data through the lens of EDA.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will know how to uncover the structures of data
    using numerical and graphical techniques, discover interesting relationships among
    variables, and spot unusual observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: EDA fundamentals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EDA in practice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To complete the exercises in this chapter, you will need to have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The latest version of the `yfR` package, which is 1.0.0 at the time of writing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of the `corrplot` package, which is 0.92 at the time of writing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code and data for this chapter are available at [https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_5/chapter_5.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_5/chapter_5.R).
  prefs: []
  type: TYPE_NORMAL
- en: EDA fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When facing a new dataset in the form of a table (a DataFrame) in Excel or a
    dataset, EDA helps us gain insight into the underlying pattern and irregularities
    of variables in the dataset. This is an important first-step exercise before building
    any predictive model. As the saying goes, *garbage in, garbage out*. When the
    input variables used for model development suffer from problems, such as missing
    values or different scales, the resulting model will either perform poorly, converge
    slowly, or even hit an error in the training stage. Therefore, understanding your
    data and ensuring the raw materials are in check are critical steps in warrantying
    a good-performing model later on.
  prefs: []
  type: TYPE_NORMAL
- en: This is where EAD comes in. Instead of being a rigid statistical procedure,
    EAD is a set of exploratory analyses that enables you to develop a better understanding
    of the features and potential relationships in the data. It serves as a transitional
    analysis to guide modeling later on, involving both the data manipulation and
    visualization techniques we learned earlier. It helps summarize salient characteristics
    of the data through various forms of visual aids, facilitating the extraction
    of important features.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two broad types of EDA: descriptive statistics such as the mean,
    median, mode, and inter-quantile range, and graphical descriptions such as density
    plots, histograms, box plots, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: A typical EAD process includes analyzing categorical and numerical variables,
    both standalone in univariate analysis and in combination via bivariate and multivariate
    analysis. Common practices include analyzing the distribution of a given set of
    variables and examining missing values and outliers. In the following sections,
    we will start by analyzing different types of data, including categorical and
    numerical variables. We will then go through a case study to apply and reinforce
    the techniques covered in previous chapters using `dplyr` and `ggplot2`.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing categorical data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will look at how to analyze two categorical variables via
    graphical and numerical summaries. We will use a dataset on comic characters from
    the Marvel comics universe, which should not be unfamiliar to you if you are a
    fan of Marvel superheroes. The dataset is published by `read_csv()` function from
    the `readr` package, the data loading arm of the `tidyverse` universe, as shown
    in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Printing out the DataFrame shows that this dataset contains `16,376` rows and
    `13` columns, including the character names, IDs, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at summarizing two categorical variables using
    the count statistic.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing categorical variables using counts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will cover different ways to analyze two categorical variables,
    including using a contingency table and a bar chart. A contingency table is a
    useful way to show the total counts of observations that fall into each unique
    combination of the two categorical variables. Let’s go through an exercise on
    how to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.1 – summarizing two categorical variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will focus on two categorical variables: `ALIGN` (indicating
    whether the character is good, neutral, or bad) and `SEX` (indicating the gender
    of the character). First, we will look at the unique values of each variable,
    followed by summarizing the respective total counts when combined:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspect the unique values of `ALIGN` and `SEX`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The results show that both variables contain `NA` values. Let’s remove the observations
    with `NA` values in either `ALIGN` or `SEX`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Remove observations with `NA` values in either `ALIGN` or `SEX` in `df` using
    the `filter` verb function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can verify whether the rows with `NA` values have been successfully removed
    by checking the dimension of the resulting DataFrame and the count of `NA` values
    in `ALIGN` and `SEX`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we must create a contingency table to summarize the frequency of each
    unique combination of values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a contingency table between `ALIGN` and `SEX`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see that most characters are male and bad. Among all male characters,
    the majority are bad, whereas good or neutral characters are dominant in female
    characters. Let’s visually present and analyze the proportions using a bar chart.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a bar chart between these two variables using `ggplot2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 5.1 – Bar chart of ALIGN and SEX](img/B18680_05_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Bar chart of ALIGN and SEX
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the total count of `Agender Characters` and `Genderfluid Characters`
    is very limited, we can remove these two combinations when plotting the bar chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Removing low-count combinations from the bar chart](img/B18680_05_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Removing low-count combinations from the bar chart
  prefs: []
  type: TYPE_NORMAL
- en: Using counts may not be as intuitive when comparing different combinations.
    In this case, converting counts into proportions will help present the information
    on a relative scale.
  prefs: []
  type: TYPE_NORMAL
- en: Converting counts into proportions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will go over an exercise that covers conditional proportions
    in a contingency table. Unlike the previous unconditional contingency table, conditioning
    along either dimension of a two-way contingency table results in a different distribution
    of proportions.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.2 – summarizing two categorical variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will learn how to express the previous contingency table
    using proportions and convert it into a conditional distribution based on a specified
    dimension:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Express the previous contingency table using proportions. Avoid scientific
    notation (for example, e+10) and keep three decimal places:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The values in the contingency table are now expressed as proportions. Since
    the proportions are derived by dividing the previous absolute counts by the total
    sum, we can verify whether the total sum of proportions is equal to one by summing
    all the values in the table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Obtain the contingency table as proportions after conditioning on rows (here,
    the `ALIGN` variable):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can verify the conditioning by calculating the row-wise summations:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this code, setting `margin=1` means row-level conditioning. We can also exercise
    column-level conditioning by setting `margin=2`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Obtain the contingency table as proportions after conditioning on columns (for
    instance, the `SEX` variable):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similarly, we can verify the conditioning by calculating the column-wise summations:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the unconditional proportions in a bar chart after applying the same filtering
    condition to `SEX`. Change the label of the *y* axis to `proportion`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.3*, where it is obvious that bad
    characters are predominantly male characters:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Visualizing the unconditional proportions in a bar chart](img/B18680_05_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Visualizing the unconditional proportions in a bar chart
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also obtain a similar result from a different angle by switching the
    two variables in the bar chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.4*, where `ALIGN` is used as the
    *x* axis and `SEX` is used as the grouping variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Switching variables in the bar chart.](img/B18680_05_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Switching variables in the bar chart.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look at describing one categorical variable using a marginal distribution
    and faceted bar chart.
  prefs: []
  type: TYPE_NORMAL
- en: Marginal distribution and faceted bar charts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Marginal distribution refers to the distribution of one variable after integrating
    other variables. This means that we are interested in the distribution of one
    specific variable, no matter how the other variables are distributed.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of our previous two-way contingency table stored in `count_df`,
    we can derive the marginal distribution of `SEX` in the form of a frequency count
    by summing over all possible values of `ALIGN`. That is, we can perform column-wise
    summation to get the marginal count of `SEX`, as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This has the same effect as directly obtaining the count of different categories
    in `SEX`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, what if we would like to obtain the marginal distribution of one variable
    for each category of another variable? This can be achieved via `ggplot2`, as
    shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this code generates *Figure 5**.5*, which contains three side-by-side
    bar charts for bad, good, and neutral characters, respectively. This is essentially
    rearranging the stacked bar chart in *Figure 5**.4*. Note that faceting can be
    added by using the `facet_wrap` function, where `~ALIGN` indicates that the faceting
    is to be performed using the `ALIGN` variable. Note that we used the `strip.text.x`
    attribute to adjust the text size of the facet grid labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Faceted bar chart](img/B18680_05_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Faceted bar chart
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, we can adjust the sequence of the individual bar facets by overriding
    the levels of `ALIGN` after converting it into a factor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the same faceting codes again will now generate *Figure 5**.6*, where
    the sequence of facets is determined according to the levels in `ALIGN`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Arranging the sequence of facets in a faceted bar chart](img/B18680_05_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – Arranging the sequence of facets in a faceted bar chart
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at different ways to explore numerical variables.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing numerical data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will look at summarizing numerical data using different
    types of plots for the Marvel dataset. Since there’s an infinite amount of values
    that a numerical/continuous variable can assume, the frequency table used earlier
    no longer applies. Instead, we often group the values into pre-specified bins,
    allowing us to work with ranges instead of single values.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.3 – exploring numerical variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will describe a numerical variable using a dot plot, histogram,
    density plot, and box plot for the `Year` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Get a summary of the `Year` variable using the `summary()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Generate a dotted plot of the `Year` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.7*, where each dot represents an
    observation at the corresponding location on the *x* axis. Similar observations
    are then stacked together on top of each top. It should be noted that using a
    dot plot is not the best option when the number of observations becomes large,
    with the *y* axis becoming meaningless due to technical limitations in `ggplot2`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Summarizing the Year variable using a dot plot](img/B18680_05_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – Summarizing the Year variable using a dot plot
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a histogram of the `Year` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.8*, where each value of `Year` is
    grouped into bins and then the number of observations in each bin is counted to
    represent the height of each bin. Note that the default number of bins is 30,
    although this can be overwritten using the `bins` argument. The histogram thus
    presents the general shape of the distribution of the underlying variable. We
    can also convert it into a density plot to smooth out the steps between bins:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Summarizing the Year variable using a histogram](img/B18680_05_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – Summarizing the Year variable using a histogram
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a density plot of the `Year` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.9*, where the distribution is represented
    as a smooth line. Note that a density plot is recommended only when there are
    many observations in the dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Summarizing the Year variable using a density plot](img/B18680_05_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – Summarizing the Year variable using a density plot
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a box plot of the `Year` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 5.10 – Summarizing the Year variable using a box plot](img/B18680_05_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – Summarizing the Year variable using a box plot
  prefs: []
  type: TYPE_NORMAL
- en: Running this command generates *Figure 5**.10*, where the central box represents
    the majority (25th to 75th percentile) of the observations, the middle line in
    the box denotes the median (50th percentile), and the outreaching whiskers include
    almost all “normal” observations. The outlier observation, which is none in this
    case, would be represented as dots outside the reach of the whiskers.
  prefs: []
  type: TYPE_NORMAL
- en: We can also add a faceting layer by `SEX` and observe the change in box plots
    across different genders.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a faceting layer to the previous box plot using the `SEX` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.11*. As we can see, most female
    characters are introduced later than many of the male characters, and recent years
    feature more female characters than male ones:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Faceting the box plot based on SEX](img/B18680_05_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – Faceting the box plot based on SEX
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how to visualize data with higher dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Visualization in higher dimensions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The previous example used facets to present the distribution of a numerical
    variable in each unique value of a categorical variable. When there is more than
    one categorical variable, we can apply the same technique and expand the facets
    accordingly. This allows us to visualize the same numerical variable in higher
    dimensions that contain more than one categorical variable. Let’s go through an
    exercise on visualizing the distribution of `Year` by `ALIGN` and `SEX`.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.4 – visualizing Year by ALIGN and SEX
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `facet_grid()` function from `ggplot2` to
    visualize the distribution of `Year` in each unique combination of `ALIGN` and
    `SEX` using both a density plot and a histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a density plot of `Year` by `ALIGN` and `SEX` after applying the same
    filtering condition to `SEX`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.12*, where we used the `facet_grid()`
    function to create six histograms, with the columns split by the first argument,
    `ALIGN`, and the rows split by the second argument, `SEX`. The result shows an
    increasing trend (more movies were produced) for all different combinations of
    `ALIGN` and `SEX`. However, since the *y* axis shows the relative density only,
    we would need to switch to a histogram to assess the absolute frequency of occurrence.
    Note that we used the `strip.text.y` attribute to adjust the text size of the
    facet grid labels along the *y* axis:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.12 – Density plot of Year by ALIGN and SEX](img/B18680_05_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – Density plot of Year by ALIGN and SEX
  prefs: []
  type: TYPE_NORMAL
- en: 'Build the same plots using a histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.13*, where we can see that good
    female and male characters are steadily increasing in recent years:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Histogram of Year by ALIGN and SEX](img/B18680_05_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – Histogram of Year by ALIGN and SEX
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will try different ways to measure the central concentration
    of a numerical variable.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the central concentration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are different ways to measure the central concentration, or central tendency,
    of a numerical variable. Depending on the context and purpose, the measure of
    center is often used to represent a typical observation out of a numerical variable
    of interest.
  prefs: []
  type: TYPE_NORMAL
- en: The most popular measure of center is the mean, which is calculated as the average
    value of a list of numbers. In other words, we can obtain the mean value by summing
    all observations divided by the number of observations. This can be achieved using
    the `mean()` function in R.
  prefs: []
  type: TYPE_NORMAL
- en: Another measure of center is the median, which is the middle value after sorting
    the list of numbers from the smallest to the largest. This can be achieved using
    the `median()` function in R.
  prefs: []
  type: TYPE_NORMAL
- en: The third measure of center is the mode, which represents the most common observation
    in the list of numbers. Since there is no built-in function for calculating the
    mode, we must write a customized function to obtain the most frequent observation
    based on the count of occurrences using the `table()` function.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to look at the shape of the distribution before deciding on
    the measure of center. For a start, note that the mean value is often drawn toward
    the long tail of a skewed distribution, a continuous distribution inferred from
    the list of numbers such as the density plot from earlier. In other words, the
    mean value is sensitive to the extreme values in the observations. On the other
    hand, the median will not suffer from such sensitivity since it is simply a measure
    that divides the ordered observations by half. Therefore, the median is a better
    and more sensible candidate measure of center when working with a skewed continuous
    distribution, unless additional treatment on the extreme values, often treated
    as outliers, is in place.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at how to obtain the three measures of center via an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.5 – calculating the measure of center
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will calculate the mean, median, and mode of `APPEARANCES`,
    which denotes the number of appearances for each character:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the mean of `APPEARANCES`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `NA` result suggests that there are `NA` values in the observations of
    `APPEARANCES`. To verify this, we can look at the summary of this continuous variable:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Indeed, there are quite a few `NA` values. To calculate the mean value after
    removing these `NA` observations, we can enable the `na.rm` argument in the `mean()`
    function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the mean of `APPEARANCES`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: When the mean and median values deviate a lot from each other, this is an obvious
    sign that we are working with a skewed distribution. In this case, the `APPEARANCES`
    variable is quite skewed, with the median character appearing three times and
    the most popular character appearing up to 4,043 times.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the mode of `APPEARANCES`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we created a customized function called `mode()` to calculate the mode
    of a numerical variable, where we first extract a list of the unique values using
    the `unique()` function, then count the number of times each unique value appears
    using the `tabulate()` and `match()` functions, and lastly obtain the index of
    the maximal value using the `which.max()` function. The result shows that the
    majority of characters only appear once in the entire history of Marvel comics.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, let’s look at a detailed breakdown of mean and median appearances by `ALIGN`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the mean and median values of `APPEARANCES` by each level of `ALIGN`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result shows that good characters appear more often than bad ones.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, we will look at how to measure the variability of a continuous variable.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring variability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with central concentration, several metrics can be used to measure the variability
    or dispersion of a continuous variable. Some are sensitive to outliers, such as
    variance and standard deviation, while others are robust to outliers, such as
    **inter-quantile range** (**IQR**). Let’s go through an exercise on how to calculate
    these metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Note that robust measures such as median and IQR are used in box plots, although
    more details are hidden compared to the full density of a given variable.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.6 – calculating the variability of a continuous variable
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will calculate different metrics on variability both manually
    and using built-in functions. We will start with variance, which is calculated
    as the average squared difference between each raw value and the mean value. Note
    that this is how population variance is calculated. To calculate the sample variance,
    we need to adjust the averaging operation by subtracting 1 from the total number
    of observations used in the variance calculation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, variance is a squared version of the original unit and is thus
    not easily interpretable. To measure the variability of the data at the same original
    scale, we can use standard deviation, which is calculated by taking the square
    root of the variance. Let’s look at how to achieve this in practice:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the population variance of `APPEARANCES` after removing `NA` values.
    Keep two decimal points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we first remove `NA` values from `APPEARANCES` and save the result in
    `tmp`. Next, we subtract the mean value of `tmp` from each original value, square
    the result, sum all values, and then divide by the number of observations in `tmp`.
    This essentially follows the definition of variance, which measures the average
    variability of each observation to the central tendency – in other words, the
    mean value.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can also calculate the sample variance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the sample variance of `APPEARANCES`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result is now slightly different from the population variance. Note that
    to calculate the sample mean, we simply use one less observation in the denominator.
    Such adjustment is necessary, especially when we are working with limited sample
    data, although the difference becomes small as the sample size grows.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can also calculate sample variance by calling the `var()` function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate sample variance using `var()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result is aligned with our previous manual calculation of the sample variance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To obtain the measure of variability at the same unit as the original observations,
    we can calculate the standard deviation. This can be achieved using the `sd()`
    function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the standard deviation using `sd()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Another measure of variability is IQR, which is the difference between the third
    and first quantiles and quantifies the range of the majority values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the IQR using `IQR()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also verify the result by calling the `summary()` function, which returns
    the different quantile values:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As discussed earlier, measures such as variance and standard deviation are sensitive
    to extreme values in the data, while IQR is a robust measure of outliers. We can
    assess the change to these measures after removing the maximal value from `tmp`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the standard deviation and IQR after removing the maximum from `tmp`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result shows that IQR stays the same after removing the maximum, thus being
    a more robust measure compared to standard deviation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can also calculate these measures by different levels of another categorical
    variable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the standard deviation, IQR, and count of `APPEARANCES` for each
    level of `ALIGN`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we will dive deeper into the skewness in the distribution of a continuous
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: Working with skewed distributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Besides the mean and standard deviation, we can also characterize the distribution
    of a continuous variable using modality and skewness. Modality refers to the number
    of humps that exist in the continuous distribution. For example, a unimodal distribution,
    the most popular distribution we have seen so far in the form of a bell curve,
    has one peak across the whole distribution. It can grow into a bimodal distribution
    when there are two humps and multimodal distribution when there are three humps
    or more. If there is no discernable mode and the distribution appears flat across
    the whole support region (the range of the continuous variable), it is referred
    to as a uniform distribution. *Figure 5**.14* summarizes the distributions of
    different modalities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14 – Different types of modalities in a distribution](img/B18680_05_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 – Different types of modalities in a distribution
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, a continuous variable may be skewed toward the left or the
    right or appear symmetric around the central tendency. A right-skewed distribution
    contains more extreme values on the right tail of the distribution, while a left-skewed
    distribution has a long tail on the left-hand side. *Figure 5**.15* illustrates
    the different types of skewness in a distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15 – Different types of skewness in a distribution](img/B18680_05_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.15 – Different types of skewness in a distribution
  prefs: []
  type: TYPE_NORMAL
- en: Distribution can also attribute its skewness to outliers in a continuous variable.
    When there are multiple outliers in the data, sensitive measures such as mean
    and variance will become distorted, causing a shift in distribution toward the
    outliers. Let’s go through an exercise to understand how to deal with skewness
    and outliers in a distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.7 – working with skewness and outliers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will look at how to work with a skewed distribution that
    contains many extreme values, especially outliers in the data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Visualize the density plot of `APPEARANCES` by `ALIGN` for observations since
    the year `2000`. Set the transparency level to `0.2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.16*, where all three distributions
    are quite skewed toward the right, an obvious sign of many outliers in the data:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.16 – Density plot of APPEARANCES by ALIGN](img/B18680_05_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.16 – Density plot of APPEARANCES by ALIGN
  prefs: []
  type: TYPE_NORMAL
- en: 'Remove observations whose `APPEARANCES` are above the 90th percentile and generate
    the same plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.17*, where all three distributions
    are much less right-skewed than before. Removing outliers is one way to work around
    extreme values, although the information contained in the removed observations
    is lost. To control the effect of outliers and retain their presence at the same
    time, we can transform the continuous variable using the `log()` function, which
    brings it to the logarithmic scale. Let’s see how this works in practice:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.17 – Density plot of APPEARANCES by ALIGN after removing outliers](img/B18680_05_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.17 – Density plot of APPEARANCES by ALIGN after removing outliers
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply log transformation to `APPEARANCES` and re-generate the same plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.18*, where the three density plots
    appear as a bimodal distribution and not as right-skewed as before. Transforming
    the continuous variable using the logarithmic function could thus bring the original
    value to a more controlled scale:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.18 – Density plot of APPEARANCES by ALIGN after applying log transformation](img/B18680_05_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.18 – Density plot of APPEARANCES by ALIGN after applying log transformation
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will go through a case study to enhance our skills when
    conducting EDA on a new dataset.
  prefs: []
  type: TYPE_NORMAL
- en: EDA in practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will analyze a dataset that consists of the stock prices
    of the top five companies in 2021\. First, we will look at how to download and
    process these stock indexes, followed by performing univariate analysis and bivariate
    analysis in terms of correlation.
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining the stock price data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To obtain the daily stock prices of a particular ticker, we can use the `yfR`
    package to download the data from Yahoo! Finance, a vast repository of financial
    data that covers a large number of markets and assets and has been widely used
    in both academia and industry. The following exercise illustrates how to download
    the stock data using `yfR`.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.8 – downloading stock prices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will look at how to specify the different parameters so
    that we can download stock prices from Yahoo! Finance, including the ticker name
    and date range:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install and load the `yfR` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that we would need to wrap the package name inside a pair of double quotes
    in the `install.packages()` function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Specify the starting and end date parameters, as well as the ticker names so
    that they cover Facebook (now `META`), Netflix (`NFLX`), Google (`GOOG`), Amazon
    (`AMZN`), and Microsoft (`MSFT`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, the start and end dates are formatted as the `Date` type, and the ticker
    names are concatenated in a vector.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Download the stock prices using the `yf_get()` function and store the result
    in `df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates the following message, which shows that the
    data for all five stocks has been downloaded successfully. Each ticker has 252
    rows in 2021 since there are 252 trading days in a year:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s examine the structure of the dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The data that’s been downloaded includes information such as the daily opening,
    closing, highest, and closet prices for each ticker.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the following sections, we will use the adjusted price field, `price_adjusted`,
    which is adjusted for corporate events such as splits, dividends, and others.
    This is usually what we would use when analyzing stocks as it represents the actual
    financial performance of the stockholders.
  prefs: []
  type: TYPE_NORMAL
- en: Univariate analysis of individual stock prices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will perform a graphical analysis based on the stock prices.
    Since the stock prices are time series data that are numerical, we will use plots
    such as histograms, density plots, and box plots for visualization purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.9 – downloading stock prices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will start with the time series plots for the five stocks,
    followed by generating other types of plots suitable for continuous variables:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate the time series plots for the five plots:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.19*, where Netflix takes the lead
    in terms of stock value. However, it also suffers from a huge fluctuation, especially
    around November 2021:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.19 – Time series plots of the five stocks](img/B18680_05_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.19 – Time series plots of the five stocks
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a histogram for each of the five stocks, with 100 bins for each histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.20*, which shows that Netflix has
    the biggest mean and variance in terms of stock value. Google and Amazon seem
    to share a similar spread, and the same goes for Facebook and Microsoft:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.20 – Histograms of the five stocks](img/B18680_05_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.20 – Histograms of the five stocks
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a density plot for each of the five stocks. Set the transparency level
    to `0.2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.21*, where the plots are now visually
    clearer compared to the histograms:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.21 – Density plots of the five stocks](img/B18680_05_021.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.21 – Density plots of the five stocks
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a box plot for each of the five stocks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this command generates *Figure 5**.22*. Box plots are good at indicating
    the central tendency and variation of each stock. For example, Netflix has the
    biggest mean and variance across all five stocks:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.22 – Box plots of the five stocks](img/B18680_05_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.22 – Box plots of the five stocks
  prefs: []
  type: TYPE_NORMAL
- en: 'Obtain the mean, standard deviation, IQR, and count of each stock:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the next section, we will look at the pairwise correlation between each pair
    of stocks.
  prefs: []
  type: TYPE_NORMAL
- en: Correlation analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Correlation measures the strength of covariation between two variables. There
    are several ways to calculate the specific value of correlation, with Pearson
    correlation being the most widely used. Pearson correlation is a value that ranges
    from -1 to 1, with 1 indicating two perfectly and positively correlated variables
    and -1 denoting perfect negative correlation. Perfect correlation means that the
    change in the value of one variable is always proportional to the change in the
    value of another variable. For example, when y = 2x, the correlation between variable
    x and y is 1 since y always changes positively in proportion to x.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of manually calculating the pairwise correlation between all variables,
    we can use the `corrplot` package to calculate and visualize pairwise correlations
    automatically. Let’s go through an exercise on how this can be achieved.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.10 – downloading stock prices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will first convert the previous DataFrame from long into
    wide format so that each stock has a separate column indicating the adjusted price
    across different days/rows. The wide-format dataset will then be used to generate
    the pairwise correlation plot:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Convert the previous dataset into a wide format using the `spread()` function
    in the `tidyr` package. Save the result in `wide_df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we first select three variables, with `ref_date` as the row-level date
    index, `ticker`, whose unique values serve as the columns to be spread across
    the DataFrame, and `price_adjusted`, to be used to fill in the cells of the wide
    DataFrame. With this, we can examine the first few rows of the new dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, the DataFrame has been converted from a long format into a wide format,
    which will facilitate the creation of correlation plots later on.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate a correlation plot using the `corrplot()` function from the `corrplot`
    package (to be installed if you have not done so already):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running these commands generates *Figure 5**.23*. Each circle represents the
    strength of correlation between the corresponding stocks, where a bigger and darker
    circle denotes a stronger correlation:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.23 – Correlation plot between each pair of stocks](img/B18680_05_023.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.23 – Correlation plot between each pair of stocks
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the correlation plot relies on the `cor_table` variable, which stores
    the pairwise correlation as a table, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: A high correlation between variables may or may not be a good thing. When the
    dependent variable (also called the target outcome) to be predicted is highly
    correlated with an independent variable (also called a predictor, feature, or
    covariate), we would prefer to include this feature in the prediction model due
    to its high covariation with the target variable. On the other hand, when two
    features are highly correlated, we tend to ignore one and choose the other or
    apply some sort of regularization and feature selection approach to downsize the
    impact of correlated features.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced basic techniques to conduct EDA. We started by
    going over the common approaches to analyzing and summarizing categorical data,
    including frequency count and bar charts. We then introduced marginal distribution
    and faceted bar charts when working with multiple categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we switched to analyzing numerical variables and covered sensitive measures
    such as central tendency (mean) and variation (variance), as well as robust measures
    such as median and IQR. Several types of charts are available for visualizing
    a numerical variable, including histograms, density plots, and box plots, all
    of which can be combined with another categorical variable.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we went through a case study using the stock price data. We started
    by downloading the real data from Yahoo! Finance and applying all the EDA techniques
    to analyze the data, followed by creating a correlation plot to indicate the strength
    of covariation between each pair of variables. This allows us to develop a helpful
    understanding of the relationship between variables and jump-start the predictive
    modeling stage.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will cover r markdown, a widely used package to generate
    interactive reports in R.
  prefs: []
  type: TYPE_NORMAL
