- en: Recommendation Engines with Apache Mahout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recommendation engines are one of the most applied data science approaches
    in startups today. There are two principal techniques for building a recommendation
    system: content-based filtering and collaborative filtering. The content-based
    algorithm uses the properties of the items to find items with similar properties.
    Collaborative filtering algorithms take user ratings, or other user behaviors,
    and make recommendations based on what users with similar behaviors liked or purchased.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will first explain the basic concepts required to understand
    recommendation engine principles, and then we will demonstrate how to utilize
    Apache Mahout's implementation of various algorithms in order to quickly get a
    scalable recommendation engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: How to build a recommendation engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting Apache Mahout ready
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The content-based approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The collaborative filtering approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have learned about the kind of recommendation
    engine that is appropriate for our problem and how to quickly implement that engine.
  prefs: []
  type: TYPE_NORMAL
- en: Basic concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recommendation engines aim at showing users items of interest. What makes them
    different from search engines is the relevant content usually appears on a website
    without having been requested, and users don't have to build queries, as recommendation
    engines observe the users' actions and construct the queries for users without
    their knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Arguably, the most well-known example of a recommendation engine is [www.amazon.com](http://www.amazon.com),
    which provides personalized recommendation in a number of ways. The following
    screenshot shows an example of Customers Who Bought This Item Also Bought. As
    you will see later on, this is an example of collaborative item-based recommendation,
    where items similar to a particular item are recommended:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bc5d5436-b9f5-42ba-8642-1f2bb6e0e6e3.png)'
  prefs: []
  type: TYPE_IMG
- en: In this section, we will introduce key concepts related to understanding and
    building recommendation engines.
  prefs: []
  type: TYPE_NORMAL
- en: Key concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recommendation engines require the following pieces of input in order to make
    recommendations:'
  prefs: []
  type: TYPE_NORMAL
- en: Item information, described with attributes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A user profile, such as age range, gender, location, friends, and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User interactions, in the form of rating, browsing, tagging, comparing, saving,
    and emailing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The context where the items will be displayed; for example, the item's category
    and the item's geographical location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This input is then combined by the recommendation engine to help obtain the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Users who bought, watched, viewed, or bookmarked this item also bought, watched,
    viewed, or bookmarked
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Items similar to this item
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other users you may know
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other users who are similar to you
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's take a closer look at how this combination works.
  prefs: []
  type: TYPE_NORMAL
- en: User-based and item-based analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building a recommendation engine depends on whether the engine searches for
    related items or users when trying to recommend a particular item.
  prefs: []
  type: TYPE_NORMAL
- en: In item-based analysis, the engine focuses on identifying items that are similar
    to a particular item, while in user-based analysis, users similar to the particular
    user are determined first. For example, users with the same profile information
    (age, gender, and so on) or action history (bought, watched, viewed, and so on)
    are determined, and then the same items are recommended to other, similar users.
  prefs: []
  type: TYPE_NORMAL
- en: Both approaches require us to compute a similarity matrix, depending on whether
    we're analyzing item attributes or user actions. Let's take a deeper look at how
    this is done.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating similarity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are three fundamental approaches to calculating similarity, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering algorithms take user ratings or other user behaviors
    and make recommendations based on what users with similar behaviors liked or purchased
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The content-based algorithm uses the properties of the items to find items with
    similar properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A hybrid approach combines collaborative and content-based filtering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a look at each approach in detail in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Collaborative filtering** is based solely on user ratings or other user behaviors,
    making recommendations based on what users with similar behaviors liked or purchased.'
  prefs: []
  type: TYPE_NORMAL
- en: A key advantage of collaborative filtering is that it does not rely on item
    content, and therefore, it is capable of accurately recommending complex items,
    such as movies, without understanding the item itself. The underlying assumption
    is that people that agreed in the past will agree in the future, and that they
    will like similar kinds of items to what they liked in the past.
  prefs: []
  type: TYPE_NORMAL
- en: A major disadvantage of this approach is the so-called cold start, meaning that
    if we want to build an accurate collaborative filtering system, the algorithm
    often needs a large amount of user ratings. This usually takes collaborative filtering
    out of the first version of the product, and it is introduced later, when a decent
    amount of data has been collected.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Content-based filtering, on the other hand, is based on a description of items
    and a profile of a user's preferences, which is combined as follows. First, the
    items are described with attributes, and to find similar items, we measure the
    distances between items using a distance measure, such as the cosine distance
    or Pearson coefficient (there is more about distance measures in [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml),
    *Applied Machine Learning Quick Start*). Now, the user profile enters the equation.
    Given the feedback about the kinds of items the user likes, we can introduce weights,
    specifying the importance of a specific item attribute. For instance, the Pandora
    Radio streaming service applies content-based filtering to create stations, using
    more than 400 attributes. A user initially picks a song with specific attributes,
    and, by providing feedback, important song attributes are emphasized.
  prefs: []
  type: TYPE_NORMAL
- en: Initially, this approach needs very little information on user feedback; thus,
    it effectively avoids the cold start issue.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, between collaborative and content-based, which one should you choose? Collaborative
    filtering is able to learn user preferences from a user's actions regarding one
    content source, and use them across other content types. Content-based filtering
    is limited to recommending content of the same type that the user is already using.
    This provides value in certain use cases; for example, recommending news articles
    based on news browsing is useful, but it is much more useful if different sources,
    such as books and movies, can be recommended based on news browsing.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering and content-based filtering are not mutually exclusive;
    they can be combined to be more effective in some cases. For example, Netflix
    uses collaborative filtering to analyze the searching and watching patterns of
    similar users, as well as content-based filtering to offer movies that share characteristics
    with films that the user has rated highly.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a wide variety of hybridization techniques: weighted, switching, and
    mixed, feature combination, feature augmentation, cascade, meta-level, and so
    on. Recommendation systems are an active area in the machine learning and data
    mining community, with special tracks on data science conferences. A good overview
    of techniques is summarized in the paper *Toward the Next Generation of Recommender
    Systems: A Survey of the State-of-the-Art and Possible Extensions,* by Adomavicius
    and Tuzhilin (2005), where the authors discuss different approaches and underlying
    algorithms, and provide references to further papers. To get more technical and
    understand all of the tiny details when a particular approach makes sense, you
    should look at the book edited by Ricci, et al.: *Recommender Systems Handbook*
    (First Edition, 2010, *S*pringer-Verlag, New York).'
  prefs: []
  type: TYPE_NORMAL
- en: Exploitation versus exploration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In recommendation systems, there is always a trade-off between recommending
    items that fall into the user's sweet spot, based on what we already know about
    the user (**exploitation**), and recommending items that don't fall into the user's
    sweet spot, with the aim to expose the user to some novelties (**exploration**).
    Recommendation systems with little exploration will only recommend items that
    are consistent with the previous user ratings, thus preventing showing items outside
    of their current bubble. In practice, the serendipity of getting new items out
    of the user's sweet spot is often desirable, leading to a pleasant surprise, and
    potentially, the discovery of new sweet spots.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discussed the essential concepts required to start building
    recommendation engines. Now, let's take a look at how to actually build one with
    Apache Mahout.
  prefs: []
  type: TYPE_NORMAL
- en: Getting Apache Mahout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mahout was introduced in [Chapter 2](6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml),
    *Java Libraries and Platforms for Machine Learning*, as a scalable machine learning
    library. It provides a rich set of components with which you can construct a customized
    recommendation system from a selection of algorithms. The creators of Mahout say
    that it is designed to be enterprise-ready; it's designed for performance, scalability,
    and flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mahout can be configured to run in two flavors: with or without Hadoop, and
    for a single machine and distributed processing, respectively. We will focus on
    configuring Mahout without Hadoop. For more advanced configurations and further
    uses of Mahout, I would recommend two recent books: *Learning Apache Mahout,*
    by *C*handramani Tiwary, Packt Publishing, and *Learning Apache Mahout Classification,*
    by Ashish Gupta, Packt Publishing.'
  prefs: []
  type: TYPE_NORMAL
- en: As Apache Mahout's build and release system is based on Maven, you will need
    to learn how to install it. We will look at the most convenient approach; using
    Eclipse with the Maven plugin.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Mahout in Eclipse with the Maven plugin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will need a recent version of Eclipse, which can be downloaded from its
    home page ([https://www.eclipse.org/downloads/](https://www.eclipse.org/downloads/)).
    In this book, we will use Eclipse Luna. Open Eclipse and start a new Maven Project
    with the default settings, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d0f0d765-b4d9-4f6b-9e91-da68d83c8b55.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The New Maven project screen will appear, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09486760-7963-446f-a3a7-a8f436d10cbc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we need to tell the project to add the Mahout JAR file and its dependencies
    to the project. Locate the `pom.xml` file and open it with the text editor (left-click
    on Open With | Text Editor), as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad5a51b9-7f0e-44ad-a6bc-0cd4695675ef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Locate the line starting with `<dependencies>` and add the following code in
    the next line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: That's it; Mahout has been added, and we are ready to begin.
  prefs: []
  type: TYPE_NORMAL
- en: Building a recommendation engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To demonstrate both the content-based filtering and collaborative filtering
    approaches, we'll build a book recommendation engine.
  prefs: []
  type: TYPE_NORMAL
- en: Book ratings dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will work with a book ratings dataset (Ziegler et al.,
    2005) that was collected in a four-week crawl. It contains data on 278,858 members
    of the Book-Crossing website and 1,157,112 ratings, both implicit and explicit,
    referring to 271,379 distinct ISBNs. User data is anonymized, but with demographic
    information. The dataset is taken from [Improving Recommendation Lists Through
    Topic Diversification](http://www2.informatik.uni-freiburg.de/~dbis/Publications/05/WWW05.html),
    *C*ai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, Georg Lausen: *Proceedings
    of the 14th International World Wide Web Conference* (WWW ''05)*,* May 10-14,
    2005, Chiba, Japan ([http://www2.informatik.uni-freiburg.de/~cziegler/BX/](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Book-Crossing dataset is comprised of three files, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`BX-Users`: This contains the users. Note that user IDs (User-ID) have been
    anonymized and mapped to integers. Demographic data is provided (Location and
    Age) if available. Otherwise, these fields contain null values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BX-Books`: Books are identified by their respective ISBNs. Invalid ISBNs have
    already been removed from the dataset. Moreover, some content-based information
    is given (Book-Title, Book-Author, Year-Of-Publication, and Publisher), which
    has been obtained from Amazon Web Services. Note that in the case of several authors,
    only the first author is provided. URLs linking to cover images are also given,
    appearing in three different flavors (Image-URL-S, Image-URL-M, and Image-URL-L),
    referring to small, medium, and large URLs. These URLs point to the Amazon website.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BX-Book-Ratings`: This contains the book rating information. Ratings (Book-Rating)
    are either explicit, expressed on a scale of 1-10 (with higher values denoting
    higher appreciation), or implicit, expressed by 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two approaches to loading the data, according to where the data is
    stored: a file or database. First, we will take a detailed look at how to load
    the data from a file, including how to deal with custom formats. At the end, we
    will quickly take a look at how to load the data from a database.'
  prefs: []
  type: TYPE_NORMAL
- en: Loading data from a file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Loading data from a file can be achieved with the `FileDataModel` class. We
    will be expecting a comma-delimited file, where each line contains a `userID`,
    an `itemID`, an optional `preference` value, and an optional `timestamp`, in the
    same order, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: An optional preference accommodates applications with binary preference values,
    that is, the user either expresses a preference for an item or not, without a
    degree of preference; for example, with a like or dislike.
  prefs: []
  type: TYPE_NORMAL
- en: A line that begins with a hash (`#`) or an empty line will be ignored. It is
    also acceptable for the lines to contain additional fields, which will be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `DataModel` class assumes the following types:'
  prefs: []
  type: TYPE_NORMAL
- en: The `userID` and `itemID` can be parsed as `long`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `preference` value can be parsed as `double`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `timestamp` can be parsed as `long`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you are able to provide the dataset in the preceding format, you can simply
    use the following line to load the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This class is not intended to be used for very large amounts of data; for example,
    tens of millions of rows. For that, a JDBC-backed `DataModel` and a database are
    more appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, however, we cannot always ensure that the input data supplied
    to us contains only integer values for `userID` and `itemID`. For example, in
    our case, `itemID` corresponds to ISBN book numbers, which uniquely identify items,
    but these are not integers, and the `FileDataModel` default won't be suitable
    to process our data.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's consider how to deal with a case where our `itemID` is a string.
    We will define our custom data model by extending `FileDataModel` and overriding
    the long `readItemIDFromString(String)` method in order to read the `itemID` as
    a string and convert it into `long`, and return a unique `long` value. To convert
    a `String` into a unique `long`, we'll extend another Mahout `AbstractIDMigrator`
    helper class, which is designed exactly for this task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at how `FileDataModel` is extended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Other useful methods that can be overridden are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`readUserIDFromString(String value)`, if user IDs are not numeric'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`readTimestampFromString(String value)`, to change how `timestamp` is parsed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at how `AbstractIDMIgrator` is extended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have everything in place, and we can load our dataset with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This provides the total number of users and items as output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We are ready to move on and start making recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Loading data from a database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alternatively, we can load the data from a database using one of the JDBC data
    models. In this chapter, we will not dive into the detailed instructions of how
    to set up a database, connections, and so on, but we will give a sketch of how
    this can be done.
  prefs: []
  type: TYPE_NORMAL
- en: 'Database connectors have been moved to a separate package, `mahout-integration`;
    hence, we have to add the package to our `dependency` list. Open the `pom.xml`
    file and add the following `dependency`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider that we want to connect to a MySQL database. In this case, we will
    also need a package that handles database connections. Add the following to the
    `pom.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have all of the packages, so we can create a connection. First, let''s
    initialize a `DataSource` class with connection details, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Mahout integration implements `JDBCDataModel` to various databases that can
    be accessed via JDBC. By default, this class assumes that there is a `DataSource`
    available under the JNDI name, `jdbc/taste`, which gives access to a database
    with a
  prefs: []
  type: TYPE_NORMAL
- en: '`taste_preferences` table, with the following schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'A database-backed data model is initialized as follows. In addition to the
    DB connection object, we can specify the custom table name and the table column
    names, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In-memory databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Last, but not least, the data model can be created on the fly and held in memory.
    A database can be created from an array of preferences, which will hold user ratings
    for a set of items.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can proceed as follows. First, we create a `FastByIdMap` hash map of preference
    arrays, `PreferenceArray`, which stores an array of preferences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can create a new preference array for a user that will hold their
    ratings. The array must be initialized with a size parameter that reserves that
    many slots in the memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we set the user ID for the current preference at the position `0`. This
    will actually set the user ID for all preferences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Set an `itemID` for the current preference at the position `0`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the preference value for the preference at `0`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Continue for other item ratings, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, add the user `preferences` to the hash map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The preference hash map can now be used to initialize `GenericDataModel`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This code demonstrates how to add two preferences for a single user; in a practical
    application, you'll want to add multiple preferences for multiple users.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The recommendation engines in Mahout can be built with the `org.apache.mahout.cf.taste`
    package, which was formerly a separate project called `Taste`, and has continued to
    be developed in Mahout.
  prefs: []
  type: TYPE_NORMAL
- en: A Mahout-based collaborative filtering engine takes the users' preferences for
    items (tastes) and returns the estimated preferences for other items. For example,
    a site that sells books or CDs could easily use Mahout to figure out the CDs that
    a customer might be interested in listening to, with the help of previous purchase
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Top-level packages define the Mahout interfaces to the following key abstractions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**DataModel**: This represents a repository of information about users and
    their preferences for items'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**UserSimilarity**: This defines a notion of similarity between two users'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ItemSimilarity**: This defines a notion of similarity between two items'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**UserNeighborhood**: This computes neighboring users for a given user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommender**: This recommends items for the user'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A general structure of the preceding concepts is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e64495c-df83-4e76-84b8-0150cf124ea9.png)'
  prefs: []
  type: TYPE_IMG
- en: User-based filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most basic user-based collaborative filtering can be implemented by initializing
    the previously described components, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, load the data model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, define how to calculate how the users are correlated; for example, using
    the Pearson correlation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, define how to tell which users are similar, that is, the users that are
    close to each other, according to their ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can initialize a `GenericUserBasedRecommender` default engine with
    the data for `model`, `neighborhood`, and similar objects, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s it. Our first basic recommendation engine is ready. Let''s discuss
    how to invoke recommendations. First, let''s print the items that the user has
    already rated, along with ten recommendations for that user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This will provide the following recommendations, along with their scores, as
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Item-based filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `ItemSimilarity` attribute is the most important point to discuss here.
    Item-based recommenders are useful, as they can take advantage of something very
    fast; they base their computations on item similarity, not user similarity, and
    item similarity is relatively static. It can be precomputed, instead of recomputed
    in real time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, it''s strongly recommended that you use `GenericItemSimilarity` with
    precomputed similarities, if you''re going to use this class. You can use `PearsonCorrelationSimilarity`,
    too, which computes similarities in real time, but you will probably find this
    painfully slow for large amounts of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The resulting list returns a set of items that are similar to a particular item
    that we selected.
  prefs: []
  type: TYPE_NORMAL
- en: Adding custom rules to recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It often happens that some business rules require us to boost the score of
    the selected items. In the book dataset, for example, if a book is recent, we
    want to give it a higher score. That''s possible by using the `IDRescorer` interface,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`rescore(long, double)` takes the `itemId` and original score as an argument
    and returns a modified score'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`isFiltered(long)` returns `true` to exclude a specific item from the recommendations,
    or `false`, otherwise'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our example can be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'An instance of `IDRescorer` is provided when invoking `recommender.recommend`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might be wondering how to make sure that the returned recommendations make
    any sense. The only way to really be sure about how effective recommendations
    are is to use A/B testing in a live system, with real users. For example, the
    A group receives a random item as a recommendation, while the B group receives
    an item that's recommended by our engine.
  prefs: []
  type: TYPE_NORMAL
- en: As this is not always possible (nor practical), we can get an estimate with
    offline statistical evaluation. One way to proceed is to use k-fold cross-validation,
    which was introduced in [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml),
    *Applied Machine Learning Quick Start*. We partition a dataset into multiple sets;
    some are used to train our recommendation engine, and the rest are used to test
    how well it recommends items to unknown users.
  prefs: []
  type: TYPE_NORMAL
- en: Mahout implements the `RecommenderEvaluator` class, which splits a dataset in
    two parts. The first part (90%, by default) is used to produce recommendations,
    while the rest of the data is compared against estimated preference values in
    order to test the match. The class does not accept a `recommender` object directly;
    you need to build a class that's implementing the `RecommenderBuilder` interface
    instead, which builds a `recommender` object for a given `DataModel` object that
    is then used for testing. Let's take a look at how this is implemented.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create a class that implements the `RecommenderBuilder` interface.
    We need to implement the `buildRecommender` method, which will return a `recommender`,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have a class that returns a recommender object, we can initialize
    a `RecommenderEvaluator` instance. The default implementation of this class is
    the `AverageAbsoluteDifferenceRecommenderEvaluator` class, which computes the
    average absolute difference between the predicted and actual ratings for users.
    The following code shows how to put the pieces together and run a hold-out test:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, load a data model, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, initialize an `evaluator` instance, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the `BookRecommender` object, implementing the `RecommenderBuilder`
    interface, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, call the `evaluate()` method, which accepts the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RecommenderBuilder`: This is the object implementing the `RecommenderBuilder`
    that can build the `recommender` to test'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DataModelBuilder`: This indicates the `DataModelBuilder` to use; if null,
    a default `DataModel` implementation will be used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DataModel`: This is the dataset that will be used for testing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trainingPercentage`: This indicates the percentage of each user''s preferences
    to use to produce recommendations; the rest are compared to estimated preference
    values in order to evaluate the performance of the `recommender`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`evaluationPercentage`: This is the percentage of users to be used in the evaluation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The method is called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The method returns a `double`, where `0` represents the best possible evaluation,
    meaning that the recommender perfectly matches user preferences. In general, the
    lower the value, the better the match.
  prefs: []
  type: TYPE_NORMAL
- en: Online learning engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In any online platform, the new users will continue increasing. The previously
    discussed approach works well for the existing user. It is expensive to create
    a recommendation instance for every new user that's added. We cannot ignore the
    users that have been added to the system after the recommendation engine is made.
    To cope with situations that are similar to this, Apache Mahout has the ability
    of adding a temporary user to a data model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The general setup is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Periodically recreate the whole recommendation using current data (for example,
    each day or hour, depending on how long it takes)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always check whether the user exists in the system before going for a recommendation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the user exists, then complete the recommendations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the user does not exist, create a temporary user, fill in the preferences,
    and do the recommendation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first step seems to be tricky, in regards to how frequently the whole recommendation
    is to be generated using the current data. If the system is huge, memory constraints
    will be there, because when the new recommender is being generated, the old, working
    recommender should be held in memory, so the request is being served from the
    old copy until the new recommender is ready.
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the temporary users, we can wrap our data model with a `PlusAnonymousConcurrentUserDataModel`
    instance. This class allows us to obtain a temporary user ID; the ID must later
    be released so that it can be reused (there''s a limited number of such IDs).
    After obtaining the ID, we have to fill in the preferences, and then we can proceed
    with the recommendation, as always:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Content-based filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Content-based filtering is out of the scope of the Mahout framework, mainly
    because it is up to you to decide how to define similar items. If we want to do
    a content-based item similarity, we need to implement our own `ItemSimilarity`.
    For instance, in our book''s dataset, we might want to make up the following rule
    for book similarity:'
  prefs: []
  type: TYPE_NORMAL
- en: If the genres are the same, add `0.15` to `similarity`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the author is the same, add `0.50` to `similarity`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can now implement our own `similarity` measure, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: We can then use this `ItemSimilarity`, instead of something like `LogLikelihoodSimilarity`,
    or other implementations with a `GenericItemBasedRecommender`. That's about it.
    This is as far as we have to go to perform content-based recommendations in the
    Mahout framework.
  prefs: []
  type: TYPE_NORMAL
- en: What we saw here is one of the simplest forms of content-based recommendation.
    Another approach would be to create a content-based profile of users, based on
    a weighted vector of item features. The weights denote the importance of each
    feature to the user, and can be computed from individually-rated content vectors.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the basic concept of recommendation engines,
    the differences between collaborative and content-based filtering, and how to
    use Apache Mahout, which is a great basis for creating recommenders, as it is
    very configurable and provides many extension points. We looked at how to pick
    the right configuration parameter values, set up rescoring, and evaluate the recommendation
    results.
  prefs: []
  type: TYPE_NORMAL
- en: With this chapter, we have completed our overview of the data science techniques
    that are used to analyze customer behavior, which started with customer relationship
    prediction in [Chapter 4](6ac8d4de-1e7f-4f60-9cf0-93ab2fe55e4d.xhtml), *Customer
    Relationship Prediction with Ensembles*, and continued with affinity analytics
    in [Chapter 5](21e9de6d-720b-416a-bb9c-4c16541d97a9.xhtml), *Affinity Analysis*.
    In the next chapter, we will move on to other topics, such as fraud and anomaly
    detection.
  prefs: []
  type: TYPE_NORMAL
