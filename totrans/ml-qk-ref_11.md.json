["```py\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\n```", "```py\niris = datasets.load_iris()\nX = iris.data \ny = iris.target\n```", "```py\nX\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n```", "```py\nX_train\n```", "```py\nfrom sklearn.decomposition import KernelPCA\nkpca = KernelPCA(n_components = 2, kernel = 'rbf')\nX_train2 = kpca.fit_transform(X_train)\nX_test2 = kpca.transform(X_test)\n```", "```py\nX_train2\n```", "```py\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\n```", "```py\niris = datasets.load_iris()\nX = iris.data \ny = iris.target\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n```", "```py\nfrom sklearn.decomposition import FastICA\n```", "```py\nICA = FastICA(n_components=3, random_state=10,whiten= True) \nX=ICA.fit_transform(X_train)\n```", "```py\nplt.figure(figsize=(8,10))\nplt.title('ICA Components')\nplt.scatter(X[:,0], X[:,1])\nplt.scatter(X[:,1], X[:,2])\nplt.scatter(X[:,2], X[:,0])\n```", "```py\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport scipy.optimize as spopt\nimport scipy.fftpack as spfft\nimport scipy.ndimage as spimg\nimport cvxpy as cvx\n```", "```py\nx = np.sort(np.random.uniform(0, 15, 30))\ny = 5 + 0.5 * x + 0.1 * np.random.randn(len(x))\n```", "```py\n\nl1 = lambda x0, x, y: np.sum(np.abs(x0[0] * x + x0[1] - y))\nopt1 = spopt.fmin(func=l1, x0=[1, 1], args=(x, y))\n```", "```py\n\nl2 = lambda x0, x, y: np.sum(np.power(x0[0] * x + x0[1] - y, 2))\nopt2 = spopt.fmin(func=l2, x0=[1, 1], args=(x, y))\n\ny2 = y.copy()\ny2[3] += 5\ny2[13] -= 10\nxopt12 = spopt.fmin(func=l1, x0=[1, 1], args=(x, y2))\nxopt22 = spopt.fmin(func=l2, x0=[1, 1], args=(x, y2))\n```", "```py\nn = 10000\nt = np.linspace(0, 1/5, n)\ny = np.sin(1250 * np.pi * t) + np.sin(3000 * np.pi * t)\nyt = spfft.dct(y, norm='ortho')\nplt.figure(figsize=[10,5])\nplt.plot(t,y)\nplt.title('Original signal')\nplt.xlabel('Time (s)')\nplt.ylabel('y')\n```", "```py\nm = 1000 # 10% sample\nran = np.random.choice(n, m, replace=False) # random sample of indices\nt2 = t[ran]\ny2 = y[ran]\n```", "```py\n# create idct matrix operator\nA = spfft.idct(np.identity(n), norm='ortho', axis=0)\nA = A[ran]\n# do L1 optimization\nvx = cvx.Variable(n)\nobjective = cvx.Minimize(cvx.norm(vx, 1))\nconstraints = [A*vx == y2]\nprob = cvx.Problem(objective, constraints)\nresult = prob.solve(verbose=True)\n```", "```py\nx = np.array(vx.value)\nx = np.squeeze(x)\nsignal = spfft.idct(x, norm='ortho', axis=0)\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n```", "```py\ndata = pd.read_csv('Credit_Card_Applications.csv')\nX = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values\n```", "```py\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0, 1))\nX = sc.fit_transform(X)\n```", "```py\nfrom minisom import MiniSom\nsom = MiniSom(x = 10, y = 10, input_len = 15, sigma = 1.0, learning_rate = 0.5)\nsom.random_weights_init(X)\nsom.train_random(data = X, num_iteration = 100)    \n```", "```py\nfrom pylab import bone, pcolor, colorbar, plot, show\nbone()\npcolor(som.distance_map().T)\ncolorbar()\nmarkers = ['o', 's']\ncolors = ['r', 'g']\nfor i, x in enumerate(X):\n w = som.winner(x)\n plot(w[0] + 0.5,\n w[1] + 0.5,\n markers[y[i]],\n markeredgecolor = colors[y[i]],\n markerfacecolor = 'None',\n markersize = 10,\n markeredgewidth = 2)\nshow()\n```", "```py\nmappings = som.win_map(X)\nfrauds = np.concatenate((mappings[(8,1)], mappings[(6,8)]), axis = 0)\nfrauds = sc.inverse_transform(frauds)                                         \n```", "```py\nlibrary(foreign)\ndataset = read.spss(\"World95.sav\", to.data.frame=TRUE)\n\nlibrary(Amelia)\n\nmyvars <- names(dataset) %in% c(\"COUNTRY\", \"RELIGION\", \"REGION\",\"CLIMATE\") \nnewdata <- dataset[!myvars]\n```", "```py\nimpute.out <- amelia(newdata, m=4)\n```"]