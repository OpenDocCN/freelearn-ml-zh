- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Building Unsupervised Models with K-Means Clustering
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 K-Means 聚类构建无监督模型
- en: So far, we have learned about building **machine learning** (**ML**) models
    where data is supplied with labels. In this chapter, we will learn about building
    ML models on a dataset without any labels by using the **K-means clustering algorithm**.
    Unlike **supervised models**, where predictions are made at the observation level,
    K-means clustering groups observations into clusters where they share a commonality
    – for example, similar demographics or reading habits.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了关于构建带有标签数据的机器学习模型（**ML**）。在本章中，我们将学习如何使用**K-means 聚类算法**在没有任何标签的数据集上构建机器学习模型。与**监督模型**不同，监督模型在观察层面进行预测，而
    K-means 聚类将观察结果分组到具有共同特征的簇中——例如，相似的人口统计或阅读习惯。
- en: This chapter will provide detailed examples of business problems that can be
    solved with these modeling techniques. By the end of this chapter, you will be
    in a position to identify a business problem that an **unsupervised modeling technique**
    can be applied to. You will also learn how to build, train, and evaluate K-means
    model performance.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将提供使用这些建模技术的详细业务问题示例。到本章结束时，您将能够识别一个可以应用**无监督建模技术**的业务问题。您还将学习如何构建、训练和评估 K-means
    模型的性能。
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Grouping data through cluster analysis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过聚类分析分组数据
- en: Creating a K-means ML model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 K-means 机器学习模型
- en: Evaluating the results of K-means clustering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估 K-means 聚类结果
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires a web browser and access to the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要使用网络浏览器并访问以下内容：
- en: An AWS account
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS 账户
- en: An Amazon Redshift Serverless endpoint
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Redshift 无服务器端点
- en: Amazon Redshift Query Editor v2
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Redshift 查询编辑器 v2
- en: Complete the *Getting started with Amazon Redshift Serverless* section in [*Chapter
    1*](B19071_01.xhtml#_idTextAnchor015)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成[第 1 章](B19071_01.xhtml#_idTextAnchor015)中的“Amazon Redshift 无服务器入门”部分
- en: 'You can find the code used in this chapter here: [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter8/chapter8.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter8/chapter8.sql).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下链接找到本章使用的代码：[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter8/chapter8.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter8/chapter8.sql).
- en: Grouping data through cluster analysis
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过聚类分析分组数据
- en: So far, we have explored datasets that contained input and target variables,
    and we trained a model with a set of input variables and a target variable. This
    is called supervised learning. However, how do you address a dataset that does
    not contain a label to supervise the training? **Amazon Redshift ML** supports
    unsupervised learning using the cluster analysis method, also known as the K-means
    algorithm. In **cluster analysis**, the ML algorithm automatically discovers the
    grouping of data points. For example, if you have a population of 1,000 people,
    a clustering algorithm can group them based on height, weight, or age.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了包含输入和目标变量的数据集，并使用一组输入变量和目标变量训练了一个模型。这被称为监督学习。然而，如何处理不包含标签以监督训练的数据集呢？**Amazon
    Redshift ML** 支持使用聚类分析方法进行无监督学习，也称为 K-means 算法。在**聚类分析**中，机器学习算法自动发现数据点的分组。例如，如果您有
    1,000 人的群体，聚类算法可以根据身高、体重或年龄将他们分组。
- en: 'Unlike supervised learning, where an ML model predicts an outcome based on
    a label, unsupervised models use unlabeled data. One type of unsupervised learning
    is clustering, where unlabeled data is grouped based on its similarity or differences.
    From a dataset with demographic information about individuals, you can create
    clusters based on young, adult, and elderly populations, underweight, normal weight,
    and overweight populations, and so on. These groups are calculated based on values
    – for example, if two people are young, then they are grouped together. These
    groups are called **clusters**. In the following diagram, you can see that input
    variables (**Age**, **Height**, and **Weight**) are grouped into **young**, **adult**,
    and **elder**:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与监督学习不同，监督学习中的机器学习模型基于标签预测结果，无监督模型使用未标记的数据。无监督学习的一种类型是聚类，其中未标记数据根据其相似性或差异分组。从关于个人人口统计信息的数据集中，你可以根据年轻、成年和老年人口，体重过轻、正常体重和超重人口等创建聚类。这些群体基于值计算——例如，如果两个人都是年轻人，那么他们会被分到一组。这些群体被称为**聚类**。在下面的图中，你可以看到输入变量（**年龄**、**身高**和**体重**）被分组到**年轻**、**成年**和**老年**：
- en: '![Figure 8.1 – A simple cluster example](img/B19071_08_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – 一个简单的聚类示例](img/B19071_08_01.jpg)'
- en: Figure 8.1 – A simple cluster example
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 一个简单的聚类示例
- en: In the preceding diagram, each individual data point is placed in a cluster,
    based on the distance from the center of the cluster, called the **centroid**.
    The distance from the centroid for each data point is calculated using the **Euclidean
    distance formula**. Data points that are closest to a given centroid have similarities
    and belong to the same group. In real-world situations, it is very common to find
    data points with overlapping clusters and too many of them. When you encounter
    too many clusters, then it is a challenge to identify the right number of clusters
    for your dataset.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，每个数据点根据其到聚类中心的距离被放置在聚类中，这个距离称为**质心**。每个数据点到质心的距离使用**欧几里得距离公式**计算。距离给定质心最近的数据点具有相似性，属于同一组。在现实世界中，经常遇到具有重叠聚类和大量数据点的情况。当你遇到过多的聚类时，确定数据集的正确聚类数量就成了一项挑战。
- en: 'Common use cases for a K-means cluster include the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: K-means聚类的常见用例包括以下内容：
- en: '**E-commerce**: Grouping customers by purchase history'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子商务**：根据购买历史分组客户'
- en: '**Healthcare**: Detecting patterns of diseases'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医疗保健**：检测疾病模式'
- en: '**Finance**: Grouping purchases into abnormal versus normal'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**金融**：将购买行为分为异常和正常'
- en: Next, we will show you one of the common methods to help you determine how many
    clusters you should use.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将向您展示一种常见的方法，帮助您确定应该使用多少个聚类。
- en: Determining the optimal number of clusters
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定最佳聚类数量
- en: One popular method that is frequently adopted is the **Elbow method**. The idea
    of the Elbow method is to run K-means algorithms with different values of K –
    for example, from 1 cluster all the way to 10 – and for each value of K, calculate
    the sum of squared errors. Then, plot a chart of the **sum of squared deviation**
    (**SSD**) values. SSD is the sum of the squared difference and is used to measure
    variance. If the line chart looks like an arm, then the *elbow* on the arm is
    the value of K that is the best among the various K values. The method behind
    this approach is that SSD usually tends to decrease as the value of K is increased,
    and the goal of the evaluation method is also to aim for lower SSD or **mean squared
    deviation** (**MSD**) values. The elbow represents a starting point, where SSD
    starts to have diminishing returns when the K value increases.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常用的方法是**肘部方法**。肘部方法的想法是运行具有不同K值的K-means算法——例如，从1个聚类到10个聚类——并为每个K值计算平方误差之和。然后，绘制**平方偏差之和**（**SSD**）值的图表。SSD是平方差的和，用于衡量方差。如果折线图看起来像一条臂，那么臂上的**肘部**就是各种K值中最佳的K值。这种方法背后的原理是，SSD通常随着K值的增加而减少，而评估方法的目的是追求更低的SSD或**均方偏差**（**MSD**）值。肘部代表一个起点，当K值增加时，SSD开始减少回报。
- en: 'In the following chart, you can see that the MSD value, when charted over different
    K values, represents an arm, and the *elbow* is at value **6**. After **6**, there
    is no significant decrease in the MSD value, so we can pick *6* as the best cluster
    value in the following scenario:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图表中，你可以看到当MSD值在不同K值上绘制时，代表一条臂，而**肘部**在值**6**处。在**6**之后，MSD值没有显著下降，因此我们可以选择**6**作为以下场景中最佳的聚类值：
- en: "![Figure 8.2 – MSD values when charted over different \uFEFFK values](img/B19071_08_02.jpg)"
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2 – 在不同的 K 值上绘制 MSD 值](img/B19071_08_02.jpg)'
- en: Figure 8.2 – MSD values when charted over different K values
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – 在不同的 K 值上绘制 MSD 值
- en: Next, let’s see how we can create a K-means clustering model with Amazon Redshift
    ML.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何使用 Amazon Redshift ML 创建 K-means 聚类模型。
- en: Creating a K-means ML model
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 K-means 机器学习模型
- en: 'In this section, we will walk through the process with the help of a use case.
    In this use case, assume you are a data analyst for an e-commerce company specializing
    in home improvement goods. You have been tasked with classifying economic segments
    in different regions, based on income, so that you can better target customers,
    based on various factors, such as median home value. We will use this dataset
    from Kaggle: [https://www.kaggle.com/datasets/camnugent/california-housing-prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过一个用例来介绍这个过程。在这个用例中，假设您是一家专注于家居改善商品的电子商务公司的数据分析师。您被要求根据收入对不同地区的经济部门进行分类，以便您可以更好地根据各种因素，如中位房价，来定位客户。我们将使用
    Kaggle 上的此数据集：[https://www.kaggle.com/datasets/camnugent/california-housing-prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices)。
- en: From this dataset, you will use the `median_income`, `latitude`, and `longitude`
    attributes so that you can create clusters based on `location` and `income`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个数据集中，您将使用 `median_income`、`latitude` 和 `longitude` 属性，以便可以根据 `location` 和
    `income` 创建聚类。
- en: The syntax to create a K-means model is slightly different from what you will
    have used up to this point, so let’s dive into that.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 K-means 模型的语法与您迄今为止所使用的语法略有不同，所以让我们深入探讨一下。
- en: Creating a model syntax overview for K-means clustering
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 K-means 聚类模型的语法概述
- en: 'Here is the basic syntax to create a K-means model:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 K-means 模型的基本语法如下：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A couple of key things to note in the preceding code snippet are the lines
    in bold, as they are required when creating K-means models:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，有几个要点需要注意，它们以粗体显示，因为它们在创建 K-means 模型时是必需的：
- en: '`AUTO OFF`: This must be turned off, since Amazon SageMaker Autopilot is not
    used for K-means'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AUTO OFF`：由于不使用 Amazon SageMaker Autopilot，因此必须关闭此选项'
- en: '`MODEL_TYPE` `KMEANS`: You must set `MODEL_TYPE`, as there is no auto-discovery
    for K-means'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MODEL_TYPE` `KMEANS`：您必须设置 `MODEL_TYPE`，因为 K-means 没有自动发现功能。'
- en: '`HYPERPARAMETERS DEFAULT EXCEPT (K ''2'')`: This tells SageMaker how many clusters
    to create in this model'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HYPERPARAMETERS DEFAULT EXCEPT (K ''2'')`：这告诉 SageMaker 在此模型中创建多少个聚类'
- en: Also, note that there are three optional preprocessors available with K-means.
    We will explore that in more detail when we create the model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，K-means 有三个可选的预处理程序可用。我们将在创建模型时更详细地探讨这一点。
- en: 'You can refer to this link for more details on the K-means parameters available:
    [https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_k-means-create-model-parameters](https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_k-means-create-model-parameters).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考此链接以获取有关可用 K-means 参数的更多详细信息：[https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_k-means-create-model-parameters](https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_k-means-create-model-parameters)。
- en: Now, we will load our dataset in preparation for creating our model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将加载数据集，为创建模型做准备。
- en: Uploading and analyzing the data
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传和分析数据
- en: For this use case, we will use a file that contains housing price information
    and summary stats, based on census data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此用例，我们将使用一个包含房价信息和基于人口普查数据的摘要统计信息的文件。
- en: Note
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Data is stored in the following S3 location: `s3://packt-serverless-ml-redshift/chapter08/housinghousing_prices.csv`.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据存储在以下 S3 位置：`s3://packt-serverless-ml-redshift/chapter08/housinghousing_prices.csv`。
- en: After successfully connecting to Redshift as an admin or database developer,
    load data into Amazon Redshift and follow the steps outlined here.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功连接到 Redshift 作为管理员或数据库开发者后，将数据加载到 Amazon Redshift 并遵循此处概述的步骤。
- en: 'Navigate to Redshift **query editor** **v****2**, connect to the **Serverless:
    default** endpoint, and then connect to the **dev** database.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '导航到 Redshift **查询编辑器** **v2**，连接到 **Serverless: default** 端点，然后连接到 **dev**
    数据库。'
- en: "![Figure 8.3 – Connecting via \uFEFFRedshift query editor v2](img/B19071_08_03.jpg)"
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3 – 通过 Redshift 查询编辑器 v2 连接](img/B19071_08_03.jpg)'
- en: Figure 8.3 – Connecting via Redshift query editor v2
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 通过 Redshift 查询编辑器 v2 连接
- en: 'Execute the following steps to create the schema and customer table and load
    the data:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下步骤以创建架构和客户表并加载数据：
- en: '[PRE1]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This dataset contains 2,064,020,640 records. We will use `longitude`, `latitude`,
    and `median_income` in our model.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集包含 2,064,020,640 条记录。我们将在模型中使用 `longitude`、`latitude` 和 `median_income`。
- en: 'Run the following query to examine some sample data:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下查询以检查一些样本数据：
- en: '[PRE17]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You should get the following result:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下结果：
- en: '![Figure 8.4 – Housing prices data](img/B19071_08_04.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – 房价数据](img/B19071_08_04.jpg)'
- en: Figure 8.4 – Housing prices data
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 房价数据
- en: Now that the data is loaded, we are ready to create the model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已加载，我们准备创建模型。
- en: Creating the K-means model
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 K-means 模型
- en: Let’s create our model and cluster based on `median_income`, `longitude`, and
    `latitude`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们根据 `median_income`、`longitude` 和 `latitude` 创建我们的模型和聚类。
- en: We will create a few models and then use the elbow method to determine the optimal
    number of clusters.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一些模型，然后使用肘部方法来确定最佳聚类数量。
- en: To begin with, let’s create our first model with two clusters using the following
    SQL. You can then experiment by creating different models by changing the K value,
    and then you can learn how the MSD value diminishes over different K values.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们使用以下 SQL 创建我们的第一个模型，包含两个聚类。然后，你可以通过改变 K 值来创建不同的模型进行实验，并了解 MSD 值在不同 K 值下的减少情况。
- en: Creating two clusters with a K value of 2
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 K 值为 2 创建两个聚类
- en: 'Let’s run the following SQL in Query Editor v2 to create a model with two clusters:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在查询编辑器 v2 中运行以下 SQL 以创建具有两个聚类的模型：
- en: '[PRE19]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: You can see in this model that we supply values for the `preprocessors` parameter.
    We chose to do this because K-means is sensitive to scale, so we can normalize
    with the `standardscaler` transformer. `standardscalar` moves the mean and scale
    to unit variance.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这个模型中看到我们为 `preprocessors` 参数提供了值。我们选择这样做是因为 K-means 对尺度敏感，因此我们可以使用 `standardscaler`
    转换器进行归一化。`standardscalar` 将均值和尺度移动到单位方差。
- en: 'The `hyperparameters` parameter is where we specify `(K ''2'')` to create two
    clusters. Remember to add your S3 bucket, where the created model artifacts are
    stored. You will find the model artifacts in `s3: s3://<your-s3-bucket>/redshift-ml/housing_segments_k2/`.
    Redshift ML will automatically append `''redshift-ml''/''your model name''` to
    your S3 bucket. Now, check the status of the model, using the `SHOW MODEL` command
    in Query Editor v2:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`hyperparameters` 参数是我们指定 `(K ''2'')` 来创建两个聚类的位置。请记住添加你的 S3 存储桶，其中存储了创建的模型工件。你将在
    `s3: s3://<your-s3-bucket>/redshift-ml/housing_segments_k2/` 中找到模型工件。Redshift
    ML 将自动将 `''redshift-ml''/''your model name''` 添加到你的 S3 存储桶。现在，使用查询编辑器 v2 中的 `SHOW
    MODEL` 命令检查模型的状态：'
- en: '[PRE20]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You will see the following output:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: "![Fi\uFEFFgure 8.5 – Two clusters](img/B19071_08_05.jpg)"
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5 – 两个聚类](img/B19071_08_05.jpg)'
- en: Figure 8.5 – Two clusters
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 两个聚类
- en: The key things to note are **Model State**, which indicates that the model is
    ready, and **train:msd**, which is the objective metric. This represents the mean
    squared distances between each record in our input dataset and the closest center
    of the model. The **MSD** value is **1.088200**, which is a good score.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的关键点是 **模型状态**，它表示模型已准备好，以及 **train:msd**，这是目标指标。这代表我们输入数据集中每个记录与模型最近中心的平均平方距离。**MSD**
    值为 **1.088200**，这是一个不错的分数。
- en: 'Let’s run a query to get the number of data points in each cluster:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行一个查询以获取每个聚类中的数据点数量：
- en: '[PRE21]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 8.6 – The data points](img/B19071_08_06.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6 – 数据点](img/B19071_08_06.jpg)'
- en: Figure 8.6 – The data points
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 数据点
- en: Clusters are numbered from `0` to `n`. Our first cluster has **8719** data points,
    and the second cluster has **11921** data points.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类从 `0` 到 `n` 编号。我们的第一个聚类有 **8719** 个数据点，第二个聚类有 **11921** 个数据点。
- en: In our use case, we want to further segment our customers. Let’s create a few
    more models with different numbers of clusters. We can then evaluate all the SSD
    values and apply the Elbow method to help us choose the optimal number of clusters
    to use for our analysis.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的用例中，我们希望进一步细分我们的客户。让我们创建一些具有不同聚类数量的更多模型。然后，我们可以评估所有 SSD 值，并应用肘部方法来帮助我们选择用于分析的最佳聚类数量。
- en: Creating three clusters with a K value of 3
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 K 值为 3 创建三个聚类
- en: 'Let’s run the following SQL in Query Editor v2 to create a model with three
    clusters:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在查询编辑器 v2 中运行以下 SQL 以创建具有三个聚类的模型：
- en: '[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Creating the remaining models with clusters 4, 5, and 6
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建剩余的模型，包含 4、5 和 6 个聚类
- en: Repeat the preceding code 3 more times to create models with 4, 5, and 6 clusters,
    respectively. You will find the code at [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter8/chapter8.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter8/chapter8.sql).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 将前面的代码重复 3 次以创建具有 4、5 和 6 个簇的模型。你可以在 [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter8/chapter8.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter8/chapter8.sql)
    找到代码。
- en: 'It will take ~15 minutes for all the models to finish training. Then, run the
    `SHOW MODEL` command, including the one for the model where `K = 2`, as shown
    here:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 所有模型完成训练将需要大约 15 分钟。然后，运行 `SHOW MODEL` 命令，包括 `K = 2` 的模型，如图所示：
- en: '[PRE23]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now, let’s find the elbow!
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们找到“肘部”吧！
- en: Gathering inputs to chart the elbow
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 收集输入以绘制“肘部”
- en: Now, from the output of each `SHOW MODEL` command, note the value for `test:msd`
    and build a `Select` statement, as shown in the following code snippet. Change
    the value for MSD using the `test:mds` value for each model.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，从每个 `SHOW MODEL` 命令的输出中，注意 `test:msd` 的值，并构建一个 `Select` 语句，如下面的代码片段所示。使用每个模型的
    `test:mds` 值更改 MSD 的值。
- en: As an example, we will use the value `1.088200,` which we saw earlier for `train:msd`,
    for the model with two clusters.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们将使用之前看到的 `train:msd` 的值 `1.088200`，用于两个簇的模型。
- en: 'Our other output from `train:mds` from the `SHOW MODEL` output is as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 `SHOW MODEL` 输出的 `train:mds` 的其他输出如下：
- en: 'Two clusters: `train:msd` – `1.088200`'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个簇：`train:msd` – `1.088200`
- en: 'Three clusters: `train:msd` – `0.775993`'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个簇：`train:msd` – `0.775993`
- en: 'Four clusters: `train:msd` – `0.532355`'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四个簇：`train:msd` – `0.532355`
- en: 'Five clusters: `train:msd` – `0.437294`'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 五个簇：`train:msd` – `0.437294`
- en: 'Six clusters: `train:msd` – `0.373781`'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 六个簇：`train:msd` – `0.373781`
- en: 'Note that your numbers may be slightly different:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你的数字可能略有不同：
- en: '[PRE24]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Run the preceding SQL command in Query Editor v2.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询编辑器 v2 中运行前面的 SQL 命令。
- en: 'By observing the output, we can see that the MSD value is highest for two clusters
    and gradually decreases as the number of clusters increases:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察输出，我们可以看到 MSD 值在两个簇中最高，随着簇数量的增加而逐渐降低：
- en: '![Figure 8.7 – msd](img/B19071_08_07.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7 – msd](img/B19071_08_07.jpg)'
- en: Figure 8.7 – msd
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – msd
- en: 'In the **Result** window, click on the **Chart** option, as shown here:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **结果** 窗口中，点击 **图表** 选项，如图所示：
- en: '![Figure 8.8 – Creating a chart](img/B19071_08_08.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.8 – 创建图表](img/B19071_08_08.jpg)'
- en: Figure 8.8 – Creating a chart
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – 创建图表
- en: 'By choosing `k` as the `X` value and `msd` as the `Y` value, you will get the
    following output:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 通过选择 `k` 作为 `X` 值，`msd` 作为 `Y` 值，你将得到以下输出：
- en: '![Figure 8.9 – The elbow method chart](img/B19071_08_09.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.9 – 肘部方法图表](img/B19071_08_09.jpg)'
- en: Figure 8.9 – The elbow method chart
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 – 肘部方法图表
- en: From the chart, we can see that when MSD is charted over a line graph, an arm
    is formed, and the elbow is at **3**. This means that there is little difference
    in the MSD value with **4** clusters compared to **3** clusters . We can see that
    after **3**, the curve is very smooth, and the difference between the MSD value
    does not drastically change compared to the beginning of the line.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中，我们可以看到当 MSD 在折线图上绘制时，形成了一个臂，肘部在 **3**。这意味着与 **3** 个簇相比，**4** 个簇的 MSD 值差异很小。我们可以看到在
    **3** 之后，曲线非常平滑，与线开始时的 MSD 值差异没有剧烈变化。
- en: 'Let’s see how data points are clustered when we use a function deployed for
    our model with three clusters:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当我们使用为我们的模型部署的函数进行聚类时，数据点是如何聚类的：
- en: '[PRE25]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can see the following output from Query Editor v2\. The counts represent
    the number of data points assigned to each cluster:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从查询编辑器 v2 中看到以下输出。计数表示分配给每个簇的数据点数量：
- en: '![Figure 8.10 – Three clusters](img/B19071_08_10.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.10 – 三个簇](img/B19071_08_10.jpg)'
- en: Figure 8.10 – Three clusters
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 – 三个簇
- en: 'We can also chart this by clicking on the **Chart** button and observing the
    cluster counts represented visually:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以通过点击 **图表** 按钮并观察可视化的簇计数来绘制这个图表：
- en: '![Figure 8.11 – The cluster data points](img/B19071_08_11.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.11 – 簇数据点](img/B19071_08_11.jpg)'
- en: Figure 8.11 – The cluster data points
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11 – 簇数据点
- en: Now, let’s see how we can use our model to help make business decisions based
    on the clusters.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们如何使用我们的模型来帮助基于簇做出业务决策。
- en: Evaluating the results of the K-means clustering
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估 K-means 聚类结果
- en: Now that you have segmented your clusters with the K-means algorithm, you are
    ready to perform various analyses using the model you created.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经使用K-means算法对聚类进行了分割，您就可以使用您创建的模型进行各种分析了。
- en: 'Here is an example query you can run to get the average median house value
    by cluster:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个您可以运行的示例查询，用于按聚类获取平均中位数房屋价值：
- en: '[PRE26]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output will look like this:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将类似于以下内容：
- en: '![Figure 8.12 – Average median house values](img/B19071_08_12.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图8.12 – 平均中位数房屋价值](img/B19071_08_12.jpg)'
- en: Figure 8.12 – Average median house values
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12 – 平均中位数房屋价值
- en: 'You can also run a query to see whether higher median incomes correspond to
    the same clusters with higher home values. Run the following query:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以运行一个查询来查看较高的中位数收入是否与具有较高房屋价值的相同聚类相对应。运行以下查询：
- en: '[PRE27]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output will look like this:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将类似于以下内容：
- en: '![Figure 8.13 – median_income](img/B19071_08_13.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图8.13 – 中位数收入](img/B19071_08_13.jpg)'
- en: Figure 8.13 – median_income
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13 – 中位数收入
- en: When we established our use case, we said this was for an e-commerce retailer
    specializing in home improvement products. Another way you could use this information
    is to create different marketing campaigns and tailor your product offerings,
    based on home values in a given cluster.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们建立用例时，我们说这是针对一个专注于家居改善产品的电子商务零售商。您还可以使用这些信息创建不同的营销活动，并根据给定聚类的房屋价值定制您的产品。
- en: Summary
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed how to do unsupervised learning with the K-means
    algorithm.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何使用K-means算法进行无监督学习。
- en: You are now able to explain what the K-means algorithm is and what use cases
    it is appropriate for. Also, you can use Amazon Redshift ML to create a K-means
    model, determine the appropriate number of clusters, and draw conclusions by analyzing
    the clusters to help make business decisions.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您能够解释K-means算法是什么以及它适用于哪些用例。您还可以使用Amazon Redshift ML创建K-means模型，确定合适的聚类数量，并通过分析聚类得出结论，以帮助做出商业决策。
- en: In the next chapter, we will show you how to use the multi-layer perceptron
    algorithm to perform deep learning with Amazon Redshift ML.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将向您展示如何使用多层感知器算法使用Amazon Redshift ML进行深度学习。
- en: Part 3:Deploying Models with Redshift ML
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分：使用Redshift ML部署模型
- en: '*Part 3* introduces you to more ways to leverage Amazon Redshift ML. You will
    learn about deep learning algorithms, how to train a customized model, and how
    you can use models trained outside of Amazon Redshift to run inference queries
    in your data warehouse.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*第3部分* 介绍了更多利用Amazon Redshift ML的方式。您将了解深度学习算法，如何训练自定义模型，以及如何使用在Amazon Redshift之外训练的模型在您的数据仓库中运行推理查询。'
- en: This part closes with an introduction to time-series forecasting, how to use
    it with Amazon Redshift ML, and how you can optimize and easily re-train your
    models.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分以时间序列预测的介绍结束，包括如何使用Amazon Redshift ML，以及如何优化和轻松重新训练您的模型。
- en: 'This part comprises the following chapters:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 9*](B19071_09.xhtml#_idTextAnchor157), *Deep Learning with Redshift
    ML*'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B19071_09.xhtml#_idTextAnchor157)，*使用Redshift ML进行深度学习*'
- en: '[*Chapter 10*](B19071_10.xhtml#_idTextAnchor178), *Creating Custom ML Models
    with XGBoost*'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B19071_10.xhtml#_idTextAnchor178)，*使用XGBoost创建自定义机器学习模型*'
- en: '[*Chapter 11*](B19071_11.xhtml#_idTextAnchor192), *Bring Your Own Models for
    In-Database Inference*'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B19071_11.xhtml#_idTextAnchor192)，*在数据库推理中使用您自己的模型*'
- en: '[*Chapter 12*](B19071_12.xhtml#_idTextAnchor217), *Time-Series Forecasting
    in Your Data Warehouse*'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B19071_12.xhtml#_idTextAnchor217)，*在您的数据仓库中进行时间序列预测*'
- en: '[*Chapter 13*](B19071_13.xhtml#_idTextAnchor233), *Operationalizing and Optimizing
    Amazon Redshift ML Models*'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B19071_13.xhtml#_idTextAnchor233)，*实施和优化Amazon Redshift ML模型*'
