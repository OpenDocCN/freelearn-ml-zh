- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: SageMaker Training and Debugging Solutions
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SageMaker训练和调试解决方案
- en: In [*Chapter 2*](B18638_02.xhtml#_idTextAnchor041), *Deep Learning AMIs*, and
    [*Chapter 3*](B18638_03.xhtml#_idTextAnchor060), *Deep Learning Containers*, we
    performed our initial ML training experiments inside EC2 instances. We took note
    of the cost per hour of running these EC2 instances as there are some cases where
    we would need to use the more expensive instance types (such as the `p2.8xlarge`
    instance at approximately *$7.20 per hour*) to run our ML training jobs and workloads.
    To manage and reduce the overall cost of running ML workloads using these EC2
    instances, we discussed a few cost optimization strategies, including manually
    turning off these instances after the training job has finished.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第2章*](B18638_02.xhtml#_idTextAnchor041) *深度学习AMIs*和[*第3章*](B18638_03.xhtml#_idTextAnchor060)
    *深度学习容器*中，我们在EC2实例内进行了最初的ML训练实验。我们注意到了运行这些EC2实例每小时的成本，因为在某些情况下，我们需要使用更昂贵的实例类型（例如每小时大约*7.20美元*的`p2.8xlarge`实例）来运行我们的ML训练作业和工作负载。为了管理和降低使用这些EC2实例运行ML工作负载的整体成本，我们讨论了几种成本优化策略，包括在训练作业完成后手动关闭这些实例。
- en: 'At this point, you might be wondering if it is possible to automate the following
    processes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，您可能想知道是否可以自动化以下流程：
- en: '*Launching the EC2 instances that will run the ML training jobs*'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*启动将运行ML训练作业的EC2实例*'
- en: '*Uploading the model artifacts of the trained ML model to a storage location
    (such as an S3 bucket) after model training*'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在模型训练后将训练好的ML模型的模型工件上传到存储位置（例如S3存储桶）*'
- en: '*Deleting the EC2 instances once the training job has been completed*'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*一旦训练作业完成，删除EC2实例*'
- en: The good news is that this is possible using automated scripts! Once a major
    portion of this process has been automated, we can focus more on preparing the
    scripts used to train our ML model. We can write our own set of automation scripts;
    however, I would recommend that you do *NOT* reinvent the wheel since AWS has
    already automated this process for us in **Amazon SageMaker**!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，这可以通过自动化脚本来实现！一旦这个流程的大部分已经自动化，我们就可以更多地关注准备用于训练我们的ML模型的脚本。我们可以编写自己的自动化脚本集；然而，我建议您不要重新发明轮子，因为AWS已经在我们使用的**Amazon
    SageMaker**中为我们自动化了这个流程！
- en: SageMaker has a lot of capabilities and features that help data scientists and
    ML practitioners perform ML experiments and deployments in the AWS cloud with
    ease. In the previous chapters, we were able to take a quick look at some of these
    capabilities, including **SageMaker Canvas**, **SageMaker Autopilot**, and **SageMaker
    Data Wrangler**. In this chapter, we will dive deeper into its capabilities and
    features that focus on training ML models inside the managed infrastructure resources
    in AWS. You would be surprised that it only takes a few additional configuration
    parameters to enable certain training techniques and solutions such as **Network
    Isolation**, **Distributed Training**, **Managed Spot Training**, **Checkpointing**,
    and **Incremental Training**. If this is your first time encountering these concepts
    and techniques, do not worry as we will discuss these in more detail in this chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker拥有许多功能和特性，可以帮助数据科学家和ML从业者轻松地在AWS云中执行ML实验和部署。在前几章中，我们快速浏览了一些这些功能，包括**SageMaker
    Canvas**、**SageMaker Autopilot**和**SageMaker Data Wrangler**。在本章中，我们将更深入地探讨其功能和特性，这些功能和特性专注于在AWS托管基础设施资源内训练ML模型。您可能会惊讶地发现，只需添加几个额外的配置参数，就可以启用某些训练技术和解决方案，例如**网络隔离**、**分布式训练**、**托管Spot训练**、**检查点**和**增量训练**。如果您第一次遇到这些概念和技术，请不要担心，我们将在本章中更详细地讨论这些内容。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Getting started with the SageMaker Python SDK
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用SageMaker Python SDK
- en: Preparing the essential prerequisites
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备基本先决条件
- en: Training an image classification model with the SageMaker Python SDK
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SageMaker Python SDK训练图像分类模型
- en: Using the Debugger Insights Dashboard
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用调试器洞察仪表板
- en: Utilizing Managed Spot Training and checkpoints
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用托管Spot训练和检查点
- en: Cleaning up
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理工作
- en: Before we proceed with the hands-on solutions in this chapter, we’ll start by
    having a quick discussion on how we will use the **SageMaker Python SDK** to help
    us utilize and work with the different capabilities and features of the SageMaker
    service.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始本章的动手解决方案之前，我们将先简要讨论如何使用**SageMaker Python SDK**来帮助我们利用和操作SageMaker服务的不同功能和特性。
- en: Technical requirements
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Before we start, we must have the following ready:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们必须准备好以下内容：
- en: A web browser (preferably Chrome or Firefox)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个网络浏览器（最好是 Chrome 或 Firefox）
- en: Access to the AWS account that was used in the first few chapters of this book
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问本书前几章中使用的 AWS 账户
- en: 'The Jupyter notebooks, source code, and other files used for each chapter are
    available in this book’s GitHub repository: https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每一章使用的 Jupyter 笔记本、源代码和其他文件都可在本书的 GitHub 仓库中找到：https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS。
- en: Important Note
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: It is recommended to use an IAM user with limited permissions instead of the
    root account when running the examples in this book. We will discuss this, along
    with other security best practices, in detail in [*Chapter 9*](B18638_09.xhtml#_idTextAnchor187),
    *Security, Governance, and Compliance Strategies*. If you are just starting to
    use AWS, you may proceed with using the root account in the meantime.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中运行示例时，建议使用具有有限权限的 IAM 用户而不是根账户。我们将在[*第 9 章*](B18638_09.xhtml#_idTextAnchor187)“安全、治理和合规策略”中详细讨论这一点，以及其他安全最佳实践。如果您刚开始使用
    AWS，您可以在同时继续使用根账户。
- en: Getting started with the SageMaker Python SDK
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker Python SDK 入门
- en: The **SageMaker Python SDK** is a library that allows ML practitioners to train
    and deploy ML models using the different features and capabilities of SageMaker.
    It provides several high-level abstractions such as **Estimators**, **Models**,
    **Predictors**, **Sessions**, **Transformers**, and **Processors**, all of which
    encapsulate and map to specific ML processes and entities. These abstractions
    allow data scientists and ML engineers to manage ML experiments and deployments
    with just a few lines of code. At the same time, infrastructure management is
    handled by SageMaker already, so all we need to do is configure these high-level
    abstractions with the correct set of parameters.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**SageMaker Python SDK** 是一个库，允许机器学习从业者使用 SageMaker 的不同特性和功能来训练和部署机器学习模型。它提供了几个高级抽象，如
    **Estimators**、**Models**、**Predictors**、**Sessions**、**Transformers** 和 **Processors**，所有这些封装并映射到特定的机器学习过程和实体。这些抽象允许数据科学家和机器学习工程师仅用几行代码来管理机器学习实验和部署。同时，基础设施管理已由
    SageMaker 处理，所以我们只需要配置这些高级抽象的正确参数集。'
- en: Note that it is also possible to use the different capabilities and features
    of SageMaker using the **boto3** library. Compared to using the SageMaker Python
    SDK, we would be working with significantly more lines of code with boto3 since
    we would have to take care of the little details when using the low-level clients
    and functions available in this library. It is recommended to use the SageMaker
    Python SDK whenever possible and just use the boto3 library for the more advanced
    scenarios not directly supported by the SageMaker Python SDK.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，也可以使用 **boto3** 库的不同功能和特性来使用 SageMaker。与使用 SageMaker Python SDK 相比，我们使用 boto3
    将会处理显著更多的代码行，因为我们必须注意使用库中提供的低级客户端和函数时的细节。建议尽可能使用 SageMaker Python SDK，并且仅在 SageMaker
    Python SDK 不直接支持的高级场景中使用 boto3 库。
- en: Note
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you are interested in learning more about how to use both libraries together
    when handling more advanced use cases, check out [*Chapter 8*](B18638_08.xhtml#_idTextAnchor172),
    *Model Monitoring and Management Solutions*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多关于如何处理更高级用例时同时使用这两个库的信息，请参阅[*第 8 章*](B18638_08.xhtml#_idTextAnchor172)“模型监控和管理解决方案”。
- en: 'The following diagram shows that training and deploying an ML model using the
    SageMaker Python SDK involves only a few lines of code:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示，使用 SageMaker Python SDK 训练和部署机器学习模型仅涉及几行代码：
- en: '![Figure 6.1 – SageMaker Python SDK ](img/B18638_06_001.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.1 – SageMaker Python SDK](img/B18638_06_001.jpg)'
- en: Figure 6.1 – SageMaker Python SDK
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1 – SageMaker Python SDK
- en: 'Here, we use the **SageMaker Python SDK** to do the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用 **SageMaker Python SDK** 来完成以下操作：
- en: We start by initializing an `Estimator` object and then using its `set_hyperparameters()`
    method to specify the desired combination of hyperparameter values. Here, we can
    specify whether to use a built-in algorithm or a custom one (using scripts and
    custom Docker container images) by providing the corresponding configuration parameter
    values while initializing the `Estimator` object.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先初始化一个 `Estimator` 对象，然后使用其 `set_hyperparameters()` 方法来指定所需的超参数值组合。在这里，我们可以通过提供初始化
    `Estimator` 对象时的相应配置参数值来指定是否使用内置算法或自定义算法（使用脚本和自定义 Docker 容器镜像）。
- en: Next, we call the `fit()` method, which runs a training job with the desired
    set of properties, as defined in the `Estimator` object configuration. This training
    job would run inside dedicated instances and once the training job completes,
    these instances would be terminated automatically.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们调用`fit()`方法，该方法使用在`Estimator`对象配置中定义的所需属性集运行训练作业。这个训练作业将在专用实例中运行，一旦训练作业完成，这些实例将自动终止。
- en: Finally, we use the `deploy()` method to deploy the trained model to a dedicated
    real-time inference endpoint prepared for us automatically by SageMaker. Then,
    we use the `predict()` method to perform sample predictions on the inference endpoint.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用`deploy()`方法将训练好的模型部署到SageMaker为我们自动准备的一个专用实时推理端点。然后，我们使用`predict()`方法在推理端点上执行样本预测。
- en: 'This is just one of the ways to use the **SageMaker Python SDK** when training
    and deploying our ML models in the AWS cloud. If we already have a pre-trained
    model available for use (for example, after downloading a prebuilt ML model from
    a repository of models), we may skip the training step altogether and deploy the
    model right away using the following block of code:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是使用**SageMaker Python SDK**在AWS云中训练和部署我们的ML模型的一种方法。如果我们已经有一个可用的预训练模型（例如，从模型存储库下载预构建的ML模型后），我们可以完全跳过训练步骤，并使用以下代码块立即部署模型：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Of course, the preceding block of code assumes that the model artifacts have
    been uploaded into an S3 bucket already and that the `model_data` variable points
    to where these model artifacts or files are stored.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，前面的代码块假设模型工件已经上传到S3桶中，并且`model_data`变量指向这些模型工件或文件存储的位置。
- en: Note
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you are interested in learning more about how to perform deployments directly
    in SageMaker using pre-trained models, check out [*Chapter 7*](B18638_07.xhtml#_idTextAnchor151),
    *SageMaker Deployment Solutions*.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要了解更多关于如何在SageMaker中直接使用预训练模型进行部署的信息，请查看《Amazon SageMaker CookBook》一书的[*第7章*](B18638_07.xhtml#_idTextAnchor151)，*SageMaker部署解决方案*。
- en: 'If we want to utilize the **Automatic Model Tuning** capability of SageMaker
    and run multiple training jobs using different combinations of hyperparameters
    automatically when looking for the “best model,” then we just need to run a couple
    of lines of code, similar to what we have in the following code block:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要利用SageMaker的**自动模型调优**功能，并在寻找“最佳模型”时自动使用不同超参数组合运行多个训练作业，那么我们只需要运行几行代码，类似于以下代码块中的内容：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, SageMaker does all the heavy lifting for us and all we need to worry about
    are the configuration parameters needed to run the hyperparameter tuning job.
    It would have taken us a few weeks (or maybe even a few months!) if we were to
    build this ourselves using custom automation scripts.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，SageMaker为我们做了所有繁重的工作，我们只需要关注运行超参数调优作业所需的配置参数。如果我们自己使用自定义自动化脚本来构建，这可能会花费我们几周（甚至可能是几个月！）的时间。
- en: Note
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you are interested in learning more about how to utilize the Automatic Model
    Tuning capability of SageMaker using the **SageMaker Python SDK**, then check
    out [*Chapter 6*](B18638_06.xhtml#_idTextAnchor132), *SageMaker Training and Debugging
    Solutions,* of the book *Machine Learning with Amazon SageMaker Cookbook*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要了解更多关于如何使用**SageMaker Python SDK**利用SageMaker的自动模型调优功能，请查看《Amazon SageMaker
    CookBook》一书的[*第6章*](B18638_06.xhtml#_idTextAnchor132)，*SageMaker训练和调试解决方案*。
- en: There are several options and features available when training models using
    Amazon SageMaker. These include network isolation, distributed training, managed
    spot training, checkpointing, incremental training, and more. Similar to the automatic
    model tuning capability discussed earlier, utilizing and enabling these would
    simply involve just a few additional lines of code. If you are wondering what
    these are, do not worry –we will discuss each of these in detail as we work on
    the hands-on solutions in this chapter.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Amazon SageMaker训练模型时，有几种选项和功能可用。这包括网络隔离、分布式训练、托管Spot训练、检查点、增量训练等等。与之前讨论的自动模型调优功能类似，利用和启用这些功能只需几行额外的代码。如果你想知道这些是什么，请不要担心——随着我们在本章中动手解决实际问题，我们将详细讨论每个这些功能。
- en: Now that we have a better understanding of how the **SageMaker Python SDK**
    helps us train and deploy ML models in the cloud, let’s proceed with creating
    a service limit request!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经更好地理解了**SageMaker Python SDK**如何帮助我们训练和部署云中的ML模型，让我们继续创建服务限制请求！
- en: Preparing the essential prerequisites
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备基本先决条件
- en: 'In this section, we will ensure that the following prerequisites are ready
    before proceeding with the hands-on solutions of this chapter:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将在进行本章的动手实践解决方案之前，确保以下先决条件已准备就绪：
- en: We have a service limit increase to run SageMaker training jobs using the `ml.p2.xlarge`
    instance (SageMaker Training)
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有一个服务限制增加请求，用于运行使用 `ml.p2.xlarge` 实例（SageMaker 训练）的 SageMaker 训练作业
- en: We have a service limit increase to run SageMaker training jobs using the `ml.p2.xlarge`
    instance (SageMaker Managed Spot Training)
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有一个服务限制增加请求，用于运行使用 `ml.p2.xlarge` 实例（SageMaker 管理预留实例训练）的 SageMaker 训练作业
- en: 'If you are wondering why we are using `ml.p2.xlarge` instances in this chapter,
    that’s because we are required to use one of the supported instance types for
    the **Image Classification Algorithm**, as shown in the following screenshot:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想知道为什么本章使用 `ml.p2.xlarge` 实例，那是因为我们被要求使用 **图像分类算法** 支持的实例类型之一，如下面的截图所示：
- en: '![Figure 6.2 – EC2 Instance Recommendation for the image classification algorithm
    ](img/B18638_06_002.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.2 – 图像分类算法的 EC2 实例推荐](img/B18638_06_002.jpg)'
- en: Figure 6.2 – EC2 Instance Recommendation for the image classification algorithm
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.2 – 图像分类算法的 EC2 实例推荐
- en: As we can see, we can use `ml.p2.xlarge`, `ml.p2.8xlarge`, `ml.p2.16xlarge`,
    `ml.p3.2xlarge`, `ml.p3.8xlarge`, and `ml.p3.16xlarge` (at the time of writing)
    when running training jobs using the Image Classification Algorithm.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，当运行图像分类算法的训练作业时，我们可以使用 `ml.p2.xlarge`、`ml.p2.8xlarge`、`ml.p2.16xlarge`、`ml.p3.2xlarge`、`ml.p3.8xlarge`
    和 `ml.p3.16xlarge`（截至编写时）。
- en: Note
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Check out [https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.xhtml)
    for more information about this topic.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 查阅 [https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.xhtml)
    了解更多关于此主题的信息。
- en: Creating a service limit increase request
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建服务限制增加请求
- en: In this chapter, we will train an Image Classification model using multiple
    `ml.p2.xlarge` instances. Before we can use this type of instance to train ML
    models, we will need to request for the service quota (or service limit) to be
    increased through the `0`; we would encounter a `ResourceLimitExceeded` error
    if we were to run training jobs using `ml.p2.xlarge` instances.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用多个 `ml.p2.xlarge` 实例来训练图像分类模型。在我们能够使用此类实例来训练机器学习模型之前，我们需要通过 `0` 请求增加服务配额（或服务限制）；如果我们使用
    `ml.p2.xlarge` 实例运行训练作业，将会遇到 `ResourceLimitExceeded` 错误。
- en: Important Note
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This chapter assumes that we are using the `us-west-2`) region when using services
    to manage and create different types of resources. You may use a different region
    but make sure to make any adjustments needed in case certain resources need to
    be transferred to the region of choice.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 本章假设我们在使用服务来管理和创建不同类型的资源时，正在使用 `us-west-2` 区域。您可以使用不同的区域，但请确保在需要将某些资源转移到所选区域的情况下，进行任何必要的调整。
- en: 'Follow these steps to create a support case and request for the SageMaker training
    instance count limits to be increased:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤创建支持案例并请求增加 SageMaker 训练实例数量限制：
- en: Navigate to the `support` in the search bar of the AWS Management Console.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 管理控制台的搜索栏中导航到 `support`
- en: Selecting **Support** from the list of results under **Services**.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 **服务** 下的结果列表中选择 **支持**。
- en: Locate and click the **Create case** button.*   On the **Create case** page,
    select **Service limit increase** from the list of options.*   Specify the following
    configuration under `SageMaker Training Jobs`*   Under `US West (Oregon)`*   `SageMaker
    Training`*   `ml.p2.xlarge`*   `2`
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定位并点击 **创建案例** 按钮。*   在 **创建案例** 页面上，从选项列表中选择 **服务限制增加**。*   在 `SageMaker 训练作业`
    下指定以下配置*   在 `US West (Oregon)` 下*   `SageMaker 训练`*   `ml.p2.xlarge`*   `2`
- en: Note
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Note that increasing the service limit for the SageMaker training resource type
    does not automatically increase the service limit for the SageMaker Managed Spot
    Training resource type.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，增加 SageMaker 训练资源类型的服务限制并不会自动增加 SageMaker 管理预留实例训练资源类型的服务限制。
- en: Click **Add another request**.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **添加另一个请求**。
- en: Under `US West (Oregon)`
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `US West (Oregon)`
- en: '`SageMaker Managed Spot Training`'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SageMaker 管理预留实例训练`'
- en: '`ml.p2.xlarge`'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ml.p2.xlarge`'
- en: '`2`'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`2`'
- en: 'Under **Case description**, specify the following use case description in the
    text area provided:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **案例描述** 下，在提供的文本区域中指定以下用例描述：
- en: '[PRE2]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Make sure that you replace `Oregon (us-west-2)` with the appropriate region
    if you are planning to run your ML experiments in another region.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 确保如果您计划在另一个区域运行您的机器学习实验，将 `Oregon (us-west-2)` 替换为适当的区域。
- en: Scroll down to **Contact options** and select **Web** (or **Chat** if available)
    from the list of options under **Contact methods**.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到 **联系方式** 并从 **联系方式** 下的选项列表中选择 **网页**（或如果可用，选择 **聊天**）。
- en: Finally, click the **Submit** button.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，点击 **提交** 按钮。
- en: Note that it may take around 24 to 48 hours for the limit increase request to
    get approved by the **AWS Support team**. While waiting, you may browse through
    the contents and concepts explained in this chapter. This will help you have a
    better idea of the capabilities of SageMaker before you work on the hands-on solutions.
    You may also skip this chapter and proceed with [*Chapter 7*](B18638_07.xhtml#_idTextAnchor151),
    *SageMaker Deployment Solutions*, while waiting for the limit increase to be approved.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，增加限制的请求可能需要大约 24 到 48 小时才能获得 **AWS 支持团队** 的批准。在等待期间，您可以浏览本章中解释的内容和概念。这将帮助您在动手解决实际问题之前更好地了解
    SageMaker 的功能。您还可以在等待限制增加获得批准的同时跳过本章，并继续阅读 [*第 7 章*](B18638_07.xhtml#_idTextAnchor151)，*SageMaker
    部署解决方案*。
- en: Training an image classification model with the SageMaker Python SDK
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker Python SDK 训练图像分类模型
- en: As mentioned in the *Getting started with the SageMaker Python SDK* section,
    we can use built-in algorithms or custom algorithms (using scripts and custom
    Docker container images) when performing training experiments in SageMaker.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如在 *使用 SageMaker Python SDK 入门* 部分中提到的，我们可以在 SageMaker 中执行训练实验时使用内置算法或自定义算法（使用脚本和自定义
    Docker 容器镜像）。
- en: 'Data scientists and ML practitioners can get started with training and deploying
    models in SageMaker quickly using one or more of the built-in algorithms prepared
    by the AWS team. There are a variety of built-in algorithms to choose from and
    each of these algorithms has been provided to help ML practitioners solve specific
    business and ML problems. Here are some of the built-in algorithms available,
    along with some of the use cases and problems these can solve:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家和机器学习从业者可以使用 AWS 团队准备的内置算法之一或多个快速开始使用 SageMaker 训练和部署模型。有各种各样的内置算法可供选择，并且每个算法都旨在帮助机器学习从业者解决特定的商业和机器学习问题。以下是一些可用的内置算法，以及它们可以解决的问题和用例：
- en: '**DeepAR Forecasting**: Time-series forecasting'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DeepAR 预测**：时间序列预测'
- en: '**Principal Component Analysis**: Dimensionality reduction'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分分析**：降维'
- en: '**IP Insights**: IP anomaly detection'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IP洞察**：IP 异常检测'
- en: '**Latent Dirichlet Allocation (LDA)**: Topic modeling'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在狄利克雷分配 (LDA**)：主题建模'
- en: '**Sequence-to-Sequence**: Text summarization'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**序列到序列**：文本摘要'
- en: '**Semantic Segmentation**: Computer vision'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义分割**：计算机视觉'
- en: The second option involves using SageMaker **script mode**, where we import
    a custom training script, which makes use of a deep learning framework (such as
    **TensorFlow**, **PyTorch**, or **MXNet**) to train a model. Here, the custom
    training script will run inside one of the pre-built containers, which includes
    **AWS Deep Learning Containers**, as discussed in [*Chapter 3*](B18638_03.xhtml#_idTextAnchor060),
    *Deep Learning Containers*. That said, all we need to worry about when choosing
    this option is preparing the training script since most of the dependencies are
    already installed inside the container environment where these scripts will run.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种选择涉及使用 SageMaker **脚本模式**，其中我们导入一个自定义训练脚本，该脚本使用深度学习框架（如 **TensorFlow**、**PyTorch**
    或 **MXNet**）来训练模型。在这里，自定义训练脚本将在预先构建的容器内运行，这些容器包括 **AWS Deep Learning Containers**，如第
    [*3章*](B18638_03.xhtml#_idTextAnchor060) 中所述，*深度学习容器*。话虽如此，当我们选择此选项时，我们只需担心准备训练脚本，因为大多数依赖项已经安装在这些脚本将运行的容器环境中。
- en: The third option involves building and using a custom container image for training
    ML models in SageMaker. This option gives us the highest level of flexibility
    as we have full control over the environment where our custom training scripts
    will run.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种选择涉及在 SageMaker 中构建和使用自定义容器镜像来训练机器学习模型。此选项为我们提供了最高级别的灵活性，因为我们完全控制自定义训练脚本将运行的环境。
- en: Note
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '*Which option is best for us?* If we want to proceed with training an ML model
    without having to prepare a custom script along with a custom container image,
    the best option would be to use SageMaker’s built-in algorithms. If we are trying
    to port our custom script to SageMaker, which makes use of open source ML libraries
    and frameworks (such as scikit-learn, PyTorch, and TensorFlow) to train a model,
    then the best option would be to use SageMaker’s script mode. If we need a bit
    more flexibility, then we may choose the option where we use our own custom container
    image instead.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*哪个选项最适合我们？* 如果我们想在不需要准备自定义脚本和自定义容器镜像的情况下继续训练ML模型，最佳选项是使用SageMaker的内置算法。如果我们试图将自定义脚本移植到SageMaker，该脚本使用开源ML库和框架（如scikit-learn、PyTorch和TensorFlow）来训练模型，那么最佳选项是使用SageMaker的脚本模式。如果我们需要更多的灵活性，那么我们可以选择使用我们自己的自定义容器镜像的选项。'
- en: Now that we have a better idea of what options are available when training ML
    models in SageMaker, let’s proceed with discussing what we will do in the hands-on
    portion of this section. In this section, we will use the built-in `ml.p2.xlarge`
    instances. To test the model we trained, we will deploy the model and launch an
    inference endpoint inside an `ml.m5.xlarge` instance. This inference endpoint
    is then used to perform sample predictions using several test images.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对在SageMaker中训练机器学习模型时有哪些选项有了更好的了解，让我们继续讨论本节实践部分我们将要做什么。在本节中，我们将使用内置的`ml.p2.xlarge`实例。为了测试我们训练的模型，我们将在`ml.m5.xlarge`实例内部部署模型并启动一个推理端点。然后，这个推理端点被用来使用几个测试图像进行样本预测。
- en: 'As shown in the following diagram, we can utilize **distributed training**
    when performing the training steps:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下图所示，在执行训练步骤时，我们可以利用**分布式训练**：
- en: '![Figure 6.3 – Training and deploying an image classification model ](img/B18638_06_003.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图6.3 – 训练和部署图像分类模型](img/B18638_06_003.jpg)'
- en: Figure 6.3 – Training and deploying an image classification model
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – 训练和部署图像分类模型
- en: Distributed Training can help reduce the training time through the use of multiple
    instances instead of one. Since we are using a built-in algorithm, all we need
    to do is configure the training job to use two or more instances to enable distributed
    training.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式训练可以通过使用多个实例而不是单个实例来帮助减少训练时间。由于我们使用的是内置算法，我们只需要配置训练作业以使用两个或更多实例来启用分布式训练。
- en: With these aspects in mind, let’s proceed with creating a new notebook in **SageMaker
    Studio**. We will use this to run the blocks of code to train our Image Classification
    model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些方面，让我们继续在**SageMaker Studio**中创建一个新的notebook。我们将使用它来运行训练图像分类模型的代码块。
- en: Creating a new Notebook in SageMaker Studio
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在SageMaker Studio中创建一个新的Notebook
- en: Start by opening SageMaker Studio and creating a new directory named `CH06`.
    Then, create a new **Jupyter notebook** and save it inside this directory.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开SageMaker Studio并创建一个名为`CH06`的新目录。然后，在这个目录中创建一个新的**Jupyter notebook**并保存。
- en: Note
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Make sure that you have completed the hands-on solutions in the *Getting started
    with SageMaker and SageMaker Studio* section of [*Chapter 1*](B18638_01.xhtml#_idTextAnchor017),
    *Introduction to ML Engineering on AWS*, before proceeding.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请确保您已经完成了[*第1章*](B18638_01.xhtml#_idTextAnchor017)“在AWS上介绍机器学习工程”中“使用SageMaker和SageMaker
    Studio入门”部分的动手实践解决方案。
- en: 'Follow these steps to launch SageMaker Studio and create the new notebook that
    will be used to run the Python scripts in this chapter:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤启动SageMaker Studio并创建用于运行本章Python脚本的新notebook：
- en: 'Navigate to SageMaker Studio by doing the following:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下步骤导航到SageMaker Studio：
- en: Typing `sagemaker studio` in the search bar of the AWS Management Console.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS管理控制台的搜索栏中输入`sagemaker studio`。
- en: Selecting **SageMaker Studio** from the list of results under **Features**.
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从**功能**下的结果列表中选择**SageMaker Studio**。
- en: Important Note
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This chapter assumes that we are using the `us-west-2`) region when using services
    to manage and create different types of resources. You may use a different region
    but make sure to make any adjustments needed if certain resources need to be transferred
    to the region of choice.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 本章假设我们在使用服务来管理和创建不同类型的资源时使用的是`us-west-2`区域。您可以使用不同的区域，但请确保如果某些资源需要转移到所选区域，则进行任何必要的调整。
- en: Next, click **Studio** under **SageMaker Domain** in the sidebar.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在侧边栏中点击**SageMaker域**下的**Studio**。
- en: 'Click **Launch app**, as highlighted in the following screenshot. Select **Studio**
    from the list of dropdown options:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**启动应用**，如以下截图所示。从下拉选项列表中选择**工作室**：
- en: '![Figure 6.4 – Opening SageMaker Studio ](img/B18638_06_004.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图6.4 – 打开SageMaker Studio](img/B18638_06_004.jpg)'
- en: Figure 6.4 – Opening SageMaker Studio
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 打开SageMaker Studio
- en: This will redirect you to SageMaker Studio. Wait a few seconds for the interface
    to load.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这将重定向你到SageMaker Studio。等待几秒钟，直到界面加载。
- en: 'Right-click on the empty space in the **File Browser** sidebar pane to open
    a context menu similar to the following:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击**文件浏览器**侧边栏中的空白区域以打开类似于以下内容的上下文菜单：
- en: '![Figure 6.5 – Creating a new folder ](img/B18638_06_005.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图6.5 – 创建新文件夹](img/B18638_06_005.jpg)'
- en: Figure 6.5 – Creating a new folder
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 创建新文件夹
- en: Select `CH06`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 选择`CH06`。
- en: Navigate to the `CH06` directory by double-clicking the corresponding folder
    name in the sidebar.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在侧边栏中双击相应的文件夹名称，导航到`CH06`目录。
- en: 'Create a new notebook by clicking the **File** menu and choosing **notebook**
    from the list of options under the **New** submenu:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击**文件**菜单并从**新建**子菜单下的选项中选择**笔记本**来创建一个新的笔记本：
- en: '![Figure 6.6 – Creating a new Notebook ](img/B18638_06_006.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图6.6 – 创建新笔记本](img/B18638_06_006.jpg)'
- en: Figure 6.6 – Creating a new Notebook
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 – 创建新笔记本
- en: Here, we can see other options as well, including creating a new **Console**,
    **Data Wrangler Flow**, **Terminal**, **Text File**, and more.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们还可以看到其他选项，包括创建新的**控制台**、**数据整理器流程**、**终端**、**文本文件**等。
- en: In the `Data Science` (option found under the Sagemaker image)
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Sagemaker图像下的`数据科学`（选项）
- en: '`Python 3`'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Python 3`'
- en: '`No script`'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`无脚本`'
- en: Click the **Select** button.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**选择**按钮。
- en: Note
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Wait for the kernel to start. This step may take around 3 to 5 minutes while
    an ML instance is being provisioned to run the Jupyter notebook cells.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 等待内核启动。这一步可能需要大约3到5分钟，因为正在为运行Jupyter笔记本单元格配置机器学习实例。
- en: 'Right-click on the tab’s name, as highlighted in the following screenshot:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击标签名称，如以下截图所示：
- en: '![Figure 6.7 – Renaming a notebook ](img/B18638_06_007.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图6.7 – 重命名笔记本](img/B18638_06_007.jpg)'
- en: Figure 6.7 – Renaming a notebook
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 – 重命名笔记本
- en: Select **Rename Notebook…** from the list of options in the context menu.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 从上下文菜单中的选项中选择**重命名笔记本…**。
- en: In the `PART01.ipynb` under **New Name**. Then, click the **Rename** button.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**新名称**下的`PART01.ipynb`。然后，点击**重命名**按钮。
- en: 'Type the following in the first cell of the Notebook:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在笔记本的第一个单元格中输入以下内容：
- en: '[PRE5]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Click the **Run the selected cell and advance** button, as highlighted in the
    following screenshot. Alternatively, you can hold **SHIFT** and press **ENTER**
    to run the selected cell and create a new cell automatically:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**运行所选单元格并前进**按钮，如以下截图所示。或者，您可以按住**SHIFT**键并按**ENTER**键来运行所选单元格并自动创建一个新单元格：
- en: '![Figure 6.8 – Running a selected cell ](img/B18638_06_008.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图6.8 – 运行所选单元格](img/B18638_06_008.jpg)'
- en: Figure 6.8 – Running a selected cell
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 – 运行所选单元格
- en: This should yield an output of `Hello`, which should show up under the cell.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会输出`Hello`，它应该显示在单元格下。
- en: Note
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If no output is displayed, this means that either no kernel is running, or the
    kernel is still starting. Once the kernel is ready, you can run the cells again.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有显示输出，这意味着要么没有内核正在运行，要么内核仍在启动。一旦内核准备好，您可以再次运行单元格。
- en: Now that our notebook is ready, we will create a new cell for each block of
    code in the succeeding sections.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在笔记本已经准备好了，我们将在后续章节的每个代码块中创建一个新的单元格。
- en: Downloading the training, validation, and test datasets
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载训练、验证和测试数据集
- en: 'At this point, you might be wondering what dataset we will use to train our
    ML model. To answer your question, we will use the **MNIST dataset**, which is
    a large collection of images of handwritten digits. An example of this can be
    seen in the following diagram:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能想知道我们将使用什么数据集来训练我们的机器学习模型。为了回答你的问题，我们将使用**MNIST数据集**，这是一个包含大量手写数字图像的大集合。以下图表中可以看到一个示例：
- en: '![Figure 6.9 – MNIST dataset ](img/B18638_06_009.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图6.9 – MNIST数据集](img/B18638_06_009.jpg)'
- en: Figure 6.9 – MNIST dataset
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9 – MNIST数据集
- en: Here, we can see that each image in the MNIST dataset has a class that corresponds
    to a number between `0` and `9`. That said, there are a total of 10 classes and
    each image in this dataset falls under exactly one class.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到MNIST数据集中的每个图像都有一个与`0`到`9`之间的数字相对应的类别。换句话说，总共有10个类别，这个数据集中的每个图像恰好属于一个类别。
- en: Note
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The MNIST dataset contains thousands of images of handwritten numbers. The usual
    challenge involves correctly identifying which number from 0 to 9 maps to the
    handwritten number displayed (in the image). It might be trivial for us humans
    to classify these handwritten numbers correctly. However, it’s not straightforward
    for machines since they would have to process the pixel data of the images and
    establish patterns of how the numbers are represented in the images. To get machines
    to properly classify these images, we’ll use deep learning (using the image classification
    algorithm of SageMaker)!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST数据集包含数千张手写数字的图片。通常的挑战在于正确识别从0到9的哪个数字对应于显示在图片中的手写数字。对于我们人类来说，正确分类这些手写数字可能微不足道。然而，对于机器来说并不简单，因为它们必须处理图片的像素数据，并建立数字在图片中的表示模式。为了使机器能够正确分类这些图片，我们将使用深度学习（使用SageMaker的图像分类算法）！
- en: 'To make our lives easier, we have already prepared the training, validation,
    and test sets and stored these inside a ZIP file. Follow these steps to download
    this ZIP file and extract the files inside a specified directory:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们的工作更简单，我们已预先准备了训练集、验证集和测试集，并将这些存储在一个ZIP文件中。按照以下步骤下载此ZIP文件并在指定目录中提取文件：
- en: 'Run the following statement to ensure that you have an empty `tmp` directory
    ready:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下语句以确保你有空的`tmp`目录准备就绪：
- en: '[PRE6]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we use an exclamation point (`!`) before the command so that we can run
    Terminal commands inside the Jupyter notebook.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在命令前使用感叹号（`!`），这样我们就可以在Jupyter笔记本中运行终端命令。
- en: 'Download the `batch1.zip` file using the `wget` command:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`wget`命令下载`batch1.zip`文件：
- en: '[PRE7]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, run the following block of code to extract the contents of the `batch1.zip`
    file inside the `tmp` directory:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，运行以下代码块以在`tmp`目录内提取`batch1.zip`文件的内容：
- en: '[PRE8]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This should yield a set of logs showing the files extracted from the ZIP file:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成一组日志，显示从ZIP文件中提取的文件：
- en: '![Figure 6.10 – Enabling scrolling for the output logs ](img/B18638_06_010.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图6.10 – 启用输出日志的滚动](img/B18638_06_010.jpg)'
- en: Figure 6.10 – Enabling scrolling for the output logs
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10 – 启用输出日志的滚动
- en: Right-click on the empty space near the generated log messages. This should
    open a context menu similar to what’s shown in the preceding screenshot. Select
    **Enable Scrolling for Outputs** from the list of options available in the context
    popup.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 右键单击生成的日志消息附近的空白区域。这应该会打开一个类似于前面截图的上下文菜单。从上下文弹出菜单中的选项列表中选择**启用输出滚动**。
- en: 'Use the `ls` command to check the extracted files in the current directory:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ls`命令检查当前目录中的提取文件：
- en: '[PRE10]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We set two flags when using the `ls` command. The first one is the `-R` flag,
    which lists the directory tree recursively. The second flag is the `-F` flag,
    which adds a specific character, depending on the type of file: `/` for directories,
    `*` for executables, `@` for symbolic links, and `|` for FIFO special files.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在使用`ls`命令时设置了两个标志。第一个是`-R`标志，它递归地列出目录树。第二个标志是`-F`标志，它根据文件类型添加特定的字符：目录为`/`，可执行文件为`*`，符号链接为`@`，FIFO特殊文件为`|`。
- en: 'Running the `ls` command should give us a set of logs similar to the following:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`ls`命令应该会给我们一组类似于以下内容的日志：
- en: '![Figure 6.11 – Listing the extracted files and folders ](img/B18638_06_011.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图6.11 – 列出提取的文件和文件夹](img/B18638_06_011.jpg)'
- en: Figure 6.11 – Listing the extracted files and folders
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11 – 列出提取的文件和文件夹
- en: 'You should find five directories inside the `tmp` directory – `test`, `train`,
    `train_lst`, `validation`, and `validation_lst`:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在`tmp`目录内找到五个目录 – `test`、`train`、`train_lst`、`validation`和`validation_lst`：
- en: '![Figure 6.12 – Files and directories extracted from the batch1.zip file ](img/B18638_06_012.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图6.12 – 从batch1.zip文件中提取的文件和目录](img/B18638_06_012.jpg)'
- en: Figure 6.12 – Files and directories extracted from the batch1.zip file
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.12 – 从batch1.zip文件中提取的文件和目录
- en: As shown in the preceding diagram, we should find 10 directories inside the
    `train` directory. Each of these directories contains several *PNG* files with
    a label corresponding to the name of the directory where these files are stored.
    For example, the PNG files stored inside the `0` directory have a label of `0`.
    Inside the `train_lst` directory is the `train.lst` file, which contains a mapping
    of the labels and the images from the `train` directory (given the specified paths
    and filenames). We should find a similar set of directories and files inside `validation`
    and `validation_lst`.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，我们应该在`train`目录内找到10个目录。这些目录中的每一个都包含几个与存储这些文件的目录名称相对应的*PNG*文件。例如，存储在`0`目录内的PNG文件标签为`0`。在`train_lst`目录内是`train.lst`文件，它包含了`train`目录中标签和图像的映射（给定指定的路径和文件名）。我们应在`validation`和`validation_lst`目录内找到类似的目录和文件集。
- en: 'Next, let’s install `IPyPlot`, which we will use to inspect the images we have
    extracted from the ZIP file:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们安装`IPyPlot`，我们将使用它来检查我们从ZIP文件中提取的图像：
- en: '[PRE11]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'With `IPyPlot` installed, let’s have a quick look at what our labeled set of
    images looks like:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在安装`IPyPlot`后，让我们快速查看我们的标记图像集看起来像什么：
- en: '[PRE12]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This should plot a series of images, similar to the following:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会绘制一系列图像，类似于以下内容：
- en: '![Figure 6.13 – Using IPyPlot to display a selected number of images ](img/B18638_06_013.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图6.13 – 使用IPyPlot显示所选数量的图像](img/B18638_06_013.jpg)'
- en: Figure 6.13 – Using IPyPlot to display a selected number of images
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.13 – 使用IPyPlot显示所选数量的图像
- en: Here, we can see the differences and variations in the images of the same group.
    For one thing, the zeros do not look alike!
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到同一组图像之间的差异和变化。例如，零看起来并不相同！
- en: Feel free to tweak and change the parameter value for `max_images` when calling
    the `plot_images()` function before proceeding to the next section.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一节之前，您可以随意调整和更改在调用`plot_images()`函数之前`max_images`参数的值。
- en: Now that we have the training, validation, and test datasets ready, let’s proceed
    with uploading these to an **Amazon S3** bucket.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了训练、验证和测试数据集，让我们继续将这些上传到**Amazon S3**存储桶。
- en: Uploading the data to S3
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据上传到S3
- en: 'Note that we will be working with two different S3 buckets in this chapter,
    as shown in the following diagram:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在本章中我们将使用两个不同的S3存储桶，如下图所示：
- en: '![Figure 6.14 – S3 buckets ](img/B18638_06_014.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图6.14 – S3存储桶](img/B18638_06_014.jpg)'
- en: Figure 6.14 – S3 buckets
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.14 – S3存储桶
- en: As we can see, the first S3 bucket will contain the input and output files for
    the training job in this section. Similarly, the second S3 bucket will contain
    the input and output files for the training job we’ll run later in the *Utilizing
    Managed Spot Training and Checkpoints* section toward the end of this chapter.
    In addition to this, we will use a technique called incremental training, where
    we will use the model generated in this section as a starting point to train a
    more accurate model. For now, let’s focus on the first S3 bucket and upload the
    data that will be used to train our ML model.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，第一个S3存储桶将包含本节中训练作业的输入和输出文件。同样，第二个S3存储桶将包含我们将在本章末尾的*利用托管Spot训练和检查点*部分运行的训练作业的输入和输出文件。此外，我们将使用一种称为增量训练的技术，其中我们将使用本节生成的模型作为起点来训练一个更精确的模型。现在，让我们专注于第一个S3存储桶，并上传用于训练我们的机器学习模型的数据。
- en: 'Follow these steps to create an S3 bucket and then upload all the files and
    folders from the `tmp` directory to the new S3 bucket:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤创建一个S3存储桶，然后将`tmp`目录中的所有文件和文件夹上传到新的S3存储桶：
- en: 'Specify a unique S3 bucket name and prefix. Make sure that you replace the
    value of `<INSERT S3 BUCKET NAME HERE>` with a unique S3 bucket name before running
    the following block of code:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定一个唯一的S3存储桶名称和前缀。确保在运行以下代码块之前，将`<INSERT S3 BUCKET NAME HERE>`的值替换为一个唯一的S3存储桶名称：
- en: '[PRE20]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: It is recommended not to use any of the S3 buckets created in the previous chapters.
    So, the S3 bucket name here should be for a bucket that doesn’t exist yet.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 建议不要使用之前章节中创建的任何S3存储桶。因此，这里的S3存储桶名称应该是一个尚未存在的存储桶的名称。
- en: 'Let’s use the `glob()` function to prepare a list containing all the images
    inside the `tmp/train` directory. Then, use the `len()` function to count the
    number of items in the list generated:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用`glob()`函数准备一个包含`tmp/train`目录内所有图像的列表。然后，使用`len()`函数来计算生成的列表中的项目数量：
- en: '[PRE22]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This should give us a value of `4000`, which is the total number of `.png` files
    inside the `tmp/train` directory.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会给我们一个 `4000` 的值，这是 `tmp/train` 目录中 `.png` 文件的总数。
- en: 'Use the `aws s3 mb` command to create a new Amazon S3 bucket. Here, `{s3_bucket}`
    automatically gets replaced with the value of `s3_bucket` from the previous code
    cells written in Python:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `aws s3 mb` 命令创建一个新的 Amazon S3 桶。在这里，`{s3_bucket}` 会自动替换为之前用 Python 编写的代码单元格中
    `s3_bucket` 的值：
- en: '[PRE24]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You should see a success log message similar to `make_bucket: <S3 bucket name>`
    if the S3 bucket creation step is successful. Note that this step may fail if
    the bucket already exists before using this command.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '如果 S3 桶创建步骤成功，你应该会看到一个类似于 `make_bucket: <S3 bucket name>` 的成功日志消息。请注意，如果在执行此命令之前桶已存在，则此步骤可能会失败。'
- en: 'Next, use the AWS CLI to upload the contents of the `tmp` directory to the
    target S3 path:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用 AWS CLI 将 `tmp` 目录的内容上传到目标 S3 路径：
- en: '[PRE25]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The first parameter of the `aws s3 cp` command is the source (`tmp/.`), while
    the second parameter is the target destination (S3 path). Here, we use the `--recursive`
    flag to copy all the files from the source to the destination recursively:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`aws s3 cp` 命令的第一个参数是源（`tmp/.`），而第二个参数是目标位置（S3 路径）。在这里，我们使用 `--recursive` 标志递归地复制所有文件从源到目标：'
- en: '![Figure 6.15 – Copying the files and directories from the tmp directory to
    the S3 bucket ](img/B18638_06_015.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.15 – 从 tmp 目录复制文件和目录到 S3 桶](img/B18638_06_015.jpg)'
- en: Figure 6.15 – Copying the files and directories from the tmp directory to the
    S3 bucket
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.15 – 从 tmp 目录复制文件和目录到 S3 桶
- en: As shown in the preceding diagram, the `aws s3 cp` command will copy all the
    contents from the `tmp` directory of the SageMaker Studio notebook to the new
    S3 bucket. This includes all the files and directories inside the `train`, `train_lst`,
    `validation`, `validation_lst`, and `test` directories.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，`aws s3 cp` 命令将复制 SageMaker Studio 笔记本中 `tmp` 目录的所有内容到新的 S3 桶。这包括 `train`、`train_lst`、`validation`、`validation_lst`
    和 `test` 目录中的所有文件和目录。
- en: Note
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This step should take about 1 to 2 minutes to complete. Feel free to grab a
    cup of coffee or tea while waiting!
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤应花费大约 1 到 2 分钟完成。在等待时，不妨拿一杯咖啡或茶！
- en: Once the upload operation has been completed, we can start training an ML model!
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦上传操作完成，我们就可以开始训练 ML 模型了！
- en: Using the SageMaker Python SDK to train an ML model
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 SageMaker Python SDK 训练 ML 模型
- en: 'In the previous section, we uploaded the training and validation datasets to
    an Amazon S3 bucket. These datasets will be used as input when running the training
    job in this section. Of course, there are a few more input parameters we need
    to prepare before we can configure and run a SageMaker training job:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们将训练和验证数据集上传到了一个 Amazon S3 桶。这些数据集将在本节中运行训练作业时作为输入使用。当然，在配置和运行 SageMaker
    训练作业之前，我们还需要准备一些更多的输入参数：
- en: '![Figure 6.16 – Requirements when initializing an Estimator object ](img/B18638_06_016.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.16 – 初始化 Estimator 对象时的要求](img/B18638_06_016.jpg)'
- en: Figure 6.16 – Requirements when initializing an Estimator object
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.16 – 初始化 Estimator 对象时的要求
- en: As shown in the preceding diagram, we need to have a few configuration parameter
    values, along with the hyperparameter configuration values, ready when initializing
    and configuring an `Estimator` object. When the `Estimator` object’s `fit()` method
    is called, SageMaker uses the parameter values used to configure the `Estimator`
    object when running the training job. For example, the instance type used to train
    the ML model depends on the parameter value for `instance_type` when initializing
    the estimator.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，在初始化和配置 `Estimator` 对象时，我们需要准备一些配置参数值，以及超参数配置值。当调用 `Estimator` 对象的 `fit()`
    方法时，SageMaker 使用配置 `Estimator` 对象时使用的参数值来运行训练作业。例如，用于训练 ML 模型的实例类型取决于初始化估计器时 `instance_type`
    的参数值。
- en: 'Follow these steps to use the **SageMaker Python SDK** to train an image classification
    model:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤使用 **SageMaker Python SDK** 训练图像分类模型：
- en: 'Import the SageMaker Python SDK and the **Boto AWS Python SDK**:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 SageMaker Python SDK 和 **Boto AWS Python SDK**：
- en: '[PRE27]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Initialize a few prerequisites, such as `session`, `role`, and `region_name`:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一些先决条件，例如 `session`、`role` 和 `region_name`：
- en: '[PRE29]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Use the `retrieve()` function to prepare the image URI for the image classification
    algorithm. Note that the `retrieve()` function returns the Amazon ECR URI of the
    built-in algorithm:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `retrieve()` 函数为图像分类算法准备图像 URI。请注意，`retrieve()` 函数返回内置算法的 Amazon ECR URI：
- en: '[PRE32]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This should give us a value similar to `'433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:1'`.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该给我们一个类似于 `'433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:1'`
    的值。
- en: 'Define the `map_path()` and `map_input()` functions:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 `map_path()` 和 `map_input()` 函数：
- en: '[PRE38]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Prepare the `data_channels` dictionary by running the following block of code:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码块来准备 `data_channels` 字典：
- en: '[PRE52]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: These data channels correspond to each of the directories we have uploaded to
    the Amazon S3 bucket (except for the `test` directory).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据通道对应于我们上传到 Amazon S3 存储桶中的每个目录（除了 `test` 目录）。
- en: 'Generate the S3 URL for the output path using the `map_path()` function we
    defined previously:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们之前定义的 `map_path()` 函数生成输出路径的 S3 URL：
- en: '[PRE59]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: This should give us an S3 path similar to `'s3://<S3 BUCKET NAME>/ch06/output'`.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该给我们一个类似于 `'s3://<S3 BUCKET NAME>/ch06/output'` 的 S3 路径。
- en: 'Before we initialize the `Estimator` object, let’s quickly review what we have
    so far:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们初始化 `Estimator` 对象之前，让我们快速回顾一下到目前为止我们已经做了什么：
- en: '![Figure 6.17 – Data channels and the output path ](img/B18638_06_017.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.17 – 数据通道和输出路径](img/B18638_06_017.jpg)'
- en: Figure 6.17 – Data channels and the output path
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.17 – 数据通道和输出路径
- en: Here, we can see that the data channels we have prepared in the previous steps
    will be used as input later when we run the training job. Once the training job
    has been completed, the output file(s) will be stored in the S3 location specified
    in `output_path`.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到在之前步骤中准备好的数据通道将在运行训练作业时作为输入使用。一旦训练作业完成，输出文件（们）将被存储在 `output_path`
    中指定的 S3 位置。
- en: 'With everything ready, let’s initialize the `Estimator` object. When initializing
    an `Estimator` object, we pass several arguments, such as the container image
    URI, the IAM role ARN, and the SageMaker `session` object. We also specify the
    number and type of ML instances used when performing the training job, along with
    the parameter values for `output_path` and `enable_network_isolation`:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一切准备就绪后，让我们初始化 `Estimator` 对象。在初始化 `Estimator` 对象时，我们需要传递几个参数，例如容器镜像 URI、IAM
    角色ARN 和 SageMaker `session` 对象。我们还指定了在执行训练作业时使用的 ML 实例的数量和类型，以及 `output_path`
    和 `enable_network_isolation` 的参数值：
- en: '[PRE61]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Note that initializing the `Estimator` object does not run the training job
    yet. When we run the training job using the `fit()` method in a later step, SageMaker
    will launch and provision two `ml.p2.xlarge` instances to run the image classification
    algorithm to train a model. Then, the results get uploaded to the S3 location
    in `output_path`. Since we set `enable_network_isolation` to `True`, we have configured
    the containers inside the SageMaker ML instances so that they don’t have external
    network access while the training jobs are running. This helps secure the setup
    since this configuration prevents the running container from downloading malicious
    code or accessing external services.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，初始化 `Estimator` 对象并不会立即运行训练作业。当我们稍后使用 `fit()` 方法运行训练作业时，SageMaker 将启动并配置两个
    `ml.p2.xlarge` 实例来运行图像分类算法以训练模型。然后，结果将被上传到 `output_path` 中的 S3 位置。由于我们已将 `enable_network_isolation`
    设置为 `True`，我们已配置 SageMaker ML 实例内部的容器，以便在训练作业运行期间没有外部网络访问。这有助于确保设置的安全性，因为此配置防止正在运行的容器下载恶意代码或访问外部服务。
- en: Note
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We should be fine since we are using a container image prepared by AWS. If we
    were to use a custom container image instead, we can set `enable_network_isolation`
    to `True`, especially if we are not expecting the container to access external
    services or download resources. This will help safeguard our ML environments and
    resources against attacks requiring network connectivity. For more information
    about this topic, check out [*Chapter 9*](B18638_09.xhtml#_idTextAnchor187), *Security,
    Governance, and Compliance Strategies*.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该没问题，因为我们正在使用 AWS 准备的容器镜像。如果我们想使用自定义容器镜像，可以将 `enable_network_isolation` 设置为
    `True`，特别是如果我们不期望容器访问外部服务或下载资源。这将有助于保护我们的机器学习环境和资源免受需要网络连接的攻击。有关此主题的更多信息，请参阅[*第
    9 章*](B18638_09.xhtml#_idTextAnchor187)，*安全、治理和合规策略*。
- en: 'Initialize the hyperparameter configuration values with the following block
    of code:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码块初始化超参数配置值：
- en: '[PRE70]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: The configurable hyperparameter values depend on the algorithm used. These are
    just some of the hyperparameters we can configure with the image classification
    algorithm.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 可配置的超参数值取决于所使用的算法。这些只是我们可以使用图像分类算法配置的一些超参数。
- en: 'Use the `set_hyperparameters()` method to configure the `Estimator` object
    with the hyperparameters prepared in the previous step:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`set_hyperparameters()`方法使用之前步骤中准备的超参数配置`Estimator`对象：
- en: '[PRE81]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Here, we can see that we used `**` to pass multiple arguments to a function
    or method directly using a dictionary. Note that this is equivalent to calling
    the `set_hyperparameters()` method, similar to what we have in the following block
    of code:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们使用`**`通过字典直接传递多个参数给函数或方法。请注意，这与调用`set_hyperparameters()`方法等效，类似于以下代码块中的内容：
- en: '[PRE82]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Note
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Optionally, we may inspect the properties of the `Estimator` object using the
    `__dict__` attribute. Feel free to run `estimator.__dict__` in a separate cell
    before proceeding with the next step.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，我们可以使用`__dict__`属性检查`Estimator`对象的属性。在继续下一步之前，请在单独的单元中运行`estimator.__dict__`。
- en: 'Use the `fit()` method to start the training job:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fit()`方法开始训练作业：
- en: '[PRE83]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Once the training job has finished, we should see a set of logs similar to
    the following:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练作业完成，我们应该看到一组类似于以下内容的日志：
- en: '![Figure 6.18 – Logs generated after the training job has been completed ](img/B18638_06_018.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![图6.18 – 训练作业完成后生成的日志](img/B18638_06_018.jpg)'
- en: Figure 6.18 – Logs generated after the training job has been completed
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.18 – 训练作业完成后生成的日志
- en: 'Several operations and steps are performed behind the scenes when the `fit()`
    method is called. After SageMaker provisions the desired number of ML instances,
    the input data and the training container image are downloaded to each of the
    instances. A container is run from the downloaded container image, and an ML model
    is trained using the input data. The resulting model files are stored inside a
    `model.tar.gz` file. This `model.tar.gz` file is then uploaded to the configured
    output S3 location. Finally, SageMaker terminates the instances after the training
    job has finished:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当调用`fit()`方法时，在幕后执行了几个操作和步骤。SageMaker分配了所需的ML实例数量后，输入数据和训练容器镜像被下载到每个实例。从下载的容器镜像中运行一个容器，并使用输入数据训练ML模型。生成的模型文件存储在`model.tar.gz`文件中。然后，将此`model.tar.gz`文件上传到配置的输出S3位置。最后，在训练作业完成后，SageMaker终止实例：
- en: '![Figure 6.19 – What happens after calling the fit() method ](img/B18638_06_019.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![图6.19 – 调用fit()方法后发生的情况](img/B18638_06_019.jpg)'
- en: Figure 6.19 – What happens after calling the fit() method
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.19 – 调用fit()方法后发生的情况
- en: As shown in the preceding diagram, each of the relevant steps performed inside
    the ML instance generates logs that automatically get stored in **CloudWatch Logs**.
    This includes the metric values, along with different types of log messages that
    were generated while the training job was running.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，在ML实例内部执行的每个相关步骤都会生成日志，这些日志会自动存储在**CloudWatch日志**中。这包括度量值，以及训练作业运行期间生成的不同类型的日志消息。
- en: Important Note
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This step may take around 5 to 10 minutes to complete. If you encounter a **ResourceLimitExceeded**
    error, it means that you have exceeded the quota when using a certain type of
    ML instance when running a training job. Make sure that you have completed the
    steps specified in the *Preparing the essential prerequisites* section of this
    chapter. For more information on this topic, check out [https://aws.amazon.com/premiumsupport/knowledge-center/resourcelimitexceeded-sagemaker/](https://aws.amazon.com/premiumsupport/knowledge-center/resourcelimitexceeded-sagemaker/).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤可能需要大约5到10分钟才能完成。如果你遇到**ResourceLimitExceeded**错误，这意味着你在运行训练作业时使用某种类型的ML实例时已超出配额。请确保你已经完成了本章“准备基本先决条件”部分中指定的步骤。有关此主题的更多信息，请参阅[https://aws.amazon.com/premiumsupport/knowledge-center/resourcelimitexceeded-sagemaker/](https://aws.amazon.com/premiumsupport/knowledge-center/resourcelimitexceeded-sagemaker/)。
- en: There’s a lot of information we can get from the logs stored in CloudWatch Logs.
    If you encounter an error when running a training job, you can check the logs
    stored in CloudWatch Logs (for example, `/aws/sagemaker/TrainingJob`) to troubleshoot
    the issue.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从存储在CloudWatch日志中的日志中获取大量信息。如果你在运行训练作业时遇到错误，你可以检查存储在CloudWatch日志中的日志（例如，`/aws/sagemaker/TrainingJob`）以解决问题。
- en: Using the %store magic to store data
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用%store魔法存储数据
- en: 'Before we deploy and test our model, let’s quickly store a backup copy of the
    values of some variables used in our first notebook (for example, `PART01.ipynb`):'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们部署和测试模型之前，让我们快速存储一下我们第一个笔记本（例如，`PART01.ipynb`）中使用的某些变量的备份副本：
- en: '![Figure 6.20 – %store magic ](img/B18638_06_020.jpg)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图6.20 – %store魔法](img/B18638_06_020.jpg)'
- en: Figure 6.20 – %store magic
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.20 – `%store` 魔法
- en: We will do this using the `%store` magic from IPython and make these variable
    values available in other notebooks as well. We will load these variable values
    later in the *Utilizing Managed Spot Training and Checkpoints* section, where
    we will create a new notebook named `PART02.ipynb`.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 IPython 的 `%store` 魔法来完成这项工作，并将这些变量值在其他笔记本中可用。我们将在 *利用托管 Spot 训练和检查点*
    部分稍后加载这些变量值，在那里我们将创建一个新的笔记本，名为 `PART02.ipynb`。
- en: 'Follow these steps to use the `%store` magic to save a copy of some of the
    variable values used in `PART01.ipynb`:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤使用 `%store` 魔法保存 `PART01.ipynb` 中使用的某些变量值的副本：
- en: 'Inspect the value of `model_data`:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `model_data` 的值：
- en: '[PRE85]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: This should return the S3 path where the training job output file (`model.tar.gz`)
    is stored.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该返回存储训练作业输出文件（`model.tar.gz`）的 S3 路径。
- en: 'Copy the value of `estimator.model_data` to a new variable named `model_data`.
    Similarly, copy the value of the name of the latest training job to a variable
    named `job_name`:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `estimator.model_data` 的值复制到一个名为 `model_data` 的新变量中。同样，将最新训练作业的名称复制到一个名为 `job_name`
    的变量中：
- en: '[PRE86]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Use the `%store` magic to store data in memory:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `%store` 魔法在内存中存储数据：
- en: '[PRE88]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: As you can see, the `%store` magic helps us divide a long Jupyter notebook into
    several smaller notebooks. Later, in the *Utilizing Managed Spot Training and
    Checkpoints* section, we will use `%store -r <variable name>` to load the variable
    values stored in this section.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`%store` 魔法帮助我们将一个长的 Jupyter notebook 划分为几个更小的笔记本。稍后，在 *利用托管 Spot 训练和检查点*
    部分，我们将使用 `%store -r <变量名>` 来加载在此部分中存储的变量值。
- en: Using the SageMaker Python SDK to deploy an ML model
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 SageMaker Python SDK 部署 ML 模型
- en: It’s time we deploy the model to an inference endpoint. Deploying an ML model
    using the SageMaker Python SDK is straightforward. All we need to do is call the
    `deploy()` method; an inference endpoint will automatically be provisioned and
    configured for us in just a few minutes.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候将模型部署到推理端点了。使用 SageMaker Python SDK 部署 ML 模型非常简单。我们只需要调用 `deploy()` 方法；推理端点将在几分钟内自动为我们配置和提供。
- en: 'Follow these steps to deploy our ML model using the SageMaker Python SDK and
    then perform some test predictions afterward:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤使用 SageMaker Python SDK 部署我们的 ML 模型，然后进行一些测试预测：
- en: 'Use the `deploy()` method to deploy the trained Image Classification model
    to a real-time inference endpoint. Model deployment should take around 5 to 10
    minutes to complete:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `deploy()` 方法将训练好的图像分类模型部署到实时推理端点。模型部署通常需要大约 5 到 10 分钟才能完成：
- en: '[PRE93]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Here, we specify that we are using an `ml.m5.xlarge` instance to host the trained
    ML model. At this point, you might be wondering why several different instance
    types are involved when training or deploying a model. The first thing you need
    to know is that the SageMaker Studio notebook instance where the Jupyter notebook
    scripts are running is different and completely separate from the instances that
    are used when training or deploying a model:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们指定我们正在使用 `ml.m5.xlarge` 实例来托管训练好的 ML 模型。此时，您可能想知道为什么在训练或部署模型时涉及了多种不同的实例类型。首先，您需要知道的是，运行
    Jupyter notebook 脚本的 SageMaker Studio 笔记本实例与用于训练或部署模型的实例不同，并且是完全独立的：
- en: '![Figure 6.21 – Different instances used to train and deploy a model ](img/B18638_06_021.jpg)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.21 – 用于训练和部署模型的实例](img/B18638_06_021.jpg)'
- en: Figure 6.21 – Different instances used to train and deploy a model
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.21 – 用于训练和部署模型的不同实例
- en: Here, we can see that the instance(s) used to train the model are different
    from the instances used during deployment as well. In most cases, the ML instances
    used to train a model are more powerful (and more expensive per hour) compared
    to the instances used when deploying the trained model. In our case, we used two
    `ml.p2.xlarge` instances (*GPU-powered | 4 vCPU | 61 GiB | $1.125 per hour per
    instance*) during training and a single `ml.m5.xlarge` instance (*4 vCPU | 16
    GiB | $0.23 per hour per instance*) to host our real-time inference endpoint.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到用于训练模型的实例与部署期间使用的实例不同。在大多数情况下，用于训练模型的 ML 实例比部署训练好的模型时使用的实例更强大（并且每小时成本更高）。在我们的例子中，我们使用了两个
    `ml.p2.xlarge` 实例（*GPU 加速 | 4 个 vCPU | 61 GiB | 每个实例每小时 1.125 美元*）进行训练，并使用单个 `ml.m5.xlarge`
    实例（*4 个 vCPU | 16 GiB | 每个实例每小时 0.23 美元*）来托管我们的实时推理端点。
- en: Important Note
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Looking at these numbers alone, we may incorrectly assume that the overall cost
    of running the `ml.p2.xlarge` training instances is higher than the overall cost
    of running the `ml.m5.xlarge` instance used to host the deployed model. In reality,
    the overall cost of running the `ml.m5.xlarge` inference instance will exceed
    the overall cost of running the `ml.p2.xlarge` training instances if we do not
    delete the inference instances right away. ML instances used during training are
    automatically terminated after the training job has been completed. Since we only
    pay for what we use, we would pay approximately `$1.125 x 2 x 0.1 = $0.225` if
    we were to run two `ml.p2.xlarge` training instances for 6 minutes each. On the
    other hand, an `ml.m5.xlarge` inference instance would cost around `$0.23 x 24
    = $5.52` if we kept it running for 24 hours. To manage costs, make sure to delete
    instances used for real-time inference during periods of inactivity. If the expected
    traffic to be received by the inference endpoint is unpredictable or intermittent,
    you may want to check the **SageMaker Serverless Inference** option. For more
    information, check out [https://aws.amazon.com/about-aws/whats-new/2021/12/amazon-sagemaker-serverless-inference/](https://aws.amazon.com/about-aws/whats-new/2021/12/amazon-sagemaker-serverless-inference/).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 仅从这些数字来看，我们可能会错误地假设运行 `ml.p2.xlarge` 训练实例的总成本高于运行用于托管已部署模型的 `ml.m5.xlarge` 实例的总成本。实际上，如果我们不立即删除推理实例，运行
    `ml.m5.xlarge` 推理实例的总成本将超过运行 `ml.p2.xlarge` 训练实例的总成本。在训练作业完成后，用于训练的 ML 实例会自动终止。由于我们只为所使用的付费，如果我们运行两个
    `ml.p2.xlarge` 训练实例，每个实例运行 6 分钟，我们将支付大约 `$1.125 x 2 x 0.1 = $0.225`。另一方面，如果我们保持
    `ml.m5.xlarge` 推理实例运行 24 小时，其成本将约为 `$0.23 x 24 = $5.52`。为了管理成本，确保在非活动期间删除用于实时推理的实例。如果预期接收到的推理端点流量不可预测或间歇性，您可能想检查
    **SageMaker Serverless Inference** 选项。更多信息，请参阅 [https://aws.amazon.com/about-aws/whats-new/2021/12/amazon-sagemaker-serverless-inference/](https://aws.amazon.com/about-aws/whats-new/2021/12/amazon-sagemaker-serverless-inference/)。
- en: 'Before we use the inference endpoint to perform test predictions, let’s quickly
    update the `serializer` property of the endpoint to accept the specified content
    type:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们使用推理端点进行测试预测之前，让我们快速更新端点的 `serializer` 属性，以便接受指定的内容类型：
- en: '[PRE97]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Let’s define the `get_class_from_results()` function, which accepts the raw
    output data from the SageMaker real-time inference endpoint and returns the corresponding
    class as a string (for example, `"ONE",` `"TWO",` `"THREE"`):'
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个名为 `get_class_from_results()` 的函数，该函数接受 SageMaker 实时推理端点的原始输出数据，并返回相应的字符串形式的类别（例如，`"ONE"`，`"TWO"`，`"THREE"`）：
- en: '[PRE101]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '[PRE116]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'Let’s define a custom `predict()` function:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个自定义的 `predict()` 函数：
- en: '[PRE119]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: '[PRE121]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'This custom `predict()` function does the following:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 这个自定义的 `predict()` 函数执行以下操作：
- en: Opens the test image, given a filename.
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个测试图像，给定一个文件名。
- en: Displays the test image in the Jupyter notebook.
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter 笔记本中显示测试图像。
- en: Uses the `predict()` method of the endpoint object to get the predicted class
    value.
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用端点对象的 `predict()` 方法获取预测的类别值。
- en: 'Prints the predicted class value right after the rendered image:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在渲染后的图像后立即打印预测的类别值：
- en: '![Figure 6.22 – Performing test predictions ](img/B18638_06_022.jpg)'
  id: totrans-388
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.22 – 执行测试预测](img/B18638_06_022.jpg)'
- en: Figure 6.22 – Performing test predictions
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.22 – 执行测试预测
- en: Note that there’s an extra processing step after the `endpoint.predict()` method
    is called. As shown in the preceding diagram, the custom `predict()` function
    uses the `get_class_from_results()` function to convert the raw output data from
    the inference endpoint into a human-friendly string representation of the predicted
    class.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在调用 `endpoint.predict()` 方法之后有一个额外的处理步骤。如图所示，自定义的 `predict()` 函数使用 `get_class_from_results()`
    函数将推理端点的原始输出数据转换为预测类别的易于理解字符串表示。
- en: 'Now, let’s use the custom `predict()` function we defined in the previous step:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用我们在上一步中定义的自定义 `predict()` 函数：
- en: '[PRE128]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'This should yield a set of results similar to the following:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会生成一组类似于以下的结果：
- en: '![Figure 6.23 – Performing test predictions ](img/B18638_06_023.jpg)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.23 – 执行测试预测](img/B18638_06_023.jpg)'
- en: Figure 6.23 – Performing test predictions
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.23 – 执行测试预测
- en: Here, we can see three sample images, along with their corresponding predicted
    class values. Our ML model seems to be doing just fine!
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到三张样本图像及其对应的预测类别值。我们的 ML 模型似乎表现得很不错！
- en: 'Finally, let’s delete the inference endpoint using the `delete_endpoint()`
    method:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们使用 `delete_endpoint()` 方法删除推理端点：
- en: '[PRE131]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: '*Wasn’t that easy?* The deployment we performed in this section is just one
    of the many possible scenarios when performing model deployments on AWS. We will
    look at other deployment strategies and techniques in [*Chapter 7*](B18638_07.xhtml#_idTextAnchor151),
    *SageMaker Deployment Solutions*.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll take a closer look at how we can use the **Debugger
    Insights Dashboard** to check the utilization of the resources that were used
    to train our Image Classification model.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: Using the Debugger Insights Dashboard
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When working on ML requirements, ML practitioners may encounter a variety of
    issues before coming up with a high-performing ML model. Like software development
    and programming, building ML models requires a bit of trial and error. Developers
    generally make use of a variety of debugging tools to help them troubleshoot issues
    and implementation errors when writing software applications. Similarly, ML practitioners
    need a way to monitor and debug training jobs when building ML models. Luckily
    for us, Amazon SageMaker has a capability called **SageMaker Debugger** that allows
    us to troubleshoot different issues and bottlenecks when training ML models:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.24 – SageMaker Debugger features ](img/B18638_06_024.jpg)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
- en: Figure 6.24 – SageMaker Debugger features
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram shows the features that are available when we use SageMaker
    Debugger to monitor, debug, and troubleshoot a variety of issues that affect an
    ML model’s performance. This includes the **data capture** capability across a
    variety of ML frameworks, **Debugger Interactive Reports**, the **SMDebug client
    library**, automated error detection with **Debugger built-in rules** and **custom
    rules**, and the **Debugger Insights Dashboard**.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will focus on using the **Debugger Insights Dashboard**
    to review and monitor the hardware system resource utilization rate of the instances
    used to train our ML model.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: Note that an `ml.m5.4xlarge` instance is provisioned whenever we use the Debugger
    Insights Dashboard. This `ml.m5.4xlarge` instance needs to be turned off manually
    since it is not automatically turned off during periods of inactivity. We will
    make sure to turn off this instance toward the end of this section.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: 'That said, let’s use the Debugger Insights Dashboard to monitor the hardware
    system resource utilization rate of the instances we used in the previous sections:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to **SageMaker resources** by clicking the left sidebar icon shown
    in the following screenshot:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.25 – Navigating to SageMaker resources ](img/B18638_06_025.jpg)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
- en: Figure 6.25 – Navigating to SageMaker resources
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: Select **Experiments and trials** from the list of options available in the
    first dropdown. Double-click on **Unassigned trial components**.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: 'Right-click on the first result in the list. It should have a name that starts
    with `image-classification`, followed by a timestamp. This should open a context
    menu, similar to the following. Select **Open Debugger for insights** from the
    list of options:'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.26 – Open Debugger for insights ](img/B18638_06_026.jpg)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
- en: Figure 6.26 – Open Debugger for insights
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see another option called **Open in trial details**. If you selected
    this option instead, you will see several charts, which help you analyze the metrics
    and results of the training job.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to turn off the `ml.m5.4xlarge` instance after using the Debugger
    Insights Dashboard.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Overview** tab, scroll down and locate the **Resource utilization
    summary** report, as shown here:'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.27 – Resource utilization summary ](img/B18638_06_027.jpg)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
- en: Figure 6.27 – Resource utilization summary
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see the hardware system resource utilization statistics such as
    the total CPU and GPU utilization, total CPU and GPU memory utilization, and more.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the **Nodes** tab.
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scroll down and locate the different reports and charts, as shown here:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.28 – Debugger insights – nodes ](img/B18638_06_028.jpg)'
  id: totrans-428
  prefs: []
  type: TYPE_IMG
- en: Figure 6.28 – Debugger insights – nodes
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see graphs that help us review and analyze the different utilization
    metrics over time. This includes reports such as **CPU utilization over time**,
    **Network utilization over time**, **GPU utilization over time**, and more.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: These reports can help ML engineers determine whether the resources used to
    train the model are “right-sized.” This can help optimize costs and identify performance
    bottlenecks during the training steps.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the **Running Instances and Kernels** icon in the sidebar, as highlighted
    in the following screenshot:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.29 – Turning off the running instances ](img/B18638_06_029.jpg)'
  id: totrans-434
  prefs: []
  type: TYPE_IMG
- en: Figure 6.29 – Turning off the running instances
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: Clicking the **Running Instances and Kernels** icon should open and show the
    running instances, apps, and terminals in SageMaker Studio.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: Turn off the `ml.m5.4xlarge` running instance under **RUNNING INSTANCES** by
    clicking the **Shutdown** button, as highlighted in the preceding screenshot.
    Clicking the **Shutdown** button will open a pop-up window verifying the instance
    shutdown operation. Click the **Shut down all** button to proceed.
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, we should have a better overall understanding of how to train
    and deploy ML models in Amazon SageMaker. Note that we’re just scratching the
    surface as there are a lot more features and capabilities available for us to
    use to manage, analyze, and troubleshoot ML experiments.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in learning more about the other features of **SageMaker
    Debugger**, then feel free to check out [*Chapter 5*](B18638_05.xhtml#_idTextAnchor105),
    *Pragmatic Data Processing and Analysis,* of the book *Machine Learning with Amazon
    SageMaker Cookbook*.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discuss a few more capabilities and features available
    in SageMaker when training ML models.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing Managed Spot Training and Checkpoints
  id: totrans-442
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have a better understanding of how to use the SageMaker Python
    SDK to train and deploy ML models, let’s proceed with using a few additional options
    that allow us to reduce costs significantly when running training jobs. In this
    section, we will utilize the following SageMaker features and capabilities when
    training a second Image Classification model:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: Managed Spot Training
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checkpointing
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incremental Training
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B18638_02.xhtml#_idTextAnchor041), *Deep Learning AMIs*, we
    mentioned that spot instances can be used to reduce the cost of running training
    jobs. Using spot instances instead of on-demand instances can help reduce the
    overall cost by up to 70% to 90%. So, why are spot instances cheaper? The downside
    of using spot instances is that these instances can be interrupted, which will
    restart the training job from the start. If we were to train our models outside
    of SageMaker, we would have to prepare our own set of custom automation scripts
    that will utilize and manage spot instances to train our model. Again, there’s
    no need for us to prepare a custom solution as SageMaker already supports the
    ability to automatically manage spot instances for us through its **Managed Spot
    Training** capability! In addition to this, if we configure our SageMaker training
    jobs to use **checkpoints**, we will be able to resume training from the last
    saved checkpoint even if there has been an interruption while we are using spot
    instances.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will also use a technique called **Incremental Training**,
    where we will use the model that was generated in the *Training an Image Classification
    model with the SageMaker Python SDK* section as a starting point to train a more
    accurate model. Here, we will be using a pre-trained model we have provided instead
    of training a new model from scratch.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: Note that Incremental Training can only be used when using the **Image Classification
    Algorithm**, **Object Detection Algorithm**, and **Semantic Segmentation Algorithm**
    built-in algorithms.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to use the **SageMaker Python SDK** to run a training job
    that utilizes checkpointing, Managed Spot Training, and Incremental Training:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: Create a new notebook by clicking the **File** menu and choosing **notebook**
    from the list of options under the **New** submenu.
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `Data Science` (option found under the Sagemaker image)
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Python 3`'
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`No script`'
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Select** button.
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the notebook `PART02.ipynb`. Now that we have our new Jupyter notebook
    ready, let’s run the blocks of code in the succeeding set of steps inside this
    Jupyter notebook.
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Specify the S3 bucket name and prefix. Make sure that you replace the value
    of `<INSERT S3 BUCKET NAME HERE>` with a unique S3 bucket name before running
    the following block of code:'
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE133]'
- en: 'Note that this should be different from the name of the S3 bucket you created
    in the *Training an Image Classification model with the SageMaker Python SDK*
    section. In this chapter, we will work with two different S3 buckets, similar
    to what’s shown in the following diagram:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.30 – Working with two S3 buckets ](img/B18638_06_030.jpg)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
- en: Figure 6.30 – Working with two S3 buckets
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: The first bucket should contain the model output files stored in a `model.tar.gz`
    file after running the first training job. Later in this section, we will use
    this `model.tar.gz` file as an input parameter for a new training job that utilizes
    Incremental Training when building a new model. The output of this training job
    will be stored in an output folder inside the second S3 bucket.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `%store` magic from IPython to load the values of the stored variables
    from the *Training an Image Classification model with the SageMaker Python SDK*
    section:'
  id: totrans-465
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE135]'
- en: '[PRE136]'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE136]'
- en: '[PRE137]'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE137]'
- en: 'Check the value of the loaded `job_name` variable:'
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE138]'
- en: This should return a value similar to `'image-classification-2022-04-11-16-22-24-589'`.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialize and import some of the training prerequisites:'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE139]'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '[PRE140]'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE141]'
- en: 'Next, load an `Estimator` object using the name of the previous training job
    using `Estimator.attach()`:'
  id: totrans-477
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE142]'
- en: 'Use the `logs()` method to inspect the logs of the training job we loaded in
    the previous step:'
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE143]'
- en: Note that this should yield a set of logs similar to the logs that were generated
    when we ran the training job in the *Training an Image Classification model with
    the SageMaker Python SDK* section.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: 'Get the location where the ML model ZIP file of the previous training job is
    stored. Store this value inside the `model_data` variable:'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE144]'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE144]'
- en: '[PRE145]'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE145]'
- en: The `model_data` variable should have a value with a format similar to `'s3://<S3
    BUCKET NAME>/ch06/output/image-classification-<DATETIME>/output/model.tar.gz'`.
    We will use this value later when initializing and configuring a new `Estimator`
    object.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the `generate_random_string()` function, which will be used to generate
    a unique base job name for the training job:'
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE146]'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '[PRE147]'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE148]'
- en: '[PRE149]'
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '[PRE150]'
  id: totrans-491
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE150]'
- en: '[PRE151]'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE152]'
- en: 'Generate a unique base job name using `generate_random_string()` and store
    it in the `base_job_name` variable:'
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE153]'
  id: totrans-495
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE153]'
- en: '[PRE154]'
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE154]'
- en: You should get a 12-character string similar to `'FTMHLGKYVOAC'` after using
    the `generate_random_string()` function.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
- en: Where will we use this? In a later step, we will specify a base job name of
    our choice when initializing a new `Estimator` object. If a base job name is not
    specified when initializing an `Estimator` object, SageMaker generally uses the
    algorithm image name (for example, `image-classification`) as the default base
    job name when running a training job. The base job name is then appended with
    a string representation of the current timestamp to produce the complete training
    job name.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: 'Prepare the different configuration parameters when enabling checkpointing
    support:'
  id: totrans-500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE155]'
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE155]'
- en: '[PRE156]'
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE156]'
- en: '[PRE157]'
  id: totrans-503
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE157]'
- en: 'Run the following block of code to ensure that an empty `tmp2` directory exists:'
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE158]'
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE158]'
- en: 'Download `batch2.zip` using the `wget` command:'
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE159]'
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE159]'
- en: '[PRE160]'
  id: totrans-508
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE160]'
- en: 'Next, run the following block of code to extract the contents of the `batch1.zip`
    file inside the `tmp` directory:'
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE161]'
  id: totrans-510
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE162]'
- en: 'Let’s use the `glob()` function to get a list containing all the images inside
    the `tmp2/train` directory. After that, we will use the `len()` function to count
    the number of items in the list that was generated:'
  id: totrans-512
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE163]'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE163]'
- en: '[PRE164]'
  id: totrans-514
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE164]'
- en: '[PRE165]'
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE165]'
- en: This should give us a value of `7200`, which is the total number of `.png` files
    inside the `tmp2/train` directory.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new S3 bucket using the `aws s3 mb` command:'
  id: totrans-517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE166]'
  id: totrans-518
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE166]'
- en: 'Use the `aws s3 cp` command to copy the contents of the `tmp2` directory to
    the S3 bucket:'
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE167]'
  id: totrans-520
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE167]'
- en: '[PRE168]'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE168]'
- en: 'Define the `map_path()` and `map_input()` functions:'
  id: totrans-522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE169]'
  id: totrans-523
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE169]'
- en: '[PRE170]'
  id: totrans-524
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE170]'
- en: '[PRE171]'
  id: totrans-525
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE171]'
- en: '[PRE172]'
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE172]'
- en: '[PRE173]'
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE173]'
- en: '[PRE174]'
  id: totrans-528
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE174]'
- en: '[PRE175]'
  id: totrans-529
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE175]'
- en: '[PRE176]'
  id: totrans-530
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE176]'
- en: '[PRE177]'
  id: totrans-531
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE177]'
- en: '[PRE178]'
  id: totrans-532
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE178]'
- en: '[PRE179]'
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE179]'
- en: '[PRE180]'
  id: totrans-534
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE180]'
- en: '[PRE181]'
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE181]'
- en: '[PRE182]'
  id: totrans-536
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE182]'
- en: 'Prepare the `data_channels` dictionary by running the following block of code:'
  id: totrans-537
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE183]'
  id: totrans-538
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE183]'
- en: '[PRE184]'
  id: totrans-539
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE184]'
- en: '[PRE185]'
  id: totrans-540
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE185]'
- en: '[PRE186]'
  id: totrans-541
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE186]'
- en: '[PRE187]'
  id: totrans-542
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE187]'
- en: '[PRE188]'
  id: totrans-543
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE188]'
- en: '[PRE189]'
  id: totrans-544
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE189]'
- en: 'Set the S3 output path using the `map_path()` function:'
  id: totrans-545
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE190]'
  id: totrans-546
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE190]'
- en: 'Initialize the `Estimator` object:'
  id: totrans-547
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE191]'
  id: totrans-548
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE191]'
- en: '[PRE192]'
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE192]'
- en: '[PRE193]'
  id: totrans-550
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE193]'
- en: '[PRE194]'
  id: totrans-551
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE194]'
- en: '[PRE195]'
  id: totrans-552
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE195]'
- en: '[PRE196]'
  id: totrans-553
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE196]'
- en: '[PRE197]'
  id: totrans-554
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE197]'
- en: '[PRE198]'
  id: totrans-555
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE198]'
- en: '[PRE199]'
  id: totrans-556
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE199]'
- en: '[PRE200]'
  id: totrans-557
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE200]'
- en: '[PRE201]'
  id: totrans-558
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE201]'
- en: '[PRE202]'
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE202]'
- en: '[PRE203]'
  id: totrans-560
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE203]'
- en: '[PRE204]'
  id: totrans-561
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE204]'
- en: '[PRE205]'
  id: totrans-562
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE205]'
- en: '[PRE206]'
  id: totrans-563
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE206]'
- en: This initialization step should be similar to what we did in the *Training an
    Image Classification model with the SageMaker Python SDK* section. In addition
    to the original set of parameter values we set when initializing the `Estimator`
    object, we have also set a few additional arguments, including `model_uri`, `use_spot_instances`,
    `max_run`, `max_wait`, `checkpoint_s3_uri`, and `checkpoint_local_path`.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.31 – Initializing the Estimator object with Checkpointing and Managed
    Spot Training ](img/B18638_06_031.jpg)'
  id: totrans-565
  prefs: []
  type: TYPE_IMG
- en: Figure 6.31 – Initializing the Estimator object with Checkpointing and Managed
    Spot Training
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding diagram, enabling checkpointing and Managed Spot Training
    is straightforward and easy. These are disabled by default when running SageMaker
    training jobs, so all we need to do is update the parameter values for `use_spot_instances`,
    `max_run`, `max_wait`, `checkpoint_s3_uri`, and `checkpoint_local_path` with the
    appropriate values.
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
- en: When using built-in algorithms, the `Estimator` classes such as `RandomCutForest`,
    `FactorizationMachines`, and `PCA` that can be used instead of the “generic” `Estimator`
    class. Using these has its own set of benefits and a lot of the configuration
    parameters already have good default starting values during initialization (which
    makes the code much shorter as well). In this chapter, we will use the “generic”
    `Estimator` class when performing the training experiments, but if you’re interested
    in learning more about the other classes available in the SageMaker Python SDK,
    then feel free to check out [https://sagemaker.readthedocs.io/en/stable/algorithms/index.xhtml](https://sagemaker.readthedocs.io/en/stable/algorithms/index.xhtml).
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
- en: 'Prepare the hyperparameter configuration and store it inside the `hyperparameters`
    variable:'
  id: totrans-570
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE207]'
  id: totrans-571
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE207]'
- en: '[PRE208]'
  id: totrans-572
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE208]'
- en: '[PRE209]'
  id: totrans-573
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE209]'
- en: '[PRE210]'
  id: totrans-574
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE210]'
- en: '[PRE211]'
  id: totrans-575
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE211]'
- en: '[PRE212]'
  id: totrans-576
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE212]'
- en: '[PRE213]'
  id: totrans-577
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE213]'
- en: '[PRE214]'
  id: totrans-578
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE214]'
- en: '[PRE215]'
  id: totrans-579
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE215]'
- en: '[PRE216]'
  id: totrans-580
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE216]'
- en: '[PRE217]'
  id: totrans-581
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE217]'
- en: This should be similar to the hyperparameter configuration we did in the *Training
    an Image Classification model with the SageMaker Python SDK* section, except for
    the value of `num_training_samples`.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
- en: Nothing is stopping us from changing the values of some of the configuration
    parameters here, such as `mini_batch_size`, `epochs`, and `learning_rate`. Once
    you are comfortable testing different combinations of hyperparameter values, you
    may also try configuring and using other hyperparameters, such as `optimizer`,
    `num_layers`, and `momentum`. For more details on this topic, check out [https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.xhtml).
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `set_hyperparameters()` method to specify the hyperparameter configuration
    values for the training job:'
  id: totrans-585
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE218]'
  id: totrans-586
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE218]'
- en: 'Start the Incremental Training job using the `fit()` method:'
  id: totrans-587
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE219]'
  id: totrans-588
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE219]'
- en: '[PRE220]'
  id: totrans-589
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE220]'
- en: 'This should yield a set of logs similar to the following:'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.32 – A portion of the logs after running the training job ](img/B18638_06_032.jpg)'
  id: totrans-591
  prefs: []
  type: TYPE_IMG
- en: Figure 6.32 – A portion of the logs after running the training job
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see the savings we get when using Managed Spot Training – approximately
    `70%` savings! Note that all we did was make some additional tweaks in the configuration
    of the `Estimator` object. By doing so, we were able to significantly reduce the
    cost of running the training job.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
- en: If you encounter an `fit()` method, you may stop the current training job and
    try again in an hour or so. Alternatively, you may run the experiment in another
    region. If you encounter a **ResourceLimitExceeded** error, this means that you
    have exceeded the quota when using a certain type of ML spot training instance
    when running a training job. Make sure that you have completed the steps specified
    in the *Preparing the essential prerequisites* section of this chapter. For more
    information on this topic, check out [https://aws.amazon.com/premiumsupport/knowledge-center/resourcelimitexceeded-sagemaker/](https://aws.amazon.com/premiumsupport/knowledge-center/resourcelimitexceeded-sagemaker/).
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspect the output location of the trained model using the `model_data` attribute:'
  id: totrans-596
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE221]'
  id: totrans-597
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE221]'
- en: We should get a value similar to `'s3://<S3 BUCKET NAME>/ch06/output/<BASE JOB
    NAME>-<DATE AND TIME>/output/model.tar.gz'.`
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
- en: If we decide to deploy the model outside of SageMaker (for example, in `estimator.model_data`
    points to.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the generated checkpoint files using the `aws s3 ls` command:'
  id: totrans-601
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE222]'
  id: totrans-602
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE222]'
- en: 'This should yield a set of results similar to the following:'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.33 – Generated checkpoint files ](img/B18638_06_033.jpg)'
  id: totrans-604
  prefs: []
  type: TYPE_IMG
- en: Figure 6.33 – Generated checkpoint files
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
- en: These saved checkpoint files can be used to restart and continue a training
    job from the last saved checkpoint.
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
- en: If you want to use the last saved checkpoint and continue a previous training
    job, you simply need to specify the same `checkpoint_s3_uri` when initializing
    the `Estimator` object. This will automatically download the checkpoint files
    from S3 to the training instance(s) and continue the training job from there.
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
- en: Checkpointing works well with the **Managed Spot Training** capability of SageMaker
    since we can easily resume model training, even if there’s an unexpected interruption
    to the training instance or training job. In addition to this, we can use checkpoints
    to analyze our model at different stages of the training step (since we have multiple
    *snapshots* of the model at various intermediate stages).
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discuss a few other strategies we can use when training and tuning ML
    models in SageMaker. The first one, **early stopping**, involves configuring a
    hyperparameter tuning job to stop training jobs earlier if the objective metric
    value is not improving significantly over a specified amount of time. This helps
    reduce costs (since the training job ends earlier), as well as prevent the model
    from overfitting. The second one, **local mode**, involves running and testing
    custom scripts inside SageMaker notebook instances before running them in dedicated
    ML instances. This helps speed up the development and debugging of custom training
    (and deployment) scripts since the feedback loop when using local mode is much
    faster. The third one, **heterogeneous cluster training**, involves running a
    training job over several different instance groups. This helps improve the scaling
    and utilization of resources by using a combination of GPU and CPU instances when
    processing ML workloads. The fourth one, **Fast File Mode**, helps significantly
    speed up training jobs by enabling high-performance data access from Amazon S3
    (when downloading the training data). There are more best practices and strategies
    outside of this list, but these should do for now!
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have finished working on the hands-on solutions of this chapter,
    it is time we clean up and turn off any resources we will no longer use.
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up
  id: totrans-613
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to locate and turn off any remaining running instances in
    SageMaker Studio:'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the **Running Instances and Kernels** icon in the sidebar of **Amazon
    SageMaker Studio**, as highlighted in the following screenshot:'
  id: totrans-615
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.34 – Turning off any remaining running instances ](img/B18638_06_034.jpg)'
  id: totrans-616
  prefs: []
  type: TYPE_IMG
- en: Figure 6.34 – Turning off any remaining running instances
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
- en: Clicking the **Running Instances and Kernels** icon should open and show the
    running instances, apps, and terminals in SageMaker Studio.
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
- en: Turn off any remaining running instances under **RUNNING INSTANCES** by clicking
    the **Shutdown** button for each of the instances as highlighted in the preceding
    screenshot. Clicking the **Shutdown** button will open a pop-up window verifying
    the instance shutdown operation. Click the **Shut down all** button to proceed.
  id: totrans-619
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that this cleanup operation needs to be performed after using SageMaker
    Studio. These resources are not turned off automatically by SageMaker, even during
    periods of inactivity. Turning off unused resources and performing regular cleanup
    operations will help reduce and manage costs.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we should be comfortable using the **SageMaker Python SDK** when
    performing ML experiments in the AWS cloud. We are just scratching the surface
    here as SageMaker has a lot more capabilities and features, all of which we will
    discuss over the next few chapters.
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-622
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we trained and deployed ML models using the **SageMaker Python
    SDK**. We started by using the MNIST dataset (training dataset) and SageMaker’s
    built-in **Image Classification Algorithm** to train an image classifier model.
    After that, we took a closer look at the resources used during the training step
    by using the **Debugger Insights Dashboard** available in SageMaker Studio. Finally,
    we performed a second training experiment that made use of several features and
    options available in SageMaker, such as **managed spot training**, **checkpointing**,
    and **incremental training**.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive deeper into the different deployment options
    and strategies when performing model deployments using SageMaker. We will be deploying
    a pre-trained model into a variety of inference endpoint types, including the
    **real-time**, **serverless**, and **asynchronous** inference endpoints.
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-625
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on the topics that were covered in this chapter, feel
    free to check out the following resources:'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
- en: '*Amazon SageMaker Debugger* ([https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.xhtml))'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Use Checkpoints in Amazon SageMaker* ([https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.xhtml))'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Incremental Training in Amazon SageMaker* ([https://docs.aws.amazon.com/sagemaker/latest/dg/incremental-training.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/incremental-training.xhtml))'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Managed Spot Training in Amazon SageMaker* ([https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.xhtml))'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
