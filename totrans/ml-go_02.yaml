- en: Matrices, Probability, and Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although we will take a mostly practical/applied approach to machine learning
    throughout this book, certain fundamental topics are essential to understand and
    properly apply machine learning. In particular, a fundamental understanding of
    probability and statistics will allow us to match certain algorithms with relevant
    problems, understand our data and results, and apply necessary transformations
    to our data. Matrices and a little linear algebra will then allow us to properly
    represent our data and implement optimizations, minimizations, and matrix-based
    transformations.
  prefs: []
  type: TYPE_NORMAL
- en: Do not worry too much if you are a little rusty in math or statistics. We will
    cover a few of the basics here and show you how to programmatically work with
    the relevant statistical measures and matrix techniques that will be utilized
    later in the book. That being said, this is not a book on statistics, probability,
    and linear algebra. To truly be proficient in machine learning, one should take
    time to learn these subjects on a deeper level.
  prefs: []
  type: TYPE_NORMAL
- en: Matrices and vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you spend much time learning and applying machine learning, you will see
    a bunch of references to matrices and vectors. In fact, many machine learning
    algorithms boil down to a series of iterative operations on matrices. What are
    matrices and vectors, and how do we represent them in our Go programs?
  prefs: []
  type: TYPE_NORMAL
- en: For the most part, we will utilize packages from `github.com/gonum` to form
    and work with matrices and vectors. This is a great series of Go packages focused
    on numerical computing, and they just keep getting better and better.
  prefs: []
  type: TYPE_NORMAL
- en: Vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A vector is an ordered collection of numbers arranged in either a row (left
    to right) or column (up and down). Each of the numbers in a vector is called a
    component. This might be, for example, a collection of numbers that represents
    our company sales, or it might be a collection of numbers representing temperatures.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s, of course, natural for us to use Go slices to represent these ordered
    collections of data, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Slices are indeed ordered collections. However, they don''t really represent
    the concept of rows or columns, and we would still need to work out various vector
    operations on top of slices. Thankfully, on the vector operation side, gonum provides
    `gonum.org/v1/gonum/floats` to operate on slices of `float64` values and `gonum.org/v1/gonum/mat`,
    which, along with matrices, provides a `Vector` type (with corresponding methods):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Vector operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned here, working with vectors necessitates the use of certain vector-/matrix-specific
    operations and rules. For example, how do we multiply vectors together? How do
    we know if two vectors are similar? Both `gonum.org/v1/gonum/floats` and `gonum.org/v1/gonum/mat`
    provide built-in methods and functions for vector/slice operations, such as dot
    products, sorting, and distance. We won''t cover all of the functionality here,
    as there is quite a bit, but we can get a general feel for how we might work with
    vectors. First, we can work with `gonum.org/v1/gonum/floats` in the following
    way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also do similar operations with `gonum.org/v1/gonum/mat`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The semantics are similar in the two cases. If you are only working with vectors
    (not matrices), and/or you just need some lightweight and quick operations on
    slices of floats, then `gonum.org/v1/gonum/floats` is likely a good choice. However,
    if you are working with both matrices and vectors, and/or want access to a wider
    range of vector/matrix functionality, you are likely better off with `gonum.org/v1/gonum/mat`
    (along with occasional references to `gonum.org/v1/gonum/blas/blas64`).
  prefs: []
  type: TYPE_NORMAL
- en: Matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Matrices and linear algebra may seem complicated to many people, but simply
    put, matrices are just rectangular organizations of numbers, and linear algebra
    dictates the rules associated with their manipulation. For example, a matrix *A*
    with numbers arranged on a 4 x 3 rectangle may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c09508b-58b4-4c41-a8af-1ef689c8f4e1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The components of *A* (*a[11]*, *a[12]*, and so on) are the individual numbers
    that we are arranging into a matrix, and the subscripts indicate the location
    of the components within the matrix. The first index is the row index and the
    second index is the column index. More generally, *A* could have any shape/size
    with *M* rows and *N* columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a3c91fdb-9642-46a9-b5e2-7b20f017b80e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To form a matrix like this with `gonum.org/v1/gonum/mat`, we need to create
    a slice of `float64` values that is a flat representation of all the matrix components.
    For instance, in our example, we want to form the following matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bb87521a-251b-4b5a-bd63-b35efd6d4df8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We would need to create a slice of `float64` values as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can supply this, along with dimension information, to `gonum.org/v1/gonum/mat`
    to form a new `mat.Dense` matrix value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we have also used the nice formatting logic in `gonum.org/v1/gonum/mat`
    to print the matrix as a sanity check. When you run this, you should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then access and modify certain values within *A* via built-in methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Matrix operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with vectors, matrices have their own set of rules for arithmetic, along
    with a whole set of special operations. Some of the arithmetic associated with
    matrices behaves in a similar way to what you might expect. However, you need
    to take special care when doing things such as multiplying matrices together or
    taking an inverse.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conveniently, `gonum.org/v1/gonum/mat` provides a nice API for this arithmetic
    and many other special operations. Here is an example showing a few operations,
    such as adding, multiplying, dividing, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In particular, note the `Apply()` method above. This functionality is extremely
    useful as it allow you to apply any function to the elements of a matrix. You
    can apply the same function to all elements or make the function dependent on
    the indices of the matrix elements. For example, you could you this method to
    perform element-wise multiplications, applications of user defined functions,
    or applications of functions from third party packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, for all the various things, such as determinants, eigenvalue/vector solvers,
    and inverses, `gonum.org/v1/gonum/mat` has you covered. Again, I won''t expand
    on all of the functionality, but here is a sample of some of the operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note that in this example, we leverage Go's explicit error handling functionality
    when we need to ensure that we are maintaining integrity and readability. Matrices
    don't always have inverses. There are various situations like this that arise
    when working with matrices and large datasets, and we want to ensure that our
    application behaves as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the end of the day, the success of your machine learning application is going
    to come down to the quality of your data, your understanding of the data, and
    your evaluation/validation of the results. All three of these things require us
    to have an understanding of statistics.
  prefs: []
  type: TYPE_NORMAL
- en: The field of statistics helps us to gain an understanding of our data, and to
    quantify what our data and results look like. It also provides us with mechanisms
    to measure how well our application is performing and prevent certain machine
    learning pitfalls (such as overfitting).
  prefs: []
  type: TYPE_NORMAL
- en: As with linear algebra, we aren't able to give a complete introduction to statistics
    here, but there are many resources online and in print to learn introductory statistics.
    Here we will focus on a fundamental understanding of the basics, along with the
    practicalities of implementation in Go. We will introduce the idea of distributions,
    along with an introduction to quantifying and visualizing these distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A distribution is a representation of how often values appear within a dataset.
    Let's say, for instance, that one thing you are tracking as a data scientist is
    the daily sales of a certain product or service, and you have a long list (which
    you could represent as a vector or part of a matrix) of these daily sales numbers.
    These sales numbers are part of our dataset, and they include one day with sales
    of $121, another day with sales of $207, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'There will be one sales number that is the lowest out of the one we have accumulated.
    There will also be one sales number that is the highest out of the one we have
    accumulated, and the rest of the sales numbers that are somewhere in between (at
    least if we assume no exact duplicates). The following image represents these
    low, high, and in-between values of sales along a line:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15145fdc-66d2-468c-b2f8-2fe1fc9eabea.png)'
  prefs: []
  type: TYPE_IMG
- en: This is, thus, a distribution of sales, or at least one representation of the
    distribution of sales. Note that this distribution has areas where there are more
    numbers and areas where the numbers are a little sparse. Additionally, note that
    there seems to be a tendency for numbers to be near the center of the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical measures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To quantify what a distribution looks like, we will use various statistical
    measures. Generally, there are two types of these measures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Central tendency measures**: These measure where most of the values are located,
    or where the *center* of the distribution is located (for example, along the preceding
    linear representation).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Spread or dispersion measures**: These measure how the values of the distribution
    are spread across the distribution''s range (from the lowest value to the highest
    value).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are various packages that allow you to quickly calculate and/or utilize
    these statistical measures. We will make use of `gonum.org/v1/gonum/stat` (you
    are probably starting to notice that we will be making heavy use of gonum) and
    `github.com/montanaflynn/stats`.
  prefs: []
  type: TYPE_NORMAL
- en: Note, there is a one letter difference in the names of the `gonum.org/v1/gonum/stat`
    and `github.com/montanaflynn/stats` packages. Keep this in mind as you review
    the examples in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of central tendency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Measures of central tendency include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Mean`: This is what you might commonly refer to as an average. We calculate
    this by summing all of the numbers in the distribution and then dividing by the
    count of the numbers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Median`: If we sort all of the numbers in our distribution from the lowest
    to highest, this is the number that separates the lowest half of the numbers from
    the highest half of the numbers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Mode`: This is the most frequently occurring value in the distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s calculate these measures for the values in one column of the iris dataset
    previously introduced in [Chapter 1](4f556f8e-6876-48ca-9ac5-f897b733e23e.xhtml),
    *Gathering and Organizing Data*. As a reminder, this dataset included four columns
    of flower measurements, along with a column of the corresponding flower species.
    Thus, each of the measurement columns includes a bunch of values that represent
    a distribution of that measurement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this program results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the mean, mode, and median are all slightly different. However,
    note that the mean and median are very close for the values in the `sepal_length`
    column.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, if we change `sepal_length` to `petal_length` in the preceding
    code, we will get the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: For the `petal_length` values, the mean and median are not as close. We can
    already start to get some intuition about the data from this information. If the
    mean and median aren't close, this implies that high or low values are dragging
    the mean higher or lower, respectively--an influence that isn't as noticeable
    in the median. We call this a **skewed** **distribution**.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of spread or dispersion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have an idea about where most of our values are located (or the
    center of our distribution), let''s try to quantify how the values of our distribution
    are spread around the center of our distribution. Some of the widely used measures
    that quantify this are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Maximum**: The highest value of the distribution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minimum**: The lowest value of the distribution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Range**: The difference between the maximum and minimum'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variance**: This measure is calculated by taking each of the values in the
    distribution, calculating each one''s difference from the distribution''s mean,
    squaring this difference, adding it to the other squared differences, and dividing
    by the number of values in the distribution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard deviation**: The square root of the variance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quantiles/quartiles**: Similar to the median, these measures define cut-off
    points in the distribution where a certain number of lower values are below the
    measure and a certain number of higher values are above the measure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using `gonum.org/v1/gonum/stat`, the calculation of these measures looks as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this program gives the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Okay, let's try to get through these numbers and see what they imply about the
    distribution of values in the `sepal_length` column. We can deduce the following.
  prefs: []
  type: TYPE_NORMAL
- en: First, the standard deviation is `1.76` and the whole range of values is `5.90`.
    As opposed to the variance, the standard deviation has the same units as the values
    themselves, and thus we can see that the values actually vary quite a bit within
    the range of values (the standard deviation value is about 30% of the total range
    of values).
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's look at the quantiles. The 25% quantile represents a point in the
    distribution where 25% of the values in the distribution are below the measure
    and the other 75% are above. This is similar for the 50% and 75% quantiles. As
    the 25% quantile is much closer to the minimum than the distance between the 75%
    quantile and the maximum, we can deduce that the higher values in the distribution
    are likely more spread out than the lower values.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you can utilize any combination of these measures, along with the
    central tendency measures, to help you quantify how a distribution looks, and
    there are other statistical measures that can't be covered here.
  prefs: []
  type: TYPE_NORMAL
- en: The point here is that you should be making use of measures like these to help
    you build mental models of your data. This will allow you to put results in context
    and sanity-check your work.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though it is important to quantify how a distribution looks, we should
    actually visualize the distribution to gain the most intuition. There are various
    types of plots and graphs that allow us to create a visual representation of a
    distribution of values. These help us form a mental model of the data and communicate
    information about our data to other members of our team, users of our applications,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Histograms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first type of these graphs or charts that help us understand our distributions
    is called a **histogram**. Actually, a histogram is really a certain way of organizing
    or counting your values, which can then be plotted in a histogram plot. To form
    a histogram, we first create a certain number of bins, carving out different areas
    of the total range of our values. For example, take the distribution of sales
    numbers that we discussed in the previous sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bad47dc3-012f-43af-a67f-fb75d8e3913a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we count how many of our values are in each of these bins:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/39fcec2e-af90-4cff-bf18-a6cb10ac9113.png)'
  prefs: []
  type: TYPE_IMG
- en: 'These counts, along with the definition of the bins, form our histogram. We
    can then easily convert this to a plot of the counts, which provides a nice visual
    representation of our distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0c7f0414-810c-45cb-bf42-1d29b2923a7a.png)'
  prefs: []
  type: TYPE_IMG
- en: We can again use gonum to create a histogram from actual data and plot the histogram.
    The packages that gonum provides for this type of plotting, along with other types
    of plotting, can be found in `gonum.org/v1/plot`. As an example, let's create
    a histogram plot for each of the columns in the iris dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the following from gonum:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we will read in the iris dataset, create a dataframe, and look over the
    numerical columns generating the histogram plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note that we have normalized our histograms (with `h.Normalize()`). This is
    typical because often you will want to compare different distributions with different
    counts of values. Normalizing the histogram allows us to compare the different
    distributions side by side.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding code will generate four `*.png` files with the following histograms
    for the numerical columns in the iris dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ad2584e-4871-43cd-ae40-3f220b1b394c.png)'
  prefs: []
  type: TYPE_IMG
- en: Each of these distributions looks different from the others. The `sepal_width`
    distribution looks like a bell curve or normal/Gaussian distribution (which we
    will discuss later in the book). On the other hand, the petal distributions look
    like they have two different distinct clumps of values. We will make use of these
    observations later on when we are developing our machine learning workflows, but
    for now, just note how these visualizations are able to help us develop a mental
    model of our data.
  prefs: []
  type: TYPE_NORMAL
- en: Box plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Histograms are by no means the only way to visually gain an understanding of
    our data. Another commonly used type of plot is called a **box plot**. This type
    of plot also gives us an idea about the grouping and spread of values in a distribution,
    but, as opposed to the histogram, the box plot has several marked features that
    help guide our eyes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f966ccf5-2b63-4ec6-a01b-b7f5cc7b5fb6.png)'
  prefs: []
  type: TYPE_IMG
- en: Because the borders of the boxes in the box plots are defined by the median,
    **first quartile** (25% quantile/percentile), and **third quartile**, the same
    number of distribution values that are contained in the two central boxes. If
    one box is bigger than the other, it means that the distribution is skewed.
  prefs: []
  type: TYPE_NORMAL
- en: The box plots also include two tails or whiskers. These give us a quick visual
    indication of the range of the distribution as compared to the area that includes
    most of the values (the middle 50%).
  prefs: []
  type: TYPE_NORMAL
- en: 'To solidify this type of plot, let''s again create plots for the iris dataset.
    Similar to the histograms, we will use `gonum.org/v1/plot`. However, in this case,
    we will put all the box plots into the same `*.png`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f089ea36-f5fb-4abf-91e2-d30e895c8f71.png)'
  prefs: []
  type: TYPE_IMG
- en: As we observed in the histograms, the `sepal_length` column appears to be relatively
    symmetrical. On the other hand, `petal_length` appears to be much less symmetrical.
    Note also that gonum has included several outliers (marked as circles or dots)
    in the box plots. Many plotting packages include these. They indicate the values
    that are at least a certain distance away from the median of the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, we now understand a couple of ways to represent/manipulate our
    data (matrices and vectors), and we know how to gain and understanding about our
    data, and how to quantify how our data looks (statistics). However, sometimes
    when we are developing machine learning applications, we also want to know how
    likely it is that a prediction is correct or how significant certain results are,
    given a history of results. Probability can help us answer these *how likely*
    and *how significant* questions.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, probability has to do with the likelihood of events or observations.
    For example, if we are going to flip a coin to make a decision, how likely is
    it that we would see heads (50%), how likely is it that we would see tails (50%),
    or even how likely is it that the coin is a fair coin? This might seem like a
    trivial example, but many similar questions come up when doing machine learning.
    In fact, some machine learning algorithms are built on probabilistic rules and
    theorems.
  prefs: []
  type: TYPE_NORMAL
- en: Random variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's say that we have an experiment, like our scenario of flipping the coin,
    which could have multiple outcomes (heads or tails). Now let's define a variable
    whose value could be one of these outcomes. This variable is referred to as a
    **random variable**.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the coin toss (at least if we are considering a fair coin), each
    of the outcomes of the random variable is equally likely. That is, we have a 50%
    chance of seeing a heads outcome and a 50% chance of seeing a tails outcome. Yet,
    the various values of the random variable need not be equally likely. If we are
    trying to predict whether it will rain or not, those outcomes will not be equally
    likely.
  prefs: []
  type: TYPE_NORMAL
- en: Random variables allow us to define these how likely and how significant sort
    of questions that we mentioned earlier. They can have a finite number of outcomes
    and/or could represent ranges of continuous variables.
  prefs: []
  type: TYPE_NORMAL
- en: Probability measures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So how likely is it that we observe a specific outcome of an experiment? Well,
    to quantify the answer to this question, we introduce **probability measures**,
    which are often referred to as probabilities. They are represented by a number
    between 0 and 1 and/or by a percentage between 0% and 100%.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of flipping a fair coin, we have the following scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a 0.5 or 50% chance, or probability, of heads, where 0.5 or 50% is
    a probability measure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a 0.5 or 50% chance of tails
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability measures for a certain experiment must add up to 1 because when
    an event occurs, it has to correspond to one of the possible outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Independent and conditional probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two events (outcomes of experiments) are independent if the probability of one
    of the events in no way affects the probability of the other events. An example
    of independent events is the flipping of coins or the rolling of dice. On the
    other hand, dependent events are those events where the probability of one event
    influences the probability of another event. An example of dependent events is
    drawing cards from a deck of cards without replacement.
  prefs: []
  type: TYPE_NORMAL
- en: How can we quantify this second type of probability, which is commonly referred
    to as conditional probability? Symbolically, independent probabilities can be
    represented by *P(A)*, which is the probability of *A* (where *A* could represent
    flipping a coin, rolling a die, and so on). Then conditional probabilities are
    represented by *P(B|A)*, which is the probability of *A* given *B* (where *B*
    is another outcome).
  prefs: []
  type: TYPE_NORMAL
- en: 'To actually calculate a conditional probability, we can use the Bayes theorem/rule:
    *P(A|B) = P(B|A) P(A) / P(B)*. Sometimes you will see these terms defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(A|B)*: The *posterior*, because it is something we know about *A* after
    observing *B*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(A)*: The *prior*, because it is data we have about *A* before observing
    *B*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(B|A)*: The *likelihood*, because it is a measure of the compatibility of
    *B* with *A*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(B)*: The *evidence*, because it measures the probability of *B*, which we
    already know is true'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This theorem is the basis for various techniques that will be discussed later
    in the book, such as the naive the Bayes technique for classification.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can quantify *how likely* questions with probabilities and can even calculate
    conditional probabilities with Bayes theorem, but how can we quantify *how significant*
    questions that correspond to real-world observations? For example, we can quantify
    the probability of heads/tails with a fair coin, but how can we determine *how
    significant* it is when we flip a coin a bunch of times and observe 48% heads
    and 52% tails? Is this significant? Does it mean that we have an unfair coin?
  prefs: []
  type: TYPE_NORMAL
- en: 'These *how significant* questions can be answered using a process called hypothesis
    testing. This process generally includes the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Formulate a **null hypothesis**, referred to as *H[0]*, and an **alternate hypothesis**,
    referred to as *H[a]*. *H[0]* represents the scenario where what you observe (for
    example, 48% heads and 52% tails) is the result of pure chance, whereas *H[a]*
    represents the scenario where some type of underlying effect is causing significant
    deviation from pure chance (for example, an unfair coin). The null hypothesis
    is always assumed to be true.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine a **test statistic** that you will use to determine the validity of
    *H[0].*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine a **p-value**, which indicates the probability of observing a test
    statistic at least as significant as your test statistic assuming that *H[0]*
    is true. This p-value can be obtained from a probability distribution corresponding
    to the test statistic (often represented as a table or distribution function).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare your p-value with a predetermined threshold. If the p-value is less
    or equal to the predetermined threshold, *H[0]* is ruled out in favor of *H[a]*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This might seem rather abstract, but this process will intersect with your machine
    learning workflows at some point. For example, you may change one of your machine
    learning models that optimizes advertisements, and then you may want to quantify
    if an increase in sales is actually statistically significant. In another scenario,
    you may be analyzing logs representing possible fraudulent network traffic, and
    you might need to build a model that recognizes statistically significant deviations
    from expected network traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Note that you may also see certain hypothesis tests referred to as A/B tests,
    and, although the process listed here is common, it is by no means the only methodology
    for hypothesis testing. There are methods for Bayesian A/B testing, bandit algorithms
    for optimization, and more, which won't be covered in detail in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Test statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many different test statistics that can be used in hypothesis testing.
    These include the Z-statistic, T-statistic, F-statistic, and chi-square statistic.
    You can, of course, implement these measures from scratch in Go without too much
    trouble. However, there are also some pre-existing implementations that you can
    use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Returning to `gonum.org/v1/gonum/stat`, we can calculate a chi-square statistic
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Calculating p-values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s say that we have the following scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A survey of local residents reveals that 60% of all residents get no regular
    exercise, 25% exercise sporadically, and 15% exercise regularly. After doing some
    fancy modeling and putting some community services in place, the survey was repeated
    with the same questions. The follow up survey was completed by 500 residents with
    the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'No Regular Exercise: 260'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sporadic Exercise: 135'
  prefs: []
  type: TYPE_NORMAL
- en: 'Regular Exercise: 105'
  prefs: []
  type: TYPE_NORMAL
- en: 'Total: 500'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we want to determine if there is evidence for a statistically significant
    shift in the responses of the residents. Our null and alternate hypotheses are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*H[0]*: The deviations from the previously observed percentages are due to
    pure chance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*H[a]*: The deviations are due to some underlying effect outside of pure chance
    (possibly our new community services)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, let''s calculate our test statistic using the chi-square test statistic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give us the following value for chi-square:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to calculate the p-value corresponding to this `Chi-square`.
    This requires us to know information about the **chi-squared distribution**, which
    defines the p-values for certain measures of chi-square and certain **degrees
    of freedom**. `github.com/gonum/stat` also includes a representation of this chi-squared
    distribution from which we can calculate our `p-value`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: So, there is a 0.01% probability that the results we see in the deviations in
    the second version of the survey are purely due to chance. If we, for example,
    are using a threshold of 5% (which is common), we would need to reject the null
    hypothesis and adopt our alternative hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Vectors and matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gonum.org/v1/gonum/floats` docs: [https://godoc.org/gonum.org/v1/gonum/floats](https://godoc.org/gonum.org/v1/gonum/floats)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gonum.org/v1/gonum/mat` docs: [https://godoc.org/gonum.org/v1/gonum/mat](https://godoc.org/gonum.org/v1/gonum/mat)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gonum.org/v1/gonum/stat` docs: [https://godoc.org/gonum.org/v1/gonum/stat](https://godoc.org/gonum.org/v1/gonum/stat)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`github.com/montanaflynn/stats` docs: [https://godoc.org/github.com/montanaflynn/stats](https://godoc.org/github.com/montanaflynn/stats)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gonum.org/v1/plot` docs: [https://godoc.org/gonum.org/v1/plot](https://godoc.org/gonum.org/v1/plot)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gonum.org/v1/plot` wiki with examples: [https://github.com/gonum/plot/wiki/Example-plots](https://github.com/gonum/plot/wiki/Example-plots)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gonum.org/v1/gonum/stat/distuv` docs: [https://godoc.org/gonum.org/v1/gonum/stat/distuv](https://godoc.org/gonum.org/v1/gonum/stat/distuv)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This introduction to matrices, linear algebra, statistics, and probability in
    Go has given us a set of tools to understand, structure, and operate on data.
    This set of tools will be used throughout the book as we work on a diverse set
    of problems, and these tools could be used in a variety of contexts outside of
    machine learning. However, in the next chapter, we will discuss some ideas and
    techniques that will be extremely important in the machine learning context, specifically,
    evaluation and validation.
  prefs: []
  type: TYPE_NORMAL
