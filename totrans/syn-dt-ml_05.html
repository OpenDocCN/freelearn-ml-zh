<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer036">
<h1 class="chapter-number" id="_idParaDest-80"><a id="_idTextAnchor083"/>5</h1>
<h1 id="_idParaDest-81"><a id="_idTextAnchor084"/>Synthetic Data as a Solution</h1>
<p>This chapter highlights the main advantages of synthetic data. You will learn why synthetic data is a promising solution for privacy issues. At the same time, you will understand how synthetic data generation approaches can be configured to cover rare scenarios that are extremely difficult and expensive to capture in the <span class="No-Break">real world.</span></p>
<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>Synthetic data <span class="No-Break">generation methods</span></li>
<li>The main advantages of <span class="No-Break">synthetic data</span></li>
<li>Synthetic data as a revolutionary solution for <span class="No-Break">privacy issues</span></li>
<li>Synthetic data as a revolutionary solution for cost and time <span class="No-Break">efficiency issues</span></li>
<li>Synthetic data as a revolutionary solution for <span class="No-Break">rare data</span></li>
</ul>
<h1 id="_idParaDest-82"><a id="_idTextAnchor085"/>The main advantages of synthetic data</h1>
<p>As <a id="_idIndexMarker184"/>we have seen so far, synthetic<a id="_idIndexMarker185"/> data has a wide set of applications because of its enormous advantages. Let’s highlight some of <span class="No-Break">these advantages:</span></p>
<ul>
<li><span class="No-Break">Unbiased</span></li>
<li><span class="No-Break">Diversity</span></li>
<li><span class="No-Break">Data controllability</span></li>
<li><span class="No-Break">Scalable</span></li>
<li>Automatic <span class="No-Break">data generation</span></li>
<li>Automatic <span class="No-Break">data labeling</span></li>
<li><span class="No-Break">Annotation quality</span></li>
<li><span class="No-Break">Low </span><span class="No-Break"><a id="_idIndexMarker186"/></span><span class="No-Break">cost</span></li>
</ul>
<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.1</em> highlights some of the <span class="No-Break">key benefits:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer033">
<img alt="Figure 5.1 – The main advantages of synthetic data" height="527" src="image/Figure_05_01_B18494.jpg" width="546"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – The main advantages of synthetic data</p>
<p>Next, we will <a id="_idIndexMarker187"/>delve into each of these advantages. We will see the limitations of real data and how synthetic data is <span class="No-Break">a solution.</span></p>
<h2 id="_idParaDest-83"><a id="_idTextAnchor086"/>Unbiased</h2>
<p>Real data is curated and <a id="_idIndexMarker188"/>annotated by human annotators. In practice, it is easy for humans, intentionally or accidentally, to neglect or overemphasize certain groups in the population based on some attributes, such as ethnicity, skin color, gender, age, or political views. This creates a biased dataset that negatively affects both training and testing ML models since biased training data gives a corrupted representation of the studied phenomenon or processes that occur in the real world. As a consequence, the ML model will be biased in its decisions. This bias may lead to race, sex, or age discrimination, which causes tremendous unwanted consequences on companies’ reputations, customers, <span class="No-Break">and revenue.</span></p>
<p>Let’s discuss one example in NLP. Researchers in the paper titled <em class="italic">The risk of racial bias in hate speech detection</em> (<a href="https://aclanthology.org/P19-1163.pdf">https://aclanthology.org/P19-1163.pdf</a>) demonstrated that tweets by African Americans are two times more likely to be flagged as offensive by automatic hate speech detection ML models. They link the reason to biased training data because of <span class="No-Break">annotators’ bias.</span></p>
<p>Another example comes from computer vision with racial discrimination in face recognition ML algorithms. Face recognition ML models developed by Microsoft, IBM, and Amazon were shown to be less accurate at predicting certain genders and skin colors. These ML models were specifically identified to be less accurate at predicting darker female faces. Some of the largest tech companies in the world, such as Microsoft and IBM, proposed immediate actions to improve their data collection process to mitigate the bias problem in their ML models. Please refer to <em class="italic">Racial Discrimination in Face Recognition Technology</em> (<a href="https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology">https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology</a>) for a thorough discussion and <span class="No-Break">more details.</span></p>
<p>As you might <a id="_idIndexMarker189"/>expect, synthetic data can be automatically generated and annotated. Thus, the error by human element factor can be<a id="_idIndexMarker190"/> removed or minimized in data generation and annotation processes. Therefore, fewer human errors are expected with synthetic data. At the same time, data can be generated so that it’s evenly distributed over the population. Thus, unbiased training and testing data can be generated to support various applications and scenarios. Additionally, in the case of any issues with dataset bias, synthetic data generation approaches can easily be reconfigured to address these problems, which is much faster compared to <span class="No-Break">real data.</span></p>
<h2 id="_idParaDest-84"><a id="_idTextAnchor087"/>Diverse</h2>
<p>The <a id="_idIndexMarker191"/>process of generating synthetic data can be customized to cover rare cases and scenarios that are not frequent, not easy to capture, or too expensive to annotate. Although it is possible to curate and annotate a diverse real dataset, it is extremely hard to achieve and requires more effort, time, and budget. For instance, capturing real data under adverse weather conditions is harder compared to normal weather. At the same time, capturing data is extremely hard during natural disasters and catastrophes, such as earthquakes, wildfires, hurricanes, tornados, and volcanoes. This limits the usability of ML models under similar scenarios. Therefore, <strong class="bold">Life-Critical Systems</strong> or <strong class="bold">Safety-Critical Systems</strong> (<strong class="bold">SCSs</strong>) that are based on ML models may fail or <a id="_idIndexMarker192"/>malfunction under these scenarios. This failure may cause death, injuries, damage<a id="_idIndexMarker193"/> to equipment, and harm to the environment. In addition to this, there are instances where certain events occur frequently, yet they are challenging to capture, such as burglary, sexual exploitation of children, domestic abuse, scams and fraud, street harassment, <span class="No-Break">and terrorism.</span></p>
<p>Synthetic <a id="_idIndexMarker194"/>data generation techniques such as statistical models or simulators can be designed or configured to cover all these scenarios. Thus, it makes the ML models more robust against similar scenarios, which saves lives and properties and also protects societies. Additionally, it opens the door for researchers to focus specifically on rare conditions, events, and scenarios. As a result, diverse and balanced synthetic datasets can be generated to advance research in various fields. At the same time, synthetic data can augment the available real datasets so that they become more diverse <span class="No-Break">and well-balanced.</span></p>
<h2 id="_idParaDest-85"><a id="_idTextAnchor088"/>Controllable</h2>
<p>Nature <a id="_idIndexMarker195"/>and its entangled processes and phenomena <a id="_idIndexMarker196"/>generate real data. For example, you can collect images of human faces to train a face recognition algorithm, but you will have no control over the data generation process itself. You may choose to consider or neglect certain attributes but you cannot perturb the process of how a human face may look in the real world! You can use filters or any image processing technique you want but still, you are only changing how you perceive these images. In other words, you do not make the world desaturated when you wear sunglasses: you only perceive the world as being darker with reduced color saturation. These are two completely <span class="No-Break">different ideas!</span></p>
<p>Synthetic data allows you to change the world itself as you want. For instance, you can create a city where all people wear the same clothes, walk the same way, and hold the same items! A good question you may ask here is, <em class="italic">why would ML researchers or practitioners want to do this in the </em><span class="No-Break"><em class="italic">first place?</em></span></p>
<p>Being able to control the process of synthetic data generation is extremely important in the field of ML. It allows you to train and test your model on extremely rare conditions, analyze the algorithm’s robustness and accuracy, and reiterate the assumptions, the ML model’s design, and the training data. Synthetic data gives you the ability to control the parameters of the environment, the elements, and their interactions with each other. Consequently, there is no need to generate irrelevant or redundant data that does not help your ML<a id="_idIndexMarker197"/> model. Thus, with synthetic data, you can manage, control, and guide the data generation and annotation processes to achieve <span class="No-Break">your objectives.</span></p>
<h2 id="_idParaDest-86"><a id="_idTextAnchor089"/>Scalable</h2>
<p>ML models <a id="_idIndexMarker198"/>are integral to a tremendous number of industries, including the automotive, healthcare, financial, and entertainment<a id="_idIndexMarker199"/> industries. The need for more accurate and robust ML models drives researchers to propose deeper and more complex ML models. These deep models are usually composed of more layers and thus more neurons. This means a huge number of parameters to tune in the training process. Consequently, ML models need more training data as these industries evolve (see <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">):</span></p>
<div>
<div class="IMG---Figure" id="_idContainer034">
<img alt="Figure 5.2 – To increase profitability, companies require precise and complex ML models, which necessitates larger amounts of training data" height="436" src="image/Figure_05_02_B18494.jpg" width="910"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – To increase profitability, companies require precise and complex ML models, which necessitates larger amounts of training data</p>
<p>Unfortunately, the process of collecting, cleaning, and annotating real data is extremely slow and expensive. Companies need to respond to market changes swiftly; otherwise, they may lose customers, reputation, <span class="No-Break">and opportunities.</span></p>
<p>Synthetic data is perfectly scalable: once the data generation and annotation pipelines have been configured, it is easy to generate large-scale datasets under new conditions as necessary. For example, you <a id="_idIndexMarker200"/>can generate an unlimited number of training images using <strong class="bold">Generative Adversarial Networks</strong> (<strong class="bold">GANs</strong>), <strong class="bold">Variational Autoencoders</strong> (<strong class="bold">VAEs</strong>), or <a id="_idIndexMarker201"/>simulators such<a id="_idIndexMarker202"/> as <span class="No-Break"><strong class="bold">CARLA</strong></span><span class="No-Break"> (</span><a href="https://carla.org/"><span class="No-Break">https://carla.org/</span></a><span class="No-Break">).</span></p>
<h2 id="_idParaDest-87"><a id="_idTextAnchor090"/>Automatic data labeling</h2>
<p>One of the<a id="_idIndexMarker203"/> main advantages of synthetic<a id="_idIndexMarker204"/> data is automatic data labeling. Since the data generation process is controlled, automatic data labeling is possible with synthetic data. For example, if you utilize a game engine such <a id="_idIndexMarker205"/>as <strong class="bold">Unreal</strong> or <strong class="bold">Unity</strong> to generate and label synthetic data, it is possible to tag objects and thus to <a id="_idIndexMarker206"/>know exactly which objects are seen by your camera at a <span class="No-Break">given frame.</span></p>
<p>This is the benefit of synthetic data! It saves you extensive time, effort, and money that you need to spend on annotating real data. Moreover, you can annotate private or confidential data without being worried about annotators disclosing <span class="No-Break">sensitive information.</span></p>
<h2 id="_idParaDest-88"><a id="_idTextAnchor091"/>Annotation quality</h2>
<p>Synthetic <a id="_idIndexMarker207"/>data is automatically annotated, unlike real data. Human factor errors are minimized and limited. Thus, annotating high-quality and large-scale synthetic datasets is possible. For example, synthetic data algorithms can provide, to the pixel level, accurate ground truth for semantic segmentation, which is impossible to achieve with real data due to the limitations of human annotators. In many situations, there is a trade-off between quality and quantity when working with real data. Using synthetic data, you can achieve both objectives with less time and a <span class="No-Break">lower budget.</span></p>
<h2 id="_idParaDest-89"><a id="_idTextAnchor092"/>Low cost</h2>
<p>Synthetic data, as<a id="_idIndexMarker208"/> we have mentioned, does not require you to capture data from the real world and it does not need annotators to annotate it. Synthetic data can be generated and automatically annotated using the appropriate algorithms. Thus, after developing the generation and annotation pipelines, it is possible to generate an unlimited number of training examples. For example, generating a training dataset of a thousand images and generating a training dataset of a million <a id="_idIndexMarker209"/>images would <a id="_idIndexMarker210"/>cost almost the <span class="No-Break">same amount!</span></p>
<p>In the next section, we will look at a particular benefit of synthetic data – that is, using it to solve privacy issues with sensitive data <span class="No-Break">and applications.</span></p>
<h1 id="_idParaDest-90"><a id="_idTextAnchor093"/>Solving privacy issues with synthetic data</h1>
<p>In certain fields, such as <a id="_idIndexMarker211"/>healthcare and finance, a lot of data is available, but the main obstacle is annotating and sharing the data. Even if we have a large-scale real dataset that is “perfectly” annotated, sometimes, we cannot share it with ML practitioners because it contains sensitive information that could be used by a third party to identify individuals or reveal critical information about businesses <span class="No-Break">and organizations.</span></p>
<p>As we know, ML models cannot work without data, so what is the solution? A simple solution is to use the <em class="italic">real</em> data to generate <em class="italic">synthetic</em> data that we can share with others without any privacy issues while still representing the real data. We can utilize some synthetic data generation approaches to leverage the real dataset to generate a synthetic dataset that still represents the relationship between variables, hidden patterns, and associations in the real data while not revealing <span class="No-Break">sensitive information:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer035">
<img alt="Figure 5.3 – Some synthetic dataset generation approaches disentangle sensitive information from data patterns" height="451" src="image/Figure_05_03_B18494.jpg" width="471"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – Some synthetic dataset generation approaches disentangle sensitive information from data patterns</p>
<p>In this scope, we can <a id="_idIndexMarker212"/>understand that synthetic data generation approaches disentangle sensitive information from the associations and relationships between the variables (see <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.3</em>). Thus, ML models can still be trained on the synthetic data and learn the hidden patterns in the original real data without being directly trained <span class="No-Break">on it.</span></p>
<p>Synthetic data does not contain information about real individuals, so no harm is caused. For example, let’s assume you have a synthetic dataset of human faces. It is fine to use this data as you want. Additionally, you would not be restricted by regulations as you would if you were using real human faces. This would allow you to explore novel creative ideas. However, if you were going to use sensitive information from real humans, you would be limited to the main purpose you used to collect the data for. Thus, you cannot investigate new ideas without permission from the people who participated. Additionally, data should not be kept longer than necessary. All of these regulations limit the usability of sensitive real datasets, which makes synthetic ones a perfect alternative. For more information, please check out <em class="italic">The Data Protection Act 2018</em>, which is the <a id="_idIndexMarker213"/>UK’s<a id="_idIndexMarker214"/> implementation of the <strong class="bold">General Data Protection Regulation</strong> (<span class="No-Break"><strong class="bold">GDPR</strong></span><span class="No-Break">)</span><span class="No-Break"><em class="italic"> </em></span><span class="No-Break">(</span><a href="https://www.gov.uk/data-protection"><span class="No-Break">https://www.gov.uk/data-protection</span></a><span class="No-Break">).</span></p>
<p>In the next section, we will discuss why synthetic data is the solution for cost and time-efficiency issues in data generation <span class="No-Break">and annotation.</span></p>
<h1 id="_idParaDest-91"><a id="_idTextAnchor094"/>Using synthetic data to solve time and efficiency issues</h1>
<p>Automatic data<a id="_idIndexMarker215"/> generation of synthetic data removes many unnecessary elements in the real data curation and annotation pipeline. Collecting real data often requires special equipment, such as high-resolution cameras, microphones, or LiDAR. At the same time, you need engineers and technicians who are trained to use such equipment. You lose time and money training engineers and buying or renting this equipment. Often, data curators need to travel and visit various locations to collect suitable data, meaning that you would have to pay for transportation, accommodation, insurance, <span class="No-Break">and more.</span></p>
<p>Synthetic data is an effective solution for these issues (see <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.4</em>). In addition to the preceding issues, it is easy to conclude that synthetic data has a lower carbon footprint than real data. Thus, it is even better for <span class="No-Break">the environment!</span></p>
<p>Data annotation is one of the main issues that makes real datasets cumbersome. Annotating large-scale datasets is an extremely expensive and time-consuming process. Annotating a large-scale dataset can take weeks, months, or even years. The huge amount of time it takes to fulfill the annotation process may make companies fall behind their competitors, causing them to lose market share <span class="No-Break">and customers.</span></p>
<p>It becomes even worse if you are working with real sensitive data. By law, it is mandatory to take extra care when it comes to storing, processing, annotating, or transferring this type of data. This means more budget, effort, and time to spend. However, using synthetic data removes all of this extra work and eases <span class="No-Break">your workload:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-2">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break">Real Data</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Synthetic Data</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Recording/Capturing Equipment</span></p>
</td>
<td class="No-Table-Style">
<p>↑</p>
</td>
<td class="No-Table-Style">
<p>↓</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Transportation/Accommodation</span></p>
</td>
<td class="No-Table-Style">
<p>↑</p>
</td>
<td class="No-Table-Style">
<p>↓</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Training</span></p>
</td>
<td class="No-Table-Style">
<p>↑</p>
</td>
<td class="No-Table-Style">
<p>↓</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Insurance</span></p>
</td>
<td class="No-Table-Style">
<p>↑</p>
</td>
<td class="No-Table-Style">
<p>↓</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Time</span></p>
</td>
<td class="No-Table-Style">
<p>↑</p>
</td>
<td class="No-Table-Style">
<p>↓</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Regulations</span></p>
</td>
<td class="No-Table-Style">
<p>↑</p>
</td>
<td class="No-Table-Style">
<p>↓</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style" colspan="3">
<p>↑ You need more and ↓ you <span class="No-Break">need less</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Comparison between synthetic and real data</p>
<p>In the next section, we will understand why synthetic data can cover rare and special scenarios compared to <span class="No-Break">real data.</span></p>
<h1 id="_idParaDest-92"><a id="_idTextAnchor095"/>Synthetic data as a revolutionary solution for rare data</h1>
<p>Rare data occurs in the real<a id="_idIndexMarker216"/> world because of infrequent events or phenomena. In other words, these events occur but with low frequency. We can broadly classify these events into <span class="No-Break">these categories:</span></p>
<ul>
<li><strong class="bold">Natural catastrophes</strong>: This category<a id="_idIndexMarker217"/> includes events such as floods, asteroid impacts, earthquakes, <span class="No-Break">and tsunamis</span></li>
<li><strong class="bold">Anthropogenic</strong>: This <a id="_idIndexMarker218"/>category includes events such as industrial accidents, financial crises, and <span class="No-Break">violent conflicts</span></li>
</ul>
<p>These events create many major changes in the environment, which may cause state-of-the-art ML models to fail. For example, a face recognition system may not work well in the case of the evacuation of a building because as the building becomes more crowded, movement patterns may change. While these events are rare, their impacts on societies are tremendous. ML models that function inappropriately may greatly increase the number of deaths <span class="No-Break">and injuries.</span></p>
<p>For ML models to be robust and accurate, these models need to be trained and tested on both standard and rare conditions. Capturing real data of rare events is extremely hard and expensive. Most ML models assume that they will work under standard conditions and scenarios. Unfortunately, these ML models generally fail or struggle under any scenarios that deviate from the standard ones. For instance, in <em class="italic">Semantic Segmentation under Adverse Conditions: A Weather and Nighttime-aware Synthetic Data-based Approach</em> (<a href="https://bmvc2022.mpi-inf.mpg.de/0977.pdf">https://bmvc2022.mpi-inf.mpg.de/0977.pdf</a>), researchers demonstrated that state-of-the-art semantic segmentation methods perform well under standard conditions, such as normal weather conditions and sufficient illumination. However, these methods struggle or fail under adverse conditions, such as foggy, rainy, and snowy weather conditions or <span class="No-Break">at nighttime.</span></p>
<p>The key reason for neglecting rare scenarios is the fact that collecting training data under these circumstances may take a long time, a lot of training and effort is required to capture these rare events, and it can be a dangerous process. Finally, we should note that rare data is not just useful for training purposes – it is essential for understanding the limitations of<a id="_idIndexMarker219"/> ML models <span class="No-Break">in practice.</span></p>
<p>As mentioned previously, real data is not balanced in the real world. Thus, the data that we collect from the real world will reflect this imbalance. Unfortunately, ML models are sensitive to imbalanced datasets. Thus, imbalanced training datasets cause ML models to develop a corrupted understanding of the problem. For example, if we train a cats-dogs classifier on a dataset that includes 30 cats and 70 dogs, the model will tend to predict dogs twice as often as it predicts cats. Thus, balanced training datasets make the models train better and <span class="No-Break">converge faster.</span></p>
<p>Standard conditions, events, and attributes are more likely to occur in the real world than rare events. Thus, you are more likely to have a dataset that specifically focuses on normal conditions and neglects <span class="No-Break">rare ones.</span></p>
<p>As you might expect, synthetic data can be used to simulate these rare events. Thus, generating a perfectly balanced large-scale dataset is easy to achieve with synthetic data. Synthetic data generation methods may be used to generate a full training dataset from scratch. At the same time, synthetic data can be utilized to complement real datasets. Thus, you can<a id="_idIndexMarker220"/> make your ML models more robust against rare events <span class="No-Break">and conditions.</span></p>
<h1 id="_idParaDest-93"><a id="_idTextAnchor096"/>Synthetic data generation methods</h1>
<p>There are different<a id="_idIndexMarker221"/> methods to generate synthetic data: some of them are based on statistical models and others rely on game engines and simulators. <em class="italic">Statistical models</em> are non-deterministic mathematical models that include variables represented as probability distributions. Based on the problem, these models are usually trained using real data to understand the hidden patterns and correlations in the data. Then, the trained ML model can be used to generate new samples automatically, such as images, text, tables, and more. These new samples can be utilized by other ML models for training or <span class="No-Break">testing purposes.</span></p>
<p>Synthetic data can also be generated using <em class="italic">game engines and simulators</em>. These tools are utilized to create 3D virtual worlds. These 3D worlds can be generated using <strong class="bold">Procedural Content Generation</strong> (<strong class="bold">PCG</strong>) techniques<a id="_idIndexMarker222"/> to control scene attributes, the interaction between scene elements, and the diversity and quality of the <span class="No-Break">generated data.</span></p>
<p>It is important to note that the main challenge for most synthetic data generation approaches is building a data generation and annotation pipeline, which requires careful design and engineering. However, once the pipeline is ready, it is usually simple to use and can be utilized for an enormous range <span class="No-Break">of applications.</span></p>
<h1 id="_idParaDest-94"><a id="_idTextAnchor097"/>Summary</h1>
<p>In this chapter, we learned about the main advantages of using synthetic data. We discussed that synthetic data is easy to generate, manage, and annotate. When it comes to privacy issues that we have with sensitive real data, utilizing synthetic data is an <span class="No-Break">ideal solution.</span></p>
<p>In the next chapter, we will learn how to utilize simulators and rendering engines to generate <span class="No-Break">synthetic data.</span></p>
</div>
</div>

<div id="sbo-rt-content"><div class="Content" id="_idContainer037">
<h1 id="_idParaDest-95" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor098"/>Part 3:Synthetic Data Generation Approaches</h1>
<p>In this part, you will be introduced to the main synthetic data generation approaches. You will learn how to leverage simulators and rendering engines, <strong class="bold">Generative Adversarial Networks</strong> (<strong class="bold">GANs</strong>), video games, and diffusion models to generate synthetic data. You will explore the potential of these approaches in ML. Moreover, you will understand the challenges and pros and cons of each method. This part will be supported with hands-on practical examples to learn how to generate and utilize synthetic data <span class="No-Break">in practice.</span></p>
<p>This part has the <span class="No-Break">following chapters:</span></p>
<ul>
<li><a href="B18494_06.xhtml#_idTextAnchor099"><em class="italic">Chapter 6</em></a>, <em class="italic">Leveraging Simulators and Rendering Engines to Generate Synthetic Data</em></li>
<li><a href="B18494_07.xhtml#_idTextAnchor120"><em class="italic">Chapter 7</em></a>, <em class="italic">Exploring Generative Adversarial Networks</em></li>
<li><a href="B18494_08.xhtml#_idTextAnchor138"><em class="italic">Chapter 8</em></a>, <em class="italic">Video Games as a Source of Synthetic Data</em></li>
<li><a href="B18494_09.xhtml#_idTextAnchor154"><em class="italic">Chapter 9</em></a>, <em class="italic">Exploring Diffusion Models for Synthetic Data</em></li>
</ul>
</div>
<div>
<div id="_idContainer038">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer039">
</div>
</div>
</div></body></html>