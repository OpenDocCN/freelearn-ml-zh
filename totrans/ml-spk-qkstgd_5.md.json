["```py\nmri_healthy_brain_image = io.imread(\n   'chapter05/data/mri-images-data/mri-healthy-brain.png')\nmri_healthy_brain_image_plot = plt.imshow(\n   mri_healthy_brain_image, cmap='gray')\n\n```", "```py\nmri_healthy_brain_matrix = img_as_float(mri_healthy_brain_image)\n```", "```py\nmri_healthy_brain_2d_array = np.array(mri_healthy_brain_matrix)\n   .astype(float)\nmri_healthy_brain_1d_array = mri_healthy_brain_2d_array.ravel()\nmri_healthy_brain_vector = np.matrix(mri_healthy_brain_1d_array)\n```", "```py\nmri_healthy_brain_vector_transposed = mri_healthy_brain_vector\n   .reshape(mri_healthy_brain_vector.shape[1], \n   mri_healthy_brain_vector.shape[0])\nmri_healthy_brain_df = sqlContext.createDataFrame(\n   pd.DataFrame(mri_healthy_brain_vector_transposed,\n   columns = ['pixel_intensity']))\n```", "```py\nfeature_columns = ['pixel_intensity']\nvector_assembler = VectorAssembler(inputCols = feature_columns,\n   outputCol = 'features')\nmri_healthy_brain_features_df = vector_assembler\n   .transform(mri_healthy_brain_df).select('features')\n```", "```py\ncost = np.zeros(20)\nfor k in range(2, 20):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    model = kmeans.fit(mri_healthy_brain_features_df\n       .sample(False, 0.1, seed=12345))\n    cost[k] = model.computeCost(mri_healthy_brain_features_df)\n\nfig, ax = plt.subplots(1, 1, figsize =(8, 6))\nax.plot(range(2, 20),cost[2:20])\nax.set_title('Optimal Number of Clusters K based on the\n   K-Means Cost Function for a range of K')\nax.set_xlabel('Number of Clusters K')\nax.set_ylabel('K-Means Cost')\n```", "```py\nk = 5\nkmeans = KMeans().setK(k).setSeed(12345).setFeaturesCol(\"features\")\nkmeans_model = kmeans.fit(mri_healthy_brain_features_df)\nkmeans_centers = kmeans_model.clusterCenters()\nprint(\"Healthy MRI Scan - K-Means Cluster Centers: \\n\")\nfor center in kmeans_centers:\n    print(center)\n```", "```py\nmri_healthy_brain_clusters_df = kmeans_model\n   .transform(mri_healthy_brain_features_df)\n   .select('features', 'prediction')\nmri_healthy_brain_clusters_matrix = mri_healthy_brain_clusters_df\n   .select(\"prediction\").toPandas().values\n   .reshape(mri_healthy_brain_matrix.shape[0],\n      mri_healthy_brain_matrix.shape[1])\nplt.imshow(mri_healthy_brain_clusters_matrix)\n```", "```py\nmri_test_brain_image = io.imread(\n   'chapter05/data/mri-images-data/mri-test-brain.png')\n```", "```py\nmri_test_brain_df = sqlContext\n   .createDataFrame(pd.DataFrame(mri_test_brain_vector_transposed,\n   columns = ['pixel_intensity']))\nmri_test_brain_features_df = vector_assembler\n   .transform(mri_test_brain_df)\n   .select('features')\nmri_test_brain_clusters_df = kmeans_model\n   .transform(mri_test_brain_features_df)\n   .select('features', 'prediction')\nmri_test_brain_clusters_matrix = mri_test_brain_clusters_df\n   .select(\"prediction\").toPandas().values.reshape(\n   mri_test_brain_matrix.shape[0], mri_test_brain_matrix.shape[1])\nplt.imshow(mri_test_brain_clusters_matrix)\n```", "```py\nuser_movie_ratings_df = sqlContext.read\n   .format('com.databricks.spark.csv').options(header = 'true', \n   inferschema = 'true', delimiter = '|')\n   .load('<Path to CSV File>')\nprint((user_movie_ratings_df.count(),\n   len(user_movie_ratings_df.columns)))\n```", "```py\nfeature_columns = user_movie_ratings_df.columns\nfeature_columns.remove('userId')\nvector_assembler = VectorAssembler(inputCols = feature_columns,\n   outputCol = 'features')\nuser_movie_ratings_features_df = vector_assembler\n   .transform(user_movie_ratings_df)\n   .select(['userId', 'features']) \n```", "```py\nstandardizer = StandardScaler(withMean=True, withStd=True,\n   inputCol='features', outputCol='std_features')\nstandardizer_model = standardizer\n   .fit(user_movie_ratings_features_df)\nuser_movie_ratings_standardized_features_df =\n   standardizer_model.transform(user_movie_ratings_features_df) \n```", "```py\nscaled_features_rows_rdd = \n   user_movie_ratings_standardized_features_df\n   .select(\"std_features\").rdd\nscaled_features_matrix = RowMatrix(scaled_features_rows_rdd\n   .map(lambda x: x[0].tolist()))\n```", "```py\nnumber_principal_components = 300\nprincipal_components = scaled_features_matrix\n   .computePrincipalComponents(number_principal_components)\n```", "```py\nprojected_matrix = scaled_features_matrix\n   .multiply(principal_components)\nprint((projected_matrix.numRows(), projected_matrix.numCols()))\n```", "```py\npca = PCA(k=number_principal_components, inputCol=\"std_features\",\n   outputCol=\"pca_features\")\npca_model = pca.fit(user_movie_ratings_standardized_features_df)\nuser_movie_ratings_pca_df = pca_model\n   .transform(user_movie_ratings_standardized_features_df) \n```", "```py\npca_model.explainedVariance\n```"]