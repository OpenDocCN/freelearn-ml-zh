- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying and Monitoring Machine Learning Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we learned a lot about different models and techniques.
    Understanding the concepts and building a machine learning model is only the beginning
    of the journey toward realizing its true value. The successful deployment and
    ongoing monitoring of these models are crucial to ensuring their effectiveness
    and reliability in real-world scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring that a model performs optimally, seamlessly integrates with existing
    systems, and adapts to evolving requirements requires a comprehensive understanding
    of the deployment process and the associated considerations. In the context of
    the Qlik platform, most of the typical pain points are handled by the platform
    itself and the design of the components, but there are still things we have to
    bear in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Once a machine learning model is deployed, it is vital to continuously monitor
    its performance to identify potential issues, maintain accuracy, and safeguard
    against unforeseen failures. Monitoring provides insights into the model’s behavior,
    helps detect data drift or concept drift, and facilitates the identification of
    performance degradation over time. By proactively monitoring and analyzing key
    metrics, organizations can make informed decisions regarding model maintenance,
    retraining, and updates as required to ensure reliable and up-to-date predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will get familiar with the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a model in an on-premises environment using Advanced Analytics Integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and debugging models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter focuses on on-premises environments. We will see how to deploy
    and monitor models using Qlik AutoML in our next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Building a model in an on-premises environment using the Advanced Analytics
    connection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 5*](B19863_05.xhtml#_idTextAnchor071), we prepared an environment
    for R and Python using the Advanced Analytics connection with Qlik. In this chapter,
    we are going to utilize this same environment. This exercise will use R specifically.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, there are two ways to utilize the Advanced Analytics connection
    with Qlik applications. These are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Live connection**: A live connection interacts with the third-party machine
    learning environment from the user interface while the user interacts with the
    application. A live connection enables *what-if* scenarios, simulations, and similar
    use cases. It is best for light models that do not require extensive training.
    The idea behind live connections is explained in the following diagram:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.1: Advanced Analytics connection](img/B19863_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: Advanced Analytics connection'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load time connection**: A load time connection is a one-time prediction model
    run that takes place when a Qlik load script is executed. When the Advanced Analytics
    connection is utilized during load time, the results are saved into a table in
    the Qlik data model. These results can be then utilized when creating an application.
    A load time connection is suitable for use cases that only require one predicted
    value. For example, if we are predicting the future value of the sales of a product
    and would like to save the prediction in the data model for later analysis, a
    load time connection is used. It is also good for models that require extensive
    training. It is possible to combine a live connection with a load time connection
    to predict some values when data is loaded and utilize scenario analysis interactively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'A prepared model can be saved and reused during load time or in live mode.
    This way we can save some time during deployment if the parameters of a model
    haven’t changed and it is known to have performed well previously. To save a model
    in R, for example, we can use the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `saveRDS()` and `readRDS()` functions: This method allows you to
    save any R object, including machine learning models, to a file using the `saveRDS()`
    function and reload it using `readRDS()`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `save()` and `load()` functions: The `save()` function allows you
    to save multiple R objects, including models, to a file in binary format, which
    can be loaded using the `load()` function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using specific package functions: Some machine learning packages in R provide
    their own dedicated functions for saving and loading models. For example, if you’re
    using the `caret` package, you can use the `saveModel()` and `loadModel()` functions.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next hands-on example, we will utilize the Advanced Analytics connection
    during load time and create a simple K-means clustering model. To begin with,
    we should have our R environment running and our `Sales Multi Table.xlsx` loaded
    in the Qlik application with the prepared data model.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we would like to create clusters based on product
    categories, sales, and average discounts to examine how different product categories
    will produce sales compared to given discounts. We will also create a slicer to
    control the number of clusters presented.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by creating a simple layout for our application. We will add
    a scatter plot object, a bar chart, a filter pane, a slicer for variables, and
    two KPI objects to the sheet. It should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2: Layout for clustering example](img/B19863_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.2: Layout for clustering example'
  prefs: []
  type: TYPE_NORMAL
- en: 'To add a slicer for variable input, the dashboard extension bundle needs to
    be installed. Create a variable named `clusters` and set its default value to
    `4`. The settings for the variable and variable input are presented respectively
    in the following screenshots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3: Variable settings](img/B19863_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: Variable settings'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4: Variable input settings](img/B19863_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: Variable input settings'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we configure our scatter plot and start creating our cluster model. Begin
    by adding `ProductName` as a dimension, `sum(Sales)` as the *x*-axis measure,
    and `avg(Discount)` as the *y*-axis measure. This should produce the following
    graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5: Scatter plot with dimensions and measures](img/B19863_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5: Scatter plot with dimensions and measures'
  prefs: []
  type: TYPE_NORMAL
- en: We would like the bubble color to be defined using the cluster model from R.
    Let’s start by selecting **Appearance** � **Colors and legend**. Turn off the
    auto coloring and select **Color** **by expression**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the following formula in the **Expression** field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code starts with the `R.ScriptEval` function, which tells the
    Qlik engine that the expression should be executed using the Advanced Analytics
    connection. `R` is the connection name and `ScriptEval` is the function used in
    this example. In total, the following expression types are supported by the R
    **server-side** **extension** (**SSE**):'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Function Name** | **Function Type** | **Argument Type** | **Return Type**
    |'
  prefs: []
  type: TYPE_TB
- en: '| ScriptEval | Scalar, Tensor | Numeric | Numeric |'
  prefs: []
  type: TYPE_TB
- en: '| ScriptEvalStr | Scalar, Tensor | String | String |'
  prefs: []
  type: TYPE_TB
- en: '| ScriptAggr | Aggregation | Numeric | Numeric |'
  prefs: []
  type: TYPE_TB
- en: '| ScriptAggrStr | Aggregation | String | String |'
  prefs: []
  type: TYPE_TB
- en: '| ScriptEvalEx | Scalar, Tensor | Numeric or String | Numeric |'
  prefs: []
  type: TYPE_TB
- en: '| ScriptEvalExStr | Scalar, Tensor | Numeric or String | String |'
  prefs: []
  type: TYPE_TB
- en: '| ScriptAggrEx | Aggregation | Numeric or String | Numeric |'
  prefs: []
  type: TYPE_TB
- en: '| ScriptAggrExStr | Aggregation | Numeric or String | String |'
  prefs: []
  type: TYPE_TB
- en: '| ScriptEvalEx | Scalar, Tensor | Numeric or String | Numeric |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7.1: Functions supported by the R SSE'
  prefs: []
  type: TYPE_NORMAL
- en: 'After the initial function call, we can write our actual R code. In the preceding
    example, we use the k-means function to calculate the cluster number for each
    of our products. The last two lines are data taken from Qlik and passed to the
    R environment. The Qlik engine creates a dataframe named *q* that contains the
    data sent. In this case, it contains our aggregated sales as `q$sales` and our
    discount as `q$discount`. We are using our previously created variable clusters
    to describe the number of clusters in our code. The following is a step-by-step
    breakdown of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`q$id <- 1:nrow(q)`: This line creates a new column in the `q` dataframe called
    `id` and assigns it values from `1` to the number of rows in `0071`. This column
    is used to preserve the original row order during sorting and clustering.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`F2 <- q[order(q$sales, q$discount), ]`: Here, the `q` dataframe is sorted
    in ascending order based on the `sales` column first, and then within each `sales`
    value, it is sorted based on the `discount` column. The sorted data is stored
    in the `F2` dataframe.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`F3 <- data.frame(sales = F2$sales, discount = F2$discount)`: This line creates
    a new `F3` dataframe that contains only the `sales` and `discount` columns from
    `F2`. It essentially extracts those two columns for further processing.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`rows <- nrow(F2)`: This line calculates the number of rows in the `F2` dataframe
    and assigns it to the `rows` variable.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`if(rows >= clusters) { ... } else { ... }`: This is an if-else statement that
    checks whether the number of rows in `F2` is greater than or equal to the value
    of the `clusters` variable. If it is, clustering is performed; otherwise, a default
    value of `1` is assigned to all rows.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`set.seed(5)`: This line sets a seed value for reproducible results in the
    clustering algorithm. The seed value of `5` is used in this case.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`clusterdata <- kmeans(F3, clusters, nstart = 20)`: This line applies the k-means
    clustering algorithm to the `F3` dataframe. The `clusters` variable determines
    the number of clusters to be formed, and `nstart = 20` specifies the number of
    times the algorithm will be restarted with different initial cluster assignments.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`df <- data.frame(rowid = F2$id, data = clusterdata$cluster)`: Here, a new
    `df` dataframe is created with two columns, `rowid` and `data`. The `rowid` column
    contains the original row identifiers from `F2`, and the `data` column contains
    the cluster assignments obtained from the `clusterdata` object.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`out <- df[order(df$rowid), ]`: This line rearranges the rows of the `df` dataframe
    in the original row order by sorting based on the `rowid` column. The sorted dataframe
    is stored in the `out` variable.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`out$data`: Finally, this line retrieves the `data` column from the `out` dataframe,
    which represents the cluster assignments or the default value of `1` for each
    row.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Qlik takes the data field from the `out` dataframe and assigns values to each
    product name. We can then use the cluster number as our color dimension in our
    scatter plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get visible results, we should disable the **The expression is a color code**
    setting and select **Diverging classes** as the color scheme. The result with
    five clusters (you can use the slicer to set the variable value to five) should
    look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6: Scatterplot with clusters as color](img/B19863_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.6: Scatterplot with clusters as color'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we have five different groups of items that have similar characteristics
    in terms of total sales and the average discount applied. The cluster number can
    be seen if you hover over the single bubble.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Using master items is always encouraged. In production environments, clusters
    should be created as master items. This way, changes made to the model will be
    inherited by all graphs.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final step, we can finish our layout. Insert **sum(Sales)** and **avg(Discount)**
    into KPI objects and take some dimensions into filter pane. Finally, add sales
    by product name into bar chart. You should get a view that looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7: Final layout](img/B19863_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.7: Final layout'
  prefs: []
  type: TYPE_NORMAL
- en: We have now successfully created our first model using R and Advanced Analytics
    Integration. Next, we will take a closer look at debugging and monitoring. We
    will implement another model with a slightly more advanced use case in [*Chapter
    10*](B19863_10.xhtml#_idTextAnchor124).
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and debugging models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Debugging a model during development is a crucial development step. With Advanced
    Analytics Integration in on-premises environments, we have several options to
    debug our model and figure out how it is performing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first and most logical place to start debugging in an interactive scenario
    is to look at the chart output. If there is something wrong with the code, you
    will get an error message here. In the following example, we can see that a library
    called `forecast` is missing from the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.8: Error message in chart](img/B19863_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.8: Error message in chart'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, you may need more comprehensive information or debug prints from
    the actual R code. Since R is running as a service, there is no easy way to get
    debug prints during execution. You can, however, use file writing. Returning to
    our previous `Rserve` example, adding the following code will produce a file called
    `debug.txt` in our `Rserve` home folder (the added code is shown in **bold**):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will print a summary of the `q` dataframe and a sample of
    it using the `capture.output` function. The result file will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You can define the file path in the file parameter if so desired. If a path
    is not defined, the file will be written to the `Rserve` home directory. An example
    path is `C:\Program Files\R\R-4.3.0\library\Rserve\libs\x64`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you need to debug the operation of the bridge component, there are log files
    stored in the `/logs` folder under the root directory of the server-side extension.
    Log files are created and stored daily. If there is something wrong with the code
    execution, these log files are a good way to start debugging. You can also monitor
    the returned data and execution times using these log files. The following is
    some sample input written during the execution of our clustering example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The preceding log entry first gives us some information about incoming requests
    from the Qlik engine. It details which user is making the call and from what application.
    It also tells us the cardinality of the data. This information is important when
    evaluating performance.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we get information about the function used and the parameters passed from
    Qlik. It will also print the entire code into the log if `DEBUG-level` is enabled.
    Finally, we get information about the total execution time and the rows returned.
    These log entries are a good starting point when evaluating model performance.
    More comprehensive performance metrics can be written into the model code and
    evaluated using the method described previously in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took a closer look at model creation and deployment using
    Advanced Analytics Integration and the server-side R extension in an on-premises
    environment (having done the initial environment setup in [*Chapter 5*](B19863_05.xhtml#_idTextAnchor071)).
  prefs: []
  type: TYPE_NORMAL
- en: We started our journey in this chapter by getting familiar with the two concepts
    of utilizing Advanced Analytics Integration. We then took a closer look at an
    on-the-fly data analytics use case and created a k-means clustering example with
    real-time integration with R.
  prefs: []
  type: TYPE_NORMAL
- en: We built a simple dashboard to support our analysis and took a deeper look at
    the Advanced Analytics Integration syntax. In the latter part of this chapter,
    we learned how to debug and monitor our models running in on-premises environments.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will shift our focus toward Qlik AutoML. We will learn
    the implementation model used with AutoML and how to utilize this tool both in
    Qlik Cloud and on-premises. We will also learn how to deploy and monitor models
    using AutoML.
  prefs: []
  type: TYPE_NORMAL
