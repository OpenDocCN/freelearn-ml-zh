["```py\n    WITH dataset AS (\n    SELECT 21 AS age UNION ALL\n    SELECT 33 AS age UNION ALL\n    SELECT 45 AS age UNION ALL SELECT 59 AS age UNION ALL\n    SELECT 66 AS age )\n    SELECT age, ML.BUCKETIZE(age, [18, 35, 50, 65]) AS age_bucket\n    FROM dataset;\n    ```", "```py\n    age  age_bucket\n    21  bin_2\n    33  bin_2\n    45  bin_3\n    59  bin_4\n    bin_5\n    ```", "```py\n    Input: array_expression, degree\n    Output: ARRAY<STRUCT<name STRING, value FLOAT64>>\n    ```", "```py\n    WITH dataset AS (\n    SELECT \"dog\" AS animal, \"brown\" AS color UNION ALL\n    SELECT \"cat\" AS animal, \"black\" AS color UNION ALL\n    SELECT \"bird\" AS animal, \"yellow\" AS color UNION ALL\n    SELECT \"fish\" AS animal, \"orange\" AS color)\n    SELECT animal, color, ML.FEATURE_CROSS(STRUCT(animal, color)) AS animal_color\n    FROM dataset;\n    ```", "```py\n    WITH dataset AS (\n    SELECT \"apple\" AS fruit, \"cherry\" AS fruit2,\"pear\" AS fruit3 UNION ALL\n    SELECT \"banana\" AS fruit, \"banana\" AS fruit2,\"melon\" AS fruit3 UNION ALL\n    SELECT \"cherry\" AS fruit, \"cherry\" AS fruit2, \"pineapple\" AS fruit3)\n    SELECT fruit,fruit2,fruit3, ML.NGRAMS([fruit,fruit2,fruit3], [2]) AS fruit_ngrams\n    FROM dataset;\n    ```", "```py\n    WITH dataset AS (\n    SELECT 21 AS age UNION ALL\n    SELECT 33 AS age UNION ALL\n    SELECT 45 AS age UNION ALL\n    SELECT 59 AS age UNION ALL\n    SELECT 66 AS age)\n    SELECT age, ML.QUANTILE_BUCKETIZE(age, 4) OVER() AS age_bucket\n    FROM dataset\n    ORDER BY age;\n    ```", "```py\n    age  age_bucket\n    21  bin_1\n    33  bin_2\n    45  bin_3\n    59  bin_4\n    66  bin_4\n    ```", "```py\n    WITH dataset AS (\n    SELECT \"horse\" AS animal UNION ALL\n    SELECT \"cat\" AS animal UNION ALL\n    SELECT \"dog\" AS animal UNION ALL\n    SELECT \"fish\" AS animal)\n    SELECT animal, ML.HASH_BUCKETIZE(animal, 2) AS animal_bucket FROM dataset;\n    ```", "```py\n    animal  animal_bucket\n    horse    1\n    cat    0\n    dog    0\n    fish  0\n    ```", "```py\n    WITH dataset AS (\n    SELECT 10 AS age UNION ALL\n    SELECT 20 AS age UNION ALL\n    SELECT 30 AS age UNION ALL\n    SELECT 40 AS age UNION ALL\n    SELECT 50 AS age)\n    SELECT age, ML.MIN_MAX_SCALER(age) Over() AS scaled_age\n    FROM dataset;\n    ```", "```py\n    age  scaled_age\n    50  1.0\n    20  0.25\n    40  0.75\n    10  0.0\n    30  0.5\n    ```", "```py\n    WITH dataset AS (\n    SELECT 10 AS age UNION ALL\n    SELECT 20 AS age UNION ALL\n    SELECT 30 AS age UNION ALL\n    SELECT 40 AS age UNION ALL\n    SELECT 50 AS age)\n    SELECT age, ML.STANDARD_SCALER(age) OVER() AS scaled_age\n    FROM dataset;\n    ```", "```py\n    age  scaled_age\n    40  0.63245553203367588\n    10  -1.2649110640673518\n    50  1.2649110640673518\n    20  -0.63245553203367588\n    30     0.0\n    ```", "```py\n    WITH dataset AS (\n    SELECT -10 AS age UNION ALL\n    SELECT 20 AS age UNION ALL\n    SELECT -30 AS age UNION ALL\n    SELECT 40 AS age UNION ALL\n    SELECT -50 AS age)\n    SELECT age, ML.MAX_ABS_SCALER(age)\n    OVER() AS scaled_age\n    FROM dataset;\n    ```", "```py\n    age    scaled_age\n    -10    -0.2\n    -50    -1.0\n    20    0.4\n    40    0.8\n    -30    -0.6\n    ```", "```py\n    WITH dataset AS (\n    SELECT 1 AS x, 2 AS y UNION ALL\n    SELECT 3 AS x, 4 AS y UNION ALL\n    SELECT 5 AS x, 6 AS y UNION ALL\n    SELECT 7 AS x, 8 AS y UNION ALL\n    SELECT 9 AS x, 10 AS y)\n    SELECT x, y, ML.NORMALIZER([x, y], 1) AS norm_xy\n    FROM dataset;\n    ```", "```py\n    x  y  norm_xy\n    1  2  \"[0.4472135954999579,0.8944271909999158]\"\n    3  4  \"[0.6,0.8]\"\n    5  6  \"[0.6401843996644799,0.7682212795973758]\"\n    7  8  \"[0.658504607868518,0.75257669470687782]\"\n    9  10  \"[0.6689647316224497,0.7432941462471663]\"\n    ```", "```py\n    WITH dataset AS (\n    SELECT 10 AS age, 20 AS height UNION ALL\n    SELECT 20 AS age, 30 AS height UNION ALL\n    SELECT 30 AS age, 40 AS height UNION ALL\n    SELECT 40 AS age, 50 AS height UNION ALL\n    SELECT 50 AS age, NULL AS height)\n    SELECT age, height, ML.IMPUTER(height,\"median\") OVER() AS imputed_height FROM dataset;\n    ```", "```py\n    age  height  imputed_height\n    20    30    30.0\n    10    20    20.0\n    40    50    50.0\n    50    null    30.0\n    30    40    40.0\n    ```", "```py\n    WITH\n      input_data AS (\n        SELECT 'red' AS color UNION ALL\n        SELECT 'blue' AS color UNION ALL\n        SELECT 'green' AS color UNION ALL\n        SELECT 'green' AS color UNION ALL\n        SELECT 'purple' AS color),\n      vocab AS (\n        SELECT color, COUNT(*) AS frequency\n        FROM input_data\n        GROUP BY color)\n    SELECT color,\n      ML.ONE_HOT_ENCODER(color) OVER()  AS encoding\n    FROM input_data\n    ```", "```py\n    WITH data AS (\n      SELECT 'apple' AS fruit UNION ALL\n      SELECT 'banana' UNION ALL\n      SELECT 'orange' UNION ALL\n      SELECT 'apple' UNION ALL\n      SELECT 'pear' UNION ALL\n      SELECT 'kiwi' UNION ALL\n      SELECT 'banana')\n    SELECT fruit, ML.LABEL_ENCODER(fruit, 2,2) OVER() AS encoded_fruit FROM data\n    ```", "```py\n{CREATE OR REPLACE MODEL} model_name\n[OPTIONS(MODEL_TYPE = { 'LINEAR_REG' | 'LOGISTIC_REG' },\n    INPUT_LABEL_COLS = string_array,\n    OPTIMIZE_STRATEGY = { 'AUTO_STRATEGY'  },\n    L1_REG = float64_value,\n    L2_REG = float64_value,\n    MAX_ITERATIONS = int64_value,\n    LEARN_RATE_STRATEGY = { 'LINE_SEARCH' | 'CONSTANT' },\n    LEARN_RATE = float64_value,\n    EARLY_STOP = { TRUE },\n    MIN_REL_PROGRESS = float64_value,\n    DATA_SPLIT_METHOD = { 'AUTO_SPLIT'},\n    DATA_SPLIT_EVAL_FRACTION = float64_value,\n    DATA_SPLIT_COL = string_value,\n    LS_INIT_LEARN_RATE = float64_value,\n    WARM_START = { FALSE },\n    AUTO_CLASS_WEIGHTS = { TRUE  },\n    CLASS_WEIGHTS = struct_array,\n    ENABLE_GLOBAL_EXPLAIN = { FALSE },\n    CALCULATE_P_VALUES = { FALSE },\n    FIT_INTERCEPT = { FALSE },\n    CATEGORY_ENCODING_METHOD = { 'ONE_HOT_ENCODING`, 'DUMMY_ENCODING' })];\n```", "```py\n {CREATE OR REPLACE MODEL} model_name\n[OPTIONS(MODEL_TYPE= {'DNN_CLASSIFIER'},\n         ACTIVATION_FN = { 'RELU' },\n         AUTO_CLASS_WEIGHTS = { TRUE | FALSE },\n         BATCH_SIZE = int64_value,\n         CLASS_WEIGHTS = struct_array,\n         DROPOUT = float64_value,\n         EARLY_STOP = { TRUE | FALSE },\n         HIDDEN_UNITS = int_array,\n         L1_REG = float64_value,\n         L2_REG = float64_value,\n         LEARN_RATE = float64_value,\n         INPUT_LABEL_COLS = string_array,\n         MAX_ITERATIONS = int64_value,\n         MIN_REL_PROGRESS = float64_value,\n         OPTIMIZER={'ADAGRAD'},\n         WARM_START = { FALSE },\n         DATA_SPLIT_METHOD={'AUTO_SPLIT'},\n         DATA_SPLIT_EVAL_FRACTION = float64_value,\n         DATA_SPLIT_COL = string_value,\n         ENABLE_GLOBAL_EXPLAIN = { FALSE },\n         INTEGRATED_GRADIENTS_NUM_STEPS = int64_value,\n         TF_VERSION = { '2.8.0' })];\n```", "```py\n{CREATE OR REPLACE MODEL} model_name\n[OPTIONS(MODEL_TYPE = { 'BOOSTED_TREE_CLASSIFIER' },\n         BOOSTER_TYPE = {'GBTREE' },\n         NUM_PARALLEL_TREE = int64_value,\n         DART_NORMALIZE_TYPE = {'TREE' },\n         TREE_METHOD={'AUTO' },\n         MIN_TREE_CHILD_WEIGHT = int64_value,\n         COLSAMPLE_BYTREE = float64_value,\n         COLSAMPLE_BYLEVEL = float64_value,\n         COLSAMPLE_BYNODE = float64_value,\n         MIN_SPLIT_LOSS = float64_value,\n         MAX_TREE_DEPTH = int64_value,\n         SUBSAMPLE = float64_value,\n         AUTO_CLASS_WEIGHTS = { TRUE },\n         CLASS_WEIGHTS = struct_array,\n         INSTANCE_WEIGHT_COL = string_value,\n         L1_REG = float64_value,\n         L2_REG = float64_value,\n         EARLY_STOP = { TRUE },\n         LEARN_RATE = float64_value,\n         INPUT_LABEL_COLS = string_array,\n         MAX_ITERATIONS = int64_value,\n         MIN_REL_PROGRESS = float64_value,\n         DATA_SPLIT_METHOD = {'AUTO_SPLIT'},\n         DATA_SPLIT_EVAL_FRACTION = float64_value,\n         DATA_SPLIT_COL = string_value,\n         ENABLE_GLOBAL_EXPLAIN = { TRUE},\n         XGBOOST_VERSION = {'1.1'})];\n```", "```py\n{CREATE OR REPLACE MODEL} model_name\n[OPTIONS(MODEL_TYPE = {'TENSORFLOW'} ,\nMODEL_PATH = string_value)]\n```", "```py\n{CREATE OR REPLACE MODEL} model_name\n[OPTIONS(MODEL_TYPE = { 'KMEANS' },\n    NUM_CLUSTERS = int64_value,\n    KMEANS_INIT_METHOD = { 'RANDOM' },\n    KMEANS_INIT_COL = string_value,\n    DISTANCE_TYPE = { 'EUCLIDEAN' | 'COSINE' },\n    STANDARDIZE_FEATURES = { TRUE  },\n    MAX_ITERATIONS = int64_value,\n    EARLY_STOP = { TRUE  },\n    MIN_REL_PROGRESS = float64_value,\n    WARM_START = {  FALSE })];\n```", "```py\n{CREATE OR REPLACE MODEL} model_name\nOPTIONS(Existing Training Options,\n   NUM_TRIALS = int64_value, [, MAX_PARALLEL_TRIALS = int64_value ]\n   [, HPARAM_TUNING_ALGORITHM = { 'VIZIER_DEFAULT' | 'RANDOM_SEARCH' | 'GRID_SEARCH' } ]\n   [, hyperparameter={HPARAM_RANGE(min, max) | HPARAM_CANDIDATES([candidates]) }... ]\n   [, HPARAM_TUNING_OBJECTIVES = { 'R2_SCORE' | 'ROC_AUC' | ... } ]\n   [, DATA_SPLIT_METHOD = { 'AUTO_SPLIT' | 'RANDOM' | 'CUSTOM' | 'SEQ' | 'NO_SPLIT' } ]\n   [, DATA_SPLIT_COL = string_value ]\n   [, DATA_SPLIT_EVAL_FRACTION = float64_value ]\n   [, DATA_SPLIT_TEST_FRACTION = float64_value ]\n) AS query_statement\n```", "```py\nML.EVALUATE(MODEL model_name\n           [, {TABLE table_name | (query_statement)}]\n           [, STRUCT<threshold FLOAT64,\n                     perform_aggregation BOOL,\n                     horizon INT64,\n                     confidence_level FLOAT64> settings]))])\n```", "```py\nML.PREDICT(MODEL model_name,\n          {TABLE table_name | (query_statement)}\n          [, STRUCT<threshold FLOAT64,\n          keep_original_columns BOOL> settings)])\n```"]