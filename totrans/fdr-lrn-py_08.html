<html><head></head><body>
		<div id="_idContainer079">
			<h1 id="_idParaDest-185" class="chapter-number"><a id="_idTextAnchor191"/>8</h1>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor192"/>Introducing Existing Federated Learning Frameworks</h1>
			<p>The objective of this chapter is to introduce <a id="_idIndexMarker626"/>existing <strong class="bold">federated learning</strong> (<strong class="bold">FL</strong>) frameworks and platforms, applying each to federated learning scenarios<a id="_idIndexMarker627"/> involving toy <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) problems. The platforms focused on in this chapter are Flower, TensorFlow Federated, OpenFL, IBM FL, and STADLE – the idea behind this selection was to help you by covering a breadth of existing FL platforms. </p>
			<p>By the end of this chapter, you should have a basic understanding of how to use each platform for FL, and you should be able to choose a platform based on its associated strengths and weaknesses for an <span class="No-Break">FL application.</span></p>
			<p>In this chapter, we will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Introduction to existing <span class="No-Break">FL frameworks</span></li>
				<li>Implementations of an example NLP FL task on movie review dataset, using <span class="No-Break">existing frameworks</span></li>
				<li>Implementations of example computer vision FL task with non-IID datasets, using <span class="No-Break">existing frameworks</span></li>
			</ul>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor193"/>Technical requirements</h1>
			<p>You can find the supplemental code files for this chapter in the book’s <span class="No-Break">GitHub repository:</span></p>
			<p><span class="No-Break">https://github.com/PacktPublishing/Federated-Learning-with-Python</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">You can use the code files for personal or educational purposes. Please note that we will not support deployments for commercial use and will not be responsible for any errors, issues, or damage caused by using <span class="No-Break">the code.</span></p>
			<p>Each implementation example in this chapter was run on an x64 machine running <span class="No-Break">Ubuntu 20.04.</span></p>
			<p>The implementation of the training code for the NLP example requires the following libraries <span class="No-Break">to run:</span></p>
			<ul>
				<li>Python 3 (version ≥ 3.8) </li>
				<li><span class="No-Break">NumPy</span></li>
				<li>TensorFlow (version ≥ <span class="No-Break">2.9.1)</span></li>
				<li>TensorFlow Hub (<strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install tensorflow-hub</strong></span><span class="No-Break">)</span></li>
				<li>TensorFlow Datasets (<strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install tensorflow-datasets</strong></span><span class="No-Break">)</span></li>
				<li>TensorFlow Text (<strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install tensorflow-text</strong></span><span class="No-Break">)</span></li>
			</ul>
			<p>Using a GPU with the appropriate TensorFlow installation is recommended to save training time for the NLP example, due to the size of <span class="No-Break">the model.</span></p>
			<p>The implementation of the training code for the <strong class="bold">non-IID</strong> (<strong class="bold">non-independent and identical distribution</strong>) computer vision example requires the following libraries <span class="No-Break">to run:</span></p>
			<ul>
				<li>Python 3 (version ≥ 3.8) </li>
				<li><span class="No-Break">NumPy</span></li>
				<li>PyTorch (version ≥ <span class="No-Break">1.9)</span></li>
				<li>Torchvision (version ≥ 0.10.0, tied to <span class="No-Break">PyTorch version)</span></li>
			</ul>
			<p>The installation instructions for each FL framework are listed in the <span class="No-Break">following subsections.</span></p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor194"/>TensorFlow Federated</h2>
			<p>You can<a id="_idIndexMarker628"/> install the following libraries to <span class="No-Break">use TFF:</span></p>
			<ul>
				<li><strong class="source-inline">tensorflow_federated</strong> (using the <strong class="source-inline">pip install </strong><span class="No-Break"><strong class="source-inline">tensorflow_federated</strong></span><span class="No-Break"> command)</span></li>
				<li><strong class="source-inline">nest_asyncio</strong> (using the <strong class="source-inline">pip install </strong><span class="No-Break"><strong class="source-inline">nest_asyncio</strong></span><span class="No-Break"> command)</span></li>
			</ul>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor195"/>OpenFL</h2>
			<p>You can install <a id="_idIndexMarker629"/>OpenFL using <strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install openfl</strong></span><span class="No-Break">.</span></p>
			<p>Alternatively, you can build from source with the <span class="No-Break">following commands:</span></p>
			<p class="source-code">git clone https://github.com/intel/openfl.git </p>
			<p class="source-code">cd openfl</p>
			<p class="source-code">pip install .</p>
			<h2 id="_idParaDest-190"><a id="_idTextAnchor196"/>IBM FL</h2>
			<p>Installing the<a id="_idIndexMarker630"/> locally hosted version of IBM FL requires the wheel installation file located in the code repository. To perform this installation, run the <span class="No-Break">following commands:</span></p>
			<p class="source-code">git clone https://github.com/IBM/federated-learning-lib.git</p>
			<p class="source-code">cd federated-learning-lib</p>
			<p class="source-code">pip install federated_learning_lib-*-py3-none-any.whl</p>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor197"/>Flower</h2>
			<p>You can install <a id="_idIndexMarker631"/>Flower using the <strong class="source-inline">pip install </strong><span class="No-Break"><strong class="source-inline">flwr</strong></span><span class="No-Break"> command.</span></p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor198"/>STADLE</h2>
			<p>You can install<a id="_idIndexMarker632"/> the STADLE client-side library using the <strong class="source-inline">pip install </strong><span class="No-Break"><strong class="source-inline">stadle-client</strong></span><span class="No-Break"> command.</span></p>
			<h1 id="_idParaDest-193"><a id="_idTextAnchor199"/>Introduction to FL frameworks</h1>
			<p>First, we <a id="_idIndexMarker633"/>introduce the FL frameworks and platforms to be used in the subsequent implementation-focused sections. </p>
			<h2 id="_idParaDest-194"><a id="_idTextAnchor200"/>Flower</h2>
			<p>Flower (<a href="https://flower.dev/">https://flower.dev/</a>) is <a id="_idIndexMarker634"/>an open source and ML framework-agnostic <a id="_idIndexMarker635"/>FL framework <a id="_idIndexMarker636"/>that aims to be accessible to users. Flower follows a standard client-server architecture, in which the clients are set up to receive the model parameters from the server, train on local data, and send the new local model parameters back to <span class="No-Break">the server.</span></p>
			<p>The high-level orchestration of the federated learning process is dictated by what Flower calls strategies, used by the server for aspects such as client selection and <span class="No-Break">parameter aggregation.</span></p>
			<p>Flower <a id="_idIndexMarker637"/>uses <strong class="bold">Remote Procedure Calls</strong> (<strong class="bold">RPCs</strong>) in order to perform said orchestration through client-side execution from messages sent by the server. The extensibility of the framework allows researchers to experiment with novel approaches such as new aggregation algorithms and communication methods (such as <span class="No-Break">model compression).</span></p>
			<h2 id="_idParaDest-195"><a id="_idTextAnchor201"/>TensorFlow Federated (TFF)</h2>
			<p>TFF (<a href="https://www.tensorflow.org/federated">https://www.tensorflow.org/federated</a>) is <a id="_idIndexMarker638"/>an open source FL/computation<a id="_idIndexMarker639"/> framework<a id="_idIndexMarker640"/> built on top of TensorFlow that aims to allow researchers to easily simulate federated learning with existing TensorFlow/Keras models and training pipelines. It consists of the Federated Core layer, which allows for the implementation of general federated computations, and the Federated Learning layer, which is built on top and provides interfaces for <span class="No-Break">FL-specific processes.</span></p>
			<p>TFF focuses on single-machine local simulations of FL, using wrappers to create TFF-specific datasets, models, and federated computations (core client and server computation performed during the FL process) from the standard TensorFlow equivalents. The focus on building everything from general federated computations allows researchers to implement each step as desired, allowing experimentation to <span class="No-Break">be supported.</span></p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor202"/>OpenFL</h2>
			<p>OpenFL (<a href="https://github.com/intel/openfl">https://github.com/intel/openfl</a>) is <a id="_idIndexMarker641"/>an open source FL<a id="_idIndexMarker642"/> framework <a id="_idIndexMarker643"/>developed by Intel, focused on allowing cross-silo privacy-preserving ML to be performed. OpenFL allows for two different workflows depending on the desired lifespan of the federation (where federation refers to the entire <span class="No-Break">FL system).</span></p>
			<p>In the aggregator-based workflow, a single experiment and associated federated learning plan are sent from the aggregator to the participating <em class="italic">collaborators</em> (agents) to be run as the local training step of the FL process—the federation is stopped after the experiment is complete. In the director-based workflow, long-lived components are instead used to allow for experiments to be run on demand. The following diagram depicts the<a id="_idIndexMarker644"/> architecture and users for the director-based workflow: </p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/B18369_08_01.jpg" alt="Figure 8.1 – Architecture of director-based workflow (adapted from https://openfl.readthedocs.io/en/latest/source/openfl/components.html)&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.1 – Architecture of director-based workflow (adapted from https://openfl.readthedocs.io/en/latest/source/openfl/components.html)</p>
			<p><strong class="bold">Director Manager</strong> oversees the running of experiments, working with long-lived <strong class="bold">Envoy</strong> components residing on the collaborator nodes to manage the short-lived components (collaborators + aggregator) for each experiment. In targeting the cross-silo data scenario, OpenFL applies a unique focus on managing data shards, including cases where data representations differ <span class="No-Break">across silos.</span></p>
			<h2 id="_idParaDest-197"><a id="_idTextAnchor203"/>IBM FL</h2>
			<p>IBM FL is a <a id="_idIndexMarker645"/>framework that also focuses on enterprise FL. It follows a<a id="_idIndexMarker646"/> straightforward aggregator-party design, where some number of parties with local data collaborate with other parties by sending incremental model training results to the aggregator and working with the produced aggregate models (following standard client-server FL architecture). IBM FL has official support for a number of fusion (aggregation) algorithms and certain fairness techniques aimed at combatting bias—the details of these algorithms can be found at the repository located at https://github.com/IBM/federated-learning-lib. One specific goal of IBM FL is to be highly extensible, allowing<a id="_idIndexMarker647"/> users to easily make necessary modifications if specific features are desired. It also supports a Jupyter-Notebook-based dashboard to aid in orchestrating <span class="No-Break">FL experiments.</span></p>
			<h2 id="_idParaDest-198"><a id="_idTextAnchor204"/>STADLE</h2>
			<p>Unlike the <a id="_idIndexMarker648"/>previous<a id="_idIndexMarker649"/> frameworks, STADLE (<a href="https://stadle.ai/">https://stadle.ai/</a>) is an <a id="_idIndexMarker650"/>ML-framework-agnostic FL and distributed learning SaaS platform that aims to allow for the seamless integration of FL into production-ready applications and ML pipelines. The goal of STADLE is to minimize the amount of FL-specific code necessary for integration, making FL accessible to newcomers while still providing flexibility to those looking to experiment. </p>
			<p>With the STADLE SaaS platform, users of varying technical abilities can collaborate on FL projects at all scales. Performance tracking and model management functionalities allow users to produce validated federated models with strong performance, while an intuitive configuration panel allows for detailed control over the federated learning process. STADLE uses a two-level component hierarchy that allows for multiple aggregators to operate in parallel, scaling to match demand. The following figure depicts the <span class="No-Break">high-level architecture:</span></p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B18369_08_02.jpg" alt="Figure 8.2 – STADLE multi-aggregator architecture&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.2 – STADLE multi-aggregator architecture</p>
			<p>Development of STADLE clients is streamlined with <strong class="source-inline">pip</strong> installation and an easy-to-understand<a id="_idIndexMarker651"/> configuration file, with several examples made publicly <a id="_idIndexMarker652"/>available for use as a reference on the different ways STADLE can be integrated into existing <span class="No-Break">ML code.</span></p>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor205"/>PySyft</h2>
			<p>While <a id="_idIndexMarker653"/>PySyft (<a href="https://github.com/OpenMined/PySyft">https://github.com/OpenMined/PySyft</a>) implementations <a id="_idIndexMarker654"/>are not included in this<a id="_idIndexMarker655"/> chapter due to ongoing changes in the codebase, it is still a major player in the privacy-preserving deep learning space. The core principle behind PySyft is to allow for the ability to perform computations over data stored on a machine without direct access to said data ever being given. This is accomplished by adding an intermediate layer between the user and the data location that sends computation requests to participating worker machines, returning the computed result to the user while maintaining the privacy of the data stored and used by each worker to perform <span class="No-Break">the computation.</span></p>
			<p>This general capability directly extends itself to FL, reworking each step of a normal deep learning training flow to be a computation over the model parameters and data stored at each worker (agent) participating in FL. To accomplish this, PySyft utilizes hooks that encapsulate the standard PyTorch/TensorFlow libraries, modifying the requisite internal functions in order to allow model training and testing to be supported as PySyft <span class="No-Break">privacy-preserving computations.</span></p>
			<p>Now that the high-level ideas behind the FL frameworks have been explained, we move to the implementation-level details for their practical usage in two example scenarios. First, we<a id="_idIndexMarker656"/> look at how to modify the existing centralized training code for <a id="_idIndexMarker657"/>an NLP model to <span class="No-Break">use FL.</span></p>
			<h1 id="_idParaDest-200"><a id="_idTextAnchor206"/>Example – the federated training of an NLP model</h1>
			<p>The first ML <a id="_idIndexMarker658"/>problem that will be converted into an FL scenario through each of the aforementioned FL frameworks will be a classification problem within the domain of NLP. At a high level, NLP refers to the intersection of computational linguistics and ML with an overarching goal of allowing computers to achieve some level of <em class="italic">understanding</em> from human language – the details of this understanding vary widely based on the specific problem being targeted. </p>
			<p>For this example, we will be performing sentiment analysis on movie reviews, classifying them as positive or negative. The dataset we will be using is the SST-2 dataset (https://nlp.stanford.edu/sentiment/), containing movie reviews in a string format and the associated binary labels 0/1 representing negative and positive <span class="No-Break">sentiment, respectively.</span></p>
			<p>The model we will use to perform binary classification is a pretrained BERT model with a custom classification head. The BERT model allows us to encode a sentence into a high-dimensional numerical vector, which can then be passed to the classification head to output the binary label prediction; more information on the BERT model can be found at https://huggingface.co/blog/bert-101. We choose to use a pretrained model that has already learned how to produce general encodings for sentences after a significant amount of training, as opposed to performing said training from scratch. This allows us to focus training on the classification head to fine-tune the model on the SST-2 dataset, saving time while <span class="No-Break">maintaining performance.</span></p>
			<p>We will now go through the local (centralized) training code that will be used as a base when showing how to use each of the FL frameworks, starting with the Keras model definition <a id="_idIndexMarker659"/>and <span class="No-Break">dataset loader.</span></p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor207"/>Defining the sentiment analysis model</h2>
			<p>The <strong class="source-inline">SSTModel</strong> object<a id="_idIndexMarker660"/> defined<a id="_idIndexMarker661"/> in the <strong class="source-inline">sst_model.py</strong> file is the Keras model we will be using for this example. </p>
			<p>First, we import the <span class="No-Break">requisite libraries:</span></p>
			<pre class="source-code">
import tensorflow as tf
from tensorflow import keras
from keras import layers
import tensorflow_text
import tensorflow_hub as hub
import tensorflow_datasets as tfds</pre>
			<p>TensorFlow Hub is used to easily download the pretrained BERT weights into a Keras layer. TensorFlow Text is used when loading in the BERT weights from TensorFlow Hub. TensorFlow Datasets will allow us to download and cache the <span class="No-Break">SST-2 dataset.</span></p>
			<p>Next, we define the model and initialize the model <span class="No-Break">layer objects:</span></p>
			<pre class="source-code">
class SSTModel(keras.Model):
    def __init__(self):
        super(SSTModel, self).__init__()
        self.preprocessor = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3")
        self.small_bert = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4")
        self.small_bert.trainable = False
        self.fc1 = layers.Dense(512, activation='relu')
        self.fc2 = layers.Dense(64, activation='relu')
        self.fc3 = layers.Dense(1, activation='sigmoid')</pre>
			<p>The <strong class="source-inline">preprocessor</strong> object takes the raw sentence input batches and converts them into the format used by the BERT model. We load the preprocessor and BERT layers from TensorFlow Hub, then initialize the dense layers that make up the classification head. We use the sigmoid activation function at the end to squash the output into the interval (0,1), allowing for comparison with the <span class="No-Break">true labels.</span></p>
			<p>We can then<a id="_idIndexMarker662"/> define the forward pass of <span class="No-Break">the model:</span></p>
			<pre class="source-code">
    def call(self, inputs):
        input_dict = self.preprocessor(inputs)
        bert_output = self.small_bert(input_dict)['pooled_output']
        output = self.fc1(keras.activations.relu(bert_output, alpha=0.2))
        scores = self.fc3(self.fc2(output))
        
        return scores</pre>
			<p>We apply leaky ReLU to the BERT output to add non-linearity before passing the output to the <a id="_idIndexMarker663"/>classification <a id="_idIndexMarker664"/><span class="No-Break">head layers.</span></p>
			<h2 id="_idParaDest-202"><a id="_idTextAnchor208"/>Creating the data loader</h2>
			<p>We also<a id="_idIndexMarker665"/> implement a function <a id="_idIndexMarker666"/>to load in the SST-2 dataset using the TensorFlow Datasets library. First, the training data is loaded and converted into a NumPy array for use <span class="No-Break">during training:</span></p>
			<pre class="source-code">
def load_sst_data(client_idx=None, num_clients=1):
    x_train = []
    y_train = []
    for d in tfds.load(name="glue/sst2", split="train"):
        x_train.append(d['sentence'].numpy())
        y_train.append(d['label'].numpy())
    x_train = np.array(x_train)
    y_train = np.array(y_train)</pre>
			<p>We load the test data in a <span class="No-Break">similar manner:</span></p>
			<pre class="source-code">
    x_test = []
    y_test = []
    for d in tfds.load(name="glue/sst2", split="validation"):
        x_test.append(d['sentence'].numpy())
        y_test.append(d['label'].numpy())
    x_test = np.array(x_test)
    y_test = np.array(y_test)</pre>
			<p>If <strong class="source-inline">client_idx</strong> and <strong class="source-inline">num_clients</strong> are specified, we return the respective partition of the training<a id="_idIndexMarker667"/> dataset – this will be <a id="_idIndexMarker668"/>used for <span class="No-Break">performing FL:</span></p>
			<pre class="source-code">
    if (client_idx is not None):
        shard_size = int(x_train.size / num_clients)
        x_train = x_train[client_idx*shard_size:(client_idx+1)*shard_size]
        y_train = x_train[client_idx*shard_size:(client_idx+1)*shard_size]
    return (x_train, y_train), (x_test, y_test)</pre>
			<p>Next, we examine the code to perform local training, located <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">local_training.py</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-203"><a id="_idTextAnchor209"/>Training the model</h2>
			<p>We first <a id="_idIndexMarker669"/>import<a id="_idIndexMarker670"/> the <span class="No-Break">requisite libraries:</span></p>
			<pre class="source-code">
import tensorflow as tf
from tensorflow import keras
from sst_model import SSTModel, load_sst_data</pre>
			<p>We can then use the previously defined dataset loader (without splitting) to load in the train and <span class="No-Break">test splits:</span></p>
			<pre class="source-code">
(x_train,y_train), (x_test,y_test) = load_sst_data()</pre>
			<p>We can now compile the model and <span class="No-Break">begin training:</span></p>
			<pre class="source-code">
model.compile(
    optimizer = keras.optimizers.Adam(learning_rate=0.0005, amsgrad=False),
    loss = keras.losses.BinaryCrossentropy(),
    metrics = [keras.metrics.BinaryAccuracy()]
)
model.fit(x_train, y_train, batch_size=64, epochs=3)</pre>
			<p>Finally, we evaluate the model on the <span class="No-Break">test split:</span></p>
			<pre class="source-code">
_, acc = model.evaluate(x_test, y_test, batch_size=64)
print(f"Accuracy of model on test set: {(100*acc):.2f}%")</pre>
			<p>The model should reach around 82% test accuracy after three epochs <span class="No-Break">of training.</span></p>
			<p>Now that we have gone through the local training code, we can examine how the code can be modified to use FL with each of the aforementioned <span class="No-Break">FL frameworks.</span></p>
			<h2 id="_idParaDest-204"><a id="_idTextAnchor210"/>Adopting an FL training approach</h2>
			<p>To demonstrate <a id="_idIndexMarker671"/>how FL can be <a id="_idIndexMarker672"/>applied to the SST model training scenario, we have to first split the original SST-2 dataset into disjoint subsets representing the local datasets in an FL application. To keep things simple, we will examine the case of three agents each training on separate thirds of the dataset. </p>
			<p>For now, these subsets are randomly sampled without replacement from the dataset – in the next section, <em class="italic">Federated training of an image classification model on non-IID data</em>, we examine the case where the local datasets are created from a biased sampling of the original dataset. Instead of locally training for three epochs, we will perform three rounds of FL with each local training phase training for one epoch on the local data. FedAvg will be used to aggregate the locally trained models at the end of each round. After these three rounds, the aforementioned validation metrics will be computed using the final aggregate model, allowing for comparisons to be drawn between the local training cases and the <span class="No-Break">FL case.</span></p>
			<h2 id="_idParaDest-205"><a id="_idTextAnchor211"/>Integrating TensorFlow Federated for SST-2</h2>
			<p>As previously <a id="_idIndexMarker673"/>mentioned, the <strong class="bold">TensorFlow Federated</strong> (<strong class="bold">TFF</strong>) framework was built on top of the TensorFlow<a id="_idIndexMarker674"/> and Keras deep learning <a id="_idIndexMarker675"/>libraries. The model implementation was done using Keras; as a result, the integration of TFF into the local training code is <span class="No-Break">relatively straightforward.</span></p>
			<p>The first step is to add the TFF-specific imports and FL-specific parameters prior to loading <span class="No-Break">the dataset:</span></p>
			<pre class="source-code">
import nest_asyncio
nest_asyncio.apply()
import tensorflow_federated as tff
NUM_CLIENTS = 3
NUM_ROUNDS = 3</pre>
			<p>TFF allows us to simulate some number of agents by passing the appropriate number of datasets (local datasets) to the FL process. To split the SST-2 dataset into thirds after preprocessing, we can use the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
client_datasets = [load_sst_data(idx, NUM_CLIENTS)[0] for idx in range(NUM_CLIENTS)]</pre>
			<p>Next, we have to wrap the Keras model using a TFF API function to easily create the respective <strong class="source-inline">tff.learning.Model</strong> object. We create a function that initializes the SST model and passes it along with the input spec (information on the size of each data element) to this API function, returning the result – TFF will use this function internally to create <a id="_idIndexMarker676"/>the<a id="_idIndexMarker677"/> model <a id="_idIndexMarker678"/>during the <span class="No-Break">FL process:</span></p>
			<pre class="source-code">
def sst_model_fn():
    sst_model = SSTModel()
    sst_model.build(input_shape=(None,64))
    return tff.learning.from_keras_model(
        sst_model,
        input_spec=tf.TensorSpec(shape=(None), dtype=tf.string),
        loss=keras.metrics.BinaryCrossentropy()
    )</pre>
			<p>The TFF FedAvg process can then be created, using the <strong class="source-inline">sst_model_fn</strong> function along with the optimizers used to update the local models and the aggregate model. Using a learning rate of 1.0 for the server optimizer function allows for the new aggregate model to replace the old one at the end of each round (as opposed to computing a weighted average of the old and <span class="No-Break">new models):</span></p>
			<pre class="source-code">
fed_avg_process = tff.learning.algorithms.build_unweighted_fed_avg(
    model_fn = sst_model_fn,
    client_optimizer_fn = lambda: keras.optimizers.Adam(learning_rate=0.001),
    server_optimizer_fn = lambda: keras.optimizers.SGD(learning_rate=1.0)
)</pre>
			<p>Finally, we initialize and run the federated learning process for 10 rounds. Each <strong class="source-inline">fed_avg_process.next()</strong> call simulates one round by performing local training with three models on the client datasets followed by aggregation using FedAvg. The resulting state after the first round is passed to the next call as the starting FL state for <span class="No-Break">the round:</span></p>
			<pre class="source-code">
state = fed_avg_process.initialize()
for round in range(NUM_ROUNDS):
    state = fed_avg_process.next(state, client_datasets).state</pre>
			<p>After the FL process is completed, we convert the final aggregate <strong class="source-inline">tff.learning.Model</strong> object back into the original Keras model format in order to compute<a id="_idIndexMarker679"/> the<a id="_idIndexMarker680"/> <span class="No-Break">validation </span><span class="No-Break"><a id="_idIndexMarker681"/></span><span class="No-Break">metrics:</span></p>
			<pre class="source-code">
fed_weights = fed_avg_process.get_model_weights(state)
fed_sst_model = SSTModel()
fed_sst_model.build(input_shape=(None, 64))
fed_sst_model.compile(
    optimizer = keras.optimizers.Adam(learning_rate=0.005, amsgrad=False),
    loss = keras.losses.BinaryCrossentropy(),
    metrics = [keras.metrics.BinaryAccuracy()]
)
fed_weights.assign_weights_to(fed_sst_model)
_, (x_test, y_test) = load_sst_data()
_, acc = fed_sst_model.evaluate(x_test, y_test, batch_size=64)
print(f"Accuracy of federated model on test set: {(100*acc):.2f}%")</pre>
			<p>The final accuracy of the aggregate model should be <span class="No-Break">around 82%.</span></p>
			<p>From this, it <a id="_idIndexMarker682"/>should be clear that the TFF FedAvg results are nearly identical to those of the local <span class="No-Break">training scenario.</span></p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor212"/>Integrating OpenFL for SST-2</h2>
			<p>Recall that<a id="_idIndexMarker683"/> OpenFL supports two different <a id="_idIndexMarker684"/>workflows: the aggregator-based workflow and the director-based workflow. This example will use the director-based workflow, involving long-living components that can conduct FL task requests as they come in. This was chosen due to the desirability of having a persistent FL setup for deploying multiple projects; however, both workflows conduct the same core FL process and thus demonstrate <span class="No-Break">similar performance.</span></p>
			<p>To help with model serialization in this case, we only aggregate the classification head weights, reconstructing the full model at runtime during training and validation (TensorFlow Hub caches the downloaded layers, so the download process only occurs once). We include the following functions in <strong class="source-inline">sst_model.py</strong> to aid with <span class="No-Break">this modification:</span></p>
			<pre class="source-code">
def get_sst_full(preprocessor, bert, classification_head):
    sst_input = keras.Input(shape=(), batch_size=64, dtype=tf.string)
    scores = classification_head(bert(preprocessor(sst_input))['pooled_output'])
    return keras.Model(inputs=sst_input, outputs=scores, name='sst_model')
def get_classification_head():
    classification_head = keras.Sequential([
        layers.Dense(512, activation='relu', input_shape=(768,)),
        layers.Dense(64, activation='relu', input_shape=(512,)),
        layers.Dense(1, activation='sigmoid', input_shape=(64,))
    ])
    return classification_head</pre>
			<p>Because OpenFL focuses on addressing the data silo case, the creation of the local datasets from the SST-2 data is slightly more involved than the TFF case. The objects needed to create the dataset will be implemented in a separate file <span class="No-Break">named </span><span class="No-Break"><strong class="source-inline">sst_fl_dataset.py</strong></span><span class="No-Break">.</span></p>
			<p>First, we include the necessary imports. The two OpenFL-specific objects we import are the <strong class="source-inline">ShardDescriptor</strong> object, which handles the dataset loading and sharding, and the <strong class="source-inline">DataInterface</strong> object, which <a id="_idIndexMarker685"/>handles<a id="_idIndexMarker686"/> access to <span class="No-Break">the datasets:</span></p>
			<pre class="source-code">
from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor
from openfl.interface.interactive_api.experiment import DataInterface
import tensorflow as tf
from sst_model import load_sst_data</pre>
			<h3>Implementing ShardDescriptor</h3>
			<p>We first<a id="_idIndexMarker687"/> implement the <strong class="source-inline">SSTShardDescriptor</strong> class. When<a id="_idIndexMarker688"/> this shard descriptor is created, we save the <strong class="source-inline">rank</strong> (client number) and <strong class="source-inline">worldsize</strong> (total number of clients) values, then load the training and <span class="No-Break">validation datasets:</span></p>
			<pre class="source-code">
class SSTShardDescriptor(ShardDescriptor):
    def __init__(
            self,
            rank_worldsize: str = '1, 1',
            **kwargs
    ):
        self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
        (x_train,y_train), (x_test,y_test) = load_sst_data(self.rank-1, self.worldsize)
        self.data_by_type = {
            'train': tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64),
            'val': tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(64)
        }</pre>
			<p>We implement the <strong class="source-inline">ShardDescriptor</strong> class functions to get the available dataset types (training <a id="_idIndexMarker689"/>and validation in this case) and the respective dataset/shard based on the rank of <span class="No-Break">the client:</span></p>
			<pre class="source-code">
    def get_shard_dataset_types(self):
        return list(self.data_by_type)
    def get_dataset(self, dataset_type='train'):
        if dataset_type not in self.data_by_type:
            raise Exception(f'Wrong dataset type: {dataset_type}')
        return self.data_by_type[dataset_type]</pre>
			<p>We also specify the properties of the specific dataset being used. Note that the sample shape is set to <strong class="source-inline">1</strong>. The preprocessor layer of the <strong class="source-inline">SSTModel</strong> allows us to pass in strings as input, which are treated as input vectors of type <strong class="source-inline">tf.string</strong> and <span class="No-Break">length </span><span class="No-Break"><strong class="source-inline">1</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
    @property
    def sample_shape(self):
        return ["1"]
    @property
    def target_shape(self):
        return ["1"]
    @property
    def dataset_description(self) -&gt; str:
        return (f'SST dataset, shard number {self.rank}'
                f' out of {self.worldsize}')</pre>
			<p>With <a id="_idIndexMarker690"/>this, the <strong class="source-inline">SSTShardDescriptor</strong> implementation<a id="_idIndexMarker691"/> <span class="No-Break">is completed.</span></p>
			<h3>Implementing DataInterface</h3>
			<p>Next, we<a id="_idIndexMarker692"/> implement the <strong class="source-inline">SSTFedDataset</strong> class <a id="_idIndexMarker693"/>as a subclass of <strong class="source-inline">DataInterface</strong>. This is done by implementing the shard descriptor getter and setter methods, with the setter method preparing the data to be provided to the training/validation <span class="No-Break">FL tasks:</span></p>
			<pre class="source-code">
class SSTFedDataset(DataInterface):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
    @property
    def shard_descriptor(self):
        return self._shard_descriptor
    @shard_descriptor.setter
    def shard_descriptor(self, shard_descriptor):
        self._shard_descriptor = shard_descriptor
        
        self.train_set = shard_descriptor.get_dataset('train')
        self.valid_set = shard_descriptor.get_dataset('val')</pre>
			<p>We also implement <a id="_idIndexMarker694"/>the API functions to grant dataset access and dataset size information (used <span class="No-Break">during aggregation):</span></p>
			<pre class="source-code">
    def get_train_loader(self):
        return self.train_set
    def get_valid_loader(self):
        return self.valid_set
    def get_train_data_size(self):
        return len(self.train_set) * 64
    def get_valid_data_size(self):
        return len(self.valid_set) * 64</pre>
			<p>With this, the<a id="_idIndexMarker695"/> local SST-2 datasets can be constructed <span class="No-Break">and used.</span></p>
			<h3>Creating FLExperiment</h3>
			<p>We now focus on<a id="_idIndexMarker696"/> the actual implementation <a id="_idIndexMarker697"/>of the FL process within a new file, <strong class="source-inline">fl_sim.py</strong>. First, we import the necessary libraries – from OpenFL, we import <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="source-inline">TaskInterface</strong>: Allows us to define our FL training and validation tasks for the model; the registered tasks are what the director instructs each envoy <span class="No-Break">to conduct</span></li>
				<li><strong class="source-inline">ModelInterface</strong>: Allows us to convert our Keras model into the format used by OpenFL in the <span class="No-Break">registered tasks</span></li>
				<li><strong class="source-inline">Federation</strong>: Manages information relating to the connection with <span class="No-Break">the director</span></li>
				<li><strong class="source-inline">FLExperiment</strong>: Uses the <strong class="source-inline">TaskInterface</strong>, <strong class="source-inline">ModelInterface</strong>, and <strong class="source-inline">Federation</strong> objects to conduct the <span class="No-Break">FL process</span></li>
			</ul>
			<p>The requisite <a id="_idIndexMarker698"/>imports are done <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
import tensorflow as tf
from tensorflow import keras
import tensorflow_hub as hub
from openfl.interface.interactive_api.experiment import TaskInterface
from openfl.interface.interactive_api.experiment import ModelInterface
from openfl.interface.interactive_api.experiment import FLExperiment
from openfl.interface.interactive_api.federation import Federation
from sst_model import get_classification_head, get_sst_full
from sst_fl_dataset import SSTFedDataset</pre>
			<p>Next, we create the <strong class="source-inline">Federation</strong> object using the default <strong class="source-inline">director</strong> <span class="No-Break">connection information:</span></p>
			<pre class="source-code">
client_id = 'api'
director_node_fqdn = 'localhost'
director_port = 50051
federation = Federation(
    client_id=client_id,
    director_node_fqdn=director_node_fqdn,
    director_port=director_port, 
    tls=False
)</pre>
			<p>We then initialize<a id="_idIndexMarker699"/> the model with the associated optimizer and loss function – these objects are used by the OpenFL <strong class="source-inline">KerasAdapter</strong> to create the <strong class="source-inline">ModelInterface</strong> object. We call the model on a dummy Keras input in order to initialize all of the weights before passing the model <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">ModelInterface</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
classification_head = get_classification_head()
optimizer = keras.optimizers.Adam(learning_rate=0.005, amsgrad=False)
loss = keras.losses.BinaryCrossentropy()
framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'
MI = ModelInterface(model=classification_head, optimizer=optimizer, framework_plugin=framework_adapter)</pre>
			<p>Next, we<a id="_idIndexMarker700"/> create a <strong class="source-inline">TaskInterface</strong> object and use it to register the training task. Note that including the optimizer in the decorator function of a task will result in the training dataset being passed to the task; otherwise, the validation dataset will be passed to <span class="No-Break">the task:</span></p>
			<pre class="source-code">
TI = TaskInterface()
@TI.register_fl_task(model='model', data_loader='train_data', device='device', optimizer='optimizer')
def train(model, train_data, optimizer, device):
    preprocessor = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3")
    small_bert = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4")
    small_bert.trainable = False
    full_model = get_sst_full(preprocessor, small_bert, model)
    full_model.compile(loss=loss, optimizer=optimizer)
    history = full_model.fit(train_data, epochs=1)
    return {'train_loss':history.history['loss'][0]}</pre>
			<p>Similarly, we register the validation task using the <strong class="source-inline">TaskInterface</strong> object. Note that we can collect the metrics generated<a id="_idIndexMarker701"/> by <a id="_idIndexMarker702"/>the <strong class="source-inline">evaluate</strong> function and return the values as a means of <span class="No-Break">tracking performance:</span></p>
			<pre class="source-code">
@TI.register_fl_task(model='model', data_loader='val_data', device='device')
def validate(model, val_data, device):
    preprocessor = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3")
    small_bert = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4")
    small_bert.trainable = False
    full_model = get_sst_full(preprocessor, small_bert, model)
    full_model.compile(loss=loss, optimizer=optimizer)
    loss, acc = full_model.evaluate(val_data, batch_size=64)
    return {'val_acc':acc, 'val_loss':loss,}</pre>
			<p>We can now load in the dataset using the <strong class="source-inline">SSTFedDataset</strong> class implemented earlier and create and start <a id="_idIndexMarker703"/>a new <strong class="source-inline">FLExperiment</strong> using the created <strong class="source-inline">ModelInterface</strong>, <strong class="source-inline">TaskInterface</strong>, and <span class="No-Break"><strong class="source-inline">SSTFedDatasets</strong></span><span class="No-Break"> objects:</span></p>
			<pre class="source-code">
fed_dataset = SSTFedDataset()
fl_experiment = FLExperiment(federation=federation, experiment_name='sst_experiment')
fl_experiment.start(
    model_provider=MI,
    task_keeper=TI,
    data_loader=fed_dataset,
    rounds_to_train=3,
    opt_treatment='CONTINUE_LOCAL'
)</pre>
			<h3>Defining the configuration files</h3>
			<p>The last step is to create the configuration files used by <strong class="source-inline">director</strong> and <strong class="source-inline">envoys</strong> in order to actually load the data and start the FL process. First, we create <strong class="source-inline">director_config</strong> containing the <span class="No-Break">following information:</span></p>
			<pre class="source-code">
settings:
  listen_host: localhost
  listen_port: 50051
  sample_shape: ["1"]
  target_shape: ["1"]</pre>
			<p>This is saved <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">director/director_config.yaml</strong></span><span class="No-Break">.</span></p>
			<p>We then create the three <strong class="source-inline">envoy</strong> configuration files. The first file (<strong class="source-inline">envoy_config_1.yaml</strong>) contains <span class="No-Break">the following:</span></p>
			<pre class="source-code">
params:
  cuda_devices: []
optional_plugin_components: {}
shard_descriptor:
  template: sst_fl_dataset.SSTShardDescriptor
  params:
    rank_worldsize: 1, 3</pre>
			<p>The second and third <strong class="source-inline">envoy</strong> config files are the same, except with the values <strong class="source-inline">rank_worldsize: 2, 3</strong> and <strong class="source-inline">rank_worldsize: 3, 3</strong>, respectively. These config files, alongside all of the code files, are stored in the experiment directory. The directory structure should look like <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline">director</strong></span><ul><li><span class="No-Break"><strong class="source-inline">director_config.yaml</strong></span></li></ul></li>
				<li><span class="No-Break"><strong class="source-inline">experiment</strong></span><ul><li><span class="No-Break"><strong class="source-inline">envoy_config_1.yaml</strong></span></li><li><span class="No-Break"><strong class="source-inline">envoy_config_2.yaml</strong></span></li><li><span class="No-Break"><strong class="source-inline">envoy_config_3.yaml</strong></span></li><li><span class="No-Break"><strong class="source-inline">sst_fl_dataset.py</strong></span></li><li><span class="No-Break"><strong class="source-inline">sst_model.py</strong></span></li><li><strong class="source-inline">fl_sim.py (file with </strong><span class="No-Break"><strong class="source-inline">FLExperiment creation)</strong></span></li></ul></li>
			</ul>
			<p>With everything set up, we can now perform FL <span class="No-Break">with OpenFL.</span></p>
			<h3>Running the OpenFL example</h3>
			<p>First, start the <a id="_idIndexMarker704"/>director by running the following command from within the <strong class="source-inline">director</strong> folder (make sure OpenFL is installed in the <span class="No-Break">working environment):</span></p>
			<p class="source-code">fx director start --disable-tls -c director_config.yaml</p>
			<p>Next, run the following commands in separate terminals from the <span class="No-Break">experiment directory:</span></p>
			<p class="source-code">fx envoy start -n envoy_1 -–disable-tls --envoy-config-path envoy_config_1.yaml -dh localhost -dp 50051</p>
			<p class="source-code">fx envoy start -n envoy_2 -–disable-tls --envoy-config-path envoy_config_2.yaml -dh localhost -dp 50051</p>
			<p class="source-code">fx envoy start -n envoy_3 -–disable-tls --envoy-config-path envoy_config_3.yaml -dh localhost -dp 50051</p>
			<p>Finally, start <strong class="source-inline">FLExperiment</strong> by running the <strong class="source-inline">fl_sim.py</strong> script. After the three rounds are <a id="_idIndexMarker705"/>completed, the aggregate model should achieve a validation accuracy of around 82%. Once again, the performance is nearly identical to the local <span class="No-Break">training scenario.</span></p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor213"/>Integrating IBM FL for SST-2</h2>
			<p>IBM FL uses a<a id="_idIndexMarker706"/> saved version<a id="_idIndexMarker707"/> of the model when performing FL. The following code (<strong class="source-inline">create_saved_model.py</strong>) initializes a model (calling the model on a dummy input to initialize the parameters) and then saves the model in the Keras <strong class="source-inline">SavedModel</strong> format for IBM FL <span class="No-Break">to use:</span></p>
			<pre class="source-code">
import tensorflow as tf
from tensorflow import keras
from sst_model import SSTModel
sst_model = SSTModel()
optimizer = keras.optimizers.Adam(learning_rate=0.005, amsgrad=False)
loss = keras.losses.BinaryCrossentropy(),
sst_model.compile(loss=loss, optimizer=optimizer)
sst_input = keras.Input(shape=(), dtype=tf.string)
sst_model(sst_input)
sst_model.save('sst_model_save_dir')</pre>
			<p>Run this once to save the model into the folder named <strong class="source-inline">sst_model_save_dir</strong> – we will point<a id="_idIndexMarker708"/> IBM FL<a id="_idIndexMarker709"/> to load in the model saved in <span class="No-Break">this directory.</span></p>
			<h3>Creating DataHandler</h3>
			<p>Next, we create a <a id="_idIndexMarker710"/>subclass of the IBM FL <strong class="source-inline">DataHandler</strong> class<a id="_idIndexMarker711"/> in charge of providing the training and validation data to the model – this subclass will load, preprocess, and store the SST datasets as class attributes. We first import the <span class="No-Break">necessary libraries:</span></p>
			<pre class="source-code">
from ibmfl.data.data_handler import DataHandler
import tensorflow as tf
from sst_model import load_sst_data</pre>
			<p>The <strong class="source-inline">init</strong> function of this class loads the data info parameters, which are then used to load the correct SST-2 <span class="No-Break">data partition:</span></p>
			<pre class="source-code">
class SSTDataHandler(DataHandler):
    def __init__(self, data_config=None):
        super().__init__()
        if (data_config is not None):
            if ('client_id' in data_config):
                self.client_id = int(data_config['client_id'])
            if ('num_clients' in data_config):
                self.num_clients = int(data_config['num_clients'])
        train_data, val_data = load_sst_data(self.client_id-1, self.num_clients)
        self.train_dataset = tf.data.Dataset.from_tensor_slices(train_data).batch(64)
        self.val_dataset = tf.data.Dataset.from_tensor_slices(val_data).batch(64)</pre>
			<p>We also <a id="_idIndexMarker712"/>implement the API function that returns the <a id="_idIndexMarker713"/>loaded datasets for use <span class="No-Break">during training/validation:</span></p>
			<pre class="source-code">
    def get_data(self):
        return self.train_dataset, self.val_dataset</pre>
			<h3>Defining the configuration files</h3>
			<p>The next step <a id="_idIndexMarker714"/>is to create the configuration JSON files used when starting the aggregator and initializing the parties. The aggregation config first specifies the connection information it will use to communicate with <span class="No-Break">the parties:</span></p>
			<pre class="source-code">
{
    "connection": {
        "info": {
            "ip": "127.0.0.1",
            "port": 5000,
            "tls_config": {
                "enable": "false"
            }
        },
        "name": "FlaskConnection",
        "path": "ibmfl.connection.flask_connection",
        "sync": "False"
    },</pre>
			<p>Next, we specify the <a id="_idIndexMarker715"/>fusion handler used <span class="No-Break">for aggregation:</span></p>
			<pre class="source-code">
    "fusion": {
        "name": "IterAvgFusionHandler",
        "path": "ibmfl.aggregator.fusion.iter_avg_fusion_handler"
    },</pre>
			<p>We also specify the hyperparameters related to both local training and aggregation. <strong class="source-inline">perc_quorum</strong> refers to the percentage of parties that must participate before aggregation <span class="No-Break">can begin:</span></p>
			<pre class="source-code">
    "hyperparams": {
        "global": {
            "max_timeout": 10800,
            "num_parties": 1,
            "perc_quorum": 1,
            "rounds": 3
        },
        "local": {
            "optimizer": {
                "lr": 0.0005
            },
            "training": {
                "epochs": 1
            }
        }
    },</pre>
			<p>Finally, we specify the IBM FL protocol handler <span class="No-Break">to use:</span></p>
			<pre class="source-code">
    "protocol_handler": {
        "name": "ProtoHandler",
        "path": "ibmfl.aggregator.protohandler.proto_handler"
    }
}</pre>
			<p>This configuration is saved <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">agg_config.json</strong></span><span class="No-Break">.</span></p>
			<p>We also create<a id="_idIndexMarker716"/> the base party configuration file used to conduct FL with the local data. We first specify the connection information of the aggregator and <span class="No-Break">the party:</span></p>
			<pre class="source-code">
{
    "aggregator":
        {
            "ip": "127.0.0.1",
            "port": 5000
        },
    "connection": {
        "info": {
            "ip": "127.0.0.1",
            "port": 8085,
            "id": "party",
            "tls_config": {
                "enable": "false"
            }
        },
        "name": "FlaskConnection",
        "path": "ibmfl.connection.flask_connection",
        "sync": "false"
    },</pre>
			<p>We then specify the data handler and the local training handler to use – this component trains the SST model <a id="_idIndexMarker717"/>using the model information and the <span class="No-Break">local data:</span></p>
			<pre class="source-code">
    "data": {
        "info": {
            "client_id": 0,
            "num_clients": 3
        },
        "name": "SSTDataHandler",
        "path": "sst_data_handler"
    },
    "local_training": {
        "name": "LocalTrainingHandler",
        "path": "ibmfl.party.training.local_training_handler"
    },</pre>
			<p>The model format and information is then specified – this is where we point to the saved model <span class="No-Break">created earlier:</span></p>
			<pre class="source-code">
    "model": {
        "name": "TensorFlowFLModel",
        "path": "ibmfl.model.tensorflow_fl_model",
        "spec": {
            "model-name": "sst_model",
            "model_definition": "sst_model_save_dir"
        }
    },</pre>
			<p>Finally, we specify<a id="_idIndexMarker718"/> the <span class="No-Break">protocol handler:</span></p>
			<pre class="source-code">
    "protocol_handler": {
        "name": "PartyProtocolHandler",
        "path": "ibmfl.party.party_protocol_handler"
    }
}</pre>
			<h3>Creating IBM FL party</h3>
			<p>With this, all that<a id="_idIndexMarker719"/> is left is the code that starts each party, saved in <strong class="source-inline">fl_sim.py</strong>. We first import the <span class="No-Break">necessary libraries:</span></p>
			<pre class="source-code">
import argparse
import json
from ibmfl.party.party import Party</pre>
			<p>We include an <strong class="source-inline">argparse</strong> argument that allows for the party number to be specified – this is used to modify the base party configuration file in order to allow for distinct parties to be started from the <span class="No-Break">same file:</span></p>
			<pre class="source-code">
parser = argparse.ArgumentParser()
parser.add_argument("party_id", type=int)
args = parser.parse_args()
party_id = args.party_id
with open('party_config.json') as cfg_file:
    party_config = json.load(cfg_file)
party_config['connection']['info']['port'] += party_id
party_config['connection']['info']['id'] += f'_{party_id}'
party_config['data']['info']['client_id'] = party_id</pre>
			<p>Finally, we create and start a new <strong class="source-inline">Party</strong> object with the modified <span class="No-Break">configuration information:</span></p>
			<pre class="source-code">
party = Party(config_dict=party_config)
party.start()
party.register_party()</pre>
			<p>With this, we <a id="_idIndexMarker720"/>can now begin performing FL using <span class="No-Break">IBM FL.</span></p>
			<h3>Running the IBM FL example</h3>
			<p>First, start <strong class="source-inline">aggregator</strong> by <a id="_idIndexMarker721"/>running the <span class="No-Break">following command:</span></p>
			<p class="source-code">python -m ibmfl.aggregator.aggregator agg_config.json</p>
			<p>After the aggregator is finished setting up, type <strong class="source-inline">START</strong> and press <em class="italic">Enter</em> key to open the aggregator to receive incoming connections. You can then start three parties using the following commands in <span class="No-Break">separate terminals:</span></p>
			<p class="source-code">python fl_sim.py 1</p>
			<p class="source-code">python fl_sim.py 2</p>
			<p class="source-code">python fl_sim.py 3</p>
			<p>Finally, type <strong class="source-inline">TRAIN</strong> into the aggregator window and press <em class="italic">Enter</em> key to begin the FL process. When <a id="_idIndexMarker722"/>three rounds are completed, you can type <strong class="source-inline">SAVE</strong> into the same window to save the latest <span class="No-Break">aggregate model.</span></p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor214"/>Integrating Flower for SST-2</h2>
			<p>The two main <a id="_idIndexMarker723"/>Flower<a id="_idIndexMarker724"/> components that must be incorporated on top of the existing local training code are the client and strategy subclass implementations. The client subclass implementation allows us to interface with Flower, with API functions that allow for model parameters to be passed between the clients and the server. The strategy subclass implementation allows us to specify the details of the aggregation approach performed by <span class="No-Break">the server.</span></p>
			<p>We begin by writing the code to implement and start a client (stored in <strong class="source-inline">fl_sim.py</strong>). First, the necessary libraries <span class="No-Break">are imported:</span></p>
			<pre class="source-code">
import argparse
import tensorflow as tf
from tensorflow import keras
from sst_model import SSTModel, load_sst_data
import flwr as fl</pre>
			<p>We add a command-line argument specifying the client ID in order to allow for the same client script to be reused for all <span class="No-Break">three agents:</span></p>
			<pre class="source-code">
parser = argparse.ArgumentParser()
parser.add_argument("client_id", type=int)
args = parser.parse_args()
client_id = args.client_id
NUM_CLIENTS = 3</pre>
			<p>We then load in the <span class="No-Break">SST-2 datasets:</span></p>
			<pre class="source-code">
(x_train,y_train), (x_test,y_test) = load_sst_data(client_id-1, NUM_CLIENTS)</pre>
			<p>Note that we use the client ID to get the respective shard from the <span class="No-Break">training dataset.</span></p>
			<p>Next, we create the model and the associated optimizer and loss objects, making sure to call the model <a id="_idIndexMarker725"/>on a dummy <a id="_idIndexMarker726"/>input to initialize <span class="No-Break">the weights:</span></p>
			<pre class="source-code">
sst_model = SSTModel()
sst_model.compile(
    optimizer = keras.optimizers.Adam(learning_rate=0.005, amsgrad=False),
    loss = keras.losses.BinaryCrossentropy(),
    metrics = [keras.metrics.BinaryAccuracy()]
)
sst_input = keras.Input(shape=(), dtype=tf.string)
sst_model(sst_input)</pre>
			<h3>Implementing the Flower client</h3>
			<p>We can now <a id="_idIndexMarker727"/>implement the Flower client object that will pass model parameters to and from the server. To implement a client subclass, we have to define <span class="No-Break">three functions:</span></p>
			<ul>
				<li><strong class="source-inline">get_parameters(self, config)</strong>: Returns the model <span class="No-Break">parameter values</span></li>
				<li><strong class="source-inline">fit(self, parameters, config)</strong>: Sets the weights of the local model to the received parameters, performs local training, and returns the new model parameters alongside the dataset size and <span class="No-Break">training metrics</span></li>
				<li><strong class="source-inline">evaluate(self, parameters, config)</strong>: Sets the weights of the local model to the received parameters, then evaluates the model on validation/test data and returns the <span class="No-Break">performance metrics</span></li>
			</ul>
			<p>Using <strong class="source-inline">fl.client.NumPyClient</strong> as the superclass allows us to take advantage of the Keras model <strong class="source-inline">get_weights</strong> and <strong class="source-inline">set_weights</strong> functions that convert the model parameters into<a id="_idIndexMarker728"/> lists of <span class="No-Break">NumPy arrays:</span></p>
			<pre class="source-code">
class SSTClient(fl.client.NumPyClient):
    def get_parameters(self, config):
        return sst_model.get_weights()
    def fit(self, parameters, config):
        sst_model.set_weights(parameters)
        history = sst_model.fit(x_train, y_train, epochs=1)
        return sst_model.get_weights(), len(x_train), {'train_loss':history.history['loss'][0]}</pre>
			<p>The <strong class="source-inline">evaluate</strong> function is <span class="No-Break">also defined:</span></p>
			<pre class="source-code">
    def evaluate(self, parameters, config):
        sst_model.set_weights(parameters)
        loss, acc = sst_model.evaluate(x_test, y_test, batch_size=64)
        return loss, len(x_train), {'val_acc':acc, 'val_loss':loss}</pre>
			<p>With this client implementation, we can finally start the client using the default connection information with the <span class="No-Break">following line:</span></p>
			<pre class="source-code">
fl.client.start_numpy_client(server_address="[::]:8080", client=SSTClient())</pre>
			<h3>Creating the Flower server</h3>
			<p>The final step <a id="_idIndexMarker729"/>before running Flower is to create the script (<strong class="source-inline">server.py</strong>) that will start the Flower server. We begin with the necessary imports and the <span class="No-Break"><strong class="source-inline">MAX_ROUNDS</strong></span><span class="No-Break"> parameter:</span></p>
			<pre class="source-code">
import flwr as fl
import tensorflow as tf
from tensorflow import keras
from sst_model import SSTModel
MAX_ROUNDS = 3</pre>
			<p>Because we want to save the model after performing federated learning, we create a subclass of the flower FedAvg strategy and add a final step that saves the model at the last round during the <span class="No-Break">aggregation phase:</span></p>
			<pre class="source-code">
class SaveKerasModelStrategy(fl.server.strategy.FedAvg):
    def aggregate_fit(self, server_round, results, failures):
        agg_weights = super().aggregate_fit(server_round, results, failures)
        if (server_round == MAX_ROUNDS):
            sst_model = SSTModel()
            sst_input = keras.Input(shape=(), dtype=tf.string)
            sst_model(sst_input)
            
            sst_model.set_weights(fl.common.parameters_to_ndarrays(agg_weights[0]))
            sst_model.save('final_agg_sst_model')
        return agg_weights</pre>
			<p>With this strategy, we can run the following line to start the server (passing the <strong class="source-inline">MAX_ROUNDS</strong> parameter through the <span class="No-Break"><strong class="source-inline">config</strong></span><span class="No-Break"> argument):</span></p>
			<pre class="source-code">
fl.server.start_server(strategy=SaveKerasModelStrategy(), config=fl.server.ServerConfig(num_rounds=MAX_ROUNDS))</pre>
			<p>We can now <a id="_idIndexMarker730"/>start the server and clients, allowing for FL to be performed <span class="No-Break">using Flower.</span></p>
			<h3>Running the Flower example</h3>
			<p>To start the<a id="_idIndexMarker731"/> server, first run the <span class="No-Break"><strong class="source-inline">server.py</strong></span><span class="No-Break"> script.</span></p>
			<p>Each of the three clients can then be started by running the following commands in separate <span class="No-Break">terminal windows:</span></p>
			<p class="source-code">python fl_sim.py 1</p>
			<p class="source-code">python fl_sim.py 2</p>
			<p class="source-code">python fl_sim.py 3</p>
			<p>The final aggregate model after FL will be saved in the <strong class="source-inline">final_agg_sst_model</strong> directory as a <span class="No-Break"><strong class="source-inline">SavedModel</strong></span><span class="No-Break"> object.</span></p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor215"/>Integrating STADLE for SST-2</h2>
			<p>STADLE differs <a id="_idIndexMarker732"/>from the<a id="_idIndexMarker733"/> previously examined FL frameworks by providing a cloud-based platform (STADLE Ops) to handle the deployment of aggregators and management of the FL process. Because the deployment of the server side can be done through the platform, the client-side implementation is all that needs to be implemented for performing FL with STADLE. This integration is done by creating a client object that occasionally sends the local model and returns the aggregate model from the previous round. To do this, we need to create the agent configuration file and modify the local training code to interface <span class="No-Break">with STADLE.</span></p>
			<p>First, we create the configuration file for the agent <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
{
    "model_path": "./data/agent",
    "aggr_ip": "localhost",
    "reg_port": "8765",
    "token": "stadle12345",
    "base_model": {
        "model_fn": "SSTModel",
        "model_fn_src": "sst_model",
        "model_format": "Keras",
        "model_name": "Keras-SST-Model"
    }
}</pre>
			<p>Information on these parameters can be found at https://stadle-documentation.readthedocs.io/en/latest/documentation.html#configuration-of-agent. Note that the aggregator IP and registration port values listed here are placeholders and will be modified when connecting to the STADLE <span class="No-Break">Ops platform.</span></p>
			<p>Next, we<a id="_idIndexMarker734"/> modify the local training <a id="_idIndexMarker735"/>code to work with STADLE. We first import the <span class="No-Break">requisite libraries:</span></p>
			<pre class="source-code">
import argparse
import tensorflow as tf
from tensorflow import keras
from sst_model import SSTModel, load_sst_data
from stadle import BasicClient</pre>
			<p>Once again, we add a command-line argument to specify which partition of the training data the agent <span class="No-Break">should receive:</span></p>
			<pre class="source-code">
parser = argparse.ArgumentParser()
parser.add_argument("client_id", type=int)
args = parser.parse_args()
client_id = args.client_id
NUM_CLIENTS = 3
(x_train,y_train), (x_test,y_test) = load_sst_data(client_id-1, NUM_CLIENTS)</pre>
			<p>Next, we instantiate a <strong class="source-inline">BasicClient</strong> object – this is the STADLE client component that handles communication between the local training process and the aggregators on the server side. We use the configuration file defined earlier to create <span class="No-Break">this client:</span></p>
			<pre class="source-code">
stadle_client = BasicClient(config_file="config_agent.json", agent_name=f"sst_agent_{client_id}")</pre>
			<p>Finally, we implement the FL training loop. In each round, the client gets the aggregate model from the previous round (starting with the base model) and trains it further on the local data before sending it back to the aggregator through <span class="No-Break">the client:</span></p>
			<pre class="source-code">
for round in range(3):
    sst_model = stadle_client.wait_for_sg_model()
    history = sst_model.fit(x_train, y_train, epochs=1)
    loss = history.history['loss'][0]
    stadle_client.send_trained_model(sst_model, {'loss_training': loss})
stadle_client.disconnect()</pre>
			<p>The <strong class="source-inline">wait_for_sg_model</strong> function returns the latest aggregate model from the server, and the <strong class="source-inline">send_trained_model</strong> function sends the locally trained model with the desired performance metrics to the server. More information on these integration steps can be found <span class="No-Break">at </span><span class="No-Break">https://stadle-documentation.readthedocs.io/en/latest/usage.html#client-side-stadle-integration</span><span class="No-Break">.</span></p>
			<p>Now that<a id="_idIndexMarker736"/> the client <a id="_idIndexMarker737"/>side has been implemented, we can use the STADLE Ops platform to start an aggregator and start an <span class="No-Break">FL process.</span></p>
			<h3>Creating a STADLE Ops project</h3>
			<p>First, go to stadle.ai <a id="_idIndexMarker738"/>and create a new account. Once you are logged in, you should be directed to the project information page in <span class="No-Break">STADLE Ops:</span></p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B18369_08_03.jpg" alt="Figure 8.3 – Project information page in STADLE Ops&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.3 – Project information page in STADLE Ops</p>
			<p>Click on <strong class="bold">Create New Project</strong>, then fill in the project information and click <strong class="bold">Create Project</strong>. The project information page should have changed to show <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B18369_08_04.jpg" alt="Figure 8.4 – New project added to the project information page&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.4 – New project added to the project information page</p>
			<p>Click on the plus icon under <strong class="bold">Initiate Aggregator</strong> to start a new aggregator for the project, then click <strong class="bold">OK</strong> on the confirmation prompt. You can now navigate to the <strong class="bold">Dashboard</strong> page on the left side, resulting in a page that looks like <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B18369_08_05.jpg" alt="Figure 8.5 – Dashboard page of STADLE Ops&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.5 – Dashboard page of STADLE Ops</p>
			<p>Replace the <strong class="source-inline">aggr_ip</strong> and <strong class="source-inline">reg_port</strong> placeholder parameter values in the <strong class="source-inline">config_agent.json</strong> file with <a id="_idIndexMarker739"/>the values under <strong class="bold">IP Address to Connect</strong> and <strong class="bold">Port to </strong><span class="No-Break"><strong class="bold">Connect</strong></span><span class="No-Break">, respectively.</span></p>
			<p>With this, we are now ready to begin the FL <span class="No-Break">training process.</span></p>
			<h3>Running the STADLE example</h3>
			<p>The first <a id="_idIndexMarker740"/>step is to send the base model object to the server, allowing it to in turn distribute the model to the training agents. This is done with the <span class="No-Break">following command:</span></p>
			<p class="source-code">stadle upload_model --config_path config_agent.json</p>
			<p>Once the command successfully runs, the <strong class="bold">Base Model Info</strong> section on the STADLE Ops dashboard should update to show the model information. We can now start the three agents by running the <span class="No-Break">following commands:</span></p>
			<p class="source-code">python fl_sim.py 1</p>
			<p class="source-code">python fl_sim.py 2</p>
			<p class="source-code">python fl_sim.py 3</p>
			<p>After three rounds, the agents will terminate and the final aggregate model will be displayed in the project dashboard, available for download in the Keras SavedModel format. The user guide located at <a href="https://stadle.ai/user_guide/guide">https://stadle.ai/user_guide/guide</a> is recommended for more information on the various functionalities of the STADLE <span class="No-Break">Ops platform.</span></p>
			<p>Evaluating the resulting aggregate models produced by each FL framework results in the same conclusion—the performance of the aggregate model essentially matches that of the centralized training model. As explained in the <em class="italic">Dataset distributions</em> section of <a href="B18369_07.xhtml#_idTextAnchor176"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Model Aggregation</em>, this is generally the expected result. The natural question to<a id="_idIndexMarker741"/> ask is how the perf<a id="_idTextAnchor216"/>ormance is affected when the local datasets are not IID—this is the focal point of the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-210"><a id="_idTextAnchor217"/>Example – the federated training of an image classification model on non-IID data</h1>
			<p>In the previous <a id="_idIndexMarker742"/>example, we<a id="_idIndexMarker743"/> examined how a centralized deep learning problem could be converted into an FL analog by training multiple clients on disjoint subsets of the original training dataset (the <em class="italic">local datasets</em>) in an FL process. One key point of this local dataset creation was that the subsets were created by random sampling, leading to local datasets that were all IID under the same distribution as the original dataset. As a result, the similar performance of FedAvg compared to the local training scenario was expected – each client’s model essentially had the same set of local minima to move toward during training, making all local training beneficial for the <span class="No-Break">global objective.</span></p>
			<p>Recall that in <a href="B18369_07.xhtml#_idTextAnchor176"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Model Aggregation</em>, we explored how FedAvg was susceptible to the divergence in training objectives induced by severely non-IID local datasets. To explore the performance of FedAvg on varying non-IID severities, this example trains the VGG-16 model (a simple deep-learning-based image classification model) on constructed non-IID local datasets sampled from the CIFAR-10 dataset (located at <a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a>). CIFAR-10 is a well-known simple image classification dataset containing 60,000 images separated into 10 different classes; the goal of models trained on CIFAR-10 is to correctly predict the class associated with an input image. The relatively low complexity and ubiquity as a benchmark dataset make CIFAR-10 ideal for exploring the response of FedAvg to <span class="No-Break">non-IID data.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">To avoid including redundant code samples, this section focuses on the key lines of code that allow FL to be performed on PyTorch models using non-IID local datasets. It is recommended that you go through the examples within the <em class="italic">Example – the federated training of an NLP model</em> section in this chapter prior to reading this section in order to understand the core components needed for each FL framework. The implementations for this example can be found in full at this book’s GitHub repository (<a href="https://github.com/PacktPublishing/Federated-Learning-with-Python">https://github.com/PacktPublishing/Federated-Learning-with-Python</a> tree/main/ch8/cv_code), for use as <span class="No-Break">a reference.</span></p>
			<p>The key point of this example is determining how the non-IID datasets should be constructed. We will change the class label distributions of each local dataset by changing the number of images of each class included in the training dataset. For example, a dataset skewed toward cars and birds might have 5,000 images of cars, 5,000 images of birds, and 500 images for every other class. By creating three disjointed subsets of <a id="_idIndexMarker744"/>the 10 classes and <a id="_idIndexMarker745"/>constructing local datasets skewed toward these classes, we produce three local datasets with non-IID severity proportional to the number of images included from the classes <span class="No-Break">not selected.</span></p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor218"/>Skewing the CIFAR-10 dataset</h2>
			<p>We first map<a id="_idIndexMarker746"/> the three class subsets to client IDs, and set the proportion of images to be taken from the original dataset for selected classes (<strong class="source-inline">sel_count</strong>) and the other <span class="No-Break">classes (</span><span class="No-Break"><strong class="source-inline">del_count</strong></span><span class="No-Break">):</span></p>
			<pre class="source-code">
classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')
class_id_map = {
    1: classes[:3],
    2: classes[3:6],
    3: classes[6:]
}
sel_count = 1.0, def_count = 0.2</pre>
			<p>We then sample the appropriate number of images from the original dataset, using the indices of the images in the dataset to construct the skewed <span class="No-Break">CIFAR-10 subset:</span></p>
			<pre class="source-code">
class_counts = int(def_count * 5000) * np.ones(len(classes))
for c in classes:
    if c in class_rank_map[self.rank]:
        class_counts[trainset.class_to_idx[c]] = int(sel_count * 5000)
class_counts_ref = np.copy(class_counts)
imbalanced_idx = []
for i,img in enumerate(trainset):
    c = img[1]
    if (class_counts[c] &gt; 0):
        imbalanced_idx.append(i)
        class_counts[c] -= 1
trainset = torch.utils.data.Subset(trainset, imbalanced_idx)</pre>
			<p>The skewed<a id="_idIndexMarker747"/> trainset is then used to create the skewed <strong class="source-inline">trainloader</strong> for local training. When we refer to biasing the training data going forward, this is the code that <span class="No-Break">is run.</span></p>
			<p>We will now demonstrate how to use different FL frameworks to run this non-IID FL process. Please refer to the installation instructions and framework-specific implementations in the previous section, <em class="italic">Example – the federated training of an NLP model</em>, for the<a id="_idIndexMarker748"/> explanations of the basics omitted in <span class="No-Break">this section.</span></p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor219"/>Integrating OpenFL for CIFAR-10</h2>
			<p>Similar to <a id="_idIndexMarker749"/>the Keras <a id="_idIndexMarker750"/>NLP example, we first create the <strong class="source-inline">ShardDescriptor</strong> and <strong class="source-inline">DataInterface</strong> subclasses for the non-IID CIFAR-10 datasets in <strong class="source-inline">cifar_fl_dataset.py</strong>. Only a few changes need to be made in order to accommodate the <span class="No-Break">new dataset.</span></p>
			<p>First, we modify the <strong class="source-inline">self.data_by_type</strong> dictionary to instead store the modified <span class="No-Break">CIFAR datasets:</span></p>
			<pre class="source-code">
        train_dataset, val_dataset = self.load_cifar_data()
        self.data_by_type = {
            'train': train_dataset,
            'val': val_dataset
        }</pre>
			<p>The <strong class="source-inline">load_cifar_data</strong> function loads in the training and test data using <strong class="source-inline">torchvision</strong>, then biases the training data based on the rank passed to <span class="No-Break">the object.</span></p>
			<p>Because the dimensions of a data element are now known (the size of CIFAR-10 image), we also modify the shape properties with <span class="No-Break">fixed values:</span></p>
			<pre class="source-code">
    @property
    def sample_shape(self):
        return ["32", "32"]
    @property
    def target_shape(self):
        return ["10"] </pre>
			<p>We then implement the <strong class="source-inline">CifarFedDataset</strong> subclass of the <strong class="source-inline">DataInterface</strong> class. No significant modifications are needed for this implementation; thus, we can now use the biased CIFAR-10 dataset <span class="No-Break">with OpenFL.</span></p>
			<p>We now move to the actual FL process implementation (<strong class="source-inline">fl_sim.py</strong>). One key difference is the framework adapter that must be used to create the <strong class="source-inline">ModelInterface</strong> object from a <span class="No-Break">PyTorch model:</span></p>
			<pre class="source-code">
model = vgg16()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)
criterion = nn.CrossEntropyLoss()
framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'
MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)</pre>
			<p>The only other major change is modifying the train and validation functions passed to the <strong class="source-inline">TaskInterface</strong> object to mirror the PyTorch implementations of these functions from the local <span class="No-Break">training code.</span></p>
			<p>The <a id="_idIndexMarker751"/>last <a id="_idIndexMarker752"/>step is to create the configuration files used by the director and envoys. The only necessary change in the director config is the updated <strong class="source-inline">sample_shape</strong> and <strong class="source-inline">target_shape</strong> for the <span class="No-Break">CIFAR-10 data:</span></p>
			<pre class="source-code">
settings:
  listen_host: localhost
  listen_port: 50051
  sample_shape: ["32","32"]
  target_shape: ["10"]</pre>
			<p>This is saved <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">director/director_config.yaml</strong></span><span class="No-Break">.</span></p>
			<p>The envoy configuration files require no changes outside of updating the object and filenames – the directory structure should look like <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline">director</strong></span><ul><li><span class="No-Break"><strong class="source-inline">director_config.yaml</strong></span></li></ul></li>
				<li><span class="No-Break"><strong class="source-inline">experiment</strong></span><ul><li><span class="No-Break"><strong class="source-inline">envoy_config_1.yaml</strong></span></li><li><span class="No-Break"><strong class="source-inline">envoy_config_2.yaml</strong></span></li><li><span class="No-Break"><strong class="source-inline">envoy_config_3.yaml</strong></span></li><li><span class="No-Break"><strong class="source-inline">cifar_fl_dataset.py</strong></span></li><li><span class="No-Break"><strong class="source-inline">fl_sim.py</strong></span></li></ul></li>
			</ul>
			<p>You can<a id="_idIndexMarker753"/> refer <a id="_idIndexMarker754"/>to <em class="italic">Running the OpenFL example</em> in the <em class="italic">Integrating OpenFL for SST-2</em> section to run <span class="No-Break">this example.</span></p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor220"/>Integrating IBM FL for CIFAR-10</h2>
			<p>Recall<a id="_idIndexMarker755"/> that IBM FL <a id="_idIndexMarker756"/>requires a saved version of the model used during training. We first run the following code in <strong class="source-inline">create_saved_model.py</strong> to create the saved VGG-16 <span class="No-Break">PyTorch model:</span></p>
			<pre class="source-code">
import torch
from torchvision.models import vgg16
model = vgg16()
torch.save(model, 'saved_vgg_model.pt')</pre>
			<p>Next, we create the <strong class="source-inline">DataHandler</strong> subclass for the skewed CIFAR-10 datasets. The only core change is the modification of the <strong class="source-inline">load_and_preprocess_data</strong> function to instead load in the CIFAR-10 data and bias the <span class="No-Break">training set.</span></p>
			<p>The next step is to create the configuration JSON files used when starting the aggregator and initializing the parties. No significant changes to the aggregator config (<strong class="source-inline">agg_config.json</strong>) are necessary, and the only core change in the party config is the modification of the model information to work <span class="No-Break">with PyTorch:</span></p>
			<pre class="source-code">
    "model": {
        "name": "PytorchFLModel",
        "path": "ibmfl.model.pytorch_fl_model",
        "spec": {
            "model-name": "vgg_model",
            "model_definition": "saved_vgg_model.pt",
            "optimizer": "optim.SGD",
            "criterion": "nn.CrossEntropyLoss"
        }
    },</pre>
			<p>The code in <strong class="source-inline">fl_sim.py</strong> responsible for starting up the parties can essentially remain unmodified due to the extensive use of the <span class="No-Break">configuration files.</span></p>
			<p>You <a id="_idIndexMarker757"/>can<a id="_idIndexMarker758"/> refer to <em class="italic">Running the IBM FL example</em> in the <em class="italic">Integrating IBM FL for SST-2</em> section to run <span class="No-Break">this example.</span></p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor221"/>Integrating Flower for CIFAR-10</h2>
			<p>After<a id="_idIndexMarker759"/> loading in the CIFAR-10 data and biasing the training data, the <a id="_idIndexMarker760"/>core change needed for the Flower implementation is the <strong class="source-inline">NumPyClient</strong> subclass. Unlike the Keras example, the <strong class="source-inline">get_parameters</strong> and <strong class="source-inline">set_parameters</strong> methods rely on the PyTorch model state dictionaries and are a bit <span class="No-Break">more involved:</span></p>
			<pre class="source-code">
class CifarClient(fl.client.NumPyClient):
    def get_parameters(self, config):
        return [val.numpy() for _, val in model.state_dict().items()]
    def set_parameters(self, parameters):
        params_dict = zip(model.state_dict().keys(), parameters)
        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})
        model.load_state_dict(state_dict)</pre>
			<p>We modify the <strong class="source-inline">fit</strong> function to mirror the training code in the local training example and modify the evaluate function to similarly mirror the local training evaluation code. Note that we call <strong class="source-inline">self.set_parameters(parameters)</strong> in order to update the local model instance with the most <span class="No-Break">recent weights.</span></p>
			<p>We also set the <strong class="source-inline">grpc_max_message_length</strong> parameter to 1 GB when starting the Flower client and server to accommodate the larger VGG16 model size. The client initialization function is now <span class="No-Break">the following:</span></p>
			<pre class="source-code">
fl.client.start_numpy_client(
    server_address="[::]:8080",
    client=CifarClient(),
    grpc_max_message_length=1024**3
)</pre>
			<p>Finally, we <a id="_idIndexMarker761"/>modify <a id="_idIndexMarker762"/>the aggregator code in <strong class="source-inline">server.py</strong> – the custom strategy we used previously to save the aggregate model at the end of the last round needs to be modified to work with <span class="No-Break">PyTorch models:</span></p>
			<pre class="source-code">
        if (server_round == MAX_ROUNDS):
            vgg_model = vgg16()
            
            np_weights = fl.common.parameters_to_ndarrays(agg_weights[0])
            params_dict = zip(vgg_model.state_dict().keys(), np_weights)
            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})
            
            torch.save(state_dict, "final_agg_vgg_model.pt")</pre>
			<p>With this strategy, we can run the following line to start the server (adding the <strong class="source-inline">grpc_max_message_length</strong> parameter here <span class="No-Break">as well):</span></p>
			<pre class="source-code">
fl.server.start_server(
    strategy=SavePyTorchModelStrategy(),
    config=fl.server.ServerConfig(num_rounds=MAX_ROUNDS),
    grpc_max_message_length=1024**3
)</pre>
			<p>Refer to <em class="italic">Running the Flower example</em> in the <em class="italic">Integrating Flower for SST-2</em> section to run <a id="_idIndexMarker763"/><span class="No-Break">this </span><span class="No-Break"><a id="_idIndexMarker764"/></span><span class="No-Break">example.</span></p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor222"/>Integrating STADLE for CIFAR-10</h2>
			<p>We first <a id="_idIndexMarker765"/>modify <a id="_idIndexMarker766"/>the <strong class="source-inline">config_agent.json</strong> config file to use the VGG16 model from the <span class="No-Break"><strong class="source-inline">torchvision</strong></span><span class="No-Break"> library:</span></p>
			<pre class="source-code">
{
    "model_path": "./data/agent",
    "aggr_ip": "localhost",
    "reg_port": "8765",
    "token": "stadle12345",
    "base_model": {
        "model_fn": "vgg16",
        "model_fn_src": "torchvision.models",
        "model_format": "PyTorch",
        "model_name": "PyTorch-VGG-Model"
    }
}</pre>
			<p>To integrate STADLE into the local training code, we initialize the <strong class="source-inline">BasicClient</strong> object and modify the training loop to send the local model every two local training epochs and wait for the new <span class="No-Break">aggregate model:</span></p>
			<pre class="source-code">
    stadle_client = BasicClient(config_file="config_agent.json")
    for epoch in range(num_epochs):
        state_dict = stadle_client.wait_for_sg_model().state_dict()
        model.load_state_dict(state_dict)
        # Normal training code...
        if (epoch % 2 == 0):
            stadle_client.send_trained_model(model)</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The code located at <a href="https://github.com/PacktPublishing/Federated-Learning-with-Python">https://github.com/PacktPublishing/Federated-Learning-with-Python</a> contains the full implementation of this integration example for reference. To start an aggregator and perform FL with the CIFAR-10 STADLE example, please refer to <em class="italic">Creating a STADLE Ops project</em> and <em class="italic">Running the STADLE example</em> in the <em class="italic">Integrating STADLE for </em><span class="No-Break"><em class="italic">SST-2</em></span><span class="No-Break"> subsection.</span></p>
			<p>Testing <a id="_idIndexMarker767"/>different<a id="_idIndexMarker768"/> levels of bias in the constructed local datasets should lead to the same conclusion stated in the <em class="italic">Dataset distributions</em> section of <a href="B18369_07.xhtml#_idTextAnchor176"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Model Aggregation</em> for non-IID cases—as the non-IID severity increases, the convergence speed and model performance decrease. The goal of this section was to build off of the understanding of each FL framework from the SST-2 example, highlighting the key changes necessary to work with a PyTorch model on a modified dataset. Using this section alongside the code examples in <a href="https://github.com/PacktPublishing/Federated-Learning-with-Python">https://github.com/PacktPublishing/Federated-Learning-with-Python</a> should help in understanding this <span class="No-Break">example integration.</span></p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor223"/>Summary</h1>
			<p>In this chapter, we covered several FL frameworks through the context of two different examples. From the first example, you learned how a traditional centralized ML problem can be converted into the analogous FL scenario by separating the data into disjointed subsets. It is now clear that random sampling leads to local datasets that are IID, allowing FedAvg to reach the same level of performance as the centralized equivalent with any of the FL frameworks. </p>
			<p>In the second example, you learned one of the many ways a group of datasets can be non-IID (different class label distributions) and observed how different severities of non-IID datasets affect the performance of FedAvg. We encourage you to explore how alternative aggregation methods can improve on FedAvg in <span class="No-Break">these cases.</span></p>
			<p>Both examples also should have given you a solid understanding of the general trends when working with different FL frameworks; while the specific implementation-level details may change (due to the rapidly changing field), the core concepts and implementation details will remain fundamentals. </p>
			<p>In the next chapter, we continue our transition to the business application side of FL by taking a look at several case studies involving the application of FL to <span class="No-Break">specific domains.</span></p>
		</div>
	</body></html>