- en: 'Chapter 8: Managing Models at Scale Using a Model Registry'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you begin to deploy multiple models and manage multiple model versions, ensuring
    core architectural practices such as governance, traceability, and recoverability
    are followed is challenging without using a model registry. A model registry is
    a central store containing metadata specific to a model version. It includes information
    on how the model was built, the performance of that model, as well as where and
    how the model is deployed. Model registry services or solutions often include
    additional capabilities, such as approval workflows and notifications.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll cover the concept of a model registry and why a model
    registry is important for managing multiple models at scale. We'll also outline
    considerations you need to make when choosing a model registry implementation,
    in order to best meet the needs of your environment and operational requirements.
    For this, we'll examine two example implementations of a model registry. These
    will be a custom-built model registry using AWS services, as well as SageMaker's
    implementation (called the SageMaker model registry).
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker provides a built-in model registry. This is a fully managed
    model registry, optimized for use within Amazon SageMaker. However, if the Amazon
    SageMaker model registry does not meet your needs, there are several common patterns
    utilizing either a custom-built model registry or a third-party solution that
    also work well with Amazon SageMaker. Although there are many third-party model
    registries available that can be used for SageMaker-trained models, we do not
    cover them specifically in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a model registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a model registry solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing models using the Amazon SageMaker model registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need an AWS account to run the examples included in this chapter. If
    you have not set up the data science environment yet, please refer to [*Chapter
    2*](B17249_02_Final_JM_ePub.xhtml#_idTextAnchor039)*, Data Science Environments*.
    This provides a walk-through of the setup process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code examples included in the book are available on GitHub at the following
    URL: https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter08\.
    You will need to install a Git client to access them ([https://git-scm.com/](https://git-scm.com/)).'
  prefs: []
  type: TYPE_NORMAL
- en: The code for this chapter is in the `CH08` folder of the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Using a model registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A model registry allows you to centrally track key metadata for each model version.
    The granularity of metadata tracked is often dependent on the chosen implementation
    (Amazon SageMaker's model registry, a custom solution, or a third-party solution).
  prefs: []
  type: TYPE_NORMAL
- en: 'Regardless of the implementation, the key metadata to consider includes model
    version identifiers, and the following information about each model version registered:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model inputs**: These include metadata related to the inputs and versions
    of those inputs used to train the model. This can include inputs such as the name
    of the Amazon S3 bucket storing the training data, training hyperparameters, and
    the **Amazon Elastic Container Registry** (**ECR**) repository or container image
    used for training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model performance**: This includes model evaluation data such as training
    and validation metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model.tar.gz`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model deployment**: This includes metadata relating to the deployment of
    a model. This includes information such as the environment(s) a model version
    is deployed to, or the inference code that can be used for the registered model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon SageMaker offers multiple options for training models including built-in
    algorithms, built-in frameworks (that is, script mode), and a bring-your-own container.
    Depending on the option chosen, the number of inputs required to train a model
    can vary. This could impact the metadata you choose to track. As a result, it's
    important to determine the minimum requirements of metadata that you need to track
    in order to meet any regulatory or internal traceability requirements you may
    have.
  prefs: []
  type: TYPE_NORMAL
- en: 'When evaluating levels of granularity, you need to track your use case. Keep
    in mind the way your teams are using Amazon SageMaker to build models. *Figure
    8.1* illustrates an example of the inputs, metrics, and artifacts to consider
    for tracking across the SageMaker options for training models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Model build metadata across training options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_08_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 – Model build metadata across training options
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar considerations exist for tracking and storing model deployment data.
    The metadata tracked for model deployments should provide enough information to
    package the model for deployment using Amazon SageMaker, to a real-time endpoint,
    or using batch transform. This should also allow someone to easily identify where
    a given model version is deployed, as well as how it is packaged for deployment
    and consumption. *Figure 8.2* illustrates an example of the inputs, deployment
    stages, and artifacts to consider for tracking across the SageMaker options for
    deploying models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Model deploy metadata across deployment options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_08_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Model deploy metadata across deployment options
  prefs: []
  type: TYPE_NORMAL
- en: 'If you had a couple of models to manage, you could potentially track the previous
    information using a simple method, such as a spreadsheet. However, as you begin
    to scale to 20, 100, or thousands of models, that mechanism for tracking model
    metadata no longer scales. Centrally storing and tracking the information (shown
    in *Figures 8.1* and *8.2*) for each model version provides the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Operational efficiencies**: A model registry provides tracking and visibility
    into key inputs used to build a specific model version, output artifacts, and
    information about the deployment stages aligned to that version. Having this metadata
    allows for the ability to quickly understand how a model was built, how the model
    performed, information about the trained model artifact, and also provides the
    ability to track the environment(s) a specific version is deployed to.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recoverability**: To be able to recover a deployed model or roll back to
    a previous version, you need to have visibility to the inputs and input versions
    used to create a deployable artifact or a deployed model. In the event of system
    or human error, you can recover to a specific point in time using the metadata
    stored in the model registry, combined with protected versioned inputs. As an
    example, if an administrator were to accidentally delete a model endpoint, it
    should be easy to identify the artifacts needed to recreate that endpoint. This
    can be identified using metadata stored in the model registry that points to the
    location of the versioned model artifact, in combination with the versioned inference
    container image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pipeline sources and triggers**: Often there is a need to bridge the model
    build and model deployment environments. This is typical in large enterprises
    that have central deployment teams, or in organizations that separate model build
    and model deployment roles. A model registry provides a mechanism to capture the
    minimum metadata needed for visibility into how a model is built. However, it
    can also be used to trigger approval workflows and downstream deployments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we'll cover three patterns for creating a model registry
    to centrally track and manage machine learning models at scale. The considerations
    and high-level architectures of each will be outlined in order to guide you to
    the right fit for your specific use case.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a model registry solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are multiple options available for implementing a model registry. While
    each implementation offers different features or capabilities, the concept of
    providing a central repository to track key metadata largely remains the same
    across implementations. In this section, we''ll cover a few common patterns for
    creating a model registry, as well as discuss the considerations for each. The
    patterns covered in this section include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker model registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a custom model registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing a third-party or **open source software** (**OSS**) model registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon SageMaker model registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Amazon SageMaker model registry is a managed service that allows you to
    centrally catalog models, manage model versions, associate metadata with your
    model versions, and manage the approval status of a model version. The service
    is continuously evolving with new features, so the information contained in this
    section is current as of the publication date. It's always recommended to validate
    the current features and capabilities with the official documentation for the
    *Amazon SageMaker model registry* ([https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html)).
    The SageMaker model registry is optimized for use in conjunction with Amazon SageMaker
    Pipelines and projects; however, it can also be used independently as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can interact with the SageMaker''s model registry programmatically, as
    well as within Amazon SageMaker Studio. Studio provides a visual interface and
    experience for version management. The Studio interface also provides additional
    search capabilities. These can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – The SageMaker Studio interface for the SageMaker model registry'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_08_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.3 – The SageMaker Studio interface for the SageMaker model registry
  prefs: []
  type: TYPE_NORMAL
- en: 'The SageMaker model registry also includes an approval status that can be modified
    when a model is approved for production. This could be after a peer or designated
    deployment approver reviews the model metadata and metrics as a final quality
    gate for deployment. In the following screenshot, you can see how the approval
    status field integrates natively with MLOps projects in Amazon SageMaker Pipelines
    to create automatic triggers based on a change in model status:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – SageMaker model registry – approval status'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_08_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.4 – SageMaker model registry – approval status
  prefs: []
  type: TYPE_NORMAL
- en: 'The main components of the SageMaker model registry include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model registry**: This is the central store containing model groups and it
    exists at the AWS account and AWS region levels. Cross-account privileges can
    be set up to interact with the model registry from other AWS accounts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model groups**: Model groups are a logical grouping. They allow you to track
    different model versions that are related to, or grouped by, the same machine
    learning problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model packages**: Model packages are registered models or specific versions
    of a model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 8.5* illustrates the main components, where each model version is a
    model package contained in a model group inside the model registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Amazon SageMaker model registry components and usage'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_08_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.5 – Amazon SageMaker model registry components and usage
  prefs: []
  type: TYPE_NORMAL
- en: When registering a new model version within a model group, you can use either
    the AWS SDK for Python (`boto3`) with the `create_model_package` method ([https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model_package](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model_package)),
    or create a step within a model build pipeline, using the `RegisterModel` step
    ([https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#pipeline](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#pipeline))
    within Amazon SageMaker Pipelines. Understanding the ways you can register a model
    is important for understanding how you can use the SageMaker model registry outside
    of SageMaker Pipelines. It is also important for understanding how you can integrate
    the SageMaker model registry into other workflow tooling options you may already
    be using.
  prefs: []
  type: TYPE_NORMAL
- en: It's possible to register a model as either **versioned** or **unversioned**.
    Model packages that are versioned are part of a model group, and unversioned model
    packages are not part of a model group. The benefit of using a model group, or
    a versioned model, is the ability to logically group and manage models that are
    related, as well as provide the ability to automatically version models related
    to a specific **machine learning** (**ML**) problem. It's recommended to register
    your models using model groups with registered models that are versioned. This
    is the default setting.
  prefs: []
  type: TYPE_NORMAL
- en: 'A registered model has specific metadata that can be associated with that version.
    The metadata is defined and configured by the API request parameters. At high-level,
    the API accepts and associates the following key metadata as input:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inference specification**: A series of parameters that provide detailed information
    and guidance on hosting the model for inference. Information passed includes data
    such as the Amazon ECR data. This contains the inference code image, the Amazon
    S3 bucket containing the trained model artifact, and the supported instance types
    when hosting the model for either real-time inference or for batch inference.
    For example, if a model requires GPU for inference, that can be captured in the
    registry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model metrics**: Model evaluation metrics across evaluated categories, such
    as statistical bias in a model, or model quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Validation specification**: Information about the SageMaker batch transform
    job(s) that were used to validate the model package (if applicable).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Algorithm specification**: Details about the algorithm(s) used to create
    the model, as well as the Amazon S3 bucket containing the trained model artifact.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CodeCommit` commit ID, author of the source, the SageMaker Pipelines project
    ID, and the name of the `CodeCommit` repository. While they are not restricted
    for use outside Amazon SageMaker Pipelines, they are direct pointers to SageMaker
    Pipelines project resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model approval status**: This parameter is used to indicate whether a model
    is approved for deployment. This parameter can be used to manage workflows. In
    the case of SageMaker Pipelines projects, the automated workflow triggers are
    automatically set up based on the status of this field. If a model status is changed
    to **approved**, a downstream deployment workflow can be triggered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon SageMaker's model registry is fully managed, meaning there are no servers
    to manage. It also natively integrates into SageMaker Pipelines, providing the
    ability to integrate directly with the model registry as a native step in your
    model build pipeline. It does this using the `RegisterModel` step.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you build a model build pipeline that contains the automated
    steps for data processing, training, and model evaluation, you can add a conditional
    step to validate the evaluation metric. If the evaluation metric is above a specified
    threshold (for example, accuracy > 90%), the pipeline can then be configured to
    automatically register your model.
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker's model registry also integrates natively with SageMaker Pipelines
    projects. Projects allow you to automatically provision MLOps pipelines and provision
    patterns that take advantage of the model registry. SageMaker projects can be
    used to automatically set up the model package group, as well as the approval
    workflows that can be used to trigger the pre-configured downstream deployment
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker Pipelines is covered in more detail in [*Chapter 12*](B17249_12_Final_JM_ePub.xhtml#_idTextAnchor222),
    *Machine Learning Automated Workflows*. The model registry is a component within
    SageMaker Pipelines but can be used independently of SageMaker Pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Many of the parameters passed as input to the `CreateModelPackage` API are tailored
    for Amazon SageMaker use and integrations with other Amazon SageMaker features.
    For example, data that can be associated with model metrics has a direct correlation
    with metrics produced with features such as Amazon SageMaker Clarify, model statistical
    bias metrics, Amazon SageMaker Model Monitor, and data quality constraint metrics.
    In another example, the validation specification relates specifically to a SageMaker
    batch transform job run to evaluate the SageMaker model package.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we reviewed the high-level architecture and usage of the Amazon
    SageMaker model registry to provide a basis for comparison against other options
    that will be covered in the next sections. Multiple options are being covered
    in this chapter. This is in order to support a variety of use cases and to help
    you choose the right option for your specific use case.
  prefs: []
  type: TYPE_NORMAL
- en: Building a custom model registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A model registry can also be built using AWS services. Building a custom registry
    requires more effort to build the solution, set up the integrations between AWS
    services, set up the ML pipeline integrations, and then manage the solution. However,
    a custom registry also offers the ability to completely customize a registry to
    meet the needs specific to your use case. This could include requirements specific
    to tracking more granular metadata, or requirements to support multiple ML services/platforms.
    In this section, we'll review one pattern for creating a custom model registry
    using AWS services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pattern shown in *Figure 8.6* illustrates a simple model registry built
    using Amazon DynamoDB. DynamoDB can be used to store model metadata using a design
    pattern that separates groups of models by partition key. You could also consider
    a design pattern establishing a new table for different teams or business units
    if table-level isolation is preferred. Controls should also be set up using **AWS
    Identity and Access Management** (**IAM**) to control access to DynamoDB for specific
    tables, as well as specific primary keys to set up controls on who can access
    specific model groupings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Custom-built model registry using AWS services'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_08_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6 – Custom-built model registry using AWS services
  prefs: []
  type: TYPE_NORMAL
- en: The schema for a model registry based on DynamoDB provides flexibility in the
    metadata that can be stored for each model version. As an example, you may want
    to track data versions that correspond to the object(s) in an Amazon S3 bucket.
    A custom-built model registry provides the flexibility to define and adjust the
    schema to meet your individual requirements for traceability or for more granular
    metadata tracking.
  prefs: []
  type: TYPE_NORMAL
- en: Interacting with a custom-built model registry can be done through the Amazon
    DynamoDB API (**PutItem**) or through a custom-built API. Using a simple **PutItem**,
    API can often work for smaller teams or teams that perform end-to-end tasks, such
    as model building, model deployment, and operating in a production environment.
    However, in many cases, a model registry is built as part of a shared service
    (or ML platform component) that serves multiple teams and use cases. In this case,
    it's recommended to build an API that includes similar controls and validations
    that are seen in a managed service, such as SageMaker's model registry.
  prefs: []
  type: TYPE_NORMAL
- en: To extend a custom-built model registry to include workflow tasks, such as triggering
    a model deployment pipeline based on a changed attribute, the solution needs to
    be extended to set up the trigger to detect a change and then execute any downstream
    processes you want to invoke. To do this, you can enable DynamoDB Streams and
    AWS Lambda triggers.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered a high-level implementation pattern for creating
    a custom model registry using AWS services. This example provides complete flexibility
    in the registry schema, data points collected, and in defining the intended usage.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, you may have some teams that utilize Amazon SageMaker features,
    but other teams that are utilizing other services or even building models on-premises.
    Building a custom registry also allows the flexibility to place the model registry
    in the AWS account you choose, based on your existing multi-account strategy,
    and adjust the schema based on usage.
  prefs: []
  type: TYPE_NORMAL
- en: The pattern discussed also utilizes AWS-managed services, DynamoDB and API Gateway,
    meaning there are still no servers to manage. However, this is not a packaged
    solution. Therefore, the services need to be set up and configured. Interfacing
    code may need to be written, integrations between services need to be set up,
    and the solution needs to be managed.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing a third-party or OSS model registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, we'll briefly cover using a third-party or OSS implementation of a model
    registry. Because there are a lot of options available, this section will focus
    on high-level considerations, rather than diving deep into any specific implementation.
    Common implementations, such as MLflow, have existing documentation provided for
    integrating with Amazon SageMaker. Those resources should be utilized when implementing
    a third-party/OSS implementation and integrating with Amazon SageMaker.
  prefs: []
  type: TYPE_NORMAL
- en: 'When considering a third-party or OSS implementation, there are a few questions
    to consider when evaluating your options:'
  prefs: []
  type: TYPE_NORMAL
- en: Does the implementation require you to manage the underlying servers, meaning
    you need to incur some additional operational overhead to ensure servers are patched,
    monitored, scaled, and set up using a readily available architecture?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the implementation offer native integrations that make it easy to integrate
    with Amazon SageMaker?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What additional credentials do you need to set up and manage in order to integrate
    with Amazon SageMaker?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a third-party or OSS option can add some additional overheads in terms
    of setup, integration, and ongoing management. However, many of these implementations
    offer robust capabilities, interfaces, and extensibility that may be preferred
    depending on your ML environments and use cases.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discussed three common patterns for model registry implementations
    for use with Amazon SageMaker models. Each pattern can be a valid choice depending
    on your requirements. As a result, key considerations for each were discussed
    to provide general guidance in order to choose the best implementation.
  prefs: []
  type: TYPE_NORMAL
- en: In general, it is recommended to choose the option that provides the capabilities
    you need based on your own requirements, combined with the option that offers
    the lowest development and operational overhead. In the next section, we'll narrow
    the focus to a technical deep dive into the Amazon SageMaker model registry.
  prefs: []
  type: TYPE_NORMAL
- en: Managing models using the Amazon SageMaker model registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An introduction to the Amazon SageMaker model registry was included in the section
    titled *Amazon SageMaker model registry*. This was done in order to explain the
    high-level architecture and features that are important to consider when choosing
    a model registry implementation. In this section, we'll dive deeper into the Amazon
    SageMaker model registry by covering the process and best practice guidance when
    setting up and using SageMaker's model registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'SageMaker''s model registry includes the model registry, as well as model groups
    and model packages. Each model group contains model versions, or model packages,
    related to the same ML problem. Each model package represents a specific version
    of a model and includes metadata associated with that version. The SageMaker model
    registry APIs are used when interacting with the SageMaker model registry, and
    those APIs can also be called through any of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`create-model-package-group` or `create-model-package` commands.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`boto3`): This uses methods to interact with the model registry, such as the
    `create_model_package_group` or `create_model_package` methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon SageMaker Studio**: This uses the click-through interface in SageMaker
    Studio (as shown in *Figure 8.7*) to create a model package group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RegisterModelstep`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 8.7* illustrates creating a model package group using the Studio UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Using SageMaker Studio to create a new model group'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_08_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.7 – Using SageMaker Studio to create a new model group
  prefs: []
  type: TYPE_NORMAL
- en: Although you can interact with the model registry using any of the methods listed,
    in this chapter we'll cover interacting with the model registry using the AWS
    Python SDK (`boto3`), to showcase a lower level of abstraction that is not dependent
    on Amazon SageMaker Studio or Amazon SageMaker Pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you learned more about the primary components of the SageMaker
    model registry, as well as the different ways you can interact with the model
    registry either programmatically or via the Studio UI.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a model package group
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A model package group contains a collection of model packages or model versions.
    A model package group is not required for registering a model package; however,
    it is recommended for the manageability of your model versions across ML use cases.
    A model package group can contain one or more model packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a model package group involves a method that accepts only a few parameters
    on input to configure, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is used to create a model package group that can then be
    used by ML builders, as well as with ML pipelines to register model packages (versions)
    for deployment. Configuration for a model package group requires only a model
    package group name and optionally a description and any tags you want to associate
    with the model group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recommendations when creating model package groups include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Establishing naming standards for model package groups**: As the number of
    model package groups grows, having clear naming standards can help with easily
    identifying and searching for related model package groups. Some considerations
    may include a team identifier and/or project identifier. Because it''s common
    to have more than one team working on models, a team identifier can help easily
    sort and search for models specific to a given team. It''s also common to have
    more than one model used in an overall solution. In this case, it is valuable
    to have a way to group models related to a specific project or solution. This
    can be done through established naming conventions, as well as tagging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MLProject` is created with the value of `weather`. In this case, let''s assume
    a weather team is responsible for building weather-related models and only team
    members belonging to the weather team should be able to view model package groups
    with this tag. Resource tags can be used to establish conditional policies for
    access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a model package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A model package is a model version that can exist outside of a model package
    group, referred to as *unversioned*, or inside a model package group, referred
    to as *versioned*. A model package outside of a model package group is referred
    to as unversioned because it's not using the versioning capabilities of a model
    package group. It's recommended to register model packages using model package
    groups for automatic management of model versions, and for added manageability
    as the number of model versions increases.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker has two concepts called `CreateModel` API. This is required
    to deploy your model using Amazon SageMaker and is discussed in the *Amazon SageMaker
    documentation* ([https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-mkt-model-pkg-model.html](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-mkt-model-pkg-model.html)).
    The second example, and the one we refer to in this chapter, is a model package
    specifically for Amazon SageMaker's model registry that is created using the `CreateModelPackage`
    API.
  prefs: []
  type: TYPE_NORMAL
- en: The `CreateModelPackage` API accepts several parameters on input. The high-level
    parameter categories were already covered in the section titled *Amazon SageMaker
    model registry*, so in this section, we'll include an example that uses those
    parameters to then register a model using our sample use case. In [*Chapter 12*](B17249_12_Final_JM_ePub.xhtml#_idTextAnchor222),
    *Machine Learning Automated Workflows*, we'll again discuss the model registry
    in the context of an ML pipeline, to demonstrate how a model registry can be integrated
    into your automated workflows. For now, we'll focus on registering a model package
    as an indication that it has passed initial model validation outside of a pipeline
    workflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the model has been trained and we''ve evaluated the training
    metrics. Once our model reaches the minimum threshold identified for our evaluation
    metric, we are ready to register the model package. Using the AWS Python SDK (`boto3`),
    we''ll register the model package, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`ModelPackageGroupName` is required to associate the model package with a model
    package group. This allows you to take advantage of automatic versioning, as previously
    discussed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The model packages can then be viewed using the `list_model_packages` method,
    as well as within Amazon SageMaker Studio. To list the model package, use the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Recommendations when creating model packages include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating versioned packages**: Associate model packages with a model group
    by specifying the model package group when you create your model package. This
    allows for automatic versioning and grouping of use cases for easier management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ApprovalStatus` can optionally be used after a peer review of the registered
    model to indicate minimum standards or criteria have been met for that model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Protecting the inputs/artifacts referred to in the model registry**: Details
    contained in the model registry can be used to recreate or roll back deployed
    models; however, those resources need to be protected from unauthorized access
    or accidental deletion. For example, if an administrator accidentally deletes
    a SageMaker endpoint, it can still be easily recreated using the resources identified
    in the model registry. This would include the S3 object containing the model artifact,
    the S3 object with inference code (optional), and the ECR inference image. If
    any of those inputs are not available or cannot be guaranteed, then re-creating
    that endpoint may not be possible. Therefore, the metadata gives the information
    required, but there are still additional steps needed to protect inputs and artifacts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Considering tags when additional metadata is needed**: The metadata within
    SageMaker''s model registry is fixed to the input parameters that are defined
    in the API. However, tags can be used to supplement additional metadata. An example
    of the recommended use of tags here would be to capture the S3 version for resources
    such as the model artifact, in order to include more granularity on artifact tracking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MLProject` is created with the value of `weather`. In this case, let''s assume
    a weather team is responsible for building weather-related models and only team
    members from this team should be able to register new models to this model package
    group or other model package groups created with this tag. Resource tags can be
    used to establish conditional policies for access, in order to create model packages
    within specific model package groups. Resource tags can be used to establish conditional
    policies for access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we detailed the steps necessary to create a model package group
    and register model packages to that model package group using the sample code
    provided for this chapter. We also outlined recommendations to consider when creating
    your own model package groups and model packages. [*Chapter 12*](B17249_12_Final_JM_ePub.xhtml#_idTextAnchor222),
    *Machine Learning Automated Workflows*, will expand on the information covered
    in this chapter to include integrating Amazon SageMaker's model registry into
    an MLOps pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered model registries and the benefits of utilizing a
    model registry to manage Amazon SageMaker models at scale. Common patterns for
    model registry implementations were covered, including Amazon SageMaker's model
    registry, building a custom model registry using AWS services, and utilizing a
    third-party or OSS model registry implementation. Each option is a valid choice
    depending on your use case and needs. However, we also highlighted some of the
    considerations when choosing the implementation that best fits your requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we did a deep dive into Amazon SageMaker's model registry, covering
    detailed recommendations for creating model package groups, as well as registering
    models by creating model packages.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll cover performing live tests and updates of production
    models using Amazon SageMaker endpoint production variants.
  prefs: []
  type: TYPE_NORMAL
