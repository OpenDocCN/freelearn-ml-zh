- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Detecting Fake Reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reviews are an important element in online marketplaces as they convey the customer
    experience and their opinions on products. Customers heavily depend upon reviews
    to determine the quality of a product, the truth about various claims in the description,
    and the experiences of other fellow customers. However, in recent times, the number
    of fake reviews has increased. Fake reviews are misleading and fraudulent and
    cause harm to consumers. They are prevalent not only on shopping sites but also
    on any site where there is a notion of reputation through reviews, such as Google
    Maps, Yelp, Tripadvisor, and even the Google Play Store.
  prefs: []
  type: TYPE_NORMAL
- en: Fraudulent reviews harm the integrity of the platform and allow scammers to
    profit, while genuine users (sellers and customers) are harmed. As data scientists
    in the security space, understanding reputation manipulation and how it presents
    itself, as well as techniques for detecting it, is essential. This chapter focuses
    on examining reputation manipulation through fake reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Reviews and integrity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling fake reviews with regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have a clear understanding of reputation
    manipulation through fake reviews and how they can be detected. You will also
    learn about statistical tests and how to apply them for analysis and how the reviews
    data can be modeled using regression.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%204](https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%204).
  prefs: []
  type: TYPE_NORMAL
- en: Reviews and integrity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us first look at the importance of online reviews and why fake reviews exist.
  prefs: []
  type: TYPE_NORMAL
- en: Why fake reviews exist
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'E-commerce websites always have reviews for products. Reviews play an important
    role in the online world. Reviews allow consumers to post their experiences and
    facilitate peer-to-peer reputation building. Reviews are important on online platforms
    for several reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Online reviews provide valuable information to potential customers about the
    quality and performance of a product or service. Customers can read about other
    people’s experiences with a product or service before deciding whether to buy
    it or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviews from other customers help build trust between the seller and the buyer.
    Positive reviews can reassure potential customers that a product or service is
    worth buying, while negative reviews can warn them about potential problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online reviews can provide businesses with valuable feedback about their products
    and services. This feedback can help businesses improve their offerings and customer
    service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online reviews can also help businesses improve their search engine rankings.
    Search engines such as Google take into account the number and quality of reviews
    when ranking websites in search results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is therefore natural that better reviews imply better sales and more profit
    for the seller. The seller has an incentive to have as many great reviews for
    their product as possible, and this has led to the problem of fake reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fake reviews are reviews that are deliberately written to mislead or deceive
    readers. They can be positive or negative and are usually written by individuals
    or companies who have a vested interest in manipulating the reputation of a product
    or service. Here are some common types of fake reviews:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Paid reviews**: Some individuals or companies pay people to write positive
    reviews about their products or services, even if they haven’t used them'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fake negative reviews**: Competitors or individuals with a grudge may write
    fake negative reviews to harm the reputation of a business or product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Review swaps**: Some individuals or companies offer to exchange positive
    reviews with other businesses or individuals to boost their own ratings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Review bots**: Some businesses use automated software programs to generate
    large numbers of fake reviews quickly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fake reviews are problematic because they can mislead potential customers into
    making poor purchasing decisions. They can also harm the reputation of businesses
    that rely on genuine customer feedback to improve their products and services.
    Many online platforms have policies in place to detect and remove fake reviews
    to protect the integrity of their review systems. For example, Amazon explicitly
    bans reviewers from receiving any compensation or free products in exchange for
    reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Evolution of fake reviews
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The problem of fake reviews and reputation manipulation is not a new one – it
    has existed for decades. However, the nature of fake reviews has changed significantly,
    from bot-generated reviews to crowdsourced reviews and then to incentivized reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Bot-generated reviews
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'These were the very first form of fake reviews that could be onboarded by sellers
    at scale. Bot-generated reviews are reviews that are created using automated software
    programs, also known as review bots. These bots are designed to generate and post
    a large number of reviews quickly, without any human intervention. These reviews
    have several tell-tale signs:'
  prefs: []
  type: TYPE_NORMAL
- en: They are usually generic and lack specific details about the product or service
    being reviewed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They may use similar language and sentence structures and often have a high
    number of positive ratings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They also exhibit similarities in terms of the IP addresses, subnets, and networks
    that they come from
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many online platforms have implemented measures to detect and remove bot-generated
    reviews to maintain the integrity of their review systems. Some of these measures
    include using machine learning algorithms to identify patterns in the reviews,
    monitoring for suspicious IP addresses and activity, and requiring reviewers to
    verify their identities.
  prefs: []
  type: TYPE_NORMAL
- en: Crowdsourced reviews
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Knowing that bot-generated reviews were easy to detect by flagging IP addresses
    and other symptoms of automated activity, malicious sellers turned to crowdsourced
    reviews. With this kind of fake reviews, crowd workers are hired simply to write
    hundreds of reviews for products. These individuals are often part of online marketplaces
    or platforms that offer payment in exchange for writing positive reviews about
    products or services. Crowd workers may not have actually used the product or
    service being reviewed and may simply be provided with basic information to write
    a review. Sourced on freelancing and crowd-working websites such as Amazon MTurk
    or Fiverr, these crowd workers work on a commission basis and earn a fee for every
    review they post. Notably, these reviews have certain peculiar characteristics
    as well. As many reviews are written by the same user, they show very high inter-review
    similarity. They also show high burstiness (that is, a sudden spike in the number
    of reviews, corresponding to the time when the crowd worker was hired). These
    signals can be used as features to detect this type of reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Incentivized reviews
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These are the latest trend in online fake reviews. Incentivized reviews are
    reviews written by customers who have received some form of compensation or reward
    in exchange for their reviews. This compensation can come in various forms, such
    as free products, discounts, gift cards, refunds, or other incentives. Incentivized
    reviews are often used by companies as a marketing strategy to increase positive
    reviews and ratings of their products or services. By providing incentives to
    customers, companies hope to encourage them to write positive reviews, which can
    then be used to attract more customers and boost sales.
  prefs: []
  type: TYPE_NORMAL
- en: However, incentivized reviews can be controversial because they can create a
    bias toward positive reviews and may not accurately reflect the true opinions
    of customers. This is because customers who receive incentives may feel obligated
    to write a positive review, even if they did not have a positive experience with
    the product or service. As a result, many review platforms and websites have strict
    policies against incentivized reviews and may remove them from their platforms
    to ensure the integrity of their review system.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to bot-generated or crowdsourced reviews, incentivized reviews are
    less easy to detect. These are written by human users and hence do not show the
    symptoms of automated activity as bots do. As these are real users and not crowd
    workers, these reviews also show less similarity.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will try to understand some review data and check whether
    there are any differences between genuine and fake reviews. We will use the Amazon
    fake reviews dataset that Amazon has published on Kaggle. It is a set of around
    20,000 reviews with associated labels (real or fake) as labeled by domain experts
    at Amazon.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory data analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will first load up the data and take a first pass over it to understand the
    features and their distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by importing the necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then read the `reviews` data. Although it is a text file, it is structured
    and therefore can be read with the `read_csv` function in Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This is what the output should look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – A glimpse of the reviews dataset](img/B19327_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – A glimpse of the reviews dataset
  prefs: []
  type: TYPE_NORMAL
- en: Notice the **LABEL** column in the data. Rather than a simple label, it has
    labels of **__label1__** and **__label2__**. Looking at the documentation for
    this dataset, we can see that **__label1__** corresponds to real reviews, and
    **__label2__** to fake ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'For easier understanding, we will transform these labels. We want `0` to correspond
    to a real review, and `1` to a fake one. The following code snippet does this
    for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The output of this code is as follows. You can see that a new column, **FRAUD_LABEL**,
    with **0** and **1** values has been created.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Dataset with clear labels added](img/B19327_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – Dataset with clear labels added
  prefs: []
  type: TYPE_NORMAL
- en: First, we want to look at the distribution of real and fake reviews. This will
    tell us whether the dataset is balanced. If it is an imbalanced dataset, we may
    have problems in building a classifier. If it is highly imbalanced (such as only
    1% of the reviews being fake), we may want to move from classification to an anomaly
    detection approach.
  prefs: []
  type: TYPE_NORMAL
- en: Note that there is a product category feature in the dataset. We want to examine
    how reviews are distributed across categories. We do this because different kinds
    of products may have different kinds of reviews. The nature of fake reviews for
    home apparel might be different from the ones for electronics products. We want
    to look at the distribution to anticipate any bias or generalization concerns.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, we will group the reviews by category, and count the number of reviews
    per category. The result in the form of a bar graph will show us the distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The output should be as follows. We can see that there are ~30 categories of
    products, and each one has 350 real and 350 fake reviews. This dataset is therefore
    well balanced and we do not need to worry about bias coming from the review category
    feature.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Review distribution across categories](img/B19327_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Review distribution across categories
  prefs: []
  type: TYPE_NORMAL
- en: Next, we want to check how the real and fake reviews are distributed across
    ratings. This is an important factor to consider, and failing to do so can result
    in a biased model. For example, if the dataset is set up so that the fake reviews
    are all 4-star and 5-star and all the real reviews are 1-star and 2-star, our
    model will learn to detect sentiment instead of review authenticity. The sentiment
    will introduce bias into our model and this beats the actual purpose of building
    the model itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will group the reviews by rating and calculate the number of real and fake
    reviews for every rating. Note that this is feasible because there are only five
    classes of ratings and they are discrete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The output is shown as follows. We can see that there is some disparity in the
    number of reviews by rating class (there are only 2,000 1-star reviews whereas
    there are around 12,000 5-star reviews). However, within each class, the number
    of real and fake reviews is roughly equal. Therefore, the data is well distributed
    on the rating front as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Review distribution across ratings](img/B19327_04_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 – Review distribution across ratings
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will review the distribution of real and fake reviews by whether
    they are verified or not. A review being verified means that the e-commerce platform
    guarantees that the product was actually purchased by the reviewer, typically
    on the platform itself. We can observe the distribution with the following code
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is shown in the following bar plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Review distribution across the verified label](img/B19327_04_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 – Review distribution across the verified label
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at it, we observe two interesting occurrences:'
  prefs: []
  type: TYPE_NORMAL
- en: In the verified reviews, the percentage of genuine (real) reviews is higher
    than the fake ones. There are almost 9,000 real reviews, but only around 3,000
    fake ones. This means that only 25% of verified reviews are fake.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the non-verified reviews, we see that the trend is reversed. There are almost
    7,000 fake reviews and approximately 1,800 real reviews. Therefore, almost 80%
    of non-verified reviews are fake.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This trend is natural. It is simpler for a bot or review service to trivially
    generate non-verified reviews. However, generating a verified review involves
    actually buying the product, which incurs additional expenses.
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will extract some features from the `reviews` data. The
    goal is to characterize fake reviews by certain signals or trends they may exhibit.
    Here, we build these features using our intuition, as well as leveraging prior
    research in the field.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will write a function to extract the length of the review. This function
    first checks whether the review text is empty. If so, it returns `0`. If not,
    it returns the number of words in the review:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will write a function to compute the average word length in the review.
    To do so, we will split the review into individual words, add up their lengths,
    and divide by the total number of words to compute the mean. Of course, we must
    first check that the review is not empty:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Another feature we will derive is the number of words spelled incorrectly in
    the review. We will use the `enchant` Python library for this. The `enchant` Python
    library is a module that provides an interface to the `enchant` spellchecking
    system. `enchant` is a C/C++ library that provides a unified interface for several
    different spellchecking engines, including Aspell, Hunspell, and MySpell. `enchant`
    can be used from within your Python code to perform spellchecking on text. `enchant`
    provides a number of useful features for spellchecking, including suggestions
    for misspelled words, the ability to add and remove words from a user dictionary,
    and the ability to work with multiple languages.
  prefs: []
  type: TYPE_NORMAL
- en: To use `enchant` in your Python code, you first need to install the `enchant`
    library on your system. This can be done using the Python `pip` utility. Once
    installed, you can import the `enchant` module into your Python code and use the
    provided functions to perform spell checking.
  prefs: []
  type: TYPE_NORMAL
- en: 'To derive our feature, we will split the review into words, and count the number
    of words that are incorrectly spelled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Finally, now that we have defined the functions to extract features, it is time
    to put them to use. We will efficiently compute the features for each review in
    our DataFrame using the `apply()` function in Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: The `apply()` function in the pandas library is used to apply a given function
    to every element of a pandas DataFrame, Series, or column. It can be used to transform,
    filter, or aggregate the data in the DataFrame, and is a powerful tool for data
    manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: The `apply()` function takes a function as an argument, which is applied to
    every element in the DataFrame. The function can be defined by the user or can
    be a built-in Python function. In this case, we will use the custom functions
    we defined earlier. The `apply()` function also has some optional arguments that
    can be used to customize its behavior, such as its axis (to specify whether to
    apply the function row-wise or column-wise) and arguments (to pass additional
    arguments to the function).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how we will use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This completes our feature-engineering code. You can, of course, add more features
    if you wish to experiment!
  prefs: []
  type: TYPE_NORMAL
- en: Statistical tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have our features, we want to check whether they differ between
    real and fake reviews. The process of testing for differences is known as hypothesis
    testing.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hypothesis testing is a statistical method used to determine whether a claim
    or hypothesis about a population parameter is supported by the evidence provided
    by a sample of data. In other words, it is a way to test the validity of a hypothesis
    or claim about a population based on a sample of data.
  prefs: []
  type: TYPE_NORMAL
- en: The hypothesis being tested is typically called the null hypothesis (H0), and
    the alternative hypothesis (H1) is the hypothesis that is considered as an alternative
    to the null hypothesis. The null hypothesis usually represents the status quo
    or the default assumption, and the alternative hypothesis represents the hypothesis
    that the researcher is trying to support.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the previous section, we have data belonging to two different groups:
    real reviews and fake reviews. Here is how the process of hypothesis testing will
    work for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Formulating the null and alternative hypotheses**: The null hypothesis represents
    the status quo or the default assumption, and the alternative hypothesis represents
    the hypothesis that the researcher is trying to support. In this case, the null
    hypothesis would be that there is no difference between the features of the group
    of fake reviews and the group of real reviews. The alternative hypothesis would
    be that there is a difference between the features of the two groups.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Collecting and analyzing data**: A sample of data is collected, and descriptive
    statistics and inferential statistics are used to analyze the data. A sample of
    reviews is collected, including both fake and real reviews. The feature of interest
    (such as the length or average word length) is computed for each review in the
    sample, and descriptive statistics are calculated for each group of reviews, including
    the mean and standard deviation of the feature.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Choosing the level of significance**: The level of significance represents
    the probability that we will reject the null hypothesis even when it is true.
    The lower the significance level, the lower the chances of falsely rejecting the
    null hypothesis, which means higher confidence in our estimate. The most commonly
    used level of significance is 0.05, which means that there is a 5% chance of rejecting
    the null hypothesis when it is actually true.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Calculating the test statistic**: A test statistic is calculated based on
    the sample data, which measures how far the sample statistic is from the null
    hypothesis. The test statistic depends on the type of test being performed. For
    example, if we are comparing the means of the two groups, we can use a t-test
    to calculate the t-value, which measures the difference between the means of the
    fake reviews and the real reviews relative to the variability of the data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Determining the p-value**: The p-value is the probability of obtaining a
    test statistic as extreme or more extreme than the one observed, assuming that
    the null hypothesis is true. In this case, the null hypothesis is that there is
    no difference between the features of the group of fake reviews and the group
    of real reviews. If the p-value is less than 0.05, we reject the null hypothesis
    and conclude that there is a significant difference between the features of the
    two groups. If the p-value is greater than or equal to 0.05, we fail to reject
    the null hypothesis and conclude that there is not enough evidence to conclude
    that there is a significant difference. Note that we can simply reject or not
    reject the null hypothesis - we can never conclude that we accept the alternate
    hypothesis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Making a decision**: Based on the p-value and the level of significance,
    a decision is made on whether to reject the null hypothesis or not. If the p-value
    is less than 0.05, we reject the null hypothesis and conclude that there is a
    significant difference between the features of the group of fake reviews and the
    group of real reviews. If the p-value is greater than or equal to 0.05, we fail
    to reject the null hypothesis and conclude that there is not enough evidence to
    conclude that there is a significant difference.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Drawing conclusions**: The final step is to draw conclusions based on the
    results of the hypothesis test and to determine whether the evidence supports
    the alternative hypothesis or not. In this case, if we reject the null hypothesis,
    we conclude that there is a significant difference between the features of the
    group of fake reviews and the group of real reviews. If we fail to reject the
    null hypothesis, we conclude that there is not enough evidence to conclude that
    there is a significant difference between the features of the two groups.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Overall, hypothesis testing is a powerful statistical method used to test claims
    about populations using sample data. By following these given steps, we can make
    informed decisions based on data and draw valid conclusions about whether there
    is a significant difference between the features of the group of fake reviews
    and the group of real reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Note that here we have used real and fake reviews as an example. In theory,
    this experiment can be repeated for any two groups and any features. In the chapters
    to come, we will see several examples of varied datasets (containing images, text,
    video, and malware). We will also collect different kinds of features (image feature
    vectors, linguistic features, and API call sequences). While we will not conduct
    hypothesis testing every time, you are highly encouraged to do so in order to
    strengthen your understanding of the concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have defined clearly the steps involved in hypothesis testing,
    let us look at the most crucial part of it: the actual tests being conducted.'
  prefs: []
  type: TYPE_NORMAL
- en: T-tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: T-tests are a statistical method used to compare the means of two groups and
    determine whether there is a statistically significant difference between them.
    The t-test is a hypothesis test that is based on the t-distribution, which is
    similar to the normal distribution but with a heavier tail.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main types of t-tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Independent samples t-test**: This test is used when we want to compare the
    means of two independent groups, such as a treatment group and a control group,
    or a group of men and a group of women. The null hypothesis is that there is no
    difference in the means of the two groups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Paired samples t-test**: This test is used when we want to compare the means
    of two related groups, such as before-and-after measurements for the same individuals,
    or measurements taken from two matched groups. The null hypothesis is that there
    is no difference between the means of the two related groups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The t-test calculates a t-value, which is a measure of how different the means
    of the two groups are, relative to the variability within each group. The t-value
    is calculated by dividing the difference between the means of the two groups by
    the standard error of the difference. The standard error of the difference takes
    into account both the sample sizes and the variances of the two groups.
  prefs: []
  type: TYPE_NORMAL
- en: 'T-tests can be one-sided or two-sided:'
  prefs: []
  type: TYPE_NORMAL
- en: '**One-sided t-test**: A one-sided t-test, also known as a directional t-test,
    is used when we have a specific hypothesis about the direction of the difference
    between the means of the two groups. For example, we might hypothesize that the
    mean of one group is greater than the mean of the other group. In this case, we
    would use a one-sided t-test to test this hypothesis. The null hypothesis for
    a one-sided t-test is that there is no difference between the means of the two
    groups in the hypothesized direction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Two-sided t-test**: A two-sided t-test, also known as a non-directional t-test,
    is used when we do not have a specific hypothesis about the direction of the difference
    between the means of the two groups. For example, we might simply want to test
    whether the means of the two groups are different. In this case, we would use
    a two-sided t-test. The null hypothesis for a two-sided t-test is that there is
    no difference between the means of the two groups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the t-value is calculated, we can determine the p-value, which is the probability
    of obtaining a t-value as extreme or more extreme than the one observed, assuming
    that the null hypothesis is true. If the p-value is less than the level of significance
    (usually 0.05), we reject the null hypothesis and conclude that there is a statistically
    significant difference between the means of the two groups.
  prefs: []
  type: TYPE_NORMAL
- en: T-tests are commonly used in many fields, such as psychology, biology, economics,
    and engineering, to compare the means of two groups and make statistical inferences.
    Note that in t-tests, we always decide on whether the null hypothesis is to be
    rejected based on the p-value. If the p-value is higher than our chosen threshold,
    we never say that we *accept* the alternate hypothesis; we simply say that we
    *failed to reject* the null hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: Conducting t-tests
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We will now see how the t-test is actually conducted in Python and what information
    it gives us. Let us use the t-test to compare the distribution of the *review
    text length* feature in the fake and real reviews group. Therefore, our hypotheses
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The null hypothesis (H0) is that the mean review length is the same for real
    and fake reviews
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The alternate hypothesis (H1) is that the mean review length between the two
    groups is different
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note that this is an unpaired t-test as samples in both groups are independent.
    This is also a two-tailed t-test as our hypothesis is not directional. Let us
    first plot the distribution of the review length for the two groups. We will obtain
    an array representing the review lengths within the two groups separately, and
    then plot their histograms on the same grid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Review length distribution across real and fake reviews](img/B19327_04_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 – Review length distribution across real and fake reviews
  prefs: []
  type: TYPE_NORMAL
- en: So we can see that there are some distributional differences between the two
    groups. The real reviews have a sharp peak at the lower values of the feature
    while the fake reviews have several intermediate peaks. Now we will do a t-test
    to see whether the difference is statistically significant. We will use the `scipy`
    module in Python to do this.
  prefs: []
  type: TYPE_NORMAL
- en: '`scipy` is a powerful and widely used scientific computing library for the
    Python programming language. It provides a broad range of functionality for scientific
    and technical computing, including optimization, integration, interpolation, linear
    algebra, signal and image processing, and more. It is built on top of the `NumPy`
    library, which provides support for large, multi-dimensional arrays and matrices,
    and extends its capabilities to higher-level mathematical functions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the key strengths of `scipy` is its sub-modules, which provide specialized
    functionality for different areas of scientific computing:'
  prefs: []
  type: TYPE_NORMAL
- en: The `optimization` sub-module provides functions for finding the minimum or
    maximum of a function, root-finding, curve-fitting, and more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `integration` sub-module provides functions for numerical integration and
    solving differential equations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `interpolate` sub-module provides functions for interpolating and smoothing
    data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `linalg` sub-module provides functions for linear algebra, including matrix
    decompositions, solving linear systems of equations, and more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `signal` sub-module provides functions for signal processing, including
    filtering, Fourier transforms, and more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `sparse` sub-module provides sparse matrix implementations and related operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code will conduct the t-test and print out some statistics from
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this, you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This tells us a couple of things:'
  prefs: []
  type: TYPE_NORMAL
- en: The mean review length in the fake reviews is 59.62 while in the real reviews,
    it is 80.63\. Therefore, the average fake review is nearly 21 words shorter than
    the average real review.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our p-value comes out to be 1.447e-68, which is of the order of 10-68 and is
    therefore very small. As this value is much smaller than 0.05, we can conclude
    that the difference we saw previously was statistically significant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As p < 0.05, this implies that the null hypothesis can be rejected. Therefore,
    we can conclude that the mean review length differs between real and fake reviews
    and this difference is statistically significant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can repeat this exercise for any feature of our choice. For example, here
    is how we do it for the number of words misspelled. The code is more or less the
    same, but note the change in the bins. The bins depend on the range of the feature
    under consideration. To plot the data, we use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows us the distribution as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Distribution of misspelled words across real and fake reviews](img/B19327_04_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 – Distribution of misspelled words across real and fake reviews
  prefs: []
  type: TYPE_NORMAL
- en: 'The distribution looks pretty similar. Let’s do the t-test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s what we see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: So this shows us that there are statistically significant differences between
    these two features as well.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis testing is a useful tool that helps us examine signals that differentiate
    between groups, and the statistical significance of those signals. It helps data
    scientists and statisticians make claims about the data and give them mathematical
    backing.
  prefs: []
  type: TYPE_NORMAL
- en: A note on ANOVA tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous section, we learned how t-tests can help compare the means of
    two dependent or independent groups. This is helpful when you have a clean binary
    class problem. However, there often may be multiple classes. For example, there
    could be real reviews, bot reviews, incentivized reviews, and crowdsourced reviews
    all labeled separately. In such cases, we compare the means using an **Analysis
    of Variance (****ANOVA)** test.
  prefs: []
  type: TYPE_NORMAL
- en: '**ANOVA** is a statistical method used to test the hypothesis that there is
    no significant difference between the means of two or more groups. ANOVA compares
    the variation within groups to the variation between groups to determine whether
    there is a significant difference in means. There are several types of ANOVA,
    but the most common is one-way ANOVA. One-way ANOVA is used to compare the means
    of two or more independent groups. For example, you might use one-way ANOVA to
    compare the average test scores of students in three different classes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic idea behind ANOVA is to partition the total variation in the data
    into two sources: variation due to differences between groups and variation due
    to differences within groups. The ratio of these two sources of variation is then
    used to determine whether the means of the groups are significantly different.
    The results of ANOVA are typically reported as an F-statistic, which is a measure
    of the ratio of the between-group variation to the within-group variation. If
    the F-statistic is large enough (that is, if the between-group variation is much
    larger than the within-group variation), then the null hypothesis of no difference
    between the groups is rejected, and it can be concluded that there is a significant
    difference between the means of the groups.'
  prefs: []
  type: TYPE_NORMAL
- en: As we only have two classes here, we will not be implementing ANOVA or seeing
    it in practice. However, the `scipy` library contains implementations for ANOVA
    just like it does for t-tests, and I encourage you to go through it.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen how to examine feature differences, let us turn toward
    modeling our data with the most fundamental machine learning algorithm – linear
    regression.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling fake reviews with regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will use the features we examined to attempt to model our
    data with linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: Ordinary Least Squares regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Ordinary Least Squares** (**OLS**) linear regression is a statistical method
    used to model the relationship between a dependent variable and one or more independent
    variables. The goal of OLS is to find the linear function that best fits the data
    by minimizing the sum of squared errors between the observed values and the predicted
    values of the dependent variable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The linear function is typically expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: Y = β 0+ β 1 X 1+ β 2 X 2+ ... + β n X n+ ε
  prefs: []
  type: TYPE_NORMAL
- en: where *Y* is the dependent variable, X1, X2, ..., Xn are the independent variables,
    β0, β1, β2, ..., βn are the coefficients (or parameters) that measure the effect
    of each independent variable on the dependent variable, and ε is the error term
    (or residual) that captures the part of the dependent variable that is not explained
    by the independent variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The OLS method estimates the coefficients by finding the values that minimize
    the sum of squared errors:'
  prefs: []
  type: TYPE_NORMAL
- en: Loss = Σ( y i − ŷ i)²
  prefs: []
  type: TYPE_NORMAL
- en: where yi is the observed value of the dependent variable, ŷi is the predicted
    value of the dependent variable based on the linear function, and the sum is taken
    over all the observations in the sample.
  prefs: []
  type: TYPE_NORMAL
- en: Once the values of the coefficients have been estimated, they can be plugged
    back into the equation to compute the predicted output value based on the defined
    equation. In this section, we will explore how linear regression can be used to
    detect whether a given review is fake or not.
  prefs: []
  type: TYPE_NORMAL
- en: OLS assumptions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'OLS regression makes several assumptions about the data, and violating these
    assumptions can lead to biased or inefficient estimates of the regression coefficients.
    Here are the main assumptions of OLS regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linearity**: The relationship between the dependent variable and the independent
    variables is linear. This means that the effect of each independent variable on
    the dependent variable is constant across the range of values of the independent
    variable. In the context of fake review detection, this assumption would mean
    that the relationship between the textual features (such as sentiment scores or
    word frequencies) and the likelihood of a review being fake is linear.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Independence**: The observations are independent of each other, meaning that
    the value of one observation does not depend on the value of another observation.
    For example, in fake review detection, this assumption would mean that the reviews
    are not systematically related to each other, such as being written by the same
    person or being about the same product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Homoscedasticity**: The variance of the errors (residuals) is constant across
    all values of the independent variables. This means that the spread of the residuals
    does not change as the values of the independent variables change. In the context
    of fake review detection, this assumption would mean that the variability in the
    likelihood of a review being fake is the same for all levels of the textual features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Normality**: The errors are normally distributed with a mean of zero. This
    means that the distribution of the residuals is symmetrical around 0 and follows
    a bell-shaped curve. In the context of fake review detection, this assumption
    would mean that the errors in the predicted probabilities of a review being fake
    are normally distributed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No multicollinearity**: There is no perfect correlation between any pair
    of independent variables. This means that the independent variables are not redundant
    or highly correlated with each other. In the context of fake review detection,
    this assumption would mean that the textual features are not too similar to each
    other, as this could lead to multicollinearity and make it difficult to identify
    which features are driving the probability of a review being fake.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To ensure that these assumptions are met in practice, it is important to carefully
    preprocess the data and to check for violations of these assumptions during and
    after the modeling process. For example, in the context of fake review detection,
    we might check for independence by removing reviews written by the same person
    or about the same product, and we might check for normality by plotting the residuals
    and checking for a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting OLS regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will look at the metrics we use to evaluate the OLS regression
    model, namely the **R-squared** (**R²**), F-statistic, and regression coefficients.
  prefs: []
  type: TYPE_NORMAL
- en: R2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In OLS linear regression, R² is a statistical measure that represents the proportion
    of variance in the dependent variable that can be explained by the independent
    variables in the model. It provides a measure of how well the regression line
    fits the data. R² takes values between 0 and 1, with 0 indicating that none of
    the variation in the dependent variable is explained by the independent variables,
    and 1 indicating that all of the variation in the dependent variable is explained
    by the independent variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adjusted R² is a modified version of the R² value in OLS linear regression
    that takes into account the number of independent variables in the model. It is
    calculated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: Adj(R 2) = 1−  (1 − R 2)(n − 1) ___________ n − k − 1
  prefs: []
  type: TYPE_NORMAL
- en: Here, *n* is the number of observations in the sample and *k* is the number
    of independent variables in the model. The adjusted R² value provides a more conservative
    estimate of the goodness of fit of the model than the R² value. Unlike the R²
    value, which increases as the number of independent variables in the model increases,
    the adjusted R² value penalizes models that have additional independent variables
    that do not significantly improve the fit of the model.
  prefs: []
  type: TYPE_NORMAL
- en: The F-statistic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The F-statistic is a statistical test used in OLS regression to determine whether
    the overall regression model is statistically significant or not. It is calculated
    by comparing the variance explained by the regression model to the variance not
    explained by the model. In particular, the F-statistic measures the ratio of the
    **mean square of the regression** (**MSR**) to the **mean squared error** (**MSE**).
    The MSR represents the variation in the dependent variable that is explained by
    the independent variables in the model, while the MSE represents the unexplained
    variation in the dependent variable that is not accounted for by the model.
  prefs: []
  type: TYPE_NORMAL
- en: A high F-statistic with a low associated p-value suggests that the regression
    model as a whole is statistically significant and that at least one of the independent
    variables in the model is related to the dependent variable. In contrast, a low
    F-statistic with a high associated p-value suggests that the model is not statistically
    significant and that the independent variables do not significantly explain the
    variation in the dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: Regression coefficients
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Regression coefficients represent the change in the dependent variable for a
    one-unit change in the independent variable, holding all other independent variables
    constant. More specifically, in linear regression, the coefficients indicate the
    slope of the regression line, which represents the relationship between the independent
    variable and the dependent variable. A positive coefficient means that as the
    independent variable increases, the dependent variable also increases. A negative
    coefficient means that as the independent variable increases, the dependent variable
    decreases. The size of the coefficient indicates the magnitude of the effect of
    the independent variable on the dependent variable. Larger coefficients indicate
    a stronger relationship between the independent variable and the dependent variable,
    while smaller coefficients indicate a weaker relationship.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that the interpretation of coefficients may be affected
    by the scaling of the variables. For example, if one independent variable is measured
    in dollars and another independent variable is measured in percentages, the coefficients
    cannot be directly compared, as they are not on the same scale. Additionally,
    coefficients may also be affected by collinearity among the independent variables,
    which can make it difficult to distinguish the unique effect of each independent
    variable on the dependent variable. Therefore, when interpreting regression coefficients,
    it is important to consider the scale of the variables, the context of the study,
    and potential confounding factors.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing OLS regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will attempt to model the fake reviews problem with an OLS regression model
    using the `statsmodels` package, which is a comprehensive Python package that
    provides a wide range of statistical tools and models for data analysis. It is
    designed to be used in conjunction with other scientific computing libraries such
    as `NumPy`, `sciPy`, and `pandas`. One of the key features of `statsmodels` is
    its ability to estimate statistical models for different types of data. For example,
    it provides a range of models for linear regression, generalized linear models,
    time-series analysis, and multilevel models. These models can be used for a variety
    of tasks such as prediction, classification, and inference.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to its model estimation capabilities, `statsmodels` also includes
    a range of statistical tests and diagnostics. These tools can be used to assess
    the quality of a model and determine whether its assumptions are being violated.
    Some of the statistical tests provided by `statsmodels` include hypothesis tests,
    goodness-of-fit tests, and tests for stationarity and cointegration. `statsmodels`
    also includes a range of visualization tools for exploring data and model results.
    These tools can help users gain insights into their data and communicate their
    findings effectively. Some of the visualization tools provided by `statsmodels`
    include scatter plots, line plots, histograms, and QQ plots.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to implement OLS regression, you specify a formula that indicates
    the dependent variable and the independent variables we want to model it on. Here
    is how it can be done in the `statsmodels` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 – OLS regression results](img/B19327_04_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 – OLS regression results
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us interpret these results:'
  prefs: []
  type: TYPE_NORMAL
- en: The R-squared value of 0.017 indicates that only 1.7% of the variance in the
    dependent variable (**FRAUD_LABEL**) is explained by the independent variables
    (**Review_Text_Length**, **Num_Misspelling**, and **Avg_Word_Len**). This means
    that the model is not very effective in predicting fraud based on the provided
    independent variables. In general, a higher R-squared value is better.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The coefficients for the independent variables give an indication of how each
    variable affects the dependent variable. The coefficient for **Review_Text_Length**
    is negative, but not statistically significant (P>|t| = 0.081). This suggests
    that there may be a weak negative relationship between the length of the review
    text and the likelihood of fraud, but this relationship is not strong enough to
    be statistically significant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The coefficient for **Num_Misspelling** is negative and statistically significant
    (P>|t| = 0.000). This suggests that there is a strong negative relationship between
    the number of misspellings in a review and the likelihood of fraud. Specifically,
    for each additional misspelling, the likelihood of fraud decreases by 0.0044.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The coefficient for **Avg_Word_Len** is positive and statistically significant
    (P>|t| = 0.027). This suggests that there is a weak positive relationship between
    the average word length in a review and the likelihood of fraud. Specifically,
    for each additional unit of average word length, the likelihood of fraud increases
    by 0.0023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Omnibus test shows that the residuals are not normally distributed (Prob(Omnibus)
    < 0.05), which suggests that the normality assumption of the model may not hold.
    The Durbin-Watson value of 0.033 indicates that there may be autocorrelation in
    the residuals, while the Jarque-Bera test suggests that there may be some small
    deviation from normality in the residuals. These results should be investigated
    further to determine whether they are problematic for the analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, the regression model suggests that the number of misspellings in a
    review is the most important predictor of fraud, while the length of the review
    text and the average word length are weaker predictors. However, the R² value
    is low, indicating that the model is not a strong predictor of fraud in general.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our previous example, we used only continuous features that we had derived.
    However, it is possible to use categorical features as well. The formula that
    we pass to the OLS regression function can be amended as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'And you see the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9 – OLS regression with categorical features](img/B19327_04_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 – OLS regression with categorical features
  prefs: []
  type: TYPE_NORMAL
- en: From this output, we can see that the R² is now 0.359, which indicates that
    the independent variables explain about 36% of the variation in the dependent
    variable. This is an improvement over our previous model, where the independent
    variables could explain less than 2% of the variance in the dependent variables.
  prefs: []
  type: TYPE_NORMAL
- en: While the interpretation for the other variables (review text length, average
    word length, and number of misspellings) remains the same, we have also added
    categorical variables to our analysis. In this OLS regression model, the coefficients
    for **RATING** and **VERIFIED_PURCHASE** correspond to the estimated difference
    in the mean value of the dependent variable, **FRAUD_LABEL**, for the corresponding
    category and the reference category.
  prefs: []
  type: TYPE_NORMAL
- en: 'For **RATING**, the reference category is assumed to be the lowest rating (1).
    The estimated coefficients for **RATING** suggest that, compared to the lowest
    rating, the mean value of **FRAUD_LABEL** is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 0.0086 units lower for a rating of 2 (not significant, p > 0.05)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0.0316 units lower for a rating of 3 (significant, p < 0.05)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0.0086 units lower for a rating of 4 (not significant, p > 0.05)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0.0520 units higher for a rating of 5 (significant, p < 0.05)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For **VERIFIED_PURCHASE**, the reference category is assumed to be a non-verified
    purchase (N). The estimated coefficient for **VERIFIED_PURCHASE** indicates that
    the mean value of **FRAUD_LABEL** is 0.5951 units lower for verified purchases
    (significant, p < 0.05) compared to non-verified purchases. This suggests that
    verified purchases are associated with a lower probability of fraud.
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth noting that the coefficients for categorical variables in this model
    are estimated relative to the reference category. Therefore, if you were to change
    the reference category for **RATING** or **VERIFIED_PURCHASE**, the estimated
    coefficients would change, but the overall model fit and significance levels would
    remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we examined the problem of fake reviews on e-commerce platforms
    through the lens of statistical and machine learning models. We began by understanding
    the review ecosystem and the nature of fake reviews, including their evolution
    over time. We then explored a dataset of fake reviews and conducted statistical
    tests to determine whether they show characteristics significantly different from
    genuine reviews. Finally, we modeled the review integrity using OLS regression
    and examined how various factors affect the likelihood that a review is fake.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter introduced you to the foundations of data science, including exploratory
    data analysis, statistics, and the beginnings of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss techniques for detecting deepfakes, which
    plague the internet and social media today.
  prefs: []
  type: TYPE_NORMAL
