["```py\nimport numpy as np \nimport neurolab as nl \nimport matplotlib.pyplot as plt \n```", "```py\n# Define input data \ndata = np.array([[0.3, 0.2], [0.1, 0.4], [0.4, 0.6], [0.9, 0.5]]) \nlabels = np.array([[0], [0], [0], [1]])\n```", "```py\n# Plot input data \nplt.figure() \nplt.scatter(data[:,0], data[:,1]) \nplt.xlabel('X-axis') \nplt.ylabel('Y-axis') \nplt.title('Input data')\n```", "```py\n# Define a perceptron with 2 inputs; \n# Each element of the list in the first argument  \n# specifies the min and max values of the inputs \nperceptron = nl.net.newp([[0, 1],[0, 1]], 1) \n```", "```py\n# Train the perceptron \nerror = perceptron.train(data, labels, epochs=50, show=15, lr=0.01) \n```", "```py\n# plot results \nplt.figure() \nplt.plot(error) \nplt.xlabel('Number of epochs') \nplt.ylabel('Training error') \nplt.grid() \nplt.title('Training error progress') \n\nplt.show() \n```", "```py\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport neurolab as nl  \n```", "```py\n# Define input data \ninput_file = 'data_single_layer.txt' \ninput_text = np.loadtxt(input_file) \ndata = input_text[:, 0:2] \nlabels = input_text[:, 2:]\n```", "```py\n# Plot input data \nplt.figure() \nplt.scatter(data[:,0], data[:,1]) \nplt.xlabel('X-axis') \nplt.ylabel('Y-axis') \nplt.title('Input data') \n```", "```py\n# Min and max values for each dimension \nx_min, x_max = data[:,0].min(), data[:,0].max() \ny_min, y_max = data[:,1].min(), data[:,1].max() \n```", "```py\n# Define a single-layer neural network with 2 neurons; \n# Each element in the list (first argument) specifies the  \n# min and max values of the inputs \nsingle_layer_net = nl.net.newp([[x_min, x_max], [y_min, y_max]], 2) \n```", "```py\n# Train the neural network \nerror = single_layer_net.train(data, labels, epochs=50, show=20, lr=0.01) \n```", "```py\n# Plot results \nplt.figure() \nplt.plot(error) \nplt.xlabel('Number of epochs') \nplt.ylabel('Training error') \nplt.title('Training error progress') \nplt.grid() \nplt.show() \n```", "```py\nprint(single_layer_net.sim([[0.3, 4.5]]))\nprint(single_layer_net.sim([[4.5, 0.5]]))\nprint(single_layer_net.sim([[4.3, 8]]))\n```", "```py\n    [[ 0\\.  0.]]\n    [[ 1\\.  0.]]\n    [[ 1\\.  1.]]\n\n```", "```py\nimport neurolab as nl \nimport numpy as np \nimport matplotlib.pyplot as plt\n```", "```py\n# Generate training data \nmin_value = -12 \nmax_value = 12 \nnum_datapoints = 90\n```", "```py\nx = np.linspace(min_value, max_value, num_datapoints) \ny = 2 * np.square(x) + 7 \ny /= np.linalg.norm(y) \n```", "```py\ndata = x.reshape(num_datapoints, 1) \nlabels = y.reshape(num_datapoints, 1) \n```", "```py\nplt.figure() \nplt.scatter(data, labels) \nplt.xlabel('X-axis') \nplt.ylabel('Y-axis') \nplt.title('Input data') \n```", "```py\nmultilayer_net = nl.net.newff([[min_value, max_value]], [10, 10, 1]) \n```", "```py\nmultilayer_net.trainf = nl.train.train_gd \n```", "```py\nerror = multilayer_net.train(data, labels, epochs=800, show=100, goal=0.01) \n```", "```py\npredicted_output = multilayer_net.sim(data)\n```", "```py\nplt.figure() \nplt.plot(error) \nplt.xlabel('Number of epochs') \nplt.ylabel('Error') \nplt.title('Training error progress')\n```", "```py\nx2 = np.linspace(min_value, max_value, num_datapoints * 2) \ny2 = multilayer_net.sim(x2.reshape(x2.size,1)).reshape(x2.size) \ny3 = predicted_output.reshape(num_datapoints) \n```", "```py\nplt.figure() \nplt.plot(x2, y2, '-', x, y, '.', x, y3, 'p') \nplt.title('Ground truth vs predicted output') \nplt.show() \n```", "```py\nEpoch: 100; Error: 4.634764957565494;\nEpoch: 200; Error: 0.7675153737786798;\nEpoch: 300; Error: 0.21543996465118723;\nEpoch: 400; Error: 0.027738499953293118;\nEpoch: 500; Error: 0.019145948877988192;\nEpoch: 600; Error: 0.11296232736352653;\nEpoch: 700; Error: 0.03446237629842832;\nEpoch: 800; Error: 0.03022668735279662;\nThe maximum number of train epochs is reached\n```", "```py\ninx = np.floor (cn0 * pc.cumsum ()). astype (int)\n```", "```py\ninx = np.floor (cn0 * pc.cumsum ())\n```", "```py\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport neurolab as nl \n```", "```py\ninput_file = 'data_vq.txt' \ninput_text = np.loadtxt(input_file) \ndata = input_text[:, 0:2] \nlabels = input_text[:, 2:]\n```", "```py\nnet = nl.net.newlvq(nl.tool.minmax(data), 10, [0.25, 0.25, 0.25, 0.25]) \n```", "```py\nerror = net.train(data, labels, epochs=100, goal=-1) \n```", "```py\nxx, yy = np.meshgrid(np.arange(0, 8, 0.2), np.arange(0, 8, 0.2)) \nxx.shape = xx.size, 1 \nyy.shape = yy.size, 1 \ninput_grid = np.concatenate((xx, yy), axis=1) \n```", "```py\noutput_grid = net.sim(input_grid) \n```", "```py\nclass1 = data[labels[:,0] == 1] \nclass2 = data[labels[:,1] == 1] \nclass3 = data[labels[:,2] == 1] \nclass4 = data[labels[:,3] == 1] \n```", "```py\ngrid1 = input_grid[output_grid[:,0] == 1] \ngrid2 = input_grid[output_grid[:,1] == 1] \ngrid3 = input_grid[output_grid[:,2] == 1] \ngrid4 = input_grid[output_grid[:,3] == 1] \n```", "```py\nplt.plot(class1[:,0], class1[:,1], 'ko', class2[:,0], class2[:,1], 'ko',  \n                class3[:,0], class3[:,1], 'ko', class4[:,0], class4[:,1], 'ko') \nplt.plot(grid1[:,0], grid1[:,1], 'b.', grid2[:,0], grid2[:,1], 'gx', \n                grid3[:,0], grid3[:,1], 'cs', grid4[:,0], grid4[:,1], 'ro') \nplt.axis([0, 8, 0, 8]) \nplt.xlabel('X-axis') \nplt.ylabel('Y-axis') \nplt.title('Vector quantization using neural networks') \nplt.show() \n```", "```py\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport neurolab as nl \n```", "```py\ndef create_waveform(num_points): \n    # Create train samples \n    data1 = 1 * np.cos(np.arange(0, num_points)) \n    data2 = 2 * np.cos(np.arange(0, num_points)) \n    data3 = 3 * np.cos(np.arange(0, num_points)) \n    data4 = 4 * np.cos(np.arange(0, num_points)) \n```", "```py\n    # Create varying amplitudes \n    amp1 = np.ones(num_points) \n    amp2 = 4 + np.zeros(num_points)  \n    amp3 = 2 * np.ones(num_points)  \n    amp4 = 0.5 + np.zeros(num_points)  \n```", "```py\n    data = np.array([data1, data2, data3, data4]).reshape(num_points * 4, 1) \n    amplitude = np.array([[amp1, amp2, amp3, amp4]]).reshape(num_points * 4, 1) \n\n    return data, amplitude  \n```", "```py\n# Draw the output using the network \ndef draw_output(net, num_points_test): \n    data_test, amplitude_test = create_waveform(num_points_test) \n    output_test = net.sim(data_test) \n    plt.plot(amplitude_test.reshape(num_points_test * 4)) \n    plt.plot(output_test.reshape(num_points_test * 4))\n```", "```py\nif __name__=='__main__': \n    # Get data \n    num_points = 30 \n    data, amplitude = create_waveform(num_points) \n```", "```py\n    # Create network with 2 layers \n    net = nl.net.newelm([[-2, 2]], [10, 1], [nl.trans.TanSig(), nl.trans.PureLin()]) \n```", "```py\n    # Set initialized functions and init \n    net.layers[0].initf = nl.init.InitRand([-0.1, 0.1], 'wb') \n    net.layers[1].initf= nl.init.InitRand([-0.1, 0.1], 'wb') \n    net.init() \n```", "```py\n    # Training the recurrent neural network \n    error = net.train(data, amplitude, epochs=1000, show=100, goal=0.01) \n```", "```py\n    # Compute output from network \n    output = net.sim(data) \n```", "```py\n    # Plot training results \n    plt.subplot(211) \n    plt.plot(error) \n    plt.xlabel('Number of epochs') \n    plt.ylabel('Error (MSE)') \n```", "```py\n    plt.subplot(212) \n    plt.plot(amplitude.reshape(num_points * 4)) \n    plt.plot(output.reshape(num_points * 4)) \n    plt.legend(['Ground truth', 'Predicted output'])\n```", "```py\n    # Testing on unknown data at multiple scales \n    plt.figure() \n\n    plt.subplot(211) \n    draw_output(net, 74) \n    plt.xlim([0, 300]) \n```", "```py\n    plt.subplot(212) \n    draw_output(net, 54) \n    plt.xlim([0, 300]) \n\n    plt.show() \n```", "```py\nEpoch: 100; Error: 1.2635865600014597;\nEpoch: 200; Error: 0.4001584483592344;\nEpoch: 300; Error: 0.06438997423142029;\nEpoch: 400; Error: 0.03772354900253485;\nEpoch: 500; Error: 0.031996105192696744;\nEpoch: 600; Error: 0.011933337009068408;\nEpoch: 700; Error: 0.012385370178600663;\nEpoch: 800; Error: 0.01116995004102195;\nEpoch: 900; Error: 0.011191016373572612;\nEpoch: 1000; Error: 0.010584255803264013;\nThe maximum number of train epochs is reached\n```", "```py\nimport cv2 \nimport numpy as np \n```", "```py\n# Load input data  \ninput_file = 'letter.data'  \n```", "```py\n# Define visualization parameters  \nscaling_factor = 10 \nstart_index = 6 \nend_index = -1 \nh, w = 16, 8 \n```", "```py\n# Loop until you encounter the Esc key \nwith open(input_file, 'r') as f: \n    for line in f.readlines(): \n        data = np.array([255*float(x) for x in line.split('\\t')[start_index:end_index]]) \n```", "```py\n        img = np.reshape(data, (h,w)) \n        img_scaled = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor) \n        cv2.imshow('Image', img_scaled) \n```", "```py\n        c = cv2.waitKey() \n        if c == 27: \n            break \n```", "```py\nimport numpy as np \nimport neurolab as nl \n```", "```py\ninput_file = 'letter.data' \n```", "```py\nnum_datapoints = 20 \n```", "```py\norig_labels = 'omandig' \nnum_output = len(orig_labels) \n```", "```py\nnum_train = int(0.9 * num_datapoints) \nnum_test = num_datapoints - num_train \n```", "```py\nstart_index = 6 \nend_index = -1 \n```", "```py\ndata = [] \nlabels = [] \nwith open(input_file, 'r') as f: \n    for line in f.readlines(): \n        # Split the line tabwise \n        list_vals = line.split('\\t')\n```", "```py\n        if list_vals[1] not in orig_labels: \n            continue \n```", "```py\n        label = np.zeros((num_output, 1)) \n        label[orig_labels.index(list_vals[1])] = 1 \n        labels.append(label) \n```", "```py\n        cur_char = np.array([float(x) for x in list_vals[start_index:end_index]]) \n        data.append(cur_char) \n```", "```py\n        if len(data) >= num_datapoints: \n            break \n```", "```py\ndata = np.asfarray(data) \nlabels = np.array(labels).reshape(num_datapoints, num_output) \n```", "```py\nnum_dims = len(data[0]) \n```", "```py\nnet = nl.net.newff([[0, 1] for _ in range(len(data[0]))], [128, 16, num_output]) \nnet.trainf = nl.train.train_gd \nerror = net.train(data[:num_train,:], labels[:num_train,:], epochs=10000,  \n        show=100, goal=0.01) \n```", "```py\npredicted_output = net.sim(data[num_train:, :])\nprint(\"Testing on unknown data:\")\nfor i in range(num_test):\n    print(\"Original:\", orig_labels[np.argmax(labels[i])])\n    print(\"Predicted:\", orig_labels[np.argmax(predicted_output[i])])\n```", "```py\nEpoch: 5000; Error: 0.032178530603536336;\nEpoch: 5100; Error: 0.023122560947574727;\nEpoch: 5200; Error: 0.040615342668364626;\nEpoch: 5300; Error: 0.01686314983574041;\nThe goal of learning is reached\n```", "```py\nTesting on unknown data:\nOriginal: o\nPredicted: o\nOriginal: m\nPredicted: m\n```", "```py\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense \n```", "```py\nIrisData = load_iris() \n```", "```py\nX = IrisData.data\nY = IrisData.target.reshape(-1, 1) \n```", "```py\nEncoder = OneHotEncoder(sparse=False)\nYHE = Encoder.fit_transform(Y)\n```", "```py\nXTrain, XTest, YTrain, YTest = train_test_split(X, YHE, test_size=0.30)\n```", "```py\nmodel = Sequential()\n```", "```py\nmodel.add(Dense(10, input_shape=(4,), activation='relu'))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(3, activation='softmax'))\n```", "```py\nmodel.compile(optimizer='SGD',loss='categorical_crossentropy', metrics=['accuracy'])\n```", "```py\nmodel.fit(XTrain, YTrain, verbose=2, batch_size=5, epochs=200)\n```", "```py\nresults = model.evaluate(XTest, YTest)\nprint('Final test set loss:' ,results[0])\nprint('Final test set accuracy:', results[1])\n```", "```py\nFinal test set loss: 0.17724286781416998\nFinal test set accuracy: 0.9555555568801032\n```", "```py\nmodel.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n```", "```py\nFinal test set loss: 0.0803464303414027\nFinal test set accuracy: 0.9777777777777777\n```"]