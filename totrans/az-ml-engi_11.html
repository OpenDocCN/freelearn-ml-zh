<html><head></head><body>
<div id="_idContainer450">
<h1 class="chapter-number" id="_idParaDest-132"><a id="_idTextAnchor204"/><span class="koboSpan" id="kobo.1.1">11</span></h1>
<h1 id="_idParaDest-133"><a id="_idTextAnchor205"/><span class="koboSpan" id="kobo.2.1"> Using Distributed Training  in AMLS</span></h1>
<p><span class="koboSpan" id="kobo.3.1">An interesting topic is how we can process large-scale datasets to train machine learning and deep learning models. </span><span class="koboSpan" id="kobo.3.2">For example, large-scale text-based mining, entity extraction, sentiments, and image or video-based, including image classification, image multiclassification, and object detection, are all very memory intensive and need large compute resources to process, which may take hours or sometimes days and weeks </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">to complete.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">In addition, if you have big data that contains business information and want to build machine learning models, then distributed learning can help. </span><span class="koboSpan" id="kobo.5.2">This chapter will cover how we can run large-scale models with large datasets. </span><span class="koboSpan" id="kobo.5.3">You will see different ways of computing large, </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">distributed models.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">There are different ways to distribute compute and data and achieve faster and better performance for large-scale training. </span><span class="koboSpan" id="kobo.7.2">Here, we are going to learn about a </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">few techniques.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">Data parallelism</span><a id="_idIndexMarker715"/><span class="koboSpan" id="kobo.10.1"> is widely used when there is a large volume of data that can be partitioned. </span><span class="koboSpan" id="kobo.10.2">We can run parallel computing to achieve better performance. </span><span class="koboSpan" id="kobo.10.3">CPU-based computing also performs well when scaled horizontally and vertically. </span><span class="koboSpan" id="kobo.10.4">The goal would be to process each partition and compute in groups, such as one partition, and then apply compute, and do that in parallel across </span><span class="No-Break"><span class="koboSpan" id="kobo.11.1">all partitions.</span></span></p>
<p><span class="koboSpan" id="kobo.12.1">Model parallelism</span><a id="_idIndexMarker716"/><span class="koboSpan" id="kobo.13.1"> is another area where you can scale the model training in deep learning modeling. </span><span class="koboSpan" id="kobo.13.2">Model parallelism is heavily compute based and, in most cases, GPU-based computing is needed to get better performance and time. </span><span class="koboSpan" id="kobo.13.3">In this chapter, we will look at some distributed training libraries available for us to use in the </span><strong class="bold"><span class="koboSpan" id="kobo.14.1">Azure Machine </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.15.1">Learning</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.16.1"> service.</span></span></p>
<p><span class="koboSpan" id="kobo.17.1">There are two main types of distributed training: data and </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">model parallelism.</span></span></p>
<p><span class="koboSpan" id="kobo.19.1">We will cover the following topics in </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">this chapter:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.21.1">Data parallelism</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.22.1">Model parallelism</span></span></li>
<li><span class="koboSpan" id="kobo.23.1">Distributed training </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">with PyTorch</span></span></li>
<li><span class="koboSpan" id="kobo.25.1">Distributed training </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">with TensorFlow</span></span></li>
</ul>
<h1 id="_idParaDest-134"><a id="_idTextAnchor206"/><span class="koboSpan" id="kobo.27.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.28.1">You can review all the code for this chapter </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">at </span></span><a href="https://github.com/PacktPublishing/Azure-Machine-Learning-Engineering"><span class="No-Break"><span class="koboSpan" id="kobo.30.1">https://github.com/PacktPublishing/Azure-Machine-Learning-Engineering</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.31.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.32.1">To access your workspace, recall the steps from the </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">previous chapter:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.34.1">Go </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">to </span></span><a href="https://ml.azure.com"><span class="No-Break"><span class="koboSpan" id="kobo.36.1">https://ml.azure.com</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.37.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.38.1">Select your workspace name from what has </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">been created.</span></span></li>
<li><span class="koboSpan" id="kobo.40.1">From the workspace user interface, on the left-hand side, </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">click </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.42.1">Compute</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.44.1">On the </span><strong class="bold"><span class="koboSpan" id="kobo.45.1">Compute</span></strong><span class="koboSpan" id="kobo.46.1"> screen, select your last used compute instance and </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">select </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.48.1">Start</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.50.1">Your compute instance will change from </span><strong class="bold"><span class="koboSpan" id="kobo.51.1">Stopped</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.52.1">to </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.53.1">Starting</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.55.1">In the previous chapter, we cloned this book’s GitHub repository. </span><span class="koboSpan" id="kobo.55.2">If you have not already done so, continue to follow the steps provided. </span><span class="koboSpan" id="kobo.55.3">If you have already cloned the repository, skip to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.56.1">step 9</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.58.1">Open the terminal on your compute instance. </span><span class="koboSpan" id="kobo.58.2">Note that the path will include your user in the directory. </span><span class="koboSpan" id="kobo.58.3">Type the following into your terminal to clone the sample notebooks into your </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">working directory:</span></span><pre class="console"><span class="koboSpan" id="kobo.60.1">
git clone </span><strong class="source-inline"><span class="koboSpan" id="kobo.61.1">https://github.com/PacktPublishing/Azure-Machine-Learning-Engineering.git</span></strong></pre></li>
<li><span class="koboSpan" id="kobo.62.1">Clicking on the </span><span class="No-Break"><span class="koboSpan" id="kobo.63.1">refresh icon.</span></span></li>
<li><span class="koboSpan" id="kobo.64.1">Now, create a compute cluster called </span><strong class="source-inline"><span class="koboSpan" id="kobo.65.1">gpu-cluster</span></strong><span class="koboSpan" id="kobo.66.1"> with two nodes and select one of the GPU’s available VMs, such as the NC6 or </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">NC24 series.</span></span></li>
<li><span class="koboSpan" id="kobo.68.1">Review the notebooks in your </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.69.1">Azure-Machine-Learning-Engineering</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.70.1"> directory.</span></span></li>
</ol>
<h1 id="_idParaDest-135"><a id="_idTextAnchor207"/><span class="koboSpan" id="kobo.71.1">Data parallelism</span></h1>
<p><span class="koboSpan" id="kobo.72.1">Data parallelism is </span><a id="_idIndexMarker717"/><span class="koboSpan" id="kobo.73.1">widely used when there is a large volume of data that can be partitioned. </span><span class="koboSpan" id="kobo.73.2">We can run parallel computing to achieve better performance. </span><span class="koboSpan" id="kobo.73.3">CPU-based computing also performs well when scaled horizontally and vertically. </span><span class="koboSpan" id="kobo.73.4">The goal would be to process each partition and compute in groups, such as one partition, and then apply compute, and do that parallel across </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">all partitions.</span></span></p>
<h1 id="_idParaDest-136"><a id="_idTextAnchor208"/><span class="koboSpan" id="kobo.75.1">Model parallelism</span></h1>
<p><span class="koboSpan" id="kobo.76.1">Model parallelism is</span><a id="_idIndexMarker718"/><span class="koboSpan" id="kobo.77.1"> another way to scale the model training in deep learning modeling. </span><span class="koboSpan" id="kobo.77.2">Model parallelism is heavily compute-based and, in most cases, GPU-based computing is needed to get better performance and time. </span><span class="koboSpan" id="kobo.77.3">Let’s look at some distributed training libraries available for us to use in the </span><strong class="bold"><span class="koboSpan" id="kobo.78.1">Azure Machine </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.79.1">Learning</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.80.1"> service.</span></span></p>
<p><span class="koboSpan" id="kobo.81.1">In Azure Machine Learning, we can perform distributed learning in </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">various ways:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.83.1">Distributed training with PyTorch</span></strong><span class="koboSpan" id="kobo.84.1">: PyTorch</span><a id="_idIndexMarker719"/><span class="koboSpan" id="kobo.85.1"> is one of the most well-known and widely used </span><a id="_idIndexMarker720"/><span class="koboSpan" id="kobo.86.1">machine learning libraries for large-scale vision, text, and other unstructured data machine learning. </span><span class="koboSpan" id="kobo.86.2">It uses </span><a id="_idIndexMarker721"/><span class="koboSpan" id="kobo.87.1">deep learning, such as convolutional neural network or recurrent neural network-based development. </span><span class="koboSpan" id="kobo.87.2">PyTorch is a deep learning framework developed by </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">Meta (Facebook).</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.89.1">PyTorch implementations are very simple and easy to use and tend to eliminate the complications of other libraries in </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">the marketplace.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.91.1">Distributed training with TensorFlow</span></strong><span class="koboSpan" id="kobo.92.1">: TensorFlow </span><a id="_idIndexMarker722"/><span class="koboSpan" id="kobo.93.1">is a deep </span><a id="_idIndexMarker723"/><span class="koboSpan" id="kobo.94.1">learning library created by Google. </span><span class="koboSpan" id="kobo.94.2">Given that the science is difficult, it was designed to make deep learning development simple and easy to implement. </span><span class="koboSpan" id="kobo.94.3">In the beginning stages, TensorFlow’s implementation was very difficult and required excessive lines of code. </span><span class="koboSpan" id="kobo.94.4">Another project called Keras was created to simplify this </span><a id="_idIndexMarker724"/><span class="koboSpan" id="kobo.95.1">process; then, they were </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">joined </span></span><span class="No-Break"><a id="_idIndexMarker725"/></span><span class="No-Break"><span class="koboSpan" id="kobo.97.1">together.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.98.1">The most current version is much more simple and easier to use compared to older versions. </span><span class="koboSpan" id="kobo.98.2">We have just covered the most popular frameworks used in the industry for distributed learning in the deep </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">learning world.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.100.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.101.1">Both of the aforementioned SDKs are being continuously developed and improved, and new functionality is always being added since the artificial intelligence field and the number of algorithms used </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">are growing.</span></span></p>
<h1 id="_idParaDest-137"><a id="_idTextAnchor209"/><span class="koboSpan" id="kobo.103.1">Distributed training with PyTorch</span></h1>
<p><span class="koboSpan" id="kobo.104.1">In this chapter, we will learn how </span><a id="_idIndexMarker726"/><span class="koboSpan" id="kobo.105.1">to use PyTorch while performing deep learning model training before distributing that training within multiple cores and </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">running it.</span></span></p>
<p><span class="koboSpan" id="kobo.107.1">Let’s look at how we can write some simple PyTorch code that can be run in Azure </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">Machine Learning.</span></span></p>
<h1 id="_idParaDest-138"><a id="_idTextAnchor210"/><span class="koboSpan" id="kobo.109.1">Distributed training code</span></h1>
<p><span class="koboSpan" id="kobo.110.1">In this section, we will learn how to write code to perform distributed training using the PyTorch framework for vision-based deep learning algorithms. </span><span class="koboSpan" id="kobo.110.2">We will be using Python code to create the model and then train it with a compute cluster. </span><span class="koboSpan" id="kobo.110.3">All the code is available in this book’s GitHub repository for learning and </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">execution purposes.</span></span></p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor211"/><span class="koboSpan" id="kobo.112.1">Creating a training job Python file to process</span></h2>
<p><span class="koboSpan" id="kobo.113.1">Follow these </span><a id="_idIndexMarker727"/><span class="koboSpan" id="kobo.114.1">steps to create a dataset while leveraging the </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">user interface:</span></span></p>
<ol>
<li value="1"><span class="koboSpan" id="kobo.116.1">Go to </span><a href="https://ml.azure.com"><span class="koboSpan" id="kobo.117.1">https://ml.azure.com</span></a><span class="koboSpan" id="kobo.118.1"> and select </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">your workspace.</span></span></li>
<li><span class="koboSpan" id="kobo.120.1">Go to </span><strong class="bold"><span class="koboSpan" id="kobo.121.1">Compute</span></strong><span class="koboSpan" id="kobo.122.1"> and click </span><strong class="bold"><span class="koboSpan" id="kobo.123.1">Start</span></strong><span class="koboSpan" id="kobo.124.1"> to start the </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">compute instance.</span></span></li>
<li><span class="koboSpan" id="kobo.126.1">Wait for the compute instance to start; then, click </span><strong class="bold"><span class="koboSpan" id="kobo.127.1">Jupyter</span></strong><span class="koboSpan" id="kobo.128.1"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">start coding.</span></span></li>
<li><span class="koboSpan" id="kobo.130.1">If you don’t have a compute cluster, please follow the instructions in the previous chapters to create a new one. </span><span class="koboSpan" id="kobo.130.2">A compute instance with a CPU is good for development; we will use GPU-based content for </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">model training.</span></span></li>
<li><span class="koboSpan" id="kobo.132.1">If you don’t have enough quotas for your GPU, please create a Service Ticket in the Azure portal to increase </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">your quotas.</span></span></li>
<li><span class="koboSpan" id="kobo.134.1">Now, create a new folder for this chapter. </span><span class="koboSpan" id="kobo.134.2">I am calling mine </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.135.1">Chapter 11</span></strong></span><span class="koboSpan" id="kobo.136.1">. </span><span class="koboSpan" id="kobo.136.2">Also, create a subfolder </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">called </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.138.1">PyTorchDistributed</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.140.1">Inside, I am also creating a new directory for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.141.1">src</span></strong><span class="koboSpan" id="kobo.142.1"> folder, where all the Python code training files will be stored. </span><span class="koboSpan" id="kobo.142.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.143.1">PyTorchDistributed</span></strong><span class="koboSpan" id="kobo.144.1"> folder (</span><strong class="source-inline"><span class="koboSpan" id="kobo.145.1">root</span></strong><span class="koboSpan" id="kobo.146.1"> folder) will be used for submitting </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">Python files.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.148.1">We can use the terminal to run our </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">Python code.</span></span></p>
<ol>
<li value="8"><span class="koboSpan" id="kobo.150.1">Now, we</span><a id="_idIndexMarker728"/><span class="koboSpan" id="kobo.151.1"> need to write our training code. </span><span class="koboSpan" id="kobo.151.2">So, navigate into the </span><strong class="source-inline"><span class="koboSpan" id="kobo.152.1">src</span></strong><span class="koboSpan" id="kobo.153.1"> folder and create a new text file </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">called </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.155.1">train.py</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.157.1">For the sample code in this chapter, we will be using an open source dataset; it has no </span><strong class="bold"><span class="koboSpan" id="kobo.158.1">Personally Identifiable Information</span></strong><span class="koboSpan" id="kobo.159.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.160.1">PII</span></strong><span class="koboSpan" id="kobo.161.1">) or privacy or </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">legal issues.</span></span></li>
<li><span class="koboSpan" id="kobo.163.1">Let’s import all the libraries needed for </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">the code:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer432">
<span class="koboSpan" id="kobo.165.1"><img alt="Figure 11.1 – Library imports" src="image/B18003_11_001.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.166.1">Figure 11.1 – Library imports</span></p>
<ol>
<li value="11"><span class="koboSpan" id="kobo.167.1">Next, we must create the neural network architecture. </span><span class="koboSpan" id="kobo.167.2">A neural network architecture is what is used for training to create the brain. </span><span class="koboSpan" id="kobo.167.3">Depending on the accuracy required, you can build your network based on how many layers are needed. </span><span class="koboSpan" id="kobo.167.4">The neural network architecture is not the focus of this book, but there are a lot of</span><a id="_idIndexMarker729"/><span class="koboSpan" id="kobo.168.1"> resources available for </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">designing one:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer433">
<span class="koboSpan" id="kobo.170.1"><img alt="Figure 11.2 – Neural network architecture" src="image/B18003_11_002.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.171.1">Figure 11.2 – Neural network architecture</span></p>
<ol>
<li value="12"><span class="koboSpan" id="kobo.172.1">Now, let’s write the </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">training code:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer434">
<span class="koboSpan" id="kobo.174.1"><img alt="Figure 11.3 – Training code" src="image/B18003_11_003.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.175.1">Figure 11.3 – Training code</span></p>
<ol>
<li value="13"><span class="koboSpan" id="kobo.176.1">Next, we </span><a id="_idIndexMarker730"/><span class="koboSpan" id="kobo.177.1">will evaluate the model metrics. </span><span class="koboSpan" id="kobo.177.2">Model evaluation is an important step in the training process as it validates model performance in terms </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">of accuracy:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer435">
<span class="koboSpan" id="kobo.179.1"><img alt="Figure 11.4 – Evaluation code" src="image/B18003_11_004.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.180.1">Figure 11.4 – Evaluation code</span></p>
<ol>
<li value="14"><span class="koboSpan" id="kobo.181.1">Next, we </span><a id="_idIndexMarker731"/><span class="koboSpan" id="kobo.182.1">need to create a </span><strong class="source-inline"><span class="koboSpan" id="kobo.183.1">main</span></strong><span class="koboSpan" id="kobo.184.1"> function that will gather the data for the model, then invoke the </span><strong class="source-inline"><span class="koboSpan" id="kobo.185.1">main</span></strong><span class="koboSpan" id="kobo.186.1"> function and start to process the training code. </span><span class="koboSpan" id="kobo.186.2">Then, it will evaluate the model. </span><span class="koboSpan" id="kobo.186.3">Please refer to the following sample code for </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">the details:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer436">
<span class="koboSpan" id="kobo.188.1"><img alt="Figure 11.5 – Sample main code" src="image/B18003_11_005.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.189.1">Figure 11.5 – Sample main code</span></p>
<p><span class="koboSpan" id="kobo.190.1">Here is the code that specifies the </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">distributed dataset:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer437">
<span class="koboSpan" id="kobo.192.1"><img alt="Figure 11.6 – Distributed dataset code" src="image/B18003_11_006.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.193.1">Figure 11.6 – Distributed dataset code</span></p>
<p><span class="koboSpan" id="kobo.194.1">This is where the model </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">is distributed:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer438">
<span class="koboSpan" id="kobo.196.1"><img alt="Figure 11.7 – Model distribution code" src="image/B18003_11_007.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.197.1">Figure 11.7 – Model distribution code</span></p>
<ol>
<li value="15"><span class="koboSpan" id="kobo.198.1">Next, we will create a </span><strong class="source-inline"><span class="koboSpan" id="kobo.199.1">job.py</span></strong><span class="koboSpan" id="kobo.200.1"> file that downloads the data needed for </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">the experiment.</span></span></li>
<li><span class="koboSpan" id="kobo.202.1">Now, let’s </span><a id="_idIndexMarker732"/><span class="koboSpan" id="kobo.203.1">create a dataset for further training processes. </span><span class="koboSpan" id="kobo.203.2">This dataset will invoke the compute cluster needed for the distributed training. </span><span class="koboSpan" id="kobo.203.3">The following sample code invokes the workspace and gets </span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">the dataset:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer439">
<span class="koboSpan" id="kobo.205.1"><img alt="Figure 11.8 – Job file dataset code" src="image/B18003_11_008.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.206.1">Figure 11.8 – Job file dataset code</span></p>
<p><span class="koboSpan" id="kobo.207.1">The following code parallelizes the </span><span class="No-Break"><span class="koboSpan" id="kobo.208.1">training process:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer440">
<span class="koboSpan" id="kobo.209.1"><img alt="Figure 11.9 – Job file invoking distributed training" src="image/B18003_11_009.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.210.1">Figure 11.9 – Job file invoking distributed training</span></p>
<ol>
<li value="17"><span class="koboSpan" id="kobo.211.1">As shown in </span><a id="_idIndexMarker733"/><span class="koboSpan" id="kobo.212.1">the preceding screenshot, the code is distributed during model training, and this process is very simple. </span><strong class="source-inline"><span class="koboSpan" id="kobo.213.1">PyTorchConfiguration</span></strong><span class="koboSpan" id="kobo.214.1">, along with </span><strong class="source-inline"><span class="koboSpan" id="kobo.215.1">process_count</span></strong><span class="koboSpan" id="kobo.216.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.217.1">node_count</span></strong><span class="koboSpan" id="kobo.218.1">, are the configurations we must provide to distribute the model </span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">training process.</span></span></li>
</ol>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.220.1">PyTorchConfiguration</span></strong><span class="koboSpan" id="kobo.221.1"> takes </span><span class="No-Break"><span class="koboSpan" id="kobo.222.1">three parameters:</span></span></p>
<ol>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.223.1">communication_backend</span></strong><span class="koboSpan" id="kobo.224.1">: This can be set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.225.1">Nccl</span></strong><span class="koboSpan" id="kobo.226.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.227.1">Gloo</span></strong><span class="koboSpan" id="kobo.228.1">. </span><strong class="source-inline"><span class="koboSpan" id="kobo.229.1">Nccl</span></strong><span class="koboSpan" id="kobo.230.1"> is selected </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">by default.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.232.1">process_count</span></strong><span class="koboSpan" id="kobo.233.1">: This parameter configures how many processes run inside the nodes for </span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">parallelization purposes.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.235.1">node_count</span></strong><span class="koboSpan" id="kobo.236.1">: This is where we specify how many nodes to use for the job. </span><strong class="source-inline"><span class="koboSpan" id="kobo.237.1">node</span></strong><span class="koboSpan" id="kobo.238.1"> is based on how many cores are available. </span><span class="koboSpan" id="kobo.238.2">The higher the number of nodes, the faster </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">the processing.</span></span></li>
</ol>
<ol>
<li value="18"><span class="koboSpan" id="kobo.240.1">Run the job </span><a id="_idIndexMarker734"/><span class="koboSpan" id="kobo.241.1">and wait for it to finish. </span><span class="koboSpan" id="kobo.241.2">Once the job has been submitted, navigate to your workspace’s user interface, click on </span><strong class="bold"><span class="koboSpan" id="kobo.242.1">jobs</span></strong><span class="koboSpan" id="kobo.243.1">, and go to </span><strong class="bold"><span class="koboSpan" id="kobo.244.1">details</span></strong><span class="koboSpan" id="kobo.245.1"> to see how </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">this works.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer441">
<span class="koboSpan" id="kobo.247.1"><img alt="Figure 11.10 – Job output" src="image/B18003_11_010.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.248.1">Figure 11.10 – Job output</span></p>
<p><span class="koboSpan" id="kobo.249.1">In this section, we learned how to run distributed training using the PyTorch framework for a large dataset for custom vision-based deep </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">learning modeling.</span></span></p>
<p><span class="koboSpan" id="kobo.251.1">Now, we are going to look at the TensorFlow framework and see how we can achieve distributed learning with a large dataset for custom vision-based deep </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">learning models.</span></span></p>
<h1 id="_idParaDest-140"><a id="_idTextAnchor212"/><span class="koboSpan" id="kobo.253.1">Distributed training with TensorFlow</span></h1>
<p><span class="koboSpan" id="kobo.254.1">In this section, we </span><a id="_idIndexMarker735"/><span class="koboSpan" id="kobo.255.1">are going to learn how to take large image files and build custom deep learning models such as object detection or image classification using TensorFlow. </span><span class="koboSpan" id="kobo.255.2">By doing so, we’ll learn how to distribute across multiple virtual machines to achieve faster performance </span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">for training.</span></span></p>
<h2 id="_idParaDest-141"><a id="_idTextAnchor213"/><span class="koboSpan" id="kobo.257.1">Creating a training job Python file to process</span></h2>
<p><span class="koboSpan" id="kobo.258.1">Follow these </span><a id="_idIndexMarker736"/><span class="koboSpan" id="kobo.259.1">steps to create a dataset that leverages the </span><span class="No-Break"><span class="koboSpan" id="kobo.260.1">user interface:</span></span></p>
<ol>
<li value="1"><span class="koboSpan" id="kobo.261.1">Go to </span><a href="https://ml.azure.com"><span class="koboSpan" id="kobo.262.1">https://ml.azure.com</span></a><span class="koboSpan" id="kobo.263.1"> and select </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1">your workspace.</span></span></li>
<li><span class="koboSpan" id="kobo.265.1">Go to </span><strong class="bold"><span class="koboSpan" id="kobo.266.1">Compute</span></strong><span class="koboSpan" id="kobo.267.1"> and click </span><strong class="bold"><span class="koboSpan" id="kobo.268.1">Start</span></strong><span class="koboSpan" id="kobo.269.1"> to start the </span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">compute instance.</span></span></li>
<li><span class="koboSpan" id="kobo.271.1">Wait for the compute instance to start; then, click </span><strong class="bold"><span class="koboSpan" id="kobo.272.1">Jupyter</span></strong><span class="koboSpan" id="kobo.273.1"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">start coding.</span></span></li>
<li><span class="koboSpan" id="kobo.275.1">If you don’t have a compute cluster, please follow the instructions in the previous chapters to create a new one. </span><span class="koboSpan" id="kobo.275.2">A compute instance with a CPU is good for development; we will use GPU-based content for </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">model training.</span></span></li>
<li><span class="koboSpan" id="kobo.277.1">If you don’t have enough quotas for your GPU, please create a Service Ticket in the Azure portal to increase </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">your quotas.</span></span></li>
<li><span class="koboSpan" id="kobo.279.1">Now, create a new folder for this chapter. </span><span class="koboSpan" id="kobo.279.2">I am creating a folder called </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.280.1">Chapter 11</span></strong></span><span class="koboSpan" id="kobo.281.1">. </span><span class="koboSpan" id="kobo.281.2">Then, create a subfolder </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">called </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.283.1">TensorflowDistributed</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.285.1">Inside, I am also creating a new directory for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.286.1">src</span></strong><span class="koboSpan" id="kobo.287.1"> folder where all the Python code training files will be stored. </span><strong class="source-inline"><span class="koboSpan" id="kobo.288.1">TensorflowDistributed</span></strong><span class="koboSpan" id="kobo.289.1">  (root folder) will be used for submitting Python files. </span><span class="koboSpan" id="kobo.289.2">If the </span><strong class="source-inline"><span class="koboSpan" id="kobo.290.1">TensorflowDistributed</span></strong><span class="koboSpan" id="kobo.291.1"> folder doesn’t exist, please create one. </span><span class="koboSpan" id="kobo.291.2">Create the preceding folder under the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.292.1">Chapter 11</span></strong></span><span class="koboSpan" id="kobo.293.1"> folder from </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.294.1">step 6</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.296.1">We can use the terminal to run our </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">Python code.</span></span></p>
<ol>
<li value="8"><span class="koboSpan" id="kobo.298.1">Now, we need to write our training code. </span><span class="koboSpan" id="kobo.298.2">So, navigate to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.299.1">src</span></strong><span class="koboSpan" id="kobo.300.1"> folder and create a new text file </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">called </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.302.1">train.py</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.304.1">For the sample code in this chapter, we are using an open source dataset; it contains no PII and doesn’t have any privacy or </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">legal issues.</span></span></li>
<li><span class="koboSpan" id="kobo.306.1">Let’s import </span><a id="_idIndexMarker737"/><span class="koboSpan" id="kobo.307.1">all the libraries needed for </span><span class="No-Break"><span class="koboSpan" id="kobo.308.1">the code:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer442">
<span class="koboSpan" id="kobo.309.1"><img alt="Figure 11.11 – Library imports" src="image/B18003_11_011.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.310.1">Figure 11.11 – Library imports</span></p>
<ol>
<li value="11"><span class="koboSpan" id="kobo.311.1">Next, we must perform </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">dataset processing:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer443">
<span class="koboSpan" id="kobo.313.1"><img alt="Figure 11.12 – Dataset processing" src="image/B18003_11_012.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.314.1">Figure 11.12 – Dataset processing</span></p>
<ol>
<li value="12"><span class="koboSpan" id="kobo.315.1">Now, let’s create a model. </span><span class="koboSpan" id="kobo.315.2">We will use the Keras library to simplify the neural network architecture. </span><span class="koboSpan" id="kobo.315.3">The layers depend on your use case and accuracy. </span><span class="koboSpan" id="kobo.315.4">I have seen large network architectures with low accuracy and too few layers produce poor results. </span><span class="koboSpan" id="kobo.315.5">So, we have to find the right balance in terms of layers through experimentation </span><a id="_idIndexMarker738"/><span class="koboSpan" id="kobo.316.1">and build the neural network architecture </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">from there:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer444">
<span class="koboSpan" id="kobo.318.1"><img alt="Figure 11.13 – Model neural network" src="image/B18003_11_013.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.319.1">Figure 11.13 – Model neural network</span></p>
<ol>
<li value="13"><span class="koboSpan" id="kobo.320.1">Now, let’s</span><a id="_idIndexMarker739"/><span class="koboSpan" id="kobo.321.1"> create the </span><strong class="source-inline"><span class="koboSpan" id="kobo.322.1">main</span></strong><span class="koboSpan" id="kobo.323.1"> function, which will run the model training process in a distributed manner. </span><span class="koboSpan" id="kobo.323.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.324.1">main</span></strong><span class="koboSpan" id="kobo.325.1"> function is where all the logic flow is tied together to get the training process working. </span><span class="koboSpan" id="kobo.325.2">As you can see, </span><strong class="source-inline"><span class="koboSpan" id="kobo.326.1">tf.distribute</span></strong><span class="koboSpan" id="kobo.327.1"> specifies the </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">distribution strategies:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer445">
<span class="koboSpan" id="kobo.329.1"><img alt="Figure 11.14 – TensorFlow distribution code" src="image/B18003_11_014.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.330.1">Figure 11.14 – TensorFlow distribution code</span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.331.1">Tf.distribute.experimental.MultiWorkerMirroredStrategy</span></strong><span class="koboSpan" id="kobo.332.1"> synchronously replicates all the variables and computation across the worker nodes to process. </span><span class="koboSpan" id="kobo.332.2">It mainly uses GPU (given the large-scale processing). </span><span class="koboSpan" id="kobo.332.3">The preceding implementation allows multiple workers to work together to achieve better performance to complete the training </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1">run faster.</span></span></p>
<ol>
<li value="14"><span class="koboSpan" id="kobo.334.1">Next, we will have to create some Python code called </span><strong class="source-inline"><span class="koboSpan" id="kobo.335.1">job</span></strong><span class="koboSpan" id="kobo.336.1"> in the root folder, which we will execute in a terminal window to execute the TensorFlow code in the </span><span class="No-Break"><span class="koboSpan" id="kobo.337.1">command line.</span></span></li>
<li><span class="koboSpan" id="kobo.338.1">Now, we must create an </span><strong class="source-inline"><span class="koboSpan" id="kobo.339.1">environment.yaml</span></strong><span class="koboSpan" id="kobo.340.1"> file. </span><span class="koboSpan" id="kobo.340.2">This will create the environment to run the model training. </span><span class="koboSpan" id="kobo.340.3">Here is the </span><span class="No-Break"><span class="koboSpan" id="kobo.341.1">sample code:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer446">
<span class="koboSpan" id="kobo.342.1"><img alt="Figure 11.15 – environment.yaml code" src="image/B18003_11_015.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.343.1">Figure 11.15 – environment.yaml code</span></p>
<ol>
<li value="16"><span class="koboSpan" id="kobo.344.1">Next, we </span><a id="_idIndexMarker740"/><span class="koboSpan" id="kobo.345.1">must create the </span><strong class="source-inline"><span class="koboSpan" id="kobo.346.1">jobtensorflow.py</span></strong><span class="koboSpan" id="kobo.347.1"> file, which uses an Azure Machine Learning SDK to configure the training process and then execute it once the job has </span><span class="No-Break"><span class="koboSpan" id="kobo.348.1">been submitted.</span></span></li>
<li><span class="koboSpan" id="kobo.349.1">In the </span><strong class="source-inline"><span class="koboSpan" id="kobo.350.1">code</span></strong><span class="koboSpan" id="kobo.351.1"> section, specify a workspace environment to use and a training Python file to use for the experiment. </span><span class="koboSpan" id="kobo.351.2">There are a few changes you need to make to execute the code. </span><span class="koboSpan" id="kobo.351.3">The workspace, environment, and training Python files’ names can change depending on how you are </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">implementing them:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer447">
<span class="koboSpan" id="kobo.353.1"><img alt="Figure 11.16 – Sample environment and experiment" src="image/B18003_11_016.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.354.1">Figure 11.16 – Sample environment and experiment</span></p>
<ol>
<li value="18"><span class="koboSpan" id="kobo.355.1">Next, we must</span><a id="_idIndexMarker741"/><span class="koboSpan" id="kobo.356.1"> create some code that will set the distribution strategy and then invoke the training experiment. </span><span class="koboSpan" id="kobo.356.2">We can use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.357.1">TensorflowConfiguration</span></strong><span class="koboSpan" id="kobo.358.1"> class to configure how to parallelize the </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">training job.</span></span></li>
</ol>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.360.1">TensorflowConfiguration</span></strong><span class="koboSpan" id="kobo.361.1"> takes two parameters, </span><span class="No-Break"><span class="koboSpan" id="kobo.362.1">as follows:</span></span></p>
<ol>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.363.1">worker_count</span></strong><span class="koboSpan" id="kobo.364.1">: The number of worker nodes used to parallelize. </span><span class="koboSpan" id="kobo.364.2">The default value </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">is </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.366.1">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.368.1">parameter_server_count</span></strong><span class="koboSpan" id="kobo.369.1">: This parameter is set for a number of tasks to run the </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1">previous </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.371.1">worker_count</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.372.1">:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer448">
<span class="koboSpan" id="kobo.373.1"><img alt="Figure 11.17 – Distribution strategy and job submission" src="image/B18003_11_017.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.374.1">Figure 11.17 – Distribution strategy and job submission</span></p>
<ol>
<li value="19"><span class="koboSpan" id="kobo.375.1">Wait for the </span><a id="_idIndexMarker742"/><span class="koboSpan" id="kobo.376.1">experiment to run. </span><span class="koboSpan" id="kobo.376.2">This will take a few minutes to a few hours, depending on the dataset’s size. </span><span class="koboSpan" id="kobo.376.3">Once the experiment has finished running, navigate to your workspace’s user interface, go to the </span><strong class="bold"><span class="koboSpan" id="kobo.377.1">job</span></strong><span class="koboSpan" id="kobo.378.1"> section, and select the job to view </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">its output:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer449">
<span class="koboSpan" id="kobo.380.1"><img alt="Figure 11.18 – Job output" src="image/B18003_11_018.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.381.1">Figure 11.18 – Job output</span></p>
<p><span class="koboSpan" id="kobo.382.1">In this section, you learned how to create code that will run large-scale TensorFlow distributed training for a large custom vision-based deep learning model. </span><span class="koboSpan" id="kobo.382.2">The code is structured to run for a long time and report backlogs for us to check and validate. </span><span class="koboSpan" id="kobo.382.3">These jobs can be submitted as batch jobs so that we don’t have to keep watching what happens. </span><span class="koboSpan" id="kobo.382.4">Instead, we can submit the job and come back after a few hours to see how the model </span><span class="No-Break"><span class="koboSpan" id="kobo.383.1">run performed.</span></span></p>
<h1 id="_idParaDest-142"><a id="_idTextAnchor214"/><span class="koboSpan" id="kobo.384.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.385.1">We have covered a lot of topics in this chapter. </span><span class="koboSpan" id="kobo.385.2">We learned how to create code to distribute PyTorch and TensorFlow deep learning models using the Azure Machine Learning service’s Python SDK. </span><span class="koboSpan" id="kobo.385.3">We also saw how easy and seamless it is to build code that performs in a timely fashion by distributing the model training with large volumes </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1">of data.</span></span></p>
<p><span class="koboSpan" id="kobo.387.1">The goal of this chapter was to show you how to build seamless code that can execute large-scale models via batch processing without you having to watch them run. </span><span class="koboSpan" id="kobo.387.2">The Azure Machine Learning SDK allows us to submit the job and then come back later and check </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">the output.</span></span></p>
<p><span class="koboSpan" id="kobo.389.1">This is the last chapter of this book; I hope you had an amazing time reading and learning about Azure Machine Learning and how to build machine learning models. </span><span class="koboSpan" id="kobo.389.2">We would like to hear about your experience in applying machine learning or deep learning in your organization. </span><span class="koboSpan" id="kobo.389.3">Azure Machine Learning will make your journey simple and easy with open source </span><span class="No-Break"><span class="koboSpan" id="kobo.390.1">in mind.</span></span></p>
<p><span class="koboSpan" id="kobo.391.1">Thank you so much for reading this book. </span><span class="koboSpan" id="kobo.391.2">This book will help you study for certifications such as AI 102 (AI Engineer – Training | Microsoft Learn: </span><a href="https://learn.microsoft.com/en-us/certifications/roles/ai-engineer"><span class="koboSpan" id="kobo.392.1">https://learn.microsoft.com/en-us/certifications/roles/ai-engineer</span></a><span class="koboSpan" id="kobo.393.1">) and DP 100 (Exam DP-100: Designing and Implementing a Data Science Solution on Azure – Certifications | Microsoft </span><span class="No-Break"><span class="koboSpan" id="kobo.394.1">Learn: </span></span><a href="https://learn.microsoft.com/en-us/certifications/exams/dp-100"><span class="No-Break"><span class="koboSpan" id="kobo.395.1">https://learn.microsoft.com/en-us/certifications/exams/dp-100</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.396.1">).</span></span></p>
</div>
</body></html>