["```py\nimport sys\nprint(sys.version)\n```", "```py\npip install jupyter\n```", "```py\njupyter notebook\n```", "```py\npip install snorkel\npip install scikit-learn\npip install Pillow\npip install tensorflow\npip install pandas\npip install numpy\n```", "```py\nfrom sklearn.datasets import fetch_openml\nimport pandas as pd\n# Fetch the credit-g dataset\ncredit_g = fetch_openml(name='credit-g')\n# Convert to DataFrame\ndf = pd.DataFrame(credit_g.data, columns=credit_g.feature_names)\ntarget = pd.Series(credit_g.target)\n# If you want to add the target variable into your DataFrame\ndf['target'] = target\n# Show top rows of the credit-g dataset\ndf.head().T\n```", "```py\ndef credit_amount_labeling_function(df):\n    if df[\"credit_amount\"] > 5000:\n        return 1\n    else:\n        return 0\ndef age_labeling_function(df):\n    if df[\"age\"] > 30:\n        return 1\n    else:\n        return 0\n```", "```py\ndf[\"credit_amount_label\"] = df.apply(credit_amount_labeling_function, axis=1)\ndf[\"age_label\"] = df.apply(age_labeling_function, axis=1)\ndf.head().T\n```", "```py\ndef lf_credit_amount_above_median(df):\n    credit_amount_median = df['credit_amount'].median()\n    return df['credit_amount'] >= credit_amount_median\n```", "```py\ndf['LF_CreditAmountAboveMedian'] = lf_credit_amount_above_median(df)\ndf.head().T\n```", "```py\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv('train_loan_prediction.csv')\ndf['LoanAmount'].fillna(df['LoanAmount'].mean(), inplace=True)\ndf['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)\ndf['Self_Employed'].fillna('No',inplace=True)\ndf['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\ndf['Married'].fillna(df['Married'].mode()[0], inplace=True)\ndf['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)\ndf['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace=True)\ndf['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)\n```", "```py\nfrom sklearn.preprocessing import LabelEncoder\ncat_features = ['Gender', 'Married','Dependents', 'Education', 'Self_Employed', 'Property_Area']\nfor feature in cat_features:\n    encoder = LabelEncoder()\n    df[feature] = encoder.fit_transform(df[feature])\n```", "```py\nfrom snorkel.labeling import labeling_function\n@labeling_function()\ndef lf1(df):\n    if df['Education'] == 0:\n        return 0\n    elif df['Self_Employed'] == 0:\n        return 1\n    else:\n        return -1\n@labeling_function()\ndef lf2(df):\n    if df['Credit_History'] == 1:\n        if df['LoanAmount'] <= 120:\n            return 1\n        else:\n            return 0\n    else:\n        return -1\n@labeling_function()\ndef lf3(df):\n    if df['Married'] == 1:\n        if df['Dependents'] == 0:\n            return 1\n        elif df['Dependents'] == 1:\n            return 0\n        else:\n            return -1\n    else:\n        return -1\n```", "```py\nLFs = [lf1, lf2, lf3]\nfrom snorkel.labeling import PandasLFApplier\napplier = PandasLFApplier(lfs=LFs)\nL_train = applier.apply(df)\n```", "```py\nfrom snorkel.labeling.model import LabelModel\nfrom snorkel.labeling import PandasLFApplier, LFAnalysis\nfrom sklearn.metrics import accuracy_score\nlabel_model = LabelModel(cardinality=2, verbose=True)\nlabel_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)\n```", "```py\nprobs_train = label_model.predict_proba(L_train)\nmapping = {'Y': 1, 'N': 0}\nY_train = df['Loan_Status'].map(mapping).values\nscore_train = label_model.score(L_train, Y_train)\ndf['label'] = probs_train.argmax(axis=1)\ndf['label'] = df['label'].map({1: 'Y', 0: 'N'})\nprint(f\"Accuracy: {accuracy_score(df['Loan_Status'].values, df['label'].values)}\")\n```", "```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom snorkel.labeling import labeling_function\nfrom snorkel.labeling import PandasLFApplier\nfrom snorkel.labeling import LFAnalysis\nfrom snorkel.labeling.model import LabelModel\ndf = pd.read_csv('train_loan_prediction.csv')\n```", "```py\ndef preprocess_data(df):\n    df['Gender'] = df['Gender'].fillna('Unknown')\n    df['Married'] = df['Married'].fillna('Unknown')\n    df['Dependents'] = df['Dependents'].fillna('0')\n    df['Self_Employed'] = df['Self_Employed'].fillna('Unknown')\n    df['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].mean())\n    df['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mean())\n    df['Credit_History'] = df['Credit_History'].fillna(-1)\n    df['LoanAmount_bin'] = pd.cut(df['LoanAmount'], bins=[0, 100, 200, 700], labels=['Low', 'Average', 'High'])\n    df['TotalIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n    df['TotalIncome_bin'] = pd.cut(df['TotalIncome'], bins=[0, 2500, 4000, 6000, 81000], labels=['Low', 'Average', 'High', 'Very high'])\n    df = df.drop(['Loan_ID', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'TotalIncome'], axis=1)\n    return df\n```", "```py\n@labeling_function()\ndef lf1(x):\n    return 0 if x['ApplicantIncome'] < 5000 else 1\n@labeling_function()\ndef lf2(x):\n    return 0 if x['LoanAmount'] > 200 else 1\n@labeling_function()\ndef lf3(x):\n    # Calculate the ratio of loan amount to applicant's income\n    loan_to_income_ratio = x['LoanAmount'] / x['ApplicantIncome']\n    # Return label based on the loan-to-income ratio\n    if loan_to_income_ratio <= 0.3:\n        return 1  # Approve loan\n    elif loan_to_income_ratio > 0.3 and loan_to_income_ratio <= 0.5:\n        return 0  # Label as uncertain\n    else:\n        return -1  # Deny loan\n```", "```py\nX = preprocess_data(df.drop('Loan_Status', axis=1))\ny = df['Loan_Status'].replace({'N': 0, 'Y': 1})\n```", "```py\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```", "```py\nlfs = [lf1, lf2, lf3]\napplier = PandasLFApplier(lfs)\nL_train_weak = applier.apply(X_train)\n```", "```py\nlabel_model = LabelModel(cardinality=2, verbose=True)\nlabel_model.fit(L_train_weak)\n```", "```py\nL_test = applier.apply(X_test)\naccuracy = label_model.score(L_test, y_test)[\"accuracy\"]\nprint(f'Test accuracy: {accuracy:.3f}')\n```", "```py\nfrom snorkel.labeling import labeling_function\nfrom snorkel.labeling import PandasLFApplier\nfrom snorkel.labeling.model import LabelModel\nfrom snorkel.labeling import LFAnalysis\ndf = pd.read_csv('train_loan_prediction.csv')\nX = preprocess_data(df.drop('Loan_Status', axis=1))\ny = df['Loan_Status'].replace({'N': 0, 'Y': 1})\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```", "```py\n@labeling_function()\ndef slice_high_income(x):\n    return 1 if x['ApplicantIncome'] > 8000 else 0\n@labeling_function()\ndef slice_low_income_high_loan(x):\n    return 1 if x['ApplicantIncome'] < 4000 and x['LoanAmount'] > 150 else 0\n@labeling_function()\ndef slice_self_employed(x):\n    return 1 if x['Self_Employed'] == 'Yes' else 0\n```", "```py\nlfs = [slice_high_income, slice_low_income_high_loan, slice_self_employed]\napplier = PandasLFApplier(lfs)\nL_train = applier.apply(df=X_train)\n```", "```py\nlabel_model = LabelModel(cardinality=2, verbose=True)\nlabel_model.fit(L_train, n_epochs=500, seed=42)\n```", "```py\nL_test = applier.apply(df=X_test)\naccuracy = label_model.score(L=L_test, Y=y_test)\nprint(f'Test accuracy: {accuracy[\"accuracy\"]:.3f}')\n```", "```py\nLFAnalysis(L=L_train, lfs=lfs).lf_summary()\n```", "```py\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n# Define preprocessor\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), ['duration', 'credit_amount', 'installment_commitment',\n                                   'residence_since', 'age', 'existing_credits', 'num_dependents']),\n        ('cat', OneHotEncoder(), ['checking_status', 'credit_history', 'purpose',\n                                  'savings_status', 'employment', 'personal_status', 'other_parties',\n                                  'property_magnitude', 'other_payment_plans', 'housing', 'job',\n                                  'own_telephone', 'foreign_worker'])])\n# Define a mapping from current labels to desired labels\nmapping = {'good': 1, 'bad': 0}\n# Apply the mapping to the target variable\ndf['target'] = df['target'].map(mapping)\n# Fit and transform the features\nfeatures = preprocessor.fit_transform(df.drop('target', axis=1))\n# Convert the features to a dataframe\nfeatures_df = pd.DataFrame(features)\n# Add the target back to the dataframe\ndf_preprocessed = pd.concat([features_df, df['target'].reset_index(drop=True)], axis=1)\n```", "```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n```", "```py\nlabeled_data, unlabeled_data = train_test_split(df_preprocessed, test_size=0.9, random_state=42)\n```", "```py\n    def least_confidence(probabilities):\n        confidence = 1 - np.max(probabilities, axis=1)\n        return np.argsort(confidence)\n    ```", "```py\n    def margin_sampling(probabilities):\n        sorted_probs = np.sort(probabilities, axis=1)\n        margin = sorted_probs[:, -1] - sorted_probs[:, -2]\n        return np.argsort(margin)\n    ```", "```py\n    def entropy_sampling(probabilities):\n        entropy = -np.sum(probabilities * np.log2(probabilities), axis=1)\n        return np.argsort(entropy)\n    ```", "```py\n# Initialize a list to store the accuracy at each iteration\naccuracies = []\n# Implement the active learning loop.\nnum_iterations = 5\nbatch_size = 20\nfor _ in range(num_iterations):\n    model = LogisticRegression()\n    model.fit(X_labeled, y_labeled)\n    # Calculate and store the accuracy on the labeled data at this iteration\n    accuracies.append(accuracy_score(y_labeled, model.predict(X_labeled)))\n    probabilities = model.predict_proba(X_unlabeled)\n    indices = least_confidence(probabilities)[:batch_size]\n    X_newly_labeled = X_unlabeled[indices]\n    y_newly_labeled = y_unlabeled[indices]\n    X_labeled = np.concatenate([X_labeled, X_newly_labeled])\n    y_labeled = np.concatenate([y_labeled, y_newly_labeled])\n    X_unlabeled = np.delete(X_unlabeled, indices, axis=0)\n    y_unlabeled = np.delete(y_unlabeled, indices)\n```", "```py\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nax = plt.figure().gca()\nax.xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.plot(range(1, num_iterations + 1), accuracies)\nplt.xlabel('Iteration')\nplt.ylabel('Accuracy')\nplt.title('Model accuracy over iterations (least_confidence)')\nplt.show()\n```", "```py\ndef create_committee(num_models):\n    committee = []\n    for _ in range(num_models):\n        model = LogisticRegression()\n        # Customize and train each model as needed\n        committee.append(model)\n    return committee\ndef get_committee_predictions(committee, data):\n    predictions = []\n    for model in committee:\n        preds = model.predict_proba(data)\n        predictions.append(preds)\n    return np.array(predictions)\ndef measure_disagreement(predictions):\n    disagreement = np.var(predictions, axis=0)\n    return np.mean(disagreement, axis=1)\n```", "```py\nlabeled_dataset = labeled_data.copy()\nnum_iterations = 5\nbatch_size = 20\ncommittee = create_committee(num_models=3)\nfor _ in range(num_iterations):\n    for model in committee:\n        X_train = labeled_dataset.drop('target', axis=1)\n        y_train = labeled_dataset['target']\n        model.fit(X_train, y_train)\n    X_unlabeled = unlabeled_data.drop('target', axis=1)\n    committee_predictions = get_committee_predictions(committee, X_unlabeled)\n    disagreement = measure_disagreement(committee_predictions)\n    indices = np.argsort(disagreement)[-batch_size:]\n    labeled_instances = unlabeled_data.iloc[indices]\n    labels = labeled_instances['Loan_Status']\n    labeled_dataset = pd.concat([labeled_dataset, labeled_instances])\n    unlabeled_data = unlabeled_data.drop(labeled_instances.index)\n```", "```py\nfrom sklearn.metrics.pairwise import pairwise_distances\n```", "```py\ndef calculate_diversity(data):\n    distance_matrix = pairwise_distances(data, metric='euclidean')\n    diversity = np.sum(distance_matrix, axis=1)\n    return diversity\ndef select_diverse_instances(data, num_instances):\n    diversity = calculate_diversity(data)\n    indices = np.argsort(diversity)[-num_instances:]\n    return data.iloc[indices]\n```", "```py\nlabeled_dataset = labeled_data.copy()\nnum_iterations = 5\nbatch_size = 20\nfor _ in range(num_iterations):\n    X_unlabeled = unlabeled_data.drop('target', axis=1)\n    diversity = calculate_diversity(X_unlabeled)\n    labeled_instances = select_diverse_instances(unlabeled_data, batch_size)\n    labels = labeled_instances['target']\n    labeled_dataset = pd.concat([labeled_dataset, labeled_instances])\n    unlabeled_data = unlabeled_data.drop(labeled_instances.index)\n```", "```py\nimport PIL\nimport PIL.Image\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\n```", "```py\nPIL.Image.open('path_to_image_2.jpg')\n```", "```py\nmodel = VGG16(weights='imagenet')\nimg_path = 'path_to_image_2.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nfeatures = model.predict(x)\ndecoded_predictions = decode_predictions(features, top=5)[0]\nfor _, label, confidence in decoded_predictions:\n    print(label, confidence)\n```", "```py\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\n```", "```py\nnum_classes = 2\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n```", "```py\nfor layer in base_model.layers:\n    layer.trainable = False\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n```", "```py\ntrain_data_dir = /path_to_training_data'\nvalidation_data_dir = '/path_to_validation_data'\nbatch_size = 32\ntrain_datagen = ImageDataGenerator(rescale=1.0/255.0)\nvalidation_datagen = ImageDataGenerator(rescale=1.0/255.0)\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(256, 256),\n    batch_size=batch_size,\n    class_mode='categorical')\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(256, 256),\n    batch_size=batch_size,\n    class_mode='categorical')\n```", "```py\nepochs = 10\nmodel.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // batch_size)\nmodel.save('fine_tuned_model.h5')\n```", "```py\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.semi_supervised import LabelPropagation\n```", "```py\nX = df_preprocessed.drop('target', axis=1)\ny = df_preprocessed['target']\n# Split the dataset into labeled and unlabeled\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nlabeled_percentage = 0.1  # Percentage of labeled data\nX_train_labeled, X_train_unlabeled, y_train_labeled, _ = train_test_split(\n    X_train, y_train, test_size=1 - labeled_percentage, random_state=42)\n```", "```py\nsupervised_model = LogisticRegression()\nsupervised_model.fit(X_train_labeled, y_train_labeled)\n```", "```py\n# Predict labels for the unlabeled data\npseudo_labels = supervised_model.predict(X_train_unlabeled)\n```", "```py\n# Concatenate the labeled data with the pseudo-labeled data\nX_combined = np.concatenate((X_labeled, X_unlabeled))\ny_combined = np.concatenate((y_labeled, pseudo_labels))\n```", "```py\nsemi_supervised_model = LabelPropagation()\nsemi_supervised_model.fit(X_combined, y_combined)\n```", "```py\ny_pred = semi_supervised_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Test accuracy: {accuracy:.3f}')\n```"]