["```py\nIn [1]: import numpy as np\nIn [2]: class Perceptron(object):\n...     def __init__(self, lr=0.01, n_iter=10):\n...     self.lr = lr\n...     self.n_iter = n_iter\n... \n```", "```py\n...         def fit(self, X, y):\n...             self.weights = np.zeros(X.shape[1])\n...             self.bias = 0.0\n```", "```py\n...         def predict(self, X):\n...             return np.where(np.dot(X, self.weights) + self.bias >= 0.0,\n...                             1, -1)\n```", "```py\n...             for _ in range(self.n_iter):\n...                 for xi, yi in zip(X, y):\n...                     delta = self.lr * (yi - self.predict(xi))\n...                     self.weights += delta * xi\n...                     self.bias += delta\n```", "```py\nIn [3]: from sklearn.datasets.samples_generator import make_blobs...     X, y = make_blobs(n_samples=100, centers=2,...                       cluster_std=2.2, random_state=42)\n```", "```py\nIn [4]: y = 2 * y - 1\n```", "```py\nIn [6]: p = Perceptron(lr=0.1, n_iter=10)\n```", "```py\nIn [7]: p.fit(X, y)\n```", "```py\nIn [8]: p.weights\nOut[8]: array([ 2.20091094, -0.4798926 ])\n```", "```py\nIn [9]: p.bias\nOut[9]: 0.20000000000000001\n```", "```py\nIn [10]: from sklearn.metrics import accuracy_score...      accuracy_score(p.predict(X), y)Out[10]: 1.0\n```", "```py\nIn [10]: def plot_decision_boundary(classifier, X_test, y_test):...          # create a mesh to plot in...          h = 0.02 # step size in mesh...          x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1...          y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1... xx, yy = np.meshgrid(np.arange(x_min, ...\n```", "```py\nIn [12]: X, y = make_blobs(n_samples=100, centers=2,\n...      cluster_std=5.2, random_state=42)\n...      y = 2 * y - 1\n```", "```py\nIn [13]: plt.scatter(X[:, 0], X[:, 1], s=100, c=y);\n...      plt.xlabel('x1')\n...      plt.ylabel('x2')\n```", "```py\nIn [14]: p = Perceptron(lr=0.1, n_iter=10)\n...      p.fit(X, y)\n```", "```py\nIn [15]: accuracy_score(p.predict(X), y)\nOut[15]: 0.81000000000000005\n```", "```py\nIn [16]: plot_decision_boundary(p, X, y)\n...      plt.xlabel('x1')\n...      plt.ylabel('x2')\n```", "```py\nIn [1]: from sklearn.datasets.samples_generator import make_blobs\n...     X_raw, y_raw = make_blobs(n_samples=100, centers=2,\n...                               cluster_std=5.2, random_state=42)\n```", "```py\nIn [2]: import numpy as np... X = X_raw.astype(np.float32)\n```", "```py\nIn [3]: from sklearn.preprocessing import OneHotEncoder...     enc = OneHotEncoder(sparse=False, dtype=np.float32)...     y = enc.fit_transform(y_raw.reshape(-1, 1))\n```", "```py\nIn [4]: import cv2\n...     mlp = cv2.ml.ANN_MLP_create()\n```", "```py\nIn [5]: n_input = 2\n...     n_hidden = 10\n...     n_output = 2\n...     mlp.setLayerSizes(np.array([n_input, n_hidden, n_output]))\n```", "```py\nIn [11]: mlp.train(X, cv2.ml.ROW_SAMPLE, y)\nOut[11]: True\n```", "```py\nIn [12]: _, y_hat = mlp.predict(X)\n```", "```py\nIn [13]: from sklearn.metrics import accuracy_score\n...      accuracy_score(y_hat.round(), y)\nOut[13]: 0.88\n```", "```py\nIn [14]: def plot_decision_boundary(classifier, X_test, y_test):\n... # create a mesh to plot in\n... h = 0.02 # step size in mesh\n... x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n... y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n... xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n... np.arange(y_min, y_max, h))\n... \n... X_hypo = np.c_[xx.ravel().astype(np.float32),\n... yy.ravel().astype(np.float32)]\n... _, zz = classifier.predict(X_hypo)\n```", "```py\n...          zz = np.argmax(zz, axis=1)\n```", "```py\n...          zz = zz.reshape(xx.shape)\n...          plt.contourf(xx, yy, zz, cmap=plt.cm.coolwarm, alpha=0.8)\n...          plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=200)\n```", "```py\nIn [15]: plot_decision_boundary(mlp, X, y_raw)\n```", "```py\nIn [1]: from keras.models import Sequential\n...     model = Sequential()\nOut[1]: Using TensorFlow backend.\n```", "```py\nIn [2]: from keras.layers import Dense\n...     model.add(Dense(1, activation='tanh', input_dim=2,\n...                     kernel_initializer='zeros'))\n```", "```py\nIn [3]: model.compile(optimizer='sgd',\n...                   loss='mean_squared_error',\n...                   metrics=['accuracy'])\n```", "```py\nIn [4]: from sklearn.datasets.samples_generator import make_blobs\n...     X, y = make_blobs(n_samples=100, centers=2,\n...     cluster_std=2.2, random_state=42)\n```", "```py\nIn [5]: model.fit(X, y, epochs=400, batch_size=100, shuffle=False,\n...               verbose=0)\n```", "```py\nIn [6]: model.evaluate(X, y)\nOut[6]: 32/100 [========>.....................] - ETA: 0s\n        [0.040941802412271501, 1.0]\n```", "```py\nIn [1]: from keras.datasets import mnist\n...     (X_train, y_train), (X_test, y_test) = mnist.load_data()\nOut[1]: Using TensorFlow backend.\n        Downloading data from\n        https://s3.amazonaws.com/img-datasets/mnist.npz\n```", "```py\nIn [2]: X_train.shape, y_train.shape\nOut[2]: ((60000, 28, 28), (60000,))\n```", "```py\nIn [3]: import numpy as np\n...     np.unique(y_train)\nOut[3]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)\n```", "```py\nIn [4]: import matplotlib.pyplot as plt\n...     %matplotlib inline\nIn [5]: for i in range(10):\n...         plt.subplot(2, 5, i + 1)\n...         plt.imshow(X_train[i, :, :], cmap='gray')\n...         plt.axis('off')\n```", "```py\nIn [9]: import cv2\n...     mlp = cv2.ml.ANN_MLP_create()\n```", "```py\nIn [10]: mlp.setLayerSizes(np.array([784, 512, 512, 10]))\n```", "```py\nIn [11]: mlp.setActivationFunction(cv2.ml.ANN_MLP_SIGMOID_SYM,\n      ...                                2.5, 1.0)\n```", "```py\nIn [12]: mlp.setTrainMethod(cv2.ml.ANN_MLP_BACKPROP)\n...      mlp.setBackpropWeightScale(0.00001)\n```", "```py\nIn [13]: term_mode = (cv2.TERM_CRITERIA_MAX_ITER + \n...                   cv2.TERM_CRITERIA_EPS)\n...      term_max_iter = 10\n...      term_eps = 0.01\n...      mlp.setTermCriteria((term_mode, term_max_iter,\n...                           term_eps))\n```", "```py\nIn [14]: mlp.train(X_train_pre, cv2.ml.ROW_SAMPLE, y_train_pre)\nOut[14]: True\n```", "```py\nIn [15]: _, y_hat_train = mlp.predict(X_train_pre)\nIn [16]: from sklearn.metrics import accuracy_score\n...      accuracy_score(y_hat_train.round(), y_train_pre)\nOut[16]: 0.92976666666666663\n```", "```py\nIn [17]: _, y_hat_test = mlp.predict(X_test_pre)\n...      accuracy_score(y_hat_test.round(), y_test_pre)\nOut[17]: 0.91690000000000005\n```", "```py\nIn [1]: import numpy as np\n...     np.random.seed(1337)\n```", "```py\nIn [2]: from keras.datasets import mnist\n...     (X_train, y_train), (X_test, y_test) = mnist.load_data()\n```", "```py\nIn [3]: img_rows, img_cols = 28, 28\n...     X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n...     X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n...     input_shape = (img_rows, img_cols, 1)\n```", "```py\n...     X_train = X_train.astype('float32') / 255.0\n...     X_test = X_test.astype('float32') / 255.0\n```", "```py\nIn [4]: from keras.utils import np_utils\n...     n_classes = 10\n...     Y_train = np_utils.to_categorical(y_train, n_classes)\n...     Y_test = np_utils.to_categorical(y_test, n_classes)\n```", "```py\nIn [5]: from keras.model import Sequential... model = Sequential()\n```", "```py\nIn [6]: from keras.layers import Convolution2D...     n_filters = 32...     kernel_size = (3, 3)...     model.add(Convolution2D(n_filters, kernel_size[0], kernel_size[1],... border_mode='valid', ...\n```", "```py\nIn [12]: model.fit(X_train, Y_train, batch_size=128, nb_epoch=12,...                verbose=1, validation_data=(X_test, Y_test))\n```", "```py\nIn [13]: model.evaluate(X_test, Y_test, verbose=0)Out[13]: 0.99\n```"]