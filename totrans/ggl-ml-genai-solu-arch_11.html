<html><head></head><body>
<div id="sbo-rt-content" class="calibre1"><div id="_idContainer142" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-183"><a id="_idTextAnchor245" class="calibre6 pcalibre pcalibre1"/>9</h1>
<h1 id="_idParaDest-184" class="calibre5"><a id="_idTextAnchor246" class="calibre6 pcalibre pcalibre1"/>Neural Networks and Deep Learning</h1>
<p class="calibre3">In this chapter, we will <a id="_idIndexMarker964" class="calibre6 pcalibre pcalibre1"/>discuss <strong class="bold">neural networks</strong> (<strong class="bold">NNs</strong>) in <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>), often referred to as <strong class="bold">artificial NNs</strong> or <strong class="bold">ANNs</strong>. We will introduce <a id="_idIndexMarker965" class="calibre6 pcalibre pcalibre1"/>many important topics in this field of science, including <a id="_idIndexMarker966" class="calibre6 pcalibre pcalibre1"/>fundamental concepts that led to the development of ANNs, and relevant use cases for their application. At this point, it’s important to <a id="_idIndexMarker967" class="calibre6 pcalibre pcalibre1"/>note that the term <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>) refers to ML that <a id="_idIndexMarker968" class="calibre6 pcalibre pcalibre1"/>is implemented with the use of <strong class="bold">deep NNs</strong> (<strong class="bold">DNNs</strong>). We will explain the term “DNN” later in <span>this chapter.</span></p>
<p class="calibre3">We will also introduce some tools and frameworks that make it easier for us to create NNs, such as TensorFlow and Keras, and we will use those tools to build an NN in our hands-on activities later in this chapter. Finally, we will expand the discussion to include different types of NN architectures, common challenges in NN implementations, and some practices for optimizing our <span>NN architectures.</span></p>
<p class="calibre3">As a side note, I first started learning about ANNs when I was in college, and I remember being absolutely fascinated by the concept because I also had an avid interest in understanding how the human brain works. Although the concept of NNs is indeed loosely based on the theorized workings of the human brain, in this chapter, we will separate hype from reality and will focus on the practical, mathematical descriptions of this technology. Let’s start by covering some important concepts in <span>this space.</span></p>
<p class="calibre3">This chapter covers the <span>following topics:</span></p>
<ul class="calibre16">
<li class="calibre8">NN and <span>DL concepts</span></li>
<li class="calibre8"><span>Libraries</span></li>
<li class="calibre8">Implementing a <strong class="bold">multilayer perceptron</strong> (<strong class="bold">MLP</strong>) <span>in </span><span><a id="_idIndexMarker969" class="calibre6 pcalibre pcalibre1"/></span><span>TensorFlow</span></li>
<li class="calibre8">NN architectures, challenges, <span>and optimization</span></li>
</ul>
<h1 id="_idParaDest-185" class="calibre5"><a id="_idTextAnchor247" class="calibre6 pcalibre pcalibre1"/>NN and DL concepts</h1>
<p class="calibre3">In this section, we discuss <a id="_idIndexMarker970" class="calibre6 pcalibre pcalibre1"/>concepts that are important <a id="_idIndexMarker971" class="calibre6 pcalibre pcalibre1"/>to understand in the context of NNs and DL. We begin by discussing how ANNs are linked to our understanding of the <span>human brain.</span></p>
<h2 id="_idParaDest-186" class="calibre9"><a id="_idTextAnchor248" class="calibre6 pcalibre pcalibre1"/>Neurons and the perceptron</h2>
<p class="calibre3">While the link between artificial neurons and biological neurons (as found in the human brain) is often <a id="_idIndexMarker972" class="calibre6 pcalibre pcalibre1"/>over-emphasized, there is a conceptual link between them that <a id="_idIndexMarker973" class="calibre6 pcalibre pcalibre1"/>helps us form a mental model of how they work. Biological neurons generally consist of three main parts, as depicted in <span><em class="italic">Figure 9</em></span><span><em class="italic">.1</em></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer133">
<img alt="Figure 9.1: Neuron (source: https://www.flickr.com/photos/187096960@N06/51173238594)" src="image/B18143_09_1.jpg" class="calibre132"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.1: Neuron (source: https://www.flickr.com/photos/187096960@N06/51173238594)</p>
<p class="calibre3">The cell body is the core part of the neuron that contains the nucleus and other important components. The dendrites (coming from the Greek word “dendron,” meaning “tree”) are structures that branch out from the cell body. They receive information from other neurons and transmit this information to the cell body. Finally, the axons are long, tube-like structures that extend from the cell body and send information out to the dendrites of other neurons (across an interface called a synapse). That’s about as deep as we’re going to get with regard to the biology of a neuron; I’ve simplified it quite a bit here because we just need high-level context for the comparison we’re going to make with ANNs, but the next thing we need to understand is how they transmit information, and this works at a high level as follows (again, simplified for <span>relevant context).</span></p>
<p class="calibre3">When a neuron <a id="_idIndexMarker974" class="calibre6 pcalibre pcalibre1"/>receives a signal from another neuron, this causes a change in what’s called the <strong class="bold">electrical potential</strong> across the neuron’s cell membrane (the difference in voltage between the inside and outside of the neuron), triggering <a id="_idIndexMarker975" class="calibre6 pcalibre pcalibre1"/>what’s called an <strong class="bold">action potential</strong>, which is an electrical impulse that travels down the axon. When it reaches the end of the axon, it triggers the release of neurotransmitters, which are chemical messengers. These neurotransmitters <a id="_idIndexMarker976" class="calibre6 pcalibre pcalibre1"/>cross something called the <strong class="bold">synaptic gap</strong> (the tiny space between neurons) and bind to receptors on the dendrites of the next neuron, and this binding can then either trigger or inhibit a new action potential in the <span>second neuron.</span></p>
<p class="calibre3">Okay – we’ve just <a id="_idIndexMarker977" class="calibre6 pcalibre pcalibre1"/>introduced a lot of biological terminology in the past two paragraphs, but those concepts are important to understand when we want to draw a comparison <a id="_idIndexMarker978" class="calibre6 pcalibre pcalibre1"/>with ANNs. With this in mind, let’s move on and discuss how ANNs are constructed, beginning with their most basic concept, the perceptron, which I briefly mentioned in <a href="B18143_01.xhtml#_idTextAnchor015" class="calibre6 pcalibre pcalibre1"><span><em class="italic">Chapter 1</em></span></a> when I summarized various milestones in the evolution <span>of ML.</span></p>
<p class="calibre3">A perceptron can be seen as one of the simplest types of ANNs and as a building block for larger, more complex networks. It was developed by Frank Rosenblatt in the late 1950s, and it’s basically a binary classifier that maps its input X (a vector) to an output value f(x) (a single binary value) using a set of weights that are applied to the <span>input features.</span></p>
<p class="calibre3">To understand this process in more detail, let’s dive deeper into how a perceptron works, which can be summarized using the following set <span>of steps:</span></p>
<ol class="calibre7">
<li class="calibre8">The perceptron receives input values, which could be features or attributes from <span>a dataset.</span></li>
<li class="calibre8">Each input has an associated <strong class="bold">weight</strong> that represents its importance. The weights are often just given random values at the beginning of training, and the values are then refined during the training process. We will discuss this in more <span>detail shortly.</span></li>
<li class="calibre8">A <strong class="bold">bias unit</strong> is also added <a id="_idIndexMarker979" class="calibre6 pcalibre pcalibre1"/>to the perceptron model to increase the model’s flexibility. This is not related to the topic of bias that we will discuss in the context of fairness in later chapters of this book; it’s simply a mathematical trick that provides an additional control mechanism for refining our model’s performance when attempting to produce the <span>desired output.</span></li>
<li class="calibre8">Next, each input is multiplied by its corresponding weight, and all of the results of those multiplications are added together (as well as the bias), which results in a <strong class="bold">weighted sum</strong>, so this <a id="_idIndexMarker980" class="calibre6 pcalibre pcalibre1"/>is simply a <strong class="bold">linear transformation</strong> of the inputs, based on the weights and <span>bias values.</span></li>
<li class="calibre8">This weighted <a id="_idIndexMarker981" class="calibre6 pcalibre pcalibre1"/>sum is then passed through an <strong class="bold">activation function</strong> that produces a binary output. We will explain activation functions in more detail shortly, but at a high level, a non-linear transformation is performed on the weighted sum, and the results of that transformation are produced as an output from the perceptron. In the case of a single perceptron, a simple example would be that if the <a id="_idIndexMarker982" class="calibre6 pcalibre pcalibre1"/>weighted sum of the inputs is greater than a threshold value, the perceptron would output a value of 1, or if the weighted sum is less <a id="_idIndexMarker983" class="calibre6 pcalibre pcalibre1"/>than or equal to the threshold, it would output <a id="_idIndexMarker984" class="calibre6 pcalibre pcalibre1"/>a value of 0, so this is basically an implementation of the process referred to as <span><strong class="bold">logistic regression</strong></span><span>.</span><p class="calibre3">Mathematically, this can be written as <span>the following:</span></p><ul class="calibre70"><li class="calibre8">If ∑ (weights * inputs) + bias &gt; 0, <span>output 1</span></li><li class="calibre8">If ∑ (weights * inputs) + bias ≤ 0, <span>output 0</span></li></ul></li>
</ol>
<p class="calibre3"><span><em class="italic">Figure 9</em></span><em class="italic">.2</em> provides a visual representation of how a <span>perceptron works:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer134">
<img alt="Figure 9.2: Perceptron (source: https://commons.wikimedia.org/wiki/File:Perceptron-unit.svg#file)" src="image/B18143_09_2.jpg" class="calibre133"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.2: Perceptron (source: https://commons.wikimedia.org/wiki/File:Perceptron-unit.svg#file)</p>
<p class="calibre3">In <span><em class="italic">Figure 9</em></span><em class="italic">.2</em>, the <em class="italic">x</em> values on the far left of the diagram represent inputs to the perceptron. The <em class="italic">x</em><span class="subscript">0</span> input is the bias, and <em class="italic">x</em><span class="subscript">1</span> through <em class="italic">x</em><span class="subscript">n</span> represent the input features from our dataset. The <em class="italic">w</em> values represent the weights, the Greek characters (sigma and phi) within the green circle represent the activation function, and the Greek character (omicron) on the far right represents <span>the output.</span></p>
<p class="calibre3">The important <a id="_idIndexMarker985" class="calibre6 pcalibre pcalibre1"/>concept to understand is that the values of the weights and bias are what our perceptron model is trying to learn. That is, our model is trying to figure out what the best weights are for each feature, which results in a pattern that gets us as <a id="_idIndexMarker986" class="calibre6 pcalibre pcalibre1"/>close as possible to the target outcome after we perform the linear and non-linear transformations we described (in combination with the bias). If we think back to the more traditional ML models we created in earlier chapters, such as linear regression, you may remember that our models were trying to figure out the optimal values of the coefficients for each of our features that would result in the desired outcomes. In perceptrons, and in ANNs in general, the weights (and the bias) are the coefficients that our models are trying <span>to optimize.</span></p>
<p class="calibre3">With this understanding of how perceptrons work, let’s discuss how they can be used to build more <span>complex NNs.</span></p>
<h3 class="calibre11">MLPs and NNs</h3>
<p class="calibre3">While the perceptron is a simple and powerful algorithm, it can only model linearly separable functions. This means that if our data isn’t linearly separable (that is, we can’t draw a straight line to separate the classes), the perceptron won’t be able to accurately distinguish <a id="_idIndexMarker987" class="calibre6 pcalibre pcalibre1"/>between the classes in the dataset. To overcome this limitation, multiple perceptrons can be combined in layers to form an MLP, which has the potential to solve non-linear problems. An MLP is a form of NN, so basically, when we combine multiple perceptrons in a sequential manner (that is, where the outputs of some perceptrons become the inputs for other perceptrons), we form a type <span>of ANN.</span></p>
<p class="calibre3">Considering that <a id="_idIndexMarker988" class="calibre6 pcalibre pcalibre1"/>the perceptron can be considered a type of artificial neuron, we will use the terms “perceptron” and “artificial neuron” (or sometimes just “neuron”) interchangeably from this <span>point onward.</span></p>
<h4 class="calibre20">Summarizing the comparison to biological neural activity</h4>
<p class="calibre3">As we’ve already discussed, a neuron receives inputs from sensory organs or from other neurons, and, depending on the resulting electrical potential, an action potential causes the neuron to fire (or not fire) a message to <span>other neurons.</span></p>
<p class="calibre3">Similarly, a perceptron (or artificial neuron) receives inputs from our dataset, or from other <a id="_idIndexMarker989" class="calibre6 pcalibre pcalibre1"/>artificial neurons if we are chaining the perceptrons together in an NN. Then, depending on the linear <a id="_idIndexMarker990" class="calibre6 pcalibre pcalibre1"/>combination of these inputs and their weights and biases, the activation function will influence the output of the perceptron, which can be used as an input to another perceptron in <span>the network.</span></p>
<p class="calibre3">Next, let’s dive into more detail on how NNs are typically structured, and introduce the important concept of <strong class="bold">layers</strong> <span>in NNs.</span></p>
<h4 class="calibre20">Layers in an NN</h4>
<p class="calibre3">When artificial <a id="_idIndexMarker991" class="calibre6 pcalibre pcalibre1"/>neurons are combined together to form an NN, they are not just connected randomly but instead are connected in a structured manner using the concept of layers, as depicted in <span><em class="italic">Figure 9</em></span><span><em class="italic">.3</em></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer135">
<img alt="Figure 9.3: NN layers" src="image/B18143_09_3.jpg" class="calibre134"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.3: NN layers</p>
<p class="calibre3">As shown in <span><em class="italic">Figure 9</em></span><em class="italic">.3</em>, the layers <a id="_idIndexMarker992" class="calibre6 pcalibre pcalibre1"/>of an NN are generally categorized into three <span>different types:</span></p>
<ol class="calibre7">
<li class="calibre8"><strong class="bold">The input layer</strong>, which, as the name suggests, is how our inputs enter our NN. It is, of course, the first layer in <span>the network.</span></li>
<li class="calibre8"><strong class="bold">Hidden layers</strong>, which sit between the input and output layers. Their job is to transform the inputs into something the output layer can use. The term “hidden” just means that they do not interface with the outside world (they are neither the input nor the output of the network). We usually do not have control over or direct interaction with them; they learn to represent the data on their own. The number of hidden layers and the number of neurons in each hidden layer define the complexity and structure of <span>the NN.</span></li>
<li class="calibre8"><strong class="bold">The output layer</strong>, which, again suggested by the name, presents the output of our NN, which is usually some kind <span>of prediction.</span></li>
</ol>
<p class="calibre3">In addition to the number of hidden layers and the number of neurons in each hidden layer, exactly how the layers are connected together depends on the architecture of the NN. We will discuss different types of common NN architectures later in this chapter, but what generally happens is that after our input data is fed into the NN’s input layer, each neuron in the subsequent layers of the network behaves similarly to how we described the perceptron earlier in <span>this chapter.</span></p>
<p class="calibre3">For example, each input is assigned a weight that represents its importance. These weights are typically initialized with random values and then refined during the learning process. The inputs are multiplied by their corresponding weights and the results are summed together, in addition to a bias value. The summed result is then used as the input to the activation function in a neuron in the subsequent layer (that is, beginning with the first hidden layer) of the NN. Generally, this process is performed by every neuron in the subsequent layers. The important thing to remember is that the weights and biases will <a id="_idIndexMarker993" class="calibre6 pcalibre pcalibre1"/>be different for each neuron. Therefore, even though the exact same input data is seen by each neuron in the first hidden layer, how each neuron reacts to the data will vary because the various weights and biases will influence each neuron’s activation <span>function differently.</span></p>
<p class="calibre3">The next thing to understand is that the outputs from the activation functions in each layer serve as inputs to the same process that will be performed again in subsequent layers of the network. So, the same process that we just described will be performed in each subsequent layer, but rather than our original dataset being used as an input in every layer, each subsequent layer will use the activation values from the previous layer as the input. This means that multiple transformations are being implemented as information travels through our network, and this is what makes NNs <span>so powerful.</span></p>
<p class="calibre3">Let’s just be sure we have a clear understanding of this process. If we take the second hidden layer as an example, the process works <span>as follows:</span></p>
<p class="calibre3">Each activation function output from the first layer is assigned a weight that represents its importance. These weights are typically initialized with random values and then refined during the learning process. The activation function outputs are multiplied by their corresponding weights and the results are summed together, in addition to the bias values. The summed result is then used as the input to the activation function in the neurons in the next layer of the NN. This process is repeated in each layer until we get to the final, output layer of <span>the network.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Different NN architectures can use slightly different ways of propagating information through the network. We will discuss some common types of NN architectures in more detail in this chapter, but what we’ve described so far can be considered the building blocks of how <span>ANNs work.</span></p>
<p class="callout">You may also hear the term “DNN” being used. Traditionally, any NN with at least two hidden layers is considered <span>a DNN.</span></p>
<p class="calibre3">The fact that activations in neurons in one layer of the network influence the activations of neurons in the next layer brings us back to the loose analogy with the human brain, in which certain neurons firing can cause other neurons to fire, resulting in varied combinations of <a id="_idIndexMarker994" class="calibre6 pcalibre pcalibre1"/>interactions that can produce much more complex higher-level functions. We must take this analogy with a pinch of salt, however, because even the most complex ANNs contain thousands of neurons, whereas the human brain has billions of neurons, and each neuron is capable of much more complex functionality than the relatively simple mathematical transformations performed by <span>artificial neurons.</span></p>
<p class="calibre3">Now that we’ve discussed how information travels through an ANN, let’s dive into more detail on how an ANN learns, and to do that, we must introduce the concept <span>of </span><span><strong class="bold">backpropagation</strong></span><span>.</span></p>
<h2 id="_idParaDest-187" class="calibre9"><a id="_idTextAnchor249" class="calibre6 pcalibre pcalibre1"/>Backpropagation</h2>
<p class="calibre3">What we described <a id="_idIndexMarker995" class="calibre6 pcalibre pcalibre1"/>in the previous section can be referred to as <strong class="bold">forward propagation</strong>, whereby information is being propagated forward from one layer to another <a id="_idIndexMarker996" class="calibre6 pcalibre pcalibre1"/>in our NN. In order to discuss backpropagation, let’s think back on what we learned earlier in this book with regard to how <strong class="bold">supervised ML</strong> (<strong class="bold">SML</strong>) algorithms work. Remember that we use labels to describe what <a id="_idIndexMarker997" class="calibre6 pcalibre pcalibre1"/>each data point is in our dataset. When we train a model, the model tries to learn patterns between the features in our dataset that will help it accurately predict the label for each data point. We then use a loss function to calculate how far off our model’s predictions were from the correct label; the primary purpose of the model training activity is to minimize the loss function (that is, to minimize the errors produced by our model), and we can use techniques such as gradient descent to minimize the <span>loss function.</span></p>
<p class="calibre3">Let’s take a basic linear regression model trained on tabular data as an example. You may remember that in such a case, each row in the table of our dataset represents a data point or observation, and each column in the table is a feature. The linear regression model tries to guess which coefficients it could use for each feature, such that multiplying each feature by its coefficient and adding all of the results together would result in something as close as possible to the <span>target label.</span></p>
<p class="calibre3">In the case of linear regression, each time the model predicted incorrectly, we would use the loss function to calculate the error, then calculate the gradients of the loss function with respect to each coefficient, and then use gradient descent to determine how to adjust the coefficients accordingly, and the process would repeat many times until the model improved or was stopped for <span>some reason.</span></p>
<p class="calibre3">This is where NNs <a id="_idIndexMarker998" class="calibre6 pcalibre pcalibre1"/>become more complex than the simple regression models we implemented earlier in this book. In the case of NNs, we don’t have a one-to-one mapping of input features to coefficients. Instead, our data propagates through a complex network consisting of multiple layers, which each contain multiple neurons, and each neuron in each layer has a different set of weights (and bias values). Therefore, when our model makes a prediction and we use a loss function to calculate the error, it’s no longer simply a case of calculating the loss function’s gradient with respect to the coefficient of each input feature and then updating each feature’s coefficient and trying again. Instead, we must perform that process for all of the weights in each layer of the NN. One way to do this is referred to as “backward propagation of errors” <span>or “backpropagation.”</span></p>
<p class="calibre3">With backpropagation, we update the weights in each layer, starting with the last layer (that is, the one closest to our output layer, which represents our model’s prediction), and then moving back through our network, layer <span>by layer.</span></p>
<p class="calibre3">Since the loss function for our NN is composed of several nested functions (due to the layers in the network), the calculation of gradients in the backpropagation step uses something <a id="_idIndexMarker999" class="calibre6 pcalibre pcalibre1"/>called the <strong class="bold">chain rule</strong>, which is a technique in calculus to compute the derivatives of the loss function with respect to the weights in each layer. These results are then used to determine how to update the weights in each pass through <span>the network.</span></p>
<p class="calibre3">We will come back to the topic of backpropagation and the chain rule later in this chapter, but first, let’s dive into more detail on what kinds of algorithms we can use to optimize our cost function in each <span>training pass.</span></p>
<h3 class="calibre11">Cost function optimization algorithms</h3>
<p class="calibre3">We’ve already discussed using mechanisms such as gradient descent for optimizing our cost function <a id="_idIndexMarker1000" class="calibre6 pcalibre pcalibre1"/>during model <a id="_idIndexMarker1001" class="calibre6 pcalibre pcalibre1"/>training. In this section, we will briefly discuss some other common types of optimization algorithms that we <span>can use.</span></p>
<h4 class="calibre20">Momentum</h4>
<p class="calibre3">This can be considered an upgrade to the basic gradient descent algorithm. When we discuss gradient <a id="_idIndexMarker1002" class="calibre6 pcalibre pcalibre1"/>descent in cost function optimization, we often use the analogy of walking downhill in a mountainous landscape until we reach the bottom of the mountain (or at least the bottom of a valley, which <a id="_idIndexMarker1003" class="calibre6 pcalibre pcalibre1"/>could be a “local minimum”). In the case of <strong class="bold">stochastic gradient descent</strong> (<strong class="bold">SGD</strong>), the analogy is more akin to jumping around somewhat randomly, in which case we may sometimes jump a little bit uphill (that is, in the incorrect direction), but overall, we usually end up going downhill (that is, in the correct direction). This case of jumping around in slightly different directions <a id="_idIndexMarker1004" class="calibre6 pcalibre pcalibre1"/>is referred to as <strong class="bold">oscillating</strong>. The Momentum algorithm accelerates SGD by navigating more prominently in the correct directions and reducing oscillations in incorrect directions. It does this by averaging the gradients of the updates in each step, which results in a smoother descent down the error gradient and often leads to reaching the bottom more quickly. The analogy used in this case is that of a ball rolling down the hill, in which case the movements are smoother than jumping around sporadically. Note that the ball can also gain momentum, which can help it to perform better even when the slope of the gradient is small (small gradient slopes result in slower learning for traditional gradient descent). In practice, Momentum almost always outperforms basic <span>gradient descent.</span></p>
<h4 class="calibre20">Adaptive Gradient Algorithm (Adagrad)</h4>
<p class="calibre3">Adagrad, as <a id="_idIndexMarker1005" class="calibre6 pcalibre pcalibre1"/>the name suggests, is an adaptive optimization algorithm. That is, in each optimization <a id="_idIndexMarker1006" class="calibre6 pcalibre pcalibre1"/>cycle, Adagrad adapts the learning rate to each individual parameter. It performs smaller updates for parameters that have large gradients and larger updates for parameters with small gradients, which makes it particularly useful for dealing with sparse data and DL models with millions of parameters. Although it can be a useful algorithm, it can cause the learning rate to get too small too quickly, and effectively stop learning. This can be a problem in long training <a id="_idIndexMarker1007" class="calibre6 pcalibre pcalibre1"/>scenarios (such as in DL) where the learning <a id="_idIndexMarker1008" class="calibre6 pcalibre pcalibre1"/>process could prematurely <a id="_idIndexMarker1009" class="calibre6 pcalibre pcalibre1"/>stop. More recent variants such as <strong class="bold">Root Mean Square Propagation</strong> (<strong class="bold">RMSProp</strong>) and <strong class="bold">Adaptive Moment Estimation</strong> (<strong class="bold">Adam</strong>) were developed to tackle this issue, and we will discuss <span>those next.</span></p>
<h4 class="calibre20">RMSProp</h4>
<p class="calibre3">RMSProp <a id="_idIndexMarker1010" class="calibre6 pcalibre pcalibre1"/>resolves Adagrad’s rapidly <a id="_idIndexMarker1011" class="calibre6 pcalibre pcalibre1"/>diminishing learning rates by <a id="_idIndexMarker1012" class="calibre6 pcalibre pcalibre1"/>dividing the learning rate over a <strong class="bold">moving average</strong> (<strong class="bold">MA</strong>) of the squared gradients. Basically, it’s faster and often better <span>than Adagrad.</span></p>
<h4 class="calibre20">Adam</h4>
<p class="calibre3">Adam combines the benefits of Momentum and RMSProp. It averages the gradients (like Momentum) and uses squared gradients (like RMSProp). It’s often the best choice of optimizer, especially <span>for DL.</span></p>
<p class="calibre3">There are <a id="_idIndexMarker1013" class="calibre6 pcalibre pcalibre1"/>many more optimization algorithms in addition to the ones we have covered in this section, and we may use other optimizers in later chapters, but we will use Adam in this <a id="_idIndexMarker1014" class="calibre6 pcalibre pcalibre1"/>chapter, so for now, we’re just introducing the popular algorithms that Adam <span>builds upon.</span></p>
<p class="calibre3">We will dive deeper into one more important concept before we begin our hands-on activities, and that is the concept of <span>activation functions.</span></p>
<h2 id="_idParaDest-188" class="calibre9"><a id="_idTextAnchor250" class="calibre6 pcalibre pcalibre1"/>Activation functions</h2>
<p class="calibre3">So far, we’ve touched <a id="_idIndexMarker1015" class="calibre6 pcalibre pcalibre1"/>upon the topic of activation functions and how they work at a high level. In this section, we dive into more details on this topic and discuss some common types of activation functions that we can use in <span>our NNs.</span></p>
<h3 class="calibre11">Linear (identity) activation function</h3>
<p class="calibre3">This activation function simply returns whatever input we provide to it, unchanged, and it’s typically <a id="_idIndexMarker1016" class="calibre6 pcalibre pcalibre1"/>used for simple tasks, or it’s often used as the output layer in regression <span>use cases.</span></p>
<p class="calibre3">It is represented mathematically as f(x) = <span>x.</span></p>
<p class="calibre3">This is generally <a id="_idIndexMarker1017" class="calibre6 pcalibre pcalibre1"/>not something we would use for the hidden layers in our network because it doesn’t allow for any kind of complex relationships to <span>be learned.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">It’s important to specifically call out the significance of non-linear transformations in NNs because the main power of NNs is their ability to combine multiple non-linear transformations in order to learn complex relationships in the data. Non-linear activation functions are, therefore, an important ingredient in <span>complex NNs.</span></p>
<p class="callout">Even if we combined many layers together in our network, if all of them just implemented a linear transformation, our whole network would just perform one big linear transformation, which we could implement without the need <span>for NNs.</span></p>
<h3 class="calibre11">Sigmoid activation function</h3>
<p class="calibre3">The sigmoid <a id="_idIndexMarker1018" class="calibre6 pcalibre pcalibre1"/>function is an implementation <a id="_idIndexMarker1019" class="calibre6 pcalibre pcalibre1"/>of logistic regression, which maps any input into a range between 0 <span>and 1.</span></p>
<p class="calibre3">It is represented mathematically as f(x) = 1 / (1 + <span>exp(-x)).</span></p>
<p class="calibre3">See <span><em class="italic">Figure 9</em></span><em class="italic">.4</em> for a visual representation of <span>this function:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer136">
<img alt="Figure 9.4: Sigmoid function (source: https://commons.wikimedia.org/wiki/File:Sigmoid-function-2.svg)" src="image/B18143_09_4.jpg" class="calibre135"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.4: Sigmoid function (source: https://commons.wikimedia.org/wiki/File:Sigmoid-function-2.svg)</p>
<p class="calibre3">The sigmoid function is one of the simpler activation functions, and it has generally been superseded <a id="_idIndexMarker1020" class="calibre6 pcalibre pcalibre1"/>by newer functions that we will discuss next. One of its <a id="_idIndexMarker1021" class="calibre6 pcalibre pcalibre1"/>limitations is that it is susceptible to a problem known as the vanishing gradient problem, which we will describe later in this chapter. However, it can still be useful in the context of output neurons in binary classification problems, where we interpret the output as the probability of the input being in one class or <span>the other.</span></p>
<h3 class="calibre11">Hyperbolic tangent (tanh) activation function</h3>
<p class="calibre3">The <a id="_idIndexMarker1022" class="calibre6 pcalibre pcalibre1"/>tanh function is <a id="_idIndexMarker1023" class="calibre6 pcalibre pcalibre1"/>like the sigmoid function but it maps any input to a value in the range between -1 <span>and 1.</span></p>
<p class="calibre3">It is represented mathematically as f(x) = (exp(x) - exp(-x)) / (exp(x) + <span>exp(-x)).</span></p>
<p class="calibre3">See <span><em class="italic">Figure 9</em></span><em class="italic">.5</em> for a visual representation of <span>this function:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer137">
<img alt="Figure 9.5: tanh function (source: https://commons.wikimedia.org/wiki/File:Mplwp_tanh.svg)" src="image/B18143_09_5.jpg" class="calibre136"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.5: tanh function (source: https://commons.wikimedia.org/wiki/File:Mplwp_tanh.svg)</p>
<p class="calibre3">Like the <a id="_idIndexMarker1024" class="calibre6 pcalibre pcalibre1"/>sigmoid function, tanh also suffers <a id="_idIndexMarker1025" class="calibre6 pcalibre pcalibre1"/>from the vanishing gradient problem, but it can still be useful <span>in practice.</span></p>
<h3 class="calibre11">Rectified Linear Unit (ReLU) activation function</h3>
<p class="calibre3">The ReLU function <a id="_idIndexMarker1026" class="calibre6 pcalibre pcalibre1"/>has become very <a id="_idIndexMarker1027" class="calibre6 pcalibre pcalibre1"/>popular in the last few years. Quite simply, it maps any positive number to itself and any negative number <span>to zero.</span></p>
<p class="calibre3">It is represented mathematically as f(x) = <span>max(0, x).</span></p>
<p class="calibre3">See <span><em class="italic">Figure 9</em></span><em class="italic">.6</em> for a visual representation of <span>this function:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer138">
<img alt="Figure 9.6: ReLU function" src="image/B18143_09_6.jpg" class="calibre137"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.6: ReLU function</p>
<p class="calibre3">A major benefit of ReLU is that it is computationally efficient because the function is essentially just checking whether the input is greater than zero and simply returning the input <a id="_idIndexMarker1028" class="calibre6 pcalibre pcalibre1"/>directly if it is greater than zero, or returning zero if it isn’t. This is an easy mathematical computation to perform, and this simplicity leads to much <span>faster training.</span></p>
<p class="calibre3">Another <a id="_idIndexMarker1029" class="calibre6 pcalibre pcalibre1"/>major benefit is that it doesn’t suffer from the vanishing gradient problem. However, it suffers from another problem known as the dying ReLU problem, which is a phenomenon where neurons effectively become useless due to consistently outputting zero. This happens because when the inputs are zero, or negative, then the gradient of the function becomes zero. This means that during backpropagation, when the weights get updated, the weights of that neuron will not be adjusted. This situation leads to the neuron becoming “stuck” and continually outputting zero – effectively causing the neuron to “die” and play no role in discriminating <span>the input.</span></p>
<h3 class="calibre11">Leaky ReLU activation function</h3>
<p class="calibre3">This <a id="_idIndexMarker1030" class="calibre6 pcalibre pcalibre1"/>function attempts to solve the dying ReLU problem by <a id="_idIndexMarker1031" class="calibre6 pcalibre pcalibre1"/>outputting small negative values when the input is less <span>than zero.</span></p>
<p class="calibre3">It is represented mathematically as f(x) = <span>max(0.01x, x).</span></p>
<p class="calibre3">In this case, the value of 0.01 represents a small, nonzero gradient for x, and it’s a hyperparameter that can <span>be changed.</span></p>
<p class="calibre3">See <span><em class="italic">Figure 9</em></span><em class="italic">.7</em> for a visual representation of <span>this function:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer139">
<img alt="Figure 9.7: Leaky ReLU" src="image/B18143_09_7.jpg" class="calibre138"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.7: Leaky ReLU</p>
<p class="calibre3">As we <a id="_idIndexMarker1032" class="calibre6 pcalibre pcalibre1"/>can see in <span><em class="italic">Figure 9</em></span><em class="italic">.7</em>, Leaky ReLU avoids the problem of the outputs becoming zero, even when the input is negative. There is <a id="_idIndexMarker1033" class="calibre6 pcalibre pcalibre1"/>also an extension of Leaky ReLU called <strong class="bold">Parametric ReLU</strong> (<strong class="bold">PReLU</strong>), which allows the small, nonzero gradient for x to be <a id="_idIndexMarker1034" class="calibre6 pcalibre pcalibre1"/>learned by backpropagation during learning, rather than specifying it as a static number via <span>a hyperparameter.</span></p>
<h3 class="calibre11">Softmax activation function</h3>
<p class="calibre3">The softmax function is often used for the output layer of an NN in multiclass classification <a id="_idIndexMarker1035" class="calibre6 pcalibre pcalibre1"/>use cases, where it transforms <a id="_idIndexMarker1036" class="calibre6 pcalibre pcalibre1"/>the raw outputs of the network into a vector of probabilities (that is, creating a probability distribution for <span>the classes).</span></p>
<p class="calibre3">It is represented mathematically as f(xi) = exp(xi) / Σ(exp(xj)), where j runs over the set of neurons in the <span>output layer.</span></p>
<p class="calibre3">It’s an extension of the sigmoid function; while the sigmoid function can be used to provide the probability that the input is a member of one class or another (in a selection between two classes), the softmax function can provide the range of probabilities of the input being a member of multiple classes. For example, if our network tries to identify images of numbers between 1 and 10, then there are 10 possible classes to choose from. If we provide an image of the number 1 and use softmax in the output layer of our network, it would hopefully determine that the number in the image has a high probability of being 1 and lower probabilities for each of the other potential classes (that is, 2 <span>through 10).</span></p>
<p class="calibre3">There are <a id="_idIndexMarker1037" class="calibre6 pcalibre pcalibre1"/>more activation functions in addition to the ones we <a id="_idIndexMarker1038" class="calibre6 pcalibre pcalibre1"/>have covered in this section, but the ones we’ve covered here are among the most well known and widely used. Our choice of activation function can depend on the specific use case and <span>other factors.</span></p>
<p class="calibre3">Now that we’ve covered many of the important theoretical concepts in the field of DL, let’s put what we’ve learned into practice by building our first NN. To do that, we’re going to introduce some <span>important libraries.</span></p>
<h1 id="_idParaDest-189" class="calibre5"><a id="_idTextAnchor251" class="calibre6 pcalibre pcalibre1"/>Libraries</h1>
<p class="calibre3">In this section, we describe <a id="_idIndexMarker1039" class="calibre6 pcalibre pcalibre1"/>the libraries we will use in this chapter, such as TensorFlow <span>and Keras.</span></p>
<h2 id="_idParaDest-190" class="calibre9"><a id="_idTextAnchor252" class="calibre6 pcalibre pcalibre1"/>TensorFlow</h2>
<p class="calibre3">TensorFlow <a id="_idIndexMarker1040" class="calibre6 pcalibre pcalibre1"/>is an <strong class="bold">open source software</strong> (<strong class="bold">OSS</strong>) library developed by the Google Brain team for ML and DNN research. However, it is also possible <a id="_idIndexMarker1041" class="calibre6 pcalibre pcalibre1"/>to run it on a wide range of systems, from mobile <a id="_idIndexMarker1042" class="calibre6 pcalibre pcalibre1"/>devices to multi-GPU setups, and it can have many applications beyond just ML. In this section, we will discuss some of its important aspects, such as <span>the following:</span></p>
<ul class="calibre16">
<li class="calibre8">Tensors, which are a generalization of vectors and matrices in multiple dimensions (we can think of them as multi-dimensional arrays or lists). They are the basic building blocks <span>in TensorFlow.</span></li>
<li class="calibre8"><strong class="bold">Data-flow graphs</strong> (<strong class="bold">DFGs</strong>), in which <a id="_idIndexMarker1043" class="calibre6 pcalibre pcalibre1"/>nodes in the graph represent mathematical operations and edges represent the data (tensors) transmitted between these nodes. This approach enables parallel computation across multiple devices, making TensorFlow suitable for training <span>large NNs.</span></li>
<li class="calibre8">Multiple options for model deployment, such as TensorFlow Serving for server-side deployments or TensorFlow Lite for mobile and <span>IoT devices.</span></li>
<li class="calibre8">Backpropagation <a id="_idIndexMarker1044" class="calibre6 pcalibre pcalibre1"/>optimization by automatically computing <a id="_idIndexMarker1045" class="calibre6 pcalibre pcalibre1"/>the gradient of the loss with respect to the <span>model weights.</span></li>
</ul>
<p class="calibre3">Anyone interested in ML and DL should be familiar with TensorFlow because it is widely used in <span>the industry.</span></p>
<h2 id="_idParaDest-191" class="calibre9"><a id="_idTextAnchor253" class="calibre6 pcalibre pcalibre1"/>Keras</h2>
<p class="calibre3">Keras is a high-level <a id="_idIndexMarker1046" class="calibre6 pcalibre pcalibre1"/>NN API written in Python that can run on top of lower-level frameworks <a id="_idIndexMarker1047" class="calibre6 pcalibre pcalibre1"/>such as TensorFlow, Theano, and <strong class="bold">Cognitive Toolkit</strong> (<strong class="bold">CNTK</strong>). It was <a id="_idIndexMarker1048" class="calibre6 pcalibre pcalibre1"/>developed to enable fast experimentation and has become the official high-level API of TensorFlow (as of TensorFlow 2.0). Some of its main features include <span>the following:</span></p>
<ul class="calibre16">
<li class="calibre8"><strong class="bold">User-friendliness</strong>: It has <a id="_idIndexMarker1049" class="calibre6 pcalibre pcalibre1"/>a simple and consistent interface that has been optimized for common use cases, and it provides clear error messages, as well as useful documentation and <span>developer guides.</span></li>
<li class="calibre8"><strong class="bold">Modularity</strong>: A Keras model <a id="_idIndexMarker1050" class="calibre6 pcalibre pcalibre1"/>is assembled by connecting configurable building blocks together. For example, we can easily construct an NN by stacking multiple <span>layers together.</span></li>
<li class="calibre8"><strong class="bold">Extensibility</strong>: We can <a id="_idIndexMarker1051" class="calibre6 pcalibre pcalibre1"/>write custom building blocks to express new ideas for research, and create new layers, loss functions, <span>and models.</span></li>
</ul>
<p class="calibre3">The core data structure of Keras is a model, which is a way to organize layers. The main type of model is the Sequential model, which is a linear stack of layers, but for more complex architectures, we can use the Keras functional API, which allows us to build our own custom graphs of layers. A layer in Keras is a class that implements common NN operations, and Keras includes a wide range of pre-defined layers that we can use to build our models. It also allows us to specify the loss function and the metrics we want to evaluate <a id="_idIndexMarker1052" class="calibre6 pcalibre pcalibre1"/>during the training phase, and it provides many pre-defined loss functions <a id="_idIndexMarker1053" class="calibre6 pcalibre pcalibre1"/>such as <strong class="source-inline">mean_squared_error</strong> and metrics such as <strong class="source-inline">accuracy</strong>. Keras also includes many optimization algorithms, such as SGD. Overall, it includes lots of useful tools that make it easy for us to <span>create NNs.</span></p>
<p class="calibre3">Now that we’ve introduced the relevant libraries, let’s dive in and build our <span>first NN!</span></p>
<h1 id="_idParaDest-192" class="calibre5"><a id="_idTextAnchor254" class="calibre6 pcalibre pcalibre1"/>Implementing an MLP in TensorFlow</h1>
<p class="calibre3">In this <a id="_idIndexMarker1054" class="calibre6 pcalibre pcalibre1"/>section, we will build an <a id="_idIndexMarker1055" class="calibre6 pcalibre pcalibre1"/>MLP using TensorFlow. We will use Keras as the high-level API for interacting with TensorFlow. We can use the same Vertex AI Workbench notebook we created in <a href="B18143_05.xhtml#_idTextAnchor168" class="calibre6 pcalibre pcalibre1"><span><em class="italic">Chapter </em></span><span><em class="italic">5</em></span></a> for this purpose. In that notebook, perform the <span>following steps:</span></p>
<ol class="calibre7">
<li class="calibre8">Navigate into the folder <span>named </span><span><strong class="source-inline">Google-Machine-Learning-for-Solutions-Architects</strong></span><span>.</span></li>
<li class="calibre8">Double-click on the <strong class="source-inline">Chapter-09</strong> folder within it and then double-click on the <strong class="source-inline">Chapter-9-TF-Keras.ipynb</strong> file to <span>open it.</span></li>
<li class="calibre8">When prompted to select a kernel, <span>select </span><span><strong class="bold">TensorFlow</strong></span><span>.</span></li>
<li class="calibre8">The notebook we have opened contains some Python code that creates and tests an MLP using Keras <span>and TensorFlow.</span></li>
<li class="calibre8">Run each of the cells in the notebook by clicking on each cell and pressing <em class="italic">Shift </em>+ <em class="italic">Enter</em> on your keyboard. If you see any errors related to CUDA, you can ignore them because we are not using GPUs in <span>this notebook.</span></li>
</ol>
<p class="calibre3">Our code in the first cell of the notebook imports the necessary libraries and modules, loads a dataset using the <strong class="source-inline">make_moons</strong> function from <strong class="source-inline">sklearn.datasets</strong>, and then visualizes the data <span>using </span><span><strong class="source-inline">matplotlib</strong></span><span>.</span></p>
<p class="calibre3">In this case, we’re using the <strong class="source-inline">moons</strong> dataset, which is a mathematically generated dataset for binary classification that is often used as a simple test case for ML algorithms, especially those designed to handle non-linear data (such as NNs). The dataset consists of a two-dimensional array of two features (usually visualized on an X-Y plane) and a binary label (0 or 1) for each sample, and the samples are generated in such a way that they form two crescent moon-like shapes when plotted (hence the name “moons”), with<a id="_idIndexMarker1056" class="calibre6 pcalibre pcalibre1"/> each “moon” corresponding<a id="_idIndexMarker1057" class="calibre6 pcalibre pcalibre1"/> to one class. See <span><em class="italic">Figure 9</em></span><em class="italic">.</em><em class="italic">8</em> <span>for reference:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer140">
<img alt="Figure 9.8: The moons dataset" src="image/B18143_09_9.jpg" class="calibre139"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.8: The moons dataset</p>
<p class="calibre3">Note that the main characteristic of the dataset is its non-linearity (that is, the decision boundary separating the two classes is not a <span>straight line).</span></p>
<p class="calibre3">The code in the second cell of our Jupyter notebook then does <span>the following:</span></p>
<ul class="calibre16">
<li class="calibre8">Splits the dataset into a training set and a <span>test set</span></li>
<li class="calibre8">Defines a Sequential model (which means that the layers are stacked on top of <span>each other)</span></li>
<li class="calibre8">Adds an input layer and the first hidden layer with 32 neurons and the <strong class="source-inline">relu</strong> <span>activation function</span></li>
<li class="calibre8">Adds a second hidden layer with 32 neurons and the <strong class="source-inline">relu</strong> <span>activation function</span></li>
<li class="calibre8">Adds an output layer with one neuron (for binary classification) and the <strong class="source-inline">sigmoid</strong> <span>activation function</span></li>
<li class="calibre8">Compiles the model with the <strong class="source-inline">adam</strong> optimizer and the <strong class="source-inline">binary_crossentropy</strong> loss function (suitable for <span>binary classification)</span></li>
<li class="calibre8">Trains <a id="_idIndexMarker1058" class="calibre6 pcalibre pcalibre1"/>the model <a id="_idIndexMarker1059" class="calibre6 pcalibre pcalibre1"/>for <span>50 epochs</span></li>
</ul>
<p class="calibre3">When the code is running, you should see outputs from each epoch, as depicted in <span><em class="italic">Figure 9</em></span><span><em class="italic">.10</em></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer141">
<img alt="Figure 9.9: Training epoch outputs" src="image/B18143_09_10.jpg" class="calibre140"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.9: Training epoch outputs</p>
<p class="calibre3">Note that <strong class="source-inline">loss</strong> and <strong class="source-inline">val_loss</strong> (validation loss) should decrease as the training progresses, and <strong class="source-inline">accuracy</strong> and <strong class="source-inline">val_accuracy</strong> (validation accuracy) should increase as the <span>training progresses.</span></p>
<p class="calibre3">Next, our code in the third cell does <span>the following:</span></p>
<ul class="calibre16">
<li class="calibre8">Evaluates our model using the <strong class="source-inline">model.evaluate</strong> method, which returns the loss value and metric values (in this case, <strong class="source-inline">accuracy</strong>) for the model, in <span>test mode.</span></li>
<li class="calibre8">Gets some predictions from our model using the <strong class="source-inline">model.predict</strong> method, which outputs the probabilities that each input sample belongs to the <span>positive class.</span></li>
<li class="calibre8">In order to treat this as a binary classification use case, our code then converts these probabilities into binary class labels based on a threshold of 0.5 (that is, anything with a probability of more than 0.5 is deemed to be a member of the <span>positive class).</span></li>
<li class="calibre8">Finally, we print out the first 10 predictions for a quick check. These outputs will be in the form of 0s and 1s, denoting the predicted <span>class labels.</span></li>
</ul>
<p class="calibre3">That’s it! You’ve just created an NN! It might not be quite as smart as a human, but this is a basic example of an MLP in TensorFlow with Keras. We could extend this to more advanced DL use cases by adjusting things such as the number of layers, neurons, types of activation functions, types of optimizers, loss functions, and training configurations (such as the number of epochs, batch size, and so on). <span>Great job!</span></p>
<p class="calibre3">Next, we will dive into <a id="_idIndexMarker1060" class="calibre6 pcalibre pcalibre1"/>additional DL <a id="_idIndexMarker1061" class="calibre6 pcalibre pcalibre1"/>concepts, such as different types of NN architectures, challenges in applications of DNN, and <span>optimization considerations.</span></p>
<h1 id="_idParaDest-193" class="calibre5"><a id="_idTextAnchor255" class="calibre6 pcalibre pcalibre1"/>NN architectures, challenges, and optimization</h1>
<p class="calibre3">We’ve primarily covered the basics of NNs so far in this chapter, and in this section, we will expand our discussion to include different types of NN architectures that can be used for different types of real-world use cases, as well as some challenges that are often encountered when training them. Finally, we will discuss how to optimize our NNs to address <span>those challenges.</span></p>
<h2 id="_idParaDest-194" class="calibre9"><a id="_idTextAnchor256" class="calibre6 pcalibre pcalibre1"/>Common NN architectures</h2>
<p class="calibre3">The “architecture” of an NN refers to its structure in terms of the number of layers it contains and the <a id="_idIndexMarker1062" class="calibre6 pcalibre pcalibre1"/>number of neurons in each layer, as well as any special characteristics that influence how information is propagated through the network. The NN architectures we’ve described so far in this chapter are the simplest forms of ANNs, which <a id="_idIndexMarker1063" class="calibre6 pcalibre pcalibre1"/>are referred to as <strong class="bold">feed-forward NNs</strong> (<strong class="bold">FFNNs</strong>). Information in these networks travels in one direction only, from the input layer, through the hidden layers, to the output layer. Next, let’s take a look at some other commonly used NN architectures. We will introduce them at a high level here, and we will dive into much more detail in <span>later chapters.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">When we talk about information traveling through the network in this section, we are not referring to the backpropagation step, because that is a separate step implemented during the iterative learning process. We are simply referring to how data is processed through our network in each training pass, or at <span>inference time.</span></p>
<h3 class="calibre11">Convolutional NNs (CNNs)</h3>
<p class="calibre3">CNNs are <a id="_idIndexMarker1064" class="calibre6 pcalibre pcalibre1"/>commonly used in <strong class="bold">computer vision</strong> (<strong class="bold">CV</strong>) for use cases such as object recognition and picture categorization. Consider the scenario where we <a id="_idIndexMarker1065" class="calibre6 pcalibre pcalibre1"/>wish to teach our model to recognize images <a id="_idIndexMarker1066" class="calibre6 pcalibre pcalibre1"/>of cats, keeping in mind that these images might take many different forms, such as being captured at various distances and perspectives. Our model would need to establish a kind of visual understanding of what a cat is, such as the shape of its face, ears, body, and tail, in order to correctly identify cats in <span>the images.</span></p>
<p class="calibre3">CNNs do this by breaking pictures down into smaller components or “features” and learning each one separately. In this way, the network learns to detect small details in a larger image, such as an edge or a curve, and then combines those into larger features such as <a id="_idIndexMarker1067" class="calibre6 pcalibre pcalibre1"/>a single whisker or a portion of a cat’s ear, regardless <a id="_idIndexMarker1068" class="calibre6 pcalibre pcalibre1"/>of where they appear in the image, and <a id="_idIndexMarker1069" class="calibre6 pcalibre pcalibre1"/>then combining those characteristics to identify a cat. The <a id="_idIndexMarker1070" class="calibre6 pcalibre pcalibre1"/>concepts of <strong class="bold">convolutional layers</strong>, <strong class="bold">pooling layers</strong>, and <strong class="bold">fully connected (FC) layers</strong> are used by CNNs to do this. In later chapters of this book, we <a id="_idIndexMarker1071" class="calibre6 pcalibre pcalibre1"/>will dive further into those ideas and how <span>they function.</span></p>
<h3 class="calibre11">Recurrent NNs (RNNs) and long short-term memory (LSTM) networks</h3>
<p class="calibre3">RNNs are designed to find patterns in sequential data such as language or time series. In RNNs, the network <a id="_idIndexMarker1072" class="calibre6 pcalibre pcalibre1"/>contains loops, which enable information to be persisted from one step to the next, and this is what allows RNNs to create a kind <a id="_idIndexMarker1073" class="calibre6 pcalibre pcalibre1"/>of memory, unlike basic NNs that <a id="_idIndexMarker1074" class="calibre6 pcalibre pcalibre1"/>assume all inputs (and outputs) are independent of each other. In this way, the network blends current data <a id="_idIndexMarker1075" class="calibre6 pcalibre pcalibre1"/>with inputs from earlier phases in each step, which is important for activities such as language comprehension, in which the model needs to understand each word in relation to the other words in the input (that is, the words are not <span>entirely independent).</span></p>
<p class="calibre3">However, one of the problems with RNNs is that, for reasons we’ll cover later, they “forget” prior inputs when dealing with long sequences. To address these issues, variations such <a id="_idIndexMarker1076" class="calibre6 pcalibre pcalibre1"/>as LSTM networks and <strong class="bold">gated recurrent unit</strong> (<strong class="bold">GRU</strong>) networks have been invented, which use gates and other techniques to <span>maintain memory.</span></p>
<h3 class="calibre11">Autoencoders (AEs)</h3>
<p class="calibre3">AEs are used <a id="_idIndexMarker1077" class="calibre6 pcalibre pcalibre1"/>to learn efficient encodings of unlabeled data, usually to <a id="_idIndexMarker1078" class="calibre6 pcalibre pcalibre1"/>reduce the dimensionality of the data. An AE’s basic idea is pretty straightforward: it is trained to try to duplicate its input to its output. Although it might seem like a simple (and redundant) operation, the restrictions we place on the network force it to discover interesting aspects of the data. Most commonly, we limit the number of nodes in the hidden layers, forcing the network to learn a compressed view of <span>the data.</span></p>
<p class="calibre3">AEs consist of an encoder, which encodes the input data as a compressed representation in a reduced-dimensional space, and a decoder, which attempts to reconstruct the <a id="_idIndexMarker1079" class="calibre6 pcalibre pcalibre1"/>input from the reduced-dimensional <a id="_idIndexMarker1080" class="calibre6 pcalibre pcalibre1"/>representation (that is, it “decodes” the compressed representation). The goal during training is to create a reconstructed output that is as close as possible to the input so that the network can learn to rebuild the input from the <span>compressed representation.</span></p>
<p class="calibre3">In the real world, AEs are used for applications such as anomaly detection and recommendation <a id="_idIndexMarker1081" class="calibre6 pcalibre pcalibre1"/>systems. One particularly popular application of AEs is in <strong class="bold">generative AI</strong> (<strong class="bold">GenAI</strong>) models. In this case, after the AE has been trained, the decoder can generate new data that mimics the <span>training data.</span></p>
<h3 class="calibre11">Generative adversarial networks (GANs)</h3>
<p class="calibre3">The basic objective of GANs, which are made up of two competing NNs called a generator <a id="_idIndexMarker1082" class="calibre6 pcalibre pcalibre1"/>and a discriminator, is to create new fake data that closely matches “real” data (as determined by the training data). The two <a id="_idIndexMarker1083" class="calibre6 pcalibre pcalibre1"/>networks are trained in tandem using a <strong class="bold">minimax</strong> game, which is a type of game where the generator tries to trick the discriminator, and the discriminator tries to reliably distinguish real data from the generated data. During training, the generator becomes ever more accurate at providing data that appears real, while the discriminator becomes increasingly skillful at <span>identifying forgeries.</span></p>
<h3 class="calibre11">Transformer networks</h3>
<p class="calibre3">Transformer networks are <a id="_idIndexMarker1084" class="calibre6 pcalibre pcalibre1"/>a type of model architecture invented by <a id="_idIndexMarker1085" class="calibre6 pcalibre pcalibre1"/>Google, in which the breakthrough innovation is the use of <strong class="bold">self-attention</strong> mechanisms, or <strong class="bold">multi-head attention</strong>, which enables the model to consider the <a id="_idIndexMarker1086" class="calibre6 pcalibre pcalibre1"/>relative significance of various words in a phrase while generating an output. For example, in a sentence such as “the dog tried to jump over the pond, but it was too wide,” the word “it” could refer to either the pond or the dog. To humans, it seems pretty obvious that it refers to the pond, but that’s because we’re using contextual awareness to intuit what makes the most sense. However, this is not inherently obvious to an ML model, and self-attention is the mechanism that allows the model to get a better understanding of the contextual meaning of each word in the sentence. The Transformer architecture also includes the concept of an encoder and a decoder, which are both made up of a stack of identical layers. And, because the self-attention mechanism alone does not account for the location of <a id="_idIndexMarker1087" class="calibre6 pcalibre pcalibre1"/>words in the input sequence, the Transformer design additionally contains a <strong class="bold">positional encoding</strong> system to track the positions of the words. We will dive into all of these components in much greater detail in a <span>later chapter.</span></p>
<p class="calibre3">Another advantage provided by Transformer models is that they handle all inputs in parallel, as opposed to sequence-based models such as RNNs or LSTM networks, and this can <a id="_idIndexMarker1088" class="calibre6 pcalibre pcalibre1"/>significantly speed up training <span>and inference.</span></p>
<p class="calibre3">Transformers <a id="_idIndexMarker1089" class="calibre6 pcalibre pcalibre1"/>have proven to be very useful for <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) tasks including <strong class="bold">sentiment analysis</strong> (<strong class="bold">SA</strong>), text summarization, and <a id="_idIndexMarker1090" class="calibre6 pcalibre pcalibre1"/>machine translation, and the Transformer <a id="_idIndexMarker1091" class="calibre6 pcalibre pcalibre1"/>architecture serves as the foundation for models such as <strong class="bold">Generative Pre-trained Transformer</strong> (<strong class="bold">GPT</strong>), <strong class="bold">Bidirectional Encoder Representations from Transformers</strong> (<strong class="bold">BERT</strong>), and T5. If you’re <a id="_idIndexMarker1092" class="calibre6 pcalibre pcalibre1"/>interested in learning more about this ground-breaking technology, I recommend reading the pivotal research paper that first introduced the concept of Transformers (Vaswani, A. et al., 2017), which can be found at the following <span>URL: </span><a href="https://arxiv.org/abs/1706.03762" class="calibre6 pcalibre pcalibre1"><span>https://arxiv.org/abs/1706.03762</span></a><span>.</span></p>
<p class="calibre3">There are more types of NN architectures in addition to the ones we have covered in this section, but the ones we’ve covered here are among the most well known and widely used. Researchers are constantly creating and experimenting with new NN configurations, and the choice of network configuration relies on the issue we’re seeking to resolve because each network type has advantages <span>and disadvantages.</span></p>
<p class="calibre3">Next, let’s discuss some common challenges that people run into when training and <span>using NNs.</span></p>
<h2 id="_idParaDest-195" class="calibre9"><a id="_idTextAnchor257" class="calibre6 pcalibre pcalibre1"/>Common NN challenges</h2>
<p class="calibre3">In addition <a id="_idIndexMarker1093" class="calibre6 pcalibre pcalibre1"/>to all of the challenges we covered in earlier chapters with regard to traditional ML implementations, DNNs introduce their own set of challenges, such as interpretability, cost, and vanishing or <span>exploding gradients.</span></p>
<h3 class="calibre11">Interpretability</h3>
<p class="calibre3">Interpretability refers to how easily we can understand the inner workings of our models, and the <a id="_idIndexMarker1094" class="calibre6 pcalibre pcalibre1"/>reasons behind the decisions they produce. Models such as linear regression are generally quite easy to understand and explain because their outputs are just a straightforward mathematical transformation of whatever input is provided to <span>the model.</span></p>
<p class="calibre3">However, DNNs can be extremely complex, with thousands of neurons and billions of parameters that influence their outputs. Also, their outputs are usually not just linear transformations of their inputs but instead are non-linear <span>in nature.</span></p>
<p class="calibre3">In a later chapter, we will discuss the importance of interpretability in much more detail and will introduce mechanisms that can help us to better understand how our <span>models work.</span></p>
<h3 class="calibre11">Cost</h3>
<p class="calibre3">DNNs can <a id="_idIndexMarker1095" class="calibre6 pcalibre pcalibre1"/>require a lot of computing resources to train and host, which can result in monetary expenses. If we consider the example of highly complex models with billions of parameters, those models can take weeks or even months to train, using large numbers of very powerful servers with the latest generation of cutting-edge GPUs. Those kinds of resources are not cheap, so we need to ensure that our models are optimized to use computing resources as efficiently <span>as possible.</span></p>
<h3 class="calibre11">Vanishing gradient problem</h3>
<p class="calibre3">We briefly touched on this topic in earlier sections of this chapter, so let’s take a look at this concept <a id="_idIndexMarker1096" class="calibre6 pcalibre pcalibre1"/>in more detail. The vanishing gradient problem develops when the gradients of the loss function are so tiny that they essentially vanish, leading to sluggish weight updates in the network’s first layers. Remember that backpropagation uses the chain rule of differentiation, which involves multiplying a sequence of derivatives (or gradients). This means that if the values of the derivatives are less than 1, we are essentially dividing them in an exponential manner into smaller and smaller values as we propagate back through the network. Because of this, early layers learn much more slowly than <span>later layers.</span></p>
<p class="calibre3">When utilizing activation functions such as the sigmoid or tanh functions, which condense their input into a small range, this problem becomes more prominent. The sigmoid function, for example, compresses input values into a range between zero and one, which means that even when the inputs are large in size (either positive or negative), the output of the sigmoid function is between zero and one, and the result is that the gradients <a id="_idIndexMarker1097" class="calibre6 pcalibre pcalibre1"/>reduce to tiny values, causing backpropagation-based learning to slow <span>down significantly.</span></p>
<h3 class="calibre11">Exploding gradient problem</h3>
<p class="calibre3">On the other hand, the exploding gradient problem happens when the gradient becomes <a id="_idIndexMarker1098" class="calibre6 pcalibre pcalibre1"/>too large, causing the weights in the network to be updated by excessive increments. This can result in the network’s performance oscillating wildly, causing the model training process <span>to fail.</span></p>
<p class="calibre3">The exploding gradient problem is more common in RNNs, especially with long sequences, but it can occur in any type <span>of network.</span></p>
<h3 class="calibre11">Optimizations to help prevent vanishing or exploding gradients</h3>
<p class="calibre3">Now that <a id="_idIndexMarker1099" class="calibre6 pcalibre pcalibre1"/>we have a better understanding of how vanishing and exploding gradient issues take place, the following considerations can help reduce their likelihood <span>of occurring.</span></p>
<h4 class="calibre20">Weight initialization</h4>
<p class="calibre3">Effective weight <a id="_idIndexMarker1100" class="calibre6 pcalibre pcalibre1"/>initialization can help mitigate <a id="_idIndexMarker1101" class="calibre6 pcalibre pcalibre1"/>problems of vanishing and exploding gradients. For example, techniques such as Xavier (Glorot) initialization and He initialization can help set the initial weights to values that prevent the gradients from becoming too small or too large early <span>in training.</span></p>
<h4 class="calibre20">Choice of activation functions</h4>
<p class="calibre3">As we <a id="_idIndexMarker1102" class="calibre6 pcalibre pcalibre1"/>discussed, using activation functions that squash their inputs, such as sigmoid or tanh, can increase the likelihood of encountering vanishing and exploding gradient issues. Therefore, it’s best to avoid those activation functions in cases that are prone to those issues. We can instead use activation functions such as Leaky ReLU or PReLU, as these functions do not squash <span>their inputs.</span></p>
<h4 class="calibre20">Batch normalization</h4>
<p class="calibre3">Using this <a id="_idIndexMarker1103" class="calibre6 pcalibre pcalibre1"/>technique, we can normalize the output of a layer to stabilize the means and variances of each layer’s inputs. This helps control the scale of gradients, mitigating both vanishing and exploding <span>gradient problems.</span></p>
<h4 class="calibre20">Gradient clipping</h4>
<p class="calibre3">This technique <a id="_idIndexMarker1104" class="calibre6 pcalibre pcalibre1"/>puts a pre-defined limit or threshold on the gradients to prevent them from getting too large, which is especially useful for tackling the exploding <span>gradient problem.</span></p>
<h4 class="calibre20">Architectural methods</h4>
<p class="calibre3">When we discussed RNNs earlier in this section, we mentioned that they “forget” prior inputs when <a id="_idIndexMarker1105" class="calibre6 pcalibre pcalibre1"/>dealing with long sequences. The vanishing gradient problem is one factor that causes this to happen, and this is one of the reasons why certain architectures such as LSTM and GRU were designed to address these issues in the context of RNNs by using a form of gating in their structure. Therefore, sometimes the choice of NN architecture can reduce the likelihood of encountering vanishing and exploding <span>gradient problems.</span></p>
<p class="calibre3">These problems and their solutions are major factors in understanding how DL models work and how to effectively <span>train DNNs.</span></p>
<p class="calibre3">We’ve covered a lot of new concepts and terminology in this chapter. Let’s take a moment to summarize everything <span>we’ve learned.</span></p>
<h1 id="_idParaDest-196" class="calibre5"><a id="_idTextAnchor258" class="calibre6 pcalibre pcalibre1"/>Summary</h1>
<p class="calibre3">In this chapter, we started by exploring the comparison between artificial neurons (in the form of the perceptron) and biological neurons in the human brain. We then extended this idea to describe the activity of multiple neurons in an NN, both in terms of combining multiple perceptrons together and in terms of how the tiny neurons in our brain work together to produce extremely complex <span>higher-level functions.</span></p>
<p class="calibre3">We then dived deeper into the inner workings and components of ANNs, including concepts such as activation functions and backpropagation. We discussed many different types of activation functions, including how they work and what use cases are most appropriate <span>for them.</span></p>
<p class="calibre3">In the context of backpropagation, we learned about various types of commonly used cost function optimization algorithms, such as Momentum and Adam, and then we introduced two very important libraries for DL: TensorFlow <span>and Keras.</span></p>
<p class="calibre3">Next, we built our first NN using those libraries, and we tested that network by successfully getting predictions based on the <strong class="source-inline">moons</strong> dataset, which we also explored in <span>some detail.</span></p>
<p class="calibre3">After building our first simple NN, we expanded our discussion to cover more advanced kinds of NN architectures and their use cases, and we explored common challenges that people often run into when training and using NNs, as well as some approaches we can use to optimize our networks in order to reduce the likelihood of running into <span>those issues.</span></p>
<p class="calibre3">These are some of the more advanced concepts in ML, so if you have understood the content we’ve covered in this chapter, then you have built an important foundation for the deeper dives we will perform on these concepts in <span>later chapters.</span></p>
<p class="calibre3">In the next chapter, let’s explore how we can bring trained models into production to host them for serving real-world <span>use cases.</span></p>
</div>
</div></body></html>