- en: '*Chapter 8*: Putting It All Together'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第八章*：整合一切'
- en: In this chapter, we will revisit the *Lending Club Loan Application* data that
    we first introduced in [*Chapter 3*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042),
    *Fundamental Workflow – Data to Deployable Model*. This time, we begin the way
    most data science projects do, that is, with a raw data file and a general objective
    or question. Along the way, we will refine both the data and the problem statements
    so that they are relevant to the business and can be answered by the available
    data. Data scientists rarely begin with modeling-ready data; therefore, the treatment
    in this chapter more accurately reflects the job of a data scientist in the enterprise.
    We will then model the data and evaluate various candidate models, updating them
    as required, until we arrive at a final model. We will evaluate the final model
    and illustrate the preparation steps required for model deployment. This reinforces
    what we introduced in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)
    through [*Chapter 7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将回顾我们在[*第三章*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042)和*基本工作流程
    – 数据到可部署模型*中首次介绍的*Lending Club贷款申请*数据。这次，我们以大多数数据科学项目的方式开始，即从一个原始数据文件和一个一般目标或问题开始。在这个过程中，我们将细化数据和问题陈述，使其与业务相关，并且可以用可用数据回答。数据科学家很少从建模准备好的数据开始；因此，本章的处理更准确地反映了企业中数据科学家的工作。然后我们将对数据进行建模，评估各种候选模型，并根据需要更新它们，直到我们得到一个最终模型。我们将评估最终模型并说明模型部署所需的准备步骤。这加强了我们从[*第五章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)到[*第七章*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127)中介绍的内容。
- en: By the end of this chapter, you will be able to take an unstructured problem
    with a raw data source and create a deployable model to answer a refined predictive
    question. For completeness, we will include all the code required to do each step
    of data preparation, feature engineering, model building, and evaluation. In general,
    any code that has already been covered in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)
    through [*Chapter 7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127) will be
    left uncommented.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将能够处理一个具有原始数据源的未结构化问题，并创建一个可部署的模型来回答一个精细的预测问题。为了完整性，我们将包括完成每个步骤（数据准备、特征工程、模型构建和评估）所需的全部代码。一般来说，任何在[*第五章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)到[*第七章*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127)中已经介绍过的代码都将保留注释。
- en: 'This chapter is divided into four sections, each of which has individual steps.
    The sections are listed as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章分为四个部分，每个部分都有单独的步骤。部分列表如下：
- en: Data wrangling
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据整理
- en: Feature engineering
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程
- en: Model building and evaluation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型构建和评估
- en: Preparation for model pipeline deployment
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型管道部署准备
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: If you still have not set up your H2O environment at this stage, to do so, please
    see [*Appendix*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268) *– Alternative*
    *Methods to Launch H2O Clusters*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在此阶段尚未设置您的H2O环境，请参阅[*附录*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268)
    *– 启动H2O集群的替代方法*。
- en: Data wrangling
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据整理
- en: It is frequently said that 80–90% of a data scientist's job is dealing with
    data. At a minimum, you should understand the data granularity (that is, what
    the rows represent) and know what each column in the dataset means. Presented
    with a raw data source, there are multiple steps required to clean, organize,
    and transform your data into a modeling-ready dataset format.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 经常有人说，数据科学家的工作中有80-90%是处理数据。至少，您应该了解数据的粒度（即行代表什么）以及了解数据集中每一列的含义。面对原始数据源时，需要多个步骤来清理、组织和转换您的数据，使其成为建模准备好的数据集格式。
- en: 'The dataset used for the *Lending Club* example in *Chapters 3*, *5*, and *7*
    was derived from a raw data file that we begin with here. In this section, we
    will illustrate the following steps:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第三章*、*第五章*和*第七章*中使用的*Lending Club*示例数据集是从我们在这里开始的原始数据文件中派生出来的。在本节中，我们将说明以下步骤：
- en: Import the raw data and determine which columns to keep.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入原始数据并确定要保留的列。
- en: Define the problem, and create a response variable.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义问题，并创建响应变量。
- en: Convert the implied numeric data from strings into numeric values.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将字符串中的隐含数值数据转换为数值。
- en: Clean up any messy categorical columns.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理任何混乱的分类列。
- en: 'Let''s begin with the first step: importing the data.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一步开始：导入数据。
- en: Importing the raw data
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入原始数据
- en: 'We import the raw data file using the following code:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下代码导入原始数据文件：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'A dictionary in the `h2o.import_file` code specifies the input column type
    of `string` for four of the input variables: `int_rate`, `revol_util`, `emp_length`,
    and `verification_status`. Specifying the column type explicitly ensures that
    the column is read in as the modeler intended. Without this code, these string
    variables might have been read as categorical columns with multiple levels.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在`h2o.import_file`代码中的字典指定了四个输入变量的输入列类型为`string`：`int_rate`、`revol_util`、`emp_length`和`verification_status`。明确指定列类型可以确保列以建模者期望的方式读取。如果没有此代码，这些字符串变量可能被读取为具有多个级别的分类列。
- en: 'The dataset dimensions are obtained by the following command:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的维度是通过以下命令获得的：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This returns 42,536 rows (corresponding to 42,536 customer credit applications)
    and 52 columns. Next, we specify the 22 columns we wish to keep for our analysis:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回了42,536行（对应42,536个客户信用申请）和52列。接下来，我们指定我们希望保留用于分析的22列：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'And we want to remove the remaining columns using the `drop` method:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想使用`drop`方法删除剩余的列：
- en: '[PRE14]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: But what about the 30 columns that we removed? They contained things such as
    text descriptions of the purpose of the loan, additional customer information
    such as the address or zip code, columns with almost completely missing information
    or other data quality issues, and more. Selecting the appropriate columns from
    a raw data source is an important task that takes much time and effort on the
    part of the data scientist.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们删除的30列包含了一些内容，例如贷款目的的文本描述、地址或邮编等额外客户信息、几乎完全缺失信息的列或其他数据质量问题等。从原始数据源中选择适当的列是数据科学家需要花费大量时间和精力的重要任务。
- en: 'The columns we keep are those we believe are most likely to be predictive.
    Explanations for each column are listed as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们保留的列是我们认为最有可能是预测性的列。每个列的解释如下：
- en: '`addr_state`: This is the US state where the borrower resides.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`addr_state`: 这是借款人居住的美国州。'
- en: '`annual_inc`: This is the self-reported annual income of the borrower.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`annual_inc`: 这是借款人自行报告的年收入。'
- en: '`delinq_2yrs`: This is the number of times the borrower has been more than
    30 days late in payments during the last 2 years.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`delinq_2yrs`: 这是借款人在过去两年内超过30天未付款的次数。'
- en: '`dti`: This is the debt-to-income ratio (current debt divided by income).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dti`: 这是债务收入比（当前债务除以收入）。'
- en: '`earliest_cr_line`: This is the date of the earliest credit line (generally,
    longer credit histories correlate with better credit risk).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`earliest_cr_line`: 这是最早信用额度的日期（通常，较长的信用历史与更好的信用风险相关）。'
- en: '`emp_length`: This is the length of employment.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`emp_length`: 这是就业年限。'
- en: '`grade`: This is a risk rating from A to G assigned to the loan by the lender.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grade`: 这是贷款人根据A到G的风险评级分配给贷款的评级。'
- en: '`home_ownership`: Does the borrower own a home or rent?'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`home_ownership`: 借款人拥有房产还是租房？'
- en: '`inq_last_6mths`: This is the number of credit inquiries in the last 6 months.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inq_last_6mths`: 这是过去6个月内的信用查询次数。'
- en: '`installment`: This is the monthly amount owed by the borrower.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`installment`: 这是借款人每月应还的金额。'
- en: '`issue_d`: This is the date the loan was issued.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`issue_d`: 这是贷款发放的日期。'
- en: '`loan_amnt`: This is the total amount lent to the borrower.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loan_amnt`: 这是借给借款人的总金额。'
- en: '`loan_status`: This is a category.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loan_status`: 这是一个类别。'
- en: '`mths_since_last_delinq`: This is the number of months since the last delinquency.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mths_since_last_delinq`: 这是自上次违约以来月份的数量。'
- en: '`open_acc`: This is the number of open credit lines.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`open_acc`: 这是开放的信用额度数量。'
- en: '`pub_rec`: This is the number of derogatory public records (bankruptcies, tax
    liens, and judgments).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pub_rec`: 这是负面公共记录（破产、税收留置权和判决）的数量。'
- en: '`purpose`: This is the borrower''s stated purpose for the loan.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`purpose`: 这是借款人声明的贷款目的。'
- en: '`revol_bal`: This is the revolving balance (that is, the amount owed on credit
    cards at the end of the billing cycle).'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revol_bal`: 这是循环余额（即在账单周期结束时信用卡上的欠款金额）。'
- en: '`revol_util`: This is the revolving utilization (that is, the amount of credit
    used divided by the total credit available to the borrower).'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revol_util`: 这是循环利用率（即使用的信用额度除以借款人可用的总信用额度）。'
- en: '`term`: This is the number of payments on the loan in months (either 36 or
    60).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`term`: 这是贷款在月份中的付款次数（要么是36个月，要么是60个月）。'
- en: '`total_acct`: This is the borrower''s total number of credit lines.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`total_acct`: 这是借款人的总信用额度数量。'
- en: '`verification_status`: This tells us whether the income was verified or not.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verification_status`：这告诉我们收入是否经过验证。'
- en: 'Assuming our data columns have been properly selected, we can move on to the
    next step: creating the response variable.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的数据列已经被正确选择，我们可以继续下一步：创建响应变量。
- en: Defining the problem and creating the response variable
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义问题和创建响应变量
- en: 'The creation of the response variable depends on the problem definition. The
    goal of this use case is to predict which customers will default on a loan. A
    model that predicts a loan default needs a response variable that differentiates
    between good and bad loans. Let''s start by investigating the `loan_status` variable
    using the following code:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 响应变量的创建取决于问题定义。本用例的目标是预测哪些客户会违约。预测贷款违约的模型需要一个区分良好和不良贷款的响应变量。让我们首先使用以下代码调查`loan_status`变量：
- en: '[PRE16]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This produces a table with all possible values of the loan status stored in
    our data:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个表格，其中存储了我们数据中贷款状态的所有可能值：
- en: '![Figure 8.1 – Loan status categories from the raw Lending Club loan default
    dataset'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.1 – 从原始Lending Club贷款违约数据集中提取的贷款状态类别]'
- en: '](img/B16721_08_001.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_08_001.jpg]'
- en: Figure 8.1 – Loan status categories from the raw Lending Club loan default dataset
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 从原始Lending Club贷款违约数据集中提取的贷款状态类别
- en: As you can see in *Figure 8.1*, the `loan_status` variable is relatively complex,
    containing 11 categories that are somewhat redundant or overlapping. For instance,
    `Charged Off` indicates that 5,435 loans were bad. `Default` contains another
    7\. `Fully Paid` shows that 30,843 loans were good. Some loans, for example, those
    indicated by the `Current` or `Late` categories, are still ongoing and so are
    not yet good or bad.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图8.1*所示，`loan_status`变量相对复杂，包含11个类别，有些是重复的或重叠的。例如，`Charged Off`表示有5,435笔贷款是坏账。`Default`包含另外7笔。`Fully
    Paid`表明有30,843笔贷款是好的。一些贷款，例如由`Current`或`Late`类别指示的贷款，仍然是持续的，因此尚未是好或坏。
- en: Multiple loans were provided that did not meet the credit policy. Why this was
    allowed is unclear and worth checking with the data source. Did the credit policy
    change so that these loans are of an earlier vintage? Are these formal overrides
    or were they accidental? Whatever the case might be, these categories hint at
    a different underlying population that might require our attention. Should we
    remove these loans altogether, ignore the issue by collapsing them into their
    corresponding categories, or create a `Meets Credit Policy` indicator variable
    and model them directly? A better understanding of the data would allow the data
    scientist to make an informed decision.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了多个不符合信贷政策的贷款。为什么允许这种情况尚不清楚，值得与数据源核实。信贷政策是否改变，使得这些贷款属于更早的批次？这些是正式的覆盖还是意外的？无论情况如何，这些类别都暗示了一个可能需要我们关注的潜在不同群体。我们应该完全删除这些贷款，将问题忽略并合并到相应的类别中，还是创建一个`符合信贷政策`的指标变量并直接对它们进行建模？对数据的更好理解将允许数据科学家做出明智的决定。
- en: In the end, we need a binary response variable based on a population of loans
    that have either been paid off or defaulted. First, filter out any ongoing loans.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要一个基于已偿还或违约的贷款群体的二元响应变量。首先，过滤掉任何持续贷款。
- en: Removing ongoing loans
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 移除持续贷款
- en: 'We need to build our model with only those loans that have either defaulted
    or been fully paid off. Ongoing loans have `loan_status` such as `Current` or
    `In Grace Period`. The following code captures the rows whose statuses indicate
    ongoing loans:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要构建一个只包含已违约或已全额偿还的贷款的模型。持续贷款的`loan_status`有如`Current`或`In Grace Period`等状态。以下代码捕获了那些状态指示持续贷款的行：
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We use the following code to remove those ongoing loans and display the status
    for the remaining loans:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下代码来移除这些持续贷款并显示剩余贷款的状态：
- en: '[PRE25]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The resulting status categories are shown in *Figure 8.2*:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 结果状态类别显示在*图8.2*中：
- en: '![Figure 8.2 – Loan status categories after filtering the ongoing loans'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.2 – 过滤后的持续贷款的贷款状态类别]'
- en: '](img/B16721_08_002.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_08_002.jpg]'
- en: Figure 8.2 – Loan status categories after filtering the ongoing loans
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 过滤后的持续贷款的贷款状态类别
- en: Note that, in *Figure 8.2*, five categories of loan status now need to be summarized
    in a binary response variable. This is detailed in the next step.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在*图8.2*中，现在需要将五个贷款状态类别总结成一个二元响应变量。这将在下一步中详细说明。
- en: Defining the binary response variable
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义二元响应变量
- en: 'We start by forming a `fully_paid` list to summarize the loan status categories:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个`fully_paid`列表来总结贷款状态类别：
- en: '[PRE27]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Next, let''s create a binary response column, `bad_loan`, as an indicator for
    any loans that were not completely paid off:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建一个二进制响应列，`bad_loan`，作为任何未完全偿还的贷款的指示符：
- en: '[PRE31]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Finally, remove the original loan status column:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，移除原始贷款状态列：
- en: '[PRE34]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We remove the original loan status column because the information we need for
    building our predictive model is now contained in the `bad_loan` response variable.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们移除了原始的贷款状态列，因为构建我们的预测模型所需的信息现在包含在`bad_loan`响应变量中。
- en: Next, we will convert string data into numeric values.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将字符串数据转换为数值。
- en: Converting implied numeric data from strings into numeric values
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将字符串中的隐含数值数据转换为数值
- en: There are various ways that data can be messy. In the preceding step, we saw
    how variables can sometimes contain redundant categories that might benefit from
    summarization. The format in which data values are displayed and stored can also
    cause problems. Therefore, the 28% that we naturally interpret as a number is,
    typically, input as a character string by a computer. Converting implied numeric
    data into actual numeric data is a very typical data quality task.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可能以各种方式变得混乱。在上一个步骤中，我们看到了变量有时可能包含冗余类别，这些类别可能从汇总中受益。数据值显示和存储的格式也可能引起问题。因此，我们自然解释为数字的28%，通常是由计算机以字符字符串的形式输入的。将隐含的数值数据转换为实际数值数据是一个非常典型的数据质量任务。
- en: 'Consider the `revol_util` and `emp_length` columns:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑`revol_util`和`emp_length`列：
- en: '[PRE35]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The output is shown in the following screenshot:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示在下图中：
- en: '![Figure 8.3 – Variables stored as strings to be converted into numeric values'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.3 – 存储为字符串并需要转换为数值的变量]'
- en: '](img/B16721_08_003.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16721_08_003.jpg]'
- en: Figure 8.3 – Variables stored as strings to be converted into numeric values
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – 存储为字符串并需要转换为数值的变量
- en: 'The `revol_util` variable, as shown in *Figure 8.3*, is inherently numeric
    but has a trailing percent sign. In this case, the solution is simple: strip the
    **%** sign and convert the strings into numeric values. This can be done with
    the following code:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图8.3*所示，`revol_util`变量本质上是数值型的，但有一个尾随的百分号。在这种情况下，解决方案很简单：移除**%**符号并将字符串转换为数值。这可以通过以下代码完成：
- en: '[PRE36]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The `gsub` method substitutes `%` with a blank space. The `trim` method removes
    any whitespace in the string. The `asnumeric` method converts the string value
    into a number.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`gsub`方法将`%`替换为空格。`trim`方法移除字符串中的任何空白字符。`asnumeric`方法将字符串值转换为数字。'
- en: 'The `emp_length` column is only slightly more complex. First, we need to strip
    out the `year` or `years` term. Also, we must deal with the `<` and `+` signs.
    If we define `< 1` as `0` and `10+` as `10`, then `emp_length` can also be cast
    as numeric. This can be done using the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`emp_length`列稍微复杂一些。首先，我们需要移除`year`或`years`术语。此外，我们必须处理`<`和`+`符号。如果我们定义`< 1`为`0`和`10+`为`10`，那么`emp_length`也可以转换为数值。这可以通过以下代码完成：'
- en: '[PRE40]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Next, we will complete our data wrangling steps by cleaning up any messy categorical
    columns.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过清理任何混乱的分类列来完成我们的数据整理步骤。
- en: Cleaning up messy categorical columns
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清理混乱的分类列
- en: 'The last step in preparation for feature engineering and modeling is clarifying
    the options or levels in often messy categorical columns. This standardization
    task is illustrated by the `verification_status` variable. Use the following code
    to find the levels of `verification_status`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 准备特征工程和建模的最后一步是明确通常混乱的分类列中的选项或级别。这个标准化任务通过`verification_status`变量来说明。使用以下代码查找`verification_status`的级别：
- en: '[PRE47]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The results are displayed in *Figure 8.4*:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在*图8.4*中：
- en: '![Figure 8.4 – The categories of the verification status from the raw data'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.4 – 原始数据中的验证状态类别]'
- en: '](img/B16721_08_004.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16721_08_004.jpg]'
- en: Figure 8.4 – The categories of the verification status from the raw data
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 – 原始数据中的验证状态类别
- en: 'Because there are multiple values in *Figure 8.4* that mean verified (`VERIFIED
    - income` and `VERIFIED - income source`), we simply replace them with `verified`.
    The following code uses the `sub` method for easy replacement:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 因为*图8.4*中有多个值表示已验证（`VERIFIED - income`和`VERIFIED - income source`），我们只需将它们替换为`verified`。以下代码使用`sub`方法进行简单替换：
- en: '[PRE48]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: After completing all our data wrangling steps, we will move on to feature engineering.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成所有数据整理步骤后，我们将继续进行特征工程。
- en: Feature engineering
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: 'In [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082), *Advanced
    Model Building – Part I*, we introduced some feature engineering concepts and
    discussed target encoding at length. In this section, we will delve into feature
    engineering in a bit more depth. We can organize feature engineering as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第5章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)，*高级模型构建 – 第一部分* 中，我们介绍了一些特征工程概念，并详细讨论了目标编码。在本节中，我们将更深入地探讨特征工程。我们可以这样组织特征工程：
- en: Algebraic transformations
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代数变换
- en: Features engineered from dates
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从日期中构建的特征
- en: Simplifying categorical variables by combining categories
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过合并类别简化分类变量
- en: Missing value indicator functions
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值指示函数
- en: Target encoding categorical columns
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标编码分类列
- en: The ordering of these transformations is not important except for the last one.
    Target encoding is the only transformation that requires data to be split into
    train and test sets. By saving it for the end, we can apply the other transformations
    to the entire dataset at once rather than separately to the training and test
    splits. Also, we introduce stratified sampling for splitting data in H2O-3\. This
    has very little impact on our current use case but is important when data is highly
    imbalanced, such as in fraud modeling.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变换的顺序并不重要，除了最后一个。目标编码是唯一需要将数据分为训练集和测试集的变换。通过将其留到最后，我们可以一次性将其他变换应用于整个数据集，而不是分别应用于训练集和测试集。此外，我们在
    H2O-3 中引入了分层抽样来分割数据。这对我们当前的使用案例影响很小，但在数据高度不平衡的情况下，例如在欺诈建模中，这很重要。
- en: In the following sections, we include all our feature engineering code for completeness.
    Code that has been introduced earlier will be merely referenced, while new feature
    engineering tasks will merit discussion. Let's begin with algebraic transformations.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将为了完整性包括所有我们的特征工程代码。之前引入的代码将仅被引用，而新的特征工程任务将值得讨论。让我们从代数变换开始。
- en: Algebraic transformations
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代数变换
- en: 'The most straightforward form of feature engineering entails taking simple
    transformations of the raw data columns: the log, the square, the square root,
    the differences in columns, the ratios of the columns, and more. Often, the inspiration
    for these transformations comes from an underlying theory or is based on subject-matter
    expertise.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 最直接的特征工程形式是对原始数据列进行简单的变换：对数、平方、平方根、列之间的差异、列之间的比率等等。通常，这些变换的灵感来自于底层理论或基于主题领域专业知识。
- en: 'The `credit_length` variable, as defined in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part I*, is one such transformation. Recall that this
    is created with the following code:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第5章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)，*高级模型构建 – 第一部分* 中定义的
    `credit_length` 变量就是这样一种变换。回想一下，这是通过以下代码创建的：
- en: '[PRE54]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The justification for this variable is based on a business observation: customers
    with longer credit histories tend to be at lower risk of defaulting. Also, we
    drop the `earliest_cr_line` variable, which is no longer needed:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这个变量的合理性基于一个业务观察：信用历史较长的客户往往违约风险较低。此外，我们删除了 `earliest_cr_line` 变量，因为它不再需要：
- en: '[PRE56]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Another simple feature we could try is *(annual income)/(number of credit lines)*,
    taking the log for distributional and numerical stability. Let''s name it `log_inc_per_acct`.
    This ratio makes intuitive sense: larger incomes should be able to support a greater
    number of credit lines. This is similar to the debt-to-income ratio in intent
    but captures slightly different information. We can code it as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个我们可以尝试的简单特征是 *(年收入)/(信用额度数量)*，取对数以实现分布和数值的稳定性。让我们称它为 `log_inc_per_acct`。这个比率具有直观的意义：收入更高的应该能够支持更多的信用额度。这与债务收入比在意图上相似，但捕捉到略微不同的信息。我们可以这样编码：
- en: '[PRE57]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Next, we will consider the second feature engineering task: encoding information
    from dates.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将考虑第二个特征工程任务：从日期中编码信息。
- en: Features engineered from dates
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从日期中构建的特征
- en: 'As noted in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part I*, there is a wealth of information contained
    in date values that are potentially predictive. To the `issue_d_year` and `issue_d_month`
    features that we created earlier, we add `issue_d_dayOfWeek` and `issue_d_weekend`
    as new factors. The code to do this is as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*第5章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)中所述，*高级模型构建 – 第一部分*，日期值中包含大量潜在预测信息。在我们之前创建的`issue_d_year`和`issue_d_month`特征基础上，我们添加了`issue_d_dayOfWeek`和`issue_d_weekend`作为新的因素。执行此操作的代码如下：
- en: '[PRE60]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'At the end, we drop the original date variable:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们删除原始日期变量：
- en: '[PRE67]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Next, we will address how to simplify categorical variables at the feature engineering
    stage.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论如何在特征工程阶段简化分类变量。
- en: Simplifying categorical variables by combining categories
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过合并类别简化分类变量
- en: In the data wrangling stage, we cleaned up the messy categorical levels for
    the `verification_status` column, removing redundant or overlapping level definitions
    and making categories mutually exclusive. On the other hand, during this feature
    engineering stage, the category levels are already non-overlapping and carefully
    defined. The data values themselves, for instance, small counts for certain categories,
    might suggest some engineering approaches to improve predictive modeling.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据整理阶段，我们对`verification_status`列的混乱分类级别进行了清理，删除了冗余或重叠的级别定义，并使类别相互排斥。另一方面，在特征工程阶段，类别级别已经是非重叠且仔细定义的。数据值本身，例如某些类别的计数较小，可能表明一些工程方法来改进预测建模。
- en: 'Summarize the `home_ownership` categorical variable using the following code:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码总结`home_ownership`分类变量：
- en: '[PRE68]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The tabled results are shown in the following screenshot:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 表格结果如下所示：
- en: '![Figure 8.5 – Levels of the raw home ownership variable'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.5 – 原始 homeownership 变量的级别'
- en: '](img/B16721_08_005.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_08_005.jpg]'
- en: Figure 8.5 – Levels of the raw home ownership variable
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5 – 原始 homeownership 变量的级别
- en: 'In *Figure 8.5*, although there are five recorded categories within home ownership,
    the largest three have thousands of observations: `MORTGAGE`, `OWN`, and `RENT`.
    The remaining two, `NONE` and `OTHER`, are so infrequent (8 and 135, respectively)
    that we will combine them with `OWN` to create an expanded `OTHER` category.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图8.5*中，尽管在home ownership中有五个记录的类别，但最大的三个类别有数千个观测值：`MORTGAGE`、`OWN`和`RENT`。其余两个，`NONE`和`OTHER`，非常罕见（分别为8和135），因此我们将它们与`OWN`合并，以创建一个扩展的`OTHER`类别。
- en: Collapsing Data Categories
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 合并数据类别
- en: Depending on the inference we want to make, or our understanding of the problem,
    it might make more sense to collapse `NONE` and `OTHER` into the `RENT` or `MORTGAGE`
    categories.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们想要进行的推断或对问题的理解，将`NONE`和`OTHER`合并到`RENT`或`MORTGAGE`类别中可能更有意义。
- en: 'The procedure for combining the categorical levels is shown by the following
    command:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 合并分类级别的过程如下所示：
- en: '[PRE70]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This is given by replacing the `NONE` and `OWN` level descriptions with `OTHER`
    and assigning it to a new variable, `home_3cat`, as shown in the following code:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过用`OTHER`替换`NONE`和`OWN`级别描述，并将其分配给一个新的变量`home_3cat`来实现，如下面的代码所示：
- en: '[PRE71]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Then, we drop the original `home_ownership` column:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们删除原始的`home_ownership`列：
- en: '[PRE74]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Next, we will visit how to create useful indicator functions for missing data.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨如何创建有用的缺失数据指示函数。
- en: Missing value indicator functions
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失值指示函数
- en: When data is not missing at random, the pattern of missingness might be a source
    of predictive information. In other words, sometimes, the fact that a value is
    missing is as, or more, important than the actual value itself. Especially in
    cases where missing values are abundant, creating a missing value indicator function
    can prove helpful.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据不是随机缺失时，缺失模式的模式可能是一个预测信息的来源。换句话说，有时，一个值缺失的事实与实际值本身一样重要，甚至更重要。特别是在缺失值大量存在的情况下，创建一个缺失值指示函数可能很有帮助。
- en: The most interesting characteristic of employment length, `emp_length`, is whether
    the value for a customer is missing. Simple pivot tables show that the proportion
    of bad loans is 26.3% for customers with missing `emp_length` values and 18.0%
    for non-missing values. That disparity in default rates suggests using a missing
    value indicator function as a predictor.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 就业长度`emp_length`最有趣的特征是客户的值是否缺失。简单的交叉表显示，对于缺失`emp_length`值的客户，不良贷款的比例为26.3%，而对于非缺失值，比例为18.0%。这种违约率差异表明使用缺失值指示函数作为预测因子是有用的。
- en: 'The code for creating a missing indicator function for the `emp_length` variable
    is simple:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Here, the new `emp_length_missing` column contains the indicator function. Unlike
    the other features that we engineered earlier, the original `emp_length` column
    does not need to be dropped as a possible predictor.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will turn to target encoding categorical columns.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Target encoding categorical columns
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082), *Advanced
    Model Building – Part I*, we introduced target encoding in H2O-3 in some detail.
    As a prerequisite to target encoding, recall that a train and test set was required.
    We split the data using the `split_frame` method with code similar to the following:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: The `split_frame` method creates a completely random sample split. This approach
    is required for all regression models and works well for relatively balanced classification
    problems. However, when binary classification is highly imbalanced, stratified
    sampling should be used instead.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Stratified sampling for binary classification data splits
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Stratified sampling for binary classification works by separately sampling the
    good and bad loans. In other words, recall that 16% of the loans in our Lending
    Club dataset are bad. We wish to split the data into 80% train and 20% test datasets.
    If we separately sample 20% of the bad loans and 20% of the good loans and then
    combine them, we have a test dataset that preserves the 16% bad loan percentage.
    Combining the remaining data results in a 16% bad loan percentage in our training
    data. Therefore, stratified sampling preserves the original category ratios.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `stratified_split` method on the response column to create a new
    variable named `split`, which contains the `train` and `test` values, as shown
    in the following code:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The results of the stratified split are shown in the following screenshot:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – The stratified split of loan data into train and test'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_08_006.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6 – The stratified split of loan data into train and test
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `split` column to create a Boolean mask for deriving the `train`
    and `test` datasets, as shown in the following code:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Note that we drop the `split` column from both datasets after their creation.
    Now we are ready to target encode using these train and test splits.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Target encoding the Lending Club data
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following code for target encoding the `purpose` and `addr_state` variables
    is similar to the code from [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part I*, which we have included here without discussion:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Next, we redefine the `train` and `test` datasets, dropping the encoded columns
    from the target-encoded `train_te` and `test_te` splits. Also, we also drop the
    `fold` column from the `train_te` dataset (note that it does not exist in the
    `test_te` dataset). The code is as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: With our updated `train` and `test` datasets, we are ready to tackle the model
    building and evaluation processes.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们更新的`train`和`test`数据集，我们准备着手进行模型构建和评估过程。
- en: Model building and evaluation
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型构建和评估
- en: Our approach to model building starts with AutoML. Global explainability applied
    to the AutoML leaderboard either results in picking a candidate model or yields
    insights that we feed back into a new round of modified AutoML models. This process
    can be repeated if improvements in modeling or explainability are apparent. If
    a single model rather than a stacked ensemble is chosen, we can show how an additional
    random grid search could produce better models. Then, the final candidate model
    is evaluated.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型构建方法从AutoML开始。将全局可解释性应用于AutoML排行榜要么选择一个候选模型，要么提供反馈到新一轮修改后的AutoML模型中的见解。如果模型或可解释性有改进，这个过程可以重复。如果选择的是单个模型而不是堆叠集成，我们可以展示如何通过额外的随机网格搜索产生更好的模型。然后，评估最终的候选模型。
- en: The beauty of this approach in H2O-3 is that the modeling heavy lifting is done
    for us automatically with AutoML. Iterating through this process is straightforward,
    and the improvement cycle can be repeated, as needed, until we have arrived at
    a satisfactory final model.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在H2O-3中，这种方法的美妙之处在于模型构建的重活由AutoML自动完成。迭代这个过程很简单，改进周期可以根据需要重复，直到我们得到一个令人满意的最终模型。
- en: 'We organize the modeling steps as follows:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将建模步骤组织如下：
- en: Model search and optimization with AutoML.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用AutoML进行模型搜索和优化。
- en: Investigate global explainability with the AutoML leaderboard models.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用AutoML排行榜模型研究全局可解释性。
- en: Select a model from the AutoML candidates, with an optional additional grid
    search.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从AutoML候选模型中选择一个模型，可选的附加网格搜索。
- en: Final model evaluation.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终模型评估。
- en: Model search and optimization with AutoML
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用AutoML进行模型搜索和优化
- en: 'The model build process using H2O-3 AutoML was extensively introduced in [*Chapter
    5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082), *Advanced Model Building
    – Part I*. Here, we will follow a virtually identical process to create a leaderboard
    of models fit by AutoML. For clarity, we redefine our `response` column and `predictors`
    before removing the `bad_loan` response from the set of `predictors`:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第5章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)中，*高级模型构建 – 第一部分*中，对使用H2O-3
    AutoML的模型构建过程进行了详细介绍。在这里，我们将遵循几乎相同的过程来创建由AutoML拟合的模型排行榜。为了清晰起见，我们在从`predictors`集中移除`bad_loan`响应变量之前重新定义了我们的`response`列和`predictors`：
- en: '[PRE100]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Our AutoML parameters only exclude deep learning models, allowing the process
    to run for up to 30 minutes, as shown in the following code snippet:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的AutoML参数仅排除深度学习模型，允许过程运行长达30分钟，如下代码片段所示：
- en: '[PRE103]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: As demonstrated in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part I*, we can access H2O Flow to monitor the model
    build process in more detail. Once the training on the `aml` object finishes,
    we proceed to investigate the resulting models with global explainability.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*第5章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)中所示，*高级模型构建 – 第一部分*，我们可以访问H2O
    Flow以更详细地监控模型构建过程。一旦对`aml`对象的训练完成，我们就开始调查生成的模型的全局可解释性。
- en: Investigating global explainability with AutoML models
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用AutoML模型研究全局可解释性
- en: 'In [*Chapter 7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127), *Understanding
    ML Models*, we outlined the use of global explainability for a series of models
    produced by AutoML. Here, we will follow the same procedure by calling the `explain`
    method with the `test` data split:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第7章*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127)中，*理解机器学习模型*，我们概述了使用全局可解释性来分析AutoML生成的一系列模型。在这里，我们将通过调用带有`test`数据分割的`explain`方法遵循相同的程序：
- en: '[PRE110]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'The resulting AutoML leaderboard is shown in the following screenshot:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的AutoML排行榜如下截图所示：
- en: '![Figure 8.7 – The top 10 models of the AutoML leaderboard'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.7 – AutoML排行榜的前10个模型'
- en: '](img/B16721_08_007.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_08_007.jpg)'
- en: Figure 8.7 – The top 10 models of the AutoML leaderboard
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 – AutoML排行榜的前10个模型
- en: The stacked ensemble `AllModels` and `BestOfFamily` models claim the top two
    positions on the leaderboard in *Figure 8.7*. The best single model is enclosed
    by a green box and labeled `model_6` from `XGBoost_grid__1`. We will investigate
    this model a bit further as a possible candidate model.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图8.7*中，堆叠集成`AllModels`和`BestOfFamily`模型占据了排行榜的前两位。最佳单个模型由一个绿色方框包围，并标记为`model_6`来自`XGBoost_grid__1`。我们将进一步研究这个模型，作为可能的候选模型。
- en: 'The **Model Correlation** plot is shown in *Figure 8.8*. The green box indicates
    the correlation between our candidate XGBoost model and the two stacked ensembles.
    It confirms that the candidate model has among the highest correlation with the
    ensembles:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 8.8 – Model Correlation plot for the AutoML leaderboard models'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_08_008.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.8 – Model Correlation plot for the AutoML leaderboard models
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Variable Importance Heatmap** diagram in *Figure 8.9* tells us more about
    the stability of the individual features than about the relationship between the
    models. The GBM grid models of 1, 2, 3, and 7 cluster together, and the XGBoost
    grid models of 6, 7, and 9 appear very similar in terms of how important variables
    are in these models:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Variable Importance Heatmap for AutoML models'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_08_009.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.9 – Variable Importance Heatmap for AutoML models
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 'The multiple model `grade`, a feature with values from A to G that appear to
    be increasing at default risk. In other words, the average response for A is less
    than that for B, which is itself less than that for C, and so forth. This diagnostic
    appears to be confirming a business rating practice:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 8.10 – The multiple model PDP for grade'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_08_010.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.10 – The multiple model PDP for grade
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 8.11*, the PDP for annual income acts as a diagnostic. Intuitively,
    an increase in annual income should correspond to a decrease in bad loan rates.
    We can formally enforce (rather than just hope for) a monotonic decreasing relationship
    between the annual income and the default rate by adding monotonicity constraints
    to our model build code:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11 – The multiple model PDP for annual income'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_08_011.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.11 – The multiple model PDP for annual income
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 'Monotonicity constraints can be applied to one or more numeric variables in
    the GBM, XGBoost, and AutoML models in H2O-3\. To do so, supply a `monotone_constraints`
    parameter with a dictionary of variable names and the direction of the monotonicity:
    `1` for a monotonic increasing relationship and `-1` for monotonic decreasing.
    The following code shows how we add a monotonic decreasing `annual_inc` constraint:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: Monotonic Increasing and Decreasing Constraints
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Formally, the monotonic increasing constraint is a monotonic non-decreasing
    constraint, meaning that the function must either be increasing or flat. Likewise,
    the monotonic decreasing constraint is more correctly termed a monotonic non-increasing
    constraint.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'Fitting a constrained model proceeds as usual:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'Here is the `explain` method:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'This produces the leaderboard, as shown in the following screenshot:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12 – The leaderboard for AutoML with monotonic constraints'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_08_012.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.12 – The leaderboard for AutoML with monotonic constraints
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: The first 10 models of the updated AutoML leaderboard are shown in *Figure 8.12*.
    Note that a new model has been added, the monotonic stacked ensemble (boxed in
    red). This stacked ensemble uses, as constituent models, only those that are monotonic.
    In our case, this means that any DRF and XRT random forest models fit by AutoML
    would be excluded. Also note that the monotonic version of XGBoost model 6 is
    once more the leading single model, boxed in green.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的 AutoML 排行榜的前 10 个模型在 *图 8.12* 中显示。注意，已经添加了一个新模型，单调堆叠集成（用红色框出）。这个堆叠集成只使用单调的模型作为组成部分。在我们的案例中，这意味着任何由
    AutoML 调整的 DRF 和 XRT 随机森林模型将被排除。此外，注意 XGBoost 模型 6 的单调版本再次成为领先的单一模型，用绿色框出。
- en: '*Figure 8.13* shows the monotonic multiple model PDP for annual income:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 8.13* 展示了年收入的单调多模型 PDP：'
- en: '![Figure 8.13 – The multiple model PDP for annual income'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.13 – 年收入的多模型 PDP'
- en: '](img/B16721_08_013.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_08_013.jpg)'
- en: Figure 8.13 – The multiple model PDP for annual income
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 – 年收入的多模型 PDP
- en: 'Note that only two of the models included in the PDP of *Figure 8.13* are not
    monotonic: the DRF and XRT models. They are both versions of random forest that
    do not have monotonic options. This plot confirms that the monotonic constraints
    on annual income worked as intended. (Note that the PDP in *Figure 8.11* is very
    similar. The models there might have displayed monotonicity, but it was not enforced.)'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，*图 8.13* 中包含的模型中只有两个不是单调的：DRF 和 XRT 模型。它们都是没有单调选项的随机森林版本。这个图证实了年收入上的单调约束按预期工作。（注意，*图
    8.11* 中的 PDP 非常相似。那里的模型可能表现出单调性，但并未强制执行。）
- en: Next, we will consider how to choose a model from the AutoML leaderboard.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将考虑如何从 AutoML 排行榜中选择一个模型。
- en: Selecting a model from the AutoML candidates
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 AutoML 候选模型中选择模型
- en: 'Once AutoML has created a class of models, it is left to the data scientist
    to determine which model to put into production. If pure predictive accuracy is
    the only requirement, then the choice is rather simple: select the top model in
    the leaderboard (usually, this is the **All Models** stacked ensemble). In the
    case where monotonic constraints are required, the monotonic stacked ensemble
    is usually the most predictive.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 AutoML 创建了一类模型，数据科学家就需要决定哪个模型可以投入生产。如果只有纯预测准确率是唯一要求，那么选择相当简单：选择排行榜上的顶级模型（通常，这是
    **所有模型** 堆叠集成）。在需要单调约束的情况下，单调堆叠集成通常是预测性最强的。
- en: 'If business or regulatory constraints only allow a single model to be deployed,
    then we can select one based on a combination of predictive performance and other
    considerations, such as the modeling type. Let''s select XGBoost model 6 as our
    candidate model:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 如果业务或监管约束只允许部署单个模型，那么我们可以根据预测性能和其他考虑因素（如建模类型）的组合来选择一个模型。让我们选择 XGBoost 模型 6 作为我们的候选模型：
- en: '[PRE120]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: H2O-3 AutoML does a tremendous job at building and tuning models across multiple
    modeling types. For individual models, it is sometimes possible to get an improvement
    in performance via an additional random grid search. We will explore this in the
    next section.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: H2O-3 AutoML 在构建和调整多个建模类型的模型方面做得非常出色。对于单个模型，有时通过额外的随机网格搜索可以获得性能提升。我们将在下一节中探讨这一点。
- en: Random grid search to improve the selected model (optional)
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随机网格搜索以改进所选模型（可选）
- en: We use the parameters of the candidate model as starting points for our random
    grid search. The idea is to search within the neighborhood of the candidate model
    for models that perform slightly better, noting that any improvements found will
    likely be minor. The stacked ensemble models give us a ceiling for how well an
    individual model can perform. The data scientist must judge whether the difference
    between candidate model performance and stacked ensemble performance warrants
    the extra effort in searching for possibly better models.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将候选模型的参数作为随机网格搜索的起点。想法是在候选模型附近搜索表现略好的模型，需要注意的是，找到的任何改进可能都是微小的。堆叠集成模型为我们设定了单个模型可以表现多好的上限。数据科学家必须判断候选模型性能与堆叠集成性能之间的差异是否值得额外努力去寻找可能更好的模型。
- en: 'We can list the model parameters using the following code:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码列出模型参数：
- en: '[PRE121]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'Start by importing `H2OGridSearch` and the candidate model estimator; in our
    case, that is `H2OXGBoostEstimator`:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入 `H2OGridSearch` 和候选模型估计器；在我们的案例中，那就是 `H2OXGBoostEstimator`：
- en: '[PRE122]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: 'The hyperparameters are selected by looking at the candidate model''s actual
    parameters and searching within the neighborhood of those values. For instance,
    the sample rate for the candidate model was reported as 80%, and in our hyperparameter
    tuning, we select a range between 60% and 100%. Likewise, a 60% column sample
    rate leads us to implement a range between 40% and 80% for the grid search. The
    hyperparameter tuning code is as follows:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数是通过观察候选模型的实际参数并在这些值的邻域内搜索来选择的。例如，候选模型的采样率报告为80%，在我们的超参数调整中，我们选择了一个介于60%和100%之间的范围。同样，60%的列采样率导致我们在网格搜索中实施了一个介于40%和80%之间的范围。超参数调整的代码如下：
- en: '[PRE124]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'We limit the overall runtime of the random grid search to 30 minutes, as follows:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将随机网格搜索的总运行时间限制为30分钟，如下所示：
- en: '[PRE132]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: '[PRE136]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: '[PRE137]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: 'We add the monotonic constraints to the model and define our grid search:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将单调约束添加到模型中，并定义我们的网格搜索：
- en: '[PRE139]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '[PRE140]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '[PRE142]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '[PRE143]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: '[PRE144]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: '[PRE145]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: '[PRE146]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '[PRE147]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: '[PRE149]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: 'Then, we train the model:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们训练模型：
- en: '[PRE150]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: '[PRE151]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: '[PRE153]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: 'Returning to our results after this long training period, we extract the top
    two models to compare them with our initial candidate model. Note that we order
    by `logloss`:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在经过这么长时间的训练后，我们提取了前两个模型来与我们的初始候选模型进行比较。请注意，我们按`logloss`排序：
- en: '[PRE154]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: '[PRE155]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE155]'
- en: '[PRE156]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE156]'
- en: '[PRE157]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE157]'
- en: 'Determine the performance of each of these models on the test data split:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 确定这些模型在测试数据分割上的性能：
- en: '[PRE158]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE158]'
- en: '[PRE159]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE159]'
- en: '[PRE160]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE160]'
- en: On the test sample, the logloss for the `candidate` model is 0.3951, `best1`
    is 0.3945, and `best2` is 0.3937\. Based on this criterion alone, the `best2`
    model is our updated candidate model. The next step is the evaluation of this
    final model.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试样本上，`candidate`模型的logloss为0.3951，`best1`为0.3945，而`best2`为0.3937。仅根据这一标准，`best2`模型是我们的更新后的候选模型。下一步是对这个最终模型进行评估。
- en: Final model evaluation
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终模型评估
- en: 'Having selected `best2` as our final candidate, next, we evaluate this individual
    model using the `explain` method:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择`best2`作为我们的最终候选模型后，接下来，我们使用`explain`方法评估这个单独的模型：
- en: '[PRE161]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE162]'
- en: 'We will use the variable importance plot in *Figure 8.14* in conjunction with
    individual PDPs to understand the impact of the input variables on this model:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将结合*图8.14*中的变量重要性图和单个PDP来了解输入变量对模型的影响：
- en: '![Figure 8.14 – Variable importance for the final model'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_08_014.jpg]'
- en: '](img/B16721_08_014.jpg)'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_08_014.jpg]'
- en: Figure 8.14 – Variable importance for the final model
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.14 – 最终模型的变量重要性
- en: The `term` variable is by far the most important variable in the final model.
    Inspecting the PDP for "term" in *Figure 8.15* explains why.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在最终模型中，`term`变量是最重要的变量。查看*图8.15*中“term”的PDP可以解释原因。
- en: '![Figure 8.15 – PDP for term'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.15 – 术语的PDP'
- en: '](img/B16721_08_015.jpg)'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_08_015.jpg]'
- en: Figure 8.15 – PDP for term
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.15 – 术语的PDP
- en: Loans with a term of 36 months have a default rate of around 12%, while 60-month
    loans have a default rate that jumps to over 25%. Note that because this is an
    XGBoost model, `term` was parameterized as `term 36 months`.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 36个月的贷款违约率约为12%，而60个月的贷款违约率则跳升至超过25%。请注意，因为这是一个XGBoost模型，`term`被参数化为`term 36
    months`。
- en: 'The next variable in importance is `grade A`. This is an indicator function
    for one level of the categorical `grade` variable. Looking at the PDP for `grade`
    in *Figure 8.16*, loans with a level of A only have a 10% default rate with an
    approximate 5% jump for the next lowest risk grade, B:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个重要变量是`grade A`。这是分类变量`grade`的一个指示函数。查看*图8.16*中`grade`的PDP，我们发现只有A级别的贷款有10%的违约率，而下一个最低风险等级B的违约率大约增加了5%：
- en: '![ Figure 8.16 – PDP for grade'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.16 – 等级的PDP'
- en: '](img/B16721_08_016.jpg)'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_08_016.jpg]'
- en: Figure 8.16 – PDP for grade
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.16 – 等级的PDP
- en: 'The next two variables are numeric and roughly equivalent in importance: credit
    inquiries in the last 6 months (`inq_last_6mths`) and annual income. Their PDPs
    are shown in *Figures 8.17* and *Figure 8.18*, respectively. The credit inquiries
    PDP appears to be monotonic except for the right-hand tail. This is likely due
    to thin data in this upper region of high numbers of inquiries. It would probably
    make sense to add a monotonic constraint to this variable as we did for annual
    income in *Figure 8.18*:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 下两个变量是数值型，重要性大致相当：过去6个月的信用查询（`inq_last_6mths`）和年收入。它们的PDP分别显示在*图8.17*和*图8.18*中。信用查询的PDP似乎是单调的，除了右尾部分。这可能是由于这个高查询数量区域的数据稀薄。我们可能需要像在*图8.18*中对年收入所做的那样，为这个变量添加单调约束：
- en: '![Figure 8.17 – PDP for the number of inquiries in the last 6 months'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.17 – 最后6个月的查询次数的PDP'
- en: '](img/B16721_08_017.jpg)'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_08_017.jpg]'
- en: Figure 8.17 – PDP for the number of inquiries in the last 6 months
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.17 – 最后6个月内的查询次数PDP]'
- en: '![Figure 8.18 – PDP for monotonic annual income'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.18 – 单调年度收入的PDP]'
- en: '](img/B16721_08_018.jpg)'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16721_08_018.jpg]'
- en: Figure 8.18 – PDP for monotonic annual income
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.18 – 单调年度收入的PDP]'
- en: '*Figure 8.19* shows the PDP for revolving credit utilization. Unlike earlier
    numeric plots, the `revol_util` variable is not visibly monotonic. In general,
    the higher the utilization, the greater the default rate. However, there is a
    relatively high default rate at the utilization of zero. Sometimes, effects such
    as this are caused by mixtures of disparate populations. For example, this could
    be a combination of customers who have credit lines but carry no balances (generally
    good risks) with customers who have no credit lines at all (generally poorer risks).
    Without reparameterization, `revol_util` should not be constrained to be monotonic:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.19*显示了循环信用利用率的PDP。与早期的数值图不同，`revol_util`变量并不明显是单调的。一般来说，利用率越高，违约率就越高。然而，在零利用率时，违约率相对较高。有时，这种效应是由不同人群的混合引起的。例如，这可能是由没有信用额度但没有任何余额的客户（通常风险较好）与完全没有信用额度的客户（通常风险较差）的组合。在不重新参数化的情况下，`revol_util`不应该被限制为单调：'
- en: '![Figure 8.19 – PDP for revolving utilization'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.19 – 循环利用率的PDP]'
- en: '](img/B16721_08_019.jpg)'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16721_08_019.jpg]'
- en: Figure 8.19 – PDP for revolving utilization
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.19 – 循环利用率的PDP]'
- en: 'Finally, *Figure 8.20* shows the SHAP summary for the final model. The relative
    importance in terms of SHAP values is slightly different than that of our feature
    importance and PDP views:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，*图8.20*显示了最终模型的SHAP摘要。从SHAP值的角度来看，相对重要性与我们特征重要性和PDP视图略有不同：
- en: '![Figure 8.20 – The SHAP Summary plot for the final model'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.20 – 最终模型的SHAP摘要图]'
- en: '](img/B16721_08_020.jpg)'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16721_08_020.jpg]'
- en: Figure 8.20 – The SHAP Summary plot for the final model
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.20 – 最终模型的SHAP摘要图]'
- en: This has been a taster of what a final model review or whitepaper would show.
    Some of these are multiple pages in length.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个最终模型审查或白皮书的预览。其中一些内容可能长达多页。
- en: Preparation for model pipeline deployment
  id: totrans-406
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型管道部署准备
- en: 'Exporting a model as a MOJO for final model deployment is trivial, for instance,
    consider the following:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型作为MOJO导出以进行最终模型部署是微不足道的，例如，考虑以下内容：
- en: '[PRE163]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE163]'
- en: 'Deployment of the MOJO in various architectures via multiple recipes is covered,
    in detail, in [*Chapter 9*](B16721_09_Final_SK_ePub.xhtml#_idTextAnchor159), *Production
    Scoring and the H2O MOJO*. In general, there is a significant amount of effort
    that must be assigned to productionizing data for model scoring. The key is that
    data used in production must have a schema identical to that of the training data
    used in modeling. In our case, that means all the data wrangling and feature engineering
    tasks must be productionized before scoring in production can occur. In other
    words, the process is simply as follows:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第9章*](B16721_09_Final_SK_ePub.xhtml#_idTextAnchor159)中详细介绍了通过多个配方在多种架构中部署MOJO，*生产评分和H2O
    MOJO*。一般来说，必须分配大量努力以将数据用于模型评分。关键是生产中使用的必须具有与建模中使用的训练数据相同的模式。在我们的案例中，这意味着所有数据整理和特征工程任务必须在生产评分之前进行生产化。换句话说，这个过程很简单：
- en: Transform raw data into the training data format.
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将原始数据转换为训练数据格式。
- en: Score the model using the MOJO on the transformed data.
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MOJO在转换后的数据上评分模型。
- en: It is a best practice to work with your DevOps or equivalent production team
    well in advance of model delivery to understand the data requirements for deployment.
    This includes specifying roles and responsibilities such as who is responsible
    for producing the data transformation code, how is the code to be tested, who
    is responsible for implementation, and more. Usually, the delivery of a MOJO is
    not the end of the effort for a data science leader. We will discuss the importance
    of this partnership, in more detail, in [*Chapter 9*](B16721_09_Final_SK_ePub.xhtml#_idTextAnchor159),
    *Production Scoring and the H2O MOJO*.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型交付之前与您的DevOps或等效生产团队合作是一项最佳实践，以便了解部署所需的数据要求。这包括指定角色和责任，例如谁负责生成数据转换代码，代码如何进行测试，谁负责实施，等等。通常，对于数据科学领导者来说，MOJO的交付并不是努力的终点。我们将在[*第9章*](B16721_09_Final_SK_ePub.xhtml#_idTextAnchor159)中更详细地讨论这一伙伴关系的重要性，*生产评分和H2O
    MOJO*。
- en: Summary
  id: totrans-413
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we reviewed the entire data science model-building process.
    We started with raw data and a somewhat vaguely defined use case. Further inspection
    of the data allowed us to refine the problem statement to one that was relevant
    to the business and that could be addressed with the data at hand. We performed
    extensive feature engineering in the hopes that some features might be important
    predictors in our model. We introduced an efficient and powerful method of model
    building using H2O AutoML to build an array of different models using multiple
    algorithms. Selecting one of those models, we demonstrated how to further refine
    the model with additional hyperparameter tuning using grid search. Throughout
    the model-building process, we used the diagnostics and model explanations introduced
    in [*Chapter 7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127), *Understanding
    ML Models*, to evaluate our ML model. After arriving at a suitable model, we showed
    the simple steps required to prepare for the enterprise deployment of a model
    pipeline built in H2O.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了整个数据科学模型构建过程。我们从原始数据和一个定义得相当模糊的使用案例开始。对数据的进一步检查使我们能够将问题陈述细化到一个与业务相关且可以使用现有数据进行解决的问题。我们进行了广泛的特征工程，希望某些特征可能是我们模型中的重要预测因子。我们引入了一种高效且强大的模型构建方法，使用H2O
    AutoML通过多种算法构建了一系列不同的模型。选择其中之一后，我们展示了如何通过网格搜索进行额外的超参数调整来进一步细化模型。在整个模型构建过程中，我们使用了在[*第7章*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127)“理解机器学习模型”中引入的诊断和模型解释来评估我们的机器学习模型。在得到一个合适的模型后，我们展示了在H2O中构建的模型管道的企业部署所需的简单步骤。
- en: The next chapter introduces us to the process of deploying these models into
    production using the H2O MOJO for scoring.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章介绍了如何使用H2O MOJO进行评分，将这些模型部署到生产过程中的步骤。
