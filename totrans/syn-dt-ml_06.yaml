- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Leveraging Simulators and Rendering Engines to Generate Synthetic Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用模拟器和渲染引擎生成合成数据
- en: In this chapter, we will introduce a well-known method for synthetic data generation
    using simulators and rendering engines. We will explore the main pipeline for
    creating a simulator and generating automatically annotated synthetic data. Following
    this, we will highlight the challenges and briefly discuss two simulators for
    synthetic data generation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍使用模拟器和渲染引擎生成合成数据的一种知名方法。我们将探讨创建模拟器和自动生成标注合成数据的主要流程。随后，我们将重点介绍挑战，并简要讨论两个用于生成合成数据的模拟器。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: 'Simulators and rendering engines: definitions, history, and evolution'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模拟器和渲染引擎：定义、历史和演变
- en: How to generate synthetic data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何生成合成数据
- en: Challenges and limitations
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挑战和限制
- en: Case studies
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 案例研究
- en: Introduction to simulators and rendering engines
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟器和渲染引擎简介
- en: In this section, we will dive into the world of simulators and rendering engines.
    We will look at the history and evolution of these powerful tools for synthetic
    data generation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入探讨模拟器和渲染引擎的世界。我们将探讨这些用于生成合成数据的有力工具的历史和演变。
- en: Simulators
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模拟器
- en: A **simulator** is software or a program written to imitate or simulate certain
    processes or phenomena of the real world. Simulators usually create a virtual
    world where scientists, engineers, and other users can test their algorithms,
    products, and hypotheses. At the same time, you can use this virtual environment
    to help you learn about and practice complex tasks. These tasks are usually dangerous
    and very expensive to perform in the real world. For example, driving simulators
    teach learners how to drive and how to react to unexpected scenarios such as a
    child suddenly crossing the street, which is extremely dangerous to do in the
    real world.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**模拟器**是一种软件或程序，旨在模仿或模拟现实世界的某些过程或现象。模拟器通常创建一个虚拟世界，科学家、工程师和其他用户可以在其中测试他们的算法、产品和假设。同时，你可以使用这个虚拟环境来帮助你了解和实践复杂任务。这些任务通常在现实世界中执行是危险且代价高昂的。例如，驾驶模拟器教导学习者如何驾驶，以及如何应对诸如儿童突然横穿街道等意外情况，这在现实世界中是极其危险的。'
- en: Simulators are used in various fields, such as aviation, healthcare, engineering,
    driving, space, farming, and gaming. In *Figure 6**.1*, you can find examples
    of these simulators.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟器被用于各种领域，如航空、医疗保健、工程、驾驶、太空、农业和游戏。在*图 6.1*中，你可以找到这些模拟器的示例。
- en: '![Figure 6.1 – Examples of simulators utilized in driving, engineering, healthcare,
    and farming](img/Figure_06_01_B18494.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.1 – 驱动、工程、医疗保健和农业中使用的模拟器示例](img/Figure_06_01_B18494.jpg)'
- en: Figure 6.1 – Examples of simulators utilized in driving, engineering, healthcare,
    and farming
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1 – 驱动、工程、医疗保健和农业中使用的模拟器示例
- en: Next, we will introduce rendering and game engines.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍渲染和游戏引擎。
- en: Rendering and game engines
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 渲染和游戏引擎
- en: Rendering and game engines are software used mainly to generate images or videos.
    They are composed of various subsystems responsible for simulating, for example,
    physics, lighting, and sound. They are usually used in fields such as gaming,
    animation, virtual reality, augmented reality, and the metaverse. Unlike simulators,
    game engines can be used to create virtual worlds that may or may not be designed
    to mimic the real world. Game engines are mainly used to develop games. However,
    they can be utilized for training and simulation, films and television, and visualization.
    In *Figure 6**.2*, you can see some examples of modern rendering and game engines.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 渲染和游戏引擎是主要用于生成图像或视频的软件。它们由各种子系统组成，负责模拟，例如物理、光照和声音。它们通常用于游戏、动画、虚拟现实、增强现实和元宇宙等领域。与模拟器不同，游戏引擎可以用来创建可能或可能不是旨在模仿现实世界的虚拟世界。游戏引擎主要用于开发游戏。然而，它们可以用于训练和模拟、电影和电视以及可视化。在*图
    6.2*中，你可以看到一些现代渲染和游戏引擎的示例。
- en: '![Figure 6.2 – Examples of modern rendering and game engines](img/Figure_06_02_B18494.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.2 – 现代渲染和游戏引擎的示例](img/Figure_06_02_B18494.jpg)'
- en: Figure 6.2 – Examples of modern rendering and game engines
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.2 – 现代渲染和游戏引擎的示例
- en: Next, we’ll learn more about the history of rendering and game engines.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将更深入地了解渲染和游戏引擎的历史。
- en: History and evolution of simulators and game engines
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模拟器和游戏引擎的历史和演变
- en: Game engines roughly started to appear in the 1970s. The computers of that era
    were limited in terms of processing capabilities and memory. At that time, most
    games were 2D games, such as *Pong* and *Spacewar!*. They were limited to simple
    graphics, basic lighting, elementary shading, and limited visual and sound effects.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏引擎的大致出现始于20世纪70年代。那个时代的计算机在处理能力和内存方面有限。当时，大多数游戏都是二维游戏，如 *《乒乓》* 和 *《太空战争》*。它们局限于简单的图形、基本的照明、基本的着色和有限的视觉和声音效果。
- en: The great advancements in hardware led to more sophisticated game engines. These
    game engines, such as *Unreal* ([https://www.unrealengine.com](https://www.unrealengine.com))
    and *Unity* ([https://unity.com](https://unity.com)) facilitated the creation
    of rich, photorealistic virtual worlds. As physics simulations became more sophisticated
    and advanced, the development of photorealistic graphics also progressed simultaneously.
    This allowed the simulation of complex physics and interactions between scene
    elements, such as fluid dynamics and cloth simulation. In more recent years, many
    photorealistic, complex games have been released, such as *Call of Duty* ([https://www.callofduty.com](https://www.callofduty.com))
    and *Grand Theft* *Auto* ([https://www.rockstargames.com/games/vicecity](https://www.rockstargames.com/games/vicecity)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件的大幅进步导致了更复杂的游戏引擎的出现。这些游戏引擎，如 *Unreal* ([https://www.unrealengine.com](https://www.unrealengine.com))
    和 *Unity* ([https://unity.com](https://unity.com))，促进了丰富、逼真的虚拟世界的创建。随着物理模拟变得更加复杂和先进，逼真图形的发展也同步进行。这使得可以模拟复杂的物理和场景元素之间的交互，例如流体动力学和布料模拟。在最近几年，许多逼真、复杂的游戏被发布，如
    *《使命召唤》* ([https://www.callofduty.com](https://www.callofduty.com)) 和 *《侠盗猎车手》*
    ([https://www.rockstargames.com/games/vicecity](https://www.rockstargames.com/games/vicecity))。
- en: The availability of complex and easy-to-use game engines such as Unity has democratized
    game development and made it more accessible than ever before. Thus, game development
    is not just limited to big tech companies but is also available to independent
    companies and artists.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂且易于使用的游戏引擎，如Unity的可用性，使游戏开发民主化，并使其比以往任何时候都更容易接触。因此，游戏开发不仅限于大型科技公司，也向独立公司和艺术家开放。
- en: At the same time, the huge sudden increase in the number of mobile phones recently
    made mobile games a more attractive destination for research and industry.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，最近手机数量的巨大突然增加使得移动游戏成为研究和工业更具吸引力的目的地。
- en: 'Recently, synthetic data researchers started to experiment with using game
    engines and video games to generate rich synthetic data. Two of the pioneer works
    in this area are *Playing for Data: Ground Truth from Computer Games* ([https://arxiv.org/abs/1608.02192](https://arxiv.org/abs/1608.02192))
    and *Domain Randomization for Transferring Deep Neural Networks from Simulation
    to the Real* *World* ([https://arxiv.org/pdf/1703.06907.pdf](https://arxiv.org/pdf/1703.06907.pdf)).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，合成数据研究人员开始尝试使用游戏引擎和视频游戏来生成丰富的合成数据。这一领域的两个先驱作品是*《玩数据：计算机游戏中的真实数据》* ([https://arxiv.org/abs/1608.02192](https://arxiv.org/abs/1608.02192))
    和 *《域随机化：将深度神经网络从仿真转移到现实世界》* ([https://arxiv.org/pdf/1703.06907.pdf](https://arxiv.org/pdf/1703.06907.pdf))。
- en: In the following section, we will explore exactly how to generate synthetic
    data using simulators and game engines.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何使用模拟器和游戏引擎生成合成数据的确切方法。
- en: Generating synthetic data
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成合成数据
- en: In this section, we will learn how to generate synthetic data using modern game
    engines such as Unity and Unreal.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用现代游戏引擎，如Unity和Unreal，生成合成数据。
- en: 'To generate synthetic data with its corresponding ground truth, it is recommended
    that we follow these steps:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成与其对应真实数据的合成数据，建议我们遵循以下步骤：
- en: Identify the task and ground truth to generate.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定要生成的任务和真实数据。
- en: Create the 3D virtual world in the game engine.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在游戏引擎中创建3D虚拟世界。
- en: Set the virtual camera.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置虚拟摄像机。
- en: Add noise and anomalies.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加噪声和异常。
- en: Set the labeling pipeline.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置标签流程。
- en: Generate the training data with the ground truth.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用真实数据生成训练数据。
- en: Throughout this section, we will thoroughly discuss each facet of this process.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细讨论这一过程的各个方面。
- en: Identify the task and ground truth to generate
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定要生成的任务和真实数据。
- en: The first step in the synthetic data generation process is defining the task,
    the type of the data, and the ground truth to generate. For example, the data
    could be images, videos, or audio. At the same time, you need to identify what
    ground truth to generate for your problem. For example, you can generate semantic
    segmentation, instance segmentation, depth maps, normal maps, human poses, and
    human body parts semantic segmentation, just to name a few.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据生成过程的第一步是定义任务、数据的类型以及要生成的真实情况。例如，数据可以是图像、视频或音频。同时，你需要确定为你的问题生成哪些真实情况。例如，你可以生成语义分割、实例分割、深度图、法线图、人体姿态以及人体部位语义分割，仅举几例。
- en: Next, we need to understand how to create the 3D virtual world, which we will
    explore in the following section.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要了解如何创建3D虚拟世界，这将在下一节中探讨。
- en: Create the 3D virtual world in the game engine
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在游戏引擎中创建3D虚拟世界
- en: 'To begin with, we must define the environment, its elements, and the interactions
    between these elements. You may need to decide on the level of photorealism, the
    degree of visual complexity, and the range of variations and diversity that you
    need to attain for your virtual scenes, and thus the synthetic data. In general,
    and for a typical plan to generate synthetic data, we can follow these steps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须定义环境、其元素以及这些元素之间的相互作用。你可能需要决定你需要的虚拟场景的 photorealism 级别、视觉复杂度程度以及变化和多样性的范围，从而确定合成数据。一般来说，对于一个典型的生成合成数据计划，我们可以遵循以下步骤：
- en: Preparation and conceptualization
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备和概念化
- en: Modeling
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建模
- en: Materialization and texturing
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实体化和纹理化
- en: Integration into the game engine
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集成到游戏引擎中
- en: Polishing and testing
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 精炼和测试
- en: Next, we will delve into each of these aspects and provide deeper insight.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入探讨这些方面的每一个，并提供更深入的见解。
- en: Preparation and conceptualization
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备和概念化
- en: 'Before creating the 3D virtual world, we need to examine our ideas about the
    virtual world to be created. It is suggested to make simple drawings and sketches
    to visualize the elements of the world and how they will interact with each other.
    You may need to jot down the following: weather conditions to simulate, whether
    an indoor or outdoor environment, the time of day, and the scenes’ crowdedness,
    just to mention a few. Additionally, you need to decide which game engine to use,
    for instance, **Unity**, **Unreal**, or **CryEngine**. You also need to decide
    which rendering pipeline to utilize, which depends on the game engine itself.
    For example, the Unity game engine has different rendering pipelines, such as
    **Built-in Render Pipeline (BRP)**, **High-Definition Render Pipeline (HDRP)**,
    **Universal Render Pipeline (URP)**, and **Scriptable Render Pipeline (SRP)**.
    The selection of the rendering pipeline also depends on the degree of photorealism
    that you want to achieve. Moreover, some game engines may support various programming
    languages, such as CryEngine, which supports C++ and C#. Thus, you may need to
    decide which language to use as well.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建3D虚拟世界之前，我们需要检查我们对要创建的虚拟世界的想法。建议绘制简单的草图和草图来可视化世界的元素以及它们将如何相互作用。你可能需要记下以下内容：要模拟的天气条件、室内或室外环境、一天中的时间以及场景的拥挤程度，仅举几例。此外，你需要决定使用哪个游戏引擎，例如**Unity**、**Unreal**或**CryEngine**。你还需要决定使用哪个渲染管线，这取决于游戏引擎本身。例如，Unity游戏引擎有不同的渲染管线，如**内置渲染管线（BRP）**、**高清渲染管线（HDRP）**、**通用渲染管线（URP）**和**可脚本渲染管线（SRP）**。渲染管线的选择也取决于你想要达到的
    photorealism 程度。此外，一些游戏引擎可能支持各种编程语言，例如支持C++和C#的CryEngine。因此，你可能需要决定使用哪种语言。
- en: After this, we need to determine the assets to use, such as objects, materials,
    visual effects, and sound effects. At the same time, you may need to consider
    the budget, timeframe, and the skills of your team.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，我们需要确定要使用的资产，例如对象、材料、视觉效果和声音效果。同时，你可能需要考虑预算、时间框架以及你团队的技能。
- en: Modeling
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 建模
- en: The next step, after creating a solid idea about the 3D virtual world, is to
    start the modeling stage. **3D modeling** is the process of creating 3D objects
    using appropriate modeling software. 3D modeling is widely used in the game and
    entertainment industries, engineering fields, and architecture. To build the 3D
    virtual world, we need to create its elements, such as buildings, trees, pedestrians,
    and vehicles. Thus, we need to decide whether to import or model these elements.
    We can do 3D modeling using software such as *Blender* ([https://www.blender.org](https://www.blender.org)),
    *ZBrush* ([https://pixologic.com](https://pixologic.com)), and *3ds Max* ([https://www.autodesk.co.uk/products/3ds-max](https://www.autodesk.co.uk/products/3ds-max)).
    As you may expect, a straightforward solution is importing these elements from
    websites such as *Adobe 3D Substance* ([https://substance3d.adobe.com](https://substance3d.adobe.com))
    and *Turbosquid* ([https://www.turbosquid.com](https://www.turbosquid.com)). However,
    high-quality 3D models are usually expensive. Additionally, it should be noted
    that modeling complex 3D objects can be a challenging and time-consuming process
    that requires technical skills, effort, and time, but that depends on the object
    being modeled and technical constraints such as the polygon count.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在对3D虚拟世界有一个明确的概念之后，下一步是开始建模阶段。**3D建模**是使用适当的建模软件创建3D对象的过程。3D建模在游戏和娱乐行业、工程领域和建筑领域得到广泛应用。为了构建3D虚拟世界，我们需要创建其元素，如建筑、树木、行人和车辆。因此，我们需要决定是导入还是建模这些元素。我们可以使用如*Blender*
    ([https://www.blender.org](https://www.blender.org))、*ZBrush* ([https://pixologic.com](https://pixologic.com))和*3ds
    Max* ([https://www.autodesk.co.uk/products/3ds-max](https://www.autodesk.co.uk/products/3ds-max))等软件进行3D建模。正如你所预期的那样，一个简单的解决方案是从如*Adobe
    3D Substance* ([https://substance3d.adobe.com](https://substance3d.adobe.com))和*Turbosquid*
    ([https://www.turbosquid.com](https://www.turbosquid.com))等网站导入这些元素。然而，高质量的3D模型通常价格昂贵。此外，需要注意的是，建模复杂的3D对象可能是一个具有挑战性且耗时的过程，需要技术技能、努力和时间，但这取决于要建模的对象和技术约束，如多边形数量。
- en: '![Figure 6.3 – An example of a 3D car model (right) created from a car sketch
    (left)](img/Figure_06_03_B18494.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图6.3 – 从汽车草图（左）创建的3D汽车模型示例（右）](img/Figure_06_03_B18494.jpg)'
- en: Figure 6.3 – An example of a 3D car model (right) created from a car sketch
    (left)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – 从汽车草图（左）创建的3D汽车模型示例（右）
- en: '*Figure 6**.3* shows an example of the output that we get after the modeling
    stage, which is a car in this instance.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.3* 展示了建模阶段后的输出示例，在这个例子中是一个汽车。'
- en: Materialization and texturing
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 材质化与纹理化
- en: After creating a 3D model or a mesh, we need to add the physical properties
    of this object, such as the color, transparency, and reflectivity. These properties
    simulate the matter and the surface of the objects. On the other hand, texturing
    is used to simulate surface details such as scratches and patterns and to give
    the object a non-uniform appearance similar to the object’s appearance in the
    real world. In most game engines, this information is encoded using a texture
    map. *Figure 6**.4* shows a 3D object after the materialization and texturing
    process.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建3D模型或网格后，我们需要添加该对象的物理属性，如颜色、透明度和反射性。这些属性模拟了物体和表面的物质。另一方面，纹理化用于模拟表面细节，如划痕和图案，并使物体呈现出类似真实世界物体的非均匀外观。在大多数游戏引擎中，这些信息使用纹理图进行编码。*图6.4*
    展示了经过材质化和纹理化过程的3D对象。
- en: '![Figure 6.4 – A 3D object before (left) and after (right) materialization
    and texturing](img/Figure_06_04_B18494.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图6.4 – 材质化与纹理化前后（左）和（右）的3D对象](img/Figure_06_04_B18494.jpg)'
- en: Figure 6.4 – A 3D object before (left) and after (right) materialization and
    texturing
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 材质化与纹理化前后（左）和（右）的3D对象
- en: Integration into the game engine
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成到游戏引擎中
- en: 'When the elements of the 3D virtual world are ready, we need to add them to
    our scene. We also need to configure and set up lighting and a virtual camera:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当3D虚拟世界的元素准备就绪后，我们需要将它们添加到场景中。我们还需要配置和设置照明和虚拟相机：
- en: '**Lighting**: This is an essential step for creating photorealistic scenes.
    Lights are added to the virtual worlds to give a sense of depth and atmosphere.
    There are usually two options for lighting: **pre-rendered lighting** using lightmaps
    and **real-time lighting**. Lighting is fundamental but it is expensive computation-wise.
    Thus, you should pay attention to this step to achieve your target photorealism
    and frame rate.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**照明**：这是创建逼真场景的一个关键步骤。在虚拟世界中添加灯光以赋予深度和氛围感。通常有两种照明选项：**预渲染照明**使用光照贴图和**实时照明**。照明是基础但计算成本高昂。因此，你应该注意这一步以达到你的目标逼真度和帧率。'
- en: '**Virtual camera**: Once the virtual world is generated, a virtual camera is
    utilized to capture the required synthetic data. The behavior of the camera is
    usually controlled using a script. The camera parameters and behaviors can be
    configured to match the real-world scenario and to achieve the intended behavior.
    Camera parameters include **Field of View (FoV)**, **Depth of Field (DoF)**, **Sensor
    Size**, and **Lens Shift**.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**虚拟相机**：一旦生成虚拟世界，就使用虚拟相机来捕获所需的合成数据。相机的行为通常使用脚本进行控制。相机的参数和行为可以配置以匹配现实世界场景并实现预期的行为。相机参数包括**视场角（FoV）**、**景深（DoF）**、**传感器尺寸**和**镜头位移**。'
- en: Polishing and testing
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精炼和测试
- en: The last step is to examine the generated synthetic data and iterate on the
    virtual world design. In this stage, you can fix bugs and optimize the performance.
    As expected, creating a 3D virtual world is not a simple process. It requires
    effort, time, and technical skills. However, once the virtual world is created,
    it can be leveraged to generate large-scale synthetic datasets for enormous applications.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是检查生成的合成数据，并对虚拟世界设计进行迭代。在这个阶段，你可以修复错误并优化性能。正如预期的那样，创建3D虚拟世界不是一个简单的过程。它需要努力、时间和技术技能。然而，一旦虚拟世界创建完成，它可以被利用来生成用于大量应用的大规模合成数据集。
- en: Setting up the virtual camera
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置虚拟相机
- en: In the virtual world, the camera plays a vital role in the synthetic data generation
    process. It represents the observer, and it is usually utilized to capture images,
    audio, and videos. The captured data may be used for training and testing ML models.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在虚拟世界中，相机在合成数据生成过程中起着至关重要的作用。它代表观察者，通常用于捕获图像、音频和视频。捕获的数据可能用于训练和测试机器学习模型。
- en: As we have mentioned previously, camera properties and attributes can be customized
    and configured to achieve the target behavior. For example, the camera FoV controls
    how much of the world your observer agent can perceive, and therefore, how much
    visual information you can capture in a single generated image. *Figure 6**.5*
    shows two images generated with different FoV values.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，相机属性和属性可以被自定义和配置以达到目标行为。例如，相机的视场角（FoV）控制你的观察者代理可以感知的世界部分，因此，你可以在一个生成的图像中捕获多少视觉信息。*图6.5*显示了使用不同视场角值生成的两个图像。
- en: '![Figure 6.5 – A scene captured using two different FoVs in the Unreal game
    engine](img/Figure_06_05_B18494.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图6.5 – 使用虚幻游戏引擎中的两种不同视场角（FoV）捕获的场景](img/Figure_06_05_B18494.jpg)'
- en: Figure 6.5 – A scene captured using two different FoVs in the Unreal game engine
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 使用虚幻游戏引擎中的两种不同视场角（FoV）捕获的场景
- en: Please note that the camera position is fixed, and we only changed the FoV.
    Additionally, we can control the camera motion and transition to achieve the required
    behavior.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，相机位置是固定的，我们只改变了视场角。此外，我们可以控制相机的运动和过渡以达到所需的行为。
- en: 'The camera can take different setups in the 3D virtual world to imitate the
    relevant ones in the real world. These are some examples of camera setups:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 相机可以在3D虚拟世界中采取不同的设置来模仿现实世界中的相关设置。以下是一些相机设置的示例：
- en: '**Fixed camera**: The camera does not change its location or orientation while
    it captures the scene. This camera setup can be used to record the scene from
    a specific viewpoint. It is the simplest setup; it is easy to implement, and it
    does not require scripting. However, you need to pay attention to the position
    and the attributes of the camera. Otherwise, dynamic objects may accidentally
    block the view of the camera. In simulators and game engines, a fixed camera can
    be used, for instance, to imitate a traffic monitoring camera or a fixed camera
    used in sports broadcasting.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**固定摄像机**: 在捕捉场景时，摄像机不会改变其位置或方向。这种摄像机设置可以用来从特定的视角记录场景。这是最简单的设置；它易于实现，且不需要脚本。然而，你需要注意摄像机的位置和属性。否则，动态物体可能会意外地阻挡摄像机的视线。在模拟器和游戏引擎中，可以使用固定摄像机，例如，来模拟交通监控摄像机或体育直播中使用的固定摄像机。'
- en: '**PTZ camera**: This is a special type of camera setup in which the camera
    can pan, tilt, and zoom. In the real world, this type is usually controlled by
    an operator to capture an object of interest or a specific event. Thus, the camera
    can change its orientation and FoV to realize that. In a virtual world, the camera
    can be programmed to achieve that, or it can be controlled by a human operator
    during simulation or the synthetic data generation process. This setup gives you
    more freedom to capture the scene. However, it may require scripting to achieve
    the intended camera behavior.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PTZ摄像机**: 这是一种特殊的摄像机设置，其中摄像机可以平移、倾斜和缩放。在现实世界中，这种类型通常由操作员控制，以捕捉感兴趣的物体或特定事件。因此，摄像机可以改变其方向和视野来实现这一点。在虚拟世界中，摄像机可以通过编程来实现这一点，或者可以在模拟或合成数据生成过程中由人工操作员控制。这种设置为您提供了更多的自由度来捕捉场景。然而，可能需要脚本来实现预期的摄像机行为。'
- en: '**First-person camera**: First-person vision is a fundamental field in computer
    vision. This camera setup simulates an agent observing the world by wearing a
    camera. It has enormous applications in gaming and virtual reality, law enforcement,
    medicine, and education. For example, an ML model trained on first-person data
    can be used to assist surgeons and improve training, decision-making, performance,
    and accuracy. For a detailed discussion, refer to *Artificial Intelligence for
    Intraoperative Guidance: Using Semantic Segmentation to Identify Surgical Anatomy
    During Laparoscopic* *Cholecystectomy* ([https://pubmed.ncbi.nlm.nih.gov/33196488](https://pubmed.ncbi.nlm.nih.gov/33196488)).'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一人称摄像机**: 第一人称视角是计算机视觉的一个基本领域。这种摄像机设置通过佩戴摄像机来模拟代理观察世界。它在游戏和虚拟现实、执法、医学和教育等领域有巨大的应用。例如，在第一人称数据上训练的机器学习模型可以用来协助外科医生并提高培训、决策、表现和准确性。有关详细讨论，请参阅*人工智能辅助手术指导：使用语义分割在腹腔镜胆囊切除术中识别手术解剖*
    ([https://pubmed.ncbi.nlm.nih.gov/33196488](https://pubmed.ncbi.nlm.nih.gov/33196488))。'
- en: '**Aerial or UAV camera**: This camera setup is key for flight and drone simulators.
    It simulates a camera mounted on a drone or UAV. Usually, it is used to simulate
    a birds-eye view of the scene. It has a wide spectrum of applications and can
    be used to enhance the performance of ML models that require training images captured
    using drones. It supports various computer vision tasks, such as object detection,
    classification, tracking, and recognition.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空中或无人机摄像机**: 这种摄像机设置对于飞行和无人机模拟器至关重要。它模拟了安装在无人机或无人机上的摄像机。通常，它用于模拟场景的鸟瞰视图。它具有广泛的应用范围，可以用来增强需要使用无人机捕获的训练图像的机器学习模型的表现。它支持各种计算机视觉任务，如目标检测、分类、跟踪和识别。'
- en: '**Stereoscopic camera**: A stereo camera is a special type of camera with two
    lenses separated by a short distance that can be leveraged to simulate how humans
    perceive depth. The distance between the two lenses is called **intra-ocular distance**
    and it is usually similar to the distance between a human’s eyes: approximately
    6.35 cm. This distance is essential for creating a sense of depth in the vision
    system. This type of camera is important for VR and immersive 3D experiences.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**立体摄像机**: 立体摄像机是一种特殊的摄像机，具有两个相距较近的镜头，可以利用它们来模拟人类感知深度的方式。两个镜头之间的距离称为**眼间距**，通常与人类眼睛之间的距离相似：大约6.35厘米。这个距离对于在视觉系统中创造深度感至关重要。这种类型的摄像机对于VR和沉浸式3D体验非常重要。'
- en: '**Tracking camera**: This type is used to track an object of interest. In the
    virtual world, this camera can be programmed to follow the desired object, which
    facilitates creating large-scale synthetic data focused on a target object. For
    example, it is possible to track a human in the virtual world for an action recognition
    task. This will help you to generate large-scale training data focused on your
    subject (human). It is possible to use other camera setups, but you will end up
    having many videos with no actions or where your object of interest is not apparent.
    Additionally, you may use this camera setup for visual object tracking and other
    similar tasks.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跟踪相机**：这种类型用于跟踪感兴趣的对象。在虚拟世界中，这种相机可以被编程来跟随所需的对象，这有助于创建专注于目标对象的大规模合成数据。例如，在虚拟世界中跟踪人类进行动作识别任务是可能的。这将帮助你生成专注于你的主题（人类）的大规模训练数据。你也可以使用其他相机设置，但最终你会得到很多没有动作或你的感兴趣对象不明显的视频。此外，你也可以使用这种相机设置进行视觉目标跟踪和其他类似任务。'
- en: The next step is adding noise.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是添加噪声。
- en: Adding noise and anomalies
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加噪声和异常
- en: The real world is not perfect and has anomalies. In the context of image generation,
    noise and anomalies refer to a deviation from the main pattern, process, and phenomenon.
    For example, when we observe street light poles at night, a small portion of them
    may have been accidentally turned off, the light may be flickering, the pole may
    be slightly rotated, painted a different color, or have different dimensions.
    Adding noise and anomalies to the attributes and behaviors of virtual world elements
    improves realism and boosts the usability of the generated synthetic data. Another
    example regarding anomalies in behavior can be seen when observing pedestrians
    crossing the road. The majority wait for the green light or walk signal, look
    both ways, and cross on the crosswalk. On the other hand, a small portion may
    cross the road when the red light is on or may cross without paying attention
    to oncoming cars. This behavior anomaly, for example, should be simulated in the
    virtual world to ensure that the generated training data is diverse. Thus, training
    an ML model on this data will ensure a robust ML model.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界并不完美，存在异常。在图像生成的背景下，噪声和异常指的是对主要模式、过程和现象的偏离。例如，当我们观察夜晚的街灯柱时，其中一小部分可能被意外关闭，灯光可能闪烁，柱子可能略微旋转，涂上不同的颜色，或者有不同的尺寸。向虚拟世界元素的属性和行为中添加噪声和异常可以提高现实感并提高生成合成数据的使用性。关于行为异常的另一个例子可以在观察行人过马路时看到。大多数人会等待绿灯或行人信号，两边看，然后在斑马线上过马路。另一方面，一小部分人可能会在红灯亮时过马路，或者可能没有注意到来车而过马路。这种行为异常，例如，应该在虚拟世界中模拟，以确保生成的训练数据多样化。因此，在这个数据上训练ML模型将确保一个鲁棒的ML模型。
- en: Setting up the labeling pipeline
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置标注流程
- en: The labeling pipeline depends on your problem and how you plan to utilize the
    synthetic data. You may want to just generate the training data because it is
    too expensive in the real world, and you may prefer to ask human annotators to
    annotate your data. On the other hand, it is possible that you want to automate
    the annotation process in the simulator or the rendering engine. Simulators such
    as CARLA, NOVA, and Silver support generating the data with its corresponding
    ground truth for various computer vision tasks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 标注流程取决于你的问题和计划如何利用合成数据。你可能只想生成训练数据，因为现实世界中这太昂贵了，你可能更愿意请人类标注员标注你的数据。另一方面，你可能希望在模拟器或渲染引擎中自动化标注过程。例如，CARLA、NOVA和Silver等模拟器支持为各种计算机视觉任务生成带有相应真实值的数据。
- en: Generating the training data with the ground truth
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用真实值生成训练数据
- en: At this point, the synthetic data generation pipeline should be ready. The previous
    steps can be challenging, costly, and time-consuming. However, they are only required
    to set up the system. Following this, you can leverage the system to generate
    your task-specific, automatically annotated, large-scale datasets. Changing the
    annotating protocol is simple and is not expensive compared to real-world datasets.
    Please note that we have not provided hands-on examples on how to generate synthetic
    data using game engines or simulators because the focus of the book is not on
    the implementation and coding of synthetic data generation approaches. However,
    it is committed to the theoretical, conceptual, and design aspects of the process.
    For more details about the implementation and coding aspects, please refer to
    Unity Computer Vision ([https://unity.com/products/computer-vision](https://unity.com/products/computer-vision))
    and Synthetic for Computer Vision ([https://github.com/unrealcv/synthetic-computer-vision](https://github.com/unrealcv/synthetic-computer-vision)).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，合成数据生成管道应该已经准备好了。之前的步骤可能具有挑战性、成本高昂且耗时。然而，它们仅用于设置系统。在此之后，您可以利用该系统生成特定任务、自动标注的大规模数据集。更改标注协议简单且与真实世界数据集相比成本不高。请注意，我们没有提供使用游戏引擎或模拟器生成合成数据的手动示例，因为本书的重点不在于合成数据生成方法的实现和编码。然而，它致力于该过程的理论、概念和设计方面。有关实现和编码方面的更多详细信息，请参阅Unity计算机视觉([https://unity.com/products/computer-vision](https://unity.com/products/computer-vision))和合成计算机视觉([https://github.com/unrealcv/synthetic-computer-vision](https://github.com/unrealcv/synthetic-computer-vision))。
- en: In the next section, you will learn about the main limitations of deploying
    this synthetic data generation approach.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将了解部署此合成数据生成方法的主要限制。
- en: Challenges and limitations
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**挑战与限制**'
- en: In this section, we will highlight the main challenges in using this approach
    for synthetic data generation. We will look at realism, diversity, and complexity
    issues that present some difficulties in utilizing this approach for synthetic
    data generation.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将强调使用此方法进行合成数据生成的主要挑战。我们将探讨现实主义、多样性和复杂性问题，这些问题在使用此方法进行合成数据生成时带来一些困难。
- en: Realism
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**现实主义**'
- en: The **domain gap** between synthetic and real data is one of the main issues
    that limit the usability of synthetic data. For synthetic data to be useful, it
    should mimic the distribution and statistical characteristics of its real counterparts.
    Thus, for computer vision problems, we need to ensure a high degree of photorealism,
    otherwise, ML models trained on synthetic data may not generalize well to real
    data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据与真实数据之间的**领域差距**是限制合成数据可用性的主要问题之一。为了使合成数据有用，它应该模仿其真实对应物的分布和统计特性。因此，对于计算机视觉问题，我们需要确保高度的真实感，否则，在合成数据上训练的机器学习模型可能无法很好地推广到真实数据。
- en: Achieving a high degree of photorealism using game engines and simulators is
    not a simple task. Even with the help of contemporary game engines such as CryEngine,
    Unreal, and Unity, we need effort, skill, and time to create photorealistic scenes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使用游戏引擎和模拟器实现高度的真实感并非易事。即便借助当代游戏引擎如CryEngine、Unreal和Unity，我们仍需付出努力、技巧和时间来创建真实感场景。
- en: The three essential elements for approaching realism and thus mitigating the
    domain gap problem for synthetic data generated by game engines and simulators
    are as follows.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 接近现实主义并因此减轻由游戏引擎和模拟器生成的合成数据的领域差距问题的三个基本要素如下。
- en: Photorealism
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**真实感**'
- en: 'Generating photorealistic images, for computer vision problems, is vital for
    training and testing ML models. Building photorealistic scenes requires the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于计算机视觉问题，生成真实感图像对于训练和测试机器学习模型至关重要。构建真实感场景需要以下条件：
- en: '**High-quality assets**: The 3D models, textures, and materials should be detailed
    and realistic.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高质量资产**：3D模型、纹理和材料应该详细且逼真。'
- en: '**Lighting**: It is essential for rendering photorealistic scenes. You may
    need to use physically based rendering and physically based materials. Additionally,
    you need to use suitable light sources and carefully configure their parameters.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**光照**：对于渲染真实感场景至关重要。您可能需要使用基于物理的渲染和基于物理的材料。此外，您还需要使用合适的光源并仔细配置它们的参数。'
- en: '**Postprocessing**: Game engines such as Unreal and Unity support postprocessing
    effects to improve photorealism. For example, you can use these techniques to
    simulate motion blur, gloom, and depth of field.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Realistic behavior
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To achieve this, we need to ensure realistic camera behavior. For example, the
    camera should not penetrate walls and its parameters should be close to real-world
    camera ones. Additionally, character animations should be realistic and emulate
    human body movement. Furthermore, scene element interactions should obey physics
    rules, for example, when objects collide.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Realistic distributions
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Objects and attributes are not randomly distributed in the real world. Thus,
    when building virtual worlds, we need to pay attention to matching these distributions
    as well. For example, people walking near shopping malls may have a higher probability
    of carrying objects. At the same time, under certain weather conditions, specific
    actions and objects may become more frequent or less. For example, in rainy weather
    conditions, pedestrians may carry umbrellas.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Diversity
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The world around us is remarkably varied and contains a multitude of elements
    that come in diverse colors, shapes, and behaviors, and possess different properties.
    Attaining a diverse virtual world requires time and effort. The usability of synthetic
    data comes from its primary advantage of generating large-scale datasets for training
    ML models. If the data is not diverse enough, this will cause ML models to overfit
    limited scenarios and attributes.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Complexity
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Nonlinearity, interdependence, uncertainty, and the dynamic nature of the real
    world make creating a realistic virtual world rather a complex task. Creating
    and simulating a realistic environment requires approximations, simplifications,
    and generalizations. This is necessary because of the trade-off between realism
    and computational complexity. Building a realistic virtual world that captures
    all real-world properties, phenomena, and processes is simply not feasible, even
    with state-of-the-art software and hardware. However, we can still approach an
    acceptable level of realism with a careful understanding of the ML problem: what
    is essential and what is auxiliary for this particular application? For example,
    if we would like to generate synthetic data for a face recognition task, we may
    need to pay extra attention to simulating photorealistic faces as compared to
    other elements in the scene.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Looking at two case studies
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will briefly discuss two well-known simulators for synthetic
    data generation, and comment on the potential of using these approaches.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: AirSim
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'AirSim is an open source, cross-platform simulator developed by Microsoft using
    the Unreal game engine. It simulates drones and cars, opening the door for enormous
    applications in computer vision for DL and RL approaches for autonomous driving.
    Some of the key features of this simulator include the following:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Various weather effects and conditions
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LIDAR and infrared sensors
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customizable environment
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Realistic physics, environments, and sensors
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, AirSim can be leveraged to generate rich, large-scale, and high-quality
    synthetic data from various sensors. Researchers in ML can train their models
    to fuse the different data modalities to develop more robust autonomous driving
    algorithms. Additionally, AirSim provides automatically labeled synthetic data
    for depth estimation, semantic segmentation, and surface normal estimation tasks.
    For more information about this simulator, please refer to *AirSim* ([https://www.microsoft.com/en-us/AI/autonomous-systems-project-airsim](https://www.microsoft.com/en-us/AI/autonomous-systems-project-airsim)).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: CARLA
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'CARLA is an open source simulator for autonomous driving. It was developed
    using the Unreal game engine by **Computer Vision Centre** (**CVC**), Intel, and
    Toyota. CARLA is a well-known simulator for synthetic data generation. It has
    a traffic manager system and users can configure several sensors, which include
    depth sensors, LIDARs, multiple cameras, and **Global Positioning System** (**GPS**).
    CARLA generates synthetic data for a number of computer vision tasks, such as
    semantic segmentation, depth estimation, object detection, and visual object tracking.
    In addition to generating automatically labeled and large-scale synthetic data,
    CARLA can be deployed to generate diverse traffic scenarios. Then, researchers
    can utilize the generated synthetic data to train more accurate and robust ML
    models on a myriad of driving scenarios. Please check the project’s *CARLA* web
    page ([https://carla.org](https://carla.org)) and the *CARLA: An Open Urban Driving
    Simulator* paper ([http://proceedings.mlr.press/v78/dosovitskiy17a/dosovitskiy17a.pdf](http://proceedings.mlr.press/v78/dosovitskiy17a/dosovitskiy17a.pdf))
    for more details.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: There are many other simulators, such as Silver, AI Habitat, SynthCity, and
    IGibson. Creating a more realistic simulator, supporting more tasks, making the
    simulator easier to use, and the virtual environment more customizable are the
    main research directions in developing future synthetic data generators using
    game engines and simulators.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced a well-known method for synthetic data generation
    based on simulators and rendering engines. We learned how to generate synthetic
    data. We highlighted the main challenges and we discussed AirSim and CARLA simulators
    as examples of this data generation approach. We have seen that by using simulators
    and game engines, we can generate large-scale, rich, and automatically annotated
    synthetic data for many applications. It reduces the cost and effort and provides
    an ideal solution for training robust ML models.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about a new method for synthetic data generation
    using **Generative Adversarial** **Networks** (**GANs**).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
