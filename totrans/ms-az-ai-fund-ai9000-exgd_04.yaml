- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Describe Core Machine Learning Concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, you were introduced to some basic **machine learning**
    (**ML**) concepts, including various models and scenarios where a particular type
    of model might be useful. In this chapter, we’re going to explore concepts surrounding
    the actual data used in ML.
  prefs: []
  type: TYPE_NORMAL
- en: 'The objectives and skills we’ll cover in this chapter include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify features and labels in a dataset for machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describe how training and validation datasets are used in machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you should be able to clearly articulate the terminology
    surrounding ML.
  prefs: []
  type: TYPE_NORMAL
- en: Identify features and labels in a dataset for machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you learned in [*Chapter 3*](B22207_03.xhtml#_idTextAnchor042), *Identify
    Common Machine Learning Techniques*, **features** and **labels** are two fundamental
    concepts that define the data you work with when training ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Features are individual measurable properties or characteristics of whatever
    is being observed. In ML models, features are used as input variables. These are
    the data points that you use to make predictions. For example, if you’re trying
    to predict the price of a house, the features might include the number of bedrooms,
    the size of the house in square feet, the neighborhood it’s in, how close it is
    to a fire station, or what the local property tax rates are. Features are represented
    by independent variables in your dataset that you believe will help you make accurate
    predictions about your target variable.
  prefs: []
  type: TYPE_NORMAL
- en: Labels, on the other hand, are the output you’re trying to predict or classify.
  prefs: []
  type: TYPE_NORMAL
- en: In **supervised learning** (**SL**), each training example includes a label.
    Continuing with the house pricing example, the label would be the actual selling
    price of the house.
  prefs: []
  type: TYPE_NORMAL
- en: In classification tasks, labels are the categories assigned to data points.
    For instance, in an ML model trained to identify whether an email is spam or not,
    the labels might be “`spam`” and “`not spam`.”
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll dive a little deeper into working with features and labels
    in your datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying features in a dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Identifying features in an ML dataset involves understanding variables that
    can be used to predict the outcome (target variable). There are many things you
    can do to narrow down what’s important for your ML model.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go through them in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the problem domain
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Begin by understanding the domain or context of the problem. This involves researching
    the subject area to understand what factors might influence the outcome. For example,
    if you are working on a project to predict house prices, potential features could
    include the size of the house, the number of bedrooms, the number of bathrooms,
    the year it was built, the location, distance to fire stations, number of public
    libraries in the area, and statistics on the local school system.
  prefs: []
  type: TYPE_NORMAL
- en: When working through this step, it would likely be helpful to speak with domain
    experts to understand important variables. You could also look for existing literature,
    research, or studies to identify common predictors or variables used in similar
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Gather your data from relevant sources. This could include databases, reports,
    files, external APIs connected to industry data sources, or direct measurements.
    The data you collect will consist of various attributes or variables. You should
    work to ensure that the data collected is relevant to the problem domain and includes
    variables identified in your research of the subject matter.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you’re working on a model that’s going to predict housing prices,
    you’d likely look at data sources such as recent sale prices of houses in a particular
    zip code. Since you’d identified other features such as school system ratings
    and the distances to fire stations and libraries, you’d need to get that data
    as well—which would likely be from different data sources. You’d need to plot
    the distance from each house to the nearest library and fire station and add the
    dataset that you’ll be training a model with.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Perform **exploratory data analysis** (**EDA**) to get a feel for the data.
    This can include summarizing the statistics of the data, visualizing distributions
    and relationships between variables, and identifying any patterns or anomalies.
    Tools such as histograms, scatter plots, and correlation matrices can be useful
    here. You should also use statistical summaries (such as mean, median, mode, and
    standard deviation) to understand the distribution of each variable and identify
    areas where you have outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of a scatter plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Scatter plot showing the relationship between housing price
    and square footage](img/B22207_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – Scatter plot showing the relationship between housing price and
    square footage
  prefs: []
  type: TYPE_NORMAL
- en: Selecting relevant variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Not all variables in your dataset may be relevant or necessary for predicting
    the outcome. Select variables that are likely to influence the target variable
    based on your domain knowledge and initial data exploration. Variables that show
    a correlation with the target variable are often good candidates for features.
  prefs: []
  type: TYPE_NORMAL
- en: When identifying variables, it’s important to consider the practical significance
    of variables in addition to their statistical significance. For example, going
    back to the housing example, you may have learned that a house’s proximity to
    a library may not have a very big impact. During the EDA, you also may discover
    other variables that may seem important, such as proximity to a shopping center
    or the number of closets and storage areas.
  prefs: []
  type: TYPE_NORMAL
- en: After reviewing your preliminary data, you may discover that you have missing
    attributes or values or that some data may be irrelevant to the problem context.
    Consider discarding that data since it may reduce the effectiveness of your model.
    Continue iterating until you settle in on relevant features.
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This involves creating new features from existing ones through various techniques
    such as binning, aggregation, and combination of attributes. For example, from
    a dataset containing dates, you might extract features such as the day of the
    week, the month, or the year. Or, you may decide to collapse or combine multiple
    date ranges into fewer features.
  prefs: []
  type: TYPE_NORMAL
- en: In the house pricing example, you may decide to aggregate data by month or week
    instead of having individual house prices by day. This may reduce some noise and
    help focus on trends more easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Advanced techniques, such as polynomial features, can help capture non-linear
    relationships. In a house, a non-linear example might be the relationship between
    the number of bathrooms and closets. One method of creating a polynomial feature
    would be by multiplying two unrelated features together. In this example, you
    could multiply the number of bathrooms and closets: a house that has 3 bathrooms
    and 7 closets could have a new feature with a value of 21.'
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering can also involve transforming variables, such as scaling
    or normalizing, to make them more suitable for ML models. For example, you may
    decide to round housing prices to the nearest $25,000 or group houses by the number
    of bedrooms, such as 0-2, 3-4, 5-6, and 7+. Each of these techniques can be used
    to help streamline the data and help produce a clearer set of predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Handling missing values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Decide how to handle missing data in your potential features. You might fill
    in missing values with the mean or median (imputation), discard them, or use a
    model to predict and fill them. Be sure to consider the reasons for missing data
    to determine if it’s random or not.
  prefs: []
  type: TYPE_NORMAL
- en: Removing irrelevant or redundant features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Eliminate features that are irrelevant to the outcome or that duplicate information
    contained in other features. Redundant or irrelevant features can introduce noise
    and lead to overfitting. As you develop the model, you may discover that you need
    to remove features to help refine the model to produce better results.
  prefs: []
  type: TYPE_NORMAL
- en: Consulting with experts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If possible, consult with domain experts to validate your selection of features
    and data sources. They might provide insights into which variables are most influential
    or suggest additional variables that you hadn’t considered, as well as indicate
    any known biases for your data source selections.
  prefs: []
  type: TYPE_NORMAL
- en: Using feature selection techniques
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are automated feature selection techniques such as **forward selection**,
    **backward elimination**, and **recursive feature elimination** that can help
    identify the most important features based on statistical tests or model performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Forward selection**: Forward selection is a feature selection technique used
    to build a model by iteratively adding one feature at a time, starting with the
    most significant or promising feature. The process continues until a stopping
    criterion is met, such as reaching a predetermined number of features or until
    the addition of new features no longer improves the model’s performance significantly.
    For example, with our house pricing example, this might mean starting with overall
    square footage as the most promising feature that has an impact on the price of
    a house, and then in the next iteration, add the number of bedrooms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backward elimination**: This is simply the opposite process of forward selection.
    Instead of adding features until the model doesn’t change, you start with all
    of the features to train a model and take out features until the stopping criterion
    is met—such as the number of features remaining or until the removal of features
    no longer improves the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recursive feature elimination**: Similar to backward elimination, recursive
    feature elimination is a process that starts with a full set of features and then
    removes them. Whereas backward elimination simply removes the least significant
    features, recursive feature elimination removes features based on their importance
    and interaction with other features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You’ll want to temper any automated feature selection tools with domain knowledge,
    expert insight, and data understanding to ensure you’re choosing the most appropriate
    set of features.
  prefs: []
  type: TYPE_NORMAL
- en: Remember—model development is an iterative process. As you build and develop
    your models, you might discover that some features are more important than others
    or that some can be removed without decreasing model performance (in regard to
    accuracy).
  prefs: []
  type: TYPE_NORMAL
- en: Identifying labels in a dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Identifying labels in an ML dataset involves understanding the outcome or target
    variable that your model aims to predict. Here’s how you can identify labels in
    a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the objective
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Start by clearly defining the objective of your ML project. Are you trying to
    predict a continuous value (regression), classify data into categories (classification),
    or identify groups of similar instances (clustering)? Your objective will guide
    what your label should be.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the data
  prefs: []
  type: TYPE_NORMAL
- en: Examine your dataset and understand each variable. In SL, the label is the variable
    that is being predicted, which could be the outcome of an event, the classification
    category, or the future value of a series.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying the target variable
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In most datasets used for SL, there is usually a specific column that serves
    as the target variable (label). This could be a column indicating “Yes” or “No”
    for a binary classification problem, a numerical value for a regression problem,
    or category labels for a multiclass classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: Consulting domain experts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If it’s not clear which variable should be used as the label, consult with domain
    experts or stakeholders of your ML project. They can provide insights into what
    predictions would be most valuable based on the dataset, business outcomes, and
    research objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Use EDA to better understand potential labels. For instance, if you’re working
    with a dataset where the objective is to predict whether an email is spam or not,
    the label could be a column indicating “spam” or “not spam.” Look for a column
    or other output with categorical or binary data that fits the problem you are
    trying to solve.
  prefs: []
  type: TYPE_NORMAL
- en: Checking data documentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If your dataset comes with documentation or a **data dictionary**, review this
    material to understand the role of each variable. Often, the documentation will
    explicitly state which column is the target variable (label) for prediction. If
    the documentation doesn’t identify the label, it may provide insights about existing
    fields or column names to help you determine a label.
  prefs: []
  type: TYPE_NORMAL
- en: Look for pre-labeled data; in some cases, especially in SL tasks, datasets are
    already labeled. This means that for each record, there is an accompanying label
    that has been previously determined. This is common in datasets used for training
    models, where the goal is to learn the relationship between input features and
    labels.
  prefs: []
  type: TYPE_NORMAL
- en: Considering the problem type
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The nature of your label depends on the type of problem you are trying to use
    ML to solve.
  prefs: []
  type: TYPE_NORMAL
- en: For classification, labels are categorical and represent different classes (for
    example, “spam” or “not spam” for binary classification dealing with whether an
    email is junk mail or not; “cat,” “dog,” and “bird” for multiclass classification
    identifying animals from pictures).
  prefs: []
  type: TYPE_NORMAL
- en: For regression, labels are continuous values (such as house prices or temperatures).
  prefs: []
  type: TYPE_NORMAL
- en: For clustering (an **unsupervised learning** (**UL**) task), labels are not
    provided, and the goal is to discover them through the grouping of similar data
    points.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ensure your label data is clean and consistent. This might involve correcting
    mislabeling, handling missing values, and ensuring labels are in a format that
    can be used for modeling (for example, converting strings to numerical categories).
  prefs: []
  type: TYPE_NORMAL
- en: As you develop your model, you may need to revisit and re-evaluate your choice
    of labels (just as you may need to revisit your choice of features). The effectiveness
    of your model in predicting these labels will help you understand if you have
    identified the correct labels or if adjustments are needed.
  prefs: []
  type: TYPE_NORMAL
- en: Describe how training and validation datasets are used in machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In ML, **training** and **validation** sets are subsets of your overall dataset
    used during the model development phase. Their roles are distinct but complementary,
    aimed at creating a model that is able to make accurate predictions about new,
    unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: You may recall seeing the concepts of training and validation sets in [*Chapter
    3*](B22207_03.xhtml#_idTextAnchor042)*, Identify Common Machine Learning Techniques*
    when we discussed dividing the dataset into sections—a subset that would be used
    to train the model, and a “held back” or “reserved” part of the data that we could
    use to test the predictions. These are the training and validation sets, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Training set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is the data on which the ML model is trained. The model learns to make
    predictions or decisions based on this data. The training set is used to fit the
    parameters of the model, such as the weights in a **neural network** (**NN**)
    or the coefficients in linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: The training set in ML is the actual dataset used to train the model. Training
    involves adjusting the model’s parameters to minimize errors, typically through
    a process known as learning. The size and quality of the training set can significantly
    influence the performance of the ML model. A larger training set provides more
    examples from which the model can learn, potentially leading to better generalization
    when the model is used to make predictions on new data. However, the data must
    also be representative of the real-world scenario the model will be applied to,
    encompassing a broad range of examples and variations.
  prefs: []
  type: TYPE_NORMAL
- en: During the training phase, the model iteratively adjusts its parameters to reduce
    the difference between the predicted output and the actual output, as defined
    by a specific mathematical loss function. This process can vary depending on the
    type of model and learning algorithm. For instance, in SL, each example in the
    training set includes both the input features and the corresponding target label.
    The model uses these pairs to learn underlying patterns in the data. In UL, where
    there are no labels, the model tries to learn the underlying structure of the
    data based on the input features alone.
  prefs: []
  type: TYPE_NORMAL
- en: The effectiveness of the training process (in both SL and UL) is largely dependent
    on the quality of the training data, the volume of data in the training set, the
    relevance of the features selected, and the suitability of the model for the problem
    at hand. If possible, training on actual data (as opposed to synthetic data) is
    preferred, as it helps the model learn about natural outliers and variances. Sometimes,
    however, due to privacy or other responsible **artificial intelligence** (**AI**)
    development principles, actual data may not be available.
  prefs: []
  type: TYPE_NORMAL
- en: Generating your own training data
  prefs: []
  type: TYPE_NORMAL
- en: You may also want to consider asking a **generative AI** (**GenAI**) model to
    create training data for you. This may be useful in helping you understand relationships
    between features or protecting privacy if a potential dataset contains personal
    information. However, training data generated by an AI model can also amplify
    any bias in the data that was used to train the generative model, leading to skewed
    or unrealistic training data. In either case, when using GenAI, you’ll need to
    take precautions to ensure that the data is representative of what you’re trying
    to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, the training set constitutes a larger portion of the entire dataset,
    often ranging from 60% to 80%. The aim is to provide the model with a diverse
    and comprehensive set of examples that mirror the real-world scenarios in which
    it will be applied.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re asking yourself, “How do I know if the model is trained well enough?”
    or “How will I know when I’m done training?” that’s where validation sets come
    in.
  prefs: []
  type: TYPE_NORMAL
- en: Validation set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This subset of the dataset is used to provide an unbiased evaluation of a model
    fit on the training dataset while tuning the model’s **hyperparameters** (settings
    or configurations that are not learned from the data) that the model is unable
    to adjust automatically. The validation set acts as a proxy for the test set since
    it is not used for training the model and hence can help in estimating how well
    the model has generalized to unseen data. Typically, the validation set might
    be about 20% to 30% of the entire dataset.
  prefs: []
  type: TYPE_NORMAL
- en: It is crucial to avoid **overfitting** (sometimes referred to as **overtraining**),
    a situation where the model performs well on the training data but poorly on new,
    unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: What’s a hyperparameter?
  prefs: []
  type: TYPE_NORMAL
- en: An ML model hyperparameter is a configuration setting that is external to the
    model and influences its learning process. Unlike model parameters, which are
    learned from the training data, hyperparameters are predefined by the user and
    affect aspects such as model complexity, regularization, and optimization. Examples
    include the learning rate in gradient descent, the depth of a decision tree, or
    the number of hidden layers in an NN. Hyperparameter tuning is crucial for optimizing
    model performance. Don’t worry, though—from the perspective of the *AI-900* exam,
    the important concept is that hyperparameters are external to the model.
  prefs: []
  type: TYPE_NORMAL
- en: Using a validation set helps detect issues such as **overfitting**. Overfitting
    happens when a model learns noise or random fluctuations in the training data
    instead of actual underlying patterns. By evaluating the model on the validation
    set, you can identify when overfitting is occurring and take steps to mitigate
    it, such as simplifying the model, applying regularization techniques, or obtaining
    more training data.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the validation set allows for the comparison of different models
    and configurations in a controlled manner. After the model has been trained on
    the training set, its performance on the validation set provides an unbiased evaluation.
    Only after the model has been optimized and selected based on its performance
    on the validation set should it be tested on the test set to assess its generalization
    capabilities to new, unseen data. This approach ensures that the final evaluation
    of the model is based on data that has not been used during the training or validation
    phases, providing a more accurate measure of its predictive performance and generalization
    ability.
  prefs: []
  type: TYPE_NORMAL
- en: The process usually involves training the model on the training set and then
    evaluating its performance on the validation set. Based on this evaluation, adjustments
    can be made to the model’s configuration. Once the model performs satisfactorily
    on the validation set, it can then be tested on a separate test set to further
    evaluate its performance in a completely unseen data scenario. This practice helps
    ensure that the model is not just memorizing the training data but actually learning
    patterns that are generalizable.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter expanded on concepts relating to data in regard to ML. You learned
    about techniques for identifying features and labels in datasets as well as techniques
    for ensuring data is suitable for learning. You learned about the concepts and
    purposes of both the training set and validation set as well.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll dive a little deeper into Azure Machine Learning
    concepts and capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Exam Readiness Drill – Chapter Review Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apart from a solid understanding of key concepts, being able to think quickly
    under time pressure is a skill that will help you ace your certification exam.
    That is why working on these skills early on in your learning journey is key.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter review questions are designed to improve your test-taking skills progressively
    with each chapter you learn and review your understanding of key concepts in the
    chapter at the same time. You’ll find these at the end of each chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Before you proceed
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have a Packt Library subscription or you haven't purchased this
    book from the Packt store, you will need to unlock the online resources to access
    the exam readiness drills. Unlocking is free and needs to be done only once. To
    learn how to do that, head over to the chapter titled [*Chapter 12*](B22207_12.xhtml#_idTextAnchor228)*,
    Accessing the* *Online Resources*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To open the Chapter Review Questions for this chapter, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click the link – [https://packt.link/AI-900_CH04](https://packt.link/AI-900_CH04).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, you can scan the following QR code (*Figure 4**.2*):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.2 – QR code that opens Chapter Review Questions for logged-in users](img/B22207_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – QR code that opens Chapter Review Questions for logged-in users
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you log in, you’ll see a page similar to the one shown in *Figure 4**.3*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Chapter Review Questions for Chapter 4](img/B22207_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Chapter Review Questions for Chapter 4
  prefs: []
  type: TYPE_NORMAL
- en: Once ready, start the following practice drills, re-attempting the quiz multiple
    times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exam Readiness Drill
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the first three attempts, don’t worry about the time limit.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first time, aim for at least **40%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix your learning gaps.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The second time, aim for at least **60%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix any remaining learning
    gaps.
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The third time, aim for at least **75%**. Once you score 75% or more, you start
    working on your timing.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: You may take more than **three** attempts to reach 75%. That’s okay. Just review
    the relevant sections in the chapter till you get there.
  prefs: []
  type: TYPE_NORMAL
- en: Working On Timing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your aim is to keep the score the same while trying to answer these questions
    as quickly as possible. Here’s an example of how your next attempts should look
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Attempt** | **Score** | **Time Taken** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 5 | 77% | 21 mins 30 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 6 | 78% | 18 mins 34 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Attempt 7 | 76% | 14 mins 44 seconds |'
  prefs: []
  type: TYPE_TB
- en: Table 4.1 – Sample timing practice drills on the online platform
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The time limits shown in the above table are just examples. Set your own time
    limits with each attempt based on the time limit of the quiz on the website.
  prefs: []
  type: TYPE_NORMAL
- en: With each new attempt, your score should stay above **75%** while your “time
    taken” to complete should “decrease”. Repeat as many attempts as you want till
    you feel confident dealing with the time pressure.
  prefs: []
  type: TYPE_NORMAL
