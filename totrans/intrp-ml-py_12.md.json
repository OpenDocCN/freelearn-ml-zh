["```py\nimport math\nimport os\nimport copy\nimport mldatasets\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing, model_selection, metrics,\\\n    linear_model, svm, neural_network, ensemble\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nimport tensorflow as tf\nfrom bayes_opt import BayesianOptimization\nimport tensorflow_lattice as tfl\nfrom tensorflow.keras.wrappers.scikit_learn import\\\n                                                  KerasClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy\nimport xai\nimport shap \n```", "```py\nrecidivism_df = mldatasets.**load**(\"recidivism-risk-balanced\") \n```", "```py\nrecidivism_df.info() \n```", "```py\nRangeIndex: 11142 entries, 0 to 11141\nData columns (total 12 columns):\n#   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n0   sex                      11142 non-null  object\n1   age                      11142 non-null  int64\n2   race                     11142 non-null  object\n3   juv_fel_count            11142 non-null  int64\n4   juv_misd_count           11142 non-null  int64\n5   juv_other_count          11142 non-null  int64\n6   priors_count             11142 non-null  int64\n7   c_charge_degree          11142 non-null  object\n8   days_b_screening_arrest  11142 non-null  float64\n9   length_of_stay           11142 non-null  float64\n10  compas_score             11142 non-null  int64\n11  is_recid                 11142 non-null  int64\ndtypes: float64(2), int64(7), object(3) \n```", "```py\ncategorical_cols_l = [\n    'sex', 'race', 'c_charge_degree', 'is_recid', 'compas_score'\n]\nxai.**imbalance_plot**(\n    recidivism_df,\n    'race',\n    'is_recid',\n    categorical_cols=categorical_cols_l\n) \n```", "```py\nrecidivism_corr_df = recidivism_df.**drop**(\n    ['compas_score'], axis=1\n)\npd.**DataFrame**(\n    {'feature': recidivism_corr_df.columns[:-1],\n     'correlation_to_target':\\\n          scipy.stats.**spearmanr**(recidivism_corr_df).\\\n          correlation[10,:-1]\n    }\n).style.background_gradient(cmap='coolwarm') \n```", "```py\nc_charge_degree category:\n```", "```py\nrecidivism_df.c_charge_degree.**value_counts()** \n```", "```py\n(F3)     6555\n(M1)     2632\n(F2)      857\n(M2)      768\n(F1)      131\n(F7)      104\n(MO3)      76\n(F5)        7\n(F6)        5\n(NI0)       4\n(CO3)       2\n(TCX)       1 \n```", "```py\ncharge_degree_code_rank = {\n    '(F10)': 15, '(F9)':14, '(F8)':13,\\\n    '(F7)':12, '(TCX)':11, '(F6)':10, '(F5)':9,\\\n    '(F4)':8, '(F3)':7, '(F2)':6, '(F1)':5, '(M1)':4,\\\n    '(NI0)':4, '(M2)':3, '(CO3)':2, '(MO3)':1, '(X)':0\n}\nrecidivism_df.c_charge_degree.**replace**(\n    charge_degree_code_rank, inplace=True\n) \n```", "```py\nmldatasets.**plot_prob_progression**(\n    recidivism_df.**c_charge_degree**,\n    recidivism_df.**is_recid**, x_intervals=12,\n    use_quantiles=False,\n    xlabel='Relative Charge Degree',\n    title='Probability of Recidivism by Relative Charge Degree'\n) \n```", "```py\nmldatasets.plot_**prob_progression**(\n    recidivism_df.**age**,\n    recidivism_df.**is_recid**,\n    x_intervals=7,\n    use_quantiles=False,\n    title='Probability of Recidivism by Age Discretized in Fix-Width \\\n    Bins',\n    xlabel='Age'\n)\nmldatasets.**plot_prob_progression**(\n    recidivism_df.**age**,\n    recidivism_df.**is_recid**,\n    x_intervals=7, use_quantiles=True,\n    title='Probability of Recidivism by Age Discretized \\\n    in Quantiles',\n    xlabel='Age'\n) \nFigure 12.4. By looking at the Observations portion of the fixed-width bin plot, you can tell that the histogram for the age feature is right-skewed, which causes the probability to shoot up for the last bin. The reason for this is that some outliers exist in this bin. On the other hand, the fixed-frequency (quantile) plot histogram is more even, and probability consistently decreases. In other words, it’s monotonic—as it should be, according to our domain knowledge on the subject.\n```", "```py\nrecidivism_df['age_group'] = pd.**qcut**(\n    recidivism_df.**age**, 7, precision=0\n).astype(str) \n```", "```py\nmldatasets.plot_**prob_contour_map**(\n    recidivism_df.**age**,\n    recidivism_df.**priors_count**,\n    recidivism_df.**is_recid**,\n    use_quantiles=True,\n    xlabel='Age',\n    ylabel='Priors Count',\n    title='Probability of Recidivism by Age/Priors Discretized in \\\n    Quantiles'\n) \nFigure 12.5, which shows how, when discretized by quantiles, the probability of 2-year recidivism increases, the lower the age and the higher the priors_count. It also shows histograms for both features. priors_count is very right-skewed, so discretization is challenging, and the contour map does not offer a perfectly diagonal progression between the bottom right and top left. And if this plot looks familiar, it’s because it’s just like the partial dependence interaction plots we produced in *Chapter 4*, *Global Model-Agnostic Interpretation Methods*, except it’s not measured against the predictions of a model but the ground truth (is_recid). We must distinguish between what the data can tell us directly and what the model has learned from it.\n```", "```py\nrecidivism_df['priors_per_year'] =\\\n            recidivism_df['priors_count']/(recidivism_df['age'] - 17) \n```", "```py\nmldatasets.**plot_prob_progression**(\n    recidivism_df.**priors_per_year**,\n    recidivism_df.**is_recid**,\n    x_intervals=8,\n    xlabel='Priors Per Year',\n    title='Probability of Recidivism by Priors per Year (\\\n    according to data)'\n) \n```", "```py\nrecidivism_df.loc[recidivism_df.priors_per_year > 3,\\\n                  'priors_per_year'] = -1 \n```", "```py\nmldatasets.**plot_prob_contour_map**(\n    recidivism_df.**age_group**,\n    recidivism_df.**priors_per_year**,\n    recidivism_df.**is_recid**,\n    y_intervals=6,\n    use_quantiles=True,\n    xlabel='Age Group',\n    title='Probability of Recidivism by Age/Priors per Year \\\n    Discretized in Quantiles', ylabel='Priors Per Year'\n) \n generates the contours in *Figure 12.7*. It shows that, for the most part, the plot moves in one direction. We were hoping to achieve this outcome because it allows us, through one interaction feature, to control the monotonicity of what used to involve two features.\n```", "```py\ncat_feat_l = ['sex', 'race', 'age_group']\nordenc = preprocessing.**OrdinalEncoder**(dtype=np.int8)\nrecidivism_df[cat_feat_l] =\\\n                  ordenc.**fit_transform**(recidivism_df[cat_feat_l])\nrecidivism_df.drop(['age', 'priors_count', 'compas_score'],\\\n                    axis=1, inplace=True) \n```", "```py\nrand = 9\nos.environ['PYTHONHASHSEED'] = str(rand)\ntf.random.set_seed(rand)\nnp.random.seed(rand)\ny = recidivism_df['is_recid']\nX = recidivism_df.drop(['is_recid'], axis=1).copy()\nX_train, X_test, y_train, y_test = model_selection.**train_test_split**(\n    X, y, test_size=0.2, random_state=rand\n)\nrecidivism_df = X.join(y) \n```", "```py\npd.DataFrame(\n    {\n        'feature': X.columns,\n        'correlation_to_target':scipy.stats.**spearmanr**(recidivism_df).\\\n        correlation[10,:-1]\n    }\n).style.background_gradient(cmap='coolwarm') \n```", "```py\ndef **build_nn_mdl**(hidden_layer_sizes, l1_reg=0, l2_reg=0, dropout=0):\n    nn_model = tf.keras.Sequential([\n        tf.keras.Input(shape=[len(X_train.keys())]),\\\n        tf.keras.layers.experimental.preprocessing.**Normalization**()\n    ])\n    reg_args = {}\n    if (l1_reg > 0) or (l2_reg > 0):\n        reg_args = {'kernel_regularizer':\\\n                    tf.keras.regularizers.**l1_l2**(l1=l1_reg, l2=l2_reg)}\n    for hidden_layer_size in hidden_layer_sizes:\n        nn_model.add(tf.keras.layers.**Dense**(hidden_layer_size,\\\n                        activation='relu', ****reg_args**))\n    if dropout > 0:\n        nn_model.add(tf.keras.layers.**Dropout**(dropout))\n    nn_model.add(tf.keras.layers.**Dense**(1, activation='sigmoid'))\n    nn_model.compile(\n        loss='binary_crossentropy',\n        optimizer=tf.keras.optimizers.Adam(lr=0.0004),\n        metrics=['accuracy',tf.keras.metrics.AUC(name='auc')]\n)\n    return nn_model \n```", "```py\ncv = model_selection.**RepeatedStratifiedKFold**(\n    n_splits=5,\n    n_repeats=3,\n    random_state=rand\n)\nnn_grid = {\n    'hidden_layer_sizes':[(80,)],\n    'l1_reg':[0,0.005],\n    'l2_reg':[0,0.01],\n    'dropout':[0,0.05]\n}\nnn_model = KerasClassifier(build_fn=build_nn_mdl)\nnn_grid_search = model_selection.**GridSearchCV**(\n    estimator=nn_model,\n    cv=cv,\n    n_jobs=-1,\n    param_grid=nn_grid,\n    scoring='precision',\n    error_score=0\n)\nnn_grid_result = nn_grid_search.**fit**(\n    X_train.astype(float),\n    y_train.astype(float),\n    epochs=400,batch_size=128\n) \n```", "```py\npd.**DataFrame**(nn_grid_result.**cv_results**_)[\n    [\n        'param_hidden_layer_sizes',\n        'param_l1_reg',\n        'param_l2_reg',\n        'param_dropout',\n        'mean_test_score',\n        'std_test_score',\n        'rank_test_score'\n    ]\n].**sort_values**(by='rank_test_score') \nFigure 12.9. The unregularized model is dead last, showing that all regularized model combinations performed better. One thing to note is that given the 1.5–2% standard deviations (std_test_score) and that the top performer is only 2.2% from the lowest performer, in this case, the benefits are marginal from a precision standpoint, but you should use a regularized model nonetheless because of other benefits.\n```", "```py\nfitted_class_mdls = {}\nfitted_class_mdls['keras_reg'] = mldatasets.**evaluate_class_mdl**(\n    nn_grid_result.best_estimator_,\n    X_train.astype(float),\n    X_test.astype(float),\n    y_train.astype(float),\n    y_test.astype(float),\n    plot_roc=False,\n    plot_conf_matrix=True,\n    **ret_eval_dict=****True**\n) \nFigure 12.10. The accuracy is a little bit better than the original COMPAS model from *Chapter 6*, *Anchors and Counterfactual Explanations*, but the strategy to optimize for higher precision while regularizing yielded a model with nearly half as many false positives but 50% more false negatives.\n```", "```py\nclass_mdls = {\n    'logistic':{\n        'model':linear_model.**LogisticRegression**(random_state=rand,\\\n                                                max_iter=1000),\n        'grid':{\n            'C':np.linspace(0.01, 0.49, 25),\n            'class_weight':[{0:6,1:5}],\n            'solver':['lbfgs', 'liblinear', 'newton-cg']\n        }\n     },\n    'svc':{\n        'model':svm.**SVC**(probability=True, random_state=rand),\n        'grid':{'C':[15,25,40], 'class_weight':[{0:6,1:5}]}\n    },\n    'nu-svc':{\n        'model':svm.**NuSVC**(\n            probability=True,\n            random_state=rand\n        ),\n        'grid':{\n            'nu':[0.2,0.3], 'gamma':[0.6,0.7],\\\n            'class_weight':[{0:6,1:5}]}\n        },\n    'mlp':{\n        'model':neural_network.**MLPClassifier**(\n            random_state=rand,\n            hidden_layer_sizes=(80,),\n            early_stopping=True\n        ),\n        'grid':{\n            'alpha':np.linspace(0.05, 0.15, 11),\n            'activation':['relu','tanh','logistic']}\n        },\n        'rf':{\n            'model':ensemble.**RandomForestClassifier**(\n                random_state=rand, max_depth=7, oob_score=True, \\\n                bootstrap=True\n             ),\n            'grid':{\n                'max_features':[6,7,8],\n                'max_samples':[0.75,0.9,1],\n                'class_weight':[{0:6,1:5}]}\n            },\n    'xgb-rf':{\n        'model':xgb.**XGBRFClassifier**(\n            seed=rand, eta=1, max_depth=7, n_estimators=200\n        ),\n        'grid':{\n            'scale_pos_weight':[0.85],\n            'reg_lambda':[1,1.5,2],\n            'reg_alpha':[0,0.5,0.75,1]}\n        },\n    'xgb':{\n        'model':xgb.**XGBClassifier**(\n            seed=rand, eta=1, max_depth=7\n        ),\n        'grid':{\n            'scale_pos_weight':[0.7],\n            'reg_lambda':[1,1.5,2],\n            'reg_alpha':[0.5,0.75,1]}\n        },\n    'lgbm':{\n        'model':lgb.**LGBMClassifier**(\n            random_seed=rand,\n            learning_rate=0.7,\n            max_depth=5\n        ),\n        'grid':{\n            'lambda_l2':[0,0.5,1],\n            'lambda_l1':[0,0.5,1],\n            'scale_pos_weight':[0.8]}\n        },\n    'catboost':{\n        'model':cb.**CatBoostClassifier**(\n            random_seed=rand,\n            depth=5,\n            learning_rate=0.5,\n            verbose=0\n        ),\n        'grid':{\n            'l2_leaf_reg':[2,2.5,3],\n            'scale_pos_weight':[0.65]}\n        }\n} \n```", "```py\nfor mdl_name in class_mdls:\n    base_mdl = copy.deepcopy(class_mdls[mdl_name]['model'])\n    base_mdl = base_mdl.**fit**(X_train, y_train)\n    fitted_class_mdls[mdl_name+'_base'] = \\\n        mldatasets.**evaluate_class_mdl**(\n            base_mdl, X_train, X_test,y_train, y_test,\n            plot_roc=False, plot_conf_matrix=False,\n            show_summary=False, ret_eval_dict=True\n    )\n    reg_mdl = copy.deepcopy(class_mdls[mdl_name]['model'])\n    grid = class_mdls[mdl_name]['grid']\n    cv = model_selection.**RepeatedStratifiedKFold**(\n        n_splits=5, n_repeats=3, random_state=rand\n    )\n    grid_search = model_selection.**GridSearchCV**(\n    estimator=reg_mdl, cv=cv, param_grid=grid,\n    scoring='precision', n_jobs=-1, error_score=0, verbose=0\n    )\n    grid_result = grid_search.**fit**(X_train, y_train)\n    fitted_class_mdls[mdl_name+'_reg'] =\\\n        mldatasets.**evaluate_class_mdl**(\n            grid_result.**best_estimator**_, X_train, X_test, y_train,\n            y_test, plot_roc=False,\n            plot_conf_matrix=False, show_summary=False,\n            ret_eval_dict=True\n    )\n    fitted_class_mdls[mdl_name+'_reg']['cv_best_params'] =\\\n        grid_result.**best_params**_ \n```", "```py\nclass_metrics = pd.DataFrame.from_dict(fitted_class_mdls, 'index')[\n    [\n        'accuracy_train',\n        'accuracy_test',\n        'precision_train',\n        'precision_test',\n        'recall_train',\n        'recall_test',\n        'roc-auc_test',\n        'f1_test',\n        'mcc_test'\n    ]\n]\nwith pd.option_context('display.precision', 3):\n    html = class_metrics.sort_values(\n        by='precision_test', ascending=False\n    ).style.background_gradient(\n        cmap='plasma',subset=['precision_test']\n    ).background_gradient(\n        cmap='viridis', subset=['recall_test'])\nhtml \n```", "```py\ny_test_pred = fitted_class_mdls['catboost_reg']['preds_test']\n_ = mldatasets.**compare_confusion_matrices**(\n    y_test[X_test.race==1],\n    y_test_pred[X_test.race==1],\n    y_test[X_test.race==0],\n    y_test_pred[X_test.race==0],\n    'Caucasian',\n    'African-American',\n    **compare_fpr=****True**\n)\ny_test_pred =  fitted_class_mdls['catboost_base']['preds_test']\n_ = mldatasets.**compare_confusion_matrices**(\n    y_test[X_test.race==1],\n    y_test_pred[X_test.race==1],\n    y_test[X_test.race==0],\n    y_test_pred[X_test.race==0],\n    'Caucasian',\n    'African-American',\n    **compare_fpr=****True**\n) \nFigure 12.14 and *Figure 12.15*, corresponding to the regularized and base models, respectively. You can see *Figure 12.14* here:\n```", "```py\ndef **weighted_penalized_pr_average**(y_true, y_pred, X_group,\\\n                    group_vals, penalty_mult=0.5,\\\n                    precision_mult=2,\\\n                    recall_mult=1):\n    precision_all = metrics.**precision_score**(\n        y_true, y_pred, zero_division=0\n    )\n    recall_all = metrics.**recall_score**(\n        y_true, y_pred, zero_division=0\n    )\n    p_by_group = []\n    r_by_group = []\n    for group_val in group_vals:\n        in_group = X_group==group_val\n        p_by_group.append(metrics.**precision_score**(\n            y_true[in_group], y_pred[in_group], zero_division=0\n            )\n        )\n        r_by_group.append(metrics.**recall_score**(\n            y_true[in_group], y_pred[in_group], zero_division=0\n            )\n        )\n    precision_all = precision_all - \\\n                   (np.array(p_by_group).std()*penalty_mult)\n    recall_all = recall_all -\\\n                (np.array(r_by_group).std()*penalty_mult)\n    return ((precision_all*precision_mult)+\n            (recall_all*recall_mult))/\\\n            (precision_mult+recall_mult) \n```", "```py\ndef **hyp_catboost**(l2_leaf_reg, scale_pos_weight):\n    cv = model_selection.**RepeatedStratifiedKFold**(\n        n_splits=4,n_repeats=3, random_state=rand\n    )\n    metric_l = []\n    for train_index, val_index in cv.split(X_train, y_train):\n        X_train_cv, X_val_cv = X_train.iloc[train_index],\\\n                               X_train.iloc[val_index]\n        y_train_cv, y_val_cv = y_train.iloc[train_index],\n                               y_train.iloc[val_index]\n        mdl = cb.**CatBoostClassifier**(\n            random_seed=rand, learning_rate=0.5, verbose=0, depth=5,\\\n            l2_leaf_reg=l2_leaf_reg, scale_pos_weight=scale_pos_weight\n        )\n        mdl = mdl.**fit**(X_train_cv, y_train_cv)\n        y_val_pred = mdl.**predict**(X_val_cv)\n        metric = **weighted_penalized_pr_average**(\n            y_val_cv,y_val_pred, X_val_cv['race'], range(3)\n        )\n        metric_l.**append**(metric)\n    return np.**median**(np.array(metric_l)) \n```", "```py\npbounds = {\n    'l2_leaf_reg': (2,4),\n    'scale_pos_weight': (0.55,0.85)\n    }\noptimizer = **BayesianOptimization**(\n    **hyp_catboost**,\n    pbounds, \n    random_state=rand\n)\noptimizer.maximize(init_points=3, n_iter=7) \n```", "```py\nprint(optimizer.max['params']) \n```", "```py\n{'l2_leaf_reg': 2.0207483077713997, 'scale_pos_weight': 0.7005623776446217} \n```", "```py\ncb_opt = cb.**CatBoostClassifier**(\n    random_seed=rand,\n    depth=5,\n    learning_rate=0.5,\n    verbose=0,\n    **optimizer.max['params']\n)\ncb_opt = cb_opt.**fit**(X_train, y_train)\nfitted_class_mdls['catboost_opt'] = mldatasets.**evaluate_class_mdl**(\n    cb_opt,\n    X_train,\n    X_test,\n    y_train,\n    y_test,\n    plot_roc=False,\n    plot_conf_matrix=True,\n    **ret_eval_dict=****True**\n) \n```", "```py\nAccuracy_train:  0.9652\t\tAccuracy_test:   0.8192\nPrecision_test:  0.8330\t\tRecall_test:     0.8058\nROC-AUC_test:    0.8791\t\tF1_test:         0.8192 \n```", "```py\ny_test_pred = fitted_class_mdls['catboost_opt']['preds_test']\n_ = mldatasets.**compare_confusion_matrices**(\n    y_test[X_test.race==1],\n    y_test_pred[X_test.race==1],\n    y_test[X_test.race==0],\n    y_test_pred[X_test.race==0],\n    'Caucasian',\n    'African-American',\n    **compare_fpr=****True**\n) \n```", "```py\nfitted_cb_mdl = fitted_class_mdls['catboost_opt']['fitted']\nshap_cb_explainer = shap.**TreeExplainer**(fitted_cb_mdl)\nshap_cb_values = shap_cb_explainer.**shap_values**(X_test)\nfitted_xgb_mdl = fitted_class_mdls['xgb_reg']['fitted']\nshap_xgb_explainer = shap.**TreeExplainer**(fitted_xgb_mdl)\nshap_xgb_values = shap_xgb_explainer.**shap_values**(X_test) \n```", "```py\nax0 = plt.subplot(1, 2, 1)\nshap.**summary_plot**(\n    **shap_xgb_values**,\n    X_test,\n    plot_type=\"dot\",\n    plot_size=None,\n    show=False\n)\nax0.set_title(\"XGBoost SHAP Summary\")\nax1 = plt.subplot(1, 2, 2)\nshap.**summary_plot**(\n    **shap_cb_values**,\n    X_test,\n    plot_type=\"dot\",\n    plot_size=None,\n    show=False\n)\nax1.set_title(\"Catboost SHAP Summary\") \nFigure 12.17, which shows how similar CatBoost and XGBoost are. This similarity shouldn’t be surprising because, after all, they are both gradient-boosted decision trees. The bad news is that race is in the top four for both. However, the prevalence of the shade that corresponds to lower feature values on the right suggests that African American (race=0) negatively correlates with recidivism.\n```", "```py\nshap_xgb_interact_values =\\\n                shap_xgb_explainer.shap_interaction_values(X_test) \n```", "```py\nshap_xgb_interact_avgs = np.abs(\n    **shap_xgb_interact_values**\n).mean(0)\nnp.fill_diagonal(shap_xgb_interact_avgs, 0)\nshap_xgb_interact_df = pd.**DataFrame**(shap_xgb_interact_avgs)\nshap_xgb_interact_df.columns = X_test.columns\nshap_xgb_interact_df.index = X_test.columns\nsns.**heatmap**(shap_xgb_interact_df, cmap='Blues', annot=True,\\\n            annot_kws={'size':13}, fmt='.2f', linewidths=.5) \n```", "```py\nX_train_con = X_train.**drop**(['race'], axis=1).copy()\nX_test_con = X_test.**drop**(['race'], axis=1).copy() \n```", "```py\n**best_xgb_params** = {'eta': 0.3, 'max_depth': 28,\\\n                   'reg_alpha': 0.2071, 'reg_lambda': 0.6534,\\\n                   'scale_pos_weight': 0.9114}\n**mono_con** = (0,0,0,0,0,0,0,0,1)\n**interact_con** = [[4, 5, 6, 7, 8],[0, 1, 2, 3]] \n```", "```py\nxgb_con = xgb.XGBClassifier(\n    seed=rand,monotone_constraints=**mono_con**,\\\n    interaction_constraints=**interact_con**, ****best_xgb_params**\n)\nxgb_con = xgb_con.**fit**(X_train_con, y_train)\nfitted_class_mdls['xgb_con'] = mldatasets.**evaluate_class_mdl**(\n    xgb_con, X_train_con, X_test_con, y_train, y_test,\\\n    plot_roc=False, ret_eval_dict=True\n)\ny_test_pred = fitted_class_mdls['xgb_con']['preds_test']\n_ = mldatasets.**compare_confusion_matrices**(\n    y_test[X_test.race==1],\n    y_test_pred[X_test.race==1],\n    y_test[X_test.race==0],\n    y_test_pred[X_test.race==0],\n    'Caucasian',\n    'African-American',\n     **compare_fpr=****True**\n) \nFigure 12.19 and some predictive performance metrics. If we compare the matrices to those in *Figure 12.16*, racial disparities, as measured by our FPR ratio, took a hit. Also, predictive performance is lower than the optimized CatBoost model across the board, by 2–4%. We could likely increase these metrics a bit by performing the same *Bayesian hyperparameter tuning* on this model.\n```", "```py\nfitted_xgb_con_mdl = fitted_class_mdls['xgb_con']['fitted']\nshap_xgb_con_explainer = shap.**TreeExplainer**(fitted_xgb_con_mdl)\nshap_xgb_con_values = shap_xgb_con_explainer.**shap_values**(\n    X_test_con\n)\nshap.**summary_plot**(\n    shap_xgb_con_values, X_test_con, plot_type=\"dot\"\n) \n```", "```py\nmldatasets.**plot_prob_contour_map**(\n    recidivism_df.**age_group**, recidivism_df.**priors_per_year**,\n    recidivism_df.**is_recid**, x_intervals=ordenc.categories_[2],\n    y_intervals=6, use_quantiles=True, xlabel='Age Group',\n    ylabel='Priors Per Year', model=**fitted_xgb_mdl**,\n    X_df=**X_test**,x_col='age_group',y_col='priors_per_year',\n    title='Probability of Recidivism by Age/Priors per Year \\\n          (according to XGBoost Regularized Model)'\n)\nmldatasets.**plot_prob_contour_map**(\n    recidivism_df.**age_group**, recidivism_df.**priors_per_year**,\n    recidivism_df.is_recid, x_intervals=ordenc.categories_[2],\n    y_intervals=6, use_quantiles=True, xlabel='Age Group',\n    ylabel='Priors Per Year', model=**fitted_xgb_con_mdl**,\n    X_df=**X_test_con**,x_col='age_group',y_col='priors_per_year',\n    title='(according to XGBoost Constrained Model)'\n) \n```", "```py\nshap_xgb_interact_values =\\\n        shap_xgb_con_explainer.**shap_interaction_values**(X_test_con)\nshap_xgb_interact_df =\\\n        pd.**DataFrame**(np.sum(**shap_xgb_interact_values**, axis=0))\nshap_xgb_interact_df.columns = X_test_con.columns\nshap_xgb_interact_df.index = X_test_con.columns\nsns.**heatmap**(\n    shap_xgb_interact_df, cmap='RdBu', annot=True,\n    annot_kws={'size':13}, fmt='.0f', linewidths=.5\n) \nFigure 12.22. It shows how the interaction constraints were effective because of zeros in the lower-left and lower-right quadrants, which correspond to interactions between the two groups of features we separated. If we compare with *Figure 12.18*, we can also tell how the constraints shifted the most salient interactions, making age_group and length_of_stay by far the most important ones.\n```", "```py\nlattice_sizes = [2, 2, 2, 2, 4, 5, 7, 7, 7] \n```", "```py\nmodel_inputs = []\nlattice_inputs = []\nsex_input = **tf.keras.layers.Input**(shape=[1], name='sex')\nlattice_inputs.append(**tfl.layers.CategoricalCalibration**(\n    name='sex_calib',\n    num_buckets=2,\n    output_min=0.0,\n    output_max=lattice_sizes[0] - 1.0,\n    kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001),\n    kernel_initializer='constant')(sex_input)\n)\nmodel_inputs.append(sex_input)\njuvf_input = **tf.keras.layers.Input**(shape=[1],\\\n                                   name='juv_fel_count')\nlattice_inputs.append(**tfl.layers.PWLCalibration**(\n    name='juvf_calib',\n    **monotonicity**='none',\n    input_keypoints=np.linspace(0, 20, num=5, dtype=np.float32),\n    output_min=0.0,\n    output_max=lattice_sizes[1] - 1.0,\\\n    kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001),\n    kernel_initializer='equal_slopes')(juvf_input)\n)\nmodel_inputs.append(juvf_input)\nage_input = **tf.keras.layers.Input**(shape=[1], name='age_group')\nlattice_inputs.append(**tfl.layers.PWLCalibration**(\n    name='age_calib',\n    **monotonicity**='none',\n    input_keypoints=np.linspace(0, 6, num=7, dtype=np.float32),\n    output_min=0.0,\n    output_max=lattice_sizes[7] - 1.0,\n    kernel_regularizer=('hessian', 0.0, 1e-4))(age_input)\n)\nmodel_inputs.append(age_input)\npriors_input = **tf.keras.layers.Input**(shape=[1],\\\n                                     name='priors_per_year')\nlattice_inputs.append(**tfl.layers.PWLCalibration**(\n    name='priors_calib',\n    **monotonicity**='increasing',\n    input_keypoints=np.quantile(X_train_con['priors_per_year'],\n                                np.linspace(0, 1, num=7)),\n    output_min=0.0,\n    output_max=lattice_sizes[8]-1.0)(priors_input))\nmodel_inputs.append(priors_input) \n```", "```py\nlattice = **tfl.layers.Lattice**(\n    name='lattice',\n    lattice_sizes=**lattice_sizes**,\n    **monotonicities**=[\n        'none', 'none', 'none', 'none', 'none',\n        'none', 'none', 'none', **'increasing'**\n    ],\n    output_min=0.0, output_max=1.0)(**lattice_inputs**)\nmodel_output = tf.keras.layers.**Dense**(1, name='output',\n                                     activation='sigmoid')(lattice) \n```", "```py\ntfl_mdl = **tf.keras.models.Model**(inputs=model_inputs,\n                                outputs=model_output) \n```", "```py\ntf.keras.utils.plot_model(tfl_mdl, rankdir='LR') \n```", "```py\ntfl_mdl.**compile**(\n    loss='binary_crossentropy',\n    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n    metrics=['accuracy',tf.keras.metrics.AUC(name='auc')]\n) \n```", "```py\nX_train_expand = np.**split**(\n    X_train_con.values.astype(np.float32),\n    indices_or_sections=9,\n    axis=1\n)\ny_train_expand = np.**expand_dims**(\n    y_train.values.astype(np.float32),\n    axis=1\n)\nX_test_expand = np.**split**(\n    X_test_con.values.astype(np.float32),\n    indices_or_sections=9,\n    axis=1)\ny_test_expand = np.**expand_dims**(\n    y_test.values.astype(np.float32),\n    axis=1\n) \n```", "```py\nes = tf.keras.callbacks.**EarlyStopping**(\n    monitor='**val_auc**',\n    mode='max',\n    patience=40,\n    restore_best_weights=True\n)\ntfl_history = tfl_mdl.**fit**(\n    X_train_expand,\n    y_train_expand,\n    **class_weight**={0:18, 1:16},\n    batch_size=128,\n    epochs=300,\n    validation_split=0.2,\n    shuffle=True,\n    callbacks=[**es**]\n) \n```", "```py\nfitted_class_mdls['tfl_con'] = mldatasets.**evaluate_class_mdl**(\n    tfl_mdl,\n    X_train_expand,\n    X_test_expand,\n    y_train.values.astype(np.float32),\n    y_test.values.astype(np.float32),\n    plot_roc=False,\n    ret_eval_dict=True\n)\ny_test_pred = fitted_class_mdls['tfl_con']['preds_test']\n_ = mldatasets.**compare_confusion_matrices**(\n    y_test[X_test.race==1],\n    y_test_pred[X_test.race==1],\n    y_test[X_test.race==0],\n    y_test_pred[X_test.race==0],\n    'Caucasian',\n    'African-American',\n    compare_fpr=True\n) \nFigure 12.25. The TensorFlow Lattice model performs much better than the regularized Keras model, yet the FPR ratio is better than the constrained XGBoost model. It must be noted that XGBoost’s parameters were previously tuned. With TensorFlow Lattice, a lot could be done to improve FPR, including using a custom loss function or better early-stopping metrics that somehow account for racial disparities.\n```", "```py\nfor mdl_name in fitted_class_mdls:\n    fitted_class_mdls[mdl_name]['wppra_test'] =\\\n    **weighted_penalized_pr_average**(\n        y_test,\n        fitted_class_mdls[mdl_name]['preds_test'],\n        X_test['race'],\n        range(3)\n    )\nclass_metrics = pd.**DataFrame.from_dict**(fitted_class_mdls, 'index')[\n    ['precision_test', 'recall_test', 'wppra_test']\n]\nwith pd.option_context('display.precision', 3):\n    html = class_metrics.**sort_values**(\n        by='**wppra_test**',\n        ascending=False\n        ).style.background_gradient(\n           cmap='plasma',subset=['precision_test']\n        ).background_gradient(\n           cmap='viridis', subset=['recall_test'])\nhtml \n```"]