["```py\nval dTree = new DecisionTreeClassifier()\n        .setLabelCol(\"label\")// Setting label column\n        .setFeaturesCol(\"features\") // Setting feature vector column\n        .setSeed(1234567L)// for reproducibility\n```", "```py\nval pipeline = new Pipeline()\n          .setStages(Array(PipelineConstruction.ipindexer,\n                            PipelineConstruction.labelindexer,\n                                PipelineConstruction.assembler,dTree))\n```", "```py\nvar paramGrid = new ParamGridBuilder()\n  .addGrid(dTree.impurity, \"gini\" :: \"entropy\" :: Nil)\n  .addGrid(dTree.maxBins, 2 :: 5 :: 10 :: 15 :: 20 :: 25 :: 30 :: Nil)\n  .addGrid(dTree.maxDepth, 5 :: 10 :: 15 :: 20 :: 25 :: 30 :: 30 :: Nil)\n  .build()\n```", "```py\nval evaluator = new BinaryClassificationEvaluator()\n                  .setLabelCol(\"label\")\n                  .setRawPredictionCol(\"prediction\")\n```", "```py\nprintln(\"Preparing for 10-fold cross-validation\")\nval numFolds = 10\n\nval crossval = new CrossValidator()\n     .setEstimator(pipeline)\n     .setEvaluator(evaluator)\n     .setEstimatorParamMaps(paramGrid)\n     .setNumFolds(numFolds)\n```", "```py\nval cvModel = crossval.fit(Preprocessing.trainDF)\n```", "```py\nval predictions = cvModel.transform(Preprocessing.testSet)\nprediction.show(10)\n```", "```py\nval accuracy = evaluator.evaluate(predictions)\nprintln(\"Classification accuracy: \" + accuracy)\n```", "```py\nAccuracy: 0.8441663599558337\n```", "```py\nval predictionAndLabels = predictions\n      .select(\"prediction\", \"label\")\n      .rdd.map(x => (x(0).asInstanceOf[Double], x(1)\n        .asInstanceOf[Double]))\n```", "```py\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)\nprintln(\"Area under the precision-recall curve: \" + metrics.areaUnderPR)\nprintln(\"Area under the receiver operating characteristic (ROC) curve: \" + metrics.areaUnderROC)\n```", "```py\nArea under the precision-recall curve: 0.6665988000794282\nArea under the receiver operating characteristic (ROC) curve: 0.8441663599558337\n```", "```py\nval TC = predDF.count() //Total count\n\nval tp = tVSpDF.filter($\"prediction\" === 0.0).filter($\"label\" === $\"prediction\")\n                    .count() / TC.toDouble // True positive rate\nval tn = tVSpDF.filter($\"prediction\" === 1.0).filter($\"label\" === $\"prediction\")\n                    .count() / TC.toDouble // True negative rate\nval fp = tVSpDF.filter($\"prediction\" === 1.0).filter(not($\"label\" === $\"prediction\"))\n                    .count() / TC.toDouble // False positive rate\nval fn = tVSpDF.filter($\"prediction\" === 0.0).filter(not($\"label\" === $\"prediction\"))\n                    .count() / TC.toDouble // False negative rate\n```", "```py\nval MCC = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (fp + tn) * (tn + fn)) \n```", "```py\nprintln(\"True positive rate: \" + tp *100 + \"%\")\nprintln(\"False positive rate: \" + fp * 100 + \"%\")\nprintln(\"True negative rate: \" + tn * 100 + \"%\")\nprintln(\"False negative rate: \" + fn * 100 + \"%\")\nprintln(\"Matthews correlation coefficient: \" + MCC)\n```", "```py\nTrue positive rate: 70.76461769115441%\nFalse positive rate: 14.992503748125937%\nTrue negative rate: 12.293853073463268%\nFalse negative rate: 1.9490254872563717%\nMatthews correlation coefficient: 0.5400720075807806\n```", "```py\nval bestModel = cvModel.bestModel\nprintln(\"The Best Model and Parameters:\\n--------------------\")\nprintln(bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel].stages(3))\n```", "```py\nThe Best Model and Parameters:\nDecisionTreeClassificationModel of depth 5 with 53 nodes\n```", "```py\nbestModel.asInstanceOf[org.apache.spark.ml.PipelineModel]\n      .stages(3)\n      .extractParamMap\nval treeModel = bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel]\n      .stages(3)\n      .asInstanceOf[DecisionTreeClassificationModel]\nprintln(\"Learned classification tree model:\\n\" + treeModel.toDebugString)\n```", "```py\nLearned classification tree model:\nIf (feature 3 <= 245.2)\n If (feature 11 <= 3.0)\n If (feature 1 in {1.0})\n If (feature 10 <= 2.0)\n Predict: 1.0\n Else (feature 10 > 2.0)\n If (feature 9 <= 12.9)\n Predict: 0.0\n Else (feature 9 > 12.9)\n Predict: 1.0\n â€¦\n Else (feature 7 > 198.0)\n If (feature 2 <= 28.0)\n Predict: 1.0\n Else (feature 2 > 28.0)\n If (feature 0 <= 60.0)\n Predict: 0.0\n Else (feature 0 > 60.0)\n Predict: 1.0\n```", "```py\nprintln(\"Feature 11:\" + Preprocessing.trainDF.filter(PipelineConstruction.featureCols(11)))\nprintln(\"Feature 3:\" + Preprocessing.trainDF.filter(PipelineConstruction.featureCols(3)))\n```", "```py\nFeature 11: [total_international_num_calls: double]\nFeature 3:  [total_day_mins: double]\n```", "```py\n// Estimator algorithm\nval model = new DecisionTreeRegressor().setFeaturesCol(\"features\").setLabelCol(\"label\")\n```", "```py\n// Search through decision tree's parameter for the best model\nvar paramGrid = new ParamGridBuilder()\n      .addGrid(rfModel.impurity, \"variance\" :: Nil)// variance for regression\n      .addGrid(rfModel.maxBins, 25 :: 30 :: 35 :: Nil)\n      .addGrid(rfModel.maxDepth, 5 :: 10 :: 15 :: Nil)\n      .addGrid(rfModel.numTrees, 3 :: 5 :: 10 :: 15 :: Nil)\n      .build()\n```", "```py\nprintln(\"Preparing K-fold Cross Validation and Grid Search: Model tuning\")\nval numFolds = 10  // 10-fold cross-validation \nval cv = new CrossValidator()\n      .setEstimator(rfModel)\n      .setEvaluator(new RegressionEvaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setNumFolds(numFolds)\n```", "```py\nprintln(\"Training model with decision tree algorithm\")\nval cvModel = cv.fit(trainingData)\n```", "```py\nprintln(\"Evaluating the model on the test set and calculating the regression metrics\")\nval trainPredictionsAndLabels = cvModel.transform(testData).select(\"label\", \"prediction\")\n                                            .map { case Row(label: Double, prediction: Double) \n                                            => (label, prediction) }.rdd\n\nval testRegressionMetrics = new RegressionMetrics(trainPredictionsAndLabels)\n```", "```py\nval results = \"\\n=====================================================================\\n\" +\n      s\"TrainingData count: ${trainingData.count}\\n\" +\n      s\"TestData count: ${testData.count}\\n\" +\n      \"=====================================================================\\n\" +\n      s\"TestData MSE = ${testRegressionMetrics.meanSquaredError}\\n\" +\n      s\"TestData RMSE = ${testRegressionMetrics.rootMeanSquaredError}\\n\" +\n      s\"TestData R-squared = ${testRegressionMetrics.r2}\\n\" +\n      s\"TestData MAE = ${testRegressionMetrics.meanAbsoluteError}\\n\" +\n      s\"TestData explained variance = ${testRegressionMetrics.explainedVariance}\\n\" +\n      \"=====================================================================\\n\"\nprintln(results)\n```", "```py\n=====================================================================\n TrainingData count: 80\n TestData count: 55\n =====================================================================\n TestData MSE = 7.871519100933004\n TestData RMSE = 2.8056227652578323\n TestData R-squared = 0.5363607928629964\n TestData MAE = 2.284866391184572\n TestData explained variance = 20.213067468774792\n =====================================================================\n```", "```py\nval bestModel = cvModel.bestModel.asInstanceOf[DecisionTreeRegressionModel]\n```", "```py\nprintln(\"Decision tree from best cross-validated model: \" + bestModel.toDebugString)\n```", "```py\nDecision tree from best cross-validated model at depth 5 with 39 nodes\n If (feature 0 <= 19.0)\n If (feature 0 <= 3.0)\n If (feature 0 <= 1.0)\n If (feature 3 <= 0.0)\n If (feature 4 <= 0.0)\n Predict: 4.1\n Else (feature 4 > 0.0)\n Predict: 3.4000000000000004\n ....\n Predict: 15.30909090909091\n Else (feature 0 > 25.0)\n Predict: 12.800000000000002\n Else (feature 11 > 1.0)\n Predict: 22.100000000000023\n Else (feature 9 > 1.0)\n Predict: 23.399999999999977\n```", "```py\nval featureImportances = bestModel.featureImportances.toArray\n\nval FI_to_List_sorted = featureImportances.toList.sorted.toArray\nprintln(\"Feature importance generated by the best model: \")\nfor(x <- FI_to_List_sorted) println(x)\n\n```", "```py\nFeature importance generated by the best model:\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 7.109215735617604E-5\n 2.1327647206851872E-4\n 0.001134987328520092\n 0.00418143999334111\n 0.025448271970345014\n 0.03446268498009088\n 0.057588305610674816\n 0.07952108027588178\n 0.7973788612117217\n\n```", "```py\nval gbt = new GBTClassifier()\n      .setLabelCol(\"label\")\n      .setFeaturesCol(\"features\")\n      .setSeed(1234567L)\n```", "```py\n// Chain indexers and tree in a Pipeline.\nval pipeline = new Pipeline()\n      .setStages(Array(ScalaClassification.PipelineConstruction.ipindexer,\n        ScalaClassification.PipelineConstruction.labelindexer,\n        ScalaClassification.PipelineConstruction.assembler,\n        gbt))\n```", "```py\n// Search through decision tree's maxDepth parameter for best model\nval paramGrid = new ParamGridBuilder()\n      .addGrid(gbt.maxDepth, 3 :: 5 :: 10 :: Nil) // :: 15 :: 20 :: 25 :: 30 :: Nil)\n      .addGrid(gbt.impurity, \"gini\" :: \"entropy\" :: Nil)\n      .addGrid(gbt.maxBins, 5 :: 10 :: 20 :: Nil) //10 :: 15 :: 25 :: 35 :: 45 :: Nil)\n      .build()\n```", "```py\nval evaluator = new BinaryClassificationEvaluator()\n                  .setLabelCol(\"label\")\n                  .setRawPredictionCol(\"prediction\")\n```", "```py\n// Set up 10-fold cross validation\nval numFolds = 10\nval crossval = new CrossValidator()\n      .setEstimator(pipeline)\n      .setEvaluator(evaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setNumFolds(numFolds)\n```", "```py\nval cvModel = crossval.fit(Preprocessing.trainDF)\n```", "```py\nval predictions = cvModel.transform(Preprocessing.testSet)\nprediction.show(10)\n```", "```py\nval accuracy = evaluator.evaluate(predictions)\nprintln(\"Classification accuracy: \" + accuracy)\n```", "```py\nAccuracy: 0.869460802355539\n```", "```py\nval predictionAndLabels = predictions\n      .select(\"prediction\", \"label\")\n      .rdd.map(x => (x(0).asInstanceOf[Double], x(1)\n      .asInstanceOf[Double]))\n```", "```py\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)\nprintln(\"Area under the precision-recall curve: \" + metrics.areaUnderPR)\nprintln(\"Area under the receiver operating characteristic (ROC) curve: \" + metrics.areaUnderROC)\n```", "```py\nArea under the precision-recall curve: 0.7270259009251356\nArea under the receiver operating characteristic (ROC) curve: 0.869460802355539\n```", "```py\nval TC = predDF.count() //Total count\n\nval tp = tVSpDF.filter($\"prediction\" === 0.0).filter($\"label\" === $\"prediction\")\n                    .count() / TC.toDouble // True positive rate\nval tn = tVSpDF.filter($\"prediction\" === 1.0).filter($\"label\" === $\"prediction\")\n                    .count() / TC.toDouble // True negative rate\nval fp = tVSpDF.filter($\"prediction\" === 1.0).filter(not($\"label\" === $\"prediction\"))\n                    .count() / TC.toDouble // False positive rate\nval fn = tVSpDF.filter($\"prediction\" === 0.0).filter(not($\"label\" === $\"prediction\"))\n                    .count() / TC.toDouble // False negative rate\n```", "```py\nval MCC = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (fp + tn) * (tn + fn)) \n```", "```py\nprintln(\"True positive rate: \" + tp *100 + \"%\")\nprintln(\"False positive rate: \" + fp * 100 + \"%\")\nprintln(\"True negative rate: \" + tn * 100 + \"%\")\nprintln(\"False negative rate: \" + fn * 100 + \"%\")\nprintln(\"Matthews correlation coefficient: \" + MCC)\n```", "```py\nTrue positive rate: 0.7781109445277361\nFalse positive rate: 0.07946026986506746\nTrue negative rate: 0.1184407796101949\nFalse negative rate: 0.0239880059970015\nMatthews correlation coefficient: 0.6481780577821629\n```", "```py\nval gbtModel = new GBTRegressor().setFeaturesCol(\"features\").setLabelCol(\"label\")\n```", "```py\n// Search through GBT's parameter for the best model\nvar paramGrid = new ParamGridBuilder()\n      .addGrid(gbtModel.impurity, \"variance\" :: Nil)// variance for regression\n      .addGrid(gbtModel.maxBins, 25 :: 30 :: 35 :: Nil)\n      .addGrid(gbtModel.maxDepth, 5 :: 10 :: 15 :: Nil)\n      .addGrid(gbtModel.numTrees, 3 :: 5 :: 10 :: 15 :: Nil)\n      .build()\n```", "```py\nprintln(\"Preparing K-fold Cross Validation and Grid Search: Model tuning\")\nval numFolds = 10  // 10-fold cross-validation \nval cv = new CrossValidator()\n      .setEstimator(gbtModel)\n      .setEvaluator(new RegressionEvaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setNumFolds(numFolds)\n```", "```py\nprintln(\"Training model with RandomForestRegressor algorithm\")\nval cvModel = cv.fit(trainingData)\n```", "```py\nprintln(\"Evaluating the model on the test set and calculating the regression metrics\")\nval trainPredictionsAndLabels = cvModel.transform(testData).select(\"label\", \"prediction\")\n                                            .map { case Row(label: Double, prediction: Double) \n                                            => (label, prediction) }.rdd\n\nval testRegressionMetrics = new RegressionMetrics(trainPredictionsAndLabels)\n```", "```py\nval results = \"\\n=====================================================================\\n\" +\n      s\"TrainingData count: ${trainingData.count}\\n\" +\n      s\"TestData count: ${testData.count}\\n\" +\n      \"=====================================================================\\n\" +\n      s\"TestData MSE = ${testRegressionMetrics.meanSquaredError}\\n\" +\n      s\"TestData RMSE = ${testRegressionMetrics.rootMeanSquaredError}\\n\" +\n      s\"TestData R-squared = ${testRegressionMetrics.r2}\\n\" +\n      s\"TestData MAE = ${testRegressionMetrics.meanAbsoluteError}\\n\" +\n      s\"TestData explained variance = ${testRegressionMetrics.explainedVariance}\\n\" +\n      \"=====================================================================\\n\"\nprintln(results)\n```", "```py\n=====================================================================\n TrainingData count: 80\n TestData count: 55\n =====================================================================\n TestData MSE = 5.99847335425882\n TestData RMSE = 2.4491780977011084\n TestData R-squared = 0.4223425609926217\n TestData MAE = 2.0564380367107646\n TestData explained variance = 20.340666319995183\n =====================================================================\n```", "```py\nval bestModel = cvModel.bestModel.asInstanceOf[GBTRegressionModel]\n```", "```py\nprintln(\"Decision tree from best cross-validated model: \" + bestModel.toDebugString)\n```", "```py\nDecision tree from best cross-validated model with 10 trees\n Tree 0 (weight 1.0):\n If (feature 0 <= 16.0)\n If (feature 2 <= 1.0)\n If (feature 15 <= 0.0)\n If (feature 13 <= 0.0)\n If (feature 16 <= 0.0)\n If (feature 0 <= 3.0)\n If (feature 3 <= 0.0)\n Predict: 6.128571428571427\n Else (feature 3 > 0.0)\n Predict: 3.3999999999999986\n ....\n Tree 9 (weight 1.0):\n If (feature 0 <= 22.0)\n If (feature 2 <= 1.0)\n If (feature 1 <= 1.0)\n If (feature 0 <= 1.0)\n Predict: 3.4\n ...\n```", "```py\nval featureImportances = bestModel.featureImportances.toArray\n\nval FI_to_List_sorted = featureImportances.toList.sorted.toArray\nprintln(\"Feature importance generated by the best model: \")\nfor(x <- FI_to_List_sorted) println(x)\n\n```", "```py\nFeature importance generated by the best model:\n 0.0\n 0.0\n 5.767724652714395E-4\n 0.001616872851121874\n 0.006381209526062637\n 0.008867810069950395\n 0.009420668763121653\n 0.01802097742361489\n 0.026755738338777407\n 0.02761531441902482\n 0.031208534172407782\n 0.033620224027091\n 0.03801721834820778\n 0.05263475066123412\n 0.05562565266841311\n 0.13221209076999635\n 0.5574261654957049\n```", "```py\nval rf = new RandomForestClassifier()\n                    .setLabelCol(\"label\")\n                    .setFeaturesCol(\"features\")\n                    .setSeed(1234567L)  // for reproducibility\n```", "```py\nval pipeline = new Pipeline()\n      .setStages(Array(PipelineConstruction.ipindexer,\n                   PipelineConstruction.labelindexer,\n                         PipelineConstruction.assembler,rf))\n```", "```py\nval paramGrid = new ParamGridBuilder()\n       .addGrid(rf.maxDepth, 3 :: 5 :: 15 :: 20 :: 50 :: Nil)\n       .addGrid(rf.featureSubsetStrategy, \"auto\" :: \"all\" :: Nil)\n       .addGrid(rf.impurity, \"gini\" :: \"entropy\" :: Nil)\n       .addGrid(rf.maxBins, 2 :: 5 :: 10 :: Nil)\n       .addGrid(rf.numTrees, 10 :: 50 :: 100 :: Nil)\n       .build()\n```", "```py\nval evaluator = new BinaryClassificationEvaluator()\n                  .setLabelCol(\"label\")\n                  .setRawPredictionCol(\"prediction\")\n```", "```py\nval crossval = new CrossValidator()\n      .setEstimator(pipeline)\n      .setEvaluator(evaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setNumFolds(numFolds)\n```", "```py\nval cvModel = crossval.fit(Preprocessing.trainDF)\n```", "```py\nval predictions = cvModel.transform(Preprocessing.testSet)\nprediction.show(10)\n```", "```py\nval accuracy = evaluator.evaluate(predictions)\nprintln(\"Classification accuracy: \" + accuracy)\n```", "```py\nAccuracy: 0.8800055207949945\n```", "```py\nval predictionAndLabels = predictions\n      .select(\"prediction\", \"label\")\n      .rdd.map(x => (x(0).asInstanceOf[Double], x(1)\n        .asInstanceOf[Double]))\n```", "```py\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)\nprintln(\"Area under the precision-recall curve: \" + metrics.areaUnderPR)\nprintln(\"Area under the receiver operating characteristic (ROC) curve: \" + metrics.areaUnderROC)\n```", "```py\nArea under the precision-recall curve: 0.7321042166486744\nArea under the receiver operating characteristic (ROC) curve: 0.8800055207949945\n```", "```py\nval TC = predDF.count() //Total count\n\nval tp = tVSpDF.filter($\"prediction\" === 0.0).filter($\"label\" === $\"prediction\")\n                    .count() / TC.toDouble // True positive rate\nval tn = tVSpDF.filter($\"prediction\" === 1.0).filter($\"label\" === $\"prediction\")\n                    .count() / TC.toDouble // True negative rate\nval fp = tVSpDF.filter($\"prediction\" === 1.0).filter(not($\"label\" === $\"prediction\"))\n                    .count() / TC.toDouble // False positive rate\nval fn = tVSpDF.filter($\"prediction\" === 0.0).filter(not($\"label\" === $\"prediction\"))\n                    .count() / TC.toDouble // False negative rate\n```", "```py\nval MCC = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (fp + tn) * (tn + fn))\n```", "```py\nprintln(\"True positive rate: \" + tp *100 + \"%\")\nprintln(\"False positive rate: \" + fp * 100 + \"%\")\nprintln(\"True negative rate: \" + tn * 100 + \"%\")\nprintln(\"False negative rate: \" + fn * 100 + \"%\")\nprintln(\"Matthews correlation coefficient: \" + MCC)\n```", "```py\nTrue positive rate: 0.7691154422788605\nFalse positive rate: 0.08845577211394302\nTrue negative rate: 0.12293853073463268\nFalse negative rate: 0.019490254872563718\nMatthews correlation coefficient: 0.6505449208932913\n```", "```py\nval rfModel = new RandomForestRegressor()\n        .setFeaturesCol(\"features\")\n        .setLabelCol(\"label\")\n```", "```py\n// Search through decision tree's maxDepth parameter for best model\nvar paramGrid = new ParamGridBuilder()\n      .addGrid(rfModel.impurity, \"variance\" :: Nil)// variance for regression\n      .addGrid(rfModel.maxBins, 25 :: 30 :: 35 :: Nil)\n      .addGrid(rfModel.maxDepth, 5 :: 10 :: 15 :: Nil)\n      .addGrid(rfModel.numTrees, 3 :: 5 :: 10 :: 15 :: Nil)\n      .build()\n```", "```py\nprintln(\"Preparing K-fold Cross Validation and Grid Search: Model tuning\")\nval numFolds = 10  // 10-fold cross-validation \nval cv = new CrossValidator()\n      .setEstimator(rfModel)\n      .setEvaluator(new RegressionEvaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setNumFolds(numFolds)\n```", "```py\nprintln(\"Training model with RandomForestRegressor algorithm\")\nval cvModel = cv.fit(trainingData)\n```", "```py\nprintln(\"Evaluating the model on the test set and calculating the regression metrics\")\nval trainPredictionsAndLabels = cvModel.transform(testData).select(\"label\", \"prediction\")\n                                            .map { case Row(label: Double, prediction: Double) \n                                            => (label, prediction) }.rdd\n\nval testRegressionMetrics = new RegressionMetrics(trainPredictionsAndLabels)\n```", "```py\nval results = \"\\n=====================================================================\\n\" +\n      s\"TrainingData count: ${trainingData.count}\\n\" +\n      s\"TestData count: ${testData.count}\\n\" +\n      \"=====================================================================\\n\" +\n      s\"TestData MSE = ${testRegressionMetrics.meanSquaredError}\\n\" +\n      s\"TestData RMSE = ${testRegressionMetrics.rootMeanSquaredError}\\n\" +\n      s\"TestData R-squared = ${testRegressionMetrics.r2}\\n\" +\n      s\"TestData MAE = ${testRegressionMetrics.meanAbsoluteError}\\n\" +\n      s\"TestData explained variance = ${testRegressionMetrics.explainedVariance}\\n\" +\n      \"=====================================================================\\n\"\nprintln(results)\n```", "```py\n=====================================================================\n TrainingData count: 80\n TestData count: 55\n =====================================================================\n TestData MSE = 5.99847335425882\n TestData RMSE = 2.4491780977011084\n TestData R-squared = 0.4223425609926217\n TestData MAE = 2.0564380367107646\n TestData explained variance = 20.340666319995183\n =====================================================================\n```", "```py\nval bestModel = cvModel.bestModel.asInstanceOf[RandomForestRegressionModel]\n```", "```py\nprintln(\"Decision tree from best cross-validated model: \" + bestModel.toDebugString)\n```", "```py\nDecision tree from best cross-validated model with 10 trees\n Tree 0 (weight 1.0):\n If (feature 0 <= 16.0)\n If (feature 2 <= 1.0)\n If (feature 15 <= 0.0)\n If (feature 13 <= 0.0)\n If (feature 16 <= 0.0)\n If (feature 0 <= 3.0)\n If (feature 3 <= 0.0)\n Predict: 6.128571428571427\n Else (feature 3 > 0.0)\n Predict: 3.3999999999999986\n ....\n Tree 9 (weight 1.0):\n If (feature 0 <= 22.0)\n If (feature 2 <= 1.0)\n If (feature 1 <= 1.0)\n If (feature 0 <= 1.0)\n Predict: 3.4\n ...\n```", "```py\nval featureImportances = bestModel.featureImportances.toArray\n\nval FI_to_List_sorted = featureImportances.toList.sorted.toArray\nprintln(\"Feature importance generated by the best model: \")\nfor(x <- FI_to_List_sorted) println(x)\n\n```", "```py\nFeature importance generated by the best model:\n 0.0\n 0.0\n 5.767724652714395E-4\n 0.001616872851121874\n 0.006381209526062637\n 0.008867810069950395\n 0.009420668763121653\n 0.01802097742361489\n 0.026755738338777407\n 0.02761531441902482\n 0.031208534172407782\n 0.033620224027091\n 0.03801721834820778\n 0.05263475066123412\n 0.05562565266841311\n 0.13221209076999635\n 0.5574261654957049\n```"]