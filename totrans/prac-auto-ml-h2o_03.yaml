- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Understanding Data Processing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解数据处理
- en: A **Machine Learning** (**ML**) model is the output we get once data is fitted
    into an ML algorithm. It represents the underlying relationship between various
    features and how that relationship impacts the target variable. This relationship
    depends entirely on the contents of the dataset. What makes every ML model unique,
    despite using the same ML algorithm, is the dataset that is used to train said
    model. Data can be collected from various sources and can have different schemas
    and structures, which need not be structurally compatible among themselves but
    may in fact be related to each other. This relationship can be very valuable and
    can also potentially be the differentiator between a good and a bad model. Thus,
    it is important to transform this data to meet the requirements of the ML algorithm
    to eventually train a good model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）模型是在数据拟合到ML算法后得到的输出。它代表了各种特征之间的潜在关系以及这种关系如何影响目标变量。这种关系完全取决于数据集的内容。尽管使用相同的ML算法，但每个ML模型都是独特的，这是因为用于训练该模型的特定数据集。数据可以从各种来源收集，并且可以具有不同的模式和结构，它们之间可能不需要结构上兼容，但实际上可能相互关联。这种关系可能非常有价值，也可能潜在地成为好模型和坏模型之间的区别。因此，将数据转换为满足ML算法的要求，最终训练出一个好模型是很重要的。'
- en: '**Data processing**, data preparation, and data preprocessing are all steps
    in the ML pipeline that focus on best exposing the underlying relationship between
    the features by transforming the structure of the data. Data processing may be
    the most challenging step in the ML pipeline, as there are no set steps to the
    transformation process. Data processing depends entirely on the problem you wish
    to solve; however, there are some similarities among all datasets that can help
    us define certain processes that we can perform to optimize our ML pipeline.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据处理**、数据准备和数据预处理都是ML管道中的步骤，它们通过转换数据结构来最佳地暴露特征之间的潜在关系。数据处理可能是ML管道中最具挑战性的步骤，因为转换过程没有固定的步骤。数据处理完全取决于您希望解决的问题；然而，所有数据集之间都有一些相似之处，这可以帮助我们定义可以执行以优化ML管道的某些过程。'
- en: In this chapter, we will learn about some of the common functionalities that
    are often used in data processing and how H2O has in-built operations that can
    help us easily perform them. We will understand some of the H2O operations that
    can reframe the structure of our dataframe. We will understand how to handle missing
    values and the importance of the imputation of values. We will then investigate
    how we can manipulate the various feature columns in the dataframe, as well as
    how to slice the dataframe for different needs. We shall also investigate what
    encoding is and what the different types of encoding are.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将了解一些在数据处理中经常使用的常见功能，以及H2O内置的操作如何帮助我们轻松地执行它们。我们将了解一些可以重构我们数据框结构的H2O操作。我们将了解如何处理缺失值以及值插补的重要性。然后，我们将研究如何操作数据框中的各种特征列，以及如何根据不同的需求切片数据框。我们还将研究编码是什么以及不同的编码类型。
- en: 'In this chapter, we are going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Reframing your dataframe
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重构你的数据框
- en: Handling missing values in the dataframe
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理数据框中的缺失值
- en: Manipulation of feature columns of the dataframe
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作数据框的特征列
- en: Tokenization of textual data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本数据的分词
- en: Encoding of data using target encoding
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用目标编码对数据进行编码
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All code examples in this chapter are run on **Jupyter Notebook** for an easy
    understanding of what each line in the code block does. You can run the whole
    block of code via a Python or R script executor and observe the output results,
    or you can follow along by installing Jupyter Notebook and observing the execution
    results of every line in the code blocks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有代码示例都是在**Jupyter Notebook**上运行的，以便于理解代码块中每一行的操作。您可以通过Python或R脚本执行器运行整个代码块并观察输出结果，或者您可以通过安装Jupyter
    Notebook并观察代码块中每一行的执行结果来跟随操作。
- en: 'To install Jupyter Notebook, make sure you have the latest version of Python
    and `pip` installed on your system and execute the following command:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装Jupyter Notebook，请确保您的系统上安装了最新版本的Python和`pip`，并执行以下命令：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once JupyterLab has successfully installed, you can start your Jupyter Notebook
    locally by executing the following command in your terminal:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦JupyterLab成功安装，您可以通过在终端执行以下命令来在本地启动Jupyter Notebook：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will open the **Jupyter Notebook** page on your default browser. You can
    then select which language you want to use and start executing the lines in the
    code step by step.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在你的默认浏览器上打开 **Jupyter Notebook** 页面。然后你可以选择你想要使用的语言并开始逐步执行代码步骤。
- en: All code examples for this chapter can be found on GitHub at [https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%203](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%203).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码示例都可以在 GitHub 上找到，网址为 [https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%203](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%203)。
- en: Now, let’s begin processing our data by first creating a dataframe and reframing
    it so that it meets our model training requirement.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过首先创建一个 dataframe 并将其重新格式化以满足我们的模型训练要求来开始处理我们的数据。
- en: Reframing your dataframe
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新格式化你的 dataframe
- en: Data collected from various sources is often termed **raw data**. It is called
    raw in the sense that there might be a lot of unnecessary or stale data, which
    might not necessarily benefit our model training. The structure of the data collected
    also might not be consistent among all the sources. Hence, it becomes very important
    to first reframe the data from various sources into a consistent format.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从各种来源收集的数据通常被称为 **原始数据**。它被称为原始数据，是因为其中可能包含很多不必要的或过时的数据，这些数据可能不会必然有利于我们的模型训练。收集到的数据结构也可能在所有来源之间不一致。因此，首先将来自各种来源的数据重新格式化为一致格式变得非常重要。
- en: You may have noticed that once we import the dataset into H2O, H2O converts
    the dataset into a `.hex` file, also called a dataframe. You have the option to
    import multiple datasets as well. Assuming you are importing multiple datasets
    from various sources, each with its own format and structure, then you will need
    a certain functionality that helps you reframe the contents of the dataset and
    merge them to form a single dataframe that you can feed to your ML pipeline.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，一旦我们将数据集导入 H2O，H2O 会将数据集转换为 `.hex` 文件，也称为 dataframe。你也可以选择导入多个数据集。假设你正在从各种来源导入多个数据集，每个数据集都有自己的格式和结构，那么你需要一个特定的功能来帮助你重新格式化数据集的内容并将它们合并成一个可以输入到你的机器学习流程中的单个
    dataframe。
- en: H2O provides several functionalities that you can use to perform the required
    manipulations.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 提供了几个你可以用来执行所需操作的功能。
- en: 'Here are some of the dataframe manipulation functionalities that help you reframe
    your dataframe:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些 dataframe 操作功能，可以帮助你重新格式化你的 dataframe：
- en: Combining columns from two dataframes
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将两个数据框的列合并
- en: Combining rows from two dataframes
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将两个数据框的行合并
- en: Merging two dataframes
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合并两个数据框
- en: Let’s see how we can combine columns from different dataframes in H2O.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在 H2O 中将来自不同 dataframe 的列合并。
- en: Combining columns from two dataframes
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将两个数据框的列合并
- en: One of the most common dataframe manipulation functionalities is combining different
    columns from different dataframes. Sometimes, the columns of one dataframe may
    be related to those of another. This could prove beneficial during model training.
    Thus, it is quite useful to have a functionality that can help us manipulate these
    columns and combine them together to form a single dataframe for model training.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的 dataframe 操作功能之一是从不同的 dataframe 中合并不同的列。有时，一个 dataframe 的列可能与另一个 dataframe
    的列相关。这在模型训练期间可能是有益的。因此，拥有一个可以帮助我们操作这些列并将它们合并成一个用于模型训练的单个 dataframe 的功能是非常有用的。
- en: H2O has a function called `cbind()` that combines the columns from one dataset
    into another.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 有一个名为 `cbind()` 的函数，可以将一个数据集的列合并到另一个数据集中。
- en: 'Let’s try this function out in our Jupyter Notebook using Python. Execute the
    following steps in sequence:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在我们的 Jupyter Notebook 中使用 Python 尝试这个函数。按顺序执行以下步骤：
- en: 'Import the `h2o` library:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `h2o` 库：
- en: '[PRE2]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Import the `numpy` library; we will use this to create a sample dataframe for
    our study:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `numpy` 库；我们将使用它来创建一个用于我们研究的样本 dataframe：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Initialize the `h2o` server:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 `h2o` 服务器：
- en: '[PRE4]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, let’s create a dataframe called `important_dataframe_1`; this is a dataframe
    whose columns are important. To ensure that you generate the same values in the
    dataset as in this example, set the random seed value for `numpy` to `123`. We
    will set the number of rows to `15` and the number of columns to `5`. You can
    name the columns anything you like:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个名为 `important_dataframe_1` 的数据框；这是一个列很重要的数据框。为了确保你在数据集中生成的值与这个例子中的相同，将
    `numpy` 的随机种子值设置为 `123`。我们将设置行数为 `15`，列数为 `5`。你可以给列取任何你喜欢的名字：
- en: '[PRE5]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s check out the content of the dataset by executing the following code:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过执行以下代码来查看数据集的内容：
- en: '[PRE6]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following screenshot shows you the contents of the dataset:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了数据集的内容：
- en: '![Figure 3.1 – important_dataframe_1 data content ](img/B17298_03_001.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – important_dataframe_1数据内容](img/B17298_03_001.jpg)'
- en: Figure 3.1 – important_dataframe_1 data content
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – important_dataframe_1数据内容
- en: 'Let’s create another dataframe called `important_dataframe_2`, as before but
    with different column names, but an equal number of rows and only `2` columns:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建另一个名为`important_dataframe_2`的数据框，就像之前一样，但具有不同的列名，但行数相等，只有`2`列：
- en: '[PRE7]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let’s check out the content of this dataframe as well:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们查看这个数据框的内容：
- en: '![Figure 3.2 – important_dataframe_2 data content ](img/B17298_03_002.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – important_dataframe_2数据内容](img/B17298_03_002.jpg)'
- en: Figure 3.2 – important_dataframe_2 data content
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – important_dataframe_2数据内容
- en: 'Now, let’s combine the columns of both the dataframes and store them in another
    variable called `final_dataframe`, using the `cbind()` function:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用`cbind()`函数将两个数据框的列合并，并将它们存储在另一个名为`final_dataframe`的变量中：
- en: '[PRE8]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s now observe `final_dataframe`:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们观察`final_dataframe`：
- en: '[PRE9]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You should see the contents of **final_dataframe** as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到**final_dataframe**的内容如下：
- en: '![Figure 3.3 – final_dataframe data content after cbind() ](img/B17298_03_003.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3 – cbind()后的final_dataframe数据内容](img/B17298_03_003.jpg)'
- en: Figure 3.3 – final_dataframe data content after cbind()
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – cbind()后的final_dataframe数据内容
- en: Here, you will notice that we have successfully combined the columns from `important_dataframe_2`
    with the columns of **important_dataframe_1**.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你会注意到我们已经成功地将`important_dataframe_2`的列与**important_dataframe_1**的列合并在一起。
- en: This is how you can use the `cbind()` function to combine the columns of two
    different datasets into a single dataframe. The only thing to bear in mind while
    using the `cbind()` function is that it is necessary to ensure that both the datasets
    to be combined have the same number of rows. Also, if you have dataframes with
    the same column name, then H2O will append a **0** in front of the column from
    dataframe.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是如何使用`cbind()`函数将两个不同数据集的列合并成一个单一的数据框。在使用`cbind()`函数时需要注意的唯一一点是，要确保要合并的两个数据集具有相同数量的行。此外，如果你有具有相同列名的数据框，那么H2O将在数据框的列名前添加一个**0**。
- en: Now that we know how to combine the columns of different dataframes, let’s see
    how we can combine the column values of multiple dataframes with the same column
    structure.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何合并不同数据框的列，让我们看看如何将具有相同列结构的多数据框的列值合并在一起。
- en: Combining rows from two dataframes
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合并两个数据框的行
- en: The majority of big corporations often handle tremendous amounts of data. This
    data is often partitioned into multiple chunks to make storing and reading it
    faster and more efficient. However, during model training, we will often need
    to access all these partitioned datasets. These datasets have the same structure
    but the data contents are distributed. In other words, the dataframes have the
    same columns; however, the data values or rows are split among them. We will often
    need a function that combines all these dataframes together so that we have all
    the data values available for model training.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数大型企业通常处理大量的数据。这些数据通常被分成多个块，以便更快、更有效地存储和读取。然而，在模型训练期间，我们经常需要访问所有这些分区的数据集。这些数据集具有相同的结构，但数据内容是分布的。换句话说，数据框具有相同的列；然而，数据值或行被分散在它们之间。我们经常需要一个函数将所有这些数据框合并在一起，以便我们有所有数据值可用于模型训练。
- en: H2O has a function called `rbind()` that combines the rows from one dataset
    into another.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: H2O有一个名为`rbind()`的函数，可以将一个数据集的行合并到另一个数据集中。
- en: 'Let’s try this function out in the following example:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在以下示例中尝试这个函数：
- en: 'Import the `h2o` library:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`h2o`库：
- en: '[PRE10]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Import the `numpy` library; we will use this to create a random dataframe for
    our study:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库；我们将使用它来创建用于我们研究的随机数据框：
- en: '[PRE11]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Initialize the `h2o` server:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化`h2o`服务器：
- en: '[PRE12]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, let’s create a random dataframe called `important_dataframe_1`. To ensure
    that you generate the same values in the dataset as in this example, set the random
    seed value for `numpy` to `123`. We will set the number of rows to `15` and the
    number of columns to `5`. You can name the columns anything you like:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个名为`important_dataframe_1`的随机数据框。为了确保你在数据集中生成与这个例子相同的值，将`numpy`的随机种子值设置为`123`。我们将设置行数为`15`，列数为`5`。你可以给列取任何你喜欢的名字：
- en: '[PRE13]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let’s check out the number of rows of the dataframe, which should be `15`:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们查看数据框的行数，它应该是`15`：
- en: '[PRE14]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let’s create another dataframe called `important_dataframe_2`, as with the
    previous one, with the same column names and any number of rows. In the example,
    I have used `10` rows:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建另一个名为`important_dataframe_2`的数据框，就像之前的一个一样，具有相同的列名和任意数量的行。在示例中，我使用了`10`行：
- en: '[PRE15]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let’s check out the number of rows for `important_dataframe_2`, which should
    be `10`:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们查看`important_dataframe_2`的行数，它应该是`10`：
- en: '[PRE16]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let’s combine the rows of both the dataframes and store them in another
    variable called `final_dataframe`, using the `rbind()` function:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用`rbind()`函数将两个数据框的行合并并存储在另一个名为`final_dataframe`的变量中：
- en: '[PRE17]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let’s now observe `final_dataframe`:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们观察`final_dataframe`：
- en: '[PRE18]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You should see the contents of **final_dataframe** as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到**final_dataframe**的内容如下：
- en: '![Figure 3.4 – final_dataframe data contents after rbind() ](img/B17298_03_004.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图3.4 – 使用rbind()后的final_dataframe数据内容](img/B17298_03_004.jpg)'
- en: Figure 3.4 – final_dataframe data contents after rbind()
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 使用rbind()后的final_dataframe数据内容
- en: 'Let’s check out the number of rows in **final_dataframe**:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们查看**final_dataframe**的行数：
- en: '[PRE19]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The output of the last operation should show you the value of the number of
    rows in the final dataset. You will see that the value is **25** and the contents
    of the dataframe are the combined row values of both the previous datasets.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个操作的输出应该显示最终数据集的行数。你会看到值是**25**，数据框的内容是前两个数据集的合并行值。
- en: Now that we have understood how to combine the rows of two dataframes in H2O
    using the `rbind()` function, let’s see how we can fully combine two datasets.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了如何在H2O中使用`rbind()`函数合并两个数据框的行，让我们看看我们如何完全合并两个数据集。
- en: Merging two dataframes
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合并两个数据框
- en: You can directly merge two dataframes, combining their rows and columns into
    a single dataframe. H2O provides a `merge()` function that combines two datasets
    that share a common column or common columns. During merging, columns that the
    two datasets have in common are used as the **merge key**. If they only have one
    column in common, then that column forms the singular primary key for the merge.
    If there are multiple common columns, then H2O will form a complex key of all
    these columns based on their data values and use that as the merge key. If there
    are multiple common columns between the two datasets and you only wish to merge
    a specific subset of them, then you will need to rename the other common columns
    to remove the corresponding commonality.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以直接合并两个数据框，将它们的行和列合并成一个数据框。H2O提供了一个`merge()`函数，用于合并具有公共列或公共列的两个数据集。在合并过程中，两个数据集共有的列用作**合并键**。如果它们只有一个公共列，那么这个列形成合并的单个主键。如果有多个公共列，那么H2O将根据这些列的数据值形成所有这些列的复杂键，并将其用作合并键。如果两个数据集之间有多个公共列，而你只想合并特定的子集，那么你需要重命名其他公共列以消除相应的公共性。
- en: 'Let’s try this function out in the following example in Python:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下面的Python示例中尝试这个函数：
- en: 'Import the `h2o` library:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`h2o`库：
- en: '[PRE20]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Import the `numpy` library; we will use this to create a random dataframe for
    our study:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库；我们将使用它来创建一个用于我们研究的随机数据框：
- en: '[PRE21]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Initialize the `h2o` server:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化`h2o`服务器：
- en: '[PRE22]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, let’s create a dataframe called `dataframe_1`. The dataframe has `3` columns:
    `words`, `numerical_representation`, and `letters`. Now, let’s fill in the data
    content as follows:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个名为`dataframe_1`的数据框。该数据框有`3`列：`words`、`numerical_representation`和`letters`。现在，让我们按照以下内容填写数据内容：
- en: '[PRE23]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let’s check out the content of the dataset:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们查看数据集的内容：
- en: '[PRE24]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: You will notice the contents of the dataset as follows:![Figure 3.5 – dataframe_1
    data content ](img/B17298_03_005.jpg)
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将注意到数据集的内容如下：![图3.5 – dataframe_1数据内容](img/B17298_03_005.jpg)
- en: Figure 3.5 – dataframe_1 data content
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – dataframe_1数据内容
- en: 'Let’s create another dataframe called `dataframe_2`. This dataframe also contains
    `3` columns: the `numerical_representation` column, the `letters` column (both
    of which it has in common with `dataframe_1`), and an uncommon column. Let’s call
    it `other_words`:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建另一个名为`dataframe_2`的数据框。这个数据框也包含`3`列：`numerical_representation`列、`letters`列（这两个列与`dataframe_1`相同），以及一个不常见的列。让我们称它为`other_words`：
- en: '[PRE25]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let’s check out the content of this dataframe as well:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们查看这个数据框的内容：
- en: '[PRE26]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'On executing the code, you should see the following output in your notebook:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 执行代码后，你应该在你的笔记本中看到以下输出：
- en: '![Figure 3.6 – dataframe_2 data contents ](img/B17298_03_006.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.6 – dataframe_2 数据内容](img/B17298_03_006.jpg)'
- en: Figure 3.6 – dataframe_2 data contents
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6 – dataframe_2 数据内容
- en: 'Now, let’s merge `dataframe_1` into `dataframe_2`, using the `merge()` operation:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `merge()` 操作将 `dataframe_1` 合并到 `dataframe_2` 中：
- en: '[PRE27]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let’s now observe `final_dataframe`:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们现在观察 `final_dataframe`：
- en: '[PRE28]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You should see the contents of **final_dataframe** as follows:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你应该看到 **final_dataframe** 的内容如下：
- en: '![Figure 3.7 – final_dataframe contents after merge() ](img/B17298_03_007.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.7 – merge() 后的 final_dataframe 内容](img/B17298_03_007.jpg)'
- en: Figure 3.7 – final_dataframe contents after merge()
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7 – merge() 后的 final_dataframe 内容
- en: You will notice that H2O used the combination of the `numerical_representation`
    column with the appropriate values in the other columns.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到 H2O 使用了 `numerical_representation` 列与其他列中适当的值的组合。
- en: 'Now, you may be wondering why there is no row for **4**. That is because while
    merging, we have two common columns: **numerical_representation** and **letters**.
    So, H2O used a complex merging key that uses both these columns: **(0, a)**, **(1,
    b)**, **(2, c)**, and so on.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可能想知道为什么没有 **4** 这一行的数据。那是因为在合并过程中，我们有两个共同的列：**numerical_representation**
    和 **letters**。所以，H2O 使用了一个复杂的合并键，它同时使用了这两个列：**（0，a）**、**（1，b）**、**（2，c）**，以此类推。
- en: Now the next question you might have is *What about the row with the value 5?
    It has no value in the letters column.* That is because even an empty value is
    treated as a unique value in ML. Thus, during merging, the complex key that was
    generated treated **(5, )** as a valid merge key.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能有的下一个问题是 *关于值 5 的那一行，它在 letters 列中没有值。* 那是因为在机器学习中，即使是空值也被视为一个独特的值。因此，在合并过程中，生成的复杂键将
    **（5，）** 视为一个有效的合并键。
- en: H2O drops all the remaining values since **dataframe_1** does not have any more
    numerical representation values.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 丢弃了所有剩余的值，因为 **dataframe_1** 没有更多的数值表示值。
- en: 'You can enforce H2O to not drop any of the values from the merge key column
    by setting the `all_x` parameter to `True` as follows:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以通过将 `all_x` 参数设置为 `True` 来强制 H2O 不丢弃合并键列中的任何值，如下所示：
- en: '[PRE29]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, let’s observe the contents of `describe` attribute:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们观察 `describe` 属性的内容：
- en: '![Figure 3.8 – final_dataframe data content after enforcing merge() ](img/B17298_03_008.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.8 – 应用 merge() 后的 final_dataframe 数据内容](img/B17298_03_008.jpg)'
- en: Figure 3.8 – final_dataframe data content after enforcing merge()
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8 – 强制 merge() 后的 final_dataframe 数据内容
- en: You will notice that we now have all the values from both dataframes merged
    into a single dataframe. We have all the numerical representations from **0 to
    9** and all letters from **a to e** from **dataframe_2** that were missing in
    the previous step, along with the correct values from the **other_words** column
    and the **words** column.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到我们现在将两个 dataframe 的所有值合并到一个单一的 dataframe 中。我们有了从 **0 到 9** 的所有数值表示，以及从
    **dataframe_2** 中缺失的 **a 到 e** 的所有字母，以及来自 **other_words** 列和 **words** 列的正确值。
- en: To recap, we learned how to combine dataframe columns and rows. We also learned
    how to combine entire dataframes together using the `merge()` function. However,
    we noticed that if we enforced the merging of dataframes despite them not having
    common data values in their key columns, we ended up with missing values in the
    dataframe.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，我们学习了如何合并 dataframe 的列和行。我们还学习了如何使用 `merge()` 函数将整个 dataframe 合并在一起。然而，我们注意到，即使数据框的关键列中没有共同的数据值，我们强制合并数据框时，最终在
    dataframe 中出现了缺失值。
- en: Now, let’s look at the different methods we can use to handle missing values
    using H2O.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们可以使用哪些不同的方法来处理 H2O 中的缺失值。
- en: Handling missing values in the dataframe
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理 dataframe 中的缺失值
- en: Missing values in datasets are the most common issue in the real world. It is
    often expected to have at least a few instances of missing data in huge chunks
    of datasets collected from various sources. Data can be missing for several reasons,
    which can range from anything from data not being generated at the source all
    the way to downtimes in data collectors. Handling missing data is very important
    for model training, as many ML algorithms don’t support missing data. Those that
    do may end up giving more importance to looking for patterns in the missing data,
    rather than the actual data that is present, which distracts the machine from
    learning.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际世界中，数据集中的缺失值是最常见的问题。通常，在从各种来源收集的大量数据块中，至少会有几个缺失数据的实例。数据可能因为多种原因而缺失，从数据在源头未生成到数据收集器的停机等。处理缺失数据对于模型训练非常重要，因为许多机器学习算法不支持缺失数据。那些支持缺失数据的算法可能会更重视寻找缺失数据中的模式，而不是实际存在的数据，这会分散机器学习的注意力。
- en: Missing data is often referred to as **Not Available** (**NA**) or **nan**.
    Before we can send a dataframe for model training, we need to handle these types
    of values first. You can either drop the entire row that contains any missing
    values or you can fill them with any default value either default or common for
    that data column. How you handle missing values depends entirely on which data
    is missing and how important it is for the overall model training.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据通常被称为**不可用**（**NA**）或**nan**。在我们可以将数据框发送给模型训练之前，我们需要首先处理这些类型的值。您可以选择删除包含任何缺失值的整个行，或者用默认值填充这些值，这些默认值可以是该数据列的默认值或常见值。您如何处理缺失值完全取决于哪些数据缺失以及这对于整体模型训练的重要性。
- en: 'H2O provides some functionalities that you can use to handle missing values
    in a dataframe. These are some of them:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: H2O提供了一些功能，您可以使用这些功能来处理数据框中的缺失值。以下是一些例子：
- en: The `fillna()` function
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fillna()`函数'
- en: Replacing values in a frame
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在框架中替换值
- en: Imputation
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 估算
- en: Next, let’s see how we can fill missing values in a dataframe using H2O.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何使用H2O在数据框中填充缺失值。
- en: Filling NA values
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 填充NA值
- en: '`fillna()` is a function in H2O that you can use to fill missing data values
    in a sequential manner. This is especially handy if you have certain data values
    in a column that are sequential in nature, for example, time series or any metric
    that increases or decreases sequentially and can be sorted. The smaller the difference
    between the values in the sequence, the more applicable this function becomes.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`fillna()`是H2O中的一个函数，您可以使用它以顺序方式填充缺失数据值。如果您有一个列中的某些数据值是按顺序排列的，例如时间序列或任何按顺序增加或减少的度量，并且可以排序，那么这个功能特别有用。序列中值的差异越小，这个函数就越适用。'
- en: 'The `fillna()` function has the following parameters:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`fillna()`函数有以下参数：'
- en: '`method`: This can either be *forward* or *backward*. It indicates the direction
    in which H2O should start filling the NA values in the dataframe.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`method`：这可以是*前向*或*后向*。它表示H2O在数据框中开始填充NA值的方向。'
- en: '`axis`: `0` for column-wise fill or `1` for row-wise fill.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`axis`：`0`表示按列填充，`1`表示按行填充。'
- en: '`maxlen`: The maximum number of consecutive NAs to fill.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxlen`：要填充的最大连续NA值数。'
- en: 'Let’s see an example in Python of how we can use this function to fill missing
    values:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过Python的例子来看看我们如何使用这个函数来填充缺失值：
- en: 'Import the `h2o` library:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`h2o`库：
- en: '[PRE30]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Import the `numpy` library; we will use this to create a random dataframe for
    our study:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库；我们将使用它来创建用于我们研究的随机数据框：
- en: '[PRE31]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Initialize the `h2o` server:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化`h2o`服务器：
- en: '[PRE32]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Create a random dataframe with `1000` rows, `3` columns, and some NA values:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含`1000`行、`3`列和一些NA值的随机数据框：
- en: '[PRE33]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s observe the contents of this dataframe. Execute the following code and
    you will see certain missing values in the dataframe:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们观察这个数据框的内容。执行以下代码，您将在数据框中看到某些缺失值：
- en: '[PRE34]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You should see the contents of the dataframe as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到数据框的内容如下：
- en: '![Figure 3.9 – Dataframe contents ](img/B17298_03_009.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图3.9 – 数据框内容](img/B17298_03_009.jpg)'
- en: Figure 3.9 – Dataframe contents
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 – 数据框内容
- en: 'Let’s now use the `fillna()` function to forward fill the NA values. Execute
    the following code:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们使用`fillna()`函数来前向填充NA值。执行以下代码：
- en: '[PRE35]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let’s observe the filled contents of the dataframe. Execute the following code:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们观察填充后的数据框内容。执行以下代码：
- en: '[PRE36]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'You should see the contents of the dataframe as follows:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该看到数据框的内容如下：
- en: '![Figure 3.10 – filled_dataframe contents ](img/B17298_03_010.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图3.10 – filled_dataframe内容](img/B17298_03_010.jpg)'
- en: Figure 3.10 – filled_dataframe contents
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 – 填充后的数据框内容
- en: The `fillna()` function has filled most of the NA values in the dataframe sequentially.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`fillna()`函数已按顺序填充数据框中的大多数NA值。'
- en: However, you will notice that we still have some `NA`. Since this is the very
    first column, H2O does not have any previous value in the record to fill it, thus
    it skips over it.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你会注意到我们仍然有一些`NA`。由于这是第一列，H2O在记录中没有先前的值来填充它，因此它跳过了它。
- en: Now that we understand how we can sequentially fill data in a dataframe using
    the `fillna()` function in H2O, let’s see how we can replace certain values in
    the dataframe.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了如何使用H2O中的`fillna()`函数按顺序在数据框中填充数据，让我们看看我们如何替换数据框中的某些值。
- en: Replacing values in a frame
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替换数据框中的值
- en: Another common functionality often needed for data processing is replacing certain
    values in the dataframe. There can be plenty of reasons why you might want to
    do this. This is especially common for numerical data where some of the most common
    transformations include rounding off values, normalizing numerical ranges, or
    just correcting a data value. In this section, we will explore some of the functions
    that we can use in H2O to replace values in the dataframe.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理中经常需要的一种常见功能是替换数据框中的某些值。你可能想这样做的原因有很多。这在数值数据中尤为常见，其中一些最常用的转换包括舍入值、规范化数值范围或只是纠正数据值。在本节中，我们将探讨我们可以在H2O中使用的一些函数来替换数据框中的值。
- en: 'Let’s first create a dataframe that we can use to test out such functions.
    Execute the following code so that we have a dataframe ready for manipulation:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先创建一个我们可以用来测试这些函数的数据框。执行以下代码，以便我们有一个可以操作的数据框：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The dataframe should look as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框应该看起来如下所示：
- en: '![Figure 3.11 – Dataframe data contents ](img/B17298_03_011.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图3.11 – 数据框数据内容](img/B17298_03_011.jpg)'
- en: Figure 3.11 – Dataframe data contents
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11 – 数据框数据内容
- en: 'So, we have a dataframe with three columns: **C1**, **C2**, and **C3**. Each
    column has a few negative numbers and some **nan** values. Let’s see how we can
    play around with this dataframe.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有一个包含三个列：**C1**、**C2**和**C3**的数据框。每个列都有几个负数和一些**nan**值。让我们看看我们如何处理这个数据框。
- en: 'Let’s start with something simple. Let’s update the value of a single data
    value, also called a `99`. You can update the value of a single data value based
    on its position in the dataframe as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从简单的事情开始。让我们更新单个数据值，也称为`99`。你可以根据其在数据框中的位置更新单个数据值的值，如下所示：
- en: '[PRE38]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Note that the columns and rows in the dataframe all start with `0`. Hence,
    we set the value in the dataframe with the row number of `3` and the column number
    of `1` as `99`. You should see the results in the dataframe by executing `dataframe.describe`
    as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，数据框中的列和行都从`0`开始。因此，我们将行号为`3`、列号为`1`的值设置为`99`。你可以通过执行以下`dataframe.describe`来在数据框中看到结果：
- en: '[PRE39]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The dataframe should look as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框应该看起来如下所示：
- en: '![Figure 3.12 – Dataframe contents after the datum update ](img/B17298_03_012.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图3.12 – 数据框内容在数据更新后](img/B17298_03_012.jpg)'
- en: Figure 3.12 – Dataframe contents after the datum update
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 – 数据更新后的数据框内容
- en: As you can see in the dataframe, we replaced the **nan** value that was previously
    in the third row of the **C2** column with **99**.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在数据框中看到的，我们将之前位于**C2**列第三行的**nan**值替换为**99**。
- en: 'This is a manipulation of just one data value. Let’s see how we can replace
    the values of an entire column. Let’s increase the data values in the **C3** column
    to three times their original value. You can do so by executing the following
    code:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个数据值的操作。让我们看看我们如何替换整个列的值。让我们将**C3**列的数据值增加到原始值的3倍。你可以通过执行以下代码来实现：
- en: '[PRE40]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You should see the results in the dataframe by executing `dataframe.describe`
    as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过执行以下`dataframe.describe`来在数据框中看到结果：
- en: '[PRE41]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The dataframe should look as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框应该看起来如下所示：
- en: '![Figure 3.13 – Dataframe contents after column value updates ](img/B17298_03_013.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图3.13 – 列值更新后的数据框内容](img/B17298_03_013.jpg)'
- en: Figure 3.13 – Dataframe contents after column value updates
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13 – 列值更新后的数据框内容
- en: We can see in the output that the values in the **C3** column have now been
    increased to three times the original values in the column.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在输出中看到，**C3**列的值现在已增加到原始列值的3倍。
- en: 'All these replacements we performed till now are straightforward. Let’s try
    some conditional updates on the dataframe. Let’s round off all the negative numbers
    in the dataframe to `0`. So, the condition is that we only update the negative
    numbers to `0` and don’t change any of the positive numbers. You can do conditional
    updates as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们到目前为止所执行的所有替换都是直接的。让我们尝试在数据框上进行一些条件更新。让我们将数据框中的所有负数四舍五入到`0`。所以，条件是我们只更新负数为`0`，不更改任何正数。您可以进行如下条件更新：
- en: '[PRE42]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'You should see the results in the dataframe by executing `dataframe.describe`
    as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过执行以下`dataframe.describe`来在数据框中看到结果：
- en: '[PRE43]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The dataframe should look as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框应如下所示：
- en: '![Figure 3.14 – Dataframe contents after conditional updates ](img/B17298_03_014.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图3.14 – 条件更新后的数据框内容](img/B17298_03_014.jpg)'
- en: Figure 3.14 – Dataframe contents after conditional updates
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 – 条件更新后的数据框内容
- en: As you can see in the dataframe, all the negative values have been rounded up/replaced
    by **0**.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在数据框中所见，所有负值都已向上舍入/替换为**0**。
- en: 'Now, what if instead of rounding the negative numbers up to **0** we wished
    to just inverse the negative numbers? We could do so by combining the conditional
    updates with arithmetic updates. Refer to the following example:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们不想将负数向上舍入到**0**，而是希望仅反转负数，我们可以通过结合条件更新和算术更新来实现。请参考以下示例：
- en: '[PRE44]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, let’s try to see whether we can replace the remaining `fillna()` function,
    but what if the **nan** values are nothing but some missing values that don’t
    exactly fall into any incremental or decremental pattern, and we just want to
    set it to 0? Let’s do that now. Run the following code:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试看看我们是否可以替换剩余的`fillna()`函数，但如果**nan**值只是某些缺失值，这些值并不完全符合任何递增或递减模式，而我们只想将其设置为0怎么办？让我们现在就做。运行以下代码：
- en: '[PRE45]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'You should see the results in the dataframe by executing `dataframe.describe`
    as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过执行以下`dataframe.describe`来在数据框中看到结果：
- en: '[PRE46]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The dataframe should look as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框应如下所示：
- en: '![Figure 3.15 – Dataframe contents after replacing nan values with 0 ](img/B17298_03_015.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图3.15 – 替换nan值为0后的数据框内容](img/B17298_03_015.jpg)'
- en: Figure 3.15 – Dataframe contents after replacing nan values with 0
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 – 替换nan值为0后的数据框内容
- en: The `isna()` function is a function that checks whether the value in the datum
    is **nan** or not and returns either **True** or **False**. We use this condition
    to replace the values in the dataframe.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`isna()`函数是一个检查数据中的值是否为**nan**的函数，并返回**True**或**False**。我们使用这个条件来替换数据框中的值。'
- en: Tip
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: 'There are plenty of ways to manipulate and replace the values in a dataframe
    and H2O provides plenty of functionality to make implementation easy. Feel free
    to explore and experiment more with manipulating the values in the dataframe.
    You can find more details here: [https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.xhtml](https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.xhtml).'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据框中操作和替换值有多种方法，H2O提供了丰富的功能来简化实现。请随意探索和实验更多关于操作数据框中的值。您可以在以下链接中找到更多详细信息：[https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.xhtml](https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.xhtml)。
- en: Now that we have learned various methods to replace values in the dataframe,
    let’s look into a more advanced approach to doing so that data scientists and
    engineers often take.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学习了在数据框中替换值的各种方法，让我们看看数据科学家和工程师经常采用的一种更高级的方法。
- en: Imputation
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 补充
- en: Previously, we have seen how we can replace nan values in the dataset using
    `fillna()`, which sequentially replaces the nan data in the dataframe. The `fillna()`
    function fills data in a sequential manner; however, data need not always be sequential
    in nature. For example, consider a dataset of people buying gaming laptops. The
    dataset will mostly contain data about people in the age demographic of 13-28,
    with a few outliers. In such a scenario, if there are any nan values in the `fillna()`
    function to fill the nan values, as any nan value after any outlier value will
    introduce a bias in the dataframe. We need to replace the nan value with a value
    that is common among the standard distribution of the age group for that product,
    something that is between 13 and 28, rather than say 59, which is less likely.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们看到了如何使用`fillna()`函数在数据集中替换nan值，该函数按顺序替换dataframe中的nan数据。`fillna()`函数以顺序方式填充数据；然而，数据不一定总是具有顺序性。例如，考虑一个关于购买游戏笔记本电脑的人的数据集。该数据集将主要包含13-28岁年龄段的关于人的数据，还有一些异常值。在这种情况下，如果`fillna()`函数中有任何nan值用于填充nan值，那么任何异常值之后的任何nan值都会在dataframe中引入偏差。我们需要用一个在产品年龄组的标准分布中常见的值来替换nan值，这个值在13和28之间，而不是像59这样的值，因为59出现的可能性较小。
- en: Imputation is the process of replacing certain values in the dataframe with
    an appropriate substitute that does not introduce any bias or outliers that may
    impact model training. The method or formulas used to calculate the substitute
    value are termed the **imputation strategy**. Imputation is one of the most important
    methods of data processing, which handles missing and nan values and tries to
    replace them with a value that will potentially introduce the least bias into
    the model training process.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 假设是替换dataframe中某些值的过程，用适当的替代值替换，这些替代值不会引入任何可能影响模型训练的偏差或异常值。用于计算替代值的计算方法被称为**假设策略**。假设是数据处理中最重要的一种方法，它处理缺失和nan值，并试图用可能对模型训练过程引入最少偏差的值来替换它们。
- en: 'H2O has a function called `impute()` that specifically provides this functionality.
    It has the following parameters:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: H2O有一个名为`impute()`的函数，专门提供此功能。它有以下参数：
- en: '`column`: This parameter accepts the column number that sets the columns to
    `impute()`. The value `1` imputes the entire dataframe.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`column`: 此参数接受要设置`impute()`列号的列。值`1`假设整个dataframe。'
- en: '`method`: This parameter sets which method of imputation to use. The methods
    can be either `mean`, `median`, or `mode`.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`method`: 此参数设置要使用的假设方法。方法可以是`mean`、`median`或`mode`。'
- en: '`combine_method`: This parameter dictates how to combine the quantiles for
    even samples when the imputation method chosen is `median`. The combination methods
    are either `interpolate`, `average`, `low`, or `high`.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`combine_method`: 此参数指定当选择`median`作为假设方法时，如何组合偶数样本的量数。组合方法可以是`interpolate`、`average`、`low`或`high`。'
- en: '`group_by_frame`: This parameter imputes the values of the selected precomputed
    grouped frame.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group_by_frame`: 此参数假设所选预计算的分组框架的值。'
- en: '`by`: This parameter groups the imputation results by the selected columns.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`by`: 此参数按所选列对假设结果进行分组。'
- en: '`values`: This parameter accepts a list of values that are imputed per column.
    Having the `None` value in the list skips the column.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`values`: 此参数接受一个列表，其中包含每列的值。列表中的`None`值会跳过该列。'
- en: Let’s see an example in Python of how we can use this function to fill missing
    values.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个Python示例来看看我们如何使用此函数来填充缺失值。
- en: For this, we shall use the **high school student sprint** dataset. The high
    school student sprint dataset is a dataset that consists of recordings of the
    age of high school students, their weight, maximum recorded speed, and their performance
    in a 100-meter sprint. The dataset is used to predict how the age, weight, and
    sprint speed affect the performance of students in a 100-meter sprint race.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个，我们将使用**高中学生短跑**数据集。高中学生短跑数据集是一个包含高中学生年龄、体重、最大记录速度和100米短跑表现的记录数据集。该数据集用于预测年龄、体重和短跑速度如何影响学生在100米短跑比赛中的表现。
- en: 'The dataset looks as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集看起来如下：
- en: '![Figure 3.16 – A high school student sprint dataset ](img/B17298_03_016.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图3.16 – 一位高中学生的短跑数据集](img/B17298_03_016.jpg)'
- en: Figure 3.16 – A high school student sprint dataset
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16 – 一位高中学生的短跑数据集
- en: 'The features of the dataset are as follows:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的特征如下：
- en: '**age**: Age of the student'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**年龄**：学生的年龄'
- en: '**weight**: Weight of the student in kilograms'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**体重**：学生的体重（千克）'
- en: '**max_speed**: The maximum sprint speed of the student in kilometers per hour'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**max_speed**：学生每小时的最大冲刺速度（千米/小时）'
- en: '**100_meter_time**: The time taken by the student to finish a 100-meter sprint
    in seconds'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**100_meter_time**：学生完成100米冲刺所需的时间（秒）'
- en: As you can see, there are plenty of missing values in the **100_meter_time**
    column.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，**100_meter_time**列中有很多缺失值。
- en: We cannot simply use the `fillna()` function, as that will introduce bias into
    the data if the missing values happen to be right after the fastest or slowest
    time. We can’t simply replace the values with a constant number either.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能简单地使用`fillna()`函数，因为这会在缺失值恰好发生在最快或最慢时间之后时引入数据偏差。我们也不能简单地用常数替换这些值。
- en: What would actually make sense is to replace these missing values with whatever
    is normal for an average teenager doing a 100-meter dash. We already have values
    for the majority of students, so we can use their results to calculate a general
    average 100-meter sprint time and use that as a baseline to replace all the missing
    values without introducing any bias.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，替换这些缺失值，用平均青少年100米冲刺的正常值来替换是有意义的。我们已经有大多数学生的数据，所以我们可以使用他们的结果来计算一个一般的100米冲刺平均时间，并以此作为基准来替换所有缺失值，而不会引入任何偏差。
- en: 'This is exactly what imputation is used for. Let’s use the imputation function
    to fill in these missing values:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是填充缺失值所用的。让我们使用填充函数来填充这些缺失值：
- en: 'Import the `h20` module and start the `h20` server:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`h20`模块并启动`h20`服务器：
- en: '[PRE47]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We then import the `high school student sprint` dataset by using `h2o.import_file()`:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们然后使用`h2o.import_file()`导入`高中学生冲刺`数据集：
- en: '[PRE48]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Using the `impute()` function, let’s impute the missing values in the `100_meter_time`
    column by `mean` and display the data:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`impute()`函数，让我们通过`mean`来填充`100_meter_time`列中的缺失值，并显示数据：
- en: '[PRE49]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'You will see the output of the imputed dataframe as follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到以下填充后的数据框输出：
- en: '![Figure 3.17 – 100_meter_time column imputed by its mean ](img/B17298_03_017.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图3.17 – 使用平均值填充的100米时间列](img/B17298_03_017.jpg)'
- en: Figure 3.17 – 100_meter_time column imputed by its mean
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17 – 使用平均值填充的100米时间列
- en: H2O calculated the `mean` value of all the values in the **100_meter_time**
    column as **23.5558** and replaced the missing values with it.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H2O计算了**100_meter_time**列所有值的**平均值**为**23.5558**，并用它替换了缺失值。
- en: 'Similarly, instead of `mean`, you can use `median` values as well. However,
    note that if a column has categorical values, then the method must be `mode`.
    The decision is up to you to make, depending on the dataset that is most useful
    when replacing the missing values:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，你还可以使用`median`值来代替`mean`。然而，请注意，如果某一列包含分类值，那么方法必须是`mode`。这个决定取决于你，根据最有助于替换缺失值的dataset：
- en: '[PRE50]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let’s increase the complexity a bit. What if the average 100-meter sprint time
    is not truly comparable between all students? What if the performances are more
    comparable age-wise? For example, students of age 16 are faster than the ones
    who are 13 since they are more physically developed. In that case, it won’t make
    sense considering a 13-year-old’s sprint time when imputing the missing value
    of a 16-year-old. This is where we can use the `group` parameter of the `impute()`
    function:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们稍微增加一下复杂性。如果平均100米冲刺时间在所有学生之间并不真正可比，会怎样？如果按年龄比较，表现会更相似呢？例如，16岁的学生比13岁的学生跑得快，因为他们身体发育得更成熟。在这种情况下，在填充16岁学生的缺失值时考虑13岁学生的冲刺时间就没有意义了。这就是我们可以使用`impute()`函数的`group`参数的地方：
- en: '[PRE51]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You will see the output as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![Figure 3.18 – 100_meter_sprint imputed by its mean and grouped by age ](img/B17298_03_018.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![图3.18 – 使用其平均值填充的100米冲刺数据，并按年龄分组](img/B17298_03_018.jpg)'
- en: Figure 3.18 – 100_meter_sprint imputed by its mean and grouped by age
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18 – 使用其平均值填充的100米冲刺数据，并按年龄分组
- en: You will notice that now H2O has calculated the `mean` values by age and replaced
    the respective missing values for that age in the `mean` value of all the `impute()`
    function to flexibly impute the correct values.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到现在H2O已经按年龄计算了平均值，并用它替换了相应年龄的`mean`值，在所有`impute()`函数中灵活地填充正确的值。
- en: The `impute()` function is extremely powerful to impute the correct values in
    a dataframe. The additional parameters for grouping via columns as well as frames
    make it very flexible for use in handling all sorts of missing values.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '`impute()`函数在填充数据框中的正确值方面非常强大。通过列以及框架进行分组的附加参数使其在处理各种缺失值时非常灵活。'
- en: Feel free to use and explore all these functions on different datasets. At the
    end of the day, all these functions are just tools used by data scientists and
    engineers to improve the quality of the data; the real skill is understanding
    when and how to use these tools to get the most out of your data, and that requires
    experimentation and practice.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 随意使用和探索这些函数在不同的数据集上。最终，所有这些函数都是数据科学家和工程师用来提高数据质量的工具；真正的技能是理解何时以及如何使用这些工具从您的数据中获得最大收益，这需要实验和实践。
- en: Now that we have learned about the different ways in which we can handle missing
    data, let’s move on to the next part of data processing, which is how to manipulate
    the feature columns of the dataframe.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了我们可以用不同的方式处理缺失数据，让我们继续到数据处理过程的下一部分，即如何操纵 dataframe 的特征列。
- en: Manipulating feature columns of the dataframe
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操纵 dataframe 的特征列
- en: The majority of the time, your data processing activities will mostly involve
    manipulating the columns of the dataframes. Most importantly, the type of values
    in the column and the ordering of the values in the column will play a major role
    in model training.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，您数据处理活动将主要涉及操纵数据框的列。最重要的是，列中的值类型和列中值的顺序将在模型训练中发挥重要作用。
- en: 'H2O provides some functionalities that help you do so. The following are some
    of the functionalities that help you handle missing values in your dataframe:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 提供了一些功能，可以帮助您做到这一点。以下是一些帮助您处理 dataframe 中缺失值的功能：
- en: Sorting of columns
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列排序
- en: Changing the type of the column
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改变列的类型
- en: Let’s first understand how we can sort a column using H2O.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先了解如何使用 H2O 对列进行排序。
- en: Sorting columns
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列排序
- en: Ideally, you want the data in a dataframe to be shuffled before passing it off
    to model training. However, there may be certain scenarios where you might want
    to re-order the dataframe based on the values in a column.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，您希望在将数据传递给模型训练之前对 dataframe 中的数据进行洗牌。然而，可能存在某些场景，您可能希望根据列中的值重新排序 dataframe。
- en: 'H2O has a functionality called `sort()` to sort dataframes based on the values
    in a column. It has the following parameters:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 有一个名为 `sort()` 的功能，可以根据列中的值对 dataframe 进行排序。它有以下参数：
- en: '`by`: The column to sort by. You can pass multiple column names as a list as
    well.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`by`：要排序的列。您也可以通过列表传递多个列名。'
- en: '`ascending`: A `boolean` array that denotes the direction in which H2O should
    sort the columns. If `True`, H2O will sort the column in ascending order. If `False`,
    then H2O will sort it in descending order. If neither of the flags is passed,
    then H2O defaults to sorting in ascending order.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ascending`：一个表示 H2O 应该按什么方向排序列的布尔数组。如果为 `True`，则 H2O 将按升序排序该列。如果为 `False`，则
    H2O 将按降序排序。如果没有传递任何标志，则 H2O 默认按升序排序。'
- en: The way H2O will sort the dataframe depends on whether one column name is passed
    to the `sort()` function or multiple column names. If only a single column name
    is passed, then H2O will return a frame that is sorted by that column.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 将如何排序 dataframe 取决于是否将单个列名传递给 `sort()` 函数或多个列名。如果只传递单个列名，则 H2O 将返回一个按该列排序的框架。
- en: 'However, if multiple columns are passed, then H2O will return a dataframe that
    is sorted as follows:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果传递了多个列，则 H2O 将返回一个按以下方式排序的数据框：
- en: H2O will first sort the dataframe on the first column that is passed in the
    parameter.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H2O 首先将对传递给参数的第一个列对 dataframe 进行排序。
- en: H2O will then sort the dataframe on the next column passed in the parameter,
    but only those rows will be sorted that have the same values as in the first sorted
    column. If there are no duplicate values in the previous columns, then no sorting
    will be done on subsequent columns.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H2O 将根据传递给参数的下一列对 dataframe 进行排序，但只有与第一排序列中相同的值的行才会被排序。如果前几列中没有重复值，则不会对后续列进行排序。
- en: 'Let’s see an example in Python of how we can use this function to sort columns:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个 Python 示例来看看我们如何使用此函数来排序列：
- en: 'Import the `h2o` library and initialize it:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `h2o` 库并初始化它：
- en: '[PRE52]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Create a dataframe by executing the following code and observe the dataset:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下代码创建一个 dataframe 并观察数据集：
- en: '[PRE53]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The contents of the dataset should be as follows:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的内容应如下所示：
- en: '![Figure 3.19 – dataframe_1 data contents ](img/B17298_03_019.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.19 – dataframe_1 数据内容](img/B17298_03_019.jpg)'
- en: Figure 3.19 – dataframe_1 data contents
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.19 – dataframe_1 数据内容
- en: 'So, at the moment, the values in columns `sort()` function to sort the dataframe
    by column `0` into the `by` parameter, indicating the first column of the dataframe,
    or by passing **[‘C1’]**, which is a list containing column names to sequentially
    sort the dataset:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，目前，列`sort()`函数中的值被放入`by`参数中，表示数据框的第一列，或者通过传递**[‘C1’]**，这是一个包含列名的列表，按顺序对数据集进行排序：
- en: '[PRE54]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'You should get an output of the code as follows:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下代码的输出：
- en: '![Figure 3.20 – dataframe_1 sorted by the C1 column ](img/B17298_03_020.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![图3.20 – dataframe_1按C1列排序](img/B17298_03_020.jpg)'
- en: Figure 3.20 – dataframe_1 sorted by the C1 column
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.20 – 按C1列排序的dataframe_1
- en: You will see that the dataframe is now sorted in ascending order by the **C1**
    column.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现数据框现在已按**C1**列的升序排序。
- en: 'Let’s see what we shall get if we pass multiple columns in the `by` parameter
    to sort on multiple columns. Run the following code line:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看如果我们通过`by`参数传递多个列来按多个列排序，我们会得到什么。运行以下代码行：
- en: '[PRE55]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'You should get an output as follows:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 3.21 – dataframe_1 sorted by columns C1 and C2 ](img/B17298_03_021.jpg)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![图3.21 – dataframe_1按列C1和C2排序](img/B17298_03_021.jpg)'
- en: Figure 3.21 – dataframe_1 sorted by columns C1 and C2
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.21 – 按列C1和C2排序的dataframe_1
- en: As you can see, H2O first sorted the columns by the `sort` function.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，H2O首先使用`sort`函数对列进行排序。
- en: 'You can also reverse the sorting order by passing `False` in the `ascending`
    parameter. Let’s test this out by running the following code line:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你也可以通过在`ascending`参数中传递`False`来反转排序顺序。让我们通过运行以下代码行来测试一下：
- en: '[PRE56]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'You should see an output as follows:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下输出：
- en: '![](img/B17298_03_022.jpg)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_03_022.jpg)'
- en: Figure 3.22 – dataframe_1 sorted by the C1 column in ascending order and the
    C2 column in descending order
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.22 – dataframe_1按C1列升序排序，按C2列降序排序
- en: In this case, H2O first sorted the columns by the **C1** column. Then, it sorted
    the rows by the **C2** column for those rows that had the same value in the **C1**
    column. However, this time it sorted the values in descending order.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，H2O首先按**C1**列对列进行排序。然后，对于在**C1**列中具有相同值的行，它按**C2**列对这些行进行排序。然而，这次它是按降序排序的。
- en: Now that you’ve learned how to sort the dataframe by a single column as well
    as by multiple columns, let’s move on to another column manipulation function
    that changes the type of the column.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何按单列以及多列对数据框进行排序，让我们继续学习另一个更改列类型的列操作函数。
- en: Changing column types
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更改列类型
- en: As we saw in [*Chapter 2*](B17298_02.xhtml#_idTextAnchor038), *Working with
    H2O Flow (H2O’s Web UI)*, we changed the type of the `Heart Disease` column to
    `enum` from `numerical`. The reason we did this is that the type of column plays
    a major role in model training. During model training, the type of column decides
    whether the ML problem is a classification problem or a regression problem. Despite
    the fact that the data in both cases is numerical in nature, how a ML algorithm
    will treat the column depends entirely on its type. Thus, it becomes very important
    to correct the types of columns that might not be correctly set during the initial
    stages of data collection.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[*第2章*](B17298_02.xhtml#_idTextAnchor038)中看到的，*使用H2O Flow (H2O的Web UI)*，我们将`Heart
    Disease`列的类型从`numerical`更改为`enum`。我们这样做的原因是列的类型在模型训练中起着重要作用。在模型训练期间，列的类型决定了ML问题是分类问题还是回归问题。尽管这两种情况中的数据本质上都是数值的，但ML算法如何处理该列完全取决于其类型。因此，在数据收集的初始阶段可能未正确设置列类型时，正确设置列类型变得非常重要。
- en: H2O has several functions that not only help you change the type of the columns
    but also run initial checks on the column types.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: H2O有几个函数不仅可以帮助你更改列的类型，还可以对列类型进行初始检查。
- en: 'Some of the functions are as follows:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些函数如下：
- en: '`.isnumeric()`: Checks whether the column in the dataframe is of the numeric
    type. Returns `True` or `False` accordingly'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.isnumeric()`: 检查数据框中的列是否为数值类型。相应地返回`True`或`False`'
- en: '`.asnumeric()`: Creates a new frame with all the values converted to numeric
    for the specified column'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.asnumeric()`: 为指定列创建一个新框架，其中所有值都转换为数值'
- en: '`.isfactor()`: Checks whether the column in the dataframe is of categorical
    type. Returns `True` or `False` accordingly'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.isfactor()`: 检查数据框中的列是否为分类类型。相应地返回`True`或`False`'
- en: '`.asfactor()`: Creates a new frame with all the values converted to the categorical
    type for the specified column'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.asfactor()`: 为指定列创建一个新框架，其中所有值都转换为分类类型'
- en: '`.isstring()`: Checks whether the column in the dataframe is of the string
    type. Returns `True` or `False` accordingly'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.isstring()`: 检查数据框中的列是否为字符串类型。相应地返回`True`或`False`'
- en: '`.ascharacter()`: Creates a new frame with all the values converted to the
    string type for the specified column'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.ascharacter()`: 为指定列创建一个新框架，其中所有值都转换为字符串类型'
- en: 'Let’s see an example in Python of how we can use these functions to change
    the column types:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在Python中使用这些函数来更改列类型的一个例子：
- en: 'Import the `h2o` library and initialize H2O:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`h2o`库并初始化H2O：
- en: '[PRE57]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Create a dataframe by executing the following code line and observe the dataset:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下代码行创建一个数据框并观察数据集：
- en: '[PRE58]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The contents of the dataset should be as follows:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的内容应该是这样的：
- en: '![Figure 3.23 – Dataframe data contents ](img/B17298_03_023.jpg)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![图3.23 – 数据框数据内容](img/B17298_03_023.jpg)'
- en: Figure 3.23 – Dataframe data contents
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.23 – 数据框数据内容
- en: 'Let’s confirm whether the `numerical` column by using the `isnumeric()` function
    as follows:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过使用`isnumeric()`函数来确认`numerical`列如下：
- en: '[PRE59]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: You should get an output of `True`.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到一个`True`的输出。
- en: 'Let’s see what we get if we check whether the `categorical` column using the
    `asfactor()` function as follows:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看如果我们使用`asfactor()`函数检查`categorical`列会得到什么：
- en: '[PRE60]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: You should get an output of `False`.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到一个`False`的输出。
- en: 'Now let’s convert the `categorical` column using the `asfactor()` function
    and then check whether `isfactor()` returns `True`:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用`asfactor()`函数将`categorical`列转换为因子类型，然后检查`isfactor()`是否返回`True`：
- en: '[PRE61]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: You should now get an output of `True`.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该得到一个`True`的输出。
- en: 'You can convert the `numerical` column by using the `asnumeric()` function:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用`asnumeric()`函数将`numerical`列转换为数值类型：
- en: '[PRE62]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: You should now get an output of `True`.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该得到一个`True`的输出。
- en: Now that you have learned how to sort the columns of a dataframe and change
    column types, let’s move on to another important topic in data processing, which
    is tokenization and encoding.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何对数据框的列进行排序和更改列类型，让我们继续学习数据处理中的另一个重要主题，即分词和编码。
- en: Tokenization of textual data
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本数据的分词
- en: Not all **Machine Learning Algorithms** (**MLAs**) are focused on mathematical
    problem-solving. **Natural Language Processing** (**NLP**) is a branch of ML that
    specializes in analyzing meaning out of textual data, though it will try to derive
    meaning and understand the contents of a document or any text for that matter.
    Training an NLP model can be very tricky, as every language has its own grammatical
    rules and the interpretation of certain words depends heavily on context. Nevertheless,
    an NLP algorithm often tries its best to train a model that can predict the meaning
    and sentiments of a textual document.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有**机器学习算法**（**MLAs**）都专注于数学问题解决。**自然语言处理**（**NLP**）是机器学习的一个分支，它专门分析从文本数据中提取的意义，尽管它也会尝试从文档或任何文本中提取意义和理解内容。训练NLP模型可能非常棘手，因为每种语言都有其自己的语法规则，某些单词的解释在很大程度上依赖于上下文。尽管如此，NLP算法通常会尽力训练一个可以预测文本文档的意义和情感的模型。
- en: The way to train an NLP algorithm is to first break down the chunk of textual
    data into smaller units called **tokens**. Tokens can be words, characters, or
    even letters. It depends on what the requirements of the MLA are and how it uses
    these tokens to train a model.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 训练NLP算法的方法是首先将文本数据块分解成更小的单元，称为**标记**。标记可以是单词、字符，甚至是字母。这取决于MLA的要求以及它是如何使用这些标记来训练模型的。
- en: H2O has a function called `tokenize()` that helps break down string data in
    a dataframe into tokens and creates a separate column containing all the tokens
    for further processing.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: H2O有一个名为`tokenize()`的函数，它可以帮助将数据框中的字符串数据分解成标记，并为进一步处理创建一个包含所有标记的单独列。
- en: 'It has the following parameter: `split`: We pass a regular expression in this
    parameter that will be used by the function to split the text data into tokens.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 它有以下参数：`split`：我们在该参数中传递一个正则表达式，该表达式将由函数用于将文本数据分割成标记。
- en: 'Let’s see an example of how we can use this function to tokenize string data
    in a dataframe:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用这个函数在数据框中对字符串数据进行分词的例子：
- en: 'Import the `h2o` library and initialize it:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`h2o`库并初始化它：
- en: '[PRE63]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Create a dataframe by executing the following code line and observe the dataset:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下代码行创建一个数据框并观察数据集：
- en: '[PRE64]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The dataset should look as follows:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集应该看起来如下所示：
- en: '![Figure 3.24 – Dataframe data contents ](img/B17298_03_024.jpg)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![图3.24 – 数据框数据内容](img/B17298_03_024.jpg)'
- en: Figure 3.24 – Dataframe data contents
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.24 – 数据框数据内容
- en: This type of textual data is usually collected in systems that generate a lot
    of log text or conversational data. To solve such NLP tasks, we need to break
    down the sentences into individual tokens so that we can eventually build the
    context and meaning of these texts that will help the ML algorithm to make semantic
    predictions. However, before diving into the complexities of NLP, data scientists
    and engineers will process this data by tokenizing it first.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的文本数据通常在生成大量日志文本或对话数据的系统中收集。为了解决这类自然语言处理任务，我们需要将句子分解成单个标记，以便我们最终可以构建这些文本的上下文和意义，这将有助于机器学习算法进行语义预测。然而，在深入研究自然语言处理的复杂性之前，数据科学家和工程师将首先通过分词来处理这些数据。
- en: 'Let’s tokenize our dataframe using this function to split the text with blank
    spaces and observe the tokenized column:'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用这个函数来分词我们的数据框，观察分词后的列：
- en: '[PRE65]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'You should see the dataframe as follows:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下数据框：
- en: '![Figure 3.25 – Tokenized dataframe data contents ](img/B17298_03_025.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.25 – 分词后的数据框内容](img/B17298_03_025.jpg)'
- en: Figure 3.25 – Tokenized dataframe data contents
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.25 – 分词后的数据框内容
- en: You will notice that the `tokenize()` function splits the text data into tokens
    and appends the tokens as rows into a single column. You will also notice that
    all tokenized sentences are separated by empty rows. You can cross-check this
    by comparing the number of words in all the sentences in the dataframe, plus the
    empty spaces between the sentences against the number of rows in the tokenized
    dataset, using `nrows`.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到`tokenize()`函数将文本数据分割成标记，并将标记作为行附加到单个列中。你还会注意到所有分词后的句子都由空行分隔。你可以通过使用`nrows`比较数据框中所有句子的单词数量以及句子之间的空格与分词数据集的行数来交叉检查这一点。
- en: These are some of the most used data processing methods that are used to process
    your data before you feed it to your ML pipeline for training. There are still
    plenty of methods and techniques that you can use to further clean and polish
    your dataframes. So much so that you could dedicate an entire book to discussing
    them. Data processing happens to be the most difficult part of the entire ML life
    cycle. The quality of the data used for training depends on the context of the
    problem statement. It also depends on the creativity and ingenuity of the data
    scientists and engineers in processing that data. The end goal of data processing
    is to extract as much information as we can from the dataset and remove noise
    and bias from the data to allow for a more efficient analysis of data during training.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是在将数据输入到机器学习管道进行训练之前用于处理数据的常用数据处理方法。还有许多方法和技巧可以用来进一步清理和抛光数据框。如此之多，以至于你可以专门写一本书来讨论它们。数据处理恰好是整个机器学习生命周期中最困难的部分。用于训练的数据质量取决于问题陈述的上下文。它还取决于数据科学家和工程师在处理数据时的创造力和独创性。数据处理的目标是从数据集中提取尽可能多的信息，并从数据中去除噪声和偏差，以便在训练期间进行更有效的数据分析。
- en: Encoding data using target encoding
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用目标编码进行数据编码
- en: As we know, machines are only capable of understanding numbers. However, plenty
    of real-world ML problems revolve around objects and information that are not
    necessarily numerical in nature. Things such as states, names, and classes, in
    general, are represented as categories rather than numbers. This kind of data
    is called **categorical data**. Categorical data will often play a big part in
    analysis and prediction. Hence, there is a need to convert these categorical values
    to a numerical format so that machines can understand them. The conversion should
    also be in such a way that we do not lose the inherent meaning of those categories,
    nor do we introduce new information into the data, such as the incremental nature
    of numbers, for example.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所知，机器只能理解数字。然而，许多现实世界的机器学习问题都围绕着非数字性质的对象和信息。例如，状态、名称和类别等通常被表示为类别而不是数字。这种数据被称为**分类数据**。分类数据在分析和预测中通常会扮演重要角色。因此，有必要将这些分类值转换为数值格式，以便机器能够理解它们。这种转换还应该以这种方式进行，即我们不会失去这些类别的固有含义，也不会向数据中引入新的信息，例如数字的增量性质等。
- en: This is where encoding is used. **Encoding** is a process where categorical
    values are transformed, in other words, *encoded*, into numerical values. There
    are plenty of encoding methods that can perform this transformation. One of the
    most commonly used ones is **target encoding**.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是编码被使用的地方。**编码**是一个过程，其中分类值被转换，换句话说，*编码*为数值。有许多编码方法可以执行这种转换。其中最常用的一种是**目标编码**。
- en: Target encoding is an encoding process that transforms categorical values into
    numerical values by calculating the average probability of the target variable
    occurring for a given category. H2O also has methods that help users implement
    target encoding on their data.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 目标编码是一种编码过程，通过计算给定类别中目标变量发生的平均概率，将分类值转换为数值。H2O也有帮助用户在数据上实现目标编码的方法。
- en: 'To better understand this method, consider the following sample `Mythical creatures`
    dataset:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这种方法，考虑以下示例`神话生物`数据集：
- en: '![Figure 3.26 – Our mythical creatures dataset ](img/B17298_03_026.jpg)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![图3.26 – 我们的神话生物数据集](img/B17298_03_026.jpg)'
- en: Figure 3.26 – Our mythical creatures dataset
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.26 – 我们的神话生物数据集
- en: 'This dataset has the following content:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集包含以下内容：
- en: '**Animals**: This column contains categorical values of the names of animals.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动物**：此列包含动物名称的分类值。'
- en: '**Mythical**: This column contains the **0** binary value and the **1** binary
    value. **1** indicates that the creature is mythical, while **0** indicates that
    the creature is not mythical.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神话**：此列包含**0**的二进制值和**1**的二进制值。**1**表示生物是神话中的，而**0**表示生物不是神话中的。'
- en: 'Now, let’s encode the `categorical` column using target encoding. Target encoding
    will perform the following steps:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用目标编码来编码**分类**列。目标编码将执行以下步骤：
- en: 'Group the categorical values and record the number of times the target value,
    **Mythical**, was **1** and when it was **0** for a given category as follows:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将分类值分组，并记录给定类别中目标值**神话**为**1**和为**0**的次数如下：
- en: '![Figure 3.27 – The mythical creatures dataset with a target count ](img/B17298_03_027.jpg)'
  id: totrans-365
  prefs: []
  type: TYPE_IMG
  zh: '![图3.27 – 带有目标计数的神话生物数据集](img/B17298_03_027.jpg)'
- en: Figure 3.27 – The mythical creatures dataset with a target count
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.27 – 带有目标计数的神话生物数据集
- en: 'Calculate the probability that the **1** target value will occur, as compared
    to the **0** target value within each specific group. This would look as follows:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算在特定组内**1**的目标值发生的概率，与**0**的目标值相比。这看起来如下所示：
- en: '![Figure 3.28 – The mythical creatures dataset with a Probability of Target
    1 Occurring column ](img/B17298_03_028.jpg)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![图3.28 – 带有目标1发生概率列的神话生物数据集](img/B17298_03_028.jpg)'
- en: Figure 3.28 – The mythical creatures dataset with a Probability of Target 1
    Occurring column
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.28 – 带有目标1发生概率列的神话生物数据集
- en: 'Drop the **Animals** column and use the **Probability of Target 1 Occurring**
    column as the encoded representation of the **Animals** column. The new encoded
    dataset will look as follows:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除**动物**列，并使用**目标1发生概率**列作为**动物**列的编码表示。新的编码数据集将如下所示：
- en: '![Figure 3.29 – A target-encoded mythical creatures dataset ](img/B17298_03_029.jpg)'
  id: totrans-371
  prefs: []
  type: TYPE_IMG
  zh: '![图3.29 – 目标编码的神话生物数据集](img/B17298_03_029.jpg)'
- en: Figure 3.29 – A target-encoded mythical creatures dataset
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.29 – 目标编码的神话生物数据集
- en: In the encoded dataset, the **Animals** feature is encoded using target encoding
    and we have a dataset that is entirely numerical in nature. This dataset will
    be easy for an ML algorithm to interpret and learn from, providing high-quality
    models.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在编码数据集中，**动物**特征使用目标编码进行编码，我们得到了一个完全数值化的数据集。这个数据集将很容易被机器学习算法解释和学习，从而提供高质量的模型。
- en: 'Let us now see how we can perform target encoding using H2O. The dataset we
    will use for this example is the `Automobile price prediction` dataset. You can
    find the details of this dataset at [https://archive.ics.uci.edu/ml/datasets/Automobile](https://archive.ics.uci.edu/ml/datasets/Automobile)
    (*Dua, D. and Graff, C. (2019). UCI Machine Learning Repository* [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)].
    *Irvine, CA: University of California, School of Information and Computer Science*).'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用H2O进行目标编码。我们将使用此示例的`汽车价格预测`数据集。您可以在[https://archive.ics.uci.edu/ml/datasets/Automobile](https://archive.ics.uci.edu/ml/datasets/Automobile)（Dua,
    D. 和 Graff, C. (2019). UCI机器学习库[[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)]。加州大学欧文分校信息与计算机科学学院，加州，欧文）找到该数据集的详细信息。
- en: The dataset is fairly straightforward. It contains various details about cars,
    such as the **make of the car**, **engine size**, **fuel system**, **compression
    ratio**, and **price**. The aim of the ML algorithm is to predict the price of
    a car based on these features.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集相当直接。它包含有关汽车的各种详细信息，例如汽车的**制造商**、**发动机尺寸**、**燃油系统**、**压缩比**和**价格**。机器学习算法的目标是根据这些特征预测汽车的价格。
- en: For our experiment, we shall encode the `categorical` columns **make**, **fuel
    type**, and **body style** using target encoding where the **price** column is
    the target.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们将使用目标编码对`categorical`列**make**、**fuel type**和**body style**进行编码，其中**price**列是目标。
- en: 'Let’s perform target encoding by following this example:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照以下示例执行目标编码：
- en: 'Import `h2o` and H2O’s `H2OTargetEncoderEstimator`, and initialize your H2O
    server. Execute the following code:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`h2o`和H2O的`H2OTargetEncoderEstimator`，并初始化你的H2O服务器。执行以下代码：
- en: '[PRE66]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Import the `Automobile price prediction` dataset and print the contents of
    the dataset. Execute the following code:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`Automobile price prediction`数据集并打印数据集的内容。执行以下代码：
- en: '[PRE67]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Let’s observe the contents of the dataframe; it should look as follows:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们观察数据框的内容；它应该如下所示：
- en: '![Figure 3.30 – An automobile price prediction dataframe ](img/B17298_03_030.jpg)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![图3.30 – 汽车价格预测数据框](img/B17298_03_030.jpg)'
- en: Figure 3.30 – An automobile price prediction dataframe
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.30 – 汽车价格预测数据框
- en: 'As you can see in the preceding figure, the dataframe consists of a large number
    of columns containing the details of cars. For the sake of understanding target
    encoding, let’s filter out the columns that we want to experiment with while dropping
    the rest. Since we plan on encoding the `make` column, the `fuel-type` column,
    and the `body-style` column, let’s use only those columns along with the `price`
    response column. Execute the following code:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，数据框包含大量列，其中包含汽车的详细信息。为了理解目标编码，让我们筛选出我们想要实验的列，同时删除其余的列。由于我们计划对`make`列、`fuel-type`列和`body-style`列进行编码，让我们只使用这些列以及`price`响应列。执行以下代码：
- en: '[PRE68]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The filtered dataframe will look as follows:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤后的数据框将如下所示：
- en: '![Figure 3.31 – The automobile price prediction dataframe with filtered columns
    ](img/B17298_03_031.jpg)'
  id: totrans-388
  prefs: []
  type: TYPE_IMG
  zh: '![图3.31 – 过滤列的汽车价格预测数据框](img/B17298_03_031.jpg)'
- en: Figure 3.31 – The automobile price prediction dataframe with filtered columns
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.31 – 过滤列的汽车价格预测数据框
- en: 'Let’s now split this dataframe into training and testing dataframes. Execute
    the following code:'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们将这个数据框拆分为训练数据框和测试数据框。执行以下代码：
- en: '[PRE69]'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Let’s now train our target encoder model using `H2OTargetEncoderEstimator`.
    Execute the following code:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们使用`H2OTargetEncoderEstimator`训练我们的目标编码器模型。执行以下代码：
- en: '[PRE70]'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Once the target encoder has finished its training, you will see the following
    output:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦目标编码器完成训练，你将看到以下输出：
- en: '![Figure 3.32 – The result of target encoder training  ](img/B17298_03_032.jpg)'
  id: totrans-395
  prefs: []
  type: TYPE_IMG
  zh: '![图3.32 – 目标编码器训练的结果](img/B17298_03_032.jpg)'
- en: Figure 3.32 – The result of target encoder training
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.32 – 目标编码器训练的结果
- en: From the preceding screenshot, you can see that the H2O target encoder will
    generate the target-encoded values for the `make` column, the `fuel-type` column,
    and the `body-style` column and store them in different columns named `make_te`,
    `fuel-type_te`, and `body-style_te`, respectively. These new columns will contain
    the encoded values.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的截图可以看出，H2O目标编码器将为`make`列、`fuel-type`列和`body-style`列生成目标编码值，并分别存储在不同的名为`make_te`、`fuel-type_te`和`body-style_te`的列中。这些新列将包含编码值。
- en: 'Let’s now use this trained target encoder to encode the training dataset and
    print the encoded dataframe:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们使用这个训练过的目标编码器对训练数据集进行编码并打印编码后的数据框：
- en: '[PRE71]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The encoded training frame should look as follows:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 编码后的训练帧应如下所示：
- en: '![Figure 3.33 – An encoded automobile price prediction training dataframe ](img/B17298_03_033.jpg)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
  zh: '![图3.33 – 编码的汽车价格预测训练数据框](img/B17298_03_033.jpg)'
- en: Figure 3.33 – An encoded automobile price prediction training dataframe
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.33 – 编码的汽车价格预测训练数据框
- en: As you can see from the figure, our training frame now has three additional
    columns, `make_te`, `fuel-type_te`, and `body-style_te`, with numerical values.
    These are the target-encoded columns for the `make` column, the `fuel-type` column,
    and the `body-style` column.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，我们的训练帧现在有三个额外的列，`make_te`、`fuel-type_te`和`body-style_te`，包含数值。这些是`make`列、`fuel-type`列和`body-style`列的目标编码列。
- en: 'Similarly, let’s now use the trained target encoder to encode the test dataframe
    and print the encoded dataframe. Execute the following code:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，现在让我们使用训练好的目标编码器来编码测试数据框架，并打印编码后的数据框架。执行以下代码：
- en: '[PRE72]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The encoded test frame should look as follows:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 编码后的测试框架应如下所示：
- en: '![Figure 3.34 – An encoded automobile price prediction test dataframe ](img/B17298_03_034.jpg)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![图3.34 – 编码的汽车价格预测测试数据框架](img/B17298_03_034.jpg)'
- en: Figure 3.34 – An encoded automobile price prediction test dataframe
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.34 – 编码的汽车价格预测测试数据框架
- en: As you can see from the figure, our test frame also has three additional columns,
    which are the encoded columns. You can now use these dataframes to train your
    ML models.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从图中所示，我们的测试框架也有三个额外的列，这些是编码列。现在您可以使用这些数据框架来训练您的机器学习模型。
- en: Depending on your next actions, you can use the encoded dataframes however you
    see fit. If you want to use the dataframe to train ML models, then you can drop
    the `categorical` columns from the dataframe and use the respective encoded columns
    as training features to train your models. If you wish to perform any further
    analytics on the dataset, then you can keep both types of columns and perform
    any comparative study.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的下一步行动，您可以使用编码后的数据框架以您认为合适的方式。如果您想使用数据框架来训练机器学习模型，那么您可以删除数据框架中的`分类`列，并使用相应的编码列作为训练特征来训练您的模型。如果您希望对数据集进行任何进一步的统计分析，那么您可以保留这两种类型的列，并进行任何比较研究。
- en: Tip
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'H2O’s target encoder has several parameters that you can set to tweak the encoding
    process. Selecting the correct settings for target encoding your dataset can get
    very complex, depending on the type of data with which you are working. So, feel
    free to experiment with this function, as the better you understand this feature
    and target encoding in general, the better you can encode your dataframe and further
    improve your model training. You can find more details about H2O’s target encoder
    here: [https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/target-encoding.xhtml](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/target-encoding.xhtml).'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: H2O的目标编码器有几个参数可以设置以调整编码过程。根据您正在处理的数据类型，为目标编码数据集选择正确的设置可能会变得非常复杂。因此，请随意尝试这个功能，因为您对这个功能和目标编码的一般理解越好，您就能更好地编码数据框架并进一步提高模型训练。您可以在以下位置找到有关H2O目标编码器的更多详细信息：[https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/target-encoding.xhtml](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/target-encoding.xhtml)。
- en: Congratulations! You have just understood how you can encode categorical values
    using H2O’s target encoder.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您刚刚了解了如何使用H2O的目标编码器对分类值进行编码。
- en: Summary
  id: totrans-414
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we first explored the various techniques and some of the common
    functions we use to preprocess our dataframe before it is sent to model training.
    We looked into how we can reframe our raw dataframe into a suitable consistent
    format that meets the requirement for model training. We learned how to manipulate
    the columns of dataframes by combining them with different columns of different
    dataframes. We learned how to combine rows from partitioned dataframes, as well
    as how to directly merge dataframes into a single dataframe.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先探讨了我们在将数据框架发送到模型训练之前所使用的各种技术和一些常见函数，以预处理我们的数据框架。我们探讨了如何将原始数据框架重新构建成适合的、一致的格式，以满足模型训练的要求。我们学习了如何通过将不同数据框架的不同列组合起来来操作数据框架的列。我们还学习了如何从分区数据框架中组合行，以及如何直接将数据框架合并成一个单一的数据框架。
- en: Once we knew how to reframe our dataframes, we learned how to handle the missing
    values that are often present in freshly collected data. We learned how to fill
    NA values, replace certain incorrect values, as well as how to use different imputation
    strategies to avoid adding noise and bias when filling missing values.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们学会了如何重新构建我们的数据框架，我们就学会了如何处理新收集的数据中经常出现的缺失值。我们学会了如何填充NA值，替换某些错误值，以及如何使用不同的插补策略来避免在填充缺失值时添加噪声和偏差。
- en: We then investigated how we can manipulate the feature columns by sorting the
    dataframes by column, as well as changing the types of columns. We also learned
    how to tokenize strings to handle textual data, as well as how to encode categorical
    values using H2O’s target encoder.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们研究了如何通过按列排序数据框架以及更改列的类型来操作特征列。我们还学习了如何对字符串进行标记化以处理文本数据，以及如何使用H2O的目标编码器对分类值进行编码。
- en: In the next chapter, we will open the black box of AutoML, explore its training,
    and what happens internally during the AutoML process. This will help us to better
    understand how H2O does its magic and efficiently automates the model training
    process.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将打开AutoML的“黑箱”，探索其训练过程，以及AutoML过程中内部发生的事情。这将帮助我们更好地理解H2O如何施展魔法并高效地自动化模型训练过程。
