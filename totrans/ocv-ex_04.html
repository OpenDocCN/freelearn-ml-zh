<html><head></head><body><div class="chapter" title="Chapter&#xA0;4.&#xA0;Delving into Histograms and Filters"><div class="titlepage"><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Delving into Histograms and Filters</h1></div></div></div><p>In the previous chapter, we learned the basics of user interfaces in OpenCV using QT or native libraries and how to use advanced OpenGL user interfaces. We learned basic color conversions and filters that helped us create our first application.</p><p>In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Histogram and histogram equalization</li><li class="listitem" style="list-style-type: disc">Look up tables</li><li class="listitem" style="list-style-type: disc">The blur and median blur</li><li class="listitem" style="list-style-type: disc">The Gaussian Canny filter</li><li class="listitem" style="list-style-type: disc">Image color equalization</li><li class="listitem" style="list-style-type: disc">Understanding conversion between image types</li></ul></div><p>After we learn the basics of OpenCV and user interfaces, we will create our first complete application and a basic photo tool with the following functionalities in this chapter:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Calculate and draw a histogram</li><li class="listitem" style="list-style-type: disc">Histogram equalization</li><li class="listitem" style="list-style-type: disc">The lomography camera effect</li><li class="listitem" style="list-style-type: disc">The cartoonize effect</li></ul></div><p>This application will help you understand how to create a whole project from scratch and understand the histogram concept. We will see how to equalize the histogram of a color image and create two effects using a combination of filters and the use of look up tables.</p><div class="section" title="Generating a CMake script file"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec31"/>Generating a CMake script file</h1></div></div></div><p>Before <a id="id144" class="indexterm"/>we start creating our source file, we will generate the <code class="literal">CMakeLists.txt</code> file that will allow us to compile our project, structure, and executable. The following <code class="literal">cmake</code> script is simple and basic but enough to compile and generate the executable:</p><div class="informalexample"><pre class="programlisting">cmake_minimum_required (VERSION 2.6)

cmake_policy(SET CMP0012 NEW)

PROJECT(Chapter4_Phototool)

# Requires OpenCV
FIND_PACKAGE( OpenCV 3.0.0 REQUIRED )

include_directories(${OpenCV_INCLUDE_DIRS})
link_directories(${OpenCV_LIB_DIR})

ADD_EXECUTABLE( ${PROJECT_NAME} main.cpp )
TARGET_LINK_LIBRARIES( ${PROJECT_NAME} ${OpenCV_LIBS} )</pre></div><p>Let's try to understand the script file.</p><p>The first line indicates the minimum <code class="literal">cmake</code> version required to generate our project, and the second line sets the <code class="literal">CMP0012</code> policy variable to allow you to identify numbers and Boolean constants and remove the CMake warning if it is not set:</p><div class="informalexample"><pre class="programlisting">cmake_minimum_required (VERSION 2.6)
cmake_policy(SET CMP0012 NEW)</pre></div><p>After these two lines, we define the project name:</p><div class="informalexample"><pre class="programlisting">PROJECT(Chapter4_Phototool)</pre></div><p>Of course, we need to include the OpenCV library. The first thing to do is find the library and show a message about the OpenCV library version with the <code class="literal">MESSAGE</code> function:</p><div class="informalexample"><pre class="programlisting"># Requires OpenCV
FIND_PACKAGE( OpenCV 3.0.0 REQUIRED )
MESSAGE("OpenCV version : ${OpenCV_VERSION}")</pre></div><p>If the library with the minimum version 3.0 is found, then we include the headers and library files in our project:</p><div class="informalexample"><pre class="programlisting">include_directories(${OpenCV_INCLUDE_DIRS})
link_directories(${OpenCV_LIB_DIR})</pre></div><p>Now, we only need to add the source files that are to be compiled; in order to link them to the <a id="id145" class="indexterm"/>OpenCV library, we use the project name variable as an executable name and use only a single source file called <code class="literal">main.cpp</code>:</p><div class="informalexample"><pre class="programlisting">ADD_EXECUTABLE( ${PROJECT_NAME} main.cpp )
TARGET_LINK_LIBRARIES( ${PROJECT_NAME} ${OpenCV_LIBS} ) </pre></div></div></div>
<div class="section" title="Creating the Graphical User Interface"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec32"/>Creating the Graphical User Interface</h1></div></div></div><p>Before <a id="id146" class="indexterm"/>we start with the image processing algorithms, we will create the main user interface for our application. We will use a QT-based user interface to allow us to create single buttons.</p><p>The application receives one input parameter to load the image to be processed, and we will create the following four buttons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Show histogram</strong></span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Equalize histogram</strong></span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Lomography effect</strong></span></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Cartoonize effect</strong></span></li></ul></div><p>We can see the four results in the following screenshot:</p><div class="mediaobject"><img src="graphics/B04283_04_01.jpg" alt="Creating the Graphical User Interface"/></div><p>Let's develop<a id="id147" class="indexterm"/> our project. First of all, we will include the required OpenCV headers. We define an <code class="literal">img</code> matrix to store the input image, and create a constant string to use the new command-line parser, which is only available in OpenCV 3.0. In this constant, we allow only two input parameters: common help and the required image input:</p><div class="informalexample"><pre class="programlisting">// OpenCV includes
#include "opencv2/core/utility.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/highgui.hpp"
using namespace cv;
// OpenCV command line parser functions
// Keys accecpted by command line parser
const char* keys =
{
    "{help h usage ? | | print this message}"
    "{@image | | Image to process}"
};</pre></div><p>The <code class="literal">main</code> function <a id="id148" class="indexterm"/>starts with the command-line parser variable. We then set the instructions and print the help message. The following lines will help you set up the help instructions for our final executable:</p><div class="informalexample"><pre class="programlisting">int main( int argc, const char** argv )
{
    CommandLineParser parser(argc, argv, keys);
    parser.about("Chapter 4. PhotoTool v1.0.0");
    //If requires help show
    if (parser.has("help"))
    {
        parser.printMessage();
        return 0;
    }</pre></div><p>If the user doesn't require help, then we need to get the file path image in an <code class="literal">imgFile</code> variable string and check whether all the required parameters are added to the <code class="literal">parser.check()</code> function:</p><div class="informalexample"><pre class="programlisting">String imgFile= parser.get&lt;String&gt;(0);

    // Check if params are correctly parsed in his variables
    if (!parser.check())
    {
        parser.printErrors();
        return 0;
    }</pre></div><p>Now, we can read the image file with the <code class="literal">imread</code> function and then create the window in which the input image will be shown later using the <code class="literal">namedWindow</code> function:</p><div class="informalexample"><pre class="programlisting">    // Load image to process
    img= imread(imgFile);
    // Create window
    namedWindow("Input");</pre></div><p>With the image loaded and window created, we only need to create the buttons for our interface and link them to the <code class="literal">callback</code> functions. Each <code class="literal">callback</code> function is defined in the source code, and we will explain them later in this chapter. We will create the buttons with the <code class="literal">createButton</code> function with the <code class="literal">QT_PUSH_BUTTON</code> constant in the button style:</p><div class="informalexample"><pre class="programlisting">    // Create UI buttons
    createButton("Show histogram", showHistoCallback, NULL, QT_PUSH_BUTTON, 0);
    createButton("Equalize histogram", equalizeCallback, NULL, QT_PUSH_BUTTON, 0);
    createButton("Lomography effect", lomoCallback, NULL, QT_PUSH_BUTTON, 0);
    createButton("Cartonize effect", cartoonCallback, NULL, QT_PUSH_BUTTON, 0);</pre></div><p>To complete <a id="id149" class="indexterm"/>our <code class="literal">main</code> function, we show the input image and wait for a key press to finish our application:</p><div class="informalexample"><pre class="programlisting">    // Show image
    imshow("Input", img);
    waitKey(0);
    return 0;</pre></div><p>Now, we only need to define the <code class="literal">callback</code> functions in the following sections, and we will define and describe each one of them.</p></div>
<div class="section" title="Drawing a histogram"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec33"/>Drawing a histogram</h1></div></div></div><p>A histogram<a id="id150" class="indexterm"/> is<a id="id151" class="indexterm"/> a statistical graphic representation of variable distribution. This allows us to understand the density estimation and probability distribution of data. The histogram is created by dividing the entire range of variable values into a fixed number of intervals and then counting how many values fall into each interval.</p><p>If we apply this histogram concept to an image, it seems to be complex to understand, but it is really very simple. In a gray image, our variable values can take any possible gray value ranging from <code class="literal">0</code> to <code class="literal">255</code>, and the density is the number of pixels in the image that have this value. This means that we have to count the number of image pixels that have the value <code class="literal">0</code>, count the number of pixels of value <code class="literal">1</code>, and so on.</p><p>The callback function that shows the histogram of the input image is called <code class="literal">showHistoCallback</code>. This<a id="id152" class="indexterm"/> function calculates the histogram of each channel image and shows the result of each histogram channel in a new image.</p><p>Now, let's check the following code:</p><div class="informalexample"><pre class="programlisting">void showHistoCallback(int state, void* userData)
{
    // Separate image in BRG
    vector&lt;Mat&gt; bgr;
    split( img, bgr );

    // Create the histogram for 256 bins
    // The number of possibles values [0..255]
    int numbins= 256;

    /// Set the ranges ( for B,G,R) ), last is not included
    float range[] = { 0, 256 } ;
    const float* histRange = { range };

    Mat b_hist, g_hist, r_hist;

    calcHist( &amp;bgr[0], 1, 0, Mat(), b_hist, 1, &amp;numbins, &amp;histRange );
    calcHist( &amp;bgr[1], 1, 0, Mat(), g_hist, 1, &amp;numbins, &amp;histRange );
    calcHist( &amp;bgr[2], 1, 0, Mat(), r_hist, 1, &amp;numbins, &amp;histRange );

    // Draw the histogram
    // We go to draw lines for each channel
    int width= 512;
    int height= 300;
    // Create image with gray base
    Mat histImage( height, width, CV_8UC3, Scalar(20,20,20) );

  // Normalize the histograms to height of image
  normalize(b_hist, b_hist, 0, height, NORM_MINMAX );
  normalize(g_hist, g_hist, 0, height, NORM_MINMAX );
  normalize(r_hist, r_hist, 0, height, NORM_MINMAX );

  int binStep= cvRound((float)width/(float)numbins);
  for( int i=1; i&lt; numbins; i++)
  {
    line( histImage, 
      Point( binStep*(i-1), height-cvRound(b_hist.at&lt;float&gt;(i-1) ) ),
        Point( binStep*(i), height-cvRound(b_hist.at&lt;float&gt;(i) ) ),
          Scalar(255,0,0));
    line( histImage, 
      Point( binStep*(i-1), height-cvRound(g_hist.at&lt;float&gt;(i-1) ) ),
        Point( binStep*(i), height-cvRound(g_hist.at&lt;float&gt;(i) ) ),
          Scalar(0,255,0));
    line( histImage, 
      Point( binStep*(i-1), height-cvRound(r_hist.at&lt;float&gt;(i-1) ) ),
        Point( binStep*(i), height-cvRound(r_hist.at&lt;float&gt;(i) ) ),
          Scalar(0,0,255));
    }
    imshow("Histogram", histImage);
}</pre></div><p>Let's try to <a id="id153" class="indexterm"/>understand how to extract each channel histogram and how to draw it.</p><p>First, we need to create three matrices to process each input image channel. We use a <code class="literal">vector</code> type variable to store each one, and use the split <code class="literal">OpenCV</code> function to divide the input image into three channels:</p><div class="informalexample"><pre class="programlisting">// Separate image in BRG
    vector&lt;Mat&gt; bgr;
    split( img, bgr );</pre></div><p>Now, we will define the number of bins in our histogram; in our case, one bin per possible pixel value:</p><div class="informalexample"><pre class="programlisting">int numbins= 256;</pre></div><p>Now, we need to define our range of variables and create three matrices to store each histogram:</p><div class="informalexample"><pre class="programlisting">    /// Set the ranges ( for B,G,R) )
    float range[] = { 0, 256 } ;
    const float* histRange = { range };
    Mat b_hist, g_hist, r_hist;</pre></div><p>Now, we can calculate the histogram using the <a id="id154" class="indexterm"/>OpenCV <code class="literal">calcHist</code> function. This function has several parameters, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The input image; in our case, we use one image channel stored in the <code class="literal">bgr</code> vector</li><li class="listitem" style="list-style-type: disc">The number of images required to calculate the histogram in the input; in our case, we only use one image</li><li class="listitem" style="list-style-type: disc">The dimensions of the number channel used to compute the histogram; we use 0 in our case</li><li class="listitem" style="list-style-type: disc">The optional mask matrix</li><li class="listitem" style="list-style-type: disc">The variable used to store the calculated histogram</li><li class="listitem" style="list-style-type: disc">The histogram dimensionality (the dimension of the space where the image (here, it's a gray plane) takes its values); in our case, it's 1</li><li class="listitem" style="list-style-type: disc">The number of bins to be calculated; in our case, we use 256 bins, one per pixel value</li><li class="listitem" style="list-style-type: disc">The range of the input variable; in our case, it's a range of possible pixel values from <code class="literal">0</code> to <code class="literal">255</code></li></ul></div><p>Our <code class="literal">calcHist</code> function <a id="id155" class="indexterm"/>for each channel looks like the following code:</p><div class="informalexample"><pre class="programlisting">calcHist( &amp;bgr[0], 1, 0, Mat(), b_hist, 1, &amp;numbins, &amp;histRange );
    calcHist( &amp;bgr[1], 1, 0, Mat(), g_hist, 1, &amp;numbins, &amp;histRange );
    calcHist( &amp;bgr[2], 1, 0, Mat(), r_hist, 1, &amp;numbins, &amp;histRange );</pre></div><p>Now, we have calculated the histogram for each channel. We need to draw each channel histogram and show it to the user. To do this, we will create a color image with a size of 512 x 300 pixels:</p><div class="informalexample"><pre class="programlisting">// Draw the histogram
    // We go to draw lines for each channel
    int width= 512;
    int height= 300;
    // Create image with gray base
    Mat histImage( height, width, CV_8UC3, Scalar(20,20,20) );</pre></div><p>Before we draw the histogram values in our image, we will normalize the histogram matrices between the <code class="literal">min</code> value <code class="literal">0</code> and a <code class="literal">max</code> value; in our case, the same value as that of the height of our image, 300 pixels:</p><div class="informalexample"><pre class="programlisting">    // Normalize the histograms to height of image
    normalize(b_hist, b_hist, 0, height, NORM_MINMAX );
    normalize(g_hist, g_hist, 0, height, NORM_MINMAX );
    normalize(r_hist, r_hist, 0, height, NORM_MINMAX );</pre></div><p>Now, we need to draw a line from bin 0 to bin 1 and so on. We need to calculate the number of pixels between each bin, and then a <code class="literal">binStep</code> variable is calculated by dividing the width by the number of bins.</p><p>Each small line is drawn from the horizontal position, <code class="literal">i-1</code> to <code class="literal">i</code>, and the vertical position is the histogram value in the corresponding <code class="literal">i</code>. It is drawn with the color channel representation, which is as follows:</p><div class="informalexample"><pre class="programlisting">int binStep= cvRound((float)width/(float)numbins);
  for( int i=1; i&lt; numbins; i++)
  {
    line( histImage, 
      Point( binStep*(i-1), height-cvRound(b_hist.at&lt;float&gt;(i-1) ) ),
        Point( binStep*(i), height-cvRound(b_hist.at&lt;float&gt;(i) ) ),
          Scalar(255,0,0));
    line( histImage, 
      Point( binStep*(i-1), height-cvRound(g_hist.at&lt;float&gt;(i-1) ) ),
        Point( binStep*(i), height-cvRound(g_hist.at&lt;float&gt;(i) ) ),
          Scalar(0,255,0));
    line( histImage, 
      Point( binStep*(i-1), height-cvRound(r_hist.at&lt;float&gt;(i-1) ) ),
        Point( binStep*(i), height-cvRound(r_hist.at&lt;float&gt;(i) ) ),
          Scalar(0,0,255));
    }</pre></div><p>Finally, we show<a id="id156" class="indexterm"/> the histogram image with the <code class="literal">imshow</code> function:</p><div class="informalexample"><pre class="programlisting">    imshow("Histogram", histImage);</pre></div><p>This is the result of the lena.png image:</p><div class="mediaobject"><img src="graphics/B04283_04_02.jpg" alt="Drawing a histogram"/></div></div>
<div class="section" title="Image color equalization"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec34"/>Image color equalization</h1></div></div></div><p>In this<a id="id157" class="indexterm"/> section, we will learn how to equalize a color image. Image equalization and histogram equalization try to obtain a histogram with a uniform distribution of values. The result of equalization is an increase in the contrast of an image. The equalization allows lower local contrast areas to gain higher contrast, spreading out the most frequent intensities.</p><p>This method is very useful when the image is almost dark or completely bright and there are very small differences between the background and foreground. Using histogram equalization, we increase the contrast and the details that are over- or under-exposed. This technique is very useful in medical images, such as X-rays.</p><p>However, there are two main disadvantages to this method: it increases the background noise and decreases useful signals.</p><p>We can see the effect of equalization in the following image and see how the histogram changes and spreads on increasing the image contrast:</p><div class="mediaobject"><img src="graphics/B04283_04_03.jpg" alt="Image color equalization"/></div><p>Let's try to implement our histogram equalization. We will implement it in the callback function defined in the user interface's code:</p><div class="informalexample"><pre class="programlisting">void equalizeCallback(int state, void* userData)
{
    Mat result;
    // Convert BGR image to YCbCr
    Mat ycrcb;
    cvtColor( img, ycrcb, COLOR_BGR2YCrCb);

    // Split image into channels
    vector&lt;Mat&gt; channels;
    split( ycrcb, channels );
    
    // Equalize the Y channel only
    equalizeHist( channels[0], channels[0] );

    // Merge the result channels
    merge( channels, ycrcb );

    // Convert color ycrcb to BGR
    cvtColor( ycrcb, result, COLOR_YCrCb2BGR );

    // Show image
    imshow("Equalized", result);
}</pre></div><p>To equalize a <a id="id158" class="indexterm"/>color image, we only need to equalize the luminance channel. We can do this with each color channel, but the result is not usable. Then, we can use any other color image format, such as HSV or YCrCb, that separates the luminance component in an individual channel. We choose this last color format and use a Y channel (luminance) to equalize it. Then, we perform the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">We convert our input BGR image into YCrCb using the <code class="literal">cvtColor</code> function:<div class="informalexample"><pre class="programlisting">Mat result;
    // Convert BGR image to YCbCr
    Mat ycrcb;
    cvtColor( img, ycrcb, COLOR_BGR2YCrCb);</pre></div></li><li class="listitem">After converting our image, we split the YCrCb image into different <code class="literal">channels</code> matrices:<div class="informalexample"><pre class="programlisting">// Split image into channels
    vector&lt;Mat&gt; channels;
    split( ycrcb, channels );</pre></div></li><li class="listitem">We then equalize the histogram only in the <code class="literal">Y channel</code> using the <code class="literal">equalizeHist</code> function, which has only two parameters: input and output matrices:<div class="informalexample"><pre class="programlisting">    // Equalize the Y channel only
    equalizeHist( channels[0], channels[0] );</pre></div></li><li class="listitem">Now, we only need to merge the resulted channels and convert the result to the BGR format to show the user the result:<div class="informalexample"><pre class="programlisting">    // Merge the result channels
    merge( channels, ycrcb );

    // Convert color ycrcb to BGR
    cvtColor( ycrcb, result, COLOR_YCrCb2BGR );

    // Show image
    imshow("Equalized", result);</pre></div><p>The process applied <a id="id159" class="indexterm"/>to a low contrast <code class="literal">Lena</code> image will have the following result:</p><div class="mediaobject"><img src="graphics/B04283_04_04.jpg" alt="Image color equalization"/></div></li></ol></div></div>
<div class="section" title="Lomography effect"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec35"/>Lomography effect</h1></div></div></div><p>In this section, we <a id="id160" class="indexterm"/>will <a id="id161" class="indexterm"/>create another image effect, a photographic effect that is commonly used in different mobile applications, such as Google Camera or Instagram.</p><p>In this section, we will discover how to use a <span class="strong"><strong>Look up Table</strong></span> or <span class="strong"><strong>LUT</strong></span>. We will discuss LUTs later in this chapter.</p><p>We will learn how to add an over image; in this case, a dark halo to create our desired effect.</p><p>The function that <a id="id162" class="indexterm"/>implements this effect is the callback <code class="literal">lomoCallback</code> and has the following code:</p><div class="informalexample"><pre class="programlisting">void lomoCallback(int state, void* userData)
{
    Mat result;

    const double exponential_e = std::exp(1.0);
    // Create Lookup table for color curve effect
    Mat lut(1, 256, CV_8UC1);
    for (int i=0; i&lt;256; i++)
    {
        float x= (float)i/256.0; 
        lut.at&lt;uchar&gt;(i)= cvRound( 256 * (1/(1 + pow(exponential_e, -((x-0.5)/0.1)) )) );
    }
   
    // Split the image channels and apply curve transform only to red channel
    vector&lt;Mat&gt; bgr;
    split(img, bgr);
    LUT(bgr[2], lut, bgr[2]);
    // merge result
    merge(bgr, result);
   
    // Create image for halo dark
    Mat halo( img.rows, img.cols, CV_32FC3, Scalar(0.3,0.3,0.3) );
    // Create circle 
    circle(halo, Point(img.cols/2, img.rows/2), img.cols/3, Scalar(1,1,1), -1); 
    blur(halo, halo, Size(img.cols/3, img.cols/3));
    
    // Convert the result to float to allow multiply by 1 factor
    Mat resultf;
    result.convertTo(resultf, CV_32FC3);
    
    // Multiply our result with halo
    multiply(resultf, halo, resultf);
    
    // convert to 8 bits
    resultf.convertTo(result, CV_8UC3);

    // show result
    imshow("Lomograpy", result);
}</pre></div><p>Let's understand the code.</p><p>The lomography effect <a id="id163" class="indexterm"/>is divided into different steps, but in our example we applied a very simple lomography effect using the following two steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">A color manipulation with a look up table that applies a curve to the red channel</li><li class="listitem">A vintage effect that applies a dark halo to the image.</li></ol></div><p>The first step is to manipulate the red color with a curve transform that applies this function:</p><div class="mediaobject"><img src="graphics/B04283_04_05.jpg" alt="Lomography effect"/></div><p>This formula generates a curve that makes the dark values darker and light values lighter, where <span class="emphasis"><em>x</em></span> is the possible pixel value (0 to 255) and <span class="emphasis"><em>s</em></span> is a constant that we set to <span class="emphasis"><em>0.1</em></span> in our tutorial. A lower constant value that generates pixels with values lower than 128 is very dark and over 128 is very bright. Values that are near to <span class="emphasis"><em>1</em></span> convert the curve to a line and do not generate our desired effect:</p><div class="mediaobject"><img src="graphics/B04283_04_06.jpg" alt="Lomography effect"/></div><p>This function is <a id="id164" class="indexterm"/>very easy to implement by applying a <span class="strong"><strong>Look Up Table</strong></span>, <a id="id165" class="indexterm"/>more commonly called a LUT. A LUT is a vector or table that returns a preprocess value for a given value to perform computation in the memory. A LUT is a common technique used to spare CPU cycles by avoiding performing costly computations repeatedly. Instead of calling the exponential/divide function for each pixel, we perform it only once for each possible pixel value (256 times) and store the result in a table. Thus, we save the CPU time at the cost of a bit of memory. While this may not make a great difference for the standard PC with small image sizes, this makes a huge difference for CPU-limited hardware, such as the Raspberry Pi. In our case, if we want to apply our function for each pixel, we need to make the width by calculating the height; in 100 x 100 pixels, there are 10,000 calculations, but there are only 256 possible values for a pixel. We can then precalculate the pixel values and save them in a LUT vector.</p><p>In our sample code, we define the <code class="literal">E</code> variable and create a <code class="literal">lut</code> matrix of 1 row and 256 columns. Then, we do a loop over all possible pixel values by applying our formula and saving them in the <code class="literal">lut</code> variable:</p><div class="informalexample"><pre class="programlisting">const double exponential_e = std::exp(1.0);
    // Create Lookup table for color curve effect
    Mat lut(1, 256, CV_8UC1);
    Uchar* plut= lut.data;
    for (int i=0; i&lt;256; i++)
    {
        double x= (double)i/256.0; 
        plut[i]= cvRound( 256.0 * (1.0/(1.0 + pow(exponential_e, -((x-0.5)/0.1)) )) );
    }</pre></div><p>As mentioned<a id="id166" class="indexterm"/> earlier, in this section we don't apply the function to all channels. We need to split our input image by channels using the <code class="literal">split</code> function:</p><div class="informalexample"><pre class="programlisting">    // Split the image channels and apply curve transform only to red channel
    vector&lt;Mat&gt; bgr;
    split(img, bgr);</pre></div><p>We then apply our <code class="literal">lut</code> table variable to the red channel. OpenCV give us the <code class="literal">LUT</code> function that has the following three parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">An input image</li><li class="listitem" style="list-style-type: disc">A matrix of a look up table</li><li class="listitem" style="list-style-type: disc">An output image</li></ul></div><p>Then, our call to the <code class="literal">LUT</code> function and red channels looks like this:</p><div class="informalexample"><pre class="programlisting">LUT(bgr[2], lut, bgr[2]);</pre></div><p>Now, we only have to merge our computed channels:</p><div class="informalexample"><pre class="programlisting">// merge result
    merge(bgr, result);</pre></div><p>The first step is done, and we only have to create the dark halo to finish our effect. Then, we create a gray image with a white circle inside with the same input image size:</p><div class="informalexample"><pre class="programlisting">// Create image for halo dark
    Mat halo( img.rows, img.cols, CV_32FC3, Scalar(0.3,0.3,0.3) );
    // Create circle 
    circle(halo, Point(img.cols/2, img.rows/2), img.cols/3, Scalar(1,1,1), -1); </pre></div><div class="mediaobject"><img src="graphics/B04283_04_07.jpg" alt="Lomography effect"/></div><p>However, if we apply <a id="id167" class="indexterm"/>this image to our input image, it will change from dark to white, and we can then apply a big blur using the <code class="literal">blur</code> filter function to our circle halo image to get a smooth effect:</p><div class="informalexample"><pre class="programlisting">    blur(halo, halo, Size(img.cols/3, img.cols/3));</pre></div><p>The result after applying the blur filter is shown in the following image:</p><div class="mediaobject"><img src="graphics/B04283_04_08.jpg" alt="Lomography effect"/></div><p>Now, we need to <a id="id168" class="indexterm"/>apply this halo to our image from step 1. An easy way to do this is to multiply both the images. But we need to convert our input image from an 8-bit image to a 32-bit float because we need to multiply our blurred image that has values ranging from 0 to 1 by our input image that has integer values:</p><div class="informalexample"><pre class="programlisting">    // Convert the result to float to allow multiply by 1 factor
    Mat resultf;
    result.convertTo(resultf, CV_32FC3);</pre></div><p>After we convert our image, we only need to multiply each matrix per element:</p><div class="informalexample"><pre class="programlisting">    // Multiply our result with halo
    multiply(resultf, halo, resultf);</pre></div><p>Finally, we convert the float image matrix result to an 8-bit image and show the result:</p><div class="informalexample"><pre class="programlisting">    // convert to 8 bits
    resultf.convertTo(result, CV_8UC3);

    // show result
    imshow("Lomograpy", result);</pre></div><div class="mediaobject"><img src="graphics/B04283_04_09.jpg" alt="Lomography effect"/></div></div>
<div class="section" title="The cartoonize effect"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec36"/>The cartoonize effect</h1></div></div></div><p>In the last section of this chapter, we create <a id="id169" class="indexterm"/>another effect called <span class="strong"><strong>cartoonize</strong></span>. The purpose of this effect is to create an image that looks like a cartoon. To do this, we<a id="id170" class="indexterm"/> divide the algorithm into two steps: edge detection and color filtering.</p><p>The <code class="literal">cartoonCallback</code> functions define this effect with the following code:</p><div class="informalexample"><pre class="programlisting">void cartoonCallback(int state, void* userData)
{
    /** EDGES **/
    // Apply median filter to remove possible noise
    Mat imgMedian;
    medianBlur(img, imgMedian, 7);

    // Detect edges with canny
    Mat imgCanny;
    Canny(imgMedian, imgCanny, 50, 150);
    
    // Dilate the edges
    Mat kernel= getStructuringElement(MORPH_RECT, Size(2,2));
    dilate(imgCanny, imgCanny, kernel);

    // Scale edges values to 1 and invert values
    imgCanny= imgCanny/255;
    imgCanny= 1-imgCanny;
    
    // Use float values to allow multiply between 0 and 1
    Mat imgCannyf;
    imgCanny.convertTo(imgCannyf, CV_32FC3);

    // Blur the edgest to do smooth effect
    blur(imgCannyf, imgCannyf, Size(5,5));

    /** COLOR **/
    // Apply bilateral filter to homogenizes color
    Mat imgBF;
    bilateralFilter(img, imgBF, 9, 150.0, 150.0);

    // truncate colors
    Mat result= imgBF/25;
    result= result*25;

    /** MERGES COLOR + EDGES **/
    // Create a 3 channles for edges
    Mat imgCanny3c;
    Mat cannyChannels[]={ imgCannyf, imgCannyf, imgCannyf};
    merge(cannyChannels, 3, imgCanny3c);

    // Convert color result to float 
    Mat resultf;
    result.convertTo(resultf, CV_32FC3);

    // Multiply color and edges matrices
    multiply(resultf, imgCanny3c, resultf);

    // convert to 8 bits color
    resultf.convertTo(result, CV_8UC3);

    // Show image
    imshow("Result", result);

}</pre></div><p>Let's try to understand the code.</p><p>The first step is to detect the most important edges of the image. We need to remove noise from the input image before we detect the edges. There are several ways and methods to do this. We <a id="id171" class="indexterm"/>will use a median filter to remove any possible small noise, but we can use other methods such as Gaussian blur and so on. The OpenCV function is called <code class="literal">medianBlur</code> and accepts three parameters: an input image, an output image, and the kernel size (a kernel is a small matrix used to apply some mathematical operation such as convolutional to an image).</p><div class="informalexample"><pre class="programlisting">Mat imgMedian;
medianBlur(img, imgMedian, 7);</pre></div><p>After removing any possible noise, we detect the strong edges with a <code class="literal">canny</code> filter:</p><div class="informalexample"><pre class="programlisting">// Detect edges with canny
Mat imgCanny;
Canny(imgMedian, imgCanny, 50, 150);</pre></div><p>The <code class="literal">canny</code> filter accepts the following parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">An input image</li><li class="listitem" style="list-style-type: disc">An output image</li><li class="listitem" style="list-style-type: disc">The first threshold</li><li class="listitem" style="list-style-type: disc">The second threshold</li><li class="listitem" style="list-style-type: disc">The Sobel size aperture</li><li class="listitem" style="list-style-type: disc">The Boolean value to check whether to use a more accurate image gradient magnitude</li></ul></div><p>The smallest value between the first and second threshold is used for edge linking. The largest value is used to find initial segments of strong edges. The <code class="literal">solbel</code> size aperture is the kernel size of the <code class="literal">sobel</code> filter that will be used in the algorithm.</p><p>After detecting the edges, we will apply a small dilation to join the broken edges:</p><div class="informalexample"><pre class="programlisting">    // Dilate the edges
    Mat kernel= getStructuringElement(MORPH_RECT, Size(2,2));
    dilate(imgCanny, imgCanny, kernel);</pre></div><p>Similar to what we did in the Lomography effect, we need to multiply our edges' result image by the color image. Then, we require a pixel value between <code class="literal">0</code> and <code class="literal">1</code>, and so we divide the canny result by <code class="literal">256</code> and invert the edges to black:</p><div class="informalexample"><pre class="programlisting">    // Scale edges values to 1 and invert values
    imgCanny= imgCanny/255;
    imgCanny= 1-imgCanny;</pre></div><p>Transform the Canny 8 unsigned bit format to a float matrix:</p><div class="informalexample"><pre class="programlisting">    // Use float values to allow multiply between 0 and 1
    Mat imgCannyf;
    imgCanny.convertTo(imgCannyf, CV_32FC3);</pre></div><p>To give a cool result, we can blur the edges to give a smooth result line, and then we apply a blur filter:</p><div class="informalexample"><pre class="programlisting">// Blur the edgest to do smooth effect
    blur(imgCannyf, imgCannyf, Size(5,5));</pre></div><p>The first step of the <a id="id172" class="indexterm"/>algorithm is complete, and now we will work with the color.</p><p>To get a cartoon look and feel, we will use the bilateral filter:</p><div class="informalexample"><pre class="programlisting">// Apply bilateral filter to homogenizes color
    Mat imgBF;
    bilateralFilter(img, imgBF, 9, 150.0, 150.0);</pre></div><p>A bilateral filter is a filter used to reduce the noise of an image while keeping edges, but we can get a cartoonish effect with appropriate parameters that we will explore later.</p><p>The bilateral filter parameters are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">An input image</li><li class="listitem" style="list-style-type: disc">An output image</li><li class="listitem" style="list-style-type: disc">The diameter of a pixel neighborhood; if it's set to negative, it is computed from a sigma space value</li><li class="listitem" style="list-style-type: disc">A sigma color value</li><li class="listitem" style="list-style-type: disc">A sigma coordinate space</li></ul></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note20"/>Note</h3><p>With a diameter greater than 5, the bilateral filter becomes slow. With sigma values greater than 150, a cartoonish effect appears.</p></div></div><p>To create a stronger cartoonish effect, we truncate the possible color values to 10 by dividing and multiplying the pixel values. For other values, and to better understand the sigma parameters, read the OpenCV documentation:</p><div class="informalexample"><pre class="programlisting">// truncate colors
    Mat result= imgBF/25;
    result= result*25;</pre></div><p>Finally, we need to merge the color and edges' results. Then, we need to create a <code class="literal">3</code>-channel image from the first step:</p><div class="informalexample"><pre class="programlisting">// Create a 3 channles for edges
    Mat imgCanny3c;
    Mat cannyChannels[]={ imgCannyf, imgCannyf, imgCannyf};
    merge(cannyChannels, 3, imgCanny3c);</pre></div><p>Then, we convert our color result image to a 32 float image and then multiply both the images per element:</p><div class="informalexample"><pre class="programlisting">    // Convert color result to float 
    Mat resultf;
    result.convertTo(resultf, CV_32FC3);

    // Multiply color and edges matrices
    multiply(resultf, imgCanny3c, resultf);</pre></div><p>Finally, we only <a id="id173" class="indexterm"/>need to convert our image to an 8-bit image and show the resulting image to the user:</p><div class="informalexample"><pre class="programlisting">// convert to 8 bits color
    resultf.convertTo(result, CV_8UC3);

    // Show image
    imshow("Result", result);</pre></div><p>In the following image, we can see the input image (the left-hand side image) and the result after applying the cartoonize effect (the right-hand side image):</p><div class="mediaobject"><img src="graphics/B04283_04_10.jpg" alt="The cartoonize effect"/></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec37"/>Summary</h1></div></div></div><p>In this chapter, we learned how to create a complete project that manipulates images after applying different effects. We also split a color image in multiple matrices in order to apply effects to only one channel. We learned how to create look up tables, merge multiple matrices in one, use a canny and bilateral filter, draw circles, and multiply images to perform halo effects.</p><p>In the next chapter, we will learn how to do object inspection and how to segment an image in different parts and detect it.</p></div></body></html>