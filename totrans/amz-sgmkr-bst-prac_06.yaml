- en: 'Chapter 5: Centralized Feature Repository with Amazon SageMaker Feature Store'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 章：使用 Amazon SageMaker Feature Store 的集中式特征仓库
- en: Let's begin with the basic questions – what is a feature store and why is it
    necessary? A feature store is a repository that persists engineered features.
    A lot of time goes into feature engineering, sometimes involving multi-step data
    processing pipelines executed over hours of compute time. ML models depend on
    these engineered features that often come from a variety of data sources. A feature
    store accelerates this process by reducing repetitive data processing that is
    required to convert raw data into features. A feature store not only allows you
    to share engineered features during model-building activities, but also allows
    consistency in using engineered features for inference.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从基本问题开始——什么是特征存储，为什么它是必要的？特征存储是一个持久化工程特征的仓库。特征工程需要花费大量时间，有时涉及多步骤的数据处理管道，这些管道需要数小时的计算时间。机器学习模型依赖于这些来自各种数据源的工程特征。特征存储通过减少将原始数据转换为特征所需的重复数据处理来加速这一过程。特征存储不仅允许你在模型构建活动中共享工程特征，还允许在使用工程特征进行推理时保持一致性。
- en: '**Amazon SageMaker Feature Store** is a managed repository with capabilities
    to store, update, retrieve, and share features. SageMaker Feature Store provides
    the ability to reuse the engineered features in two different scenarios. First,
    the features can be shared between the training and inference phases of a single
    ML project resulting in consistent model inputs and reduced training-serving skew.
    Second, features from SageMaker'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon SageMaker Feature Store** 是一个具有存储、更新、检索和共享特征功能的托管仓库。SageMaker Feature
    Store 提供了在两种不同场景下重用工程特征的能力。首先，特征可以在单个机器学习项目的训练和推理阶段之间共享，从而实现一致的模型输入和减少训练-服务偏差。其次，SageMaker'
- en: Feature Store can also be shared across multiple ML projects, leading to improved
    data scientist productivity.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 特征存储也可以在多个机器学习项目中共享，从而提高数据科学家的生产力。
- en: By the end of this chapter, you will be able to use Amazon SageMaker Feature
    Store capabilities and apply best practices to implement solutions to address
    the challenges of reducing data processing time and architecting features for
    near real-time ML inferences.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将能够使用 Amazon SageMaker Feature Store 的功能，并将最佳实践应用于解决减少数据处理时间和为近实时机器学习推理设计特征架构的挑战。
- en: 'In this chapter, we are going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Basic concepts of Amazon SageMaker Feature Store
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon SageMaker Feature Store 的基本概念
- en: Creating reusable features to reduce feature inconsistencies and inference latency
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建可重用特征以减少特征不一致性和推理延迟
- en: Designing solutions for near real-time ML predictions
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为近实时机器学习预测设计解决方案
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need an AWS account to run the examples included in this chapter. If
    you have not set up the data science environment yet, please refer to [*Chapter
    2*](B17249_02_Final_JM_ePub.xhtml#_idTextAnchor039), *Data Science Environments*,
    which provides a walk-through of the setup process.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要 AWS 账户才能运行本章中包含的示例。如果您尚未设置数据科学环境，请参阅[*第 2 章*](B17249_02_Final_JM_ePub.xhtml#_idTextAnchor039)，*数据科学环境*，其中提供了设置过程的概述。
- en: Code examples included in the book are available on GitHub at [https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter05](https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter05).
    You will need to install a Git client to access them ([https://git-scm.com/](https://git-scm.com/)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 书中包含的代码示例可在 GitHub 上找到，网址为 [https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter05](https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter05)。您需要安装
    Git 客户端才能访问它们（[https://git-scm.com/](https://git-scm.com/)）。
- en: Amazon SageMaker Feature Store essentials
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon SageMaker Feature Store 基础知识
- en: 'In this section, you will learn the basic terminology and capabilities of Amazon
    SageMaker Feature Store. Amazon SageMaker Feature Store provides a centralized
    repository with capabilities to store, update, retrieve, and share features. Scalable
    storage and near real-time feature retrieval are at the heart of Amazon SageMaker
    Feature Store. Utilizing Amazon SageMaker Feature Store involves three high-level
    steps, as shown in the following diagram:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习 Amazon SageMaker Feature Store 的基本术语和功能。Amazon SageMaker Feature Store
    提供了一个集中式仓库，具有存储、更新、检索和共享特征的能力。可扩展的存储和近实时特征检索是 Amazon SageMaker Feature Store 的核心。利用
    Amazon SageMaker Feature Store 涉及三个高级步骤，如下面的图所示：
- en: '![Figure 5.1 – High-level steps with Amazon SageMaker Feature Store'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1 – 使用Amazon SageMaker特征存储的高级步骤'
- en: '](img/B17249_05_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17249_05_01.jpg)'
- en: Figure 5.1 – High-level steps with Amazon SageMaker Feature Store
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 使用Amazon SageMaker特征存储的高级步骤
- en: Let's see what is involved in each of these steps in a bit more detail.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这些步骤中每一步涉及的内容。
- en: Creating feature groups
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建特征组
- en: In Amazon SageMaker Feature Store, features are stored in a collection called
    a `RecordIdentifier` value. Every record belonging to a feature group will use
    the same feature as `RecordIdentifier`. For example, the record identifier for
    the feature store created for the weather data could be `parameter_id` or `location_id`.
    Think of `RecordIdentifier` as a primary key for the feature group. Using this
    primary key, you can query feature groups for the fast lookup of features. It's
    also important to note that each record of a feature group must, at a minimum,
    contain a `RecordIdentifier` and an event time feature. The event time feature
    is identified by `EventTimeFeatureName` when a feature group is set up. When a
    feature record is ingested into a feature group, SageMaker adds three features
    – `is_deleted`, `api_invocation` time, and `write_time` – for each feature record.
    `is_deleted` is used to manage the deletion of records, `api_invocation_time`
    is the time when the API call is invoked to write a record to a feature store,
    and `write_time` is the time when the feature record is persisted to the offline
    store.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在Amazon SageMaker特征存储中，特征存储在一个称为 `RecordIdentifier` 的集合中。属于每个特征组的每个记录都将使用与 `RecordIdentifier`
    相同的特征。例如，为天气数据创建的特征存储的记录标识符可以是 `parameter_id` 或 `location_id`。将 `RecordIdentifier`
    视为特征组的主键。使用这个主键，您可以查询特征组以快速查找特征。还重要的是要注意，特征组的每个记录至少必须包含一个 `RecordIdentifier` 和一个事件时间特征。当设置特征组时，事件时间特征由
    `EventTimeFeatureName` 确定。当特征记录被摄入特征组时，SageMaker为每个特征记录添加三个特征 – `is_deleted`、`api_invocation`
    时间和 `write_time` –。`is_deleted` 用于管理记录的删除，`api_invocation_time` 是调用API将记录写入特征存储的时间，而
    `write_time` 是特征记录持久化到离线存储的时间。
- en: '*Figure 5.2* shows a high-level view of how a feature store is structured:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5.2* 展示了特征存储的结构的高级视图：'
- en: '![Figure 5.2 – Amazon SageMaker feature store structure'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.2 – Amazon SageMaker特征存储结构'
- en: '](img/B17249_05_02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17249_05_02.jpg)'
- en: Figure 5.2 – Amazon SageMaker feature store structure
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – Amazon SageMaker特征存储结构
- en: While each feature group is managed and scaled independently, you can search
    and discover features from multiple feature groups as long as the appropriate
    access is in place.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然每个特征组都是独立管理和扩展的，但你可以在适当访问权限的情况下搜索和发现多个特征组中的特征。
- en: When you create a feature store group with SageMaker, you can choose to enable
    an offline store, online store, or both. When both online and offline stores are
    enabled, the service replicates the online store contents into the offline store
    maintained in Amazon S3\.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用SageMaker创建特征存储组时，可以选择启用离线存储、在线存储或两者都启用。当启用在线和离线存储时，服务将在线存储内容复制到Amazon S3中维护的离线存储。
- en: 'The following code blocks show the process of creating a feature store:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块展示了创建特征存储的过程：
- en: 'First define the feature group name:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先定义特征组名称：
- en: '[PRE0]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, create the feature definitions that capture the feature name and the
    type:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，创建捕获特征名称和类型的特征定义：
- en: '[PRE1]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, define the record identifier feature:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义记录标识符特征：
- en: '[PRE2]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, create the feature group using the `create()` API, which, by default,
    creates a feature group with an offline store:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用 `create()` API创建特征组，默认情况下，它创建一个具有离线存储的特征组：
- en: '[PRE3]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To enable an online store in addition to an offline store, use `enable_online_store`,
    as shown in the following code:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要启用在线存储以及离线存储，请使用 `enable_online_store`，如下面的代码所示：
- en: '[PRE4]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To create a feature group with only an online store enabled, set `s3_uri` to
    `False`, as shown in the following code:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建仅启用在线存储的特征组，将 `s3_uri` 设置为 `False`，如下面的代码所示：
- en: '[PRE5]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Note that you can also create a feature group using **SageMaker Studio**. Once
    feature groups are created either using the APIs or SageMaker Studio, you can
    view them along with their status in SageMaker Studio. *Figure 5.3* shows a list
    of feature groups in SageMaker Studio:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，您还可以使用 **SageMaker Studio** 创建特征组。一旦使用API或SageMaker Studio创建了特征组，您就可以在SageMaker
    Studio中查看它们及其状态。*图5.3* 展示了SageMaker Studio中的特征组列表：
- en: '![Figure 5.3 – Feature groups list in SageMaker Studio'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.3 – SageMaker Studio中的特征组列表'
- en: '](img/B17249_05_03.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17249_05_03.jpg)'
- en: Figure 5.3 – Feature groups list in SageMaker Studio
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – SageMaker Studio中的特征组列表
- en: 'To wrap up the feature group creation discussion, the following table summarizes
    the differences between the online and offline feature stores:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结特征组创建的讨论，以下表格总结了在线和离线特征存储之间的差异：
- en: '![Figure 5.4 – Comparison of online and offline feature stores'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.4 – 在线和离线特征存储的比较'
- en: '](img/B17249_05_04.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17249_05_04.jpg)'
- en: Figure 5.4 – Comparison of online and offline feature stores
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 – 在线特征存储和离线特征存储的比较
- en: Now that you can create feature groups in the feature store, let's take a look
    at how to populate them.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以在特征存储中创建特征组了，让我们看看如何填充它们。
- en: Populating feature groups
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 填充特征组
- en: 'After creating the feature groups, you will populate them with features. You
    can ingest features into a feature group using either **batch ingestion** or **streaming
    ingestion**, as shown in *Figure 5.5*:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建特征组后，您将使用特征填充它们。您可以使用**批量摄取**或**流式摄取**将特征摄取到特征组中，如图5.5所示：
- en: '![Figure 5.5 – Ingesting features into feature groups'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.5 – 将特征摄取到特征组中'
- en: '](img/B17249_05_05.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17249_05_05.jpg)'
- en: Figure 5.5 – Ingesting features into feature groups
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 – 将特征摄取到特征组中
- en: To ingest features into the feature store, you create a feature pipeline that
    can populate the feature store. A `PutRecord` API call is the core SageMaker API
    for ingesting features. This is used for both online and offline feature stores
    as well as ingesting through batch or streaming methods.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要将特征摄取到特征存储中，您创建一个可以填充特征存储的特征管道。`PutRecord` API调用是摄取特征的核心SageMaker API。这适用于在线和离线特征存储，以及通过批量或流式方法摄取。
- en: 'The following code block shows the usage of the `PutRecord` API:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块显示了`PutRecord` API的使用：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can also use a wrapper API, `fg.ingest`, which takes in a pandas `dataframe`
    as input and allows you to configure multiple workers and processes to ingest
    features in parallel. The following code block shows how to use the `ingest()`
    API:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用包装API，`fg.ingest`，它接受一个pandas `dataframe`作为输入，并允许您配置多个工作进程和进程以并行摄取特征。以下代码块显示了如何使用`ingest()`
    API：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'For batch ingestion, you can author features (for example, using `PutRecord`
    API call. When ingesting records to the online feature store, you maintain only
    the latest feature values for a given record identifier. Historical values are
    only maintained in the replicated offline store if the feature group is configured
    for both online and offline stores. *Figure 5.6* outlines the methods to ingest
    features as they relate to the online and offline feature stores:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于批量摄取，您可以使用作者特征（例如，使用`PutRecord` API调用）。当将记录摄取到在线特征存储时，您仅维护给定记录标识符的最新特征值。如果特征组配置了在线和离线存储，则历史值仅在复制的离线存储中维护。图5.6概述了与在线和离线特征存储相关的摄取特征的方法：
- en: '![Figure 5.6 – Ingesting feature store records'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.6 – 摄取特征存储记录'
- en: '](img/B17249_05_06.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17249_05_06.jpg)'
- en: Figure 5.6 – Ingesting feature store records
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 – 摄取特征存储记录
- en: 'With the ingestion APIs in hand, let''s take a look at a generic batch ingestion
    architecture. *Figure 5.7* shows the architecture for batch ingestion with **Amazon
    SageMaker Processing**:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有摄取API在手，让我们看看一个通用的批量摄取架构。图5.7显示了使用**Amazon SageMaker Processing**进行批量摄取的架构：
- en: '![Figure 5.7 – Batch ingestion with SageMaker Processing'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.7 – 使用SageMaker Processing进行批量摄取'
- en: '](img/B17249_05_07.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17249_05_07.jpg)'
- en: Figure 5.7 – Batch ingestion with SageMaker Processing
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 – 使用SageMaker Processing进行批量摄取
- en: 'Here are the high-level steps involved in the batch ingestion architecture:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是批量摄取架构中涉及的高级步骤：
- en: Bulk raw data is available in an S3 bucket.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大量原始数据存储在S3桶中。
- en: The Amazon SageMaker Processing job takes raw data as input and applies feature
    engineering techniques to the data. The processing job can be configured to run
    on a distributed cluster of instances to process data at scale.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Amazon SageMaker Processing作业以原始数据作为输入，并应用特征工程技术到数据上。处理作业可以配置在实例的分布式集群上运行，以大规模处理数据。
- en: The processing job also ingests the engineered features ingested into the online
    store of the feature group, using the `PutRecord` API. Features are then automatically
    replicated to the offline store of the feature group.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理作业还使用`PutRecord` API摄取到特征组的在线存储中的工程化特征。然后，特征自动复制到特征组的离线存储。
- en: Features from the offline store can then be used for training other models and
    by other data science teams to address a wide variety of other use cases. Features
    from the online store can be used for feature lookup during real-time predictions.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 离线存储中的特征可以用于训练其他模型，以及其他数据科学团队来解决各种其他用例。在线存储中的特征可以用于实时预测期间的特性查找。
- en: Note that if the feature store used in this architecture is offline only, the
    processing job can directly write into the offline store using the `PutRecord`
    API.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果在此架构中使用的特征存储仅是离线的，处理作业可以直接使用`PutRecord` API写入离线存储。
- en: 'Next, let''s take a look at a possible streaming ingestion architecture in
    *Figure 5.8*. This should look very similar to batch ingestions, except instead
    of using a processing job, you use a single compute instance or an **AWS Lambda
    function**:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看可能的流式摄取架构，如图5.8所示。这应该看起来与批量摄取非常相似，除了不使用处理作业，而是使用单个计算实例或**AWS Lambda函数**：
- en: '![Figure 5.8 – Streaming ingestion with AWS Lambda'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.8 – 使用AWS Lambda的流式摄取'
- en: '](img/B17249_05_08.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17249_05_08.jpg)'
- en: Figure 5.8 – Streaming ingestion with AWS Lambda
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 – 使用AWS Lambda的流式摄取
- en: 'Here are the high-level steps involved in the streaming ingestion architecture:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 流式摄取架构涉及以下高级步骤：
- en: Raw data lands in an S3 bucket, which triggers an AWS Lambda function.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 原始数据落在S3存储桶中，这触发了AWS Lambda函数。
- en: The Lambda function processes data and inserts features into the online store
    of the feature group, using the `PutRecord` API.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lambda函数通过`PutRecord` API处理数据并将特征插入特征组的在线存储中。
- en: Features are then automatically replicated to the offline store of the feature
    group.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征随后会自动复制到特征组的离线存储中。
- en: Features from the offline store can then be used for training other models and
    by other data science teams to address a wide variety of other use cases. Features
    from the online store can be used for feature lookup during real-time predictions.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 离线存储中的特征可以用于训练其他模型，以及其他数据科学团队来解决各种其他用例。在线存储中的特征可以用于实时预测期间的特性查找。
- en: 'In addition to using the ingestion APIs to populate the offline store, you
    can populate the underlying S3 bucket directly. If you don''t have a need for
    real-time inference and have huge volumes of historical feature data (terabytes
    or even hundreds of gigabytes) that you want to migrate to an offline feature
    store to be used for training models, you can directly upload them to the underlying
    S3 bucket. To do this effectively, it is important to understand the S3 folder
    structure of the offline bucket. Feature groups in the offline store are organized
    in the structure `s3`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用摄取API填充离线存储之外，您还可以直接填充底层S3存储桶。如果您不需要实时推理，并且有大量历史特征数据（数太字节甚至数百吉字节）想要迁移到离线特征存储以用于训练模型，您可以直接将它们上传到底层S3存储桶。为了有效地完成这项工作，了解离线存储桶的S3文件夹结构非常重要。离线存储中的特征组按照`s3`结构组织：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Also note that, when you use ingestion APIs, the features `isdeleted`, `api_invocation_time`,
    and `write-time` are included automatically in the feature record, but when you
    write directly to the offline store, you are responsible for including them.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 还请注意，当您使用摄取API时，`isdeleted`、`api_invocation_time`和`write-time`特征会自动包含在特征记录中，但当你直接写入离线存储时，您负责包括它们。
- en: Retrieving features from feature groups
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从特征组检索特征
- en: 'Once feature groups are populated, to retrieve features from the feature store,
    there are two APIs available – `get_record` and `batch_get_record`. The following
    code block shows retrieving a single record from a feature group using the `get_record`
    API:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦特征组被填充，要从特征存储中检索特征，有两个API可用——`get_record`和`batch_get_record`。以下代码块展示了使用`get_record`
    API从一个特征组中检索单个记录：
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Similarly, the following code shows retrieving multiple records from one or
    more feature groups using the `batch_get_record` API:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，以下代码展示了使用`batch_get_record` API从一个或多个特征组中检索多个记录：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The response from the code block should look similar to the following response:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块的响应应该类似于以下响应：
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The `get_record` and `batch_get_record` APIs should be used with online stores.
    Additionally, since the underlying storage for an offline store is an S3 bucket,
    you can query the offline store directly using Athena or other ways of accessing
    S3\. The following code shows a sample Athena query that retrieves all feature
    records directly from the S3 bucket supporting the offline store:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 应该使用 `get_record` 和 `batch_get_record` API 与在线存储一起使用。此外，由于离线存储的底层存储是一个 S3 存储桶，你可以直接使用
    Athena 或其他访问 S3 的方式来查询离线存储。以下代码展示了从支持离线存储的 S3 存储桶中直接检索所有特征记录的示例 Athena 查询：
- en: '[PRE12]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For the dataset used in this book, we will use two feature groups – location
    and weather data. The location feature group will have `location_id` as the record
    identifier and capture features related to the location such as the city name. The
    weather data feature group will also have `location_id` as the record identifier
    and capture weather quality measurements such as pm25. This allows us to use the
    feature groups across multiple ML projects.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本书中使用的数据集，我们将使用两个特征组——位置和天气数据。位置特征组将使用 `location_id` 作为记录标识符，并捕获与位置相关的特征，例如城市名称。天气数据特征组也将使用
    `location_id` 作为记录标识符，并捕获天气质量测量值，例如 pm25。这使我们能够在多个 ML 项目中使用特征组。
- en: For example, features from both location and weather data feature groups are
    used for a regression model to predict future weather measurements for a given
    location. On the other hand, features from the weather data feature group can
    also be used for a clustering model to find stations with similar measurements.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，来自位置和天气数据特征组的特征被用于回归模型，以预测给定位置的未来的天气测量值。另一方面，来自天气数据特征组的特征也可以用于聚类模型，以找到具有相似测量的站点。
- en: Important note
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'The example notebook provides a walk-through of the key Amazon SageMaker Feature
    Store APIs for creating a feature group, ingesting features into feature groups,
    and retrieving features from a feature group. To see all the feature store capabilities
    in action, we recommend that you execute the sample notebook in the data science
    environment you set up in [*Chapter 2*](B17249_02_Final_JM_ePub.xhtml#_idTextAnchor039),
    *Data Science Environments*:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 示例笔记本提供了创建特征组、将特征摄入特征组以及从特征组中检索特征的 Amazon SageMaker Feature Store 关键 API 的操作指南。为了看到所有功能存储功能在实际中的应用，我们建议你在
    [*第 2 章*](B17249_02_Final_JM_ePub.xhtml#_idTextAnchor039)，*数据科学环境*中设置的数据科学环境中执行示例笔记本：
- en: '[https://gitlab.com/randydefauw/packt_book/-/blob/main/CH05/feature_store_apis.ipynb](https://gitlab.com/randydefauw/packt_book/-/blob/main/CH05/feature_store_apis.ipynb).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://gitlab.com/randydefauw/packt_book/-/blob/main/CH05/feature_store_apis.ipynb](https://gitlab.com/randydefauw/packt_book/-/blob/main/CH05/feature_store_apis.ipynb).'
- en: Now that you have learned the capabilities of SageMaker Feature Store, in the
    next two sections, you will learn how to use these capabilities to solve feature
    design challenges that data scientists and organizations face.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学习了 SageMaker Feature Store 的功能，在接下来的两节中，你将学习如何使用这些功能来解决数据科学家和组织面临的功能设计挑战。
- en: Creating reusable features to reduce feature inconsistencies and inference latency
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建可重用特征以减少特征不一致性和推理延迟
- en: One of the challenges data scientists face is the long data processing time
    – hours and sometimes days – necessary for preparing features to be used for ML
    training. Additionally, the data processing steps applied in feature engineering
    need to be applied to the inference requests during prediction time, which increases
    the inference latency. Each data science team will need to spend this data processing
    time even when they use the same raw data for different models. In this section,
    we will discuss best practices to address these challenges by using Amazon SageMaker
    Feature Store.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家面临的一个挑战是，为了准备用于 ML 训练的特征，需要花费很长时间的数据处理时间——几个小时甚至几天。此外，在特征工程中应用的数据处理步骤需要在预测时间对推理请求进行应用，这增加了推理延迟。每个数据科学团队即使使用相同的原始数据为不同的模型，也需要花费这些数据处理时间。在本节中，我们将讨论使用
    Amazon SageMaker Feature Store 解决这些挑战的最佳实践。
- en: For use cases that require low latency features for inference, an online feature
    store should be configured, and it's generally recommended to enable both the
    online and offline feature store. A feature store enabled with both online and
    offline stores allows you to reuse the same feature values for the training and
    inference phases. This configuration reduces the inconsistencies between the two
    phases and minimizes training and inference skew. In this mode, to populate the
    store, ingest features into the online store either using batch or streaming.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要低延迟特征进行推理的使用案例，应配置在线特征存储，并且通常建议同时启用在线和离线特征存储。启用在线和离线存储的特征存储允许您在训练和推理阶段重用相同的特征值。这种配置减少了两个阶段之间的不一致性，并最小化了训练和推理偏差。在此模式下，为了填充存储，可以使用批量或流式方式将特征摄取到在线存储中。
- en: As you ingest features into an online store, SageMaker automatically replicates
    feature values to an offline store, continuously appending the latest values.
    It's important to note that for the online feature store, only the most current
    feature record is maintained and the `PutRecord` API is always processed as `insert`/`upsert`.
    This is key because if you need to update a feature record, the process to do
    so is to re-insert or overlay the existing record. This is to allow the retrieval
    of features with the minimum possible latency for inference use cases.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将特征摄取到在线存储中时，SageMaker 会自动将特征值复制到离线存储中，并持续追加最新的值。重要的是要注意，对于在线特征存储，只维护最新的特征记录，并且
    `PutRecord` API 总是作为 `insert`/`upsert` 处理。这是关键，因为如果您需要更新特征记录，那么执行此操作的过程是重新插入或覆盖现有记录。这是为了允许以尽可能低的延迟检索用于推理用例的特征。
- en: Although the online feature store maintains only the latest record, the offline
    store will provide a full history of feature values over time. Records will stay
    in the offline store until they are explicitly removed. As a result, you should
    establish a process to prune unnecessary records in the offline feature store
    using the standard mechanisms provided for S3 archival.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在线特征存储只维护最新的记录，但离线存储将提供特征值随时间变化的全历史记录。记录将保留在离线存储中，直到它们被明确删除。因此，您应该建立一个流程，使用为
    S3 归档提供的标准机制来修剪离线特征存储中的不必要记录。
- en: Important note
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'The example notebook from the GitHub repository shows the end-to-end flow of
    creating a feature store, ingesting features, retrieving features, and further
    using the features for training the model, deploying the model, and using the
    features from the feature store during inference: [https://gitlab.com/randydefauw/packt_book/-/blob/main/CH04/feature_store_train_deploy_models.ipynb](https://gitlab.com/randydefauw/packt_book/-/blob/main/CH04/feature_store_train_deploy_models.ipynb).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 GitHub 仓库的示例笔记本展示了创建特征存储、摄取特征、检索特征以及进一步使用特征进行模型训练、部署模型和在使用推理期间从特征存储中获取特征的端到端流程：[https://gitlab.com/randydefauw/packt_book/-/blob/main/CH04/feature_store_train_deploy_models.ipynb](https://gitlab.com/randydefauw/packt_book/-/blob/main/CH04/feature_store_train_deploy_models.ipynb)。
- en: Another best practice is to set up standards for versioning features. As features
    evolve, it is important to keep track of feature versions. Consider versioning
    at two levels – versions of the feature group itself and versions of features
    within a feature group. You need to create a new version of the feature group
    for when the schema of the features change, such as when feature definitions need
    to be added or deleted.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个最佳实践是为特征版本设置标准。随着特征的演变，跟踪特征版本非常重要。考虑在两个级别上进行版本控制——特征组的版本和特征组内特征的版本。当需要添加或删除特征定义时，例如特征模式发生变化时，您需要为特征组创建一个新的版本。
- en: At the time of this book's publication, feature groups are immutable. To add
    or remove features, you will need to create a new feature group. To address the
    requirement of multiple versions of a feature group with different numbers of
    features, establish and stick to naming conventions. For example, you could create
    a `weather-conditions-v1` feature group initially. When that feature group needs
    to be updated, you can create a new `weather-conditions-v2` feature group. You
    can also consider adding descriptive labels on data readiness or usage, such as
    `weather-conditions-latest-v2` or `weather-conditions-stable-v2`. You also can
    tag feature groups to provide metadata. Additionally, you should also establish
    standards for how many concurrent versions to support and when to deprecate old
    versions.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书出版时，特征组是不可变的。要添加或删除特征，你需要创建一个新的特征组。为了满足具有不同数量特征的多个版本的特征组的需求，建立并坚持命名约定。例如，你可以最初创建一个
    `weather-conditions-v1` 特征组。当该特征组需要更新时，你可以创建一个新的 `weather-conditions-v2` 特征组。你也可以考虑在数据准备或使用上添加描述性标签，例如
    `weather-conditions-latest-v2` 或 `weather-conditions-stable-v2`。你还可以对特征组进行标记以提供元数据。此外，你还应该建立支持多少个并发版本的标准以及何时弃用旧版本。
- en: 'For the versioning of the individual features, the offline store keeps a history
    of all values of the features in a feature group. Each feature record is required
    to have an `eventTime`, which supports the ability to access feature versions
    by date. To retrieve previous version values of features from the offline store,
    use an Athena query with a specific timestamp, as shown in the following code
    block:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单个特征的版本控制，离线存储会保留特征组中所有特征值的记录。每个特征记录都需要有一个 `eventTime`，这支持通过日期访问特征版本。要从离线存储中检索特征的先前版本值，请使用具有特定时间戳的
    Athena 查询，如下面的代码块所示：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that you can further fine-tune the Athena query to include `write-time`
    and `api_call_time` to extract very specific versions of the features. Please
    see the references section for a link to a detailed blog on point-in-time queries
    with SageMaker Feature Store.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你可以进一步微调 Athena 查询以包括 `write-time` 和 `api_call_time` 以提取非常具体的特征版本。请参阅参考文献部分，以获取有关
    SageMaker Feature Store 中时间点查询的详细博客链接。
- en: Additionally, when a record is deleted from the online store, the corresponding
    record in the offline store is only logically deleted, which is typically referred
    to as a tombstone. When you query the offline store, you may see a tombstone in
    the results. Use the `is_deleted` feature of the record to filter these records
    from the results.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当记录从在线存储中删除时，离线存储中的相应记录仅逻辑删除，这通常被称为墓碑。当你查询离线存储时，你可能会在结果中看到墓碑。使用记录的 `is_deleted`
    特征从结果中过滤这些记录。
- en: 'Now that you have the feature groups created and populated, how do teams in
    your organization discover and reuse the features? All authorized users of the
    Amazon SageMaker Feature Store can view and browse through a list of feature groups
    in a feature store in a SageMaker Studio environment. You can also search for
    specific feature groups by name, description, record identifier, creation date,
    and tags, as shown in *Figure 5.9*:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经创建了并填充了特征组，你的组织中的团队如何发现和重用这些特征？所有授权的 Amazon SageMaker Feature Store 用户都可以在
    SageMaker Studio 环境中查看和浏览特征存储中的特征组列表。你也可以通过名称、描述、记录标识符、创建日期和标签来搜索特定的特征组，如图 *图
    5.9* 所示：
- en: '![Figure 5.9 – Search and discover feature groups'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.9 – 搜索和发现特征组'
- en: '](img/B17249_05_09.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17249_05_09.jpg)'
- en: Figure 5.9 – Search and discover feature groups
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – 搜索和发现特征组
- en: 'You can go a step further, view feature definitions of the feature group, and
    search for specific features as shown in *Figure 5.10*:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以更进一步，查看特征组的特征定义，并如图 *图 5.10* 所示搜索特定特征：
- en: '![Figure 5.10 – Search and discover features'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.10 – 搜索和发现特征'
- en: '](img/B17249_05_10.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17249_05_10.jpg)'
- en: Figure 5.10 – Search and discover features
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – 搜索和发现特征
- en: In the next section, you will learn about designing an ML system that provides
    near real-time predictions.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将了解如何设计一个提供近实时预测的机器学习系统。
- en: Designing solutions for near real-time ML predictions
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计针对近实时机器学习预测的解决方案
- en: Sometimes machine learning applications demand high-throughput updates to features
    and near real-time access to the updated features. Timely access to fast-changing
    features is critical for the accuracy of predictions made by these applications.
    As an example, consider a machine learning application in a call center that predicts
    how to route the incoming customer calls to available agents. This application
    needs to have knowledge of the customer's latest web session clicks to make accurate
    routing decisions. If you capture a customer's web-click behavior as features,
    the features need to be updated instantly and the application needs access to
    the updated features in near-real time. Similarly, for weather prediction problems,
    you may want to capture the weather measurement features frequently for accurate
    weather predictions and need the ability to look up features in real time.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 有时机器学习应用需要高吞吐量更新特征和接近实时的更新特征访问。及时访问快速变化的特征对于这些应用预测的准确性至关重要。例如，考虑一个在呼叫中心中的机器学习应用，该应用预测如何将
    incoming 客户电话路由到可用的代理。此应用需要了解客户的最新网页会话点击，以便做出准确的路由决策。如果您将客户的网页点击行为作为特征，则特征需要即时更新，并且应用需要接近实时地访问更新后的特征。同样，对于天气预报问题，您可能需要频繁捕获天气测量特征以进行准确的天气预报，并需要实时查找特征的能力。
- en: Let's look at some best practices in designing a reliable solution that meets
    the requirement of high-throughput writes and low-latency reads. At a high level,
    this solution will couple streaming ingestion into a feature group with streaming
    predictions. We will discuss the best practices to apply to ingestion into and
    serving from a feature store.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看设计一个满足高吞吐量写入和低延迟读取要求的可靠解决方案的一些最佳实践。从高层次来看，此解决方案将流式摄取与特征组中的流式预测相结合。我们将讨论应用于特征存储的摄取和服务的最佳实践。
- en: For ingesting features, the decision to choose between batch and streaming ingestion
    should be based on how often feature values in the feature store need to be updated
    for use by downstream training or inference. While simple machine models may need
    features from a single feature group, if you are working with data from multiple
    sources, you will find yourself using features from multiple feature groups. Some
    of these features need to be updated on a periodic basis (hourly, daily, weekly)
    and others must be streamed in near-real time.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 对于摄取特征，选择批处理和流式摄取的决定应基于特征存储中的特征值需要多频繁更新以供下游训练或推理使用。虽然简单的机器模型可能需要来自单个特征组的特征，但如果您正在处理来自多个来源的数据，您将发现自己正在使用来自多个特征组的特征。其中一些特征需要定期更新（每小时、每天、每周），而其他特征必须以接近实时的方式流式传输。
- en: Feature update frequency and inference access patterns should also be used as
    a consideration for creating different feature groups and isolating features.
    By isolating features that need to be inserted on different schedules, the ingestion
    throughput for streaming features can be improved independently. However, retrieving
    values from multiple feature groups increases the number of API calls and can
    increase overall retrieval times.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 特征更新频率和推理访问模式也应作为创建不同特征组和隔离特征的考虑因素。通过隔离需要在不同时间插入的特征，可以独立地提高流式特征的摄取吞吐量。然而，从多个特征组检索值会增加
    API 调用的数量，并可能增加整体检索时间。
- en: Your solution needs to balance feature isolation and retrieval performance.
    If your models require features from a large number of different feature groups
    at inference, design the solution to utilize larger feature groups or to retrieve
    from the feature store in parallel to meet the near real-time SLAs for predictions.
    For example, if your model requires features from three feature groups for inference,
    you can issue three API calls to get the feature record data in parallel before
    merging that data for model inference. This can be done through a typical inference
    workflow executing through an AWS service such as **AWS Step Functions**. Optionally,
    if that same set of features are always used together for inference, you may want
    to consider combining those into a single feature group.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您的解决方案需要平衡特征隔离和检索性能。如果您的模型在推理时需要来自大量不同特征组的特征，设计解决方案以利用更大的特征组或并行从特征存储中检索以满足预测的近实时服务级别协议。例如，如果您的模型在推理时需要来自三个特征组的特征，您可以在合并这些数据用于模型推理之前并行发出三个API调用以获取特征记录数据。这可以通过执行通过AWS服务（如**AWS
    Step Functions**）的典型推理工作流程来完成。如果相同的特征组总是用于推理，您可能还想考虑将这些特征组合成一个单独的特征组。
- en: '*Figure 5.11* shows the end-to-end architecture for streaming ingestion and
    streaming inferences to support high-throughput writes and low-latency reads:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5.11* 展示了支持高吞吐量写入和低延迟读取的流式摄入和流式推理的端到端架构：'
- en: '![Figure 5.11 – End-to-end architecture for real-time feature ingestion and
    retrieval'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.11 – 实时特征摄入和检索的端到端架构'
- en: '](img/B17249_05_11.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17249_05_11.jpg](img/B17249_05_11.jpg)'
- en: Figure 5.11 – End-to-end architecture for real-time feature ingestion and retrieval
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11 – 实时特征摄入和检索的端到端架构
- en: 'Here are the high-level steps involved in this architecture:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构中涉及到的步骤概述如下：
- en: 'On the ingestion side:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在摄入端：
- en: The client application collects and processes the live data. For streaming applications,
    one option is to use **Kinesis Data Streams**. To ingest features, the client
    application calls an ingestion API hosted by an API Gateway.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端应用程序收集并处理实时数据。对于流式应用程序，一个选项是使用**Kinesis数据流**。为了摄入特征，客户端应用程序调用由API网关托管的摄入API。
- en: An API Gateway invokes the lambda function that uses the `put_record` API to
    push features into the online feature store. As necessary, the lambda function
    can also perform additional processing on the raw data before pushing features
    to the feature store.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: API网关调用使用`put_record` API将特征推送到在线特征存储的lambda函数。根据需要，lambda函数还可以在将特征推送到特征存储之前对原始数据进行额外的处理。
- en: 'On the prediction side:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测端：
- en: A model-consuming client application calls a prediction API hosted by an API
    Gateway. An API Gateway invokes a lambda function that looks up the features related
    to inference requests from the online feature store and creates an enhanced request.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型消耗客户端应用程序调用由API网关托管的预测API。API网关调用一个lambda函数，从在线特征存储中查找与推理请求相关的特征，并创建一个增强请求。
- en: The enhanced request is sent to the SageMaker deployed endpoint. The prediction
    from the endpoint traverses back to the client application.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增强请求被发送到SageMaker部署的端点。端点的预测会回传到客户端应用程序。
- en: Using these techniques and best practices, you can design real-time ML systems.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些技术和最佳实践，您可以设计实时机器学习系统。
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you reviewed the basic capabilities of Amazon SageMaker Feature
    Store along with the APIs to use. By combining different capabilities, you learned
    how to reuse engineered features across training and inference phases of a single
    machine learning project and across multiple ML projects. Finally, you combined
    streaming ingestion and serving to design near real-time inference solutions.
    In the next chapter, you will use these engineered features to train and tune
    machine learning models at scale.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您回顾了Amazon SageMaker特征存储的基本功能以及可用的API。通过结合不同的功能，您学习了如何在单个机器学习项目的训练和推理阶段以及多个机器学习项目中重用工程化特征。最后，您结合了流式摄入和提供来设计近实时推理解决方案。在下一章中，您将使用这些工程化特征在规模上训练和调整机器学习模型。
- en: References
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'For additional reading material, please review these references:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 对于额外的阅读材料，请查阅以下参考文献：
- en: 'Using streaming ingestion with Amazon SageMaker Feature Store to make ML-backed
    decisions in near-real time:'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Amazon SageMaker特征存储的流式摄入在近实时内做出基于机器学习的决策：
- en: '[https://aws.amazon.com/blogs/machine-learning/using-streaming-ingestion-with-amazon-sagemaker-feature-store-to-make-ml-backed-decisions-in-near-real-time/](https://aws.amazon.com/blogs/machine-learning/using-streaming-ingestion-with-amazon-sagemaker-feature-store-to-make-ml-backed-decisions-in-near-real-time/
    )'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[使用 Amazon SageMaker Feature Store 进行流式摄取以在接近实时的情况下做出基于机器学习的决策](https://aws.amazon.com/blogs/machine-learning/using-streaming-ingestion-with-amazon-sagemaker-feature-store-to-make-ml-backed-decisions-in-near-real-time/
    )'
- en: 'Enable feature reuse across accounts and teams using Amazon SageMaker Feature
    Store:'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Enable feature reuse across accounts and teams using Amazon SageMaker Feature
    Store:'
- en: '[https://aws.amazon.com/blogs/machine-learning/enable-feature-reuse-across-accounts-and-teams-using-amazon-sagemaker-feature-store/](https://aws.amazon.com/blogs/machine-learning/enable-feature-reuse-across-accounts-and-teams-using-amazon-sagemaker-feature-store/
    )'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[使用 Amazon SageMaker Feature Store 在账户和团队之间启用特征重用](https://aws.amazon.com/blogs/machine-learning/enable-feature-reuse-across-accounts-and-teams-using-amazon-sagemaker-feature-store/
    )'
- en: 'Build accurate ML training datasets using point-in-time queries with Amazon
    SageMaker Feature Store and Apache Spark:'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Build accurate ML training datasets using point-in-time queries with Amazon
    SageMaker Feature Store and Apache Spark:'
- en: '[https://aws.amazon.com/blogs/machine-learning/build-accurate-ml-training-datasets-using-point-in-time-queries-with-amazon-sagemaker-feature-store-and-apache-spark/](https://aws.amazon.com/blogs/machine-learning/build-accurate-ml-training-datasets-using-point-in-time-queries-with-amazon-sagemaker-feature-store-and-apache-spark/
    )'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[使用 Amazon SageMaker Feature Store 和 Apache Spark 通过时间点查询构建准确的机器学习训练数据集](https://aws.amazon.com/blogs/machine-learning/build-accurate-ml-training-datasets-using-point-in-time-queries-with-amazon-sagemaker-feature-store-and-apache-spark/
    )'
- en: 'Ingesting historical feature data into Amazon SageMaker Feature Store:'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ingesting historical feature data into Amazon SageMaker Feature Store:'
- en: '[https://towardsdatascience.com/ingesting-historical-feature-data-into-sagemaker-feature-store-5618e41a11e6](https://towardsdatascience.com/ingesting-historical-feature-data-into-sagemaker-feature-store-5618e41a11e6)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[将历史特征数据摄取到 Amazon SageMaker Feature Store 中](https://towardsdatascience.com/ingesting-historical-feature-data-into-sagemaker-feature-store-5618e41a11e6)'
