<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer053">
			<h1 id="_idParaDest-74"><em class="italic"><a id="_idTextAnchor073"/>Chapter 4</em>: Extending the Cloud to the Edge</h1>
			<p>In the material leading up to this chapter, all of the development steps were performed on your device locally. Local development is useful for learning the tools and rapid prototyping but isn't representative of how you would typically operate a production device. In this chapter, you will treat your hub device as if it were actually deployed in the field and learn how to remotely interact with it using the cloud as a deployment engine. </p>
			<p>Instead of authoring components on the device, you will learn how to use <strong class="bold">Amazon Web Services (AWS) IoT Greengrass</strong> to synchronize cloud resources, such as code, files, and <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) models, to the edge and update devices via deployments. The tools, patterns, and skills you will learn in this chapter are important to your goals of extending the cloud to the edge and practicing how to manage an edge ML solution. You will connect a new client device to your hub device and learn how to bridge connectivity to a cloud solution. Finally, you will deploy your first real ML model to the edge. By the end of this chapter, you will be as familiar with pushing components and resources out to edge devices as you would for a production fleet.</p>
			<p>In this chapter, we're going to cover the following main topics: </p>
			<ul>
				<li>Creating and deploying remotely</li>
				<li>Storing logs in the cloud</li>
				<li>Synchronizing the state between the edge and the cloud</li>
				<li>Deploying your first ML model</li>
			</ul>
			<h1 id="_idParaDest-75"><a id="_idTextAnchor074"/>Technical requirements</h1>
			<p>To complete the hands-on steps for this chapter, you should have a hub device as defined by the hardware and software requirements in the Hands-on prerequisites section of <a href="B17595_01_Final_SS_ePub.xhtml#_idTextAnchor013"><em class="italic">Chapter 1</em></a><em class="italic">, Introduction to the Data-Driven Edge with Machine Learning</em>, and that device should be loaded with <strong class="bold">AWS IoT Greengrass</strong> core software, as defined by the steps from <a href="B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032"><em class="italic">Chapter 2</em></a><em class="italic">, Foundations of Edge Workloads</em>. You will also need access to your <strong class="bold">command-and-control</strong> (<strong class="bold">C2</strong>) system, typically your PC or a laptop that has a web browser, and access to the AWS management console.</p>
			<p>The resources provided to you for the steps in this chapter are available in the GitHub repository under the <strong class="source-inline">chapter4</strong> folder, at <a href="https://github.com/PacktPublishing/Intelligent-Workloads-at-the-Edge/tree/main/chapter4">https://github.com/PacktPublishing/Intelligent-Workloads-at-the-Edge/tree/main/chapter4</a>.</p>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor075"/>Creating and deploying remotely</h1>
			<p>Up until now, you<a id="_idIndexMarker281"/> have been interacting with your IoT Greengrass solution <a id="_idIndexMarker282"/>directly on the hub device using the IoT Greengrass <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>). Going forward, you will learn how to interact with your IoT Greengrass device from your C2 system (laptop or workstation) through the use of the AWS cloud. The CLI and local development lifecycle are great for learning the basics of IoT Greengrass and rapid iteration on component development. The best practice for production solutions is not to deploy the Greengrass CLI component to your devices and install new components locally, so next, you will learn how to <a id="_idIndexMarker283"/>package your components, store them in AWS, and complete remote deployments to your hub device. </p>
			<h2 id="_idParaDest-77"><a id="_idTextAnchor076"/>Loading resources from the cloud</h2>
			<p>Components <a id="_idIndexMarker284"/>can include any number of artifacts defined by the recipe file, and those artifacts must be stored somewhere the Greengrass device can access them. Artifacts can be static resources of any kind: binary data such as images or text, application code such as Python source code or compiled <strong class="bold">Java ARchive</strong> files (<strong class="bold">JARs</strong>), containerized <a id="_idIndexMarker285"/>code such as a Docker container, and anything else that your component needs a copy of to work, the keywords here being <strong class="bold">static</strong> and <strong class="bold">copy</strong>. Artifacts are resources that your device uses that are copies that every other device deploying that component uses. They are also not intended to change on the device after deployment.</p>
			<p>The other kind of resource that <a id="_idIndexMarker286"/>components use is <strong class="bold">dynamic resources</strong>. A dynamic resource gets loaded as a configuration specific to the device or something that gets consumed at runtime. Dynamic resources may be ephemeral in that they exist only as long as the device is online or a component is running. Some examples of dynamic resources are secrets to <a id="_idIndexMarker287"/>reference in your code such as an <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>) key, behavioral settings to include based on the<a id="_idIndexMarker288"/> device's <strong class="bold">identifier</strong> (<strong class="bold">ID</strong>) or other metadata, and communication channels between any leaf devices (those at terminal<a id="_idIndexMarker289"/> points in the solution, such as <strong class="bold">Home Base Solutions</strong> (<strong class="bold">HBS</strong>) appliance monitoring kits) and<a id="_idIndexMarker290"/> the Greengrass device (such as the HBS hub device), software components, and the cloud. </p>
			<p>In the first hands-on section of this chapter, you will get familiar with how a recipe defines static resources as artifacts and perform your first remote deployment with a custom component. Later sections of this chapter will introduce implementations for dynamic resources.</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor077"/>Packaging your components for remote deployment</h2>
			<p>The<a id="_idIndexMarker291"/> main difference between local and remote deployment on IoT Greengrass is where the component resources come from. In your local development lifecycle, you were authoring files on the hub device itself and pointing to folders containing recipe and artifact files. For remote deployment, you must store your files in the AWS cloud using <strong class="bold">Amazon Simple Storage Service</strong> (<strong class="bold">Amazon S3</strong>) and <a id="_idIndexMarker292"/>update your recipes to point at S3 object locations. In the next steps, you will update the permissions model of your IoT Greengrass device to be able to read objects from S3, package up a component to S3 using the AWS CLI, and create a new remote deployment to your hub device.</p>
			<h3>Updating IoT Greengrass permissions</h3>
			<p>In your initial <a id="_idIndexMarker293"/>setup of IoT Greengrass on your hub device, a new role was created in the <strong class="bold">AWS Identity and Access Management</strong> (<strong class="bold">AWS IAM</strong>) service<a id="_idIndexMarker294"/> that the IoT Greengrass core service uses to get authorization to interact with any AWS services. In AWS, the AWS IAM service is where all users, groups, policies, and roles are defined that grant access to resources and APIs in your account. </p>
			<p>A <strong class="bold">user</strong> is an <a id="_idIndexMarker295"/>IAM resource that serves as identification—for example, you as the <strong class="bold">internet of things</strong> (<strong class="bold">IoT</strong>) architect<a id="_idIndexMarker296"/> getting permissions to use APIs, or the <strong class="source-inline">idtgg</strong> user we defined for initially provisioning your hub device in AWS. A <strong class="bold">policy</strong> documents <a id="_idIndexMarker297"/>the sets of allowed and denied permissions that we attach to identities. A <strong class="bold">role</strong> is a<a id="_idIndexMarker298"/> façade of permissions that authorized users can assume to gain those specified permissions. A user gets permissions granted in one of three ways. Policies can be directly attached to the user or <a id="_idIndexMarker299"/>inherited from a group to which they belong. Policies can also be attached to roles that users assume for temporary sessions, letting the user perform specific session-based tasks following the <strong class="bold">principle of least privilege</strong> (<strong class="bold">POLP</strong>). By <a id="_idIndexMarker300"/>using roles, we can define abstract sets of permissions that users can gain for the completion of specific tasks to follow the best practice of limiting permission scope. Here is a simple illustration of the relationship between a user (one type of security principal), a role, a policy, and the permissions granted to the user by assuming the role:</p>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="Images/B17595_04_01.jpg" alt="Figure 4.1 – An IAM user gets temporary permissions and credentials from a role&#13;&#10;" width="553" height="354"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.1 – An IAM user gets temporary permissions and credentials from a role</p>
			<p>A real-world analogy for users, policies, and roles is when your friend temporarily gives you their house key while they are away so that you can water their plants or feed their cat. You can think of the role as <em class="italic">Someone Who Can Enter My House</em>, and the house key is the policy that grants access to their house. By trusting you with the key, your friend is granting you, the user, a temporary role to enter their home. When your task is complete and your friend returns home, you relinquish the key and thus end your session in<a id="_idIndexMarker301"/> that role. In the digital world, you as the user have your own key (such as a public certificate) that identifies you. The role and its policy grant your key temporary permission to access the resource instead of giving you the only key!</p>
			<p>The installation process of IoT Greengrass created a new role named <strong class="source-inline">GreengrassV2TokenExchangeRole</strong> and attached to it a policy named <strong class="source-inline">GreengrassV2TokenExchangeRoleAccess</strong> that grants access to the APIs for interacting with the AWS IoT Core service and for writing logs to Amazon CloudWatch. By default, and as a best security practice, this policy does not include access to objects stored in S3. It is up to you as the solution developer to describe which S3 objects your devices should be able to access and add that configuration to the role as a new policy. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">For the rest of this chapter, steps with AWS CLI commands and simple filesystem management commands (such as the creation of new directories or files) will be written in Unix format for macOS and Linux systems. To get help using commands in AWS CLI where there are distinct differences for Windows, such as referencing local files as input, please refer to the AWS CLI documentation at <a href="https://docs.aws.amazon.com/cli/latest/userguide/">https://docs.aws.amazon.com/cli/latest/userguide/</a>.</p>
			<p>In the next steps, you will use the AWS CLI to create a new bucket in S3, a new policy that grants read permissions to objects in that S3 bucket, and then attach the new policy to the role used by IoT Greengrass devices. Proceed as follows:</p>
			<ol>
				<li>From your C2 system, open the terminal (or run <strong class="source-inline">cmd.exe</strong>/PowerShell on Windows).</li>
				<li>Use the AWS CLI to print out your 12-digit account ID by running the following command: <strong class="source-inline">aws sts get-caller-identity --query 'Account'</strong> (the output should look like this: <strong class="source-inline">012345678912</strong>).</li>
				<li>Create a new S3 bucket in your account. S3 bucket names share a global namespace in AWS. A good practice for naming buckets is to include your AWS account ID as a unique string. If a bucket name is already taken, you can add unique text (such as your initials) to the name until you find one that is not taken. Use the<a id="_idIndexMarker302"/> account ID from the previous step and replace the 12-digit account ID placeholder. Be sure to update the region if you're not using the default of <strong class="source-inline">us-west-2</strong>. The output should look like this: <strong class="source-inline">aws s3 mb s3://012345678912-hbs-components --region us-west-2</strong>. </li>
				<li>From here on out, we will refer to this bucket name as <strong class="source-inline">REPLACEME_HBS_COMPONENTS_BUCKET</strong>. When you see a command or text in a file with the <strong class="source-inline">REPLACEME_HBS_COMPONENTS_BUCKET</strong> placeholder, you need to replace it with the name of your bucket, like this: <strong class="source-inline">012345678912-hbs-components</strong>.</li>
				<li>Next, you will create a local file to store the content of the new policy that grants read access to the objects in your new bucket. You can find a template of this file in the GitHub repository for this book at the <strong class="source-inline">chapter4/greengrass_read_s3.json</strong> path and update the <strong class="source-inline">REPLACEME_HBS_COMPONENTS_BUCKET</strong> placeholder. If you're creating the file yourself, name it <strong class="source-inline">greengrass_read_s3.json</strong> and add the following content (remembering to replace the placeholder!):<p class="SC---Heading" lang="en-US" xml:lang="en-US">greengrass_read_s3.json</p><p class="source-code">{</p><p class="source-code">  "Version": "2012-10-17",</p><p class="source-code">  "Statement": [</p><p class="source-code">    {</p><p class="source-code">      "Effect": "Allow",</p><p class="source-code">      "Action": [</p><p class="source-code">        "s3:GetObject"</p><p class="source-code">      ],</p><p class="source-code">      "Resource": "arn:aws:s3:::REPLACEME_HBS_COMPONENTS_BUCKET/*"</p><p class="source-code">    }</p><p class="source-code">  ]</p><p class="source-code">}</p></li>
				<li>Create a new policy in IAM with this document as its source: <strong class="source-inline">aws iam create-policy --policy-name GreengrassV2ReadComponentArtifacts --policy-document file://greengrass_read_s3.json</strong>.</li>
				<li>Add the <a id="_idIndexMarker303"/>policy to the IAM role used by IoT Greengrass. Replace the value of the <strong class="source-inline">--policy-arn</strong> argument with the <strong class="source-inline">arn</strong> value output from the previous command, as follows: <strong class="source-inline">aws iam attach-role-policy --role-name GreengrassV2TokenExchangeRole --policy-arn arn:aws:iam::012345678912:policy/ GreengrassV2ReadComponentArtifacts</strong>.</li>
			</ol>
			<p>Now, your IoT Greengrass devices, such as the HBS hub device, can read component files that are stored in your S3 bucket. Let's cover one more element of how the security model works between the hub device and an AWS resource. </p>
			<p>Earlier, we described the relationship in AWS IAM between a user, a role, and a policy. Your devices don't have any identity as a user in AWS IAM, so how do they assume the role? The answer is a feature of AWS IoT Core called the <strong class="bold">Credentials Provider service</strong>. Your<a id="_idIndexMarker304"/> devices do have an identity provisioned in AWS IoT Core using<a id="_idIndexMarker305"/> an <strong class="bold">X.509</strong> private key and public certificate. The credentials provider service is a means for connected devices to present their registered public certificates in exchange for temporary AWS credentials that have permissions granted through an IAM role. </p>
			<p>Here is a sequence diagram showing the path for your HBS hub device to get permissions and ultimately read an object in S3:</p>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="Images/B17595_04_02.jpg" alt="Figure 4.2 – Sequence diagram to fetch temporary credentials&#13;&#10;" width="571" height="351"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.2 – Sequence diagram to fetch temporary credentials</p>
			<p>As your <a id="_idIndexMarker306"/>edge solution adds features that interact with more AWS services, you must add permissions to those services using the same process you just completed. The same is true for your custom components that interact with AWS since all components get permissions through the IAM role of your device's configuration. As the number of distinct edge solutions in your account grows, the best practice is to create distinct IAM roles per distinct group of devices. For example, each HBS hub will have the same solution and can share a common role that defines permissions to access AWS. For the next project at HBS using IoT Greengrass, instead of adding more permissions to the same IAM role, it is best to create a new role for devices of that project. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">There is a regional quota for the number of roles you can define for your devices in AWS IoT. As of this writing, the quota is 100. This means you don't want to create a unique role per Greengrass device, as you will quickly reach the maximum quota as you scale. A best practice for a production solution on AWS is to use one AWS account per production solution, such as maintaining the fleets of hub devices at HBS. A different product line may be deployed in a separate AWS account, thus expanding the total number of roles to use.</p>
			<p>With the new <a id="_idIndexMarker307"/>permissions added, you can move on to the next section, where you will package up a new component and register it in the cloud service of IoT Greengrass.</p>
			<h3>Registering a component in IoT Greengrass</h3>
			<p>In order to <a id="_idIndexMarker308"/>remotely deploy a component to your hub device, you must first register the component in the cloud service of IoT Greengrass. You will provide a recipe file as input to an API, just like you did when using the local IoT Greengrass CLI on your device. The recipe file will define the location of all artifacts used <a id="_idIndexMarker309"/>by the component. These artifacts must be uploaded to an S3 bucket such as the one created in the previous step. When IoT Greengrass processes your recipe file, it will register a new component in your account that can then be referenced in a future deployment to any of your devices. </p>
			<p>The first step in registering a component is to add your artifact files to the S3 bucket. Only then will you know the addresses of those files in S3 to be able to update a recipe that can reference them. In this section, you will upload a ZIP archive as an artifact, replace the path to the artifact in the recipe file, then register the component in your account using the<a id="_idIndexMarker310"/> AWS <strong class="bold">software development kit</strong> (<strong class="bold">SDK</strong>), as follows:</p>
			<ol>
				<li value="1">From the book's GitHub repository, change directory to <strong class="source-inline">chapter 4</strong> by running the following command: <strong class="source-inline">cd chapter4</strong>.</li>
				<li>Use the AWS SDK to upload the artifact file by running the following command: <strong class="source-inline">aws s3 cp artifacts/com.hbs.hub.HelloWithConfig/1.0.0/archive.zip s3://REPLACEME_HBS_COMPONENTS_BUCKET/artifacts/com.hbs.hub.HelloWithConfig/1.0.0/archive.zip</strong>.</li>
				<li>Edit the <strong class="source-inline">recipes/com.hbs.hub.HelloWithConfig-1.0.0.json</strong> file and replace the value<a id="_idIndexMarker311"/> of the <strong class="bold">Uniform Resource Identifier</strong> (<strong class="bold">URI</strong>) key with the path to your <a id="_idIndexMarker312"/>artifact in S3 (the last argument in the previous step). After filling it in, it should look something like this:<p class="source-code">"Artifacts": [</p><p class="source-code">  {</p><p class="source-code">    "URI": "s3://012345678912-hbs-components/artifacts/com.hbs.hub.HelloWithConfig/1.0.0/archive.zip",</p><p class="source-code">    "Unarchive": "ZIP",</p></li>
				<li>Now<a id="_idIndexMarker313"/> that your artifact is in S3 and your recipe file is updated, you can use the AWS SDK to register your new component in the cloud service of IoT Greengrass. In the response will be the <strong class="bold">Amazon Resource Name</strong> (<strong class="bold">ARN</strong>) of<a id="_idIndexMarker314"/> your component that you will use for future steps. Run the following command: <strong class="source-inline">aws greengrassv2 create-component-version --inline-recipe fileb://recipes/com.hbs.hub.HelloWithConfig-1.0.0.json</strong>.</li>
				<li>The preceding command returns a status such as <strong class="source-inline">componentState=REQUESTED</strong> to signal that IoT Greengrass is taking steps to register your new component. To check on the status of your component registration, run the following command (replacing the <strong class="source-inline">--arn</strong> argument with the one found in the output from the previous step): <strong class="source-inline">aws greengrassv2 describe-component --arn arn:aws:greengrass:us-west-2:012345678912:components:com.hbs.hub.HelloWithConfig:versions:1.0.0</strong>.</li>
			</ol>
			<p>When the component is registered in the service, you will see a response to this command with the <strong class="source-inline">componentState</strong> value now showing as <strong class="source-inline">DEPLOYABLE</strong>. This means the <a id="_idIndexMarker315"/>component is now ready for inclusion in a new deployment to a device. Before moving on to the deployment, let's take a look at the recipe file now stored by IoT Greengrass with the following command (replace the <strong class="source-inline">--arn</strong> argument with your component's ARN from previous steps): <strong class="source-inline">aws greengrassv2 get-component --arn arn:aws:greengrass:us-west-2: 012345678912:components:com.hbs.hub.HelloWithConfig:versions:1.0.0 --query "recipe" --output text | base64 --decode</strong>. You may notice the recipe file doesn't look exactly like the one you sent to IoT Greengrass. Here's what the <strong class="source-inline">Artifacts</strong> object looks like now:</p>
			<p class="source-code">"Artifacts":[{"Uri":"s3://012345678912-hbs-components/artifacts/com.hbs.hub.HelloWithConfig/1.0.0/archive.zip","Digest":"wvcSArajPd+Ug3xCdt0P1J74/I7QA2UbuRJeF5ZJ7ks=","Algorithm":"SHA-256","Unarchive":"ZIP","Permission":{"Read":"OWNER","Execute":"OWNER"}}]</p>
			<p>What's<a id="_idIndexMarker316"/> new here are the <strong class="source-inline">Digest</strong> and <strong class="source-inline">Algorithm</strong> keys. This is a security feature of IoT Greengrass. When your recipe is registered as a component in the service, IoT Greengrass computes a <strong class="source-inline">SHA-256</strong> hash of each artifact file referenced by the recipe. The purpose is to ensure that the artifacts eventually downloaded by any IoT Greengrass devices have not been modified before use. This also means you cannot alter an artifact file stored on S3 after registering the component. To update any artifact requires you to register a new version of the component and deploy the new component version. </p>
			<p>Two more deltas between this component and components developed locally in previous chapters are the use of the decompressed path and artifact permissions. Here is a snapshot of the key differences in this recipe file:</p>
			<p class="source-code">"Lifecycle": {</p>
			<p class="source-code">  "Run": "cd {artifacts:decompressedPath}/archive &amp;&amp; ./hello.sh"</p>
			<p class="source-code">},</p>
			<p class="source-code">"Artifacts": [</p>
			<p class="source-code">  {</p>
			<p class="source-code">    "URI": "s3://REPLACEME_HBS_COMPONENTS_BUCKET/artifacts/com.hbs.hub.HelloWithConfig/1.0.0/archive.zip",</p>
			<p class="source-code">    "Unarchive": "ZIP",</p>
			<p class="source-code">    "Permission": {</p>
			<p class="source-code">      "Execute": "OWNER"</p>
			<p>In the <strong class="source-inline">Lifecycle</strong> object, you can see the run script that makes reference to the <strong class="source-inline">artifacts:decompressedPath</strong> variable. This variable points to the directory where Greengrass automatically unarchives your archived artifacts. Files are unpacked to a subdirectory <a id="_idIndexMarker317"/>with the same name as the archive—in this case, <strong class="source-inline">archive/</strong>. We know our <strong class="source-inline">hello.sh</strong> script will reference the adjacent <strong class="source-inline">config.txt</strong> file from the same archive. We must tell the run script to change directory to the decompressed path and then run the script in order to find the <strong class="source-inline">config.txt</strong> file in the correct directory context. </p>
			<p>The best<a id="_idIndexMarker318"/> practice for your artifacts is to consume them from the <strong class="source-inline">artifacts</strong> directory, as downloaded or unpacked by IoT Greengrass, and to use the component's work directory, available in the recipe as <strong class="source-inline">work:path</strong>, for files to which your component will write data. The <strong class="source-inline">work</strong> directory is the default context for any lifecycle script, and that is why we include a <strong class="source-inline">change</strong> directory command before running our script artifact. </p>
			<p>The other new inclusion is the <strong class="source-inline">Permission</strong> object, where you can see we are setting an <strong class="source-inline">Execute</strong> property to the <strong class="source-inline">OWNER</strong> value. By default, artifacts and files from unpacked artifacts have a filesystem permission of <strong class="source-inline">Read</strong> for the component's owner (such as the default <strong class="source-inline">ggc_user</strong>). This means a script file in our <strong class="source-inline">archive.zip</strong> file would not be executable without a change to the file's permissions. Using the <strong class="source-inline">Permission</strong> object for any artifact, we can set the <strong class="source-inline">Read</strong> and <strong class="source-inline">Execute</strong> filesystem permissions to any of <strong class="source-inline">NONE</strong>, <strong class="source-inline">OWNER</strong>, or <strong class="source-inline">ALL</strong> (all system users). This is also related to why artifacts are write-protected. Artifacts are intended to be read-only resources consumed by the component or executable files that should not be changed without a revision to the component's definition.</p>
			<p>In the next section, you will deploy your newly registered component to your device. </p>
			<h3>Remotely deploying a component</h3>
			<p>With your <a id="_idIndexMarker319"/>component now available in the IoT Greengrass service, it's time to start a remote deployment from your C2 system to your HBS hub device using the AWS CLI. This kind of deployment from a remote system using the IoT Greengrass cloud service is the standard way by which you will deploy updates to your devices. It may not always be a manual step from your developer laptop, but we will cover more details about the production pipeline in <a href="B17595_08_Final_SS_ePub.xhtml#_idTextAnchor163"><em class="italic">Chapter 8</em></a>, <em class="italic">DevOps and MLOps for the Edge</em>.</p>
			<p>In the local development lifecycle, the only device that you were deploying your component to was the local one. Deployment through the cloud service of IoT Greengrass is how you specify multiple target devices. These kinds of deployments are how you scale up your ability to manage a fleet of any size that should all have the same components running on them. A deployment will also specify rollout and success criteria, such as the rate at which to notify devices, how long they have to report a successful deployment, how long to wait for components to signal they are ready for updates, and what to do if the deployment fails. </p>
			<p>In the following steps, you will write a file that tells IoT Greengrass about the details of your deployment, initiate the deployment, and then verify the deployment's success:</p>
			<ol>
				<li value="1">You will need the ARN of the <strong class="bold">thing group</strong> to which your HBS hub device belongs. A thing group is an addressing mechanism of AWS IoT Core for grouping like devices together. You created the <strong class="source-inline">hbshubprototypes</strong> thing group as an argument in the initial IoT Greengrass core software installation. The following command will fetch the ARN of your thing group that you will use in the next step: <strong class="source-inline">aws iot describe-thing-group --thing-group-name hbshubprototypes --query "thingGroupArn"</strong>.</li>
				<li>Edit the <strong class="source-inline">chapter4/deployment-hellowithconfig.json</strong> file from the GitHub repository and replace the value of <strong class="source-inline">targetArn</strong> with the thing group ARN output from the previous step. After editing the file, it should look something like this:<p class="source-code">{</p><p class="source-code">  "targetArn": "arn:aws:iot:us-west-2:012345678912:thinggroup/hbshubprototypes",</p><p class="source-code">  "components": {</p><p class="source-code">    "aws.greengrass.Cli": {</p><p class="source-code">      "componentVersion": "2.4.0"</p><p class="source-code">    },</p><p class="source-code">    "com.hbs.hub.HelloWithConfig": {</p><p class="source-code">      "componentVersion": "1.0.0"</p><p class="source-code">    }</p><p class="source-code">  }</p><p class="source-code">}</p></li>
				<li>Start a new deployment to the group containing your hub device using the following deployment configuration: <strong class="source-inline">aws greengrassv2 create-deployment --cli-input-json file://deployment-hellowithconfig.json</strong>.</li>
				<li>The previous command starts the deployment process. To check on the status of the deployment on a particular device, such as your <strong class="source-inline">hbshub001</strong> device, you can use the following command: <strong class="source-inline">aws greengrassv2 list-effective-deployments --core-device-thing-name hbshub001</strong>.</li>
				<li>To<a id="_idIndexMarker320"/> validate on your device that the component ran as intended, you can log in <a id="_idIndexMarker321"/>or use a <strong class="bold">Secure Shell</strong> (<strong class="bold">SSH</strong>) back into your device and check the logs with <strong class="source-inline">sudo less /greengrass/v2/logs/com.hbs.hub.HelloWithConfig.log</strong> as follows:<p class="source-code"><strong class="bold">2021-07-27T20:19:07.652Z [INFO] (pool-2-thread-91) com.hbs.hub.HelloWithConfig: shell-runner-start. {scriptName=services.com.hbs.hub.HelloWithConfig.lifecycle.Run, serviceName=com.hbs.hub.HelloWithConfig, currentState=STARTING, command=["./hello.sh"]}</strong></p><p class="source-code"><strong class="bold">2021-07-27T20:19:07.685Z [INFO] (Copier) com.hbs.hub.HelloWithConfig: stdout. Hello from Zimbabwe!. {scriptName=services.com.hbs.hub.HelloWithConfig.lifecycle.Run, serviceName=com.hbs.hub.HelloWithConfig, currentState=RUNNING}</strong></p><p class="source-code"><strong class="bold">2021-07-27T20:19:07.699Z [INFO] (Copier) com.hbs.hub.HelloWithConfig: Run script exited. {exitCode=0, serviceName=com.hbs.hub.HelloWithConfig, currentState=RUNNING}</strong></p></li>
			</ol>
			<p>At this point, you have completed your first remote deployment to your hub device using IoT Greengrass! The overall process is not too different from local development. We needed to upload our artifacts to a cloud service such as S3, update the recipe file to point to these new artifact locations, and register the component before including it in a deployment. The deployment itself also has a few more options for specifying which devices to target, behavior for scaling out to a fleet, and criteria and behavior of success or failure.</p>
			<p>Each thing<a id="_idIndexMarker322"/> group has a 1:1 mapping with a deployment that represents the latest configuration each device in that group should be using. When you want to deploy a change to a group of devices, you will create a revision to the deployment instead of starting an all-new deployment. A revision still takes a deployment configuration similar to the one we used in this section and expects an explicit definition of all components and configuration, meaning it is not an amendment to the last known deployment.</p>
			<p>You can include a device in multiple thing groups, where each thing group defines a deployment of unique configuration and components. For example, you could define a thing group of monitoring components that get applied to all HBS devices, and pair this with thing groups that specify business logic components based on the kind of device it is, such as our smart home hub. A device that belongs to multiple thing groups will receive deployment notifications for each group and merge the component graph from all of them. Here is an illustration of how we can use thing groups to effectively manage the components that get deployed across a fleet of devices to build up an aggregate solution:</p>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="Images/B17595_04_03.jpg" alt="Figure 4.3 – Example of aggregating components across group deployments&#13;&#10;" width="725" height="491"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.3 – Example of aggregating components across group deployments</p>
			<p>As mentioned earlier, your deployment configuration can specify whether to allow components an option to signal they are ready for a restart or update. The value of letting components interact<a id="_idIndexMarker323"/> with deployment behavior in this way is to prevent any loss of data or business process interruption from the component suddenly being terminated. The <a id="_idIndexMarker324"/>component must include the use of IoT Greengrass <strong class="bold">interprocess communication</strong> (<strong class="bold">IPC</strong>) with the IoT Greengrass SDK and implement the <strong class="source-inline">SubscribeToComponentUpdates</strong> function. </p>
			<p>A component can then respond to component update events and request a deferment by publishing a message back over IPC using the <strong class="source-inline">DeferComponentUpdate</strong> command. There is a similar operation for components to validate configuration change requests with <strong class="source-inline">SubscribeToValidateConfigurationUpdates</strong> and the respective <strong class="source-inline">SendConfigurationValidityReport</strong> features. You can learn more about these features from the <em class="italic">References</em> section at the end of this chapter. </p>
			<p>With your first remote deployment complete and with a better understanding of how the deployment <a id="_idIndexMarker325"/>service of IoT Greengrass works, let's make it easier to remotely troubleshoot your hub device and its components by enabling the publication of local logs to the cloud.</p>
			<h1 id="_idParaDest-79"><a id="_idTextAnchor078"/>Storing logs in the cloud</h1>
			<p>An<a id="_idIndexMarker326"/> edge solution loads resources from the cloud in order to bootstrap, configure, and generally make the local solution ready for runtime. The health of the device and the solution should also be reported to the cloud to assist with production operations. By default, your HBS hub device checks in with the cloud IoT Greengrass <a id="_idIndexMarker327"/>service to report connectivity status and the result of the most recent deployment. To get more telemetry from the edge solution, such as logs and metrics, you need to deploy additional components. In this section, you will deploy a managed component that ships component logs up to Amazon CloudWatch, a service for storing and querying logs.</p>
			<p>Storing the logs of our hub devices in the cloud is a best practice and enables us to triage devices individually without needing a live connection to the device or being physically in front of it. After all, some of these devices may be in rather remote locations such as the Alaskan tundra or only come online at scheduled times, such as the narwhal-studying submersible from <a href="B17595_01_Final_SS_ePub.xhtml#_idTextAnchor013"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to the Data-Driven Edge with Machine Learning</em>.</p>
			<p>Another benefit of storing logs in the cloud is that you can run queries across a fleet of devices to discover insights about fleet performance. For example, a simplistic count of lines per device log over a 24-hour period could find outliers of <em class="italic">chatty</em> devices where there is an abnormal amount of activity, which could mean the device is processing an unusual amount of data or thrashing resources. The following histogram of log activity across our fleet would indicate a potential problem for your operations team to triage:</p>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="Images/B17595_04_04.jpg" alt="Figure 4.4 – Sample histogram showing device outliers based on log activity&#13;&#10;" width="641" height="358"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.4 – Sample histogram showing device outliers based on log activity</p>
			<p>Since<a id="_idIndexMarker328"/> storing logs is such a common use case for an edge solution and also in the wider spectrum of cloud application development, IoT Greengrass <a id="_idIndexMarker329"/>provides a managed component to make it easy to ingest your components' logs. This managed component, called <strong class="source-inline">aws.greengrass.LogManager</strong>, is authored and maintained by AWS. Managed components are anticipated as fulfilling common requirements of IoT architects but deemed as opt-in features that you need to bring in with your deployments.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The latest version of the <strong class="source-inline">aws.greengrass.LogManager</strong> managed component at the time of this writing was <em class="italic">2.2.0</em>. You may need to update the version based on the latest version of IoT Greengrass core software installed when you started this book. For the steps in <a href="B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032"><em class="italic">Chapter 2</em></a>, <em class="italic">Foundations of Edge Workloads</em>, IoT Greengrass core software version <em class="italic">2.4.0</em> was used, which is compatible with <strong class="source-inline">LogManager</strong> <em class="italic">2.2.0</em>. You can see the latest dependency information in the <em class="italic">AWS-provided components</em> documentation link in the <em class="italic">References</em> section found at the end of this chapter.</p>
			<p>In the following steps, you will revise the deployment for the <strong class="source-inline">hbshubprototypes</strong> group to include the <strong class="source-inline">aws.greengrass.LogManager</strong> managed component. The configuration for the <strong class="source-inline">LogManager</strong> component will specify which components to upload log<a id="_idIndexMarker330"/> files to. Then, you will use the AWS CLI to run a simple query to <a id="_idIndexMarker331"/>validate that log files are being stored. Proceed as follows:</p>
			<ol>
				<li value="1">Edit the <strong class="source-inline">chapter4/deployment-logmanager.json</strong> file to swap the placeholder with your account ID. This deployment adds the <strong class="source-inline">LogManager</strong> component. Remember that by not specifying other components in the deployment list—such as <strong class="source-inline">com.hbs.hub.HelloWithConfig</strong>, which you added in a previous section—they will be removed from the device. We will remove <strong class="source-inline">HelloWithConfig</strong> for this deployment so that we can see the runtime output to the log file when we add it back. All you need to do is update the <strong class="source-inline">targetArn</strong> property to replace the account ID placeholder and save the file.</li>
				<li>Create a new deployment revision and pass in this new deployment configuration file, as follows: <strong class="source-inline">aws greengrassv2 create-deployment --cli-input-json file://deployment-logmanager.json</strong>.</li>
				<li>Edit the <strong class="source-inline">chapter4/deployment-logmanager.json</strong> file to once again add the <strong class="source-inline">HelloWithConfig</strong> component. We do this to redeploy the component so that the runtime output is written to the log again and will then be uploaded to the cloud. Add the following bolded lines into the <strong class="source-inline">components</strong> object and save the file:<p class="source-code">{</p><p class="source-code">  "targetArn": "arn:aws:iot:us-west-2:0123456789012:thinggroup/hbshubprototypes",</p><p class="source-code">  "components": {</p><p class="source-code">    "aws.greengrass.Cli": {</p><p class="source-code">      "componentVersion": "2.4.0"</p><p class="source-code">    },</p><p class="source-code">    <strong class="bold">"com.hbs.hub.HelloWithConfig": {</strong></p><p class="source-code"><strong class="bold">      "componentVersion": "1.0.0"</strong></p><p class="source-code">    },</p><p class="source-code">    "aws.greengrass.LogManager": {</p></li>
				<li>Create a <a id="_idIndexMarker332"/>new deployment revision using the same command as before, like this: <strong class="source-inline">aws greengrassv2 create-deployment --cli-input-json file://deployment-logmanager.json</strong>.</li>
				<li>Once<a id="_idIndexMarker333"/> this deployment is complete, you will start seeing logs in CloudWatch Logs within 5 minutes since the configuration for <strong class="source-inline">LogManager</strong> specifies <strong class="source-inline">300</strong> seconds as the <strong class="source-inline">periodicUploadIntervalSec</strong> parameter.</li>
				<li>Use the following command to check on the status of new log groups with the prefix: <strong class="source-inline">/aws/greengrass/</strong>: <strong class="source-inline">aws logs describe-log-groups --log-group-name-prefix "/aws/greengrass/"</strong>.</li>
				<li>You know logs are being written to CloudWatch when you see a response such as the following:<p class="source-code"><strong class="bold">{</strong></p><p class="source-code"><strong class="bold">    "logGroups": [</strong></p><p class="source-code"><strong class="bold">        {</strong></p><p class="source-code"><strong class="bold">            "logGroupName": "/aws/greengrass/UserComponent/us-west-2/com.hbs.hub.HelloWithConfig",</strong></p><p class="source-code"><strong class="bold">            "creationTime": 1627593843664,</strong></p><p class="source-code"><strong class="bold">            "metricFilterCount": 0,</strong></p><p class="source-code"><strong class="bold">            "arn": "arn:aws:logs:us-west-2:012345678912:log-group:/aws/greengrass/UserComponent/us-west-2/com.hbs.hub.HelloWithConfig:*",</strong></p><p class="source-code"><strong class="bold">            "storedBytes": 2219</strong></p><p class="source-code"><strong class="bold">        }</strong></p><p class="source-code"><strong class="bold">    ]</strong></p><p class="source-code"><strong class="bold">}</strong></p></li>
				<li>You <a id="_idIndexMarker334"/>can query the log group to see devices that are storing logs for this component, as follows: <strong class="source-inline">aws logs describe-log-streams --log-group-name /aws/greengrass/UserComponent/us-west-2/com.hbs.hub.HelloWithConfig</strong>.</li>
				<li>The<a id="_idIndexMarker335"/> response, as illustrated in the following code snippet, will show log streams named in a <strong class="source-inline">/DATE/thing/THING_NAME</strong> format:<p class="source-code"><strong class="bold">{</strong></p><p class="source-code"><strong class="bold">  "logStreams": [</strong></p><p class="source-code"><strong class="bold">    {</strong></p><p class="source-code"><strong class="bold">      "logStreamName": "/2021/07/29/thing/hbshub001",</strong></p></li>
				<li>Plug the log group name into the <strong class="source-inline">filter-log-events</strong> command to see the logged output of the <strong class="source-inline">HelloWithConfig</strong> component, as follows: <strong class="source-inline">aws logs filter-log-events --log-group-name /aws/greengrass/UserComponent/us-west-2/com.hbs.hub.HelloWithConfig --filter-pattern stdout</strong>.<p>The output is as follows:</p><p class="source-code"><strong class="bold">{</strong></p><p class="source-code"><strong class="bold">    "events": [</strong></p><p class="source-code"><strong class="bold">        {</strong></p><p class="source-code"><strong class="bold">            "logStreamName": "/2021/07/29/thing/hbshub001",</strong></p><p class="source-code"><strong class="bold">            "timestamp": 1627579655321,</strong></p><p class="source-code"><strong class="bold">            "message": "2021-07-29T17:27:35.321Z [INFO] (Copier) com.hbs.hub.HelloWithConfig: stdout. Hello from Zimbabwe!. {scriptName=services.com.hbs.hub.HelloWithConfig.lifecycle.Run, serviceName=com.hbs.hub.HelloWithConfig, currentState=RUNNING}",</strong></p><p class="source-code"><strong class="bold">            "ingestionTime": 1627593843867,</strong></p><p class="source-code"><strong class="bold">            "eventId": "362…"</strong></p><p class="source-code"><strong class="bold">        </strong><strong class="bold">}</strong></p><p class="source-code"><strong class="bold">    ]</strong></p><p class="source-code"><strong class="bold">}</strong></p></li>
			</ol>
			<p>You can<a id="_idIndexMarker336"/> see from this series of instructions how to include the <strong class="source-inline">LogManager</strong> component that will automatically ship your components' log files to the cloud and how to use the<a id="_idIndexMarker337"/> Amazon CloudWatch Logs service to query into your logs. IoT Greengrass makes it easy to triage log files of one component across a fleet of devices by querying the log group or into individual devices by querying the log stream that represents one device's component. For more powerful log analysis tooling, you can explore Amazon CloudWatch Logs Insights for aggregation queries across log groups, or stream logs into an indexed querying tool <a id="_idIndexMarker338"/>such as <strong class="bold">Amazon Elasticsearch</strong>.</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor079"/>Merging component configuration</h2>
			<p>Now is a <a id="_idIndexMarker339"/>good opportunity to introduce how to merge in component configuration at deployment time, which you can see we are doing in deployment with <strong class="source-inline">logmanager.json</strong>. If you recall from earlier recipe creation in the <em class="italic">Writing your first component</em> section of <a href="B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032"><em class="italic">Chapter 2</em></a>, <em class="italic">Foundations of Edge Workloads</em>, the recipe can define a <strong class="source-inline">ComponentConfiguration</strong> object that specifies the default settings that a component will use at runtime. We used this to define a default <strong class="source-inline">World!</strong> text that gets passed into the <strong class="source-inline">HelloWorld</strong> component. This kind of component configuration can also be defined at the time of deployment to one or more devices to override these defaults. This is useful when setting the configuration for distinct groups of devices, such as telling all of our prototype devices to use verbose debug-level logging<a id="_idIndexMarker340"/> and our production devices to use warning-level logging to save on costs. Here is an illustration of that practice in effect:</p>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="Images/B17595_04_05.jpg" alt="Figure 4.5 – Overriding configuration for fleets of devices&#13;&#10;" width="745" height="457"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.5 – Overriding configuration for fleets of devices</p>
			<p>A deployment can define component configuration using either of two properties, <strong class="source-inline">reset</strong> and <strong class="source-inline">merge</strong>. The <strong class="source-inline">reset</strong> property tells the component to restore the configuration to whatever the default is for the given configuration key. The <strong class="source-inline">merge</strong> property tells the component to apply a new configuration for the given configuration key, without affecting existing values of other configuration keys. Using both the <strong class="source-inline">reset</strong> and <strong class="source-inline">merge</strong> property on the same configuration key will always first reset the value and then merge in the new value. This can be useful for restoring a tree of default values and then merging in an update for just one node in the tree.</p>
			<p>If you inspect the <strong class="source-inline">deployment-logmanager.json</strong> file, you can see the deployment-time configuration merge we are using to tell the <strong class="source-inline">LogManager</strong> component what to do. Here is a pretty-print version of the <strong class="source-inline">merge</strong> object:</p>
			<p class="source-code">{</p>
			<p class="source-code">  "logsUploaderConfiguration": {</p>
			<p class="source-code">    "systemLogsConfiguration": {</p>
			<p class="source-code">      "uploadToCloudWatch": "true",</p>
			<p class="source-code">      "minimumLogLevel": "INFO",</p>
			<p class="source-code">      "diskSpaceLimit": "10",</p>
			<p class="source-code">      "diskSpaceLimitUnit": "MB",</p>
			<p class="source-code">      "deleteLogFileAfterCloudUpload": "false"</p>
			<p class="source-code">    },</p>
			<p class="source-code">    "componentLogsConfigurationMap": {</p>
			<p class="source-code">      "com.hbs.hub.HelloWithConfig": {</p>
			<p class="source-code">        "minimumLogLevel": "INFO",</p>
			<p class="source-code">        "diskSpaceLimit": "10",</p>
			<p class="source-code">        "diskSpaceLimitUnit": "KB",</p>
			<p class="source-code">        "deleteLogFileAfterCloudUpload": "false"</p>
			<p class="source-code">      }</p>
			<p class="source-code">    }</p>
			<p class="source-code">  },</p>
			<p class="source-code">  "periodicUploadIntervalSec": "300"</p>
			<p class="source-code">}</p>
			<p>Without any <a id="_idIndexMarker341"/>merged configuration set in the deployment, the version 2.2.0 <strong class="source-inline">LogManager</strong> component used here doesn't actually do anything. You must give it some configuration at deployment time to get any logs sent to the cloud. </p>
			<p>In the preceding sample, there is a <strong class="source-inline">logsUploaderConfiguration</strong> configuration key that has two child nodes and an interval property. The <strong class="source-inline">systemLogsConfiguration</strong> node tells the <strong class="source-inline">LogManager</strong> component to upload to Amazon CloudWatch IoT Greengrass system logs such as <strong class="source-inline">greengrass.log</strong>. The <strong class="source-inline">componentLogsConfigurationMap</strong> node tells the <strong class="source-inline">LogManager</strong> component how to selectively upload logs for your other components. You can see here we are defining a <strong class="source-inline">com.hbs.hub.HelloWithConfig</strong> component for inclusion to send logs to the cloud. You would add one object to this list for each component to explicitly capture logs. Two <a id="_idIndexMarker342"/>best practices to consider are outlined here:</p>
			<ul>
				<li>Generate your deployment configuration programmatically and build out the <strong class="source-inline">LogManager</strong> configuration based on the other components included in that deployment. A script in a build process that inspects the components included in your deployment can update the <strong class="source-inline">LogManager</strong> <strong class="source-inline">componentLogsConfigurationMap</strong> node before it gets passed to the <strong class="source-inline">CreateDeployment</strong> API. </li>
				<li>Create a thing group, such as <strong class="source-inline">CommonMonitoringTools</strong>, put all of your Greengrass devices in it, and set a group-level deployment configuration to capture the system logs in the <strong class="source-inline">systemLogsConfiguration</strong> node. All of your devices would then include this component and configuration, resulting in a default behavior to upload system logs. A separate thing group deployment that represents your application's components would then merge the <strong class="source-inline">LogManager</strong> configuration for the <strong class="source-inline">componentLogsConfigurationMap</strong> node in order to specify the logs for that application's components. This works because two deployments from two different thing groups can stack on a single device, effectively merging the configuration of a single component. <em class="italic">Figure 4.3 </em>and <em class="italic">Figure 4.5</em> together illustrate this concept.</li>
			</ul>
			<p>One last note on configuration<a id="_idIndexMarker343"/> management is addressing the delta between the preceding pretty-printed <strong class="bold">JavaScript Object Notation</strong> (<strong class="bold">JSON</strong>) and the escaped JSON string you see in <strong class="source-inline">deployment-logmanager.json</strong>. At the time of this writing, the IoT Greengrass deployment API only accepts the configuration as a string object, so the configuration must be defined as JSON and then escaped as a single string before sending it to the deployment API. This is more inconvenient when hand-writing deployment files but is a simple added step when building deployments programmatically. An alternative, in this case, could be to define your deployment files using the <strong class="bold">YAML Ain't Markup Language</strong> (<strong class="bold">YAML</strong>) format instead of JSON<a id="_idIndexMarker344"/> because the YAML specification has syntactical support for constructing multiline inputs.</p>
			<p>You now <a id="_idIndexMarker345"/>have a functioning, managed component for storing your hub's log files in the cloud to facilitate remote diagnostics for your edge solution. You know how to add more components to the <strong class="source-inline">LogManager</strong> component by merging in new changes to the configuration. Through that process, you learned more about the component configuration system of IoT Greengrass that will serve you as you create new components and build deployments with multiple components working together. In the next section, you will learn how leaf devices connected to your hub can exchange messages and synchronize the state with the cloud.</p>
			<h1 id="_idParaDest-81"><a id="_idTextAnchor080"/>Synchronizing the state between the edge and the cloud</h1>
			<p>The HBS hub device, if <a id="_idIndexMarker346"/>made into a real product, would connect with local devices over a network protocol and proxy telemetry and commands with a cloud service. In the previous chapter, we used components running on our hub device to interface with local hardware interfaces on<a id="_idIndexMarker347"/> the <strong class="bold">Raspberry Pi Sense HAT</strong>. </p>
			<p>This makes sense when the hub device communicates with hardware over serial interfaces, but when communicating over a network, those appliance monitoring kits won't really be software components running on the hub device<a id="_idIndexMarker348"/> using the <strong class="bold">Greengrass IPC</strong> interface to exchange messages. Instead, they may use a network protocol such as <strong class="bold">Message Queue Telemetry Transport</strong> (<strong class="bold">MQTT</strong>) to<a id="_idIndexMarker349"/> exchange messages with the hub device over Wi-Fi or Bluetooth. </p>
			<p>In this section, you will deploy new managed components for connecting to leaf devices over MQTT and synchronize the state of a leaf device's telemetry to the cloud.</p>
			<h2 id="_idParaDest-82"><a id="_idTextAnchor081"/>Introduction to device shadows</h2>
			<p>By<a id="_idIndexMarker350"/> synchronizing state, we mean the end result of keeping two systems up to date with the latest value. When working with the edge and cloud, we must acknowledge and work with the reality that edge solutions may not currently be connected to the cloud service. Our leaf devices and the hub device may work with acquired telemetry that has yet to be reported to the cloud. Once the hub device restores the <a id="_idIndexMarker351"/>connection with the cloud, there must be a mechanism for reconciling the current state of the edge and the current state of the cloud. </p>
			<p>For example, if our <a id="_idIndexMarker352"/>hub device is disconnected from the cloud because of a network drop, new telemetry will be acquired by the leaf devices and new remote commands could be queued up from the cloud service from the customer's mobile application. When the connection is restored, something needs to update the device state so that everything gets back in sync. For this purpose, AWS IoT Core offers a service called <strong class="bold">Device Shadow</strong> that acts as a synchronization mechanism for devices and the cloud. IoT Greengrass makes this Device Shadow service available at the edge via a managed component. </p>
			<p>A device shadow is a JSON document that summarizes the current state of reported data and the desired state. Typically, this means that the device is responsible for updating the reported data, and other actors in the system instruct the device using the desired state. Let's say our hub device is supposed to keep the cloud informed of the latest temperature measurement from one of the appliance monitoring kits. Let's also say that the customer's mobile application can send a command to restart the monitoring kit as a form of troubleshooting. The following diagram illustrates how these messages are stored in the device shadow and reconciled after resuming from a network drop event:</p>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="Images/B17595_04_06.jpg" alt="Figure 4.6 – Flow of shadow messages synchronizing after a network disruption&#13;&#10;" width="751" height="778"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.6 – Flow of shadow messages synchronizing after a network disruption</p>
			<p>Device shadows<a id="_idIndexMarker353"/> are also<a id="_idIndexMarker354"/> useful for our edge ML workloads since a component running an inference task can subscribe to changes reported by the shadow service, or even register its own shadow for exchanging state and commands with the cloud and other components running on the Greengrass device. </p>
			<p>In the <em class="italic">Connecting your first device: sensing at the edge</em> and <em class="italic">Connecting your second device: actuating at the edge</em> sections of <a href="B17595_03_Final_SS_ePub.xhtml#_idTextAnchor052"><em class="italic">Chapter 3</em></a>, <em class="italic">Building the Edge</em>, you implemented IPC in order to let components exchange information in real time. Shadows can level up <a id="_idIndexMarker355"/>your edge solutions by defining synchronized state documents that also get communicated over IPC or even synchronized with the cloud. This opens up some interesting <a id="_idIndexMarker356"/>use cases that further let you as the architect focus on solving business problems without also engineering mechanisms for data exchange. Here are a few examples of how<a id="_idIndexMarker357"/> ML workloads running as edge components can benefit from using shadows:</p>
			<ul>
				<li><strong class="bold">Reporting and caching application state</strong>: Your ML inference component can create a local shadow that stores the latest inference results whenever the ML model is used to process new data. If the model is trained to report when there is an anomaly detected on new data, the local shadow could store the latest anomaly score and confidence rating. That way, other components on the device can subscribe to changes in the shadow and alter their behavior based on the output of the ML component. This may seem similar to publishing updates over IPC, but the key difference here is that components can get values from the shadow whether or not they were running at the same time as when the ML component last published the anomaly score. In that sense, the shadow is used as a caching mechanism and helps us decouple our edge solution.</li>
				<li><strong class="bold">Sending commands to components</strong>: Shadows can be used to instruct components of new commands or desired behavior, even if the component is not currently running. For example, if a component crashes or is in some other recovery state at the time a command would have otherwise been sent to it, putting that command in a shadow ensures it will be delivered to the component when it next enters its running state. Combined with synchronizing shadows to the cloud AWS IoT Core service, this enables other applications and devices to interact with components at the edge in a resilient way.</li>
			</ul>
			<p>Now that we have introduced state synchronization with shadows, let's move on to the hands-on steps for deploying this functionality to your solution.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor082"/>Steps to deploy components for state synchronization</h2>
			<p>IoT Greengrass <a id="_idIndexMarker358"/>provides the functionality for connecting leaf devices, storing shadows, and synchronizing messages to the cloud with<a id="_idIndexMarker359"/> a few separate managed components. Those<a id="_idIndexMarker360"/> components are <a id="_idIndexMarker361"/>an <strong class="bold">MQTT broker</strong> (<strong class="source-inline">aws.greengrass.clientdevices.mqtt.Moquette</strong>), <strong class="bold">Shadow Manager</strong> (<strong class="source-inline">aws.greengrass.ShadowManager</strong>), and an <strong class="bold">MQTT bridge</strong> (<strong class="source-inline">aws.greengrass.clientdevices.mqtt.Bridge</strong>), respectively. </p>
			<p>The following diagram illustrates the architecture of this solution and how these components work together to deliver state synchronization for devices:</p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="Images/B17595_04_07.jpg" alt="Figure 4.7 – Examples of message flows using managed components&#13;&#10;" width="813" height="333"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.7 – Examples of message flows using managed components</p>
			<p>By following the next steps of this section, you will create a new deployment that enables all three of these managed components to launch a new standalone application on your C2 system that connects to your hub device over MQTT and observe how the state is synchronized between the edge and the cloud using these features. Proceed as follows:</p>
			<ol>
				<li value="1">Update your Greengrass role in AWS IAM to allow the use of the device shadow APIs of AWS IoT Core. These steps are specific to AWS IAM and represent a common flow of preparing your Greengrass device to use new APIs. Then, do the following:<ol><li>From the <strong class="source-inline">chapter4</strong> directory, create a new IAM policy, as follows: <strong class="source-inline">aws iam create-policy --policy-name greengrass-use-shadows --policy-document file://greengrass_use_shadows.json --description "Allows Greengrass cores to interact with AWS IoT Core device shadows"</strong>.</li><li>Copy <a id="_idIndexMarker362"/>the policy ARN from the response of the <strong class="source-inline">create-policy</strong> command and use it in the <strong class="source-inline">attach-role-policy</strong> command next. It will look like this, but with your account number instead: <strong class="source-inline">arn:aws:iam::01234567890:policy/Greengrass-use-shadows</strong>.</li><li>Attach the new policy to your Greengrass IAM role, replacing the <strong class="source-inline">policy-arn</strong> argument with your own from the previous step, as follows: <strong class="source-inline">aws iam attach-role-policy --role-name GreengrassV2TokenExchangeRole --policy-arn arn:aws:iam::01234567890:policy/Greengrass-use-shadows</strong>.</li></ol></li>
				<li>Edit the <strong class="source-inline">deployment-syncstate.json</strong> file to update the <strong class="source-inline">targetArn</strong> property for your account ID. Save the file.</li>
				<li>Create a new deployment using the <strong class="source-inline">deployment-syncstate.json</strong> file. Confirm the deployment is complete and successful before moving on to the next step. You can use the <strong class="source-inline">list-effective-deployments</strong> AWS CLI command <a id="_idIndexMarker363"/>to verify or check the status in the AWS IoT Greengrass management console at <a href="https://console.aws.amazon.com/iot">https://console.aws.amazon.com/iot</a>.</li>
				<li>Launch the <strong class="source-inline">local device</strong> client to connect to your hub device over MQTT. From the <strong class="source-inline">chapter4/apps</strong> directory of the GitHub repository, run the following command: <strong class="source-inline">./client.sh</strong>.</li>
			</ol>
			<p>The script at <strong class="source-inline">apps/client.sh</strong> uses your AWS credentials to register a new device in AWS IoT Core, downloads a generated <strong class="source-inline">x.509</strong> private key and certificate, and adds the device to the list <a id="_idIndexMarker364"/>of associated devices for your Greengrass core. It then installs the AWS IoT Device SDK for Python and launches a Python application that discovers your hub device on the local network and connects to it for exchanging messages over MQTT. The purpose of running this application off of the hub device is to demonstrate how Greengrass supports exchanging messages for local devices. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">If your C2 laptop is not on the same network as your hub device, you can run the client application on your hub device. However, you will need to update the permissions for the <strong class="source-inline">idtgg</strong> AWS user that was configured on the hub device since it does not have the necessary permissions yet. Return to the AWS management console for IAM, find the user group named <strong class="source-inline">Provision-IDT-Greengrass</strong>, add a new permission by attaching a policy, and choose the policy named <strong class="source-inline">AWSIoTFullAccess</strong>. Then, you can run the <strong class="source-inline">client.sh</strong> application on your hub device using the existing credentials there from <a href="B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032"><em class="italic">Chapter 2</em></a>, <em class="italic">Foundations of Edge Workloads</em>.</p>
			<p>The <strong class="source-inline">client.sh</strong> application will publish new messages on a topic dedicated to device shadow communications. The topic address is <strong class="source-inline">$aws/things/localdevice/shadow/update</strong>. The client reports a randomly generated temperature value as if it were another sensor on the local network. You can verify that these messages are making it up to the cloud by using the AWS IoT Core management<a id="_idIndexMarker365"/> console at <a href="https://console.aws.amazon.com/iot">https://console.aws.amazon.com/iot</a>. Navigate to <strong class="bold">Test</strong> &gt; <strong class="bold">MQTT test client</strong> and subscribe to the <strong class="source-inline">$aws/things/localdevice/shadow/update/accepted</strong> topic to see the result of the publishing. Here is an example of what it looks like:</p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="Images/B17595_04_08.jpg" alt="Figure 4.8 – Screenshot from AWS IoT Core console of the accepted shadow update&#13;&#10;" width="841" height="886"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.8 – Screenshot from AWS IoT Core console of the accepted shadow update</p>
			<p>You can interact <a id="_idIndexMarker366"/>with the local device application through this test client, too. You can send a new desired state to the local device and it will merge the command into the next reported message. Use the MQTT test client to publish a message on the <strong class="source-inline">$aws/things/localdevice/shadow/update</strong> topic with this body: <strong class="source-inline">{"state":{"desired":{"valve":"open"}}}</strong>. You should see on your subscription and in the standard output of the <strong class="source-inline">client.sh</strong> application activity that it shows the open valve now in the reported state instead of the desired state. This means the local device received a command through Greengrass, processed the command, and updated its reported state accordingly. </p>
			<p>You can continue experimenting with this by publishing further messages to the desired state through the MQTT test client. A real device would take some action in response to the desired state, but this application just copies the command from the desired state to the reported state to simulate handling the event.</p>
			<p>To demonstrate<a id="_idIndexMarker367"/> the functionality of the MQTT bridge managed component, the <strong class="source-inline">client.py</strong> application is also publishing a heartbeat message on another topic at the <strong class="source-inline">dt/localdevice/heartbeat</strong> address. The reason for this is that the Shadow Manager component actually handles all the synchronization of state for us when using the shadow topics. For any other topics and data published, such as this heartbeat behavior, we must use the MQTT bridge component to ferry messages from the edge to the cloud (or vice versa). Use the MQTT test client to subscribe on <strong class="source-inline">dt/localdevice/heartbeat</strong> to see these messages arrive in the cloud. </p>
			<p>Something fun to try is to take your hub device offline temporarily and repeat the previous step but set the desired state of the valve to <strong class="source-inline">closed</strong>. This will demonstrate how the shadow service messages are buffered for delivery the next time the Greengrass device comes back online. On your hub device, bring down the network connection (either by unplugging the Ethernet cable or disabling Wi-Fi). You should see no more messages arriving on either the shadow or heartbeat topics in the MQTT test client. Publish a new message in the MQTT test client, such as <strong class="source-inline">{"state":{"desired":{"valve":"open"}}}</strong>, and then bring the network connection back up. You will see the local device get the new command once the hub device reestablishes connectivity as well as a resumption of the heartbeat messages. </p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor083"/>Extending the managed components</h2>
			<p>The <a id="_idIndexMarker368"/>deployed example uses components managed by AWS to establish connectivity for local devices over an MQTT broker, sending and receiving messages between the edge and the cloud, and synchronizing state with the device's shadow service. You can configure these components for your own use cases by merging further configuration updates. Let's examine the configuration used in this deployment, then review a few more options and best practices. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">For any configuration JSON reviewed in this section, the book is using a pretty-print format that doesn't match what you see in the actual deployment files where JSON is <em class="italic">stringified</em> and escaped per the API requirements. This is done for convenience and legibility in the book format. </p>
			<h3>Shadow Manager</h3>
			<p>In the <strong class="source-inline">aws.greengrass.ShadowManager</strong> component configuration of the <strong class="source-inline">deployment-syncstate.json</strong> file, we must explicitly define which device shadows <a id="_idIndexMarker369"/>will be kept in sync between the edge and cloud. The configuration we used defined the shadow to synchronize for a device named <strong class="source-inline">localdevice</strong> that matches the client ID of the <strong class="source-inline">apps/client.sh</strong> application. Here is the configuration used to achieve that: </p>
			<p class="source-code">{</p>
			<p class="source-code">  "synchronize":{</p>
			<p class="source-code">    "shadowDocuments":[</p>
			<p class="source-code">      {</p>
			<p class="source-code">        "thingName":"localdevice",</p>
			<p class="source-code">        "classic":true,</p>
			<p class="source-code">        "namedShadows":[]</p>
			<p class="source-code">    ]</p>
			<p class="source-code">  }</p>
			<p class="source-code">}</p>
			<p>A <strong class="bold">classic shadow</strong> is a<a id="_idIndexMarker370"/> root-level shadow for any device in AWS IoT Core. <strong class="bold">Named shadows</strong> are<a id="_idIndexMarker371"/> children that belong to the device, and a device can have any number of additional children shadows to help with <strong class="bold">separation of concerns</strong> (<strong class="bold">SoC</strong>). In this case, just using a classic shadow is sufficient.</p>
			<p>For each device you want your Greengrass solution to keep in sync, you would need the configuration to specify that device in the list of <strong class="source-inline">shadowDocuments</strong> where <strong class="source-inline">thingName</strong> is the name of your device that it uses to connect over MQTT (AWS IoT Core defines many resources and APIs representing devices as <em class="italic">things</em> per the IoT moniker). </p>
			<p>Your Greengrass core device is itself a thing registered in AWS IoT Core and can use both classic and named shadows. These shadows can be used for representing the state of the hub device itself or for components on the hub device to behave in coordination with some desired command; for example, sending the desired state to the hub device's shadow to enter a low bandwidth state could get picked up by any components running on the device to act accordingly. Enabling shadow synchronization for your Greengrass core device has a separate configuration outside of the <strong class="source-inline">shadowDocuments</strong> property. Here is an example of how that could look:</p>
			<p class="source-code">{</p>
			<p class="source-code">  "synchronize":{</p>
			<p class="source-code">    "coreThing":{</p>
			<p class="source-code">      "classic":true,</p>
			<p class="source-code">      "namedShadows":[</p>
			<p class="source-code">        "CoreBandwidthSettings",</p>
			<p class="source-code">        "CorePowerConsumptionSettings"</p>
			<p class="source-code">      ]</p>
			<p class="source-code">    },</p>
			<p class="source-code">    "shadowDocuments":[ ... ]</p>
			<p class="source-code">}</p>
			<p>This section covered what you need to know about shadows in AWS IoT Core and how to configure the Shadow Manager component. Next, let's review the MQTT bridge component. </p>
			<h3>MQTT bridge</h3>
			<p>The <strong class="source-inline">aws.greengrass.clientdevices.mqtt.Bridge</strong> component is responsible<a id="_idIndexMarker372"/> for relaying messages between the three kinds of messaging channels supported by Greengrass. The three kinds of messaging channels are listed here:</p>
			<ul>
				<li>Local IPC topics that components use for messaging</li>
				<li>Local MQTT topics enabled by the Moquette MQTT broker component</li>
				<li>Cloud MQTT topics from using AWS IoT Core </li>
			</ul>
			<p>Configuring <a id="_idIndexMarker373"/>the MQTT bridge enables you to create flows of messages from a topic on one channel across the boundary to a topic on another channel—for example, copying messages published on the <strong class="source-inline">dt/device1/sensors</strong> IPC topic to the <strong class="source-inline">dt/sensors/all</strong> AWS IoT Core topic for cloud ingestion. </p>
			<p>Similar to the Shadow Manager component, each mapping of source and destination topics must be explicitly defined in the component's configuration. To enable the heartbeat messages arriving from the <strong class="source-inline">client.sh</strong> application to the cloud, we used the following configuration in the MQTT bridge:</p>
			<p class="source-code">{</p>
			<p class="source-code">  "mqttTopicMapping": {</p>
			<p class="source-code">    "ForwardHeartbeatToCloud": {</p>
			<p class="source-code">      "topic": "dt/localdevice/heartbeat",</p>
			<p class="source-code">      "source": "LocalMqtt",</p>
			<p class="source-code">      "target": "IotCore"</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>Rather than create one mapping for every single device that used the heartbeat pattern, you could make use of MQTT wildcards and update the topic to <strong class="source-inline">dt/+/heartbeat</strong>. The best practice is to explicitly define one mapping for each expected device and avoid wildcards unless you have a use case where devices may be migrating between multiple gateway devices and cannot predict specifically which devices may be publishing. Wildcards are great for simplifying manually typed configuration and for legibility but introduce a risk of unanticipated behavior. Wildcards are also not supported for the <strong class="source-inline">Pubsub</strong> type of topic used for IPC.</p>
			<p>Here is another <a id="_idIndexMarker374"/>example of using an MQTT bridge to allow delivery of commands from other AWS IoT Core devices or applications directly to a component running on a Greengrass core. The idea of this example is how we might update the settings of all ML-powered components to adjust the rate at which models are used in inference activities. Components subscribed over IPC to the topic can receive updates without requiring a full Greengrass deployment:</p>
			<p class="source-code">{</p>
			<p class="source-code">  "mqttTopicMapping": {</p>
			<p class="source-code">    "RemoteUpdateMLComponents": {</p>
			<p class="source-code">      "topic": "cmd/ml-components/inferenceRate",</p>
			<p class="source-code">      "source": "IotCore",</p>
			<p class="source-code">      "target": "Pubsub"</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>You have now finished deploying managed components for the purposes of moving messages back and forth between the edge and the cloud. This functionality creates a path for local devices to communicate with each other through the hub device, for components to interact with cloud services, and any other combination of local devices, components, and the cloud exchanging messages. You also learned how AWS IoT Core and the Device Shadow service work to synchronize the state for local devices and components built on the underlying messaging systems. These tools enable you to build edge ML solutions with any kind of messaging requirements without writing any code or managing infrastructure for your messaging needs. </p>
			<p>In the next section, you will deploy your first ML model using a combination of prebuilt models, inference code, and a custom component for acting on inference results.</p>
			<h1 id="_idParaDest-85"><a id="_idTextAnchor084"/>Deploying your first ML model</h1>
			<p>Now <a id="_idIndexMarker375"/>that you are familiar with remote deployments and loading resources from the cloud, it is time to deploy your first ML-powered capability to the edge! After all, a component making use of ML models is much like other components we have deployed. It is a combination of dependencies, runtime code, and static resources that are hosted in the cloud.</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor085"/>Reviewing the ML use case</h2>
			<p>In this case, the <a id="_idIndexMarker376"/>dependencies are packages and libraries for using <strong class="source-inline">OpenCV</strong> (an open source library for <strong class="bold">computer vision</strong> (<strong class="bold">CV</strong>) use cases) and the <strong class="bold">Deep Learning Runtime</strong> (<strong class="bold">DLR</strong>), the runtime code is a preconfigured sample of inference code that <a id="_idIndexMarker377"/>uses DLR, and the static resources are a preconfigured model store for image classification and some sample images. The components deployed in this example are all provided and managed by AWS.</p>
			<p>The solution that you will deploy simulates the use case for our HBS device hub that performs a simple image classification as part of a home security story for our customers. </p>
			<p>Let's say an add-on device that HBS customers can buy for their hub is a security camera that notifies the customer when a person has approached the front door. A camera device takes a picture on an interval or paired with a motion sensor and stores that image as a file on the hub device. The hub device then performs an inference against that image using a local ML model to identify if any person is detected. If so, an audio notification can be played on the hub device or a text notification sent to the customer. Here is an illustration of the solution and its parts:</p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="Images/B17595_04_09.jpg" alt="Figure 4.9 – Sample architecture for audio notification of subject recognized by the camera&#13;&#10;" width="761" height="400"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.9 – Sample architecture for audio notification of subject recognized by the camera</p>
			<p>Today, this kind <a id="_idIndexMarker378"/>of security capability has many products in the market. However, what is not yet common is performing the ML inference at the edge. This presents a key opportunity for differentiation because the <strong class="bold">total cost of ownership</strong> (<strong class="bold">TCO</strong>) goes <a id="_idIndexMarker379"/>down by saving bandwidth on image transfer to the cloud and saving the compute costs of running the ML inference in the cloud. The security solution will remain operational even if the customer's internet service is disrupted and has no dependency on the availability of a cloud service. There are also tangible benefits for processing and notification latency, as well as a privacy story that appeals to customers since any image data is kept locally. </p>
			<p>This use case demonstrates all four of the key benefits for ML deployed to the edge that we covered in <a href="B17595_01_Final_SS_ePub.xhtml#_idTextAnchor013"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to the Data-Driven Edge with Machine Learning</em>: latency, availability, cost, and governance. </p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor086"/>Steps to deploy the ML workload</h2>
			<p>The steps to take for this<a id="_idIndexMarker380"/> section are pretty simple, thanks to the managed components provided by AWS. There are three components to deploy from the AWS catalog and one more custom component to process the inference results. Since the target prototype hardware of Raspberry Pi and Sense HAT does not <a id="_idIndexMarker381"/>include any camera interface, we will lean on the sample image provided in the managed component to emulate the sensor. The one custom component serves as our actuator, and it <a id="_idIndexMarker382"/>will display the inference results on the <strong class="bold">light-emitting diode</strong> (<strong class="bold">LED</strong>). </p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you are not using the target Raspberry Pi and Sense HAT hardware, you must alter the steps to use the <strong class="source-inline">com.hbs.hub.ScrollMessageSimulated</strong> component instead. Alternatively, you can view inference results using the AWS IoT Core management console (covered in <em class="italic">Step 5</em>), any other MQTT client connecting to AWS IoT Core (subscribe to the topic marked in <em class="italic">Step 5</em>), or review the inference component logs (locally on the device or add these logs to the <strong class="source-inline">LogManager</strong> configuration).</p>
			<p>The following steps deploy the ML solution to the hub device:</p>
			<ol>
				<li value="1">Update the Raspberry Pi to install OpenCV dependencies. We are taking a shortcut here by manually installing dependencies instead of adding complexity to the example (more on this after the steps). Other target platforms should only need <strong class="source-inline">glibc</strong> installed, and the managed components will install dependencies as needed. Open an <strong class="source-inline">ssh</strong> connection to your Pi or open the Terminal program directly on the device. Run the following command: <strong class="source-inline">sudo apt-get install libopenjp2-7 libilmbase23 libopenexr-dev libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libgtk-3-0 libwebp-dev</strong>.</li>
				<li>Create a new custom component in your AWS account from the book repository's source for the <strong class="source-inline">com.hbs.hub.ScrollMessage</strong> component. These are the same <em class="italic">1-4 steps</em> from the <em class="italic">Registering a component in IoT Greengrass</em> section. Upload the <strong class="source-inline">archive.zip</strong> file for this component to S3, edit the recipe file to point at your artifact in S3, then register the new custom component.</li>
				<li>Edit the <strong class="source-inline">deployment-ml.json</strong> file to update the <strong class="source-inline">targetArn</strong> property, as in past sections. Save the file.</li>
				<li>Create a new deployment using the <strong class="source-inline">deployment-ml.json</strong> file, as follows: <strong class="source-inline">aws greengrassv2 create-deployment --cli-input-json file://deployment-ml.json</strong>.</li>
				<li>When <a id="_idIndexMarker383"/>the deployment concludes (it can possibly take a few hours to install the bundled DLR dependencies on the Pi), you should start seeing new inference results appear on your Sense HAT LED matrix. For readers not using the Raspberry Pi with Sense HAT, you can view results using the AWS IoT Core management console. Log in to <a href="https://console.aws.amazon.com/iot">https://console.aws.amazon.com/iot</a>, navigate to <strong class="bold">Test</strong> &gt; <strong class="bold">MQTT test client</strong>, and subscribe to the <strong class="source-inline">ml/dlr/image-classification</strong> ML inference topic. </li>
			</ol>
			<p>If you are using the AWS IoT Core console or an MQTT client to check the inference results, they should look something like this:</p>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="Images/B17595_04_10.jpg" alt="Figure 4.10 – Screenshot of the inference results in AWS IoT Core&#13;&#10;" width="1448" height="1058"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.10 – Screenshot of the inference results in AWS IoT Core</p>
			<p>You have<a id="_idIndexMarker384"/> now deployed your first ML workload to the edge! This workload will continue to run at a 10-second interval and will process the file found at <strong class="source-inline">/greengrass/v2/packages/artifacts-unarchived/component-name/image_classification/sample_images/cat.jpeg</strong> on the hub device. There are a number of ways to extend this example for your own testing and use cases, such as the following:</p>
			<ul>
				<li><strong class="bold">Pass in alternate images to the inference component</strong>: You can merge in a new configuration for the <strong class="source-inline">aws.greengrass.DLRImageClassification</strong> component to specify where to source the processed image—for example, you can specify a new directory with the <strong class="source-inline">ImageDirectory</strong> parameter and a filename with the <strong class="source-inline">ImageName</strong> parameter. Then, you could create a custom component that includes your own images as artifacts and rotates them through that filename at that path to see what the classification engine identifies.</li>
				<li><strong class="bold">Hook up a camera as input</strong>: You can merge in a new configuration for the <strong class="source-inline">aws.greengrass.DLRImageClassification</strong> component to specify a camera as the source for images to classify. For prototyping on the Raspberry Pi device, you can <a id="_idIndexMarker385"/>connect a <strong class="bold">Universal Serial Bus</strong> (<strong class="bold">USB</strong>) webcam or the <strong class="bold">Raspberry Pi Camera Module v2</strong>. More details on how to set up the<a id="_idIndexMarker386"/> component to use a camera can be found in the <em class="italic">References</em> section at the end of this chapter. </li>
				<li><strong class="bold">Escalate an event for a type of classified result</strong>: The current workload reports all<a id="_idIndexMarker387"/> inference results on a specified topic. You could modify the custom component that subscribes to these results and only update the actuator when a human is classified in the inference results. Alternatively, you could publish a message on another topic reserved for alerts and configure AWS IoT Core <a id="_idIndexMarker388"/>and <strong class="bold">Amazon Simple Notification Service</strong> (<strong class="bold">Amazon SNS</strong>) to send you an alert when a human is detected. For these events, you may also want the detected image to be stored for future reference.</li>
				<li><strong class="bold">Deploy object detection workload</strong>: This example demonstrated a use case for classifying the primary object in the source image. An alternate use case is to list all objects detected in the source image. AWS also provides managed components for object detection workloads and for CV use cases running on either DLR or the TensorFlow framework.</li>
				<li><strong class="bold">Notify of new images available</strong>: The managed component is designed with an interval pattern to process the source image against the ML model. You could design a variation that subscribes to a local IPC topic and waits for notification from another component that an inference is needed and could specify the file path in the message.</li>
			</ul>
			<p>As mentioned in the step for installing the dependencies on the Raspberry Pi, these steps take a shortcut that doesn't reflect the best practices of our solution design. Rather than <a id="_idIndexMarker389"/>manually installing dependencies on the device, a better way is to use IoT Greengrass to install those missing dependencies. This section could have walked you through forking the AWS managed components in order to add more dependencies in the install lifecycle step, but for the purposes of this exercise was deemed not a valuable detour. </p>
			<p>Furthermore, the default behavior of the <strong class="source-inline">aws.greengrass.DLRImageClassification</strong> managed component publishes the inference results to a cloud topic on AWS IoT Core instead of a local topic on IPC. For workloads that report all activity to the cloud, this is the desired behavior. However, given the best practices outlined in this book to perform data analysis locally and decouple our components, it would be preferred to publish on a local IPC topic and let another component decide which messages to escalate to the cloud. </p>
			<p>This could not be achieved with a simple configuration update as defined in version 2.1.3 of the component. Again, a detour to fork the component just to swap out the cloud publish for a local publish was not deemed valuable for the purposes of this exercise, so the cloud publish behavior is left as-is.</p>
			<p>With your first ML-powered workload deployed, you now have an understanding of how ML components are deployed to the edge as a combination of dependencies, code, and static resources. </p>
			<p>In this section, you deployed three components as a decoupled set of dependencies, runtimes, and models, plus one more custom component that acts upon the inference results of your ML model. Together, you have all the basics for extending these components to deliver your own image classification and object detection workloads. Next, let's summarize everything you have learned in this chapter.</p>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor087"/>Summary</h1>
			<p>This chapter taught you the key differences in remote deploying of components to your Greengrass devices, how to accelerate your solution development using managed components provided by AWS, and getting your first ML workload on your prototype hub device. At this point, you have all the basics you need to start writing your own components and designing edge solutions. You can even extend the managed ML components to get started with some basic CV projects. If you have trained ML models and inference code being used in your business today as containerized code, you could get started with deploying them to the edge now as custom components.</p>
			<p>In the next chapter, <a href="B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090"><em class="italic">Chapter 5</em></a>, <em class="italic">Ingesting and Streaming Data from the Edge</em>, you will learn more about how data moves throughout the edge in prescriptive structures, models, and transformations. Proper handling of data at the edge is important for adding efficiency, resilience, and security to your edge ML solutions.</p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor088"/>Knowledge check</h1>
			<p>Before moving on to the next chapter, test your knowledge by answering these questions. The answers can be found at the end of the book:</p>
			<ol>
				<li value="1">What are some examples that differentiate static and dynamic resources of an edge component?</li>
				<li>Where are your components' artifacts stored so that they can be referenced by your recipe files?</li>
				<li>Can you modify an artifact stored in the cloud after it has been included in a registered custom component?</li>
				<li>Why can't you write to artifact files that have been loaded onto the edge device through deployment?</li>
				<li>True or false: Edge devices can belong to multiple thing groups in the cloud AWS IoT Core service and each thing group can have one active Greengrass deployment associated with it.</li>
				<li>Can you think of a use case for one edge device to receive deployments from multiple thing groups?</li>
				<li>True or false: A single deployment can reset a component's configuration and apply a merge of a new configuration.</li>
				<li>Which of the following managed components is responsible for deploying a local MQTT broker and connecting leaf devices? <p>MQTT bridge/Moquette/device shadows</p></li>
				<li>Which of the following managed components is responsible for synchronizing the state between the edge and the cloud? <p>MQTT bridge/Moquette/device shadows</p></li>
				<li>Which of the following managed components is responsible for relaying messages between communications channels such as MQTT, IPC, and the cloud? <p>MQTT bridge/Moquette/device shadows</p></li>
				<li>How might you design the flow of data from a local IoT sensor to an application running ML inference and play an alarm sound over an attached loudspeaker? Think about the different communications channels available and our best practice of decoupled services. Try sketching it out on paper as if you were proposing the design to a colleague.</li>
			</ol>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor089"/>References</h1>
			<p>Take a look at the following resources for additional information on the concepts discussed in this chapter:</p>
			<ul>
				<li><em class="italic">Perform sample image classification inference on images from a camera using TensorFlow Lite</em>: <a href="https://docs.aws.amazon.com/greengrass/v2/developerguide/ml-tutorial-image-classification-camera.html">https://docs.aws.amazon.com/greengrass/v2/developerguide/ml-tutorial-image-classification-camera.html</a> </li>
				<li><em class="italic">AWS-provided components</em>: <a href="https://docs.aws.amazon.com/greengrass/v2/developerguide/public-components.html">https://docs.aws.amazon.com/greengrass/v2/developerguide/public-components.html</a> </li>
				<li>OpenCV website: <a href="https://opencv.org/">https://opencv.org/</a> </li>
				<li><em class="italic">AWS IoT Device Shadow service</em>: <a href="https://docs.aws.amazon.com/iot/latest/developerguide/iot-device-shadows.html">https://docs.aws.amazon.com/iot/latest/developerguide/iot-device-shadows.html</a> </li>
				<li><em class="italic">DLR: Compact Runtime for Machine Learning Models</em>: <a href="https://neo-ai-dlr.readthedocs.io">https://neo-ai-dlr.readthedocs.io </a></li>
				<li>TensorFlow website: <a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a> </li>
			</ul>
		</div>
	</div></body></html>