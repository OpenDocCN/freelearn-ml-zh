<html><head></head><body>
<div id="sbo-rt-content" class="calibre1"><div id="_idContainer022" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-16"><a id="_idTextAnchor015" class="calibre6 pcalibre pcalibre1"/>1</h1>
<h1 id="_idParaDest-17" class="calibre5"><a id="_idTextAnchor016" class="calibre6 pcalibre pcalibre1"/>AI/ML Concepts, Real-World Applications, and Challenges</h1>
<p class="calibre3">This chapter will introduce basic concepts that will be explored in more detail throughout the rest of the book. We understand that readers of this book may be starting from different stages in their <strong class="bold">artificial intelligence/machine learning</strong> (<strong class="bold">AI/ML</strong>) journey, whereby<a id="_idIndexMarker000" class="calibre6 pcalibre pcalibre1"/> some readers may already be advanced practitioners who are familiar with running AI/ML workloads while others may be newer to AI/ML in general. For this reason, we will briefly describe important fundamental concepts as required throughout the book to ensure that all readers have a common baseline upon which to build their understanding of the topics we discuss. Readers who are newer to AI/ML will benefit from learning the important underlying concepts rather than diving straight into the deep end of each topic without a baseline context, and advanced practitioners should find them to be useful <span>knowledge refreshers.</span></p>
<p class="calibre3">In this chapter, we’re going to cover the following <span>main topics:</span></p>
<ul class="calibre16">
<li class="calibre8">Terminology—AI, <a id="_idIndexMarker001" class="calibre6 pcalibre pcalibre1"/>ML, <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>), and <strong class="bold">generative </strong><span><strong class="bold">AI</strong></span><span> (</span><span><strong class="bold">GenAI</strong></span><span>)</span></li>
<li class="calibre8">A brief history <span>of AI/ML</span></li>
<li class="calibre8">ML approaches and <span>use cases</span></li>
<li class="calibre8">A brief discussion of ML <span>basic concepts</span></li>
<li class="calibre8">Common challenges in developing <span>ML applications</span></li>
</ul>
<p class="calibre3">By the end of this chapter, you will understand the common types of AI/ML approaches and their real-world applications, as well as some historical background on the development of AI/ML concepts. Finally, you will learn about common types of challenges and pitfalls that companies encounter when they begin to implement AI/ML workloads. This is a particularly important part of the book, especially for the solutions architect role, and it provides real-world insights that are not found in academic courses; these insights come from years of experience in the field, working on large-scale AI/ML projects with many <span>different companies.</span></p>
<h1 id="_idParaDest-18" class="calibre5"><a id="_idTextAnchor017" class="calibre6 pcalibre pcalibre1"/>Terminology – AI, ML, DL, and GenAI</h1>
<p class="calibre3">Here, we<a id="_idIndexMarker002" class="calibre6 pcalibre pcalibre1"/> describe how the terms <em class="italic">AI</em> and <em class="italic">ML</em> relate to each other. It should be noted that these terms are often used interchangeably, as well as the abbreviated term, <em class="italic">AI/ML</em>, which serves as an umbrella term to encapsulate both AI and ML. We also describe how the terms <em class="italic">DL </em>and<em class="italic"> GenAI</em> fit in under the umbrella <span>of AI/ML.</span></p>
<p class="calibre3">We’ll begin by briefly including officially-accepted definitions of the terms <em class="italic">AI</em> and <em class="italic">ML</em>. We have chosen to include definitions from the <em class="italic">Collins English Dictionary</em>, in which AI is defined as “<em class="italic">a type of computer technology concerned with making machines work in an intelligent way, similar to the way that the human mind works</em>” and ML is defined as “<em class="italic">a branch of artificial intelligence in which a computer generates rules underlying or based on raw data that has been fed into it.</em>” The term <em class="italic">DL</em> has not yet been officially included as a dictionary term, but the <em class="italic">Collins English Dictionary</em> lists it as a new word suggestion, with the proposed definition of “<em class="italic">a type of machine learning concerned with artificial neural networks allowing advanced pattern recognition.</em>” We understand that official dictionary definitions don’t always explain the concepts completely, but it’s important to include them for reference, and we will cover these concepts in more detail as we progress through the book. All of those terms constitute what we are now beginning to refer to as “Traditional AI”, to distinguish it from GenAI, which is a much newer, and quite different concept. There will be an entire section of this book dedicated to GenAI, so this distinction will <span>become clearer.</span></p>
<p class="calibre3">As a general rule, DL is <a id="_idIndexMarker003" class="calibre6 pcalibre pcalibre1"/>considered to be a sub-field of ML, and ML is considered to be a sub-field of AI. GenAI can be seen as a sub-field within DL, because it uses Deep Neural Networks and concepts from Natural Language Processing in its application. You will often see them graphically represented in literature as a set of concentric circles, whereby AI is the broadest field, ML is nested as a sub-field within AI, and DL is nested as a sub-field within ML. I’m adding to this conceptual representation by including GenAI within the field of DL, although it is more of an association rather than a <span>strict sub-category:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer008">
<img alt="Figure 1.1: Depicting the relationship between the terms AI, ML, DL, and GenAI" src="image/B18143_01_1.jpg" class="calibre17"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.1: Depicting the relationship between the terms AI, ML, DL, and GenAI</p>
<p class="calibre3">Now that we have covered some basic terminology regarding AI/ML, let’s briefly discuss its history and understand how the AI/ML industry has developed <span>so far.</span></p>
<h1 id="_idParaDest-19" class="calibre5"><a id="_idTextAnchor018" class="calibre6 pcalibre pcalibre1"/>A brief history of AI/ML</h1>
<p class="calibre3">If we traveled back in time by only a few years — to the year 2015 — and compared the state of the<a id="_idIndexMarker004" class="calibre6 pcalibre pcalibre1"/> AI/ML industry to what it is today, we would see that relatively few companies had commercially implemented large-scale AI/ML use cases at that point. Although we would find academic research being performed in this space, we wouldn’t regularly hear AI/ML being discussed in mainstream media, and successful commercial or industrial implementations had mainly been achieved only by some of the world’s largest, industry-leading technology or niche companies. Jumping forward by just 2 years, we find that by the end of 2017, the tech industry is abuzz with discussions of AI/ML, and it seems to be the main topic—or at least one of the main topics—on <span>everybody’s mind.</span></p>
<p class="calibre3">Based on our time-traveling adventure, one would not be faulted for believing that AI/ML is a <a id="_idIndexMarker005" class="calibre6 pcalibre pcalibre1"/>brand-new term that suddenly emerged only in the past few years. In reality, however, these concepts have been developing over many decades. As the next step in our time-traveling journey, we travel further back in time to the 1950s. The first use of the term <em class="italic">artificial intelligence</em> is credited to Professor John McCarthy in 1955 (McCarthy et al. 1955), and a number of other important developments that contributed significantly to this field of science took place during the 1950s, such as Alan Turing’s 1950 paper, <em class="italic">Computing Machinery and Intelligence</em>, in which he posed the question, “<em class="italic">Can machines think?</em>” (Turing, 1950), and Frank Rosenblatt’s work on the “Perceptron” (Rosenblatt, 1957), which we’ll look at in more detail later in <span>this book.</span></p>
<p class="calibre3">As an extension of our time-traveling journey, it should be noted that AI/ML algorithms today use mathematical concepts that were originally discovered and formulated centuries or millennia ago. For example, many of the algorithms we will explore in this book use concepts from linear algebra and calculus, which have been in use for centuries, and when we learn about cost functions, training, and evaluation, we will be using concepts from Euclidean geometry, such as the Pythagorean theorem, which dates back millennia. Interestingly, although Pythagoras is believed to have lived around 2,500 years ago, there is some evidence that concepts from the “Pythagorean theorem” were already understood and used by previous civilizations such as the Babylonians of Mesopotamia more than 1,000 years before his birth (Götze, 1945, 37-38). How fascinating it is that some of our most cutting-edge DL algorithms today use the same mathematical constructs that were used by ancient civilizations in the Bronze Age! In the 1960’s and 1970’s, the practice of using computers to perform statistical analysis and modeling on data began to grow significantly, and specialized software such as <strong class="bold">Statistical Analysis System</strong> (<strong class="bold">SAS</strong>) and <strong class="bold">Statistical Package for the Social Sciences</strong> (<strong class="bold">SPSS</strong>) emerged for these purposes. These tools were generally used for <strong class="bold">in-memory</strong> processing, meaning that all of the data used with these tools would be loaded into memory on a single computing machine. In the next section, you will see why it’s important to call <span>this out.</span></p>
<p class="calibre3">Next, we travel forward in time, to the present day, and one of the questions that come to mind is this: If all of this started back in the 1950s, why does it seem that AI and ML are concepts that everybody has suddenly become enthusiastic about only in the past few years? Why did we not see such widespread adoption and success of AI/ML implementations before now? A number of factors have contributed to the gap in time that has been experienced between when these concepts originally began to be researched and when they finally started to gain publicly noticeable traction in the industry during the past few years (see the “AI Winter,” for example). As we will see in later chapters of this book, one such factor is that AI/ML use cases generally require large amounts of data and extensive computing resources. This is one of the reasons why—until recently—AI/ML research was usually being performed only by entities that could afford to amass these required resources, such as large technology companies, well-established research institutions, and <span>government bodies.</span></p>
<p class="calibre3">What has changed in recent years to help <a id="_idIndexMarker006" class="calibre6 pcalibre pcalibre1"/>AI/ML break out beyond the exclusive realm of large corporations and research institutions? How have smaller companies, and even amateur hobbyists, suddenly obtained access to the resources required to train, host, and evaluate ML models and experiment with new ideas on how to apply AI/ML to an ever-increasing plethora of interesting new use cases? One of the primary contributors to this sudden revolution has been “cloud computing,” as well as iterative tooling development for building and running AI/ML workloads, and advances in <span>DL approaches.</span></p>
<h2 id="_idParaDest-20" class="calibre9"><a id="_idTextAnchor019" class="calibre6 pcalibre pcalibre1"/>AI/ML and cloud computing</h2>
<p class="calibre3">To understand in more detail how <a id="_idIndexMarker007" class="calibre6 pcalibre pcalibre1"/>cloud computing<a id="_idIndexMarker008" class="calibre6 pcalibre pcalibre1"/> has helped to suddenly revolutionize AI/ML research and real-world application, let’s consider the types of resources that are required to train, host, evaluate, and manage ML models. While we could use a laptop or a home computer to train and evaluate a relatively simple model on a small dataset, as we want to scale out our research and use cases, we would quickly find that the computing resources on our personal computer would not be sufficient to train larger models and the hard drive(s) in our personal computer would not be large enough to store the required datasets. These were also the limitations experienced by the statistical modeling tools such as SAS and SPSS that we mentioned in the previous section, which processed data “in-memory” on a <span>single machine.</span></p>
<p class="calibre3">To illustrate this concept, we’re going to scale up our use cases in a series of steps. If we were to scale up only slightly beyond the resources of the most powerful personal computer on the market, we would need to run our workload on a hardware “server,” which contains more powerful computing resources, and we could attach multiple large-capacity hard drives to this server, potentially <a id="_idIndexMarker009" class="calibre6 pcalibre pcalibre1"/>as a <strong class="bold">Redundant Array of Independent Disks</strong> (<strong class="bold">RAID</strong>) array (formerly <strong class="bold">Redundant Array of Inexpensive Disks</strong>). This is still something that an individual person could perform in their home, but powerful servers—especially the “latest and greatest” servers on the market—can be quite expensive to purchase, and it would require a bit more technical knowledge to set up the server and configure the RAID array. At this point, we are already extending outside the realm of all but the most dedicated <span>amateur hobbyists.</span></p>
<p class="calibre3">Scaling beyond the resources of the most powerful hardware server on the market would require us to create a cluster of servers. Apart from the additional expense of purchasing multiple servers and their attached disks, this would also require more advanced technical knowledge to build and configure a network that links the servers together appropriately. This would not be an economically viable approach for most hobbyists, but it may still make some sense for a <span>small company.</span></p>
<p class="calibre3">Next, let’s scale all the way up to some of today’s most advanced DL use cases, which can take weeks or months to train, on hundreds of high-powered and very expensive servers. If we wanted to run these kinds of workloads completely by ourselves, we would need to build a data center, hire teams of experts to install hundreds of servers, build and configure a complex network to link them all together appropriately, and perform multiple other supporting activities to get our infrastructure set up. Let’s imagine for a moment that we want to create a start-up company that will use DL to implement a new breakthrough idea that we’ve devised. Simply building the data center could take a couple of years and would cost many millions of dollars, before we could ever start experimenting with our idea. This would not be a <span>viable option.</span></p>
<p class="calibre3">With <a id="_idIndexMarker010" class="calibre6 pcalibre pcalibre1"/>cloud computing, however, we could simply write a script or click some links and buttons on a cloud computing <a id="_idIndexMarker011" class="calibre6 pcalibre pcalibre1"/>provider’s website, and it would spin up all of the servers we need within minutes. We could then perform our experiments — iteratively train and evaluate our models — and then simply shut down the servers when our work is done. As you can imagine, this is infinitely easier, cheaper, and more achievable than trying to build and manage our own data centers. This now provides small companies and limited-funding researchers or hobbyists with access to compute power and resources that were previously only available to very <span>large organizations.</span></p>
<p class="calibre3">Note that it was not only the ability to more easily create and access the required hardware infrastructure that helped revolutionize the AI/ML industry. Relevant software tools and frameworks have also been evolving over time, as well as the amount of data that has become available. While the tools such as SAS and SPSS that were developed in the 1960’s and 1970’s were sufficient for performing statistical modeling on datasets that could fit in memory on a single machine, the rapid growth in popularity of the Internet caused a dramatic increase in the amount of data that companies could gather and produce. In parallel, libraries were developed in languages such as Python, which made activities such as data processing, analysis, and modeling much easier. I can confidently say that it is a lot easier to perform many kinds of modeling use cases with libraries such as scikit-learn, PyTorch, and Keras, than it was with the earlier tools mentioned above. Still, many of today’s machine learning algorithms can be seen as an evolutions of traditional statistical modeling techniques, which have been enhanced to handle larger and more complex use cases. In addition to this, tools such as Apache Hadoop and Apache Spark, which I will discuss in more detail later in this book, made it possible to implement use cases that could span beyond the limits of a single machine, and therefore handle much <span>larger datasets.</span></p>
<p class="calibre3">So far, in our discussion of scaling out our use cases, we have mainly focused on training and evaluating ML models, but those activities are only a subset of what’s required to create an ML application that is actually used in the real world. Throughout this book, we will often use the term <em class="italic">in production</em> to refer to the concept of creating, hosting, and serving AI/ML applications that are used in the real world, outside of a laboratory <span>testing environment.</span></p>
<p class="calibre3">Even large, well-established <a id="_idIndexMarker012" class="calibre6 pcalibre pcalibre1"/>organizations with <a id="_idIndexMarker013" class="calibre6 pcalibre pcalibre1"/>teams of experienced data scientists often find that successfully hosting an ML application in production can be more complex and challenging than the model training and evaluation process. Let’s now take a look at how cloud computing can provide additional value for addressing these challenges beyond simply spinning up the required compute and storage resources. In later chapters in this book, we will discuss all of the steps in a typical ML project in great detail, but for now, let’s consider at a high level what kinds of resources and infrastructure would be required to host an ML model in production if cloud computing did <span>not exist.</span></p>
<p class="calibre3">In addition to the activities required for model training and evaluation, such as constructing the data centers, installing the servers, building and configuring a complex network, and maintaining all of the hardware over time, we would need to perform many other activities to actually host and serve an ML model for production usage. For example, it would be necessary to create an interface to expose our model to end users or other systems. The most likely approach would be to use a web-based interface, in which case we would need to build a cluster of web servers and configure and manage those web servers on an ongoing basis. We would need to develop and build an application on those web servers to expose our model to web clients, and then install and configure load balancers and distribute load across our web servers. All of this infrastructure would, of course, need to be secured appropriately. <span><em class="italic">Figure 1</em></span><em class="italic">.2</em> shows an example of the kind of infrastructure you may need to set up; bear in mind that you may need to duplicate that infrastructure for each layer in your solution—for example, you would need to duplicate that infrastructure multiple times for your web server layer, your application server layer, and your model serving layer. The diagram shows two load balancers and routers for redundancy, in case one of those <span>components fails:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer009">
<img alt="Figure 1.2: Example infrastructure for model hosting" src="image/B18143_01_2.jpg" class="calibre18"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.2: Example infrastructure for model hosting</p>
<p class="calibre3">Unfortunately, most data scientists are not also networking experts, web server configuration experts, and security experts, so even if we had a team of the best data scientists who had created a breakthrough model, we would need many other teams of dedicated experts just to <a id="_idIndexMarker014" class="calibre6 pcalibre pcalibre1"/>build and maintain the<a id="_idIndexMarker015" class="calibre6 pcalibre pcalibre1"/> infrastructure required to expose that model to clients. On the other hand, if we wanted to use a service such as Vertex AI on Google Cloud, it would automatically build and manage all of this infrastructure for us, and we could go from laboratory testing to production hosting <span>within minutes.</span></p>
<p class="calibre3">It’s important to note that without<a id="_idIndexMarker016" class="calibre6 pcalibre pcalibre1"/> cloud computing, companies wouldn’t just find it less <a id="_idIndexMarker017" class="calibre6 pcalibre pcalibre1"/>convenient to build their AI/ML workloads, but it would also be prohibitive – that is, large companies wouldn’t invest in building the required infrastructure unless they were sure their application was going to be successful in advance, which is a very difficult thing to forecast. Smaller companies wouldn’t be able to get started without significant up-front investments in infrastructure expenses, which most would not be able to obtain. As such, AI/ML research, experimentation, and eventual implementation in the real world would be far less prevalent and achievable without <span>cloud computing.</span></p>
<p class="calibre3">Speaking of implementing AI/ML in the real world, let’s take a look at the different kinds of AI/ML approaches and some of their real-world <span>use cases.</span></p>
<h1 id="_idParaDest-21" class="calibre5"><a id="_idTextAnchor020" class="calibre6 pcalibre pcalibre1"/>ML approaches and use cases</h1>
<p class="calibre3">AI/ML applications are usually intended to make some kind of prediction based on input data, with perhaps the exception of Generative AI, because Generative AI is intended to generate content rather than simply making predictions. In order to make predictions, ML models first need to be <strong class="bold">trained</strong>, and how they are trained depends on the approach being used. While ML is a broad concept that encompasses many different fields of research, with endless new use cases being created almost every day, the industry generally groups ML approaches into three <span>high-level categories:</span></p>
<ul class="calibre16">
<li class="calibre8"><strong class="bold">Supervised </strong><span><strong class="bold">learning</strong></span><span> (</span><span><strong class="bold">SL</strong></span><span>)</span></li>
<li class="calibre8"><strong class="bold">Unsupervised </strong><span><strong class="bold">learning</strong></span><span> (</span><span><strong class="bold">UL</strong></span><span>)</span></li>
<li class="calibre8"><strong class="bold">Reinforcement </strong><span><strong class="bold">learning</strong></span><span> (</span><span><strong class="bold">RL</strong></span><span>)</span></li>
</ul>
<h2 id="_idParaDest-22" class="calibre9"><a id="_idTextAnchor021" class="calibre6 pcalibre pcalibre1"/>SL</h2>
<p class="calibre3">SL is the<a id="_idIndexMarker018" class="calibre6 pcalibre pcalibre1"/> most commonly used type<a id="_idIndexMarker019" class="calibre6 pcalibre pcalibre1"/> of ML in the industry and perhaps the easiest to describe. The term <em class="italic">supervised</em> indicates that we are informing the ML model of the correct answers during the training process. For example, let’s imagine that we want to train a model to be able to identify photographs of cats. In this case, we would use thousands or millions of photographs in our training set, and we would tell the model which photographs contain cats and which ones do not. We do this via a process called <strong class="bold">labeling</strong>, which<a id="_idIndexMarker020" class="calibre6 pcalibre pcalibre1"/> we will describe in more detail in later chapters. If trained correctly, our model would learn how to distinguish input features that identify a cat in each photograph. If we then presented new photographs that the model had never seen before (that is, that were not included in the training set), our model would be able to identify whether those photographs contained cats. More specifically, for each photograph, our model would be able to predict the<a id="_idIndexMarker021" class="calibre6 pcalibre pcalibre1"/> probability that it contains a <a id="_idIndexMarker022" class="calibre6 pcalibre pcalibre1"/>cat, based on observed features in <span>the photograph.</span></p>
<p class="calibre3">There are two subcategories of SL: classification <span>and regression.</span></p>
<h3 class="calibre11">Classification</h3>
<p class="calibre3">Our cat-identification model<a id="_idIndexMarker023" class="calibre6 pcalibre pcalibre1"/> described previously is an example of a classification<a id="_idIndexMarker024" class="calibre6 pcalibre pcalibre1"/> use case in which our model can classify whether our photo contains a cat. Classification is further broken down into binary classification or multi-class classification. Binary classification provides a “yes” or “no” prediction. For example, in this case, we would ask the model, “Does this photograph contain a cat?”, and the model would respond with either “Yes” or “No.” If we were to train our model to identify many different types of objects, then it would be capable of performing multi-class classification, and we could ask a broader question such as, “What do you see in this photograph?”. In this case, the model could respond with multiple different object classifications, including “cat” (if it sees a cat in the photograph), among other objects that it predicts to exist in the photograph (see <span><em class="italic">Figure 1</em></span><span><em class="italic">.3</em></span><span>):</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer010">
<img alt="Figure 1.3: Classification of cat and flowers in a photograph" src="image/B18143_01_3.jpg" class="calibre19"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.3: Classification of cat and flowers in a photograph</p>
<h4 class="calibre20">Real-world applications of classification</h4>
<p class="calibre3">Of course, classification<a id="_idIndexMarker025" class="calibre6 pcalibre pcalibre1"/> can be used for much more important use cases than identifying pictures of cats. An example of an important real-world classification use case is in medical diagnoses, whereby an ML model can predict the presence of a medical condition in a patient based on input data such as physical symptoms or a <span>radiology image.</span></p>
<h3 class="calibre11">Regression</h3>
<p class="calibre3">While <a id="_idIndexMarker026" class="calibre6 pcalibre pcalibre1"/>classification is useful when there are discrete answers to our questions, regression<a id="_idIndexMarker027" class="calibre6 pcalibre pcalibre1"/> is used when we deal with “continuous variables,” whereby the answer to our question could be any value in a continuum, such as 0.1, 2.3, 9894.6, 105, or 0.00000487. To introduce some terminology, the inputs that we provide to our model are referred to as “input variables,” and the variables that we wish to predict are referred to as “target variables” or “<span>dependent variables.”</span></p>
<p class="callout-heading">Note</p>
<p class="callout">When we use the term <em class="italic">regression</em> here, we are referring to linear regression. This is not to be confused with logistic regression, which is actually a type of classification that we will cover later in <span>this book.</span></p>
<p class="calibre3">The aim of<a id="_idIndexMarker028" class="calibre6 pcalibre pcalibre1"/> linear regression <a id="_idIndexMarker029" class="calibre6 pcalibre pcalibre1"/>is to define a linear <a id="_idIndexMarker030" class="calibre6 pcalibre pcalibre1"/>function that maps input variables to an output target variable. For example, we may want to predict the grade a student will achieve on an exam based on the number of hours they spent studying, from data we have regarding previous students’ grades and how many hours they spent studying. We could graph the data as follows (see <span><em class="italic">Figure 1</em></span><em class="italic">.4</em>), where the stars represent each student in the dataset; that is, they represent each student’s grade and the number of hours they <span>spent studying:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer011">
<img alt="Figure 1.4: Student grades and hours studying" src="image/B18143_01_4.jpg" class="calibre21"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.4: Student grades and hours studying</p>
<p class="calibre3">As we can see in the diagram, there appears to be a relationship or correlation between the grades achieved and the number of hours spent studying; that is, students who studied for longer hours generally got <span>higher grades.</span></p>
<p class="calibre3">A linear<a id="_idIndexMarker031" class="calibre6 pcalibre pcalibre1"/> regression <a id="_idIndexMarker032" class="calibre6 pcalibre pcalibre1"/>model trained on this dataset would try <a id="_idIndexMarker033" class="calibre6 pcalibre pcalibre1"/>to find the function or line that best represents that relationship. You may remember from school that a simple line function is often represented by the formula <em class="italic">y = ax + b</em>, where <em class="italic">a</em> is a multiple of <em class="italic">x</em>, and <em class="italic">b</em> is where the line intercepts the <em class="italic">y</em> axis. To find the most accurate function, the linear regression process tries to define a line that minimizes the distance between that line and each of the data points (stars), which may look something like <span><em class="italic">Figure 1</em></span><em class="italic">.5</em>. The distances between the line and some of the data points are shown in red for reference. In later sections, we’ll discuss in more detail how those distances <span>are calculated:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer012">
<img alt="Figure 1.5: Linear regression function" src="image/B18143_01_5.jpg" class="calibre22"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.5: Linear regression function</p>
<p class="calibre3">With this<a id="_idIndexMarker034" class="calibre6 pcalibre pcalibre1"/> function, we could now estimate or predict future student<a id="_idIndexMarker035" class="calibre6 pcalibre pcalibre1"/> grades <a id="_idIndexMarker036" class="calibre6 pcalibre pcalibre1"/>based on the number of hours they spend studying. For example, if a student spends 10 hours studying, we would predict that they would achieve a grade of approximately 70% based on what we see in <span><em class="italic">Figure 1</em></span><span><em class="italic">.6</em></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer013">
<img alt="Figure 1.6: Applying linear regression function" src="image/B18143_01_6.jpg" class="calibre23"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.6: Applying linear regression function</p>
<h4 class="calibre20">Real-world applications of linear regression</h4>
<p class="calibre3">Regression is one of the<a id="_idIndexMarker037" class="calibre6 pcalibre pcalibre1"/> most widely used types of ML, and it is useful for many different business use cases. It’s the quintessential example of “predicting the future” that is often attributed to the power of ML. Business leaders often want to predict numbers that relate to the performance of their business, such as predicting sales for the next quarter, based on historical sales and other market data. Whenever you have numerical metrics that you can track, and sufficient historical features relating to those metrics, you can try to predict or “forecast” the future values of those metrics, from stock <a id="_idIndexMarker038" class="calibre6 pcalibre pcalibre1"/>market prices and housing prices to blood pressure measurements in various <span>medical scenarios.</span></p>
<h2 id="_idParaDest-23" class="calibre9"><a id="_idTextAnchor022" class="calibre6 pcalibre pcalibre1"/>UL</h2>
<p class="calibre3">With UL, we do <a id="_idIndexMarker039" class="calibre6 pcalibre pcalibre1"/>not train the model on a dataset in which the entries are labeled<a id="_idIndexMarker040" class="calibre6 pcalibre pcalibre1"/> with the correct answers. Instead, we ask the model to find unknown or non-predetermined patterns in the data. An analogy we could use here is that in SL, we are teaching the model about what exists in the data, whereas in UL, the model is teaching us about what exists in the data, such as underlying trends among various data points in <span>our dataset.</span></p>
<p class="calibre3">The most <a id="_idIndexMarker041" class="calibre6 pcalibre pcalibre1"/>common type of UL is something known as “clustering,” whereby data points are grouped together based on some kinds of similarities that are observed by the model. <span><em class="italic">Figure 1</em></span><em class="italic">.7</em> provides a visual representation of this concept, showing the input data on the left and the resulting data clusters on <span>the right:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer014">
<img alt="Figure 1.7: Clustering" src="image/B18143_01_7.jpg" class="calibre24"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.7: Clustering</p>
<h3 class="calibre11">Real-world applications of UL</h3>
<p class="calibre3">An example <a id="_idIndexMarker042" class="calibre6 pcalibre pcalibre1"/>of a real-world application of clustering would be for categorizing groups of customers with similar purchasing preferences. You may have noticed this being utilized when you are purchasing an item online and you see recommendations for other items that may interest you, accompanied by a message such as “people who purchased this item also purchased these <span>other items.”</span></p>
<p class="calibre3">Another important <a id="_idIndexMarker043" class="calibre6 pcalibre pcalibre1"/>real-world use case is fraud detection, in which case one of the clusters could represent legitimate transactions and another cluster could represent unusual or potentially fraudulent transactions, or anything that does not match the characteristics of legitimate transactions could be flagged as potentially fraudulent. As new transactions occur, the model could group them accordingly based on their input characteristics and could trigger a warning response if a transaction appears to be fraudulent. Have you ever received notifications or questions from your bank when you tried to use your credit card on the first day of vacation in a new location? That’s because the bank’s ML models determined that the characteristics of the transaction were abnormal in some way; in this case, it was a transaction from a location that is far from where you usually use <span>your card.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Clustering can actually be considered as a type of <span>unsupervised classification.</span></p>
<h2 id="_idParaDest-24" class="calibre9"><a id="_idTextAnchor023" class="calibre6 pcalibre pcalibre1"/>RL</h2>
<p class="calibre3">In RL, the<a id="_idIndexMarker044" class="calibre6 pcalibre pcalibre1"/> mechanism for training a model is quite different from the previous<a id="_idIndexMarker045" class="calibre6 pcalibre pcalibre1"/> two approaches. To introduce some terminology, we say that the model uses <a id="_idIndexMarker046" class="calibre6 pcalibre pcalibre1"/>an <strong class="bold">agent</strong> that has an overall goal it wants to achieve (the desired model output). The agent interacts with its <strong class="bold">environment</strong> by <a id="_idIndexMarker047" class="calibre6 pcalibre pcalibre1"/>sending <strong class="bold">actions</strong> to the environment. The environment evaluates the actions and provides <a id="_idIndexMarker048" class="calibre6 pcalibre pcalibre1"/>feedback in the form<a id="_idIndexMarker049" class="calibre6 pcalibre pcalibre1"/> of a <strong class="bold">reward</strong> signal, which indicates whether or not the actions contribute to achieving the overall goal, and <strong class="bold">observations</strong>, which describe the current state of the environment. See <span><em class="italic">Figure 1</em></span><em class="italic">.8</em> for a visual <a id="_idIndexMarker050" class="calibre6 pcalibre pcalibre1"/>representation of this process. To make a very broad analogy, this is similar to how we train some animals, such as dogs. For example, if the dog performs a desired action, then the trainer rewards it with a tasty treat. Conversely, if the dog does something undesirable, the trainer may reprimand it in some way. In the case of RL, the model randomly attempts different actions in its environment. If an action or set of actions is deemed to contribute to achieving the overall goal, then the environment provides a positive reward as feedback to the agent, whereas if the action is considered to be detrimental to achieving the overall goal, then the environment provides a negative reward as feedback to the agent. In this case, the reward is usually just a numeric value, such as 0.5 or -0.2, rather than a tasty treat, because unfortunately for ML models, they aren’t yet complex enough to enjoy <span>tasty treats:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer015">
<img alt="Figure 1.8: RL" src="image/B18143_01_8.jpg" class="calibre25"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.8: RL</p>
<p class="calibre3">The model’s <a id="_idIndexMarker051" class="calibre6 pcalibre pcalibre1"/>environment is the space within which the goal and all <a id="_idIndexMarker052" class="calibre6 pcalibre pcalibre1"/>possible actions exist, and the observations are features of the environment. This can be a physical environment, such as when a robot is moving around in a physical space, or something abstract, based on the problem that the model is trying to address. For example, you could create a model that becomes an expert in playing a game such as chess or a video game. The model will begin by trying all kinds of random actions, most of which may seem silly or bizarre at first, but based on feedback from the environment, the model’s actions will gradually become more relevant and may eventually outperform the actions of human experts in <span>that task.</span></p>
<p class="calibre3">RL could actually be considered a type of SL because feedback is provided to the model when it makes a prediction, and the model learns and makes improvements based on that feedback. However, it differs from the standard concept of SL, which we described previously, because we are not providing labeled correct answers as part of the training process. Instead, the model is provided with signals that help it understand what kinds of actions it should <a id="_idIndexMarker053" class="calibre6 pcalibre pcalibre1"/>perform in order to progress toward achieving the <span>required goal.</span></p>
<h3 class="calibre11">Real-world applications of RL</h3>
<p class="calibre3">RL is not yet <a id="_idIndexMarker054" class="calibre6 pcalibre pcalibre1"/>as widely adopted in the industry as “traditional” SL and UL, but some interesting applications are emerging. In addition to the gaming use cases mentioned in a previous paragraph, one of the most recognizable applications of RL is in robotic navigation and self-driving cars. In this application, the car could be considered as the model agent, whereby it performs actions such as accelerating, braking, and steering the wheels. Sensors on the car, such as cameras and lidar sensors, provide observations on the state of the environment. If the actions performed by the car help it to achieve a goal such as navigating a course or self-parking without hitting any obstacles, then it would receive positive rewards, whereas if it collided with an obstacle, then it would receive a negative reward. Over time, it could learn to navigate the course or self-park and <span>avoid obstacles.</span></p>
<p class="calibre3">Another important real-world application of RL is in healthcare, where it has shown promising results for use cases such as medical imaging diagnoses (Zhou et al., 2021, 1-39) and determining what kinds of medical treatments work for individual patients based on their conditions, via<a id="_idIndexMarker055" class="calibre6 pcalibre pcalibre1"/> mechanisms such as <strong class="bold">dynamic treatment </strong><span><strong class="bold">regimes</strong></span><span> (</span><span><strong class="bold">DTRs</strong></span><span>).</span></p>
<p class="calibre3">Now that we’ve discussed the different types of ML approaches and examples of their real-world use cases, let’s take a look at some of the underlying concepts that form the basis for how these ML <span>implementations work.</span></p>
<h1 id="_idParaDest-25" class="calibre5"><a id="_idTextAnchor024" class="calibre6 pcalibre pcalibre1"/>A brief discussion of ML basic concepts</h1>
<p class="calibre3">Mathematics is the hidden magic behind ML, and pretty much all ML algorithms function by using mathematics to find relationships and patterns in data. This book focuses on practical implementations of AI/ML on Google Cloud; it is not a theoretical academic course, so we will not go into a lot of detail on the mathematical equations upon which ML models operate, but we will include mathematical formulae for reference where relevant throughout the book, and here we present some basic concepts that are widely used in AI/ML algorithms. There are plenty of academic materials available for learning each of these concepts in more detail. As an architect, understanding the mathematical concepts could be considered an extracurricular credit rather than a requirement; you usually would not need to dive into the mathematical details of ML algorithms in your day-to-day work, but if you want to have a better understanding of how some of the algorithms work, you can review these concepts in <span>more detail.</span></p>
<h2 id="_idParaDest-26" class="calibre9"><a id="_idTextAnchor025" class="calibre6 pcalibre pcalibre1"/>Linear algebra</h2>
<p class="calibre3">In ML, we make frequent<a id="_idIndexMarker056" class="calibre6 pcalibre pcalibre1"/> use of <a id="_idIndexMarker057" class="calibre6 pcalibre pcalibre1"/>vectors and matrices to store and represent information. To briefly cover some definitions, <em class="italic">Collins Dictionary</em> defines a vector as “<em class="italic">a variable quantity, such as force, that has size and direction</em>” and a matrix as “<em class="italic">an arrangement of numbers, symbols, or letters in rows and columns which is used in solving mathematical problems.</em>” Let’s take a look at what this really means. Representing information in matrices is most easily demonstrated if we use tabular data as an example. Consider the information in <em class="italic">Table 1.1</em>, which represents house sales in King County, Washington (excerpted from a Kaggle <span>dataset: </span><a href="https://www.kaggle.com/datasets/harlfoxem/housesalesprediction" class="calibre6 pcalibre pcalibre1"><span>https://www.kaggle.com/datasets/harlfoxem/housesalesprediction</span></a><span>):</span></p>
<p class="calibre3"><a id="_idIndexMarker058" class="calibre6 pcalibre pcalibre1"/></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer016">
<img alt="Table 1.1: King County house sales" src="image/B18143_01_9.jpg" class="calibre26"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Table 1.1: King County house sales</p>
<p class="calibre3">The dataset depicted in <em class="italic">Table 1.1</em> has 7 rows (not including the title row) and 13 columns, where each row represents a single house sale, which we consider a data point or an observation in our dataset, and each column represents individual features of the data points. We can consider each row and each column to be vectors. Bear in mind that a vector can also be considered as a matrix with one row or one column (that is, a one-dimensional vector). So, for each individual house purchase in our dataset, we have a vector that contains each of the features of that house. Let’s imagine that we want to predict the price of houses based on the features (other than the price) of each house. We would want to find the function that best describes the relationship between the price and all of the other features, and linear regression is one way in which we could do this. In this case, we would want to find the set of values by which we should multiply each feature and then add all of the results of those multiplications together in order to correctly estimate the price of each house. This means that each feature would have a corresponding multiplier (or “coefficient”). In order to efficiently compute the multiplications of the features and the coefficients and then add all of the results together, we could represent all of the coefficients also as a vector and calculate the dot product of the feature vector and the coefficient vector. We’ll take a minute here to clarify what it means to calculate the dot product. If we have two vectors, <em class="italic">A</em> and <em class="italic">B</em>, where <em class="italic">A = [a b c]</em>, and <em class="italic">B = [d e f]</em>, the dot product is calculated <span>as follows:</span></p>
<p class="calibre3"><em class="italic"> a*d + b*e + </em><span><em class="italic">c*f</em></span></p>
<p class="calibre3">To illustrate, let’s take the first row of <em class="italic">Table 1.1</em> (without the price) as a feature vector; it would look <span>like this:</span></p>
<pre class="source-code">
[3 1 1180 5650 1 0 0 3 7 1955 0]</pre> <p class="calibre3">Now, let’s<a id="_idIndexMarker059" class="calibre6 pcalibre pcalibre1"/> create an<a id="_idIndexMarker060" class="calibre6 pcalibre pcalibre1"/> initial vector of random coefficients (we can just create random coefficients at first and improve our guesses later during the model training process), which needs to have the same number of elements as our preceding <span>feature vector:</span></p>
<pre class="source-code">
[1 5 0.3 0.001 2 7 2.5 108.67 14.234 0.103 8]</pre> <p class="callout-heading">Note</p>
<p class="callout">When calculating the dot product, there are rules regarding the shapes of each vector, but we are omitting those details here for simplicity. We will go deeper into those details in <span>later chapters.</span></p>
<p class="calibre3">The dot product of our feature vector and coefficient vector is <span>shown here:</span></p>
<pre class="source-code">
3*1 + 1*5 + 1180*0.3 + 5650*0.001 + 1*2 + 0*7 + 0*2.5 + 3*108.67 + 7*14.234 + 1955*0.103 + 0*8 = 996.663</pre> <p class="calibre3">From our first guess at what the coefficients should be, we estimate that the price of the house in <em class="italic">row 1</em> of <em class="italic">Table 1.1</em> would be $996.663. However, we can see in <em class="italic">Table 1.1</em> that the actual price of that house was $221,900. We can now calculate the error resulting from our guess <span>as follows:</span></p>
<pre class="source-code">
221900 – 996.663 = 220903</pre> <p class="calibre3">We often<a id="_idIndexMarker061" class="calibre6 pcalibre pcalibre1"/> refer to this as the <strong class="bold">loss</strong> or the <strong class="bold">cost</strong> of our linear function, and it is similar to what was <a id="_idIndexMarker062" class="calibre6 pcalibre pcalibre1"/>represented by the red lines in <span><em class="italic">Figure 1</em></span><em class="italic">.5</em> earlier, where this value represents the “distance” from the correct answer; that is, how far away our guess is from the correct answer. This is the first step in the learning process, and in later sections, we will want to find coefficients that minimize <span>this error.</span></p>
<h2 id="_idParaDest-27" class="calibre9"><a id="_idTextAnchor026" class="calibre6 pcalibre pcalibre1"/>Calculus</h2>
<p class="calibre3">One common use <a id="_idIndexMarker063" class="calibre6 pcalibre pcalibre1"/>of calculus<a id="_idIndexMarker064" class="calibre6 pcalibre pcalibre1"/> in ML is in the error minimization process mentioned previously. In later <a id="_idIndexMarker065" class="calibre6 pcalibre pcalibre1"/>chapters, we will define something called a <strong class="bold">loss function</strong> (or a <strong class="bold">cost function</strong>), and we will<a id="_idIndexMarker066" class="calibre6 pcalibre pcalibre1"/> use mechanisms such as “Gradient descent” (described later) to minimize that loss function. In that case, we will use calculus to derive the slope at various points on the curve that represents the loss function, and we will use that information to work toward minimizing the cost function (see <span><em class="italic">Figure 1</em></span><span><em class="italic">.9</em></span><span>):</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer017">
<img alt="Figure 1.9: The slope at a point on a function curve (source: https://commons.wikimedia.org/wiki/File:Parabola_tangent.png)" src="image/B18143_01_10.jpg" class="calibre27"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.9: The slope at a point on a function curve (source: https://commons.wikimedia.org/wiki/File:Parabola_tangent.png)</p>
<h2 id="_idParaDest-28" class="calibre9"><a id="_idTextAnchor027" class="calibre6 pcalibre pcalibre1"/>Statistics and probability</h2>
<p class="calibre3">ML models don’t provide answers as<a id="_idIndexMarker067" class="calibre6 pcalibre pcalibre1"/> definite facts. Instead, the results from an ML model are often provided as approximations, probabilities, or inferences. We most commonly call the results from an ML model invocation <a id="_idIndexMarker068" class="calibre6 pcalibre pcalibre1"/>an <strong class="bold">inference</strong>. Referencing our cat classification model<a id="_idIndexMarker069" class="calibre6 pcalibre pcalibre1"/> from earlier in this chapter, a model that we would use to identify cats in a photograph would usually respond to us <a id="_idIndexMarker070" class="calibre6 pcalibre pcalibre1"/>with the “probability” of a cat<a id="_idIndexMarker071" class="calibre6 pcalibre pcalibre1"/> existing in the photograph. For example, the model may tell us that it is 97.3% sure that it sees a cat in the photograph. One of the main goals of ML is to ensure that these probabilities are as accurate as possible. A model would not be effective if it says it’s 100% sure it sees a cat, but there is actually no cat in the photograph. In the case of binary classification, where the response is either true or false, there would generally be a threshold above which we consider the probability response to be true or below which we would consider it to be false. For example, we could determine that anything above 72.3% probability is deemed to be positive, and anything below that threshold is negative. The threshold value would vary based on the use case and is one of the parameters that need to be determined when building <span>such models.</span></p>
<p class="calibre3">If we break the process down a bit further, in the case of the cat classification model, it has observed some features in the photograph, and based on previous training in which it has seen those kinds of features (or features similar to those), it estimates the probability of a cat being present in <span>the photograph.</span></p>
<p class="calibre3">We will also see later in this book that statistical analysis plays an important role in the early stages of an ML project when data scientists are exploring how datasets can be used to address a business problem. In such data exploration activities, data scientists usually analyze the statistical distributions of values for each of the variables or features in the dataset. For<a id="_idIndexMarker072" class="calibre6 pcalibre pcalibre1"/> example, when exploring a dataset, data scientists often want to see statistical<a id="_idIndexMarker073" class="calibre6 pcalibre pcalibre1"/> information<a id="_idIndexMarker074" class="calibre6 pcalibre pcalibre1"/> regarding each of<a id="_idIndexMarker075" class="calibre6 pcalibre pcalibre1"/> the numeric variables in the data, such as the mean, median, mode, and the minimum and maximum range in the values; see <span><em class="italic">Figure 1</em></span><em class="italic">.10</em>, in which the statistical distributions of some features from our house sales dataset <span>are shown:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer018">
<img alt="Figure 1.10: Statistical distributions of dataset features" src="image/B18143_01_11.jpg" class="calibre28"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.10: Statistical distributions of dataset features</p>
<h2 id="_idParaDest-29" class="calibre9"><a id="_idTextAnchor028" class="calibre6 pcalibre pcalibre1"/>Metrics</h2>
<p class="callout-heading">Note</p>
<p class="callout">We also introduce the <a id="_idIndexMarker076" class="calibre6 pcalibre pcalibre1"/>term <em class="italic">data science</em> here. While data science is a broad scientific field, for the purposes of this book, we use the term <em class="italic">data science</em> to incorporate all of the steps required to create an ML model, including all data preparation and <span>processing steps.</span></p>
<p class="calibre3">Data science<a id="_idIndexMarker077" class="calibre6 pcalibre pcalibre1"/> and ML <a id="_idIndexMarker078" class="calibre6 pcalibre pcalibre1"/>are fields in which we constantly<a id="_idIndexMarker079" class="calibre6 pcalibre pcalibre1"/> strive for improvement, whether it’s to improve the accuracy of our models, how quickly they train and perform, or how much compute power they use. There’s a well-known saying, “<em class="italic">What isn’t measured cannot be improved</em>” (this is actually an approximation of slightly different observations from Peter Drucker and Lord Kelvin), and this saying holds a lot of truth; in order to improve something in a methodical way, you need to be able to measure some attribute of that thing. For this reason, metrics are an essential component of any ML project, and selecting the correct metric to monitor can have a critical impact on the success of an <span>ML implementation.</span></p>
<p class="calibre3">Apart from operational metrics, such as measuring the latency of responses from your ML models, there are also various metrics for measuring how accurate an ML model’s <span>inferences are.</span></p>
<p class="calibre3">For<a id="_idIndexMarker080" class="calibre6 pcalibre pcalibre1"/> example, in<a id="_idIndexMarker081" class="calibre6 pcalibre pcalibre1"/> linear regression, it’s common to measure the <strong class="bold">Mean Absolute Error</strong> (<strong class="bold">MAE</strong>), <strong class="bold">Mean Squared Error</strong> (<strong class="bold">MSE</strong>), or <strong class="bold">Root Mean Squared Error</strong> (<strong class="bold">RMSE</strong>), while for classification use-cases, we <a id="_idIndexMarker082" class="calibre6 pcalibre pcalibre1"/>often use metrics such as Accuracy and Precision. We will explore all of these metrics, and many others, in <span>later chapters.</span></p>
<p class="calibre3">Having discussed some of the underlying theory and mathematical concepts that are used in ML, let’s bring the discussion back to the real world again, and let’s take a look at what kinds of challenges exist for companies when they try to implement <span>ML workloads.</span></p>
<h1 id="_idParaDest-30" class="calibre5"><a id="_idTextAnchor029" class="calibre6 pcalibre pcalibre1"/>Common challenges in developing ML applications</h1>
<p class="calibre3">Companies typically <a id="_idIndexMarker083" class="calibre6 pcalibre pcalibre1"/>run into common kinds of challenges when they embark on an AI/ML development journey, and it is often a key requirement of an architect’s role to understand common challenges in a given problem space. As an architect, if you are not aware of challenges and how to address them, it’s unlikely that you will design an appropriate solution. In this section, we introduce the most frequently encountered challenges and pitfalls at a high level, and in later sections of this book, we discuss ways to address or alleviate some of these hurdles of <span>AI/ML development.</span></p>
<h2 id="_idParaDest-31" class="calibre9"><a id="_idTextAnchor030" class="calibre6 pcalibre pcalibre1"/>Gathering, processing, and labeling data</h2>
<p class="calibre3">Data is the <a id="_idIndexMarker084" class="calibre6 pcalibre pcalibre1"/>key ingredient in ML because, in general, ML models cannot function without data. There’s an often-quoted adage that data scientists spend up to 80% of their time working on finding, cleaning, and <a id="_idIndexMarker085" class="calibre6 pcalibre pcalibre1"/>processing data before they can begin to make use of it for analytical or data science purposes. This is an important concept to understand; that is, data scientists are not tasked simply with finding <a id="_idIndexMarker086" class="calibre6 pcalibre pcalibre1"/>relevant data, although that is, in itself, often a difficult task; they also need to convert that data to a state that can be used efficiently by ML algorithms. Not only may data be unusable for many kinds of ML models in its raw format, but a data scientist may also need to combine data from many different sources, each with different formats and different problems that need to be addressed in the raw data before it can be used by an ML model. Also, the available data may not be sufficient to make the kinds of predictions that we’d like to get from an ML model, and data scientists often need to invent ways to generate new data by cleverly using what’s available from their existing data sources. We will cover this in more detail when we discuss a practice known as “feature engineering” later in <span>this book.</span></p>
<h3 class="calibre11">Data quality impact on model performance</h3>
<p class="calibre3">The effectiveness of a <a id="_idIndexMarker087" class="calibre6 pcalibre pcalibre1"/>data scientist in performing the aforementioned tasks can have drastic impacts on how well or poorly the resulting ML models function because the data that is fed into ML models usually has a direct influence on the model’s output accuracy. Bear in mind that for some business applications, a tiny difference in the ML model’s accuracy can result in a difference of millions of dollars in revenue for business owners. Another well-known expression that describes this process well is “garbage in, garbage out.” The concept is quite simple; if the data you feed into the model doesn’t accurately represent what you’re trying to predict, the model will not be able to make <span>accurate predictions.</span></p>
<p class="calibre3">It’s not just a model’s outputs that are affected by the quality or contents of the data. Large ML models can be expensive and time-consuming to train, and inadequately prepared data can increase the time and expense required to train a model. As an architect or data scientist, these factors play a fundamental role in how we design our workloads because an architect’s purpose is not just to design solutions that address technical challenges, but often what will be equally or even more important will be the cost of implementing the solution. If we designed a solution that would be too expensive to implement, then the project may not get approval to proceed, or the company may lose <a id="_idIndexMarker088" class="calibre6 pcalibre pcalibre1"/>money by implementing <span>the solution.</span></p>
<h3 class="calibre11">Bias and fairness</h3>
<p class="calibre3">Another important concept that we will cover in more detail in this book is the concept of bias<a id="_idIndexMarker089" class="calibre6 pcalibre pcalibre1"/> and fairness. The goal and challenge in this regard is to ensure that the <a id="_idIndexMarker090" class="calibre6 pcalibre pcalibre1"/>data we use to train and evaluate ML models represents a fair distribution of all relevant classes for our dataset. For example, if our model will make predictions that will affect people’s lives, such as approving a loan or a credit card application, we need to ensure that the dataset used to train the model fairly represents all relevant demographic groups and does not become inadvertently biased in relation to any particular <span>demographic groups.</span></p>
<h3 class="calibre11">Data labeling</h3>
<p class="calibre3">In addition to the<a id="_idIndexMarker091" class="calibre6 pcalibre pcalibre1"/> challenges described previously, another substantial challenge exists specifically for <strong class="bold">supervised ML</strong> (<strong class="bold">SML</strong>) applications. As we discussed earlier in this chapter, SML models learn from labels in the data that provide the “correct” answer for each data entry. See <span><em class="italic">Figure 1</em></span><em class="italic">.11</em> for an example, in which the dataset contains labels describing whether or not students passed their exams, in addition to other details regarding those exams, such as the grade received and the number of hours spent studying. However, usually, these datasets and the related labels need to be generated or created somehow, and considering that some datasets may contain millions of data points, it can be difficult, time-consuming, and error-prone to label all of the <span>data accurately:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer019">
<img alt="Figure 1.11: Example of labels (highlighted in green) in a dataset" src="image/B18143_01_12.jpg" class="calibre29"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.11: Example of labels (highlighted in green) in a dataset</p>
<h3 class="calibre11">Data governance and regulatory compliance</h3>
<p class="calibre3">It’s important<a id="_idIndexMarker092" class="calibre6 pcalibre pcalibre1"/> to control how data is being stored and processed within your company and who has access to the data. Special care must be taken with regard to sensitive data — for example, data that contains customers’ personal details such as their address, date of birth, or credit card number. There are specific regulations that need to be upheld in this<a id="_idIndexMarker093" class="calibre6 pcalibre pcalibre1"/> regard, such as <a id="_idIndexMarker094" class="calibre6 pcalibre pcalibre1"/>the <strong class="bold">California Consumer Privacy Act</strong> (<strong class="bold">CCPA</strong>), the <strong class="bold">Children’s Online Privacy Protection Act</strong> (<strong class="bold">COPPA</strong>), the <strong class="bold">General Data Protection Regulation</strong> (<strong class="bold">GDPR</strong>), and<a id="_idIndexMarker095" class="calibre6 pcalibre pcalibre1"/> the <strong class="bold">Health Insurance Portability and Accountability Act </strong>(<strong class="bold">HIPAA</strong>), which <a id="_idIndexMarker096" class="calibre6 pcalibre pcalibre1"/>outline detailed rules on how specific types of data must be handled. For companies that operate on an international scale, abiding by all of the varying regulations in different countries can be quite complicated. When data scientists are gathering, storing, exploring, processing, and labeling data, they need to keep these security requirements in mind, and as an AI/ML solutions architect, you will need to ensure that the data storage and processing infrastructure facilitates adhering to these regulations and other important information security practices. We will cover each of Google Cloud’s relevant data storage and processing infrastructure options in this book and provide additional guidance on data governance concepts <span>where appropriate.</span></p>
<h3 class="calibre11">Data and model lineage</h3>
<p class="calibre3">Data science<a id="_idIndexMarker097" class="calibre6 pcalibre pcalibre1"/> contains the <a id="_idIndexMarker098" class="calibre6 pcalibre pcalibre1"/>word “science” for a reason. As with most scientific fields, it involves iterative experimentation. When data scientists create new models, they usually go through a complex process in which they need to experiment with different datasets, different transformations on the datasets, different algorithms and parameters, and other supporting activities and resources. A team of data scientists could try hundreds of different combinations of steps before they create the desired model, and each of those steps has inputs and outputs. If a data scientist has a breakthrough discovery and creates a killer new model, and then they leave the company or something happens to them, we would not be able to recreate their work unless they kept detailed notes of all of the steps they took to create that model, including all input and output artifacts that were used and created by <span>each step.</span></p>
<p class="calibre3">This is also important during the experimentation process, in which data scientists may want to collaborate with other scientists on their team or on other teams. If a data scientist gets some promising results from an experiment, they could share the details with their peers, who could validate the results or build on top of them by combining the outputs of other experiments they had performed. This kind of collaboration is fundamental to many kinds of scientific research and is often required for significant progress <span>to occur.</span></p>
<p class="calibre3">Data and model lineage refers to this process of tracking all of the steps and their associated inputs and outputs that were required to create a model. It’s not only important for collaboration and progress but also for governance purposes and fairness in AI/ML development; it’s also important to understand how a model was created and which data artifacts, algorithms, and parameters were used along <span>the way.</span></p>
<p class="calibre3">As companies begin to perform AI/ML research, they often do not have robust lineage tracking mechanisms in place, and collaboration at scale can be hampered as a result. Even worse, companies sometimes find themselves using models for which nobody has a good understanding of how they work or how they were created. This is not a good position to be in if you want to update those models or they need to be audited for compliance reasons. Later in this book, we’ll see how Google Cloud’s Vertex AI platform can help to ensure that data and model lineage are being <span>tracked appropriately.</span></p>
<h2 id="_idParaDest-32" class="calibre9"><a id="_idTextAnchor031" class="calibre6 pcalibre pcalibre1"/>Organizational challenges</h2>
<p class="calibre3">Most large companies have<a id="_idIndexMarker099" class="calibre6 pcalibre pcalibre1"/> evolved over time and generally consist of multiple organizations that are loosely connected to each other. As large companies begin to experiment with AI/ML, research often takes place organically in each organization without coordination between the different parts of the company. When this happens, knowledge and data are often not shared adequately — or at all — across the company, and this leads to the formation of silos within each organization, which in turn create obstacles that impede the company’s overall success regarding AI/ML solution development. As an AI/ML solutions architect, you will need to advise company leadership on how to structure their organizations and their corporate policies to make their AI/ML journey as successful <span>as possible.</span></p>
<p class="calibre3">Let’s imagine that we own a large company, and a data science team in one organization — let’s call it “Organization A” — in our company has spent the past year gathering, cleaning, and experimenting with a large dataset, and they finally had some success in training an ML model that is providing promising results. Let’s also imagine that — similar to most companies — the organizations that make up our business operate mainly independently of each other, with little communication between them unless it is required as part of regular business operations. Now, another organization in our company, named “Organization B,” starts exploring AI/ML, and they have a similar use case to Organization A. Because the organizations operate independently and do not regularly communicate with each other, Organization B will start from scratch and will spend the next year wasting their time doing work that has already been completed elsewhere in <span>the company.</span></p>
<p class="calibre3">Now, let’s imagine that<a id="_idIndexMarker100" class="calibre6 pcalibre pcalibre1"/> our company consists of 20 large organizations, each with hundreds of product development teams. Consider how much time would be wasted if even just 20% of those product development teams started creating AI/ML workloads without communicating with each other. It may be hard to believe, but this is how most large companies operate when they begin to experiment <span>with AI/ML.</span></p>
<p class="calibre3">There are mainly four different types of silos that form in the scenarios described previously, and they are related to the following <span>four topics:</span></p>
<ul class="calibre16">
<li class="calibre8"><span>Knowledge</span></li>
<li class="calibre8"><span>Data</span></li>
<li class="calibre8"><span>AI/ML models</span></li>
<li class="calibre8">Tooling <span>and development</span></li>
</ul>
<h3 class="calibre11">Knowledge silos</h3>
<p class="calibre3">This<a id="_idIndexMarker101" class="calibre6 pcalibre pcalibre1"/> one is pretty straightforward: if organizations are not sharing knowledge effectively with each other, teams all across the company will waste time trying to solve similar problems from scratch again <span>and again.</span></p>
<h3 class="calibre11">Data silos</h3>
<p class="calibre3">We’ve already talked <a id="_idIndexMarker102" class="calibre6 pcalibre pcalibre1"/>about the importance and difficulty of getting access to data; especially getting access to clean, processed data that is ready to be used for training ML models. In most companies, each organization (and, possibly, each team) will build its own datasets. If a team in Organization B wanted to get access to a dataset that was built by Organization A, they would first need to learn of the existence of that dataset (which requires some knowledge sharing to occur). Then, they would need to request access to the data, which can often go through months of escalations through upper management just to get the required approvals. Next, a multi-month project would need to be carried out in order to actually set up the integration between the  Organization A and Organization B systems. In an industry where AI/ML use cases and opportunities are evolving so quickly, these are the kinds of obstacles and processes that kill a company’s ability to rapidly innovate in this space. <span><em class="italic">Figure 1</em></span><em class="italic">.12</em> shows an example of data silos in a company. You will soon learn about ways to effectively and securely share datasets between organizations in order to break down <span>data silos:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer020">
<img alt="Figure 1.12: An example of data silos" src="image/B18143_01_13.jpg" class="calibre30"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.12: An example of data silos</p>
<h3 class="calibre11">Model silos</h3>
<p class="calibre3">This is an extension of the knowledge and<a id="_idIndexMarker103" class="calibre6 pcalibre pcalibre1"/> data silo concepts. Just as with knowledge and datasets, some kinds of models can be reused once they’ve been developed. If a team in Organization A has created a useful model, and that model could be reused by other teams in the company, then we should ensure that such sharing is enabled not only by our corporate structure, culture, and policies but also by our AI/ML development infrastructure. To understand this in more detail, you will learn how to share models, what kinds of requirements that entails, and how our AI/ML development tools and infrastructure can help or hinder <span>this process.</span></p>
<h3 class="calibre11">Tooling and development silos</h3>
<p class="calibre3">In large companies, various development teams may use different tools and methodologies to build their <a id="_idIndexMarker104" class="calibre6 pcalibre pcalibre1"/>AI/ML workloads. The selection of those tools and methodologies is often based on arbitrary factors such as what kinds of tools the employees used at previous companies. Employees in each organization or team will install their chosen tools on their machines and start developing in an ad hoc manner. For example, Employee A in the Organization B organization will install and use a tool named <strong class="source-inline">scikit-learn</strong> for their development and will use MySQL databases to store their application data, while Employee B in the Organization B organization will install and use PyTorch for their development and will use Oracle databases to store their application data. Next, Employee A may leave the company, and a new employee, Employee C, will be hired, and they will prefer using TensorFlow and some other type of database. This “wild west” approach makes it very difficult for employees and teams to collaborate and share artifacts at scale across <span>the company.</span></p>
<p class="calibre3">In later chapters, we will go into detail on how to prevent, fix, and design around these pitfalls, but for now, it’s critical to highlight the importance of standardization. As companies begin to build their data science strategies, they should standardize as much as possible. Standardize the toolsets that will be used for AI/ML development and the types of data systems and formats that will be used. Establish company practices that encourage knowledge sharing and simplify data and model sharing across teams and organizations in a secure manner. Without these strategies, it will be difficult to collaborate and innovate rapidly at scale. One caveat is that you will need to find the balance between standardization and flexibility. Lack of standardization leads to the problems mentioned previously, but if your standardization strategy is too rigid, it could hinder your developers’ productivity. For example, it would be too rigid to force all of your developers to use only one type of database and only one specific programming language or framework. Different tools are best suited to different use cases, and your company should provide guidelines to your employees on what tools are recommended for which <span>use cases.</span></p>
<h2 id="_idParaDest-33" class="calibre9"><a id="_idTextAnchor032" class="calibre6 pcalibre pcalibre1"/>Operationalization and ongoing management of AI/ML models</h2>
<p class="calibre3">By now, it’s hopefully pretty clear that AI/ML model development can be complicated and challenging. However, even <a id="_idIndexMarker105" class="calibre6 pcalibre pcalibre1"/>when you’ve successfully created a model that makes useful predictions, your work is still not done. Companies often find it difficult to bring a model out into the real world even though it has been working well in the lab. We already covered some of the infrastructural and logistical activities that need to be performed in order to host a model, but what introduces additional complexity is that most models need to evolve over time, because the environment in which they operate will almost inevitably evolve and change over time. This is similar to regular software development, in which we need to update our applications in order to provide new functionality or to react to changes in how our customers are using <span>our products.</span></p>
<p class="calibre3">Another important factor is knowing when we may need to update our models. When our models are running in the real world, we need to monitor them on an ongoing basis in order to determine whether they continue to adequately meet the business needs they were created <span>to address.</span></p>
<p class="calibre3">In this book, you’ll learn about the unique requirements for monitoring and updating AI/ML models and how traditional software DevOps mechanisms are not sufficient by themselves for these purposes, but how we can build upon those mechanisms to suit the needs of <span>AI/ML workloads.</span></p>
<h2 id="_idParaDest-34" class="calibre9"><a id="_idTextAnchor033" class="calibre6 pcalibre pcalibre1"/>Edge cases</h2>
<p class="calibre3">The term <em class="italic">edge cases</em> is <a id="_idIndexMarker106" class="calibre6 pcalibre pcalibre1"/>being used as a pun with a double meaning here. In traditional software development, edge cases are abnormal or extreme use cases that can cause anomalous behavior. However, in this case, we also refer to the concept of edge computing, which is a sub-field of cloud computing that focuses on providing compute resources as close as possible to customers with low-latency requirements (see <span><em class="italic">Figure 1</em></span><em class="italic">.13</em>). We refer to the locations of these compute resources as “edge locations” because they exist outside the core cloud computing infrastructure locations, and they generally have limited resources in comparison to core cloud computing <span>infrastructure locations.</span></p>
<p class="calibre3">ML models often require powerful compute resources in order to function, and this can present challenges for edge computing use cases due to limited resources at <span>edge locations.</span></p>
<p class="calibre3">However, some ML models need to<a id="_idIndexMarker107" class="calibre6 pcalibre pcalibre1"/> operate at or close to the “edge.” For example, consider a self-driving car, which needs to perform actions to navigate in its environment. Before and after each action, it needs to consult an ML model to determine the best next actions to perform. In this case, it cannot use a model that is hosted in a far-away data center because it cannot wait for an API request to travel over the internet to a server in the cloud, and then wait for the server to provide a response before it decides what to do next. Instead, it needs to make decisions and react to its environment within milliseconds. This is a clear use case for <span>edge computing.</span></p>
<p class="calibre3">In later chapters, we explore some of the requirements and solutions for these scenarios and how to address them for <span>AI/ML workloads:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer021">
<img alt="Figure 1.13: Edge computing" src="image/B18143_01_14.jpg" class="calibre31"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.13: Edge computing</p>
<h1 id="_idParaDest-35" class="calibre5"><a id="_idTextAnchor034" class="calibre6 pcalibre pcalibre1"/>Summary</h1>
<p class="calibre3">In this chapter, we introduced basic terminology related to AI/ML and some background information on how AI/ML has developed over time. We also explored different AI/ML approaches that exist today and some of their applications in the real world. Finally, and perhaps most importantly, we summarized common challenges and pitfalls that companies typically run into when they begin to implement <span>AI/ML workloads.</span></p>
<p class="calibre3">In the coming chapters, we will dive deeper into the model <span>development process.</span></p>
</div>
</div></body></html>