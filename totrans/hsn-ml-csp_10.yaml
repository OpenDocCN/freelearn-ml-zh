- en: Deep Belief â€“ Deep Networks and Dreaming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've all heard of deep learning, but how many of us know what a **Deep Belief
    Network** is? Let's start this chapter by answering that very question. A Deep
    Belief Network is a very advanced form of machine learning, one whose meaning
    is rapidly evolving. As a machine learning developer, it's important that you
    have a bit of exposure to this concept so that you are familiar with it when you
    encounter it or it encounters you!
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, a Deep Belief Network is technically a deep neural network.
    We should state that the meaning of **deep**, when it comes to deep learning or
    deep belief, means that the network is composed of multiple layers (hidden units).
    In a Deep Belief Network, these connections span internally between each neuron
    within a layer, but not between different layers. A Deep Belief Network can be
    trained to learn unsupervised in order to probabilistically reconstruct the network's
    inputs. The layers then function as 'feature detectors' to recognize or classify
    images, letters, and so on. You can also watch a Deep Belief Network dream, which
    is a very interesting topic in and of itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Restricted Boltzmann Machines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and training a Deep Belief Network in C#
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restricted Boltzmann Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One popular method of constructing a Deep Belief Network is to comprise it as
    a layered collection of **Restricted Boltzmann Machines** (**RBMs**). These RMBs
    function as auto-encoders, with each hidden layer, serving as the visible layer
    for the next. This composition leads to a fast, layer-by-layer and unsupervised
    training procedure. The Deep Belief Network will have layers of RBMs for the pre-train
    phase, and then a feedforward network for the fine-tune phase. The first step
    of the training will be to learn a layer of features from the visible units. The
    next step is to take the activations from the previously trained features and
    make them the new visible units. We then repeat the process so that we can learn
    more features in the second hidden layer. The process then continues for all hidden
    layers.
  prefs: []
  type: TYPE_NORMAL
- en: We should provide two notes of information here.
  prefs: []
  type: TYPE_NORMAL
- en: First, we should explain a bit about what an auto-encoder is and does. Auto-encoders
    are at the heart of what is known as **representational learning**. They encode
    input, which is usually compressed vectors of significant features, as well as
    data for reconstructing via unsupervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: Second, we should note that stacking RBMs within a Deep Belief Network is but
    one way to approach this. Stacking Restricted Linear Units (ReLUs) with dropout
    and training, and then accompanying that with backpropagation, has once again
    become state of the art. I say once again because 30 years ago, the supervised
    approach was the way to go. Rather than let the algorithm look at all the data
    and determine the feature of interest, sometimes we as humans can actually better
    find the feature we want.
  prefs: []
  type: TYPE_NORMAL
- en: 'What I would consider the two most significant properties of Deep Belief Networks
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: There is an efficient, layer-by-layer process for learning top-down, generative
    weights. It determines how variables in one layer depend on variables in the layers
    above it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the learning is complete, the values of the variables in every layer can
    easily be inferred by a single, bottom-up pass which starts with an observed data
    vector in the bottom layer and uses the generative weights in reverse direction
    to reconstruct the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that said, let's now talk about RBMs as well as Boltzmann machines in general.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Boltzmann machine is a recurrent neural network with binary units and undirected
    edges between these units. For those of you who weren''t paying attention in your
    graph theory class, undirected means the edges (or links) are bidirectional, they
    are not pointing in any specific direction. For those not experienced in graph
    theory, the following is a diagram of an undirected graph with undirected edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6107d56-83c7-438d-9796-8d0d9372a8d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Boltzmann machines were one of the first neural networks capable of learning
    internal representations, and given enough time, they can solve difficult problems.
    They are, however, not good at scaling, which leads us to our next topic, RBMs.
  prefs: []
  type: TYPE_NORMAL
- en: RBMs were introduced to deal with the Boltzmann Machines' inability to scale.
    They have hidden layers, with connections restricted between each hidden unit
    but not outside those units, which helps with efficient learning. More formally,
    we must dive into a little bit of graph theory to properly explain this.
  prefs: []
  type: TYPE_NORMAL
- en: RBMs must have their neurons form what is known as a **bipartite graph**, a
    more advanced form of graph theory; a pair of nodes from each of the two groups
    of units (visible and hidden layers) may have a symmetric connection between them.
    There can be no connections between the nodes within any group. A bipartite graph,
    sometimes called a **biograph**, is a set of graph vertices decomposed into two
    disjoint sets such that no two vertices within the same set are adjacent.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a good example that will help visualize this topic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that there are no connections within the same set (red on the left or
    black on the right), but there are connections between the two sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f5eb229-6889-43c9-858a-889d54e19878.png)'
  prefs: []
  type: TYPE_IMG
- en: More formally, an RBM is what is known as a **symmetrical bipartite graph*.***
    This is because inputs from all visible nodes are passed to all hidden nodes.
    We say symmetrical because each visible node relates to a hidden node; bipartite
    because there are two layers; and graph because, well, it's a graph, or a collection
    of nodes if you prefer!
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine for a second that our RBM is presented images of cats and dogs, and
    we have two output nodes, one for each animal. On our forward learning pass, our
    RBM asks itself "*With the pixels I am seeing, should I send stronger weight signals
    for the cat or for the dog?*" On the backward pass, it wonders "*Being a dog,
    which distribution of pixels should I see?*" That, my friends, was today''s lesson
    on joint probability: the simultaneous probability of *X* given *A* and *A* given
    *X*. In our case, this joint probability is expressed as the weights between the
    two layers and is an important aspect of RBMs.'
  prefs: []
  type: TYPE_NORMAL
- en: With today's mini lessons in joint probability and graph theory behind us, we'll
    now talk about **reconstruction**, which is an important piece of what RBMs do.
    In the example we have been discussing, we are learning which groups of pixels
    occur (meaning being *on*) for a set of images. When a hidden layer node is activated
    by a significant weight (whatever that is determined to be to turn it *on*), it
    represents co-occurrences of something happening, in our case, the dog or the
    cat. Pointy ears + round face + small eyes might be what we are looking for if
    the image is a cat. Big ears + long tail + big nose may make the image a dog.
    These activations represent what our RBM "thinks" the original data looks like.
    For all intents and purposes, we are in fact reconstructing the original data.
  prefs: []
  type: TYPE_NORMAL
- en: We should also quickly point out that an RBM has two biases instead of one.
    This is very important as this is what distinguishes it from other auto-encoding
    algorithms. The hidden bias helps our RBM produce the activations we need when
    it's on the forward pass, and the visible layer bias helps learn the correct reconstructions
    on the backward pass. The hidden bias is important because its main job is to
    ensure that some of the nodes fire no matter how sparse our data might be. You
    will see how this impacts the way a Deep Belief Network dreams a little later
    on.
  prefs: []
  type: TYPE_NORMAL
- en: Layering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once our RBM learns the structure of the input data, which is related to the
    activations made in our first hidden layer, the data gets passed down to the next
    hidden layer. The first hidden layer then becomes the new visible layer. The activations
    we created in the hidden layer now become our inputs. They will be multiplied
    by the weights in the new hidden layer to produce another set of activations.
    This process continues through all the hidden layers in our network. The hidden
    layer becomes the visible layer, we have another hidden layer whose weights we
    will use, and we repeat. Each new hidden layer results in adjusted weights, until
    we get to the point where we can recognize the input from the previous layer.
  prefs: []
  type: TYPE_NORMAL
- en: To elaborate just a bit more (helping you in your quest to remain buzzword-compliant),
    this is technically called **unsupervised, greedy, layer-wise training**. No input
    is required to improve the weights of each layer, which means no outside influence
    of any type is involved. This further means we should be able to use our algorithm
    to train on unsupervised data that has not been seen previously. As we have continually
    stressed, *the more the data we have, the better our results*! As each layer gets
    better and hopefully more accurate, we are in a much better position to increase
    our learning through each hidden layer, with the weights having the responsibility
    of guiding us to the correct image classification along the way.
  prefs: []
  type: TYPE_NORMAL
- en: But as we discuss reconstruction, we should point out that each time a number
    (weight) in our reconstruction effort is non-zero, that is an indication that
    our RBM has learned something from the data. In a sense, you can treat the returned
    numbers exactly as you would treat a percentage indicator. The higher the number,
    the more confident the algorithm is of what it is seeing. Remember, we have the
    master dataset that we are trying to get back to, and we have a reference dataset
    to use in our reconstruction efforts. As our RBM iterates over each image, it
    doesn't yet know what image it is dealing with; that's what it is trying to determine.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a brief moment to clarify something. When we say we are using a greedy
    algorithm, what we really mean is that our RBM will take the shortest path to
    achieve the best result. We will sample random pixels from the image we see, and
    test which ones lead us to the correct answer. The RBM will test each hypothesis
    against the master dataset (test set), which is our correct end goal. Keep in
    mind that each image is just a set of pixels we're trying to classify. Those pixels
    house features and characteristics of data. For example, a pixel can have different
    shades of light, wherein dark pixels perhaps indicate borders, light pixels perhaps
    indicate numbers, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: But what happens when things don't go our way? What happens if whatever we learn
    at any given step is not correct? Should this occur, it would mean that our algorithm
    has guessed incorrectly. Our course of action is then to go back and try again.
    This is not as bad, nor as time-consuming, as it may seem. Of course, there is
    a temporal cost associated with an incorrect hypothesis, but the end goal is that
    we must increase our learning efficiency and reduce our error with each stage.
    Each weighted connection that was wrong will be penalized like what we did in
    reinforcement learning. These connections will decrease in weight and no longer
    be as strong. Hopefully, the next pass through will increase our accuracy while
    decreasing our error, and the stronger the weight, the more the influence it will
    have.
  prefs: []
  type: TYPE_NORMAL
- en: So, let's take a hypothetical scenario and think aloud for a second. Let's say
    we are classifying numeric images, meaning numbers. Some images will have curves,
    such as 2, 3, 6, 8, 9, and so on. Other numbers, such as 1, 4 and 7, will not.
    Knowledge such as this is very important, because our RBM, will use it to continue
    to improve its learning and reduce error. If we think we're dealing with the number
    2, then the weights to the path that indicate this to us will be more heavily
    weighted than others. This is a drastic oversimplification, but hopefully it's
    enough to help you understand what we are about to embark upon.
  prefs: []
  type: TYPE_NORMAL
- en: As we put all this together, we now have the theoretical framework for a Deep
    Belief Network. Although we have delved into more theory than other chapters,
    as you see our example program working, it will all start to make sense. And you
    will be much better prepared to use it in your applications, knowing what's happening
    behind the scenes. Remember, black hole versus black box!
  prefs: []
  type: TYPE_NORMAL
- en: To show you about both Deep Belief Networks and RBMs, we are going to use the
    fantastic open source software SharpRBM written by Mattia Fagerlund. This software
    is an incredible contribution to the open source community, and I have no doubt
    you will spend hours, if not days, working with it. This software comes with some
    very incredible demos. For this chapter, we will use the Letter Classification
    Demo.
  prefs: []
  type: TYPE_NORMAL
- en: The following screenshot is of our deep belief test application. Ever wonder
    what a computer dreams of when it's sleeping? Well my friend, you are about to
    find out!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/96b442c2-cc23-40d2-804b-93be033833d3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As usual, we will also use ReflectInsight to provide us with a behind-the-scenes
    look into what is going on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f78e506e-9303-4f84-9db3-2439e859a16e.png)'
  prefs: []
  type: TYPE_IMG
- en: The first thing you will notice about our demo application is that there is
    a lot going on. Let's take a moment and break it down into smaller chunks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the upper-left corner of the program screen is the area where we designate
    the layer that we want to train. We have three hidden layers, all of which need
    proper training before testing. We can train each layer one at a time, starting
    with the first layer. You may train for as long or as little as you like, but
    the more you train, the better your system will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6f26651d-7b4a-4ae7-af21-aa68a286482a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The next section following our training options is our progress. As we are
    training, all pertinent information, such as generation, reconstruction error,
    detector error, and learning rate, is displayed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d0b445f-cde3-4a56-9a75-476a9d084326.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The next section is the drawing of our feature detectors, which will update
    themselves throughout training if the Draw checkbox is checked:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2ee0d8b4-17bd-45f1-ae42-f1e12880e9bf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you begin training a layer, you will notice that the reconstructions and
    feature detectors are basically empty. They will refine themselves as your training
    progresses. Remember, we are reconstructing what we already know to be true! As
    the training continues, the reconstructed digits become more and more defined,
    along with our feature detector:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/91cb9918-4fc0-4c6b-bab7-86cd979531fc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here is a snapshot from the application during training. As you can see, it
    is on generation 31 and the reconstructed digits are very well defined. They are
    still not complete or correct, but you can see just how much progress we are making:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/262f7890-b936-4657-98c7-a676cdcb747f.png)'
  prefs: []
  type: TYPE_IMG
- en: What does a computer dream?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*What does a computer dream when it dreams*? is a famous saying. The intuition
    for us will be a feature which allows us to see what the computer is thinking
    during its reconstruction phase. As the program is trying to reconstruct our digits,
    the feature detectors themselves will take various forms throughout the process.
    It is these forms that we display in the dream window (indicated by the red circle):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/031211f7-91d7-49ca-b5fa-b747c14b9516.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Well, we have spent quite a bit of time looking at screenshots of our application.
    I think it''s time that we now look at the code. Let''s start by looking at how
    we create the `DeepBeliefNetwork` object itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once this is created, we need to create our network trainer, and we do this
    based on the weights from the layer that we are training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Both of these objects are used within our main `TrainNetwork` loop, the part
    of our application where most of the activity happens. This loop will continue
    until told to stop.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we highlighted the `trainer.Train()` function, which
    is an array-based learning algorithm that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This code uses parallel processing (highlighted section) to train single cases
    in parallel. This function is responsible for handling the changing of input and
    hidden layers, as we discussed at the beginning of the chapter. It uses the `TrainOnSingleCase`
    function, which looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we accumulate the errors during processing, which is the difference
    between what our model should believe and what it actually does. Obviously, the
    lower the error rate the better, for the most accurate reconstruction of our images.
    The `AccumulateErrors` function is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Well folks, there you have it! In this chapter, you learned about RBMs, a little
    bit of graph theory, and how to create and train a Deep Belief Network in C#.
    Your buzzword-compliant checklist is almost complete! I recommend that you experiment
    with the code, train your network layers to different thresholds, and watch how
    your computer dreams while reconstructing. Remember, the more you train the better,
    so spend time with each layer to ensure it has enough data to do an accurate job
    of reconstruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'A quick note of warning: if you enable drawing of your feature detectors and
    reconstructed inputs, you will notice a huge decrease in performance. If you are
    trying to train your layers, you may wish to train them without visualizations
    first in order to reduce the time required. Trust me, with visualizations it will
    feel like an eternity if you train each level to a high iteration! Feel free to
    continually save your network as you progress. Good luck, and happy dreaming!'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about micro benchmarking and get to use one
    of the most powerful open source micro benchmarking toolkit ever written!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Mattias Fagerlund: [https://lotsacode.wordpress.com/2010/09/14/sharprbm-restricted-boltzmann-machines-in-c-net/#comments](https://lotsacode.wordpress.com/2010/09/14/sharprbm-restricted-boltzmann-machines-in-c-net/#comments)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nykamp DQ, *Undirected graph definition*, from *Math Insight*: [http://mathinsight.org/definition/undirected_graph](http://mathinsight.org/definition/undirected_graph)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
