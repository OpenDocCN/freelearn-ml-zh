- en: Deep Belief – Deep Networks and Dreaming
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've all heard of deep learning, but how many of us know what a **Deep Belief
    Network** is? Let's start this chapter by answering that very question. A Deep
    Belief Network is a very advanced form of machine learning, one whose meaning
    is rapidly evolving. As a machine learning developer, it's important that you
    have a bit of exposure to this concept so that you are familiar with it when you
    encounter it or it encounters you!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, a Deep Belief Network is technically a deep neural network.
    We should state that the meaning of **deep**, when it comes to deep learning or
    deep belief, means that the network is composed of multiple layers (hidden units).
    In a Deep Belief Network, these connections span internally between each neuron
    within a layer, but not between different layers. A Deep Belief Network can be
    trained to learn unsupervised in order to probabilistically reconstruct the network's
    inputs. The layers then function as 'feature detectors' to recognize or classify
    images, letters, and so on. You can also watch a Deep Belief Network dream, which
    is a very interesting topic in and of itself.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we will cover:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Restricted Boltzmann Machines
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and training a Deep Belief Network in C#
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restricted Boltzmann Machines
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One popular method of constructing a Deep Belief Network is to comprise it as
    a layered collection of **Restricted Boltzmann Machines** (**RBMs**). These RMBs
    function as auto-encoders, with each hidden layer, serving as the visible layer
    for the next. This composition leads to a fast, layer-by-layer and unsupervised
    training procedure. The Deep Belief Network will have layers of RBMs for the pre-train
    phase, and then a feedforward network for the fine-tune phase. The first step
    of the training will be to learn a layer of features from the visible units. The
    next step is to take the activations from the previously trained features and
    make them the new visible units. We then repeat the process so that we can learn
    more features in the second hidden layer. The process then continues for all hidden
    layers.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: We should provide two notes of information here.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: First, we should explain a bit about what an auto-encoder is and does. Auto-encoders
    are at the heart of what is known as **representational learning**. They encode
    input, which is usually compressed vectors of significant features, as well as
    data for reconstructing via unsupervised learning.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Second, we should note that stacking RBMs within a Deep Belief Network is but
    one way to approach this. Stacking Restricted Linear Units (ReLUs) with dropout
    and training, and then accompanying that with backpropagation, has once again
    become state of the art. I say once again because 30 years ago, the supervised
    approach was the way to go. Rather than let the algorithm look at all the data
    and determine the feature of interest, sometimes we as humans can actually better
    find the feature we want.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'What I would consider the two most significant properties of Deep Belief Networks
    are as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为深度信念网络最显著的两个特性如下：
- en: There is an efficient, layer-by-layer process for learning top-down, generative
    weights. It determines how variables in one layer depend on variables in the layers
    above it.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在一个高效、逐层的学习过程，用于学习自上而下的生成权重。它决定了某一层的变量如何依赖于其上层的变量。
- en: After the learning is complete, the values of the variables in every layer can
    easily be inferred by a single, bottom-up pass which starts with an observed data
    vector in the bottom layer and uses the generative weights in reverse direction
    to reconstruct the data.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习完成后，可以通过从底层观察到的数据向量开始的单个自下而上的遍历，很容易地推断出每一层变量的值，并使用生成权重反向重建数据。
- en: With that said, let's now talk about RBMs as well as Boltzmann machines in general.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，现在让我们也来谈谈RBM以及一般的霍尔兹曼机。
- en: 'A Boltzmann machine is a recurrent neural network with binary units and undirected
    edges between these units. For those of you who weren''t paying attention in your
    graph theory class, undirected means the edges (or links) are bidirectional, they
    are not pointing in any specific direction. For those not experienced in graph
    theory, the following is a diagram of an undirected graph with undirected edges:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 霍尔兹曼机是一种具有二元单元和单元之间无向边的循环神经网络。对于那些在图论课程中没注意听讲的同学，无向意味着边（或链接）是双向的，它们不指向任何特定方向。对于那些不熟悉图论的人来说，以下是一个具有无向边的无向图的示意图：
- en: '![](img/f6107d56-83c7-438d-9796-8d0d9372a8d7.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f6107d56-83c7-438d-9796-8d0d9372a8d7.png)'
- en: Boltzmann machines were one of the first neural networks capable of learning
    internal representations, and given enough time, they can solve difficult problems.
    They are, however, not good at scaling, which leads us to our next topic, RBMs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 霍尔兹曼机是第一批能够学习内部表示的神经网络之一，并且如果给定足够的时间，它们可以解决难题。然而，它们在扩展方面并不擅长，这让我们转向下一个主题，即RBMs。
- en: RBMs were introduced to deal with the Boltzmann Machines' inability to scale.
    They have hidden layers, with connections restricted between each hidden unit
    but not outside those units, which helps with efficient learning. More formally,
    we must dive into a little bit of graph theory to properly explain this.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: RBM被引入来处理霍尔兹曼机无法扩展的问题。它们有隐藏层，隐藏单元之间的连接受到限制，但不在这些单元之外，这有助于高效学习。更正式地说，我们必须稍微深入研究一下图论，才能正确解释这一点。
- en: RBMs must have their neurons form what is known as a **bipartite graph**, a
    more advanced form of graph theory; a pair of nodes from each of the two groups
    of units (visible and hidden layers) may have a symmetric connection between them.
    There can be no connections between the nodes within any group. A bipartite graph,
    sometimes called a **biograph**, is a set of graph vertices decomposed into two
    disjoint sets such that no two vertices within the same set are adjacent.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: RBM必须让它们的神经元形成所谓的**二分图**，这是一种更高级的图论形式；两组单元（可见层和隐藏层）中的每一对节点之间可能存在对称连接。任何一组内的节点之间不能有连接。二分图，有时称为**双图**，是一组图顶点分解为两个不相交的集合，使得同一集合内的两个顶点不相邻。
- en: Here is a good example that will help visualize this topic.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个很好的例子，可以帮助可视化这个主题。
- en: 'Note that there are no connections within the same set (red on the left or
    black on the right), but there are connections between the two sets:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，同一集合内（左侧的红色或右侧的黑色）没有连接，但两个集合之间存在连接：
- en: '![](img/1f5eb229-6889-43c9-858a-889d54e19878.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1f5eb229-6889-43c9-858a-889d54e19878.png)'
- en: More formally, an RBM is what is known as a **symmetrical bipartite graph*.***
    This is because inputs from all visible nodes are passed to all hidden nodes.
    We say symmetrical because each visible node relates to a hidden node; bipartite
    because there are two layers; and graph because, well, it's a graph, or a collection
    of nodes if you prefer!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，RBM被称为**对称二分图**。这是因为所有可见节点的输入都传递给所有隐藏节点。我们称之为对称，因为每个可见节点都与一个隐藏节点相关联；二分是因为有两个层次；而图是因为，嗯，它是一个图，或者如果你更喜欢，它是一组节点！
- en: 'Imagine for a second that our RBM is presented images of cats and dogs, and
    we have two output nodes, one for each animal. On our forward learning pass, our
    RBM asks itself "*With the pixels I am seeing, should I send stronger weight signals
    for the cat or for the dog?*" On the backward pass, it wonders "*Being a dog,
    which distribution of pixels should I see?*" That, my friends, was today''s lesson
    on joint probability: the simultaneous probability of *X* given *A* and *A* given
    *X*. In our case, this joint probability is expressed as the weights between the
    two layers and is an important aspect of RBMs.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们的RBM被呈现了猫和狗的图像，并且我们有两个输出节点，一个用于每种动物。在我们的正向学习过程中，我们的RBM会问自己“*看到这些像素，我应该为猫还是狗发送更强的权重信号？*”在反向过程中，它会思考“*作为一个狗，我应该看到什么样的像素分布？*”朋友们，这就是今天关于联合概率的教训：给定*A*的*X*和给定*X*的*A*的同时概率。在我们的案例中，这个联合概率以两层之间的权重表示，并且是RBMs的一个重要方面。
- en: With today's mini lessons in joint probability and graph theory behind us, we'll
    now talk about **reconstruction**, which is an important piece of what RBMs do.
    In the example we have been discussing, we are learning which groups of pixels
    occur (meaning being *on*) for a set of images. When a hidden layer node is activated
    by a significant weight (whatever that is determined to be to turn it *on*), it
    represents co-occurrences of something happening, in our case, the dog or the
    cat. Pointy ears + round face + small eyes might be what we are looking for if
    the image is a cat. Big ears + long tail + big nose may make the image a dog.
    These activations represent what our RBM "thinks" the original data looks like.
    For all intents and purposes, we are in fact reconstructing the original data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在掌握了今天的联合概率和图论的小课程之后，我们现在将讨论**重建**，这是RBMs（限制玻尔兹曼机）所做的重要部分。在我们一直在讨论的例子中，我们正在学习哪些像素组在一系列图像中发生（意味着处于*开启*状态）。当一个隐藏层节点被一个显著权重激活（无论这个权重是如何确定的以将其*开启*），它代表了某些事件同时发生的共现，在我们的案例中，是狗或猫。如果图像是一只猫，尖耳朵+圆脸+小眼睛可能就是我们要找的特征。大耳朵+长尾巴+大鼻子可能使图像成为一只狗。这些激活代表了我们的RBM“认为”原始数据看起来像什么。从所有目的和用途来看，我们实际上正在重建原始数据。
- en: We should also quickly point out that an RBM has two biases instead of one.
    This is very important as this is what distinguishes it from other auto-encoding
    algorithms. The hidden bias helps our RBM produce the activations we need when
    it's on the forward pass, and the visible layer bias helps learn the correct reconstructions
    on the backward pass. The hidden bias is important because its main job is to
    ensure that some of the nodes fire no matter how sparse our data might be. You
    will see how this impacts the way a Deep Belief Network dreams a little later
    on.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该迅速指出，RBM有两个偏差而不是一个。这一点非常重要，因为它将RBM与其他自动编码算法区分开来。隐藏偏差帮助我们的RBM在正向过程中产生所需的激活，而可见层偏差帮助在反向过程中学习正确的重建。隐藏偏差很重要，因为它的主要任务是确保在数据可能非常稀疏的情况下，某些节点仍然会激活。你将在稍后看到这如何影响深度信念网络做梦的方式。
- en: Layering
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层次化
- en: Once our RBM learns the structure of the input data, which is related to the
    activations made in our first hidden layer, the data gets passed down to the next
    hidden layer. The first hidden layer then becomes the new visible layer. The activations
    we created in the hidden layer now become our inputs. They will be multiplied
    by the weights in the new hidden layer to produce another set of activations.
    This process continues through all the hidden layers in our network. The hidden
    layer becomes the visible layer, we have another hidden layer whose weights we
    will use, and we repeat. Each new hidden layer results in adjusted weights, until
    we get to the point where we can recognize the input from the previous layer.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的RBM学会了输入数据的结构，这与我们在第一隐藏层中做出的激活有关，数据就会传递到下一个隐藏层。第一隐藏层随后成为新的可见层。我们在隐藏层中创建的激活现在成为我们的输入。它们将被新的隐藏层中的权重相乘，产生另一组激活。这个过程会继续通过我们网络中的所有隐藏层。隐藏层变成可见层，我们有了另一个我们将使用的权重的隐藏层，我们重复这个过程。每个新的隐藏层都会导致权重的调整，直到我们达到可以识别来自前一层的输入的点。
- en: To elaborate just a bit more (helping you in your quest to remain buzzword-compliant),
    this is technically called **unsupervised, greedy, layer-wise training**. No input
    is required to improve the weights of each layer, which means no outside influence
    of any type is involved. This further means we should be able to use our algorithm
    to train on unsupervised data that has not been seen previously. As we have continually
    stressed, *the more the data we have, the better our results*! As each layer gets
    better and hopefully more accurate, we are in a much better position to increase
    our learning through each hidden layer, with the weights having the responsibility
    of guiding us to the correct image classification along the way.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更详细地说明（帮助你保持术语的合规性），这从技术上讲被称为**无监督、贪婪、分层训练**。不需要输入来改进每一层的权重，这意味着没有任何类型的外部影响。这进一步意味着我们应该能够使用我们的算法在之前未见过的不监督数据上进行训练。正如我们一直强调的那样，*数据越多，我们的结果越好*！随着每一层变得更好，希望也更准确，我们就有更好的位置通过每一隐藏层增加我们的学习，权重在这个过程中负责引导我们到达正确的图像分类。
- en: But as we discuss reconstruction, we should point out that each time a number
    (weight) in our reconstruction effort is non-zero, that is an indication that
    our RBM has learned something from the data. In a sense, you can treat the returned
    numbers exactly as you would treat a percentage indicator. The higher the number,
    the more confident the algorithm is of what it is seeing. Remember, we have the
    master dataset that we are trying to get back to, and we have a reference dataset
    to use in our reconstruction efforts. As our RBM iterates over each image, it
    doesn't yet know what image it is dealing with; that's what it is trying to determine.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 但当我们讨论重建时，我们应该指出，在我们重建努力中，每当一个数字（权重）不为零，这表明我们的RBM已经从数据中学习到了一些东西。从某种意义上说，你可以将返回的数字当作你对待百分比指示器一样来处理。数字越高，算法对其所看到的东西就越有信心。记住，我们有一个主数据集，我们试图恢复到这个数据集，并且我们有一个参考数据集用于我们的重建工作。随着我们的RBM遍历每一张图像，它还不知道它正在处理什么图像；这正是它试图确定的事情。
- en: Let's take a brief moment to clarify something. When we say we are using a greedy
    algorithm, what we really mean is that our RBM will take the shortest path to
    achieve the best result. We will sample random pixels from the image we see, and
    test which ones lead us to the correct answer. The RBM will test each hypothesis
    against the master dataset (test set), which is our correct end goal. Keep in
    mind that each image is just a set of pixels we're trying to classify. Those pixels
    house features and characteristics of data. For example, a pixel can have different
    shades of light, wherein dark pixels perhaps indicate borders, light pixels perhaps
    indicate numbers, and so forth.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要澄清一下。当我们说我们使用贪婪算法时，我们真正意思是我们的RBM将采取最短路径以实现最佳结果。我们将从我们看到的图像中采样随机像素，并测试哪些像素能引导我们到达正确答案。RBM将测试每个假设与主数据集（测试集）的对比，这是我们正确的最终目标。记住，每张图像只是我们试图分类的一组像素。这些像素包含了数据的特征和特性。例如，一个像素可以有不同亮度的阴影，其中深色像素可能表示边界，浅色像素可能表示数字，等等。
- en: But what happens when things don't go our way? What happens if whatever we learn
    at any given step is not correct? Should this occur, it would mean that our algorithm
    has guessed incorrectly. Our course of action is then to go back and try again.
    This is not as bad, nor as time-consuming, as it may seem. Of course, there is
    a temporal cost associated with an incorrect hypothesis, but the end goal is that
    we must increase our learning efficiency and reduce our error with each stage.
    Each weighted connection that was wrong will be penalized like what we did in
    reinforcement learning. These connections will decrease in weight and no longer
    be as strong. Hopefully, the next pass through will increase our accuracy while
    decreasing our error, and the stronger the weight, the more the influence it will
    have.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 但当事情不按我们的意愿发展时会发生什么？如果我们在任何给定步骤中学到的任何东西都不正确，会发生什么？如果发生这种情况，这意味着我们的算法猜错了。我们的行动方案是回过头去再试一次。这并不像看起来那么糟糕，也不那么耗时。当然，一个错误假设有一个时间成本，但最终目标是我们必须提高我们的学习效率并减少每个阶段的错误。每个错误的加权连接将像我们在强化学习中做的那样受到惩罚。这些连接的权重将减少，不再那么强大。希望下一次遍历将提高我们的准确性，同时减少错误，权重越强，它的影响就越大。
- en: So, let's take a hypothetical scenario and think aloud for a second. Let's say
    we are classifying numeric images, meaning numbers. Some images will have curves,
    such as 2, 3, 6, 8, 9, and so on. Other numbers, such as 1, 4 and 7, will not.
    Knowledge such as this is very important, because our RBM, will use it to continue
    to improve its learning and reduce error. If we think we're dealing with the number
    2, then the weights to the path that indicate this to us will be more heavily
    weighted than others. This is a drastic oversimplification, but hopefully it's
    enough to help you understand what we are about to embark upon.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: As we put all this together, we now have the theoretical framework for a Deep
    Belief Network. Although we have delved into more theory than other chapters,
    as you see our example program working, it will all start to make sense. And you
    will be much better prepared to use it in your applications, knowing what's happening
    behind the scenes. Remember, black hole versus black box!
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: To show you about both Deep Belief Networks and RBMs, we are going to use the
    fantastic open source software SharpRBM written by Mattia Fagerlund. This software
    is an incredible contribution to the open source community, and I have no doubt
    you will spend hours, if not days, working with it. This software comes with some
    very incredible demos. For this chapter, we will use the Letter Classification
    Demo.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: The following screenshot is of our deep belief test application. Ever wonder
    what a computer dreams of when it's sleeping? Well my friend, you are about to
    find out!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/96b442c2-cc23-40d2-804b-93be033833d3.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
- en: 'As usual, we will also use ReflectInsight to provide us with a behind-the-scenes
    look into what is going on:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f78e506e-9303-4f84-9db3-2439e859a16e.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: The first thing you will notice about our demo application is that there is
    a lot going on. Let's take a moment and break it down into smaller chunks.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'In the upper-left corner of the program screen is the area where we designate
    the layer that we want to train. We have three hidden layers, all of which need
    proper training before testing. We can train each layer one at a time, starting
    with the first layer. You may train for as long or as little as you like, but
    the more you train, the better your system will be:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6f26651d-7b4a-4ae7-af21-aa68a286482a.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: 'The next section following our training options is our progress. As we are
    training, all pertinent information, such as generation, reconstruction error,
    detector error, and learning rate, is displayed here:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d0b445f-cde3-4a56-9a75-476a9d084326.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: 'The next section is the drawing of our feature detectors, which will update
    themselves throughout training if the Draw checkbox is checked:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2ee0d8b4-17bd-45f1-ae42-f1e12880e9bf.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: 'As you begin training a layer, you will notice that the reconstructions and
    feature detectors are basically empty. They will refine themselves as your training
    progresses. Remember, we are reconstructing what we already know to be true! As
    the training continues, the reconstructed digits become more and more defined,
    along with our feature detector:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/91cb9918-4fc0-4c6b-bab7-86cd979531fc.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: 'Here is a snapshot from the application during training. As you can see, it
    is on generation 31 and the reconstructed digits are very well defined. They are
    still not complete or correct, but you can see just how much progress we are making:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/262f7890-b936-4657-98c7-a676cdcb747f.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: What does a computer dream?
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*What does a computer dream when it dreams*? is a famous saying. The intuition
    for us will be a feature which allows us to see what the computer is thinking
    during its reconstruction phase. As the program is trying to reconstruct our digits,
    the feature detectors themselves will take various forms throughout the process.
    It is these forms that we display in the dream window (indicated by the red circle):'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/031211f7-91d7-49ca-b5fa-b747c14b9516.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: 'Well, we have spent quite a bit of time looking at screenshots of our application.
    I think it''s time that we now look at the code. Let''s start by looking at how
    we create the `DeepBeliefNetwork` object itself:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once this is created, we need to create our network trainer, and we do this
    based on the weights from the layer that we are training:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Both of these objects are used within our main `TrainNetwork` loop, the part
    of our application where most of the activity happens. This loop will continue
    until told to stop.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the preceding code, we highlighted the `trainer.Train()` function, which
    is an array-based learning algorithm that looks like this:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This code uses parallel processing (highlighted section) to train single cases
    in parallel. This function is responsible for handling the changing of input and
    hidden layers, as we discussed at the beginning of the chapter. It uses the `TrainOnSingleCase`
    function, which looks like this:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we accumulate the errors during processing, which is the difference
    between what our model should believe and what it actually does. Obviously, the
    lower the error rate the better, for the most accurate reconstruction of our images.
    The `AccumulateErrors` function is shown here:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Summary
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Well folks, there you have it! In this chapter, you learned about RBMs, a little
    bit of graph theory, and how to create and train a Deep Belief Network in C#.
    Your buzzword-compliant checklist is almost complete! I recommend that you experiment
    with the code, train your network layers to different thresholds, and watch how
    your computer dreams while reconstructing. Remember, the more you train the better,
    so spend time with each layer to ensure it has enough data to do an accurate job
    of reconstruction.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'A quick note of warning: if you enable drawing of your feature detectors and
    reconstructed inputs, you will notice a huge decrease in performance. If you are
    trying to train your layers, you may wish to train them without visualizations
    first in order to reduce the time required. Trust me, with visualizations it will
    feel like an eternity if you train each level to a high iteration! Feel free to
    continually save your network as you progress. Good luck, and happy dreaming!'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简短的警告：如果你启用了绘制你的特征检测器和重建输入的功能，你会注意到性能会有大幅下降。如果你正在尝试训练你的层，你可能希望在首先不进行可视化的情况下训练它们，以减少所需的时间。相信我，如果你将每个级别训练到高迭代次数，那么使用可视化将感觉像永恒！在你进步的过程中，随时保存你的网络。祝你好运，祝你梦想成真！
- en: In the next chapter, we will learn about micro benchmarking and get to use one
    of the most powerful open source micro benchmarking toolkit ever written!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习微基准测试，并有机会使用有史以来最强大的开源微基准测试工具包之一！
- en: References
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Mattias Fagerlund: [https://lotsacode.wordpress.com/2010/09/14/sharprbm-restricted-boltzmann-machines-in-c-net/#comments](https://lotsacode.wordpress.com/2010/09/14/sharprbm-restricted-boltzmann-machines-in-c-net/#comments)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mattias Fagerlund: [https://lotsacode.wordpress.com/2010/09/14/sharprbm-restricted-boltzmann-machines-in-c-net/#comments](https://lotsacode.wordpress.com/2010/09/14/sharprbm-restricted-boltzmann-machines-in-c-net/#comments)'
- en: 'Nykamp DQ, *Undirected graph definition*, from *Math Insight*: [http://mathinsight.org/definition/undirected_graph](http://mathinsight.org/definition/undirected_graph)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nykamp DQ, *无向图定义*, 来自 *Math Insight*: [http://mathinsight.org/definition/undirected_graph](http://mathinsight.org/definition/undirected_graph)'
