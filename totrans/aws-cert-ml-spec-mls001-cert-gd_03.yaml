- en: '*Chapter 2*: AWS Application Services for AI/ML'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*: AWS 人工智能/机器学习应用服务'
- en: In this chapter, we will learn about the AWS AI services for building chatbots,
    advanced text analysis, document analysis, transcription, and so on. This chapter
    has been designed in such a way that you can solve different use cases by integrating
    AWS AI services and get an idea of how they work. AWS is growing every day and
    they are adding new AI services regularly.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将了解 AWS 人工智能服务，用于构建聊天机器人、高级文本分析、文档分析、转录等。本章的设计方式是，您可以通过集成 AWS 人工智能服务来解决不同的用例，并了解它们的工作原理。AWS
    每天都在增长，并且他们定期添加新的 AI 服务。
- en: In this chapter, you will approach different use cases programmatically or from
    the console. This will help you understand different APIs and their usages. We
    will use S3 for storage and AWS Lambda to execute any code. The examples in this
    chapter are in Python, but you can use other supported languages such as Java,
    Node.js, .NET, PowerShell, Ruby, and so on.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将通过编程或从控制台来处理不同的用例。这将帮助您了解不同的 API 及其用法。我们将使用 S3 进行存储，并使用 AWS Lambda 来执行任何代码。本章的示例是用
    Python 编写的，但您可以使用其他支持的语言，如 Java、Node.js、.NET、PowerShell、Ruby 等。
- en: 'We are going to cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Analyzing images and videos with Amazon Rekognition
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Rekognition 分析图像和视频
- en: Text to speech with Amazon Polly
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Polly 进行语音合成
- en: Speech to text with Amazon Transcribe
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Transcribe 进行语音转文本
- en: Implementing natural language processing with Amazon Comprehend
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Comprehend 实现自然语言处理
- en: Translating documents with Amazon Translate
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Translate 翻译文档
- en: Extracting text from documents with Amazon Textract
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Textract 从文档中提取文本
- en: Creating chatbots on Amazon Lex
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Amazon Lex 上创建聊天机器人
- en: Let's get started!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All you will need for this chapter is an AWS account.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您在本章中需要的只是一个 AWS 账户。
- en: You can download the code examples for this chapter from GitHub at [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从 GitHub 下载本章的代码示例，网址为[https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2)。
- en: Analyzing images and videos with Amazon Rekognition
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon Rekognition 分析图像和视频
- en: If you need to add powerful visual analysis to your applications, then **Amazon
    Rekognition** is the service to opt for. **Rekognition Image** lets you easily
    build powerful applications to search, verify, and organize millions of images.
    **Rekognition Video** lets you extract motion-based context from stored or live
    stream videos, and helps you analyze them. Rekognition Video also allows you to
    index metadata such as objects, activities, scene, celebrities, and faces, making
    video searches easy. Rekognition Image uses deep neural network models to detect
    and label thousands of objects and scenes in your images. It helps you capture
    text in an image, a bit like **Optical Character Recognition** (**OCR**). A perfect
    example is a T-shirt with quotes on it. If you were to take a picture of one and
    ask Amazon Rekognition to extract the text from it, it would be able to tell you
    what the text says. You can also perform celebrity recognition using Amazon Rekognition.
    I am not a celebrity, so I won't be using the celebrity recognition API for my
    face; instead, I will use the face comparison API.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要为您的应用程序添加强大的视觉分析功能，那么**Amazon Rekognition**是您应该选择的服务。**Rekognition Image**让您能够轻松构建强大的应用程序，用于搜索、验证和组织数百万张图像。**Rekognition
    Video**让您能够从存储或实时流视频中提取基于运动的内容，并帮助您分析它们。Rekognition Video 还允许您索引诸如对象、活动、场景、名人以及面部等元数据，使视频搜索变得简单。Rekognition
    Image 使用深度神经网络模型检测和标记您图像中的数千个对象和场景。它帮助您捕获图像中的文本，有点像**光学字符识别**（**OCR**）。一个完美的例子就是印有引语的T恤。如果您要拍一张照片并让
    Amazon Rekognition 从中提取文本，它就能告诉您文本的内容。您还可以使用 Amazon Rekognition 进行名人识别。我不是名人，所以我不会使用名人识别API来识别我的面部；相反，我将使用面部比较API。
- en: 'The official documentation, available at [https://aws.amazon.com/rekognition/faqs/](https://aws.amazon.com/rekognition/faqs/),
    states the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在[https://aws.amazon.com/rekognition/faqs/](https://aws.amazon.com/rekognition/faqs/)提供的官方文档中，说明了以下内容：
- en: '"With Rekognition Image, you only pay for the images you analyze and the face
    metadata you store. You will not be charged for the compute resources if, at any
    point of time, your training fails."'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'Some common uses of Amazon Rekognition include the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Image and video analysis
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Searchable image library
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Face-based user verification
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text in image
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Facial recognition
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image moderation
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Search index for video archives
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy filtering for videos, for explicit and suggestive content
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of explicit nudity – sexual activity, graphical nudity, adult toys,
    and so on
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of suggestive content – partial nudity, swimwear or underwear, and
    so on
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the benefits of Amazon Rekognition
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s look at some of the benefits of using Amazon Rekognition:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: AWS manages the infrastructure it runs on. In short, just use the API for your
    image analysis. We just need to focus on building and managing our deep learning
    pipelines.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With or without knowledge of image processing, you can perform image and video
    analysis just by using the APIs provided in Amazon Rekognition, which can be used
    for any application or service on several platforms.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The Labels API''s response will identify real-world entities within an image
    through the DetectLabels API. These labels include city, town, table, home, garden,
    animal, pets, food, drink, electronics, flowers, and more. The entities are classified
    based on their **Confidence** score, which indicates the probability that a given
    prediction is correct: the higher the better. Similarly, we can use the DetectText
    API to extract the text in an image. Amazon Rekognition may detect multiple lines
    based on the gap between words. Periods don''t represent the end of a line.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Rekognition can be integrated with AWS Kinesis Video Stream, AWS S3,
    and AWS Lambda for seamless and affordable image and video analysis. With the
    AWS IAM service, Amazon Rekognition API calls can easily be secured and controlled.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Low cost. You only pay for the images and videos that are analyzed.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Through AWS CloudTrail, all the API calls for Amazon Rekognition can be captured
    as events. It captures all calls made from the console, or the CLI, or code calls
    for APIs, which further enables the user to create Amazon SNS notifications based
    on CloudTrail events.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can create a VPC Endpoint policy for specific API calls to establish a private
    connection between your VPC and Amazon Rekognition. This helps you leverage enhanced
    security. As per the AWS shared responsibility model, AWS takes care of the security
    of the infrastructure and software, and we have to take care of the security of
    our content in the cloud.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting hands-on with Amazon Rekognition
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will learn how to integrate AWS Lambda with Amazon Rekognition
    to detect the labels in our image (uploaded at [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Rekognition%20Demo/images](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Rekognition%20Demo/images))
    and print the detected objects in the CloudWatch console. We will use the `detect_labels`
    API from Amazon Rekognition in the code.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何将 AWS Lambda 与 Amazon Rekognition 集成，以检测我们图像（上传至 [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Rekognition%20Demo/images](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Rekognition%20Demo/images)）中的标签，并在
    CloudWatch 控制台中打印检测到的对象。我们将在代码中使用 Amazon Rekognition 的 `detect_labels` API。
- en: 'We will begin by creating an IAM role for Lambda:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先为 Lambda 创建一个 IAM 角色：
- en: Navigate to the IAM console page.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 IAM 控制台页面。
- en: Select **Roles** from the left-hand menu.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧菜单中选择**角色**。
- en: Select **Create role**.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**创建角色**。
- en: Select **Lambda** from the **Choose a use case** section.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从**选择一个用例**部分选择**Lambda**。
- en: 'Add the following managed policies:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下托管策略：
- en: '`AmazonS3ReadOnlyAccess`'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AmazonS3ReadOnlyAccess`'
- en: '`AmazonRekognitionFullAccess`'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AmazonRekognitionFullAccess`'
- en: '`CloudWatchLogsFullAccess`'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CloudWatchLogsFullAccess`'
- en: Name the role `rekognition-lambda-role`:![Figure 2.1 – The Create role dialog
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将角色命名为 `rekognition-lambda-role`：![图 2.1 – 创建角色对话框
- en: '](img/B16735_02_001.jpg)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16735_02_001.jpg)'
- en: Figure 2.1 – The Create role dialog
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.1 – 创建角色对话框
- en: Next, we will create a Lambda function.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个 Lambda 函数。
- en: Navigate to the AWS Lambda console page.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 AWS Lambda 控制台页面。
- en: Select **Create function**.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**创建函数**。
- en: 'Create a function:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数：
- en: Select `lambda-rekognition`.
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择 `lambda-rekognition`。
- en: 'Choose `Python 3.6` from the `rekognition-lambda-role`:'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 `rekognition-lambda-role` 选择 `Python 3.6`：
- en: '![Figure 2.2 – Creating the Lambda function'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.2 – 创建 Lambda 函数'
- en: '](img/B16735_02_002.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_02_002.jpg)'
- en: Figure 2.2 – Creating the Lambda function
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – 创建 Lambda 函数
- en: 'Enter the following code in `lambda_function.py`:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `lambda_function.py` 中输入以下代码：
- en: '[PRE0]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, we will create a trigger for the Lambda Function.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们将为 Lambda 函数创建一个触发器。
- en: Navigate to the AWS S3 console page. Create a bucket, for example, `rekognition-test-baba`,
    as shown in the following screenshot:![Figure 2.3 – AWS S3 console page
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 AWS S3 控制台页面。创建一个存储桶，例如，`rekognition-test-baba`，如下截图所示：![图 2.3 – AWS S3
    控制台页面
- en: '](img/B16735_02_003.jpg)'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16735_02_003.jpg)'
- en: Figure 2.3 – AWS S3 console page
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.3 – AWS S3 控制台页面
- en: Click on `images`. Click **Save**.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `images`。点击**保存**。
- en: Click the **Properties** tab of our bucket.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击我们的存储桶的**属性**标签页。
- en: Scroll to **Events** for that bucket.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将滚动到该存储桶的**事件**。
- en: Inside the `rekognition_event`
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `rekognition_event`
- en: '`All object create events`'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`所有对象创建事件`'
- en: '`images`*/*'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`images`*/*'
- en: '`Lambda Function`'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Lambda 函数`'
- en: '`lambda-rekognition`:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`lambda-rekognition`：'
- en: '![Figure 2.4 –S3 bucket Events window'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.4 – S3 存储桶事件窗口'
- en: '](img/B16735_02_004.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_02_004.jpg)'
- en: Figure 2.4 –S3 bucket Events window
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 –S3 存储桶事件窗口
- en: Next, we will upload the image from the shared GitHub repository to the S3 bucket
    `images` folder.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将从共享的 GitHub 仓库上传图像到 S3 存储桶 `images` 文件夹。
- en: As soon as you upload, you can check the **Monitoring** tab in the Lambda console
    to monitor the events, as shown in the following screenshot:![Figure 2.5 – CloudWatch
    monitoring the event in the Lambda console
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦上传，您就可以检查 Lambda 控制台中的**监控**标签页以监控事件，如下截图所示：![图 2.5 – CloudWatch 在 Lambda
    控制台中监控事件
- en: '](img/B16735_02_005.jpg)'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16735_02_005.jpg)'
- en: Figure 2.5 – CloudWatch monitoring the event in the Lambda console
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.5 – CloudWatch 在 Lambda 控制台中监控事件
- en: 'Navigate to **CloudWatch > CloudWatch Logs > Log groups > /aws/lambda/lambda-rekognition**.
    Select the latest stream from all the streams and scroll down in the logs to see
    your output, as shown in the following screenshot:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 **CloudWatch > CloudWatch Logs > Log groups > /aws/lambda/lambda-rekognition**。选择所有流中的最新流，并在日志中向下滚动以查看您的输出，如下截图所示：
- en: '![Figure 2.6 – CloudWatch logs'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.6 – CloudWatch 日志'
- en: '](img/B16735_02_006.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_02_006.jpg)'
- en: Figure 2.6 – CloudWatch logs
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – CloudWatch 日志
- en: In this section, we learned how to implement the Amazon Rekognition AI service
    to detect objects in an image and get a confidence score for each. We will see
    more use cases for Amazon Rekognition in the upcoming sections, when we detect
    text in images. In the next section, we will learn about Amazon's text-to-speech
    service and implement it.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何实现Amazon Rekognition AI服务以检测图像中的对象并为每个对象获取置信度分数。在接下来的章节中，我们将看到Amazon
    Rekognition的更多用例，届时我们将检测图像中的文本。在下一节中，我们将了解Amazon的文本到语音服务并实现它。
- en: Text to speech with Amazon Polly
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Amazon Polly进行文本到语音
- en: '**Amazon Polly** is all about converting text into speech, and does so using
    pretrained deep learning models. It''s a fully managed service, so we don''t have
    to do anything. You provide the plain text as input for synthesizing or in **Speech
    Synthesis Markup Language** (**SSML**) format so that an audio stream is returned.
    It also gives you different languages and voices to choose from, with both male
    and female options. The output audio from Amazon Polly can be saved in MP3 format
    for further usage in the application (web or mobile) or can be a JSON output for
    written speech.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon Polly**全关于将文本转换为语音，并且使用预训练的深度学习模型来完成。这是一个完全托管的服务，所以我们不需要做任何事情。您提供纯文本作为合成输入或在**语音合成标记语言（SSML**）格式中，以便返回音频流。它还提供了不同的语言和声音供您选择，包括男性和女性选项。Amazon
    Polly的输出音频可以保存为MP3格式，以便在应用程序（网页或移动）中进一步使用，或者可以是一个JSON输出，用于书面语音。'
- en: 'For example, if we were to input the text "Baba went to the library" into Amazon
    Polly, the output speech mark object would look as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们把文本“巴巴去了图书馆”输入到Amazon Polly中，输出的语音标记对象将如下所示：
- en: '[PRE1]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The word `"went"` begins 370 milliseconds after the audio stream begins, and
    starts at byte 5 and ends at byte 9 of the given input text.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 单词“去了”在音频流开始后的370毫秒处开始，从给定输入文本的5个字节开始，到9个字节结束。
- en: It also returns output in `ogg_vorbis` and `pcm` format. When `pcm` is used,
    the content that's returned is audio/pcm in a signed 16-bit, 1 channel (mono),
    little-endian format.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 它还以`ogg_vorbis`和`pcm`格式返回输出。当使用`pcm`时，返回的内容是16位有符号、单通道（单声道）、小端格式的音频/pcm。
- en: 'Some common uses of Amazon Polly include the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Polly的一些常见用途包括以下内容：
- en: Can be used as an accessibility tool for reading web content.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用作阅读网络内容的辅助工具。
- en: Can be integrated with Amazon Rekognition to help visually impaired people read
    signs. You can click a picture of the sign with text and feed it to Amazon Rekognition
    to extract text. The output text can be used as input for Polly, and it will return
    a voice as output.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可与Amazon Rekognition集成，帮助视障人士阅读标志。您可以点击带有文本的标志图片并将其输入到Amazon Rekognition中提取文本。输出文本可以用作Polly的输入，它将返回语音输出。
- en: Can be used in a public address system, where the admin team can just pass on
    the text to be announced and Amazon Polly does the magic.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用于公共广播系统，管理员团队只需传递要宣布的文本，Amazon Polly即可完成魔法般的转换。
- en: By combining Amazon Polly with **Amazon Connect** (telephony backend service),
    you can build an **audio/video receiver** (**AVR**) system.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将Amazon Polly与**Amazon Connect**（电话后端服务）结合使用，您可以构建**音频/视频接收器（AVR**）系统。
- en: Smart devices such as smart tvs, smart watches, and **Internet of Things** (**IoT**)
    devices can use this for audio output.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 智能设备，如智能电视、智能手表和**物联网（IoT**）设备，可以使用此功能进行音频输出。
- en: Narration generation.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 叙事生成。
- en: When combined with Amazon Lex, full-blown voice user interfaces for applications
    can be developed.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当与Amazon Lex结合使用时，可以开发应用程序的完整语音用户界面。
- en: Now, let's explore the benefits of Amazon Polly.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探索Amazon Polly的好处。
- en: Exploring the benefits of Amazon Polly
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索Amazon Polly的好处
- en: 'Some of the benefits of using Amazon Polly include the following:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Amazon Polly的一些好处包括以下内容：
- en: This service is fully managed and doesn't require any admin cost to maintain
    or manage resources.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此服务完全托管，无需任何管理成本来维护或管理资源。
- en: It provides an instant speech corrections and enhancements facility.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供即时语音校正和增强功能。
- en: You can develop your own access layer using the HTTP API from Amazon Polly.
    Development is easy due to the huge amount of language support that's available,
    such as Python, Ruby, Go, C++, Java, and Node.js.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用Amazon Polly的HTTP API开发自己的访问层。由于有大量的语言支持，如Python、Ruby、Go、C++、Java和Node.js，因此开发变得非常容易。
- en: For certain neural voices, speech can be synthesized by using the Newscaster
    style, to make them sound like a TV or radio broadcaster.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于某些神经网络语音，可以使用新闻主播风格进行语音合成，使其听起来像电视或广播电台的广播员。
- en: Amazon Polly also allows you to modify the pronunciation of particular words
    or the use of new words.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Polly还允许您修改特定单词的发音或使用新单词。
- en: Next, we'll get hands-on with Amazon Polly.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将亲身体验Amazon Polly。
- en: Getting hands-on with Amazon Polly
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亲身体验Amazon Polly
- en: In this section, we will build a pipeline where we can integrate AWS Lambda
    with Amazon Polly to read a text file, and then generate an **MP3** file of the
    same to another folder in the same bucket. We will monitor the task's progress
    in CloudWatch logs.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将构建一个管道，可以集成AWS Lambda与Amazon Polly，读取一个文本文件，然后将其生成相同内容的**MP3**文件到同一个桶的另一个文件夹中。我们将通过CloudWatch日志监控任务的进度。
- en: 'We will begin by creating an IAM Role for Lambda. Let''s get started:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先为Lambda创建一个IAM角色。让我们开始吧：
- en: Navigate to the IAM console page.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到IAM控制台页面。
- en: Select **Roles** from the left-hand menu.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧菜单中选择**角色**。
- en: Select **Create role**.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**创建角色**。
- en: Select **Lambda** as the trusted entity.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**Lambda**作为受信任实体。
- en: 'Add the following managed policies:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下托管策略：
- en: '`AmazonS3FullAccess`'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AmazonS3FullAccess`'
- en: '`AmazonPollyFullAccess`'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AmazonPollyFullAccess`'
- en: '`CloudWatchFullAccess`'
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CloudWatchFullAccess`'
- en: Save the role as `polly-lambda-role`.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将角色保存为`polly-lambda-role`。
- en: 'Next, we will create a Lambda function:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个Lambda函数：
- en: Navigate to `polly-lambda`
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到`polly-lambda`
- en: Set the runtime to `python 3.6`.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置运行时为`python 3.6`。
- en: Use an existing role; that is, `polly-lambda-role`
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用现有角色；即`polly-lambda-role`
- en: Paste the code at [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Rekognition%20Demo/lambda_code](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Rekognition%20Demo/lambda_code)
    into your lambda function and check its progress in the CloudWatch console. We
    will be using the `start_speech_synthesis_task` API from Amazon Polly for this
    code; it is an asynchronous synthesis task.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将代码粘贴到[https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Rekognition%20Demo/lambda_code](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Rekognition%20Demo/lambda_code)中的您的lambda函数，并在CloudWatch控制台中检查其进度。我们将使用Amazon
    Polly的`start_speech_synthesis_task` API来运行此代码；它是一个异步合成任务。
- en: 'Scroll down and in `59` **sec**, as shown in the following screenshot, and
    click **Save**:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到`59` **秒**，如图下所示，然后点击**保存**：
- en: Important note
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: The default is 3 sec. Since this is an asynchronous operation, any retried attempts
    will create more files.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认为3秒。由于这是一个异步操作，任何重试尝试都将创建更多文件。
- en: '![Figure 2.7 – Edit basic settings window'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图2.7 – 编辑基本设置窗口'
- en: '](img/B16735_02_007.jpg)'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16735_02_007.jpg)'
- en: Figure 2.7 – Edit basic settings window
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.7 – 编辑基本设置窗口
- en: Now, we will create a bucket to trigger an event.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们将创建一个桶以触发事件。
- en: Navigate to the AWS S3 console and create a bucket called `polly-test-baba`.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到AWS S3控制台，创建一个名为`polly-test-baba`的桶。
- en: Create a folder called `input-text` (in this example, we will only upload .`txt`
    files).
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`input-text`的文件夹（在这个例子中，我们只会上传`.txt`文件）。
- en: Navigate to `polly_event`
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到`polly_event`
- en: '`All object create events`'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`所有对象创建事件`'
- en: '`input-text/`'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`input-text/`'
- en: '`txt`'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`txt`'
- en: '`Lambda Function`'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Lambda Function`'
- en: '`polly-lambda`'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`polly-lambda`'
- en: Next, we will upload a file in order to trigger an event and check its progress
    in CloudWatchUpload, in this case, a file `test_file.txt` in `input-text`, as
    shown in the following screenshot. You can download the sample file from this
    book's GitHub repository at [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Polly%20Demo/text_file](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Polly%20Demo/text_file):![Figure
    2.8 – The S3 bucket after uploading a text file for further processing
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将上传一个文件以触发事件，并在CloudWatchUpload中检查其进度，在这种情况下，`input-text`中的文件`test_file.txt`，如图下所示。您可以从本书的GitHub仓库下载示例文件：[https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Polly%20Demo/text_file](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Polly%20Demo/text_file)：![图2.8
    – 上传文本文件以进行进一步处理后的S3桶
- en: '](img/B16735_02_008.jpg)'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16735_02_008.jpg)'
- en: Figure 2.8 – The S3 bucket after uploading a text file for further processing
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.8 – 上传文本文件以进行进一步处理后的S3桶
- en: This will trigger the lambda function. You can monitor your logs by going to
    **CloudWatch> CloudWatch Logs> Log groups> /aws/lambda/polly-lambda**:![Figure
    2.9 – Log groups in the CloudWatch console
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将触发 lambda 函数。您可以通过访问 **CloudWatch> CloudWatch 日志> 日志组> /aws/lambda/polly-lambda**
    来监控您的日志：![图 2.9 – CloudWatch 控制台中的日志组
- en: '](img/B16735_02_009.jpg)'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16735_02_009.jpg)'
- en: Figure 2.9 – Log groups in the CloudWatch console
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.9 – CloudWatch 控制台中的日志组
- en: 'Click on the latest stream; the log will look as follows:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击最新的流；日志将如下所示：
- en: '[PRE2]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The logs sample is shown in the following screenshot:'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示了日志样本：
- en: '![Figure 2.10 – The logs in the CloudWatch console'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.10 – CloudWatch 控制台中的日志'
- en: '](img/B16735_02_010.jpg)'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16735_02_010.jpg)'
- en: Figure 2.10 – The logs in the CloudWatch console
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.10 – CloudWatch 控制台中的日志
- en: 'It will create output in MP3 format, as shown in the following screenshot.
    Download and listen to it:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将以 MP3 格式创建输出，如下面的截图所示。下载并收听它：
- en: '![Figure 2.11 – The output file that was created in the S3 bucket'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.11 – 在 S3 存储桶中创建的输出文件'
- en: '](img/B16735_02_011.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_02_011.jpg)'
- en: Figure 2.11 – The output file that was created in the S3 bucket
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – 在 S3 存储桶中创建的输出文件
- en: Important note
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The most scalable and cost-effective way for your mobile apps or web apps is
    to generate an AWS pre-signed URL for S3 buckets and provide it to your users.
    These S3 Put events asynchronously invoke downstream AI workflows to generate
    results and send a response to the end users. Many users can be served at the
    same time through this approach, and it may increase performance and throughput.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 对于您的移动应用或Web应用来说，最可扩展且成本效益最高的方式是为 S3 存储桶生成 AWS 预签名URL，并将其提供给用户。这些 S3 Put 事件异步调用下游
    AI 工作流程以生成结果，并向最终用户发送响应。通过这种方法，可以同时为许多用户提供服务，并且可能会提高性能和吞吐量。
- en: In this section, we learned how to implement text to speech. In the next section,
    we will learn about Amazon Transcribe, a speech-to-text AI service.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何实现文本到语音。在下一节中，我们将了解 Amazon Transcribe，这是一种语音到文本的 AI 服务。
- en: Speech to text with Amazon Transcribe
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon Transcribe 进行语音到文本转换
- en: 'In the previous section, we learned about text to speech. In this section,
    we will learn about speech to text and the service that provides this: **Amazon
    Transcribe**. It is an automatic speech recognition service that uses pre-trained
    deep learning models, which means that we don''t have to train on petabytes of
    data to produce a model; Amazon does this for us. We just have to use the APIs
    that are available to transcribe audio files or video files; it supports a number
    of different languages and custom vocabulary too. Accuracy is the key and through
    custom vocabulary, you can enhance it based on the desired domain or industry:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们学习了文本到语音。在本节中，我们将学习语音到文本以及提供此服务的服务：**Amazon Transcribe**。它是一种使用预训练的深度学习模型的自动语音识别服务，这意味着我们不需要在数PB的数据上进行训练以生成模型；亚马逊为我们完成这项工作。我们只需使用可用的
    API 来转录音频文件或视频文件；它还支持多种不同的语言和自定义词汇。准确性是关键，并且通过自定义词汇，您可以根据所需的领域或行业来增强它：
- en: '![Figure 2.12 – Block diagram of Amazon Transcribe''s input and output'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.12 – Amazon Transcribe 输入和输出块的示意图'
- en: '](img/B16735_02_012.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_02_012.jpg)'
- en: Figure 2.12 – Block diagram of Amazon Transcribe's input and output
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – Amazon Transcribe 输入和输出块的示意图
- en: 'Some common uses of Amazon Transcribe include the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Transcribe 的常见用途包括以下内容：
- en: Real-time audio streaming and transcription.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时音频流和转录。
- en: Transcripting pre-recorded audio files.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转录预录制的音频文件。
- en: Enable text searching from a media file by combining AWS Elasticsearch and Amazon
    Transcribe.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过结合 AWS Elasticsearch 和 Amazon Transcribe，启用从媒体文件中进行文本搜索。
- en: Performing sentiment analysis on recorded audio files for voice helpdesk (contact
    center analytics).
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对录音音频文件进行情感分析以帮助语音客服（接触中心分析）。
- en: Channel identification separation.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信道识别分离。
- en: Next, we'll explore the benefits of Amazon Transcribe.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨 Amazon Transcribe 的好处。
- en: Exploring the benefits of Amazon Transcribe
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 Amazon Transcribe 的好处
- en: 'Let''s look at some of the benefits of using Amazon Transcribe:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用 Amazon Transcribe 的一些好处：
- en: '*Content Redaction*: Customer privacy can be ensured by instructing Amazon
    Transcribe to identify and redact `VocabularyFilterName` and `VocabularyFilterMethod`,
    which are provided by the `StratTranscriptionJob` operation. For example, in financial
    organizations, this can be used to redact a caller''s details.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*内容编辑*：通过指示 Amazon Transcribe 识别和编辑 `VocabularyFilterName` 和 `VocabularyFilterMethod`（由
    `StratTranscriptionJob` 操作提供），可以确保客户隐私。例如，在金融机构中，这可以用来编辑呼叫者的详细信息。'
- en: '*Language Identification*: It can automatically identify the most used language
    in an audio file and generate transcriptions. If you have several audio files,
    then this service would help you classify them by language.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*语言识别*：它可以自动识别音频文件中最常用的语言并生成转录。如果您有多个音频文件，则这项服务可以帮助您按语言对它们进行分类。'
- en: '*Streaming Transcription*: You can send recorded audio files or live audio
    streams to Amazon Transcribe and output a stream of text in real time.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*流式转录*：您可以将记录的音频文件或实时音频流发送到 Amazon Transcribe，并实时输出文本流。'
- en: '*Custom Vocabulary or Customized Transcription*: You can use your custom vocabulary
    list as per your custom needs to generate accurate transcriptions.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自定义词汇或定制转录*：您可以根据您的特定需求使用自定义词汇列表来生成准确的转录。'
- en: '*TimeStamp Generation*: If you want to build or add subtitles for your videos,
    then Amazon Transcribe can return the timestamp for each word or phrase from the
    audio.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*时间戳生成*：如果您想为视频创建或添加字幕，那么 Amazon Transcribe 可以返回音频中每个单词或短语的时戳。'
- en: '*Cost Effectiveness*: Being a managed service, there is no infrastructure cost.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*成本效益*：作为一个托管服务，没有基础设施成本。'
- en: Now, let's get hands-on with Amazon Transcribe.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们亲身体验 Amazon Transcribe。
- en: Getting hands-on with Amazon Transcribe
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亲身体验 Amazon Transcribe
- en: 'In this section, we will build a pipeline where we can integrate AWS Lambda
    with Amazon Transcribe to read an audio file stored in a folder in an S3 bucket,
    and then store the output JSON file in another S3 bucket. We will monitor the
    task''s progress in CloudWatch logs too. We will use the `start_transcription_job`
    asynchronous function to start our job and we will constantly monitor the job
    through `get_transcription_job` until its status becomes `COMPLETED`. Let''s get
    started:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将构建一个管道，其中我们可以将 AWS Lambda 与 Amazon Transcribe 集成，以读取存储在 S3 桶中文件夹内的音频文件，然后将输出
    JSON 文件存储在另一个 S3 桶中。我们还将通过 CloudWatch 日志监控任务的进度。我们将使用 `start_transcription_job`
    异步函数来启动我们的工作，并通过 `get_transcription_job` 持续监控工作，直到其状态变为 `COMPLETED`。让我们开始吧：
- en: 'First, create an IAM role called `transcribe-demo-role` for the Lambda function
    to execute. Ensure that it can read and write from/to S3, use Amazon Transcribe,
    and print the output in CloudWatch logs. Add the following policies to the IAM
    role:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，为 Lambda 函数创建一个名为 `transcribe-demo-role` 的 IAM 角色，以确保它可以读取和写入 S3，使用 Amazon
    Transcribe，并在 CloudWatch 日志中打印输出。将以下策略添加到 IAM 角色中：
- en: '`AmazonS3FullAccess`'
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AmazonS3FullAccess`'
- en: '`CloudWatchFullAccess`'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CloudWatchFullAccess`'
- en: '`AmazonTranscribeFullAccess`'
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AmazonTranscribeFullAccess`'
- en: Now, we will create a Lambda function called `transcribe-lambda` with our existing
    IAM role, `transcribe-demo-role`, and save it.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将使用现有的 IAM 角色 `transcribe-demo-role` 创建一个名为 `transcribe-lambda` 的 Lambda
    函数，并将其保存。
- en: Please make sure you change the default timeout to a higher value in the`start_transcription_job`
    to start the task and monitor the same by using the `get_transcription_job` API.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请确保您将 `start_transcription_job` 中的默认超时值更改为更高的值以启动任务，并使用 `get_transcription_job`
    API 进行监控。
- en: Paste the code available at [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/blob/master/Chapter-2/Amazon%20Transcribe%20Demo/lambda_function/lambda_function.py](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/blob/master/Chapter-2/Amazon%20Transcribe%20Demo/lambda_function/lambda_function.py)
    and click on **Deploy**.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将可用的代码粘贴到 [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/blob/master/Chapter-2/Amazon%20Transcribe%20Demo/lambda_function/lambda_function.py](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/blob/master/Chapter-2/Amazon%20Transcribe%20Demo/lambda_function/lambda_function.py)
    并点击 **部署**。
- en: 'This should give us the following output:'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这应该会给我们以下输出：
- en: '![Figure 2.13 – The Basic settings section of our created lambda function'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.13 – 我们创建的 lambda 函数的基本设置部分'
- en: '](img/B16735_02_013.jpg)'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16735_02_013.jpg)'
- en: Figure 2.13 – The Basic settings section of our created lambda function
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.13 – 我们创建的 lambda 函数的基本设置部分
- en: Next, we will be creating the an S3 bucket called `transcribe-demo-101` and
    a folder called `input`. Create an event by going to the `audio-event`
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个名为 `transcribe-demo-101` 的 S3 桶和一个名为 `input` 的文件夹。通过访问 `audio-event`
    创建一个事件。
- en: '`All object create events`'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`所有对象创建事件`'
- en: '`input/`'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`input/`'
- en: '`Lambda Function`'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Lambda 函数`'
- en: '`transcribe-lambda`'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`transcribe-lambda`'
- en: Upload the audio file in `.mp4`format to the `input` folder. This will trigger
    the Lambda function. As per the code, the output will be stored in the S3 bucket
    in JSON format, which you can then use to read the contents of the file.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `.mp4` 格式的音频文件上传到 `input` 文件夹。这将触发 Lambda 函数。根据代码，输出将以 JSON 格式存储在 S3 桶中，然后您可以使用它来读取文件内容。
- en: Navigate to **CloudWatch > CloudWatch Logs > Log groups > aws/lambda/transcribe-lambda**.
    Choose the latest stream from the list. It will look as follows:![Figure 2.14
    – The logs in a Log Stream for the specified log groups in the CloudWatch console
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 **CloudWatch > CloudWatch Logs > Log groups > aws/lambda/transcribe-lambda**。从列表中选择最新的流。它看起来如下所示：![图
    2.14 – CloudWatch 控制台中指定日志组的日志流
- en: '](img/B16735_02_014.jpg)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B16735_02_014.jpg](img/B16735_02_014.jpg)'
- en: Figure 2.14 – The logs in a Log Stream for the specified log groups in the CloudWatch
    console
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.14 – CloudWatch 控制台中指定日志组的日志流
- en: 'The output is saved to the S3 bucket in JSON format, as per the jobname mentioned
    in your code (you can use the the S3 `getObject` API to download and read it):'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出以 JSON 格式保存在提到的作业名称的 S3 桶中（您可以使用 S3 的 `getObject` API 下载并读取它）：
- en: '![Figure 2.15 – The output JSON file in an S3 bucket'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.15 – S3 桶中的输出 JSON 文件'
- en: '](img/B16735_02_015.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16735_02_015.jpg](img/B16735_02_015.jpg)'
- en: Figure 2.15 – The output JSON file in an S3 bucket
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.15 – S3 桶中的输出 JSON 文件
- en: Important note
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: It is a best practice not to overprovision your function's timeout settings.
    Always understand your code performance and set a function timeout accordingly.
    Overprovisioning a function timeout results in Lambda functions running longer
    and it causes unexpected costs. If you're using asynchronous API calls in your
    Lambda function, then it's good to write them into SNS topics on success and trigger
    another Lambda function from that. If it needs human intervention, then it is
    suggested that you use AWS Step Functions.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 不过度配置您函数的超时设置是一种最佳实践。始终了解您的代码性能并根据需要设置函数超时。过度配置函数超时会导致 Lambda 函数运行时间更长，并造成意外的成本。如果您在
    Lambda 函数中使用异步 API 调用，那么在成功时将它们写入 SNS 主题，并从那里触发另一个 Lambda 函数是个好主意。如果需要人工干预，建议您使用
    AWS Step Functions。
- en: In this section, we learned and applied Amazon Transcribe to convert speech
    into text. In the next section, we will learn about one of the most powerful AWS
    AI services we can use to get the maximum amount of insight from our text data.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了并应用了 Amazon Transcribe 将语音转换为文本。在下一节中，我们将了解我们可以使用的最强大的 AWS AI 服务之一，以从我们的文本数据中获得最大洞察力。
- en: Implementing natural language processing with Amazon Comprehend
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon Comprehend 实现自然语言处理
- en: 'This service helps you extract insights from unstructured text. Unstructured
    text information is growing exponentially. A few data source examples are as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 此服务帮助您从非结构化文本中提取洞察力。非结构化文本信息呈指数增长。以下是一些数据源示例：
- en: '*Customer engagement*: Call center, issue triage, customer surveys, and product
    reviews'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户参与度*：呼叫中心、问题分类、客户调查和产品评论'
- en: '*Business processes*: Customer/vendor emails, product support messages, and
    operation support feedback'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*业务流程*：客户/供应商电子邮件、产品支持消息和运营支持反馈'
- en: '*Records and research*: Whitepapers and medical records'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*记录和研究*：白皮书和医疗记录'
- en: '*News and social media*: Social media analytics, brand trends, and correlated
    events'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*新闻和社交媒体*：社交媒体分析、品牌趋势和相关事件'
- en: Now, the question is, what can we do with this data? How can we analyze it and
    extract any value out of it? The answer is Amazon Comprehend, which is used to
    get insights from your unstructured data.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，问题是，我们能用这些数据做什么？我们如何分析它并从中提取任何价值？答案是 Amazon Comprehend，它用于从您的非结构化数据中获取洞察力。
- en: 'Some common uses of Amazon Comprehend include the following:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Comprehend 的常见用途包括以下内容：
- en: Information management system
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息管理系统
- en: More accurate search system on organized topics
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有组织的主题上的更精确的搜索系统
- en: Sentiment analysis of users
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户情感分析
- en: Support ticket classification
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持票分类
- en: Language detection from a document and then translating it into English using
    Amazon Translate
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文档中检测语言，然后使用 Amazon Translate 翻译成英语
- en: Creating a system to label unstructured clinical data to assist in research
    and analysis purposes
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting topics from the saved audio files of company meetings or TV news
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we'll explore the benefits of Amazon Comprehend.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the benefits of Amazon Comprehend
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some of the advantages of using Comprehend can be seen in the following image:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – A block diagram showing Amazon Comprehend''s capabilities'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16735_02_016.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.16 – A block diagram showing Amazon Comprehend's capabilities
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at these in more detail:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: It detects the language of the text and extract key phrases. Amazon Comprehend
    can be used for sentiment analysis and topic modeling too.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Comprehend Medical can be used to extract medical information.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You pay for what you use since this is a fully managed service; you do not have
    to pay for the infrastructure. You don't need to train, develop, and deploy your
    own model.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The topic modeling service works by extracting up to 100 topics. A topic is
    a keyword bucket so that you can see what's in the actual corpus of documents.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's accurate, continuously trained, and easy to use.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we'll get hands-on with Amazon Comprehend.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Getting hands-on with Amazon Comprehend
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will build a pipeline where we can integrate AWS Lambda
    with Amazon Rekognition and Amazon Comprehend. We will then read an image file
    stored in an S3 bucket and detect the language of the text that''s been extracted
    from the image. We will also use CloudWatch to print out the output. The following
    is a diagram of our use case:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Architecture diagram of the required use case'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16735_02_017.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.17 – Architecture diagram of the required use case
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin by creating an IAM Role:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the IAM console page.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Roles** from the left-hand menu.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Create role**.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Lambda** as the trusted entity.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following managed `policies`:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`AmazonS3ReadOnlyAccess`'
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AmazonRekognitionFullAccess`'
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ComprehendFullAccess`'
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CloudWatchFullAccess`'
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Save the role as `language-detection-from-image-role`.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, let's create the Lambda function. Navigate to **Lambda > Functions > Create
    Function**.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name the function `language-detection-from-image`.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the runtime to `Python 3.6`.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use our existing role; that is, `language-detection-from-image-role`.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download the code from [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Transcribe%20Demo/lambda_function](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Transcribe%20Demo/lambda_function),
    paste it into the function, and click `detect_text` API from Amazon Rekognition
    to detect text from an image and the `batch_detect_dominant_language` API from
    Amazon Comprehend to detect the language of the text.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, go to your AWS S3 console and create a bucket called *language-detection-image*.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a folder called `input-image` (in this example, we will only upload `.jpg`
    files).
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to **Properties > Events> Add notification**.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill in the required fields in the `image-upload-event`
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`All object create events`'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`input-image/`'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`.jpg`'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Lambda Function`'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`language-detection-from-image`'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to `sign-image.jpg` image in the folder. (This file is available in
    this book's GitHub repository at [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Comprehend%20Demo/input_image](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Comprehend%20Demo/input_image)).
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This file upload will trigger the lambda function. You can monitor the logs
    from **CloudWatch> CloudWatch Logs> Log groups> /aws/lambda/language-detection-from-image**.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the streams and select the latest one. The detected language is printed
    in the logs, as shown in the following screenshot:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.18 – The logs in CloudWatch for verifying the output'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16735_02_018.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.18 – The logs in CloudWatch for verifying the output
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: 'It is suggested that you use batch operations such as `BatchDetectSentiment`or
    `BatchDetectDominantLanguage` in your production environment. This is because
    single API operations can cause API-level throttling. More details are available
    here: [https://docs.aws.amazon.com/comprehend/latest/dg/functionality.html](https://docs.aws.amazon.com/comprehend/latest/dg/functionality.html).'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned how to use Amazon Comprehend to detect the language
    of texts. The text is extracted into our Lambda function using Amazon Rekognition.
    In the next section, we will learn about translating the same text into English
    via Amazon Translate.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Translating documents with Amazon Translate
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the time, people prefer to communicate in their own language, even on
    digital platforms. Amazon Translate is a text translation service. We can provide
    documents or strings of text in various languages and get it back in a different
    language. It uses pre-trained deep learning techniques, so we shouldn't be worried
    about the models, nor how they are managed. We can make API requests and get the
    results back.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'Some common uses of Amazon Translate include the following:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: If there's an organization-wide requirement to prepare documents in different
    languages, then Translate is the solution for converting one language into many.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online chat applications can be translated in real time to provide a better
    customer experience.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To localize website content faster and more affordably into more languages.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis can be applied to different languages once they have been
    translated.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To provide non-English language support for a news publishing website.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we'll explore the benefits of Amazon Translate.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the benefits of Amazon Translate
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some of the benefits of using Amazon Translate include the following:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: It uses neural machine translation, which mimics the way the human brain works.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No need to maintain your resources.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Produces high-quality results and maintains their consistency.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can customize your brand names and model names, and any other unique terms
    get translated using the Custom Terminology Feature.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be easily integrated with applications through APIs.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Translate scales itself when you need it to do more.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will get hands-on with Amazon Translate.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: Getting hands-on with Amazon Translate
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will build a product by integrating AWS Lambda with Amazon
    Rekognition, Amazon Comprehend, and Amazon Translate to read an image file stored
    in an S3 bucket. Then, we will detect the language of the text that''s been extracted
    from the image so that we can translate it into English. We will also use CloudWatch
    to print the translated output. The following is a diagram of our use case:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.19 – Architecture diagram of the required use case'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16735_02_019.jpg)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.19 – Architecture diagram of the required use case
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by creating an IAM role:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the IAM console page.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Roles** from the left-hand menu.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Create role**.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Lambda** as the trusted entity.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following managed policies:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`AmazonS3ReadOnlyAccess`'
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AmazonRekognitionFullAccess`'
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ComprehendFullAccess`'
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CloudWatchFullAccess`'
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TranslateFullAccess`'
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Save the role as `language-translation-from-image`.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next immediate step is to create a Lambda function. Navigate to **Lambda
    > Functions > Create Function**.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name the function `language-detection-from-image`.
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the runtime to `Python 3.6`.
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use an existing role; that is, `language-detection-from-image-role`.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste the code available at [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/blob/master/Chapter-2/Amazon%20Translate%20Demo/lambda_function/lambda_function.py](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/blob/master/Chapter-2/Amazon%20Translate%20Demo/lambda_function/lambda_function.py)
    and click `translate_text` API to translate the input text.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next step is to create a bucket called `language-translation-from-image`.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a folder named `image`. Then, navigate to **Properties > Events> Add
    notification**.
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Fill in the required fields, as shown here, and click on `.jpg` as the suffix;
    otherwise, it will trigger the lambda function for any object creation process):'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`All object create events`'
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image/`'
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.jpg`'
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Lambda Function`'
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`language-translation-from-image`'
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Navigate to `sign-image.jpg` image into the folder. This file is available
    in this book''s GitHub repository: [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Translate%20Demo/input_image](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Translate%20Demo/input_image).'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Uploading this image will trigger the lambda function. You can monitor the logs
    by going to **CloudWatch> CloudWatch Logs> Log groups> /aws/lambda/language-translation-from-image**.
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the streams and select the latest one. It will look as follow:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.20 – The logs in CloudWatch for verifying the output'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16735_02_020.jpg)'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.20 – The logs in CloudWatch for verifying the output
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: 'The translation is as follows:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Important note
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: For production use cases, it is recommended to use AWS Lambda with AWS Step
    Function if you have dependent services or a chain of services.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Using the same S3 bucket to store input and output objects is not recommended.
    Output object creation in the same bucket may trigger recursive Lambda invocation.
    If you're using same bucket, then we recommend that you use a prefix and suffix
    to trigger events. Similarly, we recommend using a prefixto store output objects.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned how to combine multiple services and chain their
    output to achieve a particular use case outcome. We learned how to integrate Amazon
    Rekognition to detect text in an image. The language can then be detected by using
    Amazon Comprehend. Then, we used the same input and translated it into English
    with the help of Amazon Translate. The translated output was then printed on CloudWatch
    logs for verification. In the next section, we will learn about Amazon Textract,
    which we can use to extract text from a document.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: Extracting text from documents with Amazon Textract
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Manually extracting information from documents is slow, expensive, and prone
    to errors. Traditional optical character recognition software needs a lot of customization,
    and it will still give erroneous output. To avoid such manual processes and errors,
    you should use **Amazon Textract**. Generally, we convert the documents into images
    in order to detect bounding boxes around the texts in images. We then apply character
    recognition technique to read the text from it. Textract does all this for you,
    and also extracts text, tables, forms, and other data for you with minimal effort.
    If you get low-confidence results from Amazon Textract, then Amazon A2I is the
    best solution.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: 'Textract reduces the manual effort of extracting text from millions of scanned
    document pages. Once the information has been captured, actions can be taken on
    the text, such as storing it in different data stores, analyzing sentiments, or
    searching for keywords. The following diagram shows how Amazon Textract works:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.21 – Block diagram representation of Amazon Textract and how it
    stores its output'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16735_02_021.jpg)'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.21 – Block diagram representation of Amazon Textract and how it stores
    its output
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'Some common uses of Amazon Textract include the following:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: Documenting processing workflows to extract tables or forms.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating search indexes from documents using Amazon Elasticsearch.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redacting personally identifiable information in a workflow; Textract identifies
    data types and form labels automatically.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we'll explore the benefits of Amazon Textract.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the benefits of Amazon Textract
  id: totrans-351
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several reasons to use Textract, as follows:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Zero infrastructure cost.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fully managed service (reduced development and management overhead).
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helps you extract both structured and unstructured data.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handwritten reviews can be analyzed.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Textract performs better than OCR apps, which use flat bag of words.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we'll get hands-on with Amazon Textract.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting hands-on with Amazon Textract
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will use the Amazon Textract API to read an image file
    from our S3 bucket and print the "FORM" details on Cloudwatch. The same can be
    stored in S3 in your desired format for further use or can be stored in DynamoDB
    as a key-value pair. Let''s get started:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create an IAM role called `textract-use-case-role` with the following
    policies. This will allow the Lambda function to execute so that it can read from
    S3, use Amazon Textract, and print the output in CloudWatch logs:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`CloudWatchFullAccess`'
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AmazonTextractFullAccess`'
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AmazonS3ReadOnlyAccess`'
  id: totrans-364
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's create an S3 bucket called `textract-document-analysis` and upload the
    `receipt.png` image file. This will be used to contain the FORM details that will
    be extracted. The image file is available here at [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Textract%20Demo/input_doc](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-2/Amazon%20Textract%20Demo/input_doc):![Figure
    2.22 – An S3 bucket with an image (.png) file uploaded to the input folder
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16735_02_022.jpg)'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.22 – An S3 bucket with an image (.png) file uploaded to the input folder
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The next step is to create a Lambda function called `read-scanned-doc`, as shown
    in the following screenshot, with an existing execution role called `textract-use-case-role`:![Figure
    2.23 – The AWS Lambda Create function dialog
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16735_02_023.jpg)'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.23 – The AWS Lambda Create function dialog
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once the function has been created, paste the following code and deploy it.
    Scroll down to `analyze_document` API from Amazon Textract to get the `Table and
    Form` details via the `FeatureTypes` parameter of the API:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Unlike the previous examples, we will create a test configuration to run our
    code.
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the dropdown left of the **Test** button.
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Configure test events** and choose **Create new test event**.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Amazon S3 Put** from the **Event template** dropdown.
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the JSON body, change the highlighted values as per our bucket name and key,
    as shown here:![Figure 2.24 – The Event template for testing the lambda function
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16735_02_024.jpg)'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.24 – The Event template for testing the lambda function
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the `TextractDemo`.
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Save**.
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select your test configuration (`TextractDemo`) and click on **Test**:![Figure
    2.25 – Selecting the test configuration before running your test
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16735_02_025.jpg)'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.25 – Selecting the test configuration before running your test
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This will trigger the lambda function. You can monitor the logs from **CloudWatch>
    CloudWatch Logs> Log groups> /aws/lambda/ read-scanned-doc**.
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the streams and select the latest one. It will look as follows; the
    key-value pairs can be seen in the following screenshot:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.26 – The logs in CloudWatch for verifying the output'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16735_02_026.jpg)'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.26 – The logs in CloudWatch for verifying the output
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: The most scalable and cost-effective way to generate S3 Put events for asynchronously
    invocating downstream AI workflows via Lambda is to generate an AWS Pre-Signed
    URL, and then provide it to your mobile or web application users. Many users can
    be served at the same time via this approach, and it may increase performance
    and throughput.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: Considering the same region for your AWS AI services and S3 bucket may improve
    performance and reduce network latency. AWS VPC endpoints can leverage enhanced
    security without using the public internet. You can store the AWS AI results in
    an AWS S3 bucket and encrypt the rest to attain better security.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned how to extract text from a scanned document and
    print the form data out of it. Unlike the other sections, we used the testing
    feature of a lambda function by creating a test configuration that includes an
    event template. In the next section, we will learn about creating a chatbot for
    organizations and learn how to use it.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Creating chatbots on Amazon Lex
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the features that are available in Alexa are powered by **Amazon Lex**.
    You can easily build a chatbot using Amazon Lex. It uses natural language understanding
    and automatic speech recognition behind the scenes. Through SLU, Amazon Lex takes
    natural language speech and text input, understands the intent, and fulfills the
    intent of the user. An Amazon Lex bot can be created either from the console or
    via APIs. Its basic requirements are shown in the upcoming diagram.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: 'Some common uses of Amazon Lex include the following:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: Apps that both listen and take input as text.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatbots.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conversational AI products to provide a better customer and sales experience.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom business bots for assistance through AWS Lambda functions.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voice assistants for your call center, which can speak to a user, schedule a
    meeting, or request details of your account.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By integrating with Amazon Cognito, you can control user management, authentication,
    and sync across all your devices.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will explore the benefits of Amazon Lex.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the benefits of Amazon Lex
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some reasons for using Lex include the following:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: Chatbots can be directly built and tested from the AWS management console. These
    chatbots can be easily integrated into Facebook Messenger, Slack, and Twilio SMS
    via its rich formatting capabilities.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conversation logs can be stored in Amazon CloudWatch for further analysis. You
    can use them to monitor your bot and derive insights to improve your user experience.
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Lex can be integrated into other AWS services such as Amazon Cognito,
    AWS Lambda, Amazon DynamoDB, Amazon CloudWatch, and AWS Mobile Hub to leverage
    application security, monitoring, user authentication, business logic, storage,
    and mobile app development in AWS platforms.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Lex chatbots can be integrated into your custom web applications too.
    You just need to build a chatbot widget and integrate it into your UI.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we'll get hands-on with Amazon Lex.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: Getting hands-on with Amazon Lex
  id: totrans-411
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s get started:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: Log into [https://console.aws.amazon.com/lex/](https://console.aws.amazon.com/lex/).
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Get Started** and select **Custom bot**.
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill in the following details and click on **Create**:![Figure 2.27 – The Create
    dialog of Amazon Lex
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16735_02_027.jpg)'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.27 – The Create dialog of Amazon Lex
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on **Create Intent**. A dialog will appear. Select **Create Intent**.
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name the new intent `MovieIntent` and click on **Add**.
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the `movie_type`
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Slot type: `AMAZON.Genre`'
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Prompt: `Which movie do you like?`'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the `movie_type` is my variable:![Figure 2.28 – The Sample utterances
    section
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16735_02_028.jpg)'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.28 – The Sample utterances section
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Scroll down to the **Response** section to add a message:![Figure 2.29 – The
    Response section of Amazon Lex
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16735_02_029.jpg)'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.29 – The Response section of Amazon Lex
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Scroll down to **Save Intent** and click on **Build**. Upon successfully building
    the prompt, the following success message will appear:![Figure 2.30 – The Response
    section of Amazon Lex
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16735_02_030.jpg)'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.30 – The Response section of Amazon Lex
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, you can test your bot, as shown in the following screenshot:'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.31 – The Test bot dialog'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16735_02_031.jpg)'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.31 – The Test bot dialog
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: Not all Amazon Polly features are available within Alexa – particularly the
    Amazon Polly SSML features – which makes Amazon Polly and Alexa different.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: That concludes this chapter's introduction to the various AWS application services
    that are available.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-439
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about a few of the AWS AI services that can be used
    to solve various problems. We used the Amazon Rekognition service, which detects
    objects and faces (including celebrity faces), and can also extract text from
    images. For text to speech, we used Amazon Polly, while for speech to text, we
    used Amazon Transcribe. Toward the end of this chapter, we built a chatbot in
    Amazon Lex.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: For language detection and translation in an image, we used Amazon Rekognition,
    Amazon Comprehend, and Amazon Translate. We learned how to combine all of them
    into one Lambda function to solve our problem.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: For the certification exam, you don't need to remember all the APIs we used
    in this chapter. There may be questions on a few of the best practices that we
    learned or on the names of services that solve a specific problem. It is always
    good to practice using these AWS AI services as it will enhance your architecting
    skills.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about data preparation and transformation,
    which is the most important aspect of machine learning.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-444
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using pre-defined logic and rules to make product recommendations to online
    shoppers is an example of machine learning.
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. TRUE
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. FALSE
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which level of the ML stack helps you build custom ML models without managing
    infrastructure?
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Top level (the AI services)
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Middle level (Amazon SageMaker)
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Bottom level (ML frameworks and infrastructure)
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Your own infrastructure and code level
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following can you do with Amazon Textract?
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Detect key-value pairs in documents
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Build a custom ML model for text extraction
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Send text extraction with low confidence scores for human review
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Translate the detected text into English
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With Amazon Comprehend, a new model can be trained to help you extract custom
    entities from text.
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. FALSE
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. TRUE
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following is an example of the type of data Amazon Comprehend is
    designed to analyze?
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Social media posts
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Data in a table
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Log files
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. GPS data
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For log files, we can use CloudWatch Log Insights.
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When calling the `DetectKeyPhrases` API, which of the following is not returned
    by Amazon Comprehend?
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. The key phrases
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. The count of each key phrase
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. The confidence level for each key phrase
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. The sentiment of each key phrase
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It has nothing to do with sentiment.
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You want to create a Lex bot that can help you order pizza. Why is it important
    to add slots as part of intent configuration?
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. So you can customize your orders with different pizza sizes and toppings.
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. So you can account for different ways you might convey your intent to order
    pizza.
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. So that a lambda function can be automatically set up for you to fulfill
    the intent.
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let's say you're responsible for building a system that analyzes the sentiment
    of a customer chat. Which service should you integrate with Amazon Lex to do this?
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Amazon Transcribe
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Amazon Comprehend
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Amazon Translate
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Amazon Textract
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In which situation would an Amazon Lex fallback intent help?
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. When a user orders pizza but, due to background noise, the bot needs the
    user to repeat what they said.
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. When a bot has to use a previous exchange with a user to pretend to understand
    an unclear message from that user.
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. When a bot is asked a question that is not programmed to answer.
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Fallback intent is meant for those inputs that a bot doesn't expect.
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which three of the following options can Amazon Textract handle that traditional
    OCR methods are not able to?
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Extracting words and lines from documents
  id: totrans-491
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Extracting forms (key/values) from documents without using any templates
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Handling non-textual content such as radio buttons and checkboxes
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Preserving the composition of data stored in tables
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following is a common use case for integrating Amazon Textract
    with Amazon A2I (human review)?
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. You want to identify form labels and values from an image or PDF document.
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. You are extracting data from a document that requires review due to regulatory
    requirements or sensitive business decisions.
  id: totrans-497
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. You have tables in your document, and you need to preserve the composition
    of the data stored in those tables.
  id: totrans-498
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You are looking to extract form or table data in a document. You need to do
    this synchronously because your use is latency-sensitive, such as mobile capture.
    What API should you use?
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. AnalyzeDocument
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. DetectDocumentText
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. StartDocumentAnalysis
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. GetDocumentTextDetection
  id: totrans-503
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers
  id: totrans-504
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 1\. B
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: 2\. B
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
- en: 3\. A, C
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: 4\. B
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
- en: 5\. A
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: 6\. D
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
- en: 7\. A
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
- en: 8\. B
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: 9\. C
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: 10\. B, C, D
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
- en: 11\. B
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
- en: 12\. A
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
