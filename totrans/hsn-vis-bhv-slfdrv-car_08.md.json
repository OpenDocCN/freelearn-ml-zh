["```py\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',    input_shape=x_train.shape[1:]))\nmodel.add(AveragePooling2D())\nmodel.add(Conv2D(filters=256, kernel_size=(3, 3),    activation='relu'))\nmodel.add(AveragePooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dense(units=256, activation='relu'))\nmodel.add(Dense(units=num_classes, activation = 'softmax'))\n```", "```py\nTotal params: 5,002,506\n```", "```py\nTraining time: 645.9990749359131\nMin Loss: 0.12497963292273692\nMin Validation Loss: 0.9336215916395187\nMax Accuracy: 0.95826\nMax Validation Accuracy: 0.6966000199317932\n```", "```py\n52s 1ms/step - loss: 0.5393 - accuracy: 0.8093 - val_loss: 0.9496 - val_accuracy: 0.6949 \n```", "```py\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',    input_shape=x_train.shape[1:]))\nmodel.add(AveragePooling2D())\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3),     activation='relu', padding=\"same\"))\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3),     activation='relu', padding=\"same\"))\nmodel.add(AveragePooling2D())\n```", "```py\nTotal params: 3,568,906\n```", "```py\nTraining time: 567.7167596817017\nMin Loss: 0.1018450417491654\nMin Validation Loss: 0.8735350118398666\nMax Accuracy: 0.96568\nMax Validation Accuracy: 0.7249000072479248\n```", "```py\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3),     activation='relu', input_shape=x_train.shape[1:]))model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',    input_shape=x_train.shape[1:], padding=\"same\"))model.add(AveragePooling2D())model.add(Conv2D(filters=128, kernel_size=(3, 3),     activation='relu', padding=\"same\"))model.add(Conv2D(filters=128, kernel_size=(3, 3),     activation='relu', padding=\"same\"))model.add(AveragePooling2D())\n```", "```py\nTraining time: 584.955037355423\nMin Loss: 0.10728564778155182\nMin Validation Loss: 0.7890052844524383\nMax Accuracy: 0.965\nMax Validation Accuracy: 0.739300012588501\n```", "```py\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:], padding=\"same\"))model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:], padding=\"same\"))model.add(AveragePooling2D())model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding=\"same\"))model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding=\"same\"))model.add(AveragePooling2D())model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding=\"same\"))model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding=\"same\"))model.add(AveragePooling2D())\n```", "```py\nTraining time: 741.1498856544495\nMin Loss: 0.22022022939510644\nMin Validation Loss: 0.7586277635633946\nMax Accuracy: 0.92434\nMax Validation Accuracy: 0.7630000114440918\n```", "```py\nmodel.add(Flatten())model.add(Dense(units=256, activation='relu'))model.add(Dense(units=128, activation='relu'))model.add(Dense(units=num_classes, activation = 'softmax'))\n```", "```py\nTotal params: 2,162,986\n```", "```py\nTraining time: 670.0584089756012\nMin Loss: 2.3028031995391847\nMin Validation Loss: 2.302628245162964\nMax Accuracy: 0.09902\nMax Validation Accuracy: 0.10000000149011612\n```", "```py\nTraining time: 686.5172057151794\nMin Loss: 0.24410496438018978\nMin Validation Loss: 0.7960220139861107\nMax Accuracy: 0.91434\nMax Validation Accuracy: 0.7454000115394592\n```", "```py\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:], padding=\"same\"))\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu',    input_shape=x_train.shape[1:], padding=\"same\"))\nmodel.add(AveragePooling2D())\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',    padding=\"same\"))\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',    padding=\"same\"))\nmodel.add(AveragePooling2D())\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',    padding=\"same\"))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',    padding=\"same\"))\n```", "```py\nTotal params: 829,146\n```", "```py\nTraining time: 422.8525400161743\nMin Loss: 0.27083665314182637\nMin Validation Loss: 0.8076118688702584\nMax Accuracy: 0.90398\nMax Validation Accuracy: 0.7415000200271606\n```", "```py\nTotal params: 759,962\n```", "```py\nTraining time: 376.09818053245544\nMin Loss: 0.30105597005218265\nMin Validation Loss: 0.8148738072395325\nMax Accuracy: 0.89274\nMax Validation Accuracy: 0.7391999959945679\n```", "```py\nTotal params: 368,666\n```", "```py\nTraining time: 326.9148383140564\nMin Loss: 0.296858479853943\nMin Validation Loss: 0.7925313812971115\nMax Accuracy: 0.89276\nMax Validation Accuracy: 0.7425000071525574\n```", "```py\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu',    input_shape=x_train.shape[1:], padding=\"same\"))model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu',    input_shape=x_train.shape[1:], padding=\"same\"))model.add(BatchNormalization())model.add(AveragePooling2D())model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',    padding=\"same\"))model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',    padding=\"same\"))model.add(BatchNormalization())model.add(AveragePooling2D())model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',    padding=\"same\"))model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',    padding=\"same\"))model.add(BatchNormalization())model.add(AveragePooling2D())\n```", "```py\nTotal params: 369,114\n```", "```py\nTraining time: 518.0608556270599\nMin Loss: 0.1616916553277429\nMin Validation Loss: 0.7272815862298012\nMax Accuracy: 0.94308\nMax Validation Accuracy: 0.7675999999046326\n```", "```py\nTraining time: 698.9837136268616\nMin Loss: 0.13732857785719446\nMin Validation Loss: 0.6836542286396027\nMax Accuracy: 0.95206\nMax Validation Accuracy: 0.7918999791145325\n```", "```py\nstop = EarlyStopping(min_delta=0.0005, patience=7, verbose=1)\n```", "```py\nImageDataGenerator(rotation_range=15, width_shift_range=[-5, 0, 5],    horizontal_flip=True)\n```", "```py\nEpoch 00031: val_loss did not improve from 0.48613\nEpoch 00031: early stopping\nTraining time: 1951.4751739501953\nMin Loss: 0.3638068118467927\nMin Validation Loss: 0.48612626193910835\nMax Accuracy: 0.87454\nMax Validation Accuracy: 0.8460999727249146\n```", "```py\nImageDataGenerator(rotation_range=15, width_shift_range=[-8, -4, 0,    4, 8], horizontal_flip=True, height_shift_range=[-5, 0, 5],    zoom_range=[0.9, 1.1])\n```", "```py\nEpoch 00040: early stopping\nTraining time: 2923.3936190605164\nMin Loss: 0.5091392234659194\nMin Validation Loss: 0.5033097203373909\nMax Accuracy: 0.8243\nMax Validation Accuracy: 0.8331999778747559\n```", "```py\nmodel.add(Flatten())\nmodel.add(Dense(units=256, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units=128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=num_classes, activation = 'softmax'))\n```", "```py\nEpoch 00097: early stopping\nTraining time: 6541.777503728867\nMin Loss: 0.38114651718586684\nMin Validation Loss: 0.44884318161308767\nMax Accuracy: 0.87218\nMax Validation Accuracy: 0.8585000038146973\n```", "```py\nmodel.add(Flatten())model.add(Dense(units=384, activation='relu'))model.add(Dropout(0.5))model.add(Dense(units=192, activation='relu'))model.add(Dropout(0.1))model.add(Dense(units=num_classes, activation='softmax'))\n```", "```py\nTotal params: 542,426\n```", "```py\nEpoch 00122: early stopping\nTraining time: 8456.040931940079\nMin Loss: 0.3601766444931924\nMin Validation Loss: 0.4270844452492893\nMax Accuracy: 0.87942\nMax Validation Accuracy: 0.864799976348877\n```", "```py\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:],    padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:],    padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(AveragePooling2D())\nmodel.add(Dropout(0.5))\n```", "```py\nEpoch 00133: early stopping\nTraining time: 9261.82032418251\nMin Loss: 0.6104169194960594\nMin Validation Loss: 0.4887285701841116\nMax Accuracy: 0.79362\nMax Validation Accuracy: 0.8417999744415283\n```", "```py\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:], padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:], padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(AveragePooling2D())\nmodel.add(SpatialDropout2D(0.2))\n\nmodel.add(Conv2D(filters=48, kernel_size=(3, 3), activation='relu',    padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=48, kernel_size=(3, 3), activation='relu',    padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(AveragePooling2D())\nmodel.add(SpatialDropout2D(0.2))\n\nmodel.add(Conv2D(filters=72, kernel_size=(3, 3), activation='relu',    padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=72, kernel_size=(3, 3), activation='relu',    padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(AveragePooling2D())\nmodel.add(Dropout(0.1))\n\nAnd this is the part with the dense layers:model.add(Flatten())\nmodel.add(Dense(units=384, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=192, activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(units=num_classes, activation='softmax'))\n```", "```py\nEpoch 00168: early stopping\nTraining time: 13122.931826591492\nMin Loss: 0.4703261657243967\nMin Validation Loss: 0.3803714614287019\nMax Accuracy: 0.84324\nMax Validation Accuracy: 0.8779000043869019\n```", "```py\nEpoch 00077: early stopping\nTraining time: 7110.028198957443\nMin Loss: 0.04797766085289389\nMin Validation Loss: 0.02718053938352254\nMax Accuracy: 0.98681664\nMax Validation Accuracy: 0.9919000267982483\n```"]