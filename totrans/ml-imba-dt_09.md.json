["```py\nimport pandas as pd\nfrom torch_geometric.datasets import FacebookPagePage\ndataset = FacebookPagePage(root=\".\")\ndata = dataset[0]\n```", "```py\nDataset: FacebookPagePage()\n-----------------------\nNumber of graphs: 1\nNumber of features: 128\nNumber of classes: 4\nNumber of graphs: 1\nNumber of nodes: 22,470\nNumber of edges: 342,004\nAverage node degree: 15.22\nContains isolated nodes: False\nContains self-loops: True\nIs undirected: True\n```", "```py\ndfx = pd.DataFrame(data.x.numpy())\ndfx['label'] = pd.DataFrame(data.y)\ndfx\n```", "```py\n22470 rows × 129 columns\n```", "```py\n# Create masks\ndata.train_mask = range(4368)\ndata.val_mask = range(4368, 4611)\ndata.test_mask = range(4611, 4853)\n```", "```py\nX_train, X_test, y_train, y_test = \\\n    data1.x[data1.train_mask].cpu().numpy(), \\\n    data1.x[data1.test_mask].cpu().numpy(), \\\n    data1.y[data1.train_mask].cpu().numpy(), \\\n    data1.y[data1.test_mask].cpu().numpy()\n```", "```py\nxgb_clf = XGBClassifier(eval_metric='logloss')\nxgb_clf.fit(X_train, y_train)\ny_pred = xgb_clf.predict_proba(X_test)\ntest_acc = accuracy_score(y_test, np.argmax(y_pred,axis=1))\ntest_acc.round(3)\n```", "```py\n0.793\n```", "```py\ny1_test_one_hot = F.one_hot(data1.y[data1.test_mask], \\\n    num_classes=4)\ndisplay_precision_recall_curve(y1_test_one_hot, y_pred)\n```", "```py\nimport torch\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\n```", "```py\nclass GraphConvolutionalNetwork(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.convolution_layer1 = GCNConv(input_dim, hidden_dim)\n        self.convolution_layer2 = GCNConv(hidden_dim, output_dim)\n```", "```py\n    def forward(self, node_features, edge_index):\n        hidden_representation = self.convolution_layer1( \\\n            node_features,edge_index)\n        hidden_representation = torch.relu(hidden_representation)\n        output_representation = self.convolution_layer2 \\\n            (hidden_representation, edge_index)\n        return F.log_softmax(output_representation, dim=1)\n```", "```py\n    def train_model(self, data, num_epochs):\n        loss_function = torch.nn.NLLLoss()\n        optimizer = torch.optim.Adam(self.parameters(),\\\n            lr=0.01, weight_decay=5e-4)\n        self.train()\n        for epoch in range(num_epochs + 1):\n            optimizer.zero_grad()\n            network_output = self(data.x, data.edge_index)\n            true_train_labels = data.y[data.train_mask]\n            loss = loss_function(network_output[data.train_mask], \\\n                true_train_labels)\n            accuracy = compute_accuracy(\\\n                network_output[data.train_mask].argmax(\\\n                    dim=1), true_train_labels)\n            loss.backward()\n            optimizer.step()\n            if(epoch % 20 == 0):\n                true_val_labels = data.y[data.val_mask]\n                val_loss = loss_function(\\\n                    network_output[data.val_mask], true_val_labels)\n                val_accuracy = compute_accuracy(\\\n                    network_output[data.val_mask].argmax(\\\n                    dim=1), true_val_labels)\n                print(f'Epoch: {epoch}\\n'\\\n                    f'Train Loss: {loss:.3f}, Accuracy:\\\n                    {accuracy*100:.0f}%\\n'\\\n                    f'Validation Loss: {val_loss:.2f},\\\n                    Accuracy: {val_accuracy*100:.0f}%\\n'\\\n                    '-------------------')\n```", "```py\n    @torch.no_grad()\n    def evaluate_model(self, data):\n        self.eval()\n        network_output = self(data.x, data.edge_index)\n        test_accuracy = compute_accuracy(\\\n            network_output.argmax(dim=1)[data.test_mask],\\\n            data.y[data.test_mask])\n        return test_accuracy,network_output[data.test_mask,:]\n```", "```py\ngcn = GraphConvolutionalNetwork(dataset.num_features, 16,\\\n    dataset.num_classes)\ngcn.train_model(data1, num_epochs=100)\nacc,_ = gcn.evaluate_model(data1)\nprint(f'\\nGCN test accuracy: {acc*100:.2f}%\\n')\n```", "```py\nEpoch: 0\nTrain Loss: 1.414, Accuracy: 32%\nValidation Loss: 1.38, Accuracy: 29%\n-------------------\nEpoch: 20\nTrain Loss: 0.432, Accuracy: 85%\nValidation Loss: 0.48, Accuracy: 83%\n-------------------\nEpoch: 40\nTrain Loss: 0.304, Accuracy: 89%\nValidation Loss: 0.43, Accuracy: 86%\n-------------------\nEpoch: 60\nTrain Loss: 0.247, Accuracy: 92%\nValidation Loss: 0.43, Accuracy: 86%\n-------------------\nEpoch: 80\nTrain Loss: 0.211, Accuracy: 93%\nValidation Loss: 0.43, Accuracy: 88%\n-------------------\nEpoch: 100\nTrain Loss: 0.184, Accuracy: 94%\nValidation Loss: 0.44, Accuracy: 88%\n-------------------\nGCN test accuracy: 90.91%\n```", "```py\n_, y1_score = gcn.evaluate_model(data1)\ny1_test_one_hot = F.one_hot(data1.y[data1.test_mask], num_classes=4)\ndisplay_precision_recall_curve(y1_test_one_hot, y1_score)\n```", "```py\nclass NLL_OHEM(torch.nn.NLLLoss):\n    def __init__(self):\n        super(NLL_OHEM, self).__init__()\n    def forward(self, cls_pred, cls_target, rate=0.95):\n        batch_size = cls_pred.size(0)\n        ohem_cls_loss = F.cross_entropy(cls_pred,\\\n            cls_target, ignore_index=-1)\n        keep_num = int(batch_size*rate)\n        ohem_cls_loss = ohem_cls_loss.topk(keep_num)[0]\n        cls_loss = ohem_cls_loss.sum() / keep_num # mean\n        return cls_loss\n```"]