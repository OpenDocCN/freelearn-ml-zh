["```py\n    import pandas as pd\n    df = pd.read_csv(\"./data.csv\")\n    df.info() \n    ```", "```py\n    df[\"Revenue\"] = df[\"Revenue\"].astype(int)\n    df[\"Weekend\"] = df[\"Weekend\"].astype(int) \n    ```", "```py\n    from time import strptime\n    df[\"MonthNum\"] = df[\"Month\"].apply(lambda x: strptime(x[:3],'%b').tm_mon)\n    df[\"VisitorTypeNum\"] = df[\"VisitorType\"].apply(\n            lambda x: 0 if x == \"New_Visitor\" else 1 if x == \"Returning_Visitor\" else 2\n    ) \n    ```", "```py\n    TARGET = \"Revenue\"\n    FEATURES = [\n        'Administrative',\n        'Administrative_Duration',\n        'BounceRates',\n        'Browser',\n        'ExitRates',\n        'Informational',\n        'Informational_Duration',\n        'MonthNum',\n        'OperatingSystems',\n        'PageValues',\n        'ProductRelated',\n        'ProductRelated_Duration',\n        'Region',\n        'SpecialDay',\n        'TrafficType',\n        'VisitorTypeNum',\n        'Weekend'\n    ]\n    X = df[FEATURES]\n    Y = df[TARGET] \n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    train_x, test_x, train_y, test_y= train_test_split(\n        X, Y, test_size=0.2\n    ) \n    ```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(\n    n_estimators=250, max_depth=5, class_weight=\"balanced\", n_jobs=-1\n)\nrf_model.fit(train_x, train_y) \n```", "```py\nrf_pred = rf_model.predict(test_x)\nrf_pred_proba = rf_model.predict_proba(test_x)[:,1] \n```", "```py\nfrom sklearn import metrics\naccuracy = (test_y == rf_pred).mean()\nprecision = metrics.precision_score(test_y, rf_pred)\nrecall = metrics.recall_score(test_y, rf_pred) \n```", "```py\ndp = metrics.RocCurveDisplay.from_predictions(\n    test_y,\n    rf_pred_proba,\n    name=\"Conversion\",\n    color=\"darkorange\",\n)\n_ = dp.ax_.set(\n    xlabel=\"False Positive Rate\",\n    ylabel=\"True Positive Rate\",\n    title=\"ROC Curve\",\n)\nplt.grid()\nplt.show() \n```", "```py\nimport seaborn as sns\ncf_matrix = metrics.confusion_matrix(test_y, rf_pred)\nax = plt.subplot()\nsns.heatmap(\n    cf_matrix,\n    annot=True,\n    annot_kws={\"size\": 10},\n    fmt=\"g\",\n    ax=ax\n)\nax.set_xlabel(\"Predicted\")\nax.set_ylabel(\"Actual\")\nax.set_title(f\"Confusion Matrix\")\nplt.show() \n```", "```py\npip install xgboost \n```", "```py\nfrom xgboost import XGBClassifier\nxgb_model = XGBClassifier(\n    n_estimators=100,\n    max_depth=5,\n    scale_pos_weight=1/train_y.mean(),\n)\nxgb_model.fit(train_x, train_y) \n```", "```py\nxgb_pred = xgb_model.predict(test_x)\nxgb_pred_proba = xgb_model.predict_proba(test_x)[:,1] \n```", "```py\naccuracy = (test_y == xgb_pred).mean()\nprecision = metrics.precision_score(test_y, xgb_pred)\nrecall = metrics.recall_score(test_y, xgb_pred) \n```", "```py\ndp = metrics.RocCurveDisplay.from_predictions(\n    test_y,\n    xgb_pred_proba,\n    name=\"Conversion\",\n    color=\"darkorange\",\n)\n_ = dp.ax_.set(\n    xlabel=\"False Positive Rate\",\n    ylabel=\"True Positive Rate\",\n    title=\"ROC Curve\",\n)\nplt.grid()\nplt.show() \n```", "```py\nimport seaborn as sns\ncf_matrix = metrics.confusion_matrix(test_y, xgb_pred)\nax = plt.subplot()\nsns.heatmap(\n    cf_matrix,\n    annot=True,\n    annot_kws={\"size\": 10},\n    fmt=\"g\",\n    ax=ax\n)\nax.set_xlabel(\"Predicted\")\nax.set_ylabel(\"Actual\")\nax.set_title(f\"Confusion Matrix\")\nplt.show() \n```", "```py\nmean = train_x.mean()\nstd = train_x.std()\nnormed_train_x = (train_x - mean)/std\nnormed_test_x = (test_x - mean)/std \n```", "```py\npip install keras \n```", "```py\nimport keras\nmodel = keras.Sequential(\n    [\n        keras.Input(shape=normed_train_x.shape[1:]),\n        keras.layers.Dense(2048, activation=\"relu\"),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ]\n) \n```", "```py\n    model_metrics = [\n        keras.metrics.Accuracy(name=\"accuracy\"),\n        keras.metrics.Precision(name=\"precision\"),\n        keras.metrics.Recall(name=\"recall\"),\n    ]\n    model.compile(\n        optimizer=keras.optimizers.Adam(0.001),\n        loss=\"binary_crossentropy\",\n        metrics=model_metrics\n    ) \n    ```", "```py\n    best_model_path = \"./checkpoint.wide-model.keras\"\n    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n        filepath=best_model_path,\n        monitor=\"val_precision\",\n        mode=\"max\",\n        save_best_only=True\n    ) \n    ```", "```py\n    class_weight = {0: 1, 1: 1/train_y.mean()}\n    history = model.fit(\n        normed_train_x.to_numpy(),\n        train_y.to_numpy(),\n        batch_size=64,\n        epochs=30,\n        verbose=2,\n        callbacks=[\n            model_checkpoint_callback,\n        ],\n        validation_data=(normed_test_x.to_numpy(), test_y.to_numpy()),\n        class_weight=class_weight,\n    ) \n    ```", "```py\nwide_best_model = keras.models.load_model(best_model_path) \n```", "```py\nwide_pred_proba = wide_best_model.predict(normed_test_x).flatten()\nwide_preds = [1 if x > 0.5 else 0 for x in wide_pred_proba] \n```", "```py\nmodel = keras.Sequential(\n    [\n        keras.Input(shape=normed_train_x.shape[1:]),\n        keras.layers.Dense(128, activation=\"relu\"),\n        keras.layers.Dense(128, activation=\"relu\"),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(128, activation=\"relu\"),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ]\n) \n```", "```py\ndeep_best_model = keras.models.load_model(best_model_path)\ndeep_pred_proba = deep_best_model.predict(normed_test_x).flatten() \n```", "```py\ngroup_a_indexes = sorted(list(np.random.choice(2000, 1000, replace=False)))\ngroup_b_indexes = [x for x in range(2000) if x not in group_a_indexes] \n```", "```py\ngroup_a_actuals = test_y.iloc[group_a_indexes].to_numpy()\ngroup_b_actuals = test_y.iloc[group_b_indexes].to_numpy()\ngroup_a_preds = []\ngroup_b_preds = []\nfor customer in range(2000):\n    if customer in group_a_indexes:\n        # route to XGBoost\n        conversion = test_y.iloc[customer]\n        pred_prob = xgb_model.predict_proba(\n            np.array([test_x.iloc[customer].to_numpy(),])\n        )[0][1]\n        pred = 1 if pred_prob > 0.5 else 0\n        group_a_preds.append(pred)\n    elif customer in group_b_indexes:\n        # route to Wide Net\n        conversion = test_y.iloc[customer]\n        pred_prob = wide_best_model.predict(\n            np.array([normed_test_x.iloc[customer].to_numpy(),]), verbose=0\n        )[0][0]\n        pred = 1 if pred_prob > 0.5 else 0\n        group_b_preds.append(pred) \n```", "```py\ndef get_cumulative_metrics(actuals, preds):\n    cum_conversions = []\n    missed_opportunities = []\n\n    customer_counter = 0\n    cum_conversion_count = 0\n    missed_opp_count = 0\n    for actual, pred in zip(actuals, preds):\n        customer_counter += 1\n        if pred == 1:\n            if actual == 1:\n                cum_conversion_count += 1\n        else:\n            if actual == 1:\n                missed_opp_count += 1\n        cum_conversions.append(cum_conversion_count/customer_counter)\n        missed_opportunities.append(missed_opp_count/customer_counter)\n    return cum_conversions, missed_opportunities \n```", "```py\na_cum_conv_rates, a_missed_opp_rates = get_cumulative_metrics(\n    group_a_actuals, group_a_preds\n)\nb_cum_conv_rates, b_missed_opp_rates = get_cumulative_metrics(\n    group_b_actuals, group_b_preds\n)\nab_results_df = pd.DataFrame({\n    \"group_a_cum_conversion_rate\": a_cum_conv_rates,\n    \"group_a_cum_missed_opportunity_rate\": a_missed_opp_rates,\n    \"group_b_cum_conversion_rate\": b_cum_conv_rates,\n    \"group_b_cum_missed_opportunity_rate\": b_missed_opp_rates,\n}) \n```", "```py\nax = (\n    ab_results_df[[\n        \"group_a_cum_conversion_rate\", \"group_b_cum_conversion_rate\"\n    ]]*100\n).plot(\n    style=['-', '--'],\n    figsize=(8, 5),\n    grid=True\n)\nax.set_ylabel(\"Conversion Rate (%)\")\nax.set_xlabel(\"Customer Count\")\nax.set_title(\n    \"Cumulative Conversion Rates over Time (A: XGBoost, B: Wide Net)\"\n)\nplt.show() \n```", "```py\nax = (\n    ab_results_df[[\n        \"group_a_cum_missed_opportunity_rate\",\n        \"group_b_cum_missed_opportunity_rate\"\n    ]]*100\n).plot(\n    style=['-','--'],\n    figsize=(8, 5),\n    grid=True\n)\nax.set_ylabel(\"Missed Opportunity Rate (%)\")\nax.set_xlabel(\"Customer Count\")\nax.set_title(\n    \"Cumulative Missed Opportunity Rates over Time (A: XGBoost, B: Wide Net)\"\n)\nplt.show() \n```", "```py\npip install scipy \n```", "```py\nfrom scipy.stats import ttest_ind\nt, p = ttest_ind(a_cum_conv_rates, b_cum_conv_rates)\nprint(\n    f\"Conversion Rate Difference Significance -- t: {t:.3f} & p: {p:.3f}\"\n)\nt, p = ttest_ind(a_missed_opp_rates, b_missed_opp_rates)\nprint(\n    f\"Missed Opportunity Rate Difference Significance -- t: {t:.3f} & p: {p:.3f}\"\n) \n```"]