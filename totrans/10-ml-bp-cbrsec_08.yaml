- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Attributing Authorship and How to Evade It
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The internet has provided the impetus to the fundamental right of freedom of
    expression by providing a public platform for individuals to voice their opinions,
    thoughts, findings, and concerns. Any person can express their views through an
    article, a blog post, or a video and post it online, free of charge in some cases
    (such as on Blogspot, Facebook, or YouTube). However, this has also led to malicious
    actors being able to generate misinformation, slander, libel, and abusive content
    freely. Authorship attribution is a task where we identify the author of a text
    based on the contents. Attributing authorship can help law enforcement authorities
    trace hate speech and threats to the perpetrator, or help social media companies
    detect coordinated attacks and Sybil accounts.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, individuals may wish to remain anonymous as authors. They
    may want to protect their identity to avoid scrutiny or public interest. This
    is where authorship obfuscation comes into play. Authorship obfuscation is the
    task of modifying the text so that the author cannot be identified with attribution
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Authorship attribution and obfuscation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Techniques for authorship attribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Techniques for authorship obfuscation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have an understanding of authorship attribution,
    the socio-technical aspects behind it, and methods to evade it.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%207](https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%207).
  prefs: []
  type: TYPE_NORMAL
- en: Authorship attribution and obfuscation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss exactly what authorship attribution is and
    the incentives for designing attribution systems. While there are some very good
    reasons for doing so, there are some nefarious ones as well; we will therefore
    also discuss the importance of obfuscation to protect against attacks by nefarious
    attackers.
  prefs: []
  type: TYPE_NORMAL
- en: What is authorship attribution?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Authorship attribution** is the task of identifying the author of a given
    text. The fundamental idea behind attribution is that different authors have different
    styles of writing that will reflect in the vocabulary, grammar, structure, and
    overall organization of the text. Attribution can be based on heuristic methods
    (such as similarity, common word analysis, or manual expert analysis). Recent
    advances in **machine learning** (**ML**) have also made it possible to build
    classifiers that can learn to detect the author of a given text.'
  prefs: []
  type: TYPE_NORMAL
- en: Authorship attribution is not a new problem—the study of this field goes back
    to 1964\. A series of papers known as *The Federalist Papers* had been published,
    which contained over 140 political essays. While the work was jointly authored
    by 3 people, 12 of those essays were claimed by 2 authors. The study by Mosteller
    and Wallace involving Bayesian modeling and statistical analysis using *n*-grams,
    which produced statistically significant differences between the authors, is known
    to be the first actual work in authorship attribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Authorship attribution is important for several reasons, as outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Historical significance**: Scientists and researchers rely on historical
    documents and texts for evidence of certain events. At times, these may have immense
    political and cultural significance, and knowing the author would help place them
    in the proper context and determine their credibility. For example, if an account
    describing certain historical periods and projecting dictators or known malicious
    actors in a positive light were to be found, it would be important to ascertain
    who the author is, as that could change the credibility of the text. Authorship
    attribution would help in determining whether the text could be accepted as an
    authoritative source or not.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Intellectual property**: As with *The Federalist Papers*, there is often
    contention on who the owner of certain creative or academic works is. This happens
    when multiple people claim ownership over the same book, article, or research
    paper. At other times, one individual may be accused of plagiarizing the work
    of another. In such cases, it is extremely important to trace who the author of
    a particular text is. Authorship attribution can help identify the author, match
    similarity in style and tone, and resolve issues of contended intellectual property.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Criminal investigation**: Criminals often use text as a means of communicating
    with victims and law enforcement. This can be in the form of a ransom note or
    threats. If there is a significant amount of text, it may be possible that it
    reflects some of the stylistic habits of the author. Law enforcement officers
    use authorship attribution methods to determine whether the messages received
    fit the style of any known criminal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Abuse detection**: Sybil accounts are a growing challenge on the internet
    and social media. These are a group of accounts controlled by the same entity
    but masquerading as different people. Sybil accounts have nefarious purposes such
    as multiple Facebook accounts generating fake engagement, or multiple Amazon accounts
    to write fake product reviews. As they are controlled by the same entity, the
    content produced (posts, tweets, reviews) is generally similar. Authorship attribution
    can be used to identify groups of accounts that post content written by the same
    author.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the prevalence of the internet and social media platforms, cybercrime has
    been on the rise, and malicious actors are preying on unknowing victims. Authorship
    attribution, therefore, is also a cybersecurity problem. The next section will
    describe authorship obfuscation, a task that counters authorship attribution.
  prefs: []
  type: TYPE_NORMAL
- en: What is authorship obfuscation?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we discussed authorship attribution, which is the task
    of identifying the author of a given text. Authorship obfuscation is a task that
    works exactly toward the opposite.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a text, authorship obfuscation aims to manipulate and modify the text
    in such a way that the end result is this:'
  prefs: []
  type: TYPE_NORMAL
- en: The meaning and key points in the text are left intact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The style, structure, and vocabulary are suitably modified so that the text
    cannot be attributed to the original author (that is, authorship attribution techniques
    will be evaded)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Individuals may use obfuscation techniques to hide their identity. Consider
    the sentence *“We have observed great corruption at the highest levels of government
    in this country.”* If this is re-written as *“Analysis has shown tremendous corrupt
    happenings in the uppermost echelons of this nation’s administration,”* the meaning
    is left intact. However, the style is clearly different and does not bear much
    resemblance to the original author. This is effective obfuscation. An analyst
    examining the text will not be easily able to map it to the same author.
  prefs: []
  type: TYPE_NORMAL
- en: Note that both of the objectives in obfuscation (that is, retaining the original
    meaning and stripping off the style markers) are equally important and there is
    a trade-off between them. We can obtain high obfuscation by making extreme changes
    to the text, but at that point, the text may have lost its original meaning and
    intent. On the other hand, we can retain the meaning with extremely minor tweaks—but
    this may not lead to effective obfuscation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Authorship obfuscation has both positive and negative use cases. Malicious
    actors can use obfuscation techniques in order to counter the attribution purposes
    discussed previously and avoid detection. For example, a criminal who wants to
    stay undetected and yet send ransom notes and emails may obfuscate their text
    by choosing a different vocabulary, grammatical structure, and organization. However,
    obfuscation has several important use cases in civil and human rights, as detailed
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Oppressive governments**: As discussed before, the internet has greatly facilitated
    the human right to freely express oneself. However, some governments may try to
    curtail these rights by targeting individuals who speak up against them. For example,
    an autocratic government may want to prohibit reporting on content that speaks
    against its agenda or expose corruption and malicious schemes. At such times,
    journalists and individuals may want to remain anonymous—their identity being
    detected could lead to them being captured. Obfuscation techniques will alter
    the text they write so that the matter they want to convey will be retained, but
    the writing style will be significantly different than their usual one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sensitive issues**: Even if the government is not oppressive by nature, certain
    issues may be sensitive to discuss and controversial. Examples of such issues
    include religion, racial discrimination, reports of sexual violence, homosexuality,
    and reproductive healthcare. Individuals who write about such issues may offend
    the public or certain other groups or sects. Authorship obfuscation allows such
    individuals to publish such content and yet remain anonymous (or, at least, makes
    it harder to discern the author of the text).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Privacy and anonymity**: Many believe that privacy is a fundamental human
    right. Therefore, even if an issue is not sensitive or the government is not corrupt,
    users have the right to protect their identity if they want to. Every individual
    should be free to post what they want and hide their identity. Authorship obfuscation
    allows users to maintain their privacy while expressing themselves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you have a good understanding of authorship attribution and obfuscation
    and why it is actually needed, let us go into implementing it with Python.
  prefs: []
  type: TYPE_NORMAL
- en: Techniques for authorship attribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous section described the importance of authorship attribution and
    obfuscation. This section will focus on the attribution aspect—how we can design
    and build models to pinpoint the author of a given text.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There has been prior research in the field of authorship attribution and obfuscation.
    The standard dataset for benchmarking on this task is the *Brennan-Greenstadt
    Corpus*. This dataset was collected through a survey at a university in the United
    States. 12 authors were recruited, and each author was required to submit a pre-written
    text that comprised at least 5,000 words.
  prefs: []
  type: TYPE_NORMAL
- en: A modified and improved version of this data—called the *Extended Brennan-Greenstadt
    Corpus*—was released later by the same authors. To generate this dataset, the
    authors conducted a large-scale survey by recruiting participants from Amazon
    **Mechanical Turk** (**MTurk**). MTurk is a platform that allows researchers and
    scientists to conduct human-subjects research. Users sign up for MTurk and fill
    out detailed questionnaires, which makes it easier for researchers to survey the
    segment or demographic (by gender, age, nationality) they want. Participants get
    paid for every **human interaction task** (**HIT**) they complete.
  prefs: []
  type: TYPE_NORMAL
- en: To create the extended corpus, MTurk was used so that the submissions would
    be diverse and varied and not limited to university students. Each piece of writing
    was scientific or scholarly (such as an essay, a research paper, or an opinion
    paper). The submission only contained text and no other information (such as references,
    citations, URLs, images, footnotes, endnotes, and section breaks). Quotations
    were to be kept to a minimum as most of the text was supposed to be author generated.
    Each sample had at least 500 words.
  prefs: []
  type: TYPE_NORMAL
- en: Both the *Brennan-Greenstadt Corpus* and the *Extended Brennan-Greenstadt Corpus*
    are available online to the public for free. For simplicity, we will run our experiments
    with the *Brennan-Greenstadt Corpus* (which contains writing samples from university
    students). However, readers are encouraged to reproduce the results on the extended
    corpus, and tune models as required. The process and code would remain the same—you
    would have to just change the underlying dataset.
  prefs: []
  type: TYPE_NORMAL
- en: For convenience, we have provided the dataset we're using ([https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/blob/main/Chapter%207/Chapter_7.ipynb](https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/blob/main/Chapter%207/Chapter_7.ipynb)).
    The dataset consists of a root folder that has one subfolder for every author.
    Each subfolder contains writing samples for the author. You will need to unzip
    the data and place it into the folder you want (and change `data_root_dir` in
    the following code accordingly).
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that for our experiments, we need to read the dataset such that the
    input (features) is in an array and the labels are in a separate array. The following
    code snippet parses the folder structure and produces data in this format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The dataset also contains some housekeeping files as well as some files that
    indicate the training, test, and validation data. We need a function to filter
    out these so that this information is not read in the data. Here’s what we’ll
    use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Our dataset has been read, and we can now extract features from it. For authorship
    attribution, most features are stylometric and hand-crafted. In the next section,
    we will explore some features that have shown success in prior work.
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now implement a series of functions, each of which extracts a particular
    feature from our data. Each function will take in the input text as a parameter,
    process it, and return the feature as output.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin as usual by importing the required libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As a first feature, we will use the number of characters in the input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will design a feature that measures the average word length (number
    of characters per word). For this, we first split the text into an array of words
    and clean it up by removing any special characters such as braces, symbols, and
    punctuation. Then, we calculate the number of characters and the number of words
    separately. Their ratio is our desired feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we calculate the frequency of alphabets. We will first create a 26-element
    array where each element counts the number of times that alphabet appears in the
    text. The first element corresponds to A, the next to B, and so on. Note that
    as we are counting alphabets, we need to convert the text to lowercase. However,
    if this were our feature, it would depend heavily on the length of the text. Therefore,
    we normalize this by the total number of characters. Each element of the array,
    therefore, depicts the percentage of that particular alphabet in the text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will calculate the frequency of common bigrams. Prior research in
    linguistics and phonetics has indicated which bigrams are common in English writing.
    We will first compile a list of such bigrams. Then, we will parse through the
    list and calculate the frequency of each bigram and compute a vector. Finally,
    we normalize this vector, and the result represents our feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Just as with the common bigrams, we also compute the frequency of common trigrams
    (sequences of three alphabets). The final feature represents a normalized vector,
    similar to what we had for bigrams:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The next feature is the percentage of characters that are digits. First, we
    calculate the total number of characters in the text. Then, we parse through the
    text character by character and check whether each character is numeric. We count
    all such occurrences and divide them by the total number we computed earlier—this
    gives us our feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the next feature is the percentage of characters that are alphabets.
    We will first need to convert the text to lowercase. Just as with the previous
    feature, we parse character by character, now checking whether each character
    we encounter is in the range `[a-z]`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Previously, we calculated the frequency of alphabets. On similar lines, we
    calculate the frequency of each digit from `0` to `9` and normalize it. The normalized
    vector is used as our feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now calculate the percentage of characters that are uppercase. We follow
    a similar procedure as we did for counting the characters, but now we count for
    capital letters instead. The result is normalized, and the normalized value forms
    our feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will calculate the frequency of special characters in our text. We
    first compile a list of special characters of interest in a file. We parse the
    file and count the frequency of each character and form a vector. Finally, we
    normalize this vector by the total number of characters. Note that the following
    function uses a static file where the list of characters is stored—you will need
    to change this line of code to reflect the path where the file is stored on your
    system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will count the number of short words in the text. We define a short
    word as one with fewer than or at most three characters. This is a rather heuristic
    definition; there is no globally accepted standard for a word being short. You
    can play around with different values here and see whether it affects the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'As a very simple feature, we compute the total number of words in the input.
    This involves splitting the text into an array of words (cleaning up special characters)
    and counting the length of the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we calculate the average word length. We simply calculate the length of
    each word in the text and use the mean of all such length values as the feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have all of the functions to compute features in place. Each function
    will take in the text as a parameter and process it to produce the feature we
    designed. Now, we will write a wrapper function to put it all together. This function,
    on being passed the text, will run it through all of our feature extraction functions
    and compute each feature. Each feature will be appended to a vector. This forms
    our final feature vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, all that is to be done is to apply this function to our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: After this is executed, `X` will be an array containing features that we designed,
    and `Y` will contain the corresponding labels. The hard part is done! Next, we
    will turn to the modeling phase.
  prefs: []
  type: TYPE_NORMAL
- en: Training the attributor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we processed our dataset, hand-crafted several features,
    and now have one feature vector per text and the ground-truth label corresponding
    to it. At this point, this is essentially a **supervised learning** (**SL**) problem;
    we have the features and labels and want to learn the association between them.
    We will approach this as we did with all other supervised problems we have seen
    so far.
  prefs: []
  type: TYPE_NORMAL
- en: 'To recap, here are the steps we’ll take:'
  prefs: []
  type: TYPE_NORMAL
- en: Split the data into training and testing sets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train a supervised classifier on the training set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the performance of the trained model on the testing set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, we split the data as follows. Note that we have a mix of authors, therefore
    we have multiple labels. We must ensure that the distribution of labels in the
    training and test sets is roughly similar; otherwise, our model will be biased
    toward specific authors. If a particular author does not appear in the training
    set, the model will not be able to detect them at all.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we train our classification model (logistic regression, decision tree,
    random forest, **deep neural network** (**DNN**)) on the training set. We use
    this model to make predictions for the data in the test set and compare the predictions
    with the ground truth. As this procedure has been covered in preceding chapters,
    we will not go into detailed explanations here.
  prefs: []
  type: TYPE_NORMAL
- en: 'A sample code snippet that performs the previous steps with a random forest
    is shown next. Readers should repeat it with other models as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As you run this, you will notice that the confusion matrix now looks different.
    Whereas previously we had a 2x2 matrix, now we get a 6x6 matrix. This is because
    our dataset now contains six different labels (one for every author). Therefore,
    for every data point with a given class, there are six possible classes to be
    predicted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculating accuracy is still the same; we need to find the fraction of examples
    that were predicted correctly. Here is a function that does this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In multi-class problems, the definitions of precision and recall are no longer
    as simple as computing false positives and negatives. Rather, these metrics are
    calculated per class. For example, if there are six labels (1-6), then for class
    2, we say the following:'
  prefs: []
  type: TYPE_NORMAL
- en: True positives are those where the actual and predicted classes are both 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: False positives are the ones where the predicted class is 2, but the actual
    class is anything other than 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: True negatives are those where both the actual and predicted classes are anything
    other than 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: False negatives are those where the predicted class is anything other than 2,
    but the actual class is 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using these definitions and the usual expressions for calculating metrics, we
    can calculate per-class metrics. The per-class precision and recall may be averaged
    to compute the overall precision, recall, and F1 scores.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, we do not need to manually implement this per-class metric calculation.
    `scikit-learn` has an inbuilt classification report that will compute and produce
    these metrics for you. This can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This completes our implementation and analysis of authorship attribution. Next,
    we will suggest some experiments that readers can pursue to explore the topic
    more.
  prefs: []
  type: TYPE_NORMAL
- en: Improving authorship attribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have presented vanilla models and techniques for authorship attribution.
    However, there is a large scope for improvement here. As data scientists, we must
    be willing to explore new ideas and techniques and continuously improve our models.
    Here are a few suggestions that readers should try out to see whether they can
    obtain a better performance.
  prefs: []
  type: TYPE_NORMAL
- en: Additional features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have used the feature set that is known as the Writeprints set of features.
    This has shown success in prior research. However, this is not an exhaustive list
    of features. Readers can explore more hand-crafted and automatic features to evaluate
    whether performance is improved. Examples of some features are set out here:'
  prefs: []
  type: TYPE_NORMAL
- en: Text sentiment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text polarity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number and fraction of function words
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Term Frequency – Inverse Document Frequency** (**TF-IDF**) features'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Word embeddings derived from Word2vec
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contextual word embeddings derived from **Bidirectional Encoder Representations
    from** **Transformers** (**BERT**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data configurations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The experiment we ran was on a subset of six authors from the dataset. In the
    real world, the problem is much more open-ended and there may be several more
    authors. It is worth exploring how the model performance varies as the number
    of authors changes. In particular, readers should explore the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the performance measures if we choose only 3 authors? What about if
    we choose 12?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does the performance change if we model this problem as binary classification?
    Instead of predicting the author, we predict whether a particular text was written
    by a particular author or not. This would involve training a separate classifier
    per author. Does this show better predictive power and practical application than
    the multi-class approach?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model improvements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For brevity and to avoid repetition, we showed only the example of a random
    forest. However, readers should experiment with more models, including but not
    limited to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support vector** **machines** (**SVMs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naïve-Bayes classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DNN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **neural network** (**NN**) algorithms will be particularly useful as the
    number of features increases. When the embeddings and TF-IDF scores are added,
    the features will not be easily interpretable anymore—NNs excel in such situations
    where they can discover high-dimensional features.
  prefs: []
  type: TYPE_NORMAL
- en: This completes our discussion of authorship attribution. In the next section,
    we will discuss a problem that is the opposite of the attribution task.
  prefs: []
  type: TYPE_NORMAL
- en: Techniques for authorship obfuscation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen how authorship can be attributed to the writer and how
    to build models to detect the author. In this section, we will turn to the authorship
    obfuscation problem. Authorship obfuscation, as discussed in the initial section
    of this chapter, is the art of purposefully manipulating the text to strip it
    of any stylistic features that might give away the author.
  prefs: []
  type: TYPE_NORMAL
- en: The code is inspired by an implementation that is freely available online ([https://github.com/asad1996172/Obfuscation-Systems](https://github.com/asad1996172/Obfuscation-Systems))
    with a few minor tweaks.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will import the required libraries. The most important library here
    is the **Natural Language Toolkit** (**NLTK**) library ([https://www.nltk.org/](https://www.nltk.org/))
    developed by Stanford. This library contains standard off-the-shelf implementations
    for several **natural language processing** (**NLP**) tasks such as tokenization,
    **part-of-speech** (**POS**) tagging, **named entity recognition** (**NER**),
    and so on. It has a powerful set of functionalities that greatly simplify feature
    extraction in text data. You are encouraged to explore the library in detail.
    The **word-sense disambiguation** (**WSD**) implementation ([https://github.com/asad1996172/Obfuscation-Systems/blob/master/Document%20Simplification%20PAN17/WSD_with_UKB.py](https://github.com/asad1996172/Obfuscation-Systems/blob/master/Document%20Simplification%20PAN17/WSD_with_UKB.py))
    can be found online and should be downloaded locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code to import the libraries is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we will implement a function for the expansion and contraction replacement.
    We begin by reading the extraction-contraction list from the `pickle` file (you
    will have to change the path to it accordingly). The result is a dictionary where
    the keys are contractions and values associated are corresponding expansions.
    We parse through the sentence and count the expansions and contractions occurring.
    If there are mostly contractions, we replace them with expansions, and if there
    are mostly expansions, we replace them with contractions. If both are the same,
    we do nothing at all:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will remove any parentheses occurring in the text. This means that
    we have to search for characters associated with brackets—`(, ), [, ], {, }`—and
    remove them from the text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We will implement a function to purge discourse markers from the text. We will
    first read a list of discourse markers (you will need to change the filename and
    path, depending on how you have saved it locally). We then iterate through the
    list and remove each item from the text, if found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will implement a function to remove appositions from the text. We
    will use **regular expression** (**regex**) matching for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now implement a function to change expressions of possession. We will
    first use regex matching to find expressions of the form “X of Y.” We will then
    replace this with “Y’s X.” For example, “book of Jacob” will become “Jacob’s book.”
    Note that we are not making this replacement deterministically. We will randomly
    choose whether to replace or not (biased with the probability of replacement being
    2/3):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will apply equation transformation where we will replace mathematical
    expressions with their textual representations. We will define a dictionary where
    common symbols and their text representations are defined (such as “+” translating
    to “plus” and "*" translating to “multiplied by”). Then, we will find occurrences
    of each symbol in the text and make the necessary replacements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is synonym replacement. However, as a helper function for synonym
    replacement, we need a function for *untokenization*. This is the exact opposite
    of tokenization and can be done with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will implement the actual synonym substitution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will put all of this together in a wrapper function. This function
    will take in the text and apply all of our transformations (contraction-expansion
    replacement, parenthesis removal, discourse and apposition removal, synonym replacement,
    equation transformation, and possessive transformation) to each sentence of the
    text, and then join the sentences back to form the obfuscated text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We now will test how effective this obfuscation is. We will train a vanilla
    model and then test it on the obfuscated data. This mirrors exactly the threat
    model that would occur in the real world; at the time of training, we would not
    have access to the obfuscated data. Here is the process we will follow in order
    to evaluate the model:'
  prefs: []
  type: TYPE_NORMAL
- en: Split the data into training and test sets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract features from the training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train an authorship attribution ML model based on these features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the obfuscator on the test data to transform the raw text into obfuscated
    text.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract features from the obfuscated text and use them to run inference on the
    previously trained model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We load the data and split it as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we extract features and train a model. Note that we extract features
    only from the training data, not the test data (which we need to obfuscate):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will obfuscate the test data using the functions we defined earlier,
    and then extract features from the obfuscated version of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can run inference on the trained model using the newly generated
    (obfuscated) data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Comparing the two values of accuracy should give you the performance degradation
    caused due to the obfuscation. The first calculated value represents the accuracy
    of the original data, and the second one represents the accuracy of the model
    when our obfuscation tactics are applied. When the second value is lower than
    the first, our obfuscation has been successful.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will provide an overview of some strategies to improve the performance
    of our obfuscators.
  prefs: []
  type: TYPE_NORMAL
- en: Improving obfuscation techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, we describe potential changes and improvements that can help us achieve
    a better performance of our obfuscator. Readers are highly encouraged to experiment
    with these to examine which ones show the best performance.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced manipulations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In our example obfuscator, we implemented basic obfuscation tactics such as
    the replacement of synonyms, changing of contractions, removing parentheses, and
    so on. There is a vast arena of features that can be manipulated here. A few possibilities
    are given next:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Antonym replacement**: Replacing words with the negation of their antonyms.
    For example, *good* is replaced by *not bad*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Function word manipulation**: Adding extra helper words at the beginning
    of sentences, or removing existing words that add no value. For example, *“Thus,
    we have shown that the plan works”* becomes *“We have shown that the* *plan works.”*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Punctuation manipulation**: Adding punctuation symbols (two question marks,
    two exclamation marks, trailing periods) or removing existing ones. This may affect
    the grammar and structure of the sentence, which may or may not be acceptable
    depending on your use case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recent advances such as transformers and the attention mechanism have led to
    the development of several improved language models, which have excellent text-generation
    capabilities. Such models can be used to generate obfuscated text. An example
    is using a transformer-based document summarizer as an obfuscator. The summarizer
    aims to reproduce the text in the original document in a short and concise manner.
    The hope is that in doing so, it will strip off the stylistic features from the
    text. Readers are encouraged to experiment with various summarization models and
    compare the accuracy before and after obfuscation. Note that it is also important
    to check the similarity of the text against the original in terms of meaning.
  prefs: []
  type: TYPE_NORMAL
- en: This completes our discussion of authorship obfuscation models!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter focused on two important problems in security and privacy. We began
    by discussing authorship attribution, a task of identifying who wrote a particular
    piece of text. We designed a series of linguistic and text-based features and
    trained ML models for authorship attribution. Then, we turned to authorship obfuscation,
    a task that aims to evade the attribution models by making changes to the text
    such that author-identifying characteristics and style markers are removed. We
    looked at a series of obfuscation methods for this. For both tasks, we looked
    at the improvements that could be made to the performance.
  prefs: []
  type: TYPE_NORMAL
- en: Both authorship attribution and obfuscation have important applications in cybersecurity.
    Attribution can be used to detect Sybil accounts, trace cybercriminals, and protect
    intellectual property rights. Similarly, obfuscation can help preserve the anonymity
    of individuals and provide privacy guarantees. This chapter enables ML practitioners
    in cybersecurity and privacy to effectively tackle these two tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In the next one, we will change tracks slightly and look at how fake news can
    be detected using graph ML.
  prefs: []
  type: TYPE_NORMAL
