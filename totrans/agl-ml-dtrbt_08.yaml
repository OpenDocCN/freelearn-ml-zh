- en: '*Chapter 6*: Model Building with DataRobot'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will see how DataRobot is used to build models. Much of
    the model-building process has been automated, and DataRobot offers many capabilities
    to explore a wide range of algorithms automatically, as well as allowing data
    scientists to fine-tune what they want to build. This results in significant time
    savings for data science teams and leads to the exploration of many more models
    than would otherwise be possible. It also leads to better adherence to best practices
    and hence fewer chances of making mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will have learned how to utilize DataRobot
    to build a wide range of models. In this chapter, we''re going to cover the following
    main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a modeling project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building models and the model leaderboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding model blueprints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building ensemble models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring a modeling project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we created a project and performed data analysis. We
    also saw that DataRobot automatically built several models for us. To build these
    models, we used default project settings.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will cover what DataRobot did for us by default and look
    at how we can fine-tune that behavior. If you remember, once we click the **Start**
    button on the project page (see *Figure 5.1* in [*Chapter 5*](B17159_05_Final_NM_ePub.xhtml#_idTextAnchor097),
    *Exploratory Data Analysis with DataRobot*), we cannot make any changes to the
    project options. We will therefore create a new project to review and select the
    options we want.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, let''s go into DataRobot and select the `Automobile Example 2`, as
    illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Uploading the dataset for a new project'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.1_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 – Uploading the dataset for a new project
  prefs: []
  type: TYPE_NORMAL
- en: 'You can select the same target feature (price) as we did previously. Now, instead
    of clicking the **Start** button, please click on **Show advanced options** at
    the bottom of the screen. You will now see the **Advanced Options** screen, as
    illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Advanced Options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.2_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.2 – Advanced Options
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you can see the partitioning options. You can see the default settings
    and can change them as needed. Since the amount of data we have is very limited,
    I have reduced the number of cross-validation folds to `3` and the holdout percentage
    to 15%. You can easily change these values and run with a different setup as needed.
    Next, we click on the **Smart Downsampling** tab, as illustrated in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Smart Downsampling'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.3_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.3 – Smart Downsampling
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that this is not a classification problem, we need not worry about downsampling
    here. If you have an imbalanced dataset for a classification problem, you can
    use this option to downsample. Let''s now look at the **Feature Constraints**
    tab, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Feature Constraints'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.4_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.4 – Feature Constraints
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you can set up constraints on features such as monotonicity—that is,
    whether the target values move in the same direction as the value of a feature
    increases. At this point, we do not foresee a need to set such constraints. Such
    constraints could be part of regulatory requirements in certain use cases. If
    they are, they can be specified here. Most use cases do not require such a constraint.
    Let''s now click on the **Additional** tab, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Additional options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.5_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.5 – Additional options
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we see an option to change the **optimization metric** to be used for
    modeling. I have found DataRobot''s recommendations to be very good and you should
    use this option unless you have a compelling business reason to select a different
    metric. Given that we are in the early stages of modeling and we are interested
    in understanding our data, we will select the **Search for interactions** option,
    unselect the **Create blenders from top models** option, and select the **Include
    only models with SHAP value support** option. As discussed in [*Chapter 2*](B17159_02_Final_NM_ePub.xhtml#_idTextAnchor039),
    *Machine Learning Basics*, **SHapley Additive exPlanations** (**SHAP**) values
    are helpful for understanding the models and will provide additional insights
    into our problem. This might come at the cost of model accuracy, but we will worry
    about improving accuracy later. If you scroll down further on this page, you will
    see even more options, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – More options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.6_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.6 – More options
  prefs: []
  type: TYPE_NORMAL
- en: Here, you can set options to place an upper bound on running time, cap the value
    of target variable predictions, set a random seed, or add a weighting for a specific
    feature. For now, we do not see a need to change any of these defaults.
  prefs: []
  type: TYPE_NORMAL
- en: This completes the configuration process, and we are now ready to build the
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Building models and the model leaderboard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we are done making any changes to the configuration settings, we can scroll
    up and click the **Start** button. DataRobot will now start automatically building
    the models, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Automated building of models'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.7_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.7 – Automated building of models
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see which models DataRobot is building and how much training data is
    being used. You will notice that DataRobot will first build quick models with
    smaller datasets, learn which one performs better, and then selectively build
    models with more data. In the present case, you might not see this because there
    is very little data to begin with. Once DataRobot is done building the models,
    it will show the model leaderboard, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Model leaderboard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.8_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.8 – Model leaderboard
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding screenshot, you will see which models rise to the top based
    on the metric you have selected for cross-validations. You can also choose different
    metrics from the dropdown to see how the models compare for different metrics.
    You can clearly see which models rose to the top. It is not uncommon to see gradient
    boosted models in the top tier. You will also notice that the model rankings change
    a bit based on the metric selected. You will see that once DataRobot has selected
    a model for deployment, it has unlocked the holdout results and trained the model
    with 100% data to prepare for deployment. For now, we will ignore that as we are
    not yet ready to discuss deployment. Another thing to notice is the feature list
    used for the top models. You will see that a new **Informative Features +** feature
    list has been used. This is a feature list that DataRobot created for these models.
    Let''s take a look at what this list contains, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – New feature list'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.9_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.9 – New feature list
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, this list contains a subset of the features, and it also contains
    a new feature that DataRobot created automatically: `(bore) DIVIDED BY (length)`.
    This ratio might have significance for an engine, and you should discuss its role
    with **subject-matter experts** (**SMEs**). If not previously known, this could
    represent a new insight for your business team. It turns out that this is called
    **stroke ratio** and is considered an important parameter for engines. The next
    step in the modeling process is to see if there is a need to further refine this
    feature list. Let''s go back to the model leaderboard, select the top-performing
    model **eXtreme Gradient Boosted Trees Regressor (Gamma Loss)**, go to the **Understand**
    tab and select the **Feature Impact** sub-tab, as illustrated in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Understand and Feature Impact tabs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.10_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.10 – Understand and Feature Impact tabs
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see that feature impacts are not computed for every model, so go ahead
    and click on the **Enable Feature Impact** button to let DataRobot compute it.
    Once clicked, DataRobot will start computing the impacts and show you the results,
    as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.11 – Feature impacts'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.11_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.11 – Feature impacts
  prefs: []
  type: TYPE_NORMAL
- en: 'You will notice that the feature impacts are computed using SHAP values, which
    we discussed previously. By default, it shows the top 25 features. We will discuss
    the details of the features and the model later on. For now, we want to look at
    the entire feature set. For this, we will click on the **Export** button in the
    bottom-right corner. We will now see the **Export** option, as illustrated in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Exporting feature impacts'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.12_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.12 – Exporting feature impacts
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download this information as a `.csv` file to explore it in more detail.
    Let''s use Excel to open the `.csv` file to review the feature impacts, as illustrated
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.13 – Feature impacts of the entire set'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.13_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.13 – Feature impacts of the entire set
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the last seven features don''t add much, and we can try removing
    them and see the impact. One of the benefits of a tool such as DataRobot is that
    running these experiments is very quick and easy. Now that we know what we want
    to do, let''s go back to the **Feature Impact** screen. Notice the **+ Create
    feature list** button on the bottom left. Clicking on that button brings up a
    dialog box for creating a new feature list, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14 – Creating a new feature list'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.14_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.14 – Creating a new feature list
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can give the feature list a new name, `FL1 top23`, and specify that
    we want the 23 best features. Now, we can click the **Create feature list** button
    to save this new feature list. Now that a new feature list has been created, we
    can now click on **Configure Modeling Settings** in the column on the right side
    of the page. This will bring up the configuration dialog box, as illustrated in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15 – Configure Modeling Settings'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.15_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.15 – Configure Modeling Settings
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now select the new feature list, `FL1 top23`, from the dropdown. We
    can modify the other settings if we need and click the **Run** button. DataRobot
    will now start building models with the new feature list and when the process
    completes, you can see the new models in the leaderboard, as illustrated in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16 – Leaderboard with new models'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.16_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.16 – Leaderboard with new models
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the model built with the new feature list did better and is
    now at the top of the leaderboard (ignore the deployment-ready model, as it uses
    the entire dataset). As we can see, removing features that did not contribute
    much actually helped the model (even if just a little). Given that this model
    uses a smaller set of features, it is a more desirable model. We can continue
    this process as needed. At this point, we also start looking more deeply at the
    model's details and the results it is producing. We will come back to that topic
    in the next chapter. For now, we want to look at the model blueprints or the steps
    DataRobot takes to build a model.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding model blueprints
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DataRobot performs a lot of data transformations and hyperparameter tuning
    while building a model. It leverages a lot of best practices to build a specific
    type of model, and these best practices are codified in the form of blueprints.
    You can inspect these blueprints to gain insights into these best practices and
    also to better understand which steps were taken to build a model. To inspect
    the blueprint for a model, you can click on a model, go to the **Describe** tab,
    and then select the **Blueprint** tab, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.17 – Model blueprint'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.17_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.17 – Model blueprint
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you can see the workflow steps. As you can see, this blueprint is fairly
    simple. This is because gradient boost methods are very flexible and do not require
    a lot of preprocessing. Let''s look at another model that did pretty well, the
    **Generalized Additive2 Model (Gamma Loss)** blueprint, as illustrated in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.18 – Model blueprint for Generalized Additive2 Model (Gamma Loss)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.18_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.18 – Model blueprint for Generalized Additive2 Model (Gamma Loss)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you can see that preprocessing was required for categorical variables
    and also for missing values. Let''s now look at another blueprint for a **deep
    learning** (**DL**) model. Select the **Keras Slim Residual Neural Network Regressor
    using Training Schedule** model and select the **Blueprint** tab, as illustrated
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19 – Model blueprint for Keras'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.19_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.19 – Model blueprint for Keras
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see that for Keras, we need to perform data cleansing, scaling, and
    one-hot encoding for categorical variables. You can inspect the details of each
    of these steps by clicking on the model box, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20 – Process step details'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.20_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.20 – Process step details
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now see an explanation of which tasks were performed and which hyperparameter
    settings were used for building the model. There is also a link to additional
    details about the method used. After inspecting the blueprints, you might see
    that one of your favorite algorithms was not used by DataRobot, and you might
    wonder what the performance of that algorithm or model might look like. To do
    this, you can click on the **Repository** tab at the top left of the page, as
    illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.21 – Repository of blueprints'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.21_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.21 – Repository of blueprints
  prefs: []
  type: TYPE_NORMAL
- en: Here, you will see all the blueprints DataRobot has to offer that are relevant
    to this project. As you can see, this is a pretty comprehensive list. Please note
    that this list will vary for projects of different types (for example, a time-series
    project). You can select any one of these blueprints and build a model. The new
    model will be shown on the leaderboard, where you can assess its relative performance.
    For now, we are not interested in doing that for this particular project.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are interested at this point in comparing some of the models to see how
    well they compare at a more detailed level. For this, let''s click on the rightmost
    tab at the top, called **Model Comparison**. This brings up a page where you can
    select any two models to see how they match up, as illustrated in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.22 – Model Comparison'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.22_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.22 – Model Comparison
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we have selected the XGBoost model and the **generalized additive model**
    (**GAM**) model for comparison across multiple metrics. We can see that the two
    models are not too far apart, and you can select either one depending on other
    factors. As we discussed previously, GAMs have the advantage of being easy to
    explain to business users and can be presented as a factor **lookup table** (**LUT**),
    sometimes called a rating table. There might also be regulatory reasons to select
    a GAM model. Let''s explore a bit further by clicking on the **Compute dual lift
    data** button, to take us to the following screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.23 – Dual lift chart'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.23_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.23 – Dual lift chart
  prefs: []
  type: TYPE_NORMAL
- en: '**Dual lift charts** are used to compare the results of two models. For a dual
    lift chart, the results are sorted by the difference between the two models as
    opposed to the target value. The values are then binned to display the results
    for each bin. The shaded area depicts the difference between the two models. Here,
    again, we see that the two models are very similar in their performance.'
  prefs: []
  type: TYPE_NORMAL
- en: If two models have overall good scores but show large deviations in values in
    this chart, then these models will be good candidates for creating an ensemble
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Building ensemble models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is well known that ensembles of models tend to perform better and also tend
    to be more robust. DataRobot provides the capability to automatically build ensemble
    models; however, this does require some trade-offs. For example, ensemble models
    take more time and computational resources to build and deploy, and they also
    tend to be more opaque. This is the reason we did not start off by building ensemble
    models. Once you have built several models and you are interested in ways of improving
    your model accuracy, you can decide to build ensembles. As we saw in the previous
    sections, we have to explicitly select the option to build ensembles, and that
    also means that we cannot compute SHAP values. Let''s look at how this is done.
    Let''s first go to the project list page, which shows all of your current projects,
    as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.24 – Project list'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.24_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.24 – Project list
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will select the `Automobile Example 2`. From the menu, we will select
    the **Duplicate** option. You will now see the **Duplicate** dialog box, as illustrated
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.25 – Duplicating a project'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.25_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.25 – Duplicating a project
  prefs: []
  type: TYPE_NORMAL
- en: 'We can give it a new name, `Automobile Example 3`, and we will select **Copy
    dataset only**. This way, we can apply new project settings. Let''s click **Confirm**.
    This will create a new project. We can select the target as price, and now we
    click on the **Advanced Options** tab, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.26 – Advanced options for ensembles (blenders)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.26_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.26 – Advanced options for ensembles (blenders)
  prefs: []
  type: TYPE_NORMAL
- en: 'This time, we will select the **Create blenders from top models** option and
    uncheck the **Include only models with SHAP value support** option. Now, we can
    click the **Start** button to let DataRobot build the models. Once DataRobot has
    finished building the models, we can inspect the leaderboard, as illustrated in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.27 – Leaderboard with ensemble models'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.27_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.27 – Leaderboard with ensemble models
  prefs: []
  type: TYPE_NORMAL
- en: 'You will notice the DataRobot has built an **AVG Blender** model that seems
    to be the top model, but not by much. Blended models can sometimes produce substantial
    lift over individual models, so it is worthwhile exploring this option. We can
    select this model and click on the **Describe** tab and then the **Blueprint**
    tab, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.28 – Blueprint for AVG Blender'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_6.28_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.28 – Blueprint for AVG Blender
  prefs: []
  type: TYPE_NORMAL
- en: We can now see that the blender has selected two XGBoost models, and hence it
    is not surprising that the lift is not much better. In this case, we will not
    select the blended model, and we go back to the previous project.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to build and compare models by leveraging DataRobot's
    capabilities. As you saw, DataRobot makes it very easy to build many models quickly
    and helps us compare those models. As you experienced, we tried many things and
    built dozens of models. This rapid model exploration is DataRobot's key capability,
    and its importance to a data science team cannot be overstated. If you were to
    build these models on your own in Python, it would have taken a lot more time
    and effort. Instead, we used that time and thinking to experiment with different
    ideas and put more energy toward understanding the problem. We also learned about
    blueprints that encode best practices. These blueprints can be useful learning
    tools for new and experienced data scientists alike. We also learned how DataRobot
    can build ensemble or blended models for us.
  prefs: []
  type: TYPE_NORMAL
- en: It might be tempting to jump ahead and start deploying one of these models,
    but it is important to not directly jump into that without doing some analysis.
    We are now ready to dig deeper into the models, understand them, and see if we
    can gain more insights from them.
  prefs: []
  type: TYPE_NORMAL
