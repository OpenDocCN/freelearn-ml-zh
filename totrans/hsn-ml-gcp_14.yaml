- en: Time Series with LSTMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In many situations involving multiple fields of real life, the need to plan
    future actions arises. **Forecasting** is an important tool for efficient planning.
    Moreover, this tool makes the decision-maker less susceptible to unexpected events
    because it requires a more scientific approach to the knowledge of the environment
    in which it operates. Often, the planning of future action arises from the analysis
    of data accumulated over time to extract information for the characterization
    of the phenomenon under observation.
  prefs: []
  type: TYPE_NORMAL
- en: 'A chronological recording of events gives rise to a new type of act, which
    is precisely called a **time series**. A time series constitutes a sequence of
    observations on a phenomenon carried out in consecutive instants or time intervals.
    Usually, even if not necessarily, they are evenly spaced or of the same length.
    Time series prediction requires the neural network to have some sort of memory
    on the sequence of data. Specific architectures called **Long Short-Term Memory**
    (**LSTM**) network, are well suited for time series analysis. In this chapter
    we show how to create and train our own LSTMs using Keras on GCD and apply them
    to predicting financial time series. We''ll discover the most used modeling approaches:
    **autoregressive** (**AR**), **moving average** (**MA**), **autoregressive moving
    average** (**ARMA**), and **autoregressive integrated moving average** (**ARIMA**).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics covered in this chapter are:'
  prefs: []
  type: TYPE_NORMAL
- en: Classical approach to time series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series decomposition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LSTM for time series analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of the chapter, we will be able to deal with problems regarding time
    series. We will know how to identify the different components of a time series,
    trend seasonality and residual, as well as eliminate seasonality to make predictions
    easier to understand. Finally, we will understand how to implement a recurring
    LSTM network with a practical example.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing time series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A time series constitutes a sequence of observations on a phenomenon *y* carried
    out in consecutive instants or time intervals that are usually, even if not necessarily,
    evenly spaced or of the same length. The trend of commodity prices, stock market
    indices, the BTP/BUND spread, and the unemployment rate are just a few examples
    of times series.
  prefs: []
  type: TYPE_NORMAL
- en: Contrary to what happens in classical statistics, where it is assumed that an
    independent observations come from a single random variable, in a time series,
    it is assumed that there are n observations coming from as many dependent random
    variables. The inference of the time series is thus configured as a procedure
    that attempts to bring the time series back to its generating process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The time series can be of two types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deterministic**: If the values of the variable can be exactly determined
    on the basis of the previous values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stochastic**: If the values of the variable can be determined on the basis
    of the previous values only partially'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The majority of time series are stochastic, and therefore it is impossible to
    draw up forecasts without errors. It is generally assumed that an observed time
    series is the result of the composition of these two components. The two sequences
    are not individually observable but must be determined on the basis of a sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'We indicate the series as the sum of these two contributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y[t] = f(t) + w(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: According to the classical approach to time series, it is assumed that there
    exists a law of temporal evolution of the phenomenon, represented by *f(t)*. The
    random component *w(t)* is assumed to represent the set of circumstances, each
    of negligible entities, which we do not want or cannot consider in *Y[t]*.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the residual part of *Y[t]*, not explained by *f(t)*, is imputed
    to the case and assimilated to a set of accidental errors. This is equivalent
    to hypothesizing that the stochastic component *w(t)* is generated by a white
    noise process, that is, by a sequence of independent and identically distributed
    random variables of zero mean and constant variance. In summary, in the classic
    approach, the attention is concentrated on *f(t)**,* being *w(t)* considered a
    process with uncorrelated components and therefore negligible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Denoting the time with *t = 1…. T*, we will indicate this sequence *y[t]*;
    time is the parameter that determines the sequence of events that cannot be neglected,
    so we also need to know the position of observation along the temporal dimension.
    Generally, it is used to represent the pair of values ​​*(t, y[t])* on a Cartesian
    diagram with a continuous line graph as if the phenomenon were detected continuously.
    This graph is called a **time series plot**. In the following graph, we see a
    time series plot of the flow of the river Nile at Aswan from 1871 to 1970:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d67c0c49-def5-4e0f-a85a-645ed7397742.png)'
  prefs: []
  type: TYPE_IMG
- en: A time series plot immediately reveals trends or regular oscillations, and other
    systematic trends over time. The previous graph shows annual data in a systematically
    decreasing trend over the long term. In particular, it has a zigzag pattern; since
    the data is monthly, there is the phenomenon called **seasonality**. It can be
    noted that high peaks are always recorded in those months when rains are expected.
  prefs: []
  type: TYPE_NORMAL
- en: The univariate analysis of the time series proposes to interpret the dynamic
    mechanism that generated the series, and to foresee future realizations of the
    phenomenon. In these operations, the information that is exploited regards only
    the couple *(t; Y[t])*, where *t = 1,…, T*. The fundamental point is that the
    past and the present contain relevant information to predict the future evolution
    of the phenomenon.
  prefs: []
  type: TYPE_NORMAL
- en: It can be considered that univariate analysis is too restrictive; we usually
    have information on phenomena related to the one to be forecast, which should
    be appropriately incorporated in order to improve the performance of the model
    of revision. Nonetheless, it is a useful benchmark that allows validation more
    sophisticated alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a time series plot, four types of patterns can be identified with respect
    to time:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Horizontal pattern**: In this case, the series oscillates around a constant
    value (series average). This series is called **stationary** on **average**. This
    is the typical case that occurs in quality control when the process is kept under
    control with respect to the average.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Seasonal pattern**: This exists when the series is influenced by seasonal
    factors (example, monthly, semi-annual, quarterly, and so on). Products such as
    ice cream, soft drinks, electricity consumption are subject to the seasonal phenomenon.
    The series influenced by seasonality are also called **periodic series** since
    the seasonal cycle repeats itself in a fixed period. In the annual data, seasonality
    is not present.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cyclic pattern**: This type of trend is present when the series has increases
    and decreases that are not of fixed period. This is the main difference between
    cyclical and seasonal fluctuations. Moreover, the amplitude of cyclical oscillations
    is generally larger than that due to seasonality. In economic series, the cyclical
    pattern is determined by the expansions and contractions of the economy due to
    conjectural phenomena.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trend or underlying trend**: It is characterized by an increasing or decreasing
    long-term trend. The series of the world resident population is an example of
    an increasing trend; the series of monthly beer sales, on the other hand, does
    not show any trend. It has a horizontal background pattern.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many series highlight a combination of these patterns. It is precisely this
    kind of complexity that makes the forecasting operation extremely interesting.
    The forecasting methods, in fact, must be able to recognize the various components
    of the series in order to reproduce them in the future, in the hypothesis that
    the past pattern continues to repeat itself in its evolutionary characteristics
    also in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'The classic approach to time series is based on the decomposition of the deterministic
    part of the series into a set of signal components (which express the structural
    information of the series) with respect to the negligible part of noise. In practice,
    we will try to identify some of the patterns that we have previously listed in
    the time series trend. The following figure shows a time series with some components
    identified:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/69e99378-6407-4224-a3d5-4d085775b33c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the previous figure, the components we have identified are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trend**: It is the underlying trend of the phenomenon considered, referring
    to a long period of time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Seasonal**: This consists of movements of the phenomena during the year.
    Due to the influence of climatic and social factors, they tend to repeat themselves
    in a similar way in the same period (for example, month, quarter, and so on).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Residual**: In the time series models, there is never a perfect relation
    between the variable under observation and the different components. The accidental
    component takes into account this and the unpredictable behavior of economic agents,
    social, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we can say that by adopting this approach a time series can be seen
    as the sum of the three components just analyzed (additive method).
  prefs: []
  type: TYPE_NORMAL
- en: Classical approach to time series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far we have dealt with time series according to a classic approach to the
    topic. In this perspective, the classic models that try to simulate the phenomenon
    can be of two types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Composition models**: The elementary components are known, and, by assuming
    a certain form of aggregation, the resulting series is obtained'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decomposition models**: From an observed series is hypothesized the existence
    of some elementary trends of which we want to establish the characteristics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The decomposition models are the most used in practice, and, for this reason,
    we will analyze them in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'The components of a time series can be aggregated according to different types
    of methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Additive method**: *Y(t) = τ(t) + C(t) + S(t) + r(t)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiplicative method**: *Y(t) = τ(t) * C(t) * S(t) * r(t)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mixed method**: *Y(t) = τ(t) * C(t) + S(t) * r(t)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In these formulas, the factors are defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y(t)* represents the time series'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*τ(t)* represents the trend component'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*C(t)* represents the cyclic component'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*S(t)* represents the seasonality component'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*r(t)* represents the residual component'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The multiplicative model can be traced back to the additive model through a
    logarithmic transformation of the components of the series:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y(t) = τ(t) * C(t) * S(t) * r(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This formula, by applying the logarithm function to all factors, becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '*lnY(t) = lnτ(t) + lnC(t) + lnS(t) + lnr(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: Estimation of the trend component
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Estimation of the trend component can occur in two different modes depending
    on the linear/non-linear characteristic.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the series trend is linear or linearizable in the parameters through a logarithmic
    transformation, then these trends can be estimated through the procedures derived
    from linear regression. We can hypothesize a polynomial trend that can be represented
    by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*τ (t) = α[0] + α[1] t + α[2] t[2] + ... + α[q] t[q] + εt*'
  prefs: []
  type: TYPE_NORMAL
- en: In this formula, *q* represents the degree of the polynomial.
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on the value assumed by *q*, the following cases can be represented:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **q** | **Cases** |'
  prefs: []
  type: TYPE_TB
- en: '| *0* | A constant trend is obtained |'
  prefs: []
  type: TYPE_TB
- en: '| *1* | We obtain a linear trend |'
  prefs: []
  type: TYPE_TB
- en: '| *2* | We obtain a parabolic trend |'
  prefs: []
  type: TYPE_TB
- en: On the contrary, the presence of a non-linear trend makes it difficult, if not
    impossible, to identify a known functional form *f(t)* with which to express the
    trend component.
  prefs: []
  type: TYPE_NORMAL
- en: In these cases, the MA instrument is used. MA is an arithmetic mean (simple
    or weighted) that moves to each new iteration (at any time *t*) from the beginning
    to the end of the data sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we have *n* data terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '*a1, a2, a3, ..., a^((n-1)), a^n*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following procedure is adopted:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we calculate the average of the first three data and substitute the average
    value for the central data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we repeat the procedure with the second three data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The procedure is exhausted when there is no more data available
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the case considered, the MA is composed of only three data. The MA order
    can be extended to 5, 7, 9, and so on. In order for the MA to be centered with
    respect to the available data, the order must be odd.
  prefs: []
  type: TYPE_NORMAL
- en: Estimating the seasonality component
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The study of the seasonality of a historical series can have the purpose of:'
  prefs: []
  type: TYPE_NORMAL
- en: Simply estimating the seasonal component
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eliminating it from the general course once it has been estimated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have to compare several time series with different seasonality, the only
    way to compare them is by a seasonal adjustment of them.
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to estimate the seasonal component. One of these is the
    use of a regression model using dichotomous auxiliary variables (dummy variables).
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose the existence of an additive model without a trend component:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y(t) = S(t) + r(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'And suppose we have measured the series on a monthly basis. The dummy variables
    can be defined in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '*d[j](t)*: 1 if the observation *t* is relative to the *j^(th)* month of the
    year'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*d[j](t)*: 0 otherwise'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once the periodic dummy variables have been created, the seasonal component
    can be estimated using the following regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y(t) = β[1]D[1] + β[2]D[2] + ... + β[n]D[n] + ε(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: The remaining *ε(t)* part of the model represents the part of the series not
    explained by seasonality. If a trend component is present in the series, it will
    coincide precisely with *ε(t)*.
  prefs: []
  type: TYPE_NORMAL
- en: Time series models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous sections, we explored the basics behind time series. To perform
    correct predictions of future events based on what happened in the past, it is
    necessary to construct an appropriate numerical simulation model. Choosing an
    appropriate model is extremely important as it reflects the underlying structure
    of the series. In practice, two types of models are available: linear or non-linear
    (depending on whether the current value of the series is a linear or non-linear
    function of past observations).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the most widely used models for forecasting time series data:'
  prefs: []
  type: TYPE_NORMAL
- en: AR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ARMA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ARIMA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoregressive models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AR models are a very useful tool to tackle the prediction problem in relation
    to a time series. A strong correlation between consecutive values of a series
    is often observed. In this case, we speak of autocorrelation of the first order
    when we consider adjacent values, of the second order if we refer to the relation
    between the values of the series after two periods, and in general of the *p^(th)*
    order if the values considered have *p* periods between them. AR models allow
    exploiting these bonds to obtain useful forecasts of the future behavior of the
    series.
  prefs: []
  type: TYPE_NORMAL
- en: 'AR is a linear predictive modeling technique. This model tries to predict the
    time series based on the previous values assumed using the AR parameters as coefficients.
    The number of samples used for the forecast determines the order of the model
    (*p*). As the name indicates, it is a regression of the variable against itself;
    that is, a linear combination of past values of the variables is used to forecast
    the future value. The AR model of *p* order is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8eda0e86-d38f-4a1b-8bef-eaef767b632f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the previous formula, the terms are defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y[t]* is the actual value at time period *t*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*c* is a constant'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ϕ[i] (i = 1,2,..., p)* are model parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Y[t-i]* is the past value at time period *t-i*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ε[t]* is the random error at time period *t* (white noise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It may happen that the constant term is omitted; this is done to make the model
    as simple as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Moving average models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The MA model specifies that the output variable depends linearly on the past
    and current past values of a stochastic term (imperfectly predictable). The MA
    model should not be confused with the MA we have seen in the previous sections.
    This is an essentially different concept although some similarities are evident.
    Unlike the AR model, the finished MA model is always stationary.
  prefs: []
  type: TYPE_NORMAL
- en: Just as a model AR (*p*) regresses with respect to the past values of the series,
    an MA (*q*) model uses past errors as explanatory variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The MA model of *q* order is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c1d41ff4-ed45-4e09-8e06-0f0627147180.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the previous formula, the terms are defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y[t]* is the actual value at time period *t*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*μ* is the mean of the series'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*θ[i] (i = 1,2,..., q)* are model parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ε[t-i]* is the past random error at time period *t-i*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ε[t]* is the random error at time period *t* (white noise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The MA model is essentially a finite impulsive response filter applied to white
    noise, with some additional interpretations placed on it.
  prefs: []
  type: TYPE_NORMAL
- en: Autoregressive moving average model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ARMA is a type of linear mathematical model that provides instant by instant
    an output value based on the previous input and output values. The system is seen
    as an entity that, instant by instant, receives an input value (input) and generates
    an output (output), calculated on the basis of internal parameters that in turn
    vary according to linear laws. Each internal parameter, therefore, will be at
    each instant place equal to a linear combination of all internal parameters of
    the previous instant and the incoming value. The output value, in turn, will be
    a linear combination of internal parameters, and, in rare cases, also of the incoming
    one.
  prefs: []
  type: TYPE_NORMAL
- en: Much more simply, ARMA can be seen as an effective combination of the AR and
    MA models to form a general and useful class of time series models.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model is generally defined as the ARMA model *(p, q)* where *p* is the
    order of the AR part and *q* is the order of the part of the MA. The ARMA model
    is defined by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e0a27b4-8a05-46ac-9914-23ff6eb59e28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The terms are defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y[t]* is the actual value at time period *t*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*c* is again a constant'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ϕ[i] (i = 1,2,..., p)* are AR model parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Y[t-i]* is the past value at time period *t-i*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*θ[i] (i = 1,2,..., q)* are MA model parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ε[t-i]* is the past random error at time period *t-i*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ε[t]* is the random error at time period *t* (white noise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, once the order *(p, q)* has been chosen, the parameters of an ARMA
    model *(p, q)* can be estimated through the maximum likelihood estimator, for
    example. As for the AR model, the choice of the model order must respond to the
    opposing needs of a good adaptation to the data and parsimony in the number of
    parameters to be estimated.
  prefs: []
  type: TYPE_NORMAL
- en: Autoregressive integrated moving average models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An ARIMA model is a generalization of a ARMA model. ARIMA models are applied
    in cases where data show a clear tendency to non-stationarity. In these cases,
    to eliminate the non-stationarity, an initial differentiation step is added to
    the ARMA algorithm (corresponding to the integrated part of the model) that is
    applied one or more times.
  prefs: []
  type: TYPE_NORMAL
- en: 'This algorithm is therefore essentially composed of three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: The part AR that determines a regression on its own delayed (that is, previous)
    values ​​to the evolving variable of interest.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The MA part. It indicates that the regression error is actually a linear combination
    of error terms whose values ​​have occurred simultaneously and at various times
    in the past.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The integrated part; it indicates that the data values ​​have been replaced
    with the difference between their current values ​​and the previous values ​​(and
    this differentiation process may have been performed more than once).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The purpose of each of these features is to make the model suitable for data
    in the best possible way.
  prefs: []
  type: TYPE_NORMAL
- en: 'To formulate the representative equation of the ARIMA model we start from the
    ARMA model equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fdfb1f75-0c54-4ca2-9945-90f23595341a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Simply move the AR part to the right side of equation to obtain the following
    equation (less than the constant *c*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a889d8fd-b97c-47e2-b994-81c1815c0107.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By introducing the lag operator (*L*), we can rewrite this equation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e458fe3c-64d7-4820-94e3-a8b40bdebfc0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Remember: The lag operator (*L*) operates on an element of a time series to
    produce the previous element, with the meaning that *LY[t] = Y[t-1]*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67e700d3-edea-4f37-8641-01f05a20fb3a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Which expresses precisely the factoring procedure of order *d* previously carried
    out to eliminate the non-stationarity. Based on this assumption and setting *p
    = p''-d*, we can write the following equation to represent the mathematical formulation
    of the ARIMA *(p,d,q)* model using lag polynomials:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d7a23d6b-bc3e-45c2-b110-a3c4ae0931c7.png)'
  prefs: []
  type: TYPE_IMG
- en: The *d* parameter controls the level of differentiating. Generally *d=1* is
    enough in most cases.
  prefs: []
  type: TYPE_NORMAL
- en: Removing seasonality from a time series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In economic and financial analyses, which are commonly carried out on the basis
    of numerous indicators, the use of data presented in a seasonally adjusted form
    (that is, net of seasonal fluctuations), is widely used in order to be able to
    grasp more clearly the short-term evolution of the phenomena considered.
  prefs: []
  type: TYPE_NORMAL
- en: Seasonality, in the dynamics of a time series, is the component that repeats
    itself at regular intervals every year, with variations of intensity more or less
    similar in the same period (month, quarter, semester, and so on) of successive
    years; there is different intensity during the same year. Typical examples of
    this are a decrease in industrial production in August following holiday closures
    of many companies, and increase in retail sales in December due to the holiday
    season.
  prefs: []
  type: TYPE_NORMAL
- en: Seasonal fluctuations, disguising other movements of interest (typically cyclical
    fluctuations), are often considered to be a nuisance in the analysis of economic
    conjuncture. The presence of seasonality creates, for example, problems in analysis
    and interpretation of the variations observed in a historical series between two
    consecutive periods (months and quarters) of the year—so-called **economic variation**.
    These are often influenced to a prevalent extent by seasonal fluctuations rather
    than movements due to other causes (for example, the economic cycle). The latter,
    on the other hand, can be correctly highlighted by calculating economic variations
    on seasonally adjusted data. Furthermore, since each time series is characterized
    by a specific seasonal profile, the use of seasonally adjusted data makes it possible
    to compare the evolution of different time series, and it is widely applied in
    joint use of statistics produced by different countries.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing a time series dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To see how to perform a seasonality removal operation on a time series, we
    will use a dataset on monthly milk production (pounds per cow; January 1962 –
    December 1975). Here is some useful information about this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Units**: Pounds per cow'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dataset metrics**: 168 fact values in one time series'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time granularity**: Month'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time range**: January 1962 – December 1975'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Source**: Time Series Data Library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Time Series Data Library** (**TSDL**) was created by Rob Hyndman, a professor
    of statistics at Monash University, Australia.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data is available in a `.csv` file named `milk-production-pounds.csv`.
    To start, let''s see how to import the data into Python and then how to display
    it to identify the possible presence of seasonality. The first thing to do is
    to import the library that we will use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: With the first line, we imported the `pandas` library, and with the second line,
    we imported the `pyplot` module from the `matplotlib` library.
  prefs: []
  type: TYPE_NORMAL
- en: '`pandas` is an open source, BSD-licensed library providing high-performance,
    easy-to-use data structures and data analysis tools for the Python programming
    language. In particular, it offers data structures and operations for manipulating
    numerical tables and time series.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Matplotlib is a Python 2D plotting library that produces publication-quality
    figures in a variety of hard copy formats and interactive environments across
    platforms. Matplotlib can be used in Python scripts, the Python and IPython shell,
    Jupyter Notebook, web application servers, and four graphical user interface toolkits.
    The `matplotlib.pyplot` module contains functions that allow you to generate many
    kinds of plots quickly. Now let''s see how to import the data contained in the
    dataset in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To import a dataset, we used the `read_csv` module of the `pandas` library.
    The `read_csv` method loads the data in a Pandas DataFrame we named `data`. To
    display the first five rows of the DataFrame imported on video, we can use the
    `head()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `head()` function, with no arguments, gets the first five rows of data
    from the DataFrame. Now the time series is available in our Python environment;
    to get a preview of the data contained in it, we can calculate a series of basic
    statistics. To do so, we will use the `describe()` function in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The `describe()` function generates descriptive statistics that summarize the
    central tendency, dispersion, and shape of a dataset''s distribution, excluding
    NaN values. It analyzes both numeric and object series, as well as DataFrame column
    sets of mixed data types. The output will vary depending on what is provided.
    To extract further information, we can invoke the function `info()` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'After having taken a look at the content of the dataset, we are going to perform
    an initial visual exploratory analysis. There''s a relatively extensive plotting
    functionality built into Pandas that can be used for exploratory charts—especially
    useful in data analysis. A huge amount of functionality is provided by the `.plot()`
    command natively by Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `data.plot()` command makes plots of the DataFrame using `matplotlib`/`pylab`.
    To display the graph just created on video, we have to use the `plt.show()` function,
    as shown in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/92e6df22-1259-4c7e-bbd4-83510b84d329.png)'
  prefs: []
  type: TYPE_IMG
- en: From the analysis of the previous figure, we can certainly recognize that milk
    production is growing (we note a positive trend) but denoting a certain variability
    (oscillations around a hypothetical trend line). This is maintained almost constantly
    with the passage of time.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying a trend in a time series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we want to try a prediction of milk production in the next January, we can
    think in the following way: with the acquired data, we can trace the trend line
    and extend it until the following January. In this way, we would have a rough
    estimate of milk production that we should expect in the immediate future.'
  prefs: []
  type: TYPE_NORMAL
- en: But tracing a trend line means tracing the regression line. The linear regression
    method consists of precisely identifying a line that is capable of representing
    point distribution in a two-dimensional plane. As is easy to imagine, if the points
    corresponding to the observations are near the line, then the chosen model will
    be able to effectively describe the link between the variables. In theory, there
    are an infinite number of lines that may approximate the observations. In practice,
    there is only one mathematical model that optimizes the representation of the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'To fit a linear regression model, we start importing two more libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'NumPy is the fundamental package for scientific computing with Python. It contains,
    among other things:'
  prefs: []
  type: TYPE_NORMAL
- en: A powerful N-dimensional array object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sophisticated (broadcasting) functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools for integrating C/C++ and FORTRAN code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Useful linear algebra, Fourier transform, and random number capabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides its obvious scientific uses, NumPy can also be used as an efficient
    multi-dimensional container of generic data. Arbitrary datatypes can be defined.
    This allows NumPy to seamlessly and speedily integrate with a wide variety of
    databases.
  prefs: []
  type: TYPE_NORMAL
- en: sklearn is a free software machine learning library for the Python programming
    language. It features various classification, regression and clustering algorithms
    including support vector machines, random forests, gradient boosting, k-means
    and DBSCAN, and is designed to interoperate with the Python numerical and scientific
    libraries NumPy and SciPy.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, to import a library that is not present in the initial distribution
    of Python, you must use the `pip` install command followed by the name of the
    library. This command should be used only once and not every time you run the
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin to prepare the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we counted the data; then we used the `reshape()` function to give a
    new shape to an array without changing its data. Finally, we inserted the time
    series values into the `y` variable. Now we can build the linear regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `LinearRegression()` function performs a ordinary least squares linear regression.
    The ordinary least squares method is an optimization technique (or regression)
    that allows us to find a function, represented by an optimal curve (or regression
    curve) that is as close as possible to a set of data. In particular, the function
    found must be one that minimizes the sum of squares of distances between the observed
    data and those of the curve that represents the function itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given n points (*x[1]*, *y[1]*), (*x[2]*, *y[2]*), ... (*x[n]*, *y[n]*) in
    the observed population, a least squares regression line is defined as the equation
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '*y=α*x+β*'
  prefs: []
  type: TYPE_NORMAL
- en: 'For which the following quantity is minimal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/030fe6e9-bb43-4d99-9110-c10d99248be8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This quantity represents the sum of squares of distances of each experimental
    datum (*x[i], y[i]*) from the corresponding point on the straight line *(x[i],
    αx[i]+β)*, as shown in the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c3f1540d-3f16-4fd4-b574-131621ec52d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we have to apply the `fit` method to fit the linear model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'A linear regression model basically finds the best value for the intercept
    and slope, which results in a line that best fits the data. To see the value of
    the intercept and slope calculated by the linear regression algorithm for our
    dataset, execute the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The first is the intercept; the second is the coefficient of the regression
    line. Now that we have trained our algorithm, it''s time to make some predictions.
    To do so, we will use the whole data and see how accurately our algorithm predicts
    the percentage score. Remember, our scope is to locate the time series trend.
    To make predictions on the whole data, execute the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'It is time to visualize what we have achieved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'With this code, we first traced the time series. So we added the regression
    line that represents the data trend, and finally we printed the whole thing, as
    shown in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/56c969c3-7c64-45f7-b228-360787f01f08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We recall that this represents a long-term monotonous trend movement, which
    highlights a structural evolution of the phenomenon due to causes that act in
    a systematic manner on the same. From the analysis of the previous figure, it
    is possible to note this: making a estimation of milk production in a precise
    period based on the line that indicates the trend of the time series can, in some
    cases, be disastrous. This is due to the fact that the seasonal highs and lows
    are at important distances from the line of regression. It is clear that it is
    not possible to use this line to make estimates of milk production.'
  prefs: []
  type: TYPE_NORMAL
- en: Time series decomposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the fundamental purposes of the classical analysis of time series is
    to break down the series into its components, isolating them in order to study
    them better. Moreover, to be able to apply the stochastic approach to a time series,
    it is almost always necessary to eliminate the trend and the seasonality to have
    a steady process. As we have specified in the previous sections, the components
    of a time series are usually the following: trend, seasonality, cycle, and residual.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As already mentioned, they can be decomposed by an additive way:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y(t) = τ(t) + S(t) + r(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'They can also be decomposed by a multiplicative method:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y(t) = τ(t) * S(t) * r(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will look at how to derive these components using
    both these methods.
  prefs: []
  type: TYPE_NORMAL
- en: Additive method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To perform a time series decomposition, we can use automated procedures. The
    `stats` models library provides an implementation of the naive, or classical,
    decomposition method in a function called `seasonal_decompose()`. Additive or
    multiplicative methods are available.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start importing the `stats` models library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'In particular, we imported the `seasonal_decompose` module to perform seasonal
    decomposition using MAs. We perform the decomposition by applying the additive
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The seasonal component is first removed by applying a convolution filter to
    the data. The average of this smoothed series for each period is the returned
    seasonal component. Let''s see what happened through the visualization of the
    components identified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph shows the decomposition results by additive method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8cc10757-6cf6-406d-befa-8600a842f876.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this figure, the three components of the time series are clearly represented:
    trend, seasonal, and residual. These attributes are contained in the object returned
    by the method `seasonal_decompose()`. This means that we can use the content of
    that object to remove the effect of seasonality from the time series. Let''s see
    how:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'With this line of code, we have simplified the seasonal attribute returned
    by the `seasonal_decompose()` method from the data. At this point, we just have
    to visualize the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph shows the monthly milk production (pounds per cow from
    January 1962 – December 1975) net of seasonality:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/60c6dbf7-ad1c-45e7-a3ea-1c240e5f8ac1.png)'
  prefs: []
  type: TYPE_IMG
- en: In the graph obtained, the component due to seasonality has clearly been removed,
    while the one due to the trend is clearly visible.
  prefs: []
  type: TYPE_NORMAL
- en: Multiplicative method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we said, the `seasonal_decompose()` performs both additive and multiplicative
    decomposition. To run multiplicative method, just type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we just have to visualize the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph shows the decomposition results by multiplicative method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb7bd241-4501-42ec-bfd0-50badb4e87a2.png)'
  prefs: []
  type: TYPE_IMG
- en: In the previous figure, we can note that the trend and seasonality information
    extracted from the time series do seem reasonable. The residuals show an interesting
    variation; periods of high variability are clearly identified in the early and
    later years of the time series.
  prefs: []
  type: TYPE_NORMAL
- en: LSTM for time series analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LSTM is a particular architecture of recurrent neural network, originally conceived
    by Hochreiter and Schmidhuber in 1997\. This type of neural network has been recently
    rediscovered in the context of deep learning because it is free from the problem
    of vanishing gradient, and in practice it offers excellent results and performance.
  prefs: []
  type: TYPE_NORMAL
- en: LSTM-based networks are ideal for prediction and classification of time series,
    and are supplanting many classic machine learning approaches. This is due to the
    fact that LSTM networks are able to consider long-term dependencies between data,
    and in the case of speech recognition, this means managing the context within
    a sentence to improve recognition capacity.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of the time series dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Scientists from the US **National Oceanic and Atmospheric Administration**
    (**NOAA**) have measured atmospheric carbon dioxide from 1965 to 1980 near the
    top of the Mauna Loa volcanic cone (Hawaii). The dataset covers carbon dioxide
    concentrations of 317.25 to 341.19 **parts per million** (**ppm**) by volume and
    contains 192 monthly records. Here is some useful information about this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Units**: ppm'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dataset metrics**: 192 fact values in one time series'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time granularity**: Month'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time range**: January 1965-December 1980'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Source: TSDL, created by Rob Hyndman, a professor of statistics at Monash University,
    Australia.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data is available in the `.csv` file named `co2-ppm-mauna-loa-19651980.csv`.
    To start, let''s see how to import data into Python and then how to display them
    to identify the possible presence of seasonality. The first thing to do is to
    import the library that we will use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'With the first line, we imported `pandas` and with second line we imported
    the `pyplot` module from the `matplotlib` library. Now let''s see how to import
    the data contained in the dataset in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'To import a dataset, we used the `read_csv` module of the `pandas` library.
    The `read_csv` method loads the data in a Pandas DataFrame we named dataset. To
    display on video the first five rows of DataFrame imported, we can use the `head()`
    function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The `head()` function, with no arguments, gets the first five rows of data
    from the DataFrame. Now the time series is now available in our Python environment;
    to get a preview of the data contained in it, we can calculate a series of basic
    statistics. To do so, we will use the `describe()` function in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The `describe()` function generates descriptive statistics that summarize the
    central tendency, dispersion and shape of a dataset''s distribution, excluding
    NaN values. It analyzes both numeric and object series, as well as DataFrame column
    sets of mixed data types. The output will vary depending on what is provided.
    To extract further information, we can invoke the function `info()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'After having taken a look at the content of the dataset, we are going to perform
    an initial visual exploratory analysis. There''s a relatively extensive plotting
    functionality built into Pandas that can be used for exploratory charts; this
    is especially useful in data analysis. A huge amount of functionality is provided
    by the `.plot()` command natively by Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The `dataset.plot()` command make plots of the DataFrame using `matplotlib`/`pylab`.
    To display the graph just created on video, we have to use the `plt.show()` function,
    as shown in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c0e05687-3b9f-41fe-91da-f4d54da69b3f.png)'
  prefs: []
  type: TYPE_IMG
- en: From the analysis of the previous figure, we can certainly recognize that atmospheric
    carbon dioxide is growing. We note a positive trend. But it is also denoting a
    certain variability (oscillations around a hypothetical trend line), which is
    maintained almost constantly with the passage of time.
  prefs: []
  type: TYPE_NORMAL
- en: Data scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Data scaling** is a preprocessing technique usually employed before feature
    selection and classification. Many artificial intelligence-based systems use features
    that are generated by many different feature extraction algorithms, with different
    kinds of sources. These features may have different dynamic ranges.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition, in several data mining applications with huge numbers of features
    with large dynamic ranges, feature scaling may improve the performance of the
    fitting model. However, the appropriate choice of these techniques is an important
    issue, since applying scaling on the input could change the structure of data
    and thereby affect the outcome of multivariate analysis used in data mining.
  prefs: []
  type: TYPE_NORMAL
- en: 'To scaling the data we will use the min-max normalization (usually called **feature
    scaling**); it performs a linear transformation on the original data. This technique
    gets all the scaled data in the range (0,1). The formula to achieve this is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7acb1819-3d3e-494d-844b-c4cd6ff64476.png)'
  prefs: []
  type: TYPE_IMG
- en: Min-max normalization preserves the relationships among the original data values.
    The cost of having this bounded range is that we will end up with smaller standard
    deviations, which can suppress the effect of outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform min-max normalization, we will use the `MinMaxScaler()` module of
    the `sklearn.preprocessing` class. This module transforms features by scaling
    each feature to a given range. This estimator scales and translates each feature
    individually such that it is in the given range on the training set, that is,
    between zero and one. The following codes show how to apply this module to our
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: First we have used the `MinMaxScaler()` function to set the normalization interval
    (by default (0, 1)). In the second line of the code, we applied the `fit_transform()`
    function; it fits the transformer to the dataset and returns a transformed version
    of the data. This function is particularly useful as it stores the transformation
    parameters used. These parameters will be useful when, after having made the forecasts,
    we will have to report the data in the initial form (before normalization) to
    compare it with actual data.
  prefs: []
  type: TYPE_NORMAL
- en: Data splitting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's now split the data for the training and the test model. Training and testing
    the model forms the basis for further usage of the model for prediction in predictive
    analytics. Given a dataset of 192 rows of data, we split it into a convenient
    ratio (say 70:30), and allocate 134 rows for training and 58 rows for testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, in the algorithms based on artificial neural networks, the splitting
    is done by selecting rows randomly to reduce the bias. With the time series data,
    the sequence of values is important, so this procedure is not practicable. A simple
    method that we can use is to divide the ordered dataset into train and test. As
    we anticipated, the following code calculates the division point index and separates
    the data in the training datasets, with 70% of the observations for us to use
    to train our model; this leaves the remaining 30% to test the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The first two lines of code set the length of the two groups of data. The next
    two lines split the dataset into two parts: from row 1 to row `train_len -1` for
    the train set, and from the `train_len` row to the last row for the test set.
    To confirm the correct split of data, we can print the length of the two datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: As we anticipated, the operation divided the dataset into `134` (train set)
    and `58` rows (test set).
  prefs: []
  type: TYPE_NORMAL
- en: Building the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our aim is to use data in the dataset to make predictions. In particular, we
    want to predict the presence of carbon dioxide in the air based on the data available
    in the `.csv` file. We need input and output to train and test our network. It
    is clear that the input is represented by the data present in the dataset. We
    must then construct our output; we will do so by supposing we want to predict
    the CO2 present in the atmosphere at time *t + 1* with respect to the value measured
    at time *t*. So we will have:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Input = data(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Output = data(t + 1)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have said that a recurrent network has memory, and it is maintained by fixing
    the so-called **time step**. The time step has to do with how many steps back
    in time backprop uses when calculating gradients for weight updates during training.
    In this way, we set *time step = 1*. Then we define a function that gives a dataset
    and a time step returns the input and output data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'In this function, `Xdata=Input= data(t)` is the input variable and `Ydata=output=
    data(t + 1)` is the predicted value at the next time period. Let''s use this function
    to set the train and test datasets that we will use in the next phase (network
    modeling):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: In this way, we created all the data needed for the network training and testing.
    This function converts an array of values into a dataset matrix. Now we have to
    prepare the two input datasets (`trainX` and `testX`) in the form required by
    the machine learning algorithm we intend to use (LSTM). To do this, it is necessary
    to deepen this concept.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a classic feed-forward network, like those already analyzed in the previous
    chapters, the input contains the values assumed by the variables for each observation
    made. This means that the input takes the following shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '*(number of observations, number of features)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In an LSTM/RNN network, the input for each LSTM layer must contain the following
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Observations**: Number of observations collected'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time steps**: A time step is an observation point in the sample'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Features**: One feature for each step'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Therefore it is necessary to add a temporal dimension to those foreseen for
    a classical network. Thus the input shape becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '*(number of observations, number of time steps, number of features per steps)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this way, the input for each LSTM layer becomes three-dimensional. To transform
    the input datasets in 3D form, we will use the `numpy.reshape()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The `numpy.reshape()` function gives a new shape to an array without changing
    its data. The function parameters used are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`trainX`, `testX`: Array to be reshaped'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(trainX.shape[0], 1, 1)`, `(testX.shape[0], 1, 1)`: New shape'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The new shape should be compatible with the original shape. In our case, the
    new shape is (133,1,1) for `trainX` and (57,1,1) for `testX`. Now that the data
    is in the right format, it''s time to create the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We start defining the time steps; then we use a sequential model, that is,
    a linear stack of layers. To create a sequential model, we have to pass a list
    of layer instances to the constructor. We can also simply add layers via the `.add()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The first layer is an LSTM layer, with a hidden layer with four LSTM blocks.
    The model needs to know what input shape it should expect. For this reason, we
    passed an `input_shape` argument to this layer. In the next line, we added a dense
    layer that implements the default sigmoid activation function. Now, we have to
    configure the model for training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'To do this, we used the compile module. The arguments passed are a loss function
    as `mean_squared_error` and stochastic gradient descent as `optimizer`. Finally,
    we can fit the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: In the training phase, the `trainX` and `trainY` data is used, with 1,000 epochs
    (full training cycle on the training set). A batch size of 1 (batch_size = number
    of samples per gradient update) is passed. Fynally `verbose=2` (verbose argument
    provides additional details as to what the computer is doing) prints the loss
    value for each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our model is now ready for use. We can therefore use it to execute our predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The `predict()` module has been used, which generates output predictions for
    the input samples. Computation is done in batches. A Numpy array of predictions
    is returned. Previously, when data scaling was performed, we used the `fit_transform()`
    function. As we said, this function is particularly useful as it stores the transformation
    parameters used. These parameters will be useful when, after having made the forecasts,
    we will have to report the data in the initial form (before normalization), to
    compare it to the actual data. In fact, now the predictions must be reported in
    original form to compare with the actual values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'This code block is used exclusively to cancel the effect of normalization and
    to restore the initial form to the dataset. To estimate the performance of the
    algorithm, we will calculate the root mean squared error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '**Root mean square error** (**RMSE**) measures how much error there is between
    two datasets. In other words, it compares a predicted value and an observed value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'After evaluating the method''s performance, we can now visualize the results
    by drawing an appropriate graph. To display the time series correctly, a prediction
    shift is required. This operation must be carried out both on the train set and
    on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Then perform the same operation on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we have to plot the actual data and the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following graph are shown the actual data and the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/74b02eb1-05a0-43a4-9d19-74b49c5a736a.png)'
  prefs: []
  type: TYPE_IMG
- en: From the analysis of the previous graph, we can see that what is reported by
    the RMSE is confirmed by the graph. In fact, we can see that the model has done
    an excellent job in the fitting of both the training and test datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we explored time series data. A time series constitutes a
    sequence of observations on a phenomenon. In a time series, we can identify several
    components: trend, seasonality, cycle, and residual. We learned how to remove
    seasonality from a time series with a practical example.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then the most used models to represent time series were addressed: AR, MA,
    ARMA, and ARIMA. For each one, the basic concepts were analyzed and then a mathematical
    formulation of the model was provided.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, an LSTM model for time series analysis was proposed. Using a practical
    example, we could see how to deal with a time series regression problem with a
    recurrent neural network model of the LSTM type.
  prefs: []
  type: TYPE_NORMAL
