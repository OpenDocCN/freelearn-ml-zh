- en: Chapter 4. Building a Product Recommendation System
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章。构建产品推荐系统
- en: The digital world has made everything available at the click of a button. With
    everything going the online way, online shopping or e-commerce has become a big
    thing. From groceries to electronics to even cars, everything is available at
    the Amazon, Flipkart, and eBay of the world. This ever expanding digital market
    is just the right place for data science to show its magic.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数字世界让一切都可以一键获取。随着一切转向线上，在线购物或电子商务已经成为一大趋势。从杂货到电子产品，甚至汽车，一切都可以在亚马逊、Flipkart和eBay等全球平台找到。这个不断扩大的数字市场正是数据科学展示其魔力的理想场所。
- en: The online revolution of e-commerce has not only empowered the customers, it
    has also overwhelmed them with too many choices. Choices are not only in terms
    of products or categories but also between different e-commerce platforms. Being
    an ecommerce company in this highly competitive market can be really difficult.
    Standing out is a challenge and that is where data yet again comes to the rescue.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 电子商务的在线革命不仅赋予了顾客权力，还让他们因选择过多而感到不知所措。选择不仅限于产品或类别，还包括不同的电子商务平台。在这个高度竞争的市场中，作为一家电子商务公司确实非常困难。脱颖而出是一个挑战，而数据再次发挥了救星的作用。
- en: As we saw in [Chapter 3](part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis"),
    *Predicting Customer Shopping Trends with Market Basket Analysis*, purchase patterns
    can provide a lot of insights about shopping behaviors. We utilized such data
    to find association rules to not only help the customers quickly find the right
    products but also help the retailers increase revenues (see [Chapter 3](part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis"),
    *Predicting Customer Shopping Trends with Market Basket Analysis*). For association
    rules, the granularity lies at the transaction level. They use transactions as
    a central entity and hence do not provide user specific insights.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第3章](part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8 "第3章。使用市场篮子分析预测客户购物趋势")中看到的，“使用市场篮子分析预测客户购物趋势”，购买模式可以提供关于购物行为的很多见解。我们利用此类数据来找到关联规则，不仅帮助客户快速找到合适的产品，还帮助零售商增加收入（参见[第3章](part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8
    "第3章。使用市场篮子分析预测客户购物趋势")，“使用市场篮子分析预测客户购物趋势”）。对于关联规则，其粒度位于交易层面。它们使用交易作为中心实体，因此不提供特定于用户的见解。
- en: In this chapter as well, we will continue our project work in the e-commerce
    domain. Here we will tackle the problem of personalization. We will use machine
    learning algorithms to provide user specific recommendations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们也将继续在电子商务领域进行我们的项目工作。在这里，我们将解决个性化的问题。我们将使用机器学习算法提供特定于用户的推荐。
- en: 'Through this chapter we will learn about:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章，我们将了解：
- en: Recommendation systems and their types
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统及其类型
- en: Issues with recommendation systems
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统的问题
- en: Collaborative filters
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协同过滤器
- en: Building a recommendation system from scratch based on matrix factorization
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于矩阵分解从头开始构建推荐系统
- en: Utilizing highly optimized R packages to build a production ready recommendation
    engine and evaluate its recommendations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用高度优化的R包构建一个生产就绪的推荐引擎并评估其推荐
- en: Throughout this chapter we will use the terms **recommender engines** and **recommendation
    systems** interchangeably.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的整个过程中，我们将交替使用术语**推荐引擎**和**推荐系统**。
- en: Understanding recommendation systems
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解推荐系统
- en: '*Every individual in unique*, the way we do things is what defines us uniquely.
    We eat, walk, talk, and even shop in a very unique way. Since the focus of this
    chapter is e-commerce, we will focus mostly on our shopping behaviors. We will
    utilize each customer''s unique behavior to provide a personalized shopping experience.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*每个人都是独一无二的*，我们做事的方式定义了我们独特的个性。我们吃饭、走路、说话，甚至购物都有非常独特的方式。由于本章的重点是电子商务，我们将主要关注我们的购物行为。我们将利用每位客户的独特行为来提供个性化的购物体验。'
- en: To accomplish the task of providing a personalized shopping experience, we need
    a system to understand and model our customers. Recommendation engines are the
    systems which learn about customer preferences, choices, and so on, to recommend
    new products which are closer to what the user might have purchased themselves,
    thus providing a personalized experience. The options presented by such systems
    would have a high probability of the customer purchasing them.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成提供个性化购物体验的任务，我们需要一个系统来理解和模拟我们的客户。推荐引擎是学习客户偏好、选择等信息的系统，以推荐更接近用户可能自己购买的新产品，从而提供个性化体验。这些系统提供的选项有很大的可能性会被客户购买。
- en: Let us try to formally define a recommendation system.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试正式定义一个推荐系统。
- en: '**Recommendation systems** (or **recommender engines**) are a class of information
    filtering systems which analyze the input data to predict preferences of a user
    as they might have done for themselves.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**推荐系统**（或**推荐引擎**）是一类信息过滤系统，它们分析输入数据以预测用户的偏好，就像他们为自己做的那样。'
- en: Unlike information filtering systems which remove or filter information, recommender
    engines add or re-arrange the information flowing towards the user, which is more
    relevant to the current context.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与信息过滤系统不同，后者会删除或过滤信息，推荐引擎会添加或重新排列流向用户的信息，使其与当前上下文更相关。
- en: Recommender engines are not a new concept. They have existed long before the
    internet was there. They existed in the form of our friends and family who used
    to recommend us things to buy because they understood our choices. These were
    and still are a sort of **offline-recommender engines**. The web is full of **online-recommender
    engines**. From recommendation related to **Who to follow** on Twitter to **Other
    movies you might enjoy** on Netflix to **Jobs you may be interested in** on LinkedIn,
    recommender engines are everywhere and not just on e-commerce platforms.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎并不是一个新概念。在互联网出现之前，它们就已经存在了。它们以我们的朋友和家人的形式存在，他们曾经向我们推荐购买的东西，因为他们理解我们的选择。这些就是，并且仍然是某种**离线推荐引擎**。网络上充满了**在线推荐引擎**。从Twitter上的**关注推荐**到Netflix上的**你可能喜欢的其他电影**，再到LinkedIn上的**你可能感兴趣的工作**，推荐引擎无处不在，而不仅仅是电子商务平台。
- en: 'Now that we have understood what a recommendation engine is, let us look at
    their different types:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了推荐引擎是什么，让我们来看看它们的不同类型：
- en: '**User-based recommender engines**: As the name suggests, these systems have
    the user as the central entity. The activities, preferences, or behavior of the
    users are analyzed to predict what they might like depending upon their similarity
    with other such users. They are also termed as User Based Collaborative Filters
    in general due to extensive use of collaborative filters specifically for such
    recommender engines.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于用户的推荐引擎**：正如其名所示，这些系统以用户为中心实体。通过分析用户的活跃度、偏好或行为来预测他们可能喜欢的东西，这取决于他们与其他类似用户的相似性。由于这些推荐引擎广泛使用协同过滤器，因此它们通常被称为基于用户的协同过滤器。'
- en: '**Content-based recommender engines**: As the name suggests, these engines
    have the content or the items as the central entities. These items are analyzed
    to extract features; also the user profiles are built to map user preferences
    to the type of items. The engines then use this information to predict items which
    are similar to the ones the users have liked in the past. Such recommender engines
    are also known as **item-based collaborative filters** and have their roots in
    information retrieval theory.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于内容的推荐引擎**：正如其名所示，这些引擎以内容或项目为中心实体。这些项目被分析以提取特征；同时，也建立用户档案以将用户偏好映射到项目类型。然后，这些引擎使用这些信息来预测与用户过去喜欢的项目相似的项目。这类推荐引擎也被称为**基于项目的协同过滤器**，其根源在于信息检索理论。'
- en: '**Hybrid recommender engines**: These systems take the best of both worlds
    to improve upon the prediction results. The two pure types can be used simultaneously
    and then their results can be combined; they can be used by adding collaborative
    filtering capabilities to content based systems or even by unifying both the approaches
    into a single model. Multiple studies have been conducted to demonstrate that
    hybrid approaches are better than the simple ones. Hybrid recommendation engines
    are also better at tackling the problems which haunt recommender engines in general.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合推荐引擎**：这些系统结合了两种方法的优点，以改进预测结果。两种纯类型可以同时使用，然后合并它们的结果；它们可以通过向基于内容的系统添加协同过滤功能或甚至将两种方法统一到一个单一模型中来实现。已经进行了多项研究来证明混合方法比简单方法更好。混合推荐引擎在解决一般推荐引擎面临的难题方面也更为出色。'
- en: Before we dive deep into the intricacies of these algorithms, let us see the
    issues that affect the recommender systems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨这些算法的复杂性之前，让我们看看影响推荐系统的问题。
- en: Issues with recommendation systems
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统的问题
- en: 'Recommender engines are affected mainly by the following two issues:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎主要受以下两个问题的影响：
- en: '**The sparsity problem**: Recommender engines work upon user preferences (or
    ratings for different items, depending upon the application) to predict or recommend
    products. Usually the ratings are given on some chosen scale but the user may
    choose not to rate certain items which he/she hasn''t bought or looked at. For
    such cases, the rating is blank or zero. Hence, the ratings matrix R has elements
    of the form:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稀疏性问题**：推荐引擎根据用户偏好（或根据应用的不同，对不同项目的评分）来预测或推荐产品。通常评分是在某个选定的尺度上给出的，但用户可能选择不对他/她未购买或查看的项目进行评分。对于这种情况，评分是空白或零。因此，评分矩阵
    R 的元素形式如下：'
- en: '![Issues with recommendation systems](img/00105.jpeg)'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![推荐系统的问题](img/00105.jpeg)'
- en: For any real world application, such as an e-commerce platform, the size of
    such a ratings matrix is huge due to the large number of users and items available
    on the platform. Even though a lot of user related information is gathered on
    such a platform, the ratings matrix itself might still be pretty sparse, that
    is the matrix might have a many elements as blanks (or zeroes). This problem in
    general is termed the **sparsity** **problem**. The sparsity problem renders the
    recommender engine's predictions ineffective as the algorithms are not able to
    infer the correlations correctly due to blanks or missing ratings. In the worst
    cases, the algorithm may term two users as un-correlated when actually they have
    highly similar preferences. The sparsity problem usually affects collaborative
    filtering algorithms.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于任何现实世界应用，例如电子商务平台，由于平台上可用的用户和项目数量庞大，这样的评分矩阵的大小是巨大的。尽管在这样一个平台上收集了大量的用户相关信息，但评分矩阵本身可能仍然相当稀疏，即矩阵可能有大量空白（或零）元素。这个问题通常被称为**稀疏性问题**。稀疏性问题使得推荐引擎的预测无效，因为算法无法正确推断出由于空白或缺失评分而产生的相关性。在最坏的情况下，算法可能会将两个用户视为不相关，而实际上他们有高度相似的选择偏好。稀疏性问题通常影响协同过滤算法。
- en: '**The cold start problem**: A special case of the sparsity problem is the cold
    start issue. As mentioned previously, when the ratings matrix contains sparsely
    populated elements (or ratings), the recommender engine fails to return valid
    recommendations. The cold start problem occurs in two particular cases. Firstly,
    assume a user has newly been added to the system. In this case, the row representing
    the user would contain zeroes (mostly). Recommending items to such a user is virtually
    impossible due to unavailability of information related to his/her preferences.
    The second scenario is when an item is newly added to the system. Since the newly
    added item will not have any ratings by the users, recommending such an item would
    be difficult for the recommender system. Hence, these two scenarios represent
    what is termed the cold start problem. Very much like the sparsity problem, the
    cold start problem also plagues collaborative filters.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**冷启动问题**：稀疏问题的特殊情况是冷启动问题。如前所述，当评分矩阵包含稀疏元素（或评分）时，推荐引擎无法返回有效的推荐。冷启动问题在两种特定情况下发生。首先，假设一个新用户被添加到系统中。在这种情况下，代表该用户的行将包含零（大多数情况下）。由于缺乏与用户偏好相关的信息，向此类用户推荐项目几乎是不可能的。第二种情况是当新项目被添加到系统中。由于新添加的项目不会有任何用户评分，因此推荐此类项目对推荐系统来说将是困难的。因此，这两个场景代表了所谓的冷启动问题。与稀疏问题非常相似，冷启动问题也困扰着协同过滤器。'
- en: Collaborative filters
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协同过滤器
- en: Recommendation systems and collaborative filters share a long history. From
    the early days of primitive recommender engines which utilized specific categorizations
    with hard-coded results, to current sophisticated recommender engines on various
    e-commerce platforms, recommender engines have made use of collaborative filters
    throughout. They are not only easy to understand but are equally simple to implement.
    Let us take this opportunity to learn more about collaborative filters before
    we dive into implementation details.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统和协同过滤器有着悠久的历史。从早期使用特定分类和硬编码结果的原始推荐引擎，到当前各种电子商务平台上的复杂推荐引擎，推荐引擎一直使用协同过滤器。它们不仅易于理解，而且同样易于实现。在我们深入了解实现细节之前，让我们利用这个机会更多地了解协同过滤器。
- en: Note
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Fun Fact**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**趣味事实**'
- en: Recommender engines surely outdate any known e-commerce platform! Grundy, a
    virtual librarian, was developed in 1979\. It was a system for recommending books
    to users. It modeled the users based upon certain pre-defined stereotypes and
    recommended books from a known list for each such category.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎无疑已经过时了任何已知的电子商务平台！1979年开发的Grundy是一个虚拟图书管理员。它是一个向用户推荐书籍的系统。它根据某些预定义的刻板印象来模拟用户，并为每个此类类别推荐已知列表中的书籍。
- en: Core concepts and definitions
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核心概念和定义
- en: '**Collaborative filters** (denoted as **CF** henceforth) and recommender engines
    in general use certain terms and definitions to formally define and tackle the
    problem.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**协同过滤器**（以下简称**CF**）和一般的推荐引擎使用某些术语和定义来正式定义和解决该问题。'
- en: The problem domain of recommender engines revolves around the users and the
    items they are interested in. A **user** is anybody who interacts with the system
    and performs certain actions on the **item** (say purchases or views it). Similarly,
    a **rating** defines a user's preference for an item in consideration. Generally,
    this trio is represented as a `(user, item, rating)` tuple. Since the ratings
    quantify a user's preference, the ratings can themselves be defined in different
    ways depending upon the application. Applications define ratings as integer-valued
    scales ranging from say *0-5*, while others may define a real-valued scale. Some
    applications might use binary scales with values such as *Like/Dislike* or *Purchased/Not-Purchased*.
    Thus, each application makes use of a rating scale to suit its user's preferences.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎的问题领域围绕着用户和他们感兴趣的项目。一个**用户**是任何与系统互动并在**项目**（例如购买或查看它）上执行某些操作的人。同样，一个**评分**定义了用户对考虑中的项目的偏好。通常，这个三元组表示为`(用户，项目，评分)`元组。由于评分量化了用户的偏好，评分可以根据应用的不同以不同的方式定义。应用将评分定义为从*0-5*等整数刻度，而其他可能定义实值刻度。某些应用可能使用*喜欢/不喜欢*或*购买/未购买*等值的二进制刻度。因此，每个应用都使用评分尺度来满足其用户的偏好。
- en: 'Now that we know the key players involved, the next step is the representation
    of these core-concepts mathematically. A tuple of `(user, item, rating)` is usually
    represented in the form of a sparse matrix called a **ratings matrix**. Each user
    is represented by a row while the columns denote the items. Each element of this
    ratings matrix refers to the rating or preference of the user for an item. The
    ratings matrix is a **sparse matrix** since not all the items would be rated by
    every user and hence such unrated items would contain nulls or blank values. A
    ratings matrix using a 0-5 scale (unrated/missing ratings are denoted by `?`)
    looks like the following matrix showing the preference of three users for different
    laptop models:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了涉及的关键角色，下一步是数学上表示这些核心概念。一个`(用户, 项目, 评分)`元组通常以稀疏矩阵的形式表示，称为**评分矩阵**。每一行代表一个用户，而列表示项目。这个评分矩阵的每个元素都指代用户对项目的评分或偏好。由于并非所有项目都会被每个用户评分，因此这些未评分的项目将包含空值或空白值。使用0-5评分尺度（未评分/缺失评分用`?`表示）的评分矩阵如下所示，显示了三个用户对不同笔记本电脑型号的偏好：
- en: '![Core concepts and definitions](img/00106.jpeg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![核心概念和定义](img/00106.jpeg)'
- en: A sample ratings matrix
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例评分矩阵
- en: 'A recommender engine is tasked to perform two main operations: **predict**
    and **recommend**. The prediction operation works upon a given user and item to
    determine the user''s likely preference for the item in consideration. For the
    ratings matrix (like the one shown earlier), prediction is like identification
    of the missing values (represented by `?` in the previous example).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎被赋予执行两个主要操作的任务：**预测**和**推荐**。预测操作针对给定的用户和项目，以确定用户对所考虑项目的可能偏好。对于评分矩阵（如前面所示），预测就像识别缺失值（在先前的例子中用`?`表示）。
- en: The recommendation operation comes after the predictions have been done. Given
    a user, the recommendation operation generates a list of top *N* items based on
    the user's preferences.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐操作在预测完成后进行。给定一个用户，推荐操作会根据用户的偏好生成一个包含前*N*个项目的列表。
- en: Note
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that the user in consideration for the predict and recommend tasks is termed
    the **active-user** in the context of recommender engines.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在推荐引擎的上下文中，用于预测和推荐任务的用户被称为**活跃用户**。
- en: The collaborative filtering algorithm
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协同过滤算法
- en: Collaborative filters are a popular set of algorithms heavily used across applications.
    As we know, collaborative filters utilize the behaviour of similar users to predict
    and recommend items for the active user. These algorithms work on a simple assumption
    that similar users showcase similar behaviours. More formally, the algorithm assumes
    that the preferences or ratings of the other users in the system can be utilized
    to provide reasonable predictions for the active user.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤算法是一组流行的算法，在众多应用中被广泛使用。众所周知，协同过滤算法利用类似用户的行为来预测和为活跃用户推荐项目。这些算法基于一个简单的假设，即类似用户会表现出类似的行为。更正式地说，算法假设系统中其他用户的偏好或评分可以用来为活跃用户提供合理的预测。
- en: '**Neighbour-based** **collaborative filtering**, also known as **user-user
    collaborative filtering** or **kNN collaborative filtering**, is one of the earliest
    and most widely used algorithms from the family of collaborative filters. The
    kNN collaborative filter is based on the core assumption of similar behaviour
    amongst users with similar preferences. This algorithm makes use of similarity
    measures (discussed in [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let''s Help Machines Learn"), *Let''s Help Machines Learn*) to predict
    and recommend items for the active user. The algorithm follows a two-step approach
    of first computing the predictions followed by the recommendations. The three
    main components of this algorithm are discussed next.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于邻居的**协同过滤，也称为**用户-用户协同过滤**或**kNN协同过滤**，是协同过滤算法家族中最早和最广泛使用的算法之一。kNN协同过滤算法基于用户具有类似偏好的用户之间类似行为的核心假设。该算法利用相似度度量（在第2章中讨论，*让我们帮助机器学习*），来预测和为活跃用户推荐项目。该算法遵循两步方法，首先计算预测，然后进行推荐。接下来讨论该算法的三个主要组成部分。'
- en: Predictions
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测
- en: The first step of kNN CF is to make use of the ratings matrix (usually denoted
    as `R`) to calculate predictions. Since we are concerned about user-user CF, the
    neighbourhood of active user (the user in consideration), denoted as `u`, is to
    be taken into account.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: kNN CF 的第一步是利用评分矩阵（通常表示为 `R`）来计算预测。由于我们关注的是用户-用户 CF，因此需要考虑活跃用户（考虑中的用户）的邻域，表示为
    `u`。
- en: Let `U` be the set of all available users in the system and `N` denote the required
    neighbourhood where ![Predictions](img/00107.jpeg). The algorithm then uses a
    similarity measure, say `s`, to compute the neighbours of `u`. Once `N` (the neighborhood
    of `u`) has been identified, the ratings of the neighbouring users are aggregated
    to compute `u`'s preference for the current item. The most common measure to aggregate
    preferences is to use the **weighted average** of `N` neighboring users.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 设 `U` 为系统中所有可用用户的集合，`N` 表示所需的邻域 ![预测](img/00107.jpeg)。然后算法使用一个相似度度量，例如 `s`，来计算
    `u` 的邻居。一旦确定了 `N`（`u` 的邻域），就会汇总相邻用户的评分来计算 `u` 对当前项目的偏好。最常用的汇总偏好的方法是使用 `N` 个相邻用户的
    **加权平均**。
- en: 'Mathematically, the active user `u`''s predicted preference for item `i`, denoted
    as `p[ui]` is given as:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，活跃用户 `u` 对项目 `i` 的预测偏好，表示为 `p[ui]`，如下所示：
- en: '![Predictions](img/00108.jpeg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![预测](img/00108.jpeg)'
- en: 'Where:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![Predictions](img/00109.jpeg) is the active user `u''s` mean rating'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![预测](img/00109.jpeg) 是活跃用户 `u` 的平均评分'
- en: '![Predictions](img/00110.jpeg) is the similarity measure between the active
    user u and the neighbouring user ![Predictions](img/00111.jpeg)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![预测](img/00110.jpeg) 是活跃用户 `u` 和相邻用户 ![预测](img/00111.jpeg) 之间的相似度度量'
- en: 'In the preceding equation, we subtract the mean of the active user''s rating
    ![Predictions](img/00109.jpeg) from the neighbouring user''s mean rating to remove
    the rating bias of the users (some users give extremely high or low ratings and
    thus they may bias the overall predicted rating). A biased recommender engine
    might prevent better user-product matches in favour of popular or against not
    so popular ones. We can further improve the predictions by normalizing the user''s
    ratings by using standard deviation to control the rating spread across the mean.
    To keep things simple, we will use the equation as mentioned previously. The following
    image depicts the nearest neighbours for an active user:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的公式中，我们从相邻用户的平均评分中减去活跃用户评分的均值 ![预测](img/00109.jpeg)，以消除用户评分的偏差（一些用户给出极高或极低的评分，因此他们可能会影响整体预测评分）。一个有偏差的推荐引擎可能会阻碍更好的用户-产品匹配，偏向于受欢迎的产品或反对不太受欢迎的产品。我们可以通过使用标准差来规范化用户的评分，以控制评分在均值周围的分布，从而进一步提高预测的准确性。为了简化问题，我们将使用之前提到的公式。以下图像展示了活跃用户的最近邻：
- en: '![Predictions](img/00112.jpeg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![预测](img/00112.jpeg)'
- en: Nearest neighbors (*K=3*)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻（*K=3*）
- en: The question now arises that why only weighted average was used to predict the
    ratings and what the optimal number of neighbours (`N`) is. The reason behind
    using weighted average is that it is one of the measures which helps in generating
    consistent results. Different systems over the years have used various methods,
    such as *multivariate regressions* (the BellCore system for video recommendations),
    *unweighted averages* (Ringo for music recommendations), and so on, but weighted
    average performs pretty well in practice.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在出现的问题是，为什么只使用加权平均来预测评分，以及最优的邻居数量（`N`）是多少。使用加权平均的原因是，它是有助于生成一致结果的一种度量方法。多年来，不同的系统使用了各种方法，例如
    *多元回归*（BellCore 系统用于视频推荐）、*未加权平均*（Ringo 用于音乐推荐）等等，但在实践中加权平均表现相当好。
- en: Note
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more information, have a look at W. Hill, L. Stead, M. Rosenstein, and G.
    Furnas, *Recommending and evaluating choices in a virtual community of use*, in
    ACM CHI '95, pp. 194–201, ACM Press/Addison-Wesley Publishing Co., 1995.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，请参阅 W. Hill, L. Stead, M. Rosenstein, 和 G. Furnas 的论文，*在虚拟使用社区中推荐和评估选择*，发表于
    ACM CHI '95，第 194–201 页，ACM Press/Addison-Wesley 出版公司，1995年。
- en: Coming onto the second question of the optimal number of neighbours, this is
    something very application dependent. We saw in [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machines Learn*, how the
    number of neighbours can change the outcome of an algorithm (see *K-Nearest Neighbors*
    (*KNN*)), similarly the value of `N` can affect the outcome of a recommender engine.
    In general, limiting the number of neighbouring users helps in reducing the noise
    by removing users with low correlation to the active user. But then again, the
    value of `N` is application dependent and requires due diligence at the data scientist's
    end.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是关于最优邻居数量的第二个问题，这非常依赖于具体的应用。我们在[第二章](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "第二章. 让我们帮助机器学习")中看到，“让我们帮助机器学习”，邻居的数量如何改变算法的结果（参见*K-最近邻* (*KNN*)），同样，`N`的值也会影响推荐引擎的结果。一般来说，限制邻居用户数量有助于通过移除与活跃用户相关性低的用户来减少噪声。但再次强调，`N`的值依赖于具体应用，并且需要数据科学家进行适当的尽职调查。
- en: Recommendations
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推荐
- en: Once predictions have been done for the *active user*, a recommendation list
    can be generated by ordering the items by predicted rank. This recommendation
    list may be further fine-tuned by applying certain minimal thresholds and other
    user specific characteristics, such as preferences for color, size, price sensitivity,
    and so on. Thus, this step generates a list of probable items which the user is
    more likely to buy based on his/her personal preferences. We will cover more on
    this in the coming section, *Building a recommender engine*.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦对*活跃用户*进行了预测，可以通过按预测排名对项目进行排序来生成推荐列表。这个推荐列表可以通过应用某些最小阈值和其他用户特定特征（如对颜色、尺寸、价格敏感度等）进一步微调。因此，这一步生成了一份可能的项目列表，用户更有可能根据个人偏好购买这些项目。我们将在下一节“构建推荐引擎”中详细介绍这一点。
- en: Similarity
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相似度
- en: A similarity measure is an important component of our collaborative filtering
    based recommender engine algorithm. There are various similarity measures available
    for use. The most common amongst them is the **cosine similarity** measure. This
    approach represents each user as an `n` dimensional vector of ratings and similarity
    is measured by calculating the cosine distance between two such user vectors.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 相似度度量是我们基于协同过滤的推荐引擎算法的一个重要组成部分。有各种相似度度量可供使用。其中最常见的是**余弦相似度**度量。这种方法将每个用户表示为一个`n`维度的评分向量，相似度通过计算两个此类用户向量之间的余弦距离来衡量。
- en: 'Mathematically, cosine similarity is given as:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，余弦相似度表示为：
- en: '![Similarity](img/00113.jpeg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![相似度](img/00113.jpeg)'
- en: Where, ![Similarity](img/00114.jpeg) and ![Similarity](img/00115.jpeg) are the
    **L2** or **Euclidean ** **norms** for each of the rating vectors.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，![相似度](img/00114.jpeg)和![相似度](img/00115.jpeg)是每个评分向量的**L2**或**欧几里得**范数。
- en: '**Pearson** **correlation** and **Spearman rank correlation** are a couple
    of statistical similarity measures which are also used widely.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**皮尔逊** **相关系数**和**斯皮尔曼秩相关系数**是两种广泛使用的统计相似度度量。'
- en: Now that we understand the basics of collaborative filters and general concepts,
    we are ready to get our hands dirty with implementation details. Let us start
    with building the recommender system, brick-by-brick!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了协同过滤和一般概念的基础，我们准备着手处理实现细节。让我们从构建推荐系统，一块一块地开始！
- en: Building a recommender engine
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建推荐引擎
- en: As discussed in the previous section, collaborative filtering is a simple yet
    very effective approach for predicting and recommending items to users. If we
    look closely, the algorithms work on input data, which is nothing but a matrix
    representation of the user ratings for different products.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，协同过滤是一种简单而非常有效的预测和推荐项目给用户的方法。如果我们仔细观察，算法是针对输入数据工作的，这实际上只是不同产品用户评分的矩阵表示。
- en: Bringing in a mathematical perspective into the picture, **matrix factorization**
    is a technique to manipulate matrices and identify latent or hidden features from
    the data represented in the matrix. Building on the same concept, let us use matrix
    factorization as the basis for predicting ratings for items which the user has
    not yet rated.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度来说，**矩阵分解**是一种操纵矩阵并从矩阵表示的数据中识别潜在或隐藏特征的技术。基于同样的概念，让我们使用矩阵分解作为预测用户尚未评分的项目评分的基础。
- en: Matrix factorization
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵分解
- en: Matrix factorization refers to the identification of two or more matrices such
    that when these matrices are multiplied we get the original matrix. Matrix factorization,
    as mentioned earlier, can be used to discover latent features between two different
    kinds of entities. We will understand and use the concepts of matrix factorization
    as we go along preparing our recommender engine for our e-commerce platform.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵分解指的是识别两个或多个矩阵，当这些矩阵相乘时，我们得到原始矩阵。如前所述，矩阵分解可以用来发现两种不同实体之间的潜在特征。随着我们为电子商务平台准备推荐引擎，我们将理解和使用矩阵分解的概念。
- en: 'As our aim for the current project is to personalize the shopping experience
    and recommend product ratings for an e-commerce platform, our input data contains
    user ratings for various products on the website. We process the input data and
    transform it into a matrix representation for analyzing it using matrix factorization.
    The input data looks like this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们当前项目的目标是个性化购物体验并为电子商务平台推荐产品评分，我们的输入数据包含网站上各种产品的用户评分。我们处理输入数据，将其转换为矩阵表示，以便使用矩阵分解进行分析。输入数据看起来像这样：
- en: '![Matrix factorization](img/00116.jpeg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解](img/00116.jpeg)'
- en: User ratings matrix
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 用户评分矩阵
- en: As you can see, the input data is a matrix with each row representing a particular
    user's rating for different items represented in the columns. For the current
    case, the columns representing items are different mobile phones such as iPhone
    4, iPhone 5s, Nexus 5, and so on. Each row contains ratings for each of these
    mobile phones as given by eight different users. The ratings range from 1 to 5
    with 1 being the lowest and 5 being the highest. A rating of 0 represents unrated
    items or missing rating.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，输入数据是一个矩阵，其中每一行代表特定用户对不同项目（在列中表示）的评分。对于当前情况，表示项目的列是不同的手机，如iPhone 4、iPhone
    5s、Nexus 5等。每一行包含由八个不同用户给出的这些手机的评分。评分范围从1到5，1为最低，5为最高。评分为0表示未评分的项目或缺失的评分。
- en: The task of our recommender engine will be to predict the correct rating for
    the missing ones in the input matrix. We could then use the predicted ratings
    to recommend items most desired by the user.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们推荐引擎的任务将是预测输入矩阵中缺失的正确评分。然后我们可以使用预测的评分来推荐用户最希望得到的物品。
- en: The premise here is that two users would rate a product similarly if they like
    similar features of the product or item. Since our current data is related to
    user ratings for different mobile phones, people might rate the phones based on
    their hardware configuration, price, OS, and so on. Hence, matrix factorization
    tries to identify these latent features to predict ratings for a certain user
    and a certain product.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里的前提是，如果两个用户喜欢类似的产品或物品特征，他们会对该产品或物品进行相似的评分。由于我们当前的数据与不同手机的用户评分相关，人们可能会根据硬件配置、价格、操作系统等因素对手机进行评分。因此，矩阵分解试图识别这些潜在特征，以预测特定用户和特定产品的评分。
- en: While trying to identify these latent features, we proceed with the basic assumption
    that the number of such features is less than the total number of items in consideration.
    This assumption makes sense because if this was the case, then each user would
    have a specific feature associated with him/her (and similarly for the product).
    This would in turn make recommendations futile as none of the users would be interested
    in items rated by other users (which is not usually the case).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试识别这些潜在特征时，我们基于一个基本假设进行操作，即这些特征的数目少于考虑中的项目总数。这个假设是有意义的，因为如果是这样的话，那么每个用户都会有一个与他自己/她自己（以及类似地对于产品）相关的特定特征。这反过来会使推荐变得毫无意义，因为没有任何用户会对其他用户评分的项目感兴趣（这通常不是情况）。
- en: Now let us get into the mathematical details of matrix factorization and our
    recommender engine.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们深入了解矩阵分解和我们的推荐引擎的数学细节。
- en: Since we are dealing with user ratings for different products, let us assume
    `U` to be a matrix representing user preferences and similarly a matrix `P` represents
    the products for which we have the ratings. Then the ratings matrix `R` will be
    defined as ![Matrix factorization](img/00117.jpeg).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们处理的是不同产品的用户评分，让我们假设`U`是一个表示用户偏好的矩阵，同样地，一个矩阵`P`表示我们对其有评分的产品。然后评分矩阵`R`将被定义为![矩阵分解](img/00117.jpeg)。
- en: Assuming the process helps us identify `K` latent features, our aim is to find
    two matrices `X` and `Y` such that their product (matrix multiplication) approximates
    `R`.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这个过程帮助我们识别出 `K` 个潜在特征，我们的目标是找到两个矩阵 `X` 和 `Y`，使得它们的乘积（矩阵乘法）近似于 `R`。
- en: '![Matrix factorization](img/00118.jpeg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解](img/00118.jpeg)'
- en: Where, `X` is a user related matrix which represents the associations between
    the users and the latent features. `Y`, on the other hand, is the product related
    matrix which represents the associations between the products and the latent features.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，`X` 是与用户相关的矩阵，它表示用户和潜在特征之间的关联。另一方面，`Y` 是与产品相关的矩阵，它表示产品和潜在特征之间的关联。
- en: The task of predicting the rating ![Matrix factorization](img/00119.jpeg) of
    a product `p[j]` by a user `u[i]` is done by calculating the dot product of the
    vectors corresponding to `p[j]` (`vector Y`, that is the user) and `u[i]` (`vector
    X`, that is the product`)`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 预测用户 `u[i]` 对产品 `p[j]` 的评分 ![矩阵分解](img/00119.jpeg) 的任务是通过计算对应于 `p[j]` 的向量（即用户向量
    Y）和 `u[i]` 的向量（即产品向量 X）的点积来完成的。
- en: '![Matrix factorization](img/00120.jpeg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解](img/00120.jpeg)'
- en: Now, to find the matrices `X` and `Y`, we utilize a technique called **gradient
    descent**. Gradient descent, in simple terms, tries to find the local minimum
    of a function; it is an optimization technique. We use gradient descent in the
    current context to iteratively minimize the difference between the predicted ratings
    and the actual ratings. To begin with, we randomly initialize the matrices `X`
    and `Y` and then calculate how different their product is from the actual ratings
    matrix `R`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了找到矩阵 `X` 和 `Y`，我们利用一种称为 **梯度下降** 的技术。简单来说，梯度下降试图找到一个函数的局部最小值；它是一种优化技术。在当前上下文中，我们使用梯度下降来迭代地最小化预测评分和实际评分之间的差异。首先，我们随机初始化矩阵
    `X` 和 `Y`，然后计算它们的乘积与实际评分矩阵 `R` 的差异。
- en: 'The difference between the predicted and the actual values is what is termed
    the **error**. For our problem, we will consider the **squared error,** which
    is calculated as:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 预测值和实际值之间的差异被称为 **误差**。对于我们的问题，我们将考虑 **平方误差**，其计算方式如下：
- en: '![Matrix factorization](img/00121.jpeg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解](img/00121.jpeg)'
- en: Where, `r[ij]` is the actual rating by user `i` for product `j` and ![Matrix
    factorization](img/00119.jpeg) is the predicted value of the same.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`r[ij]` 是用户 `i` 对产品 `j` 的实际评分，而 ![矩阵分解](img/00119.jpeg) 是相同评分的预测值。
- en: 'To minimize the error, we need to find the correct direction or gradient to
    change our values to. To obtain the gradient for each of the variables `x` and
    `y`, we differentiate them separately as:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最小化误差，我们需要找到正确的方向或梯度来改变我们的值。为了获得变量 `x` 和 `y` 的梯度，我们分别对它们进行微分：
- en: '![Matrix factorization](img/00122.jpeg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解](img/00122.jpeg)'
- en: 'Hence, the equations to find `x[ik]` and `y[kj]` can be given as:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，找到 `x[ik]` 和 `y[kj]` 的方程可以表示为：
- en: '![Matrix factorization](img/00123.jpeg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解](img/00123.jpeg)'
- en: Where `α` is the constant to denote the **rate of descent** or the rate of approaching
    the minima (also known as the learning rate). The value of `α` defines the size
    of steps we take in either direction to reach the minima. Large values may lead
    to oscillations as we may overshoot the minima every time. Usual practice is to
    select very small values for `α`, of the order `10^(-4)`. ![Matrix factorization](img/00124.jpeg)
    and ![Matrix factorization](img/00125.jpeg) are the updated values of `x[ik]`
    and `y[kj]` after each iteration of gradient descent.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，`α` 是表示 **下降率** 或接近最小值的速率的常数（也称为学习率）。`α` 的值定义了我们在两个方向上采取的步长的大小。较大的值可能导致振荡，因为我们可能会每次都超过最小值。通常的做法是选择非常小的
    `α` 值，大约为 `10^(-4)`。![矩阵分解](img/00124.jpeg) 和 ![矩阵分解](img/00125.jpeg) 是梯度下降每次迭代后
    `x[ik]` 和 `y[kj]` 的更新值。
- en: As seen in [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machines Learn*, machine
    learning algorithms can suffer from overfitting. To avoid overfitting, along with
    controlling extreme or large values in the matrices `X` and `Y`, we introduce
    the concept of regularization. Formally, **regularization** refers to the process
    of introducing additional information in order to prevent overfitting. Regularization
    penalizes models with extreme values.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第二章](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8 "第二章。让我们帮助机器学习")中所述，在《让我们帮助机器学习》中，机器学习算法可能会出现过拟合问题。为了避免过拟合，除了控制矩阵`X`和`Y`中的极端或大值外，我们引入了正则化的概念。正式来说，**正则化**是指引入额外信息以防止过拟合的过程。正则化会惩罚具有极端值的模型。
- en: 'To prevent overfitting in our case, we introduce the regularization constant
    called `β`. With the introduction of `β`, the equations are updated as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止我们的模型过拟合，我们引入了正则化常数`β`。引入`β`后，方程更新如下：
- en: '![Matrix factorization](img/00126.jpeg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解](img/00126.jpeg)'
- en: Also,
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，
- en: '![Matrix factorization](img/00127.jpeg)![Matrix factorization](img/00128.jpeg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解](img/00127.jpeg)![矩阵分解](img/00128.jpeg)'
- en: As we already have the ratings matrix `R` and we use it to determine how far
    our predicted values are from the actual, matrix factorization turns into a supervised
    learning problem. For this supervised problem, just as we saw in [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machines Learn*, we use some
    of the rows as our training samples. Let `S` be our training set with elements
    being tuples of the form `(u[i], p[j], r[ij])`. Thus, our task is to minimize
    the error (`e[ij]`) for every tuple `(u[i], p[j], r[ij])` `є` in training set
    `S`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经有评分矩阵`R`，并使用它来确定我们的预测值与实际值之间的距离，矩阵分解变成了一个监督学习问题。对于这个监督问题，正如我们在[第二章](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "第二章。让我们帮助机器学习")中看到的，《让我们帮助机器学习》，我们使用一些行作为我们的训练样本。设`S`为我们的训练集，其元素为形式为`(u[i], p[j],
    r[ij])`的元组。因此，我们的任务是使训练集`S`中每个元组`(u[i], p[j], r[ij])`的误差(`e[ij]`)最小化。
- en: 'The overall error (say `E`) can be calculated as:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 总体误差（例如`E`）可以计算如下：
- en: '![Matrix factorization](img/00129.jpeg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵分解](img/00129.jpeg)'
- en: Implementation
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: Now that we have looked into the mathematics of matrix factorization, let us
    convert the algorithm into code and prepare a recommender engine for the mobile
    phone ratings input data set discussed earlier.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经研究了矩阵分解的数学原理，让我们将算法转换为代码，并为之前讨论的移动电话评分数据集准备推荐引擎。
- en: As shown in the *Matrix factorization* section, the input dataset is a matrix
    with each row representing a user's rating for the products mentioned as columns.
    The ratings range from 1 to 5 with 0 representing the missing values.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如*矩阵分解*部分所示，输入数据集是一个矩阵，其中每一行代表用户对列中提到的产品的评分。评分范围从1到5，0代表缺失值。
- en: 'To transform our algorithm into working code, we need to compute and complete
    the following tasks:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们的算法转换为可工作的代码，我们需要完成以下任务：
- en: Load the input data and transform it into ratings matrix representation
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载输入数据并将其转换为评分矩阵表示
- en: Prepare a matrix factorization based recommendation model
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备基于矩阵分解的推荐模型
- en: Predict and recommend products to the users
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测并向用户推荐产品
- en: Interpret and evaluate the model
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释和评估模型
- en: Loading and transforming input data into matrix representation is simple. As
    seen earlier, R provides us with easy to use utility functions for the same.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 加载并将输入数据转换为矩阵表示很简单。如前所述，R为我们提供了易于使用的实用函数来完成这项任务。
- en: '[PRE0]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that we have our data loaded into an `R` matrix, we proceed and prepare
    the user-latent features matrix `X` and item-latent features matrix `Y`. We initialize
    both from uniform distributions using the `runif` function.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将数据加载到`R`矩阵中，我们继续准备用户潜在特征矩阵`X`和项目潜在特征矩阵`Y`。我们使用`runif`函数从均匀分布中初始化这两个矩阵。
- en: '[PRE1]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The major component is the matrix factorization function itself. Let us split
    the task into two, calculation of the gradient and subsequently the overall error.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 主要组成部分是矩阵分解函数本身。让我们将任务分为两部分，计算梯度以及随后计算总体误差。
- en: The calculation of the gradient involves the ratings matrix `R` and the two
    factor matrices `X` and `Y,` along with the constants `α` and `β`. Since we are
    dealing with matrix manipulations (specifically, multiplication), we transpose
    `Y` before we begin with any further calculations. The following lines of code
    convert the algorithm discussed previously into R syntax. All variables follow
    naming convention similar to the algorithm for ease of understanding.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度计算的涉及评分矩阵 `R` 和两个因子矩阵 `X` 和 `Y`，以及常数 `α` 和 `β`。由于我们处理的是矩阵操作（特别是乘法），我们在开始任何进一步的计算之前将
    `Y` 转置。以下代码行将之前讨论的算法转换为 R 语法。所有变量都遵循与算法相似的命名约定，以便于理解。
- en: '[PRE2]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The next part of the algorithm is to calculate the overall error; we again
    use similar variable names for consistency:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的下一部分是计算整体误差；我们再次使用相似的变量名以保持一致性：
- en: '[PRE3]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As a final piece, we iterate over these calculations multiple times to mitigate
    the risks of cold start and sparsity. We term the variable controlling multiple
    starts as **epoch**. We also terminate the calculations once the overall error
    drops below a certain threshold.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一部分，我们多次迭代这些计算以减轻冷启动和稀疏性的风险。我们将控制多次启动的变量称为**epoch**。一旦整体误差下降到某个阈值以下，我们也会停止计算。
- en: Moreover, as we had initialized `X` and `Y` from uniform distributions, the
    predicted values would be real numbers. We round the final output before returning
    the predicted matrix.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于我们从均匀分布初始化了 `X` 和 `Y`，预测值将是实数。在返回预测矩阵之前，我们将最终输出四舍五入。
- en: Note that this is a very simplistic implementation and a lot of complexity has
    been kept out for ease of understanding. Hence, this may result in the predicted
    matrix containing values greater than 5\. For the current scenario, it is safe
    to assume the values above the max scale of 5 are equivalent to 5 (and similarly
    for values less than 0). We encourage the reader to fine tune the code to handle
    such cases.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这是一个非常简单的实现，为了便于理解，省略了很多复杂性。因此，预测矩阵中可能包含大于5的值。对于当前场景，可以安全地假设超过5的最大刻度值等同于5（同样适用于小于0的值）。我们鼓励读者调整代码以处理此类情况。
- en: 'Setting `α` to `0.0002`, `β` to `0.02`, `K` (that is, latent features) to `2`,
    and `epoch` to `1000`, let us see a sample run of our code with overall error
    threshold set to `0.001`:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `α` 设置为 `0.0002`，`β` 设置为 `0.02`，`K`（即潜在特征）设置为 `2`，并将 `epoch` 设置为 `1000`，让我们看看我们的代码的一个样本运行，整体误差阈值设置为
    `0.001`：
- en: '[PRE4]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding lines of code utilize the functions explained earlier to prepare
    the recommendation model. The predicted ratings or the output matrix looks like
    the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码行利用前面解释过的函数来准备推荐模型。预测评分或输出矩阵看起来如下：
- en: '![Implementation](img/00130.jpeg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![实现](img/00130.jpeg)'
- en: Predicted ratings matrix
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 预测评分矩阵
- en: Result interpretation
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果解释
- en: 'Let us do a quick visual inspection to see how good or bad our predictions
    have been. Consider users 1 and 3 as our training samples. From the input dataset,
    we can clearly see that user 1 has given high ratings to iPhones while user 3
    has done the same for Android based phones. The following side by side comparison
    shows that our algorithm has predicted values close enough to the actual values:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速进行视觉检查，看看我们的预测做得有多好或有多差。以用户1和用户3作为我们的训练样本。从输入数据集中，我们可以清楚地看到用户1对iPhone给出了高评分，而用户3对基于Android的手机也做了同样的操作。以下并排比较显示了我们的算法预测的值与实际值非常接近：
- en: '![Result interpretation](img/00131.jpeg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![结果解释](img/00131.jpeg)'
- en: Ratings by user 1
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 用户1的评分
- en: 'Let us see the ratings of user 3 in the following screenshot:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看以下截图中的用户3的评分：
- en: '![Result interpretation](img/00132.jpeg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![结果解释](img/00132.jpeg)'
- en: Ratings by user 3
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 用户3的评分
- en: Now that we have our ratings matrix with updated values, we are ready to recommend
    products to users. It is common sense to show only the products which the user
    hasn't rated yet. The right set of recommendations will also enable the seller
    to pitch the products which have high probability of being purchased by the user.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了更新值的评分矩阵，我们准备向用户推荐产品。只显示用户尚未评分的产品是常识。正确的推荐集也将使卖家能够推销那些有较高概率被用户购买的产品。
- en: The usual practice is to return a list of the top *N* items from the unrated
    list of products for each user. The user in consideration is usually termed the
    **active-user**. Let us consider user 6 as our active-user. This user has only
    rated Nexus 6, One Plus One, Nexus 5, and iPhone4 in that order of rating, that
    is Nexus 6 was highly rated and iPhone4 was rated the least. Getting a list of
    the *Top 2* recommended phones for such a customer using our algorithm would result
    in Moto X and Moto G (very rightly indeed, do you see why?).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 常规做法是返回每个用户未评分产品列表中排名前*N*的项目列表。考虑的用户通常被称为**活跃用户**。让我们以用户6作为我们的活跃用户。这位用户只按以下顺序对Nexus
    6、One Plus One、Nexus 5和iPhone4进行了评分，即Nexus 6评分很高，而iPhone4评分最低。使用我们的算法为这样的客户提供*Top
    2*推荐手机的结果将是Moto X和Moto G（确实非常正确，你明白为什么吗？）。
- en: Thus, we built a recommender engine smart enough to recommend the right mobile
    phones to an Android fanboy and saved the world from yet another catastrophe!
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们构建了一个足够智能的推荐引擎，能够为安卓爱好者推荐合适的手机，并拯救了世界免于又一次灾难！
- en: '*Data to the rescue!*'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据拯救！*'
- en: This simple implementation of a recommender engine using matrix factorization
    gave us a flavor of how such a system actually works. Next, let us get into some
    real world action using recommender engines.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用矩阵分解的简单推荐引擎实现让我们领略了此类系统实际运作的方式。接下来，让我们通过使用推荐引擎来进入一些实际操作。
- en: Production ready recommender engines
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 适用于生产的推荐引擎
- en: In this chapter so far, we have learnt about recommender engines in detail and
    even developed one from scratch (using matrix factorization). Through all this,
    it is clearly evident how widespread the application of such systems is.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经详细了解了推荐引擎，甚至从头开始开发了一个（使用矩阵分解）。通过所有这些，我们可以清楚地看到此类系统的应用范围是多么广泛。
- en: E-commerce websites (or for that fact, any popular technology platform) out
    there today have tones of content to offer. Not only that, but the number of users
    is also huge. In such a scenario, where thousands of users are browsing/buying
    stuff simultaneously across the globe, providing recommendations to them is a
    task in itself. To complicate things even further, a good user experience (response
    times, for example) can create a big difference between two competitors. These
    are live examples of production systems handling millions of customers day in
    and day out.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 电子商务网站（或者更确切地说，任何流行的技术平台）今天都提供了大量的内容。不仅如此，用户数量也非常庞大。在这种场景下，当成千上万的用户在全球范围内同时浏览/购买商品时，为他们提供推荐本身就是一项任务。更复杂的是，良好的用户体验（例如响应时间）可以在两个竞争对手之间产生巨大差异。这些都是处理数百万客户日复一日生产的实时系统实例。
- en: Note
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Fun Fact**'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**有趣的事实**'
- en: Amazon.com is one of the biggest names in the e-commerce space with 244 million
    active customers. Imagine the amount of data being processed to provide recommendations
    to such a huge customer base browsing through millions of products!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon.com是电子商务领域最大的名字之一，拥有2.44亿活跃客户。想象一下，为了向如此庞大的客户群提供推荐，需要处理多少数据！
- en: 'Source: [http://www.amazon.com/b?ie=UTF8&node=8445211011](http://www.amazon.com/b?ie=UTF8&node=8445211011)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[http://www.amazon.com/b?ie=UTF8&node=8445211011](http://www.amazon.com/b?ie=UTF8&node=8445211011)
- en: In order to provide a seamless capability for use in such platforms, we need
    highly optimized libraries and hardware. For a recommender engine to handle thousands
    of users simultaneously every second, R has a robust and reliable framework called
    the **recommenderlab**.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在这些平台上提供无缝的使用能力，我们需要高度优化的库和硬件。对于一个推荐引擎来说，要同时处理每秒成千上万的用户，R 语言有一个强大且可靠的框架，称为**recommenderlab**。
- en: Recommenderlab is a widely used R extension designed to provide a robust foundation
    for recommender engines. The focus of this library is to provide efficient handling
    of data, availability of standard algorithms and evaluation capabilities. In this
    section, we will be using recommenderlab to handle a considerably larger data
    set for recommending items to users. We will also use the evaluation functions
    from recommenderlab to see how good or bad our recommendation system is. These
    capabilities will help us build a production ready recommender system similar
    (or at least closer) to what many online applications such as Amazon or Netflix
    use.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: The dataset used in this section contains ratings for 100 items as rated by
    5000 users. The data has been anonymized and the product names have been replaced
    by product IDs. The rating scale used is 0 to 5 with 1 being the worst, 5 being
    the best, and 0 representing unrated items or missing ratings.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'To build a recommender engine using recommenderlab for a production ready system,
    the following steps are to be performed:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Extract, transform, and analyze the data.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prepare a recommendation model and generate recommendations.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the recommendation model.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will look at all these steps in the following subsections.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Extract, transform, and analyze
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As in case of any data intensive (particularly machine learning) application,
    the first and foremost step is to get the data, understand/explore it, and then
    transform it into the format required by the algorithm deemed fit for the current
    application. For our recommender engine using the recommenderlab package, we will
    first load the data from a csv file described in the previous section and then
    explore it using various R functions.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The preceding section of code loads the recommenderlab package and then uses
    the standard utility function to read the `product_ratings_data.csv` file. For
    exploratory as well as further steps, we need the data to be transformed into
    the user-item ratings matrix format (as described in the *Core concepts and definitions*
    section).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: The `as(<data>,<type>)` utility converts `csv` into the required ratings matrix
    format.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: The `csv` file contains data in the format shown in the following screenshot.
    Each row contains a user's rating for a specific product. The column headers are
    self explanatory.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '![Extract, transform, and analyze](img/00133.jpeg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
- en: Product ratings data
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: The `realRatingMatrix` conversion transforms the data into a matrix as shown
    in the following image. The users are depicted as rows while the columns represent
    the products. Ratings are represented using a gradient scale where white represents
    missing/unrated rating while black denotes a rating of 5/best.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![Extract, transform, and analyze](img/00134.jpeg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: Ratings matrix representation of our data
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the data in our environment, let us explore some of its characteristics
    and see if we can decipher some key patterns.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we extract a representative sample from our main data set (refer
    to the screenshot *Product ratings data*) and analyze it for:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从主数据集中提取一个代表性样本（参见图 *产品评分数据*）并对其进行分析，以了解：
- en: Average rating score for our user population
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们用户群体的平均评分分数
- en: Spread/distribution of item ratings across the user population
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户群体中项目评分的分布/扩散
- en: Number of items rated per user
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个用户评分的项目数量
- en: 'The following lines of code help us explore our data set sample and analyze
    the points mentioned previously:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码行帮助我们探索数据集样本并分析之前提到的点：
- en: '[PRE6]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We extract a sample of 1,000 users from our dataset for exploration purposes.
    The mean of product ratings as given by the first row in our user-rating sample
    is `2.055`. This tells us that this user either hasn''t seen/rated many products
    or he usually rates the products pretty low. To get a better idea of how the users
    rate products, we generate a histogram of item rating distribution. This distribution
    peaks around the middle, that is, `3`. The histogram is shown next:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从数据集中提取了1,000个用户的样本用于探索目的。用户评分的平均值，即用户评分样本的第一行给出的`2.055`，告诉我们这个用户要么没有看到/评分很多产品，要么通常评分很低。为了更好地了解用户如何评分产品，我们生成了一个项目评分分布的直方图。这个分布峰值在中间，即`3`。直方图如下所示：
- en: '![Extract, transform, and analyze](img/00135.jpeg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![提取、转换和分析](img/00135.jpeg)'
- en: Histogram for ratings distribution
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 评分分布的直方图
- en: The histogram shows that the ratings are normally distributed around the mean
    with low counts for products with very high or very low ratings.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图显示评分围绕平均值正常分布，对于评分非常高或非常低的产品计数较低。
- en: 'Finally, we check the spread of the number of products rated by the users.
    We prepare a histogram which shows this spread:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们检查用户评分产品数量的分布。我们准备了一个直方图来显示这种分布：
- en: '![Extract, transform, and analyze](img/00136.jpeg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![提取、转换和分析](img/00136.jpeg)'
- en: Histogram of number of rated products
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 评分数量的直方图
- en: The preceding histogram shows that there are many users who have rated `70`
    or more products, as well as there are many users who have rated all `100` products.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的直方图显示有许多用户评分了`70`个或更多的产品，同样也有许多用户评分了所有`100`个产品。
- en: The exploration step helps us get an idea of how our data is. We also get an
    idea about the way the users generally rate the products and how many products
    are being rated.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 探索步骤帮助我们了解我们的数据是什么样的。我们还对用户通常如何评分产品以及有多少产品被评分有了了解。
- en: Model preparation and prediction
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型准备和预测
- en: We have the data in our R environment which has been transformed into the ratings
    matrix format. In this section, we are interested in preparing a recommender engine
    based on user-based collaborative filtering. We will be using similar terminology
    as described in the previous sections. Recommenderlab provides straight-forward
    utilities to learn and prepare a model for building recommender engines.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据已经在我们转换成评分矩阵格式的R环境中。在本节中，我们感兴趣的是基于用户协同过滤准备推荐引擎。我们将使用与之前章节中描述的类似术语。Recommenderlab提供了直观的实用工具来学习和准备构建推荐引擎的模型。
- en: 'We prepare our model based upon a sample of just 1,000 users. This way, we
    can use this model to predict the missing ratings for the rest of the users in
    our ratings matrix. The following lines of code utilize the first thousand rows
    for learning the model:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基于仅1,000个用户的样本来准备我们的模型。这样，我们可以使用这个模型来预测评分矩阵中其余用户的缺失评分。以下代码行利用前1,000行来学习模型：
- en: '[PRE7]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '"`UBCF`" in the preceding code signifies user-based collaborative filtering.
    Recommenderlab also provides other algorithms, such as **IBCF** or **Item-Based
    Collaborative Filtering**, **PCA** or **Principal Component Analysis**, and others
    as well.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中的"`UBCF`"代表基于用户的协同过滤。Recommenderlab还提供了其他算法，例如**IBCF**或**基于项目的协同过滤**，**PCA**或**主成分分析**，以及其他算法。
- en: After preparing the model, we use it to predict the ratings for our 1,010^(th)
    and 1,011^(th) users in the system. Recommenderlab also requires us to mention
    the number of items to be recommended to the users (in the order of preference
    of course). For the current case, we mention 5 as the number of items to be recommended.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备模型之后，我们使用它来预测系统中第1,010个和第1,011个用户的评分。Recommenderlab还要求我们提及要推荐给用户的物品数量（当然按照偏好顺序）。对于当前情况，我们提到推荐5个物品。
- en: '[PRE8]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The preceding lines of code generate two lists, one for each of the users. Each
    element in these lists is a product for recommendation. The model predicted that,
    for user 1,010, product `prod_93` should be recommended as the top most product
    followed by `prod_79`, and so on.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了两个列表，每个列表对应一个用户。这些列表中的每个元素都是推荐的产品。模型预测，对于用户 1,010，应该推荐产品 `prod_93` 作为最推荐的产品，其次是
    `prod_79`，依此类推。
- en: '[PRE9]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Recommenderlab is a robust platform which is optimized to handle large datasets.
    With a few lines of code, we were able to load the data, learn a model, and even
    recommend products to the users in virtually no time. Compare this with the basic
    recommender engine we developed using matrix factorization which involved many
    lines of code (when compared to recommenderlab) apart from the obvious difference
    in performance.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Recommenderlab 是一个健壮的平台，经过优化以处理大型数据集。我们只需几行代码就能加载数据，学习模型，甚至在几乎没有任何时间的情况下向用户推荐产品。与使用矩阵分解开发的简单推荐引擎相比（与
    recommenderlab 相比，代码行数很多），除了明显的性能差异之外，这也有很大的不同。
- en: Model evaluation
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估
- en: We have successfully prepared a model and used it for predicting and recommending
    products to the users in our system. But what do we know about the accuracy of
    our model? To evaluate the prepared model, recommenderlab has handy and easy to
    use utilities. Since we need to evaluate our model, we need to split it into training
    and test data sets. Also, recommenderlab requires us to mention the number of
    items to be used for testing (it uses the rest for computing the error).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功准备了一个模型，并使用它来预测和向系统中的用户推荐产品。但我们对我们模型的准确性了解多少？为了评估准备好的模型，recommenderlab
    提供了方便易用的工具。由于我们需要评估我们的模型，我们需要将其分为训练数据和测试数据集。此外，recommenderlab 要求我们说明用于测试的物品数量（它使用其余部分来计算误差）。
- en: For the current case, we will use 500 users to prepare an evaluation model.
    The model will be based on a 90-10 training-testing dataset split with 15 items
    used for test sets.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 对于当前案例，我们将使用 500 个用户来准备一个评估模型。该模型将基于 90-10 的训练-测试数据集分割，其中 15 个项目用于测试集。
- en: '[PRE10]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We use the evaluation scheme to train our model based on the *UBCF* algorithm.
    The prepared model from the training dataset is used to predict ratings for the
    given items. We finally use the method `calcPredictionAccuracy` to calculate the
    error in predicting the ratings between known and unknown components of the test
    set. For our case, we get an output as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用基于 *UBCF* 算法的评估方案来训练我们的模型。从训练数据集中准备好的模型用于预测给定项目的评分。我们最终使用 `calcPredictionAccuracy`
    方法来计算测试集中已知和未知成分预测评分之间的误差。对于我们的案例，我们得到以下输出：
- en: '![Model evaluation](img/00137.jpeg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![模型评估](img/00137.jpeg)'
- en: The generated output mentions the values for **RMSE** or root mean squared error,
    **MSE** or mean squared error, and **MAE** or mean absolute error. For RMSE in
    particular, the values deviate from the correct values by `1.162` (note that the
    values might deviate slightly across runs due to various factors such as sampling,
    iterations, and so on). This evaluation will make more sense when the outcomes
    are compared from different CF algorithms.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的输出提到了 **RMSE**（均方根误差）、**MSE**（均方误差）和 **MAE**（平均绝对误差）的值。特别是对于 RMSE，其值与正确值相差
    `1.162`（请注意，由于采样、迭代等各种因素，值可能略有偏差）。当将不同 CF 算法的输出进行比较时，这种评估将更有意义。
- en: 'To evaluate UBCF, we use IBCF as comparison. The following few lines of code
    help us prepare an IBCF based model and test the ratings, which can then be compared
    using the `calcPredictionAccuracy` utility:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 UBCF，我们使用 IBCF 作为比较。以下几行代码帮助我们准备一个基于 IBCF 的模型并测试评分，然后可以使用 `calcPredictionAccuracy`
    工具进行比较：
- en: '[PRE11]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The comparative output shows that UBCF outperforms IBCF with lower values of
    RMSE, MSE, and MAE.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 比较输出显示，UBCF 在 RMSE、MSE 和 MAE 的值方面优于 IBCF。
- en: '![Model evaluation](img/00138.jpeg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![模型评估](img/00138.jpeg)'
- en: Similarly, we can use the other algorithms available in recommenderlab to test/evaluate
    our models. We encourage the user to try out a few more and see which algorithm
    has the least error in predicted ratings.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以使用 recommenderlab 中可用的其他算法来测试/评估我们的模型。我们鼓励用户尝试更多，看看哪个算法在预测评分中的误差最小。
- en: Summary
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we continued our pursuit of using machine learning in the field
    of e-commerce to enhance sales and overall user experience. The previous chapter
    had discussed recommendations based on transactional logs; in this chapter, we
    accounted for the human factor and looked into the recommendation engines based
    on user behavior.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们继续追求在电子商务领域应用机器学习以提升销售和整体用户体验。上一章讨论了基于交易日志的推荐；在本章中，我们考虑了人为因素，并探讨了基于用户行为的推荐引擎。
- en: We started off by understanding what recommendation systems and their classifications
    into user-based, content-based, and hybrid recommender systems. We touched on
    the problems associated with recommender engines in general. Then we dived deep
    into the specifics of collaborative filters and discussed the math around prediction
    and similarity measures. After getting our basics straight, we moved onto building
    a recommender engine of our own from scratch. We utilized matrix factorization
    to build a recommender engine step by step using a small dummy dataset. We then
    moved onto building a production ready recommender engine using R's popular library
    called recommenderlab. We used user-based CF as our core algorithm to build a
    recommendation model on a bigger dataset containing ratings for 100 products by
    5,000 users. We closed our discussion by evaluating our recommendation model using
    recommenderlab's utility methods.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先理解了推荐系统及其分类为基于用户、基于内容和混合推荐系统。我们简要提到了与推荐引擎相关的一般性问题。然后我们深入探讨了协同过滤的具体细节，并讨论了预测和相似度度量的数学原理。在弄清楚基础知识后，我们从头开始构建自己的推荐引擎。我们使用矩阵分解，通过一个小型虚拟数据集逐步构建推荐引擎。然后我们转向使用R语言中流行的库recommenderlab来构建一个生产就绪的推荐引擎。我们使用基于用户的CF作为核心算法，在一个包含5,000个用户对100个产品进行评分的大数据集上构建推荐模型。我们通过使用recommenderlab的实用方法来评估我们的推荐模型来结束我们的讨论。
- en: The next couple of chapters will move from e-commerce to the financial domain
    and utilize machine learning for some more interesting use cases.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的几章将从电子商务领域转向金融领域，并利用机器学习来处理一些更有趣的应用场景。
