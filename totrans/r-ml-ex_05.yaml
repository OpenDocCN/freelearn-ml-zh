- en: Chapter 4. Building a Product Recommendation System
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The digital world has made everything available at the click of a button. With
    everything going the online way, online shopping or e-commerce has become a big
    thing. From groceries to electronics to even cars, everything is available at
    the Amazon, Flipkart, and eBay of the world. This ever expanding digital market
    is just the right place for data science to show its magic.
  prefs: []
  type: TYPE_NORMAL
- en: The online revolution of e-commerce has not only empowered the customers, it
    has also overwhelmed them with too many choices. Choices are not only in terms
    of products or categories but also between different e-commerce platforms. Being
    an ecommerce company in this highly competitive market can be really difficult.
    Standing out is a challenge and that is where data yet again comes to the rescue.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in [Chapter 3](part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis"),
    *Predicting Customer Shopping Trends with Market Basket Analysis*, purchase patterns
    can provide a lot of insights about shopping behaviors. We utilized such data
    to find association rules to not only help the customers quickly find the right
    products but also help the retailers increase revenues (see [Chapter 3](part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis"),
    *Predicting Customer Shopping Trends with Market Basket Analysis*). For association
    rules, the granularity lies at the transaction level. They use transactions as
    a central entity and hence do not provide user specific insights.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter as well, we will continue our project work in the e-commerce
    domain. Here we will tackle the problem of personalization. We will use machine
    learning algorithms to provide user specific recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Through this chapter we will learn about:'
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation systems and their types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Issues with recommendation systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborative filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a recommendation system from scratch based on matrix factorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing highly optimized R packages to build a production ready recommendation
    engine and evaluate its recommendations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughout this chapter we will use the terms **recommender engines** and **recommendation
    systems** interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding recommendation systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Every individual in unique*, the way we do things is what defines us uniquely.
    We eat, walk, talk, and even shop in a very unique way. Since the focus of this
    chapter is e-commerce, we will focus mostly on our shopping behaviors. We will
    utilize each customer''s unique behavior to provide a personalized shopping experience.'
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish the task of providing a personalized shopping experience, we need
    a system to understand and model our customers. Recommendation engines are the
    systems which learn about customer preferences, choices, and so on, to recommend
    new products which are closer to what the user might have purchased themselves,
    thus providing a personalized experience. The options presented by such systems
    would have a high probability of the customer purchasing them.
  prefs: []
  type: TYPE_NORMAL
- en: Let us try to formally define a recommendation system.
  prefs: []
  type: TYPE_NORMAL
- en: '**Recommendation systems** (or **recommender engines**) are a class of information
    filtering systems which analyze the input data to predict preferences of a user
    as they might have done for themselves.'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike information filtering systems which remove or filter information, recommender
    engines add or re-arrange the information flowing towards the user, which is more
    relevant to the current context.
  prefs: []
  type: TYPE_NORMAL
- en: Recommender engines are not a new concept. They have existed long before the
    internet was there. They existed in the form of our friends and family who used
    to recommend us things to buy because they understood our choices. These were
    and still are a sort of **offline-recommender engines**. The web is full of **online-recommender
    engines**. From recommendation related to **Who to follow** on Twitter to **Other
    movies you might enjoy** on Netflix to **Jobs you may be interested in** on LinkedIn,
    recommender engines are everywhere and not just on e-commerce platforms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have understood what a recommendation engine is, let us look at
    their different types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User-based recommender engines**: As the name suggests, these systems have
    the user as the central entity. The activities, preferences, or behavior of the
    users are analyzed to predict what they might like depending upon their similarity
    with other such users. They are also termed as User Based Collaborative Filters
    in general due to extensive use of collaborative filters specifically for such
    recommender engines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Content-based recommender engines**: As the name suggests, these engines
    have the content or the items as the central entities. These items are analyzed
    to extract features; also the user profiles are built to map user preferences
    to the type of items. The engines then use this information to predict items which
    are similar to the ones the users have liked in the past. Such recommender engines
    are also known as **item-based collaborative filters** and have their roots in
    information retrieval theory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid recommender engines**: These systems take the best of both worlds
    to improve upon the prediction results. The two pure types can be used simultaneously
    and then their results can be combined; they can be used by adding collaborative
    filtering capabilities to content based systems or even by unifying both the approaches
    into a single model. Multiple studies have been conducted to demonstrate that
    hybrid approaches are better than the simple ones. Hybrid recommendation engines
    are also better at tackling the problems which haunt recommender engines in general.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we dive deep into the intricacies of these algorithms, let us see the
    issues that affect the recommender systems.
  prefs: []
  type: TYPE_NORMAL
- en: Issues with recommendation systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recommender engines are affected mainly by the following two issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The sparsity problem**: Recommender engines work upon user preferences (or
    ratings for different items, depending upon the application) to predict or recommend
    products. Usually the ratings are given on some chosen scale but the user may
    choose not to rate certain items which he/she hasn''t bought or looked at. For
    such cases, the rating is blank or zero. Hence, the ratings matrix R has elements
    of the form:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Issues with recommendation systems](img/00105.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: For any real world application, such as an e-commerce platform, the size of
    such a ratings matrix is huge due to the large number of users and items available
    on the platform. Even though a lot of user related information is gathered on
    such a platform, the ratings matrix itself might still be pretty sparse, that
    is the matrix might have a many elements as blanks (or zeroes). This problem in
    general is termed the **sparsity** **problem**. The sparsity problem renders the
    recommender engine's predictions ineffective as the algorithms are not able to
    infer the correlations correctly due to blanks or missing ratings. In the worst
    cases, the algorithm may term two users as un-correlated when actually they have
    highly similar preferences. The sparsity problem usually affects collaborative
    filtering algorithms.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**The cold start problem**: A special case of the sparsity problem is the cold
    start issue. As mentioned previously, when the ratings matrix contains sparsely
    populated elements (or ratings), the recommender engine fails to return valid
    recommendations. The cold start problem occurs in two particular cases. Firstly,
    assume a user has newly been added to the system. In this case, the row representing
    the user would contain zeroes (mostly). Recommending items to such a user is virtually
    impossible due to unavailability of information related to his/her preferences.
    The second scenario is when an item is newly added to the system. Since the newly
    added item will not have any ratings by the users, recommending such an item would
    be difficult for the recommender system. Hence, these two scenarios represent
    what is termed the cold start problem. Very much like the sparsity problem, the
    cold start problem also plagues collaborative filters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborative filters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recommendation systems and collaborative filters share a long history. From
    the early days of primitive recommender engines which utilized specific categorizations
    with hard-coded results, to current sophisticated recommender engines on various
    e-commerce platforms, recommender engines have made use of collaborative filters
    throughout. They are not only easy to understand but are equally simple to implement.
    Let us take this opportunity to learn more about collaborative filters before
    we dive into implementation details.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Fun Fact**'
  prefs: []
  type: TYPE_NORMAL
- en: Recommender engines surely outdate any known e-commerce platform! Grundy, a
    virtual librarian, was developed in 1979\. It was a system for recommending books
    to users. It modeled the users based upon certain pre-defined stereotypes and
    recommended books from a known list for each such category.
  prefs: []
  type: TYPE_NORMAL
- en: Core concepts and definitions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Collaborative filters** (denoted as **CF** henceforth) and recommender engines
    in general use certain terms and definitions to formally define and tackle the
    problem.'
  prefs: []
  type: TYPE_NORMAL
- en: The problem domain of recommender engines revolves around the users and the
    items they are interested in. A **user** is anybody who interacts with the system
    and performs certain actions on the **item** (say purchases or views it). Similarly,
    a **rating** defines a user's preference for an item in consideration. Generally,
    this trio is represented as a `(user, item, rating)` tuple. Since the ratings
    quantify a user's preference, the ratings can themselves be defined in different
    ways depending upon the application. Applications define ratings as integer-valued
    scales ranging from say *0-5*, while others may define a real-valued scale. Some
    applications might use binary scales with values such as *Like/Dislike* or *Purchased/Not-Purchased*.
    Thus, each application makes use of a rating scale to suit its user's preferences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know the key players involved, the next step is the representation
    of these core-concepts mathematically. A tuple of `(user, item, rating)` is usually
    represented in the form of a sparse matrix called a **ratings matrix**. Each user
    is represented by a row while the columns denote the items. Each element of this
    ratings matrix refers to the rating or preference of the user for an item. The
    ratings matrix is a **sparse matrix** since not all the items would be rated by
    every user and hence such unrated items would contain nulls or blank values. A
    ratings matrix using a 0-5 scale (unrated/missing ratings are denoted by `?`)
    looks like the following matrix showing the preference of three users for different
    laptop models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts and definitions](img/00106.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: A sample ratings matrix
  prefs: []
  type: TYPE_NORMAL
- en: 'A recommender engine is tasked to perform two main operations: **predict**
    and **recommend**. The prediction operation works upon a given user and item to
    determine the user''s likely preference for the item in consideration. For the
    ratings matrix (like the one shown earlier), prediction is like identification
    of the missing values (represented by `?` in the previous example).'
  prefs: []
  type: TYPE_NORMAL
- en: The recommendation operation comes after the predictions have been done. Given
    a user, the recommendation operation generates a list of top *N* items based on
    the user's preferences.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the user in consideration for the predict and recommend tasks is termed
    the **active-user** in the context of recommender engines.
  prefs: []
  type: TYPE_NORMAL
- en: The collaborative filtering algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Collaborative filters are a popular set of algorithms heavily used across applications.
    As we know, collaborative filters utilize the behaviour of similar users to predict
    and recommend items for the active user. These algorithms work on a simple assumption
    that similar users showcase similar behaviours. More formally, the algorithm assumes
    that the preferences or ratings of the other users in the system can be utilized
    to provide reasonable predictions for the active user.
  prefs: []
  type: TYPE_NORMAL
- en: '**Neighbour-based** **collaborative filtering**, also known as **user-user
    collaborative filtering** or **kNN collaborative filtering**, is one of the earliest
    and most widely used algorithms from the family of collaborative filters. The
    kNN collaborative filter is based on the core assumption of similar behaviour
    amongst users with similar preferences. This algorithm makes use of similarity
    measures (discussed in [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let''s Help Machines Learn"), *Let''s Help Machines Learn*) to predict
    and recommend items for the active user. The algorithm follows a two-step approach
    of first computing the predictions followed by the recommendations. The three
    main components of this algorithm are discussed next.'
  prefs: []
  type: TYPE_NORMAL
- en: Predictions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first step of kNN CF is to make use of the ratings matrix (usually denoted
    as `R`) to calculate predictions. Since we are concerned about user-user CF, the
    neighbourhood of active user (the user in consideration), denoted as `u`, is to
    be taken into account.
  prefs: []
  type: TYPE_NORMAL
- en: Let `U` be the set of all available users in the system and `N` denote the required
    neighbourhood where ![Predictions](img/00107.jpeg). The algorithm then uses a
    similarity measure, say `s`, to compute the neighbours of `u`. Once `N` (the neighborhood
    of `u`) has been identified, the ratings of the neighbouring users are aggregated
    to compute `u`'s preference for the current item. The most common measure to aggregate
    preferences is to use the **weighted average** of `N` neighboring users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, the active user `u`''s predicted preference for item `i`, denoted
    as `p[ui]` is given as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Predictions](img/00108.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Predictions](img/00109.jpeg) is the active user `u''s` mean rating'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Predictions](img/00110.jpeg) is the similarity measure between the active
    user u and the neighbouring user ![Predictions](img/00111.jpeg)'
  prefs:
  - PREF_UL
  type: TYPE_IMG
- en: 'In the preceding equation, we subtract the mean of the active user''s rating
    ![Predictions](img/00109.jpeg) from the neighbouring user''s mean rating to remove
    the rating bias of the users (some users give extremely high or low ratings and
    thus they may bias the overall predicted rating). A biased recommender engine
    might prevent better user-product matches in favour of popular or against not
    so popular ones. We can further improve the predictions by normalizing the user''s
    ratings by using standard deviation to control the rating spread across the mean.
    To keep things simple, we will use the equation as mentioned previously. The following
    image depicts the nearest neighbours for an active user:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Predictions](img/00112.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Nearest neighbors (*K=3*)
  prefs: []
  type: TYPE_NORMAL
- en: The question now arises that why only weighted average was used to predict the
    ratings and what the optimal number of neighbours (`N`) is. The reason behind
    using weighted average is that it is one of the measures which helps in generating
    consistent results. Different systems over the years have used various methods,
    such as *multivariate regressions* (the BellCore system for video recommendations),
    *unweighted averages* (Ringo for music recommendations), and so on, but weighted
    average performs pretty well in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more information, have a look at W. Hill, L. Stead, M. Rosenstein, and G.
    Furnas, *Recommending and evaluating choices in a virtual community of use*, in
    ACM CHI '95, pp. 194–201, ACM Press/Addison-Wesley Publishing Co., 1995.
  prefs: []
  type: TYPE_NORMAL
- en: Coming onto the second question of the optimal number of neighbours, this is
    something very application dependent. We saw in [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machines Learn*, how the
    number of neighbours can change the outcome of an algorithm (see *K-Nearest Neighbors*
    (*KNN*)), similarly the value of `N` can affect the outcome of a recommender engine.
    In general, limiting the number of neighbouring users helps in reducing the noise
    by removing users with low correlation to the active user. But then again, the
    value of `N` is application dependent and requires due diligence at the data scientist's
    end.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once predictions have been done for the *active user*, a recommendation list
    can be generated by ordering the items by predicted rank. This recommendation
    list may be further fine-tuned by applying certain minimal thresholds and other
    user specific characteristics, such as preferences for color, size, price sensitivity,
    and so on. Thus, this step generates a list of probable items which the user is
    more likely to buy based on his/her personal preferences. We will cover more on
    this in the coming section, *Building a recommender engine*.
  prefs: []
  type: TYPE_NORMAL
- en: Similarity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A similarity measure is an important component of our collaborative filtering
    based recommender engine algorithm. There are various similarity measures available
    for use. The most common amongst them is the **cosine similarity** measure. This
    approach represents each user as an `n` dimensional vector of ratings and similarity
    is measured by calculating the cosine distance between two such user vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, cosine similarity is given as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Similarity](img/00113.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Where, ![Similarity](img/00114.jpeg) and ![Similarity](img/00115.jpeg) are the
    **L2** or **Euclidean ** **norms** for each of the rating vectors.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pearson** **correlation** and **Spearman rank correlation** are a couple
    of statistical similarity measures which are also used widely.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the basics of collaborative filters and general concepts,
    we are ready to get our hands dirty with implementation details. Let us start
    with building the recommender system, brick-by-brick!
  prefs: []
  type: TYPE_NORMAL
- en: Building a recommender engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in the previous section, collaborative filtering is a simple yet
    very effective approach for predicting and recommending items to users. If we
    look closely, the algorithms work on input data, which is nothing but a matrix
    representation of the user ratings for different products.
  prefs: []
  type: TYPE_NORMAL
- en: Bringing in a mathematical perspective into the picture, **matrix factorization**
    is a technique to manipulate matrices and identify latent or hidden features from
    the data represented in the matrix. Building on the same concept, let us use matrix
    factorization as the basis for predicting ratings for items which the user has
    not yet rated.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix factorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Matrix factorization refers to the identification of two or more matrices such
    that when these matrices are multiplied we get the original matrix. Matrix factorization,
    as mentioned earlier, can be used to discover latent features between two different
    kinds of entities. We will understand and use the concepts of matrix factorization
    as we go along preparing our recommender engine for our e-commerce platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'As our aim for the current project is to personalize the shopping experience
    and recommend product ratings for an e-commerce platform, our input data contains
    user ratings for various products on the website. We process the input data and
    transform it into a matrix representation for analyzing it using matrix factorization.
    The input data looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix factorization](img/00116.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: User ratings matrix
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the input data is a matrix with each row representing a particular
    user's rating for different items represented in the columns. For the current
    case, the columns representing items are different mobile phones such as iPhone
    4, iPhone 5s, Nexus 5, and so on. Each row contains ratings for each of these
    mobile phones as given by eight different users. The ratings range from 1 to 5
    with 1 being the lowest and 5 being the highest. A rating of 0 represents unrated
    items or missing rating.
  prefs: []
  type: TYPE_NORMAL
- en: The task of our recommender engine will be to predict the correct rating for
    the missing ones in the input matrix. We could then use the predicted ratings
    to recommend items most desired by the user.
  prefs: []
  type: TYPE_NORMAL
- en: The premise here is that two users would rate a product similarly if they like
    similar features of the product or item. Since our current data is related to
    user ratings for different mobile phones, people might rate the phones based on
    their hardware configuration, price, OS, and so on. Hence, matrix factorization
    tries to identify these latent features to predict ratings for a certain user
    and a certain product.
  prefs: []
  type: TYPE_NORMAL
- en: While trying to identify these latent features, we proceed with the basic assumption
    that the number of such features is less than the total number of items in consideration.
    This assumption makes sense because if this was the case, then each user would
    have a specific feature associated with him/her (and similarly for the product).
    This would in turn make recommendations futile as none of the users would be interested
    in items rated by other users (which is not usually the case).
  prefs: []
  type: TYPE_NORMAL
- en: Now let us get into the mathematical details of matrix factorization and our
    recommender engine.
  prefs: []
  type: TYPE_NORMAL
- en: Since we are dealing with user ratings for different products, let us assume
    `U` to be a matrix representing user preferences and similarly a matrix `P` represents
    the products for which we have the ratings. Then the ratings matrix `R` will be
    defined as ![Matrix factorization](img/00117.jpeg).
  prefs: []
  type: TYPE_NORMAL
- en: Assuming the process helps us identify `K` latent features, our aim is to find
    two matrices `X` and `Y` such that their product (matrix multiplication) approximates
    `R`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix factorization](img/00118.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Where, `X` is a user related matrix which represents the associations between
    the users and the latent features. `Y`, on the other hand, is the product related
    matrix which represents the associations between the products and the latent features.
  prefs: []
  type: TYPE_NORMAL
- en: The task of predicting the rating ![Matrix factorization](img/00119.jpeg) of
    a product `p[j]` by a user `u[i]` is done by calculating the dot product of the
    vectors corresponding to `p[j]` (`vector Y`, that is the user) and `u[i]` (`vector
    X`, that is the product`)`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix factorization](img/00120.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Now, to find the matrices `X` and `Y`, we utilize a technique called **gradient
    descent**. Gradient descent, in simple terms, tries to find the local minimum
    of a function; it is an optimization technique. We use gradient descent in the
    current context to iteratively minimize the difference between the predicted ratings
    and the actual ratings. To begin with, we randomly initialize the matrices `X`
    and `Y` and then calculate how different their product is from the actual ratings
    matrix `R`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The difference between the predicted and the actual values is what is termed
    the **error**. For our problem, we will consider the **squared error,** which
    is calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix factorization](img/00121.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Where, `r[ij]` is the actual rating by user `i` for product `j` and ![Matrix
    factorization](img/00119.jpeg) is the predicted value of the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'To minimize the error, we need to find the correct direction or gradient to
    change our values to. To obtain the gradient for each of the variables `x` and
    `y`, we differentiate them separately as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix factorization](img/00122.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Hence, the equations to find `x[ik]` and `y[kj]` can be given as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix factorization](img/00123.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Where `α` is the constant to denote the **rate of descent** or the rate of approaching
    the minima (also known as the learning rate). The value of `α` defines the size
    of steps we take in either direction to reach the minima. Large values may lead
    to oscillations as we may overshoot the minima every time. Usual practice is to
    select very small values for `α`, of the order `10^(-4)`. ![Matrix factorization](img/00124.jpeg)
    and ![Matrix factorization](img/00125.jpeg) are the updated values of `x[ik]`
    and `y[kj]` after each iteration of gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: As seen in [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machines Learn*, machine
    learning algorithms can suffer from overfitting. To avoid overfitting, along with
    controlling extreme or large values in the matrices `X` and `Y`, we introduce
    the concept of regularization. Formally, **regularization** refers to the process
    of introducing additional information in order to prevent overfitting. Regularization
    penalizes models with extreme values.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prevent overfitting in our case, we introduce the regularization constant
    called `β`. With the introduction of `β`, the equations are updated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix factorization](img/00126.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Also,
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix factorization](img/00127.jpeg)![Matrix factorization](img/00128.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As we already have the ratings matrix `R` and we use it to determine how far
    our predicted values are from the actual, matrix factorization turns into a supervised
    learning problem. For this supervised problem, just as we saw in [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machines Learn*, we use some
    of the rows as our training samples. Let `S` be our training set with elements
    being tuples of the form `(u[i], p[j], r[ij])`. Thus, our task is to minimize
    the error (`e[ij]`) for every tuple `(u[i], p[j], r[ij])` `є` in training set
    `S`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The overall error (say `E`) can be calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix factorization](img/00129.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have looked into the mathematics of matrix factorization, let us
    convert the algorithm into code and prepare a recommender engine for the mobile
    phone ratings input data set discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the *Matrix factorization* section, the input dataset is a matrix
    with each row representing a user's rating for the products mentioned as columns.
    The ratings range from 1 to 5 with 0 representing the missing values.
  prefs: []
  type: TYPE_NORMAL
- en: 'To transform our algorithm into working code, we need to compute and complete
    the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the input data and transform it into ratings matrix representation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prepare a matrix factorization based recommendation model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predict and recommend products to the users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpret and evaluate the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading and transforming input data into matrix representation is simple. As
    seen earlier, R provides us with easy to use utility functions for the same.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our data loaded into an `R` matrix, we proceed and prepare
    the user-latent features matrix `X` and item-latent features matrix `Y`. We initialize
    both from uniform distributions using the `runif` function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The major component is the matrix factorization function itself. Let us split
    the task into two, calculation of the gradient and subsequently the overall error.
  prefs: []
  type: TYPE_NORMAL
- en: The calculation of the gradient involves the ratings matrix `R` and the two
    factor matrices `X` and `Y,` along with the constants `α` and `β`. Since we are
    dealing with matrix manipulations (specifically, multiplication), we transpose
    `Y` before we begin with any further calculations. The following lines of code
    convert the algorithm discussed previously into R syntax. All variables follow
    naming convention similar to the algorithm for ease of understanding.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The next part of the algorithm is to calculate the overall error; we again
    use similar variable names for consistency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As a final piece, we iterate over these calculations multiple times to mitigate
    the risks of cold start and sparsity. We term the variable controlling multiple
    starts as **epoch**. We also terminate the calculations once the overall error
    drops below a certain threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, as we had initialized `X` and `Y` from uniform distributions, the
    predicted values would be real numbers. We round the final output before returning
    the predicted matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is a very simplistic implementation and a lot of complexity has
    been kept out for ease of understanding. Hence, this may result in the predicted
    matrix containing values greater than 5\. For the current scenario, it is safe
    to assume the values above the max scale of 5 are equivalent to 5 (and similarly
    for values less than 0). We encourage the reader to fine tune the code to handle
    such cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting `α` to `0.0002`, `β` to `0.02`, `K` (that is, latent features) to `2`,
    and `epoch` to `1000`, let us see a sample run of our code with overall error
    threshold set to `0.001`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding lines of code utilize the functions explained earlier to prepare
    the recommendation model. The predicted ratings or the output matrix looks like
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementation](img/00130.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Predicted ratings matrix
  prefs: []
  type: TYPE_NORMAL
- en: Result interpretation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us do a quick visual inspection to see how good or bad our predictions
    have been. Consider users 1 and 3 as our training samples. From the input dataset,
    we can clearly see that user 1 has given high ratings to iPhones while user 3
    has done the same for Android based phones. The following side by side comparison
    shows that our algorithm has predicted values close enough to the actual values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Result interpretation](img/00131.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Ratings by user 1
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us see the ratings of user 3 in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Result interpretation](img/00132.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Ratings by user 3
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our ratings matrix with updated values, we are ready to recommend
    products to users. It is common sense to show only the products which the user
    hasn't rated yet. The right set of recommendations will also enable the seller
    to pitch the products which have high probability of being purchased by the user.
  prefs: []
  type: TYPE_NORMAL
- en: The usual practice is to return a list of the top *N* items from the unrated
    list of products for each user. The user in consideration is usually termed the
    **active-user**. Let us consider user 6 as our active-user. This user has only
    rated Nexus 6, One Plus One, Nexus 5, and iPhone4 in that order of rating, that
    is Nexus 6 was highly rated and iPhone4 was rated the least. Getting a list of
    the *Top 2* recommended phones for such a customer using our algorithm would result
    in Moto X and Moto G (very rightly indeed, do you see why?).
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we built a recommender engine smart enough to recommend the right mobile
    phones to an Android fanboy and saved the world from yet another catastrophe!
  prefs: []
  type: TYPE_NORMAL
- en: '*Data to the rescue!*'
  prefs: []
  type: TYPE_NORMAL
- en: This simple implementation of a recommender engine using matrix factorization
    gave us a flavor of how such a system actually works. Next, let us get into some
    real world action using recommender engines.
  prefs: []
  type: TYPE_NORMAL
- en: Production ready recommender engines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter so far, we have learnt about recommender engines in detail and
    even developed one from scratch (using matrix factorization). Through all this,
    it is clearly evident how widespread the application of such systems is.
  prefs: []
  type: TYPE_NORMAL
- en: E-commerce websites (or for that fact, any popular technology platform) out
    there today have tones of content to offer. Not only that, but the number of users
    is also huge. In such a scenario, where thousands of users are browsing/buying
    stuff simultaneously across the globe, providing recommendations to them is a
    task in itself. To complicate things even further, a good user experience (response
    times, for example) can create a big difference between two competitors. These
    are live examples of production systems handling millions of customers day in
    and day out.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Fun Fact**'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon.com is one of the biggest names in the e-commerce space with 244 million
    active customers. Imagine the amount of data being processed to provide recommendations
    to such a huge customer base browsing through millions of products!
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: [http://www.amazon.com/b?ie=UTF8&node=8445211011](http://www.amazon.com/b?ie=UTF8&node=8445211011)'
  prefs: []
  type: TYPE_NORMAL
- en: In order to provide a seamless capability for use in such platforms, we need
    highly optimized libraries and hardware. For a recommender engine to handle thousands
    of users simultaneously every second, R has a robust and reliable framework called
    the **recommenderlab**.
  prefs: []
  type: TYPE_NORMAL
- en: Recommenderlab is a widely used R extension designed to provide a robust foundation
    for recommender engines. The focus of this library is to provide efficient handling
    of data, availability of standard algorithms and evaluation capabilities. In this
    section, we will be using recommenderlab to handle a considerably larger data
    set for recommending items to users. We will also use the evaluation functions
    from recommenderlab to see how good or bad our recommendation system is. These
    capabilities will help us build a production ready recommender system similar
    (or at least closer) to what many online applications such as Amazon or Netflix
    use.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset used in this section contains ratings for 100 items as rated by
    5000 users. The data has been anonymized and the product names have been replaced
    by product IDs. The rating scale used is 0 to 5 with 1 being the worst, 5 being
    the best, and 0 representing unrated items or missing ratings.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build a recommender engine using recommenderlab for a production ready system,
    the following steps are to be performed:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract, transform, and analyze the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prepare a recommendation model and generate recommendations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the recommendation model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will look at all these steps in the following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Extract, transform, and analyze
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As in case of any data intensive (particularly machine learning) application,
    the first and foremost step is to get the data, understand/explore it, and then
    transform it into the format required by the algorithm deemed fit for the current
    application. For our recommender engine using the recommenderlab package, we will
    first load the data from a csv file described in the previous section and then
    explore it using various R functions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The preceding section of code loads the recommenderlab package and then uses
    the standard utility function to read the `product_ratings_data.csv` file. For
    exploratory as well as further steps, we need the data to be transformed into
    the user-item ratings matrix format (as described in the *Core concepts and definitions*
    section).
  prefs: []
  type: TYPE_NORMAL
- en: The `as(<data>,<type>)` utility converts `csv` into the required ratings matrix
    format.
  prefs: []
  type: TYPE_NORMAL
- en: The `csv` file contains data in the format shown in the following screenshot.
    Each row contains a user's rating for a specific product. The column headers are
    self explanatory.
  prefs: []
  type: TYPE_NORMAL
- en: '![Extract, transform, and analyze](img/00133.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Product ratings data
  prefs: []
  type: TYPE_NORMAL
- en: The `realRatingMatrix` conversion transforms the data into a matrix as shown
    in the following image. The users are depicted as rows while the columns represent
    the products. Ratings are represented using a gradient scale where white represents
    missing/unrated rating while black denotes a rating of 5/best.
  prefs: []
  type: TYPE_NORMAL
- en: '![Extract, transform, and analyze](img/00134.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Ratings matrix representation of our data
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the data in our environment, let us explore some of its characteristics
    and see if we can decipher some key patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we extract a representative sample from our main data set (refer
    to the screenshot *Product ratings data*) and analyze it for:'
  prefs: []
  type: TYPE_NORMAL
- en: Average rating score for our user population
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spread/distribution of item ratings across the user population
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of items rated per user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following lines of code help us explore our data set sample and analyze
    the points mentioned previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We extract a sample of 1,000 users from our dataset for exploration purposes.
    The mean of product ratings as given by the first row in our user-rating sample
    is `2.055`. This tells us that this user either hasn''t seen/rated many products
    or he usually rates the products pretty low. To get a better idea of how the users
    rate products, we generate a histogram of item rating distribution. This distribution
    peaks around the middle, that is, `3`. The histogram is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Extract, transform, and analyze](img/00135.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Histogram for ratings distribution
  prefs: []
  type: TYPE_NORMAL
- en: The histogram shows that the ratings are normally distributed around the mean
    with low counts for products with very high or very low ratings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we check the spread of the number of products rated by the users.
    We prepare a histogram which shows this spread:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Extract, transform, and analyze](img/00136.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Histogram of number of rated products
  prefs: []
  type: TYPE_NORMAL
- en: The preceding histogram shows that there are many users who have rated `70`
    or more products, as well as there are many users who have rated all `100` products.
  prefs: []
  type: TYPE_NORMAL
- en: The exploration step helps us get an idea of how our data is. We also get an
    idea about the way the users generally rate the products and how many products
    are being rated.
  prefs: []
  type: TYPE_NORMAL
- en: Model preparation and prediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have the data in our R environment which has been transformed into the ratings
    matrix format. In this section, we are interested in preparing a recommender engine
    based on user-based collaborative filtering. We will be using similar terminology
    as described in the previous sections. Recommenderlab provides straight-forward
    utilities to learn and prepare a model for building recommender engines.
  prefs: []
  type: TYPE_NORMAL
- en: 'We prepare our model based upon a sample of just 1,000 users. This way, we
    can use this model to predict the missing ratings for the rest of the users in
    our ratings matrix. The following lines of code utilize the first thousand rows
    for learning the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '"`UBCF`" in the preceding code signifies user-based collaborative filtering.
    Recommenderlab also provides other algorithms, such as **IBCF** or **Item-Based
    Collaborative Filtering**, **PCA** or **Principal Component Analysis**, and others
    as well.'
  prefs: []
  type: TYPE_NORMAL
- en: After preparing the model, we use it to predict the ratings for our 1,010^(th)
    and 1,011^(th) users in the system. Recommenderlab also requires us to mention
    the number of items to be recommended to the users (in the order of preference
    of course). For the current case, we mention 5 as the number of items to be recommended.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The preceding lines of code generate two lists, one for each of the users. Each
    element in these lists is a product for recommendation. The model predicted that,
    for user 1,010, product `prod_93` should be recommended as the top most product
    followed by `prod_79`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Recommenderlab is a robust platform which is optimized to handle large datasets.
    With a few lines of code, we were able to load the data, learn a model, and even
    recommend products to the users in virtually no time. Compare this with the basic
    recommender engine we developed using matrix factorization which involved many
    lines of code (when compared to recommenderlab) apart from the obvious difference
    in performance.
  prefs: []
  type: TYPE_NORMAL
- en: Model evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have successfully prepared a model and used it for predicting and recommending
    products to the users in our system. But what do we know about the accuracy of
    our model? To evaluate the prepared model, recommenderlab has handy and easy to
    use utilities. Since we need to evaluate our model, we need to split it into training
    and test data sets. Also, recommenderlab requires us to mention the number of
    items to be used for testing (it uses the rest for computing the error).
  prefs: []
  type: TYPE_NORMAL
- en: For the current case, we will use 500 users to prepare an evaluation model.
    The model will be based on a 90-10 training-testing dataset split with 15 items
    used for test sets.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the evaluation scheme to train our model based on the *UBCF* algorithm.
    The prepared model from the training dataset is used to predict ratings for the
    given items. We finally use the method `calcPredictionAccuracy` to calculate the
    error in predicting the ratings between known and unknown components of the test
    set. For our case, we get an output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Model evaluation](img/00137.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The generated output mentions the values for **RMSE** or root mean squared error,
    **MSE** or mean squared error, and **MAE** or mean absolute error. For RMSE in
    particular, the values deviate from the correct values by `1.162` (note that the
    values might deviate slightly across runs due to various factors such as sampling,
    iterations, and so on). This evaluation will make more sense when the outcomes
    are compared from different CF algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'To evaluate UBCF, we use IBCF as comparison. The following few lines of code
    help us prepare an IBCF based model and test the ratings, which can then be compared
    using the `calcPredictionAccuracy` utility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The comparative output shows that UBCF outperforms IBCF with lower values of
    RMSE, MSE, and MAE.
  prefs: []
  type: TYPE_NORMAL
- en: '![Model evaluation](img/00138.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Similarly, we can use the other algorithms available in recommenderlab to test/evaluate
    our models. We encourage the user to try out a few more and see which algorithm
    has the least error in predicted ratings.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we continued our pursuit of using machine learning in the field
    of e-commerce to enhance sales and overall user experience. The previous chapter
    had discussed recommendations based on transactional logs; in this chapter, we
    accounted for the human factor and looked into the recommendation engines based
    on user behavior.
  prefs: []
  type: TYPE_NORMAL
- en: We started off by understanding what recommendation systems and their classifications
    into user-based, content-based, and hybrid recommender systems. We touched on
    the problems associated with recommender engines in general. Then we dived deep
    into the specifics of collaborative filters and discussed the math around prediction
    and similarity measures. After getting our basics straight, we moved onto building
    a recommender engine of our own from scratch. We utilized matrix factorization
    to build a recommender engine step by step using a small dummy dataset. We then
    moved onto building a production ready recommender engine using R's popular library
    called recommenderlab. We used user-based CF as our core algorithm to build a
    recommendation model on a bigger dataset containing ratings for 100 products by
    5,000 users. We closed our discussion by evaluating our recommendation model using
    recommenderlab's utility methods.
  prefs: []
  type: TYPE_NORMAL
- en: The next couple of chapters will move from e-commerce to the financial domain
    and utilize machine learning for some more interesting use cases.
  prefs: []
  type: TYPE_NORMAL
