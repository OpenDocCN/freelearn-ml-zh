- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Charting the Course of Your ML Journey
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The journey of transforming businesses in areas such as customer experience
    enhancement, operational efficiency, faster and better decision making, risk reduction,
    and new products and services with AI/ML is an exciting yet challenging endeavor
    that requires careful planning, execution, and ongoing management. Having a good
    understanding of what an AI/ML journey might look like and what the key challenges
    are will help ML practitioners and decision makers plan better throughout this
    journey. In this chapter, I will go over some of the essential topics for understanding
    the ML journey, such as the stages of adoption and the assessment of ML maturity.
    We will explore the various challenges, including developing an AI/ML vision,
    initiating AI/ML projects, and scaling use cases, infrastructure, and governance,
    to address the growing needs of the market.
  prefs: []
  type: TYPE_NORMAL
- en: 'Business and technology decision makers who are responsible for establishing
    an ML strategy and scaling ML adoption will find this chapter useful, as it provides
    valuable insights into the critical dimensions when building an organization’s
    ML maturity and capabilities, as well as factors to bear in mind while scaling
    the organization’s AI/ML adoption. By following the recommendations presented
    in this chapter, decision-makers can optimize their ML strategy and achieve a
    successful ML adoption journey. Specifically, I will discuss the following topics
    with firsthand experience having worked with many organizations on their AI/ML
    journey:'
  prefs: []
  type: TYPE_NORMAL
- en: Stages of ML adoption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding ML maturity and assessment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI/ML operating models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solving adoption challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML adoption stages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The paths to adopting and maturing AI/ML can vary for organizations. As an ML
    solutions architect, I have collaborated with organizations at different stages
    of AI/ML adoption and with varying levels of ML experience. Understanding what
    organizations look like at different stages of the AI/ML journey can help decision-makers
    prioritize what’s important at each stage, identify the challenges an organization
    may face, and determine what needs to be done to move to the next level.
  prefs: []
  type: TYPE_NORMAL
- en: Based on my experience working with various organizations, I have observed that
    companies generally fall into the following stages.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring AI/ML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Companies in this stage are those that are just beginning to delve into the
    world of AI/ML. They usually don’t have any prior experience with AI/ML, but they
    recognize its promising potential and are eager to explore its impact on their
    business.
  prefs: []
  type: TYPE_NORMAL
- en: These companies often face several challenges as they attempt to assess the
    impact of AI/ML on their business. One of the biggest challenges is identifying
    the right AI/ML project to showcase its value. With so many potential applications
    of AI/ML, it can be difficult for these companies to determine the best place
    to start. They may struggle with choosing the right problem to solve or the right
    data set to use.
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge for companies in this stage is acquiring the necessary business
    and technical expertise to execute a pilot project. AI/ML is a complex field that
    requires a high level of technical expertise and experience. These companies may
    need to hire or train new employees or work with outside partners to gain the
    necessary knowledge and skills.
  prefs: []
  type: TYPE_NORMAL
- en: Despite these challenges, companies in this stage have a great opportunity to
    learn about the potential of AI/ML and to lay the foundation for a successful
    AI/ML integration. By starting with a pilot project, they can gain valuable experience
    and insights into the potential of AI/ML, and they can begin to build the necessary
    skills and expertise to support future AI/ML initiatives.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the customers I worked with four or more years ago fell into this category,
    and the interest and initiative mostly came from senior business and technology
    leaders, such as VPs or directors of engineering, and heads of business functions
    like marketing. Successful companies at this stage usually began with use cases
    that solved real business problems and delivered measurable benefits that resonated
    with other stakeholders in the organization. For example, one organization I worked
    with started with a sports analytics use case that addressed a labor-intensive
    task, resulting in lower costs and faster delivery of insights. On the other hand,
    another organization started with a forward-looking use case that required significant
    ROI analysis and process changes, but it failed to take off. Since these organizations
    usually didn’t have in-house ML expertise, the successful ones typically chose
    to work with partners who had ML experience to get a proof of concept or pilot
    off the ground. At this stage, ML technology stack and infrastructure efficiency
    were usually not a focus for these organizations, as the main goal was to prove
    business value.
  prefs: []
  type: TYPE_NORMAL
- en: Disjointed AI/ML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Organizations in this stage often focus on adopting AI/ML more broadly across
    business areas based on some early successes and formulating a long-term strategic
    AI/ML vision. These organizations normally have varying degrees of AI/ML capabilities
    within different departments but lack a cohesive, enterprise-wide strategy for
    AI/ML, and most likely do not have an enterprise ML platform. Each department
    operates its AI/ML initiatives independently, using AI/ML to meet specific business
    requirements. There is limited collaboration and sharing between departments,
    leading to siloed data and AI/ML efforts.
  prefs: []
  type: TYPE_NORMAL
- en: These organizations often face challenges when it comes to scaling and executing
    AI/ML initiatives. One of the biggest challenges is a lack of dedicated ML engineering
    support. Data scientists are expected to be proficient in both science and engineering,
    and they may face technical challenges that span both domains. Another challenge
    faced by these organizations is the lack of an ML governance process, resulting
    in low confidence and adoption in the models being developed, many science projects,
    and no real production workload.
  prefs: []
  type: TYPE_NORMAL
- en: As organizations in this stage continue to scale their AI/ML efforts across
    more business areas, they should think about establishing more cohesive and integrated
    AI/ML efforts, such as ML platform and technology standardization, unified development
    and governance processes, organization alignment, reuse of data and models, and
    knowledge sharing.
  prefs: []
  type: TYPE_NORMAL
- en: Fast-forwarding to today, the majority of organizations I work with fall into
    this category. Many of these organizations have limited oversight to validate
    the business benefits of these initiatives in the different silos, which has resulted
    in many of these projects becoming science experiments rather than business-outcome-driven
    initiatives. In addition, the lack of dedicated effort in business process integration
    has resulted in many projects not making it into production. To move forward from
    this stage, some of the organizations I worked with have started initiatives to
    rationalize their AI/ML efforts, including both organizational and technological
    rationalization. For example, several organizations I worked with have established
    a new Chief Data Officer function to oversee data, analytics, and ML initiatives
    across the organization. They started to formulate a multi-year strategy to move
    toward a more integrated organization and technology stack. Many of these organizations
    have also created dedicated engineering functions to drive technical standards
    and common ML infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Integrated AI/ML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Companies in this stage understand the importance of AI/ML for their business
    and have taken steps to fully integrate AI/ML into their operations. They have
    established a clear organizational structure to support AI/ML initiatives from
    both a business and technical perspective.
  prefs: []
  type: TYPE_NORMAL
- en: These companies have invested in enterprise-grade ML and data infrastructure
    to support experimentation and production deployment across multiple business
    units. They have consolidated siloed technology efforts where it makes sense and
    established ML governance and security as critical concerns. They have put in
    place specific governance capabilities, such as AI/ML policies and procedures,
    defined roles and responsibilities, and enabled technology capabilities for governance.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of their comprehensive approach to AI/ML, these organizations have
    seen a range of benefits, including cost savings, risk reduction, improved user
    experiences, and faster ML deployment. AI/ML has become an integral part of their
    business operations, and they continue to invest in and develop their AI/ML capabilities
    to stay ahead of the curve.
  prefs: []
  type: TYPE_NORMAL
- en: Among the organizations that I have have worked with, the number in this stage
    is still small, with most of them still evolving. More mature organizations in
    this stage have also invested in AI/ML adoption efforts for both their businesses
    and technology platforms. For example, a number of organizations have established
    dedicated solution engineering teams that work with different lines of businesses
    to adopt their enterprise ML platform and onboard AI/ML workloads. Some organizations
    have also established enterprise-wide AI/ML conferences/summits to drive internal
    knowledge sharing on use cases, business values, best practices, and innovations.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced AI/ML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Companies in the “Advanced AI/ML” stage have fully embraced AI/ML as a key part
    of their business operations and have achieved a high level of proficiency in
    incorporating AI/ML into their products and services. They are leaders in the
    industry and are pioneers in AI/ML research and real-world applications of AI/ML,
    helping to shape the direction of the broader industry.
  prefs: []
  type: TYPE_NORMAL
- en: These companies have the capability to generate AI/ML-driven disruptive business
    concepts and products that have a lasting impact on the industry. They possess
    a deep understanding of AI/ML and are able to use this knowledge to drive innovation
    and stay ahead of the curve.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, these companies have a well-established ML infrastructure and governance
    system, which allows them to quickly experiment with new AI/ML models and to bring
    new products and services to market. They are also able to effectively manage
    the risks associated with AI/ML and ensure that their applications meet regulatory
    and ethical standards.
  prefs: []
  type: TYPE_NORMAL
- en: I have worked with several organizations at this stage, primarily in the financial
    services and high-tech industries. These organizations have not only adopted state-of-the-art
    ML technology, fostered a data-driven culture, and developed a strong AI/ML product
    and solution mindset but have also established AI/ML research functions to help
    advance AI/ML research with a potential industry-wide impact. Examples of such
    research include financial market simulation, AI/ML security, and privacy.
  prefs: []
  type: TYPE_NORMAL
- en: AI/ML maturity and assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To assess the level of an organization’s readiness to adopt ML at different
    stages, the concept of ML maturity is often used as a measure. ML maturity refers
    to the organization’s capability to implement ML successfully from multiple dimensions.
    At a high level, there are four key dimensions that can be considered when describing
    an organization’s ML maturity:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Technical maturity**: This refers to the technical expertise and capabilities
    of the organization in the domain of ML. Technical maturity can be measured in
    terms of the sophistication of ML algorithms and models used, the quality and
    availability of data, the scale and efficiency of ML infrastructure, and the ability
    of the organization to integrate ML with other systems and processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Business maturity**: This refers to the extent to which ML is integrated
    into the organization’s product development lifecycle, business processes, and
    decision making. Business maturity can be measured in terms of the number of ML
    use cases, the impact of ML on the organization’s **key performance indicators**
    (**KPIs**), and the level of integration between ML and other business functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Governance maturity**: This refers to the organization’s policies and practices
    around the responsible use of ML. Governance maturity can be measured in terms
    of the organization’s ability to ensure data privacy and security, the level of
    transparency and explainability of ML models, the level of compliance with relevant
    regulations and standards, the ability to identify and mitigate potential risks
    associated with ML adoption, and the ability to instrument and manage the overall
    process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Organizational and talent maturity**: Talent maturity can be measured in
    terms of the organization’s ability to hire and retain data scientists and ML
    engineers, the availability of training and development opportunities for ML talent,
    and the organization’s overall culture of innovation and collaboration. This also
    refers to the organization’s ability to establish a supportive culture and processes
    to facilitate the development and adoption of AI/ML products and capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to assess an organization’s maturity in each dimension of AI/ML, a
    questionnaire can be developed to determine whether the organization possesses
    the desired capabilities. In the following sections we will review some sample
    questions intended to provide a directional assessment of maturity. Note that
    they do not provide an actual score or weights for each question, as the importance
    of each AI/ML capability can vary for different organizations. The purpose of
    these questions is to help identify gaps in each area so that organizations can
    evaluate the criticality of these gaps based on their own needs and context, and
    determine how best to address them. Organizations should customize and build upon
    these sample questions to tailor them to their individual needs.
  prefs: []
  type: TYPE_NORMAL
- en: Technical maturity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The technical maturity assessment for AI systems focuses on evaluating the organization’s
    capabilities and readiness in several key subdomains related to the development,
    deployment, and maintenance of AI systems. This assessment plays a crucial role
    in ensuring that the organization has the necessary technical foundations and
    resources to support the responsible and effective implementation of AI solutions.
    By assessing these technical subdomains, the organization can identify strengths,
    weaknesses, and areas for improvement in its AI capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dimension** | **Assessment Questions** |'
  prefs: []
  type: TYPE_TB
- en: '| Data | Has the organization established comprehensive data management frameworks
    for data acquisition, storage, processing, and protection? |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established data governance processes and policies,
    including considerations for data privacy, security, and ethics? |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established processes and capabilities to acquire new
    data, generate new derived data from existing data, and generate synthetic data
    for business uses? |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established processes and controls to ensure the quality
    and reliability of its data including data cleaning, normalization, and validation?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established processes to ensure the relevant data is
    easily accessible to all stakeholders, including data scientists, engineers, and
    business users? |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established security controls to protect its data, including
    encryption, access control, and audit trails? |'
  prefs: []
  type: TYPE_TB
- en: '| Technology infrastructure and ML tools | Has the organization established
    robust and scalable technology infrastructure to support the development of AI,
    including consideration for hardware, software, and network security? |'
  prefs: []
  type: TYPE_TB
- en: '| Does the organization have access to tools and platforms for the development
    and deployment of AI products or solutions, including data science and ML platforms?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established capabilities to integrate AI into existing
    systems and workflows, including considerations for data integration, system integration,
    and security integration? |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established capabilities to automate development and
    deployment workflows? |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established processes and capabilities to monitor and
    maintain its AI systems and models, including consideration for performance, accuracy,
    and security? |'
  prefs: []
  type: TYPE_TB
- en: '| Does the organization have the ability to scale its AI systems and models
    to meet changing business needs, including considerations for data volume, velocity,
    and variety? |'
  prefs: []
  type: TYPE_TB
- en: '| Algorithms and models | Does the organization use any advanced ML techniques
    and algorithms such as a neural network, generative adversarial network, or reinforcement
    learning to solve business problems? |'
  prefs: []
  type: TYPE_TB
- en: '| Does the organization use algorithms that leverage multiple modalities (e.g.,
    text, images, tabular data, etc.) to solve business problems? |'
  prefs: []
  type: TYPE_TB
- en: '| Does the organization use advanced model development patterns such as transfer
    learning, fine-tuning from foundational models, or multi-task learning? |'
  prefs: []
  type: TYPE_TB
- en: Business maturity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The business maturity dimension examines the quantity and variety of ML use
    cases implemented to solve real business problems, as well as any established
    business metrics to measure the impact of ML. Organizations that have adopted
    AI/ML across more businesses probably have a higher level of business maturity
    than organizations with a smaller number of business adoptions. The range of business
    problems addressed through ML is another key indicator of an organization’s business
    maturity in AI/ML. For instance, ML can be applied in various scenarios, including
    basic predictive analytics such as sales forecasting and targeted marketing, critical
    decision support such as medical diagnosis, and complex cognitive reasoning and
    strategic planning such as autonomous driving. To assess this maturity level,
    some sample questions can be:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dimension** | **Assessment Questions** |'
  prefs: []
  type: TYPE_TB
- en: '| Business adoption of AI/ML | How many different business functions or areas
    have integrated AI/ML into their workflow? |'
  prefs: []
  type: TYPE_TB
- en: '| How complex are the business problems that have been solved using AI/ML?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Are there any business decisions that have been fully automated with AI/ML?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Is there a process established to identify business use cases for AI/ML?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Has a mechanism been established to make decisions about AI/ML business cases?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Is there a mechanism to integrate AI/ML into existing business processes?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Measurement | Has the organization established metrics for measuring the
    impact of different AI/ML solutions (**return on investment** (**ROI**))? |'
  prefs: []
  type: TYPE_TB
- en: '| How much improvement has been achieved since the adoption of AI/ML, compared
    to the baseline? |'
  prefs: []
  type: TYPE_TB
- en: '| Are the mechanisms for measuring the impact reviewed regularly and updated
    to ensure they remain effective? |'
  prefs: []
  type: TYPE_TB
- en: Governance maturity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The governance maturity assessment aims to evaluate an organization’s level
    of maturity in three key areas: policy and compliance, model governance, and risk
    management. These areas are crucial for ensuring the responsible development,
    deployment, and monitoring of AI systems, particularly in high-stakes domains.
    By assessing these three areas, the governance maturity assessment provides organizations
    with a good understanding of their strengths and weaknesses in managing AI systems
    responsibly. It helps identify gaps and areas for improvement, enabling organizations
    to develop and implement robust governance frameworks that align with best practices
    and regulatory requirements.'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dimension** | **Assessment Questions** |'
  prefs: []
  type: TYPE_TB
- en: '| Policy and compliance | Has the organization established policies and processes
    to ensure compliance with legal, ethical, and regulatory requirements related
    to AI and ML, including considerations for data privacy, security, and bias? |'
  prefs: []
  type: TYPE_TB
- en: '| Model governance | Has the organization established processes and frameworks
    to govern the development, deployment, and ongoing maintenance of AI and ML models,
    including considerations for model risk management, transparency, and accountability?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Risk management and mitigation | Has the organization established risk management
    processes and frameworks to identify, assess, and manage the risks associated
    with AI and ML, including considerations for reputation, security, and ethics?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established guardrails and mitigation mechanisms and
    techniques? |'
  prefs: []
  type: TYPE_TB
- en: Organization and talent maturity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The organization and talent maturity dimension assesses whether an organization
    has the right organizational processes, structures, and talent management practices
    in place to successfully execute its AI/ML strategy and programs. This includes
    evaluating factors such as organizational alignment and support for AI/ML initiatives,
    governance frameworks and decision-making processes, talent acquisition and development
    strategies for AI/ML roles, change management readiness for AI adoption, and incentive
    systems to encourage AI innovation. By examining this dimension, organizations
    can identify gaps and develop strategies to build the necessary organizational
    capabilities, processes, and talent pipelines to support their AI/ML goals effectively.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dimension** | **Assessment Questions** |'
  prefs: []
  type: TYPE_TB
- en: '| Organization | Does the organization have a culture that supports and encourages
    the use of AI, including a focus on innovation and experimentation? |'
  prefs: []
  type: TYPE_TB
- en: '| Does the organization have processes and workflows that support the development
    and deployment of AI, including project management, quality assurance, and risk
    management? |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established cross-functional teams and collaboration
    frameworks to support the development and deployment of AI? |'
  prefs: []
  type: TYPE_TB
- en: '| Has the organization established change management frameworks to manage the
    impact of AI on the organization and its stakeholders, including considerations
    for adoption, training, and communication? |'
  prefs: []
  type: TYPE_TB
- en: '| Talent | Does the organization have a talent strategy in place to attract,
    retain, and develop the necessary skills and expertise for AI, including data
    science, engineering, DevOps/MLOps, and business skills? |'
  prefs: []
  type: TYPE_TB
- en: Your answers to these questions are not intended to provide a complete evaluation
    of each area but rather highlight some of the critical AI/ML capabilities for
    organizations to develop to reach different maturity. Organizations can use these
    answers to help identify areas for improvement and develop tailored strategies
    and detailed plans to enhance their AI capabilities in each of the areas based
    on their unique situation and needs.
  prefs: []
  type: TYPE_NORMAL
- en: Maturity assessment and improvement process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To achieve AI maturity over time, an organization needs to follow a structured
    process to assess, plan, improve, and measure across different dimensions, and
    it is an iterative process. The following diagram illustrates an example process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20836_14_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.1: AI maturity assessment and improvement'
  prefs: []
  type: TYPE_NORMAL
- en: The process starts with the assessment of current AI capabilities in one or
    more dimensions depending on an organization’s specific needs. This is usually
    conducted by answering questions from assessment questionnaires with data points
    and inputs collected from different teams and stakeholders involved in AI initiatives
    across the organizations. Some of the pitfalls to avoid in this step include a
    lack of well-defined objectives for the assessment, biased assessment criteria,
    limited stakeholder engagement, overemphasis on technology, and lack of actionable
    insights.
  prefs: []
  type: TYPE_NORMAL
- en: With the information collected and questions answered, an organization can identify
    gaps between the current state and the desired state across different dimensions.
    For example, an organization might identify gaps such as poor data quality due
    to a lack of data management process and technology, or low adoption of AI due
    to poor AI use case review mechanisms and a lack of effective change management.
    Some of the pitfalls to avoid in this step include a lack of specificity in identified
    gaps, bias in interpretation, a lack of priority in the findings, and failure
    to consider organization culture in change.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the findings and organizational goals in AI adoption, an organization
    can develop plans with clear milestones to close gaps that are important for the
    organization. For example, if an organization wants to better understand the ROI
    from AI initiatives, then they should define clear KPIs and mechanisms for collecting
    and measuring the impacts of AI programs. If the organization wants higher efficiency
    through standardization of technology and processes, then they should think about
    adjusting operating models and programs to achieve this goal. Some of the pitfalls
    to avoid in this step include unrealistic expectations, a lack of communication,
    insufficient resources, and inadequate stakeholder involvement.
  prefs: []
  type: TYPE_NORMAL
- en: Plan implementation is a complex and challenging endeavor depending on the scope
    and the impacts it will have on people, the organization, technology, and processes.
    Organizations need to consider pragmatic approaches for implementation to minimize
    the negative impacts these changes might bring to the organizations. For example,
    if the plan calls for a change of the operating model, then it is important to
    consider its impact on people and processes and make sure effective change management
    programs are put in place to facilitate the change. Also, consider the scope of
    the change based on organizational needs, such as department wide, **line of business**
    (**LOB**) wide, or organization wide. Other considerations include the selection
    of target dimensions for implementation (e.g., technical maturity versus organizational
    maturity). Some of the pitfalls to avoid in this step are scope creep, overly
    ambitious timelines, resistance to change, inadequate training and support, and
    a lack of senior leadership support.
  prefs: []
  type: TYPE_NORMAL
- en: In order to know whether the organization is improving, it is important to measure
    the effectiveness of the plans and their implementations. Specific KPIs should
    be established to help measure progress. These KPIs can include metrics such as
    the velocity of AI workload deployment, average ROI on AI workloads, the number
    of people trained in AI/ML, productivity improvement, and customer satisfaction
    improvement. Some of the pitfalls to avoid in this step include a lack of clear
    metrics, overemphasis on quantitative metrics, and a lack of industry benchmarking.
  prefs: []
  type: TYPE_NORMAL
- en: The assessment and improvement of AI maturity is an iterative process that requires
    ongoing adjustment of the process, plan, and implementation to make it successful
    across different dimensions. There are also tools and frameworks that can be leveraged
    for assessment and measurement, such as the MITRE AI maturity model and organizational
    assessment tool guide.
  prefs: []
  type: TYPE_NORMAL
- en: AI/ML operating models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The AI/ML operating model plays a crucial role in how an organization can achieve
    its AI maturity goals. It can have a profound impact across a range of key dimensions
    such as organizational agility, governance and standardization, resource and technology
    efficiency, domain expertise, risk management, and ownership and accountability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Organizations will need to consider their unique organizational needs when
    deciding on the operating model for their AI initiatives. At a high level, there
    are three main operating models to consider: centralized, decentralized, and hub
    and spoke.'
  prefs: []
  type: TYPE_NORMAL
- en: Centralized model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For organizations starting their ML journey and looking for efficient use of
    their scarce ML talents, they probably want to consider a centralized model, especially
    if the main goals are unified AI/ML strategy, consolidation of ML talents, and
    standardization of technology and tools.
  prefs: []
  type: TYPE_NORMAL
- en: In a centralized model, a single central team is responsible for all aspects
    of ML activities, from data collection to model development to deployment. This
    team mainly consists of data scientists, ML engineers, MLOps engineers, and software
    engineers as well as other related roles such as project management. This team
    works with different lines of business on AI/ML initiatives from ideation to production
    deployment. This model enables organizations to consolidate AI/ML expertise, infrastructure,
    and tools within a single team, fostering knowledge sharing, consistency, and
    efficient resource utilization.
  prefs: []
  type: TYPE_NORMAL
- en: While a centralized operating model for AI/ML offers advantages like consolidated
    expertise, resource optimization, and consistent governance, organizations must
    be aware of potential bottlenecks, delays, and knowledge gaps. As demand grows,
    a single central team driving all initiatives risks becoming overwhelmed, slowing
    innovation and deployment. This team may also lack deep domain-specific understanding,
    leading to solutions that inadequately address unique business unit or functional
    area needs. Consequently, there could be resistance to adoption if end users feel
    disconnected from development or misaligned with requirements. Moreover, the centralized
    approach may constrain agility, limiting experimentation and rapid adaptation
    to market changes across different domains.
  prefs: []
  type: TYPE_NORMAL
- en: Decentralized model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If an organization prioritizes delivering speedy responses tailored to local
    and domain-specific requirements, with extensive and deep local and domain expertise
    and autonomy, then adopting a decentralized operating model may be a good option.
    This is particularly viable when the organization has sufficient ML resources
    across the organization, and when establishing unified AI/ML technology standards
    and strategy is not of primary importance.
  prefs: []
  type: TYPE_NORMAL
- en: In this model, instead of a centralized team driving all AI/ML efforts, individual
    units or teams have the autonomy and resources to develop and deploy AI/ML solutions
    tailored to their specific domains or use cases. This decentralized approach allows
    for greater agility, as teams can quickly respond to changing business needs and
    market conditions without being constrained by centralized processes or bottlenecks.
    Additionally, it fosters innovation by enabling teams to experiment with new AI/ML
    techniques and approaches that are most relevant to their respective domains.
  prefs: []
  type: TYPE_NORMAL
- en: When implementing this model, organizations must consider potential challenges.
    With multiple teams or business units autonomously developing AI/ML solutions,
    there is a risk of inconsistencies in approaches, methodologies, tools, and best
    practices. This lack of standardization may result in compatibility issues, redundant
    efforts, and difficulties in integrating or scaling solutions across the organization.
  prefs: []
  type: TYPE_NORMAL
- en: In a decentralized model, establishing and enforcing a consistent governance
    framework, policies, and guidelines for responsible AI development and deployment
    becomes more challenging. This increases the risk of non-compliance with regulations,
    ethical principles, or organizational standards. Decentralized teams may operate
    in isolation, limiting knowledge sharing and the cross-pollination of ideas across
    the organization. Without a centralized coordination mechanism, inefficient resource
    allocation may occur, with some teams being under resourced while others have
    redundant or underutilized resources.
  prefs: []
  type: TYPE_NORMAL
- en: Hub and spoke model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If an organization needs to strike a balance between agility, innovation, and
    domain-specific solutions while maintaining consistency, compliance, and efficient
    resource allocation, they can consider the hub and spoke model. This is especially
    beneficial when an organization is large and operates across multiple business
    units, product lines, or geographical regions.
  prefs: []
  type: TYPE_NORMAL
- en: In the hub-and-spoke model, a centralized cross-functional team comprised of
    mainly data scientists, ML experts, AI platform specialists, and, at times, risk
    management professionals serves as the hub. This hub collaborates with decentralized
    teams throughout the organization, referred to as spokes. The hub team provides
    foundational resources, tools, and guidance to support the organization’s AI initiatives.
    Their responsibilities include developing and maintaining the organization’s AI
    strategy and roadmap in alignment with overall business objectives, establishing
    standards, best practices, and governance frameworks for AI development, deployment,
    and monitoring, providing training and upskilling programs to enhance AI capabilities
    across the organization, and facilitating collaboration, knowledge sharing, and
    the adoption of best practices among the spoke teams.
  prefs: []
  type: TYPE_NORMAL
- en: The spoke teams, sitting within individual business units, or functional areas
    of the organization, utilize the resources, tools, and guidance furnished by the
    hub to design and implement AI solutions tailored to their unique business requirements.
    These teams can encompass various roles, including domain experts with deep knowledge
    of specific business domains or problem spaces, ML and data engineers managing
    domain-specific data and ML models, application developers tasked with integrating
    and deploying AI models into existing systems, applications, or products, and
    business stakeholders and product owners accountable for identifying and prioritizing
    AI use cases and opportunities within their respective domains. They collaborate
    with the hub team to ensure alignment with the organization’s AI strategy and
    governance frameworks, developing, testing, and deploying AI models and applications
    utilizing the centralized AI platform and tools provided by the hub, monitoring
    the performance and impact of deployed AI systems within their domains, and furnishing
    domain-specific expertise and feedback to the hub team to facilitate continuous
    improvement and knowledge sharing.
  prefs: []
  type: TYPE_NORMAL
- en: The hub and spoke model also presents its own set of challenges. Effective operation
    of this model heavily depends on strong communication and coordination between
    the hub and spoke teams, which can be particularly daunting when managing numerous
    teams across various business units and functional areas. Moreover, optimizing
    resource allocation among these teams can prove challenging, as some may face
    resource shortages while others may have excess resources, resulting in inefficiencies.
    Establishing and enforcing governance frameworks and compliance standards for
    AI development and deployment across decentralized teams adds another layer of
    complexity. Successfully overcoming these obstacles requires a well-defined governance
    structure, effective communication channels, agile development processes, and
    a culture that fosters collaboration and knowledge sharing throughout the organization.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, the choice of ML operating model depends on a variety of factors,
    including the size and structure of the organization, the level of expertise within
    the organization, and the specific business needs and objectives. Regardless of
    the model chosen, it is important to establish clear roles and responsibilities,
    robust processes, and effective communication channels to ensure that ML solutions
    and products are developed and deployed successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Solving ML journey challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, you should have a good understanding of key ML maturity dimensions
    including technical, business, governance, and organizational and talent, for
    the successful adoption of AI/ML. Next, let’s delve into the key steps needed
    to establish some of these AI maturity capabilities and solve some of the key
    challenges faced along the ML journey, starting with creating an AI vision and
    strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Developing the AI vision and strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To develop an AI vision and strategy, an organization should first define the
    purpose and scope of the AI vision. The vision should explain why an organization
    is pursuing an AI strategy and what business values it hopes to achieve. For example,
    the vision for a customer support organization in a bank might be to transform
    its business operations and improve customer experience using AI; a pharmaceutical
    company might have the vision of using AI to streamline the drug discovery process
    and improve patient care; and a manufacturer might have the vision to transform
    its factories into smart factories using AI technologies to improve manufacturing
    efficiency and reduce downtime.
  prefs: []
  type: TYPE_NORMAL
- en: With an overall vision defined, an organization should conduct a thorough analysis
    of its current state capabilities and describe the desired future state outcomes
    and goals. Gaps between current states and the desired target state should be
    identified; actionable and achievable strategies should be established for the
    organization to move toward the future state.
  prefs: []
  type: TYPE_NORMAL
- en: The strategies should cover areas such as what ML technology to invest in, what
    culture and organizational changes to introduce, what tasks and business functions
    to use the AI for, and what AI technologies products and solutions to build and
    implement.
  prefs: []
  type: TYPE_NORMAL
- en: Next, an organization should define an implementation strategy and milestones
    for the short, medium, and long term. This should describe how the AI vision will
    be implemented across multiple phases and the expected scope, use cases, and outcomes
    for each of the phases.
  prefs: []
  type: TYPE_NORMAL
- en: A strategy should include how the success of AI vision will be measured through
    a combination of financial and non-financial metrics, such as customer satisfaction
    score, operational efficiency improvement, and increased revenue.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, an organization should clearly identify all the key stakeholders for
    the AI vision and execution. This includes customers, partners, employees, and
    their respective roles and responsibilities.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with the first AI/ML initiative
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For organizations without prior AI/ML expertise, getting started with the first
    AI/ML is often a challenging undertaking. There are many factors to consider,
    including what will be the first project and its scope, the sponsors and stakeholders,
    the necessary skills and resources, data availability and quality, the choice
    of tools and technologies, the implementation strategy, and the broader implication
    of change management. As an ML architect, I have worked with many organizations
    that have successfully launched their first AI/ML project, as well as those that
    have struggled to get started. In the following section, I will provide real-world
    examples from my professional experience to illustrate these challenges and best
    practices.
  prefs: []
  type: TYPE_NORMAL
- en: I once worked with an engineering leadership at an organization that aimed to
    introduce AI capabilities into their customer support workflow to increase the
    cross-sell and upsell of the company’s products. The team had an idea to use AI
    to extract insights from call transcripts to identify customer intent and recommend
    new products based on the customer’s profile and intent. A lot of analysis was
    conducted on the business benefits, operations workflows, and potential solution
    architecture. While the idea made sense in concept, it failed to account for other
    factors including business changes in downstream organizations and systems, a
    lack of cross-functional stakeholders, buy-in, and misalignment with the core
    customer engagement model for its products. As a result the project failed to
    secure funding as the perceived business benefit did not justify the investment
    and change management required.
  prefs: []
  type: TYPE_NORMAL
- en: In another project I was involved in, an organization sought to use ML to maximize
    the return of their advertising budget by predicting the likelihood of users clicking
    on ad impressions and the potential value of the users.
  prefs: []
  type: TYPE_NORMAL
- en: A financial analysis was conducted and a business case was written on the proposal,
    and the project was given the green light to move forward as a pilot. However,
    the execution team refused to use any outside assistance, even though the team
    had very limited data science experience in this area – they opted to learn on
    the job. As a result, the project moved very slowly, as the team had to do many
    time-consuming experiments on the data science and engineering approaches to validate
    any assumptions and decisions they came across. While the team was eventually
    able to develop a working pilot after significant delays, it did not deliver the
    anticipated business lift, and no further funding was allocated to continue the
    project.
  prefs: []
  type: TYPE_NORMAL
- en: One of the organizations I engaged with had several ideas for improving their
    fan engagement experience using AI-enabled analytics. The organization did not
    have any ML experience on this topic but was open to working with a partner who
    had ML competency. The team collectively analyzed the technical feasibility and
    business benefits of each of the ideas, the data availability and quality, and
    the change management required for both business workflow and upstream and downstream
    systems. The decision was to go with an idea that had a high degree of being successful
    in model outcome and adoption. The idea also resonated with internal stakeholders
    as they could relate to the idea. The pilot was successfully executed with the
    expected outcome and a longer-term vision and plan were established to extend
    the adoption of AI/ML, and a talent upskill program was put in place to develop
    in-house talent for future projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'In summary, getting started with the first AI/ML project can be a challenging
    task for many organizations and the success or failure of the first pilot can
    have a significant impact on the future direction of AI/ML adoption within an
    organization. The following are some of the key best practices to follow when
    starting your first AI/ML pilot:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Project selection**: Pick a project that has clear business benefits in the
    context of the organization. The business benefit does not need to be only a financial
    benefit, but it needs to resonate with internal and external stakeholders as these
    stakeholders can be strong supporters of the project. Avoid high-risk and complex
    projects, and make sure there is a clear business sponsor for the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Project scope and execution**: Keep the scope small, as long as it can demonstrate
    the business benefits. Ensure the project is achievable in terms of people, skills,
    data, infrastructure, change management, and execution. Use an experienced partner
    to help reduce risk where needed. Start with a POC to provethetechnical feasibility
    and business value if they are not clear or defined.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Measurement**: Establish business metrics to measure the incremental value
    of the project. This is important to secure approval for future investment and
    evaluate the success of the project. Also, measure the ROI for the costs to develop
    and maintain the project to make sure there is ongoing benefit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In conclusion, starting your first AI/ML project can be a daunting task, and
    the success or failure of the first pilot can significantly impact the future
    direction of AI/ML adoption within your organization.
  prefs: []
  type: TYPE_NORMAL
- en: Solving scaling challenges with AI/ML adoption
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As organizations adopt AI/ML technology, they are often faced with scaling challenges.
    These challenges are diverse and can range from difficulty in defining and implementing
    the right use cases, obtaining and managing the necessary data, acquiring and
    retaining the required talent and technology, to ensuring the organizational design
    and governance frameworks are in place for the AI/ML initiative.
  prefs: []
  type: TYPE_NORMAL
- en: One of the biggest challenges organizations face when scaling AI/ML is identifying
    the most suitable use cases to implement. It may not always be clear what problems
    AI/ML can help solve, or how the technology can be integrated into existing business
    processes. As a result, organizations may end up investing in use cases that are
    not fully aligned with their needs, which leads to delays, inefficiencies, and
    low ROI. I recall speaking with a chief data scientist at a large financial services
    organization and asking about his biggest challenges in adopting AI/ML. To my
    surprise, his response was not related to science or technology, but rather finding
    the right use cases that bring value to both his customers and the company was
    his biggest challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Another scaling challenge organizations face is in securing the right data.
    Unlike traditional data management and analytics, AI/ML relies on large amounts
    of data from different modalities to train a model and make predictions, so having
    access to high-quality, reliable data is critical. This is not a unique challenge
    for data-constrained organizations, as even data-rich organizations also face
    challenges with data ownership, data quality, data security and privacy, and data
    access. I have personally witnessed the difficulty organizations face in obtaining
    the required data at scale to support their AI/ML expansion efforts, particularly
    when it comes to migrating data to the public cloud, where many enterprises are
    constructing their AI/ML infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Attracting and retaining talent with the right skills and experience is another
    challenge that organizations face when scaling AI/ML. This is especially true
    for organizations that are looking to build in-house AI/ML capabilities, as the
    demand for AI/ML professionals is high and the pool of available talent is limited.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, organizations need to invest in training and development programs
    to help build the skills of their existing employees or look for alternative ways
    to access the talent they need.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, organizations need to ensure that their technology and organization
    design and governance frameworks are aligned with their AI/ML initiatives. This
    requires organizations to have a clear understanding of what is required, including
    any regulatory requirements, to enable AI/ML adoption at scale, as well as an
    assessment of current systems, processes, policies, and changes necessary to support
    the integration and scaling of AI/ML. For example, organizations may need to invest
    in new infrastructure and tools, implement new security and privacy protocols,
    or revise their decision-making processes to ensure that the use of AI/ML is in
    line with ethical and legal requirements. As most organizations are new to this
    domain, it often takes a long time and many iterations to get everything in place
    correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Addressing the various scaling challenges for ML adoption is a complex task
    that requires significant investment and detailed planning and execution by an
    organization. Next, I will go over some recommendations for addressing some of
    the challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Solving ML use case scaling challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When it comes to identifying ML use cases at scale, it is important to follow
    a structured approach with cross-functional collaboration to ensure success. The
    following are a few best practices for identifying ML use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Conduct analysis of business processes and engage stakeholders
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For organizations to effectively adopt and utilize ML technology, it is important
    to conduct a thorough analysis of their business processes. This analysis should
    aim to identify any gaps or areas for improvement that can be addressed through
    the use of ML.
  prefs: []
  type: TYPE_NORMAL
- en: The analysis should be a collaborative effort that involves stakeholders from
    across the organization, including individuals from different departments and
    business units. This will help to ensure that the organization has a clear understanding
    of the needs and requirements of all stakeholders and that the use of ML aligns
    with the overall goals and objectives of the organization.
  prefs: []
  type: TYPE_NORMAL
- en: Engaging stakeholders in the analysis process will also help to identify opportunities
    for ML to improve business processes and outcomes. For example, ML can be used
    to automate repetitive tasks, streamline decision-making processes, and improve
    the accuracy and efficiency of various business operations. However, to fully
    realize these benefits, it is important to understand the specific needs of different
    stakeholders and how ML can be used to meet those needs.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluate commonly known industry use cases and solutions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Organizations should learn about and review common ML use cases and solutions
    that are being used in their industry to identify potential opportunities for
    improvement using ML in their own organizations. This helps identify opportunities
    that are already proven effective and can provide proven ROI. This also helps
    the organization to keep up to date with the latest ML trends and best practices
    in their industry.
  prefs: []
  type: TYPE_NORMAL
- en: Organizations can start by researching and reviewing common ML use cases and
    solutions that are being used in their industry. This can include case studies,
    whitepapers, and reports that provide insights into the successes and challenges
    faced by organizations in their industry when using ML. By studying these examples,
    organizations can gain a better understanding of the various applications of ML,
    and identify opportunities for improvement in their own processes and operations.
  prefs: []
  type: TYPE_NORMAL
- en: Run new idea-generation programs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Organizations can foster innovation and creativity by running structured programs
    for idea generation. These programs can take the form of regular events such as
    knowledge-sharing sessions, patent drives, or hackathons, and can provide a platform
    for employees to come up with new and innovative ideas related to ML and other
    related technologies.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, knowledge-sharing sessions can be organized to bring together
    experts from various domains within the organization to share their experiences,
    learnings, and best practices in ML. These sessions can help to promote cross-functional
    collaboration and encourage the exchange of ideas, leading to the development
    of new and innovative solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Hackathons are another popular mechanism for idea generation in organizations.
    They provide a platform for employees to work together for a short period of time
    to come up with new and creative ideas. Hackathons can be organized around specific
    themes related to ML, such as developing new models for a particular domain or
    improving the performance of existing models. The goal of a hackathon is to encourage
    employees to think creatively and come up with new and innovative solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Build ML use case repositories and model hubs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Organizations can create centralized repositories and hubs to store and manage
    various ML use cases and models. These repositories and hubs can help organizations
    to better manage their ML assets, promote collaboration and idea sharing, and
    encourage the reuse of existing models and solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The ML use case repositories can contain a catalog of various use cases that
    have been implemented within the organization, along with relevant information
    such as the problem statement, data used, model architecture, and performance
    metrics. This information can be used by other teams within the organization to
    understand the approaches taken for different use cases and help them identify
    potential solutions for their own projects.
  prefs: []
  type: TYPE_NORMAL
- en: The model hubs, on the other hand, can serve as a centralized location for storing
    and managing various ML models developed within the organization. These models
    can be easily accessed and reused by other teams, reducing the need for re-inventing
    the wheel and speeding up the development process. The model hubs can also include
    information about the models such as the performance metrics, data used for training,
    and the application domain.
  prefs: []
  type: TYPE_NORMAL
- en: New business models and product innovation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As organizations explore new business models and product concepts, it is important
    to consider the potential for ML to play a role in providing unique and valuable
    offerings to customers.
  prefs: []
  type: TYPE_NORMAL
- en: One way to do this is by incorporating ML into the design of new business models
    and products. This can involve using ML to automate certain processes, improve
    the accuracy of decision making, and provide customers with more personalized
    and relevant experiences. For example, an e-commerce company could use ML to recommend
    products to customers based on their individual preferences and purchase history,
    providing a more personalized shopping experience.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to incorporating ML into existing business models and products,
    organizations can also explore new markets and identify new revenue streams that
    can be generated through the use of ML. For example, an organization could use
    ML to analyze customer data and identify new product or service offerings that
    would appeal to a specific customer segment. Alternatively, an organization could
    use ML to automate certain processes and reduce costs, allowing it to enter new
    markets or expand its existing offerings.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating and approving use cases
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To ensure that AI/ML use cases deliver their intended business value, it is
    important to establish a qualification framework and process for evaluating and
    approving the use cases before implementation. Some of the considerations that
    can be included in the qualification framework are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Business impact**: The use case should have a meaningful business impact,
    such as increasing revenue, reducing costs, reducing work, or improving customer
    satisfaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data availability**: Sufficient high-quality data should be available for
    the use case. This includes both training data for model development and real-time
    data for model deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feasibility**: The use case should be technically feasible to implement,
    taking into account factors such as data integration, infrastructure requirements,
    and resource availability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ethical considerations**: The use case should not have any negative ethical
    implications, such as infringing on privacy or discriminating against certain
    groups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regulatory compliance**: The use case should comply with all relevant regulations
    and legal requirements, such as data privacy laws or industry-specific regulations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Risk assessment**: The potential risks associated with the use case, such
    as model bias or incorrect predictions, should be assessed and mitigated to ensure
    the use case is safe to deploy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By following these best practices, organizations can identify suitable ML use
    cases at scale, and ensure that their ML initiatives are aligned with their business
    goals and have the best chance of success. It is also important for organizations
    to continually monitor and evaluate their ML initiatives to ensure that they are
    delivering the desired results and that they remain aligned with the overall AI
    vision and goals of the organization.
  prefs: []
  type: TYPE_NORMAL
- en: Solving technology scaling challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When starting AI/ML initiatives, early in the ML journey, organizations may
    have limited technology infrastructure and tools, leading them to use open-source
    tools such as Jupyter Notebook and ML libraries on personal laptops or desktops
    without formal IT support. Data scientists in these organizations would manually
    install and configure these data science environments, collect data manually,
    create their own training data, and train models locally before deployment into
    production environments. I have worked with several organizations that faced different
    challenges from this approach, such as data and IP loss, data privacy violation,
    and the inability to validate and audit model performance before and after deployment.
    The inadequate technology infrastructure also limited these organizations’ ability
    to work on more advanced ML problems.
  prefs: []
  type: TYPE_NORMAL
- en: To mitigate these risks and challenges, many mature organizations choose to
    implement enterprise-grade ML platforms to support their increasing ML project
    demands and manage risk and compliance more thoroughly. Depending on the current
    state of their ML infrastructure, organizations may face different scaling challenges
    and choose different paths to expand their technology infrastructure. Next, I
    will outline the various considerations and paths for scaling technology and governance
    frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: For organizations without standard ML tools and infrastructure in place, the
    recommended path for scaling is to invest in standard ML infrastructure and tools
    and establish dedicated teams to build and manage the infrastructure and tools,
    and drive their adoption.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the business needs and organization structure, the scope of ML
    infrastructure and team investment can vary to support the needs of a functional
    department, a line of business, or the entire enterprise. Through my experience
    working with various organizations, I have seen firsthand the benefits of implementing
    a standardized ML platform to meet growing needs. Here are some of the best practices
    and considerations to keep in mind when embarking on the path of building an ML
    platform and driving its adoption.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a blueprint
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Creating a clear blueprint for an ML platform is an important step in the implementation
    process. The blueprint should outline the key features and capabilities of the
    platform, the target audience and users, and how the platform will integrate into
    existing business workflows and systems.
  prefs: []
  type: TYPE_NORMAL
- en: The first step in creating a blueprint is to identify the key features and capabilities
    of the ML platform. This should include a detailed description of the platform
    capabilities, such as experimentation, training, hosting, the data sources that
    will be integrated, and the user interfaces and tools that will be provided. It
    is also important to consider managing models post deployment, the scalability
    and reliability of the platform, and any security and privacy concerns that may
    need to be addressed.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the blueprint should outline the target audience and users of the platform.
    This should include a detailed description of the role and responsibilities of
    each user, as well as the specific requirements and needs of each user group.
    This information can be used to design the user interface and tools and to ensure
    that the platform meets the needs of all users.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the blueprint should describe how the ML platform will integrate into
    existing business workflows and systems. This includes identifying the data sources
    that will be used, and how data will be collected, processed, and stored. It also
    includes identifying the systems and applications that will need to be integrated,
    and how the ML platform will interact with these systems.
  prefs: []
  type: TYPE_NORMAL
- en: Taking a phased approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Building an enterprise ML platform is a complex and challenging project that
    requires careful planning and execution. To ensure the success of the project,
    it is important to avoid a “big bang” approach, where all components of the platform
    are developed and deployed at once. Instead, organizations should adopt a phased
    approach to building their ML platform.
  prefs: []
  type: TYPE_NORMAL
- en: A phased approach involves dividing the development and deployment of the ML
    platform into smaller, manageable phases. This approach allows organizations to
    validate their assumptions about user needs and requirements, and adjust the course
    of the project if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: For example, an organization might start by building a basic ML platform that
    provides a limited set of features and capabilities, and then gradually add additional
    features and capabilities over time.
  prefs: []
  type: TYPE_NORMAL
- en: Using a phased approach has several benefits. First, it allows organizations
    to validate their assumptions about user needs and requirements and make any necessary
    adjustments before investing significant resources into the development of the
    entire platform. Second, it allows organizations to prioritize their development
    efforts based on the most pressing needs of their business. Third, it reduces
    the risk of costly re-dos by allowing organizations to test and refine the platform
    before deploying it at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring a parallel data strategy that supports the ML platform strategy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: ML platforms rely heavily on the availability of high-quality, relevant data
    to train and validate models. Therefore, it is critical to ensure that there is
    a parallel data strategy in place that supports the ML platform strategy. A data
    strategy should outline how data will be collected, stored, processed, and made
    available for the ML platform and its users to use. Difficulty in data discovery
    or access can slow down or hamper an ML project.
  prefs: []
  type: TYPE_NORMAL
- en: Making technology stack decisions based on needs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When building an ML platform, organizations have several technology options
    to choose from, including open-source technology, managed ML platforms, and hybrid
    solutions. The right technology option depends on the organization’s overall technology
    strategy, budget, and talent availability:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Open-source technology**: Organizations that have already made an open-source
    first strategy decision and have invested in open-source technology, engineering
    expertise, and enterprise applications may choose to build their ML platform using
    open-source technology and self-manage it. This option provides organizations
    with the greatest level of control and flexibility to introduce innovations into
    the technology stack for competitive advantage. However, building and maintaining
    an ML platform using open-source technology can also be a significant cost and
    challenge, and require specialized technical skills and resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managed ML platforms**: Organizations that do not want to compete on ML infrastructure
    and face challenges in hiring and retaining engineering talent may choose to adopt
    a managed ML platform such as Amazon SageMaker. This option provides organizations
    with a fully managed platform that eliminates the need to manage the underlying
    technology stack. Organizations can customize and integrate the managed platform
    into their existing technology stacks, but may also face limitations in terms
    of flexibility and control.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid approach**: Other organizations may choose to adopt a hybrid approach,
    where they build out part of the ML platform using open-source or proprietary
    technology stacks and integrate commercial solutions into the end-to-end platform.
    This option provides organizations with the best of both worlds, combining the
    flexibility and control of open-source technology with the ease of use and scalability
    of commercial solutions. However, this option can also be the most complex and
    challenging to implement, maintain, and provide users with a seamless end-to-end
    experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bringing along pilot ML projects
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Incorporating pilot ML projects into the implementation plan of building an
    ML platform is an important consideration. This helps to ensure that the platform
    is designed and built to meet the specific needs of the actual users and real
    ML use cases. By bringing along pilot projects, organizations can test the platform
    with real data and real use cases to validate its functionality, performance,
    and scalability. This also provides an opportunity to receive feedback from users
    and stakeholders and make any necessary adjustments to the platform before its
    wider deployment. This approach helps to ensure that the ML platform is fit for
    purpose and meets the needs of the organization, which can ultimately lead to
    faster adoption and more successful outcomes from the platform.
  prefs: []
  type: TYPE_NORMAL
- en: Investing in an adoption program
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Investing in an adoption program is crucial to the success of an ML platform.
    Building the platform is only half the battle; organizations also need to ensure
    that their users are aware of the platform and are equipped with the skills and
    knowledge to use it effectively. This is why it is important to invest in enablement
    and knowledge-sharing programs that aim to increase awareness and understanding
    of the platform and the new technologies that are used in it.
  prefs: []
  type: TYPE_NORMAL
- en: One way to drive adoption is to provide self-service capabilities, such as self-service
    provisioning, which allows users to easily access the platform and its resources.
    This can help to reduce friction and increase user adoption, as users are not
    required to wait for approval or assistance from IT or other teams.
  prefs: []
  type: TYPE_NORMAL
- en: Another effective approach is to form a solution engagement team, whose role
    is to help different LOBs and users onboard their workloads onto the platform.
    This solution team can provide support and guidance to users, helping to ensure
    a smooth and successful transition to the new platform.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, building and scaling an ML platform is a complex and challenging
    project that requires careful planning and execution. Organizations should invest
    in standard ML infrastructure and tools, establish dedicated teams to build and
    manage the infrastructure and tools, and drive their adoption. They should create
    a clear blueprint for the ML platform, take a phased approach to building it,
    ensure there is a parallel data strategy that supports it, and make technology
    stack decisions based on their needs.
  prefs: []
  type: TYPE_NORMAL
- en: Solving governance scaling challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ML governance encompasses the policies, processes, and standards that organizations
    establish to govern the development, deployment, and usage of ML models. Its purpose
    is to ensure that the deployment of ML models aligns with the organization’s objectives,
    values, and ethical standards.
  prefs: []
  type: TYPE_NORMAL
- en: ML governance also manages the risks involved in deploying ML models, such as
    incorrect predictions, discriminatory outcomes, and privacy breaches. A well-designed
    governance framework provides peace of mind to both the organization and its stakeholders
    and increases trust in the organization’s AI/ML capabilities. On the contrary,
    a lack of governance can lead to various problems, such as privacy violations,
    biased model consequences, model drift, and non-compliance with regulations. Thus,
    it is essential for organizations to invest in building and maintaining a robust
    governance framework as they embark on their AI/ML journey.
  prefs: []
  type: TYPE_NORMAL
- en: However, many organizations find it challenging to implement an effective ML
    governance framework that balances responsibility and ethics with the need for
    innovation and fast-paced deployment. This requires finding a delicate balance
    between control and flexibility, having the appropriate processes in place to
    regulate and monitor the deployment of ML models, and considering the organization’s
    specific needs, resources, and goals. It is also essential for organizations to
    periodically review and update their governance framework as the field of ML continues
    to change and evolve.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s take a look at some best practices in establishing a governance framework.
  prefs: []
  type: TYPE_NORMAL
- en: Define objectives clearly
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Having clear and well-defined objectives for the ML governance framework is
    crucial to ensure that it is focused on the right issues and will not impede the
    pace of innovation. These objectives should be aligned with the overall goals
    and values of the organization and should reflect the organization’s priorities
    for the responsible and ethical deployment of ML. Examples of objectives for an
    ML governance framework may include ensuring compliance with regulations and ethical
    standards, promoting transparency in decision making, and protecting sensitive
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Establish clear responsibility and accountability
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Defining clear responsibility and accountability is a critical component of
    a successful ML governance framework. This means that the framework should clearly
    outline the responsibilities of different teams and individuals involved in the
    ML deployment process. This will help to ensure that the framework is properly
    implemented and that any issues or concerns are addressed in a timely manner.
  prefs: []
  type: TYPE_NORMAL
- en: Address data privacy concerns
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A well-designed ML governance framework should address data management and privacy
    concerns to ensure that personal data is protected and used responsibly. This
    is particularly important in industries such as healthcare, finance, and retail,
    where large amounts of sensitive personal data are collected and used.
  prefs: []
  type: TYPE_NORMAL
- en: The framework should include policies and procedures for data collection, storage,
    and use, as well as security measures to prevent unauthorized access to sensitive
    data. This may include data privacy policies, data protection regulations, and
    data management protocols that are designed to ensure that data is collected,
    stored, and used in a responsible and ethical manner, and in compliance with various
    regulations, such as the **General Data Protection Regulation** (**GDPR**) or
    **California Privacy Rights Act** (**CPRA**).
  prefs: []
  type: TYPE_NORMAL
- en: Enable governance automation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Governance automation refers to the use of technology and automated processes
    to support and manage the ML governance framework. Automating certain aspects
    of the framework can significantly reduce the overhead and manual operations involved
    in managing and monitoring the deployment of ML models.
  prefs: []
  type: TYPE_NORMAL
- en: For example, automating data collection processes can help to ensure that data
    is collected accurately and consistently, without the need for manual data entry
    or verification. Automated evidence validation and compliance analysis can also
    help to streamline the compliance review process, reducing the time and effort
    required to manually review and validate evidence.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, automation can be used to support ongoing monitoring and reporting
    of the deployment of ML models. For example, automated monitoring and reporting
    systems can be used to track and report on the performance and impact of the models,
    and to identify any potential risks or issues that may arise.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing a governance framework for ML is essential for ensuring the responsible
    and ethical deployment of ML models. By following guidelines and best practices,
    organizations can ensure that their ML models are deployed in a responsible and
    ethical manner that aligns with their overall goals and values. This will not
    only help to prevent potential risks and issues, but also promote transparency
    and trust with customers, stakeholders, and regulators.
  prefs: []
  type: TYPE_NORMAL
- en: Establish a dedicated AI governance function
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The need for responsible development and deployment of AI systems presents significant
    governance challenges due to the complexity and potential risks involved. AI systems
    can perpetuate biases, raise privacy concerns, and have unintended consequences
    if not properly governed. Additionally, the rapidly evolving regulatory landscape
    surrounding AI, such as the EU AI Act and Singapore Model AI Governance Framework,
    demands robust compliance measures. Given these complexities and challenges, instead
    of having individual functions and project teams to navigate through their organization’s
    own principles and external regulatory guidelines, an organization should establish
    dedicated AI governance teams or functions to help streamline the governance processes
    for faster AI solution delivery. This team would be responsible for developing
    and enforcing standards, policies, and best practices to ensure the ethical and
    responsible use of AI across the enterprise, and they would support the internal
    functional and project teams to assess risks, implement appropriate controls,
    and maintain compliance with relevant regulations and industry guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: Solving user onboarding and business integration challenges
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Simply having a lot of ML models does not guarantee successful business integration.
    Integrating ML models into the business requires a significant amount of effort
    and investment– sometimes even more than the initial efforts of identifying ML
    use cases and implementing the ML models and infrastructure. This is because integrating
    ML models into the business process requires changes to the way the business operates,
    as well as investment in communication, training, and onboarding.
  prefs: []
  type: TYPE_NORMAL
- en: One key challenge when integrating ML models into the business is ensuring that
    everyone in the organization understands the changes and is on the same page.
    Communication is critical, and it is important to keep all stakeholders informed
    and engaged throughout the process. This includes not only the technical teams
    responsible for building the models but also business stakeholders who will be
    affected by the changes.
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge is redesigning business workflows to accommodate the new ML
    capabilities. This involves identifying where ML can be integrated most effectively,
    rethinking existing business processes, and identifying new workflows that take
    advantage of the new capabilities. For example, if you have developed ML models
    to identify customers with high cross-sell and upsell potential, you need to implement
    the required business process changes to act on these insights, such as building
    outbound engagement teams or mechanisms to reach out to these customers.
  prefs: []
  type: TYPE_NORMAL
- en: To enhance the effectiveness of AI/ML integration, organizations must not only
    implement the ML solution but also take action and make decisions based on the
    insights provided by these systems. For instance, if an organization has implemented
    a credit decision system that automatically scores users’ eligibility for loans,
    but continues to rely on humans to make the final decision for the majority of
    cases, the value of the ML system will be diminished. This undermines the potential
    for the sustained adoption of ML across the organization. Therefore, it is crucial
    for organizations to trust and utilize the insights provided by ML solutions to
    fully realize the benefits of the technology.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, investing in training and onboarding is essential to ensure that end
    users and teams are able to ramp up on the new ML capabilities and workflows.
    This includes not only technical training for those responsible for using and
    maintaining the models but also training for business stakeholders who may not
    have technical expertise but will be using the models in their day-to-day work.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the different phases of ML adoption and AI/ML capabilities.
    You were introduced to the assessment of ML adoption maturity through a set of
    questions aimed at identifying key areas for developing AI/ML maturity. We also
    discussed the best practices in establishing an AI/ML vision, initiating an AI/ML
    initiative, and scaling your AI/ML adoption across different ML use cases, ML
    infrastructure, and ML governance.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming two chapters, we will delve deeper into generative AI, exploring
    its impact on businesses, its use cases, technological solutions, architectural
    considerations, and practical applications that leverage generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: Leave a review!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enjoying this book? Help readers like you by leaving an Amazon review. Scan
    the QR code below to get a free eBook of your choice.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Review_Copy.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Limited Offer*'
  prefs: []
  type: TYPE_NORMAL
