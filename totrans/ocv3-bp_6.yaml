- en: 2D scale space relation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2D尺度空间关系
- en: 'Another large advantage that we can exploit in industrial cases is the fact
    that many of these setups have a fixed camera position. This is interesting when
    the objects that need to be detected follow a fixed ground plane, like in the
    case of pedestrians or objects passing by on a conveyor belt. If these conditions
    exist, then there is actually a possibility to model the scale of an object at
    each position in the image. This yields two possible advantages:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个在工业案例中可以充分利用的巨大优势是，许多这些设置都有一个固定的相机位置。当需要检测的对象遵循一个固定的地面平面时，这很有趣，例如在行人或通过传送带的物体的情况下。如果这些条件存在，那么实际上就有可能在每个图像位置建模对象的尺度。这产生了两个可能的优势：
- en: First of all, you can use this knowledge to effectively reduce the number of
    false positive detections while still keeping your certainty threshold low enough
    so that low certainty and good detection still stick around. This can be done
    in some sort of post-processing step after the object detection phase.
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，你可以利用这些知识有效地减少误报检测的数量，同时保持你的置信度阈值足够低，以便低置信度和良好的检测仍然存在。这可以在对象检测阶段之后的某些后处理步骤中完成。
- en: Secondly, this knowledge can be used to effectively reduce the detection time
    and search space for object candidates inside the image pyramid.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，这些知识可以用来有效地减少图像金字塔中对象候选者的检测时间和搜索空间。
- en: Let's start by focusing on the following case, illustrated in the following
    figure. Consider the fact that we want to create a pedestrian detection and that
    we have an existing model for doing so. We have a 360-degree camera mounted on
    top of a car and are grabbing those cycloramic images at continuous intervals.
    The cycloramas are now passed on towards the computer vision component that needs
    to define if a pedestrian is actually occurring in the image. Due to the very
    large resolution of such a 360-degree cyclorama, the image pyramid will be huge,
    leading to a lot of false positive detections and a very long processing time.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从关注以下案例开始，该案例在下面的图中进行了说明。考虑这样一个事实：我们想要创建一个行人检测系统，并且我们已经有一个用于此目的的现有模型。我们有一个安装在汽车顶部的360度相机，并且以连续的时间间隔抓取这些全景图像。由于这种360度全景图像的分辨率非常大，图像金字塔将会非常庞大，导致大量的误报检测和非常长的处理时间。
- en: '![2D scale space relation](img/00087.jpeg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![2D尺度空间关系](img/00087.jpeg)'
- en: An example of the Viola and Jones cascade classifier pedestrian detection model
    in OpenCV 3 based on HAAR features
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 基于HAAR特征的OpenCV 3中Viola和Jones级联分类器行人检测模型的示例
- en: 'The example clearly shows that when applying the detector it is very hard to
    find a decent score threshold to only find pedestrians and no longer have a bunch
    of false positive detections. Therefore, we took a base set of 40 cycloramic images
    and manually annotated each pedestrian inside, using our object annotation tool.
    If we then visualized the annotation heights of the bounding box in function of
    the x position location of appearance in the image, we could derive the following
    relation, as shown in the following graph:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 例子清楚地表明，在应用检测器时，很难找到一个合适的分数阈值，以仅检测行人而不再有一系列误报检测。因此，我们选取了一组40张全景图像，并使用我们的对象标注工具手动标注了其中的每个行人。如果我们然后可视化边界框的标注高度与图像中出现的x位置位置的关系，我们就可以得出以下关系，如图所示：
- en: '![2D scale space relation](img/00088.jpeg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![2D尺度空间关系](img/00088.jpeg)'
- en: Scale space relation between the position of the annotation in the image and
    the scale of the found detection
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图像中标注位置与找到的检测尺度之间的尺度空间关系
- en: 'The red dots in this figure are all possible ground truth annotations that
    we retrieved from the test bench of 40 cycloramas. The red line is the linear
    relation that we fitted to the data and which describes more or less which scale
    should be detected on which location in the image. However, we do know that there
    could be a small variation on that specific scale as defined by the green borders,
    in order to contain as much of the annotations as possible. We used the rule of
    assigning a Gaussian distribution and thus agree that in the range [-3sigma,+3sigma]
    98% of all detections should fall. We then apply the minimal and maximal value
    according to our ranges and define a region where objects can occur naturally,
    assigned with the blue borders and visualized in the following picture:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图中的红色点都是我们从40个圆柱形场景的测试平台上检索到的所有可能的地面真实标注。红色线条是我们拟合到数据上的线性关系，它描述了在图像的哪个位置应该检测到哪个尺度。然而，我们知道，根据绿色边界定义的特定尺度可能会有轻微的变化，以便尽可能包含更多的标注。我们使用了分配高斯分布的规则，因此同意在[-3sigma,+3sigma]范围内，98%的所有检测都应该落在该范围内。然后，我们根据我们的范围应用最小值和最大值，并定义了一个物体可以自然出现的区域，用蓝色边界标记，并在以下图片中可视化：
- en: '![2D scale space relation](img/00089.jpeg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![2D尺度空间关系](img/00089.jpeg)'
- en: Possible locations of pedestrians walking in the same ground plane and fully
    visible by the camera system
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 行人在同一地面平面上且完全被摄像头系统看到的可能位置
- en: This means that if we run a detector on this input image, we already can eliminate
    more than 50% of the image because training data clearly shows that a pedestrian
    cannot occur in that location. This reduces the search space quite a lot! The
    only downside to this approach of limiting the search space with an image mask
    is that people on, for example, balconies will simply be ignored. But again, in
    this application, it was not necessary to find these people since they are not
    in the same ground plane.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，如果我们在这个输入图像上运行检测器，我们就可以消除超过50%的图像，因为训练数据清楚地显示，行人不可能出现在那个位置。这大大减少了搜索空间！这种使用图像掩码限制搜索空间的方法的唯一缺点是，例如，阳台上的行人将被简单地忽略。但再次强调，在这个应用中，没有必要找到这些人，因为他们不在同一个地面平面上。
- en: We then finally combined everything we know from this chapter together. We applied
    a scale space relation for all possible scales that can occur, already only inside
    the mask area because objects cannot exist outside of it in our application. We
    then lowered the score threshold to have more detections and to ensure that we
    have detected as many pedestrians as possible before applying our filtering based
    on the scale-space relation. The result can be shown here. It clearly shows that
    there are applications where the contextual information can increase your detection
    rates a lot!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们最终将本章中我们知道的所有内容结合起来。我们对所有可能出现的尺度应用了尺度空间关系，这仅限于掩码区域内部，因为在我们应用中，物体不能存在于该区域之外。然后，我们将分数阈值降低，以便有更多的检测，并确保在应用基于尺度空间关系的过滤之前，我们已经检测到尽可能多的行人。结果可以在这里展示。它清楚地表明，在某些应用中，上下文信息可以大大提高检测率！
- en: '![2D scale space relation](img/00090.jpeg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![2D尺度空间关系](img/00090.jpeg)'
- en: 'The complete pipeline: 1) detection with low threshold, 2) applying the mask
    and removing a lot of false positives, 3) enforcing the scale space location to
    remove extra false positive detections'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的流程：1）使用低阈值进行检测，2）应用掩码并移除大量误报，3）强制执行尺度空间位置以移除额外的误报检测
- en: Performance evaluation and GPU optimizations
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能评估和GPU优化
- en: We are heading towards the end of this chapter, but before we end, I would like
    to address two small but still important topics. Let's start by discussing the
    evaluation of the performance of cascade classifier object detection models by
    using not only a visual check but by actually looking at how good our model performs
    over a larger dataset.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在接近本章的结尾，但在结束之前，我想讨论两个虽然小但仍然重要的话题。让我们首先讨论通过不仅进行视觉检查，而且实际查看我们的模型在更大的数据集上表现如何来评估级联分类器物体检测模型的性能。
- en: Object detection performance testing
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 物体检测性能测试
- en: We will do this by using the concept of precision recall curves. They differ
    a bit from the more common ROC curves from the statistics field, which have the
    downside that they depend on true negative values, and with sliding windows applications,
    this value becomes so high that the true positive, false positive, and false negative
    values will disappear in relation to the true negatives. Precision-recall curves
    avoid this measurement and thus are better for creating an evaluation of our cascade
    classifier model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过使用精确度-召回率曲线的概念来完成这项工作。它们与统计学领域更常见的ROC曲线略有不同，其缺点是它们依赖于真实负值，而在滑动窗口应用中，这个值变得如此之高，以至于真实正例、假正例和假负例的值相对于真实负例将消失。精确度-召回率曲线避免了这种测量，因此更适合创建对我们级联分类器模型的评估。
- en: '*Precision = TP / (TP + FP)* and *Recall = TP / (TP + FN)* with a true positive
    (TP) being an annotation that is also found as detection, a false positive (FP)
    being a detection for which no annotation exist, and a false negative (FN) being
    an annotation for which no detection exists.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*精确度 = TP / (TP + FP)* 和 *召回率 = TP / (TP + FN)*，其中真实正例（TP）是指既被标注又被检测到的注释，假正例（FP）是指没有标注但被检测到的检测，假负例（FN）是指没有检测到的标注。'
- en: These values describe how good your model works for a certain threshold value.
    We use the certainty score as a threshold value. The **precision** defines how
    much of the found detections are actual objects, while the **recall** defines
    how many of the objects that are in the image are actually found.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值描述了你的模型在某个阈值值下的表现。我们使用置信度分数作为阈值值。**精确度**定义了所找到的检测中有多少是实际对象，而**召回率**定义了图像中实际找到的对象数量。
- en: Note
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Software for creating PR curves over a varying threshold can be found at [https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_5/source_code/precision_recall/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_5/source_code/precision_recall/).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_5/source_code/precision_recall/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_5/source_code/precision_recall/)可以找到用于在变化阈值上创建PR曲线的软件。
- en: 'The software requires several input elements:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 该软件需要几个输入元素：
- en: First of all, you need to collect a validation/test set that is independent
    of the training set because otherwise you will never be able to decide if your
    model was overfitted for a set of training data and thus worse for generalizing
    over a set of class instances.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，你需要收集一个与训练集独立的验证/测试集，因为否则你永远无法决定你的模型是否对一组训练数据过拟合，从而在泛化到一组类别实例时表现更差。
- en: Secondly, you need an annotation file of the validation set, which can be seen
    as a ground truth of the validation set. This can be made with the object annotation
    software that is supplied with this chapter.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，你需要验证集的标注文件，这可以被视为验证集的基准。这可以使用本章提供的对象标注软件来完成。
- en: Third, you need a detection file created with the detection software that also
    outputs the score, in order to be able to vary over those retrieved scores. Also,
    ensure that the nonmaxima suppression is only set at 1 so that detections on the
    same location get merged but none of the detections get rejected.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三，你需要一个由检测软件创建的检测文件，该文件还输出分数，以便能够改变这些检索到的分数。同时，确保非极大值抑制仅设置为1，以便在同一位置的检测被合并，但没有任何检测被拒绝。
- en: When running the software on such a validation set, you will receive a precision
    recall result file as shown here. Combined with a precision recall coordinate
    for each threshold step, you will also receive the threshold itself, so that you
    could select the most ideal working point for your application in the precision
    recall curve and then find the threshold needed for that!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当在这样一个验证集上运行软件时，你将收到一个精确度-召回率结果文件，如这里所示。结合每个阈值步骤的精确度-召回率坐标，你还将收到阈值本身，这样你就可以在精确度-召回率曲线上选择最适合你应用的最佳工作点，然后找到所需的阈值！
- en: '![Object detection performance testing](img/00091.jpeg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![目标检测性能测试](img/00091.jpeg)'
- en: Precision recall results for a self trained cascade classifier object model
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 自训练级联分类器对象模型的精确度-召回率结果
- en: This output can then be visualized by software packages such as MATLAB ([http://nl.mathworks.com/products/matlab/](http://nl.mathworks.com/products/matlab/))
    or Octave ([http://www.gnu.org/software/octave/](http://www.gnu.org/software/octave/)),
    which have better support for graph generation than OpenCV. The result from the
    preceding file can be seen in the following figure. A MATLAB sample script for
    generating those visualizations is supplied together with the precision recall
    software.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些输出可以通过MATLAB ([http://nl.mathworks.com/products/matlab/](http://nl.mathworks.com/products/matlab/))
    或 Octave ([http://www.gnu.org/software/octave/](http://www.gnu.org/software/octave/))
    等软件包进行可视化，这些软件包比OpenCV有更好的图形生成支持。前一个文件的结果可以在以下图表中看到。附带的MATLAB示例脚本用于生成这些可视化，以及精确度召回率软件。
- en: '![Object detection performance testing](img/00092.jpeg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![目标检测性能测试](img/00092.jpeg)'
- en: Precision recall results on a graph
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度召回率结果图表
- en: Looking at the graph, we see that both precision and recall have a scale of
    [0 1]. The most ideal point in the graph would be the upper-right corner (precision=1/recall=1),
    which would mean that all objects in the image are found and that no false positive
    detections are found. So basically, the closer the slope of your graph goes towards
    the upper right corner, the better your detector will be.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 观察图表，我们可以看到精确度和召回率都有一个[0 1]的尺度。图表中最理想的位置是右上角（精确度=1/召回率=1），这意味着图像中的所有对象都被找到，且没有发现任何误报。所以，基本上，你的图表斜率越接近右上角，你的检测器就越好。
- en: In order to add a value of accuracy to a certain curve of the precision recall
    graph (when comparing models with different parameters), the computer vision research
    community uses the principle of the area under the curve (AUC), expressed in a
    percentage, which can also be seen in the generated graph. Again, getting an AUC
    of 100% would mean that you have developed the ideal object detector.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将准确度值添加到精确度召回率图的某条曲线上（当比较具有不同参数的模型时），计算机视觉研究社区使用曲线下面积（AUC）的原则，用百分比表示，这也可以在生成的图表中看到。再次强调，获得100%的AUC意味着你已经开发出了理想的物体检测器。
- en: Optimizations using GPU code
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用GPU代码进行优化
- en: To be able to reconstruct the experiments done in the discussion about GPU usage,
    you will need to have an NVIDIA GPU, which is compatible with the OpenCV CUDA
    module. Furthermore, you will need to rebuild OpenCV with different configurations
    (which I will highlight later) to get the exact same output.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够重建关于GPU使用的讨论中进行的实验，你需要拥有一块与OpenCV CUDA模块兼容的NVIDIA GPU。此外，你需要使用不同的配置（我将在后面强调）重新构建OpenCV，以获得完全相同的输出。
- en: The tests from my end were done with a Dell Precision T7610 computer containing
    an Intel Xeon(R) CPU that has two processors, each supporting 12 cores and 32
    GB of RAM memory. As GPU interface, I am using an NVIDIA Quadro K2000 with 1 GB
    of dedicated on-board memory.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我端进行的测试是在一台戴尔Precision T7610电脑上进行的，该电脑配备了一颗英特尔Xeon(R) CPU，具有两个处理器，每个处理器支持12个核心和32
    GB的RAM内存。作为GPU接口，我使用了一块配备1 GB独立板载内存的NVIDIA Quadro K2000。
- en: Similar results can be achieved with a non-NVIDIA GPU through OpenCL and the
    newly introduced T-API in OpenCV 3\. However, since this technique is fairly new
    and still not bug free, we will stick to the CUDA interface.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通过OpenCL和OpenCV 3中引入的新T-API，可以使用非NVIDIA GPU获得类似的结果。然而，由于这项技术相对较新且尚未完全无错误，我们将坚持使用CUDA接口。
- en: 'OpenCV 3 contains a GPU implementation of the cascade classifier detection
    system, which can be found under the CUDA module in. This interface could help
    to increase the performance when processing larger images. An example of that
    can be seen in the following figure:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 3 包含了级联分类器检测系统的GPU实现，可以在CUDA模块下找到。这个接口可以帮助处理大图像时提高性能。以下图示就是一个例子：
- en: '![Optimizations using GPU code](img/00093.jpeg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![使用GPU代码进行优化](img/00093.jpeg)'
- en: CPU-GPU comparison without using any CPU optimizations
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 不使用任何CPU优化的CPU-GPU比较
- en: Note
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: These results were obtained by using the software that can be retrieved from
    [https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_5/source_code/CPU_GPU_comparison/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_5/source_code/CPU_GPU_comparison/).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果是通过使用可以从[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_5/source_code/CPU_GPU_comparison/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_5/source_code/CPU_GPU_comparison/)获取的软件获得的。
- en: 'For achieving this result, I built OpenCV without any CPU optimization and
    CUDA support. For this, you will need to disable several CMAKE flags, thus disabling
    the following packages: IPP, TBB, SSE, SSE2, SSE3, SSE4, OPENCL, and PTHREAD.
    In order to avoid any bias from a single image being loaded at a moment that the
    CPU is doing something in the background, I processed the image 10 times in a
    row.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这个结果，我没有对OpenCV进行任何CPU优化和CUDA支持。为此，你需要禁用几个CMAKE标志，从而禁用以下包：IPP、TBB、SSE、SSE2、SSE3、SSE4、OPENCL和PTHREAD。为了避免在CPU在后台执行某些操作时加载单个图像造成的任何偏差，我连续处理了图像10次。
- en: The original input image has a size of 8000x4000 pixels, but after some testing,
    it seemed that the `detectMultiScale` function on GPU would require memory larger
    than the dedicated 1 GB. Therefore, we only run tests starting from having the
    image size as 4000*2000 pixels. It is clear that, when processing images on a
    single core CPU, the GPU interface is way more efficient, even if you take into
    account that at each run, it needs to push data from memory to the GPU and get
    it back. We still get a speedup of about 4-6 times.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 原始输入图像的大小为8000x4000像素，但在一些测试之后，似乎GPU上的`detectMultiScale`函数需要的内存将超过专门的1 GB。因此，我们只从图像大小为4000*2000像素开始进行测试。很明显，当在单个核心CPU上处理图像时，GPU接口的效率要高得多，即使考虑到每次运行都需要将数据从内存推送到GPU并取回。我们仍然可以获得大约4-6倍的速度提升。
- en: 'However, the GPU implementation is not always the best way to go, as we will
    prove by a second test. Let''s start by summing up some reasons why the GPU could
    be a bad idea:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，GPU实现并不总是最佳选择，我们将通过第二次测试来证明这一点。让我们先总结一下为什么GPU可能不是一个好主意的原因：
- en: If your image resolution is small, then it is possible that the time needed
    to initialize the GPU, parse the data towards the GPU, process the data, and grab
    it back to memory will be the bottleneck in your application and will actually
    take longer than simply processing it on the CPU. In this case, it is better to
    use a CPU-based implementation of the detection software.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的图像分辨率较小，那么初始化GPU、解析数据到GPU、处理数据以及将其抓回到内存所需的时间可能会成为你应用程序的瓶颈，实际上可能比在CPU上直接处理所需的时间更长。在这种情况下，最好使用基于CPU的检测软件实现。
- en: The GPU implementation does not provide the ability to return the stage weights
    and thus creating a precision recall curve based on the GPU optimized function
    will be difficult.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU实现不提供返回阶段权重的功能，因此基于GPU优化的函数创建精确度召回率曲线将很困难。
- en: The preceding case was tested with a single core CPU without any optimizations,
    which is actually a bad reference nowadays. OpenCV has been putting huge efforts
    into making their algorithms run efficiently on CPU with tons of optimizations.
    In this case, it is not for granted that a GPU with the data transfer bottleneck
    will still run faster.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前面的案例是在没有任何优化且仅使用单个核心CPU的情况下进行的测试，这在当今实际上是一个糟糕的参考。OpenCV已经投入了大量精力，通过大量优化使他们的算法在CPU上高效运行。在这种情况下，并不能保证具有数据传输瓶颈的GPU仍然会更快地运行。
- en: 'To prove the fact that a GPU implementation can be worse than a CPU implementation,
    we built OpenCV with the following freely available optimization parameters: IPP
    (free compact set provided by OpenCV), TBB, SSE2, SSE3, SSE4 (SSE instructions
    selected automatically by the CMAKE script for my system), pthread (for using
    parallel for loop structures), and of course, with the CUDA interface.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明GPU实现可能比CPU实现更差，我们使用以下免费可用的优化参数构建了OpenCV：IPP（OpenCV提供的免费紧凑型集）、TBB、SSE2、SSE3、SSE4（由CMAKE脚本能动选择为我系统选择的SSE指令）、pthread（用于使用并行for循环结构），当然，还有CUDA接口。
- en: We will then run the same software test again, as shown here.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将再次运行相同的软件测试，如下所示。
- en: '![Optimizations using GPU code](img/00094.jpeg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![使用GPU代码的优化](img/00094.jpeg)'
- en: CPU-GPU comparison with basic CPU optimizations provided by OpenCV 3.0
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 3.0提供的基本CPU优化与CPU-GPU比较
- en: We will clearly see now that using the optimizations on my system yield a better
    result on CPU than on GPU. In this case, one would make a bad decision by only
    looking at the fact that he/she has a GPU available. Basically, this proves that
    you should always pay attention to how you will optimize your algorithm. Of course,
    this result is a bit biased, since a normal computer does not have 24 cores and
    32 GB of RAM memory, but seeing that the performance of personal computers increase
    every day, it will not take long before everyone has access to these kind of setups.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以清楚地看到，在我系统上的优化使用在CPU上比在GPU上产生更好的结果。在这种情况下，如果只看到他/她有GPU可用的事实，那么将做出一个糟糕的决定。基本上，这证明了你应该始终注意你将如何优化你的算法。当然，这个结果有点偏颇，因为普通计算机没有24个核心和32GB的RAM内存，但鉴于个人计算机的性能每天都在提高，不久的将来，每个人都能访问这些类型的设置。
- en: 'I even took it one step further, by taking the original image of 8000*4000
    pixels, which has no memory limits on my system for the CPU due to the 32 GB or
    RAM, and performed the software again on that single size. For the GPU, this meant
    that I had to break down the image into two parts and process those. Again, we
    processed 10 images in a row. The result can be seen in the following image:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我甚至更进一步，通过将原始的8000*4000像素图像，由于系统中的32GB RAM，没有对CPU的内存限制，再次在该单一尺寸上执行软件。对于GPU来说，这意味着我必须将图像分成两部分并处理它们。再次，我们连续处理了10张图像。结果可以在以下图像中看到：
- en: '![Optimizations using GPU code](img/00095.jpeg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![使用GPU代码的优化](img/00095.jpeg)'
- en: Comparison of an 8000x4000 pixel processed on GPU versus multicore CPU
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPU上处理8000x4000像素图像与多核CPU处理的比较
- en: As you can see, there is still a difference of the GPU interface taking about
    four times as long as the CPU interface, and thus in this case, it would be a
    very bad decision to select a GPU solution for the project, rather than a multicore
    CPU solution.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，GPU接口与CPU接口相比，仍然存在差异，GPU接口大约是CPU接口的四倍，因此在这种情况下，选择GPU解决方案而不是多核CPU解决方案将是一个非常糟糕的决定。
- en: Practical applications
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际应用
- en: 'If you are still wondering what the actual industrial applications for this
    object detection software could be, then take a look at the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还在想这种目标检测软件的实际工业应用可能是什么，那么请看以下内容：
- en: '![Practical applications](img/00096.jpeg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![实际应用](img/00096.jpeg)'
- en: Examples of industrial object detection
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 工业目标检测的示例
- en: 'This is a quick overview of the applications that I used this software for
    to get accurate locations of detected objects:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我使用此软件获取检测对象准确位置的应用快速概述：
- en: Dummy test cases containing rotation invariant detection of both cookies and
    candies on a set of different backgrounds.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含在一系列不同背景上旋转不变检测饼干和糖果的模拟测试用例。
- en: Automated detection and counting of microorganisms under a microscope instead
    of counting them yourself.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在显微镜下自动检测和计数微生物，而不是自己计数。
- en: Localization of strawberries for ripeness classification.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鲜草莓的成熟度分类定位。
- en: Localization of road markings in an aerial imagery for automated creation of
    a GIS (Geographic Information System) based on the retrieved data.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在航空影像中对道路标记进行定位，以基于检索数据的自动创建GIS（地理信息系统）。
- en: Rotation invariant detection of peppers (green, yellow, and red combined) on
    a conveyor belt combined with the detection of the stoke for effective robot gripping.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在传送带上对（绿色、黄色和红色混合）辣椒的旋转不变检测，结合对有效机器人抓取的斯托克检测。
- en: Traffic sign detection for ADAS (Automated Driver Assist System) systems.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于ADAS（自动驾驶员辅助系统）系统的交通标志检测。
- en: Orchid detection for automated classification orchid species.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 兰花检测，用于自动分类兰花物种。
- en: Pedestrian detection and tracking in NIR images for security applications.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在近红外图像中进行行人检测和跟踪，用于安全应用。
- en: So, as you can see, the possibilities are endless! Now, try to come up with
    your own application and conquer the world with it.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，正如你所看到的，可能性是无限的！现在，尝试想出你自己的应用，并用它征服世界。
- en: Let's wrap up the chapter with a critical note on object detection using the
    Viola and Jones object categorization framework. As long as your application is
    focusing on detecting one or two object classes, then this approach works fairly
    well. However, once you want to tackle multiclass detection problems, it might
    be good to look for all the other object categorization techniques out there and
    find a more suitable one for your application, since running a ton of cascade
    classifiers on top of a single image will take forever.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以对Viola和Jones目标分类框架进行目标检测的批判性评论来结束本章。只要你的应用专注于检测一个或两个目标类别，那么这种方法相当有效。然而，一旦你想要处理多类别检测问题，可能需要寻找所有其他的目标分类技术，并找到一个更适合你应用的更合适的方法，因为在一个单独的图像上运行大量的级联分类器将花费很长时间。
- en: Note
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Some very promising object categorization frameworks that are in research focus
    at the moment, or that are a solid base for newer techniques, can be found below.
    They might be an interesting starting point for people wanting to go further than
    the OpenCV possibilities.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 目前研究焦点中的一些非常有前景的目标分类框架，或者作为新技术的坚实基础，可以在下面找到。它们可能对于想要超越OpenCV可能性的人来说是一个有趣的起点。
- en: Dollár P., Tu Z., Perona P., and Belongie S (2009, September), Integral Channel
    Features. In BMVC (Vol. 2, No. 3, p. 5)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dollár P., Tu Z., Perona P., 和 Belongie S (2009年9月), 整合通道特征。在BMVC（第2卷第3期，第5页）。
- en: Dollár P., Appel R., Belongie S., and Perona P (2014), Fast feature pyramids
    for object detection. Pattern Analysis and Machine Intelligence, IEEE transactions
    on, 36(8), 1532-1545.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dollár P., Appel R., Belongie S., 和 Perona P (2014), 快速特征金字塔用于目标检测。模式分析与机器智能，IEEE
    交易，36(8), 1532-1545。
- en: Krizhevsky A., Sutskever I., and Hinton G. E (2012), Imagenet classification
    with deep convolutional neural networks. In Advances in neural information processing
    systems (pp. 1097-1105).
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky A., Sutskever I., 和 Hinton G. E (2012), 使用深度卷积神经网络进行ImageNet分类。在神经信息处理系统进展（第1097-1105页）。
- en: Felzenszwalb P. F., Girshick R. B., McAllester D., and Ramanan D (2010), Object
    detection with discriminatively trained part-based models. Pattern Analysis and
    Machine Intelligence, IEEE Transactions on, 32(9), 1627-1645.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Felzenszwalb P. F., Girshick R. B., McAllester D., 和 Ramanan D (2010), 使用判别性训练的基于部分模型进行目标检测。模式分析与机器智能，IEEE
    交易，32(9), 1627-1645。
- en: Summary
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter brought together a wide variety of tips and tricks concerning the
    cascade classifier object detection interface in OpenCV 3 based on the Viola and
    Jones framework for face detection. We went through each step of the object detection
    pipeline and raised attention to points where it can go wrong. This chapter supplied
    you with tools to optimize the result of your cascade classifier for any desired
    object model, while at the same time suggesting optimal parameters to choose from.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 本章汇集了关于基于Viola和Jones框架的OpenCV 3中级联分类器对象检测接口的广泛技巧和窍门。我们走过了对象检测管道的每一步，并关注了可能出错的地方。本章为你提供了优化任何所需目标模型级联分类器结果的工具，同时建议从中选择最佳参数。
- en: Finally, some scene specific examples were used to illustrate that a weaker
    trained object model can also perform well if you use the knowledge of the scene
    to remove false positive detections.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一些特定场景的示例被用来说明，即使使用较弱训练的目标模型，如果你利用场景知识来去除误报检测，也能表现良好。
