<html><head></head><body>
		<div id="_idContainer041">
			<h1 id="_idParaDest-51"><a id="_idTextAnchor050"/>Chapter 3: Feature Store Fundamentals, Terminology, and Usage </h1>
			<p>In the last chapter, we discussed the need to bring features into production and different ways of doing so, along with a look at common issues with these approaches and how feature stores can solve them. We have built up a lot of expectations about feature stores, and it's time to understand how they work. As mentioned in the last chapter, a feature store is different from a traditional database – it is a data storage service for managing machine learning features, a hybrid system that can be used for storage and retrieval of historical features for model training. It can also serve the latest features at low latency for real-time prediction, and at sub-second latency for batch prediction.</p>
			<p>In this chapter, we will discuss what a feature store is, how it works, and the range of terminology used in the feature store world. For this chapter, we will use one of the most widely<a id="_idIndexMarker102"/> used open source feature stores, called <strong class="bold">Feast</strong>. The goal of this chapter is for you to understand the basic usage of Feast feature store terms and APIs along with gaining a brief understanding of how it works internally. </p>
			<p>In this chapter, we will discuss the following topics:</p>
			<ul>
				<li>Introduction to Feast and installation</li>
				<li>Feast terminology and definitions</li>
				<li>Feast initialization</li>
				<li>Feast usage</li>
				<li>Feast behind the scenes</li>
			</ul>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor051"/>Technical requirements</h1>
			<p>To follow the code examples in this chapter, all you need is familiarity with Python and any notebook environment, which could be a local setup such as Jupyter or an online notebook environment such as Google Colab or Kaggle. You can download the code examples for this chapter from the following GitHub link: <a href="https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/Chapter03">https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/Chapter03</a>.</p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor052"/>Introduction to Feast and installation</h1>
			<p><strong class="bold">Feast</strong> is <a id="_idIndexMarker103"/>an open source feature management system for serving and managing ML features. It was a collaboration between <em class="italic">Google</em> and <em class="italic">Gojek</em>, which was then adopted by <em class="italic">Linux Foundation AI and Data</em>. Feast was initially built for <strong class="bold">Google Cloud Platform (GCP)</strong>, then <a id="_idIndexMarker104"/>extended to run on other cloud <a id="_idIndexMarker105"/>platforms like <strong class="bold">Amazon Web Services (AWS)</strong> and <strong class="bold">Microsoft Azure</strong>. Today, you <a id="_idIndexMarker106"/>can run Feast on <strong class="bold">on-premise</strong> infrastructure as well. Cloud agnosticism is the biggest advantage Feast offers over other feature stores. </p>
			<p>However, Feast is a self-managed infrastructure. Depending on your organization structure, you need a team to create and manage the infrastructure for Feast. Another key thing to note here is Feast moved <a id="_idIndexMarker107"/>from <strong class="bold">Service-Oriented Architecture (SOA)</strong> to an <strong class="bold">Software Development Kit (SDK)/Command Line Interface (CLI)</strong> basis. This enables small teams to quickly install, run, and <a id="_idIndexMarker108"/>experiment with Feast for projects without spending a lot of time in its initial setup, only to then realize Feast isn't the right fit. However, for production environments, engineering teams might have to manage multiple infrastructures to run their set of projects. There are alternatives to Feast if you are not a fan of self-managed infrastructures. These include <em class="italic">Tecton</em>, which is one of the main contributors to Feast today, <em class="italic">SageMaker Feature Store</em> which is an AWS-managed feature store, <em class="italic">Databricks Feature Store,</em> and more.</p>
			<p>Now that we briefly know what Feast is, let's look at the installation. Unlike other feature stores that require you to run the service on the cloud or register with a cloud provider, Feast can be installed in a notebook environment without having to set up any additional services. </p>
			<p>The following command<a id="_idIndexMarker109"/> installs the latest version of Feast in your notebook environment:</p>
			<pre class="source-code">!pip install feast</pre>
			<p>Yes, that's all you need to do to install and run Feast if you want to try it out. However, to collaborate with<a id="_idIndexMarker110"/> a team, developer, stage, and production environment, the setup involves some additional steps. We will get there in the next set of chapters. For now, this is enough to look at the APIs, terminology, and project structure. </p>
			<p>In the next section, let's look at Feast terminology, initialization, and a few APIs.</p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/>Feast terminology and definitions</h1>
			<p>New discoveries<a id="_idIndexMarker111"/> in software applications often give birth to new terms or redefine some existing terms in the context of the new software. For example, <strong class="bold">Directed Acyclic Graph (DAG)</strong> in<a id="_idIndexMarker112"/> general means a type of graph; whereas in the context of Airflow (assuming you're familiar with it), it means defining a collection of tasks and their <a id="_idIndexMarker113"/>dependencies. Similarly, Feast and the wider feature store context have a set of terms that are used frequently. Let's learn what they are in this section. </p>
			<p><strong class="bold">Entity</strong>: <em class="italic">An entity is a collection of semantically related features</em>. Entities are domain objects to <a id="_idIndexMarker114"/>which the features can be mapped. In a ride-hailing service, <em class="italic">customer</em> and <em class="italic">driver</em> could be the entities, and features can then be grouped with their corresponding entities. </p>
			<p>The following code block is an example of entity definition:</p>
			<pre class="source-code">driver = Entity(name='driver', value_type=ValueType.STRING,</pre>
			<pre class="source-code">                join_key='driver_id')</pre>
			<p>Entities are part of a feature view, which acts as a primary key in the feature ingestion and retrieval process. <strong class="bold">Point-in-time</strong> joins <a id="_idIndexMarker115"/>and feature lookups can be done on primary keys during model training and prediction, respectively. </p>
			<p><strong class="bold">Feature</strong>: <em class="italic">A feature is individual measurable property</em>. <em class="italic">It is typically a property observed on a specific entity but does not have to be associated with an entity.</em> For instance, the <a id="_idIndexMarker116"/>average time a customer spends on the website could be a feature. A non-associated feature could be the number of new customers on the website today. The following <a id="_idIndexMarker117"/>code block is an example feature definition:</p>
			<pre class="source-code">trips_today = Feature(name="trips_today", </pre>
			<pre class="source-code">                      dtype=ValueType.INT64)</pre>
			<p>Features <a id="_idIndexMarker118"/>represent the columns of the underlying feature data. As you can see in the preceding example, it has <strong class="source-inline">name</strong> and <strong class="source-inline">dtype</strong> properties.</p>
			<p><strong class="bold">Data source</strong>: The data source <a id="_idIndexMarker119"/>represents the underlying data. Feast supports a <a id="_idIndexMarker120"/>range of <a id="_idIndexMarker121"/>data sources<a id="_idIndexMarker122"/> including <strong class="bold">FileSource</strong> (local, S3, GCS), <strong class="bold">BigQuery</strong>, and <strong class="bold">Redshift</strong>.</p>
			<p>The following screenshot is an <a id="_idIndexMarker123"/>example data source:</p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B18024_03_001.jpg" alt="Figure 3.1 – Data source&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.1 – Data source</p>
			<p>As you can see in the preceding figure, the dataset has a <strong class="source-inline">driver_id</strong> entity, <strong class="source-inline">trips_today</strong> and <strong class="source-inline">rating</strong> features, and a <strong class="source-inline">timestamp</strong> column. The structure of the data in the table you see in <em class="italic">Figure 3.1</em> is a <em class="italic">Feature view</em>.</p>
			<p><strong class="bold">Feature view</strong>: A <a id="_idIndexMarker124"/>feature view is like a database table, it represents the structure of the feature data at its source. A feature view consists of entities, one or more features, and the data source. A feature view is generally modeled around a domain object similar to databases objects. There are cases where a feature view can be entity-less. </p>
			<p>The following code block is <a id="_idIndexMarker125"/>an example <strong class="source-inline">FeatureView</strong> definition:</p>
			<pre class="source-code">driver_stats_fv = FeatureView(</pre>
			<pre class="source-code">    name="driver_activity",</pre>
			<pre class="source-code">    entities=["driver"],</pre>
			<pre class="source-code">    ttl=timedelta(hours=2),</pre>
			<pre class="source-code">    features=[</pre>
			<pre class="source-code">        Feature(name="trips_today", dtype=ValueType.INT64),</pre>
			<pre class="source-code">        Feature(name="rating", dtype=ValueType.FLOAT),</pre>
			<pre class="source-code">    ],</pre>
			<pre class="source-code">    batch_source=BigQuerySource(</pre>
			<pre class="source-code">        table_ref="feast-oss.demo_data.driver_activity"</pre>
			<pre class="source-code">    )</pre>
			<pre class="source-code">)</pre>
			<p>As you can see in <a id="_idIndexMarker126"/>the preceding code block, <strong class="source-inline">FeatureView</strong> has a <strong class="source-inline">driver</strong> entity, <strong class="source-inline">trips_today</strong> and <strong class="source-inline">rating</strong> features, and <strong class="source-inline">BigQuerySource</strong> as the data source. Depending on the feature store, Feature view has other synonyms. For instance, in SageMaker Feature Store, it is <a id="_idIndexMarker127"/>called <strong class="bold">Feature Group</strong>, in Databricks Feature Store, it is <a id="_idIndexMarker128"/>called <strong class="bold">Feature Table</strong>, in the older version of Feast, it was <a id="_idIndexMarker129"/>called a <strong class="bold">Feature Set</strong> and <strong class="bold">Feature Table</strong>. </p>
			<p><strong class="bold">Point-in-time joins</strong>: In the <a id="_idIndexMarker130"/>previous chapters, we discussed the need for a data scientist in order to reproduce the state of the system for model reproducibility and for debugging any data/prediction issues. In Feast and other feature stores, the data is <em class="italic">modeled as time-series records</em>. As you can see in <em class="italic">Figure 3.1</em>, the <strong class="source-inline">timestamp</strong> column stores the information of when a particular event occurred (that is, when a particular event was produced in the system). Along with this, feature stores offer flexibility to add additional columns such as <em class="italic">creation time</em>, <em class="italic">ingest API invocation time</em>, and more. This enables data scientists and data engineers to reproduce the state of a system at any time in the past. To reproduce the state in past, the system performs <strong class="bold">point-in-time joins</strong>. In Feast, this capability is available out of the box as an API. In others, users might have to write code for it. </p>
			<p>Let's look at an example of a point-in-time join in practice. The following dataset has a schema that matches the <strong class="source-inline">FeatureView</strong> defined in <em class="italic">Figure 3.1</em>. </p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B18024_03_002.jpg" alt="Figure 3.2 – Point-in-time join dataset&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.2 – Point-in-time join dataset</p>
			<p>As you will see in the<a id="_idIndexMarker131"/> later section, to fetch historical data you need an entity DataFrame like the following:</p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B18024_03_003.jpg" alt="Figure 3.3 – Point-in-time join entity DataFrame&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.3 – Point-in-time join entity DataFrame</p>
			<p>When the user invokes <strong class="source-inline">store.get_historical_features()</strong>, with the entity DataFrame in <em class="italic">Figure 3.3</em> and a feature list, Feast performs a <strong class="bold">point-in-time join</strong> to fetch the latest value of the features at the given timestamp. For instance, for the first row in <em class="italic">Figure 3.3</em>, the timestamp value is <strong class="source-inline">2022-01-01 23:52:20</strong>. The <strong class="bold">point-in-time join</strong> looks for the driver features with the latest timestamp. </p>
			<p>The following screenshot <a id="_idIndexMarker132"/>shows the <strong class="bold">point-in-time join</strong> in action:</p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B18024_03_004.jpg" alt="Figure 3.4 – Point-in-time join&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.4 – Point-in-time join</p>
			<p>The <strong class="bold">time-to-live (ttl)</strong> set<a id="_idIndexMarker133"/> in the <strong class="source-inline">FeatureView</strong> is 2 hours. This indicates that features live only for 2 hours from the<a id="_idIndexMarker134"/> time an event occurs (<strong class="source-inline">event_timestamp + 2 hours</strong> window). The logic for point-in-time joins is <strong class="source-inline">timestamp_in_data &gt;= timestamp_in_entity_dataframe</strong> and <strong class="source-inline">timestamp_in_entity_dataframe &lt;= timestamp_in_data + ttl (2 hours)</strong>. As you can see in <em class="italic">Figure 3.4</em>, the first row doesn't have a matching window in the data, whereas the second, third, and fourth rows of the entity DataFrame have a matching window for the events that occurred at <strong class="source-inline">2022-01-02 1:00:00</strong>, <strong class="source-inline">2022-01-01 4:00:00</strong>, and <strong class="source-inline">2022-01-01 5:00:00</strong> respectively. Following the same logic, the last row in the entity DataFrame doesn't have any matching window in the data.</p>
			<p>The <a id="_idIndexMarker135"/>output DataFrame of the point-in-time join is as follows:</p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B18024_03_005.jpg" alt="Figure 3.5 – Point-in-time join output&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.5 – Point-in-time join output</p>
			<p>As seen in <em class="italic">Figure 3.5</em>, for the rows that don't have matching windows, the feature values are <strong class="source-inline">NULL</strong>, and for the rows with matching windows, the features are available. </p>
			<p>In the next section, let's learn how to initialize a Feast project, what its contents are, and basic API usage. </p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor054"/>Feast initialization</h1>
			<p>Let's open<a id="_idIndexMarker136"/> a new notebook and install a specific version of <strong class="source-inline">feast</strong> and the <strong class="source-inline">Pygments</strong> library to get a more nicely formatted view when we look at the files. The following code installs the required libraries:</p>
			<pre class="source-code">!pip install feast==0.18.1</pre>
			<pre class="source-code">!pip install Pygments</pre>
			<p>Let's initialize the Feast project and look through the folder structure and files. The following code block initializes a Feast project called <strong class="source-inline">demo</strong>:</p>
			<pre class="source-code">!feast init <strong class="bold">demo</strong></pre>
			<p>The preceding code will output the following lines:</p>
			<pre class="source-code">Feast is an open source project that collects anonymized error reporting and usage statistics. To opt out or learn more see https://docs.feast.dev/reference/usage</pre>
			<pre class="source-code">Creating a new Feast repository in /content/demo.</pre>
			<p>Let's ignore the warning message in the first line. In the second line, you can see where the Feast repo is initialized. If you are using Google Colab you will see a similar path, <strong class="source-inline">/content/&lt;repo_name&gt;</strong>; if not, the repo will be created in the current working directory. </p>
			<p>To understand what the <strong class="source-inline">feast init</strong> command did in the background, we need to look through the folder that the command created. You can use the left navigation bar on Google Colab to look through the files or use the CLI:</p>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B18024_03_006.jpg" alt="Figure 3.6 – Folder structure&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.6 – Folder structure</p>
			<p><em class="italic">Figure 3.6</em> is the snapshot from Google Colab. As you can see, the <strong class="source-inline">feast init</strong> command created a sample <a id="_idIndexMarker137"/>project repo for starters. There is a <strong class="source-inline">driver_stats.parquet</strong> file in the <strong class="source-inline">data</strong> folder, and a <strong class="source-inline">example.py</strong>, and <strong class="source-inline">feature_store.yaml</strong> file. Let's go through the files and see what's in them. The simplest file to understand is the <strong class="source-inline">driver_stats.parquet</strong> file in the <strong class="source-inline">data</strong> folder. As the folder says, it contains sample data for the demo project. </p>
			<p>The following code block loads the dataset in <strong class="source-inline">driver_stats.parquet</strong> and displays the first ten rows from it:</p>
			<pre class="source-code">import pandas as pd</pre>
			<pre class="source-code">df = pd.read_parquet("demo/data/driver_stats.parquet")</pre>
			<pre class="source-code">df.head(10)</pre>
			<p>The preceding code block produces the following output:</p>
			<div>
				<div id="_idContainer035" class="IMG---Figure">
					<img src="image/B18024_03_007.jpg" alt="Figure 3.7 – Sample dataset&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.7 – Sample dataset</p>
			<p>The <strong class="source-inline">driver_stats.parquet</strong> file is a sample feature dataset, as you can see in <em class="italic">Figure 3.7</em>. It contains driver features such as <strong class="source-inline">conv_rate</strong> and <strong class="source-inline">avg_daily_trips</strong>. It also has additional <a id="_idIndexMarker138"/>columns, such as <strong class="source-inline">event_timestamp</strong> and <strong class="source-inline">created</strong>. These are special columns used for performing point-in-time joins, as discussed in the previous section.</p>
			<p>Let's look at the <strong class="source-inline">feature_store.yaml</strong> file next. The following command prints the file content:</p>
			<pre class="source-code">!pygmentize demo/feature_store.yaml</pre>
			<p>The preceding command outputs the following:</p>
			<pre class="source-code">project: demo</pre>
			<pre class="source-code">registry: data/registry.db</pre>
			<pre class="source-code">provider: local</pre>
			<pre class="source-code">online_store:</pre>
			<pre class="source-code">    path: data/online_store.db</pre>
			<p>The <strong class="source-inline">feature_store.yaml</strong> file contains the following variables:</p>
			<ul>
				<li><strong class="source-inline">project</strong>: This is<a id="_idIndexMarker139"/> the project name. It uses the input of the <strong class="source-inline">feast init</strong> command as the project name. We ran <strong class="source-inline">feast init demo</strong>, hence the project name is <strong class="source-inline">demo</strong>.</li>
				<li><strong class="source-inline">registry</strong>: This<a id="_idIndexMarker140"/> variable stores the feature registry path for the project. The registry stores all the metadata for the project including <strong class="source-inline">FeatureView</strong>, <strong class="source-inline">Entity</strong>, <strong class="source-inline">DataSources</strong>, and more. As you can see, the <strong class="source-inline">registry.db</strong> file doesn't yet exist in the <strong class="source-inline">data</strong> folder. It gets created when we run the <strong class="source-inline">apply</strong> command; we will look at it in the <em class="italic">Feast usage</em> section.</li>
				<li><strong class="source-inline">provider</strong>: This <a id="_idIndexMarker141"/>variable defines where the feature store is going to run. The value is set to <strong class="source-inline">local</strong>, which indicates the infrastructure will be run on the local system. The other possible values are <strong class="source-inline">aws</strong>, <strong class="source-inline">gcp</strong>, and more. For <strong class="source-inline">aws</strong> and <strong class="source-inline">gcp</strong> providers, additional dependencies need to be installed and additional params need to be passed to the <strong class="source-inline">feast init</strong> command.  </li>
				<li><strong class="source-inline">online_store</strong>: As the <a id="_idIndexMarker142"/>name of the <strong class="source-inline">online_store</strong> param indicates, it is used for storing and serving features at low latency. By default, it uses SQLite, but Feast offers a variety of options for the online store, from <em class="italic">DynamoDB</em> to a <em class="italic">custom store</em>. The following page lists the supported options for online stores: <a href="https://docs.feast.dev/roadmap">https://docs.feast.dev/roadmap</a>.</li>
				<li><strong class="source-inline">offline_store</strong>: You <a id="_idIndexMarker143"/>don't see this variable in the <strong class="source-inline">feature_store.yaml</strong> file. However, this is another important parameter that is used to set <em class="italic">historical stores</em> from the available options. Again, Feast offers a lot of flexibility here: you can choose anything from <em class="italic">file store</em> to <em class="italic">Snowflake</em>. The link in the preceding bullet has the information on supported offline stores.  </li>
			</ul>
			<p>Other than the ones <a id="_idIndexMarker144"/>mentioned previously, each of the variables might include some additional setup based on what is chosen for that option. For example, if Snowflake is chosen as the offline store, it needs additional inputs like the schema name, table name, Snowflake URL, and more. </p>
			<p>Let's look at what the <strong class="source-inline">example.py</strong> file consists of. The following command prints the contents of the file:</p>
			<pre class="source-code">!pygmentize -f terminal16m demo/example.py</pre>
			<p>The output of the preceding command is very lengthy, so instead of looking at all the content at once, we'll break<a id="_idIndexMarker145"/> it down into parts. The following code block contains the first part of the file:</p>
			<pre class="source-code"># This is an example feature definition file</pre>
			<pre class="source-code">from google.protobuf.duration_pb2 import Duration</pre>
			<pre class="source-code">from feast import Entity, Feature, FeatureView, FileSource, ValueType</pre>
			<pre class="source-code">""" Read data from parquet files. Parquet is convenient for local development mode. For production, you can use your favorite DWH, such as BigQuery. See Feast documentation for more info."""</pre>
			<pre class="source-code">Driver_hourly_stats = FileSource(</pre>
			<pre class="source-code">    path="/content/demo/data/driver_stats.parquet",</pre>
			<pre class="source-code">    event_timestamp_column="event_timestamp",</pre>
			<pre class="source-code">    created_timestamp_column="created",</pre>
			<pre class="source-code">)</pre>
			<p>In the preceding block, there are a couple of imports from the installed libraries, but what follows the imports is of particular interest to us. The code defines a data source of type <strong class="source-inline">FileSource</strong> and provides the path to the sample data in <em class="italic">Figure 3.7</em>. As mentioned earlier, the <strong class="source-inline">event_timestamp_column</strong> and <strong class="source-inline">created_timestamp_column</strong> columns are special columns, which indicate when a particular event (row in the data) occurred and when the row was ingested into the data source, respectively. </p>
			<p>The following code block contains the second part of the file:</p>
			<pre class="source-code"># Define an entity for the driver. You can think of entity as a primary key used to fetch features.</pre>
			<pre class="source-code">Driver = Entity(name="driver_id", </pre>
			<pre class="source-code">                value_type=ValueType.INT64, </pre>
			<pre class="source-code">                description="driver id",)</pre>
			<p>In the preceding<a id="_idIndexMarker146"/> code block, a <strong class="source-inline">driver_id</strong> entity is defined along with its value type and description.</p>
			<p>The following code block contains the last part of the file:</p>
			<pre class="source-code">""" Our parquet files contain sample data that includes a driver_id column, timestamps and three feature column. Here we define a Feature View that will allow us to serve this data to our model online."""</pre>
			<pre class="source-code">Driver_hourly_stats_view = FeatureView(</pre>
			<pre class="source-code">    name="driver_hourly_stats",</pre>
			<pre class="source-code">    entities=["driver_id"],</pre>
			<pre class="source-code">    ttl=Duration(seconds=86400 * 1),</pre>
			<pre class="source-code">    features=[</pre>
			<pre class="source-code">        Feature(name="conv_rate", dtype=ValueType.FLOAT),</pre>
			<pre class="source-code">        Feature(name="acc_rate", dtype=ValueType.FLOAT),</pre>
			<pre class="source-code">        Feature(name="avg_daily_trips", </pre>
			<pre class="source-code">                dtype=ValueType.INT64),</pre>
			<pre class="source-code">    ],</pre>
			<pre class="source-code">    online=True,</pre>
			<pre class="source-code">    batch_source=driver_hourly_stats,</pre>
			<pre class="source-code">    tags={},</pre>
			<pre class="source-code">)</pre>
			<p>The preceding block contains a <strong class="source-inline">FeatureView</strong>. The definition contains three features, <strong class="source-inline">conv_rate</strong>, <strong class="source-inline">acc_rate</strong>, and <strong class="source-inline">avg_daily_trips</strong>, and uses the <strong class="source-inline">driver_id</strong> entity defined in the second part of the file and the <strong class="source-inline">driver_hourly_stats</strong> batch source defined in the first part of the file. Apart from these, there are additional variables: <strong class="source-inline">ttl</strong>, <strong class="source-inline">online</strong>, and <strong class="source-inline">tags</strong>.  <strong class="source-inline">ttl</strong> defines how long the features live. For instance, if you set <strong class="source-inline">ttl</strong> to 60 seconds, it will appear in the retrieval for only 60 seconds from the event time. After that, it is considered as an expired feature. The <strong class="source-inline">online</strong> variable indicates if the online store is<a id="_idIndexMarker147"/> enabled for <strong class="source-inline">FeatureView</strong> or not. <strong class="source-inline">Tags</strong> are used to store additional information about <strong class="source-inline">FeatureView</strong> such as the team, owner, and more, which may be usable in feature discovery. </p>
			<p>In short, the <strong class="source-inline">example.py</strong> file consists of the entities, feature views, and data sources of the <strong class="source-inline">demo</strong> project. This is just a starter template for a demo. We can add additional entities, feature views, and data sources.</p>
			<p>Now that we understand the fundamentals and basic project structure, let's familiarize ourselves with Feast APIs.</p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor055"/>Feast usage</h1>
			<p>In this section, let's <a id="_idIndexMarker148"/>continue in the same notebook in which we initialized the <strong class="source-inline">demo</strong> project previously, register the feature view and entities, and use the Feast API to retrieve features.</p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor056"/>Register feature definitions</h2>
			<p>The<a id="_idIndexMarker149"/> following code block registers all the entities and feature views defined in the <strong class="source-inline">example.py</strong> file:</p>
			<pre class="source-code">%cd demo</pre>
			<pre class="source-code">!feast apply</pre>
			<p>The preceding code produces the following output:</p>
			<pre class="source-code">/content/demo</pre>
			<pre class="source-code">Created entity <strong class="bold">driver_id</strong></pre>
			<pre class="source-code">Created feature view <strong class="bold">driver_hourly_stats</strong></pre>
			<pre class="source-code">Created sqlite table <strong class="bold">demo_driver_hourly_stats</strong></pre>
			<p>The <a id="_idIndexMarker150"/>output message is straightforward except the last line, where it says <strong class="bold">Created sqlite table demo_driver_hourly_stats</strong>. This comes up if you have <strong class="source-inline">online=True</strong> set in the <strong class="source-inline">FeatureView</strong>. The <strong class="source-inline">apply</strong> command creates the <strong class="source-inline">registry.db</strong> and <strong class="source-inline">online_store.db</strong> files, which have been set in <strong class="source-inline">feature_store.yaml</strong>. </p>
			<p>Now that entities and feature views have been registered, we can connect to the feature store and browse through the existing definitions. </p>
			<h2 id="_idParaDest-58"><a id="_idTextAnchor057"/>Browsing the feature store</h2>
			<p>The following <a id="_idIndexMarker151"/>code connects to the feature store and lists all the entities:</p>
			<pre class="source-code">from feast import FeatureStore</pre>
			<pre class="source-code">store = FeatureStore(repo_path=".")</pre>
			<pre class="source-code">for entity in store.list_entities():</pre>
			<pre class="source-code">    print(entity.to_dict())</pre>
			<p>The preceding code block looks for the <strong class="source-inline">feature_store.yaml</strong> file in the current directory and uses the <strong class="source-inline">store.list_entities()</strong> API to get all the entities. Similarly, the <strong class="source-inline">store.list_feature_views()</strong> API can be used to get all the available feature views. I will leave that as an exercise for you.</p>
			<p>Let's add a new entity and feature view to the feature store.</p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor058"/>Adding an entity and FeatureView</h2>
			<p>To add a new<a id="_idIndexMarker152"/> entity<a id="_idIndexMarker153"/> and feature view, we need a feature dataset. For now, let's produce a synthetic dataset using the <strong class="source-inline">numpy</strong> library and use that as the new features for which the entity and feature view need to be defined.</p>
			<p>The following <a id="_idIndexMarker154"/>code <a id="_idIndexMarker155"/>generates the synthetic feature data:</p>
			<pre class="source-code">import pandas as pd</pre>
			<pre class="source-code">import numpy as np</pre>
			<pre class="source-code">from pytz import timezone, utc</pre>
			<pre class="source-code">from datetime import datetime, timedelta</pre>
			<pre class="source-code">import random</pre>
			<pre class="source-code">days = [datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0).replace(tzinfo=utc) \</pre>
			<pre class="source-code">        - timedelta(day) for day in range(10)][::-1]</pre>
			<pre class="source-code">customers = [1001, 1002, 1003, 1004, 1005]</pre>
			<pre class="source-code">customer_features = pd.DataFrame(</pre>
			<pre class="source-code">    {</pre>
			<pre class="source-code">        "datetime": [day for day in days for customer in customers], # Datetime is required</pre>
			<pre class="source-code">        "customer_id": [customer for day in days for customer in customers], # Customer is the entity</pre>
			<pre class="source-code">        "daily_transactions": [np.random.rand() * 10 for _ in range(len(days) * len(customers))], # Feature 1</pre>
			<pre class="source-code">        "total_transactions": [np.random.randint(100) for _ in range(len(days) * len(customers))], # Feature 2</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">)</pre>
			<pre class="source-code"><strong class="bold">customer_features.to_parquet("/content/demo/data/customer_features.parquet")</strong></pre>
			<pre class="source-code">customer_features.head(5)</pre>
			<p>The preceding code generates a dataset with four columns and writes the dataset to <strong class="source-inline">/content/demo/data/</strong>. If you are running this on a local system, set the path accordingly for the <strong class="source-inline">customer_features.to_parquet</strong> API call, which is highlighted in the preceding code block.</p>
			<p>The preceding code <a id="_idIndexMarker156"/>produces <a id="_idIndexMarker157"/>the dataset as shown in <em class="italic">Figure 3.8</em>:</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="image/B18024_03_008.jpg" alt="Figure 3.8 – Synthetic customer data&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.8 – Synthetic customer data</p>
			<p>The definitions of <strong class="source-inline">Entity</strong> and <strong class="source-inline">FeatureView</strong> for the dataset in <em class="italic">Figure 3.4</em> can be added to the existing <strong class="source-inline">example.py</strong> file, or you can create a new Python file and add the lines in the following code block.</p>
			<p>The following code block defines the required <strong class="source-inline">Entity</strong>, <strong class="source-inline">DataSource</strong>, and <strong class="source-inline">FeatureView</strong> for the dataset in <em class="italic">Figure 3.8</em>:</p>
			<pre class="source-code">from google.protobuf.duration_pb2 import Duration</pre>
			<pre class="source-code">from feast import Entity, Feature, FeatureView, FileSource, ValueType</pre>
			<pre class="source-code">#Customer data source</pre>
			<pre class="source-code">customer_features = FileSource(</pre>
			<pre class="source-code">    path="/content/demo/data/customer_features.parquet",</pre>
			<pre class="source-code">    event_timestamp_column="datetime"</pre>
			<pre class="source-code">)</pre>
			<pre class="source-code">#Customer Entity</pre>
			<pre class="source-code">customer = Entity(name="customer_id", </pre>
			<pre class="source-code">                  value_type=ValueType.INT64, </pre>
			<pre class="source-code">                  description="customer id",)</pre>
			<pre class="source-code"># Customer Feature view</pre>
			<pre class="source-code">customer_features_view = FeatureView(</pre>
			<pre class="source-code">    name="customer_features",</pre>
			<pre class="source-code">    entities=["customer_id"],</pre>
			<pre class="source-code">    ttl=Duration(seconds=86400 * 1),</pre>
			<pre class="source-code">    features=[</pre>
			<pre class="source-code">        Feature(name="daily_transactions",</pre>
			<pre class="source-code">                dtype=ValueType.FLOAT),</pre>
			<pre class="source-code">        Feature(name="total_transactions", </pre>
			<pre class="source-code">                dtype=ValueType.INT64),</pre>
			<pre class="source-code">    ],</pre>
			<pre class="source-code">    online=True,</pre>
			<pre class="source-code">    batch_source=customer_features,</pre>
			<pre class="source-code">    tags={},</pre>
			<pre class="source-code">)</pre>
			<p>Like the <strong class="source-inline">example.py</strong> file we <a id="_idIndexMarker158"/>encountered, this file has the definition <a id="_idIndexMarker159"/>for the <strong class="source-inline">customer_features</strong> data source, the <strong class="source-inline">customer</strong> entity, and <strong class="source-inline">customer_features_view</strong>. Upload the newly created file or updated  <strong class="source-inline">example.py</strong> file to the project root directory (the same directory as that of the existing <strong class="source-inline">example.py</strong> file). </p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Don't remove <strong class="source-inline">example.py</strong> or replace the contents, but append new entities to the file or upload the new file. After running <strong class="source-inline">feast apply</strong>, you should have two entities, <strong class="source-inline">driver_id</strong> and <strong class="source-inline">customer_id</strong>, and two feature views, <strong class="source-inline">driver_hourly_stats</strong> and <strong class="source-inline">customer_features</strong>.</p>
			<p>After <a id="_idIndexMarker160"/>uploading/copying <a id="_idIndexMarker161"/>the file to the root directory, run the following command to apply new definitions:</p>
			<pre class="source-code">!feast apply</pre>
			<p>The preceding code block produces the following output:</p>
			<pre class="source-code">Created entity <strong class="bold">customer_id</strong></pre>
			<pre class="source-code">Created feature view <strong class="bold">customer_features</strong></pre>
			<pre class="source-code">Created sqlite table <strong class="bold">demo_customer_features</strong></pre>
			<p>Similar to the output of the previous <strong class="source-inline">apply</strong> command, the output is straightforward. If you browse through the feature store again, you will see the updated definitions. We will leave that as an exercise for you.</p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor059"/>Generate training data</h2>
			<p>After <a id="_idIndexMarker162"/>running the <strong class="source-inline">apply</strong> command in the previous section, the feature store contains two entities: <strong class="source-inline">driver_id</strong> and <strong class="source-inline">customer_id</strong>, and two feature views: <strong class="source-inline">driver_hourly_stats</strong> and <strong class="source-inline">customer_features</strong>. We can generate training data by querying the historical store for either or both of the feature views using the corresponding entities. In this example, we will query for the <strong class="source-inline">driver_hourly_stats</strong> feature view. Feel free to try out the <strong class="source-inline">get_historical_features</strong> API on <strong class="source-inline">customer_features</strong>. </p>
			<p>To generate the training data, an entity DataFrame is required. The entity DataFrame must <a id="_idIndexMarker163"/>have the following two columns:</p>
			<ul>
				<li><strong class="source-inline">entity_id</strong>: This <a id="_idIndexMarker164"/>is the id of the entity defined in the feature store. For instance, to fetch the driver features, you need the <strong class="source-inline">driver_id</strong> column and the list of values for which the historical features are required.</li>
				<li><strong class="source-inline">event_timestamp</strong>: A<a id="_idIndexMarker165"/> timestamp for each <strong class="source-inline">driver_id</strong> for the point-in-time join.</li>
			</ul>
			<p>The following <a id="_idIndexMarker166"/>code block produces an entity DataFrame to fetch driver features:</p>
			<pre class="source-code">from datetime import datetime, timedelta</pre>
			<pre class="source-code">import pandas as pd</pre>
			<pre class="source-code">from feast import FeatureStore</pre>
			<pre class="source-code"># The entity DataFrame is the DataFrame we want to enrich with feature values</pre>
			<pre class="source-code">entity_df = pd.DataFrame.from_dict(</pre>
			<pre class="source-code">    {</pre>
			<pre class="source-code">        "driver_id": [1001, 1002, 1003],</pre>
			<pre class="source-code">        "event_timestamp": [</pre>
			<pre class="source-code">            datetime.now() – timedelta(minutes=11),</pre>
			<pre class="source-code">            datetime.now() – timedelta(minutes=36),</pre>
			<pre class="source-code">            datetime.now() – timedelta(minutes=73),</pre>
			<pre class="source-code">        ],</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">)</pre>
			<pre class="source-code">entity_df.head()</pre>
			<p>The preceding code produces the following entity DataFrame:</p>
			<div>
				<div id="_idContainer037" class="IMG---Figure">
					<img src="image/B18024_03_009.jpg" alt="Figure 3.9 – Entity DataFrame&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.9 – Entity DataFrame</p>
			<p>Once you have <a id="_idIndexMarker167"/>the entity DataFrame, it is straightforward to fetch the data from the historical store. All that is required to do is connect to feature store and invoke the <strong class="source-inline">store.get_historical_features()</strong> API with the entity DataFrame created in the preceding code block and the list of required features. </p>
			<p>The following code block connects to the feature store and fetches historical features for the entities:</p>
			<pre class="source-code">store = FeatureStore(repo_path=".")</pre>
			<pre class="source-code">training_df = store.get_historical_features(</pre>
			<pre class="source-code">    entity_df=entity_df,</pre>
			<pre class="source-code">    features=[</pre>
			<pre class="source-code">        "driver_hourly_stats:conv_rate",</pre>
			<pre class="source-code">        "driver_hourly_stats:acc_rate",</pre>
			<pre class="source-code">        "driver_hourly_stats:avg_daily_trips",</pre>
			<pre class="source-code">    ],</pre>
			<pre class="source-code">).to_df()</pre>
			<pre class="source-code">training_df.head()</pre>
			<p>You may notice that one of the inputs to the API is a list of features. The format of the elements in the list is <strong class="source-inline">&lt;FeatureViewName&gt;:&lt;FeatureName&gt;</strong>. For instance, to fetch the <strong class="source-inline">conv_rate</strong> feature, which is part of the <strong class="source-inline">driver_hourly_stats </strong>FeatureView, the element in the list would be <strong class="source-inline">driver_hourly_stats:conv_rate</strong>.</p>
			<p>The preceding <a id="_idIndexMarker168"/>code block produces the following output:</p>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="image/B18024_03_010.jpg" alt="Figure 3.10 – Get the historical features output&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.10 – Get the historical features output</p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor060"/>Load features to the online store</h2>
			<p>The <a id="_idIndexMarker169"/>historical data source is used for generating a training dataset, which can also be used for prediction in batch models. However, we already know that for online models, low-latency feature serving is required. To enable that, it is required to fetch the latest features from the historical data source and load the features into the online store. This can be done with a single command in Feast.</p>
			<p>The following command loads the latest features to the online store:</p>
			<pre class="source-code">!feast materialize-incremental {datetime.now().isoformat()}</pre>
			<p>The command takes a timestamp as one of the inputs, fetches the latest features at the time of the input timestamp, and loads the features to the online store. In this example, it is a SQLite database. </p>
			<p>The preceding line of code outputs the following information:</p>
			<div>
				<div id="_idContainer039" class="IMG---Figure">
					<img src="image/B18024_03_011.jpg" alt="Figure 3.11 – Feast materializing the output&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.11 – Feast materializing the output</p>
			<p>Now that the features are available in the online store, they can be fetched during model prediction at low latency. The online store can be queried using <strong class="source-inline">store.get_online_features()</strong> and passing the features list in the same format as that of the<a id="_idIndexMarker170"/> list passed for querying historical data.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">The <strong class="source-inline">feast materialize-incremental</strong> command will sync all the existing feature views to the online store (in this case, SQLite). In the output shown in <em class="italic">Figure 3.11</em>, you can see two feature views: <strong class="source-inline">driver_hourly_stats</strong> and <strong class="source-inline">customer_features</strong>. You can query either of them. In this example, we are querying <strong class="source-inline">driver_hourly_stats</strong>. </p>
			<p>The following code block fetches <strong class="source-inline">conv_rate</strong> and <strong class="source-inline">avg_daily_trips</strong> for drivers with <strong class="source-inline">id</strong> values of <strong class="source-inline">1001</strong> and <strong class="source-inline">1004</strong>:</p>
			<pre class="source-code">store = FeatureStore(repo_path=".")</pre>
			<pre class="source-code">feature_vector = store.get_online_features(</pre>
			<pre class="source-code">    features=[</pre>
			<pre class="source-code">        "driver_hourly_stats:conv_rate",</pre>
			<pre class="source-code">        "driver_hourly_stats:avg_daily_trips",</pre>
			<pre class="source-code">    ],</pre>
			<pre class="source-code">    entity_rows=[</pre>
			<pre class="source-code">        {"driver_id": 1004},</pre>
			<pre class="source-code">        {"driver_id": 1005},</pre>
			<pre class="source-code">    ],</pre>
			<pre class="source-code">).to_dict()</pre>
			<pre class="source-code">feature_vector</pre>
			<p>The preceding code block produces the following output. If the value for a specific entity row doesn't exist, it will return <strong class="source-inline">NULL</strong> values:</p>
			<pre class="source-code">{'avg_daily_trips': [34, 256],</pre>
			<pre class="source-code"> 'conv_rate': [0.9326972365379333, 0.07134518772363663],</pre>
			<pre class="source-code"> 'driver_id': [1004, 1005]}</pre>
			<p>Now that we <a id="_idIndexMarker171"/>have learned the Feast fundamentals, it is time to understand briefly what's going on behind the scenes to make it work. In the next section, let's look at the Feast components and set the stage for incorporating Feast in a project.</p>
			<h1 id="_idParaDest-62"><a id="_idTextAnchor061"/>Feast behind the scenes</h1>
			<p>The following diagram <a id="_idIndexMarker172"/>shows different components that make up the architecture of Feast:</p>
			<div>
				<div id="_idContainer040" class="IMG---Figure">
					<img src="image/B18024_03_012.jpg" alt="Figure 3.12 – Feast architecture (v0.18)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.12 – Feast architecture (v0.18)</p>
			<p>As seen in the preceding diagram, there are a lot of components involved in Feast. Let's break it down one by one: </p>
			<ul>
				<li><strong class="bold">Feature Repo</strong>: A <a id="_idIndexMarker173"/>feature repository is a set of configuration files defining the infrastructure and feature definitions. In the demo project, <em class="italic">Figure 3.6</em> shows an example feature repo. The <strong class="source-inline">data</strong> folder is optional; the <strong class="source-inline">feature_store.yml</strong> file that defines the feature store configuration and the <strong class="source-inline">example.py</strong> file that defines the feature definitions constitute a feature repo.</li>
				<li><strong class="bold">Feast SDK</strong>: The Feast SDK <a id="_idIndexMarker174"/>is the development kit with which users can interact with Feast. It is used for creating and updating feature definitions (<strong class="source-inline">feast apply</strong>), loading features from the offline to the online store (<strong class="source-inline">feast materialize</strong>), and providing a great set of APIs for users to browse through Feast and query online and offline stores. We used some of the Feast SDK APIs in the usage section.</li>
				<li><strong class="bold">Feast Registry</strong>: The Feast registry<a id="_idIndexMarker175"/> uses the object store to persist the feature definitions, which can be browsed through using the Feast SDK. </li>
				<li><strong class="bold">Online store</strong>: The<a id="_idIndexMarker176"/> online store is a low-latency database used for serving the latest features for model prediction. Users can load the latest features or query the online store using the Feast SDK. A streaming source can also be used for loading features into the online store.</li>
				<li><strong class="bold">Offline store</strong>: The<a id="_idIndexMarker177"/> offline store is used for the storage and retrieval of historical data. It is also used for model training and batch scoring. In Feast, data in the offline store is user-managed.</li>
			</ul>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor062"/>Data flow in Feast</h2>
			<p>The following steps <a id="_idIndexMarker178"/>give an <a id="_idIndexMarker179"/>example of the data flow in Feast:</p>
			<ol>
				<li>Data engineers build ETL/data pipelines to generate features and load them to an offline store supported by Feast.</li>
				<li>Feature definitions are created, the Feast store configuration is defined, and the <strong class="source-inline">feast apply</strong> command is run. <p class="callout-heading">Important Note </p><p class="callout">Feature store configuration involves defining the infrastructure details, hence it might also involve the creation of the infrastructure as well.</p></li>
				<li>Using the Feast SDK, the data scientist/data engineer connects to the Feast repo and generates training data for the model. The model is trained, and if it doesn't meet the acceptance criteria, new features may be generated by adding an additional data pipeline. </li>
				<li>Steps <em class="italic">1-3</em> will be executed again. <p class="callout-heading">Important Note </p><p class="callout">In <em class="italic">step 2</em>, only new entities and feature definitions need to be added. </p></li>
				<li>Features <a id="_idIndexMarker180"/>are loaded from the offline to the online store using<a id="_idIndexMarker181"/> the <strong class="source-inline">feast materialize</strong> command. This command may be run on schedule to load the latest features using an orchestration tool such <a id="_idIndexMarker182"/>as <strong class="bold">Airflow</strong>. </li>
				<li>The trained model is packaged along with the Feast SDK code to fetch the required feature for model scoring during prediction. The packaged model is deployed to production.</li>
				<li>During prediction, the model fetches the required features using the Feast SDK, runs the prediction, and returns the results.</li>
				<li>The offline store can be monitored for data drift to determine whether it's time to retrain the model.</li>
			</ol>
			<p>Let's summarize what we learned in this chapter next and move on to using Feast in our actual project next.</p>
			<h1 id="_idParaDest-64"><a id="_idTextAnchor063"/>Summary</h1>
			<p>In this chapter, we discussed the terminology used in the feature store world, specifically terminology that relate to <em class="italic">Feast</em>. However, keep in mind that many of the existing feature stores use similar terminology, so if you are familiar with one, it is easy to understand the others. We also discussed how the <em class="italic">point-in-time join</em> works in Feast, along with the Feast fundamentals such as installation, initialization, project structure, and API usage. Finally, we explored the components of Feast and how the operationalization of a model works with Feast. </p>
			<p>In the next chapter, we'll use Feast in the model we built in <a href="B18024_01_ePub.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>,<em class="italic"> An Overview of the Machine Learning Life Cycle</em>, learn how it changes the way data scientists and engineers work, and see how it opens the door to new opportunities in feature sharing, monitoring, and easy productionization of our ML models. </p>
			<h1 id="_idParaDest-65"><a id="_idTextAnchor064"/>Further reading</h1>
			<ul>
				<li><em class="italic">Introduction to Feast</em>: <a href="https://docs.feast.dev/">https://docs.feast.dev/</a></li>
				<li><em class="italic">Overview of Feast</em>: <a href="https://github.com/feast-dev/feast/blob/v0.18.1/examples/quickstart/quickstart.ipynb">https://github.com/feast-dev/feast/blob/v0.18.1/examples/quickstart/quickstart.ipynb</a></li>
			</ul>
		</div>
	</body></html>