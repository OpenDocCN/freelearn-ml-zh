["```py\n    import json\n    import numpy as np\n    import os\n    import pickle\n    import joblib\n    import onnxruntime\n    import logging\n    import time\n    from azureml.core.model import Model\n    from applicationinsights import TelemetryClient\n    from azureml.monitoring import ModelDataCollector\n    from inference_schema.schema_decorators import input_schema, output_schema\n    from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n    ```", "```py\n    def init():\n        global model, scaler, input_name, label_name, inputs_dc, prediction_dc, tc\n            init function to monitor whether a FileNotFound error occurs when we load the scaler and model artifacts. If a file is not found, the tc.track_events() function will log the error message that's generated by the exception and tag the custom code 101. \n    ```", "```py\n    @input_schema('data', NumpyParameterType(np.array([[34.927778, 0.24, 7.3899, 83, 16.1000, 1016.51, 1]])))\n    @output_schema(NumpyParameterType(np.array([0])))\n    def run(data):\n                try:              \n                    inputs_dc.collect(data)\n                except Exception as e:\n                    try and except to collect incoming data using the model data collector function. This collects the incoming data and stores it in the blob storage connected to the Azure ML service. If the incoming data contains some anomalous data or a missing value, an exception is raised. We will raise a ValueNotFound error using the track_event function so that we can log the exception message and custom code (in this case, a random or custom number of 201 is given to track the error). After collecting the incoming data, we will attempt to scale the data before inference:\n\n    ```", "```py\n                try:        \n                    # model inference\n                    result = model.run([label_name], {input_name: \n    data.astype(np.float32)})[2]\n    # this call is saving model output data into Azure Blob\n                    prediction_dc.collect(result)\n                    if result == 0:\n                        output = \"Rain\"                 \n                    else: \n                        output = \"No Rain\"\n                    return output\n                except Exception as e:\n    track_event() function to generate a custom event called InferenceError. This will be logged on Application Insights with an error message and a custom error code of 401. This way, we can log custom errors and exceptions on Application Insights and generate actions based on these errors and exceptions. \n    ```", "```py\n\n    ```", "```py\n    python3 test_inference.py\n    ```"]