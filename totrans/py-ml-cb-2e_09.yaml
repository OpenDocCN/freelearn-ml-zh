- en: Dissecting Time Series and Sequential Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Transforming data into a time series format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slicing time series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating on time series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting statistics from time series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building HMMs for sequential data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building CRFs for sequential text data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing stock market data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using RNNs to predict time series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To address the recipes in this chapter, you need the following files (available
    on GitHub):'
  prefs: []
  type: TYPE_NORMAL
- en: '`convert_to_timeseries.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data_timeseries.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`slicing_data.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`operating_on_data.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`extract_stats.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hmm.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`` `data_hmm.txt` ``'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crf.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AmazonStock.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AMZN.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LSTMstock.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing time series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time series data is basically a sequence of measurements that are collected
    over time. These measurements are taken with respect to a predetermined variable
    and at regular time intervals. One of the main characteristics of time series
    data is that the ordering matters!
  prefs: []
  type: TYPE_NORMAL
- en: The list of observations that we collect is ordered on a timeline, and the order
    in which they appear says a lot about underlying patterns. If you change the order,
    this would totally change the meaning of the data. Sequential data is a generalized
    notion that encompasses any data that comes in a sequential form, including time
    series data.
  prefs: []
  type: TYPE_NORMAL
- en: Our objective here is to build a model that describes the pattern of the time
    series or any sequence in general. Such models are used to describe important
    features of the time series pattern. We can use these models to explain how the
    past might affect the future. We can also use them to see how two datasets can
    be correlated, to forecast future values, or to control a given variable that
    is based on some metric.
  prefs: []
  type: TYPE_NORMAL
- en: To visualize time series data, we tend to plot it using line charts or bar graphs.
    Time series data analysis is frequently used in finance, signal processing, weather
    prediction, trajectory forecasting, predicting earthquakes, or any field where
    we have to deal with temporal data. The models that we build in time series and
    sequential data analysis should take into account the ordering of data and extract
    the relationships among neighbors. Let's go ahead and check out a few recipes
    to analyze time series and sequential data in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming data into a time series format
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **time series** constitutes a sequence of observations of a phenomenon that's
    carried out in consecutive instants or time intervals that are usually, even if
    not necessarily, evenly spaced or of the same length. It follows that time is
    a fundamental parameter in the analysis of a time series. To start, we must therefore
    acquire a certain confidence in manipulating data that represents a long-term
    observation of a certain phenomenon.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will start by understanding how to convert a sequence of observations into
    time series data and visualize it. We will use a library called `pandas` to analyze
    time series data. Make sure that you install `pandas` before you proceed further.
    You can find the installation instructions for `pandas` at the following link: [http://pandas.pydata.org/pandas-docs/stable/install.html](http://pandas.pydata.org/pandas-docs/stable/install.html).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can transform data into a time series format:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file (the full code is given in the `convert_to_timeseries.py` file
    that is provided for you) and import the following packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define a function that reads an input file and converts sequential observations
    into time-indexed data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use a text file consisting of four columns. The first column denotes
    the year, the second column denotes the month, and the third and fourth columns
    denote data. Let''s load this into a NumPy array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As this is arranged chronologically, the first row contains the start date
    and the last row contains the end date. Let''s extract the start and end dates
    of this dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'There is also a `verbose` mode for this function. So, if this is set to `true`, it
    will print a few things. Let''s print out the start and end dates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create a `pandas` variable, which contains the date sequence with monthly
    intervals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Our next step is to convert the given column into time series data. You can
    access this data using the month and the year (as opposed to the index):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `verbose` mode to print out the first 10 elements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Return the time-indexed variable, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the main function, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the `data_timeseries.txt` file that is already provided to you:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the third column from this text file and convert it into time series data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `pandas` library provides a nice plotting function that you can run directly
    on the variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the code, you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/940ee777-eb54-4832-b1c5-f6c2fcdbbb17.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we learned how to convert a sequence of observations into time
    series data and display it. To do this, we first loaded the input file in a `.txt`
    format, so we extracted the start and end dates. Then, we created a sequence of
    dates with monthly intervals and converted the data into time series data. Finally,
    we plotted the time series data.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `pandas` library is particularly suitable for working with time series data
    for all domains, thanks to the extensive capabilities and features it has. These
    features take advantage of the NumPy `datetime64` and `timedelta64` variables, and
    a large number of functionality from other Python libraries such as `scikits.timeseries.`
    These features have made `pandas` particularly efficient for manipulating time
    series data.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the official documentation of the `pandas` time series and date functionality:
    [https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time Series Basics* (from The Pennsylvania State University): [https://newonlinecourses.science.psu.edu/stat510/node/41/](https://newonlinecourses.science.psu.edu/stat510/node/41/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slicing time series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Slice** and **dice** are two terms that refer to a dataset meaning to divide
    a large DataFrame into smaller parts or examine them from different points of
    view to understand it better. The term comes from culinary jargon and describes
    two types of knife skills that every chef has to master. To slice means to cut,
    while to dice means to cut food into very small and uniform sections, and the
    two actions are often performed in sequence. In data analysis, the term **slice
    and dice** generally involves a systematic reduction of a large dataset into smaller
    parts to extract more information.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to slice time series data. This will help
    you extract information from various intervals in the time series data. We will
    learn how to use dates to handle subsets of our data.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can perform slicing time series data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `slicing_data.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, `convert_to_timeseries` is the function we defined in the previous recipe *Transforming
    data into a time series format*, that reads an input file and converts sequential
    observations into time-indexed data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same text file that we used in the previous recipe (`data_timeseries.txt`)
    to slice and dice the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We will extract only the third column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s assume that we want to extract the data between the given `start` and
    `end` years. Let''s define these, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the data between the given year range:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also slice the data based on a certain range of months:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the data, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the code, you will see the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb612a80-360f-4836-8904-92fa1215cb67.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following screenshot displays a smaller time frame; hence, it looks as
    if we have zoomed into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/99f7bdeb-2652-4ff9-b62a-c46bf625924d.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we learned how to break up time series data. First, we imported
    the data contained in a `.txt` file. This data was transformed into a time series
    format using a function that we defined in the previous recipe. Thus, we have
    plotted the data, first within a certain period of years, and then within a certain
    range of dates.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To transform data into a time series format, the `pandas` library was used.
    This library is particularly efficient for manipulating time series data.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the official documentation of the pandas time series and date functionality: [https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time Series* (by Prof Gesine Reinert, from the University of Oxford): [http://www.stats.ox.ac.uk/~reinert/time/notesht10short.pdf](http://www.stats.ox.ac.uk/~reinert/time/notesht10short.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating on time series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we know how to slice data and extract various subsets, let's discuss
    how to operate on time series data. You can filter the data in many different
    ways. The `pandas` library allows you to operate on time series data in any way
    that you want.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will use data contained in a `.txt` file and load it. Then,
    we will filter the data using a certain threshold to extract only a portion of
    the starting dataset that meets specific requirements.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can operate on time series data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `operating_on_data.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Here, `convert_to_timeseries` is the function we defined in the previous recipe, *Transforming
    data into a time series format*, that read an input file and converted sequential
    observations into time-indexed data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same text file that we used in the previous recipes (`data_timeseries.txt`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use both the third and fourth columns in this `.txt` file (remember,
    Python lists the data starting from position 0, so the third and fourth columns
    have the indices 2 and 3):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert the data into a `pandas` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the data in the given year range:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s assume that we want to plot the difference between the two columns that
    we just loaded in the given year range. We can do this using the following lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to filter the data based on different conditions for the first and
    second columns, we can just specify these conditions and plot this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the preceding code, the first output will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95ef968f-8117-466e-83cc-bb02335bfc8f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second output screenshot denotes the difference, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2496b36b-19df-4b72-b296-917d135271f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The third output screenshot denotes the filtered data, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d7837dd2-957f-479c-a374-bae91b59aa16.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we learned how to filter the data contained in a time series.
    First, we plotted the data between two years (from 1952 to 1955). Then, we plotted
    the difference between the data contained in two columns for a specific time interval
    (from 1952 to 1955). Finally, we plotted data using a certain threshold to extract
    only a portion of the starting dataset that meets specific requirements—in particular,
    when the first column is greater than 60 and when the second column is smaller
    than 20.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To perform two-column filtering at the same time, the `&` operator was used.
    The `&` (and) operator is a logical operator (Boolean operator) of logical conjunction
    between two propositions. Given two propositions, A and B, the logical conjunction
    determines a third proposition, C*,* that manifests itself as true only when both
    propositions are true.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the *Fundamental concepts in Time Series Analysis* lecture, (from
    the University of Lausanne): [https://math.unice.fr/~frapetti/CorsoP/chapitre_1_part_1_IMEA_1.pdf](https://math.unice.fr/~frapetti/CorsoP/chapitre_1_part_1_IMEA_1.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting statistics from time series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main reasons that we want to analyze time series data is to extract
    interesting statistics from it. This provides a lot of information regarding the
    nature of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will take a look at how to extract some statistics.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can extract statistics from time series data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `extract_stats.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `convert_to_timeseries` function is the function we defined in the previous
    recipe, *Transforming data into a time series format*, that read an input file
    and converted sequential observations into time-indexed data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same text file that we used in the previous recipes for analysis
    (`data_timeseries.txt`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Load both the data columns (third and fourth columns):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `pandas` data structure to hold this data. This DataFrame is like
    a dictionary that has keys and values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s start extracting some stats now. To extract the maximum and minimum
    values, use the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'To print the mean values of your data or just the row-wise mean, use the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The rolling mean is an important statistic that''s used a lot in time series
    processing. One of the most famous applications is smoothing a signal to remove
    noise. *Rolling mean* refers to computing the mean of a signal in a window that
    keeps sliding on the time scale. Let''s consider a window size of `24` and plot
    this, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Correlation coefficients are useful in understanding the nature of the data,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s plot this using a window size of `60`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the preceding code, the rolling mean will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ca055cc5-4cb0-4389-ac92-7b969f423cb1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second output indicates the rolling correlation (the following output is
    the result of a zoomed rectangle operation that was performed in the `matplotlib`
    window):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/40cb9669-d1a2-49a1-8a6d-df47979ae75b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the upper half of the Terminal, you will the see max, min, and mean values
    printed, as shown in the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f5eab4b8-8343-4a9b-9dd6-a1c217637675.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the lower half of the terminal, you will see the row-wise mean stats and
    correlation coefficients printed, as shown in the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/cf91ac64-c670-4527-aa2b-309b00cb6896.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we learned how to extract some statistics. We started by calculating
    the minimum, maximum, and mean of each of the two columns that were extracted
    from the dataset. Then, we calculated the mean for each row for the first 10 rows
    of the DataFrame. Finally, we performed a correlation analysis between the two
    features.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To perform a correlation analysis, the `pandas.DataFrame.corr` function was
    used. This function computes a pairwise correlation of columns, excluding N/A
    or null values. The following methods are available:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pearson`: This is the standard correlation coefficient'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kendall`: This is the **Kendall Tau** correlation coefficient'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spearman`: This is the **Spearman rank** correlation coefficient'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the official documentation of the `pandas.DataFrame.corr` function:
    [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Correlation* (from the SRM University): [http://www.srmuniv.ac.in/sites/default/files/downloads/CORRELATION.pdf](http://www.srmuniv.ac.in/sites/default/files/downloads/CORRELATION.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building HMMs for sequential data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Hidden Markov models** (**HMMs**) are particularly suitable for sequential
    data analysis problems. They are widely used in fields such as speech analysis,
    finance, word sequencing, weather forecasting, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Any source of data that produces a sequence of outputs can produce patterns.
    Note that HMMs are generative models, which means that they can generate the data
    once they learn the underlying structure. HMMs cannot discriminate between classes
    in their base forms. This is in contrast to discriminative models that can learn
    to discriminate between classes but cannot generate data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s say that we want to predict whether the weather will be sunny, chilly,
    or rainy tomorrow. To do this, we look at all the parameters, such as temperature,
    pressure, and so on, whereas the underlying state is hidden. Here, the underlying
    state refers to the three available options: sunny, chilly, or rainy.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can build HMMs for sequential data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `hmm.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the data from a file named `data_hmm.txt` that is already provided
    to you. This file contains comma-separated lines. Each line contains three values:
    a year, a month, and a piece of floating-point data. Let''s load this into a NumPy
    array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s stack the data column-wise for analysis. We don''t need to technically
    column-stack this because it''s only one column. However, if you have more than
    one column to analyze, you can use the following structure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Create and train the HMM using four components. The number of components is
    a hyperparameter that we have to choose. Here, by selecting four, we say that
    the data is being generated using four underlying states. We will see how the
    performance varies with this parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the predictor to get the hidden states:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute the mean and variance of the hidden states:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'As we discussed earlier, HMMs are generative models. So, let''s generate, for
    example, `1000` samples and plot this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The full code is given in the `hmm.py` file that is already provided to you.
    If you run the preceding code, you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f7ca760-fe8a-4f2e-9775-42e56d237035.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can experiment with the `n_components` parameter to see how the curve gets
    nicer as you increase it. You can basically give it more freedom to train and
    customize by allowing a larger number of hidden states. If you increase it to
    `8`, you will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f808d661-11ee-48ad-868b-cfbd6a10a5ac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you increase this to `12`, it will get even smoother:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6f68f940-7cb3-453f-9198-0ed5de91f93f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the terminal, you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HMM is a model in which the system being modeled is assumed to be a Markov process
    with unobserved states. A stochastic process is called Markovian when, having
    chosen a certain instance of *t* for observation, the evolution of the process,
    starting with *t*, depends only on *t* and does not depend in any way on the previous
    instances. Thus, a process is Markovian when, given the moment of observation,
    only this instance determines the future evolution of the process, while this
    evolution does not depend on the past. In this recipe, we learned how to use HMMs
    to generate a time series.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we used `hmmlearn` to build and train HMMs, which implements
    the HMMs. A HMM is a generative probabilistic model, wherein a sequence of observable
    variables is computed using a sequence of hidden internal states. Hidden states
    are not observed directly.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the official documentation of the `hmmlearn` library to find out more: [https://hmmlearn.readthedocs.io/en/latest/](https://hmmlearn.readthedocs.io/en/latest/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*A Tutorial on Hidden Markov Models* (by Lawrence R Rabiner from Oxford University):
    [https://www.robots.ox.ac.uk/~vgg/rg/slides/hmm.pdf](https://www.robots.ox.ac.uk/~vgg/rg/slides/hmm.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building CRFs for sequential text data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Conditional random fields** (**CRFs**) are probabilistic models that are
    used to analyze structured data. They are frequently used to label and segment
    sequential data. CRFs are discriminative models as opposed to HMMs, which are
    generative models. CRFs are used extensively to analyze sequences, stock, speech,
    words, and so on. In these models, given a particular labeled observation sequence,
    we define a conditional probability distribution over this sequence. This is in
    contrast to HMMs, where we define a joint distribution over the label and the
    observed sequence.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will use a library called `pystruct` to build and train CRFs.
    Make sure that you install this before you proceed. You can find the installation
    instructions at [https://pystruct.github.io/installation.html](https://pystruct.github.io/installation.html).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can build CRFs for sequential text data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `crf.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Define an argument parser to take the `C` value as an input argument. Here,
    `C` is a hyperparameter that controls how specific you want your model to be without
    losing the power to generalize:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a `class` to handle all CRF-related processing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Define an `init` function to initialize the values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use `ChainCRF` to analyze the data. We need to add an error check to
    this, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the classifier that we will use with our CRF model. We will use a type
    of SVM to achieve this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the `letters` dataset. This dataset consists of segmented letters and
    their associated feature vectors. We will not analyze the images because we already
    have the feature vectors. The first letter from each word has been removed, so
    all we have are lowercase letters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the data and labels into their respective variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a training method, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a method to evaluate the performance of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a method to classify new data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The letters are indexed in a numbered array. To check the output and make it
    readable, we need to transform these numbers into alphabets. Define a function
    to do this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the main function and parse the input arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the variable with the class and the `C` value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the `letters` data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Separate the data into training and testing datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the CRF model, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Evaluate the performance of the CRF model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a random test vector and predict the output using the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the preceding code, you will get the following output on your terminal.
    As we can see, the word is supposed to be `commanding`. The CRF does a pretty
    good job of predicting all the letters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HMMs assume that the current output is statistically independent of the previous
    outputs. This is needed by HMMs to ensure that the inference works in a robust
    way. However, this assumption doesn't always have to be true! The current output
    in a time series setup, more often than not, depends on previous outputs. One
    of the main advantages of CRFs over HMMs is that they are conditional by nature,
    which means that we are not assuming any independence between output observations.
    There are a few other advantages of using CRFs over HMMs. CRFs tend to outperform
    HMMs in a number of applications, such as linguistics, bioinformatics, speech
    analysis, and so on. In this recipe, we will learn how to use CRFs to analyze
    sequences of letters.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyStruct is a structured library of easy-to-use machine learning algorithms.
    It implements the max-margin and perceptron methods. Examples of learning algorithms
    that are implemented in PyStruct are CRFs, **maximum-margin Markov** **random
    fields** (**M3Ns**), and structural SVMs.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the official documentation of the `pystruct` library for more information: [https://pystruct.github.io/](https://pystruct.github.io/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Look at the *Conditional Random Fields* lecture (from the University of Notre
    Dame): [https://www3.nd.edu/~dchiang/teaching/nlp/2015/notes/chapter8v1.pdf](https://www3.nd.edu/~dchiang/teaching/nlp/2015/notes/chapter8v1.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing stock market data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The stock market has always been a very popular topic; this is because stock
    market trends involve a truly impressive turnover. The interest that this topic
    arouses is clearly linked to the opportunity to get rich through good forecasting
    by a stock market title. A positive difference between the purchased stock price
    and that of the sold stock price entails a gain on the part of the investor. But,
    as we know, the performance of the stock market depends on multiple factors.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll look at how to analyze the stock price of a very popular
    company: I am referring to Amazon, the US e-commerce company, based in Seattle,
    Washington, which is the largest internet company in the world.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we analyze stock market data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `AmazonStock.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Get the stock quotes from the `AMZN.csv` file that is provided for you:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'To extract preliminary information about the imported dataset, we can invoke
    the `info()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: This function prints information about a DataFrame, including the index and
    the `dtypes` column, `non-null` values, and `memory usage`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To display the first five rows of the imported DataFrame, we can use the `head()`
    function, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'This function returns the first *n* rows for the object based on position.
    It is useful for quickly testing whether your object has the right type of data
    in it. By default, (if *n* is omitted), the first five rows are displayed. The
    following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'To get a preview of the data contained in it, we can calculate a series of
    basic statistics. To do so, we will use the `describe()` function in the following
    way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The `describe()` function generates descriptive statistics that summarize the
    central tendency, the dispersion, and the form of the distribution of a dataset,
    excluding the `NaN` values. This function analyzes both numerical and object series,
    as well as the DataFrame column sets of mixed data types. The following results
    are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are going to perform an initial visual exploratory analysis of the
    time series:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following graph, Amazon stock prices from 2000-11-21 to 2018-11-21 are
    shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7dd54eda-2970-4787-99af-3b14fa0b5bb3.png)'
  prefs: []
  type: TYPE_IMG
- en: From the analysis of the previous graph, we can see that prices have increased
    considerably over time. In particular, starting from 2015, this increase has shown
    an exponential trend.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s try to obtain a deeper understanding of the change that Amazon
    stock has recorded over time. To calculate percentage changes in Python, we will
    use the `pct_change()` function. This function returns percentage changes over
    a given number of periods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: What we have just calculated coincides with the concept of return.
  prefs: []
  type: TYPE_NORMAL
- en: 'To calculate the logarithm of returns, we will use the `log()` function from
    `numpy`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The `tail()` function returns the last *n* rows from the object, based on position.
    It is useful for quickly verifying data—for example, after sorting or appending
    rows. The following values are returned (the last 10 rows of the `LogReturns`
    object):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will draw a diagram with the logarithm of the returns we have calculated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'As we have done previously, we first set the dimensions of the graph, then
    we will plot the graph, and finally we will visualize it. The following graph
    shows the logarithm of the returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/067332e5-a62c-40f6-ab09-29ea44dd5d21.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To study the evolution of a phenomenon, a graph of its time series is not enough;
    we need to make comparisons between the intensity of the phenomenon at different
    times, that is, calculating the variations of intensity from one period to another.
    Furthermore, it can be interesting to analyze the trend of the variations of the
    phenomenon that occurred between adjoining periods of time. We indicate a time
    series with Y1,..., Yt,..., Yn. The time series is the chronological recording
    of experimental observations of a variable, such as price trends, stock market
    indices, spreads, and unemployment rates. It is therefore a succession of data
    that's been ordered over time from which we want to extract information for the
    characterization of the phenomenon under observation, and for the prediction of
    future values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The variation that occurs between two different times (let''s indicate them
    with *t* and *t + 1*) can be measured using the following ratio:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6f1d5748-9875-4c3d-a708-3bfe00fa6cb2.png)'
  prefs: []
  type: TYPE_IMG
- en: This index is a percentage ratio and is called a **percentage change**. In particular,
    this is the percentage rate of variation of the phenomenon *Y* of the time *t
    + 1*, with respect to the previous time, *t*. This method gives a more detailed
    explanation about how the data has changed over a period of time. With this technique,
    we can track the prices of individual stocks and large market indices, as well
    as compare the values of different currencies.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The advantage of using returns, compared to prices, lies in the normalization
    that allows us to measure all the variables in a comparable metric, thus allowing
    for the evaluation of analytical relationships between two or more variables.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the official documentation of the `pandas.DataFrame.pct_change` function:
    [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pct_change.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pct_change.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using RNNs to predict time series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Long short-term memory** (**LSTM**) is a particular architecture of **recurrent
    neural networks** (**RNNs**). RNNs are based on the need to preserve the memory
    of past events; this behavior is not possible with normal networks, and that is
    why RNNs are used in areas where the classic networks do not produce results,
    such as the prediction of time series (weather, quotations, and so on) that refer
    to previous data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'An LSTM network consists of cells (LSTM blocks) that are linked together. Each
    cell is, in turn, composed of three types of ports: the input gate, output gate,
    and forget gate. They implement the write, read, and reset functions on the cell
    memory, respectively, so the LSTM modules are able to regulate what is stored
    and deleted. This is possible thanks to the presence of various elements called
    **gates**, which are composed of a sigmoid neural layer and a pointwise product. The
    output of each gate is in the range (0, 1), representing the percentage of information
    that flows inside it.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll look at how the LSTM model can be applied to predict
    the future stock price of a very popular company: I refer to Amazon, the US e-commerce
    company, based in Seattle, Washington, which is the largest internet company in
    the world.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can use RNNs to predict time series data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `LSTMstock.py` file that is provided for you). The first part of
    the file was tackled in the previous recipe, *Analyzing stock market data*. We
    report it only for the completeness of the algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'It is good practice to rescale the data before training an LSTM algorithm.
    With rescaling, data units are eliminated, allowing you to compare data from different
    locations easily. In this case, we will use the min-max method (usually called
    **feature scaling**) to get all the scaled data in the range [0, 1]. To perform
    feature scaling, we can use the preprocessing package that''s available in the
    `sklearn` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s split the data for the training and test model. Training and testing
    the model forms the basis for further usage of the model for prediction in predictive
    analytics. Given a dataset of 4,529 rows of data, we split it into a convenient
    ratio (say 70:30) and allocate 3,170 rows for training and 1,359 rows for testing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we need input and output to train and test our network. It is clear that
    the input is represented by the data that''s present in the dataset. Therefore,
    we must construct our output; we will do so by supposing we want to predict the
    Amazon stock price at time *t + 1* with respect to the value stored at time *t*. A
    recurrent network has memory, and this is maintained by fixing the so-called time
    step. The time step is all about how many steps back in time backpropagation uses
    when calculating gradients for weight updates during training. In this way, we
    set `TimeStep=1`. Then, we define a function that gives a dataset and a time step,
    which then returns the input and output data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: In this function, `dataX =Input= data(t)` is the input variable and `DataY=output=
    data(t + 1)` is the predicted value at the next time period.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use this function to set the train and test datasets that we will use
    in the next phase (network modeling):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'In an LSTM/RNN network, the input for each LSTM layer must contain the following
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Observations**: Number of observations collected'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time steps**: A time step is an observation point in the sample'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Features**: One feature for each step'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Therefore, it is necessary to add a temporal dimension to those foreseen for
    a classical network. Thus, the input shape is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: (*Number of observations, number of time steps, number of features per steps*)
  prefs: []
  type: TYPE_NORMAL
- en: In this way, the input for each LSTM layer becomes three-dimensional.
  prefs: []
  type: TYPE_NORMAL
- en: 'To transform the input datasets into 3D form, we will use the `np.reshape()`
    function, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the data is in the right format, it''s time to create the model. Let''s
    start by importing the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use a `Sequential` model, that is, a linear stack of layers. To create
    a sequential model, we have to pass a list of layer instances to the constructor.
    We can also simply add layers via the `add()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result is printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b0198263-2a08-40c5-a32f-5ba727792200.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To evaluate the performance of the model we have just adapted, we can use the
    `evaluate()` function, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding function displays the loss value and metrics values for the model
    in the test mode. This is computed in batches. The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'The model is now ready for use. We can therefore use it to execute our predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'The predictions must be reported in their original form so that they can be
    compared to the actual values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'To verify the correct prediction of data, we can now visualize the results
    by drawing an appropriate graph. To display the time series correctly, a prediction
    shift is required. This operation must be carried out both on the train set and
    the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'As we stated previously, the same operation must then be performed on the test
    set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we have to plot the actual data and the predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the actual data and the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b0a827d7-3058-4be1-a038-b0b715dd7d6b.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the beginning of this recipe, we said that the LSTM modules are able to
    regulate what is stored and deleted. This is possible thanks to the presence of
    various elements called gates, which are composed of a sigmoid neural layer and
    a pointwise product. The first part of the LSTM module decides what information
    is deleted from the cell. The gate takes the inputs and returns a value between
    0 and 1 for each state of the cell. The gate output can take two values:'
  prefs: []
  type: TYPE_NORMAL
- en: '`0`: Complete reset of the cell status'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`1`: Total storage of the cell value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data storage is divided into two phases:'
  prefs: []
  type: TYPE_NORMAL
- en: The first is entrusted to one sigmoid layer called the **input gate layer**;
    it carries out an operation that establishes which values will need to be updated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second phase is instead entrusted to a `tanh` layer that creates a vector
    of values, intended to be updated. To create an updated set of values, the outputs
    of the two layers are combined.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the result will be given by a `sigmoid` layer, which determines which
    parts of the cell will contribute to the output and from the current state of
    the cell, filtered through a `tanh` function to obtain a range from -1 to 1. The
    result of this operation is multiplied by the value of the `sigmoid` layer so
    that only the desired outputs are given.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A RNN is a neural model in which a bidirectional flow of information is present.
    In other words, while the propagation of signals in feedforward networks takes
    place only in a continuous manner in one direction, from inputs to outputs, recurrent
    networks are different. In recurrent networks, this propagation can also occur
    from a neural layer following a previous one, between neurons belonging to the
    same layer, or even between a neuron and itself.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the official documentation of the Keras library: [https://keras.io/](https://keras.io/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to *Recurrent Neural Networks* (from Yale University): [http://euler.stat.yale.edu/~tba3/stat665/lectures/lec21/lecture21.pdf](http://euler.stat.yale.edu/~tba3/stat665/lectures/lec21/lecture21.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to *Long Short-Term Memory* (from the University of Wisconsin, Madison):
    [http://pages.cs.wisc.edu/~shavlik/cs638/lectureNotes/Long%20Short-Term%20Memory%20Networks.pdf](http://pages.cs.wisc.edu/~shavlik/cs638/lectureNotes/Long%20Short-Term%20Memory%20Networks.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
