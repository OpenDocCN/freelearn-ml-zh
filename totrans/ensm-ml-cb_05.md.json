["```py\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.utils import resample\n\nimport matplotlib.pyplot as plt\n\n```", "```py\nos.chdir('.../.../Chapter 5')\nos.getcwd()\n```", "```py\ndf_autodata = pd.read_csv(\"autompg.csv\")\n```", "```py\n# The below syntax returns the column names which has any missing value\ncolumns_with_missing_values=df_autodata.columns[df_autodata.isnull().any()]\n\n# We pass the column names with missing values to the dataframe to count the number\n# of missing values\ndf_autodata[columns_with_missing_values].isnull().sum()\n```", "```py\ndf_autodata['horsepower'].fillna(df_autodata['horsepower'].median(), inplace=True)\n```", "```py\ndf_autodata.drop(['carname'], axis=1, inplace=True)\n```", "```py\ndf_autodata.head()\n```", "```py\ndef create_bootstrap_oob(df):\n    global df_OOB\n    global df_bootstrap_sample \n    # creating the bootstrap sample\n    df_bootstrap_sample = resample(df, replace=True, n_samples=100)\n\n    # creating the OOB sample \n    bootstrap_sample_index = tuple(df_bootstrap_sample.index)\n    bootstrap_df = df.index.isin(bootstrap_sample_index)\n\n    df_OOB = df[~bootstrap_df]\n```", "```py\niteration=50\nmse_each_iterations = list()\nlm=SGDRegressor()\ntotal_mse=0\naverage_mse= list()\n\nfor i in range(iteration):\n    create_bootstrap_oob(df_autodata)\n\n    # Bootstrap sample features set\n    X_BS = df_bootstrap_sample.iloc[:,1:8] \n\n    # bootstrap sample response variable\n    Y_BS = df_bootstrap_sample.iloc[:,0] \n\n    X_OOB = df_OOB.iloc[:,1:8] #OOB sample features\n    Y_OOB = df_OOB.iloc[:,0] #OOB sample response variable \n\n    # fit your model with bootstrap sample\n    lm=SGDRegressor()\n    lm.fit(X_BS, Y_BS)\n\n    # test your model on out-of-bag sample \n    predictedvalues = lm.predict(X_OOB)\n\n    # capture MSE for the predicted values against OOB actuals\n    mse = mean_squared_error(Y_OOB, predictedvalues)\n\n    # create a list of mse values\n    mse_each_iterations.append(mse) \n```", "```py\nimport matplotlib.pyplot as plt\nf, ax= plt.subplots(figsize=(8,6))\n\nplt.plot(mse_each_iterations, 'c--', label='MSE by Iteration')\n\nplt.xlabel('Iterations')\nplt.ylabel('Mean Squared Error')\nplt.legend(loc=1)\nplt.show()\n```", "```py\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n```", "```py\ndf_winedata = pd.read_csv('winedata.csv')\ndf_winedata.shape\n```", "```py\nX = df_winedata.iloc[:,1:14]\nY = df_winedata.iloc[:,0]\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)\n```", "```py\ndt_model = DecisionTreeClassifier(criterion='entropy')\nbag_dt_model = BaggingClassifier(dt_model, max_features=1.0, n_estimators=5, \\\n                                 random_state=1, bootstrap=True)\n```", "```py\nbag_dt_model.fit(X_train, Y_train)\n```", "```py\nbag_dt_model.score(X_test, Y_test)\n```", "```py\npredictedvalues = bag_dt_model.predict(X_test)\n```", "```py\n# code from \n# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Actuals')\n    plt.xlabel('Predicted')\n```", "```py\n# This variable holds the class labels of our target variable\ntarget_names = [ '1', '2', '3']\n\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n# Constructing the Confusion Matrix\ncm = confusion_matrix(Y_test, predictedvalues)\n\n# Plotting the confusion matrix\nplt.figure(figsize=(3,3))\nplot_confusion_matrix(cm, classes=target_names, normalize=False)\nplt.show()\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\n```", "```py\nparam_values = {'n_estimators': [10, 20, 25, 30], 'base_estimator__max_leaf_nodes':[5, 10, 15, 20], 'base_estimator__max_depth':[3, 4, 5]}\n```", "```py\ndt_model = DecisionTreeClassifier()\nbag_dt_model_grid = BaggingClassifier(base_estimator=dt_model, oob_score=True, random_state=1) \n```", "```py\nbc_grid = GridSearchCV(estimator=bag_dt_model_grid, param_grid=param_values, cv=20, n_jobs=-1)\nbc_grid.fit(X_train, Y_train)\nbest_params = bc_grid.best_params_\nprint(best_params)\n```", "```py\nbest_dt_model = DecisionTreeClassifier(criterion='entropy', max_leaf_nodes=10, max_depth=3) \nfinal_bag_dt_model = BaggingClassifier(base_estimator=best_dt_model, n_estimators=150, bootstrap=True, random_state=1, oob_score=True)\n```", "```py\nfinal_bag_dt_model.fit(X_train, Y_train)\nbag_predictedvalues = final_bag_dt_model.predict(X_test)\n\n# See the OOB accuracy\nacc_oob = final_bag_dt_model.oob_score_\nprint(acc_oob)\n```", "```py\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n```", "```py\ndf_housingdata = pd.read_csv('bostonhousing.csv')\ndf_housingdata.shape\n```", "```py\nX = df_housingdata.iloc[:,1:14]\nY = df_housingdata.iloc[:,-1]\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)\n```", "```py\ndt_model = DecisionTreeRegressor()\nbag_dt_model = BaggingRegressor(dt_model, max_features=1.0, n_estimators=5, bootstrap=True, random_state=1, )\n```", "```py\nbag_dt_model.fit(X_train, Y_train)\n```", "```py\nbag_dt_model.score(X_test, Y_test)\n```", "```py\npredictedvalues = bag_dt_model.predict(X_test)\n```", "```py\n#We can plot the actuals and the predicted values \nplt.figure(figsize=(4, 4))\nplt.scatter(Y_test, predictedvalues)\nplt.xlabel('Actual')\nplt.ylabel('Predicted')\nplt.tight_layout()\n```", "```py\nbag_dt_model = BaggingRegressor(dt_model, max_features=1.0, n_estimators=30, bootstrap=True, random_state=1, )\n```"]