["```py\n!pip3 install google-cloud-aiplatform\n!pip3 install kfp --upgrade\n!pip install google_cloud_pipeline_components\n```", "```py\nfrom typing import NamedTuple\nimport typing\nimport pandas as pd\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import (Artifact, Dataset, Input, Model, Output, Metrics, ClassificationMetrics, component, OutputPath, InputPath)\nfrom kfp.v2 import compiler\nfrom google.cloud import bigquery\nfrom google.cloud import aiplatform\nfrom google.cloud.aiplatform import pipeline_jobs\nfrom google_cloud_pipeline_components import aiplatform as gcc_aip\n```", "```py\nfrom datetime import datetime\nTIMESTAMP =datetime.now().strftime(\"%Y%m%d%H%M%S\")\n```", "```py\nPROJECT_ID='417xxxxxxx97'\nREGION='us-west2'\nSERVICE_ACCOUNT='417xxxxxxx97-compute@developer.gserviceaccount.com'\nBUCKET_URI='gs://my-training-artifacts'\n```", "```py\ndf_wine = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", delimiter=\";\")\ndf_wine.head()\n```", "```py\n@component(\n    packages_to_install=[\"pandas\", \"pyarrow\", \"scikit-learn==1.0.0\"],\n    base_image=\"python:3.9\",\n    output_component_file=\"load_data_component.yaml\"\n)\n```", "```py\ndef get_wine_data(\n    url: str,\n    dataset_train: Output[Dataset],\n    dataset_test: Output[Dataset]\n):\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split as tts\n    df_wine = pd.read_csv(url, delimiter=\";\")\n    df_wine['best_quality'] = [1 if x>=7 else 0 for x in df_wine.quality]\n    df_wine['target'] = df_wine.best_quality\n    df_wine = df_wine.drop(\n        ['quality', 'total sulfur dioxide', 'best_quality'],\n         axis=1,\n    )\n```", "```py\n    train, test = tts(df_wine, test_size=0.3)\n    train.to_csv(\n        dataset_train.path + \".csv\",\n        index=False,\n        encoding='utf-8-sig',\n    )\n    test.to_csv(\n        dataset_test.path + \".csv\",\n        index=False,\n        encoding='utf-8-sig',\n    )\n```", "```py\n@component(\n    packages_to_install = [\n        \"pandas\",\n        \"scikit-learn\"\n    ],\n    base_image=\"python:3.9\",\n    output_component_file=\"model_training_component.yml\",\n)\n```", "```py\ndef train_winequality(\n    dataset:  Input[Dataset],\n    model: Output[Model],\n):\n    from sklearn.ensemble import RandomForestClassifier\n    import pandas as pd\n    import pickle\n    data = pd.read_csv(dataset.path+\".csv\")\n    model_rf = RandomForestClassifier(n_estimators=10)\n    model_rf.fit(\n        data.drop(columns=[\"target\"]),\n        data.target,\n    )\n    model.metadata[\"framework\"] = \"RF\"\n    file_name = model.path + f\".pkl\"\n    with open(file_name, 'wb') as file:\n        pickle.dump(model_rf, file)\n```", "```py\n@component(\n    packages_to_install = [\n        \"pandas\",\n        \"scikit-learn\"\n    ],\n    base_image=\"python:3.9\",\n    output_component_file=\"model_evaluation_component.yml\",\n)\n```", "```py\ndef winequality_evaluation(\n    test_set:  Input[Dataset],\n    rf_winequality_model: Input[Model],\n    thresholds_dict_str: str,\n    metrics: Output[ClassificationMetrics],\n    kpi: Output[Metrics]\n) -> NamedTuple(\"output\", [(\"deploy\", str)]):\n    from sklearn.ensemble import RandomForestClassifier\n    import pandas as pd\n    import logging\n    import pickle\n    from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score\n    import json\n    import typing\n```", "```py\n    def threshold_check(val1, val2):\n        cond = \"false\"\n        if val1 >= val2 :\n            cond = \"true\"\n        return cond\n    data = pd.read_csv(test_set.path+\".csv\")\n    model = RandomForestClassifier()\n    file_name = rf_winequality_model.path + \".pkl\"\n    with open(file_name, 'rb') as file:\n        model = pickle.load(file)\n    y_test = data.drop(columns=[\"target\"])\n    y_target=data.target\n    y_pred = model.predict(y_test)\n```", "```py\n    y_scores =  model.predict_proba(\n        data.drop(columns=[\"target\"])\n    )[:, 1]\n    fpr, tpr, thresholds = roc_curve(\n         y_true=data.target.to_numpy(),\n        y_score=y_scores, pos_label=True\n    )\n    metrics.log_roc_curve(\n        fpr.tolist(),\n        tpr.tolist(),\n        thresholds.tolist()\n    )\n    metrics.log_confusion_matrix(\n       [\"False\", \"True\"],\n       confusion_matrix(\n           data.target, y_pred\n       ).tolist(),\n    )\n```", "```py\n    accuracy = accuracy_score(data.target, y_pred.round())\n    thresholds_dict = json.loads(thresholds_dict_str)\n    rf_winequality_model.metadata[\"accuracy\"] = float(accuracy)\n    kpi.log_metric(\"accuracy\", float(accuracy))\n    deploy = threshold_check(float(accuracy), int(thresholds_dict['roc']))\n    return (deploy,)\n```", "```py\n@component(\n    packages_to_install=[\"google-cloud-aiplatform\", \"scikit-learn\",  \"kfp\"],\n    base_image=\"python:3.9\",\n    output_component_file=\"model_winequality_component.yml\"\n)\n```", "```py\ndef deploy_winequality(\n    model: Input[Model],\n    project: str,\n    region: str,\n    serving_container_image_uri : str,\n    vertex_endpoint: Output[Artifact],\n    vertex_model: Output[Model]\n):\n    from google.cloud import aiplatform\n    aiplatform.init(project=project, location=region)\n    DISPLAY_NAME  = \"winequality\"\n    MODEL_NAME = \"winequality-rf\"\n    ENDPOINT_NAME = \"winequality_endpoint\"\n```", "```py\n    def create_endpoint():\n        endpoints = aiplatform.Endpoint.list(\n        filter='display_name=\"{}\"'.format(ENDPOINT_NAME),\n        order_by='create_time desc',\n        project=project,\n        location=region,\n        )\n        if len(endpoints) > 0:\n            endpoint = endpoints[0]  # most recently created\n        else:\n            endpoint = aiplatform.Endpoint.create(\n            display_name=ENDPOINT_NAME, project=project, location=region\n        )\n    endpoint = create_endpoint()\n```", "```py\n    #Import a model programmatically\n    model_upload = aiplatform.Model.upload(\n        display_name = DISPLAY_NAME,\n        artifact_uri = model.uri.replace(\"model\", \"\"),\n        serving_container_image_uri =  serving_container_image_uri,\n        serving_container_health_route=f\"/v1/models/{MODEL_NAME}\",\n        serving_container_predict_route=f\"/v1/models/{MODEL_NAME}:predict\",\n        serving_container_environment_variables={\n        \"MODEL_NAME\": MODEL_NAME,\n    },\n    )\n```", "```py\n    model_deploy = model_upload.deploy(\n        machine_type=\"n1-standard-4\",\n        endpoint=endpoint,\n        traffic_split={\"0\": 100},\n        deployed_model_display_name=DISPLAY_NAME,\n    )\n    # Save data to the output params\n    vertex_model.uri = model_deploy.resource_name\n```", "```py\nDISPLAY_NAME = 'pipeline-winequality job{}'.format(TIMESTAMP)\n```", "```py\n@dsl.pipeline(\n    pipeline_root=BUCKET_URI,\n    name=\"pipeline-winequality\",\n)\ndef pipeline(\n    url: str = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n    project: str = PROJECT_ID,\n    region: str = REGION,\n    display_name: str = DISPLAY_NAME,\n    api_endpoint: str = REGION+\"-aiplatform.googleapis.com\",\n    thresholds_dict_str: str = '{\"roc\":0.8}',\n    serving_container_image_uri: str = \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n    ):\n```", "```py\n    # adding first component\n    data_op = get_wine_data(url)\n    # second component uses output of first component as input\n    train_model_op = train_winequality(data_op.outputs[\"dataset_train\"])\n    # add third component (uses outputs of comp1 and comp2 as input)\n    model_evaluation_op = winequality_evaluation(\n        test_set=data_op.outputs[\"dataset_test\"],\n        rf_winequality_model=train_model_op.outputs[\"model\"],\n        # We deploy the model only if the model performance is above the threshold\n        thresholds_dict_str = thresholds_dict_str,\n    )\n```", "```py\n    # condition to deploy the model\n    with dsl.Condition(\n        model_evaluation_op.outputs[\"deploy\"]==\"true\",\n        name=\"deploy-winequality\",\n    ):\n        deploy_model_op = deploy_winequality(\n        model=train_model_op.outputs['model'],\n        project=project,\n        region=region,\n        serving_container_image_uri = serving_container_image_uri,\n        )\n```", "```py\ncompiler.Compiler().compile(\n    pipeline_func=pipeline,\n    package_path='ml_winequality.json',\n)\n```", "```py\npipeline_job = pipeline_jobs.PipelineJob(\n    display_name=\"winequality-pipeline\",\n    template_path=\"ml_winequality.json\",\n    enable_caching=False,\n    location=REGION,\n)\npipeline_job.run()\n```", "```py\nfrom datetime import timedelta\nfrom textwrap import dedent\n# The DAG object; we'll need this to instantiate a DAG\nfrom airflow import DAG\n# Operators; we need this to operate!\nfrom airflow.operators.bash import BashOperator\nfrom airflow.utils.dates import days_ago\n# These args will get passed on to each operator\n# You can override them on a per-task basis during operator initialization\n```", "```py\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email': ['airflow@example.com'],\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n    # 'queue': 'bash_queue',\n    # 'execution_timeout': timedelta(seconds=300),\n    # 'on_failure_callback': some_function,\n    # 'on_success_callback': some_other_function,\n    # 'on_retry_callback': another_function,\n    # 'sla_miss_callback': yet_another_function,\n}\n```", "```py\nwith DAG(\n    'composer-test-dag',\n    default_args=default_args,\n    description='A simple composer DAG',\n    schedule_interval=timedelta(days=1),\n    start_date=days_ago(2),\n    tags=['example'],\n) as dag:\n```", "```py\n    # t1, t2 and t3 are examples of tasks created by instantiating operators\n    t1 = BashOperator(\n        task_id='print_date',\n        bash_command='date',\n    )\n    t2 = BashOperator(\n        task_id='sleep',\n        depends_on_past=False,\n        bash_command='sleep 5',\n        retries=3,\n    )\n```", "```py\n    t1.doc_md = dedent(\n    )\n    dag.doc_md = __doc__\n    dag.doc_md = \"\"\"a documentation placed anywhere\"\"\"\n    templated_command = dedent(\n        \"\"\"\n    {% for i in range(5) %}\n        echo \"{{ ds }}\"\n        echo \"{{ macros.ds_add(ds, 7)}}\"\n        echo \"{{ params.my_param }}\"\n    {% endfor %}\n    \"\"\"\n    )\n```", "```py\n    t3 = BashOperator(\n        task_id='templated',\n        depends_on_past=False,\n        bash_command=templated_command,\n        params={'my_param': 'Parameter I passed in'},\n    )\n```", "```py\n    t1 >> [t2, t3]\n```", "```py\ndef create_endpoint_sample(\n    project: str,\n    display_name: str,\n    location: str,\n):\n    aiplatform.init(project=project, location=location)\n    endpoint = aiplatform.Endpoint.create(\n        display_name=display_name,\n        project=project,\n        location=location,\n    )\n    print(endpoint.display_name)\n    print(endpoint.resource_name)\n    return endpoint\n```", "```py\ngcloud ai endpoints list \\\n  --region=LOCATION \\\n  --filter=display_name=ENDPOINT_NAME\n```", "```py\ndef deploy_model_with_dedicated_resources_sample(\n    project,\n    location,\n    model_name: str,\n    machine_type: str,\n    endpoint: Optional[aiplatform.Endpoint] = None,\n    deployed_model_display_name: Optional[str] = None,\n    traffic_percentage: Optional[int] = 0,\n    traffic_split: Optional[Dict[str, int]] = None,\n    min_replica_count: int = 1,\n    max_replica_count: int = 1,\n    accelerator_type: Optional[str] = None,\n    accelerator_count: Optional[int] = None,\n    explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n    explanation_parameters: Optional[explain.ExplanationParameters] = None,\n    metadata: Optional[Sequence[Tuple[str, str]]] = (),\n    sync: bool = True,\n):\n```", "```py\n    aiplatform.init(project=project, location=location)\n    model = aiplatform.Model(model_name=model_name)\n    model.deploy(\n        endpoint=endpoint, deployed_model_display_name=deployed_model_display_name,\n        traffic_percentage=traffic_percentage,\n        traffic_split=traffic_split,\n        machine_type=machine_type,\n        min_replica_count=min_replica_count,\n        max_replica_count=max_replica_count,\n        accelerator_type=accelerator_type,\n        accelerator_count=accelerator_count,\n        explanation_metadata=explanation_metadata,\n        explanation_parameters=explanation_parameters,\n        metadata=metadata,\n        sync=sync,\n    )\n    model.wait()\n    print(model.display_name)\n    print(model.resource_name)\n    return model\n```", "```py\ndef endpoint_predict_sample(\n    project: str, location: str, instances: list, endpoint: str\n):\n    aiplatform.init(project=project, location=location)\n    endpoint = aiplatform.Endpoint(endpoint)\n    prediction = endpoint.predict(instances=instances)\n    print(prediction)\n    return prediction\n```", "```py\n{\n  \"instances\": [\n    [0.0, 1.1, 2.2],\n    [3.3, 4.4, 5.5],\n    ...\n  ]\n}\n```", "```py\n{\n  \"predictions\": [\n    {\n      \"label\": \"tree\",\n      \"scores\": [0.2, 0.8]\n    },\n    {\n      \"label\": \"bike\",\n      \"scores\": [0.85, 0.15]\n    }\n  ],\n  \"deployedModelId\": 123456789012345678\n}\n```", "```py\n{\"error\": \"Divide by zero\"}\n```", "```py\n{\"instances\": [\n    { \"b64\": \"b64EncodedASCIIString\" },\n    { \"b64\": \"b64EncodedASCIIString\" }\n  ]}\n```", "```py\ndef create_batch_prediction_job_dedicated_resources_sample(\n    project: str,\n    location: str,\n    model_resource_name: str,\n    job_display_name: str,\n    gcs_source: Union[str, Sequence[str]],\n    gcs_destination: str,\n    instances_format: str = \"jsonl\",\n    machine_type: str = \"n1-standard-2\",\n    accelerator_count: int = 1,\n    accelerator_type: Union[str, aiplatform_v1.AcceleratorType] = \"NVIDIA_TESLA_K80\",\n    starting_replica_count: int = 1,\n    max_replica_count: int = 1,\n    sync: bool = True,\n):\n```", "```py\n    aiplatform.init(project=project, location=location)\n    my_model = aiplatform.Model(model_resource_name)\n    batch_prediction_job = my_model.batch_predict(\n        job_display_name=job_display_name,\n        gcs_source=gcs_source,\n        gcs_destination_prefix=gcs_destination,\n        instances_format=instances_format,\n        machine_type=machine_type,\n        accelerator_count=accelerator_count,\n        accelerator_type=accelerator_type,\n        starting_replica_count=starting_replica_count,\n        max_replica_count=max_replica_count,\n        sync=sync,\n    )\n    batch_prediction_job.wait()\n    print(batch_prediction_job.display_name)\n    print(batch_prediction_job.resource_name)\n    print(batch_prediction_job.state)\n    return batch_prediction_job\n```", "```py\n{ \"instance\": [1, 2, 3, 4], \"prediction\": [0.1,0.9]}\n{ \"instance\": [5, 6, 7, 8], \"prediction\": [0.7,0.3]}\n```"]