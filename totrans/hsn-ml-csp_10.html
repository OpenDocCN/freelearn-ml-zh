<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Deep Belief â€“ Deep Networks and Dreaming</h1>
                </header>
            
            <article>
                
<p>We've all heard of deep learning, but how many of us know what a <strong>Deep Belief Network</strong> is? Let's start this chapter by answering that very question. A Deep Belief Network is a very advanced form of machine learning, one whose meaning is rapidly evolving. As a machine learning developer, it's important that you have a bit of exposure to this concept so that you are familiar with it when you encounter it or it encounters you!</p>
<p>In machine learning, a Deep Belief Network is technically a deep neural network. We should state that the meaning of <strong>deep</strong>, when it comes to deep learning or deep belief, means that the network is composed of multiple layers (hidden units). In a Deep Belief Network, these connections span internally between each neuron within a layer, but not between different layers. A Deep Belief Network can be trained to learn unsupervised in order to probabilistically reconstruct the network's inputs. The layers then function as 'feature detectors' to recognize or classify images, letters, and so on. You can also watch a Deep Belief Network dream, which is a very interesting topic in and of itself.</p>
<p>In this chapter we will cover:</p>
<ul>
<li>Restricted Boltzmann Machines</li>
<li>Creating and training a Deep Belief Network in C#</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Restricted Boltzmann Machines</h1>
                </header>
            
            <article>
                
<p>One popular method of constructing a Deep Belief Network is to comprise it as a layered collection of <strong>Restricted Boltzmann Machines</strong> (<strong>RBMs</strong>). These RMBs function as auto-encoders, with each hidden layer, serving as the visible layer for the next. This composition leads to a fast, layer-by-layer and unsupervised training procedure. The Deep Belief Network will have layers of RBMs for the pre-train phase, and then a feedforward network for the fine-tune phase. The first step of the training will be to learn a layer of features from the visible units. The next step is to take the activations from the previously trained features and make them the new visible units. We then repeat the process so that we can learn more features in the second hidden layer. The process then continues for all hidden layers.</p>
<p>We should provide two notes of information here.</p>
<p>First, we should explain a bit about what an auto-encoder is and does. Auto-encoders are at the heart of what is known as <strong>representational learning</strong>. They encode input, which is usually compressed vectors of significant features, as well as data for reconstructing via unsupervised learning.</p>
<p>Second, we should note that stacking RBMs within a Deep Belief Network is but one way to approach this. Stacking Restricted Linear Units (ReLUs) with dropout and training, and then accompanying that with backpropagation, has once again become state of the art. I say once again because 30 years ago, the supervised approach was the way to go. Rather than let the algorithm look at all the data and determine the feature of interest, sometimes we as humans can actually better find the feature we want.</p>
<p>What I would consider the two most significant properties of Deep Belief Networks are as follows:</p>
<ul>
<li>There is an efficient, layer-by-layer process for learning top-down, generative weights. It determines how variables in one layer depend on variables in the layers above it.</li>
<li>After the learning is complete, the values of the variables in every layer can easily be inferred by a single, bottom-up pass which starts with an observed data vector in the bottom layer and uses the generative weights in reverse direction to reconstruct the data.</li>
</ul>
<p>With that said, let's now talk about RBMs as well as Boltzmann machines in general.</p>
<p>A Boltzmann machine is a recurrent neural network with binary units and undirected edges between these units. For those of you who weren't paying attention in your graph theory class, undirected means the edges (or links) are bidirectional, they are not pointing in any specific direction. For those not experienced in graph theory, the following is a diagram of an undirected graph with undirected edges:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f6107d56-83c7-438d-9796-8d0d9372a8d7.png" style=""/></div>
<p>Boltzmann machines were one of the first neural networks capable of learning internal representations, and given enough time, they can solve difficult problems. They are, however, not good at scaling, which leads us to our next topic, RBMs.</p>
<p>RBMs were introduced to deal with the Boltzmann Machines' inability to scale. They have hidden layers, with connections restricted between each hidden unit but not outside those units, which helps with efficient learning. More formally, we must dive into a little bit of graph theory to properly explain this.</p>
<p>RBMs must have their neurons form what is known as a <strong>bipartite graph</strong>, a more advanced form of graph theory; a pair of nodes from each of the two groups of units (visible and hidden layers) may have a symmetric connection between them. There can be no connections between the nodes within any group. A bipartite graph, sometimes called a <strong>biograph</strong>, is a set of graph vertices decomposed into two disjoint sets such that no two vertices within the same set are adjacent.</p>
<p>Here is a good example that will help visualize this topic.</p>
<div class="packt_tip CDPAlignLeft CDPAlign">Note that there are no connections within the same set (red on the left or black on the right), but there are connections between the two sets:<br/>
<br/>
<img src="assets/1f5eb229-6889-43c9-858a-889d54e19878.png" style="width:12.83em;height:10.83em;"/></div>
<p>More formally, an RBM is what is known as a <strong>symmetrical bipartite graph<em>.</em></strong> This is because inputs from all visible nodes are passed to all hidden nodes. We say symmetrical because each visible node relates to a hidden node; bipartite because there are two layers; and graph because, well, it's a graph, or a collection of nodes if you prefer!</p>
<p>Imagine for a second that our RBM is presented images of cats and dogs, and we have two output nodes, one for each animal. On our forward learning pass, our RBM asks itself "<em>With the pixels I am seeing, should I send stronger weight signals for the cat or for the dog?</em>" On the backward pass, it wonders "<em>Being a dog, which distribution of pixels should I see?</em>" That, my friends, was today's lesson on joint probability: the simultaneous probability of <em>X</em> given <em>A</em> and <em>A</em> given <em>X</em>. In our case, this joint probability is expressed as the weights between the two layers and is an important aspect of RBMs.</p>
<p>With today's mini lessons in joint probability and graph theory behind us, we'll now talk about <strong>reconstruction</strong>, which is an important piece of what RBMs do. In the example we have been discussing, we are learning which groups of pixels occur (meaning being <em>on</em>) for a set of images. When a hidden layer node is activated by a significant weight (whatever that is determined to be to turn it <em>on</em>), it represents co-occurrences of something happening, in our case, the dog or the cat. Pointy ears + round face + small eyes might be what we are looking for if the image is a cat. Big ears + long tail + big nose may make the image a dog. These activations represent what our RBM "thinks" the original data looks like. For all intents and purposes, we are in fact reconstructing the original data.</p>
<p>We should also quickly point out that an RBM has two biases instead of one. This is very important as this is what distinguishes it from other auto-encoding algorithms. The hidden bias helps our RBM produce the activations we need when it's on the forward pass, and the visible layer bias helps learn the correct reconstructions on the backward pass. The hidden bias is important because its main job is to ensure that some of the nodes fire no matter how sparse our data might be. You will see how this impacts the way a Deep Belief Network dreams a little later on.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Layering</h1>
                </header>
            
            <article>
                
<p>Once our RBM learns the structure of the input data, which is related to the activations made in our first hidden layer, the data gets passed down to the next hidden layer. The first hidden layer then becomes the new visible layer. The activations we created in the hidden layer now become our inputs. They will be multiplied by the weights in the new hidden layer to produce another set of activations. This process continues through all the hidden layers in our network. The hidden layer becomes the visible layer, we have another hidden layer whose weights we will use, and we repeat. Each new hidden layer results in adjusted weights, until we get to the point where we can recognize the input from the previous layer.</p>
<p>To elaborate just a bit more (helping you in your quest to remain buzzword-compliant), this is technically called <strong>unsupervised, greedy, layer-wise training</strong>. No input is required to improve the weights of each layer, which means no outside influence of any type is involved. This further means we should be able to use our algorithm to train on unsupervised data that has <span>not been seen </span>previously. As we have continually stressed, <em>the more the data we have, the better our results</em>! As each layer gets better and hopefully more accurate, we are in a much better position to increase our learning through each hidden layer, with the weights having the responsibility of guiding us to the correct image classification along the way.</p>
<p>But as we discuss reconstruction, we should point out that each time a number (weight) in our reconstruction effort is non-zero, that is an indication that our RBM has learned something from the data. In a sense, you can treat the returned numbers exactly as you would <span>treat </span>a percentage indicator. The higher the number, the more confident the algorithm is of what it is seeing. Remember, we have the master dataset that we are trying to get back to, and we have a reference dataset to use in our reconstruction efforts. As our RBM iterates over each image, it doesn't yet know what image it is dealing with; that's what it is trying to determine.</p>
<p>Let's take a brief moment to clarify something. When we say we are using a greedy algorithm, what we really mean is that our RBM will take the shortest path to achieve the best result. We will sample random pixels from the image we see, and test which ones lead us to the correct answer. The RBM will test each hypothesis against the master dataset (test set), which is our correct end goal. Keep in mind that each image is just a set of pixels we're trying to classify. Those pixels house features and characteristics of data. For example, a pixel can have different shades of light, wherein dark pixels perhaps indicate borders, light pixels perhaps indicate numbers, and so forth.</p>
<p>But what happens when things don't go our way? What happens if whatever we learn at any given step is not correct? Should this occur, it would mean that our algorithm has guessed incorrectly. Our course of action is then to go back and try again. This is not as bad, nor as time-consuming, as it may seem. Of course, there is a temporal cost associated with an incorrect hypothesis, but the end goal is that we must increase our learning efficiency and reduce our error with each stage. Each weighted connection that was wrong will be penalized like what we did in reinforcement learning. These connections will decrease in weight and no longer be as strong. Hopefully, the next pass through will increase our accuracy while decreasing our error, and the stronger the weight, the more the influence it will have.</p>
<p>So, let's take a hypothetical scenario and think aloud for a second. Let's say we are classifying numeric images, meaning numbers. Some images will have curves, such as 2, 3, 6, 8, 9, and so on. Other numbers, such as 1, 4 and 7, will not. Knowledge such as this is very important, because our RBM, will use it to continue to improve its learning and reduce error. If we think we're dealing with the number 2, then the weights to the path that indicate this to us will be more heavily weighted than others. This is a drastic oversimplification, but hopefully it's enough to help you understand what we are about to embark upon.</p>
<p>As we put all this together, we now have the theoretical framework for a Deep Belief Network. Although we have delved into more theory than other chapters, as you see our example program working, it will all start to make sense. And you will be much better prepared to use it in your applications, knowing what's happening behind the scenes. Remember, black hole versus black box!</p>
<p>To show you about both Deep Belief Networks and RBMs, we are going to use the fantastic open source software SharpRBM written by Mattia Fagerlund. This software is an incredible contribution to the open source community, and I have no doubt you will spend hours, if not days, working with it. This software comes with some very incredible demos. For this chapter, we will use the Letter Classification Demo.</p>
<p>The following screenshot is of our deep belief test application. Ever wonder what a computer dreams of when it's sleeping? Well my friend, you are about to find out!</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/96b442c2-cc23-40d2-804b-93be033833d3.png"/></div>
<p>As usual, we will also use ReflectInsight to provide us with a behind-the-scenes look into what is going on:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f78e506e-9303-4f84-9db3-2439e859a16e.png" style=""/></div>
<p>The first thing you will notice about our demo application is that there is a lot going on. Let's take a moment and break it down into smaller chunks.</p>
<p>In the upper-left corner of the program screen is the area where we designate the layer that we want to train. We have three hidden layers, all of which need proper training before testing. We can train each layer one at a time, starting with the first layer. You may train for as long or as little as you like, but the more you train, the better your system will be:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6f26651d-7b4a-4ae7-af21-aa68a286482a.png" style=""/></div>
<p>The next section following our training options is our progress. As we are training, all pertinent information, such as generation, reconstruction error, detector error, and learning rate, is displayed here:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2d0b445f-cde3-4a56-9a75-476a9d084326.png" style=""/></div>
<p>The next section is the drawing of our feature detectors, which will update themselves throughout training if the <span class="packt_screen">Draw</span> checkbox is checked:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2ee0d8b4-17bd-45f1-ae42-f1e12880e9bf.png"/></div>
<p>As you begin training a layer, you will notice that the reconstructions and feature detectors are basically empty. They will refine themselves as your training progresses. Remember, we are reconstructing what we already know to be true! As the training continues, the reconstructed digits become more and more defined, along with our feature detector:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/91cb9918-4fc0-4c6b-bab7-86cd979531fc.png"/></div>
<p>Here is a snapshot from the application during training. As you can see, it is on generation 31 and the reconstructed digits are very well defined. They are still not complete or correct, but you can see just how much progress we are making:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/262f7890-b936-4657-98c7-a676cdcb747f.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What does a computer dream?</h1>
                </header>
            
            <article>
                
<p><em>What does a computer dream when it dreams</em>? is a famous saying. The intuition for us will be a feature which allows us to see what the computer is thinking during its reconstruction phase. As the program is trying to reconstruct our digits, the feature detectors themselves will take various forms throughout the process. It is these forms that we display in the dream window (indicated by the red circle):</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/031211f7-91d7-49ca-b5fa-b747c14b9516.png"/></div>
<p>Well, we have spent quite a bit of time looking at screenshots of our application. I think it's time that we now look at the code. Let's start by looking at how we create the <kbd>DeepBeliefNetwork</kbd> object itself:</p>
<pre>DeepBeliefNetwork = new DeepBeliefNetwork(28 * 29, 500, 500, 1000);</pre>
<p>Once this is created, we need to create our network trainer, and we do this based on the weights from the layer that we are training:</p>
<pre class="mce-root">DeepBeliefNetworkTrainer trainer = new<br/>  DeepBeliefNetworkTrainer(DeepBeliefNetwork,<br/>  DeepBeliefNetwork?.LayerWeights?[layerId], inputs);</pre>
<p>Both of these objects are used within our main <kbd>TrainNetwork</kbd> loop, the part of our application where most of the activity happens. This loop will continue until told to stop.</p>
<pre>private void TrainNetwork(DeepBeliefNetworkTrainer trainer)<br/>         {<br/>             try<br/>             {<br/>                 Stopping = false;<br/>                 ClearBoxes();<br/>                 _unsavedChanges = true;<br/>                 int generation = 0;<br/> <br/>                 SetThreadExecutionState(EXECUTION_STATE.ES_CONTINUOUS<br/>                   | EXECUTION_STATE.ES_SYSTEM_REQUIRED);<br/> <br/>                 while (Stopping == false)<br/>                 {<br/>                     Stopwatch stopwatch = Stopwatch.StartNew();<br/>                     <strong>TrainingError error = trainer?.Train();</strong><br/>                     label1.Text = string.Format(<br/>                         "Gen {0} ({4:0.00} s): ReconstructionError=<br/>                           {1:0.00}, DetectorError={2:0.00},<br/>                           LearningRate={3:0.0000}",<br/>                         generation, error.ReconstructionError,<br/>                         error.FeatureDetectorError,<br/>                         trainer.TrainingWeights.AdjustedLearningRate,<br/>                           stopwatch.ElapsedMilliseconds / 1000.0);<br/> <br/>                     Application.DoEvents();<br/>                     ShowReconstructed(trainer);<br/>                     ShowFeatureDetectors(trainer);<br/>                     Application.DoEvents();<br/> <br/>                     if (Stopping)<br/>                     {<br/>                         break;<br/>                     }<br/>                     generation++;<br/>                 }<br/>                 DocumentDeepBeliefNetwork();<br/>             }<br/>             finally<br/>             {<br/>                 SetThreadExecutionState(EXECUTION_STATE.ES_CONTINUOUS);<br/>             }<br/>         }</pre>
<div class="CDPAlignCenter CDPAlign"/>
<p>In the preceding code, we highlighted the <kbd>trainer.Train()</kbd> function, which is an array-based learning algorithm that looks like this:</p>
<pre> public TrainingError Train()<br/>         {<br/>             TrainingError trainingError = null;<br/>             if (_weights != null)<br/>             {<br/>                 ClearDetectorErrors(_weights.LowerLayerSize,<br/>                  _weights.UpperLayerSize);<br/> <br/>                 float reconstructionError = 0;<br/> <br/>                <strong> ParallelFor(MultiThreaded, 0, _testCount,</strong><br/><strong>                     testCase =&gt;</strong><br/><strong>                     {</strong><br/><strong>                         float errorPart = </strong><br/><strong>                           TrainOnSingleCase(_rawTestCases, </strong><br/><strong>                           _weights?.Weights, _detectorError,</strong><br/><strong>                             testCase, _weights.LowerLayerSize, </strong><br/><strong>                             _weights.UpperLayerSize, _testCount);</strong><br/> <br/><strong>                         lock (_locks?[testCase % </strong><br/><strong>                         _weights.LowerLayerSize])</strong><br/><strong>                         {</strong><br/><strong>                             reconstructionError += errorPart;</strong><br/><strong>                         }</strong><br/><strong>                     });</strong><br/> <br/>                 float epsilon = <br/>                 _weights.GetAdjustedAndScaledTrainingRate(_testCount);<br/>                 UpdateWeights(_weights.Weights, <br/>                   _weights.LowerLayerSize, _weights.UpperLayerSize, <br/>                   _detectorError, epsilon);<br/>                 trainingError = new <br/>                   TrainingError(_detectorError.Sum(val =&gt; <br/>                   Math.Abs(val)), reconstructionError);<br/>                   _weights?.RegisterLastTrainingError(trainingError);<br/>                 return trainingError;<br/>             }<br/>             return trainingError;<br/>         }</pre>
<p>This code uses parallel processing (highlighted section) to train single cases in parallel. This function is responsible for handling the changing of input and hidden layers, as we discussed at the beginning of the chapter. It uses the <span><kbd>TrainOnSingleCase</kbd> </span>function, which looks like this:</p>
<pre>private float TrainOnSingleCase(float[] rawTestCases, float[] weights, float[] detectorErrors, int testCase,<br/>             int lowerCount, int upperCount, int testCaseCount)<br/>         {<br/>             float[] model = new float[upperCount];<br/>             float[] reconstructed = new float[lowerCount];<br/>             float[] reconstructedModel = new float[upperCount];<br/>             int rawTestCaseOffset = testCase * lowerCount;<br/> <br/>             ActivateLowerToUpperBinary(rawTestCases, lowerCount, <br/>               rawTestCaseOffset, model, upperCount, weights); // Model<br/>             ActivateUpperToLower(reconstructed, lowerCount, model,<br/>               upperCount, weights); // Reconstruction<br/>             ActivateLowerToUpper(reconstructed, lowerCount, 0,<br/>             reconstructedModel, upperCount, weights); // <br/>             Reconstruction model<br/>             return AccumulateErrors(rawTestCases, lowerCount, <br/>             rawTestCaseOffset, model, upperCount, reconstructed,<br/>                 reconstructedModel, detectorErrors); // Accumulate <br/>                  detector errors<br/>         }</pre>
<p>Finally, we accumulate the errors during processing, which is the difference between what our model should believe and what it actually does. Obviously, the lower the error rate the better, for the most accurate reconstruction of our images. The <kbd>AccumulateErrors</kbd> function is shown here:</p>
<pre>private float AccumulateErrors(float[] rawTestCases, int lowerCount, int rawTestCaseOffset, float[] model,<br/>             int upperCount, float[] reconstructed, float[] reconstructedModel, float[] detectorErrors)<br/>         {<br/>             float reconstructedError = 0;<br/>             float[] errorRow = new float[upperCount];<br/> <br/>             for (int lower = 0; lower &lt; lowerCount; lower++)<br/>             {<br/>                 int errorOffset = upperCount * lower;<br/>                 for (int upper = 0; upper &lt; upperCount; upper++)<br/>                 {<br/>                     errorRow[upper] = rawTestCases[rawTestCaseOffset + <br/>                       lower] * model[upper] + <br/>                       // What the model should believe in<br/>                         -reconstructed[lower] * <br/>                           reconstructedModel[upper]; <br/>                           // What the model actually believes in<br/>                 }<br/> <br/>                 lock (_locks[lower])<br/>                 {<br/>                     for (int upper = 0; upper &lt; upperCount; upper++)<br/>                     {<br/>                         detectorErrors[errorOffset + upper] -= <br/>                           errorRow[upper];<br/>                     }<br/>                 }<br/> <br/>                 reconstructedError += <br/>                   Math.Abs(rawTestCases[rawTestCaseOffset + lower] - <br/>                   reconstructed[lower]);<br/>             }<br/> <br/>             return reconstructedError;<br/>         }</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Well folks, there you have it! In this chapter, you learned about RBMs, a little bit of graph theory, and how to create and train a Deep Belief Network in C#. Your buzzword-compliant checklist is almost complete! I recommend that you experiment with the code, train your network layers to different thresholds, and watch how your computer dreams while reconstructing. Remember, the more you train the better, so spend time with each layer to ensure it has enough data to do an accurate job of reconstruction.</p>
<p>A quick note of warning: if you enable drawing of your feature detectors and reconstructed inputs, you will notice a huge decrease in performance. If you are trying to train your layers, you may wish to train them without visualizations first in order to reduce the time required. Trust me, with visualizations it will feel like an eternity if you train each level to a high iteration! Feel free to continually save your network as you progress. Good luck, and happy dreaming!</p>
<p>In the next chapter, we will learn about micro benchmarking and get to use one of the most powerful open source micro benchmarking toolkit ever written!<em><br/></em></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">References</h1>
                </header>
            
            <article>
                
<ul>
<li>Mattias Fagerlund:<span> </span><a href="https://lotsacode.wordpress.com/2010/09/14/sharprbm-restricted-boltzmann-machines-in-c-net/#comments">https://lotsacode.wordpress.com/2010/09/14/sharprbm-restricted-boltzmann-machines-in-c-net/#comments</a></li>
<li>Nykamp DQ, <em>Undirected graph definition</em>, from<span> </span><em>Math Insight</em>:<span> </span><a href="http://mathinsight.org/definition/undirected_graph">http://mathinsight.org/definition/undirected_graph</a></li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>