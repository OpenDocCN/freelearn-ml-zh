- en: Encyclopedias and Neurons – Traveling Salesman Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we are going to solve one of the most famous of all problems
    for machine learners. We will also dive into the world of graph theory (just a
    bit) as well as neural network neurons. Let's start off by explaining the traveling
    salesman problem, shall we?
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Traveling salesman problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning rate parameter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traveling salesman problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have a salesman who must travel between *n* cities. He doesn't care about
    which order this happens in, nor which city he visits first or last. His only
    concern is that he visits each city only once and finishes at home, where he started.
  prefs: []
  type: TYPE_NORMAL
- en: Each city is a node, and each node is connected to other close nodes by an edge
    (think of it like a road, plane, train, car, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: Now, each of those connections has one or more weights associated with it, which
    we will call the **cost**.
  prefs: []
  type: TYPE_NORMAL
- en: The cost describes the difficulty of travel along that connection, such as the
    cost of the plane ticket, the amount of gas the car needs, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Our salesman has a boss as we met in [Chapter 1](7a1f2cca-1be5-426a-8e8a-6a4a3828cd76.xhtml),
    *Machine Learning Basics*, so his marching orders are to keep the cost and distance
    he travels as low as possible.
  prefs: []
  type: TYPE_NORMAL
- en: '*How does this apply to me in real life?* you may ask. This problem actually
    has several applications in real life such as'
  prefs: []
  type: TYPE_NORMAL
- en: The design and creation of circuit boards for your computer. With millions of
    transistors, the circuit board needs to be drilled and created precisely.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also appears as a subproblem in DNA sequencing, which has become a big part
    of machine learning for many people.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For those that have taken up or are familiar with graph theory, you hopefully
    remember the undirected weighted graph. That is exactly what we are dealing with
    here. The cities are vertices, the paths are edges, and the path distance is the
    edge weight. Never thought you'd use that knowledge again, did you? In essence,
    we have a minimization problem of starting and finishing at a specific vertex
    after having visited every other vertex just once. We may, in fact, end up with
    a complete graph when we are done, where each pair of vertices is connected by
    an edge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we must talk about asymmetry and symmetry, because this problem may end
    up being either. What do we mean exactly? Well, we have either an asymmetric traveling
    salesman problem or a symmetric traveling salesman problem. It all depends upon
    the distance between two cities. If the distances are the same in each direction,
    we have a symmetric traveling salesman problem, and the symmetry helps us have
    the possible solutions. If the paths do not exist in both directions, or if the
    distances are different, we have a directed graph. Here is a diagram showing the
    preceding description:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ea1158d-5dd6-46d9-927a-3243696efbf9.png)'
  prefs: []
  type: TYPE_IMG
- en: The traveling salesman problem can be symmetric or asymmetric. In this chapter,
    we are going to take you through the wonderful land of genetic algorithms. Let's
    start with an incredibly oversimplistic description of what's going to happen.
  prefs: []
  type: TYPE_NORMAL
- en: In the biology world, when we want to create a new genotype, we take a little
    bit from parent **A** and the rest from parent **B**. This is called crossover
    mutation, if you are updating your buzzword-compliant checklist! After this happens,
    these genotypes are perturbed, or altered, ever so slightly. This is called **mutation**
    (update that buzzword compliant list again), and this is how genetic material
    is created.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we delete the original generation, replaced by the new one, and each genotype
    is tested. The newer genotypes, being the better part of their previous components,
    will now be skewed towards higher fitness; on an average, this generation should
    score higher than its predecessor.
  prefs: []
  type: TYPE_NORMAL
- en: This process continues for many generations, and over time, the average fitness
    of the population will evolve and increase. This doesn't always work, as in real
    life, but generally speaking, it does.
  prefs: []
  type: TYPE_NORMAL
- en: With a seminar of genetic algorithmic programming behind us, let's dive into
    our application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s what our sample application looks like. It is based on the Accord.NET
    framework. After we''ve defined the number of houses we need to visit, we simply
    click on the Generate button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5852916c-ce94-4bba-adb9-ff2010210271.png)'
  prefs: []
  type: TYPE_IMG
- en: In our test application, we can change the number of houses that we want to
    visit very easily, as shown in the highlighted area.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could have a very simple problem space or a more complicated one. Here is
    an example of a very simple problem space:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/11f8c269-cfe9-4e8c-8c1a-30b2f450db74.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And here is an example of a more complicated problem space:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f22d22ab-aa44-4951-82b8-13f4631562b3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We also have three different types of selection methods for our algorithm to
    work with, namely Elite, Rank, and Roulette:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab140719-461c-4cf3-b830-d2be1935a592.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Elite: Specifies the number of best chromosomes to work within the next generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Roulette: Selects chromosomes based on their rank (fitness value).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rank: Selects chromosomes based on their rank (fitness value). This differs
    from the Roulette selection method in that the wheel and sector sizes are different
    within the calculation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we choose the total number of iterations we want our algorithm to
    use. We select the Calculate Route button, and, assuming all goes well, we''ll
    end up with our map looking similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b913e5cd-325a-4d20-a531-77f68c56c7de.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a look at what happens when we select the number of cities we want
    and then click on the Generate button:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first thing that we do is initialize our random number generator and seed
    it. Next, we get the total number of cities that the user specified, and then
    create a new array from that. Finally, we plot each point and update our map.
    The map is a chart control from Accord.NET that will take care of a lot of visual
    plotting for us.
  prefs: []
  type: TYPE_NORMAL
- en: With that done, we are ready to calculate our route and (hopefully) solve our
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s see what our main search solution looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s try and break all that down into more usable chunks for you. The first
    thing we do is determine the selection method that we''ll use to rank our chromosomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'I want to take this opportunity to point out the `TSPChromosome` you see here.
    This object is based on a short-array chromosome (one that is an array of unsigned
    short values ranging from 2 to 65,536\. There are two specific features:'
  prefs: []
  type: TYPE_NORMAL
- en: All genes are unique within the chromosome, meaning there are no two genes with
    the same value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum value of each gene is equal to the chromosome length minus 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we must create the path variable for us to fill in with our data points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'After this is complete, we can enter our `while` loop and begin our processing.
    To do that, we will process a single generation by running a single epoch. You
    can think of an epoch as an iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We then get the best values from that effort:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We update and create our path between each city:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'And we supply that value to our chart control:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Let's see some examples of what our route might look like based on the selection
    method that we choose.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Elite selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/97c489e9-78a5-4c48-b6c3-a16089603056.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Rank selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f3947c7-7cce-46f5-b247-12539e267f3c.png)'
  prefs: []
  type: TYPE_IMG
- en: The difference between this and the Roulette selection method is in the wheel
    and its sector size calculation methods. The size of the wheel equals *size *
    (size +1) / 2*, where *size* is the size of the current population. The worst
    chromosome has its sector size equal to 1, the next has a size of 2, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Roulette selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9f9e0630-f82a-4842-a908-bf94bb5fbcb1.png)'
  prefs: []
  type: TYPE_IMG
- en: This algorithm selects chromosomes of the new generation according to their
    fitness values. The higher the value, the greater the chances of it becoming a
    member of the new generation.
  prefs: []
  type: TYPE_NORMAL
- en: What you will notice as you generate your routes is that the Elite method finds
    its solution right away. The Rank method continues refining its route throughout
    the iterations, and the Roulette method refines its routes even more.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate what I mean, define a huge load for your salesman today. Let's
    say he has 200 houses to visit, as we need to sell a lot of encyclopedias today.
    This is where the beauty of our algorithm shines. It's easy to create the optimal
    map and route if we are dealing with five houses. But if we are dealing with 200
    houses, not so much!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67bf4408-40f4-424e-824c-84f4a98aca18.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we've solved our problem, let's see if we can apply what we learned
    from our earlier chapter about **self-organizing maps** (**SOM**) here to approach
    this problem from a different angle. If you recall, back in [Chapter 6](01438011-1511-48a3-af59-1d6451a3128e.xhtml),
    *Color Blending – Self-Organizing Maps and Elastic Neural Networks*, we discussed
    SOM in general. So we'll preclude the academia from happening here! We're going
    to use a technique called Elastic Network Training, which is a great unsupervised
    approach to such a problem as we have here.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d7c46099-1bea-474c-ba05-f411d6e93957.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's first talk briefly about what an **Elastic Map** is. Elastic Maps provide
    a tool for creating nonlinear dimensionality reduction. They are a system of elastic
    springs in our data space that approximate a low-dimensional manifold. With this
    capability, we can go from completely unstructured clustering (no elasticity)
    to a closer linear principal components analysis manifold for high bending/low
    stretching of the springs. You'll see when using our sample application that the
    lines are not necessarily as rigid as they were in our previous solution. And
    in many cases, they may not even get into the center of the city we are visiting
    (the line generates off the center) but approach only the outskirts of the city
    limits, as in the preceding example!
  prefs: []
  type: TYPE_NORMAL
- en: Once again, we'll be dealing with neurons, one of my favorite objects of all.
    This time we'll have a bit more control though, by being able to specify our learning
    rate and radius. As with our previous example, we'll be able to specify the total
    number of cities our salesman must visit today. Let's go easier on him this time
    though!
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, we''ll visit 50 cities and use a learning rate of `0.3` and radius
    of `0.75`. Finally, we will run for 50,000 iterations (don''t worry; this will
    go fast). Our output will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/41121417-820a-4800-87e1-686bd0f6d353.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, what happens if we change our radius to a different value, say, 0.25?
    Note how our angles between some cities become more pronounced:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0b891719-fb9b-43b8-8b1d-fbe52275dafe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, let''s change our learning rate from 0.3 to 0.75:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/35e19e73-4025-40fc-8e21-82c8d0c333af.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Even though our route looks very similar in the end, there is one important
    difference. In the previous example, the route path for our salesman was not drawn
    until all the iterations were complete. By raising the learning rate, the route
    gets drawn several times before the perfect route is complete. Here are some images
    showing the progression:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/785cc6e2-d233-47ce-9176-2a1edf306085.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here we are at iteration 5777 of our solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/08874e3a-19a4-4bdc-b944-43b3bfc5abc9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This shows how our solution looks at iteration 44636:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09a4e84c-51e5-479f-b3dc-7289dd36ce4f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This one shows how our solution looks at iteration 34299:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7dc9b79e-c1b5-48a1-b58f-3b9da4438abb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s look into a small bit of code to see how our search solution differs
    this time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The first thing you see that we've done is creating a `DistanceNetwork` object.
    This object contains only a single `DistanceLayer`, which is a single layer of
    distance neurons. A distance neuron computes its output as the distance between
    its weights and inputs—the sum of absolute differences between the weight values
    and input values. All of this together makes up our SOM and, more importantly,
    our Elastic Network.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we have to initialize our network with some random weights. We will do
    this by creating a **uniform continuous distribution** for each neuron. A uniform
    continuous distribution, or rectangular distribution, is a symmetric probability
    distribution such that, for each member of the family, all intervals of the same
    length on the distribution's support have the same probability. You will usually
    see this written out as U(*a*, *b*), with parameters *a* and *b* being the minimum
    and maximum values respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create our elastic learner object, which allows us to train our distance
    network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s what the `ElasticNetworkLearning` constructor looks like internally:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/945ba172-7ba3-4692-8100-e0f4148b24b7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we calculate our learning rate and radius:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we are in our central processing loop, where we will remain until
    told to stop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding loop, the trainer is running one epoch (iteration) per loop
    increment. Here''s what the `trainer.Run` function looks like, so you can see
    what''s happening. Basically, the method finds the winning neuron (the one that
    has the weights with values closest to the specified input vector). It then updates
    its weights as well as the weights of the neighboring neurons:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The two main functions of this method that we will look deeper into are computing
    the network and obtaining the winner (highlighted items).
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we compute the network? Basically, we work ourselves down through the
    distance layer and into each neuron in order to update the weights correctly,
    similar to what you see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need to compute the winner, the neuron with the minimum weight
    and therefore the minimum distance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Let's talk briefly about the parameters you can enter on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: Learning rate parameter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The learning rate is a parameter that determines the speed of learning. More
    formally, it determines how much we are adjusting the weights of our network with
    respect to the loss gradient. If it is too low, we travel slower down our slope.
    Even though we desire to have a low learning rate, it could mean that we'll be
    taking a long time to reach convergence. The learning rate also affects how quickly
    our model can converge tolocal minima (best accuracy).
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with neurons, it determines the acquisition time (the amount of
    time it takes for a response to a new experience to be learned) for neurons with
    weights being used for training.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0dd70be0-c08f-44a6-8af2-60d03935a5d8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Effect of various learning rates on convergence (image credit: [cs231n](http://cs231n.github.io/neural-networks-3/))'
  prefs: []
  type: TYPE_NORMAL
- en: Learning radius
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The learning radius determines the number of neurons to be updated around the
    winning neuron. Any neuron that is in the circle of the radius will be updated
    during the learning process. The closer the neuron, the more updates that are
    happening. The farther away, the fewer.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we learned about neurons, which is an incredibly fascinating
    branch of research, focused on heavily for several years. We also learned about
    the famous traveling salesman problem, what it is, and how we can solve it with
    a computer. This little example has wide-reaching applications in the real world.
    In our next chapter, we are going to put all this neural knowledge we have gained
    and apply it to **Restricted Boltzmann Machines** (**RBM**) with a **Deep Belief
    Network** (**DBN**). This chapter will be sure to add a lot of terminology to
    your buzzword-compliant checklist! In the next chapter, we will answer the question
    that we all, as developers, face: *Should I take the job?*'
  prefs: []
  type: TYPE_NORMAL
