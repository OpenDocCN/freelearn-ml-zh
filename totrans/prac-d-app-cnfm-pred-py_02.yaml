- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview of Conformal Prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In today’s world, where data plays a crucial role in decision making, it has
    become increasingly important to measure uncertainty in predictions. To achieve
    this, a relatively new framework called **conformal p****rediction** is gaining
    popularity. This framework provides probabilistic predictions that are not only
    robust and reliable but also trustworthy. It is a powerful tool that offers measures
    of confidence, accuracy, and reliability for a given prediction, allowing users
    to make informed choices with more certainty.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will provide an overview of conformal prediction.
  prefs: []
  type: TYPE_NORMAL
- en: It will explain why conformal prediction is a valuable tool for quantifying
    the uncertainty of predictions, especially in critical settings such as healthcare,
    self-driving cars, and finance. We will also discuss the concept of **uncertainty
    quantification** (**UQ**) and how the conformal prediction framework has successfully
    addressed the challenge of quantifying uncertainty. By the end of this chapter,
    you will have a better understanding of conformal prediction and its potential
    applications in various fields.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding uncertainty quantification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different ways to quantify uncertainty
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantifying uncertainty using conformal prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding uncertainty quantification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Uncertainty is an inherent part of any prediction, as there are always factors
    that are unknown or difficult to measure. Predictions are typically made based
    on incomplete data or models that are unable to capture the full complexity of
    the real world. As a result, the predictions are subject to various sources of
    uncertainty, including randomness, bias, and model errors.
  prefs: []
  type: TYPE_NORMAL
- en: To mitigate the risks associated with uncertainty, it is essential to quantify
    it accurately. By quantifying uncertainty, we can estimate the range of possible
    outcomes and assess the degree of confidence we can have in our predictions. This
    information can be used to make informed decisions and to identify areas where
    further research or data collection is needed.
  prefs: []
  type: TYPE_NORMAL
- en: '**UQ** is a field of study that helps us measure how much we don’t know when
    we make predictions. UQ tries to estimate the probability of outcomes even if
    some aspects of the system under study are not known exactly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Uncertainty is often broken down into two types: **aleatoric** and **epistemic**.
    Aleatoric uncertainty is caused by the inherent randomness and unpredictability
    of the system being studied, while epistemic uncertainty arises from our lack
    of knowledge about the system.'
  prefs: []
  type: TYPE_NORMAL
- en: Aleatoric uncertainty
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Aleatoric uncertainty refers to the type of uncertainty that is caused by inherent
    randomness and unpredictability in a system. Here are a few examples of aleatoric
    uncertainty:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rolling a dice**: The outcome of rolling a dice is inherently random and
    unpredictable. You cannot predict with certainty what number will come up on the
    dice, so there is aleatoric uncertainty associated with this process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weather forecasting**: Weather is a complex system that is influenced by
    many factors, some of which are inherently random and difficult to predict. For
    example, the exact path and strength of a storm system may be difficult to predict
    due to aleatoric uncertainty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stock market fluctuations**: The stock market is a complex system that is
    influenced by many factors, including human behavior, economic conditions, and
    news events. Some of these factors are inherently unpredictable and may cause
    fluctuations in stock prices, leading to aleatoric uncertainty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traffic flow**: Traffic flow is a complex system that is influenced by many
    factors, including the number of vehicles on the road, road conditions, and driver
    behavior. The exact flow of traffic at any given time is difficult to predict
    with certainty, leading to aleatoric uncertainty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s cover epistemic uncertainty next.
  prefs: []
  type: TYPE_NORMAL
- en: Epistemic uncertainty
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Epistemic uncertainty refers to the type of uncertainty that arises from a
    lack of knowledge or understanding about a system. Here are a few examples of
    epistemic uncertainty:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Medical diagnosis**: Diagnosing a medical condition involves making predictions
    based on available data, such as symptoms, medical history, and test results.
    However, there may be epistemic uncertainty associated with the diagnosis if there
    is incomplete or unreliable data, or if the medical condition is not well understood.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Financial forecasting**: Predicting future economic conditions is a complex
    task that involves making predictions based on a wide range of factors, including
    interest rates, inflation, and political events. However, there is always epistemic
    uncertainty associated with these predictions due to our limited understanding
    of the economic system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Natural disaster prediction**: Predicting the likelihood and severity of
    natural disasters, such as earthquakes or hurricanes, involves making predictions
    based on data from past events and current environmental conditions. However,
    there may be epistemic uncertainty associated with these predictions if we do
    not have a complete understanding of the underlying physical processes involved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Illustration of aleatoric and epistemic uncertainty](img/B19925_02_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – Illustration of aleatoric and epistemic uncertainty
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram delineates two distinct point regions. The left region
    exhibits pronounced randomness, while the right region showcases a structured
    data pattern, evident from a straight line that can be drawn through its clustered
    points. The left cluster demonstrates high aleatoric uncertainty, in contrast
    to the low aleatoric uncertainty in the right cluster, attributed to its data
    regularities. Additionally, three areas manifesting high epistemic uncertainty
    correspond to the voids in data, indicating gaps in our understanding or knowledge
    of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move on to cover different ways to quantify uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Different ways to quantify uncertainty
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several different approaches to quantify uncertainty, each with its
    own strengths and limitations. Here are a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Statistical methods**: Statistical methods are widely used for UQ and involve
    using probability distributions to model the uncertainty in data and predictions.
    These methods are widely used in fields such as finance, engineering, and physics
    and involve tools such as confidence intervals, regression analysis, Monte Carlo
    simulations and hypothesis testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bayesian methods**: Bayesian methods involve using prior knowledge and data
    to update our beliefs about the uncertainty in predictions. These methods are
    widely used in machine learning, natural language processing, and image processing.
    Bayesian tools include Bayesian inference – statistical methods to update beliefs
    about the uncertainty of predictions based on new data – and Bayesian networks
    – graphical models that represent probability relationships between the variables
    that can be used to model various systems and calculate the probabilities of different
    outcomes. Bayesian tools also include **Markov Chain Monte Carlo** (**MCMC**)
    – a computational method used to sample from complex probability distributions
    – as well as Bayesian optimization – methods used to optimize a function that
    is expensive to evaluate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fuzzy logic methods**: Fuzzy logic involves using sets and membership functions
    to represent uncertainty in a system. This approach is widely used in control
    systems, robotics, and artificial intelligence. Fuzzy logic includes fuzzy sets
    – that is, sets that allow partial membership. Rather than a binary classification
    of an element as either a member or non-member of a set, fuzzy sets allow elements
    to have degrees of membership. This allows uncertainty to be represented in a
    more nuanced way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will now talk about quantifying uncertainty using conformal prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Quantifying uncertainty using conformal prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Quantifying the uncertainty of machine learning predictions is becoming increasingly
    important as machine learning is used more widely in critical applications such
    as healthcare, finance, and self-driving cars. In these applications, the consequences
    of incorrect predictions can be severe, making it essential to understand the
    uncertainty associated with each prediction.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in healthcare, machine learning models are used to make predictions
    about patient outcomes, such as the likelihood of a disease or the effectiveness
    of a treatment. These predictions can have a significant impact on patient care
    and treatment decisions. However, if the model is unable to produce an estimate
    of its own confidence, it may not be useful and could potentially be risky to
    rely upon.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, if the model can provide a measure of its own uncertainty, clinicians
    can use this information to make more informed decisions about patient care and
    treatment.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a situation where a doctor has obtained a patient’s MRI scan and has
    to deduce whether the patient has cancer. In this application, high accuracy is
    not enough, as the doctor’s diagnosis has to rule out (or not) a patient having
    such a critical, life-changing disease as cancer.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, in finance, machine learning models are used to make predictions
    about market trends, stock prices, and risk assessments. These predictions can
    have a significant impact on investment decisions and portfolio management. However,
    if the model is unable to produce an estimate of its own confidence, it may not
    be useful and could potentially lead to poor investment decisions. On the other
    hand, if the model can provide a measure of its own uncertainty, investors can
    use this information to make more informed decisions and reduce the risks associated
    with uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Quantifying uncertainty is a prerequisite for explainability and trust in machine
    learning models. If a model cannot provide an estimate of its own confidence,
    it may be difficult to explain why it made a certain prediction or to gain the
    trust of stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, if the model can provide a measure of its own uncertainty, stakeholders
    can better understand how the model arrived at its predictions and can have more
    confidence in the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction is a relatively new framework for quantifying uncertainty
    in predictions that offers several advantages over traditional statistical, Bayesian,
    and fuzzy logic methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some advantages of using conformal prediction for UQ:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Probabilistic predictions**: Conformal prediction provides probabilistic
    predictions that include measures of confidence, accuracy, and reliability for
    each prediction. This allows users to make informed choices and to estimate the
    range of possible outcomes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Coverage guarantees**: Unlike other methods, prediction regions generated
    by conformal prediction models (prediction sets for classification tasks/predictive
    intervals for regression tasks) come with rigorous statistical validity guarantees.
    This valuable information can be used to assess the reliability of the model,
    mitigate the risks, and identify areas where further research or data collection
    is needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-parametric**: Conformal prediction does not require assumptions about
    the underlying probability distributions, making it applicable to a wide range
    of problems and data types.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distribution agnostic**: Conformal prediction models work for any data distribution
    as long as exchangeability assumptions can be maintained. However, conformal prediction
    models have recently been extended to contexts where the exchangeability assumption
    is no longer met, including successful applications in time series forecasting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No restrictions on dataset size**: Unlike statistical and Bayesian models,
    conformal prediction models are not concerned with dataset size – the validity
    of predictions is maintained regardless of the size of the dataset. However, prediction
    intervals are usually narrower where there is a larger amount of data. This is
    due to the general pattern of machine learning models being able to learn more
    effectively from more data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Robustness**: Conformal prediction is robust to outliers and noisy data,
    making it particularly useful in settings where the data may be imperfect or incomplete.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wide application**: Conformal prediction has been successfully applied to
    a wide variety of problem classes, including classification, regression, time
    series and forecasting, computer vision, NLP, reinforcement learning, and much
    more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low computation cost**: Conformal prediction models, while offering very
    rigorous prediction regions for UQ, maintain computational efficiency and don’t
    heavily burden system resources, making them ideal for real-time applications
    and large datasets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In contrast to alternative approaches, conformal prediction offers robust and
    non-parametric probabilistic predictions with assured validity. This becomes especially
    beneficial in scenarios where analytical modeling of uncertainty is challenging
    and probabilistic predictions are needed for decision making.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction quantifies uncertainty by offering a probability measure
    that indicates the likelihood of a prediction being accurate. This uncertainty
    measure is rooted in the notion of validity, which denotes the expected ratio
    of correct predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In classification tasks, a machine learning model typically produces class scores
    and assigns the label with the highest score. However, this can pose issues when
    the prediction certainty is low.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following images from a *Gentle Introduction to Conformal Prediction
    and Distribution-Free Uncertainty* ([https://arxiv.org/abs/2107.07511](https://arxiv.org/abs/2107.07511))
    by Anastasios N. Angelopoulos and Stephen Bates. A trained deep learning model
    will output class scores for new images just like the three in the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that these three examples do not produce the same results.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Uncertainty in a classification problem](img/B19925_02_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Uncertainty in a classification problem
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The preceding figure is sourced from *Angelopoulos and Bates, 2023* (used with
    permission by the authors).
  prefs: []
  type: TYPE_NORMAL
- en: The left-hand picture is easy to predict – the model would have seen a lot of
    examples of squirrels and is rather certain about its prediction. As a result,
    the prediction set contains just one potential label – fox squirrel.
  prefs: []
  type: TYPE_NORMAL
- en: The middle picture has a medium level of uncertainty associated with it – while
    there are additional objects in the background, the model is still quite sure
    that it is most likely a fox squirrel. However, to hedge its predictions, the
    model now outputs additional labels such as *gray fox, bucket, and* *rain barrel*.
  prefs: []
  type: TYPE_NORMAL
- en: The picture on the right is the hardest to classify as there is a lot of uncertainty
    in the dataset; the head of the animal is partially occluded and the background
    is unusual. To account for this prediction uncertainty, the model has not only
    reduced the probability of the `fox squirrel` class but also introduced the possibility
    that the animal is in fact a marmot. In addition, the model has extended the prediction
    set by leaving open the possibility that this animal can in fact also be *a mink,
    weasel, beaver, or even* *a polecat*.
  prefs: []
  type: TYPE_NORMAL
- en: Note how the conformal prediction model extended the point prediction of the
    deep neural network as, instead of generating a point prediction, it produced
    a prediction set given the specified 95% confidence level. The prediction set
    produced by the conformal prediction model provides much more information to improve
    downstream decision making.
  prefs: []
  type: TYPE_NORMAL
- en: The conformal prediction framework is based on the idea of constructing a set
    of predictions that includes the true value with a certain degree of confidence.
    This set is known as a conformal prediction set and is constructed based on a
    set of training data.
  prefs: []
  type: TYPE_NORMAL
- en: To construct a conformal prediction set, the framework uses a non-conformity
    function that measures how well a prediction fits the training data.
  prefs: []
  type: TYPE_NORMAL
- en: The non-conformity measure is used to rank the predictions in order of how well
    they fit the training data. The most similar predictions are included in the conformal
    prediction set, along with a set of additional predictions that have a certain
    degree of confidence based on the non-conformity measure. By following this approach,
    the conformal prediction model can provide a measure of its own uncertainty. This
    allows both the modelers and the stakeholders to better understand how the model
    arrived at its predictions and can engender more confidence in the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have provided an overview of conformal prediction and explained
    why conformal prediction is a valuable tool for quantifying the uncertainty of
    predictions, especially in critical settings such as healthcare, self-driving
    cars, and finance. We also discussed the concept of UQ and how the conformal prediction
    framework has successfully addressed the challenge of quantifying uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive deeper into the fundamentals of conformal
    prediction and apply it to binary classification problems. We will illustrate
    how you can apply conformal prediction to your own binary classification problems
    by computing non conformity scores and p-values and then using the p-values to
    decide which class labels should be included in your prediction sets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 2: Conformal Prediction Framework'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part will explain the fundamentals of conformal prediction. You will learn
    about the types of conformal prediction models and the critical concepts of conformal
    prediction, including validity, efficiency, and non-conformity measures.
  prefs: []
  type: TYPE_NORMAL
- en: This section has the following chapters*:*
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B19925_03.xhtml#_idTextAnchor033)*, Fundamentals of Conformal
    Prediction*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B19925_04.xhtml#_idTextAnchor040)*, Validity and Efficiency of
    Conformal Prediction*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B19925_05.xhtml#_idTextAnchor046)*, Types of Conformal Predictors*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
