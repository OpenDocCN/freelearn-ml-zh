<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Fraud and Anomaly Detection</h1>
                </header>
            
            <article>
                
<p>Outlier detection is used to identify exceptions, rare events, and other anomalous situations. Such anomalies may be needles in a haystack, but their consequences can nonetheless be quite dramatic; for instance, credit card fraud detection, identifying network intrusions, faults in manufacturing processes, clinical trials, voting activities, and criminal activities in e-commerce. Therefore, anomalies represent a high value when they are found and high costs if they are not. Applying machine learning to outlier detection problems can bring new insights and better detection of outlier events. Machine learning can take into account many disparate sources of data, and can find correlations that are too obscure for human analysis to identify.</p>
<p>Take the example of e-commerce fraud detection. With machine learning algorithms in place, the purchaser's online behavior, that is, website browsing history, becomes a part of the fraud detection algorithm, rather than simply the history of purchases made by the cardholder. This involves analyzing a variety of data sources, but it is also a far more robust approach to e-commerce fraud detection.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Problems and challenges</li>
<li>Suspicious pattern detection</li>
<li>Anomalous pattern detection</li>
<li>Working with unbalanced datasets</li>
<li>Anomaly detection in time series</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Suspicious and anomalous behavior detection</h1>
                </header>
            
            <article>
                
<p>The problem of learning patterns from sensor data arises in many applications, including e-commerce, smart environments, video surveillance, network analysis, human-robot interaction, ambient assisted living, and so on. We focus on detecting patterns that deviate from regular behaviors and might represent a security risk, health problem, or any other abnormal behavior contingency.</p>
<p>In other words, deviant behavior is a data pattern that either does not conform to the expected behavior (anomalous behavior) or matches a previously defined unwanted behavior (suspicious behavior). Deviant behavior patterns are also referred to as outliers, exceptions, peculiarities, surprises, misuse, and so on. Such patterns occur relatively infrequently; however, when they do occur, their consequences can be quite dramatic, and often negatively so. Typical examples include credit card fraud, cyber intrusions, and industrial damage. In e-commerce, fraud is estimated to cost merchants more than $200 billion a year; in healthcare, fraud is estimated to cost taxpayers $60 billion a year; for banks, the cost is over $12 billion.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Unknown unknowns</h1>
                </header>
            
            <article>
                
<p>When Donald Rumsfeld, US Secretary of Defense, had a news briefing on February 12, 2002, about the lack of evidence linking the government of Iraq to the supply of weapons of mass destruction to terrorist groups, it immediately became a subject of much commentary. Rumsfeld stated the following (<em>DoD News</em>, 2012):</p>
<div class="packt_quote">"Reports that say that something hasn't happened are always interesting to me, because as we know, there are known knowns; there are things we know we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns-the ones we don't know we don't know. And if one looks throughout the history of our country and other free countries, it is the latter category that tend to be the difficult ones."</div>
<p>This statement might seem confusing at first, but the idea of unknown unknowns was well studied among scholars dealing with risk, NSA, and other intelligence agencies. What the statement basically implies is the following:</p>
<ul>
<li><strong>Known knowns</strong>: These are well-known problems or issues; we know how to recognize them and how deal with them</li>
<li><strong>Known unknowns</strong>: These are expected or foreseeable problems, which can be reasonably anticipated, but have not occurred before</li>
<li><strong>Unknown unknowns</strong>: These are unexpected and unforeseeable problems, which pose significant risk, as they cannot be anticipated, based on previous experience</li>
</ul>
<p>In the following sections, we will look into two fundamental approaches dealing with the first two types of knowns and unknowns: suspicious pattern detection dealing with known knowns, and anomalous pattern detection targeting known unknowns.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Suspicious pattern detection</h1>
                </header>
            
            <article>
                
<p>The first approach involves a behavior library that encodes negative patterns, shown as red minus signs in the following diagram, and recognizes that observed behavior corresponds to identifying a match in the library. If a new pattern can be matched against negative patterns, then it is considered suspicious:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-672 image-border" src="Images/f8a12c37-d928-4b52-8fb9-f64f58b30ef8.png" style="width:18.58em;height:15.42em;" width="223" height="185"/></div>
<p>For example, when you visit a doctor, he/she inspects various health symptoms (body temperature, pain levels, affected areas, and so on) and matches the symptoms to a known disease. In machine learning terms, the doctor collects attributes and performs classifications.</p>
<p>An advantage of this approach is that we immediately know what is wrong; for example, assuming that we know the disease, we can select an appropriate treatment procedure.</p>
<p>A major disadvantage of this approach is that it can only detect suspicious patterns that are known in advance. If a pattern is not inserted into a negative pattern library, then we will not be able to recognize it. This approach is, therefore, appropriate for modeling known knowns.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Anomalous pattern detection</h1>
                </header>
            
            <article>
                
<p>The second approach uses the pattern library in an inverse fashion, meaning that the library encodes only the positive patterns, which are marked with green plus signs in the following diagram. When an observed behavior (the blue circle) cannot be matched against the library, it is considered anomalous:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-673 image-border" src="Images/06313d61-ed0f-438c-be5b-41c210160dca.png" style="width:34.83em;height:14.92em;" width="532" height="228"/></p>
<p>This approach requires us to model only what we have seen in the past, that is, normal patterns. If we return to the doctor example, the main reason that we visited the doctor in the first place was because we did not feel well. Our perceived state of feelings (for example, a headache and sore skin) did not match our usual feelings, and therefore, we decided to seek a doctor. We don't know which disease caused this state, nor do we know the treatment, but we were able to observe that it doesn't match the usual state.</p>
<p>A major advantage of this approach is that it does not require us to say anything about abnormal patterns; hence, it is appropriate for modeling known unknowns and unknown unknowns. On the other hand, it does not tell us exactly what is wrong.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Analysis types</h1>
                </header>
            
            <article>
                
<p>Several approaches have been proposed to tackle this problem. We broadly classify anomalous and suspicious behavior detection in the following three categories: pattern analysis, transaction analysis, and plan recognition. In the following sections, we will quickly look at some real-life applications.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Pattern analysis</h1>
                </header>
            
            <article>
                
<p>An active area of anomalous and suspicious behavior detection from patterns is based on visual modalities, such as a camera. Zhang, et al. (2007) proposed a system for a visual human motion analysis from a video sequence, which recognizes unusual behavior based on walking trajectories; Lin, et al. (2009) described a video surveillance system based on color features, distance features, and a count feature, where evolutionary techniques are used to measure observation similarity. The system tracks each person and classifies their behavior by analyzing their trajectory patterns. The system extracts a set of visual low-level features in different parts of the image, and performs a classification with SVMs in order to detect aggressive, cheerful, intoxicated, nervous, neutral, and tired behavior.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Transaction analysis</h1>
                </header>
            
            <article>
                
<p>Transaction analysis assumes discrete states/transactions, in contrast to continuous observations. A major research area is <strong>intrusion detection</strong> (<strong>ID</strong>), which aims to detect attacks against information systems, in general. There are two types of ID systems, signature-based and anomaly-based, that broadly follow the suspicious and anomalous pattern detection that was described in the previous sections. A comprehensive review of ID approaches was published by Gyanchandani, et al. (2012).</p>
<p>Furthermore, applications in ambient assisted living that are based on wearable sensors also fit to transaction analysis as sensing is typically event-based. Lymberopoulos, et al. (2008) proposed a system for automatic extraction of the user<span>'</span>s spatio-temporal patterns, encoded as sensor activation from the sensor network deployed inside their home. The proposed method, based on location, time, and duration, was able to extract frequent patterns using the Apriori algorithm and encode the most frequent patterns in the form of a Markov chain. Another area of related work includes the <strong>hidden Markov models</strong> (<strong>HMMs</strong>) that are widely used in traditional activity recognition for modeling a sequence of actions, but these topics are already out of the scope of this book.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Plan recognition</h1>
                </header>
            
            <article>
                
<p>Plan recognition focuses on a mechanism for recognizing the unobservable state of an agent, given observations of its interaction with its environment (Avrahami-Zilberbrand, 2009). Most existing investigations assume discrete observations in the form of activities. To perform anomalous and suspicious behavior detection, plan recognition algorithms may use a hybrid approach. A symbolic plan recognizer is used to filter consistent hypotheses and passes them to an evaluation engine, which focuses on ranking.</p>
<p>These were advanced approaches that were applied to various real-life scenarios, targeted at discovering anomalies. In the following sections, we'll dive into more basic approaches for suspicious and anomalous pattern detection.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Outlier detection using ELKI</h1>
                </header>
            
            <article>
                
<p><strong>ELKI</strong> stands for <strong>Environment for Loping KDD applications Index</strong> structures, where <strong>KDD</strong> stands for <strong>Knowledge Discovery</strong> <strong>in Database</strong>. It is an open source software used mainly for data mining, with an emphasis on unsupervised learning. It supports various algorithms for cluster analysis and outlier detection. The following are some outlier algorithms:</p>
<ul>
<li><strong>Distance-based outlier detection</strong>: This is used to specify two parameters. The object is flagged <strong>outlier</strong> if its fraction, p, for all the data objects that have a distance above d from c. There are many algorithms, such as <kbd>DBOutlierDetection</kbd>, <kbd>DBOutlierScore</kbd>, <kbd>KNNOutlier</kbd>, <kbd>KNNWeightOutlier</kbd>, <kbd>ParallelKNNOutlier</kbd>, <kbd>ParallelKNNWeightOutlier</kbd>, <kbd>ReferenceBasedOutlierDetection</kbd>, and so on.</li>
<li><strong>LOF family methods</strong>: This computes density-based local outlier factors on specific parameters. It includes algorithms such as <kbd>LOF</kbd>, <kbd>ParallelLOF</kbd>, <kbd>ALOCI</kbd>, <kbd>COF</kbd>, <kbd>LDF</kbd>, <kbd>LDOF</kbd>, and so on.</li>
<li><strong>Angle-based outlier detection</strong>: This uses the variance analysis of angles, using mostly high-dimensional datasets. Common algorithms include <kbd>ABOD</kbd>, <kbd>FastABOD</kbd>, and <kbd>LBABOD</kbd>.</li>
<li><strong>Clustering-based outlier detection</strong>: This uses EM clustering; if the object does not belong to a cluster, it is taken as an outlier. This includes algorithms such as <kbd>EMOutlier</kbd> and <kbd>KMeansOutlierDetection</kbd>.</li>
<li><strong>Subspace outlier detection</strong>: This uses the outlier detection method for axis-parallel subspaces. It has algorithms such as <kbd>SOD</kbd>, <kbd>OutRankS1</kbd>, <kbd>OUTRES</kbd>, <kbd>AggrawalYuNaive</kbd>, and <kbd>AggrawalYuEvolutionary</kbd>.</li>
<li><strong>Spatial outlier detection</strong>: This has large datasets based on locations which are collected from different sources and the data point that is an extreme relative to neighbors. It has algorithms such as <kbd>CTLuGLSBackwardSearchAlgorithm</kbd>, <kbd>CTLuMeanMultipleAttributes</kbd>, <kbd>CTLuMedianAlgorithm</kbd>, <kbd>CTLuScatterplotOutlier</kbd>, and so on.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">An example using ELKI</h1>
                </header>
            
            <article>
                
<p>In <a href="e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml">Chapter 3</a>, <em>Basic Algorithms – Classification, Regression, and Clustering</em>, you already saw how to get the required <kbd>.jar</kbd> file for ELKI. We will follow a similar process, as follows:</p>
<p>Open Command Prompt or Terminal, and execute the following command:</p>
<pre><strong>java -jar elki-bundle-0.7.1.jar</strong></pre>
<p>This will provide the GUI interface, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-674 image-border" src="Images/5e04484b-a85a-4193-b0d0-db8ea5a05187.png" style="width:62.75em;height:51.17em;" width="796" height="649"/></p>
<p>In the GUI, the <span class="packt_screen">dbc.in</span> and <span class="packt_screen">algorithm</span> parameters are highlighted and need to be set. We will use <kbd>pov.csv</kbd> file, as <span class="packt_screen">dbc.in</span>. This CSV file can be downloaded from <a href="https://github.com/elki-project/elki/blob/master/data/synthetic/ABC-publication/pov.csv">https://github.com/elki-project/elki/blob/master/data/synthetic/ABC-publication/pov.csv</a>.</p>
<p>For the <span class="packt_screen">algorithm</span>, select <span class="packt_screen">outlier.clustering.EMOutlier</span>, and in <span class="packt_screen">em.k</span>, pass <kbd>3</kbd> as the value. The following screenshot shows all of the filled-in options:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-675 image-border" src="Images/25c7747f-c7ec-41fb-8105-fff08d32f593.png" style="width:67.58em;height:47.25em;" width="800" height="559"/></p>
<p>Click on the <span class="packt_screen">Run Task</span> button, and it will process and generate the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-676 image-border" src="Images/a54b3ac3-cc1d-4041-8111-a9bcd32b2818.png" style="width:70.42em;height:37.58em;" width="1950" height="1040"/></p>
<p>This shows clustering and the possible outliers.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Fraud detection in insurance claims</h1>
                </header>
            
            <article>
                
<p>First, we'll take a look at suspicious behavior detection, where the goal is to learn about patterns of fraud, which corresponds to modeling known knowns.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Dataset</h1>
                </header>
            
            <article>
                
<p>We'll work with a dataset describing insurance transactions, which is publicly available in the Oracle database online documentation at <span class="URLPACKT"><a href="http://docs.oracle.com/cd/B28359_01/datamine.111/b28129/anomalies.htm">http://docs.oracle.com/cd/B28359_01/datamine.111/b28129/anomalies.htm</a>.</span></p>
<p><span class="URLPACKT"> </span></p>
<p>The dataset describes insurance claims on vehicle incidents for an undisclosed insurance company. It contains 15,430 claims; each claim is comprised of 33 attributes, describing the following components:</p>
<ul>
<li>Customer demographic details (<span class="packt_screen">Age</span>, <span class="packt_screen">Sex</span>, <span class="packt_screen">MartialStatus</span>, and so on)</li>
<li>Purchased policy (<span class="packt_screen">PolicyType</span>, <span class="packt_screen">VehicleCategory</span>, number of supplements, agent type, and so on)</li>
<li>Claim circumstances (day/month/week claimed, policy report filed, witness present, past days between incident-policy report, incident claim, and so on)</li>
<li>Other customer data (number of cars, previous claims, <span class="packt_screen">DriverRating</span>, and so on)</li>
<li>Fraud found (yes or no)</li>
</ul>
<p>The sample of the database shown in the following screenshot depicts the data that's been loaded into Weka:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-677 image-border" src="Images/b856867d-d998-4e54-8ff0-0c66fd7f414b.png" style="width:94.17em;height:58.92em;" width="1130" height="707"/></p>
<p>Now, the task is to create a model that will be able to identify suspicious claims in the future. The challenging thing about this task is the fact that only 6% of the claims are suspicious. If we create a dummy classifier saying that no claim is suspicious, it will be accurate in 94% of cases. Therefore, in this task, we will use different accuracy measures: precision and recall.</p>
<p>Let's recall the outcome table from <a href="11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml"><span class="ChapterrefPACKT">Chapter 1</span></a>, <em>Applied Machine Learning Quick Start</em>, where there are four possible outcomes, denoted as true positive, false positive, false negative, and true negative:</p>
<div class="packt_figure">
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td/>
<td/>
<td class="CDPAlignCenter CDPAlign" colspan="2"><strong>Classified as</strong></td>
</tr>
<tr>
<td rowspan="3"><strong>Actual</strong></td>
<td/>
<td class="CDPAlignCenter CDPAlign"><strong>Fraud</strong></td>
<td class="CDPAlignCenter CDPAlign"><strong>No fraud</strong></td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign"><strong>Fraud</strong></td>
<td>TP - true positive</td>
<td>FN - false negative</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign"><strong>No fraud</strong></td>
<td>FP - false positive</td>
<td>TN - true negative</td>
</tr>
</tbody>
</table>
</div>
<p> </p>
<p>Precision and recall are defined as follows:</p>
<ul>
<li><strong>Precision</strong> is equal to the proportion of correctly raised alarms, as follows:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/aaae16aa-e167-4849-99ed-8b994958e828.png" style="width:7.83em;height:2.50em;" width="1310" height="420"/></p>
<ul>
<li><strong>Recall</strong> is equal to the proportion of deviant signatures, which are correctly identified as follows:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/37de70de-abc6-4fa8-81fc-1065b24dcb12.png" style="width:8.25em;height:2.58em;" width="1340" height="420"/></p>
<ul>
<li>With these measures–our dummy classifier scores–we find that <em>Pr = 0</em> and <em>Re = 0</em>, as it never marks any instance as fraud (<em>TP = 0</em>). In practice, we want to compare classifiers by both numbers; hence, we use <em>F - measure</em>. This is a de facto measure that calculates a harmonic mean between the precision and recall, as follows:</li>
</ul>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/05941bf8-3cd2-4fe7-8226-47141dd632ac.png" style="width:14.58em;height:2.67em;" width="2290" height="420"/></div>
<p>Now, let's move on to designing a real classifier.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Modeling suspicious patterns</h1>
                </header>
            
            <article>
                
<p>To design a classifier, we can follow the standard supervised learning steps, as described in <a href="11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml"><span class="ChapterrefPACKT">Chapter 1</span></a>, <em>Applied Machine Learning Quick Start</em>. In this recipe, we will include some additional steps to handle unbalanced datasets and evaluate classifiers based on precision and recall. The plan is as follows:</p>
<ol>
<li>Load the data in the <kbd>.csv</kbd> format.</li>
<li>Assign the class attribute.</li>
<li>Convert all of the attributes from a numeric to nominal value to make sure that there are no incorrectly loaded numerical values.</li>
<li><strong>Experiment 1</strong>: Evaluating the models with k-fold cross-validation.</li>
<li><strong>Experiment 2</strong>: Rebalancing the dataset to a more balanced class distribution, and manually perform cross-validation.</li>
<li>Compare the classifiers by recall, precision, and f-measure.</li>
</ol>
<p>First, let's load the data using the <kbd>CSVLoader</kbd> class, as follows:</p>
<pre>String filePath = "/Users/bostjan/Dropbox/ML Java Book/book/datasets/chap07/claims.csv"; 
 
CSVLoader loader = new CSVLoader(); 
loader.setFieldSeparator(","); 
loader.setSource(new File(filePath)); 
Instances data = loader.getDataSet(); </pre>
<p>Next, we need to make sure that all of the attributes are nominal. During the data import, Weka applies some heuristics to guess the most probable attribute type, that is, numeric, nominal, string, or date. As heuristics cannot always guess the correct type, we can set the types manually, as follows:</p>
<pre>NumericToNominal toNominal = new NumericToNominal(); 
toNominal.setInputFormat(data); 
data = Filter.useFilter(data, toNominal); </pre>
<p>Before we continue, we need to specify the attribute that we will try to predict. We can achieve this by calling the <kbd>setClassIndex(int)</kbd> function:</p>
<pre>int CLASS_INDEX = 15; 
data.setClassIndex(CLASS_INDEX); </pre>
<p>Next, we need to remove an attribute describing the policy number, as it has no predictive value. We simply apply the <kbd>Remove</kbd> filter, as follows:</p>
<pre>Remove remove = new Remove(); 
remove.setInputFormat(data); 
remove.setOptions(new String[]{"-R", ""+POLICY_INDEX}); 
data = Filter.useFilter(data, remove); </pre>
<p>Now, we are ready to start modeling.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The vanilla approach</h1>
                </header>
            
            <article>
                
<p>The vanilla approach is to directly apply the lesson, just like as it was demonstrated in <a href="e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml"><span class="ChapterrefPACKT">Chapter 3</span></a>, <em>Basic Algorithms - Classification, Regression, Clustering</em>, without any preprocessing, and not taking dataset specifics into account. To demonstrate the drawbacks of the vanilla approach, we will simply build a model with the default parameters and apply k-fold cross-validation.</p>
<p>First, let's define some classifiers that we want to test, as follows:</p>
<pre>ArrayList&lt;Classifier&gt;models = new ArrayList&lt;Classifier&gt;(); 
models.add(new J48()); 
models.add(new RandomForest()); 
models.add(new NaiveBayes()); 
models.add(new AdaBoostM1()); 
models.add(new Logistic()); </pre>
<p>Next, we need to create an <kbd>Evaluation</kbd> object and perform k-fold cross-validation by calling the <kbd>crossValidate(Classifier, Instances, int, Random, String[])</kbd> method, providing the <kbd>precision</kbd>, <kbd>recall</kbd>, and <kbd>fMeasure</kbd> as output:</p>
<pre>int FOLDS = 3; 
Evaluation eval = new Evaluation(data); 
 
for(Classifier model : models){ 
  eval.crossValidateModel(model, data, FOLDS,  
  new Random(1), new String[] {}); 
  System.out.println(model.getClass().getName() + "\n"+ 
    "\tRecall:    "+eval.recall(FRAUD) + "\n"+ 
    "\tPrecision: "+eval.precision(FRAUD) + "\n"+ 
    "\tF-measure: "+eval.fMeasure(FRAUD)); 
} </pre>
<p>The evaluation provides the following scores as output:</p>
<pre>    weka.classifiers.trees.J48
      Recall:    0.03358613217768147
      Precision: 0.9117647058823529
      F-measure: 0.06478578892371996
    ...
    weka.classifiers.functions.Logistic
      Recall:    0.037486457204767065
      Precision: 0.2521865889212828
      F-measure: 0.06527070364082249
  </pre>
<p>We can see that the results are not very promising. The recall, that is, the share of discovered frauds among all frauds, is only 1-3%, meaning that only 1-3/100 frauds are detected. On the other hand, the precision, that is, the accuracy of alarms, is 91%, meaning that in 9/10 cases, when a claim is marked as fraud, the model is correct.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Dataset rebalancing</h1>
                </header>
            
            <article>
                
<p>As the number of negative examples, that is, instances of fraud, is very small compared to positive examples, the learning algorithms struggle with induction. We can help them by giving them a dataset where the share of positive and negative examples is comparable. This can be achieved with dataset rebalancing.</p>
<p>Weka has a built-in filter, <kbd>Resample</kbd>, which produces a random subsample of a dataset, using sampling either with replacement or without replacement. The filter can also bias the distribution toward a uniform class distribution.</p>
<p>We will proceed by manually implementing k-fold cross-validation. First, we will split the dataset into <em>k</em> equal folds. Fold <em>k</em> will be used for testing, while the other folds will be used for learning. To split the dataset into folds, we'll use the <kbd>StratifiedRemoveFolds</kbd> filter, which maintains the class distribution within the folds, as follows:</p>
<pre>StratifiedRemoveFolds kFold = new StratifiedRemoveFolds(); 
kFold.setInputFormat(data); 
 
double measures[][] = new double[models.size()][3]; 
 
for(int k = 1; k &lt;= FOLDS; k++){ 
 
  // Split data to test and train folds 
  kFold.setOptions(new String[]{ 
    "-N", ""+FOLDS, "-F", ""+k, "-S", "1"}); 
  Instances test = Filter.useFilter(data, kFold); 
   
  kFold.setOptions(new String[]{ 
    "-N", ""+FOLDS, "-F", ""+k, "-S", "1", "-V"}); 
    // select inverse "-V" 
  Instances train = Filter.useFilter(data, kFold); </pre>
<p>Next, we can rebalance the training dataset, where the <kbd>-Z</kbd> parameter specifies the percentage of the dataset to be resampled, and <kbd>-B</kbd> biases the class distribution toward uniform distribution:</p>
<pre>Resample resample = new Resample(); 
resample.setInputFormat(data); 
resample.setOptions(new String[]{"-Z", "100", "-B", "1"}); //with <br/>   replacement 
Instances balancedTrain = Filter.useFilter(train, resample); </pre>
<p>Next, we can build classifiers and perform evaluation:</p>
<pre>for(ListIterator&lt;Classifier&gt;it = models.listIterator(); <br/>   it.hasNext();){ 
  Classifier model = it.next(); 
  model.buildClassifier(balancedTrain); 
  eval = new Evaluation(balancedTrain); 
  eval.evaluateModel(model, test); 
   
// save results for average 
  measures[it.previousIndex()][0] += eval.recall(FRAUD); 
  measures[it.previousIndex()][1] += eval.precision(FRAUD); 
 measures[it.previousIndex()][2] += eval.fMeasure(FRAUD); 
} </pre>
<p>Finally, we calculate the average and provide the best model as output using the following lines of code:</p>
<pre>// calculate average 
for(int i = 0; i &lt; models.size(); i++){ 
  measures[i][0] /= 1.0 * FOLDS; 
  measures[i][1] /= 1.0 * FOLDS; 
  measures[i][2] /= 1.0 * FOLDS; 
} 
 
// output results and select best model 
Classifier bestModel = null; double bestScore = -1; 
for(ListIterator&lt;Classifier&gt; it = models.listIterator(); <br/>   it.hasNext();){ 
  Classifier model = it.next(); 
  double fMeasure = measures[it.previousIndex()][2]; 
  System.out.println( 
    model.getClass().getName() + "\n"+ 
    "\tRecall:    "+measures[it.previousIndex()][0] + "\n"+ 
    "\tPrecision: "+measures[it.previousIndex()][1] + "\n"+ 
    "\tF-measure: "+fMeasure); 
  if(fMeasure &gt; bestScore){ 
    bestScore = fMeasure; 
    bestModel = model; 
     
  } 
} 
System.out.println("Best model:"+bestModel.getClass().getName()); </pre>
<p>Now, the performance of the models has significantly improved, as follows:</p>
<pre>    weka.classifiers.trees.J48
      Recall:    0.44204845100610574
      Precision: 0.14570766048577555
      F-measure: 0.21912423640160392
    ...
    weka.classifiers.functions.Logistic
      Recall:    0.7670657247204478
      Precision: 0.13507459756495374
      F-measure: 0.22969038530557626
    Best model: weka.classifiers.functions.Logistic
  </pre>
<p>We can see that all of the models have scored significantly better; for instance, the best model, logistic regression, correctly discovers 76% of the fraud, while producing a reasonable amount of false alarms–only 13% of the claims marked as fraud are indeed fraudulent. If an undetected fraud is significantly more expensive than the investigation of false alarms, then it makes sense to deal with an increased number of false alarms.</p>
<p>The overall performance most likely still has some room for improvement; we could perform attribute selection and feature generation and apply more complex model learning, which we discussed in <a href="e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml"><span class="ChapterrefPACKT">Chapter 3</span></a>, <em>Basic Algorithms – Classification, Regression, Clustering</em>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Anomaly detection in website traffic</h1>
                </header>
            
            <article>
                
<p>In the second example, we'll focus on modeling the opposite of the previous example. Instead of discussing what typical fraudless cases are, we'll discuss the normal expected behavior of the system. If something cannot be matched against our expected model, it will be considered anomalous.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Dataset</h1>
                </header>
            
            <article>
                
<p>We'll work with a publicly available dataset that was released by Yahoo! Labs, which is useful for discussing how to detect anomalies in time series data. For Yahoo, the main use case is in detecting unusual traffic on Yahoo servers.</p>
<p>Even though Yahoo has announced that their data is publicly available, you have to apply to use it, and it takes about 24 hours before the approval is granted. The dataset is available at <span class="URLPACKT"><a href="http://webscope.sandbox.yahoo.com/catalog.php?datatype=s&amp;did=70">http://webscope.sandbox.yahoo.com/catalog.php?datatype=s&amp;did=70</a>.<br/></span></p>
<p>The dataset is comprised of real traffic for Yahoo services, along with some synthetic data. In total, the dataset contains 367 time series, each of which contains between 741 and 1,680 observations, which have been recorded at regular intervals. Each series is written in its own file, one observation per line. A series is accompanied by a second column indicator, with a one being used if the observation was an anomaly, and zero otherwise. The anomalies in real data were determined by human judgment, while those in the synthetic data were generated algorithmically. A snippet of the synthetic times series data is shown in the following table:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-678 image-border" src="Images/dba0f780-5990-40b0-a735-5374a17d729e.png" style="width:52.75em;height:23.17em;" width="633" height="278"/></p>
<p>In the following section, you'll learn how to transform time series data into an attribute presentation that allows us to apply machine learning algorithms.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Anomaly detection in time series data</h1>
                </header>
            
            <article>
                
<p>Detecting anomalies in raw, streaming time series data requires some data transformation. The most obvious way to do this is to select a time window and sample a time series with a fixed length. In the next step, we want to compare a new time series to our previously collected set to detect whether something is out of the ordinary.</p>
<p>The comparison can be done with various techniques, as follows:</p>
<ul>
<li>Forecasting the most probable following value, as well as the confidence intervals (for example, Holt-Winters exponential smoothing). If a new value is out of the forecasted confidence interval, it is considered anomalous.</li>
<li>Cross-correlation compares a new sample to a library of positive samples, and it looks for an exact match. If the match is not found, it is marked as anomalous.</li>
<li>Dynamic time wrapping is similar to cross-correlation, but allows for signal distortion in comparison.</li>
<li>Discretizing signals to bands, where each band corresponds to a letter. For example, <kbd>A=[min, mean/3]</kbd>, <kbd>B=[mean/3, mean*2/3]</kbd>, and <kbd>C=[mean*2/3, max]</kbd> transforms the signal into a sequence of letters, such as <kbd>aAABAACAABBA...<span><span>.</span></span></kbd> This approach reduces the storage and allows us to apply the text mining algorithms that we will discuss in <a href="c3fd3723-2c46-4f0f-aaed-49329c3481ce.xhtml"><span class="ChapterrefPACKT">Chapter 10</span></a>, <em>Text Mining with Mallet <span>–</span> Topic Modeling and Spam Detection</em>.</li>
<li>A distribution-based approach estimates the distribution of values in a specific time window. When we observe a new sample, we can compare whether the distribution matches the previously observed one.</li>
</ul>
<p>This list is by no means exhaustive. Different approaches are focused on detecting different anomalies (for example, in the value, frequency, and distribution). We will focus on a version of distribution-based approaches in this chapter.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using Encog for time series</h1>
                </header>
            
            <article>
                
<p>We have to download the time series data from <a href="https://solarscience.msfc.nasa.gov/greenwch/spot_num.txt">https://solarscience.msfc.nasa.gov/greenwch/spot_num.txt</a> and save the file in the <kbd>data</kbd> folder. In the <kbd>.java</kbd> file, we will specify the file path, and then we will indicate the format of the file using the following code block:</p>
<pre>File filename = new File("data/spot_num.txt");<br/>CSVFormat format = new CSVFormat('.', ' ');<br/>VersatileDataSource source = new CSVDataSource(filename, true, format);<br/>VersatileMLDataSet data = new VersatileMLDataSet(source);<br/>data.getNormHelper().setFormat(format);<br/>ColumnDefinition columnSSN = data.defineSourceColumn("SSN", ColumnType.continuous);<br/>ColumnDefinition columnDEV = data.defineSourceColumn("DEV", ColumnType.continuous);<br/>data.analyze();<br/>data.defineInput(columnSSN);<br/>data.defineInput(columnDEV);<br/>data.defineOutput(columnSSN);</pre>
<p>Now, we will create the feedforward network with the window size <kbd>1</kbd>. When processing a time series, you should keep in mind that it should never be shuffled. We will hold some data back for validation. We will use the following lines of code to do so:</p>
<pre>EncogModel model = new EncogModel(data);<br/>model.selectMethod(data, MLMethodFactory.TYPE_FEEDFORWARD);<br/><br/>model.setReport(new ConsoleStatusReportable());<br/>data.normalize();<br/><br/>// Set time series.<br/>data.setLeadWindowSize(1);<br/>data.setLagWindowSize(WINDOW_SIZE);<br/>model.holdBackValidation(0.3, false, 1001);<br/>model.selectTrainingType(data);</pre>
<p>The next step is to run the training with five-fold cross-validation using the following line:</p>
<pre>MLRegression bestMethod = (MLRegression) model.crossvalidate(5, false);</pre>
<p>Now, it's time to display the error and the final model. We will do that by using the following lines of code:</p>
<pre>System.out.println("Training error: " + model.calculateError(bestMethod, model.getTrainingDataset()));<br/>System.out.println("Validation error: " + model.calculateError(bestMethod, model.getValidationDataset()));<br/><br/>NormalizationHelper helper = data.getNormHelper();<br/>System.out.println(helper.toString());<br/><br/>// Display the final model.<br/>System.out.println("Final model: " + bestMethod);</pre>
<p>The output will be similar to the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-679 image-border" src="Images/59db7ca2-59d5-4895-8b20-e0493e2f63a1.png" style="width:69.42em;height:20.17em;" width="833" height="242"/></p>
<p>Now, we will test the model using the following code block:</p>
<pre>while (csv.next() &amp;&amp; stopAfter &gt; 0) {<br/>                StringBuilder result = new StringBuilder();<br/><br/>                line[0] = csv.get(2);// ssn<br/>                line[1] = csv.get(3);// dev<br/>                helper.normalizeInputVector(line, slice, false);<br/><br/>                if (window.isReady()) {<br/>                    window.copyWindow(input.getData(), 0);<br/>                    String correct = csv.get(2); // trying to predict SSN.<br/>                    MLData output = bestMethod.compute(input);<br/>                    String predicted = helper<br/>                            .denormalizeOutputVectorToString(output)[0];<br/><br/>                    result.append(Arrays.toString(line));<br/>                    result.append(" -&gt; predicted: ");<br/>                    result.append(predicted);<br/>                    result.append("(correct: ");<br/>                    result.append(correct);<br/>                    result.append(")");<br/><br/>                    System.out.println(result.toString());<br/>                }<br/><br/>                window.add(slice);<br/><br/>                stopAfter--;<br/>            }</pre>
<p>The output will be similar to the following screenshot: </p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-680 image-border" src="Images/a6f7bd2b-0899-4495-b84a-9324fedeab78.png" style="width:33.75em;height:29.25em;" width="557" height="482"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Histogram-based anomaly detection</h1>
                </header>
            
            <article>
                
<p>In histogram-based anomaly detection, we split the signals by a selected time window, as shown in the following diagram.</p>
<p>For each window, we calculate the histogram; that is, for a selected number of buckets, we count how many values fall into each bucket. The histogram captures the basic distribution of values in a selected time window, as shown in the center of the diagram.</p>
<p>Histograms can then be directly presented as instances, where each bin corresponds to an attribute. Furthermore, we can reduce the number of attributes by applying a dimensionality-reduction technique, such as <strong>Principal Component Analysis</strong> (<strong>PCA</strong>), which allows us to visualize the reduced-dimension histograms in a plot, as shown at the bottom-right of the diagram, where each dot corresponds to a histogram.</p>
<p>In our example, the idea is to observe website traffic for a couple of days, and then create histograms; for example, four-hour time windows, to build a library of positive behavior. If a new time window histogram cannot be matched against a positive library, we can mark it as an anomaly:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-681 image-border" src="Images/29066236-a70f-48e7-b278-fcc60cd3e79d.png" style="width:55.58em;height:50.25em;" width="924" height="836"/></p>
<p>For comparing a new histogram to a set of existing histograms, we will use a density-based k-nearest neighbor algorithm, <strong>Local Outlier Factor</strong> (<strong>LOF</strong>) (Breunig, et al., 2000). The algorithm is able to handle clusters with different densities, as shown in the following diagram. For example, the upper-right cluster is large and widespread, compared to the bottom-left cluster, which is smaller and denser:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-682 image-border" src="Images/619eb30f-21be-43a2-a7c6-e91a99d8d4ad.png" style="width:54.58em;height:48.75em;" width="655" height="585"/></p>
<p>Let's get started!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Loading the data</h1>
                </header>
            
            <article>
                
<p>In the first step, we'll need to load the data from text files to a Java object. The files are stored in a folder, and each file contains one time series, with values per line. We'll load them into a <kbd>Double</kbd> list, as follows:</p>
<pre>String filePath = "chap07/ydata/A1Benchmark/real"; 
List&lt;List&lt;Double&gt;&gt; rawData = new ArrayList&lt;List&lt;Double&gt;&gt;(); </pre>
<p>We will need the <kbd>min</kbd> and <kbd>max</kbd> value for histogram normalization; so, let's collect them in this data pass:</p>
<pre>double max = Double.MIN_VALUE; 
double min = Double.MAX_VALUE; 
 
for(int i = 1; i&lt;= 67; i++){ 
  List&lt;Double&gt; sample = new ArrayList&lt;Double&gt;(); 
  BufferedReader reader = new BufferedReader(new <br/>     FileReader(filePath+i+".csv")); 
   
  boolean isAnomaly = false; 
  reader.readLine(); 
  while(reader.ready()){ 
    String line[] = reader.readLine().split(","); 
    double value = Double.parseDouble(line[1]); 
    sample.add(value); 
     
    max = Math.max(max, value); 
    min = Double.min(min, value); 
     
    if(line[2] == "1") 
      isAnomaly = true; 
     
  } 
  System.out.println(isAnomaly); 
  reader.close(); 
   
  rawData.add(sample); 
} </pre>
<p>The data has been loaded. Next, let's move on to histograms.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating histograms</h1>
                </header>
            
            <article>
                
<p>We will create a histogram for a selected time window with the <kbd>WIN_SIZE</kbd> width.</p>
<p>The histogram will hold the <kbd>HIST_BINS</kbd> value buckets. The histograms consisting of lists of doubles will be stored in an array list:</p>
<pre>int WIN_SIZE = 500; 
int HIST_BINS = 20; 
int current = 0; 
 
List&lt;double[]&gt; dataHist = new ArrayList&lt;double[]&gt;(); 
for(List&lt;Double&gt; sample : rawData){ 
  double[] histogram = new double[HIST_BINS]; 
  for(double value : sample){ 
    int bin = toBin(normalize(value, min, max), HIST_BINS); 
    histogram[bin]++; 
    current++; 
    if(current == WIN_SIZE){ 
      current = 0; 
      dataHist.add(histogram); 
      histogram = new double[HIST_BINS]; 
    } 
  } 
  dataHist.add(histogram); 
} </pre>
<p>The histograms are now completed. The last step is to transform them into Weka's <kbd>Instance</kbd> objects. Each histogram value will correspond to one Weka attribute, as follows:</p>
<pre>ArrayList&lt;Attribute&gt; attributes = new ArrayList&lt;Attribute&gt;(); 
for(int i = 0; i&lt;HIST_BINS; i++){ 
  attributes.add(new Attribute("Hist-"+i)); 
} 
Instances dataset = new Instances("My dataset", attributes, <br/>   dataHist.size()); 
for(double[] histogram: dataHist){ 
  dataset.add(new Instance(1.0, histogram)); 
} </pre>
<p>The dataset has been now loaded, and is ready to be plugged into an anomaly detection algorithm.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Density-based k-nearest neighbors</h1>
                </header>
            
            <article>
                
<p>To demonstrate how LOF calculates scores, we'll first split the dataset into training and testing sets by using the <kbd>testCV(int, int)</kbd> function. The first parameter specifies the number of folds, while the second parameter specifies which fold to return:</p>
<pre>// split data to train and test 
Instances trainData = dataset.testCV(2, 0); 
Instances testData = dataset.testCV(2, 1); </pre>
<p>The LOF algorithm is not a part of the default Weka distribution, but it can be downloaded through Weka's package manager at <span class="URLPACKT"><a href="http://weka.sourceforge.net/packageMetaData/localOutlierFactor/index.html">http://weka.sourceforge.net/packageMetaData/localOutlierFactor/index.html</a>.<br/></span></p>
<p>The LOF algorithm has two implemented interfaces: as an unsupervised filter that calculates LOF values (known unknowns), and as a supervised k-nearest neighbors classifier (known knowns). In our case, we want to calculate the outlierness factor, and therefore, we'll use the unsupervised filter interface:</p>
<pre>import weka.filters.unsupervised.attribute.LOF; </pre>
<p>The filter is initialized in the same way as a usual filter. We can specify <kbd>k</kbd> number of neighbors (for example, <kbd>k=3</kbd>) with the <kbd>-min</kbd> and <kbd>-max</kbd> parameters. <kbd>LOF</kbd> allows us to specify two different <kbd>k</kbd> parameters, which are used internally as the upper and lower bound, to find the minimum or maximum number of <kbd>lof</kbd> values:</p>
<pre>LOF lof = new LOF(); 
lof.setInputFormat(trainData); 
lof.setOptions(new String[]{"-min", "3", "-max", "3"}); </pre>
<p>Next, we load the training instances into the filter that will serve as a positive example library. After we complete the loading, we will call the <kbd>batchFinished()</kbd> method to initialize the internal calculations:</p>
<pre>for(Instance inst : trainData){ 
  lof.input(inst); 
} 
lof.batchFinished(); </pre>
<p>Finally, we can apply the filter to the test data. The <kbd>Filter()</kbd> function will process the instances and append an additional attribute at the end, containing the LOF score. We can simply provide the score as output in the console:</p>
<pre>Instances testDataLofScore = Filter.useFilter(testData, lof); 
 
for(Instance inst : testDataLofScore){ 
  System.out.println(inst.value(inst.numAttributes()-1)); 
} </pre>
<p>The LOF score of the first couple of test instances is as follows:</p>
<pre>    1.306740014927325
    1.318239332210458
    1.0294812291949587
    1.1715039094530768
  </pre>
<p>To understand the <kbd>LOF</kbd> values, we need some background on the LOF algorithm. It compares the density of an instance to the density of its nearest neighbors. The two scores are divided, producing the LOF score. An LOF score of around 1 indicates that the density is approximately equal, while higher LOF values indicate that the density of the instance is substantially lower than the density of its neighbors. In such cases, the instance can be marked as anomalous.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we looked into detecting anomalous and suspicious patterns. We discussed the two fundamental approaches, focusing on library encoding, either positive or negative patterns. Next, we got our hands on two real-life datasets, and we discussed how to deal with unbalanced class distributions and how to perform anomaly detection on time series data.</p>
<p>In the next chapter, we'll dive deeper into patterns and more advanced approaches to building pattern-based classifiers, and discuss how to assign labels to images using deep learning<span> automatically</span>.</p>


            </article>

            
        </section>
    </div>



  </body></html>