- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analyzing Acoustic Signals to Predict the Next Simulated Earthquake
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we explored basic table-formatted data, covering categories
    like categorical, ordinal, and numerical data, as well as text, geographical coordinates,
    and imagery. The current chapter shifts our focus to a different data category,
    specifically, simulated or experimental signal data. This data type often appears
    in a range of formats beyond the standard CSV file format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our primary case study will be data from the *LANL Earthquake Prediction* Kaggle
    competition (see *Reference 1*). I contributed to this competition with a widely
    recognized and frequently forked notebook titled *LANL Earthquake EDA and Prediction*
    (see *Reference* *2*), which will serve as the foundational resource for this
    chapter’s principal notebook. We’ll then delve into feature engineering, employing
    a variety of signal analysis techniques vital for developing a predictive model
    for the competition. Our goal will be to construct an initial model that predicts
    the competition’s target variable: the time until failure, which is the remaining
    time before the next simulated lab earthquake.'
  prefs: []
  type: TYPE_NORMAL
- en: The research in the domain of earthquake prediction has shown that before earthquakes,
    the movement of the tectonic plates generates signals in a low-frequency acoustic
    spectrum. By studying these signals, researchers try to understand the relationship
    between the signal’s profile and the moment when the failure (that is, the earthquake)
    occurs. In a laboratory, the sliding and shearing of tectonic plates are simulated.
    This competition uses the laboratory measurement data, including the acoustic
    signals, as well as the time when failures occur.
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, this chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Data formats used for various signal data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploration of the *LANL Earthquake Prediction* Kaggle competition data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training the model for the competition *LANL Earthquake Prediction*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing the LANL Earthquake Prediction competition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *LANL Earthquake Prediction* competition centers on utilizing seismic signals
    to determine the precise timing of a laboratory-induced earthquake. Currently,
    predicting natural earthquakes remains beyond the reach of our scientific knowledge
    and technological capabilities. The ideal scenario for scientists is to predict
    the timing, location, and magnitude of such an event.
  prefs: []
  type: TYPE_NORMAL
- en: 'Simulated earthquakes, however, created in highly controlled artificial environments,
    mimic real-world seismic activities. These simulations enable attempts to forecast
    lab-generated quakes using the same types of signals observed in natural settings.
    In this competition, participants use an acoustic data input signal to estimate
    the time until the next artificial earthquake occurs, as detailed in *Reference
    3*. The challenge is to predict the timing of the earthquake, addressing one of
    the three critical unknowns in earthquake forecasting: when it will happen, where
    it will occur, and how powerful it will be.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The training data is a single file with two columns: acoustic signal amplitude
    and time to failure. The test data consists of multiple files (2,526 in total)
    with acoustic signal amplitude segments for which we will have to predict the
    time to failure. A sample submission file has one column with the segment ID,
    `seg_id`, and the value to predict: `time_to_failure`.'
  prefs: []
  type: TYPE_NORMAL
- en: The competitors are tasked with training their models with the acoustic signal
    and time-to-failure data in the training file and predicting the time-to-failure
    for each segment from each file in the test folder. This competition data is in
    a very convenient format, that is, **comma-separated values** (**CSV**) format,
    but this is not a requirement. Other competitions or datasets on Kaggle with signal
    data use different, less common formats. Because this chapter is about analyzing
    signal data, this is the right place to review this format. Let’s first look into
    some of these formats.
  prefs: []
  type: TYPE_NORMAL
- en: Formats for signal data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Several competitions on Kaggle used sound data as an addition to regular tabular
    features. There were three competitions organized by Cornell Lab of Ornithology’s
    BirdCLEF (LifeCLEF Bird Recognition Challenge) in 2021, 2022, and 2023 for predicting
    a bird species from samples of bird songs (see *Reference 4* for an example of
    one of these competitions). The format used in these competitions was `.ogg`.
    The `.ogg` format is used to store audio data with less bandwidth. It is considered
    technically superior to the `.mp3` format.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can read these types of file formats using the `librosa` library (see *Reference
    5*). The following code can be used to load an `.ogg` file and display the sound
    wave:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The library `librosa`, when loading the audio sound, will return values as a
    time series with floating-point values (see *Reference 6*). It isn’t just the
    `.ogg` format that is supported; it will work with any code supported by soundfile
    or Audioread. The default sampling rate is 22050 but this can be also set upon
    load, using the parameter *sr*. Other parameters that can be used when loading
    an audio wave are the offset and the duration (both given in seconds – together,
    they allow you to select the time interval of the sound wave you will load).
  prefs: []
  type: TYPE_NORMAL
- en: In an earlier version of the BirdCLEF competition, *Cornell Birdcall Identification*
    (see *Reference 7*), audio sounds in the dataset were given in `.mp3` format.
    For this format, we can use librosa to load, transform, or visualize the sound
    waves. **Waveform Audio File** format (or **WAV**), another frequently used format,
    can also be loaded using librosa.
  prefs: []
  type: TYPE_NORMAL
- en: 'For `.wav` format, we can alternatively use the `scipy.io` module `wavfile`
    to load data. The following code will load and display a file in `.wav` format.
    In this case, the amplitude is not scaled down to a -1:1 interval (the maximum
    value is 32K):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Signal, not specifically audio signal, data can also be stored in `.npy` or
    `.npz` format, which are both `numpy` formats to store array data. These formats
    can be loaded using `numpy` functions, as you can see in the following code snippets.
    For `npy` format, this will load a multi-column array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For `.npz` format, the following code will load a similar structure, previously
    compressed (one file only):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'For data stored in `.rds` format, an R-specific format for saving data, we
    can load the data using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: For more details, you can consult *Reference 9*. For now, let’s get back to
    our competition data, which is in CSV format, although it represents an audio
    signal (sound waves), as we already clarified.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring our competition data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `LANL Earthquake Prediction` dataset consists of the following data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A `train.csv` file, with two columns only:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`acoustic_data`: This is the amplitude of the acoustic signal.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`time_to_failure`: This is the time to failure corresponding to the current
    data segment.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A test folder with 2,624 files with small segments of acoustic data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `sample_submission.csv` file; for each test file, those competing will need
    to give an estimate for time to failure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The training data (9.56 GB) contains 692 million rows. The actual time constant
    for the samples in the training data results from the continuous variation of
    `time_to_failure` values. The acoustic data is integer values, from -5,515 to
    5,444, with an average of 4.52 and a standard deviation of 10.7 (values oscillating
    around 0). The `time_to_failure` values are real numbers, ranging from 0 to 16,
    with a mean of 5.68 and a standard deviation of 3.67\. To reduce the memory footprint
    for the training data, we read the data with a reduced dimension for both acoustic
    data and `time_to_failure`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s check the first values in the `training` data. We will not use all the
    `time_to_failure` data (only values associated with the end-of-time interval for
    which we will aggregate interval acoustic data); therefore, rounding in order
    to reduce the size of the time to failure from double to float is not important
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated](img/B20963_08_01.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1\. First rows of data in the training data
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s visualize, on the same graph, the acoustic signal values and the time
    to failure. We will use a subsampling rate of 1/100 (sample each 100^(th) row)
    to represent the full training data (see *Figure 8.2*). We will use the following
    code to represent these graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![A graph with red and blue lines  Description automatically generated](img/B20963_08_02.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2\. Acoustic signal data and time to failure data over an entire training
    set, subsampled at 1/100
  prefs: []
  type: TYPE_NORMAL
- en: Let’s zoom into the first part of the time interval. We will show the first
    1% of the data (no subsampling). In *Figure 8.3*, we are showing, on the same
    graph, the acoustic signal and time to failure for the first 6.29 million rows
    of data. We can observe that before the failure (but not very close in time),
    there is a large oscillation, with both negative and positive peaks. This oscillation
    is also preceded by a few smaller ones, at irregular time intervals.
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph with red lines and blue lines  Description automatically generated](img/B20963_08_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: Acoustic signal data and time to failure data for the first 1%
    of the data'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s also look at the next 1% of the training data (without subsampling). In
    *Figure 8.4*, we show this time series for acoustic signal values and time to
    failure. There is no failure during this time interval. We observe many irregular
    small oscillations, with both negative and positive peaks.
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph with red lines  Description automatically generated](img/B20963_08_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.4: Acoustic signal data and time to failure for the second 1% of the
    data in the training set'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s also look at the last few percentages of the data (last 5% of time) in
    the training set. In *Figure 8.5*, we observe the same pattern of several larger
    oscillations superposed on smaller irregular oscillations, and with a major oscillation
    just before the failure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph with red and blue lines  Description automatically generated](img/B20963_08_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.5: Acoustic signal data and time to failure for the last 5% of the
    data in the training set'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now also look at a few examples of variations of the acoustic signal
    in the test data samples. There are 2,624 data segment files in the test data.
    We will select a few of them to visualize. We will use a modified visualization
    function since in the test data, we only have the acoustic signals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In *Figure 8.6*, we are showing the acoustic signal graph for the segment **seg_00030f**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph showing a red line  Description automatically generated](img/B20963_08_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.6: Acoustic signal data for test segment seg_00030f'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next figure, we are showing the acoustic signal graph for segment **seg_0012b5**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph showing a red line  Description automatically generated](img/B20963_08_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.7: Acoustic signal data for test segment seg_0012b5'
  prefs: []
  type: TYPE_NORMAL
- en: In the notebooks associated with this chapter, you can see more examples of
    such test acoustic signals. The test segments show quite a large variety of signal
    profiles, depicting the same sequence of small oscillations with intercalated
    peaks with variable amplitude, similar to what we can see in the `training` data
    subsampled earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Solution approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The task in the competition is to accurately forecast a singular `time_to_failure`
    value for each segment in the test dataset. Each segment of the `test` set comprises
    150,000 data rows. In contrast, the `training` dataset is vast, encompassing 692
    million rows, with one column dedicated to our target variable: the time until
    failure. We plan to divide the training data into uniform segments, each containing
    150,000 rows, and use the final time-to-failure value from each segment as the
    target variable for that segment. This approach is designed to align the training
    data with the format of the test data, facilitating more effective model training.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we will engineer new features by aggregating values across both
    the training and test datasets, resulting in a single row that encapsulates multiple
    features for each data segment. The subsequent section will delve into the signal
    processing techniques employed for feature generation.
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use several libraries specific to signal processing to generate most
    of the features. From SciPy (Python scientific library), we are using a few functions
    from the `signal` module. The Hann function returns a Hann window, which modifies
    the signal to smooth the values at the end of the sampled signal to 0 (uses a
    cosine “bell” function). The Hilbert function computes the analytic signal, using
    the `Hilbert` transform. The Hilbert transform is a mathematical technique used
    in signal processing, with a property that shifts the phase of the original signal
    by 90 degrees.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other library functions used are from `numpy`: Fast Fourier Transform (FFT),
    `mean`, `min`, `max`, `std` (standard deviation), `abs` (absolute value), `diff`
    (the difference between two successive values in the signal), and `quantile` (where
    a sample is divided into equal-sized, adjacent groups). We are also using a few
    statistical functions that are available from `pandas`: `mad` (median absolute
    deviation), `kurtosis`, `skew`, and `median`. We are implementing functions to
    calculate trend features and classic STA/LTA. Classic STA/LTA represents the ratio
    between the amplitude of the signal of a short time window of length STA and a
    long time window, LTA. Let’s dive in!'
  prefs: []
  type: TYPE_NORMAL
- en: Trend feature and classic STA/LTA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We start by defining two functions, for the calculation of a trend feature and
    classic **Short-Term Average**/**Long-Term Average** (**STA**/**LTA**). STA/LTA
    is a seismic signal analysis technique used in seismology. It measures the ratio
    of short-term to long-term signal averages. It is useful in earthquake detection
    as it identifies distinct patterns in seismic data. Therefore, it will also be
    a useful feature to include in our model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We show here the code to calculate the trend feature. This is calculated using
    a linear regression model (for 1D data) and retrieves the slope of the resulting
    regression line. We use the option to transform all the sampled data into positive
    values before performing regression (that is, calculating the slope/trend for
    the absolute values of the data). The trend data contains important information
    about the overall signal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we calculate the classic STA/LTA, which represents the ratio between
    the amplitude of the signal of a short time window of length `STA` and a long
    time window, `LTA`. The function receives as parameters the signal and the length
    for the short-time average and long-time average windows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Next, we implement the function to calculate features, which receives as parameters
    the sample index, the data subsample, and a handle to the transformed training
    data. This function will use various signal processing algorithms to build aggregated
    features from the time variation acoustic signal per segment. In the case of the
    training data, we use windows of 150K rows from the training set (without stride).
    In the case of the test set, each test file represents a segment of 150K. In the
    following subsections, we will review the engineered features that will be included
    in the model.
  prefs: []
  type: TYPE_NORMAL
- en: FFT-derived features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the features of the model is the **Fast Fourier Transform** (**FFT**)
    applied to the entire segment; this is not directly used as a feature but as a
    basis for the calculation of multiple aggregation functions (see next subsection).
    The FFT is calculated using a fast implementation of the discrete Fourier transform.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are using `numpy` implementations for **FFT** for one-dimensional arrays
    (`fft.fft`), which is extremely fast, `numpy` being based on **BLAS** (**Basic
    Linear Algebra Subprograms**) and **Lapack** (**Linear Algebra PACkage**), two
    libraries that provide routines for performing basic vector and matrix operations
    and solving linear algebra equations. The output of the function used here is
    a one-dimensional array of complex values. Then, we extract the vectors of real
    and imaginary parts from the array of complex values, and we calculate the following
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract real and imaginary parts of the FFT; this is the first part of further
    processing the Fourier fast transform of the acoustic signal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate the mean, standard deviation, min, and max for both the real and imaginary
    parts of the FFT. From the previous transformation, which separates the real and
    imaginary parts of the FFT, we then calculate these aggregate functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate the mean, standard deviation, min and max for both the real and imaginary
    parts of the FFT for 5K and 15K data points from the end of the FFT vector.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code to create the file segment as well as the FFT and FFT-derived features
    is given here. First, we calculate the FFT for the subset of the acoustic data.
    Then, we calculate the real and imaginary parts of the FFT. From the real FFT
    component, we calculate, using pandas’ aggregated functions, the mean, standard
    deviation, max, and min values. We then calculate similar values from the imaginary
    part of the FFT signal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We then follow with calculating features derived from various aggregated functions.
  prefs: []
  type: TYPE_NORMAL
- en: Features derived from aggregate functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The mean, standard deviation, max, and min applied to the entire segment are
    calculated with the following code, using pandas’ aggregate functions `mean`,
    `std`, `max`, and `min`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We continue to compute additional aggregated features. For our model, we will
    include various signal processing techniques, as you’ll notice, and then, by measuring
    the feature importance after we train our baseline model, we will qualify which
    features contribute more to our model prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving on, we calculate the mean change for the entire segment; here, “segment”
    refers to the original subset of acoustic data. `change` is calculated with the
    `numpy` function `diff` and the parameter `1`. This function receives an array
    of values and calculates the difference between each successive value in the array.
    Then we calculate the average of the values in the array of differences. We also
    calculate the mean change rate for the entire acoustic data segment. This is calculated
    as the average of non-zero values in the new change vector divided by the original
    values in the data segment. The code for these features is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Additionally, we also calculate the maximum and minimum of the absolute values
    (per entire segment). After calculating the absolute values, we calculate the
    minimum and maximum values.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are trying to include a diverse range of features, to capture as much of
    the signal patterns as possible, when we aggregate the temporal signal. The code
    for this is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'A set of aggregated functions on the first and last 10K and 50K values per
    acoustic data segment can also be calculated, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Standard deviation for first 50K and last 10K values per acoustic data segment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Average value for first 50K and last 10K values per acoustic data segment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimum values for first 50K and last 10K values per acoustic data segment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum values for first 50K and last 10K values per acoustic data segment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These features are aggregating a smaller part of the signal and therefore will
    capture signal characteristics from only a smaller interval before the failure.
    The combination of aggregated features on the whole signal length and on a smaller
    part of the signal will add more information about the signal. The code for these
    features will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we include the ratio of maximum to minimum values for the entire acoustic
    data segment and the difference between the maximum and minimum values for the
    entire acoustic data segment. We also add the number of values exceeding a certain
    amplitude of oscillation (above 500 units) and the sum of values per entire segment.
    We try to capture some of the hidden patterns in the signal using this diversity
    of features we engineer. In particular, here, we include information from the
    extreme oscillations in the signal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We continue to add diverse aggregated features that try to capture various
    characteristics of the original signal. We further calculate the mean change rate
    (excluding nulls) for the first 10K and last 50K data points per acoustic data
    segment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Some of the features we are adding will exclude the elements in the data that
    are `0`, to ensure only non-zero values are included in the calculation of the
    aggregated function. The code for using the `nonzero` function is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'A set of engineered features involves quantiles, specifically the 01%, 05%,
    95%, and 99% quantile values, for the entire acoustic data segment. The quantiles
    are calculated using the `numpy` `quantile` function. A quantile is a statistical
    term that refers to dividing a dataset into intervals of equal probability. For
    example, a 75% quantile value is the point where 75% of the data has values less
    than that number. A 50% quantile is the point where 50% of the data has values
    less than that number (and is also called the median). We also add absolute values
    for the 01%, 05%, 95%, and 99% quantile values. See the following code for the
    calculation of these features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Another type of engineered feature introduced is trend values (calculated with
    the `add_trend_values` function with the absolute flag off). Trend values will
    capture the general direction in which the acoustic data signal is changing. For
    a signal that shows an oscillation around 0 with high frequency, the trend will
    capture the change in the average value of the actual signal.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also add absolute trend values (calculated with the `add_trend_values` function
    with the absolute flag on). We include this type of engineering feature to capture
    patterns in the signal that appear in the absolute value of the signal. In this
    case, for the calculation of the trend, we use the absolute values of the original
    signal. Therefore, this trend will capture the direction of variation of the absolute
    value of the signal. The corresponding code is given here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we include the mean of absolute values and the standard deviation of
    absolute values. Median absolute deviation (`mad`), `Kurtosis`, `Skew` (skewness),
    and `Median` values are also calculated. These functions are calculated using
    a `numpy` implementation. The median absolute deviation is a robust measure of
    the variability of a univariate sample of quantitative data. Kurtosis is a measure
    of the combined weight of a distribution tail relative to the center of the distribution.
    Skew (from skewness) is a measure of the asymmetry or distortion of a symmetric
    distribution. The median is, as we’ve already observed, the value separating the
    higher half from the lower half of a set of data. All these aggregated functions
    capture complementary information about the signal. The code for the calculation
    of these aggregation functions is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Next, we include several features calculated by using transformation functions
    specific to signal processing.
  prefs: []
  type: TYPE_NORMAL
- en: Features derived using the Hilbert transform and Hann window
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We also calculate the Hilbert mean. We apply the Hilbert transform of the acoustic
    signal segment using the `scipy.signal.hilbert` function. This calculates the
    analytic signal, using the Hilbert transform. Then, we calculate the mean of the
    absolute value of the transformed data. The Hilbert transform is used frequently
    in signal processing and captures important information about the signal. Because
    we use aggregation functions to generate features from our temporal data, we would
    like to include a large, diverse range of existing signal processing techniques,
    to add important complementary elements of the signal when training the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we include a feature derived from the Hann window mean value. We use
    this feature derived from the Hann window to reduce the abrupt discontinuities
    at the edge of the signal. The Hann window mean value is calculated using the
    convolution of the original signal with the result of the Hanning window and dividing
    by the sum of all values in the Hanning window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We previously introduced the definition of classical STA/LTA. We calculate
    a few features like classical STA/LTA mean for 500-10K, 5K-100K, 3,333-6,666,
    and 10K-25K STA/LTA windows. These are calculated with the STA/LTA function introduced
    previously. We include a variety of transformations to try to capture diverse
    signal characteristics in the aggregated engineering features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we will also calculate features based on moving averages.
  prefs: []
  type: TYPE_NORMAL
- en: Features based on moving averages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we calculate several moving averages, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Moving average means for the 700, 1.5K, 3K, and 6K windows (and excluding NaNs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exponentially weighted moving average with spans of 300, 3K, and 6K
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Average standard deviation moving average over 700 and 400 windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving averages means for 700-size window plus or minus 2 times average standard
    deviation moving average over the same size window
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The moving averages help us to discern patterns, reduce noise, and provide
    a clear picture of the underlying trends in the data. The code for that will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We also calculate the **IQR**, the 001% and 999% quantiles. The **IQR** (meaning
    **interquartile range**) is calculated by subtracting the 25% percentile from
    the 75% percentile (using `numpy` functions). The interquartile range is the region
    where 50% of the data is found. The 001% and 999% quantiles are also calculated
    with the `numpy` function for quantiles. The IQR and the various other quantiles
    we have included are useful because they provide important information about the
    central tendency and the spread of the signal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'For windows of 10, 100, and 1,000, we calculate the moving average and moving
    standard deviation. With these values, we then calculate the min, max, mean, standard
    deviation, average absolute and relative change, 01%, 05%, 95%, and 99% quantiles,
    and absolute max roll. We include these features because they reveal information
    about the local characteristics of the signal within the specified window. Subsequently,
    for the features derived from the moving average standard deviation calculated
    for windows of 10, 100, and 1,000, the code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'For the features derived from the moving average mean, calculated for windows
    of 10, 100, and 1,000, the code is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'For each 150K-row segment generated from the training data, we are calculating
    these features. Then, the time to failure is selected as the value from the last
    row in the current segment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we are scaling all features using a `StandardScaler`. This is not mandatory
    if we are using a model based on decision trees (such as random forest or XGBoost).
    We include this step for a case where we would like to use other models, for example,
    one based on neural networks, where normalizing the features would be a necessary
    step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We repeat the same process for test data segments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: After we analyzed the data, we generated a set of engineered features. We intend
    to use these features to build a baseline model. Then, based on the model evaluation,
    we can further select what features to keep and, eventually, to create new features.
  prefs: []
  type: TYPE_NORMAL
- en: Building a baseline model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From the original temporal data, through feature engineering, we generated
    time-aggregated features for each time segment in the training data, equal in
    duration with one test set. For the baseline model demonstrated in this competition,
    we chose `LGBMRegressor`, one of the best-performing algorithms at the time of
    the competition, which, in many cases, had a similar performance to `XGBoost`.
    The training data is split using `KFold` into five splits, and we run training
    and validation for each fold until we reach the final number of iterations or
    when the validation error ceases to improve after a specified number of steps
    (given by the *patience* parameter). For each split, we then also run the prediction
    for the test set, with the best model – trained with the current train split for
    the current fold, that is, with 4/5 from the training set. At the end, we will
    work out the average of the predictions obtained for each fold. We can use this
    cross-validation approach because our data is no longer temporal (time-series)
    data. We split the data into segments of 150K rows, of the same length as the
    test data, and then created aggregated features from this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The model parameters are given in the following code excerpt. We set some of
    the usual parameters for LightGBM, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The number of leaves**: This parameter controls the number of leaves (or
    terminal nodes) in each tree. An increasing number of leaves allows the model
    to capture more complex patterns but also increases the risk of overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minimum data in leaf**: If the number of samples in a leaf node is below
    this threshold, the node will not split. This parameter helps control overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The objective**: This is regression for our model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning rate**: This will control how fast the model learns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The boosting method**: We can choose between gradient-boosted decision trees
    (*gbdt*), dart gradient boosting (*dgb*), and gradient-based one-side sampling
    (*goss*). We are using *gbdt* here.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The feature fraction**: This is the percentage of features used in a subset
    of data presented to a tree within the tree ensemble employed by the algorithm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bagging frequency, bagging fraction, and bagging seed**: These control how
    we divide the sample set presented to the algorithm when we subsample it to present
    it to different trees.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metric**: In this case, *mae*, which is the mean absolute error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regularization factor lambda_l1**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Verbosity**: This parameter controls the amount of information the algorithm
    prints to the console during training. A verbosity of 0 means silent mode (no
    information), while a verbosity of 1 prints messages about the training progress.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of parallel processing threads**: This parameter controls the number
    of parallel threads used by the algorithm during training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The randomization factor random_state**: This parameter is the random seed
    used to initialize various parameters of the algorithm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The code for training, validation, and testing (per fold) is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We initialize the prediction vector (which has the dimension of the submission
    file, that is, one entry for each test segment) with zeros. We also initialize
    an out-of-folds vector (the length of the training data, which is the number of
    training segments).
  prefs: []
  type: TYPE_NORMAL
- en: For each fold, we sample subsets of data and target values for both the training
    and validation sets. Then, we use them as input for the model, `LGBMRegressor`,
    initialized with the model parameters defined before (we also add the number of
    estimators and the number of workers). We fit the model with the subset of the
    training set corresponding to the current fold and validate it with the corresponding
    validation subset of the training data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We set the evaluation metric as well: *mae* – meaning *mean absolute error*
    – the frequency for printing out the evaluation error, and the number of iterations
    for early stopping. This parameter (number of iterations for early stopping) controls
    the number of steps that the algorithm waits before stopping, when the validation
    error does not improve during training. We accumulate the validation results in
    the **oof** (**out-of-folds**) vector and concatenate the feature importance vector
    for the current fold to the feature importance DataFrame. Early stopping is used
    to keep the best model for prediction – based on validation during training.'
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance will be used to observe, during the iterative process of
    feature engineering, feature selection, and model training – if, for a model trained
    with certain features, the feature importance does not have a high variation between
    folds. At each fold, we are also running a prediction for the entire test set,
    with the model trained and validated per fold. Then, we increment the prediction
    vector with the values per fold, divided by the number of folds. This is equivalent
    to a model ensemble, where each model is trained with a different subset of data,
    corresponding to each fold split.
  prefs: []
  type: TYPE_NORMAL
- en: 'When evaluating the current model, we will examine three pieces of information:
    the training and validation errors, the variation of these errors across the folds,
    and the variation of feature importance between the folds. Ideally, these variations
    – of training and validation errors across folds, as well as the feature importance
    variation across folds – are smaller. *Figure 8.8* shows the evaluation plots
    from the training of the baseline model.'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we plot the training progress at every 1,000th step (verbosity
    set to `1000`), and implement an early stop at 500 (training stops if there’s
    no improvement in the validation error for the last 500 iterations). The best
    model (in terms of validation error) is retained for predicting from the test.
    Test prediction is averaged over the five splits.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer program  Description automatically generated](img/B20963_08_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.8: Model training evaluation output – training and validation error'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8.9* shows the feature importance graph, with the average value per
    fold and the standard deviation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A colorful graph with numbers  Description automatically generated with medium
    confidence](img/B20963_08_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.9: Feature importance: average and standard deviation values (from
    values on the five folds) – top 20 features'
  prefs: []
  type: TYPE_NORMAL
- en: After we performed data analysis, we proceeded with building time-aggregated
    features, on subsets of the training set with the same duration as the test sets.
    With the new dataset formed with the engineered features, we trained a baseline
    model. For the baseline model, we used cross-validation with five folds and used
    each fold model for the prediction of the test set. The final prediction was formed
    by averaging the predictions for each fold.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we delved into handling signal data, focusing particularly
    on audio signals. We explored various storage formats for such data and examined
    libraries for loading, transforming, and visualizing this data type. To develop
    potent features, we applied a range of signal-processing techniques. Our feature
    engineering efforts transformed time-series data from each training segment and
    aggregated features for each test set.
  prefs: []
  type: TYPE_NORMAL
- en: We consolidated all feature engineering processes into a single function, applicable
    to all training segments and test sets. The transformed features underwent scaling.
    We then used this prepared data to train a baseline model utilizing the LGBMRegressor
    algorithm. This model employed cross-validation, and we generated predictions
    for the test set using the model trained in each fold. Subsequently, we aggregated
    these predictions to create the submission file. Additionally, we captured and
    visualized the feature importance for each fold.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'LANL Earthquake Prediction, Can you predict upcoming laboratory earthquakes?,
    Kaggle Competition: [https://www.kaggle.com/competitions/LANL-Earthquake-Prediction](https://www.kaggle.com/competitions/LANL-Earthquake-Prediction)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Gabriel Preda, LANL Earthquake EDA and Prediction: [https://www.kaggle.com/code/gpreda/lanl-earthquake-eda-and-prediction](https://www.kaggle.com/code/gpreda/lanl-earthquake-eda-and-prediction)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'LANL Earthquake Prediction, dataset description: [https://www.kaggle.com/competitions/LANL-Earthquake-Prediction/data](https://www.kaggle.com/competitions/LANL-Earthquake-Prediction/data)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'BirdCLEF 2021 - Birdcall Identification, identify bird calls in soundscape
    recordings, Kaggle competition: [https://www.kaggle.com/competitions/birdclef-2021](https://www.kaggle.com/competitions/birdclef-2021)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'McFee, Brian, Colin Raffel, Dawen Liang, Daniel PW Ellis, Matt McVicar, Eric
    Battenberg, and Oriol Nieto. “librosa: Audio and music signal analysis in Python.”
    In Proceedings of the 14th Python in Science Conference, pp. 18-25\. 2015'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'librosa load function: [https://librosa.org/doc/main/generated/librosa.load.html](https://librosa.org/doc/main/generated/librosa.load.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Cornell Birdcall Identification, Kaggle competition: [https://www.kaggle.com/competitions/birdsong-recognition](https://www.kaggle.com/competitions/birdsong-recognition)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'EarthData MERRA2 CO, Earth Data NASA Satellite Measurements, Kaggle dataset:
    [https://www.kaggle.com/datasets/gpreda/earthdata-merra2-co](https://www.kaggle.com/datasets/gpreda/earthdata-merra2-co)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Gabriel Preda, EARTHDATA-MERRA2 Data Exploration, Kaggle Notebook: [https://www.kaggle.com/code/gpreda/earthdata-merra2-data-exploration](https://www.kaggle.com/code/gpreda/earthdata-merra2-data-exploration)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/kaggle](https://packt.link/kaggle)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code9220780366773140.png)'
  prefs: []
  type: TYPE_IMG
