- en: Evaluating Results with TensorBoard
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorBoard评估结果
- en: In the previous chapter, we understood how a neural network works, what the
    various hyper parameters in a neural network are, and how they can be tweaked
    further to improve our model's accuracy.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解了神经网络的工作原理，神经网络中的各种超参数是什么，以及如何进一步调整它们以提高我们模型的准确性。
- en: Google offers TensorBoard, a visualization of the model training logs. In this
    chapter, we show how to use TensorBoard for TensorFlow and Keras. We interpret
    the visualizations generated by TensorBoard to understand the performance of our
    models, and also understand the other functionalities in TensorBoard that can
    help visualize our dataset better.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Google提供了TensorBoard，它是模型训练日志的可视化。在本章中，我们展示了如何使用TensorBoard进行TensorFlow和Keras。我们解释TensorBoard生成的可视化，以了解我们模型的性能，并了解TensorBoard中的其他功能，这些功能可以帮助我们更好地可视化数据集。
- en: As discussed in the previous chapter, Keras as a framework is a wrapper on top
    of either TensorFlow or Theano. The computations that you'll use TensorFlow for,
    such as training a massive deep neural network, can be complex and confusing.
    To make it easier to understand, debug, and optimize TensorFlow programs, the
    creators of TensorFlow have included a suite of visualization tools called TensorBoard.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，Keras作为一个框架，是TensorFlow或Theano之上的包装器。你将使用TensorFlow进行的一些计算，例如训练一个大规模的深度神经网络，可能很复杂且令人困惑。为了使其更容易理解、调试和优化TensorFlow程序，TensorFlow的创建者包括了一套名为TensorBoard的可视化工具。
- en: 'You can use TensorBoard to visualize your TensorFlow graph, plot quantitative
    metrics about the execution of your graph, and also to see additional data such
    as images that were given as input. When TensorBoard is fully configured, it looks
    like this:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用TensorBoard来可视化你的TensorFlow图，绘制关于图执行的定量指标，还可以看到输入的图像等额外数据。当TensorBoard完全配置后，它看起来像这样：
- en: '![](img/1f8752e6-b68a-47ca-9948-880978984c6c.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1f8752e6-b68a-47ca-9948-880978984c6c.png)'
- en: 'From this screenshot, you can note that the chart shows a reduction in mean
    cross-entropy error over an increasing number of epochs. In the later sections
    of the chapter, we will go through the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 从这张截图，你可以注意到图表显示了随着epoch数量的增加，平均交叉熵误差的减少。在章节的后续部分，我们将介绍以下内容：
- en: Installing TensorBoard
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装TensorBoard
- en: Overview of the various summary operations captured by TensorBoard
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorBoard捕获的各种总结操作的概述
- en: Ways to debug the code
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试代码的方法
- en: Setting up TensorBoard
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置TensorBoard
- en: 'In the previous chapter, we understood how Datalab can be set up. Installing
    TensorBoard in Datalab is as simple as specifying the following code:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解了如何设置Datalab。在Datalab中安装TensorBoard与指定以下代码一样简单：
- en: '![](img/511333e7-ab7a-4ca9-bea2-b029111e5df1.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/511333e7-ab7a-4ca9-bea2-b029111e5df1.png)'
- en: Note that we need not make any separate installations for TensorBoard and it
    comes in prebuilt within the `google.datalab.ml` package.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们不需要为TensorBoard进行任何单独的安装，它包含在`google.datalab.ml`包中预构建的。
- en: Once the package is imported, we need to start TensorBoard by specifying the
    location of logs that contain the summaries written by the model fitting process.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦导入包，我们需要通过指定包含模型拟合过程写入的总结的日志位置来启动TensorBoard。
- en: 'The `tb.start` method works as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`tb.start`方法的工作原理如下：'
- en: '![](img/9c3873ed-70ef-4ff0-8a78-176c7d92b25f.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9c3873ed-70ef-4ff0-8a78-176c7d92b25f.png)'
- en: Note that, in the first step, it checks whether the user is permitted to perform
    the calculation. Next, it picks up an unused port to open TensorBoard, and finally
    it starts TensorBoard along with printing the link to open TensorBoard.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在第一步中，它检查用户是否有权执行计算。接下来，它选择一个未使用的端口来打开TensorBoard，最后它启动TensorBoard并打印打开TensorBoard的链接。
- en: We will learn more about writing to logs in the next section.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中学习更多关于写入日志的内容。
- en: Overview of summary operations
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结操作的概述
- en: Summaries provide a way to export condensed information about a model, which
    is then accessible in tools such as TensorBoard.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 总结提供了一种导出关于模型压缩信息的方法，然后可以在TensorBoard等工具中访问。
- en: 'Some of the commonly used summary functions are:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常用的总结函数包括：
- en: '`scalar`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`标量`'
- en: '`histogram`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`直方图`'
- en: '`audio`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`音频`'
- en: '`image`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`图像`'
- en: '`merge`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`合并`'
- en: '`merge_all`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`merge_all`'
- en: A `scalar` summary operation returns a scalar, that is, the value of a certain
    metric over an increasing number of epochs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`标量`总结操作返回一个标量，即随着epoch数量的增加，某个度量值的值。
- en: A `histogram` summary operation returns the histogram of various values—potentially
    weights and biases at each layer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: The `image` and `audio` summary operations return images and audio, which can
    be visualized and played in TensorBoard respectively.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: A `merge` operation returns the union of all the values of input summaries,
    while `merge_all` returns the union of all the summaries contained in the model
    specification.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: A visualization of some of the summaries discussed here will be provided in
    the next section.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Ways to debug the code
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to understand how TensorBoard helps, let''s initialize a model structure
    as follows, one that is bound not to work:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f3e3e0a0-cdf1-4c9f-8ff0-08992cd12529.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: Note that, in this code snippet, the validation accuracy is only around 19%.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: The reason for such a low validation accuracy is that the input dataset is not
    scaled and we are performing ReLU activation on top of an unscaled dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Note that, in the preceding code, we are storing the logs of the model run in
    the directory `logs/tensor_new6` (the sub-directory could be named anything).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the logs are stored in this location, we start TensorBoard as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d6a09942-e1d6-4b66-90f0-9298a2042a29.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: 'The preceding code starts TensorBoard, which looks like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d81b685-ae67-4660-b155-8dae3419df78.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: Note that, by default, the output gives a measure of the scalars, that is, the
    accuracy and loss values of both the train and test datasets.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'The outputs can be visualized adjacent to each other using the regular expression
    `.*` in `Filter` tags, as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d87aac5c-cfc5-4c46-98c1-63da4e1f35ee.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: Note that the first two graphs in this screenshot represent the accuracy and
    loss of train datasets, while the next two graphs represent the accuracy and loss
    of validation datasets.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'When we look at the histogram of weights and bias across various layers, we
    learn that the weights and biases do not change across epochs:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ecc83cb-f675-4804-920f-46e33f2ac6e8.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: This is an indication that no learning is happening in the network architecture.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'The same can be noted when we look at the distribution of weights and biases
    across epochs in a different tab:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f4d12641-71a9-499b-9f6f-63fde2752466.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: From this screenshot, we can conclude why the accuracy of the model is so low;
    it's because the model is not able to update the weights.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, by clicking on the GRAPHS tab, let us explore whether the model was initialized
    correctly:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9593e451-3861-4eb7-b386-00c49adc8c6e.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: You should notice that the training block is connected to every other block
    in the graph. This is because, in order to compute the gradients, one needs to
    connect to every variable in the graph (as every variable contains weights that
    need to be adjusted).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us, for now, remove the training block from the graph. This is done by
    right-clicking on the training block, as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e44be15-e1ee-4505-924e-aef7c22bc855.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
- en: 'The resultant graph after removing the training block is as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dc17e10a-a576-45a9-9064-6f845e13dc31.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: 'Note that the input layer is connected to hidden layer, which in turn is connected
    to output layer, from which the metrics and loss are calculated. Let us explore
    the connections by double-clicking on the individual blocks, as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ca36387e-45c9-4775-83e5-2c4939cad734.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
- en: 'A zoom-in of these connections helps us understand the shapes at various blocks:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/957aa933-eadd-4b45-920a-94f5db891ece.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
- en: The input layer is (784) in dimension, as there could be any number of input
    samples but each of them are 784-dimensional. Similarly, the kernel (weight matrix)
    is 784 x 784 in dimensions and the bias would have 784 initialized values, and
    so on.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Note that, in the preceding diagram, we take the values in input layer and perform
    matrix multiplication with the kernel that is initialized using `random_normal`
    initialization. Also note that `random_normal` initialization is not connected
    to the training block, while the kernel block is connected to the training block.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us also find out whether the output layer is connected to all the relevant
    blocks per expectations. Given that the graph looks very complicated, we can use
    another functionality provided in TensorBoard: Trace inputs. Trace inputs help
    in highlighting only those blocks that are connected to any block of interest.
    It is activated by selecting the block of interest and toggling the switch in
    the left-hand pane, as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/92b85145-05ad-468f-9c22-cc3bffe95a54.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: 'Now all the connections look fine, but the gradients are still not getting
    updated; let us change the activation function to sigmoid and then check the weight
    histograms:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'We build a neural network with sigmoid activation as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/546cb038-f973-42c9-8560-4998769eef5a.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: 'Once the neural network structure is defined and compiled, let us fit the model
    as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/81de7d25-9b97-4a62-b351-2bb125af4b68.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: 'In order to open TensorBoard, we will execute the following code:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will then receive the following output:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2f94c332-4bbb-407b-936a-db78f0c9c2cf.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: 'At the same time, we should notice that the accuracy and loss metrics have
    improved considerably:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/108592f0-b4a0-44c1-b55a-bd973f9c8245.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: 'One would also be able to visualize the histogram of gradients by specifying
    write_grads=True in the TensorBoard function. The output would then be as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/08f06dd8-d983-49f5-acf5-2c8127f65375.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: Setting up TensorBoard from TensorFlow
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, we have seen that there are two ways to define a model
    in TensorFlow:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Premade estimators
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a custom estimator
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following code, we will consider one additional snippet of code that
    would enable us to visualize the various summary operations:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d6200657-4ef8-4d03-a86f-3f3ed8fecd99.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
- en: Note that we only need to specify the `model_dir` in the premade estimator to
    store the various log files generated from TensorFlow operations.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们只需要在预制的估计器中指定 `model_dir` 来存储由 TensorFlow 操作生成的各种日志文件。
- en: 'TensorBoard can then be initialized by referring to the model directory, as
    follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以通过引用模型目录来初始化 TensorBoard，如下所示：
- en: '![](img/9662f9da-adb9-48f9-8d79-d1fe88ef3c8b.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9662f9da-adb9-48f9-8d79-d1fe88ef3c8b.png)'
- en: The preceding code would result in a TensorBoard visualization that would have
    all the summaries built in.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将导致 TensorBoard 可视化，其中将包含所有内置的摘要。
- en: Summaries from custom estimator
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义估计器的摘要
- en: In the previous section, we looked at obtaining predefined summaries from premade
    estimators in TensorBoard. In this section, we will understand obtaining summaries
    in custom estimators so that they can be visualized in TensorBoard.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们探讨了在 TensorBoard 中从预制的估计器获取预定义摘要的方法。在本节中，我们将了解如何在自定义估计器中获取摘要，以便它们可以在
    TensorBoard 中进行可视化。
- en: 'The summary operations that need to be captured should be specified in the
    custom estimator function, as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 需要捕获的摘要操作应在自定义估计器函数中指定，如下所示：
- en: '![](img/f0b30c65-9d1a-4d65-9e46-f6b8bdde557a.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f0b30c65-9d1a-4d65-9e46-f6b8bdde557a.png)'
- en: Note that the model function remains very similar to what we defined in the
    previous section while learning about custom estimators; however, a few lines
    of code that write summary to log files are added.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，模型函数与我们之前在了解自定义估计器时定义的非常相似；然而，添加了一些将摘要写入日志文件的代码行。
- en: '`tf.summary.scalar` adds the accuracy metric. Similarly, we might have wanted
    to add loss (which is another scalar) to logs; however, it gets added by default
    (note that loss is displayed when we train the model).'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.summary.scalar` 添加了准确度指标。同样，我们可能还想将损失（另一个标量）添加到日志中；然而，它默认添加（注意，当训练模型时损失会被显示）。'
- en: '`tf.summary.histogram` gives a distribution of weights within the network.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.summary.histogram` 提供了网络中权重的分布。'
- en: 'Once the model is trained, we should notice the scalars and histogram/distributions
    in the TensorBoard output. The code to train the model and start TensorBoard is
    as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，我们应该注意 TensorBoard 输出中的标量和直方图/分布。训练模型并启动 TensorBoard 的代码如下：
- en: '![](img/35306ac3-eb5e-4b9f-a8c1-689db7b14520.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/35306ac3-eb5e-4b9f-a8c1-689db7b14520.png)'
- en: 'In the preceding code snippet, we have specified the model function and parameters
    and the directory to which the log files would be written:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码片段中，我们指定了模型函数和参数以及日志文件将被写入的目录：
- en: '[PRE1]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding code snippet trains the model for 1,000 batches of 1,024 (batch
    size) data points:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段训练了包含 1,024（批大小）数据点的 1,000 批次的模型：
- en: '[PRE2]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This code snippet starts TensorBoard by using the log files written in the given
    folder.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段通过使用给定文件夹中编写的日志文件启动 TensorBoard。
- en: Summary
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we understood visualizing neural network models in TensorBoard,
    both from Keras and TensorFlow. We also considered how to visualize the models,
    distribution of weights, and loss/accuracy metrics in both premade estimators
    and custom defined estimators. And also the various metrics in neural networks.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了在 TensorBoard 中可视化神经网络模型的方法，包括从 Keras 和 TensorFlow 中进行可视化。我们还考虑了如何在预制的估计器和自定义定义的估计器中可视化模型、权重分布以及损失/准确度指标。以及神经网络中的各种指标。
