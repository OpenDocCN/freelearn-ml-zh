- en: Customer Relationship Prediction with Ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Any type of company that offers a service, product, or experience needs a solid
    understanding of their relationship with their customers; therefore, **customer
    relationship management** (**CRM**) is a key element of modern marketing strategies.
    One of the biggest challenges that businesses face is the need to understand exactly
    what causes a customer to buy new products.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will work on a real-world marketing database provided by
    the French telecom company, Orange. The task will be to estimate the likelihood
    of the following customer actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Switch provider (churn)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buy new products or services (appetency)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buy upgrades or add-ons proposed to them to make the sale more profitable (upselling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will tackle the **Knowledge Discovery and Data Mining** (**KDD**) Cup 2009
    challenge and show the steps to process the data using Weka. First, we will parse
    and load the data and implement the basic baseline models. Later, we will address
    advanced modeling techniques, including data preprocessing, attribute selection,
    model selection, and evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: The KDD Cup is the leading data mining competition in the world. It is organized
    annually by the ACM **Special Interest Group on Knowledge Discovery and Data Mining**.
    The winners are announced at the Conference on Knowledge Discovery and Data Mining,
    which is usually held in August. Yearly archives, including all of the corresponding
    datasets, are available at [http://www.kdd.org/kdd-cup](http://www.kdd.org/kdd-cup).
  prefs: []
  type: TYPE_NORMAL
- en: The customer relationship database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most practical way to build knowledge on customer behavior is to produce
    scores that explain a target variable, such as churn, appetency, or upselling.
    The score is computed by a model using input variables that describe customers;
    for example, their current subscription, purchased devices, consumed minutes,
    and so on. The scores are then used by the information system for things like
    providing relevant personalized marketing actions.
  prefs: []
  type: TYPE_NORMAL
- en: A customer is the main entity in most of the customer-based relationship databases;
    getting to know the customer's behavior is important. The customer's behavior
    produces a score in relation to the churn, appetency, or upselling. The basic
    idea is to produce a score using a computational model, which may use different
    parameters, such as the current subscription of the customer, devices purchased,
    minutes consumed, and so on. Once the score is formed, it is used by the information
    system to decide on the next strategy, which is especially designed for the customer,
    based on his or her behavior.
  prefs: []
  type: TYPE_NORMAL
- en: In 2009, the conference on KDD organized a machine learning challenge on customer
    relationship prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Challenge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Given a large set of customer attributes, the task in the challenge was to
    estimate the following target variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Churn probability**: This is the likelihood that a customer will switch providers.
    The churn rate is also known as the attrition rate or the participant turnover
    rate, and is a measure used to find the number of individuals, objects, terms,
    or items moving into or out of a given collection, over a given time period. The
    term is heavily used in industries that are driven by customers and use subscriber-based
    models; for example, the cell phone industry and cable TV operators.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Appetency probability**: This is the propensity to buy a service or product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Upselling probability**: This is the likelihood that a customer will buy
    an add-on or upgrade. Upselling implies selling something in addition to what
    the customer is already using. Consider it like the value-added services that
    are provided by most cell phone operators. Using sales techniques, salesmen try
    to make customers opt for value-added services, which will bring more revenue.
    Many times, customers are not aware of other options, and the salesmen convince
    them to use or consider those options.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The challenge was to beat the in-house system developed by Orange Labs. This
    was an opportunity for the participants to prove that they could handle a large
    database, including heterogeneous, noisy data, and unbalanced class distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the challenge, Orange released a large dataset of customer data, containing
    about one million customers, described in ten tables with hundreds of fields.
    In the first step, they resampled the data to select a less unbalanced subset,
    containing 100,000 customers. In the second step, they used an automatic feature
    construction tool that generated 20,000 features describing the customers, which
    was then narrowed down to 15,000 features. In the third step, the dataset was
    anonymized by randomizing the order of features, discarding the attribute names,
    replacing the nominal variables with randomly generated strings, and multiplying
    the continuous attributes by a random factor. Finally, all of the instances were
    split randomly into training and testing datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The KDD Cup provided two sets of data, a large set and a small set, corresponding
    to fast and slow challenges, respectively. Both the training and testing sets
    contained 50,000 examples, and the data was split similarly, but the samples were
    ordered differently for each set.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will work with the small dataset, consisting of 50,000 instances,
    each described with 230 variables. Each of the 50,000 rows of data corresponds
    to a client, and they are associated with three binary outcomes, one for each
    of the three challenges (upselling, churn, and appetency).
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this clearer, the following table illustrates the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fda8bb7a-606b-453b-9097-f8d72776f4eb.png)'
  prefs: []
  type: TYPE_IMG
- en: The table depicts the first 25 instances, that is, customers, each described
    with 250 attributes. For this example, only a selected subset of 10 attributes
    is shown. The dataset contains many missing values, and even empty or constant
    attributes. The last three columns of the table correspond to the three distinct
    class labels involving the ground truth, that is, if the customer indeed switched
    providers (churn), bought a service (appetency), or bought an upgrade (upsell).
    However, note that the labels are provided separately from the data in three distinct
    files, hence it is essential to retain the order of the instances and the corresponding
    class labels to ensure proper correspondence.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The submissions were evaluated according to the arithmetic mean of the area
    under the ROC curve for the three tasks (churn, appetency, and upselling). The
    ROC curve shows the performance of the model as a curve obtained by plotting the
    sensitivity against specificity for various threshold values used to determine
    the classification result (refer to [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml),
    *Applied Machine Learning Quick Start*, in the section *ROC curves*). Now, the
    **area under the ROC** **curve** (**AUC**) is related to the area under this curve
    â€“ the larger the area, the better the classifier). Most toolboxes, including Weka,
    provide an API to calculate the AUC score.
  prefs: []
  type: TYPE_NORMAL
- en: Basic Naive Bayes classifier baseline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As per the rules of the challenge, the participants had to outperform the basic
    Naive Bayes classifier in order to qualify for prizes, which makes an assumption
    that features are independent (refer to [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml),
    *Applied Machine Learning Quick Start*).
  prefs: []
  type: TYPE_NORMAL
- en: 'The KDD Cup organizers ran the vanilla Naive Bayes classifier, without any
    feature selection or hyperparameter adjustments. For the large dataset, the overall
    scores of the Naive Bayes on the test set were as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Churn problem**: AUC = 0.6468'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Appetency problem**: AUC = 0.6453'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Upselling problem**: AUC=0.7211'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the baseline results are only reported for the large dataset. Moreover,
    while both the training and testing datasets are provided at the KDD Cup site,
    the actual true labels for the test set are not provided. Therefore, when we process
    the data with our models, there is no way to know how well the models will perform
    on the test set. What we will do is only use the training data, and evaluate our
    models with cross-validation. The results will not be directly comparable, but
    nevertheless, we will have an idea about what a reasonable magnitude of the AUC
    score should be.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the KDD Cup web page ([http://kdd.org/kdd-cup/view/kdd-cup-2009/Data](http://kdd.org/kdd-cup/view/kdd-cup-2009/Data)),
    you should see a page that looks similar to the following screenshot. First, under
    the Small version (230 var.) header, download `orange_small_train.data.zip`. Next,
    download the three sets of true labels associated with this training data. The
    following files are found under the Real binary targets (small) header:'
  prefs: []
  type: TYPE_NORMAL
- en: '`orange_small_train_appentency.labels`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`orange_small_train_churn.labels`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`orange_small_train_upselling.labels`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Save and unzip all of the files marked in the red boxes, as shown in the screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/80d5b9c9-2bfa-43a1-9351-51a883eae104.png)'
  prefs: []
  type: TYPE_IMG
- en: In the following sections, first, we will load the data into Weka and apply
    basic modeling with the Naive Bayes classifier, in order to obtain our own baseline
    AUC scores. Later, we will look at more advanced modeling techniques and tricks.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will load the data to Weka directly from the `.csv` format. For this purpose,
    we will write a function that accepts the path to the data file and the true labels
    file. The function will load and merge both datasets and remove empty attributes.
    We will begin with the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we load the data using the `CSVLoader()` class. Additionally, we specify
    the `\t` tab as a field separator and force the last 40 attributes to be parsed
    as nominal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `CSVLoader` class accepts many additional parameters, specifying the column
    separator, string enclosures, whether a header row is present, and so on. The
    complete documentation is available at [http://weka.sourceforge.net/doc.dev/weka/core/converters/CSVLoader.html](http://weka.sourceforge.net/doc.dev/weka/core/converters/CSVLoader.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the attributes do not contain a single value, and Weka automatically
    recognizes them asÂ `String` attributes. We actually do not need them, so we can
    safely remove them by using the `RemoveType` filter. Additionally, we specify
    the `-T` parameters, which removes an attribute of a specific type and specifies
    the attribute type that we want to remove:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Alternatively, we could use the `void deleteStringAttributes()` method, implemented
    within the `Instances` class, which has the same effect; for example, `data.removeStringAttributes()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will load and assign class labels to the data. We will utilize `CVSLoader`
    again, where we specify that the file does not have any header line, that is,
    `setNoHeaderRowPresent(true)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have loaded both files, we can merge them together by calling the `Instances.mergeInstances
    (Instances, Instances)` static method. The method returns a new dataset that has
    all of the attributes from the first dataset, plus the attributes from the second
    set. Note that the number of instances in both datasets must be the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we set the last attribute, that is, the label attribute that we just
    added, as a target variable, and return the resulting dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The function provides a summary as output, as shown in the following code block,
    and returns the labeled dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Basic modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will implement our own baseline model by following the approach
    that the KDD Cup organizers took. However, before we get to the model, let's first
    implement the evaluation engine that will return the AUC on all three problems.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s take a closer look at the evaluation function. The evaluation function
    accepts an initialized model, cross-validates the model on all three problems,
    and reports the results as an area under the ROC curve (AUC), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we call the `Instance loadData(String, String)` function that we implemented
    earlier to load the training data and merge it with the selected labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we initialize the `weka.classifiers.Evaluation` class and pass our dataset.
    (The dataset is only used to extract data properties; the actual data is not considered.)
    We call the `void crossValidateModel(Classifier, Instances, int, Random)` method
    to begin cross-validation, and we create five folds. As validation is done on
    random subsets of the data, we need to pass a random seed, as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'After the evaluation completes, we read the results by calling the `double
    areUnderROC(int)` method. As the metric depends on the target value that we are
    interested in, the method expects a class value index, which can be extracted
    by searching the index of the `"1"` value in the class attribute, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the results are averaged and returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Implementing the Naive Bayes baseline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, when we have all of the ingredients, we can replicate the Naive Bayes approach
    that we are expected to outperform. This approach will not include any additional
    data preprocessing, attribute selection, or model selection. As we do not have
    true labels for the test data, we will apply five-fold cross-validation to evaluate
    the model on a small dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we initialize a Naive Bayes classifier, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we pass the classifier to our evaluation function, which loads the data
    and applies cross-validation. The function returns an area under the ROC curve
    score for all three problems, and the overall results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In our case, the model returns the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: These results will serve as a baseline when we tackle the challenge with more
    advanced modeling. If we process the data with significantly more sophisticated,
    time-consuming, and complex techniques, we expect the results to be much better.
    Otherwise, we are simply wasting resources. In general, when solving machine learning
    problems, it is always a good idea to create a simple baseline classifier that
    serves us as an orientation point.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced modeling with ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we implemented an orientation baseline; now, let's
    focus on heavy machinery. We will follow the approach taken by the KDD Cup 2009
    winning solution, developed by the IBM research team (Niculescu-Mizil and others).
  prefs: []
  type: TYPE_NORMAL
- en: 'To address this challenge, they used the ensemble selection algorithm (Caruana
    and Niculescu-Mizil, 2004). This is an ensemble method, which means it constructs
    a series of models and combines their output in a specific way, in order to provide
    the final classification. It has several desirable properties that make it a good
    fit for this challenge, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It was proven to be robust, yielding excellent performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can be optimized for a specific performance metric, including AUC.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It allows for different classifiers to be added to the library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is an anytime method, meaning that if we run out of time, we have a solution
    available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we will loosely follow the steps as they are described in their
    report. Note that this is not an exact implementation of their approach, but rather
    a solution overview that will include the necessary steps to dive deeper.
  prefs: []
  type: TYPE_NORMAL
- en: 'A general overview of the steps is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we will preprocess the data by removing attributes that clearly do not
    bring any value â€“ for example, all of the missing or constant values; fixing missing
    values, in order to help machine learning algorithms, which cannot deal with them;
    and converting categorical attributes to numerical attributes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we will run the attribute selection algorithm to select only a subset
    of attributes that can help in the prediction of tasks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the third step, we will instantiate the ensemble selection algorithms with
    a wide variety of models, and finally, we will evaluate the performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Before we start
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this task, we will need an additional Weka package, `ensembleLibrary`.
    Weka 3.7.2 and higher versions support external packages, mainly developed by
    the academic community. A list of WEKA Packages is available at [http://weka.sourceforge.net/packageMetaData](http://weka.sourceforge.net/packageMetaData),
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fbd6a8f5-6251-4690-a3f0-014f6baab657.png)'
  prefs: []
  type: TYPE_IMG
- en: Find and download the latest available version of the `ensembleLibrary` package
    at [http://prdownloads.sourceforge.net/weka/ensembleLibrary1.0.5.zip?download](http://prdownloads.sourceforge.net/weka/ensembleLibrary1.0.5.zip?download).
  prefs: []
  type: TYPE_NORMAL
- en: 'After you unzip the package, locate `ensembleLibrary.jar` and import it into
    your code, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Data preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we will utilize Weka''s built-in `weka.filters.unsupervised.attribute.RemoveUseless`
    filter, which works exactly as its name suggests. It removes the attributes that
    do not vary much, for instance, all constant attributes are removed. The maximum
    variance, which is only applied to nominal attributes, is specified with the `-M`
    parameter. The default parameter is 99%, which means that if more than 99% of
    all instances have unique attribute values, the attribute is removed, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will replace all of the missing values in the dataset with the modes
    (nominal attributes) and means (numeric attributes) from the training data, by
    using the `weka.filters.unsupervised.attribute.ReplaceMissingValues` filter. In
    general, missing value replacement should be proceeded with caution, while taking
    into consideration the meaning and context of the attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will discretize numeric attributes, that is, we will transform
    numeric attributes into intervals by using the `weka.filters.unsupervised.attribute.Discretize`
    filter. With the `-B` option, we set splitting numeric attributes into four intervals,
    and the `-R` option specifies the range of attributes (only numeric attributes
    will be discretized):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Attribute selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the next step, we will select only informative attributes, that is, attributes
    that are more likely to help with prediction. A standard approach to this problem
    is to check the information gain carried by each attribute. We will use the `weka.attributeSelection.AttributeSelection`
    filter, which requires two additional methods: an evaluator (how attribute usefulness
    is calculated) and search algorithms (how to select a subset of attributes).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, first, we initialize `weka.attributeSelection.InfoGainAttributeEval`,
    which implements the calculation of information gain:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To only select the top attributes above a threshold, we initialize `weka.attributeSelection.Ranker`,
    in order to rank the attributes with information gain above a specific threshold.
    We specify this with the `-T` parameter, while keeping the value of the threshold
    low, in order to keep the attributes with at least some information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The general rule for setting this threshold is to sort the attributes by information
    gain and pick the threshold where the information gain drops to a negligible value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can initialize the `AttributeSelection` class, set the evaluator and
    ranker, and apply the attribute selection to our dataset, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we remove the attributes that were not selected in the last run by
    calling the `reduceDimensionality(Instances)` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the end, we are left with 214 out of 230 attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Model selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the years, practitioners in the field of machine learning have developed
    a wide variety of learning algorithms and improvements for existing ones. There
    are so many unique supervised learning methods that it is challenging to keep
    track of all of them. As the characteristics of the datasets vary, no one method
    is the best in all of the cases, but different algorithms are able to take advantage
    of the different characteristics and relationships of a given dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create the model library by initializing the `weka.classifiers.EnsembleLibrary`
    class, which will help us define the models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we add the models and their parameters to the library as string values;
    for example, we can add three decision tree learners with different parameters,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are familiar with the Weka graphical interface, you can also explore
    the algorithms and their configurations there and copy the configuration, as shown
    in the following screenshot. Right-click on the algorithm name and navigate to
    Edit configuration | Copy configuration string:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0824df77-7948-4eea-bc5a-dcf2f64fe21e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To complete this example, we added the following algorithms and their parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Naive Bayes that was used as the default baseline:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The k-nearest neighbors, based on lazy models:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Logistic regression as a simple logistic with default parameters:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Support vector machines with default parameters:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '`AdaBoost`, which is, in itself, an ensemble method:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '`LogitBoost`, an ensemble method based on logistic regression:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '`DecisionStump`, an ensemble method based on one-level decision trees:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'As the `EnsembleLibrary` implementation is primarily focused on GUI and console
    users, we have to save the models into a file by calling the `saveLibrary(File,
    EnsembleLibrary, JComponent)` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can initialize the ensemble selection algorithm by instantiating the
    `weka.classifiers.meta.EnsembleSelection` class. First, let''s review the following
    method options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-L </path/to/modelLibrary>`: This specifies the `modelLibrary` file, continuing
    the list of all models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-W </path/to/working/directory>`: This specifies the working directory, where
    all models will be stored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-B <numModelBags>`: This sets the number of bags, that is, the number of iterations
    to run the ensemble selection algorithm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-E <modelRatio>`: This sets the ratio of library models that will be randomly
    chosen to populate each bag of models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-V <validationRatio>`: This sets the ratio of the training dataset that will
    be reserved for validation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-H <hillClimbIterations>`: This sets the number of hill climbing iterations
    to be performed on each model bag.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-I <sortInitialization>`: This sets the ratio of the ensemble library that
    the sort initialization algorithm will be able to choose from, while initializing
    the ensemble for each model bag.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-X <numFolds>`: This sets the number of cross-validation folds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-P <hillclimbMetric>`: This specifies the metric that will be used for model
    selection during the hill climbing algorithm. Valid metrics include the accuracy,
    rmse, roc, precision, recall, fscore, and all.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-A <algorithm>`: This specifies the algorithm to be used for ensemble selection.
    Valid algorithms include forward (default) for forward selection, backward for
    backward elimination, both for both forward and backward elimination, best to
    simply print the top performer from the ensemble library, and library to only
    train the models in the ensemble library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-R`: This flags whether the models can be selected more than once for an ensemble.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-G`: This states whether the sort initialization greedily stops adding models
    when the performance degrades.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-O`: This is a flag for verbose output. This prints the performance of all
    of the selected models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-S <num>`: This is a random number seed (the default is `1`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-D`: If set, the classifier is run in debug mode, and may provide additional
    information to the console as output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We initialize the algorithm with the following initial parameters, where we
    specify optimizing the ROC metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Performance evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The evaluation is heavy, both computationally and memory-wise, so make sure
    that you initialize the JVM with extra heap space (for instance, `java -Xmx16g`).
    The computation can take a couple of hours or days, depending on the number of
    algorithms that you include in the model library. This example took 4 hours and
    22 minutes on a 12-core Intel Xeon E5-2420 CPU with 32 GB of memory and utilizing
    10% CPU and 6 GB of memory on average.
  prefs: []
  type: TYPE_NORMAL
- en: 'We call our evaluation method and provide the results as output, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The specific set of classifiers in the model library achieved the following
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Overall, the approach has brought us to a significant improvement of more than
    15 percentage points, compared to the initial baseline that we designed at the
    beginning of this chapter. While it is hard to give a definite answer, the improvement
    was mainly due to three factors: data preprocessing and attribute selection, the
    exploration of a large variety of learning methods, and the use of an ensemble-building
    technique that is able to take advantage of the variety of base classifiers without
    overfitting. However, the improvement requires a significant increase in processing
    time, as well as working memory.'
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble methods â€“ MOA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To ensemble, as the word suggests, is to view together, or at the same time.
    It is used to combine multiple learner algorithms, in order to obtain better results
    and performance. There are various techniques that you can use for an ensemble.
    Some commonly used ensemble techniques or classifiers include bagging, boosting,
    stacking, a bucket of models, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '**Massive Online Analysis** (**MOA**) supports ensemble classifiers, such as
    accuracy weighted ensembles, accuracy updated ensembles, and many more. In this
    section, we will show you how to use the leveraging bagging algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Terminal and execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Select the Classification tab and click on the Configure button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/902e7a65-f7d5-486b-840f-dfd65d228b1d.png)'
  prefs: []
  type: TYPE_IMG
- en: This will open the Configure task option.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the learner option, select bayes.NaiveBayes, and then, in the stream option,
    click on Edit, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1fd2f759-4284-4077-a77d-e5802c8f3fac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select ConceptDriftStream, and, in stream and driftstream, select the AgrawalGenerator;
    it will use the Agrawal dataset for the stream generator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d730b01b-0e88-4452-94a4-c46d1f63eff9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Close all of the windows and click on the Run button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7ffe2372-c8cb-4cb3-a1df-404c63e883da.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This will run the task and generate the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9795215c-7212-4bb4-ba51-471c42c203bf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s use the LeveragingBag option. For this, open the Configure task window
    and select the Edit option in baseLearner, which will show the following; select
    LeveragingBag from the first drop-down box. You can find other options, such as
    boosting and average weight ensembles, in the first drop-down box:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/04f39f1f-151f-496c-ba95-3c1db7d83177.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Leave the stream as AgrawalGenerator, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eeba95e7-a148-45d0-aeb7-30083591f15a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Close the Configure task window and click on the Run button; this will take
    some time to complete:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7f2c9091-b62a-4db9-aed2-5b14052603a8.png)'
  prefs: []
  type: TYPE_IMG
- en: The output shows the evaluation after every 10,000 instances, how much RAM time
    is taken with classification correctness, as well as Kappa statistics. As you
    can see, over time, the classification correctness increases, along with the increasing
    instances. The graph in the preceding screenshot shows the correctness and the
    number of instances.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we tackled the KDD Cup 2009 challenge on customer relationship
    predictions, implementing the data preprocessing steps and addressing the missing
    values and redundant attributes. We followed the winning KDD Cup solution and
    studied how to leverage ensemble methods by using a basket of learning algorithms,
    which can significantly boost classification performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will tackle another problem concerning customer behavior:
    purchasing behavior. You will learn how to use algorithms that detect frequently
    occurring patterns.'
  prefs: []
  type: TYPE_NORMAL
