["```py\nimport sys \nimport cv2 \n```", "```py\n# Load and display an image -- 'forest.jpg' \ninput_file = sys.argv[1] \nimg = cv2.imread(input_file) \n```", "```py\ncv2.imshow('Original', img)\n```", "```py\n# Cropping an image \nh, w = img.shape[:2] \nstart_row, end_row = int(0.21*h), int(0.73*h) \nstart_col, end_col= int(0.37*w), int(0.92*w) \n```", "```py\nimg_cropped = img[start_row:end_row, start_col:end_col] \ncv2.imshow('Cropped', img_cropped) \n```", "```py\n# Resizing an image \nscaling_factor = 1.3 \nimg_scaled = cv2.resize(img, None, fx=scaling_factor,               fy=scaling_factor,  \ninterpolation=cv2.INTER_LINEAR) \ncv2.imshow('Uniform resizing', img_scaled) \n```", "```py\nimg_scaled = cv2.resize(img, (250, 400), interpolation=cv2.INTER_AREA) \ncv2.imshow('Skewed resizing', img_scaled) \n```", "```py\n# Save an image \noutput_file = input_file[:-4] + '_cropped.jpg' \ncv2.imwrite(output_file, img_cropped) \n\ncv2.waitKey() \n```", "```py\n$ python operating_on_images.py capri.jpg\n```", "```py\nimport sys \nimport cv2 \n```", "```py\n# Load the input image -- 'chair.jpg' \n# Convert it to grayscale  \ninput_file = sys.argv[1] \nimg = cv2.imread(input_file, cv2.IMREAD_GRAYSCALE)\n```", "```py\nh, w = img.shape \n```", "```py\nsobel_horizontal = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5) \n```", "```py\nsobel_vertical = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5) \n```", "```py\nlaplacian = cv2.Laplacian(img, cv2.CV_64F) \n```", "```py\ncanny = cv2.Canny(img, 50, 240) \n```", "```py\ncv2.imshow('Original', img) \ncv2.imshow('Sobel horizontal', sobel_horizontal) \ncv2.imshow('Sobel vertical', sobel_vertical) \ncv2.imshow('Laplacian', laplacian) \ncv2.imshow('Canny', canny) \n\ncv2.waitKey() \n```", "```py\n$ python edge_detector.py siracusa.jpg\n```", "```py\nimport sys \nimport cv2   \n```", "```py\n# Load input image -- 'sunrise.jpg' \ninput_file = sys.argv[1] \nimg = cv2.imread(input_file) \n```", "```py\n# Convert it to grayscale \nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \ncv2.imshow('Input grayscale image', img_gray) \n```", "```py\n# Equalize the histogram \nimg_gray_histeq = cv2.equalizeHist(img_gray) \ncv2.imshow('Histogram equalized - grayscale', img_gray_histeq) \n```", "```py\n# Histogram equalization of color images \nimg_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV) \n```", "```py\nimg_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0]) \n```", "```py\nimg_histeq = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR) \n```", "```py\ncv2.imshow('Input color image', img) \ncv2.imshow('Histogram equalized - color', img_histeq) \n\ncv2.waitKey()\n```", "```py\n$ python histogram_equalizer.py gubbio.jpg\n```", "```py\nimport sys \nimport cv2 \nimport numpy as np\n```", "```py\n# Load input image -- 'box.png' \ninput_file = sys.argv[1] \nimg = cv2.imread(input_file) \ncv2.imshow('Input image', img) \n```", "```py\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \nimg_gray = np.float32(img_gray) \n```", "```py\n# Harris corner detector  \nimg_harris = cv2.cornerHarris(img_gray, 7, 5, 0.04) \n```", "```py\n# Resultant image is dilated to mark the corners \nimg_harris = cv2.dilate(img_harris, None) \n```", "```py\n# Threshold the image  \nimg[img_harris > 0.01 * img_harris.max()] = [0, 0, 0] \n```", "```py\ncv2.imshow('Harris Corners', img) \ncv2.waitKey() \n```", "```py\n$ python corner_detector.py box.png\n```", "```py\nimport sys \nimport cv2 \nimport numpy as np  \n```", "```py\n# Load input image -- 'table.jpg' \ninput_file = sys.argv[1] \nimg = cv2.imread(input_file)\n```", "```py\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n```", "```py\nsift = cv2.xfeatures2d.SIFT_create() \nkeypoints = sift.detect(img_gray, None) \n```", "```py\nimg_sift = np.copy(img) \ncv2.drawKeypoints(img, keypoints, img_sift, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS) \n```", "```py\ncv2.imshow('Input image', img) \ncv2.imshow('SIFT features', img_sift) \ncv2.waitKey() \n```", "```py\n$ python feature_detector.py flowers.jpg\n```", "```py\nimport sys \nimport cv2  \n```", "```py\nclass StarFeatureDetector(object): \n    def __init__(self): \n        self.detector = cv2.xfeatures2d.StarDetector_create() \n```", "```py\n    def detect(self, img): \n        return self.detector.detect(img) \n```", "```py\nif __name__=='__main__': \n    # Load input image -- 'table.jpg' \n    input_file = sys.argv[1] \n    input_img = cv2.imread(input_file) \n```", "```py\n    # Convert to grayscale \n    img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY) \n```", "```py\n    # Detect features using Star feature detector \n    keypoints = StarFeatureDetector().detect(input_img)\n```", "```py\n    cv2.drawKeypoints(input_img, keypoints, input_img,  \n               flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS) \n```", "```py\n    cv2.imshow('Star features', input_img) \n    cv2.waitKey() \n```", "```py\n$ python star_detector.py table.jpg\n```", "```py\nclass FeatureBuilder(object): \n```", "```py\n    def extract_ features(self, img): \n        keypoints = StarFeatureDetector().detect(img) \n        keypoints, feature_vectors = compute_sift_features(img, keypoints) \n        return feature_vectors \n```", "```py\n    def get_codewords(self, input_map, scaling_size, max_samples=12): \n        keypoints_all = [] \n\n        count = 0 \n        cur_label = '' \n```", "```py\n        for item in input_map: \n            if count >= max_samples: \n                if cur_class != item['object_class']: \n                    count = 0 \n            else: \n                continue \n\n        count += 1 \n```", "```py\n        if count == max_samples: \n            print(\"Built centroids for\", item['object_class']) \n```", "```py\n        cur_class = item['object_class'] \n```", "```py\n        img = cv2.imread(item['image_path']) \n        img = resize_image(img, scaling_size) \n```", "```py\n        feature_vectors = self.extract_image_features(img) \n        keypoints_all.extend(feature_vectors)  \n```", "```py\n        kmeans, centroids = BagOfWords().cluster(keypoints_all) \n        return kmeans, centroids \n```", "```py\nclass BagOfWords(object): \n    def __init__(self, num_clusters=32): \n        self.num_dims = 128 \n        self.num_clusters = num_clusters \n        self.num_retries = 10\n```", "```py\ndef cluster(self, datapoints): \n    kmeans = KMeans(self.num_clusters,  \n        n_init=max(self.num_retries, 1), \n        max_iter=10, tol=1.0) \n```", "```py\n    res = kmeans.fit(datapoints) \n    centroids = res.cluster_centers_ \n    return kmeans, centroids \n```", "```py\ndef normalize(self, input_data): \n    sum_input = np.sum(input_data) \n\n    if sum_input > 0: \n        return input_data / sum_input \n    else: \n        return input_data \n```", "```py\ndef construct_feature(self, img, kmeans, centroids): \n    keypoints = StarFeatureDetector().detect(img) \n    keypoints, feature_vectors = compute_sift_features(img, keypoints) \n    labels = kmeans.predict(feature_vectors) \n    feature_vector = np.zeros(self.num_clusters) \n```", "```py\n    for i, item in enumerate(feature_vectors): \n        feature_vector[labels[i]] += 1 \n\n        feature_vector_img = np.reshape(feature_vector,  \n((1, feature_vector.shape[0]))) \n        return self.normalize(feature_vector_img) \n```", "```py\n# Extract SIFT features \ndef compute_sift_features(img, keypoints): \n    if img is None: \n        raise TypeError('Invalid input image') \n\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n    keypoints, descriptors = cv2.xfeatures2d.SIFT_create().compute(img_gray, keypoints) \n    return keypoints, descriptors \n```", "```py\n$ python build_features.py --data-folder /path/to/training_images/ --codebook-file codebook.pkl --feature-map-file feature_map.pkl\n\n```", "```py\nimport argparse \nimport _pickle as pickle\n\nimport numpy as np\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn import preprocessing\n```", "```py\ndef build_arg_parser():\n    parser = argparse.ArgumentParser(description='Trains the classifier')\n    parser.add_argument(\"--feature-map-file\", dest=\"feature_map_file\", required=True,\n            help=\"Input pickle file containing the feature map\")\n    parser.add_argument(\"--model-file\", dest=\"model_file\", required=False,\n            help=\"Output file where the trained model will be stored\")\n    return parser\n```", "```py\nclass ERFTrainer(object):\n    def __init__(self, X, label_words):\n        self.le = preprocessing.LabelEncoder() \n        self.clf = ExtraTreesClassifier(n_estimators=100, \n                max_depth=16, random_state=0) \n```", "```py\n        y = self.encode_labels(label_words) \n        self.clf.fit(np.asarray(X), y) \n```", "```py\ndef encode_labels(self, label_words): \n    self.le.fit(label_words)  \n    return np.array(self.le.transform(label_words), dtype=np.float32) \n```", "```py\ndef classify(self, X): \n    label_nums = self.clf.predict(np.asarray(X)) \n    label_words = self.le.inverse_transform([int(x) for x in label_nums])  \n    return label_words \n```", "```py\nif __name__=='__main__': \n    args = build_arg_parser().parse_args() \n    feature_map_file = args.feature_map_file \n    model_file = args.model_file\n```", "```py\n    # Load the feature map \n    with open(feature_map_file, 'rb') as f: \n        feature_map = pickle.load(f) \n```", "```py\n    # Extract feature vectors and the labels\n    label_words = [x['object_class'] for x in feature_map]\n    dim_size = feature_map[0]['feature_vector'].shape[1] \n    X = [np.reshape(x['feature_vector'], (dim_size,)) for x in feature_map]\n```", "```py\n    # Train the Extremely Random Forests classifier \n    erf = ERFTrainer(X, label_words)  \n```", "```py\n    if args.model_file: \n        with open(args.model_file, 'wb') as f: \n            pickle.dump(erf, f) \n```", "```py\n    $ python trainer.py --feature-map-file feature_map.pkl \n    --model-file erf.pkl\n```", "```py\nimport argparse \nimport _pickle as pickle\n\nimport cv2\n\nimport build_features as bf\nfrom trainer import ERFTrainer\n```", "```py\ndef build_arg_parser():\n    parser = argparse.ArgumentParser(description='Extracts features \\\n            from each line and classifies the data')\n    parser.add_argument(\"--input-image\", dest=\"input_image\", required=True,\n            help=\"Input image to be classified\")\n    parser.add_argument(\"--model-file\", dest=\"model_file\", required=True,\n            help=\"Input file containing the trained model\")\n    parser.add_argument(\"--codebook-file\", dest=\"codebook_file\", \n            required=True, help=\"Input file containing the codebook\")\n    return parser\n```", "```py\nclass ImageTagExtractor(object):\n    def __init__(self, model_file, codebook_file):\n        with open(model_file, 'rb') as f:\n            self.erf = pickle.load(f)\n\n        with open(codebook_file, 'rb') as f:\n            self.kmeans, self.centroids = pickle.load(f)\n```", "```py\n    def predict(self, img, scaling_size):\n        img = bf.resize_image(img, scaling_size)\n        feature_vector = bf.BagOfWords().construct_feature(\n                img, self.kmeans, self.centroids)\n        image_tag = self.erf.classify(feature_vector)[0]\n        return image_tag\n```", "```py\nif __name__=='__main__':\n    args = build_arg_parser().parse_args()\n    model_file = args.model_file\n    codebook_file = args.codebook_file\n    input_image = cv2.imread(args.input_image)\n```", "```py\n    scaling_size = 200 \n```", "```py\n    print(\"Output:\", ImageTagExtractor(model_file, \n            codebook_file).predict(input_image, scaling_size))\n```", "```py\n$ python object_recognizer.py --input-image imagefile.jpg --model-file erf.pkl --codebook-file codebook.pkl\n```", "```py\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom keras.datasets import mnist\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n```", "```py\n(XTrain, YTrain), (XTest, YTest) = mnist.load_data()\n```", "```py\nXTrain = XTrain.reshape((len(XTrain), np.prod(XTrain.shape[1:])))\nXTest = XTest.reshape((len(XTest), np.prod(XTest.shape[1:]))) \n```", "```py\nTrainFilter = np.where((YTrain == 0 ) | (YTrain == 1))\nTestFilter = np.where((YTest == 0) | (YTest == 1))\n\nXTrain, YTrain = XTrain[TrainFilter], YTrain[TrainFilter]\nXTest, YTest = XTest[TestFilter], YTest[TestFilter]\n```", "```py\nLgbTrain = lgb.Dataset(XTrain, YTrain)\nLgbEval = lgb.Dataset(XTest, YTest, reference=LgbTrain)\n```", "```py\nParameters = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'verbose': 0\n}\n```", "```py\ngbm = lgb.train(Parameters,\n                LgbTrain,\n                num_boost_round=10,\n                valid_sets=LgbTrain)\n```", "```py\nYPred = gbm.predict(XTest, num_iteration=gbm.best_iteration)\nYPred = np.round(YPred)\nYPred = YPred.astype(int)\n```", "```py\nprint('Rmse of the model is:', mean_squared_error(YTest, YPred) ** 0.5)\n```", "```py\nRmse of the model is: 0.05752992848417943\n```", "```py\nConfMatrix = confusion_matrix(YTest, YPred)\nprint(ConfMatrix)\n```", "```py\n[[ 978 2]\n [ 5 1130]]\n```", "```py\nprint(accuracy_score(YTest, YPred))\n```", "```py\n0.9966903073286052\n```"]