["```py\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \n```", "```py\ndef convert_data_to_timeseries(input_file, column, verbose=False): \n```", "```py\n    # Load the input file \n    data = np.loadtxt(input_file, delimiter=',') \n```", "```py\n    # Extract the start and end dates \n    start_date = str(int(data[0,0])) + '-' + str(int(data[0,1])) \n    end_date = str(int(data[-1,0] + 1)) + '-' + str(int(data[-1,1] % 12 + 1)) \n```", "```py\n    if verbose: \n        print(\"Start date =\", start_date)\n        print(\"End date =\", end_date) \n```", "```py\n    # Create a date sequence with monthly intervals \n    dates = pd.date_range(start_date, end_date, freq='M') \n```", "```py\n    # Convert the data into time series data \n    data_timeseries = pd.Series(data[:,column], index=dates) \n```", "```py\n    if verbose: \n        print(\"Time series data:\\n\", data_timeseries[:10]) \n```", "```py\n    return data_timeseries \n```", "```py\nif __name__=='__main__': \n```", "```py\n    # Input file containing data \n    input_file = 'data_timeseries.txt' \n```", "```py\n    # Load input data \n    column_num = 2 \n    data_timeseries = convert_data_to_timeseries(input_file, column_num) \n```", "```py\n    # Plot the time series data \n    data_timeseries.plot() \n    plt.title('Input data') \n\n    plt.show() \n```", "```py\nimport numpy as np \nfrom convert_to_timeseries import convert_data_to_timeseries \n```", "```py\n# Input file containing data \ninput_file = 'data_timeseries.txt' \n```", "```py\n# Load data \ncolumn_num = 2 \ndata_timeseries = convert_data_to_timeseries(input_file, column_num) \n```", "```py\n# Plot within a certain year range \nstart = '2000' \nend = '2015' \n```", "```py\nplt.figure() \ndata_timeseries[start:end].plot() \nplt.title('Data from ' + start + ' to ' + end) \n```", "```py\n# Plot within a certain range of dates \nstart = '2008-1' \nend = '2008-12' \n```", "```py\nplt.figure() \ndata_timeseries[start:end].plot() \nplt.title('Data from ' + start + ' to ' + end) \nplt.show() \n```", "```py\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom convert_to_timeseries import convert_data_to_timeseries \n```", "```py\n# Input file containing data \ninput_file = 'data_timeseries.txt' \n```", "```py\n# Load data \ndata1 = convert_data_to_timeseries(input_file, 2) \ndata2 = convert_data_to_timeseries(input_file, 3) \n```", "```py\ndataframe = pd.DataFrame({'first': data1, 'second': data2}) \n```", "```py\n# Plot data \ndataframe['1952':'1955'].plot() \nplt.title('Data overlapped on top of each other') \n```", "```py\n# Plot the difference \nplt.figure() \ndifference = dataframe['1952':'1955']['first'] - dataframe['1952':'1955']['second'] \ndifference.plot() \nplt.title('Difference (first - second)') \n```", "```py\n# When 'first' is greater than a certain threshold \n# and 'second' is smaller than a certain threshold \ndataframe[(dataframe['first'] > 60) & (dataframe['second'] < 20)].plot(style='o') \nplt.title('first > 60 and second < 20') \n\nplt.show() \n```", "```py\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom convert_to_timeseries import convert_data_to_timeseries \n```", "```py\n# Input file containing data \ninput_file = 'data_timeseries.txt' \n```", "```py\n# Load data \ndata1 = convert_data_to_timeseries(input_file, 2) \ndata2 = convert_data_to_timeseries(input_file, 3) \n```", "```py\ndataframe = pd.DataFrame({'first': data1, 'second': data2}) \n```", "```py\n# Print max and min \nprint('Maximum:\\n', dataframe.max())\nprint('Minimum:\\n', dataframe.min())\n```", "```py\n# Print mean \nprint('Mean:\\n', dataframe.mean())\nprint('Mean row-wise:\\n', dataframe.mean(1)[:10])\n```", "```py\n# Plot rolling mean \nDFMean = dataframe.rolling(window=24).mean()\nplt.plot(DFMean) \n```", "```py\n# Print correlation coefficients \nprint('Correlation coefficients:\\n', dataframe.corr()) \n```", "```py\n# Plot rolling correlation \nplt.figure()\nDFCorr= dataframe.rolling(window=60).corr(pairwise=False)\nplt.plot(DFCorr)\nplt.show()\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt \nfrom hmmlearn.hmm import GaussianHMM \n```", "```py\n# Load data from input file \ninput_file = 'data_hmm.txt' \ndata = np.loadtxt(input_file, delimiter=',') \n```", "```py\n# Arrange data for training  \nX = np.column_stack([data[:,2]]) \n```", "```py\n# Create and train Gaussian HMM  \nprint(\"Training HMM....\") \nnum_components = 4 \nmodel = GaussianHMM(n_components=num_components, covariance_type=\"diag\", n_iter=1000) \nmodel.fit(X) \n```", "```py\n# Predict the hidden states of HMM  \nhidden_states = model.predict(X) \n```", "```py\nprint(\"Means and variances of hidden states:\")\nfor i in range(model.n_components):\n    print(\"Hidden state\", i+1)\n    print(\"Mean =\", round(model.means_[i][0], 3))\n    print(\"Variance =\", round(np.diag(model.covars_[i])[0], 3))\n```", "```py\n# Generate data using model \nnum_samples = 1000 \nsamples, _ = model.sample(num_samples)  \nplt.plot(np.arange(num_samples), samples[:,0], c='black') \nplt.title('Number of components = ' + str(num_components)) \nplt.show() \n```", "```py\nTraining HMM....\nMeans and variances of hidden states:\nHidden state 1\nMean = 5.592\nVariance = 0.253\nHidden state 2\nMean = 1.098\nVariance = 0.004\nHidden state 3\nMean = 7.102\nVariance = 0.003\nHidden state 4\nMean = 3.098\nVariance = 0.003\nHidden state 5\nMean = 4.104\nVariance = 0.003\n```", "```py\nimport argparse \nimport numpy as np\nfrom pystruct.datasets import load_letters\nfrom pystruct.models import ChainCRF\nfrom pystruct.learners import FrankWolfeSSVM\n```", "```py\ndef build_arg_parser():\n    parser = argparse.ArgumentParser(description='Trains the CRF classifier')\n    parser.add_argument(\"--c-value\", dest=\"c_value\", required=False, type=float,\n            default=1.0, help=\"The C value that will be used for training\")\n    return parser\n```", "```py\nclass CRFTrainer(object): \n```", "```py\n    def __init__(self, c_value, classifier_name='ChainCRF'): \n        self.c_value = c_value \n        self.classifier_name = classifier_name \n```", "```py\n        if self.classifier_name == 'ChainCRF': \n            model = ChainCRF() \n```", "```py\n            self.clf = FrankWolfeSSVM(model=model, C=self.c_value, max_iter=50)  \n        else: \n            raise TypeError('Invalid classifier type') \n```", "```py\n    def load_data(self): \n        letters = load_letters() \n```", "```py\n        X, y, folds = letters['data'], letters['labels'], letters['folds'] \n        X, y = np.array(X), np.array(y) \n        return X, y, folds \n```", "```py\n    # X is a numpy array of samples where each sample \n    # has the shape (n_letters, n_features)  \n    def train(self, X_train, y_train): \n        self.clf.fit(X_train, y_train) \n```", "```py\n    def evaluate(self, X_test, y_test): \n        return self.clf.score(X_test, y_test) \n```", "```py\n    # Run the classifier on input data \n    def classify(self, input_data): \n        return self.clf.predict(input_data)[0] \n```", "```py\ndef decoder(arr): \n    alphabets = 'abcdefghijklmnopqrstuvwxyz' \n    output = '' \n    for i in arr: \n        output += alphabets[i]  \n\n    return output \n```", "```py\nif __name__=='__main__': \n    args = build_arg_parser().parse_args() \n    c_value = args.c_value \n```", "```py\n    crf = CRFTrainer(c_value) \n```", "```py\n    X, y, folds = crf.load_data() \n```", "```py\n    X_train, X_test = X[folds == 1], X[folds != 1] \n    y_train, y_test = y[folds == 1], y[folds != 1] \n```", "```py\n    print(\"Training the CRF model...\")\n    crf.train(X_train, y_train) \n```", "```py\n    score = crf.evaluate(X_test, y_test) \n    print(\"Accuracy score =\", str(round(score*100, 2)) + '%') \n```", "```py\n    print(\"True label =\", decoder(y_test[0]))\n    predicted_output = crf.classify([X_test[0]])\n    print(\"Predicted output =\", decoder(predicted_output))\n```", "```py\nTraining the CRF model...\nAccuracy score = 77.93%\nTrue label = ommanding\nPredicted output = ommanging\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import seed\n```", "```py\nseed(0)\nData = pd.read_csv('AMZN.csv',header=0, usecols=['Date', 'Close'],parse_dates=True,index_col='Date')\n```", "```py\nprint(Data.info())\n```", "```py\n<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 4529 entries, 2000-11-21 to 2018-11-21\nData columns (total 1 columns):\nClose 4529 non-null float64\ndtypes: float64(1)\nmemory usage: 70.8 KB\nNone\n```", "```py\nprint(Data.head())\n```", "```py\n Close\nDate \n2000-11-21 24.2500\n2000-11-22 25.1875\n2000-11-24 28.9375\n2000-11-27 28.0000\n2000-11-28 25.0312\n```", "```py\nprint(Data.describe())\n```", "```py\n Close\ncount      4529.000000\nmean        290.353723\nstd         407.211585\nmin           5.970000\n25%          39.849998\n50%         117.889999\n75%         327.440002\nmax        2039.510010\n```", "```py\nplt.figure(figsize=(10,5))\nplt.plot(Data)\nplt.show()\n```", "```py\nDataPCh = Data.pct_change()\n```", "```py\nLogReturns = np.log(1 + DataPCh) \nprint(LogReturns.tail(10))\n```", "```py\n Close\nDate \n2018-11-08     -0.000330\n2018-11-09     -0.024504\n2018-11-12     -0.045140\n2018-11-13     -0.003476\n2018-11-14     -0.019913\n2018-11-15      0.012696\n2018-11-16     -0.016204\n2018-11-19     -0.052251\n2018-11-20     -0.011191\n2018-11-21      0.014123\n```", "```py\nplt.figure(figsize=(10,5))\nplt.plot(LogReturns)\nplt.show()\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import seed\n\nseed(0)\n\nData = pd.read_csv('AMZN.csv',header=0, usecols=['Date', 'Close'],parse_dates=True,index_col='Date')\n```", "```py\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nDataScaled = scaler.fit_transform(Data)\n```", "```py\nnp.random.seed(7)\nTrainLen = int(len(DataScaled) * 0.70)\nTestLen = len(DataScaled) - TrainLen\nTrainData = DataScaled[0:TrainLen,:] \nTestData = DataScaled[TrainLen:len(DataScaled),:]\n\nprint(len(TrainData), len(TestData))\n```", "```py\n3170 1359\n```", "```py\ndef DatasetCreation(dataset, TimeStep=1):\n  DataX, DataY = [], []\n  for i in range(len(dataset)-TimeStep-1):\n    a = dataset[i:(i+TimeStep), 0]\n    DataX.append(a)\n    DataY.append(dataset[i + TimeStep, 0])\n  return np.array(DataX), np.array(DataY)\n```", "```py\nTimeStep = 1\nTrainX, TrainY = DatasetCreation(TrainData, TimeStep)\nTestX, TestY = DatasetCreation(TestData, TimeStep)\n```", "```py\nTrainX = np.reshape(TrainX, (TrainX.shape[0], 1, TrainX.shape[1]))\nTestX = np.reshape(TestX, (TestX.shape[0], 1, TestX.shape[1]))\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\n```", "```py\nmodel = Sequential()\nmodel.add(LSTM(256, input_shape=(1, TimeStep)))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nmodel.fit(TrainX, TrainY, epochs=100, batch_size=1, verbose=1)\nmodel.summary()\n```", "```py\nscore = model.evaluate(TrainX, TrainY, verbose=0)\nprint('Keras Model Loss = ',score[0])\nprint('Keras Model Accuracy = ',score[1])\n```", "```py\nKeras Model Loss = 2.4628453362992094e-06\nKeras Model Accuracy = 0.0003156565656565657\n```", "```py\nTrainPred = model.predict(TrainX)\nTestPred = model.predict(TestX)\n```", "```py\nTrainPred = scaler.inverse_transform(TrainPred)\nTrainY = scaler.inverse_transform([TrainY])\nTestPred = scaler.inverse_transform(TestPred)\nTestY = scaler.inverse_transform([TestY])\n```", "```py\nTrainPredictPlot = np.empty_like(DataScaled)\nTrainPredictPlot[:, :] = np.nan\nTrainPredictPlot[1:len(TrainPred)+1, :] = TrainPred\n```", "```py\nTestPredictPlot = np.empty_like(DataScaled)\nTestPredictPlot[:, :] = np.nan\nTestPredictPlot[len(TrainPred)+(1*2)+1:len(DataScaled)-1, :] = TestPred\n```", "```py\nplt.figure(figsize=(10,5))\nplt.plot(scaler.inverse_transform(DataScaled))\nplt.plot(TrainPredictPlot)\nplt.plot(TestPredictPlot)\nplt.show()\n```"]