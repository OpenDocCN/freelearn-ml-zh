["```py\npublic static Instances loadData(String pathData, String \n  pathLabeles) throws Exception { \n```", "```py\n// Load data \nCSVLoader loader = new CSVLoader(); \nloader.setFieldSeparator(\"\\t\"); \nloader.setNominalAttributes(\"191-last\"); \nloader.setSource(new File(pathData)); \nInstances data = loader.getDataSet(); \n```", "```py\n// remove empty attributes identified as String attribute  \nRemoveType removeString = new RemoveType(); \nremoveString.setOptions(new String[]{\"-T\", \"string\"}); \nremoveString.setInputFormat(data); \nInstances filteredData = Filter.useFilter(data, removeString); \n```", "```py\n// Load labeles \nloader = new CSVLoader(); \nloader.setFieldSeparator(\"\\t\"); \nloader.setNoHeaderRowPresent(true); \nloader.setNominalAttributes(\"first-last\"); \nloader.setSource(new File(pathLabeles)); \nInstances labels = loader.getDataSet(); \n```", "```py\n// Append label as class value \nInstances labeledData = Instances.mergeInstances(filteredData, \n   labeles); \n```", "```py\n// set the label attribute as class  \nlabeledData.setClassIndex(labeledData.numAttributes() - 1); \n\nSystem.out.println(labeledData.toSummaryString()); \nreturn labeledData; \n} \n```", "```py\n    Relation Name:  orange_small_train.data-weka.filters.unsupervised.attribute.RemoveType-Tstring_orange_small_train_churn.labels.txt\n    Num Instances:  50000\n    Num Attributes: 215\n\n    Name          Type  Nom  Int Real     Missing      Unique  Dist\n    1 Var1        Num   0%   1%   0% 49298 / 99%     8 /  0%    18 \n    2 Var2        Num   0%   2%   0% 48759 / 98%     1 /  0%     2 \n    3 Var3        Num   0%   2%   0% 48760 / 98%   104 /  0%   146 \n    4 Var4        Num   0%   3%   0% 48421 / 97%     1 /  0%     4\n    ...\n\n```", "```py\npublic static double[] evaluate(Classifier model) \n   throws Exception { \n\n  double results[] = new double[4]; \n\n  String[] labelFiles = new String[]{ \n    \"churn\", \"appetency\", \"upselling\"}; \n\n  double overallScore = 0.0; \n  for (int i = 0; i < labelFiles.length; i++) { \n```", "```py\n    // Load data \n    Instances train_data = loadData( \n     path + \"orange_small_train.data\", \n      path+\"orange_small_train_\"+labelFiles[i]+\".labels.txt\"); \n```", "```py\n    // cross-validate the data \n    Evaluation eval = new Evaluation(train_data); \n    eval.crossValidateModel(model, train_data, 5,  \n    new Random(1)); \n```", "```py\n    // Save results \n    results[i] = eval.areaUnderROC( \n      train_data.classAttribute().indexOfValue(\"1\")); \n    overallScore += results[i]; \n  } \n```", "```py\n  // Get average results over all three problems \n  results[3] = overallScore / 3; \n  return results; \n}\n```", "```py\nClassifier baselineNB = new NaiveBayes(); \n```", "```py\ndouble resNB[] = evaluate(baselineNB); \nSystem.out.println(\"Naive Bayes\\n\" +  \n\"\\tchurn:     \" + resNB[0] + \"\\n\" +  \n\"\\tappetency: \" + resNB[1] + \"\\n\" +  \n\"\\tup-sell:   \" + resNB[2] + \"\\n\" +  \n\"\\toverall:   \" + resNB[3] + \"\\n\"); \n```", "```py\n    Naive Bayes\n      churn:     0.5897891153549814\n      appetency: 0.630778394752436\n      up-sell:   0.6686116692438094\n      overall:   0.6297263931170756\n\n```", "```py\nimport weka.classifiers.meta.EnsembleSelection; \n```", "```py\nRemoveUseless removeUseless = new RemoveUseless(); \nremoveUseless.setOptions(new String[] { \"-M\", \"99\" });// threshold \nremoveUseless.setInputFormat(data); \ndata = Filter.useFilter(data, removeUseless); \n```", "```py\nReplaceMissingValues fixMissing = new ReplaceMissingValues(); \nfixMissing.setInputFormat(data); \ndata = Filter.useFilter(data, fixMissing); \n```", "```py\nDiscretize discretizeNumeric = new Discretize(); \ndiscretizeNumeric.setOptions(new String[] { \n    \"-B\",  \"4\",  // no of bins \n    \"-R\",  \"first-last\"}); //range of attributes \nfixMissing.setInputFormat(data); \ndata = Filter.useFilter(data, fixMissing); \n```", "```py\nInfoGainAttributeEval eval = new InfoGainAttributeEval(); \nRanker search = new Ranker(); \n```", "```py\nsearch.setOptions(new String[] { \"-T\", \"0.001\" }); \n```", "```py\nAttributeSelection attSelect = new AttributeSelection(); \nattSelect.setEvaluator(eval); \nattSelect.setSearch(search); \n\n// apply attribute selection \nattSelect.SelectAttributes(data); \n```", "```py\n// remove the attributes not selected in the last run \ndata = attSelect.reduceDimensionality(data); \n```", "```py\nEnsembleLibrary ensembleLib = new EnsembleLibrary(); \n```", "```py\nensembleLib.addModel(\"weka.classifiers.trees.J48 -S -C 0.25 -B -M \n   2\"); \nensembleLib.addModel(\"weka.classifiers.trees.J48 -S -C 0.25 -B -M \n   2 -A\"); \n```", "```py\nensembleLib.addModel(\"weka.classifiers.bayes.NaiveBayes\"); \n```", "```py\nensembleLib.addModel(\"weka.classifiers.lazy.IBk\"); \n```", "```py\nensembleLib.addModel(\"weka.classifiers.functions.SimpleLogi\n   stic\"); \n```", "```py\nensembleLib.addModel(\"weka.classifiers.functions.SMO\"); \n```", "```py\nensembleLib.addModel(\"weka.classifiers.meta.AdaBoostM1\"); \n```", "```py\nensembleLib.addModel(\"weka.classifiers.meta.LogitBoost\"); \n```", "```py\nensembleLib.addModel(\"classifiers.trees.DecisionStump\"); \n```", "```py\nEnsembleLibrary.saveLibrary(new \n   File(path+\"ensembleLib.model.xml\"), ensembleLib, null); \nSystem.out.println(ensembleLib.getModels()); \n```", "```py\nEnsembleSelection ensambleSel = new EnsembleSelection(); \nensambleSel.setOptions(new String[]{ \n  \"-L\", path+\"ensembleLib.model.xml\", // </path/to/modelLibrary>\n     \"-W\", path+\"esTmp\", // </path/to/working/directory> -  \n\"-B\", \"10\", // <numModelBags>  \n  \"-E\", \"1.0\", // <modelRatio>. \n  \"-V\", \"0.25\", // <validationRatio> \n  \"-H\", \"100\", // <hillClimbIterations>  \n\"-I\", \"1.0\", // <sortInitialization>  \n  \"-X\", \"2\", // <numFolds> \n  \"-P\", \"roc\", // <hillclimbMettric> \n  \"-A\", \"forward\", // <algorithm>  \n  \"-R\", \"true\", // - Flag to be selected more than once \n  \"-G\", \"true\", // - stops adding models when performance degrades \n  \"-O\", \"true\", // - verbose output. \n  \"-S\", \"1\", // <num> - Random number seed. \n  \"-D\", \"true\" // - run in debug mode  \n}); \n```", "```py\ndouble resES[] = evaluate(ensambleSel); \nSystem.out.println(\"Ensemble Selection\\n\"  \n+ \"\\tchurn:     \" + resES[0] + \"\\n\" \n+ \"\\tappetency: \" + resES[1] + \"\\n\"  \n+ \"\\tup-sell:   \" + resES[2] + \"\\n\"  \n+ \"\\toverall:   \" + resES[3] + \"\\n\"); \n```", "```py\n    Ensamble\n      churn:     0.7109874158176481\n      appetency: 0.786325687118347\n      up-sell:   0.8521363243575182\n      overall:   0.7831498090978378\n\n```", "```py\njava -cp moa.jar -javaagent:sizeofag-1.0.4.jar moa.gui.GUI\n```"]