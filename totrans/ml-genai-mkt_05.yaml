- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enhancing Customer Insight with Sentiment Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In today’s digital age, understanding customer sentiment is key for shaping
    marketing strategies, refining brand messaging, and improving customer experience.
    Sentiment analysis, a subset of **natural language processing** (**NLP**), empowers
    marketers to sort through massive amounts of unstructured text data, such as customer
    feedback, social media conversations, and product reviews, to gauge public sentiment.
    This analytical approach not only helps in monitoring brand reputation but also
    in tailoring marketing messages according to customer preferences, which enhances
    the overall customer insight.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter explores the world of sentiment analysis for marketing. Using the
    power of Python, you will learn how to classify sentiments as positive, negative,
    or neutral, and identify the nuances embedded within customer feedback. We will
    also use hands-on examples, based on the “Twitter Airline Sentiment” dataset from
    Kaggle, to equip you with the skills to perform sentiment analysis, interpret
    the results, and apply these insights to craft more effective marketing strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, this chapter will give you a comprehensive walkthrough of the fundamentals
    of sentiment analysis in marketing and then guide you through the practical aspects
    of data preparation, analysis, and results visualization. By the end of this chapter,
    you will gain proficiency in:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the critical role of sentiment analysis in marketing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocessing text data to prepare it for analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying Python libraries to perform sentiment analysis using traditional natural
    language processing and elements from generative AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpreting and visualizing the outcomes to derive actionable marketing insights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to sentiment analysis in marketing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the fast-paced world of marketing, staying attuned to customer sentiments
    is not just beneficial; it’s a necessity. Sentiment analysis, or the process of
    detecting positive, negative, or neutral tones in text data, stands at the forefront
    of this effort, offering a lens through which marketers can view and understand
    the emotional undertones of customer interactions. This approach uses NLP, machine
    learning, and computational linguistics to systematically identify, extract, quantify,
    and study patterns within text. These patterns can range from the presence of
    certain keywords and phrases to the structure of sentences and the context in
    which terms are used.
  prefs: []
  type: TYPE_NORMAL
- en: The significance of sentiment analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The importance of sentiment analysis in marketing cannot be overstated. It acts
    as a compass, guiding brands through the vast and often turbulent sea of public
    opinion. By analyzing customer feedback, social media conversations, and product
    reviews, sentiment analysis helps marketers understand not just what people say
    but how they feel.
  prefs: []
  type: TYPE_NORMAL
- en: '**Further reading on sentiment analysis in marketing**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For an overview of approaches to automated textual analysis in marketing, refer
    to the article “*Uniting the Tribes: Using Text for Marketing Insight*” ([https://journals.sagepub.com/doi/full/10.1177/0022242919873106](https://journals.sagepub.com/doi/full/10.1177/0022242919873106)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, the application of sentiment analysis in marketing opens
    an array of opportunities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Brand monitoring**: Sentiment analysis enables real-time monitoring of brand
    perception across various digital platforms. By tracking shifts in sentiment,
    marketers can anticipate and mitigate potential PR crises. For example, during
    the United Airlines incident on April 9, 2017, where a passenger was forcibly
    removed from a flight due to overbooking, sentiment analysis could have helped
    United detect the rapidly escalating negative sentiment around the viral social
    media footage and respond more proactively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Campaign analysis**: Understanding emotional responses to marketing campaigns
    allows for agile strategy adjustments. Sentiment analysis can reveal whether a
    campaign resonates positively with the target audience or if it misses the mark.
    For instance, Pepsi’s 2017 ad featuring Kendall Jenner received backlash for being
    perceived as trivializing social justice movements. Early sentiment analysis could
    have identified negative feedback and allowed for a timely campaign pivot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Product feedback**: Detailed sentiment insights help pinpoint specific aspects
    of products or services that delight or disappoint customers. This feedback loop
    is invaluable for continuous improvement and innovation. Consider the case of
    Apple’s launch of the iPhone 6, where sentiment analysis of customer feedback
    highlighted the “Bendgate” issue, prompting Apple to address the problem quickly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Market research**: Sentiment analysis offers a window into the broader market
    landscape, providing a competitive edge by uncovering trends, competitor standings,
    and gaps in the market. For example, Netflix uses sentiment analysis to understand
    viewer preferences and trends, which aids in content creation and recommendation
    algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By harnessing the insights gained through sentiment analysis, marketers can
    not only monitor brand reputation but also tailor their communications to resonate
    more deeply with their audience, leading to more effective and impactful marketing
    strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Advancements in AI and sentiment analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The emergence of **large language models** (**LLMs**) and **Generative AI**
    (**GenAI**) has transformed sentiment analysis, offering unprecedented depth and
    accuracy in understanding text data. LLMs are trained on vast datasets that encompass
    diverse linguistic patterns, enabling them to understand and generate human-like
    text. For example, LLMs can grasp context and nuance in ways that were previously
    unattainable, with state-of-the-art models that can distinguish between sarcasm
    and genuine dissatisfaction, or recognize the underlying positivity in a complaint
    that includes a suggestion for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: These advancements are particularly relevant for sentiment analysis, where the
    difference between a satisfied and dissatisfied customer can often be subtle and
    context-dependent. However, it is important to note that while LLMs offer these
    advantages, they also come with certain limitations. They can be computationally
    expensive and require significant processing power, which might not be accessible
    to all users or can come at a cost. Additionally, LLMs are not infallible, and
    they can sometimes produce biased or inaccurate results based on the data they
    were trained on.
  prefs: []
  type: TYPE_NORMAL
- en: While a more in-depth discussion of GenAI models and their limitations will
    come in *Part IV* of the book, this chapter will touch upon the targeted application
    of GenAI for sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Practical example: Twitter Airline Sentiment dataset'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our exploration of sentiment analysis will be based on the `Twitter Airline
    Sentiment` dataset. This collection of tweets directed at various airlines provides
    a rich dataset for understanding how sentiment analysis can be applied to real-world
    marketing challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Here, sentiments are classified as positive, negative, or neutral via human
    annotation, reflecting a range of customer emotions from satisfaction to frustration.
  prefs: []
  type: TYPE_NORMAL
- en: '**Source code and data**: [https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.5/SentimentAnalysis.ipynb](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.5/SentimentAnalysis.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data source**: [https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment)'
  prefs: []
  type: TYPE_NORMAL
- en: Conveniently, this dataset contains not only tweets and their sentiment classifications
    but also, in some cases, explanations for tweets with negative sentiment. These
    will provide useful benchmarks for us to evaluate the approaches we will develop
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving into the data, below are some sample tweets, highlighting the
    sentiment classifications, the topics present, and the nature of the tweet content.
    As you can see, the first couple of rows of the dataset contain terms that are
    a result of real-world data entry errors, which will be addressed during the data
    preprocessing stage.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1: Sample tweets from the Twitter Airline Sentiment dataset'
  prefs: []
  type: TYPE_NORMAL
- en: In the subsequent sections, we’ll tackle the data preparation, model building,
    analysis, and visualization stages, employing both conventional NLP techniques
    and a more modern approach using LLMs. Initially, we’ll apply NLP tools for data
    cleaning and structuring, laying the groundwork for traditional sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing the challenges of class imbalance, we’ll demonstrate how GenAI can
    be used as a tool to augment our dataset with additional examples, as necessary.
    We will then use the models we’ve built to derive actionable insights that can
    help guide marketing campaigns.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing data for sentiment analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before diving into sentiment analysis, it’s crucial to prepare your data effectively.
    Data preparation is a process that involves cleaning, structuring, and enhancing
    data to improve analysis outcomes. The goal of these steps is to ensure that the
    data is in a form that is directly usable for analysis and to remove any inaccuracies
    or irregularities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin by loading the `Twitter Airline Sentiment` dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `df.columns`, we can see a number of columns, such as `text`, which contains
    the tweet itself, along with several valuable metadata and sentiment-related fields.
    The following is a summary of the columns, along with a short description of their
    meaning:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Column** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `tweet_id` | ID of tweet |'
  prefs: []
  type: TYPE_TB
- en: '| `airline_sentiment` | Class label of tweets (positive, neutral, or negative)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `airline_sentiment_confidence` | Confidence level in sentiment classification
    |'
  prefs: []
  type: TYPE_TB
- en: '| `negative_reason` | Reason for negative sentiment |'
  prefs: []
  type: TYPE_TB
- en: '| `airline` | Official name of the airline |'
  prefs: []
  type: TYPE_TB
- en: '| `airline_sentiment_gold` | Gold standard for airline sentiment classification
    |'
  prefs: []
  type: TYPE_TB
- en: '| `name` | Name of the user |'
  prefs: []
  type: TYPE_TB
- en: '| `negativereason_gold` | Gold standard for the rationale behind the negative
    reason |'
  prefs: []
  type: TYPE_TB
- en: '| `retweet_count` | Numerical value representing the number of retweets |'
  prefs: []
  type: TYPE_TB
- en: '| `text` | Text of the tweet as typed by the user |'
  prefs: []
  type: TYPE_TB
- en: '| `tweet_coord` | Latitude and longitude of the Twitter user |'
  prefs: []
  type: TYPE_TB
- en: '| `tweet_created` | Creation date of the tweet |'
  prefs: []
  type: TYPE_TB
- en: '| `tweet_location` | Location from which the tweet was sent |'
  prefs: []
  type: TYPE_TB
- en: '| `user_timezone` | Timezone of the user |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5.2: Columns and their description for the Twitter Airline Sentiment
    dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Traditional NLP techniques for data preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In traditional NLP techniques, careful text preparation—encompassing cleaning,
    tokenization, stop word removal, and lemmatization—is important to structure the
    input text for effective analysis. We’ll discuss these processes in detail in
    this section.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, modern techniques such as word embeddings (e.g., Word2Vec and GloVe)
    and contextual embeddings (e.g., BERT and GPT-4) offer more advanced ways to represent
    and process text data. These modern techniques will also be explained in greater
    detail in *Part IV* of the book. Unlike traditional methods that rely on manual
    feature extraction, modern techniques automatically learn dense representations
    of words and context from their pre-training on other texts.
  prefs: []
  type: TYPE_NORMAL
- en: 'For illustration, we will take a sample of five tweet texts and use them as
    examples to see the impact of traditional data preparation steps. We will also
    use the column width setting via `pd.set_option` to show the full column width
    in our DataFrame, thus displaying the full tweet text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Cleaning text data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Text cleaning enhances the quality of data analysis by removing noise and making
    the format of text uniform. The primary advantages include improved model accuracy
    and faster computation. However, it’s essential to approach cleaning carefully
    to avoid removing contextually important information. Cleaning is especially useful
    for the Twitter dataset, due to the informal and diverse nature of social media
    text. Tweets often contain URLs, mentions, emojis, and hashtags that can sometimes
    detract from the primary sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our approach targets these specifics to preserve the core message while eliminating
    extraneous elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2: Examples of tweet text before and after cleaning'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the removal of (`@`) mentions from the text does little to detract
    from the context, as our dataset already has the subject of the tweet captured
    by the `airline` column.
  prefs: []
  type: TYPE_NORMAL
- en: '**Additional packages for text preprocessing**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other useful Python tools for NLP and text preprocessing not used in this section
    include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**NLTK** ([https://www.nltk.org/](https://www.nltk.org/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TextBlob** ([https://textblob.readthedocs.io](https://textblob.readthedocs.io))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gensim** ([https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tokenization and stop word removal
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tokenization divides text into smaller units, such as words or phrases, making
    it easier for algorithms to understand language structure. Stop words are commonly
    used words like “is,” “and,” or “the,” and they are often removed because they
    add little semantic value, allowing models to focus on more meaningful content.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this implementation, we use spaCy’s model to apply both tokenization and
    stop word removal and show the results of each step of the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.3: Examples of tweet texts after tokenization and stop word removal'
  prefs: []
  type: TYPE_NORMAL
- en: Lemmatization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lemmatization reduces words to their dictionary form, ensuring the outcome is
    a valid word. This process aims to consolidate different forms of a word to analyze
    them as a single item, enhancing the efficiency and accuracy of the downstream
    task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at the last row of the below code, we see that the final lemmatized
    text standardizes `wheels` to its singular form, `wheel`, and converts `thanks`
    to its base verb form, `thank`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4: Examples of the tweet text after lemmatization'
  prefs: []
  type: TYPE_NORMAL
- en: Class imbalance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now introduce why it is important to understand class balance through
    exploratory data analysis on our dataset. Class balance directly impacts a model’s
    ability to learn from data effectively. Unaddressed class imbalances can obscure
    insights and lead to models that do not perform as intended in real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will not only quantify class imbalance but also
    discuss both simple and more advanced strategies to address it.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating class balance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Identifying the overall sentiment distribution is crucial, as it helps us understand
    the general mood and opinions expressed in a dataset. This understanding is also
    essential for understanding any biases that may be present due to class imbalance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code groups tweets by airlines and sentiment, calculates the
    size of each group, and generates a bar plot to visualize the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This code generates the following graph, illustrating how the airline tweets
    captured in this dataset are primarily negative in sentiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.5: Distribution of tweets, grouped by airline and sentiment'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we look at the class balance across the dataset, we can see there are 9,178
    negative examples, 3,099 neutral examples, and 2,363 positive tweets. This can
    be shown via:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Datasets with class imbalance are frequently encountered in real-world datasets,
    and therefore, we will retain this characteristic of the data throughout the chapter,
    allowing us to understand the impact that class imbalance can have on modeling
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Addressing class imbalance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following traditional strategies can be employed to address class imbalance:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Undersampling** reduces the size of the majority class to match the minority
    class. This helps balance the dataset but may result in the loss of valuable majority
    class examples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Oversampling** increases the size of the minority class to match the majority
    class by duplicating existing examples. This improves balance but can lead to
    model overfitting on the repeated data examples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synthetic Minority Over-sampling TEchnique** (**SMOTE**) is similar to oversampling,
    except that it generates synthetic examples instead of simply duplicating existing
    ones. It does this by generating new instances based on examples that are similar
    in feature space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As an exercise, you can undersample the majority class (negative sentiment)
    to achieve a more balanced dataset. This can be achieved with the following code,
    where we first divide our training data into the negative, neutral, and positive
    classes and then downsample the negative class to match the number of examples
    in the minority (positive) class, resulting in a more balanced starting dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Experimenting with undersampling**'
  prefs: []
  type: TYPE_NORMAL
- en: As an exercise, run the downsampling code given in the text and substitute `df_downsampled`
    for `df` in the remainder of the chapter to see how your results differ with a
    more balanced dataset.
  prefs: []
  type: TYPE_NORMAL
- en: GenAI for data augmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this section, we will demonstrate a strategy to augment the underrepresented
    positive class by generating new examples, using a seed text via GenAI. This more
    novel approach complements traditional techniques to address class imbalance but
    with greater potential diversity in the new examples. However, using AI-generated
    data can introduce risks, such as overfitting to generated patterns or reflecting
    potential biases from the generative model itself. Ensuring a variety of seed
    texts can help mitigate these issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will utilize the `distilgpt2` model from Hugging Face’s Transformers library
    to augment our dataset. This model, a simplified version of GPT-2, is tailored
    toward resource efficiency, thus making this example accessible to users with
    varying computational resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that GenAI’s probabilistic nature means that output may vary with
    each execution. By starting with a carefully chosen seed text of `"``Fantastic
    airline service on this flight. My favorite part of the flight was"` we are able
    to generate varied positive sentiments about airline services. When using this
    seed text in the `text-generation` pipeline above, we generate outputs such as
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fantastic airline service on this flight. My favorite part of the flight
    was** *enjoying the fantastic view of all the flight attendants and the runway*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fantastic airline service on this flight. My favorite part of the flight
    was** *that it was the first time I ever flew in it, and it was worth it*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, most LLMs will produce language that’s reflective of what you’d
    expect to hear in everyday life. For example, try removing the end part of the
    seed statement “`My favorite part of the flight was`" and see how much more difficult
    it is to have the LLM produce examples with positive sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: '**Importance of GenAI model selection and prompt sensitivity**'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring more sophisticated models available from Hugging Face, such as `gpt-neo`,
    `gpt-j`, and `EleutherAI/gpt-neo-2.7B`, will yield more impressively nuanced and
    realistic augmentations.
  prefs: []
  type: TYPE_NORMAL
- en: The choice of prompt also plays a crucial role in steering the generative model’s
    output. A subtle change in the seed text can lead to dramatically different results,
    underscoring the importance of prompt design in GenAI applications. This topic
    is explored in detail in *Chapter 9* of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this augmentation step enhances the representation of positive sentiment
    tweets within our dataset, achieving true class balance would require more extensive
    data augmentation, as well as a variety of seed texts, to ensure that the model
    does not overfit on the beginning part of the tweet. We can increase the number
    of augmentation examples generated by changing the `augment_times` parameter in
    the above `augment_text()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: By carefully employing GenAI for data augmentation, we now have `df_augmented`
    as a dataframe, with additional data that can be added to our existing dataset
    to mitigate class imbalance and enhance the dataset with varied expressions of
    positive sentiment. However, in order to illustrate the impact of the class imbalance
    in the original dataset on our results, we will refrain from adding these examples
    to our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Performing sentiment analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The power of sentiment analysis lies in its ability to uncover the emotions
    behind text data, providing invaluable insights into customer sentiments. While
    the focus of the Twitter Airline Sentiment dataset is on categorizing sentiments
    into positive, negative, and neutral classes, sentiment analysis can also extend
    beyond these basic categories. Depending on the application, sentiments can be
    analyzed to detect more nuanced emotional states or attitudes, such as happiness,
    anger, surprise, or disappointment.
  prefs: []
  type: TYPE_NORMAL
- en: Building your own ML model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A fundamental aspect of training sentiment analysis models, especially with
    traditional NLP techniques, is the necessity for pre-labeled data. These labels
    are typically derived from human annotations, a process that involves individuals
    assessing the sentiment of a piece of text and categorizing it accordingly. The
    sentiment scores in this Twitter dataset were collected with the help of volunteers,
    and some of the negative tweets were also broken down based on specific issues
    they highlighted, such as flight delays or poor service, providing a more nuanced
    view of customer dissatisfaction.
  prefs: []
  type: TYPE_NORMAL
- en: Using `scikit-learn`, we will construct sentiment analysis models that leverage
    this pre-labeled dataset. These models will utilize the text preprocessing demonstrated
    in the previous section to extract TF-IDF features from the text, which, in turn,
    serve as inputs for machine learning inferences that can predict the sentiment
    of unseen tweets.
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before training a model, we need to convert the text data into numerical features.
    One common approach is to use the **TF-IDF** (**Term Frequency-Inverse Document
    Frequency**) technique. TF-IDF is a statistical measure used to evaluate the importance
    of a word to a document in a collection or corpus. We will utilize the text preprocessing
    steps we performed earlier and apply the `tfidf` vectorizer directly to the processed
    text, limiting the features to the top 1,000 terms `(max_features=1000)`. This
    step is important because reducing dimensionality helps to simplify the model,
    making it faster to train and reducing the risk of overfitting. By focusing on
    the most relevant words, we ensure that the model captures the most significant
    patterns in the data while ignoring less important details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**Exploring feature engineering with TF-IDF**'
  prefs: []
  type: TYPE_NORMAL
- en: Another parameter to explore on your own during TF-IDF feature engineering is
    `ngram_range`.
  prefs: []
  type: TYPE_NORMAL
- en: N-grams allow you to go beyond individual words and consider pairs (bigrams)
    or triples (trigrams) of consecutive words as single features. This can capture
    more context and the relationship between words – for example, while “not” and
    “good” individually might not be very informative, the bigram “not good” carries
    a clear sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: Model training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With our features ready, we can proceed to train a simple model using scikit-learn.
    Logistic regression is a simple yet powerful algorithm that works well with the
    dimensionality of the data contained in these short tweets. It models the probabilities
    for classification problems with two possible outcomes, but it can be extended
    to handle multiple classes, which is applicable in our case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: With our logistic regression model trained, we can now interpret the model’s
    coefficients to obtain insight into how specific words influence sentiment classification.
    For each sentiment category, the coefficients represent the influence of these
    terms on the likelihood of a text being classified within that particular sentiment,
    and the magnitude represents the importance of each term in the model’s decision-making
    process.
  prefs: []
  type: TYPE_NORMAL
- en: 'To accomplish this, we iterate over each class label to extract and display
    the most influential features, sorted by the absolute value of their coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.6: Most influential features by sentiment class for the logistic regression
    model'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see from the above coefficients the influence of the following words
    on the three sentiment classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Negative sentiment**: The word `thank` `(-3.88`) decreases the likelihood
    of a tweet being classified as negative, whereas words like `hour` (`3.61`), `bad`
    (`2.96`), `delay` (`2.84`), and `cancel` (`2.63`) increase this likelihood and
    are characteristic of complaints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neutral sentiment**: Words such as `customer` (`-2.24`), `experience` (`-1.91`),
    and `fix` (`-1.88`) decrease the likelihood of neutral classification, indicating
    that these terms are more often used in non-neutral contexts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Positive sentiment**: Terms like `thank` (`4.36`), `great` (`3.54`), `awesome`
    (`3.18`), and `amazing` (`3.07`) significantly increase the likelihood of a tweet
    being classified as positive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Evaluating our model’s performance is a critical step after training. Without
    proper evaluation, we risk deploying a model that may perform poorly in real-world
    scenarios, potentially leading to incorrect conclusions based on its predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Classification report
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The classification report from scikit-learn gives us the precision, recall,
    and F1 score for each class. These metrics are crucial, as they tell us not just
    about the overall accuracy but also how well the model performs for each sentiment
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B30999_05_07.png)Figure 5.7: Classification report metrics evaluating
    logistic regression model performance'
  prefs: []
  type: TYPE_NORMAL
- en: The macro average and weighted average scores give us an understanding of the
    model’s performance across all classes. The macro average treats all classes equally,
    while the weighted average takes the class imbalance into account. The differences
    between these scores highlight the impact of the class imbalance on the model’s
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look more closely at the results for each class:'
  prefs: []
  type: TYPE_NORMAL
- en: The negative sentiment, as the majority class, has high precision (`0.82`) and
    recall (`0.92`), indicating that the model is particularly good at identifying
    negative tweets. This is an expected side effect of our class imbalance, since
    the model has more examples of this class to learn from, leading to a higher likelihood
    of predicting this class correctly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The neutral sentiment, being less represented than the negative but more than
    the positive, shows a significantly lower precision (`0.61`) and recall (`0.49`).
    The precision is reasonably good, meaning that when the model predicts a tweet
    as neutral, it’s correct a little over half the time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The positive sentiment, the least represented class, has a relatively high precision
    (`0.79`) but lower recall (`0.61`) than the negative class. High precision here
    indicates that most tweets predicted as positive are indeed positive, but the
    model fails to catch many positive sentiments (low recall).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Confusion matrix
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A confusion matrix is an excellent next step to further understanding a model’s
    performance. It shows a matrix with the actual classes on one axis and the predicted
    classes on the other. By analyzing the confusion matrix, we can see which classes
    are being confused with one another. For example, if many neutral tweets are misclassified
    as negative, this might suggest that the model is biased toward predicting negative
    and that the features for neutral tweets are not distinctive enough. We can calculate
    and visualize the confusion matrix using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then see the following confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.8: Confusion matrix of tweet sentiment classes for the logistic regression
    model'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s break this down to understand it better:'
  prefs: []
  type: TYPE_NORMAL
- en: Consistent with our observations from the classification report, the model shows
    strong performance in correctly identifying negative tweets, as captured by the
    first row in the confusion matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When it comes to neutral sentiments, the second row indicates a tendency of
    the model to confuse neutral tweets with negative ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, the third row corresponds to positive sentiments. While the model correctly
    identifies positive tweets more than half the time, there is still a considerable
    portion that is confused with negative or neutral sentiments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding misclassifications
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: After assessing our model with various metrics, we can investigate examples
    when the model fails, giving insight into its limitations and opportunities for
    improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the instances where the model’s predictions clash with the trusted
    classifications provided by `airline_sentiment_gold` data labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.9: Example tweets where the dataset labels disagree with model predictions
    from the logistic regression model'
  prefs: []
  type: TYPE_NORMAL
- en: An analysis of the misclassified examples demonstrates where our model’s `predicted_sentiment`
    falls short of accurately capturing the context of the full tweet. For instance,
    the second misclassification example of a tweet expressing disappointment over
    a canceled flight, cloaked in a humorous tone, highlights the inherent challenge
    in detecting sarcasm and underscores the importance of model training that encompasses
    a wider spectrum of sentiment expressions. Then, for the last example, we have
    an encouraging tweet, acknowledging the opportunity for improvement from negative
    experiences, which is predicted to be negative. This illustrates the difficulty
    of TF-IDF features in a model to interpret nuanced positive sentiments, especially
    when intertwined with negative words. These mischaracterizations could benefit
    from more advanced NLP models that are capable of better discerning context and
    nuance, a topic we will explore in the next section on pre-trained LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhancing the performance of traditional sentiment models**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Address training data gaps**: Ensure that your dataset includes a wide range
    of sentiment expressions such as sarcasm, humor, and conditional positivity. A
    model’s ability to accurately interpret sentiments is directly tied to the diversity
    of examples it has learned from. Sampling techniques, such as stratified sampling,
    can be used to ensure that all sentiment types are adequately represented in the
    training set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understand feature representation limitations**: Traditional feature representation
    methods like TF-IDF may not fully capture complex sentiment nuances, especially
    where overall sentiment is not the sum of its parts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhance models with contextual features**: Enrich feature sets by incorporating
    contextual cues like n-grams or part-of-speech tagging. These additions help capture
    sentiment nuances by considering word order and grammatical structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explore more robust ML algorithms**: Beyond simpler methods such as logistic
    regression and naive Bayes, ensemble methods like random forests and boosting
    algorithms (XGBoost) capture complex patterns better. Additionally, hyperparameter
    tuning on logistic regression (e.g., adjusting regularization strength) can significantly
    improve performance. Deep learning methods such as CNNs and RNNs often provide
    the best performance, provided there are enough training examples present.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having explored various techniques to enhance traditional sentiment models,
    including addressing data gaps, feature representation, and appropriate algorithms,
    we now turn our attention to a more modern advancement in sentiment analysis,
    using pre-trained LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Using pre-trained LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before applying pre-trained LLMs for sentiment analysis, it is important to
    understand the concept of embeddings, which serve as the foundation for these
    advanced models. At their core, embeddings are dense vector representations of
    data, which could be anything, from words and entire documents to even images
    and relational data. These vectors are designed to capture the key features of
    data in a high-dimensional space.
  prefs: []
  type: TYPE_NORMAL
- en: Early examples of NLP embeddings include Word2Vec and GloVe, which generate
    **static embeddings**. In Word2Vec, the embeddings are influenced by local context
    through techniques like skip-grams and **continuous bag of words** (**CBOW**),
    but once trained, the same word has the same vector representation regardless
    of the broader context. However, state-of-the-art LLMs like BERT and GPT introduced
    true **contextual embeddings**, where the representation of a word dynamically
    changes based on its contextual usage. The key attribute of an effective NLP embedding
    is that it preserves the original data’s semantic relationships in its vector
    space, meaning that similar vectors (words, phrases, or documents) are closer
    together than less similar data.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating LLMs for sentiment analysis marks a significant advancement in
    the field of NLP, streamlining the process of understanding complex textual data.
    These models excel in capturing the subtleties of human language through extensive
    pre-training on diverse datasets, thus bypassing the need for elaborate text preprocessing,
    hyperparameter tuning – or even the need for pre-labeled data. For marketing professionals,
    this translates into a more efficient way to gauge customer sentiment across different
    platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing pre-trained models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To demonstrate the efficacy of a pre-trained LLM, the `sentiment-analysis` pipeline
    from the `distilbert-base-uncased-finetuned-sst-2-english` model in the Transformers
    library will be used. DistilBERT is a smaller, faster version of BERT that retains
    95% of its contextual embedding performance. This particular variant has been
    fine-tuned on the **Stanford Sentiment Treebank** (**SST-2**) dataset, a standard
    benchmark for sentiment analysis, consisting of movie reviews with human-annotated
    `positive` or `negative` sentiments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given its binary classification nature, `neutral` sentiments are excluded from
    our test set to align the model’s available predictions between `positive` and
    `negative`. For this example, we will also incorporate the `time` and `tqdm` modules
    into our code to track the execution time. After the model loads, inference on
    all of the test texts may take a few minutes to complete using the `sentiment-analysis`
    pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Utilizing the ``sentiment-analysis`` pipeline for DistilBERT simplifies the
    sentiment analysis process by encapsulating several complex steps into one efficient
    process. Without this, the tokenization, text embeddings, inference, and post-processing
    would all need to be handled separately.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating model performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The classification report from the LLM inference can be obtained using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.10: Classification report metrics evaluating LLM performance'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s generate the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.11: Confusion matrix of tweet sentiment classes for the LLM'
  prefs: []
  type: TYPE_NORMAL
- en: When comparing the performances of the previous logistic regression model utilizing
    TF-IDF features and our pre-trained LLM, several observations emerge. The logistic
    regression model, while providing a strong baseline for sentiment analysis, has
    limitations in handling the nuances of natural language. While class imbalance
    likely played some role in the model’s performance issues, it is important to
    note that the LLM’s capabilities to understand language nuances, derived from
    its extensive pre-training and fine-tuning, likely played a larger role in its
    superior performance. Additionally, the logistic regression model only used unigrams
    for TF-IDF, which fails to capture context and contributes to mischaracterizations.
    For these reasons, it particularly struggles at classifying positive (and neutral)
    sentiments amid a dominant negative sentiment class.
  prefs: []
  type: TYPE_NORMAL
- en: The LLM – keeping in mind we excluded the neutral class from its classification
    task to stay consistent with the nature of its fine-tuning procedure – demonstrates
    a more robust performance.
  prefs: []
  type: TYPE_NORMAL
- en: This is showcased by its heightened accuracy in distinguishing between positive
    and negative sentiments. It is important to note that the logistic regression
    model started with imbalanced data to illustrate its impact on results, whereas
    the LLM did not undergo any task-specific training on the Twitter data and was
    trained only on the SST-2 movie reviews. The key takeaway here is that the LLM’s
    knowledge is generalized effectively, from movie reviews to Twitter data, highlighting
    its robust language understanding capabilities. With a precision of `0.96` for
    negative sentiments and a recall rate of `0.90`, the model underscores the potential
    of leveraging pre-trained neural networks for sentiment analysis. The improvement
    in positive sentiment detection, achieving a precision of `0.68` and a recall
    of `0.84`, further emphasizes the model’s predictive power.
  prefs: []
  type: TYPE_NORMAL
- en: One drawback of using advanced machine-learning models like LLMs is their lack
    of explainability. Understanding what exactly creates negative sentiment can be
    challenging with these black-box models. Techniques such as **LIME** (**local
    interpretable model-agnostic explanations**) can be used to improve explainability.
    For a more detailed discussion on model transparency and techniques to elucidate
    LLM decisions, please refer to *Chapter 13*.
  prefs: []
  type: TYPE_NORMAL
- en: While the LLM performance is noteworthy, fine-tuning the LLM on the specific
    sentiment labels present in our airline tweets dataset would further improve its
    performance. Fine-tuning adapts a model more closely to a task’s unique context,
    allowing the model to leverage and understand the nuances of the classification
    task.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to fine-tuning, transfer learning and few-shot learning are powerful
    methodologies that further refine a model’s ability to classify sentiments with
    high accuracy. Transfer learning involves adapting a pre-trained model on a related
    task to perform well on the target task, even with minimal additional training
    data. Conversely, few-shot learning trains the model to make accurate predictions
    with only a few examples of the target task available.
  prefs: []
  type: TYPE_NORMAL
- en: '**Improving LLMs: transfer and few-shot learning**'
  prefs: []
  type: TYPE_NORMAL
- en: In *Part 4* of this book, we will explore these cutting-edge methodologies in
    more depth. We will explore how fine-tuning, transfer learning, and few-shot learning
    can be applied to pre-trained models, transforming them into highly specialized
    tools for domain-specific tasks like sentiment classification.
  prefs: []
  type: TYPE_NORMAL
- en: When we arrive at Part 4 of this book, we will delve deeper into related methodologies
    at the cutting edge of adapting pre-trained models for domain-specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Translating sentiment into actionable insights
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this chapter, we have explored the tools and strategies needed to
    understand and apply sentiment analysis to your data, from the foundational techniques
    of data preparation and prediction using traditional NLP methods to the advanced
    capabilities of GenAI. In this final part of the chapter, we will discuss how
    these insights can be analyzed to generate actionable strategies that can guide
    a brand to success across all stages of a marketing campaign.
  prefs: []
  type: TYPE_NORMAL
- en: Creating your own dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before applying this analysis to your use case, we need an approach to collecting
    the data that captures the underlying customer sentiment related to your brand.
    While this chapter utilizes the Twitter Airline dataset as an example, the techniques
    we’ve explored are applicable regardless of the industry or data source. This
    section will present the general steps you can take to curate your own proprietary
    dataset for analysis, whether it be from Twitter or another major data platform.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ethics and governance in AI-enabled marketing**'
  prefs: []
  type: TYPE_NORMAL
- en: Ethics and governance in AI-enabled marketing is the topic of *Chapter 13*,
    and it is crucial to adhere to ethical guidelines and governance frameworks that
    respect consumer privacy and data protection laws when collecting data. Ethical
    practices in marketing include obtaining consent for data collection, ensuring
    data anonymization to protect individual identities, and providing clear opt-out
    mechanisms. Companies should establish robust data governance policies that define
    data handling procedures and compliance with legal standards such as the EU’s
    **General Data Protection Regulation** (**GDPR**) or the **California Consumer
    Privacy Act** (**CCPA**).
  prefs: []
  type: TYPE_NORMAL
- en: Collecting twitter data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To start, ensure you have a Twitter Developer account and access to the Twitter
    (now rebranded as X) API. You can follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll first need to create a project and obtain your API keys and tokens,
    and then, using the credentials from your Twitter Developer account ([https://developer.twitter.com/en/portal/petition/essential/basic-info](https://developer.twitter.com/en/portal/petition/essential/basic-info)),
    authenticate your session to access the Twitter API. The following are general
    instructions to do this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that we have access to the Twitter API, you can use the Twitter handle
    or relevant hashtags associated with your brand and combine this with the `search_tweets`
    method to find relevant tweets. This example collects the latest 100 tweets mentioning
    `"@YourBrandHandle"`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Due to recent changes, the Twitter (X) API may have limited access, and certain
    endpoints may require elevated access levels. If you encounter a `403` `Forbidden`
    error, you may need to upgrade your access level or use alternative endpoints
    available in the API documentation. More details can be found on the Twitter developer
    portal ([https://developer.twitter.com/en/portal/petition/essential/basic-info](https://developer.twitter.com/en/portal/petition/essential/basic-info)).
  prefs: []
  type: TYPE_NORMAL
- en: 'With the tweets collected, we can extract relevant information such as the
    tweet ID, text, creation time, and location. We can then structure this data into
    a `pandas` DataFrame for easier analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There are many further metadata fields available in the API response documentation
    that are worth considering, including retweet count `(tweet.retweet_count)`, hashtags
    `(tweet.entities['hashtags'])`, and mentions `(tweet.entities['user_mentions'])`.
    As discussed in the sections below, these fields can provide valuable insight
    into topics that are pivotal for understanding your brand’s sentiment narrative,
    including salient topics, tweet engagement, and virality.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting data from other platforms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Analyzing brand sentiment extends beyond Twitter, encompassing a variety of
    social media platforms including Facebook, Instagram, Google reviews, and more.
    Each platform presents unique challenges and opportunities to gather and analyze
    data. The approach to collecting data differs, based on each platform’s API capabilities
    and data availability. For platforms like Google reviews, APIs may allow you to
    directly access reviews and ratings. On platforms like Facebook and Instagram,
    you might rely on posts, comments, and hashtags to gauge sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: '**Accessing developer APIs**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To collect data from different social media platforms, you need to access their
    respective developer APIs. Here are some useful links to get you started:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Facebook**: [https://developers.facebook.com/docs/graph-api](https://developers.facebook.com/docs/graph-api
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instagram**: [https://developers.facebook.com/docs/instagram-api](https://developers.facebook.com/docs/instagram-api
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reddit**: [https://www.reddit.com/dev/api/](https://www.reddit.com/dev/api/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YouTube**: [https://developers.google.com/youtube/v3](https://developers.google.com/youtube/v3)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TikTok**[:https://developers.tiktok.com/products/research-api/](https://developers.tiktok.com/products/research-api/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the data is obtained, a primary challenge can be accurately identifying
    mentions and discussions related to your brand. This is where **named entity recognition**
    (**NER**) and entity mapping techniques come into play. NER can help identify
    proper nouns, like brand names or products, within texts, while entity mapping
    can link these mentions to your brand across datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Performing NER on a dataset for a fictional retailer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For example, let’s consider a series of customer reviews from a fictional online
    retailer, Optimal Hiking Gear, which sells outdoor equipment. To extract mentions
    of the brand, we can use the built-in capabilities for NER in the spaCy language
    model and look for its `ORG` tag to identify relevant mentions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '**Enhancing NER with custom training**'
  prefs: []
  type: TYPE_NORMAL
- en: To tailor NER models more closely to your needs, consider training them with
    your data. This involves providing examples of texts with manually labeled entities
    that are specific to your brand or industry. By doing so, a model learns to recognize
    and categorize these custom entities more accurately. Tools like spaCy offer functionalities
    to train your NER models.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding topics and themes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section delves into various tools to extract insights from your dataset
    to provide an overview of the key topics and themes present. Such insights are
    crucial for grasping the broader context of customer sentiment within your data.
    As a starting point, we can use, for reference, the number of different reasons
    for negative sentiment that were tagged by the annotators of this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.12: Counts of different negative sentiment tweets’ reasons given in
    the Twitter dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Using word clouds
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Word clouds**, where the size of each word in a plot corresponds to its frequency
    of occurrence, are a valuable starting tool to visualize text data. In order to
    enrich our word clouds and ensure that visualizations reflect not only the most
    frequent terms but also those that are most indicative of unique sentiments and
    topics, we will incorporate TF-IDF analysis to produce our plot. By introducing
    the `ngram_range=(1, 2)` argument into our `tfidf_vectorizer`, we create both
    unigrams and bigrams. Leveraging the `WordCloud` library, we can create word clouds
    via:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll then see something similar to the following word cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.13: Word clouds showing the frequency of occurrence of different terms
    from TF-IDF analysis'
  prefs: []
  type: TYPE_NORMAL
- en: 'The analysis so far reveals pivotal themes through prevalent words such as
    `delay`, `cancel`, and `help`. Through the inclusion of bigrams, key terms such
    as `customer service` and `cancel flight` can also be captured. In the context
    of Twitter data, hashtags offer a direct glimpse into the core topics and sentiments
    expressed. To dive deeper, we will proceed to extract hashtags from the tweets,
    creating a word cloud to visualize these key phrases differently. This approach
    aims to provide a different lens to view the themes within our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We then see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.14: Word clouds showing the frequency of occurrence of Twitter hashtags'
  prefs: []
  type: TYPE_NORMAL
- en: Excluding direct airline mentions, the word cloud distinctly highlights prevalent
    negative sentiments through hashtags like `#Fail`, `#Disappointed`, and `#BadCustomerService`.
    In contrast to these, `#DestinationDragons` emerges prominently as well, signifying
    a well-publicized tour by Southwest Airlines, showcasing the duality of customer
    feedback captured in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering latent topics with LDA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Latent Dirichlet allocation** (**LDA**) is an advanced technique that goes
    beyond simple frequency metrics, like those seen in word clouds, by identifying
    the underlying topics within a text corpus through unsupervised machine learning.
    Unlike word clouds, which only highlight the most frequent words, LDA discerns
    the hidden thematic structure by considering documents as mixtures of topics,
    where each topic is defined by a particular set of words. This process involves
    Bayesian inference, using the Dirichlet distribution to estimate not just the
    presence but also the proportion of topics within documents. For example, in a
    collection of hotel reviews, LDA might identify topics related to location, parking,
    bathroom cleanliness, and check-in experience. The sophistication of LDA lies
    in its ability to capture the context and co-occurrence of words across the corpus,
    providing a more nuanced understanding of the text’s thematic content without
    prior labeling.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can implement this approach via:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Analyzing the clusters generated by LDA allows us to pinpoint important themes
    in the tweets, such as flight delays and customer service issues, represented
    in topics `#1` and `#2`, respectively. By changing the `n_components` parameter,
    we can alter the algorithm’s assumption around the number of topics present, leading
    to more granular topics as the parameter increases in value.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to recognize that not all topics identified by LDA will directly
    align with key sentiment expressions, and some may simply reflect common, non-specific
    language pervasive throughout the dataset, as seen in topic `#0`.
  prefs: []
  type: TYPE_NORMAL
- en: To extract meaningful insights, additional scrutiny is often required to discern
    which topics are most relevant for analysis. This process can be facilitated either
    through human review or by employing a carefully designed prompt for a language
    model, helping to summarize the word groupings according to their possible topics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Temporal trends: tracking the brand narrative'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the dynamic realm of social media, the viral nature of tweets often acts
    as a barometer for the sentiments that are most impactful to a brand’s perception.
    This is especially true for negative sentiments, which carry a substantial risk
    to a brand’s image. By scrutinizing the Twitter activity around airlines, such
    as JetBlue, we can unearth insights into tweets that may significantly influence
    brand reputation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This paper presents a social media-based brand reputation tracker that monitors
    brand events in real time and connects them to specific drivers of brand reputation:
    [https://ora.ox.ac.uk/objects/uuid:00e9fcb7-9bf1-486a-b4dd-3c1d086af24e/files/rz316q188f](https://ora.ox.ac.uk/objects/uuid:00e9fcb7-9bf1-486a-b4dd-3c1d086af24e/files/rz316q188f).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This analysis involves sifting through tweets mentioning the `@JetBlue` handle.
    The code below categorizes the sentiment of these tweets over time, where each
    data point’s bubble size corresponds to that day’s aggregate retweets, providing
    a visual scale of engagement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.15: Sentiment of JetBlue tweets over time, where each data point’s
    bubble size corresponds to that day’s aggregate retweets'
  prefs: []
  type: TYPE_NORMAL
- en: Significant peaks in negative sentiment tweets are observed on February 22 and
    23, with an unusual surge in retweets on the latter day indicating widespread
    engagement. Those focusing on brand reputation for JetBlue may find it valuable
    to delve into the specifics of these tweets.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can aggregate and rank the tweets in this date range, as well as the day
    before, according to those with the highest retweets, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.16: Analysis of peak negative sentiment tweets for JetBlue on February
    22–24, 2015'
  prefs: []
  type: TYPE_NORMAL
- en: The first and last day of the result reveal typical grievances, like late flights
    and poor service, that are common in the airline industry. However, the backlash
    on February 23 highlights a controversy around a marketing campaign by JetBlue,
    encapsulated by the phrase “Our fleet’s on fleek.” As discussed in the introduction
    to this chapter, real-time monitoring of brand perception would have enabled them
    to track this shift in campaign sentiment early on, enabling them to anticipate
    and potentially mitigate the PR issues that ensued.
  prefs: []
  type: TYPE_NORMAL
- en: The potential long-term repercussions of this negative publicity would necessitate
    further monitoring and analysis – using metrics such as the KPIs discussed in
    *Chapter 2* – to assess the impact on brand reputation. Nonetheless, this analysis
    illustrates the importance of monitoring social media trends over time to preemptively
    address issues that could adversely affect brand perception.
  prefs: []
  type: TYPE_NORMAL
- en: Mapping sentiments using geospatial analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Geospatial analysis offers a powerful lens through which to view customer sentiment,
    enabling companies to identify areas of concern – from customer service issues
    to poorly designed marketing campaigns — potentially even before such issues become
    apparent to on-site staff. To illustrate how to generate such insights, let’s
    utilize the `folium` package to create a heat map that pinpoints the origins of
    negative sentiments, based on tweet coordinates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This code yields the following map:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_05_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.17: Heat map that pinpoints the origins of negative JetBlue sentiments,
    based on tweet coordinates'
  prefs: []
  type: TYPE_NORMAL
- en: The resulting heat map reveals concentrations of negative sentiment in regions
    where JetBlue predominantly operates – a correlation that is expected, given that
    a greater volume of flights naturally leads to more reports of negative experiences.
    However, by looking at the time evolution of these patterns, we can see that this
    method can serve as a real-time tool to spot unusual patterns of sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, a sudden influx of negative tweets from a new location could signal
    service issues and foreshadow potential PR challenges to follow. Conversely, identifying
    areas with a high number of positive tweets might highlight strengths within a
    company. Coupling geospatial analysis with the topic modeling approaches introduced
    earlier can also unlock further insights, revealing not only what is discussed
    but also where these conversations take place, providing a valuable trove of actionable
    marketing intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter underscored the importance of sentiment analysis in modern marketing
    strategies. It introduced sentiment analysis as a key tool to interpret vast quantities
    of unstructured text data, such as social media conversations, to refine marketing
    strategies, brand messaging, or customer experience. By utilizing the Twitter
    Airline dataset, we covered the end-to-end process needed to classify sentiment
    as positive or negative, using both traditional NLP and more advanced GenAI methods
    involving pre-trained LLMs. We then covered an array of tools for the visualization
    and interpretation of these results to derive actionable marketing insights. This
    chapter should leave you equipped with the necessary skills to harness sentiment
    analysis effectively, for applications ranging from brand reputation monitoring
    to aligning marketing messages with customer preferences.
  prefs: []
  type: TYPE_NORMAL
- en: Looking ahead to the next chapter, we will progress from understanding customer
    sentiment to actively shaping customer engagement using predictive analytics,
    with a focus on the empirical validation of marketing strategies through A/B testing.
    We will discuss identifying features to predict customer engagement, training
    machine learning models, model evaluation, and the implementation of A/B testing.
    The chapter is designed to advance your knowledge by providing skills in feature
    selection, building predictive models, optimizing model performance, conducting
    A/B tests, and integrating insights into effective marketing strategies. This
    next step will equip you with the ability to not only forecast customer behaviors
    but also empirically validate and refine marketing strategies for heightened effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genai](https://packt.link/genai)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code12856128601808671.png)'
  prefs: []
  type: TYPE_IMG
