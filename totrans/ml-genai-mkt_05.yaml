- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Enhancing Customer Insight with Sentiment Analysis
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用情感分析增强客户洞察
- en: In today’s digital age, understanding customer sentiment is key for shaping
    marketing strategies, refining brand messaging, and improving customer experience.
    Sentiment analysis, a subset of **natural language processing** (**NLP**), empowers
    marketers to sort through massive amounts of unstructured text data, such as customer
    feedback, social media conversations, and product reviews, to gauge public sentiment.
    This analytical approach not only helps in monitoring brand reputation but also
    in tailoring marketing messages according to customer preferences, which enhances
    the overall customer insight.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今的数字时代，理解客户情感对于塑造营销策略、完善品牌信息和提升客户体验至关重要。情感分析，作为自然语言处理（NLP）的一个子集，赋予营销人员处理大量非结构化文本数据的能力，如客户反馈、社交媒体对话和产品评论，以衡量公众情绪。这种分析方法不仅有助于监控品牌声誉，还能根据客户偏好定制营销信息，从而增强整体客户洞察。
- en: This chapter explores the world of sentiment analysis for marketing. Using the
    power of Python, you will learn how to classify sentiments as positive, negative,
    or neutral, and identify the nuances embedded within customer feedback. We will
    also use hands-on examples, based on the “Twitter Airline Sentiment” dataset from
    Kaggle, to equip you with the skills to perform sentiment analysis, interpret
    the results, and apply these insights to craft more effective marketing strategies.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了营销领域的情感分析世界。利用Python的力量，你将学习如何将情感分类为正面、负面或中性，并识别客户反馈中嵌入的细微差别。我们还将使用基于Kaggle的“Twitter航空情感”数据集的实战示例，为你提供执行情感分析、解读结果并将这些见解应用于制定更有效的营销策略的技能。
- en: 'Overall, this chapter will give you a comprehensive walkthrough of the fundamentals
    of sentiment analysis in marketing and then guide you through the practical aspects
    of data preparation, analysis, and results visualization. By the end of this chapter,
    you will gain proficiency in:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，本章将为你全面介绍营销中情感分析的基础知识，然后指导你通过数据准备、分析和结果可视化的实际方面。到本章结束时，你将精通：
- en: Understanding the critical role of sentiment analysis in marketing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解情感分析在营销中的关键作用
- en: Preprocessing text data to prepare it for analysis
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理文本数据以准备分析
- en: Applying Python libraries to perform sentiment analysis using traditional natural
    language processing and elements from generative AI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用Python库使用传统自然语言处理和生成式AI元素执行情感分析
- en: Interpreting and visualizing the outcomes to derive actionable marketing insights
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释和可视化结果以得出可操作的营销见解
- en: Introduction to sentiment analysis in marketing
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 营销中情感分析简介
- en: In the fast-paced world of marketing, staying attuned to customer sentiments
    is not just beneficial; it’s a necessity. Sentiment analysis, or the process of
    detecting positive, negative, or neutral tones in text data, stands at the forefront
    of this effort, offering a lens through which marketers can view and understand
    the emotional undertones of customer interactions. This approach uses NLP, machine
    learning, and computational linguistics to systematically identify, extract, quantify,
    and study patterns within text. These patterns can range from the presence of
    certain keywords and phrases to the structure of sentences and the context in
    which terms are used.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在营销这个快节奏的世界里，关注客户情感不仅有益，而且是必需的。情感分析，即检测文本数据中的正面、负面或中性语调的过程，是这个努力的前沿，为营销人员提供了一个观察和理解客户互动情感基调的视角。这种方法使用自然语言处理（NLP）、机器学习和计算语言学来系统地识别、提取、量化和研究文本中的模式。这些模式可以从某些关键词和短语的呈现到句子的结构和术语使用的上下文。
- en: The significance of sentiment analysis
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 情感分析的重要性
- en: The importance of sentiment analysis in marketing cannot be overstated. It acts
    as a compass, guiding brands through the vast and often turbulent sea of public
    opinion. By analyzing customer feedback, social media conversations, and product
    reviews, sentiment analysis helps marketers understand not just what people say
    but how they feel.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析在营销中的重要性不容小觑。它就像指南针，引导品牌穿越浩瀚且常常波涛汹涌的公众舆论大海。通过分析客户反馈、社交媒体对话和产品评论，情感分析帮助营销人员理解人们说了什么，以及他们的感受。
- en: '**Further reading on sentiment analysis in marketing**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**关于营销中情感分析的进一步阅读**'
- en: 'For an overview of approaches to automated textual analysis in marketing, refer
    to the article “*Uniting the Tribes: Using Text for Marketing Insight*” ([https://journals.sagepub.com/doi/full/10.1177/0022242919873106](https://journals.sagepub.com/doi/full/10.1177/0022242919873106)).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 关于营销中自动化文本分析方法的概述，请参阅文章“*团结各部落：利用文本进行营销洞察*”([https://journals.sagepub.com/doi/full/10.1177/0022242919873106](https://journals.sagepub.com/doi/full/10.1177/0022242919873106))。
- en: 'More specifically, the application of sentiment analysis in marketing opens
    an array of opportunities:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，情感分析在营销中的应用开辟了一系列机会：
- en: '**Brand monitoring**: Sentiment analysis enables real-time monitoring of brand
    perception across various digital platforms. By tracking shifts in sentiment,
    marketers can anticipate and mitigate potential PR crises. For example, during
    the United Airlines incident on April 9, 2017, where a passenger was forcibly
    removed from a flight due to overbooking, sentiment analysis could have helped
    United detect the rapidly escalating negative sentiment around the viral social
    media footage and respond more proactively.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**品牌监控**：情感分析能够实时监控品牌在各个数字平台上的感知。通过跟踪情感变化，营销人员可以预测并减轻潜在的公关危机。例如，在2017年4月9日，由于超售，一名乘客被从航班上强制带离的事件中，情感分析本可以帮助联合航空检测到社交媒体上病毒式传播的负面情绪的迅速升级，并更积极地做出反应。'
- en: '**Campaign analysis**: Understanding emotional responses to marketing campaigns
    allows for agile strategy adjustments. Sentiment analysis can reveal whether a
    campaign resonates positively with the target audience or if it misses the mark.
    For instance, Pepsi’s 2017 ad featuring Kendall Jenner received backlash for being
    perceived as trivializing social justice movements. Early sentiment analysis could
    have identified negative feedback and allowed for a timely campaign pivot.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**活动分析**：了解营销活动引起的情感反应，允许灵活调整策略。情感分析可以揭示活动是否与目标受众产生积极共鸣，或者是否偏离了目标。例如，百事公司在2017年推出的以肯达尔·詹纳为特色的广告，因其被认为轻视社会正义运动而受到抨击。早期的情感分析本可以识别出负面反馈，并允许及时调整活动策略。'
- en: '**Product feedback**: Detailed sentiment insights help pinpoint specific aspects
    of products or services that delight or disappoint customers. This feedback loop
    is invaluable for continuous improvement and innovation. Consider the case of
    Apple’s launch of the iPhone 6, where sentiment analysis of customer feedback
    highlighted the “Bendgate” issue, prompting Apple to address the problem quickly.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**产品反馈**：详细的情感洞察有助于精确指出产品或服务中令客户满意或不满意的特定方面。这种反馈循环对于持续改进和创新至关重要。以苹果公司发布iPhone
    6为例，对客户反馈的情感分析突出了“弯曲门”问题，促使苹果公司迅速解决问题。'
- en: '**Market research**: Sentiment analysis offers a window into the broader market
    landscape, providing a competitive edge by uncovering trends, competitor standings,
    and gaps in the market. For example, Netflix uses sentiment analysis to understand
    viewer preferences and trends, which aids in content creation and recommendation
    algorithms.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**市场研究**：情感分析为更广泛的市场格局提供了一个窗口，通过揭示趋势、竞争对手地位和市场空白，提供竞争优势。例如，Netflix利用情感分析来了解观众偏好和趋势，这有助于内容创作和推荐算法。'
- en: By harnessing the insights gained through sentiment analysis, marketers can
    not only monitor brand reputation but also tailor their communications to resonate
    more deeply with their audience, leading to more effective and impactful marketing
    strategies.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用情感分析获得的洞察，营销人员不仅可以监控品牌声誉，还可以调整他们的沟通方式，使其更深入地与受众产生共鸣，从而实现更有效和有影响力的营销策略。
- en: Advancements in AI and sentiment analysis
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能和情感分析方面的进步
- en: The emergence of **large language models** (**LLMs**) and **Generative AI**
    (**GenAI**) has transformed sentiment analysis, offering unprecedented depth and
    accuracy in understanding text data. LLMs are trained on vast datasets that encompass
    diverse linguistic patterns, enabling them to understand and generate human-like
    text. For example, LLMs can grasp context and nuance in ways that were previously
    unattainable, with state-of-the-art models that can distinguish between sarcasm
    and genuine dissatisfaction, or recognize the underlying positivity in a complaint
    that includes a suggestion for improvement.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**大型语言模型**（LLMs）和**生成式人工智能**（GenAI）的出现已经改变了情感分析，为理解文本数据提供了前所未有的深度和准确性。LLMs在包含各种语言模式的庞大数据集上训练，使它们能够理解和生成类似人类的文本。例如，LLMs可以以以前无法实现的方式理解上下文和细微差别，最先进的模型可以区分讽刺和真正的不满，或者识别包含改进建议的投诉中的潜在积极因素。'
- en: These advancements are particularly relevant for sentiment analysis, where the
    difference between a satisfied and dissatisfied customer can often be subtle and
    context-dependent. However, it is important to note that while LLMs offer these
    advantages, they also come with certain limitations. They can be computationally
    expensive and require significant processing power, which might not be accessible
    to all users or can come at a cost. Additionally, LLMs are not infallible, and
    they can sometimes produce biased or inaccurate results based on the data they
    were trained on.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些进步对于情感分析尤其相关，因为在满意和不满意的客户之间，差异往往微妙且依赖于上下文。然而，需要注意的是，尽管LLMs提供了这些优势，但它们也带来了一定的局限性。它们可能计算成本高昂，需要大量的处理能力，这可能不是所有用户都能负担得起，或者可能需要付出代价。此外，LLMs并非完美无缺，它们有时可能会基于训练数据产生有偏见或不准确的结果。
- en: While a more in-depth discussion of GenAI models and their limitations will
    come in *Part IV* of the book, this chapter will touch upon the targeted application
    of GenAI for sentiment analysis.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对GenAI模型及其局限性的更深入讨论将在本书的*第四部分*中展开，但本章将涉及GenAI在情感分析方面的针对性应用。
- en: 'Practical example: Twitter Airline Sentiment dataset'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际示例：Twitter Airline Sentiment数据集
- en: Our exploration of sentiment analysis will be based on the `Twitter Airline
    Sentiment` dataset. This collection of tweets directed at various airlines provides
    a rich dataset for understanding how sentiment analysis can be applied to real-world
    marketing challenges.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对情感分析的研究将基于`Twitter Airline Sentiment`数据集。这个针对不同航空公司的推文集合为理解如何将情感分析应用于现实世界的营销挑战提供了一个丰富的数据集。
- en: Here, sentiments are classified as positive, negative, or neutral via human
    annotation, reflecting a range of customer emotions from satisfaction to frustration.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，情感通过人工标注被分类为正面、负面或中性，反映了从满意到挫败的多种客户情绪。
- en: '**Source code and data**: [https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.5/SentimentAnalysis.ipynb](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.5/SentimentAnalysis.ipynb)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**源代码和数据**：[https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.5/SentimentAnalysis.ipynb](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.5/SentimentAnalysis.ipynb)'
- en: '**Data source**: [https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据来源**：[https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment)'
- en: Conveniently, this dataset contains not only tweets and their sentiment classifications
    but also, in some cases, explanations for tweets with negative sentiment. These
    will provide useful benchmarks for us to evaluate the approaches we will develop
    in this chapter.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 便利的是，这个数据集不仅包含推文及其情感分类，在某些情况下还包含对负面情感推文的解释。这些将为我们提供有用的基准，以评估我们在本章中开发的方法。
- en: Before diving into the data, below are some sample tweets, highlighting the
    sentiment classifications, the topics present, and the nature of the tweet content.
    As you can see, the first couple of rows of the dataset contain terms that are
    a result of real-world data entry errors, which will be addressed during the data
    preprocessing stage.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入数据之前，以下是几个样本推文，突出了情感分类、存在的主题以及推文内容的性质。正如您所看到的，数据集的前几行包含由现实世界数据输入错误产生的术语，这些问题将在数据预处理阶段解决。
- en: '![](img/B30999_05_01.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_05_01.png)'
- en: 'Figure 5.1: Sample tweets from the Twitter Airline Sentiment dataset'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1：Twitter航空公司情绪数据集的样本推文
- en: In the subsequent sections, we’ll tackle the data preparation, model building,
    analysis, and visualization stages, employing both conventional NLP techniques
    and a more modern approach using LLMs. Initially, we’ll apply NLP tools for data
    cleaning and structuring, laying the groundwork for traditional sentiment analysis.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将处理数据准备、模型构建、分析和可视化阶段，同时采用传统的NLP技术和使用LLMs的更现代方法。最初，我们将应用NLP工具进行数据清理和结构化，为传统的情绪分析打下基础。
- en: Recognizing the challenges of class imbalance, we’ll demonstrate how GenAI can
    be used as a tool to augment our dataset with additional examples, as necessary.
    We will then use the models we’ve built to derive actionable insights that can
    help guide marketing campaigns.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到类别不平衡的挑战，我们将展示如何使用GenAI作为工具，根据需要通过添加额外的示例来增强我们的数据集。然后，我们将使用我们构建的模型来得出可操作的见解，这些见解可以帮助指导营销活动。
- en: Preparing data for sentiment analysis
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据以进行情绪分析
- en: Before diving into sentiment analysis, it’s crucial to prepare your data effectively.
    Data preparation is a process that involves cleaning, structuring, and enhancing
    data to improve analysis outcomes. The goal of these steps is to ensure that the
    data is in a form that is directly usable for analysis and to remove any inaccuracies
    or irregularities.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行情绪分析之前，有效地准备数据至关重要。数据准备是一个涉及清理、结构和增强数据以改善分析结果的过程。这些步骤的目标是确保数据以可以直接用于分析的形式存在，并消除任何不准确或不规则性。
- en: 'Let’s begin by loading the `Twitter Airline Sentiment` dataset:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从加载`Twitter Airline Sentiment`数据集开始：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Using `df.columns`, we can see a number of columns, such as `text`, which contains
    the tweet itself, along with several valuable metadata and sentiment-related fields.
    The following is a summary of the columns, along with a short description of their
    meaning:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`df.columns`，我们可以看到许多列，例如包含推文本身的`text`列，以及几个有价值的元数据和情绪相关字段。以下是对列的总结，以及它们含义的简要描述：
- en: '| **Column** | **Description** |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| **列** | **描述** |'
- en: '| `tweet_id` | ID of tweet |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `tweet_id` | 推文的ID |'
- en: '| `airline_sentiment` | Class label of tweets (positive, neutral, or negative)
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `airline_sentiment` | 推文的类别标签（正面、中性或负面） |'
- en: '| `airline_sentiment_confidence` | Confidence level in sentiment classification
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `airline_sentiment_confidence` | 情绪分类的置信水平 |'
- en: '| `negative_reason` | Reason for negative sentiment |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `negative_reason` | 负面情绪的原因 |'
- en: '| `airline` | Official name of the airline |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `airline` | 航空公司的官方名称 |'
- en: '| `airline_sentiment_gold` | Gold standard for airline sentiment classification
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| `airline_sentiment_gold` | 航空公司情绪分类的黄金标准 |'
- en: '| `name` | Name of the user |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `name` | 用户的名称 |'
- en: '| `negativereason_gold` | Gold standard for the rationale behind the negative
    reason |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `negativereason_gold` | 负面原因背后的黄金标准 |'
- en: '| `retweet_count` | Numerical value representing the number of retweets |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `retweet_count` | 表示转发次数的数值 |'
- en: '| `text` | Text of the tweet as typed by the user |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `text` | 用户输入的推文文本 |'
- en: '| `tweet_coord` | Latitude and longitude of the Twitter user |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `tweet_coord` | Twitter用户的纬度和经度 |'
- en: '| `tweet_created` | Creation date of the tweet |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `tweet_created` | 推文的创建日期 |'
- en: '| `tweet_location` | Location from which the tweet was sent |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| `tweet_location` | 发送推文的位置 |'
- en: '| `user_timezone` | Timezone of the user |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| `user_timezone` | 用户的时区 |'
- en: 'Table 5.2: Columns and their description for the Twitter Airline Sentiment
    dataset'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.2：Twitter航空公司情绪数据集的列及其描述
- en: Traditional NLP techniques for data preparation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统的NLP数据准备技术
- en: In traditional NLP techniques, careful text preparation—encompassing cleaning,
    tokenization, stop word removal, and lemmatization—is important to structure the
    input text for effective analysis. We’ll discuss these processes in detail in
    this section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的NLP技术中，仔细的文本准备——包括清理、分词、停用词去除和词形还原——对于构建输入文本以进行有效分析非常重要。我们将在本节中详细讨论这些过程。
- en: In contrast, modern techniques such as word embeddings (e.g., Word2Vec and GloVe)
    and contextual embeddings (e.g., BERT and GPT-4) offer more advanced ways to represent
    and process text data. These modern techniques will also be explained in greater
    detail in *Part IV* of the book. Unlike traditional methods that rely on manual
    feature extraction, modern techniques automatically learn dense representations
    of words and context from their pre-training on other texts.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，现代技术如词嵌入（例如Word2Vec和GloVe）和上下文嵌入（例如BERT和GPT-4）提供了更高级的表示和处理文本数据的方法。这些现代技术将在本书的*第IV部分*中更详细地解释。与依赖于手动特征提取的传统方法不同，现代技术会自动从其他文本的预训练中学习单词和上下文的密集表示。
- en: 'For illustration, we will take a sample of five tweet texts and use them as
    examples to see the impact of traditional data preparation steps. We will also
    use the column width setting via `pd.set_option` to show the full column width
    in our DataFrame, thus displaying the full tweet text:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，我们将选取五个推文文本的样本，并使用它们作为示例来观察传统数据准备步骤的影响。我们还将通过`pd.set_option`设置列宽来显示DataFrame的全列宽，从而显示完整的推文文本：
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Cleaning text data
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清洗文本数据
- en: Text cleaning enhances the quality of data analysis by removing noise and making
    the format of text uniform. The primary advantages include improved model accuracy
    and faster computation. However, it’s essential to approach cleaning carefully
    to avoid removing contextually important information. Cleaning is especially useful
    for the Twitter dataset, due to the informal and diverse nature of social media
    text. Tweets often contain URLs, mentions, emojis, and hashtags that can sometimes
    detract from the primary sentiment analysis.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 文本清洗通过去除噪声并使文本格式统一，从而提高了数据分析的质量。其主要优势包括提高模型准确性和加快计算速度。然而，谨慎地处理清洗过程是必要的，以避免删除上下文中重要的信息。对于Twitter数据集来说，由于社交媒体文本的非正式和多样性，清洗特别有用。推文通常包含URL、提及、表情符号和标签，这些有时会分散对主要情感分析的关注。
- en: 'Our approach targets these specifics to preserve the core message while eliminating
    extraneous elements:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法针对这些具体内容，以保留核心信息的同时消除无关元素：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This yields the following output:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下输出：
- en: '![](img/B30999_05_02.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_05_02.png)'
- en: 'Figure 5.2: Examples of tweet text before and after cleaning'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2：清洗前后推文文本的示例
- en: Note that the removal of (`@`) mentions from the text does little to detract
    from the context, as our dataset already has the subject of the tweet captured
    by the `airline` column.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，从文本中移除（`@`）提及对上下文的影响很小，因为我们的数据集已经通过`airline`列捕获了推文的主题。
- en: '**Additional packages for text preprocessing**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**额外的文本预处理包**'
- en: 'Other useful Python tools for NLP and text preprocessing not used in this section
    include:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中没有使用的其他有用的Python NLP和文本预处理工具包括：
- en: '**NLTK** ([https://www.nltk.org/](https://www.nltk.org/))'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NLTK** ([https://www.nltk.org/](https://www.nltk.org/))'
- en: '**TextBlob** ([https://textblob.readthedocs.io](https://textblob.readthedocs.io))'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TextBlob** ([https://textblob.readthedocs.io](https://textblob.readthedocs.io))'
- en: '**Gensim** ([https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/))'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Gensim** ([https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/))'
- en: Tokenization and stop word removal
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分词和停用词移除
- en: Tokenization divides text into smaller units, such as words or phrases, making
    it easier for algorithms to understand language structure. Stop words are commonly
    used words like “is,” “and,” or “the,” and they are often removed because they
    add little semantic value, allowing models to focus on more meaningful content.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 分词将文本划分为更小的单元，如单词或短语，这使得算法更容易理解语言结构。停用词是常用词，如“是”、“和”、“the”，它们通常被移除，因为它们添加的语义价值很小，允许模型关注更有意义的内容。
- en: 'In this implementation, we use spaCy’s model to apply both tokenization and
    stop word removal and show the results of each step of the process:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在此实现中，我们使用spaCy的模型来应用分词和停用词移除，并展示每个步骤的结果：
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This gives us the following output:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下输出：
- en: '![](img/B30999_05_03.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_05_03.png)'
- en: 'Figure 5.3: Examples of tweet texts after tokenization and stop word removal'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3：分词和停用词移除后的推文文本示例
- en: Lemmatization
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词形还原
- en: Lemmatization reduces words to their dictionary form, ensuring the outcome is
    a valid word. This process aims to consolidate different forms of a word to analyze
    them as a single item, enhancing the efficiency and accuracy of the downstream
    task.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 词形还原将单词还原为其词典形式，确保结果是一个有效的单词。这个过程旨在将单词的不同形式合并为单个项目进行分析，从而提高下游任务的效率和准确性。
- en: 'Looking at the last row of the below code, we see that the final lemmatized
    text standardizes `wheels` to its singular form, `wheel`, and converts `thanks`
    to its base verb form, `thank`:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 观察以下代码的最后一行，我们看到最终词元还原后的文本将`wheels`标准化为单数形式`wheel`，并将`thanks`转换为基本动词形式`thank`：
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This gives us the following output:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下输出：
- en: '![](img/B30999_05_04.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_05_04.png)'
- en: 'Figure 5.4: Examples of the tweet text after lemmatization'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4：词元还原后的推文文本示例
- en: Class imbalance
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类别不平衡
- en: We will now introduce why it is important to understand class balance through
    exploratory data analysis on our dataset. Class balance directly impacts a model’s
    ability to learn from data effectively. Unaddressed class imbalances can obscure
    insights and lead to models that do not perform as intended in real-world applications.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将通过在我们数据集上的探索性数据分析来介绍理解类别平衡的重要性。类别平衡直接影响模型从数据中有效学习的能力。未解决的类别不平衡可能会掩盖洞察力，导致模型在实际应用中表现不佳。
- en: In the following sections, we will not only quantify class imbalance but also
    discuss both simple and more advanced strategies to address it.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们不仅将量化类别不平衡，还将讨论解决它的简单和更高级的策略。
- en: Evaluating class balance
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估类别平衡
- en: Identifying the overall sentiment distribution is crucial, as it helps us understand
    the general mood and opinions expressed in a dataset. This understanding is also
    essential for understanding any biases that may be present due to class imbalance.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 确定整体情感分布至关重要，因为它有助于我们了解数据集中表达的一般情绪和观点。这种理解对于理解由于类别不平衡可能存在的任何偏差也是必不可少的。
- en: 'The following code groups tweets by airlines and sentiment, calculates the
    size of each group, and generates a bar plot to visualize the result:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码按航空公司和情感分组推文，计算每个组的大小，并生成条形图来可视化结果：
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This code generates the following graph, illustrating how the airline tweets
    captured in this dataset are primarily negative in sentiment:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码生成了以下图表，展示了该数据集中捕获的航空公司推文的情感主要是负面的：
- en: '![](img/B30999_05_05.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_05_05.png)'
- en: 'Figure 5.5: Distribution of tweets, grouped by airline and sentiment'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B30999_05_05.png)'
- en: 'If we look at the class balance across the dataset, we can see there are 9,178
    negative examples, 3,099 neutral examples, and 2,363 positive tweets. This can
    be shown via:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看数据集中的类别平衡，我们可以看到有9,178个负面示例，3,099个中性示例，以及2,363个正面推文。这可以通过以下方式展示：
- en: '[PRE6]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Datasets with class imbalance are frequently encountered in real-world datasets,
    and therefore, we will retain this characteristic of the data throughout the chapter,
    allowing us to understand the impact that class imbalance can have on modeling
    results.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的数据集中，经常遇到具有类别不平衡的数据集，因此，我们将保留本章中的数据特征，以便我们能够理解类别不平衡对建模结果可能产生的影响。
- en: Addressing class imbalance
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决类别不平衡
- en: 'The following traditional strategies can be employed to address class imbalance:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些可以用来解决类别不平衡的传统策略：
- en: '**Undersampling** reduces the size of the majority class to match the minority
    class. This helps balance the dataset but may result in the loss of valuable majority
    class examples.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欠采样**通过减少多数类的样本大小以匹配少数类来平衡数据集。这有助于平衡数据集，但可能会导致丢失有价值的多数类示例。'
- en: '**Oversampling** increases the size of the minority class to match the majority
    class by duplicating existing examples. This improves balance but can lead to
    model overfitting on the repeated data examples.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过采样**通过复制现有示例来增加少数类的样本大小以匹配多数类。这改善了平衡，但可能导致模型在重复数据示例上过拟合。'
- en: '**Synthetic Minority Over-sampling TEchnique** (**SMOTE**) is similar to oversampling,
    except that it generates synthetic examples instead of simply duplicating existing
    ones. It does this by generating new instances based on examples that are similar
    in feature space.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合成少数过采样技术**（**SMOTE**）与过采样类似，不同之处在于它生成合成示例而不是简单地复制现有的示例。它是通过基于特征空间中相似的示例生成新实例来实现的。'
- en: 'As an exercise, you can undersample the majority class (negative sentiment)
    to achieve a more balanced dataset. This can be achieved with the following code,
    where we first divide our training data into the negative, neutral, and positive
    classes and then downsample the negative class to match the number of examples
    in the minority (positive) class, resulting in a more balanced starting dataset:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一项练习，你可以对多数类（负面情感）进行欠采样，以实现更平衡的数据集。这可以通过以下代码实现，我们首先将我们的训练数据分为负面、中立和正面类别，然后对负面类别进行下采样以匹配少数（正面）类别的示例数量，从而得到一个更平衡的起始数据集：
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Experimenting with undersampling**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**进行欠采样实验**'
- en: As an exercise, run the downsampling code given in the text and substitute `df_downsampled`
    for `df` in the remainder of the chapter to see how your results differ with a
    more balanced dataset.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一项练习，运行文本中给出的下采样代码，并在本章剩余部分将`df_downsampled`替换为`df`，以查看你的结果如何随着更平衡的数据集而变化。
- en: GenAI for data augmentation
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据增强的GenAI
- en: For this section, we will demonstrate a strategy to augment the underrepresented
    positive class by generating new examples, using a seed text via GenAI. This more
    novel approach complements traditional techniques to address class imbalance but
    with greater potential diversity in the new examples. However, using AI-generated
    data can introduce risks, such as overfitting to generated patterns or reflecting
    potential biases from the generative model itself. Ensuring a variety of seed
    texts can help mitigate these issues.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示一种通过使用GenAI的种子文本生成新示例来增强代表性不足的正面类别的策略。这种更新颖的方法补充了传统技术以解决类别不平衡问题，但新示例具有更大的潜在多样性。然而，使用AI生成数据可能会引入风险，例如过度拟合到生成的模式或反映生成模型本身的潜在偏差。确保种子文本的多样性可以帮助减轻这些问题。
- en: 'We will utilize the `distilgpt2` model from Hugging Face’s Transformers library
    to augment our dataset. This model, a simplified version of GPT-2, is tailored
    toward resource efficiency, thus making this example accessible to users with
    varying computational resources:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将利用Hugging Face的Transformers库中的`distilgpt2`模型来增强我们的数据集。这个模型是GPT-2的简化版本，旨在提高资源效率，因此使得这个例子对具有不同计算资源的用户都易于访问：
- en: '[PRE8]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Remember that GenAI’s probabilistic nature means that output may vary with
    each execution. By starting with a carefully chosen seed text of `"``Fantastic
    airline service on this flight. My favorite part of the flight was"` we are able
    to generate varied positive sentiments about airline services. When using this
    seed text in the `text-generation` pipeline above, we generate outputs such as
    the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，GenAI的概率性质意味着输出可能随着每次执行而变化。通过使用精心选择的种子文本“``这次航班的航空公司服务太棒了。我最喜欢的飞行部分是”我们能够生成关于航空公司服务的各种正面情感。当在上述`text-generation`管道中使用此种子文本时，我们生成如下输出：
- en: '**Fantastic airline service on this flight. My favorite part of the flight
    was** *enjoying the fantastic view of all the flight attendants and the runway*.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**这次航班的航空公司服务太棒了。我最喜欢的飞行部分是** *享受所有乘务员和跑道的壮观景色*。'
- en: '**Fantastic airline service on this flight. My favorite part of the flight
    was** *that it was the first time I ever flew in it, and it was worth it*.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**这次航班的航空公司服务太棒了。我最喜欢的飞行部分是** *这是我第一次乘坐它，而且非常值得*。'
- en: By default, most LLMs will produce language that’s reflective of what you’d
    expect to hear in everyday life. For example, try removing the end part of the
    seed statement “`My favorite part of the flight was`" and see how much more difficult
    it is to have the LLM produce examples with positive sentiment.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，大多数LLM将产生反映你期望在日常生活中听到的语言的输出。例如，尝试移除种子语句的结尾部分“`我最喜欢的飞行部分是`"并看看LLM产生具有正面情感的示例有多困难。
- en: '**Importance of GenAI model selection and prompt sensitivity**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**GenAI模型选择和提示敏感性的重要性**'
- en: Exploring more sophisticated models available from Hugging Face, such as `gpt-neo`,
    `gpt-j`, and `EleutherAI/gpt-neo-2.7B`, will yield more impressively nuanced and
    realistic augmentations.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 探索Hugging Face提供的更复杂的模型，如`gpt-neo`、`gpt-j`和`EleutherAI/gpt-neo-2.7B`，将产生更细腻和逼真的增强效果。
- en: The choice of prompt also plays a crucial role in steering the generative model’s
    output. A subtle change in the seed text can lead to dramatically different results,
    underscoring the importance of prompt design in GenAI applications. This topic
    is explored in detail in *Chapter 9* of this book.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 提示的选择在引导生成模型输出中也起着至关重要的作用。种子文本的微妙变化可能导致结果发生巨大变化，这强调了提示设计在 GenAI 应用中的重要性。这个主题在本书的第
    9 章中进行了详细探讨。
- en: 'While this augmentation step enhances the representation of positive sentiment
    tweets within our dataset, achieving true class balance would require more extensive
    data augmentation, as well as a variety of seed texts, to ensure that the model
    does not overfit on the beginning part of the tweet. We can increase the number
    of augmentation examples generated by changing the `augment_times` parameter in
    the above `augment_text()` function:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个增强步骤增强了我们数据集中积极情感推文的代表性，但要实现真正的类别平衡需要更广泛的数据增强以及各种种子文本，以确保模型不会过度拟合推文的开始部分。我们可以通过更改上述
    `augment_text()` 函数中的 `augment_times` 参数来增加生成的增强示例的数量：
- en: '[PRE9]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: By carefully employing GenAI for data augmentation, we now have `df_augmented`
    as a dataframe, with additional data that can be added to our existing dataset
    to mitigate class imbalance and enhance the dataset with varied expressions of
    positive sentiment. However, in order to illustrate the impact of the class imbalance
    in the original dataset on our results, we will refrain from adding these examples
    to our dataset.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仔细使用 GenAI 进行数据增强，我们现在有了 `df_augmented` 数据框，其中包含了可以添加到现有数据集以减轻类别不平衡并增强数据集中积极情感表达的额外数据。然而，为了说明原始数据集中类别不平衡对我们结果的影响，我们将不将这些示例添加到我们的数据集中。
- en: Performing sentiment analysis
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行情感分析
- en: The power of sentiment analysis lies in its ability to uncover the emotions
    behind text data, providing invaluable insights into customer sentiments. While
    the focus of the Twitter Airline Sentiment dataset is on categorizing sentiments
    into positive, negative, and neutral classes, sentiment analysis can also extend
    beyond these basic categories. Depending on the application, sentiments can be
    analyzed to detect more nuanced emotional states or attitudes, such as happiness,
    anger, surprise, or disappointment.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析的力量在于其揭示文本数据背后情感的能力，为顾客情感提供了无价的见解。虽然 Twitter Airline Sentiment 数据集的焦点是将情感分类为积极、消极和中性类别，但情感分析也可以超出这些基本类别。根据应用的不同，情感可以分析以检测更细微的情感状态或态度，如快乐、愤怒、惊讶或失望。
- en: Building your own ML model
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建自己的 ML 模型
- en: A fundamental aspect of training sentiment analysis models, especially with
    traditional NLP techniques, is the necessity for pre-labeled data. These labels
    are typically derived from human annotations, a process that involves individuals
    assessing the sentiment of a piece of text and categorizing it accordingly. The
    sentiment scores in this Twitter dataset were collected with the help of volunteers,
    and some of the negative tweets were also broken down based on specific issues
    they highlighted, such as flight delays or poor service, providing a more nuanced
    view of customer dissatisfaction.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 sentiment analysis 模型的基本方面，尤其是在使用传统 NLP 技术时，是预标注数据的需求。这些标签通常来源于人工标注，这个过程涉及个人评估文本的情感并根据其进行分类。这个
    Twitter 数据集中的情感分数是在志愿者的帮助下收集的，其中一些负面推文也根据它们所强调的具体问题进行了分解，例如航班延误或服务质量差，从而提供了对客户不满的更细致的视角。
- en: Using `scikit-learn`, we will construct sentiment analysis models that leverage
    this pre-labeled dataset. These models will utilize the text preprocessing demonstrated
    in the previous section to extract TF-IDF features from the text, which, in turn,
    serve as inputs for machine learning inferences that can predict the sentiment
    of unseen tweets.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `scikit-learn`，我们将构建利用此预标注数据集的 sentiment analysis 模型。这些模型将利用前一小节中展示的文本预处理方法从文本中提取
    TF-IDF 特征，这些特征反过来又作为机器学习推理的输入，可以预测未见过的推文的情感。
- en: Feature engineering
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征工程
- en: 'Before training a model, we need to convert the text data into numerical features.
    One common approach is to use the **TF-IDF** (**Term Frequency-Inverse Document
    Frequency**) technique. TF-IDF is a statistical measure used to evaluate the importance
    of a word to a document in a collection or corpus. We will utilize the text preprocessing
    steps we performed earlier and apply the `tfidf` vectorizer directly to the processed
    text, limiting the features to the top 1,000 terms `(max_features=1000)`. This
    step is important because reducing dimensionality helps to simplify the model,
    making it faster to train and reducing the risk of overfitting. By focusing on
    the most relevant words, we ensure that the model captures the most significant
    patterns in the data while ignoring less important details:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型之前，我们需要将文本数据转换为数值特征。一种常见的方法是使用**TF-IDF**（**词频-逆文档频率**）技术。TF-IDF是一种用于评估一个词在集合或语料库中对于文档重要性的统计度量。我们将利用之前执行的文本预处理步骤，并将`tfidf`向量器直接应用于处理后的文本，将特征限制在顶级1,000个术语（`max_features=1000`）。这一步很重要，因为降低维度有助于简化模型，使其训练更快，并减少过拟合的风险。通过关注最相关的词语，我们确保模型捕捉到数据中最显著的模式，同时忽略不那么重要的细节：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Exploring feature engineering with TF-IDF**'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索TF-IDF的特征工程**'
- en: Another parameter to explore on your own during TF-IDF feature engineering is
    `ngram_range`.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在TF-IDF特征工程期间，你可以探索的另一个参数是`ngram_range`。
- en: N-grams allow you to go beyond individual words and consider pairs (bigrams)
    or triples (trigrams) of consecutive words as single features. This can capture
    more context and the relationship between words – for example, while “not” and
    “good” individually might not be very informative, the bigram “not good” carries
    a clear sentiment.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: N-gram允许你超越单个单词，将连续单词的成对（bigram）或三元组（trigram）视为单个特征。这可以捕捉到更多的上下文和词语之间的关系——例如，虽然“not”和“good”单独可能并不很有信息量，但bigram“not
    good”却传达了明确的情感。
- en: Model training
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'With our features ready, we can proceed to train a simple model using scikit-learn.
    Logistic regression is a simple yet powerful algorithm that works well with the
    dimensionality of the data contained in these short tweets. It models the probabilities
    for classification problems with two possible outcomes, but it can be extended
    to handle multiple classes, which is applicable in our case:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的特性准备就绪后，我们可以继续使用scikit-learn训练一个简单的模型。逻辑回归是一种简单而强大的算法，适用于包含在这些简短推文中的数据的维度。它为具有两种可能结果的分类问题建模概率，但它可以扩展以处理多个类别，这在我们的案例中适用：
- en: '[PRE11]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: With our logistic regression model trained, we can now interpret the model’s
    coefficients to obtain insight into how specific words influence sentiment classification.
    For each sentiment category, the coefficients represent the influence of these
    terms on the likelihood of a text being classified within that particular sentiment,
    and the magnitude represents the importance of each term in the model’s decision-making
    process.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的逻辑回归模型训练完成后，现在我们可以解释模型的系数，以了解特定词语如何影响情感分类。对于每个情感类别，系数代表这些术语对文本被分类为该特定情感类别的可能性的影响，而其幅度代表每个术语在模型决策过程中的重要性。
- en: 'To accomplish this, we iterate over each class label to extract and display
    the most influential features, sorted by the absolute value of their coefficients:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们遍历每个类别标签，提取并显示系数绝对值排序的最具影响力的特征：
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This yields the following output:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下输出：
- en: '![](img/B30999_05_06.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_05_06.png)'
- en: 'Figure 5.6: Most influential features by sentiment class for the logistic regression
    model'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6：逻辑回归模型按情感类别排序的最具影响力的特征
- en: 'We can see from the above coefficients the influence of the following words
    on the three sentiment classes:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从上述系数中看到以下词语对三个情感类别的影响：
- en: '**Negative sentiment**: The word `thank` `(-3.88`) decreases the likelihood
    of a tweet being classified as negative, whereas words like `hour` (`3.61`), `bad`
    (`2.96`), `delay` (`2.84`), and `cancel` (`2.63`) increase this likelihood and
    are characteristic of complaints.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负面情感**：单词`thank`（-3.88）降低了推文被分类为负面的可能性，而像`hour`（3.61）、`bad`（2.96）、`delay`（2.84）和`cancel`（2.63）这样的词语则增加了这种可能性，并且是投诉的特征。'
- en: '**Neutral sentiment**: Words such as `customer` (`-2.24`), `experience` (`-1.91`),
    and `fix` (`-1.88`) decrease the likelihood of neutral classification, indicating
    that these terms are more often used in non-neutral contexts.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中性情感**：例如，“customer”（`-2.24`）、“experience”（`-1.91`）和“fix”（`-1.88`）等词语会降低中性分类的可能性，表明这些术语更常用于非中性语境中。'
- en: '**Positive sentiment**: Terms like `thank` (`4.36`), `great` (`3.54`), `awesome`
    (`3.18`), and `amazing` (`3.07`) significantly increase the likelihood of a tweet
    being classified as positive.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正面情感**：例如，“thank”（`4.36`）、“great”（`3.54`）、“awesome”（`3.18`）和“amazing”（`3.07`）等词语会显著增加推文被分类为正面的可能性。'
- en: Model evaluation
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型评估
- en: Evaluating our model’s performance is a critical step after training. Without
    proper evaluation, we risk deploying a model that may perform poorly in real-world
    scenarios, potentially leading to incorrect conclusions based on its predictions.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型后的关键一步是评估我们的模型性能。如果没有适当的评估，我们可能会部署一个在实际场景中表现不佳的模型，这可能导致基于其预测的错误结论。
- en: Classification report
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类报告
- en: 'The classification report from scikit-learn gives us the precision, recall,
    and F1 score for each class. These metrics are crucial, as they tell us not just
    about the overall accuracy but also how well the model performs for each sentiment
    class:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn的分类报告为我们提供了每个类别的精确度、召回率和F1分数。这些指标至关重要，因为它们不仅告诉我们整体准确度，还告诉我们模型在每个情感类别上的表现：
- en: '[PRE13]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](img/B30999_05_07.png)Figure 5.7: Classification report metrics evaluating
    logistic regression model performance'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.7：评估逻辑回归模型性能的分类报告指标](img/B30999_05_07.png)'
- en: The macro average and weighted average scores give us an understanding of the
    model’s performance across all classes. The macro average treats all classes equally,
    while the weighted average takes the class imbalance into account. The differences
    between these scores highlight the impact of the class imbalance on the model’s
    performance.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 宏平均和加权平均分数让我们了解模型在所有类别上的性能。宏平均对待所有类别同等，而加权平均则考虑了类别不平衡。这些分数之间的差异突出了类别不平衡对模型性能的影响。
- en: 'Let’s look more closely at the results for each class:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看每个类别的结果：
- en: The negative sentiment, as the majority class, has high precision (`0.82`) and
    recall (`0.92`), indicating that the model is particularly good at identifying
    negative tweets. This is an expected side effect of our class imbalance, since
    the model has more examples of this class to learn from, leading to a higher likelihood
    of predicting this class correctly.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负面情感，作为多数类，具有高精确度（`0.82`）和高召回率（`0.92`），表明模型在识别负面推文方面特别出色。这是由于我们的类别不平衡的预期副作用，因为模型有更多这个类别的例子来学习，导致预测这个类别正确的可能性更高。
- en: The neutral sentiment, being less represented than the negative but more than
    the positive, shows a significantly lower precision (`0.61`) and recall (`0.49`).
    The precision is reasonably good, meaning that when the model predicts a tweet
    as neutral, it’s correct a little over half the time.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中性情感，比负面情感少，但比正面情感多，显示出显著较低的精确度（`0.61`）和召回率（`0.49`）。精确度相当好，这意味着当模型预测一条推文为中性时，正确率略超过一半。
- en: The positive sentiment, the least represented class, has a relatively high precision
    (`0.79`) but lower recall (`0.61`) than the negative class. High precision here
    indicates that most tweets predicted as positive are indeed positive, but the
    model fails to catch many positive sentiments (low recall).
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正面情感，最少代表的类别，具有相对较高的精确度（`0.79`），但比负面类别的召回率（`0.61`）低。这里的精确度较高表明，大多数被预测为正面的推文确实是正面的，但模型未能捕捉到许多正面情感（召回率低）。
- en: Confusion matrix
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'A confusion matrix is an excellent next step to further understanding a model’s
    performance. It shows a matrix with the actual classes on one axis and the predicted
    classes on the other. By analyzing the confusion matrix, we can see which classes
    are being confused with one another. For example, if many neutral tweets are misclassified
    as negative, this might suggest that the model is biased toward predicting negative
    and that the features for neutral tweets are not distinctive enough. We can calculate
    and visualize the confusion matrix using the following:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵是进一步了解模型性能的一个很好的下一步。它显示了一个矩阵，其中实际类别在一轴上，预测类别在另一轴上。通过分析混淆矩阵，我们可以看到哪些类别被相互混淆。例如，如果许多中性推文被错误地分类为负面，这可能会表明模型倾向于预测负面，并且中性推文的特征不够独特。我们可以使用以下方法计算和可视化混淆矩阵：
- en: '[PRE14]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can then see the following confusion matrix:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以接着看到以下混淆矩阵：
- en: '![](img/B30999_05_08.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_05_08.png)'
- en: 'Figure 5.8: Confusion matrix of tweet sentiment classes for the logistic regression
    model'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8：逻辑回归模型的推文情感类别混淆矩阵
- en: 'Let’s break this down to understand it better:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将其分解以更好地理解：
- en: Consistent with our observations from the classification report, the model shows
    strong performance in correctly identifying negative tweets, as captured by the
    first row in the confusion matrix.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与我们从分类报告中观察到的结果一致，模型在正确识别负面推文方面表现出色，这在混淆矩阵的第一行中有所体现。
- en: When it comes to neutral sentiments, the second row indicates a tendency of
    the model to confuse neutral tweets with negative ones.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当涉及到中性情感时，第二行表明模型倾向于将中性推文与负面推文混淆。
- en: Lastly, the third row corresponds to positive sentiments. While the model correctly
    identifies positive tweets more than half the time, there is still a considerable
    portion that is confused with negative or neutral sentiments.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，第三行对应于积极情感。虽然模型正确识别积极推文的时间超过一半，但仍有一大部分被误认为是负面或中性情感。
- en: Understanding misclassifications
  id: totrans-170
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 理解误分类
- en: After assessing our model with various metrics, we can investigate examples
    when the model fails, giving insight into its limitations and opportunities for
    improvement.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在用各种指标评估我们的模型后，我们可以调查模型失败时的示例，从而了解其局限性和改进的机会。
- en: 'Let’s look at the instances where the model’s predictions clash with the trusted
    classifications provided by `airline_sentiment_gold` data labels:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看模型预测与`airline_sentiment_gold`数据标签提供的可信分类发生冲突的实例：
- en: '[PRE15]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We get the following output:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/B30999_05_09.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_05_09.png)'
- en: 'Figure 5.9: Example tweets where the dataset labels disagree with model predictions
    from the logistic regression model'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9：数据集标签与逻辑回归模型预测不一致的示例推文
- en: An analysis of the misclassified examples demonstrates where our model’s `predicted_sentiment`
    falls short of accurately capturing the context of the full tweet. For instance,
    the second misclassification example of a tweet expressing disappointment over
    a canceled flight, cloaked in a humorous tone, highlights the inherent challenge
    in detecting sarcasm and underscores the importance of model training that encompasses
    a wider spectrum of sentiment expressions. Then, for the last example, we have
    an encouraging tweet, acknowledging the opportunity for improvement from negative
    experiences, which is predicted to be negative. This illustrates the difficulty
    of TF-IDF features in a model to interpret nuanced positive sentiments, especially
    when intertwined with negative words. These mischaracterizations could benefit
    from more advanced NLP models that are capable of better discerning context and
    nuance, a topic we will explore in the next section on pre-trained LLMs.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 对误分类示例的分析表明，我们的模型的`predicted_sentiment`在准确捕捉完整推文语境方面存在不足。例如，一个表达对取消航班失望的推文的第二个误分类示例，以幽默的语气包装，突显了检测讽刺的内在挑战，并强调了模型训练涵盖更广泛情感表达的重要性。然后，对于最后一个例子，我们有一个令人鼓舞的推文，承认从负面经历中看到改进的机会，但预测为负面。这说明了TF-IDF特征在模型中解释细微积极情感时的困难，尤其是在与负面词汇交织在一起时。这些误分类可以从更先进的NLP模型中受益，这些模型能够更好地辨别语境和细微差别，这是我们将在下一节关于预训练LLMs的讨论中探讨的主题。
- en: '**Enhancing the performance of traditional sentiment models**'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**提高传统情感模型性能**'
- en: '**Address training data gaps**: Ensure that your dataset includes a wide range
    of sentiment expressions such as sarcasm, humor, and conditional positivity. A
    model’s ability to accurately interpret sentiments is directly tied to the diversity
    of examples it has learned from. Sampling techniques, such as stratified sampling,
    can be used to ensure that all sentiment types are adequately represented in the
    training set.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解决训练数据差距**：确保您的数据集包括广泛的情感表达，如讽刺、幽默和条件积极。模型准确解释情感的能力直接与其从中学到的例子多样性相关。可以使用分层抽样等采样技术来确保所有情感类型在训练集中得到充分代表。'
- en: '**Understand feature representation limitations**: Traditional feature representation
    methods like TF-IDF may not fully capture complex sentiment nuances, especially
    where overall sentiment is not the sum of its parts.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理解特征表示的限制**：传统的特征表示方法，如TF-IDF，可能无法完全捕捉复杂的情感细微差别，尤其是在整体情感不是其各部分之和的情况下。'
- en: '**Enhance models with contextual features**: Enrich feature sets by incorporating
    contextual cues like n-grams or part-of-speech tagging. These additions help capture
    sentiment nuances by considering word order and grammatical structure.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强模型中的上下文特征**：通过结合上下文线索如n-gram或词性标注来丰富特征集。这些添加有助于通过考虑词序和语法结构来捕捉情感细微差别。'
- en: '**Explore more robust ML algorithms**: Beyond simpler methods such as logistic
    regression and naive Bayes, ensemble methods like random forests and boosting
    algorithms (XGBoost) capture complex patterns better. Additionally, hyperparameter
    tuning on logistic regression (e.g., adjusting regularization strength) can significantly
    improve performance. Deep learning methods such as CNNs and RNNs often provide
    the best performance, provided there are enough training examples present.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**探索更稳健的机器学习算法**：除了像逻辑回归和朴素贝叶斯这样的简单方法之外，集成方法如随机森林和提升算法（XGBoost）能更好地捕捉复杂模式。此外，对逻辑回归进行超参数调整（例如，调整正则化强度）可以显著提高性能。深度学习方法如CNN和RNN通常提供最佳性能，前提是有足够的训练示例。'
- en: Having explored various techniques to enhance traditional sentiment models,
    including addressing data gaps, feature representation, and appropriate algorithms,
    we now turn our attention to a more modern advancement in sentiment analysis,
    using pre-trained LLMs.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索了各种增强传统情感模型的技术，包括解决数据差距、特征表示和适当的算法之后，我们现在将注意力转向情感分析领域的一项更现代的进步，即使用预训练的LLM。
- en: Using pre-trained LLMs
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用预训练的LLM
- en: Before applying pre-trained LLMs for sentiment analysis, it is important to
    understand the concept of embeddings, which serve as the foundation for these
    advanced models. At their core, embeddings are dense vector representations of
    data, which could be anything, from words and entire documents to even images
    and relational data. These vectors are designed to capture the key features of
    data in a high-dimensional space.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用预训练的LLM进行情感分析之前，理解嵌入的概念非常重要，这些嵌入是这些高级模型的基础。本质上，嵌入是数据的密集向量表示，可以是任何东西，从单词和整个文档到图像和关系数据。这些向量被设计用来在多维空间中捕捉数据的关键特征。
- en: Early examples of NLP embeddings include Word2Vec and GloVe, which generate
    **static embeddings**. In Word2Vec, the embeddings are influenced by local context
    through techniques like skip-grams and **continuous bag of words** (**CBOW**),
    but once trained, the same word has the same vector representation regardless
    of the broader context. However, state-of-the-art LLMs like BERT and GPT introduced
    true **contextual embeddings**, where the representation of a word dynamically
    changes based on its contextual usage. The key attribute of an effective NLP embedding
    is that it preserves the original data’s semantic relationships in its vector
    space, meaning that similar vectors (words, phrases, or documents) are closer
    together than less similar data.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理嵌入的早期例子包括Word2Vec和GloVe，它们生成**静态嵌入**。在Word2Vec中，嵌入受到局部上下文的影响，通过跳字模型和**连续词袋模型**（CBOW）等技术，但一旦训练完成，相同的词无论在更广泛的上下文中都有相同的向量表示。然而，像BERT和GPT这样的最先进LLM引入了真正的**上下文嵌入**，其中词的表示根据其上下文使用动态变化。有效的NLP嵌入的关键属性是它在向量空间中保留了原始数据的语义关系，这意味着相似的向量（单词、短语或文档）比不相似的数据更接近。
- en: Incorporating LLMs for sentiment analysis marks a significant advancement in
    the field of NLP, streamlining the process of understanding complex textual data.
    These models excel in capturing the subtleties of human language through extensive
    pre-training on diverse datasets, thus bypassing the need for elaborate text preprocessing,
    hyperparameter tuning – or even the need for pre-labeled data. For marketing professionals,
    this translates into a more efficient way to gauge customer sentiment across different
    platforms.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 将LLM应用于情感分析标志着自然语言处理领域的一项重大进步，简化了理解复杂文本数据的过程。这些模型通过在多样化的数据集上进行广泛的预训练，在捕捉人类语言的细微差别方面表现出色，从而绕过了复杂的文本预处理、超参数调整——甚至预标注数据的需要。对于市场营销专业人士来说，这意味着更有效地衡量不同平台上的客户情绪。
- en: Implementing pre-trained models
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实施预训练模型
- en: To demonstrate the efficacy of a pre-trained LLM, the `sentiment-analysis` pipeline
    from the `distilbert-base-uncased-finetuned-sst-2-english` model in the Transformers
    library will be used. DistilBERT is a smaller, faster version of BERT that retains
    95% of its contextual embedding performance. This particular variant has been
    fine-tuned on the **Stanford Sentiment Treebank** (**SST-2**) dataset, a standard
    benchmark for sentiment analysis, consisting of movie reviews with human-annotated
    `positive` or `negative` sentiments.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示预训练 LLM 的有效性，我们将使用 Transformers 库中 `distilbert-base-uncased-finetuned-sst-2-english`
    模型的 `sentiment-analysis` 管道。DistilBERT 是 BERT 的一个更小、更快的版本，保留了 95% 的上下文嵌入性能。这个特定的变体在**斯坦福情感树库**（**SST-2**）数据集上进行了微调，这是一个情感分析的标准基准，包含带有人类标注的`正面`或`负面`情感的电影评论。
- en: 'Given its binary classification nature, `neutral` sentiments are excluded from
    our test set to align the model’s available predictions between `positive` and
    `negative`. For this example, we will also incorporate the `time` and `tqdm` modules
    into our code to track the execution time. After the model loads, inference on
    all of the test texts may take a few minutes to complete using the `sentiment-analysis`
    pipeline:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其二元分类性质，`中性`情感被排除在我们的测试集之外，以使模型在`正面`和`负面`之间的可用预测保持一致。在这个例子中，我们还将`time`和`tqdm`模块纳入我们的代码中，以跟踪执行时间。在模型加载后，使用`sentiment-analysis`管道对所有测试文本进行推理可能需要几分钟才能完成：
- en: '[PRE16]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Utilizing the ``sentiment-analysis`` pipeline for DistilBERT simplifies the
    sentiment analysis process by encapsulating several complex steps into one efficient
    process. Without this, the tokenization, text embeddings, inference, and post-processing
    would all need to be handled separately.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DistilBERT 的 `sentiment-analysis` 管道简化了情感分析过程，因为它将几个复杂的步骤封装成一个高效的过程。如果没有这个，标记化、文本嵌入、推理和后处理都需要单独处理。
- en: Evaluating model performance
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估模型性能
- en: 'The classification report from the LLM inference can be obtained using the
    following code:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下代码从 LLM 推理中获取分类报告：
- en: '[PRE17]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This yields the following results:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下结果：
- en: '![](img/B30999_05_10.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_05_10.png)'
- en: 'Figure 5.10: Classification report metrics evaluating LLM performance'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10：评估 LLM 性能的分类报告指标
- en: 'Next, let’s generate the confusion matrix:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们生成混淆矩阵：
- en: '[PRE18]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This gives us the following output:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下输出：
- en: '![](img/B30999_05_11.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_05_11.png)'
- en: 'Figure 5.11: Confusion matrix of tweet sentiment classes for the LLM'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11：LLM 对推文情感类别的混淆矩阵
- en: When comparing the performances of the previous logistic regression model utilizing
    TF-IDF features and our pre-trained LLM, several observations emerge. The logistic
    regression model, while providing a strong baseline for sentiment analysis, has
    limitations in handling the nuances of natural language. While class imbalance
    likely played some role in the model’s performance issues, it is important to
    note that the LLM’s capabilities to understand language nuances, derived from
    its extensive pre-training and fine-tuning, likely played a larger role in its
    superior performance. Additionally, the logistic regression model only used unigrams
    for TF-IDF, which fails to capture context and contributes to mischaracterizations.
    For these reasons, it particularly struggles at classifying positive (and neutral)
    sentiments amid a dominant negative sentiment class.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当比较使用 TF-IDF 特征的前一个逻辑回归模型和我们的预训练 LLM 的性能时，出现了一些观察结果。虽然逻辑回归模型为情感分析提供了一个强大的基线，但在处理自然语言的细微差别方面存在局限性。虽然类别不平衡可能在模型性能问题中起到了一定作用，但重要的是要注意，LLM
    理解语言细微差别的能力，源于其广泛的预训练和微调，可能在其优越性能中发挥了更大的作用。此外，逻辑回归模型仅使用了 TF-IDF 的单词，这未能捕捉到上下文，并导致了错误的描述。因此，它在分类主导的负面情感类别中的正面（和中性）情感分类上尤其困难。
- en: The LLM – keeping in mind we excluded the neutral class from its classification
    task to stay consistent with the nature of its fine-tuning procedure – demonstrates
    a more robust performance.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（考虑到我们排除了中性类别以保持与微调过程性质的一致性）表现出更稳健的性能。
- en: This is showcased by its heightened accuracy in distinguishing between positive
    and negative sentiments. It is important to note that the logistic regression
    model started with imbalanced data to illustrate its impact on results, whereas
    the LLM did not undergo any task-specific training on the Twitter data and was
    trained only on the SST-2 movie reviews. The key takeaway here is that the LLM’s
    knowledge is generalized effectively, from movie reviews to Twitter data, highlighting
    its robust language understanding capabilities. With a precision of `0.96` for
    negative sentiments and a recall rate of `0.90`, the model underscores the potential
    of leveraging pre-trained neural networks for sentiment analysis. The improvement
    in positive sentiment detection, achieving a precision of `0.68` and a recall
    of `0.84`, further emphasizes the model’s predictive power.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过其在区分积极和消极情感方面的提高准确性得到展示。需要注意的是，逻辑回归模型从不平衡数据开始，以说明其对结果的影响，而LLM没有在Twitter数据上进行任何特定任务的训练，而是在SST-2电影评论上进行了训练。关键要点是LLM的知识被有效地推广，从电影评论到Twitter数据，突显了其强大的语言理解能力。对于消极情感的精确度为`0.96`，召回率为`0.90`，该模型强调了利用预训练神经网络进行情感分析的可能性。在积极情感检测方面的改进，精确度达到`0.68`，召回率为`0.84`，进一步强调了模型的预测能力。
- en: One drawback of using advanced machine-learning models like LLMs is their lack
    of explainability. Understanding what exactly creates negative sentiment can be
    challenging with these black-box models. Techniques such as **LIME** (**local
    interpretable model-agnostic explanations**) can be used to improve explainability.
    For a more detailed discussion on model transparency and techniques to elucidate
    LLM decisions, please refer to *Chapter 13*.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像LLM（大型语言模型）这样的高级机器学习模型的一个缺点是它们缺乏可解释性。理解这些黑盒模型中确切是什么创造了负面情绪可能具有挑战性。可以使用如**LIME（局部可解释模型无关解释）**等技术来提高可解释性。有关模型透明度和阐明LLM决策的技术更详细讨论，请参阅*第13章*。
- en: While the LLM performance is noteworthy, fine-tuning the LLM on the specific
    sentiment labels present in our airline tweets dataset would further improve its
    performance. Fine-tuning adapts a model more closely to a task’s unique context,
    allowing the model to leverage and understand the nuances of the classification
    task.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然LLM的表现值得注意，但将LLM微调到我们航空公司推文数据集中存在的特定情感标签将进一步提高其性能。微调使模型更紧密地适应任务的独特上下文，使模型能够利用并理解分类任务的细微差别。
- en: In addition to fine-tuning, transfer learning and few-shot learning are powerful
    methodologies that further refine a model’s ability to classify sentiments with
    high accuracy. Transfer learning involves adapting a pre-trained model on a related
    task to perform well on the target task, even with minimal additional training
    data. Conversely, few-shot learning trains the model to make accurate predictions
    with only a few examples of the target task available.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 除了微调之外，迁移学习和少样本学习是进一步细化模型在情感分类上高精度分类能力的强大方法。迁移学习涉及将预训练模型在相关任务上调整以在目标任务上表现良好，即使只有最少量的额外训练数据。相反，少样本学习训练模型仅使用少量目标任务的示例来做出准确预测。
- en: '**Improving LLMs: transfer and few-shot learning**'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**改进LLM：迁移和少样本学习**'
- en: In *Part 4* of this book, we will explore these cutting-edge methodologies in
    more depth. We will explore how fine-tuning, transfer learning, and few-shot learning
    can be applied to pre-trained models, transforming them into highly specialized
    tools for domain-specific tasks like sentiment classification.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的*第四部分*中，我们将更深入地探讨这些尖端方法。我们将探讨如何将微调、迁移学习和少样本学习应用于预训练模型，将它们转化为针对特定领域任务（如情感分类）的高度专业化的工具。
- en: When we arrive at Part 4 of this book, we will delve deeper into related methodologies
    at the cutting edge of adapting pre-trained models for domain-specific tasks.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们到达本书的第四部分时，我们将更深入地探讨适应预训练模型以用于特定领域任务的尖端方法。
- en: Translating sentiment into actionable insights
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将情感转化为可操作的见解
- en: So far in this chapter, we have explored the tools and strategies needed to
    understand and apply sentiment analysis to your data, from the foundational techniques
    of data preparation and prediction using traditional NLP methods to the advanced
    capabilities of GenAI. In this final part of the chapter, we will discuss how
    these insights can be analyzed to generate actionable strategies that can guide
    a brand to success across all stages of a marketing campaign.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中，我们已经探讨了理解和应用情感分析到您的数据中所需的工具和策略，从使用传统NLP方法的数据准备和预测的基础技术到GenAI的高级功能。在本章的最后一部分，我们将讨论如何分析这些见解以生成可操作的战略，这些战略可以指导品牌在营销活动的各个阶段取得成功。
- en: Creating your own dataset
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建您的数据集
- en: Before applying this analysis to your use case, we need an approach to collecting
    the data that captures the underlying customer sentiment related to your brand.
    While this chapter utilizes the Twitter Airline dataset as an example, the techniques
    we’ve explored are applicable regardless of the industry or data source. This
    section will present the general steps you can take to curate your own proprietary
    dataset for analysis, whether it be from Twitter or another major data platform.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在将此分析应用于您的用例之前，我们需要一种收集数据的方法，该方法能够捕捉与您的品牌相关的潜在客户情绪。虽然本章以Twitter航空数据集为例，但我们探讨的技术适用于任何行业或数据源。本节将介绍您可以采取的一般步骤，以创建用于分析的专有数据集，无论这些数据来自Twitter还是其他主要数据平台。
- en: '**Ethics and governance in AI-enabled marketing**'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能赋能营销中的伦理和治理**'
- en: Ethics and governance in AI-enabled marketing is the topic of *Chapter 13*,
    and it is crucial to adhere to ethical guidelines and governance frameworks that
    respect consumer privacy and data protection laws when collecting data. Ethical
    practices in marketing include obtaining consent for data collection, ensuring
    data anonymization to protect individual identities, and providing clear opt-out
    mechanisms. Companies should establish robust data governance policies that define
    data handling procedures and compliance with legal standards such as the EU’s
    **General Data Protection Regulation** (**GDPR**) or the **California Consumer
    Privacy Act** (**CCPA**).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能赋能的营销中的伦理和治理是第13章的主题，在收集数据时遵守尊重消费者隐私和数据保护法律的伦理准则和治理框架至关重要。营销中的伦理实践包括为数据收集获得同意，确保数据匿名化以保护个人身份，以及提供明确的退出机制。公司应建立强大的数据治理政策，定义数据处理程序和遵守如欧盟的**通用数据保护条例**（**GDPR**）或**加利福尼亚消费者隐私法案**（**CCPA**）等法律标准。
- en: Collecting twitter data
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 收集Twitter数据
- en: 'To start, ensure you have a Twitter Developer account and access to the Twitter
    (now rebranded as X) API. You can follow these steps:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请确保您拥有Twitter开发者账户并可以访问Twitter（现在更名为X）API。您可以遵循以下步骤：
- en: 'You’ll first need to create a project and obtain your API keys and tokens,
    and then, using the credentials from your Twitter Developer account ([https://developer.twitter.com/en/portal/petition/essential/basic-info](https://developer.twitter.com/en/portal/petition/essential/basic-info)),
    authenticate your session to access the Twitter API. The following are general
    instructions to do this:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您首先需要创建一个项目并获取您的API密钥和令牌，然后，使用您的Twitter开发者账户的凭证（[https://developer.twitter.com/en/portal/petition/essential/basic-info](https://developer.twitter.com/en/portal/petition/essential/basic-info)），验证您的会话以访问Twitter
    API。以下是一般步骤：
- en: '[PRE19]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now that we have access to the Twitter API, you can use the Twitter handle
    or relevant hashtags associated with your brand and combine this with the `search_tweets`
    method to find relevant tweets. This example collects the latest 100 tweets mentioning
    `"@YourBrandHandle"`:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经可以访问Twitter API，您可以使用与您的品牌相关的Twitter账号或相关标签，并结合`search_tweets`方法来查找相关推文。以下示例收集了提及`"@YourBrandHandle"`的最新100条推文：
- en: '[PRE20]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Due to recent changes, the Twitter (X) API may have limited access, and certain
    endpoints may require elevated access levels. If you encounter a `403` `Forbidden`
    error, you may need to upgrade your access level or use alternative endpoints
    available in the API documentation. More details can be found on the Twitter developer
    portal ([https://developer.twitter.com/en/portal/petition/essential/basic-info](https://developer.twitter.com/en/portal/petition/essential/basic-info)).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最近的变化，Twitter（X）API可能访问受限，某些端点可能需要提高访问级别。如果您遇到`403` `Forbidden`错误，您可能需要升级访问级别或使用API文档中提供的替代端点。更多详情可以在Twitter开发者门户（[https://developer.twitter.com/en/portal/petition/essential/basic-info](https://developer.twitter.com/en/portal/petition/essential/basic-info)）找到。
- en: 'With the tweets collected, we can extract relevant information such as the
    tweet ID, text, creation time, and location. We can then structure this data into
    a `pandas` DataFrame for easier analysis:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集推文后，我们可以提取相关信息，例如推文ID、文本、创建时间和位置。然后我们可以将这些数据结构化为`pandas` DataFrame，以便更容易分析：
- en: '[PRE21]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: There are many further metadata fields available in the API response documentation
    that are worth considering, including retweet count `(tweet.retweet_count)`, hashtags
    `(tweet.entities['hashtags'])`, and mentions `(tweet.entities['user_mentions'])`.
    As discussed in the sections below, these fields can provide valuable insight
    into topics that are pivotal for understanding your brand’s sentiment narrative,
    including salient topics, tweet engagement, and virality.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: API响应文档中还有许多其他值得考虑的元数据字段，包括转发计数（`tweet.retweet_count`）、标签（`tweet.entities['hashtags']`）和提及（`tweet.entities['user_mentions']`）。如以下章节所述，这些字段可以为理解您的品牌情感叙事提供有价值的见解，包括显著话题、推文参与度和病毒性。
- en: Collecting data from other platforms
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从其他平台收集数据
- en: Analyzing brand sentiment extends beyond Twitter, encompassing a variety of
    social media platforms including Facebook, Instagram, Google reviews, and more.
    Each platform presents unique challenges and opportunities to gather and analyze
    data. The approach to collecting data differs, based on each platform’s API capabilities
    and data availability. For platforms like Google reviews, APIs may allow you to
    directly access reviews and ratings. On platforms like Facebook and Instagram,
    you might rely on posts, comments, and hashtags to gauge sentiment.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 分析品牌情感不仅限于Twitter，还包括Facebook、Instagram、Google评论等多种社交媒体平台。每个平台都面临着独特的挑战和机会，以收集和分析数据。收集数据的方法根据每个平台的API功能和数据可用性而有所不同。对于Google评论等平台，API可能允许您直接访问评论和评分。在Facebook和Instagram等平台上，您可能需要依赖帖子、评论和标签来衡量情感。
- en: '**Accessing developer APIs**'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '**访问开发者API**'
- en: 'To collect data from different social media platforms, you need to access their
    respective developer APIs. Here are some useful links to get you started:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 要从不同的社交媒体平台收集数据，您需要访问它们各自的开发者API。以下是一些有用的链接，以帮助您开始：
- en: '**Facebook**: [https://developers.facebook.com/docs/graph-api](https://developers.facebook.com/docs/graph-api
    )'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Facebook**：[https://developers.facebook.com/docs/graph-api](https://developers.facebook.com/docs/graph-api)'
- en: '**Instagram**: [https://developers.facebook.com/docs/instagram-api](https://developers.facebook.com/docs/instagram-api
    )'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Instagram**：[https://developers.facebook.com/docs/instagram-api](https://developers.facebook.com/docs/instagram-api)'
- en: '**Reddit**: [https://www.reddit.com/dev/api/](https://www.reddit.com/dev/api/)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Reddit**：[https://www.reddit.com/dev/api/](https://www.reddit.com/dev/api/)'
- en: '**YouTube**: [https://developers.google.com/youtube/v3](https://developers.google.com/youtube/v3)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**YouTube**：[https://developers.google.com/youtube/v3](https://developers.google.com/youtube/v3)'
- en: '**TikTok**[:https://developers.tiktok.com/products/research-api/](https://developers.tiktok.com/products/research-api/)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TikTok**：[https://developers.tiktok.com/products/research-api/](https://developers.tiktok.com/products/research-api/)'
- en: Once the data is obtained, a primary challenge can be accurately identifying
    mentions and discussions related to your brand. This is where **named entity recognition**
    (**NER**) and entity mapping techniques come into play. NER can help identify
    proper nouns, like brand names or products, within texts, while entity mapping
    can link these mentions to your brand across datasets.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获取数据，一个主要挑战就是准确识别与您的品牌相关的提及和讨论。这正是**命名实体识别**（NER）和实体映射技术发挥作用的地方。NER可以帮助识别文本中的专有名词，如品牌名称或产品，而实体映射可以将这些提及与数据集中的您的品牌联系起来。
- en: Performing NER on a dataset for a fictional retailer
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在一个虚构零售商的数据集上执行命名实体识别（NER）
- en: 'For example, let’s consider a series of customer reviews from a fictional online
    retailer, Optimal Hiking Gear, which sells outdoor equipment. To extract mentions
    of the brand, we can use the built-in capabilities for NER in the spaCy language
    model and look for its `ORG` tag to identify relevant mentions:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑一系列来自虚构在线零售商Optimal Hiking Gear（销售户外装备）的客户评论。为了提取品牌提及，我们可以使用spaCy语言模型内建的NER功能，并查找其`ORG`标签以识别相关提及：
- en: '[PRE22]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This yields the following result:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下结果：
- en: '[PRE23]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '**Enhancing NER with custom training**'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '**通过定制训练增强NER**'
- en: To tailor NER models more closely to your needs, consider training them with
    your data. This involves providing examples of texts with manually labeled entities
    that are specific to your brand or industry. By doing so, a model learns to recognize
    and categorize these custom entities more accurately. Tools like spaCy offer functionalities
    to train your NER models.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 NER 模型更贴近您的需求，考虑使用您的数据进行训练。这包括提供一些文本示例，其中包含您品牌或行业特有的手动标注实体。通过这样做，模型可以更准确地识别和分类这些自定义实体。spaCy
    等工具提供了训练您的 NER 模型的功能。
- en: Understanding topics and themes
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解主题和主题
- en: 'This section delves into various tools to extract insights from your dataset
    to provide an overview of the key topics and themes present. Such insights are
    crucial for grasping the broader context of customer sentiment within your data.
    As a starting point, we can use, for reference, the number of different reasons
    for negative sentiment that were tagged by the annotators of this dataset:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 本节深入探讨了各种工具，以从您的数据集中提取见解，概述关键主题和主题。这些见解对于理解数据中客户情绪的更广泛背景至关重要。作为一个起点，我们可以参考该数据集标注者标记的负面情感的不同原因的数量：
- en: '[PRE24]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This gives us the following output:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下输出：
- en: '![](img/B30999_05_12.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_05_12.png)'
- en: 'Figure 5.12: Counts of different negative sentiment tweets’ reasons given in
    the Twitter dataset'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12：Twitter 数据集中不同负面情感推文原因的计数
- en: Using word clouds
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用词云
- en: '**Word clouds**, where the size of each word in a plot corresponds to its frequency
    of occurrence, are a valuable starting tool to visualize text data. In order to
    enrich our word clouds and ensure that visualizations reflect not only the most
    frequent terms but also those that are most indicative of unique sentiments and
    topics, we will incorporate TF-IDF analysis to produce our plot. By introducing
    the `ngram_range=(1, 2)` argument into our `tfidf_vectorizer`, we create both
    unigrams and bigrams. Leveraging the `WordCloud` library, we can create word clouds
    via:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**词云**，其中每个词在图中的大小对应其出现的频率，是可视化文本数据的有价值起点工具。为了丰富我们的词云并确保可视化不仅反映最频繁的术语，还反映最能指示独特情感和主题的术语，我们将结合
    TF-IDF 分析来生成我们的图。通过将 `ngram_range=(1, 2)` 参数引入我们的 `tfidf_vectorizer`，我们创建了单语和双语。利用
    `WordCloud` 库，我们可以通过以下方式创建词云：'
- en: '[PRE25]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We’ll then see something similar to the following word cloud:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来会看到类似以下这样的词云：
- en: '![](img/B30999_05_13.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_05_13.png)'
- en: 'Figure 5.13: Word clouds showing the frequency of occurrence of different terms
    from TF-IDF analysis'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13：显示 TF-IDF 分析中不同术语出现频率的词云
- en: 'The analysis so far reveals pivotal themes through prevalent words such as
    `delay`, `cancel`, and `help`. Through the inclusion of bigrams, key terms such
    as `customer service` and `cancel flight` can also be captured. In the context
    of Twitter data, hashtags offer a direct glimpse into the core topics and sentiments
    expressed. To dive deeper, we will proceed to extract hashtags from the tweets,
    creating a word cloud to visualize these key phrases differently. This approach
    aims to provide a different lens to view the themes within our dataset:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止的分析通过诸如 `delay`、`cancel` 和 `help` 等常见词汇揭示了关键主题。通过包含双语，我们还可以捕捉到诸如 `customer
    service` 和 `cancel flight` 这样的关键术语。在 Twitter 数据的背景下，标签提供了直接了解核心主题和情感的方法。为了深入了解，我们将继续从推文中提取标签，创建一个词云来以不同的方式可视化这些关键短语。这种方法旨在为我们数据集中的主题提供不同的视角：
- en: '[PRE26]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We then see the following:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来看到以下内容：
- en: '![](img/B30999_05_14.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_05_14.png)'
- en: 'Figure 5.14: Word clouds showing the frequency of occurrence of Twitter hashtags'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.14：显示 Twitter 标签出现频率的词云
- en: Excluding direct airline mentions, the word cloud distinctly highlights prevalent
    negative sentiments through hashtags like `#Fail`, `#Disappointed`, and `#BadCustomerService`.
    In contrast to these, `#DestinationDragons` emerges prominently as well, signifying
    a well-publicized tour by Southwest Airlines, showcasing the duality of customer
    feedback captured in our dataset.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 排除直接提及航空公司的情况，词云通过诸如 `#Fail`、`#Disappointed` 和 `#BadCustomerService` 这样的标签清晰地突出了普遍的负面情绪。与这些相反，`#DestinationDragons`
    也显著出现，这标志着西南航空公司的广为人知的旅游活动，展示了我们数据集中捕获的客户反馈的双重性。
- en: Discovering latent topics with LDA
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 LDA 发现潜在主题
- en: '**Latent Dirichlet allocation** (**LDA**) is an advanced technique that goes
    beyond simple frequency metrics, like those seen in word clouds, by identifying
    the underlying topics within a text corpus through unsupervised machine learning.
    Unlike word clouds, which only highlight the most frequent words, LDA discerns
    the hidden thematic structure by considering documents as mixtures of topics,
    where each topic is defined by a particular set of words. This process involves
    Bayesian inference, using the Dirichlet distribution to estimate not just the
    presence but also the proportion of topics within documents. For example, in a
    collection of hotel reviews, LDA might identify topics related to location, parking,
    bathroom cleanliness, and check-in experience. The sophistication of LDA lies
    in its ability to capture the context and co-occurrence of words across the corpus,
    providing a more nuanced understanding of the text’s thematic content without
    prior labeling.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '**潜在狄利克雷分配**（**LDA**）是一种超越简单频率指标的高级技术，如词云中所示，它通过无监督机器学习识别文本语料库中的潜在主题。与仅突出最频繁单词的词云不同，LDA通过将文档视为主题的混合体来辨别隐藏的主题结构，其中每个主题由一组特定的单词定义。这个过程涉及贝叶斯推理，使用狄利克雷分布来估计文档中主题的存在及其比例。例如，在酒店评论集合中，LDA可能会识别与位置、停车、浴室清洁和入住体验相关的主题。LDA的复杂性在于其能够捕捉语料库中单词的上下文和共现，从而在不进行预先标记的情况下提供对文本主题内容的更细致的理解。'
- en: 'We can implement this approach via:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下方式实施这种方法：
- en: '[PRE27]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This gives us the following output:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下输出：
- en: '[PRE28]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Analyzing the clusters generated by LDA allows us to pinpoint important themes
    in the tweets, such as flight delays and customer service issues, represented
    in topics `#1` and `#2`, respectively. By changing the `n_components` parameter,
    we can alter the algorithm’s assumption around the number of topics present, leading
    to more granular topics as the parameter increases in value.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 分析LDA生成的聚类使我们能够确定推文中的重要主题，例如在主题`#1`和`#2`中分别表示的航班延误和客户服务问题。通过改变`n_components`参数，我们可以改变算法对存在主题数量的假设，随着参数值的增加，导致更细粒度的主题。
- en: It’s important to recognize that not all topics identified by LDA will directly
    align with key sentiment expressions, and some may simply reflect common, non-specific
    language pervasive throughout the dataset, as seen in topic `#0`.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要认识到，LDA识别出的所有主题并不都会直接与关键情感表达相一致，其中一些可能只是简单地反映了数据集中普遍存在的、非特定的语言，正如在主题`#0`中看到的那样。
- en: To extract meaningful insights, additional scrutiny is often required to discern
    which topics are most relevant for analysis. This process can be facilitated either
    through human review or by employing a carefully designed prompt for a language
    model, helping to summarize the word groupings according to their possible topics.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取有意义的见解，通常需要额外的审查来辨别哪些主题对于分析最为相关。这个过程可以通过人工审查或通过为语言模型设计一个精心设计的提示来促进，帮助根据可能的主题总结单词分组。
- en: 'Temporal trends: tracking the brand narrative'
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间趋势：追踪品牌叙事
- en: In the dynamic realm of social media, the viral nature of tweets often acts
    as a barometer for the sentiments that are most impactful to a brand’s perception.
    This is especially true for negative sentiments, which carry a substantial risk
    to a brand’s image. By scrutinizing the Twitter activity around airlines, such
    as JetBlue, we can unearth insights into tweets that may significantly influence
    brand reputation.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在社交媒体的动态领域，推文的病毒性往往充当衡量对品牌感知最具影响力的情感的温度计。这对于负面情感尤其如此，因为它们对品牌形象的风险很大。通过审查围绕航空公司（如JetBlue）的Twitter活动，我们可以揭示可能显著影响品牌声誉的推文。
- en: 'This paper presents a social media-based brand reputation tracker that monitors
    brand events in real time and connects them to specific drivers of brand reputation:
    [https://ora.ox.ac.uk/objects/uuid:00e9fcb7-9bf1-486a-b4dd-3c1d086af24e/files/rz316q188f](https://ora.ox.ac.uk/objects/uuid:00e9fcb7-9bf1-486a-b4dd-3c1d086af24e/files/rz316q188f).'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了一种基于社交媒体的品牌声誉追踪器，该追踪器实时监控品牌事件，并将它们与品牌声誉的具体驱动因素相连接：[https://ora.ox.ac.uk/objects/uuid:00e9fcb7-9bf1-486a-b4dd-3c1d086af24e/files/rz316q188f](https://ora.ox.ac.uk/objects/uuid:00e9fcb7-9bf1-486a-b4dd-3c1d086af24e/files/rz316q188f)。
- en: 'This analysis involves sifting through tweets mentioning the `@JetBlue` handle.
    The code below categorizes the sentiment of these tweets over time, where each
    data point’s bubble size corresponds to that day’s aggregate retweets, providing
    a visual scale of engagement:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这项分析涉及筛选提及`@JetBlue`账号的推文。下面的代码将随着时间的推移对这些推文的情感进行分类，其中每个数据点的气泡大小对应于那天总的转发量，提供了一个参与度的视觉尺度：
- en: '[PRE29]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This yields the following graph:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下图表：
- en: '![](img/B30999_05_15.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_05_15.png)'
- en: 'Figure 5.15: Sentiment of JetBlue tweets over time, where each data point’s
    bubble size corresponds to that day’s aggregate retweets'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15：JetBlue推文随时间变化的情感，其中每个数据点的气泡大小对应于那天总的转发量
- en: Significant peaks in negative sentiment tweets are observed on February 22 and
    23, with an unusual surge in retweets on the latter day indicating widespread
    engagement. Those focusing on brand reputation for JetBlue may find it valuable
    to delve into the specifics of these tweets.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在2月22日和23日观察到显著的负面情感推文高峰，后者转发量的异常激增表明广泛的参与。那些关注JetBlue品牌声誉的人可能会发现深入研究这些推文的细节很有价值。
- en: 'We can aggregate and rank the tweets in this date range, as well as the day
    before, according to those with the highest retweets, using the following code:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据转发量最高的推文，以及在此日期范围内以及前一天，对这些推文进行汇总和排名，以下代码可以实现：
- en: '[PRE30]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This gives us the following result:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下结果：
- en: '![](img/B30999_05_16.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_05_16.png)'
- en: 'Figure 5.16: Analysis of peak negative sentiment tweets for JetBlue on February
    22–24, 2015'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16：2015年2月22日至24日JetBlue负面情感推文高峰的分析
- en: The first and last day of the result reveal typical grievances, like late flights
    and poor service, that are common in the airline industry. However, the backlash
    on February 23 highlights a controversy around a marketing campaign by JetBlue,
    encapsulated by the phrase “Our fleet’s on fleek.” As discussed in the introduction
    to this chapter, real-time monitoring of brand perception would have enabled them
    to track this shift in campaign sentiment early on, enabling them to anticipate
    and potentially mitigate the PR issues that ensued.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的第一天和最后一天揭示了典型的抱怨，如晚点航班和糟糕的服务，这在航空业很常见。然而，2月23日的反弹突显了JetBlue一项营销活动的争议，该活动被短语“我们的机队很酷”所概括。正如本章引言中讨论的，实时监控品牌认知将使他们能够及早跟踪这种营销情感的变化，使他们能够预测并可能减轻随之而来的公关问题。
- en: The potential long-term repercussions of this negative publicity would necessitate
    further monitoring and analysis – using metrics such as the KPIs discussed in
    *Chapter 2* – to assess the impact on brand reputation. Nonetheless, this analysis
    illustrates the importance of monitoring social media trends over time to preemptively
    address issues that could adversely affect brand perception.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这种负面宣传的潜在长期影响需要进一步的监控和分析——使用第2章中讨论的KPI等指标——以评估对品牌声誉的影响。尽管如此，这项分析说明了随着时间的推移监控社交媒体趋势的重要性，以便提前解决可能损害品牌认知的问题。
- en: Mapping sentiments using geospatial analysis
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用地理空间分析映射情感
- en: 'Geospatial analysis offers a powerful lens through which to view customer sentiment,
    enabling companies to identify areas of concern – from customer service issues
    to poorly designed marketing campaigns — potentially even before such issues become
    apparent to on-site staff. To illustrate how to generate such insights, let’s
    utilize the `folium` package to create a heat map that pinpoints the origins of
    negative sentiments, based on tweet coordinates:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 地理空间分析提供了一个强大的视角，通过这个视角可以观察客户情感，使公司能够识别出关注点——从客户服务问题到设计不佳的市场营销活动——甚至在这些问题对现场工作人员变得明显之前。为了说明如何生成这样的见解，让我们利用`folium`包创建一个热图，该热图基于推文坐标精确指出负面情感的来源：
- en: '[PRE31]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This code yields the following map:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码产生了以下地图：
- en: '![](img/B30999_05_17.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_05_17.png)'
- en: 'Figure 5.17: Heat map that pinpoints the origins of negative JetBlue sentiments,
    based on tweet coordinates'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.17：基于推文坐标的热图，精确指出负面JetBlue情感的来源
- en: The resulting heat map reveals concentrations of negative sentiment in regions
    where JetBlue predominantly operates – a correlation that is expected, given that
    a greater volume of flights naturally leads to more reports of negative experiences.
    However, by looking at the time evolution of these patterns, we can see that this
    method can serve as a real-time tool to spot unusual patterns of sentiment.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的热图揭示了JetBlue主要运营区域中负面情感的集中——这一相关性是预期的，因为更多的航班自然会导致更多负面经历的报告。然而，通过观察这些模式的时间演变，我们可以看到这种方法可以作为实时工具来发现异常的情感模式。
- en: For instance, a sudden influx of negative tweets from a new location could signal
    service issues and foreshadow potential PR challenges to follow. Conversely, identifying
    areas with a high number of positive tweets might highlight strengths within a
    company. Coupling geospatial analysis with the topic modeling approaches introduced
    earlier can also unlock further insights, revealing not only what is discussed
    but also where these conversations take place, providing a valuable trove of actionable
    marketing intelligence.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，来自新位置的负面推文的突然涌入可能表明服务问题，并预示着可能出现的公关挑战。相反，识别出拥有大量正面推文的高频区域可能凸显出公司内的优势。将地理空间分析与之前介绍的主题建模方法相结合，也可以解锁更多见解，不仅揭示讨论的内容，还揭示这些对话发生的地方，提供宝贵的可操作营销情报。
- en: Summary
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter underscored the importance of sentiment analysis in modern marketing
    strategies. It introduced sentiment analysis as a key tool to interpret vast quantities
    of unstructured text data, such as social media conversations, to refine marketing
    strategies, brand messaging, or customer experience. By utilizing the Twitter
    Airline dataset, we covered the end-to-end process needed to classify sentiment
    as positive or negative, using both traditional NLP and more advanced GenAI methods
    involving pre-trained LLMs. We then covered an array of tools for the visualization
    and interpretation of these results to derive actionable marketing insights. This
    chapter should leave you equipped with the necessary skills to harness sentiment
    analysis effectively, for applications ranging from brand reputation monitoring
    to aligning marketing messages with customer preferences.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 本章强调了情感分析在现代营销策略中的重要性。它介绍了情感分析作为一项关键工具，用于解释大量非结构化文本数据，例如社交媒体对话，以精炼营销策略、品牌信息或客户体验。通过利用Twitter航空公司数据集，我们涵盖了将情感分类为正面或负面的端到端流程，使用了传统的NLP和更先进的涉及预训练LLMs的GenAI方法。然后，我们介绍了一系列工具，用于可视化这些结果，以得出可操作的营销见解。本章应该使你具备有效利用情感分析所需的基本技能，适用于从品牌声誉监控到将营销信息与客户偏好对齐的各种应用。
- en: Looking ahead to the next chapter, we will progress from understanding customer
    sentiment to actively shaping customer engagement using predictive analytics,
    with a focus on the empirical validation of marketing strategies through A/B testing.
    We will discuss identifying features to predict customer engagement, training
    machine learning models, model evaluation, and the implementation of A/B testing.
    The chapter is designed to advance your knowledge by providing skills in feature
    selection, building predictive models, optimizing model performance, conducting
    A/B tests, and integrating insights into effective marketing strategies. This
    next step will equip you with the ability to not only forecast customer behaviors
    but also empirically validate and refine marketing strategies for heightened effectiveness.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 展望下一章，我们将从理解客户情感进步到利用预测分析积极塑造客户参与度，重点关注通过A/B测试对营销策略的实证验证。我们将讨论识别预测客户参与度的特征、训练机器学习模型、模型评估以及A/B测试的实施。本章旨在通过提供特征选择、构建预测模型、优化模型性能、进行A/B测试以及将见解融入有效营销策略的技能来提升你的知识。这一步将使你不仅能够预测客户行为，而且能够通过实证验证和精炼营销策略以提高其有效性。
- en: Join our book’s Discord space
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的Discord空间
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区，与志同道合的人交流，并与其他5000多名成员一起学习：
- en: '[https://packt.link/genai](https://packt.link/genai)'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/genai](https://packt.link/genai)'
- en: '![](img/QR_Code12856128601808671.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code12856128601808671.png)'
