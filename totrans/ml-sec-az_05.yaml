- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Data Privacy and Responsible AI Best Practices
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据隐私和负责任AI最佳实践
- en: In the previous chapter, we talked about how to build a data governance program
    for our organization and how to identify types of sensitive data. Our work does
    not stop there. Although in some cases we can safely exclude sensitive information,
    other times we cannot. So, our **machine learning** (**ML**) models that solve
    problems might need to contain personal data. Sometimes that data can be relevant
    and useful, or it can create unintended correlations that make the model biased.
    This is the issue that we will tackle in this chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了如何为我们组织构建数据治理计划以及如何识别敏感数据类型。我们的工作并没有停止在那里。尽管在某些情况下我们可以安全地排除敏感信息，但在其他时候我们却不能。因此，我们解决问题的**机器学习**（**ML**）模型可能需要包含个人数据。有时这些数据可能是相关且有用的，或者它们可能产生意外的相关性，导致模型偏差。这就是本章我们将要解决的问题。
- en: We will talk about how to recognize sensitive information and how to mitigate
    it if it is not relevant to the model training process by using techniques such
    as differential privacy. We will explore how to protect individual information
    even from aggregated data or the model results. To help us with that, we will
    see how we can use the SmartNoise **software development** **kit** (**SDK**).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论如何识别敏感信息，以及如果这些信息与模型训练过程无关，如何使用差分隐私等技巧来减轻其影响。我们将探讨如何保护个人信息，即使是从汇总数据或模型结果中。为了帮助我们做到这一点，我们将了解如何使用SmartNoise
    **软件开发** **套件**（**SDK**）。
- en: We will also discuss fairness and how you can recognize bias in your model’s
    predictions. Here, we will apply the responsible AI principles we have learned
    together with the Fairlearn library and the Responsible AI dashboard. Together
    with bias comes model interpretability. We will analyze together how to calculate
    which features affect the prediction of your model for global or individual predictions
    by generating feature-importance values with model explainers.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论公平性以及你如何识别模型预测中的偏差。在这里，我们将应用我们共同学习的负责任AI原则，以及Fairlearn库和负责任AI仪表板。与偏差相伴而来的是模型可解释性。我们将一起分析如何通过生成特征重要性值来计算哪些特征会影响你模型的全球或个体预测。
- en: Finally, we will wrap up by explaining **federated learning** (**FL**) and secure
    multi-party computation to protect sensitive data in cross-organizational ML scenarios.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将总结解释**联邦学习**（**FL**）和安全多方计算，以保护跨组织机器学习场景中的敏感数据。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主要主题：
- en: Discovering and protecting sensitive data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现和保护敏感数据
- en: Introducing differential privacy
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍差分隐私
- en: Mitigating fairness
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓解公平性问题
- en: Working with model interpretability
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与模型可解释性合作
- en: Exploring FL and secure multi-party computation
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索联邦学习和安全多方计算
- en: By the end of this chapter, you will be able to protect your data against bias
    and privacy without compromising the quality of your predictions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够保护你的数据免受偏差和隐私问题的侵害，同时不会影响预测的质量。
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The code for this chapter is available in this repository under the `ch5` folder:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码存储在本存储库的`ch5`文件夹中：
- en: '[https://github.com/PacktPublishing/Machine-Learning-Model-Security-in-Azure/](https://github.com/PacktPublishing/Machine-Learning-Model-Security-in-Azure/)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Machine-Learning-Model-Security-in-Azure/](https://github.com/PacktPublishing/Machine-Learning-Model-Security-in-Azure/)'
- en: Working with Python
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Python进行工作
- en: To use the libraries, you need to be familiar with Python. In this book, we
    will use notebooks from the Azure Machine Learning environment to run the examples,
    but if you prefer to use your own development environment and tools, that is fine.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这些库，你需要熟悉Python。在这本书中，我们将使用Azure Machine Learning环境中的笔记本来运行示例，但如果你更喜欢使用自己的开发环境和工具，那也是可以的。
- en: Getting started with Python
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用Python
- en: 'New to Python and ML? Take a look at this learning path to learn the basics
    of Python: [https://learn.microsoft.com/en-us/training/paths/beginner-python/](https://learn.microsoft.com/en-us/training/paths/beginner-python/).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是Python和ML的新手？请查看这个学习路径，了解Python的基础知识：[https://learn.microsoft.com/en-us/training/paths/beginner-python/](https://learn.microsoft.com/en-us/training/paths/beginner-python/)。
- en: Running a notebook in Azure Machine Learning
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Azure Machine Learning中运行笔记本
- en: 'The process of running a notebook in Azure Machine Learning is very straightforward.
    All you need to do is import or create a workbook in the interface, attach a compute
    target, and then run the cells. Let us see the steps together:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the **Notebooks** section and upload or create your file:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Azure Machine Learning notebooks](img/B21076_05_1.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Azure Machine Learning notebooks
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the notebook file and attach a running compute target from the **Compute**
    dropdown:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Attaching a compute target to a notebook](img/B21076_05_2.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Attaching a compute target to a notebook
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Run the cells in the notebook as usual.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Installing the SmartNoise SDK
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The SmartNoise SDK ([https://smartnoise.org/](https://smartnoise.org/)) is a
    differential privacy toolkit that you can use in ML or analytics. Here, we’ll
    see how we can install the library in order to use it later in this chapter.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'To install SmartNoise SQL, run the following command:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To install SmartNoise Synthesizers, run this command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: SmartNoise documentation
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the complete documentation here: [https://docs.smartnoise.org/](https://docs.smartnoise.org/).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Installing Fairlearn
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Fairlearn can be installed with `pip` from PyPI using the following command:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Fairlearn documentation
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the complete documentation here: [https://fairlearn.org/](https://fairlearn.org/).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Discovering and protecting sensitive data
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although having good governance and working with multiple tools that work with
    data can help us with sensitive data discovery classification and profiling, more
    often than not, the data used in our ML experiments comes from outside sources,
    or maybe we are simply not developing for our own organization. In that case,
    we need to train ourselves on what sensitive data is and how to do a quick cleanup
    if we need to use Azure Machine Learning.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Identifying sensitive data
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sensitive data refers to any information that, if exposed, could cause harm,
    privacy breaches, or lead to identity theft, monetary loss, or other adverse consequences
    for individuals or organizations. This data requires special protection due to
    its nature and the potential risks associated with its disclosure.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many categories of sensitive data, many of which are outlined ahead,
    together with examples that we need to be aware of:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '**Personally identifiable information** (**PII**): Information that can be
    used to identify an individual, such as full name, date of birth, social security
    number, driver’s license number, passport number, and so on'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Financial information**: Credit card numbers, bank account details, financial
    transaction records, and so on'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Health information**: Medical records, health insurance information, mental
    health records, and other health-related data'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Passwords and authentication data**: Usernames, passwords, security questions,
    or any other credentials used to access systems or accounts'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Biometric data**: Fingerprints, retinal scans, facial recognition data, and
    other biometric identifiers'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生物识别数据**：指纹、视网膜扫描、面部识别数据和其他生物识别标识符'
- en: '**Confidential business information**: Trade secrets, **intellectual property**
    (**IP**), financial reports, customer lists, proprietary algorithms, and so on'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机密商业信息**：商业机密、**知识产权**（IP）、财务报告、客户名单、专有算法等等'
- en: '**Government classified information**: Information classified by governments
    for national security reasons'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**政府机密信息**：政府出于国家安全原因进行分类的信息'
- en: '**Personal communications**: Private messages, emails, and other communications
    that individuals expect to be confidential'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个人通讯**：私人消息、电子邮件和其他个人期望保密的通讯'
- en: '**Social and demographic information**: Race, ethnicity, religion, sexual orientation,
    and other sensitive demographic data'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社会和人口信息**：种族、民族、宗教、性取向和其他敏感的人口数据'
- en: '**Geolocation data**: Precise location data of individuals or assets'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地理位置数据**：个人或资产的精确位置数据'
- en: Some of that data we can exclude from our ML process. For example, if we are
    training a model to predict diabetes, we don’t need the patient data but the symptom
    data. In this case, we can safely exclude that information from our dataset by
    using the techniques we will explore in the next section. But if we are training
    a model to recognize faces, we need the actual biometric data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以排除一些数据，使其不进入我们的机器学习过程。例如，如果我们正在训练一个预测糖尿病的模型，我们不需要患者数据，只需要症状数据。在这种情况下，我们可以通过使用下一节中将要探讨的技术，安全地从数据集中排除这些信息。但如果我们正在训练一个用于识别面部的模型，我们需要实际的生物识别数据。
- en: Let us see some techniques that help us clean up sensitive data so that it is
    not known to the ML model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些帮助我们清理敏感数据的技术，以便它不会被机器学习模型所知。
- en: Exploring data anonymization
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索数据匿名化
- en: Data anonymization is a process of removing or obfuscating PII from a dataset
    to protect the privacy of individuals while still maintaining the data’s overall
    usefulness for analysis and research purposes. The goal is to ensure that the
    data cannot be linked back to specific individuals.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据匿名化是一个从数据集中移除或模糊化PII（个人身份信息）的过程，以保护个人的隐私，同时仍然保持数据在分析和研究目的上的整体有用性。目标是确保数据不能追溯到特定的个人。
- en: 'Here are some common techniques used in data anonymization:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些在数据匿名化中常用的技术：
- en: '**Removing direct identifiers**: The most straightforward method is to remove
    direct identifiers such as names, social security numbers, phone numbers, email
    addresses, and so on from the dataset. We can use a unique identification number
    that identifies each record to maintain uniqueness or correlation, but anything
    that can identify a person is removed completely.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移除直接标识符**：最直接的方法是从数据集中移除直接标识符，如姓名、社会保障号码、电话号码、电子邮件地址等。我们可以使用一个唯一的识别号来标识每条记录以保持唯一性或相关性，但任何可以识别个人的信息都将被完全移除。'
- en: '**Pseudonymization**: The process of replacing sensitive data with pseudonyms
    or randomly generated identifiers is called pseudonymization. The objective is
    to obscure the original identity of individuals or entities in a dataset while
    allowing data processing and analysis to continue using the pseudonymized data.
    Unlike full anonymization, pseudonymization retains the structure and format of
    the original data, making it useful for certain purposes while still protecting
    privacy. This way, the original data is still present in the dataset, but the
    linkage to specific individuals is broken.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**化名化**：将敏感数据替换为化名或随机生成的标识符的过程称为化名化。目标是模糊化数据集中个人或实体的原始身份，同时允许使用化名化数据继续进行数据处理和分析。与完全匿名化不同，化名化保留了原始数据的结构和格式，使其在某些目的上仍然有用，同时保护隐私。这样，原始数据仍然存在于数据集中，但与特定个人的联系已被切断。'
- en: Best practice – combining pseudonymization with other techniques
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践 - 将化名化与其他技术相结合
- en: Pseudonymization is a very good privacy-enhancing technique, but it’s not guaranteed.
    If additional information or external datasets can be combined with the pseudonymized
    data, identification of the individual may still be possible. Therefore, it’s
    good to combine pseudonymization with other security measures to effectively protect
    sensitive data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 化名化是一种非常好的增强隐私的技术，但并不保证。如果额外的信息或外部数据集可以与化名化数据相结合，个体的识别仍然可能发生。因此，将化名化与其他安全措施相结合以有效保护敏感数据是很好的。
- en: '**Data masking or tokenization**: This technique is very similar to pseudonymization,
    but instead of encrypting or replacing sensitive data, data masking or tokenization
    replaces the values with randomly generated tokens or symbols. For example, if
    there is a credit card number present, all digits except the last four will be
    replaced by a star symbol. Data masking or tokenization might result in data that
    is not useful to the ML process. Therefore, you might want to remove the data
    altogether.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据掩码或标记化**：这种技术与匿名化非常相似，但不是加密或替换敏感数据，而是用随机生成的标记或符号替换数据值。例如，如果存在信用卡号码，所有数字除了最后四位将被星号符号替换。数据掩码或标记化可能导致对机器学习过程无用的数据。因此，你可能希望完全删除数据。'
- en: '**Generalization or aggregation**: This involves grouping data into broader
    categories to reduce the level of detail while still preserving overall patterns
    and trends. This technique is often used in data anonymization to protect individual
    privacy. The goal of generalization or aggregation is to strike a balance between
    data utility and privacy. While it reduces the risk of directly identifying individuals,
    it still provides valuable insights for analysis and research. However, it’s important
    to carefully consider the level of generalization to avoid potential re-identification
    risks, especially when combined with other available information. Here are some
    examples of generalization or aggregation:'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**泛化或聚合**：这涉及到将数据分组到更广泛的类别中，以减少细节水平，同时仍然保留整体模式和趋势。这种技术在数据匿名化中常用于保护个人隐私。泛化或聚合的目标是在数据效用和隐私之间取得平衡。虽然它降低了直接识别个人的风险，但仍然为分析和研究提供了有价值的见解。然而，重要的是要仔细考虑泛化的程度，以避免潜在的重新识别风险，尤其是在与其他可用信息结合使用时。以下是一些泛化或聚合的例子：'
- en: '**Age ranges**: Instead of using exact ages, data can be generalized into age
    ranges such as *18-24*, *25-34*, *35-44*, and so on. This maintains the information
    about age groups without revealing precise ages.'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**年龄范围**：而不是使用确切的年龄，数据可以泛化到如 *18-24*、*25-34*、*35-44* 等年龄范围。这样保持了关于年龄组的信息，而不透露确切的年龄。'
- en: '**Geographical aggregation**: Instead of using precise addresses, data can
    be aggregated at the city, state, or country level. For instance, *New York* could
    represent data from various neighborhoods within the city.'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地理聚合**：而不是使用精确的地址，数据可以在城市、州或国家级别进行聚合。例如，*纽约* 可以代表城市内各个社区的数据。'
- en: '**Income brackets**: Instead of exact income values, data can be grouped into
    income brackets such as *Low Income*, *Middle Income*, and *High Income*.'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收入区间**：而不是确切的收入值，数据可以分组到如 *低收入*、*中等收入* 和 *高收入* 等收入区间。'
- en: '**Time intervals**: Temporal data can be aggregated into time intervals, such
    as days, weeks, or months, rather than using exact timestamps. For example, *Q1
    2023* could represent data from *January* to *March*.'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间间隔**：时间数据可以聚合到如天、周或月的时间间隔中，而不是使用确切的日期和时间戳。例如，*Q1 2023* 可以代表从 *一月* 到 *三月*
    的数据。'
- en: '**Education levels**: Instead of specific degrees, data can be grouped by education-level
    categories such as *high school diploma*, *bachelor’s degree*, *master’s degree*,
    and so on.'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**教育水平**：而不是具体的学位，数据可以根据如 *高中文凭*、*学士学位*、*硕士学位* 等教育水平类别进行分组。'
- en: '**Product categories**: Sales data can be aggregated at the product category
    level rather than listing individual products; for example, *electronics*, *clothing*,
    and *furniture*.'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**产品类别**：销售数据可以在产品类别级别进行聚合，而不是列出单个产品；例如，*电子产品*、*服装* 和 *家具*。'
- en: '**Customer segments**: Data can be grouped into segments based on customer
    behavior or characteristics, such as *frequent shoppers*, *new customers*, or
    *high-spending customers*.'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户细分**：数据可以根据客户行为或特征进行分组，例如 *常客购物者*、*新客户* 或 *高消费客户*。'
- en: '**Transaction amount ranges**: Instead of exact transaction amounts, financial
    data can be grouped into ranges such as *$0-$50*, *$50-$100*, and so on.'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易金额范围**：金融数据可以分组到如 *$0-$50*、*$50-$100* 等范围，而不是精确的交易金额。'
- en: '**Health conditions**: Medical data can be aggregated into broader health condition
    categories instead of specifying individual diagnoses; for example, *cardiovascular*,
    *respiratory*, and *neurological*.'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**健康状况**：医疗数据可以聚合到更广泛的健康状况类别中，而不是指定个体诊断；例如，*心血管*、*呼吸系统* 和 *神经系统*。'
- en: '**Web browsing patterns**: Internet browsing data can be aggregated based on
    website categories (for example, news, entertainment, shopping) rather than recording
    every visited website.'
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Web浏览模式**：基于网站类别（例如，新闻、娱乐、购物）而不是记录每个访问的网站，可以对互联网浏览数据进行汇总。'
- en: Removing, combining, or masking sensitive information is not the only option.
    When we need to use sensitive data to train models, there are other techniques
    to either protect the data or manipulate the data in a way that still protects
    any sensitive information without limiting our model’s potential.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 删除、合并或屏蔽敏感信息不是唯一的选择。当我们需要使用敏感数据来训练模型时，还有其他技术可以保护数据或以保护任何敏感信息的方式操纵数据，同时不会限制我们模型的可能性。
- en: Let us explore how to protect the privacy of individual data without removing
    it from the dataset.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨如何在不从数据集中删除数据的情况下保护个体数据的隐私。
- en: Introducing differential privacy
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍差分隐私
- en: Differential privacy is a concept that has the purpose of protecting the privacy
    of individual data contributors while still allowing useful statistical analysis.
    The basic idea behind differential privacy is to add noise or random perturbations
    to the data in such a way that the statistical properties of the dataset stay
    the same, but it is much more difficult to identify individual information within
    the dataset.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私是一个旨在保护单个数据贡献者隐私的同时，仍然允许进行有用统计分析的概念。差分隐私背后的基本思想是在数据中添加噪声或随机扰动，使得数据集的统计属性保持不变，但识别数据集中个体信息变得更加困难。
- en: 'The level of privacy protection in differential privacy is controlled by a
    parameter called epsilon (ε). A smaller value of epsilon indicates a higher level
    of privacy, but it might also lead to a decrease in data utility (usefulness of
    the data for analysis). Striking a balance between privacy and utility is a key
    challenge in implementing differential privacy:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私中的隐私保护级别由一个称为epsilon（ε）的参数控制。epsilon值越小，表示隐私保护级别越高，但也可能导致数据效用（数据用于分析的有用性）降低。在隐私和效用之间取得平衡是实现差分隐私的关键挑战：
- en: "![Figure 5.3 – Epsilon (\uFEFFƐ) value relationship with privacy and accuracy](img/B21076_05_3.jpg)"
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: "![图5.3 – Epsilon（\uFEFFƐ）值与隐私和准确性的关系](img/B21076_05_3.jpg)"
- en: Figure 5.3 – Epsilon (Ɛ) value relationship with privacy and accuracy
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – Epsilon（Ɛ）值与隐私和准确性的关系
- en: A library that we can use to add noise to the data is the SmartNoise SDK. SmartNoise
    is an open source SDK designed to implement differential privacy in various data
    analysis and ML workflows. It is developed by OpenDP and aims to make it easier
    for data analysts, researchers, and data scientists to apply differential privacy
    techniques to their data without extensive knowledge of the underlying mathematical
    complexities.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用SmartNoise SDK来向数据添加噪声。SmartNoise是一个开源SDK，旨在在各种数据分析和工作流程中实现差分隐私。它由OpenDP开发，旨在使数据分析师、研究人员和数据科学家更容易将差分隐私技术应用于他们的数据，而无需深入了解底层数学复杂性。
- en: The SmartNoise SDK provides a set of tools and utilities that can be integrated
    into existing data analysis and ML pipelines to ensure privacy-preserving computations.
    It offers an abstraction layer for adding differential privacy to computations,
    allowing data analysts to easily specify privacy parameters (such as epsilon)
    and apply privacy-preserving mechanisms without dealing directly with the intricacies
    of differential privacy algorithms.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: SmartNoise SDK提供了一套工具和实用程序，可以集成到现有的数据分析和工作流程中，以确保隐私保护的计算。它提供了一个抽象层，用于向计算添加差分隐私，允许数据分析师轻松指定隐私参数（如epsilon），并应用隐私保护机制，而无需直接处理差分隐私算法的复杂性。
- en: 'There are different components you can use, and these are the official recommendations
    from the documentation:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用不同的组件，以下是文档中的官方推荐：
- en: Use **OpenDP** directly when working with Jupyter notebooks and reproducible
    research or if you require fine-grained control over processing and privacy
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用Jupyter笔记本和可重复研究或需要精细控制处理和隐私时，直接使用**OpenDP**。
- en: Use **SmartNoise SQL** if you are working with large datasets or data cubes
    over tabular data stored in SQL databases or Spark
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您正在处理大型数据集或存储在SQL数据库或Spark中的表格数据的数据立方体，请使用**SmartNoise SQL**。
- en: Use **SmartNoise Synthesizers** if you are still in the research process and
    you want to see what the result will look like with other collaborators
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您仍在研究过程中，并希望看到与其他合作者合作的结果，请使用**SmartNoise Synthesizers**。
- en: 'Here, we will see an example by using SmartNoise SQL:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将通过使用SmartNoise SQL来举一个例子：
- en: 'First, you need to install SmartNoise SQL by running this command:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，你需要通过运行以下命令安装SmartNoise SQL：
- en: '[PRE3]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: import pandas as pd
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: data_path = 'mockdata.csv'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: data_path = 'mockdata.csv'
- en: mockdata = pd.read_csv(data_path)
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: mockdata = pd.read_csv(data_path)
- en: actualdata = mockdata[['age','diabetic']].groupby(\
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: actualdata = mockdata[['age','diabetic']].groupby(\
- en: '[''diabetic'']).mean().to_markdown()'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[''diabetic'']).mean().to_markdown()'
- en: print(actualdata)
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print(actualdata)
- en: '[PRE4]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let us see what happens when we add noise to the data. First, we need to declare
    the epsilon variable. We will execute this code multiple times, first with a low
    epsilon value for greater privacy (`0.05`) and second with a high epsilon value
    for accuracy (`0.90`), and compare the results:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看当我们向数据添加噪声时会发生什么。首先，我们需要声明epsilon变量。我们将执行此代码多次，首先使用低epsilon值以获得更高的隐私性（`0.05`），然后使用高epsilon值以提高准确率（`0.90`），并比较结果：
- en: '[PRE5]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can see in the following table a comparison of multiple executions of the
    preceding code side by side, and the average age for non-diabetic and diabetic
    patients is almost the same (around 47 years old), but when we use the SmartNoise
    SDK library with different epsilon values, the results start to vary from 1% to
    15% depending on the epsilon value used. This percentage might seem high; however,
    it is up to us to determine the balance between privacy and accuracy. The only
    thing the library guarantees is to maintain statistical uniformity:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在下表中看到前面代码多次执行的比较，非糖尿病和糖尿病患者的平均年龄几乎相同（大约47岁），但当我们使用具有不同epsilon值的SmartNoise
    SDK库时，结果开始从1%到15%不等，具体取决于使用的epsilon值。这个百分比可能看起来很高；然而，我们决定隐私和准确率之间的平衡。库唯一保证的是保持统计一致性：
- en: '|  | **Actual average** **age** | **Execution 1****Average age** | **Execution
    2****Average age** | **Execution 3****Average age** | **Execution 4****Average
    age** |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '|  | **实际平均** **年龄** | **执行 1** **平均年龄** | **执行 2** **平均年龄** | **执行 3** **平均年龄**
    | **执行 4** **平均年龄** |'
- en: '| Epsilon value | N/A | 0.05 | 0.05 | 0.90 | 0.80 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Epsilon值 | N/A | 0.05 | 0.05 | 0.90 | 0.80 |'
- en: '| Non- diabetic | 47.4101 | 54.2823275862069 | 53.209829867674856 | 47.72727272727273
    | 47.38953488372093 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 非糖尿病患者 | 47.4101 | 54.2823275862069 | 53.209829867674856 | 47.72727272727273
    | 47.38953488372093 |'
- en: '| Diabetic | 47.4741 | 42.19132149901381 | 44.00204081632653 | 47.36438923395445
    | 47.616977225672876 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 糖尿病患者 | 47.4741 | 42.19132149901381 | 44.00204081632653 | 47.36438923395445
    | 47.616977225672876 |'
- en: Table 5.1 – Dataset results
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5.1 – 数据集结果
- en: You can see how to run this notebook in the book repository mentioned previously
    in the *Technical requirements* section. This way, we can protect the privacy
    of the data without compromising the results of our model. What happens, though,
    when the data we are trying to protect actually affects the predictions, resulting
    in a negative impact?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在之前在*技术要求*部分提到的书籍仓库中看到如何运行这个笔记本。这样，我们可以在不损害模型结果的情况下保护数据的隐私。然而，当我们试图保护的数据实际上影响了预测，导致负面影响时，会发生什么呢？
- en: Let’s see how we can ensure our data is private and the model also provides
    fair results for different sensitive groups.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何确保我们的数据是私密的，并且模型也为不同的敏感群体提供公平的结果。
- en: Mitigating fairness
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓解公平性
- en: Mitigating fairness in ML models is an essential step to ensure that the model
    does not exhibit bias or discrimination against certain groups of individuals.
    Even though we can remove PII from our datasets, predictions might favor different
    groups based on characteristics such as race, gender, age, or religion. If the
    training data is not diverse and representative of the population you aim to serve,
    bias can creep into the model if the data does not adequately represent all groups.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习模型中缓解公平性是确保模型不会对某些个体群体表现出偏见或歧视的必要步骤。尽管我们可以从数据集中移除PII，但预测可能会根据种族、性别、年龄或宗教等特征偏向不同的群体。如果训练数据不具有多样性，也不能代表你希望服务的群体，那么如果数据不能充分代表所有群体，偏见就可能渗入模型。
- en: 'Firstly, we need to learn to identify bias in our models. This is easy by conducting
    an analysis of the metrics of the model. Suppose you suspect that your load approval
    model favors people above a certain age to get their loan application approved.
    You can start by looking at the metrics for the complete dataset as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要学会识别模型中的偏见。通过分析模型的指标，这很容易做到。假设你怀疑你的贷款批准模型倾向于让年龄超过一定的人获得贷款申请批准。你可以从查看以下完整数据集的指标开始：
- en: '|  | **Selection Rate** | **Accuracy** | **Recall** | **Precision** |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|  | **选择率** | **准确率** | **召回率** | **精确率** |'
- en: '| Complete dataset | 0.337 | 0.8895 | 0.8385650224215246 | 0.8323442136498517
    |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 完整数据集 | 0.337 | 0.8895 | 0.8385650224215246 | 0.8323442136498517 |'
- en: Table 5.2 – Dataset metrics
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.2 – 数据集指标
- en: 'Now, calculate the same metrics by age group. We can do this by using a library
    such as Fairlearn. The result from the split looks like this:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，按年龄组计算相同的指标。我们可以通过使用Fairlearn等库来完成这项工作。分割后的结果如下：
- en: '|  | **Selection Rate** | **Accuracy** | **Recall** | **Precision** |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|  | **选择率** | **准确率** | **召回率** | **精确率** |'
- en: '| Age 30 or younger | 0.299282 | 0.890668 | 0.818519 | 0.815498 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 30岁或以下 | 0.299282 | 0.890668 | 0.818519 | 0.815498 |'
- en: '| Age over 30 | 0.698413 | 0.878307 | 0.922481 | 0.901515 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 年龄超过30岁 | 0.698413 | 0.878307 | 0.922481 | 0.901515 |'
- en: Table 5.3 – Metrics per age group
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.3 – 每个年龄组的指标
- en: Metrics explained
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 指标解释
- en: 'Metrics are specific to the type of model. The preceding metrics are for classification
    models. You can find a list of metrics for different models and charts with an
    explanation here: [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml?view=azureml-api-2](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml?view=azureml-api-2).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 指标是特定于模型类型的。前面的指标是针对分类模型的。您可以在以下位置找到不同模型的指标列表和解释图表：[https://learn.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml?view=azureml-api-2](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml?view=azureml-api-2).
- en: From these metrics, you should be able to discern that a larger proportion of
    older individuals are predicted to be approved for the loan. Accuracy should be
    more or less equal for the two groups, but a closer inspection of precision and
    recall indicates some disparity in how well the model predicts for each age group.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些指标中，您应该能够辨别出，预测获得贷款批准的老年人数比例较大。两组的准确率应该大致相等，但更仔细地检查精确率和召回率表明，模型对每个年龄组的预测能力存在一些差异。
- en: In this scenario, consider **Recall**. This metric indicates the proportion
    of positive cases that were correctly identified by the model. In other words,
    of all the individuals who should get approval for their loan application and
    they actually do, how many did the model find? The model seems to do a better
    job in the older age group.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个场景中，考虑**召回率**。这个指标表示模型正确识别出的正例所占的比例。换句话说，对于所有应该获得贷款批准并且实际上确实获得批准的个人，模型找到了多少？模型似乎在老年年龄组中做得更好。
- en: So, what do we do now? Do we try to correct the data and model to predict equally
    between the two groups? The short answer is *not yet*. We need to consider the
    context first and evaluate why the model exhibits this behavior, and whether this
    is justified. Remember that metrics are just metrics, and it is up to us to interpret
    them. Maybe our model favors the older age group because they are more financially
    stable. We need to investigate more before we reach a decision because this identified
    bias might be reasonable. Suppose we had a face recognition application that favored
    light-skinned people over dark-skinned people; this would be a clear bias and
    would need to be corrected. The context and the model’s purpose will define our
    next steps.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们现在该怎么做？我们是否尝试纠正数据和模型以在两组之间进行平等预测？简短的答案是*还不行*。我们需要首先考虑上下文，并评估模型表现出这种行为的理由，以及这是否合理。记住，指标只是指标，解释它们的责任在我们。也许我们的模型偏好老年年龄组，因为他们更经济稳定。在我们做出决定之前，我们需要进行更多的调查，因为这种识别出的偏差可能是合理的。假设我们有一个偏好浅色皮肤人群的肤色识别应用程序，那么这将是一个明显的偏差，需要纠正。上下文和模型的目的将定义我们的下一步行动。
- en: Fairlearn
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Fairlearn
- en: Fairlearn is an open source project to help ML engineers and data scientists
    improve the fairness of AI systems. It can assist by providing fairness-related
    metrics that can be compared between groups and for the overall population. To
    calculate those metrics and conduct an investigation, the Fairlearn SDK is immensely
    helpful. It breaks down the metrics from each sensitive group, and then you can
    use the fairness dashboard to complete your assessment, as looking at the data
    visually always helps.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Fairlearn是一个开源项目，旨在帮助机器学习工程师和数据科学家提高人工智能系统的公平性。它可以通过提供可以比较不同组和整体人群的公平性相关指标来协助。为了计算这些指标并进行调查，Fairlearn
    SDK非常有帮助。它将每个敏感组的指标分解开来，然后您可以使用公平性仪表板来完成您的评估，因为直观地查看数据总是有帮助的。
- en: Fairlearn SDK and Azure Machine Learning
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Fairlearn SDK和Azure Machine Learning
- en: 'This feature is in Preview at the time of writing, so you can see limitations
    and applications in the Azure Machine Learning environment here: [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml?view=azureml-api-1](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml?view=azureml-api-1).
    The Fairlearn project documentation can be found here: [https://fairlearn.org/](https://fairlearn.org/).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，此功能处于预览阶段，因此您可以在 Azure Machine Learning 环境中看到局限性和应用：[https://learn.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml?view=azureml-api-1](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml?view=azureml-api-1)。Fairlearn
    项目的文档可以在这里找到：[https://fairlearn.org/](https://fairlearn.org/)。
- en: 'Here, you can see an example process of working with the visual dashboard.
    You can generate the UI in your notebooks, and it looks like this:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到一个使用可视化仪表板的工作流程示例。您可以在笔记本中生成 UI，看起来像这样：
- en: '![Figure 5.4 – Fairness dashboard main page](img/B21076_05_4.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.4 – 公平性仪表板主页面](img/B21076_05_4.jpg)'
- en: Figure 5.4 – Fairness dashboard main page
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 – 公平性仪表板主页面
- en: 'You can also register the model and upload the dashboard data to your workspace
    to conduct your assessment, as seen in the following screenshot. The process is
    much easier with the help of the wizard:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将模型注册到您的空间，并将仪表板数据上传以进行评估，如下面的截图所示。在向导的帮助下，这个过程会容易得多：
- en: 'The first step is to choose sensitive features; for example, the **Age** column:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是选择敏感特征；例如，**年龄**列：
- en: '![Figure 5.5 – Step 1: Choosing your sensitive features](img/B21076_05_5.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.5 – 步骤 1：选择您的敏感特征](img/B21076_05_5.jpg)'
- en: 'Figure 5.5 – Step 1: Choosing your sensitive features'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 – 步骤 1：选择您的敏感特征
- en: 'The second step is to choose a metric to evaluate against in order to examine
    any possible bias. Depending on the model algorithm, you might get different metrics
    here to choose from:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二步是选择一个指标来评估，以便检查任何可能的偏差。根据模型算法，您可能在这里获得不同的指标以供选择：
- en: '![Figure 5.6 – Step 2: Choosing a primary metric to measure performance](img/B21076_05_6.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.6 – 步骤 2：选择主要指标以衡量性能](img/B21076_05_6.jpg)'
- en: 'Figure 5.6 – Step 2: Choosing a primary metric to measure performance'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 – 步骤 2：选择主要指标以衡量性能
- en: 'In the third and final step, you set the parity constraints against which you
    want to measure fairness; for example, demographic parity or selection rate:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三和最后一步，您设置要衡量公平性的对等约束；例如，人口统计学对等或选择率：
- en: '![Figure 5.7 – Step 3: Choose how you want to measure fairness](img/B21076_05_7.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.7 – 步骤 3：选择您想要如何衡量公平性](img/B21076_05_7.jpg)'
- en: 'Figure 5.7 – Step 3: Choose how you want to measure fairness'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 – 步骤 3：选择您想要如何衡量公平性
- en: 'The service runs an analysis based on the parameters and returns results that
    we can use to determine if the model favors one or more groups based on sensitive
    features:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 服务基于参数运行分析，并返回我们可以用来确定模型是否基于敏感特征偏向一个或多个群体的结果：
- en: '![Figure 5.8 – Reviewing the results](img/B21076_05_8.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.8 – 查看结果](img/B21076_05_8.jpg)'
- en: Figure 5.8 – Reviewing the results
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 – 查看结果
- en: Note
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The integration with the Fairlearn open source package is supported at the time
    of writing only on the `azureml v1` Python SDK.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，与 Fairlearn 开源包的集成仅支持 `azureml v1` Python SDK。
- en: Always remember that complete fairness may not always be achievable, and trade-offs
    may exist between different fairness goals. We need to ensure that the model performs
    adequately for all sensitive groups in our datasets. The key is to make informed
    decisions about fairness trade-offs and continuously strive to improve the model’s
    fairness.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 总是记住，完全的公平性可能并不总是能够实现，不同公平性目标之间可能存在权衡。我们需要确保模型在数据集中的所有敏感群体中都能良好地表现。关键是就公平性权衡做出明智的决定，并持续努力提高模型公平性。
- en: Another part of responsible AI is the ability to explain how a model makes predictions.
    Let us see some techniques in the following section.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 负责任的人工智能的另一部分是解释模型如何进行预测的能力。让我们在下一节中看看一些技术。
- en: Working with model interpretability
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与模型可解释性一起工作
- en: Model interpretability in ML refers to the ability to understand and explain
    how a particular model makes predictions or decisions. Interpretable models provide
    clear insights into the features or variables that are most influential in the
    model’s decision-making process. This is particularly important in domains where
    the decision-making process needs to be transparent and understandable, such as
    healthcare, finance, and legal systems.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Although you can never explain 100% why a model makes a prediction, you can
    use explainers to understand which features affect the results. Explainers can
    help us provide global explanations; for example, which features affect the overall
    behavior of the model or local explanations that provide us with information on
    what influenced an individual prediction.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us explore some methods we can use to achieve model interpretability:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature importance** (**FI**) determines the influence of each feature in
    influencing the model’s predictions. Techniques such as the following can be used:'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Permutation FI** (**PFI**): This method involves randomly shuffling the values
    of each feature and measuring the impact on the model’s performance. Features
    with the highest drop in performance after shuffling are considered more important.'
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SHapley Additive exPlanations (SHAP) values**: SHAP values provide a unified
    measure of FI based on cooperative game theory. They assign contributions to each
    feature in a prediction, considering all possible feature combinations.'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local Interpretable Model-agnostic Explanations** (**LIME**): LIME creates
    local interpretable models around a specific prediction by perturbing the data
    and observing the impact on the prediction. It helps explain individual predictions
    for any model.'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Partial dependence plots** (**PDP**) and **individual conditional expectation**
    (**ICE**) test the feature influence on the model by using different techniques:'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PDP plots the average effect of a single feature on the model’s predictions
    while keeping other features constant.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: ICE plots multiple individual PDPs, one for each instance, providing a more
    granular view of how the feature affects different instances.
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rule-based models**: Decision trees and linear models are inherently interpretable
    as their structure can be easily visualized and understood.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Proxy models**: Train a simpler, interpretable model to approximate the behavior
    of a more complex model. This allows for better understanding without sacrificing
    too much accuracy.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visualizations**: Visualizations such as heatmaps, saliency maps, and activation
    maps can help understand how the model processes and weighs different input features.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer-wise Relevance Propagation** (**LRP**): LRP is a technique used in
    **neural networks** (**NNs**) to understand which input features contribute most
    to a specific output.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The method we choose depends on our model and the flavor used to create it.
    Let us see the options we have for model interpretability in Azure Machine Learning.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the Responsible AI dashboard
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work with interpretability in Azure Machine Learning, you can use the Interpret-Community
    package for the v1 SDK, or it is recommended to use the newer version, which is
    part of the new Responsible AI dashboard.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us explore the capabilities available:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Model interpretability in Azure Machine Learning
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'Learn more about the Interpret-Community package in Azure Machine Learning
    and how common explainers work in the following documentation: [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability?view=azureml-api-2#supported-model-interpretability-techniques](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability?view=azureml-api-2#supported-model-interpretability-techniques).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'You can generate a dashboard in any model in the MLflow format generated with
    the scikit-learn by going to your registered model under the **Models** menu,
    choosing the **Responsible AI** tab, and clicking on the **Create dashboard**
    button, as shown in the following screenshot:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Creating a Responsible AI dashboard](img/B21076_05_9.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – Creating a Responsible AI dashboard
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: MLflow models
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'MLflow is an open source platform designed to manage the end-to-end ML life
    cycle by providing a consistent and easy-to-use framework, making collaboration
    and reproducibility more accessible for data science and ML teams. Find out more
    here: [https://mlflow.org/](https://mlflow.org/).'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'As soon as the dashboard is generated, you can click on it on the list to view
    more details:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.10 – Opening the dashboard](img/B21076_05_10.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – Opening the dashboard
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'The dashboard has a lot of information to help not only with explainability
    but also metrics about fairness, data distribution, and individual predictions.
    Along with the data, there are numerous visualizations you can take advantage
    of to analyze your model, as seen in the following screenshot. Make sure you adhere
    to responsible AI development principles:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Reviewing the metrics](img/B21076_05_11.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – Reviewing the metrics
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to model interpretability, you can see FIs for the complete dataset
    and for individual predictions. You can tweak the class importance weights and
    the chart to suit your needs and understand the model better.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the next screenshot, we can see global FIs for a sample diabetes dataset:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.12 – Reviewing FIs](img/B21076_05_12.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – Reviewing FIs
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Model interpretability is a balance between simplicity and accuracy. Highly
    interpretable models might sacrifice some predictive performance, while very complex
    models might be difficult to explain comprehensively. The choice of interpretability
    method depends on the specific use case, audience, and the trade-off between model
    complexity and transparency.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Generating an AI dashboard using the SDK
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'For further resources to build the AI dashboard using the SDK using YAML and
    Python, see here: [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-insights-sdk-cli?view=azureml-api-2&tabs=yaml](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-insights-sdk-cli?view=azureml-api-2&tabs=yaml).'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: All the techniques we have seen so far focus on having one dataset that is trained
    on one compute resource to generate the resulting model. In the next section,
    we will see some techniques that focus on splitting model training and datasets
    between different compute sources.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Exploring FL and secure multi-party computation
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**FL** is an ML approach that enables the training of models across multiple
    devices or servers without centrally aggregating the raw data. In traditional
    ML, data is usually collected and sent to a central compute server for training,
    which raises privacy and security concerns, especially when dealing with sensitive
    or personal information.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: In FL, the training process happens locally on the devices or nodes (for example
    smartphones, edge devices, or compute instances) that generate or store the data.
    These nodes collaborate by sharing only model updates (gradients) rather than
    the raw data itself. The central compute server aggregates these updates to create
    an improved global model. This process is repeated iteratively, with each node
    contributing to the model’s improvement while keeping its data private.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'The main advantages of FL are as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '**Privacy**: As the raw data remains on the local nodes, there is no need to
    share sensitive information with a central server, reducing the risk of data leaks
    and breaches'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduced data transmission**: FL decreases the amount of data that needs to
    be sent over the network, which can be beneficial when dealing with large datasets
    or bandwidth constraints'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decentralization**: The model training process can be distributed across
    a large number of nodes, enabling scalability and robustness in a distributed
    environment'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local adaptation**: Nodes can update the global model while taking into account
    their local data distribution, leading to models that are more relevant and tailored
    to specific local characteristics'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FL is especially useful in scenarios where data privacy and security are crucial,
    such as healthcare and financial services, and processing can be distributed as
    in **Internet of Things** (**IoT**) applications. It gives us the opportunity
    to leverage the collective knowledge from distributed data sources without compromising
    the privacy of individual users.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Let us see a quick introduction to FL and its applications with Azure Machine
    Learning.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: FL with Azure Machine Learning
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When working in the cloud, FL can be easier than you might think. With on-demand
    compute and processing power come a lot of benefits. Especially with the `azureml`
    SDK v2, FL features are built in.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to integrate is by using designer pipelines. The designer has
    a drag-and-drop interface. With the new version of the SDK come several exciting
    features. We can create our own component very easily, and each component that
    you drag and drop in the pipeline can be run on a different compute target.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see a pipeline created in the designer
    from the pre-built samples. By clicking on a component, we can easily change the
    compute target from the **Pipeline interface** button by going to the **Run settings**
    option and choosing **Use other** **compute target**:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Changing the compute target in Azure Machine Learning](img/B21076_05_13.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – Changing the compute target in Azure Machine Learning
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: If we extend the functionality and train multiple models at the same time using
    different datasets, we have an FL implementation and multi-party computation.
    For compute, we can also leverage Azure confidential computing to make the implementation
    even more secure, but we will talk about securing Azure compute in Azure Machine
    Learning later in the book. This can also be extended to using multiple workspaces
    connected to the same or different data stores.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: The great thing about using FL with Azure Machine Learning is that you can still
    combine and apply all the metrics and techniques we have outlined in this chapter
    since we are still working within the workspace.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: FL recipes and examples
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'Find out more on how to implement Azure Machine Learning here: [https://github.com/Azure-Samples/azure-ml-federated-learning](https://github.com/Azure-Samples/azure-ml-federated-learning).'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Protecting sensitive data is a multi-faceted problem. There are ways and techniques
    to mitigate fairness and protect privacy work ethically and responsibly with AI,
    but the balance between prediction accuracy and data protection is very sensitive.
    If you add the complexity of choosing the right combination of techniques based
    on your data and algorithms, it can seem daunting.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we learned to identify different types of sensitive data and
    common techniques to remove or mask them. However, it is not always possible to
    completely eliminate them as they are useful for the model training process. In
    this case, there are several libraries available to help. We can use the SmartNoise
    SDK to introduce noise to our data and protect privacy, work with the Fairlearn
    SDK to mitigate fairness, and use the Responsible AI dashboard together with explainers
    to interpret our models. We ended this chapter by introducing the concept of FL
    and how to apply it using Azure Machine Learning.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: We can talk about data until the end of the book, but the truth is, there is
    only so much you can do in data processing. In the next chapter, we will focus
    on working with access to the data, the workspace, and the roles required for
    each part.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Run a Federated Learning Demo in 5* *mins*: [https://github.com/Azure-Samples/azure-ml-federated-learning/blob/main/docs/quickstart.md](https://github.com/Azure-Samples/azure-ml-federated-learning/blob/main/docs/quickstart.md)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Federated Learning with Azure Machine Learning, NVIDIA FLARE and MONAI* –
    Build session: [https://build.microsoft.com/en-US/sessions/5bd5120f-5239-450d-8a57-373efb43c0cf?source=sessions](https://build.microsoft.com/en-US/sessions/5bd5120f-5239-450d-8a57-373efb43c0cf?source=sessions)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Medical Imaging with Azure Machine Learning* *Demos*: [https://github.com/Azure/medical-imaging](https://github.com/Azure/medical-imaging)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 3: Securing and Monitoring Your AI Environment'
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to the cloud, there is more to security than data. In this part,
    you will learn how to secure identity and access and all the cloud infrastructure
    around your Azure Machine Learning resources. Then, you will learn how to automate
    those processes using MLOps practices and how to set up system monitoring to detect
    and resolve any security issues.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B21076_06.xhtml#_idTextAnchor141)*, Managing and Securing Access*'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B21076_07.xhtml#_idTextAnchor160)*, Managing and Securing your
    Azure Machine Learning Workspace*'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B21076_08.xhtml#_idTextAnchor176)*, Managing and Securing the
    MLOps Life Cycle*'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B21076_09.xhtml#_idTextAnchor189)*, Logging, Monitoring, and
    Threat Detection*'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
