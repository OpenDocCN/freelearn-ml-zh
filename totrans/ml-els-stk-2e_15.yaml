- en: '*Chapter 12*: Regression'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第12章*: 回归分析'
- en: In the previous chapter, we studied classification – one of the two supervised
    learning techniques available in the Elastic Stack. However, not all real-world
    applications of supervised learning lend themselves to the format required for
    classification. What if, for example, we wanted to predict the sales prices of
    apartments in our neighborhood? Or the amount of money a customer will spend in
    our online store? Notice that the value we are interested in here is not a discrete
    class, but instead is a value that can take a variety of continuous values in
    a range.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们研究了分类——Elastic Stack中可用的两种监督学习技术之一。然而，并非所有监督学习的实际应用都适合分类所需的格式。例如，如果我们想预测我们邻里的公寓销售价格？或者我们在线商店中客户将花费的金额？请注意，我们这里感兴趣的不是离散类别，而是一个可以在一定范围内取各种连续值的值。
- en: This is exactly the problem solved by regression analysis. Instead of predicting
    which class a given datapoint belongs to, we can predict a continuous value. Although
    the end goal is slightly different than that in classification, the underlying
    algorithm that is used for regression is the same as the one we examined for classification
    in the previous chapter. Thus, we already know a lot about how regression works
    from the foundations we built in [*Chapter 11*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*,
    Classification Analysis*
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是回归分析解决的问题。我们不是预测给定数据点属于哪个类别，而是预测一个连续值。尽管最终目标与分类中的目标略有不同，但用于回归的底层算法与我们在上一章中检查的分类算法相同。因此，我们已经从[*第11章*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*，分类分析*中建立的基础中了解了回归的工作原理。
- en: Because the result of regression is continuous values instead of a discrete
    class label like in the case of classification, the ways in which we evaluate
    the performance of a regression model are slightly different than the ways we
    examined for classification in the previous chapter. Instead of using confusion
    matrices and various metrics computed from the number of correctly labeled and
    mislabeled examples, we compute aggregate metrics that capture how far the continuous
    values predicted for our dataset are from the actual values in our dataset. We
    will take a closer look at how this works in practice and what measures are used
    later in this chapter.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由于回归分析的结果是连续值而不是分类中的离散类别标签，因此我们评估回归模型性能的方式与上一章中检查分类的方式略有不同。我们不是使用混淆矩阵和从正确标记和错误标记的示例数量计算的各种指标，而是计算汇总指标，这些指标捕捉了预测数据集中连续值与数据集中实际值之间的差距。我们将在本章后面更详细地探讨这一过程以及所使用的措施。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Using regression to predict house prices in a geographic location
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用回归分析预测地理位置的房价
- en: Understanding how decision trees can be applied to create regression models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解决策树如何应用于创建回归模型
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The material in this chapter will require an Elasticsearch cluster running version
    7.10.1 or later. Some examples may include screenshots or guidance about details
    that are only available in later versions of Elasticsearch. In such cases, the
    text will explicitly mention which later version is required to run the example.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的材料需要运行7.10.1或更高版本的Elasticsearch集群。一些示例可能包括截图或关于仅在Elasticsearch后续版本中可用的详细信息的指导。在这种情况下，文本将明确指出需要运行示例的后续版本。
- en: Using regression analysis to predict house prices
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用回归分析预测房价
- en: In the previous chapter, we examined the first of the two supervised learning
    methods in the Elastic Stack – classification. The goal of classification analysis
    is to use a labeled dataset to train a model that can predict a class label for
    a previously unseen datapoint. For example, we could train a model on historical
    measurements of cell samples coupled with information about whether or not the
    cell was malignant and use this to predict the malignancy of previously unseen
    cells. In classification, the class or **dependent variable** that we are interested
    in predicting is always a **discrete quantity**. In regression, on the other hand,
    we are interested in predicting a continuous variable.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们探讨了Elastic Stack中的两种监督学习方法中的第一种——分类。分类分析的目标是使用标记的数据集来训练一个模型，该模型可以预测先前未见过的数据点的类别标签。例如，我们可以在细胞样本的历史测量数据上训练一个模型，并附带有关细胞是否恶性的信息，然后使用它来预测先前未见过的细胞的恶性。在分类中，我们感兴趣预测的类别或**因变量**始终是一个**离散量**。另一方面，在回归中，我们感兴趣的是预测一个连续变量。
- en: 'Before we examine the theoretical underpinnings of regression a bit closer,
    let''s dive right in and do a practical walk-through of how to train a regression
    model in Elasticsearch. The dataset we will be using is available on Kaggle ([https://www.kaggle.com/harlfoxem/housesalesprediction](https://www.kaggle.com/harlfoxem/housesalesprediction))
    and describes the prices of houses sold in an area of Washington State in the
    United States between 2014 and 2015\. The original dataset has been modified slightly
    to make it easier to ingest into Elasticsearch and is available in the book''s
    GitHub repository here (https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition/blob/main/Chapter%2012%20-%20Regression%20Analysis/kc_house_data_modified.csv).
    We will get started as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们更深入地探讨回归的理论基础之前，让我们直接深入实践，看看如何在Elasticsearch中训练一个回归模型。我们将使用的数据集可在Kaggle上找到（[https://www.kaggle.com/harlfoxem/housesalesprediction](https://www.kaggle.com/harlfoxem/housesalesprediction)），描述了2014年至2015年间在美国华盛顿州某个地区出售的房价。原始数据集已稍作修改，以便更容易地导入Elasticsearch，并在本书的GitHub存储库中提供（[https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition/blob/main/Chapter%2012%20-%20Regression%20Analysis/kc_house_data_modified.csv]）。我们将按照以下步骤开始：
- en: Ingest the dataset into Elasticsearch using your preferred method. If you wish,
    you can use the **Upload file** functionality available in the **Machine** **Learning**
    app's **Data** **Visualizer** as shown in *Figure 12.1*:![Figure 12.1 – The Upload
    file functionality in the Machine Learning app's Data Visualizer
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您首选的方法将数据集导入Elasticsearch。如果您愿意，可以使用**机器学习**应用中的**数据可视化器**提供的**上传文件**功能，如图*图12.1*所示：![图12.1
    – 机器学习应用的数据可视化器中的上传文件功能
- en: '](img/B17040_12_1.jpg)'
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_12_1.jpg)'
- en: Figure 12.1 – The Upload file functionality in the Machine Learning app's Data
    Visualizer
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.1 – 机器学习应用的数据可视化器中的上传文件功能
- en: Once we have ingested this data, let's take a moment to examine it in the **Machine**
    **Learning** app's **Data** **Visualizer**. In this view, we can see at a glance
    what fields are present in the data and what the distribution of values is for
    each field. For example, for our house price dataset, we can see in a histogram
    visualization of the price values in *Figure 12.2* that most house prices in this
    dataset fall between 200,000 USD and 900,000 USD, with a small minority of houses
    selling for more than 900,000 USD:![Figure 12.2 – The distribution of values for
    the price field as shown in Data Visualizer
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们吸收了这些数据，让我们花一点时间在**机器学习**应用中的**数据可视化器**中检查它。在这个视图中，我们可以一眼看出数据中存在哪些字段以及每个字段的值分布情况。例如，对于我们的房价数据集，我们可以在*图12.2*中看到价格值的直方图可视化，这个数据集中大多数房价介于20万至90万美元之间，只有少数房子的售价超过90万美元：![图12.2
    – 数据可视化器中显示的价格字段的值分布
- en: '](img/B17040_12_2.jpg)'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_12_2.jpg)'
- en: Figure 12.2 – The distribution of values for the price field as shown in Data
    Visualizer
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.2 – 数据可视化器中显示的价格字段的值分布
- en: Looking at data values and distributions in **Data Visualizer** can quickly
    alert us to potential problems, such as invalid or missing values in a given field,
    with a dataset.
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在**数据可视化器**中查看数据值和分布可以迅速提醒我们潜在的问题，例如数据集中某个字段中的无效或缺失值。
- en: Next, let's navigate to the **Data Frame Analytics** wizard. In the left-hand
    side sliding menu in Kibana, click on **Machine Learning** to navigate to the
    **Machine Learning** app's main page. On this page, in the **Data Frame Analytics**
    jobs section, if you have not yet created a Data Frame Analytics job, click on
    the **Create job** button. If you have, first click on the **Manage jobs** button.
    This will take you to the **Data Frame Analytics** page, where you will find a
    list of existing Data Frame Analytics jobs (for example, if you had created any
    from following the walk-throughs in the previous chapters) and the **Create job**
    button.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，让我们导航到**数据帧分析**向导。在Kibana的左侧滑动菜单中，点击**机器学习**以导航到**机器学习**应用的主页。在此页面上，在**数据帧分析**作业部分，如果您尚未创建数据帧分析作业，请点击**创建作业**按钮。如果您已经有了，首先点击**管理作业**按钮。这将带您进入**数据帧分析**页面，在那里您将找到现有数据帧分析作业的列表（例如，如果您在上一章的演练中创建了任何作业）以及**创建作业**按钮。
- en: This will take you to the Data Frame Analytics wizard that we have already seen
    in[*Chapter 10*](B17040_10_Epub_AM.xhtml#_idTextAnchor177)*, Outlier Detection*,
    as well as in [*Chapter 11*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*, Classification
    Analysis*.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将带您进入我们已经在[*第10章*](B17040_10_Epub_AM.xhtml#_idTextAnchor177)“异常检测”以及[*第11章*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)“分类分析”中见过的数据帧分析向导。
- en: Once you have selected your source index pattern (this should match the name
    of the index pattern you selected when importing or uploading the data in *step
    1*), select **Regression** from the Data Frame Analytics wizard's job type selector
    as shown in *Figure 12.3*:![Figure 12.3 – Select Regression as the job type in
    the Data Frame Analytics job wizard selector
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您已选择您的源索引模式（这应该与您在*步骤1*中导入或上传数据时选择的索引模式名称相匹配），请从数据帧分析向导的作业类型选择器中选择**回归**，如图12.3所示：![图12.3
    – 在数据帧分析作业向导选择器中选择“回归”作为作业类型
- en: '](img/B17040_12_3.jpg)'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_12_3.jpg)'
- en: Figure 12.3 – Select Regression as the job type in the Data Frame Analytics
    job wizard selector
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.3 – 在数据帧分析作业向导选择器中选择“回归”作为作业类型
- en: Next, let's configure the `price` field.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们配置`价格`字段。
- en: After selecting the dependent variable, let's move on to selecting the fields
    that are going to be included or excluded from our analysis. While many of the
    fields in the dataset provide useful information for predicting the value of the
    dependent variable (`price`), *there are a* *few fields that we know from the
    beginning will not correlate with the price and thus should be removed*. The first
    of these is the ID (`id`) of the datapoint. It is simply a row number denoting
    the position of the datapoint in the original data file and thus is not expected
    to carry useful information. In fact, including it could result in more harm than
    good. For example, if the original data file were organized in such a way that
    all low-priced houses were situated at the beginning of the file with low `id`
    numbers and all high-priced houses at the end of the file, the model might consider
    the `id` datapoint important in determining the price of the house even though
    we know that this is nothing but an artifact of the dataset. This, in turn, would
    be detrimental to the model's performance on future, yet-unseen datapoints. If
    we assume that the `id` value of the datapoints is growing, any new datapoint
    added to the dataset would automatically have a higher `id` number than any datapoint
    in the training data and would thus lead to the model assuming that any new datapoint
    has a higher price.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在选择因变量之后，让我们继续选择将要包含或排除在分析中的字段。虽然数据集中的许多字段提供了对预测因变量（`价格`）有用的信息，但*有一些字段我们从一开始就知道它们与价格不相关，因此应该被移除*。这些字段中的第一个是数据点的ID（`id`）。它只是一个表示数据点在原始数据文件中位置的行号，因此不期望它包含有用的信息。实际上，包括它可能会带来更多的坏处而不是好处。例如，如果原始数据文件是以这样的方式组织的，即所有低价房屋都位于文件的开头，具有低的`id`编号，而所有高价房屋都位于文件末尾，那么模型可能会认为`id`数据点在确定房屋价格时很重要，尽管我们知道这仅仅是数据集的一个特征。这反过来又会损害模型在未来的、尚未看到的观测点上的性能。如果我们假设数据点的`id`值在增长，任何添加到数据集的新数据点都会自动具有比训练数据中任何数据点更高的`id`编号，因此会导致模型认为任何新的数据点价格更高。
- en: 'Additionally, we will also exclude information about the latitude and the longitude
    of the house''s location, since these variables cannot be interpreted as geographic
    locations by the machine learning algorithm and would thus be simply interpreted
    as numbers. The final configuration should look like *Figure 12.4*:'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，我们还将排除关于房屋位置纬度和经度的信息，因为这些变量不能被机器学习算法解释为地理位置，因此将被简单地解释为数字。最终的配置应如图*12.4*所示：
- en: '![Figure 12.4 – Fields that are not included in the analysis'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_12_4.jpg](img/B17040_12_4.jpg)'
- en: '](img/B17040_12_4.jpg)'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_12_4.jpg](img/B17040_12_4.jpg)'
- en: Figure 12.4 – Fields that are not included in the analysis
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.4 – 不包含在分析中的字段
- en: After configuring the dependent variable and the included and excluded fields,
    we can move on to the additional configuration items. While we will leave most
    of the values in this section set to the defaults, we will change the number for
    **Feature importance values** from *0* to *4*. If set to *0*, no feature importance
    values are written out. When set to *4*, four of the most important feature values
    are written out for each datapoint. As briefly discussed in [*Chapter 11*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*,
    Classification Analysis*, feature importance values are written out separately
    for each document and help to determine why the model classified a particular
    document in a particular way. We will return to this point slightly later in the
    chapter:![Figure 12.5 – Feature importance values configuration
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在配置了因变量以及包含和排除的字段后，我们可以继续进行其他配置项。虽然我们将在这个部分保留大部分值设置为默认值，但我们将**特征重要性值**的数量从*0*更改为*4*。如果设置为*0*，则不会输出任何特征重要性值。当设置为*4*时，每个数据点将输出四个最重要的特征值。如在第[*11章*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)“分类分析”中简要讨论的，特征重要性值将分别针对每个文档输出，有助于确定模型为何以特定方式对特定文档进行分类。我们将在本章稍后回到这一点：![图12.5
    – 特征重要性值配置
- en: '](img/B17040_12_5.jpg)'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_12_5.jpg](img/B17040_12_5.jpg)'
- en: Figure 12.5 – Feature importance values configuration
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.5 – 特征重要性值配置
- en: We leave the rest of the settings on the defaults and start running the job
    by scrolling to the bottom of the wizard and clicking the **Create and start**
    button.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将其他设置保留为默认值，并通过滚动到向导底部并点击**创建并启动**按钮来开始运行作业。
- en: After completing the steps in the wizard and creating and starting your job,
    navigate back to the **Data Frame Analytics** page. This will show you an overview
    of all of the Data Frame Analytics jobs you have created, including the regression
    job we created in the preceding steps. Once the job has completed, click on the
    menu on the right-hand side and click on **View** as shown in *Figure 12.6:*![Figure
    12.6 – Select View to see the results for the Data Frame Analytics job
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在完成向导中的步骤并创建并启动作业后，返回到**数据帧分析**页面。这将显示您创建的所有数据帧分析作业的概述，包括我们在前面的步骤中创建的回归作业。一旦作业完成，点击右侧菜单，然后点击**查看**，如图*12.6:*所示：![图12.6
    – 选择查看数据帧分析作业的结果
- en: '](img/B17040_12_6.jpg)'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_12_6.jpg](img/B17040_12_6.jpg)'
- en: Figure 12.6 – Select View to see the results for the Data Frame Analytics job
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.6 – 选择视图查看数据帧分析作业的结果
- en: 'This will take us to the **Exploration** page, which allows us to explore various
    metrics of the newly trained regression model. The first thing that requires attention
    on this page is the **Training**/**Testing** dataset toggle, which is displayed
    in *Figure 12.7*:'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将带我们进入**探索**页面，该页面允许我们探索新训练的回归模型的各项指标。在这个页面上需要特别注意的第一件事是**训练**/**测试**数据集切换，如图*12.7*所示：
- en: '![Figure 12.7 – The Training/Testing toggle in the Data Frame Analytics results
    viewer'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_12_7.jpg](img/B17040_12_7.jpg)'
- en: '](img/B17040_12_7.jpg)'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_12_7.jpg](img/B17040_12_7.jpg)'
- en: Figure 12.7 – The Training/Testing toggle in the Data Frame Analytics results
    viewer
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.7 – 数据帧分析结果查看器中的训练/测试切换
- en: It is important to keep this toggle in mind when viewing the metrics on the
    **Exploration** page, because the evaluation metrics of the model mean different
    things depending on which of the metrics is selected. In this case, we are interested
    in how the model will perform when it is trying to make predictions on previously
    unseen datapoints. The dataset that most closely approximates this is the testing
    dataset – in other words, the dataset that was not used in the training process.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在查看**探索**页面上的指标时，要注意这个切换，因为模型的评估指标根据所选的指标而意味着不同的事情。在这种情况下，我们感兴趣的是当模型试图对之前未见过的数据点进行预测时，其表现如何。最接近这一点的数据集是测试数据集——换句话说，即未用于训练过程的数据集。
- en: Let's scroll down and take a look at the **Model evaluation** metrics for the
    testing dataset, which is shown in *Figure 12.8*:![Figure 12.8 – The generalization
    error
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们向下滚动并查看测试数据集的**模型评估**指标，如图*图12.8*所示：![图12.8 – 泛化误差
- en: '](img/B17040_12_8.jpg)'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_12_8.jpg]'
- en: Figure 12.8 – The generalization error
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.8 – 泛化误差
- en: We will take a more detailed look at what each of these metrics means later
    in the chapter, but for now you can treat them as aggregate measures of how close
    the model's predictions of the house prices were to the actual house prices.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将在本章后面更详细地探讨这些指标的含义，但到目前为止，你可以将它们视为模型对房屋价格预测与实际房屋价格接近程度的综合度量。
- en: Finally, what might be of interest to many users is which of the fields in our
    dataset were most important in determining the final prediction of the model.
    We can see this by taking a look at the **Total feature importance** section on
    the **Exploration** page as shown in *Figure 12.9:*![Figure 12.9 – The total feature
    importance
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，许多用户可能感兴趣的是，我们数据集中哪些字段在确定模型的最终预测中最为重要。我们可以通过查看**探索**页面上的**总特征重要性**部分来了解这一点，如图*图12.9*所示：![图12.9
    – 总特征重要性
- en: '](img/B17040_12_9.jpg)'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_12_9.jpg]'
- en: Figure 12.9 – The total feature importance
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 – 总特征重要性
- en: As we can see from the figure, the most important factor in determining the
    sales price of a house in King Country in Washington State is `zip code`, or the
    location of the house. Among the least important factors are the year the house
    was renovated, `yt_renovated`, and the number of floors (`floors`) it has.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以看出，华盛顿州金郡的房屋销售价格最重要的因素是`zip code`，即房屋的位置。在不太重要的因素中包括房屋翻新年份`yt_renovated`和楼层数量（`floors`）。
- en: 'It is good to keep in mind that the features shown in this diagram are the
    most important features across the whole dataset. The features that determine
    the sales price of an individual datapoint in the dataset can, however, be very
    different. A bit earlier in this walk-through, during the creation of the job
    in the `4`. This means that after the model has been trained, the four most important
    feature importance values will be written out to the results index. Let''s take
    a look at a sample document in our results index, `king-county-houses-regression`.
    This document is shown in *Figure 12.10*:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，图中显示的特征是整个数据集中最重要的特征。然而，确定数据集中单个数据点的销售价格的特征可能会有很大不同。在这次讲解的早期，在创建`4`中的工作期间。这意味着在模型训练完成后，四个最重要的特征重要性值将被写入结果索引。让我们看一下结果索引中的样本文档，`king-county-houses-regression`。该文档如图*图12.10*所示：
- en: '![Figure 12.10 – Feature importance values for a sample document in the results
    index'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图12.10 – 结果索引中样本文档的特征重要性值'
- en: '](img/B17040_12_10.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17040_12_10.jpg]'
- en: Figure 12.10 – Feature importance values for a sample document in the results
    index
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.10 – 结果索引中样本文档的特征重要性值
- en: As we can see in *Figure 12.10*, for this particular house, the four most important
    feature values are `grade`, `sqft_living` (the amount of living space in the house
    measured in square feet), `yr_built` (the year the house was built), and `zipcode`
    (a numerical representation of the location of the house). One thing to note is
    that all of the feature importance values here are negative, which means that
    they contribute to lowering the price of the house.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在*图12.10*中可以看到，对于这所特定的房子，最重要的四个特征值是`grade`（评级）、`sqft_living`（以平方英尺计的房屋居住面积）、`yr_built`（房屋建造年份）和`zipcode`（房屋位置的数值表示）。需要注意的是，这里所有的特征重要性值都是负数，这意味着它们有助于降低房屋的价格。
- en: 'Let''s take a look at the top four feature importance values in another document
    (shown in *Figure 12.11*) in the results index and compare them to the previous
    feature importance values to see how much variation there can be:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一份文档（如图 *图 12.11* 所示）中的前四个特征重要性值在结果索引中的情况，并将它们与之前的特征重要性值进行比较，以了解可能存在多少变化：
- en: '![Figure 12.11 – The four most important features for determining the price
    of this house'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 12.11 – 确定这所房子价格最重要的四个特征'
- en: '](img/B17040_12_11.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_12_11.jpg)'
- en: Figure 12.11 – The four most important features for determining the price of
    this house
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.11 – 确定这所房子价格最重要的四个特征
- en: As we can see, the house represented by the document in *Figure 12.11* shares
    some features with the house in *Figure 12.10* but also has some unique ones.
    In addition, the feature importance values for this house affect its price positively.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，*图 12.11* 中的房屋与 *图 12.10* 中的房屋有一些共同的特征，但也有些独特的特征。此外，这个房屋的特征重要性值对其价格有积极的影响。
- en: Now that you have briefly seen how to train a regression model and evaluate
    its results, a natural question to ask is, what next? If you were using this model
    for a real-world use case, such as to predict the potential house prices of yet-unsold
    houses in King County or another geographic location, you could use inference
    to examine and deploy this model. This will be covered in greater detail in [*Chapter
    13*](B17040_13_Epub_AM.xhtml#_idTextAnchor236)*, Inference*. In the next section,
    we will briefly return to our discussion of decision trees that we began in [*Chapter
    11*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*, Classification Analysis*, and
    see how the ideas we developed in that chapter apply to regression problems.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经简要地看到了如何训练一个回归模型并评估其结果，一个自然的问题就是接下来该做什么？如果你使用这个模型进行实际应用，例如预测金县或其他地理位置尚未售出的房屋的潜在房价，你可以使用推理来检查和部署这个模型。这将在
    [*第 13 章*](B17040_13_Epub_AM.xhtml#_idTextAnchor236)*，推理* 中更详细地介绍。在下一节中，我们将简要回顾我们在
    [*第 11 章*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*，分类分析* 中开始的决策树讨论，并看看我们当时提出的想法如何应用于回归问题。
- en: Using decision trees for regression
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用决策树进行回归
- en: As we have discussed in the preceding chapters, regression is a supervised learning
    technique. As discussed in [*Chapter 11*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*,
    Classification Analysis*, the goal of supervised learning is to take a labeled
    dataset (for example, a dataset that has features of houses and their sales price
    – the dependent variable) and distill the knowledge in this data into an artifact
    known as a trained model. This trained model can then be used to predict the sales
    prices of houses that the model has not previously seen. When the dependent variable
    that we are trying to predict is a continuous variable, as opposed to a discrete
    variable, which is the domain of classification, we are dealing with regression.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中讨论的，回归是一种监督学习技术。正如在 [*第 11 章*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*，分类分析*
    中讨论的，监督学习的目标是接受一个标记的数据集（例如，具有房屋特征及其销售价格 – 因变量）的数据集，并将这些数据中的知识提炼成一个称为训练模型的人工制品。然后，这个训练模型可以用来预测模型之前未见过的房屋的销售价格。当我们试图预测的因变量是一个连续变量，而不是分类领域的离散变量时，我们就处于回归的状态。
- en: Regression – the task of distilling the information presented in real-world
    observations or data – is a field of machine learning that encompasses techniques
    far broader than the decision tree technique that is used in Elasticsearch's Machine
    learning functionality. However, we will limit ourselves here to a conceptual
    discussion of how regression can be carried out using decision trees (a simplified
    version of the process that takes place inside the Elastic Stack) and refer readers
    interested in learning more about regression to the literature. For example, the
    book *Mathematics for Machine Learning* (https://mml-book.github.io/) has a good
    introduction to regression.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 回归 – 从现实世界的观察或数据中提炼信息的过程 – 是机器学习的一个领域，它包含的技术远比在 Elasticsearch 的机器学习功能中使用的决策树技术更广泛。然而，在这里我们将限制自己只讨论如何使用决策树（Elastic
    Stack 内部发生过程的简化版本）进行回归的概念性讨论，并将对学习更多关于回归的读者推荐到相关文献。例如，书籍 *机器学习数学*（https://mml-book.github.io/）对回归有很好的介绍。
- en: 'In [*Chapter 11*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*, Classification
    Analysis*, we started our discussion of decision trees when applied to classification
    problems with a conceptual introduction of a flowchart that you might construct
    if you wanted to take houses and try and deduce what their sales price would be.
    An example fictional flowchart that you might construct is presented in *Figure
    12.12*:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第11章*](B17040_11_Epub_AM.xhtml#_idTextAnchor209)*，分类分析*中，我们开始讨论决策树在分类问题中的应用，通过介绍如果你想要尝试推断房屋的销售价格，可能会构建的流程图的概念。一个可能构建的虚构流程图的例子在*图12.12*中展示：
- en: '![Figure 12.12 – A sample flowchart that illustrates the decisions that you
    might make to try to predict the sales price of a house'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 12.12 – A sample flowchart that illustrates the decisions that you
    might make to try to predict the sales price of a house](Figure 12.12 – A sample
    flowchart that illustrates the decisions that you might make to try to predict
    the sales price of a house)'
- en: '](img/B17040_12_12.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17040_12_12.jpg](img/B17040_12_12.jpg)'
- en: Figure 12.12 – A sample flowchart that illustrates the decisions that you might
    make to try to predict the sales price of a house
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.12 – A sample flowchart that illustrates the decisions that you might make
    to try to predict the sales price of a house
- en: 'In the fictional flowchart shown in *Figure 12.12*, we have a sample house
    depicted by the box in the upper left-hand corner. This house has 5,000 square
    feet of living space, 5 bedrooms, and 5 bathrooms. We would like to predict the
    final sales price of the house based on these attributes and we are going to use
    the flowchart to help us. The way we do this in practice is we start at the top
    of the flowchart (or the root of the decision tree) and work our way downward
    toward the terminal nodes (the nodes that are not connected to any downstream
    nodes). Our sample house has a living area of 5,000 square feet, so we reply **Yes**
    for the first node and **Yes** again for the second child node. This leads to
    a terminal or a leaf node that contains the predicted price of our house: 956,000
    USD.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图12.12*所示的虚构流程图中，我们有一个由左上角方框表示的样本房屋。这个房屋有5,000平方英尺的居住空间，5个卧室和5个浴室。我们希望根据这些属性预测房屋的最终销售价格，并打算使用流程图来帮助我们。我们在实践中这样做的方式是，从流程图的顶部（或决策树的根）开始，逐步向下工作，直到终端节点（不连接任何下游节点的节点）。我们的样本房屋有5,000平方英尺的居住区，所以我们对于第一个节点回答**是**，对于第二个子节点再次回答**是**。这导致了一个终端或叶节点，其中包含我们房屋的预测价格：956,000美元。
- en: 'A natural question to ask is, how do we create a flowchart like the one in
    *Figure 12.12*? There are two ingredients required to create this flowchart (or
    decision tree): the labeled dataset, which contains features of each house and
    its sales price, and the training algorithm, which will take this dataset and
    use it to construct a populated flowchart or decision tree that can then be used
    to make price predictions for previously unseen houses (this is done using inference,
    which is covered in detail in [*Chapter 13*](B17040_13_Epub_AM.xhtml#_idTextAnchor236)*,
    Inference*).'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一个自然的问题是要问，我们如何创建像*图12.12*那样的流程图？创建此流程图（或决策树）需要两个要素：标记的数据集，其中包含每栋房屋的特征及其销售价格，以及训练算法，该算法将使用此数据集，并构建一个填充的流程图或决策树，然后可以用来对先前未见过的房屋进行价格预测（这是通过推理完成的，这在[*第13章*](B17040_13_Epub_AM.xhtml#_idTextAnchor236)*，推理*中详细说明）。
- en: The process of training a decision tree based on a labeled dataset involves
    creating nodes like the ones depicted in *Figure 12.12*. These nodes split the
    dataset into progressively smaller and smaller subsets until we reach a situation
    where each subset fulfills certain criteria. In the case of classification, the
    process of progressively splitting the training dataset is stopped when the subsets
    reach a certain purity. This can be measured using several different metrics that
    capture the proportion of datapoints that belong to a certain class in a node.
    The purest node is the kind that contains only datapoints belonging to a certain
    class.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 基于标记数据集训练决策树的过程涉及创建像*图12.12*中展示的节点。这些节点将数据集分成越来越小的子集，直到我们达到每个子集满足某些标准的情况。在分类的情况下，当子集达到一定的纯度时，逐步分割训练数据集的过程就会停止。这可以通过使用几个不同的指标来衡量，这些指标捕捉了节点中属于某一类的数据点的比例。最纯的节点是只包含属于某一类的数据点的节点。
- en: Since regression deals with continuous values, we cannot use purity as a measure
    to determine when to stop recursively splitting the dataset. Instead, we have
    another measure known as the loss function. A sample loss function for regression
    is the **mean squared error**. This measure captures how far the values predicted
    for the points falling in each node are from the actual errors.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由于回归处理连续值，我们不能使用纯度作为确定何时递归分割数据集的停止标准的度量。相反，我们有一个称为损失函数的另一个度量。回归的一个示例损失函数是**均方误差**。这个度量捕捉了预测值与每个节点中每个点的实际误差之间的距离。
- en: 'Finally, if were cursively split the dataset many times, we end up with a simplified
    decision tree as depicted in *Figure 12.13*:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果我们多次递归分割数据集，我们将得到如图12.13所示的简化决策树：
- en: '![Figure 12.13 – A simplified trained decision tree. The leaf nodes contain
    several datapoints'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![图12.13 – 一个简化的训练决策树。叶节点包含多个数据点'
- en: '](img/B17040_12_13.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_12_13.jpg)'
- en: Figure 12.13 – A simplified trained decision tree. The leaf nodes contain several
    datapoints
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.13 – 一个简化的训练决策树。叶节点包含多个数据点
- en: As we see in *Figure 12.13*, at the end of the training process the terminal
    node leaves contain several datapoints each.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在图12.13中看到的，在训练过程的最后，终端节点叶包含每个节点多个数据点。
- en: Summary
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Regression is the second of the two supervised learning methods in the Elastic
    Stack. The goal of regression is to take a trained dataset (a dataset that contains
    some features and a dependent variable that we want to predict) and distill it
    into a trained model. In regression, the dependent variable is a continuous value,
    which makes it distinct from classification, which handles discrete values. In
    this chapter, we have made use of the Elastic Stack's machine learning functionality
    to use regression to predict the sales price of a house based on a number of attributes,
    such as the house's location and the number of bedrooms. While there are numerous
    regression techniques available, the Elastic Stack uses gradient boosted decision
    trees to train a model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是Elastic Stack中两种监督学习方法中的第二种。回归的目标是将一个训练好的数据集（包含一些特征和我们要预测的因变量的数据集）提炼成一个训练好的模型。在回归中，因变量是一个连续值，这使得它与处理离散值的分类方法不同。在本章中，我们使用了Elastic
    Stack的机器学习功能，利用回归根据房屋的位置和卧室数量等属性预测房屋的销售价格。虽然有许多回归技术可用，但Elastic Stack使用梯度提升决策树来训练模型。
- en: In the next chapter, we will take a look at how supervised learning models can
    be used together with inference processors and ingest pipelines to create powerful,
    machine learning-powered data analysis pipelines.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨如何将监督学习模型与推理处理器和摄取管道结合使用，以创建强大的、由机器学习驱动的数据分析管道。
- en: Further reading
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For further information on how feature importance values are computed, please
    see the blogpost *Feature importance for data frame analytics with Elastic machine
    learning* here: https://www.elastic.co/blog/feature-importance-for-data-frame-analytics-with-elastic-machine-learning.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何计算特征重要性值的更多信息，请参阅此处博客文章 *使用Elastic机器学习进行数据框分析的特征重要性*：https://www.elastic.co/blog/feature-importance-for-data-frame-analytics-with-elastic-machine-learning。
- en: If you are looking for a more mathematical introduction to regression, please
    consult the book *Mathematics for Machine Learning*, available here [https://mml-book.github.io/](https://mml-book.github.io/).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在寻找回归的更数学化的介绍，请参阅此处可用的书籍 *机器学习数学* [https://mml-book.github.io/](https://mml-book.github.io/)。
