- en: Mathematics for Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the book, we are using several advanced algorithms that require a good background
    in mathematics. This appendix begins by describing some prerequisites, with Python
    implementations wherever required.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this appendix, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear algebraic operation and properties of vectors and matrices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability and common probabilistic functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Datasets and libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this appendix, we won't use a specific dataset; rather, we will use example
    values to show the workings. The libraries used are NumPy and scipy. In [Chapter
    2](prac-cv_ch02.html), *Libraries, Development Platform, and Datasets* we saw
    the installation of the Anaconda tool, which has both NumPy and SciPy; therefore,
    there is no need of a new installation.
  prefs: []
  type: TYPE_NORMAL
- en: 'If Anaconda is not installed, then to install Numpy and SciPy, use the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To plot a figure, we will use `matplotlib`. This also comes with Anaconda;
    however, if there is a need for installation, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To begin with the codes in the chapter, we will use this common import:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Linear algebra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computer vision tools and techniques are highly dependent on linear algebraic
    operations. We will use see an explanation of basic to advanced operations that
    are required in developing CV applications.
  prefs: []
  type: TYPE_NORMAL
- en: Vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a 2D plane, vectors are denoted as a point ![](img/020ab844-5f5d-4de5-8339-2cc76ebd72d2.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the magnitude of `p` is denoted as ![](img/9e346d48-09b8-4a5e-8835-3f1418d57213.png) and
    is given by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/33607bcc-a031-4f4b-9b36-0ddc696fb7d0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Python, a vector is denoted by a one-dimensional array, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the common properties required are length of the vector and magnitude
    of the vector, which is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Common vector operations are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Addition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subtraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector multiplication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector norm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orthogonality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Addition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s say there are two vectors denoted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting vector is the element-wise sum, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Subtraction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Subtraction is similar to addition; instead of the element-wise sum, we compute
    the element-wise difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Vector multiplication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two methods of computing vector multiplication:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inner product—this is also known as dot product and is the sum of element-wise
    products of two vectors:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/4489a6aa-c2be-478a-b863-374244d28164.png)'
  prefs: []
  type: TYPE_IMG
- en: Where  ![](img/fbc0fad0-c76a-4a6d-bacf-b94f56ef3ea7.png) and  ![](img/c0bd8e6e-8050-41f0-881f-e127dbc178f9.png)
    are ![](img/85401d86-2e14-4b89-bab8-089a4b3c0542.png)th elements of vectors ![](img/8e7755a1-b3f2-4cf4-a4b0-930607923da1.png)
    and ![](img/359233f1-8fcd-4c78-ab56-e5ad2b25f24f.png) respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, we can compute this using NumPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Outer product—this takes in two vectors and computes a matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/d3777a57-8a11-40c5-8166-cc0d0439b5f6.png) where each element `i`, `j`
    in *V[3]* is given as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/867ed238-0d5b-4156-9f5b-e704a88a2520.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Python we can compute this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Vector norm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A ![](img/fa4e3c9c-b6b4-4451-ad66-a76c56a501d2.png)th order norm of a vector
    *V* is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/657e7e9e-cf5e-4d23-9170-b38c904197ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are two popular kinds of norms for vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/650d12a4-fec9-4487-8293-2dd540d4f483.png) norm—this is given as ![](img/cb13a987-1b45-46ff-a011-fe8bae9f6e36.png) and
    an example is as shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/156cdc07-de10-409f-ad83-f55b15c4be1e.png) norm—this is given as ![](img/e9c191c5-0c1a-463f-883f-b42d74cc72e6.png) and
    an example is as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Orthogonality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Two vectors are said to be orthogonal if their inner product is zero. From
    the geometric point of view, if the two vectors are perpendicular, they are said
    to be orthogonal to each other:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two-dimensional arrays are referred to as matrices and, in computer vision,
    these play a significant role. An image in the digital world is represented as
    a matrix; hence, the operations that we will study here are applicable to images
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Matrix ![](img/87cc0af2-5de1-4537-9109-a3b43d5c8df5.png) is denoted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cf2d5797-d82c-4783-af6c-18c51b1d6156.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the shape of the matrix is m x n  with ![](img/10eaa40b-1f57-4ade-866d-e0f4567ff54d.png) rows
    and ![](img/f44f6cfc-e944-4dc7-9f10-08b3a8c31806.png) columns. If ![](img/71eb906d-a20f-4811-82fa-3c1bac00b478.png),
    the matrix is termed as a square matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, we can make a sample matrix, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This is printed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Operations on matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be performing similar operations on matrices as we did on vectors. The
    only difference will be in the way we perform these operations. To understand
    this in detail, go through the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Addition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to perform the addition of two matrices `A` and `B`, both of them
    should be of the same shape. The addition operation is an element-wise addition
    done to create a matrix `C` of the same shape as `A` and `B`. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Subtraction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to addition, subtracting matrix `B` from matrix `A` requires both of
    them to be of the same shape. The resulting matrix `C` will be of the same shape
    as `A` and `B`. The following is an example of subtracting `B` from `A`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Matrix multiplication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let there be two matrices: `A` with size *m x n*  and `B` with size *q x p*.
    The assumption here is that ![](img/02925eb1-b19c-467d-aaf3-ffbd710d3db6.png).
    Now, the two matrices of sizes *m x n* and *n x p* are compatible for matrix multiplication.
    The multiplication is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/85f9afbc-9a90-46f3-8251-560263f08e64.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, each element in ![](img/156acaf4-f860-4faf-bdbb-d454b7636383.png) is
    given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d78baab5-f8e8-4770-aeeb-afd5510d4bd6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is performed with Python, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Since matrix multiplication depends on the order of multiplication, reversing
    the order may result in a different matrix or an invalid multiplication due to
    size mismatch.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen the basic operations with matrices; now we will some properties
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix properties
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few properties that are used on matrices for executing mathematical
    operations. They are mentioned in detail in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Transpose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we interchange columns and rows of a matrix with each other, the resulting
    matrix is termed as the transpose of the matrix and is denoted as ![](img/c1354917-508e-4b04-b062-0417ea7b9138.png),
    for an original matrix ![](img/4ef088d6-9beb-4aa1-9061-c3e86d79d624.png). An example
    of this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Identity matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is a special kind of matrix with diagonal elements as `1` and all other
    elements as zero:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: An interesting property of the identity matrix is that it doesn't modify target
    matrix after multiplication, that is  ![](img/ae534000-7fe4-42c5-87a9-22c0b85136bc.png) or ![](img/6ab373f5-b9ba-41c2-ad46-0f81c7bcf5fb.png) will
    result in ![](img/dbdcff17-60f6-4cb0-a474-59c2593751d3.png).
  prefs: []
  type: TYPE_NORMAL
- en: Diagonal matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Extending the definition of an identity matrix, in a diagonal matrix, the entries
    of a matrix along the main diagonal are non-zero and the rest of the values are
    zero. An example is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Symmetric matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a symmetric matrix, the elements follow a property: ![](img/a81e61a1-073e-4fc9-b921-558404d57d1a.png).
    This element wise property for a given symmetric matrix ![](img/dcba0d39-a0c9-48c1-9199-89644596afe5.png), can
    also be defined in terms of a transpose as ![](img/3b5d0f91-d7a5-40d7-b772-4d2b13ccfd9e.png).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider an asymmetric square matrix (with size *n x n *) given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Its transpose can be computed, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We can show that ![](img/04422d51-ef98-4847-975d-ee83dab65d11.png) is a symmetric
    matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that the elements ![](img/f7fb4de1-e365-4884-b210-b4ae1a41576b.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, we can compute anti-symmetric matrix as ![](img/9a658818-17ce-4ad9-9cfc-b9a4d861c36e.png),
    where each element ![](img/2bed7459-9f42-4084-8224-eea4b2fd16af.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'An important property arises from this; we can break any square matrix into
    a summation of symmetric and anti-symmetric matrix, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/800c93cd-badb-4cd2-b800-aa8b046d1016.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Continuing the Python Scripts as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Trace of a matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The trace of a matrix is the sum of all its diagonal elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Determinant
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Geometrically, the absolute value of a determinant of a matrix is the volume
    enclosed by taking each row as a vector. This can be computed, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Norm of a matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Continuing the norm formulation from the previous section on vectors, in a
    matrix, the most common type of norm is the Frobenius norm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7b0bbb7c-1e44-4b11-b6d6-385e3e057b2b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Python we compute this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Getting the inverse of a matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An inverse of a matrix, denoted as ![](img/e2331019-1793-48d8-8d78-67303b16eb8c.png),
    has an interesting property; ![](img/00c984ab-d764-4889-a631-96f2b7d0e825.png).
    The inverse is unique for each matrix; however, not all matrices have inverse
    matrices. An example of inverse of matrix is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we take a product of ![](img/d42cff23-486b-4408-9b4c-2b6184a48542.png) and
    ![](img/abe60ef9-ac86-49a6-9342-21a209fdcec3.png), we get the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the diagonal elements are `1` and all others are approximately
    `0`.
  prefs: []
  type: TYPE_NORMAL
- en: Orthogonality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another property associated with a square matrix is orthogonality, where ![](img/cabcfb29-1bb2-4614-92bc-a0dca5ae5e01.png) or![](img/84222b8f-b739-42a3-a941-2e921315fb59.png).
    This is also leads to ![](img/6d9cc25f-6b55-4919-a0a4-18ef3d5c0f82.png).
  prefs: []
  type: TYPE_NORMAL
- en: Computing eigen values and eigen vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The eigenvalue λ of a square matrix `A` has the property such that any transformation
    on it with eigen vector ![](img/d45a8fdd-3757-4214-9f27-8e87b8f0c9fc.png) is equal
    to the scalar multiplication of ![](img/0ba4f1bd-e748-408e-b5dc-c1c0ff8ad46e.png) with
    ![](img/220778cc-0dae-4349-a55a-aaec4ecacd56.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d7b43bee-2210-4bb8-89f1-05c194771b3e.png) where ![](img/a248ac34-737a-4e02-ba46-e1223b3da5a2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To compute eigenvalues and eigen vectors of ![](img/3a80067e-3bba-4517-b190-dc8cf1c61947.png),
    we need to solve the characteristic equation, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4b1aacfb-1ddc-482e-96f9-a72bcc321967.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/5b4a4312-b4c4-48b6-ace8-4394d7cbe8a6.png) is an identity matrix
    of the same size as ![](img/d5c33285-fda9-49db-bb3c-ca45a9126974.png):'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can do this using NumPy as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Hessian matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A first-order gradient matrix of ![](img/252b67d7-9a15-4d7f-b814-30b2d6bd1ff4.png) is
    formed by computing partial gradients on each element of `A`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e71b6667-5161-44cb-a7f1-5b66cf4b07c2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, the second-order gradient of ![](img/30829119-fa88-42fa-ba63-11d705719f15.png)
    for a function ![](img/3360cf59-6e94-4961-a422-100b4d09474a.png) is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e94cae52-f606-4645-9889-8d888fbe9e8f.png)'
  prefs: []
  type: TYPE_IMG
- en: The Hessian is denoted by ![](img/e40ac39a-fb49-40fa-b29e-ce6ed61b6b77.png).
  prefs: []
  type: TYPE_NORMAL
- en: Singular Value Decomposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Singular Value Decomposition** (**SVD**) is used to perform decomposition
    of a matrix ![](img/4d0709dd-1f76-44d0-9316-5348c2de806a.png) into ![](img/e8390785-e3c4-4ce9-b49f-c5825964fe5d.png),
    where ![](img/848a59e4-cddc-4613-a63b-a62ba437d1cf.png) and ![](img/25546536-ba98-46fe-a70e-e0629ba170bf.png) are
    orthogonal matrices and ![](img/9a7c0bfc-41b6-4e73-9931-bbd72f06dcf0.png) is a
    diagonal matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Introduction to probability theory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have studied probability in several courses through university or elsewhere.
    In this section, the aim is to fill in the gaps, so that computer vision algorithms
    that require probability theory can be easily built upon. The motivation to use
    probability theory in computer vision is to model uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: What are random variables?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Random variables are used to define the possibilities of an event in terms
    of real numbers. The values it can represent are random and, by applying certain
    assumptions, we can restrict it to given range. To get started with random variables,
    we need to either compute a function that approximates its behavior or assume
    and prove our hypothesis function through experimentation. These functions are
    of two types:'
  prefs: []
  type: TYPE_NORMAL
- en: In the discrete domain, random variables' values are discrete. Then the function
    used to model probabilities is termed as **Probability Mass Function** (**PMF**).
    For example, let ![](img/9a01c3a0-eec6-4889-961d-c0da2b1470c6.png) be a discrete
    random variable; its PMF is given by ![](img/ff30e722-e6ec-4526-bd44-a0c6895111dc.png),
    where ![](img/bad0294c-856d-4618-929e-b5dbe45a0dbd.png) is one of the ![](img/c79dbb2a-3a00-402f-b5ac-65c7dc7bd62d.png) different
    values of random variable ![](img/8b6ddfc2-2316-46f4-afe3-72955b56d19e.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the continuous domain, the function to model random variable's is termed
    as **Probability Density Function** (**PDF**), which takes in continuous domain
    values of a random variable ![](img/830f3962-3ffb-4fd5-8bba-4e8c9cd8eed6.png) to
    produce probabilities ![](img/3f393ffc-a85a-4d72-a746-9a8e540fa587.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expectation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For a discrete random variable ![](img/4a3fc903-dc58-4ab1-aeea-6296a683f2c8.png),
    the expectation of a function ![](img/49c8958c-35d2-4ce9-a0ea-10950c4b42a4.png) is
    given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3932fda6-f162-4fc6-9b5b-04db0358cee7.png)'
  prefs: []
  type: TYPE_IMG
- en: Here ![](img/0d6376c4-f74e-46f0-8bd2-4131840e9394.png) is the probability mass
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a continuous random variable ![](img/7e0bcb65-173d-4aec-aa38-3db40c04d902.png),
    the expectation of a function ![](img/ea870582-c36b-4485-9876-53f1459d468d.png)
    is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/617c943b-f4df-4909-9770-00853adc5ae2.png)'
  prefs: []
  type: TYPE_IMG
- en: Variance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To measure the quality of concentration of a random variable ![](img/885c3976-994e-493b-ba91-a1e53ba82a8f.png),
    we use variance. Mathematically, it is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a6e2059f-4674-43db-914d-4f76603c2ae7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This expression can also be converted into:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d9ed2c7-2694-46fa-8d1e-233f576ec14d.png)'
  prefs: []
  type: TYPE_IMG
- en: Probability distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The distributions are explained in detail in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Bernoulli distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Bernoulli distribution the function is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e07a7462-9aa4-433c-995a-3143f17ab841.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the parameter is ![](img/62cf1039-437b-4928-a5d1-82e27f8067cb.png) and
    we can model this using SciPy as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Binomial distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Binomial distribution the function is given as ![](img/cd0407f9-c2ea-45e5-a434-c1164b75fb6c.png),
    with parameters ![](img/d6466402-c319-4dd8-8979-a002babd6b44.png) and ![](img/90b4a68f-cdd6-483a-bfe7-9bc978c1e941.png).
    We can model this using SciPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting plot can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53b2d56d-4ffe-434a-bd24-dd3d157ecf41.png)'
  prefs: []
  type: TYPE_IMG
- en: Poisson distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The function for Poisson distribution is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eda0303f-9dfe-48b3-95a8-30e92e16b832.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the parameter is λ and an example script in SciPy is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Uniform distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A distribution between ![](img/f6ad6b2a-a777-43d9-bc93-18842871818e.png) and
    ![](img/24a9c917-ce4a-4eb0-a14e-0d11cf6f4c21.png) is said to be uniform if it
    follows this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/25e11e52-31f6-4c46-8683-7c851df4bfed.png)'
  prefs: []
  type: TYPE_IMG
- en: Gaussian distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the most common distributions used in computer vision, Gaussian distribution
    is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/877da509-4fc8-4635-865e-5ea55f1b3c48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the parameters are ![](img/cb1138b5-e95d-4376-a4fc-1c3e0ac8d705.png) and
    ![](img/9695bc95-5359-477a-b276-7ce73f53a5ae.png), which are also termed as **mean**
    and **variance**. A special case arises when ![](img/e50c4f52-d4d3-4a48-a446-991f017e264c.png) is
    0 and ![](img/be5b9734-f354-4293-aa18-54186638d44b.png) is 1.0; it is termed as
    normal distribution. Using SciPy, we can model it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting plot can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/615b50ed-da31-48d6-b2d0-5e3598733e79.png)'
  prefs: []
  type: TYPE_IMG
- en: Joint distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Joint distribution is used for two random variables, if we would like to find
    the effective probabilities if the two events associated with them happen together.
    Let ![](img/583cced1-d114-4365-b4c4-4ab479196da6.png) and ![](img/a895bbe7-4e82-444a-bb67-6bed9d650eee.png) be
    the two random variables; their joint distribution function is given by ![](img/a88bba39-7cfc-437e-b205-617fd6a5ccb0.png).
  prefs: []
  type: TYPE_NORMAL
- en: Marginal distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the case of joint distribution, we want to know the probability density
    function of one event assuming we can observe all the other events. We term this
    marginal distribution and it is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/615b89e2-0bb5-43d9-b042-d083b710566f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For a discrete case, the marginal distribution is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b08724e4-5e11-46d5-b394-54552f1662b0.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we are finding the marginal distribution of ![](img/e38f26ce-d07f-49fe-a830-86a084b9a140.png) with
    respect to ![](img/34322146-e6c1-4ca3-a8be-81b74f8cd781.png).
  prefs: []
  type: TYPE_NORMAL
- en: Conditional distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We would like to compute the probabilities after having known the values of
    one of the random variables. This is denoted mathematically as ![](img/e149697a-3c81-4283-9827-5cc52c24584e.png) for
    the known variable ![](img/fd3f73fe-d7ac-48d1-a80e-7a31765112c5.png), and a relation
    with joint probability distribution is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8a6535a4-9819-4bb0-90a1-b2910400a616.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/8746fc5e-4f15-4580-955a-7d0d61c65832.png) is the joint distribution
    and ![](img/f33a3678-5b00-4ed4-9673-8a66fac834b5.png) is the marginal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Bayes theorem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An important theorem used implicitly in many computer vision applications is
    Bayes theorem, which extends conditional probabilities as follows in the case
    of a continuous random variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/888b97d4-6e14-4c89-89a8-e17560a14751.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7834e1e0-6092-43b6-bbdc-2188b1b65e54.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this appendix, we explained some prerequisites for computer vision algorithms.
    Linear algebraic expressions explained here are used in geometric modifications
    of image, such as translation, rotation, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic approaches are used in a range of applications including, but
    not limited to, object detection, segmentation, and tracking applications. As
    such, having a good understanding of these prerequisites will make our application
    implementation faster and more efficient.
  prefs: []
  type: TYPE_NORMAL
