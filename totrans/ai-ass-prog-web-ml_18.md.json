["```py\nimport pandas as pd \n\n# Replace <file-path> with the path of your dataset \nfile_path = \"<file-path>\" \n\n# Load the dataset \ndf = pd.read_csv(file_path) \n\n# Display the first few rows of the dataset \nprint(df.head()) \n```", "```py\nimport pandas as pd \n\n# Replace <file-path> with the path of your dataset \nfile_path = \"/your-path/.csv\" \n\n# Load the dataset \ndf = pd.read_csv(file_path) \n\n# Display the first few rows of the dataset \nprint(df.head()) \n```", "```py\n Date  Close/Last     Volume      Open      High       Low \n0  02/28/2020     $273.36  106721200   $257.26   $278.41   $256.37 \n1  02/27/2020     $273.52   80151380    $281.1      $286   $272.96 \n2  02/26/2020     $292.65   49678430   $286.53   $297.88    $286.5 \n3  02/25/2020     $288.08   57668360   $300.95   $302.53   $286.13 \n4  02/24/2020     $298.18   55548830   $297.26   $304.18   $289.23 \n```", "```py\n# Check the data types of each column \nprint(df.dtypes) \n```", "```py\n# Check the data types of each column \nprint(df.dtypes) \nDate           object \nClose/Last    object \nVolume         int64 \nOpen          object \nHigh          object \nLow           object \ndtype: object \n```", "```py\n# Convert 'Date' to datetime \ndf['Date'] = pd.to_datetime(df['Date']) \n\n# Remove $ from price columns and convert to float \nprice_columns = [' Close/Last', ' Open', ' High', ' Low'] \nfor col in price_columns: \n    df[col] = df[col].str.replace('$', '').astype(float) \n\n# Check the data types again \nprint(df.dtypes) \n```", "```py\n# Convert 'Date' to datetime \ndf['Date'] = pd.to_datetime(df['Date']) \n\n# Remove $ from price columns and convert to float \nprice_columns = [' Close/Last', ' Open', ' High', ' Low'] \nfor col in price_columns: \n    df[col] = df[col].str.replace('$', '').astype(float) \n\n# Check the data types again \nprint(df.dtypes) \n```", "```py\nDate           datetime64[ns] \nClose/Last           float64 \nVolume                 int64 \nOpen                 float64 \nHigh                 float64 \nLow                  float64 \ndtype: object \n```", "```py\n# Check for missing values \nprint(df.isnull().sum()) \n```", "```py\n# Check for missing values \nprint(df.isnull().sum()) \n```", "```py\nDate           0 \nClose/Last    0 \nVolume        0 \nOpen          0 \nHigh          0 \nLow           0 \ndtype: int64 \n```", "```py\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n# Set up the matplotlib figure \nf, axes = plt.subplots(2, 2, figsize=(15, 10)) \n\n# Plot a simple histogram with binsize determined automatically \nsns.boxplot(data=df[' Close/Last'], ax=axes[0, 0]) \naxes[0, 0].set_title('Close/Last') \n\nsns.boxplot(data=df[' Open'], ax=axes[0, 1]) \naxes[0, 1].set_title('Open') \n\nsns.boxplot(data=df[' High'], ax=axes[1, 0]) \naxes[1, 0].set_title('High') \n\nsns.boxplot(data=df[' Low'], ax=axes[1, 1]) \naxes[1, 1].set_title('Low') \n\nplt.tight_layout() \n```", "```py\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n# Set up the matplotlib figure \nf, axes = plt.subplots(2, 2, figsize=(15, 10)) \n\n# Plot a simple histogram with binsize determined automatically \nsns.boxplot(data=df[' Close/Last'], ax=axes[0, 0]) \naxes[0, 0].set_title('Close/Last') \n\nsns.boxplot(data=df[' Open'], ax=axes[0, 1]) \naxes[0, 1].set_title('Open') \n\nsns.boxplot(data=df[' High'], ax=axes[1, 0]) \naxes[1, 0].set_title('High') \n\nsns.boxplot(data=df[' Low'], ax=axes[1, 1]) \naxes[1, 1].set_title('Low') \n\nplt.tight_layout() \n```", "```py\n# Calculate the correlation matrix \ncorr = df.corr() \n\n# Plot the heatmap \nsns.heatmap(corr, annot=True, cmap='coolwarm') \n\nplt.show() \n```", "```py\n# Calculate the correlation matrix \ncorr = df.corr() \n\n# Plot the heatmap \nsns.heatmap(corr, annot=True, cmap='coolwarm') \n\nplt.show() \n```", "```py\nfrom sklearn.model_selection import train_test_split \n\n# Define the feature variables and the target variable \nX = df.drop(' Close/Last', axis=1) \ny = df[' Close/Last'] \n\n# Split the data into training set and test set \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n```", "```py\nfrom sklearn.model_selection import train_test_split \n\n# Define the feature variables and the target variable \nX = df.drop(' Close/Last', axis=1) \ny = df[' Close/Last'] \n\n# Split the data into training set and test set \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n```", "```py\n# Print the shape of the training set and the test set \nprint(\"Training set (X):\", X_train.shape) \nprint(\"Training set (y):\", y_train.shape) \nprint(\"Test set (X):\", X_test.shape) \nprint(\"Test set (y):\", y_test.shape) \n```", "```py\n# Print the shape of the training set and the test set \nprint(\"Training set (X):\", X_train.shape) \nprint(\"Training set (y):\", y_train.shape) \nprint(\"Test set (X):\", X_test.shape) \nprint(\"Test set (y):\", y_test.shape) \n```", "```py\nTraining set (X): (2014, 5) \nTraining set (y): (2014,) \nTest set (X): (504, 5) \nTest set (y): (504,) \n```", "```py\nfrom sklearn.linear_model import LinearRegression \n\n# Create a Linear Regression model \nmodel = LinearRegression() \n\n# Train the model \nmodel.fit(X_train, y_train) \n```", "```py\nfrom sklearn.linear_model import LinearRegression \n\n# Create a Linear Regression model \nmodel = LinearRegression() \n\n# Train the model \nmodel.fit(X_train, y_train) \n```", "```py\n--------------------------------------------------------------------------- \nDTypePromotionError                       Traceback (most recent call last) \n\nFile ~/.conda/envs/myenv/lib/python3.12/site-packages/sklearn/base.py:1152, in _fit_context.<locals>.decorator.<locals>.wrapper(estimator, *args, **kwargs) \n   1145     estimator._validate_params() \n   1147 with config_context( \n   1148     skip_parameter_validation=( \n   1149         prefer_skip_nested_validation or global_skip_validation \n   1150     ) \n   1151 ): \n-> 1152     return fit_method(estimator, *args, **kwargs) \n\nFile ~/.conda/envs/myenv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:678, in LinearRegression.fit(self, X, y, sample_weight) \n    674 n_jobs_ = self.n_jobs \n    676 accept_sparse = False if self.positive else [\"csr\", \"csc\", \"coo\"] \n--> 678 X, y = self._validate_data( \n    679     X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True \n    680 ) \n    682 has_sw = sample_weight is not None \n    683 if has_sw: \n\nFile ~/.conda/envs/myenv/lib/python3.12/site-packages/sklearn/base.py:622, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params) \n    620         y = check_array(y, input_name=\"y\", **check_y_params) \n    621     else: \n--> 622         X, y = check_X_y(X, y, **check_params) \n    623     out = X, y \n    625 if not no_val_X and check_params.get(\"ensure_2d\", True): \n\nFile ~/.conda/envs/myenv/lib/python3.12/site-packages/sklearn/utils/validation.py:1146, in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator) \n   1141         estimator_name = _check_estimator_name(estimator) \n   1142     raise ValueError( \n   1143         f\"{estimator_name} requires y to be passed, but the target y is None\" \n   1144     ) \n-> 1146 X = check_array( \n   1147     X, \n   1148     accept_sparse=accept_sparse, \n   1149     accept_large_sparse=accept_large_sparse, \n   1150     dtype=dtype, \n   1151     order=order, \n   1152     copy=copy, \n   1153     force_all_finite=force_all_finite, \n   1154     ensure_2d=ensure_2d, \n   1155     allow_nd=allow_nd, \n   1156     ensure_min_samples=ensure_min_samples, \n   1157     ensure_min_features=ensure_min_features, \n   1158     estimator=estimator, \n   1159     input_name=\"X\", \n   1160 ) \n   1162 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator) \n   1164 check_consistent_length(X, y) \n\nFile ~/.conda/envs/myenv/lib/python3.12/site-packages/sklearn/utils/validation.py:795, in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name) \n    791 pandas_requires_conversion = any( \n    792     _pandas_dtype_needs_early_conversion(i) for i in dtypes_orig \n    793 ) \n    794 if all(isinstance(dtype_iter, np.dtype) for dtype_iter in dtypes_orig): \n--> 795     dtype_orig = np.result_type(*dtypes_orig) \n    796 elif pandas_requires_conversion and any(d == object for d in dtypes_orig): \n    797     # Force object if any of the dtypes is an object \n    798     dtype_orig = object \n\nDTypePromotionError: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class \n'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>) \n```", "```py\nCell 39 line 7 4 model = LinearRegression() 6 # Train the model ----> 7 model.fit(X_train, y_train) \nFile ~/.conda/envs/myenv/lib/python3.12/site-packages/sklearn/base.py:1152, in _fit_context..decorator..wrapper(estimator, *args, **kwargs) 1145 estimator._validate_params() 1147 with config_context( 1148 skip_parameter_validation=( 1149 prefer_skip_nested_validation or global_skip_validation 1150 ) 1151 ): -> 1152 return fit_method(estimator, *args, **kwargs) \nFile ~/.conda/envs/myenv/lib/python3.12/site-packages/sklearn/linear_model/base.py:678, in LinearRegression.fit(self, X, y, sample_weight) 674 n_jobs = self.n_jobs 676 accept_sparse = False if self.positive else [\"csr\", \"csc\", \"coo\"] --> 678 X, y = self._validate_data( 679 X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True 680 ) 682 has_sw = sample_weight is not None 683 if has_sw: ... 796 elif pandas_requires_conversion and any(d == object for d in dtypes_orig): 797 # Force object if any of the dtypes is an object 798 dtype_orig = object \nDTypePromotionError: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is object. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>) \n```", "```py\n# Extract features from 'Date' \nX_train['Year'] = X_train['Date'].dt.year \nX_train['Month'] = X_train['Date'].dt.month \nX_train['Day'] = X_train['Date'].dt.day \n\n# Drop the original 'Date' column \nX_train = X_train.drop('Date', axis=1) \n\n# Do the same for the test set \nX_test['Year'] = X_test['Date'].dt.year \nX_test['Month'] = X_test['Date'].dt.month \nX_test['Day'] = X_test['Date'].dt.day \nX_test = X_test.drop('Date', axis=1) \n\n# Now try to fit the model again \nmodel.fit(X_train, y_train) \n```", "```py\n# Extract features from 'Date' \nX_train['Year'] = X_train['Date'].dt.year \nX_train['Month'] = X_train['Date'].dt.month \nX_train['Day'] = X_train['Date'].dt.day \n\n# Drop the original 'Date' column \nX_train = X_train.drop('Date', axis=1) \n\n# Do the same for the test set \nX_test['Year'] = X_test['Date'].dt.year \nX_test['Month'] = X_test['Date'].dt.month \nX_test['Day'] = X_test['Date'].dt.day \nX_test = X_test.drop('Date', axis=1) \n\n# Now try to fit the model again \nmodel.fit(X_train, y_train) \nLinearRegression() \n```", "```py\nfrom sklearn import metrics \nimport numpy as np \n\n# Make predictions on the test data \ny_pred = model.predict(X_test) \n\n# Calculate MAE, MSE, RMSE, and R2 \nmae = metrics.mean_absolute_error(y_test, y_pred) \nmse = metrics.mean_squared_error(y_test, y_pred) \nrmse = np.sqrt(mse) # or metrics.mean_squared_error(y_test, y_pred, squared=False) \nr2 = metrics.r2_score(y_test, y_pred) \n\n# Print the metrics \nprint(\"Mean Absolute Error (MAE):\", mae) \nprint(\"Mean Squared Error (MSE):\", mse) \nprint(\"Root Mean Squared Error (RMSE):\", rmse) \nprint(\"R-squared (R2 ):\", r2) \n```", "```py\nfrom sklearn import metrics \nimport numpy as np \n\n# Make predictions on the test data \ny_pred = model.predict(X_test) \n\n# Calculate MAE, MSE, RMSE, and R2 \nmae = metrics.mean_absolute_error(y_test, y_pred) \nmse = metrics.mean_squared_error(y_test, y_pred) \nrmse = np.sqrt(mse) # or metrics.mean_squared_error(y_test, y_pred, squared=False) \nr2 = metrics.r2_score(y_test, y_pred) \n\n# Print the metrics \nprint(\"Mean Absolute Error (MAE):\", mae) \nprint(\"Mean Squared Error (MSE):\", mse) \nprint(\"Root Mean Squared Error (RMSE):\", rmse) \nprint(\"R-squared (R2 ):\", r2) \n```", "```py\nMean Absolute Error (MAE): 0.458844690389933 \nMean Squared Error (MSE): 0.4236006011305136 \nRoot Mean Squared Error (RMSE): 0.6508460656180642 \nR-squared (R2 ): 0.999868004623502 \n```", "```py\nBelow is the output, Mean Absolute Error (MAE): 0.458844690389933 Mean Squared Error (MSE): 0.4236006011305136 Root Mean Squared Error (RMSE): 0.6508460656180642 R-squared (R2 ): 0.999868004623502 \n```", "```py\nimport matplotlib.pyplot as plt \n\n# Plot the actual values \nplt.scatter(X_test.index, y_test, color='blue', label='Actual') \n\n# Plot the predicted values \nplt.scatter(X_test.index, y_pred, color='red', label='Predicted') \n\nplt.title('Actual vs Predicted') \nplt.xlabel('Index') \nplt.ylabel('Target') \nplt.legend() \nplt.show() \n```", "```py\nimport matplotlib.pyplot as plt \n\n# Plot the actual values \nplt.scatter(X_test.index, y_test, color='blue', label='Actual') \n\n# Plot the predicted values \nplt.scatter(X_test.index, y_pred, color='red', label='Predicted') \n\nplt.title('Actual vs Predicted') \nplt.xlabel('Index') \nplt.ylabel('Target') \nplt.legend() \nplt.show() \n```"]