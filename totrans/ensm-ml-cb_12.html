<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Homogenous Ensemble for Multiclass Classification Using Keras</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">In this chapter, we'll cover the following recipe:</span></p>
<ul class="calibre10">
<li class="calibre11">An ensemble of homogeneous models to classify fashion products</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">Many studies have been done in classification problems to find out how to obtain better classification accuracy. This problem tends to be more complex when there's a large number of classes on which to make a prediction. In the case of multiclass classification, it's assumed that each class in the target variable are independent of each other. A multiclass classification technique involves training one or more models to classify a target variable that can take more than two classes.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An ensemble of homogeneous models to classify fashion products</h1>
                </header>
            
            <article>
                
<p class="calibre2">In this example, we'll use the Fashion-MNIST dataset. <span class="calibre5">This dataset has 60,000 images of fashion products from ten categories.</span> <span class="calibre5">The target variable can be classified into ten classes:</span></p>
<ul class="calibre10">
<li class="calibre11"><span>T-shirt/top </span></li>
<li class="calibre11"><span>Trouser </span></li>
<li class="calibre11"><span><span>Pullover </span></span></li>
<li class="calibre11"><span>Dress </span></li>
<li class="calibre11"><span>Coat </span></li>
<li class="calibre11"><span>Sandal </span></li>
<li class="calibre11"><span>Shirt </span></li>
<li class="calibre11"><span>Sneakers</span></li>
<li class="calibre11"><span>Bag </span></li>
<li class="calibre11"><span>Ankle boot</span></li>
</ul>
<p class="calibre2">Each image is <span class="calibre5">a </span>28 x 28 grayscale image. We will proceed by reading the data to build a few homogeneous models over a few iterations to see whether the ensemble can deliver a higher accuracy.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="calibre2">We'll use Google Colab to train our models. Google Colab comes with TensorFlow installed, so we don't have to install it separately in our system.</p>
<p class="calibre2">We import the required libraries as follows:</p>
<pre class="calibre15">import numpy as np<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import seaborn as sns<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/><br class="title-page-name"/>import tensorflow as tf<br class="title-page-name"/>from tensorflow import keras<br class="title-page-name"/>from sklearn.utils import resample<br class="title-page-name"/>from sklearn.metrics import accuracy_score<br class="title-page-name"/>from sklearn.metrics import confusion_matrix<br class="title-page-name"/>from sklearn.metrics import classification_report<br class="title-page-name"/>from scipy import stats</pre>
<p class="calibre2">We load our data from the datasets that come with <kbd class="calibre12">tf.keras</kbd>:</p>
<pre class="calibre15"><span># Load the fashion-mnist pre-shuffled train data and test data</span>
<span>(</span><span>x_train</span><span>,</span> <span>y_train</span><span>),</span> <span>(</span><span>x_test</span><span>,</span> <span>y_test</span><span>)</span> <span>=</span> <span>tf</span><span>.</span><span>keras</span><span>.</span><span>datasets</span><span>.</span><span>fashion_mnist</span><span>.</span><span>load_data</span><span>()</span></pre>
<p class="calibre2">We check the dimensions of the train and test subsets:</p>
<pre class="calibre15"># Print training set shape <br class="title-page-name"/>print("x_train shape:", x_train.shape, "y_train shape:", y_train.shape)</pre>
<p class="calibre2">This gives us the following output:</p>
<p class="CDPAlignCenter"><img class="aligncenter124" src="assets/c7c78596-8409-45b0-9b07-88787f16e63b.png"/></p>
<p class="calibre2">We take note of the unique values in the target variable: </p>
<pre class="calibre15">np.unique(y_train)</pre>
<p class="calibre2">We can see that there are 10 classes labelled from 0 to 9:</p>
<p class="CDPAlignCenter"><img class="aligncenter125" src="assets/adb643ea-43b7-4070-967a-1a60c4a811c5.png"/></p>
<p class="calibre2">We can take a quick glimpse at the first few observations as follows:</p>
<pre class="calibre15">fig=plt.figure(figsize=(16,8))<br class="title-page-name"/><br class="title-page-name"/># number of columns for images in plot<br class="title-page-name"/>columns=5 <br class="title-page-name"/><br class="title-page-name"/># number of rows for images in plot<br class="title-page-name"/>rows=3<br class="title-page-name"/><br class="title-page-name"/>for i in range (1,columns*rows+1):<br class="title-page-name"/>      fig.add_subplot(rows,columns,i)<br class="title-page-name"/>      plt.title("Actual Class: {}".\<br class="title-page-name"/>              format((y_train[i])),color='r',fontsize=16)<br class="title-page-name"/>      plt.imshow(x_train[i])<br class="title-page-name"/>plt.show()</pre>
<p class="calibre2"/>
<p class="calibre2">With the preceding code, we plot the first 15 images, along with the associated labels:</p>
<p class="CDPAlignCenter"><img class="aligncenter126" src="assets/3a825ef7-c292-420e-8539-a852303b3206.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">We'll now move on to training our models:</span></p>
<ol class="calibre14">
<li class="calibre11">In the following code block, we'll create multiple homogeneous models over a few iterations using <kbd class="calibre12">tf.keras</kbd>:</li>
</ol>
<pre class="calibre18">accuracy = pd.DataFrame( columns=["Accuracy","Precision","Recall"])<br class="title-page-name"/>predictions = np.zeros(shape=(10000,7))<br class="title-page-name"/>row_index = 0<br class="title-page-name"/>for i in range(7):<br class="title-page-name"/>        # bootstrap sampling <br class="title-page-name"/>        boot_train = resample(x_train,y_train,replace=True, n_samples=40000, random_state=None)<br class="title-page-name"/>        model = tf.keras.Sequential([<br class="title-page-name"/>            tf.keras.layers.Flatten(input_shape=(28, 28)),<br class="title-page-name"/>            tf.keras.layers.Dense(256, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(128, activation=tf.nn.relu),<br class="title-page-name"/>            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])<br class="title-page-name"/>  <br class="title-page-name"/>        # compile the model<br class="title-page-name"/>        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])<br class="title-page-name"/>  <br class="title-page-name"/>        # Train the model<br class="title-page-name"/>        model.fit(x_train,y_train,epochs=10,batch_size=64)<br class="title-page-name"/>  <br class="title-page-name"/>        # Evaluate accuracy<br class="title-page-name"/>        score = model.evaluate(x_test, y_test, batch_size=64)<br class="title-page-name"/>        accuracy.loc[row_index,"Accuracy"]=score[1]<br class="title-page-name"/>  <br class="title-page-name"/>        # Make predictions<br class="title-page-name"/>        model_pred= model.predict(x_test)<br class="title-page-name"/>        pred_classes =model_pred.argmax(axis=-1)<br class="title-page-name"/>        accuracy.loc[row_index, 'Precision'] = precision_score(y_test, pred_classes, average='weighted')<br class="title-page-name"/>        accuracy.loc[row_index, 'Recall'] = recall_score(y_test, pred_classes,average='weighted')<br class="title-page-name"/>  <br class="title-page-name"/>        # Save predictions to predictions array<br class="title-page-name"/>        predictions[:,i] = pred_classes<br class="title-page-name"/>  <br class="title-page-name"/>        print(score)<br class="title-page-name"/>        row_index+=1<br class="title-page-name"/><br class="title-page-name"/>        print("Iteration " + str(i+1)+ " Accuracy : " + "{0}".format(score[1]))</pre>
<p class="calibre2">We mention seven iterations and 10 epochs in each iteration. In the following screenshot, we can see the progress as the model gets trained:</p>
<p class="CDPAlignCenter"><img class="aligncenter127" src="assets/facfdce9-3e8f-43c7-91ba-7b757885f4c1.png"/></p>
<ol start="2" class="calibre14">
<li class="calibre11">With the code in <em class="calibre23">Step 1</em>, we collate the accuracy, precision, and recall for every iteration on the test data:</li>
</ol>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre18"><span>accuracy</span></pre></div>
</div>
</div>
</div>
<div class="title-page-name">
<div class="title-page-name">
<p class="outputarea">In the following screenshot, we can see how the preceding three metrics change in each iteration:</p>
<div class="CDPAlignCenter2"><img class="aligncenter128" src="assets/66b6e227-2ba8-4c36-bc2b-8232068e5a6e.png"/></div>
</div>
</div>
<ol start="3" class="calibre14">
<li class="calibre11">We'll form a DataFrame with the predictions that are returned by all of the models in each iteration:</li>
</ol>
<pre class="calibre18"><span># Create dataframe using prediction of each iteration</span>
<span>df_iteration</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>([</span><span>predictions</span><span>[:,</span><span>0</span><span>],</span>\
                           <span>predictions</span><span>[:,</span><span>1</span><span>],</span>\
                           <span>predictions</span><span>[:,</span><span>2</span><span>],</span>\
                           <span>predictions</span><span>[:,</span><span>3</span><span>],</span>\
                           <span>predictions</span><span>[:,</span><span>4</span><span>],</span>\
                           <span>predictions</span><span>[:,</span><span>5</span><span>],</span>\
                           <span>predictions</span><span>[:,</span><span>6</span><span>]])</span></pre>
<ol start="4" class="calibre14">
<li class="calibre11">We convert the type into an integer:</li>
</ol>
<pre class="calibre18">df_iteration = df_iteration.astype('int64')</pre>
<ol start="5" class="calibre14">
<li class="calibre11">We perform max-voting to identify the most predicted class for each observation. We simply use <kbd class="calibre12">mode</kbd> to find out which class was predicted the most times for an observation:</li>
</ol>
<pre class="calibre18"># find the mode for result<br class="title-page-name"/>mode = stats.mode(df_iteration)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">We calculate the accuracy of the test data:</li>
</ol>
<pre class="calibre18"># calculate the accuracy for test dataset<br class="title-page-name"/>print(accuracy_score( y_test, mode[0].T))</pre>
<ol start="7" class="calibre14">
<li class="calibre11">We generate the confusion matrix with the required labels:</li>
</ol>
<pre class="calibre18"># confusion matrix<br class="title-page-name"/>cm = confusion_matrix(y_test, mode[0].T, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8])</pre>
<ol start="8" class="calibre14">
<li class="calibre11">We plot the confusion matrix:</li>
</ol>
<pre class="calibre18"><span>ax</span><span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>()<br class="title-page-name"/></span><br class="title-page-name"/># <span>annot=True to annotate cells<br class="title-page-name"/></span><span>sns</span><span>.</span><span>heatmap</span><span>(</span><span>cm</span><span>,</span> <span>annot</span><span>=</span><span>True</span><span>,</span> <span>ax</span> <span>=</span> <span>ax</span><span>, </span><span>fmt</span><span>=</span><span>'g'</span><span>, </span><span>cmap</span><span>=</span><span>'Blues'</span><span>)</span></pre>
<p class="calibre20">The confusion matrix plot appears as follows:</p>
<p class="CDPAlignCenter"><img class="aligncenter129" src="assets/1e7a1a0d-f59b-4d09-b8fd-ccb1c8cf2eae.png"/></p>
<ol start="9" class="calibre14">
<li class="calibre11">We create a DataFrame with all of the iteration numbers:</li>
</ol>
<pre class="calibre18">accuracy["Models"]=["Model 1",\<br class="title-page-name"/>                   "Model 2",\<br class="title-page-name"/>                   "Model 3",\<br class="title-page-name"/>                   "Model 4",\<br class="title-page-name"/>                   "Model 5",\<br class="title-page-name"/>                   "Model 6",\<br class="title-page-name"/>                   "Model 7"]</pre>
<ol start="10" class="calibre14">
<li class="calibre11">We then combine the accuracy, precision, and recall in one single table:</li>
</ol>
<pre class="calibre18">accuracy=accuracy.append(pd.DataFrame([[\<br class="title-page-name"/>                                        accuracy_score(y_test,\<br class="title-page-name"/>                                        mode[0].T),0,0,\<br class="title-page-name"/>                                        "Ensemble Model"]], \<br class="title-page-name"/>                                        columns=["Accuracy",\<br class="title-page-name"/>                                        "Precision","Recall",\<br class="title-page-name"/>                                        "Models"]))<br class="title-page-name"/><br class="title-page-name"/>accuracy.index=range(accuracy.shape[0])<br class="title-page-name"/><br class="title-page-name"/>accuracy.set_value(7, 'Precision', precision_score(y_test, mode[0].T, average='micro'))<br class="title-page-name"/>accuracy.set_value(7, 'Recall', recall_score(y_test, mode[0].T, average='micro'))</pre>
<p class="calibre20">In the following screenshot, we can see the structure that holds the metrics from each of the models and the ensemble model:</p>
<p class="CDPAlignCenter"><img class="aligncenter130" src="assets/033e6f18-7e95-4b79-95c9-c433448cce9a.png"/></p>
<ol start="11" class="calibre14">
<li class="calibre11">We plot the accuracy returned by each iteration and the accuracy from max-voting:</li>
</ol>
<pre class="calibre18">plt.figure(figsize=(20,8))<br class="title-page-name"/>plt.plot(accuracy.Models,accuracy.Accuracy)<br class="title-page-name"/>plt.title("Accuracy across all Iterations and Ensemble")<br class="title-page-name"/>plt.ylabel("Accuracy")<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20">This gives us the following plot. We notice that the accuracy returned by the max-voting method is the highest compared to individual models:</p>
<p class="CDPAlignCenter"><img class="aligncenter131" src="assets/de750f3d-1583-4900-aa77-1e788d9ac40d.png"/></p>
<ol start="12" class="calibre14">
<li class="calibre11">We also plot the precision and recall for each model and the ensemble:</li>
</ol>
<pre class="calibre18">plt.figure(figsize=(20,8))<br class="title-page-name"/>plt.plot(accuracy.Models,accuracy.Accuracy,accuracy.Models,accuracy.Precision)<br class="title-page-name"/>plt.title("Metrics across all Iterations and models")<br class="title-page-name"/>plt.legend(["Accuracy","Precision"])<br class="title-page-name"/>plt.show()</pre>
<p class="calibre2"/>
<p class="calibre20">This is shown in the following screenshot:</p>
<p class="CDPAlignCenter"><img class="aligncenter132" src="assets/2bb4181e-f699-495d-9bf5-d5aab4558174.png"/></p>
<p class="calibre2">From the preceding screenshot, we notice that the precision and recall improve for an ensemble model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="calibre2">In the <em class="calibre13">Getting ready</em> section, we imported our required libraries. Note that we've imported the <kbd class="calibre12">TensorFlow</kbd> library. We can directly access the datasets by importing the <span class="calibre5"><kbd class="calibre12">tf.keras.datasets</kbd></span> <span class="calibre5">module</span><span class="calibre5">. This module comes with various built-in datasets, including the following:</span></p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre12">boston_housing</kbd>: <span>Boston housing price regression dataset</span></li>
<li class="calibre11"><kbd class="calibre12">cifar10</kbd>: CIFAR10 small images classification dataset</li>
<li class="calibre11"><kbd class="calibre12">fashion_mnist</kbd>: <span>Fashion-MNIST dataset</span></li>
<li class="calibre11"><kbd class="calibre12">imdb</kbd>: <span>IMDB sentiment classification dataset</span></li>
<li class="calibre11"><kbd class="calibre12">mnist</kbd>: <span>MNIST handwritten digits dataset</span></li>
<li class="calibre11"><kbd class="calibre12">reuters</kbd>: <span>Reuters topic classification dataset</span></li>
</ul>
<p class="calibre2">We used the <kbd class="calibre12">fashion_mnist</kbd> dataset from this module. We loaded the pre-shuffled train and test data and checked the shape of the train and test subsets.</p>
<p class="calibre2">We noticed, in the G<em class="calibre13">etting</em><span class="calibre5"> <em class="calibre13">ready</em> section, that </span>the shape of the training subset is (60000, 28, 28), which means that we have 60,000 images that are of 28 X 28 pixel in size.</p>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2">We checked the distinct levels in the target variable with the <kbd class="calibre12">unique()</kbd> method. We saw that there were 10 classes from 0 to 9.</p>
<p class="calibre2">We also took a quick look at some of the images. We defined the number of columns and rows that we required. Running an iteration, we plotted the images with <kbd class="calibre12">matplotlib.pyplot.imshow()</kbd> in grayscale. We also printed the actual class labels against each of the images using <span class="calibre5"><kbd class="calibre12">matplotlib.pyplot.title()</kbd>.</span></p>
<p class="calibre2">In the <em class="calibre13">How to do it...</em> section, in <em class="calibre13">Step 1</em>, we created multiple homogeneous models using the <kbd class="calibre12">tf.keras</kbd> module. In each iteration, we used the <kbd class="calibre12">resample()</kbd> method to create bootstrap samples. We passed <kbd class="calibre12">replace=True</kbd> to the <kbd class="calibre12">resample()</kbd> method to ensure that we have samples with replacement.</p>
<p class="calibre2">In this step, we also defined the model architecture. We added layers to the model using <kbd class="calibre12">tf.keras.layers</kbd>. In each layer, we defined the number of units.</p>
<div class="packtinfobox">"Model architecture" refers to the overall neural network structure, which includes groups of units called layers. These layers are arranged in a chain-like structure. Each layer is a function of its previous layer. Determining the model architecture is key to neural networks.</div>
<p class="calibre2">We ran through a few iterations in our example. We set the number of iterations. In each iteration, we compiled the model and fit it to our training data. We made predictions on our test data and captured the following metrics in a DataFrame:</p>
<ul class="calibre10">
<li class="calibre11">Accuracy</li>
<li class="calibre11">Precision</li>
<li class="calibre11">Recall</li>
</ul>
<p class="calibre2">We've used <kbd class="calibre12">Rectified Linear Units (RELU)</kbd> as the activation function for the hidden layers. ReLU is represented by the <kbd class="calibre12">f(x) = max{0, x}</kbd>. In neural networks, ReLU is recommended as the default activation function.</p>
<div class="packtinfobox">Note that, in the last layer of the model architecture, we've used softmax as the activation function. The softmax function can be considered a generalization of the sigmoid function. While the sigmoid function is used to represent a probability distribution of a dichotomous variable, the softmax function is used to represent a probability distribution of a target variable with more than two classes. When the softmax function is used for multi-class classification, it returns a probability value between 0 and 1 for each class. The sum of all probabilities will be equal to one.</div>
<p class="calibre2"/>
<p class="calibre2">In <em class="calibre13">Step 2</em>, we checked the structure of the accuracy DataFrame that we created in <em class="calibre13">Step 1</em>. We noticed that we had three columns for accuracy, precision, and recall and the metrics for each iteration were captured. In <em class="calibre13">Step 3</em>, we converted the datatypes in the DataFrame into an integer.</p>
<p class="calibre2">In <em class="calibre13">Step 4</em>, we performed max-voting using <kbd class="calibre12">stats.mode()</kbd> for each observation. Since we ran seven iterations, we had seven predictions for each observation. <kbd class="calibre12">stats.mode()</kbd> returned the prediction with the maximum occurrence.</p>
<p class="calibre2">In <em class="calibre13">Step 5</em>, we checked the accuracy of the model with the max-voted predictions. In <em class="calibre13">Step 6</em> and <em class="calibre13"><span class="calibre5">Step </span>7</em>, we generated the confusion matrix to visualize the correct predictions. The diagonal elements in the plot were the correct predictions, while the off-diagonal elements were the misclassifications. We saw that there was a higher number of correct classifications compared to misclassifications.</p>
<p class="calibre2">In <em class="calibre13">Step 8</em> and <em class="calibre13"><span class="calibre5">Step </span>9</em>, we proceeded to create a structure to hold the performance metrics (accuracy, precision, and recall), along with the labels for each iteration and the ensemble. We used this structure to plot our charts for the performance metrics.</p>
<p class="calibre2">In <em class="calibre13">Step 10</em>, we plotted the accuracy for each iteration and the max-voted predictions. Similarly, in <em class="calibre13">Step 11</em>, we plotted the precision and recall for each iteration and the max-voted predictions.</p>
<p class="calibre2">From the plots we generated in <em class="calibre13">Step 10</em> and <em class="calibre13">Step 11</em>, we noticed how the accuracy, precision, and recall improved for the max-voted predictions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p class="calibre2">The <kbd class="calibre12">tf.keras</kbd> module provides us with TensorFlow-specific functionality, such as eager-execution, data pipelines, and estimators. You can take a look at the various options the <kbd class="calibre12">tf.keras</kbd> module provides us. </p>
<p class="calibre2">In our example, we used the built-in optimizer classes provided by the <kbd class="calibre12">tf.keras.optimizer</kbd> module. We used the <strong class="calibre4">Adam</strong> <strong class="calibre4">optimizer</strong> in our example, but there are other optimizers you can use, such as Adadelta, Adagrad, Adamax, RMSprop, or SGD.</p>
<p class="calibre2"/>
<p class="calibre2"/>
<div class="packtinfobox">In the present day, the Adam optimizer is one of the best optimizers. It's an extension of <strong class="calibre1">Stochastic Gradient Descent</strong> (<strong class="calibre1">SGD</strong>). <span>SGD considers a single learning rate for all weight updates and the learning rate remains unchanged during the model training process. The Adam algorithm considers adaptive learning rates methods to compute individual learning rates for each parameter. </span></div>
<p class="calibre2">The <kbd class="calibre12">tf.keras.losses</kbd> module provides us with various options so that we can choose our loss function. We used <kbd class="calibre12">sparse_categorical_crossentropy</kbd>. Depending on your task, you might opt for other options, such as <kbd class="calibre12">binary_crossentropy</kbd>, <kbd class="calibre12">categorical_crossentropy</kbd>, <kbd class="calibre12">mean_squared_error</kbd>, and so on.</p>
<div class="packttip">In the case of multiclass classification, if the target variable is one-hot encoded, use <kbd class="calibre19">categorical_crossentropy</kbd>. If the classes in the target variable are represented as integers, use <kbd class="calibre19">sparse_categorical_crossentropy</kbd>.</div>
<p class="calibre2">You can get more detailed information about the other hyperparameters that can be used with <kbd class="calibre12">tf.keras</kbd> at <a href="https://www.tensorflow.org/api_docs/python/tf/keras" class="calibre9">https://www.tensorflow.org/api_docs/python/tf/keras</a>.</p>


            </article>

            
        </section>
    </body></html>