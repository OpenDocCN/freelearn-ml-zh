<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Selected Topics in Deep Learning</h1>
                </header>
            
            <article>
                
<p>In <a href="6fd48e9f-f2fd-4b29-a006-1b151de4960f.xhtml" target="_blank">Chapter 4</a><em>, </em><span><em>Training Neural Networks</em>, </span>we looked at what an <strong>artificial neural network</strong> (<strong>ANN</strong>) is and how this kind of model is built. You can say that a deep neural network is an elongated version of an ANN; however, it has got its own set of challenges.</p>
<p>In this chapter, we will learn about the following topics:</p>
<ul>
<li>What is a deep neural network?</li>
<li>How to initialize parameters</li>
<li>Adversarial networks—generative adversarial networks and Bayesian generative adversarial networks</li>
<li>Deep Gaussian processes</li>
<li>Hinton's Capsule network</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep neural networks</h1>
                </header>
            
            <article>
                
<p>Let's recap on what we learned in <a href="6fd48e9f-f2fd-4b29-a006-1b151de4960f.xhtml" target="_blank">Chapter 4</a><em>, Training Neural Networks</em><span>. A neural network is a machine emulation of the human brain that is seen as a</span> set <span>of algorithms that have been set out to extract patterns out of data. It has got three different layers:</span></p>
<ul>
<li>Input layer</li>
<li>Hidden layer</li>
<li><span>Output layer</span></li>
</ul>
<p class="CDPAlignLeft CDPAlign" style="color: black">Sensory numerical data (in the form of a vector) passes through the input layer and then goes through the hidden layers to generate its own set of perceptions and reasoning to yield the final result in the output layer.</p>
<p class="mce-root"/>
<p>Can you recall what we learned in <a href="6fd48e9f-f2fd-4b29-a006-1b151de4960f.xhtml" target="_blank">Chapter 4</a>, <em>Training Neural Networks</em><em>, </em>regarding the number of layers in ANN and how we count them? When we have got the layers like the ones shown in the following diagram, can you count the number of layers? Remember, we always count just the hidden layer and the output layer. So, if somebody is asking you how many layers there are in your network, you don't include the input layer while answering:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-597 image-border" src="assets/3c7c2035-a325-4e73-8071-99a1ae84c085.png" style="width:16.92em;height:8.00em;"/></p>
<p>Yes, that's right—there are two layers in the preceding architecture. What about for the following network?</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-596 image-border" src="assets/20b65667-28a5-42c9-a8ba-e4d1ecfa8e30.png" style="width:19.33em;height:8.75em;"/></p>
<p>This network has got three layers, which includes two hidden layers. As the layers increase, the model becomes deeper.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Why do we need a deep learning model?</h1>
                </header>
            
            <article>
                
<p>A deep learning model is a highly non-linear model that has got multiple layers with multiple nodes acting in sequence to solve a business problem. Every layer has been assigned a different task.</p>
<p>For example, if we have got a face detection problem, hidden layer 1 finds out which edges are present in the image. Layer 2 finds out the combination of edges, which start taking the shape of eyes, a nose, and other parts. Layer 3 enables the object models, which creates the shape of the face. The following diagram shows the different hidden layers:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-593 image-border" src="assets/25fca5bd-3031-4453-8260-dc708618b000.png" style="width:36.08em;height:29.00em;"/></p>
<p>Here, we have got a logistic regression model, also known as a <strong>single layer neural network</strong>. Sometimes, it is also called the most <strong>shallow network</strong>. The second network that can be seen here has got a two-layer network. Again, it's a shallow network, but it's not as shallow as the previous one. The next architecture has got three layers, which is making things more interesting now. The network is getting deep now. The last architecture has got a six layer architecture, which is comprised of five hidden layers. The number of layers is getting even deeper.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep neural network notation</h1>
                </header>
            
            <article>
                
<p>The explanation of the notation is as follows:</p>
<ul>
<li><em>l</em>: Number of layers is 4</li>
<li><em>n<sup>[l]</sup></em>: Number of nodes in layer <em>l </em></li>
</ul>
<p>For the following architecture, this is as follows:</p>
<ul>
<li><em>n <sup>[0]</sup>:</em> Number of nodes in input layer, that is, 3</li>
<li><em>n<span> </span><sup>[1]</sup></em>: 5</li>
<li><em>n<span> </span><sup>[2]</sup></em>: 5</li>
<li> <em>n<span> </span><sup>[3]</sup>:</em> 3</li>
<li><em>n<span> </span><sup>[4]</sup></em>: 1</li>
<li><em><span>a </span><sup>[l]</sup></em>: Activations in layer <em>l:</em></li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-592 image-border" src="assets/2dc827b1-5595-4a37-b9b8-d58cb1a98826.png" style="width:23.42em;height:10.83em;"/></p>
<p>As we already know, the following equation goes through the layers:</p>
<p class="CDPAlignCenter CDPAlign"><em>z = w<sup>T</sup>X + b</em></p>
<p>Hence, we get the following results:</p>
<ul>
<li> Activation: <em>a = σ(z)</em> </li>
<li><em>w<sup>[l]</sup></em>: Weight in layer <em>l</em></li>
<li><em><span>b</span><sup>[l]</sup></em>: Bias in layer <em>l</em></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Forward propagation in a deep network</h1>
                </header>
            
            <article>
                
<p>Let's see how these equations set up for layer 1 and layer 2. If the training example set, X is (<em>x1</em>, <em>x2</em>, <em>x3</em>) for the preceding network.</p>
<p>Let's see how the equation comes along for layer 1:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/39d24283-bd5c-405f-b28c-30dbc286f3ba.png" style="width:8.67em;height:1.42em;"/></p>
<p>The activation function for layer 1 is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/fb5b4b19-d107-4c3b-b931-830f85a5f13d.png" style="width:17.75em;height:1.75em;"/></p>
<p>The input can also be expressed as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/efa63eef-38f6-4f0c-a623-5f61322c8531.png" style="width:4.08em;height:1.42em;"/></p>
<p>For layer 2, the input will be as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8824d96b-e31e-485e-b996-ea8995819a89.png" style="width:9.67em;height:1.42em;"/></p>
<p>The activation function that's applied here is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/de51ced3-93d0-4e7c-a632-668cb1a049b2.png" style="width:7.67em;height:1.75em;"/></p>
<p>Similarly, for layer 3, the input that's applied is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/87e6ec32-b73e-4e88-8ae5-e4c1d2ab84a3.png" style="width:9.08em;height:1.33em;"/></p>
<p>The activation function for the third layer is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4f055318-9468-48a3-833c-bfe8c4d84297.png" style="width:7.33em;height:1.67em;"/></p>
<p>Finally, here's the input for the last layer:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ad73712c-6c74-4216-9426-ea03e83737f9.png" style="width:10.25em;height:1.50em;"/></p>
<p>This is its activation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/fb5e5016-951f-4828-b429-6641e712e412.png" style="width:9.50em;height:1.67em;"/></p>
<p>Hence, the generalized forward propagation equation turns out to be as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/9b0cc83d-c92e-459d-8c45-005037bbaa69.png" style="width:10.67em;height:1.50em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/22c42f32-4024-4aaa-b7f0-909e019056ce.png" style="width:6.08em;height:1.50em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Parameters W and b</h1>
                </header>
            
            <article>
                
<p>Let's talk about the following architecture. First, let's note down what we learned about in the previous section. Take a look at the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-607 image-border" src="assets/b3ce16ca-11d7-4056-b2e9-5ac66bb93668.png" style="width:23.83em;height:8.17em;"/></p>
<p>Here, we can see the following:</p>
<ul>
<li><em>l</em>: Number of layers: 6</li>
<li><em>n<span> </span><sup>[l]</sup></em>: Number of nodes in layer <img class="fm-editor-equation" src="assets/c830fe26-cc8a-4f06-b7d6-42cda47290ae.png" style="width:0.50em;height:1.42em;"/></li>
<li><em>n<span> </span><sup>[0]</sup></em>: Number of nodes in input layer: 3 ::</li>
<li><em>n<span> </span><sup>[1]</sup></em>: Number of nodes in first layer: 4 :: </li>
</ul>
<p>The equation for this is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><em>n<span> </span><sup>[2]</sup>= 4 :: n<span> </span><sup>[3]</sup> = 4 :: n<span> </span><sup>[4]</sup> = 4 :: n<span> </span><sup>[5]</sup> =3 :: n<span> </span><sup>[6]</sup>= 1</em></p>
<p>Implementing forward propagation would mean that hidden layer 1 can be expressed via the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/02ba8710-56e1-443e-935c-7cfd7f5d91bd.png" style="width:9.08em;height:1.42em;"/>…..(1)</p>
<p>Can you determine the dimensions of z, w, and X for forward propagation?</p>
<p>Let's discuss this. <em>X</em> indicates the input layer vectors or nodes, and we know that there are 3 nodes. Can we find out the dimension of the input layer? Well, yes, it's (<em>n<sup>[0]</sup></em>, 1) <span>– alternatively, </span>you can say that it is (3,1).</p>
<p>What about for first hidden layer? Since the first hidden layer has got three nodes, the dimension of <em><span>z</span><sup>[1]</sup></em> will be (<em>n<span> </span><sup>[1]</sup></em>,1). This means that the dimension will be (4,1).</p>
<p>The dimensions of <em><span>z</span><sup>[1] </sup></em>and X have been ascertained. By looking at the preceding equation, it is evident that the dimensions of <em><span>z</span><sup>[1]</sup></em> and <em><span>w</span><sup>[1]</sup></em><em>X</em> have to be the same (from linear algebra). So, can you come up with the dimension of <em><span>w</span><sup>[1]</sup></em>? We know from linear algebra that matrix multiplication between matrix 1 and 2 is possible only when the number of columns of matrix 1 is equal to the number of rows of matrix 2. So, the number of columns of <em>w<sup>[1] </sup></em>has to be equal to the number of rows of matrix <em>X</em>. This will make the number of columns of <em>w<sup>[1]</sup></em>3. However, as we've already discussed, the dimensions of <em><span>z</span><sup>[1] </sup></em>and <em><span>w</span><sup>[1]</sup></em><em>X</em> have to be the same, and so the number of rows of the former should be equal to the number of rows of the latter. Hence, the number of rows of <em>w<sup>[1]</sup></em>will turn out to be 4. Alright, we have got the dimension of <em>w<sup>[1]</sup></em> now, which is (4,3). To make this more general, we can also say that the dimension of <em>w<sup>[1]</sup></em> is (<em><span>n</span><sup>[1]</sup></em>,<em>n<sup>[0]</sup></em>). Similarly, the dimension of <em>w<sup>[2]</sup></em> will be equal to <span>(</span><em><span>n</span><sup>[2]</sup></em><span>,</span><em>n<sup>[1]</sup></em><span>)</span> or (number of nodes of the current layer, number of nodes of the previous layer). It will make the dimension of <em>w<sup>[2] </sup></em>(4,4). Let's generalize this. Let's look at the dimension of the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><em>w<sup>[1]</sup>= (n<sup>[1]</sup>,n<sup>[l-1]</sup>)</em></p>
<p>What about the dimension of bias <em>b<sup>[1]</sup></em>? Can you make use of linear algebra and figure that out? This must be a cake walk for you by now. Yes, you would have probably guessed it correctly by now. It is has the same dimension as <em>z<sup>[1]</sup></em>. Let me explain this, for everyone’s benefit. Going by the equation, the dimension of the left-hand side should be equal to the dimension of the right-hand side. Besides, <em><span>w</span><sup>[1]</sup></em><em>X + b<sup>[1]</sup></em> is an addition of two matrices and it is well-known that two matrices can only be added if they have the same dimension; that is, they must have the same number of rows and columns. So, the dimension of <em>b<sup>[1] </sup></em>will be equal to <em><span>w</span><sup>[1]</sup></em><em>X</em>; in turn, it will be equal to <em>z<sup>[1]</sup></em> (which is (4,1)).</p>
<p>In terms of generalization, the dimension of <em>b<sup>[1]</sup>= (n<sup>[1]</sup>, 1)</em>.</p>
<p>For backpropagation, this is as follows:</p>
<ul>
<li>Dimension of <em>d</em><em>w<sup>[l]</sup>= (n<sup>[l]</sup>,n<sup>[l-1]</sup>)</em></li>
<li>Dimension of <em>db</em><em><sup>[l]</sup>= (n<sup>[l]</sup>, 1)</em></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Forward and backward propagation</h1>
                </header>
            
            <article>
                
<p>Let me show you how forward pass and backward pass work with the help of an example.</p>
<p class="mce-root"/>
<p>We have got a network that has got two layers (1 hidden layer and 1 output layer). Every layer (including the input) has got two nodes. It has got bias nodes as well, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-591 image-border" src="assets/fe2b3f04-2d32-478b-9b8b-4732b81ecf6d.png" style="width:28.92em;height:18.75em;"/></p>
<p>The notations that are used in the preceding diagram are as follows:</p>
<ul>
<li><em>IL</em>: Input layer</li>
<li><em>HL</em>: Hidden layer</li>
<li><em>OL</em>: Output layer</li>
<li><em>w</em>: Weight</li>
<li><em>B</em>: Bias</li>
</ul>
<p>We have got the values for all of the required fields. Let's feed this into the network and see how it flows. The activation function that's being used here is the sigmoid.</p>
<p>The input that's given to the first node of the hidden layer is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><em>InputHL1 = w1*IL1 + w3*IL2 + B1</em></p>
<p class="CDPAlignCenter CDPAlign"><em>InputHL1= (0.2*0.8)+(0.4*0.15) + 0.4 =0.62</em></p>
<p>The input that's given to the second node of the hidden layer is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><em>InputHL2 = w2*IL1 + w4*IL2 + B1</em></p>
<p class="CDPAlignCenter CDPAlign"><em>InputHL2 = (0.25*0.8) +(0.1*0.15) + 0.4 = 0.615</em></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>To find out the output, we will use our activation function, like so:</p>
<p class="CDPAlignCenter CDPAlign"><em>OutputHL1 = <img class="fm-editor-equation" src="assets/8b156d03-3ef6-4e23-84bd-819530ddd10c.png" style="width:7.08em;height:2.58em;"/>  = 0.650219</em></p>
<p class="CDPAlignCenter CDPAlign"><em>OutputHL2 = <img class="fm-editor-equation" src="assets/534e2915-fe06-4d9a-940a-c198ee8bfb4f.png" style="width:6.67em;height:2.42em;"/>= 0.649081</em></p>
<p>Now, these outputs will be passed on to the output layer as input. Let's calculate the value of the input for the nodes in the output layer:</p>
<p class="CDPAlignCenter CDPAlign"><em>InputOL1 = w5*Output_HL1 + w7*Output_HL2 + B2 = 0.804641</em></p>
<p class="CDPAlignCenter CDPAlign"><em>InputOL2= w6*Output_HL1 + w8*Output_HL2 + B2= 0.869606</em></p>
<p>Now, let's compute the output:</p>
<p class="CDPAlignCenter CDPAlign"><em>Output<sub>OL1</sub> = <img class="fm-editor-equation" src="assets/24d98aeb-c845-4fc7-9cd0-271853b5256a.png" style="width:6.33em;height:2.33em;"/> = 0.690966</em></p>
<p class="CDPAlignCenter CDPAlign"><em>Output<sub>OL2</sub> =<img class="fm-editor-equation" src="assets/56e40684-a2a9-4320-8c70-47b23ae15bfd.png" style="width:6.83em;height:2.50em;"/> = 0.704664</em></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Error computation</h1>
                </header>
            
            <article>
                
<p>We can now calculate the error for each output neuron using the square error function and sum them together to get the total error:</p>
<p class="CDPAlignCenter CDPAlign"><em>Etotal = </em><img class="fm-editor-equation" src="assets/ed8a52d3-9fa1-4903-9c32-db4474463294.png" style="width:10.00em;height:2.08em;"/></p>
<p class="CDPAlignCenter CDPAlign"><em>EOL1 = Error at first node of output layer =</em><img class="fm-editor-equation" src="assets/4fb5246b-2012-47dc-960a-b7f7ab5c16e9.png" style="width:13.25em;height:2.42em;"/></p>
<p class="CDPAlignCenter CDPAlign"><em>=0.021848</em></p>
<p class="CDPAlignCenter CDPAlign"><em>EOL2 = Error at second node of output layer =</em> <img class="fm-editor-equation" src="assets/1598226c-3004-42d0-9f4e-afcc5b93b24c.png" style="width:14.67em;height:2.67em;"/></p>
<p class="CDPAlignCenter CDPAlign"><em>=0.182809</em></p>
<p class="CDPAlignCenter CDPAlign"><em>Total Error = Etotal= EOL1 + EOL2 = 0.021848 + 0.182809 = 0.204657</em></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Backward propagation</h1>
                </header>
            
            <article>
                
<p>The purpose of backpropagation is to update each of the weights in the network so that they cause the actual output to be closer to the target output, thereby minimizing the error for each output neuron and the network as a whole.</p>
<p>Let's focus on an output layer first. We are supposed to find out the impact of change in w5 on the total error.</p>
<p>This will be decided by <img class="fm-editor-equation" src="assets/19ebbc28-eeac-4d1d-b685-1f7adeafdfa3.png" style="width:3.83em;height:2.00em;"/>. It is the partial derivative of Etotal with respect to w5.</p>
<p>Let's apply the chain rule here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8b71d76e-07e9-49dc-bdaf-eda319eadd55.png" style="width:30.00em;height:3.08em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/2f68c391-d1a5-482f-a663-ab7b1ce167d7.png" style="width:33.58em;height:2.50em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1143e171-c1c6-4fe7-9c8b-55bd3f9b062f.png" style="width:41.25em;height:3.00em;"/></p>
<p class="CDPAlignCenter CDPAlign"/>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><em>= 0.690966 – 0.9 = -0.209034</em></p>
<p> </p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d7f4f53f-c931-452b-8e67-9ea901f3c615.png" style="width:16.42em;height:3.17em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4ef3d0fd-7a77-4c98-b36d-e80053d71f84.png" style="width:14.75em;height:3.00em;"/></p>
<p class="CDPAlignCenter CDPAlign"><em>= 0.213532</em></p>
<p class="CDPAlignCenter CDPAlign"><em>InputOL1 = w5*OutputHL1 + w7*OutputHL2 + B2</em></p>
<p class="CDPAlignCenter"><em><img class="fm-editor-equation" src="assets/d594ec43-ddbf-45a9-883e-19c75ad8a624.png" style="width:12.42em;height:2.58em;"/>= 0.650219</em></p>
<p>Now, let's get back to the old equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/759a15cf-94d3-4f7f-9814-4590259b23bf.png" style="width:27.50em;height:2.83em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/dd625504-e1a7-43f4-b88c-948fb580e10c.png" style="width:35.58em;height:3.00em;"/></p>
<p>To update the weight, we will use the following formula. <span>We have set the learning rate to be <em>α = 0.1</em>:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/76b005cf-55a2-4935-b7d5-9fd8d59b8ac0.png" style="width:39.92em;height:1.67em;"/></p>
<p>Similarly, <img class="fm-editor-equation" src="assets/b27156ea-8276-45b1-92e3-e1a34a2d67bc.png" style="width:11.92em;height:1.25em;"/> are supposed to be calculated. The approach remains the same. We will leave this to compute as it will help you in understanding the concepts better.</p>
<p>When it comes down to the hidden layer and computing, the approach still remains the same. However, the formula will change a bit. I will help you with the formula, but the rest of the computation has to be done by you.</p>
<p>We will take <em>w1</em> here.</p>
<p>Let's apply the chain rule here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c72c8107-c603-4256-98be-ec0d735c48ae.png" style="width:28.67em;height:2.92em;"/></p>
<p>This formula has to be utilized for <em>w2</em>, <em>w3</em>, and <em>w4</em>. Please ensure that you are doing partial differentiation of <em>E_total</em> with respect to other weights and, in the end, that you are using the learning rate formula to get the updated weight.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Forward propagation equation</h1>
                </header>
            
            <article>
                
<p>We know the equations around it. If the input for this is <em>a<sup>[l-1]</sup></em>, then the output will be <em>a<sup>[l]</sup></em>. However, there is a cache part, which is nothing but z<em><sup>[l]</sup></em>, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-598 image-border" src="assets/bd54a557-21c3-42af-8627-540138cb1f1e.png" style="width:20.58em;height:9.58em;"/></p>
<p> Here, this breaks down into <em>w<sup>[1]</sup>a<sup>[l-1]</sup> +b<sup>[l]</sup></em> (remember that <em>a<sup>[0]</sup></em> is equal to <em>X</em>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Backward propagation equation</h1>
                </header>
            
            <article>
                
<p>The following equations would be required to execute backward propagation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ae157002-f173-49f2-8834-e62dde566376.png" style="width:11.25em;height:1.58em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-606 image-border" src="assets/10786584-fc12-4a34-bc22-a86a3b48ce3e.png" style="width:19.92em;height:8.92em;"/></p>
<p>These equations will give you an idea of what is going on behind the scenes. Here, a suffix, <em>d</em>, has been added, which is a representation of the partial derivative that acts during backward propagation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/484cc2b3-97cd-4819-bf37-e8a1449f47ff.png" style="width:12.42em;height:1.58em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/2b119630-edde-4f04-8387-58b8cf1dc790.png" style="width:9.75em;height:1.83em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Parameters and hyperparameters</h1>
                </header>
            
            <article>
                
<p>While we are getting on with building a deep learning model, you need to know how to keep a tab on both parameters and hyperparameters. But how well do we understand these?</p>
<p>When it comes down to parameters, we have got weights and biases. As we begin to train the network, one of the prime steps is to initialize the parameters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Bias initialization</h1>
                </header>
            
            <article>
                
<p>It is a common practice to initialize the bias by zero as the symmetrical breaking of neurons is taken care of by the random weights' initialization.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hyperparameters</h1>
                </header>
            
            <article>
                
<p>Hyperparameters are one of the building blocks of the deep learning network. It is an element that determines the optimal architecture of the network (for example, number of layers) and also a factor that is responsible for ensuring how the network will be trained.</p>
<p>The following are the various hyperparameters of the deep learning network:</p>
<ul>
<li><strong>Learning rate</strong>: This is responsible for determining the pace at which the network is trained. A slow learning rate ensures a smooth convergence, whereas a fast learning rate may not have smooth convergence.</li>
<li><strong>Epoch</strong>: The number of epochs is the number of times the whole training data is consumed by the network while training. </li>
<li><strong>Number of hidden layers</strong>: This determines the structure of the model, which helps in achieving the optimal capacity of the model.</li>
<li><strong>Number of nodes (neurons)</strong>: There should be a trade-off between the number of nodes to be used. It decides whether all of the necessary information has been extracted to produce the required output. Overfitting or underfitting will be decided by the number of nodes. Hence, it is advisable to use it with regularization.</li>
<li><strong>Dropout</strong>: Dropout is a regularization technique that's used to increase generalizing power by avoiding overfitting. This was discussed in detail in <a href="e994d382-9a54-427c-86db-caf852e5c084.xhtml" target="_blank">Chapter 4</a>, <em>Training Neural Networks</em>. The dropout value can be between 0.2 and 0.5.</li>
</ul>
<p class="mce-root"/>
<ul>
<li><strong>Momentum</strong>: This determines the direction of the next step toward convergence. With a value between 0.6 and 0.9, it handles oscillation.</li>
<li><strong>Batch size</strong>: This is the number of samples that are fed into the network, after which a parameter update happens. Typically, it is taken as 32, 64, 128, 256.</li>
</ul>
<p>To find the optimal number of hyperparameters, it is prudent to deploy a grid search or random search.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case – digit recognizer</h1>
                </header>
            
            <article>
                
<p>The <strong>Modified National Institute of Standards and Technology</strong> (<span><strong>MNIST</strong>) </span>is in fact the dataset of computer vision for <em>hello world</em>. Considering its release in 1999, this dataset has served as the main fundamental basis for benchmarking classification algorithms.</p>
<p> Our goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We have curated a set of tutorial-style kernels that cover everything from regression to neural networks:</p>
<pre>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/>import seaborn as sns<br/>%matplotlib inline<br/>from sklearn.model_selection import train_test_split<br/>import itertools<br/>from keras.utils.np_utils import to_categorical # convert to one-hot-encoding<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D<br/>from keras.optimizers import SGD<br/>from keras.preprocessing.image import ImageDataGenerator<br/>sns.set(style='white', context='notebook', palette='deep')<br/>np.random.seed(2)<br/><br/># Load the data<br/>train = pd.read_csv("train.csv")<br/>test = pd.read_csv("test.csv")<br/><br/>Y_train = train["label"]<br/># Drop 'label' column<br/>X_train = train.drop(labels = ["label"],axis = 1)<br/><br/>Y_train.value_counts()</pre>
<p>The output of the preceding code is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-608 image-border" src="assets/80896871-a1bb-46e5-9c71-5e2b39b1abb9.png" style="width:13.50em;height:12.42em;"/></p>
<pre>X_train.isnull().any().describe()</pre>
<p>Here, we get the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-599 image-border" src="assets/cc8d0828-a5b6-42d9-a851-660c411b9025.png" style="width:9.92em;height:6.58em;"/></p>
<pre>test.isnull().any().describe()</pre>
<p>Here, we get the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-605 image-border" src="assets/0e8f70db-2c67-40c5-a9af-59a109e83736.png" style="width:9.83em;height:6.83em;"/></p>
<pre>X_train = X_train / 255.0<br/>test = test / 255.0</pre>
<p>By reshaping the image into 3 dimensions, we get the following:</p>
<pre> Reshape image in 3 dimensions (height = 28px, width = 28px, canal = 1)<br/>X_train = X_train.values.reshape(-1,28,28,1)<br/>test = test.values.reshape(-1,28,28,1)<br/><br/>Encode labels to one hot vectors <br/>Y_train = to_categorical(Y_train, num_classes = 10)<br/><br/># Split the dataset into train and the validation set <br/>X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)</pre>
<p>By executing the following code, we will be able to see the numbered plot:</p>
<pre>pic = plt.imshow(X_train[9][:,:,0])</pre>
<p>The output is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-595 image-border" src="assets/cf01e7a0-dc45-4863-8a0b-870e9f549a52.png" style="width:25.83em;height:26.00em;"/></p>
<p>The sequential model is now as follows:</p>
<pre>model = Sequential()<br/>model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))<br/>model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))<br/>model.add(MaxPool2D(pool_size=(2,2)))<br/>model.add(Dropout(0.25))<br/>model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))<br/>model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))<br/>model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))<br/>model.add(Dropout(0.25))<br/>model.add(Flatten())<br/>model.add(Dense(256, activation = "relu"))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(10, activation = "softmax"))</pre>
<p>When we define the optimizer, we get the following output:</p>
<pre># Define the optimizer<br/>optimizer = SGD(lr=0.01, momentum=0.0, decay=0.0)</pre>
<p>When we compile the model, we get the following output:</p>
<pre># Compile the model<br/>model.compile(optimizer = optimizer, loss = "categorical_crossentropy", metrics=["accuracy"])<br/><br/>epochs = 5<br/>batch_size = 64</pre>
<p>Next, we generate the image generator:</p>
<pre>datagen = ImageDataGenerator(<br/> featurewise_center=False, # set input mean to 0 over the dataset<br/> samplewise_center=False, # set each sample mean to 0<br/> featurewise_std_normalization=False, # divide inputs by std of the dataset<br/> samplewise_std_normalization=False, # divide each input by its std<br/> zca_whitening=False, # apply ZCA whitening<br/> rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)<br/> zoom_range = 0.1, # Randomly zoom image <br/> width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)<br/> height_shift_range=0.1, # randomly shift images vertically (fraction of total height)<br/> horizontal_flip=False, # randomly flip images<br/> vertical_flip=False) # randomly flip images<br/>datagen.fit(X_train)<br/><br/>history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),<br/> epochs = epochs, validation_data = (X_val,Y_val),<br/> verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size)</pre>
<p>The output can be seen as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-600 image-border" src="assets/6c892255-d1c4-47f1-b62d-ff8b95726881.png" style="width:38.83em;height:11.58em;"/></p>
<p>We predict the model as follows:</p>
<pre>results = model.predict(test)<br/># select with the maximum probability<br/>results = np.argmax(results,axis = 1)<br/>results = pd.Series(results,name="Label")<br/>results</pre>
<p>The output can be seen as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-603 image-border" src="assets/5e3c6373-055f-4d8e-8465-d835d9774367.png" style="width:5.50em;height:28.75em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generative adversarial networks</h1>
                </header>
            
            <article>
                
<p><strong>Generative adversarial networks</strong> (<strong>GANs</strong>) are another form of deep neural network architecture, and is a combination of two networks that compete and cooperate with each other. It was introduced by Ian Goodfellow and Yoshua Bengio in 2014.</p>
<p>GANs can learn to mimic any distribution of data, which ideally means that GANs can be taught to create an object that's similar to an existing one in any domain, such as images, music, speech, and prose. It can create photos of any object that has never existed before. They are robot artists in a sense, and their output is impressive.</p>
<p>It falls under unsupervised learning wherein both of the networks learn their task upon training. One of the networks is called the <strong>generator</strong> and the other is called the <strong>discriminator</strong>.</p>
<p>To make this more understandable, we can think of a <strong>GAN</strong> as a case of a counterfeiter (generator) and a cop (discriminator). At the outset, the counterfeiter shows the cop fake money. The cop works like a detective and finds out that it is a fake money (you can think of D as a detective too if you want to understand how a discriminator works). The cop passes his feedback to the counterfeiter, explaining why the money is fake. The counterfeiter makes a few adjustments and makes new, fake money based on the feedback it received. The cop says that the money is still fake and he shares his new feedback with the counterfeiter. The counterfeiter then attempts to make new, fake money based on the latest feedback. The cycle continues indefinitely until the cop is fooled by the fake money because it looks real. When a GAN model is being created, the generator and discriminator start to learn from scratch and from each other. It may seem that they are pitted against each other, but they are helping each other learn. The feedback mechanism between these two is helping the model to be more robust.</p>
<p>A discriminator is quite a good learner, since it is capable of learning anything from the real world. That is, if you want it to learn about images of cats and dogs, and its 1,000 different categories where it's asked to differentiate between the images, it will be able to do so without any hassle, like so:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-609 image-border" src="assets/5f4c7150-07a3-481e-a605-e43d9d713791.png" style="width:56.50em;height:29.42em;"/></p>
<p>Noise goes into the generator; then, the output of the generator goes through the discriminator and we get an output. Simultaneously, the discriminator is being trained on the images of dogs. However, in the very beginning, even the dog images can be classified by the discriminator as being non-dog images, and it picks up on this error. This error gets back propagated through the network.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hinton's Capsule network</h1>
                </header>
            
            <article>
                
<p>Geoffrey Hinton, the father of deep learning, created a huge stir in the space of deep learning by introducing a new network. This network was called the <strong>Capsule Network</strong> (<strong>CapsNet</strong>). An algorithm to train this network was also brought forth, which is called <strong>dynamic routing</strong> <strong>between capsules</strong>. For the first time, Hinton spoke about it in 2011 in the paper called <strong>transforming autoencoder</strong>. In 2017 November, a full paper was published by Hinton and his team regarding the Capsule network.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Capsule Network and convolutional neural networks</h1>
                </header>
            
            <article>
                
<p>The <strong>convolutional neural network</strong> (<strong>CNN</strong>) has been one of the most important milestones in the area of deep learning. It has got everyone excited and has been the cornerstone for new research, too. But, as they say, <em>Nothing is perfect in this world</em>. Nor is our beloved CNN.</p>
<p>Can you recall how CNNs work? The most important job of a CNN is to execute convolution. What this means is that once you pass an image through CNN, the features, such as edges and color gradients, are extracted from image pixels by the convolution layer. Other layers will combine these features into a more complex one. And on top of it, once the dense layer is kept, it enables the network to carry out the classification job. The following diagram shows the image that we are working on:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-594 image-border" src="assets/c0ef9182-2bff-467b-b8e4-7dc60d19db61.png" style="width:136.50em;height:35.17em;"/></p>
<p>The preceding diagram is a basic CNN network, which is being used to detect the car in the image. The following diagram shows the image of a car that is in perfect order, and a fragmented image of the same:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-602 image-border" src="assets/d34d0009-4a1a-40ab-9935-52be22d7ee52.png" style="width:43.00em;height:13.83em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Let's say we pass on these two images through the CNN network (to detect the car) <span>–</span> what will be the response of the network for both images? Can you ponder over this and come up with an answer? Just to help you, a car has got a number of components such as wheels, a windshield, a bonnet, and so on, but a car is deemed as a car to human eyes when all of these parts/components are set in order. However, for a CNN, only the features are important. A CNN doesn't take relative positional and orientational relationship into account. So, both of these images will be classified as a car by the network, even though this is not the case to the human eye.</p>
<p> To make amends, CNNs include max-pooling, which helps in increasing the view of a higher layer's neurons, thus making the detection of higher order features possible. Max-pooling makes CNNs work, but at the same time, information loss also takes place. It's a big drawback of CNN. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we studied deep neural networks and why we need a deep learning model. We also learned about forward and backward prorogation, along with parameters and hyperparameters. We also talked about GANs, along with deep Gaussian processes, the Capsule Network, and CNNs.</p>
<p>In the next chapter, we will study causal inference.</p>


            </article>

            
        </section>
    </body></html>