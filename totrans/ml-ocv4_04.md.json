["```py\nIn [1]: import numpy as np\nIn [2]: np.random.seed(42)\n```", "```py\nIn [3]: y_true = np.random.randint(0, 2, size=5)\n...     y_true\nOut[3]: array([0, 1, 0, 0, 0])\n```", "```py\nIn [4]: y_pred = np.ones(5, dtype=np.int32)\n...     y_pred\nOut[4]: array([1, 1, 1, 1, 1], dtype=int32)\n```", "```py\nIn [5]: test_set_size = len(y_true)\nIn [6]: predict_correct = np.sum(y_true == y_pred)\nIn [7]: predict_correct / test_set_size\nOut[7]: 0.2\n```", "```py\nIn [8]: from sklearn import metrics\nIn [9]: metrics.accuracy_score(y_true, y_pred)\nOut[9]: 0.2\n```", "```py\nIn [10]: truly_a_positive = (y_true == 1)\nIn [11]: predicted_a_positive = (y_pred == 1)\nIn [12]: true_positive = np.sum(predicted_a_positive * truly_a_positive )\n...      true_positive\nOut[12]: 1\n```", "```py\nIn [13]: false_positive = np.sum((y_pred == 1) * (y_true == 0))\n...      false_positive\nOut[13]: 4\n```", "```py\nIn [14]: false_negative = np.sum((y_pred == 0) * (y_true == 1))\n...      false_negative\nOut[14]: 0\nIn [15]: true_negative = np.sum((y_pred == 0) * (y_true == 0))\n...      true_negative\nOut[15]: 0\n```", "```py\nIn [16]: accuracy = (true_positive + true_negative) / test_set_size\n...      accuracy\nOut[16]: 0.2\n```", "```py\nIn [17]: precision = true_positive / (true_positive + false_positive)\n...      precision\nOut[17]: 0.2\n```", "```py\nIn [18]: metrics.precision_score(y_true, y_pred)\nOut[18]: 0.2\n```", "```py\nIn [19]: recall = true_positive / (true_positive + false_negative)\n...      recall\nOut[19]: 1.0\nIn [20]: metrics.recall_score(y_true, y_pred)\nOut[20]: 1.0\n```", "```py\nIn [1]: import numpy as np\n...     import cv2\n...     import matplotlib.pyplot as plt\n...     %matplotlib inline\nIn [2]: plt.style.use('ggplot')\n```", "```py\nIn [3]: np.random.seed(42)\n```", "```py\nIn [15]: knn = cv2.ml.KNearest_create()\n```", "```py\nIn [16]: knn.train(train_data, cv2.ml.ROW_SAMPLE, labels)\nOut[16]: True\n```", "```py\nIn [17]: newcomer, _ = generate_data(1)...      newcomerOut[17]: array([[91., 59.]], dtype=float32)\n```", "```py\nIn [1]: import cv2\n...     import numpy as np\n...     import matplotlib.pyplot as plt\n...     from sklearn import linear_model\n...     from sklearn.model_selection import train_test_split\n...     plt.style.use('ggplot')\n...     %matplotlib inline\nIn [2]: x = np.linspace(0,10,100)\n...     y_hat = x*5+5\n...     np.random.seed(42)\n...     y = x*5 + 20*(np.random.rand(x.size) - 0.5)+5\n```", "```py\nIn [3]: plt.figure(figsize=(10, 6))\n...     plt.plot(x, y_hat, linewidth=4)\n...     plt.plot(x,y,'x')\n...     plt.xlabel('x')\n...     plt.ylabel('y')\n```", "```py\nIn [4]: x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n```", "```py\nIn [5]: distTypeOptions = [cv2.DIST_L2,\\\n...                 cv2.DIST_L1,\\\n...                 cv2.DIST_L12,\\\n...                 cv2.DIST_FAIR,\\\n...                 cv2.DIST_WELSCH,\\\n...                 cv2.DIST_HUBER]\n\nIn [6]: distTypeLabels = ['DIST_L2',\\\n...                 'DIST_L1',\\\n...                 'DIST_L12',\\\n...                 'DIST_FAIR',\\\n...                 'DIST_WELSCH',\\\n...                 'DIST_HUBER']\n\nIn [7]: colors = ['g','c','m','y','k','b']\nIn [8]: points = np.array([(xi,yi) for xi,yi in zip(x_train,y_train)])\n```", "```py\nIn [9]: linreg = linear_model.LinearRegression()\nIn [10]: linreg.fit(x_train.reshape(-1,1),y_train.reshape(-1,1))\nOut[10]:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,normalize=False)\nIn [11]: y_sklearn = linreg.predict(x.reshape(-1,1))\nIn [12]: y_sklearn = list(y_sklearn.reshape(1,-1)[0])\n```", "```py\nIn [13]: plt.figure(figsize=(10, 6))\n...      plt.plot(x, y_hat,linewidth=2,label='Ideal')\n...      plt.plot(x,y,'x',label='Data')\n\n...      for i in range(len(colors)):\n...          distType = distTypeOptions[i]\n...          distTypeLabel = distTypeLabels[i]\n...          c = colors[i]\n\n...          [vxl, vyl, xl, yl] = cv2.fitLine(np.array(points, dtype=np.int32), distType, 0, 0.01, 0.01)\n...          y_cv = [vyl[0]/vxl[0] * (xi - xl[0]) + yl[0] for xi in x]\n...          plt.plot(x,y_cv,c=c,linewidth=2,label=distTypeLabel)\n\n...      plt.plot(x,list(y_sklearn),c='0.5',\\\nlinewidth=2,label='Scikit-Learn API')\n...      plt.xlabel('x')\n...      plt.ylabel('y')\n...      plt.legend(loc='upper left')\n```", "```py\nIn [14]: from sklearn import datasets\n...      from sklearn import metrics\n```", "```py\nIn [15]: boston = datasets.load_boston()\n```", "```py\nIn [16]: dir(boston)\nOut[16]: ['DESCR', 'data', 'feature_names', 'filename', 'target']\n```", "```py\nIn [17]: boston.data.shape\nOut[17]: (506, 13)\n```", "```py\nIn [18]: boston.target.shape\nOut[18]: (506,)\n```", "```py\nIn [19]: linreg = linear_model.LinearRegression()\n```", "```py\nIn [20]: X_train, X_test, y_train, y_test = train_test_split(...            boston.data, boston.target, test_size=0.1,...            random_state=42...      )\n```", "```py\nIn [21]: linreg.fit(X_train, y_train)Out[21]: LinearRegression(copy_X=True, fit_intercept=True, ...\n```", "```py\nIn [24]: y_pred = linreg.predict(X_test)\nIn [25]: metrics.mean_squared_error(y_test, y_pred)\nOut[25]: 14.995852876582541\n```", "```py\nIn [26]: plt.figure(figsize=(10, 6))\n...      plt.plot(y_test, linewidth=3, label='ground truth')\n...      plt.plot(y_pred, linewidth=3, label='predicted')\n...      plt.legend(loc='best')\n...      plt.xlabel('test data points')\n...      plt.ylabel('target value')\nOut[26]: <matplotlib.text.Text at 0x7ff46783c7b8>\n```", "```py\nIn [27]: plt.figure(figsize=(10, 6))\n...      plt.plot(y_test, y_pred, 'o')\n...      plt.plot([-10, 60], [-10, 60], 'k--')\n...      plt.axis([-10, 60, -10, 60])\n...      plt.xlabel('ground truth')\n...      plt.ylabel('predicted')\n```", "```py\n...      scorestr = r'R$^2$ = %.3f' % linreg.score(X_test, y_test)\n...      errstr = 'MSE = %.3f' % metrics.mean_squared_error(y_test, y_pred)\n...      plt.text(-5, 50, scorestr, fontsize=12)\n...      plt.text(-5, 45, errstr, fontsize=12)\nOut[27]: <matplotlib.text.Text at 0x7ff4642d0400>\n```", "```py\nIn [1]: import numpy as np\n...     import cv2\n...     from sklearn import datasets\n...     from sklearn import model_selection\n...     from sklearn import metrics\n...     import matplotlib.pyplot as plt\n...     %matplotlib inline\nIn [2]: plt.style.use('ggplot')\n```", "```py\nIn [3]: iris = datasets.load_iris()\n```", "```py\nIn [4]: dir(iris)\nOut[4]: ['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']\n```", "```py\nIn [5]: iris.data.shape\nOut[5]: (150, 4)\n```", "```py\nIn [6]: iris.feature_names\nOut[6]: ['sepal length (cm)',\n         'sepal width (cm)',\n         'petal length (cm)',\n         'petal width (cm)']\n```", "```py\nIn [7]: iris.target.shape\nOut[7]: (150,)\n```", "```py\nIn [8]: np.unique(iris.target)\nOut[8]: array([0, 1, 2])\n```", "```py\nIn [9]: idx = iris.target != 2...     data = iris.data[idx].astype(np.float32)...     target = iris.target[idx].astype(np.float32)\n```", "```py\nIn [10]: plt.scatter(data[:, 0], data[:, 1], c=target,  \n                     cmap=plt.cm.Paired, s=100)\n...      plt.xlabel(iris.feature_names[0])\n...      plt.ylabel(iris.feature_names[1])\nOut[10]: <matplotlib.text.Text at 0x23bb5e03eb8>\n```", "```py\nIn [11]: X_train, X_test, y_train, y_test = model_selection.train_test_split(...            data, target, test_size=0.1, random_state=42...      )\n```", "```py\nIn [12]: X_train.shape, y_train.shapeOut[12]: ((90, 4), (90,))In [13]: X_test.shape, y_test.shapeOut[13]: ((10, 4), (10,))\n```", "```py\nIn [14]: lr = cv2.ml.LogisticRegression_create()\n```", "```py\nIn [15]: lr.setTrainMethod(cv2.ml.LogisticRegression_MINI_BATCH)\n...      lr.setMiniBatchSize(1)\n```", "```py\nIn [16]: lr.setIterations(100)\n```", "```py\nIn [17]: lr.train(X_train, cv2.ml.ROW_SAMPLE, y_train)\nOut[17]: True\n```", "```py\nIn [18]: lr.get_learnt_thetas()\nOut[18]: array([[-0.04090132, -0.01910266, -0.16340332, 0.28743777, 0.11909772]], dtype=float32)\n```", "```py\nIn [19]: ret, y_pred = lr.predict(X_train)In [20]: metrics.accuracy_score(y_train, y_pred)Out[20]: 1.0\n```", "```py\nIn [21]: ret, y_pred = lr.predict(X_test)...      metrics.accuracy_score(y_test, y_pred)Out[21]: 1.0\n```"]