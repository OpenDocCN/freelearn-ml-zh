<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Image Recognition Using Deep Neural Networks</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">In 1966, Professor Seymour Papert at MIT conceptualized an ambitious summer project titled <em class="calibre15">The Summer Vision Project</em>. The task for the graduate student was to <em class="calibre15">plug a camera into a computer and enable it to understand what it sees</em>! I am sure it would have been super-difficult for the graduate student to have finished this project, as even today the task remains half complete.<span class="calibre4"> </span></span></p>
<p class="mce-root"><span class="calibre4">A human being, when they look outside, is able to recognize the objects that they see. Without thinking, they are able to classify a cat as a cat, a dog as a dog, a plant as a plant, an animal as an animal—this is happening because the human brain draws knowledge from its extensive prelearned database. After all, as human beings, we have millions of years' worth of evolutionary context that enables us draw inferences from the thing that we see. Computer vision deals with replicating the human vision processes so as to pass them on to machines and automate them.</span></p>
<p class="mce-root"><span class="calibre4">This chapter is all about learning the theory and implementation of computer vision through <strong class="calibre3">machine learning</strong> (<strong class="calibre3">ML</strong>). We will build a feedforward deep learning network and <strong class="calibre3">LeNet</strong> to enable handwritten digit recognition. We will also build a project that uses a pretrained Inception-BatchNorm network to identify objects in an image. We will cover the following topics as we progress in this chapter:</span></p>
<ul class="calibre9">
<li class="calibre10">Understanding computer vision</li>
<li class="calibre10">Achieving computer vision with deep learning</li>
<li class="calibre10">Introduction to the MNIST dataset</li>
<li class="calibre10">Implementing a deep learning network for handwritten digit recognition</li>
<li class="calibre10">Implementing computer vision with pretrained models</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">For the projects covered in this chapter, we'll make use of a very popular open dataset called MNIST. </span><span class="calibre4">We'll use <strong class="calibre3">Apache MXNet</strong>, a</span><span class="calibre4"> </span><span class="calibre4">modern open source deep learning software framework to train and deploy the required deep neural networks.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding computer vision</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">In today's world, we have advanced cameras that are very successful at mimicking how a human eye captures light and color; but image-capturing in the right way is just stage one in the whole image-comprehension aspect. Post image-capturing, we will need to enable technology that interprets what has been captured and build context around it. This is what the human brain does when the eyes see something. Here comes the huge challenge: we all know that computers see images as huge piles of integer values that represent intensities across a spectrum of colors, and of course, computer have no context associated with the image itself. This is where ML comes into play. ML allows us to train a context for a dataset such that it enables computers to understand what objects certain sequences of numbers actually represent.</span></p>
<p class="mce-root"><span class="calibre4">Computer vision is one of the emerging areas where ML is applied. It can be used for several purposes in various domains, including healthcare, agriculture, insurance, and the automotive industry. The following are some of its most popular applications:</span></p>
<ul class="calibre9">
<li class="calibre10"><span>Detecting diseases from medical images, such as CT scan/MRI scan images</span></li>
<li class="calibre10"><span>Identifying crop diseases and soil quality to support a better crop yield</span></li>
<li class="calibre10"><span>Identifying oil reserves from satellite images</span></li>
<li class="calibre10"><span>Self-driving cars</span></li>
<li class="calibre10"><span>Monitoring and managing skin condition for psoriasis patients</span></li>
<li class="calibre10"><span>Classifying and distinguishing weeds from crops</span></li>
<li class="calibre10"><span>Facial recognition</span></li>
<li class="calibre10"><span>Extracting information from personal documents, such as passports and ID cards</span></li>
<li class="calibre10"><span>Detecting terrain for drones and airplanes</span></li>
<li class="calibre10"><span>Biometrics</span></li>
<li class="calibre10"><span>Public surveillance</span></li>
<li class="calibre10"><span>Organizing personal photos</span></li>
<li class="calibre10"><span>Answering visual questions</span></li>
</ul>
<p class="mce-root"><span class="calibre4">This is just the tip of the iceberg. It's not an overstatement to say that there is no domain where we cannot find an application for computer vision. Therefore, computer vision is a key area for ML practitioners to focus on.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Achieving computer vision with deep learning</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">To start with, let's understand the term <strong class="calibre3">deep learning</strong>. It simply means <strong class="calibre3">multilayered neural networks</strong>. The multiple layers enable deep learning to be an enhanced and powerful form of a neural network. <strong class="calibre3">Artificial neural networks</strong> (<strong class="calibre3">ANNs</strong>) have been in existence since the 1950s. They have always been designed with two layers; however, deep learning models are built with multiple hidden layers. The following diagram shows a hypothetical deep learning model:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter64" src="assets/9d09fdae-a6ec-4587-9d21-fe9efc0062dc.png"/></p>
<div class="packtfigref">Deep learning model—High level architecture</div>
<p class="mce-root"><span class="calibre4">Neural networks are heavy on computation, therefore the <strong class="calibre3">central processing unit</strong> (<strong class="calibre3">CPU</strong>) that can be enabled with a maximum of 22 cores is generally thought of as an infrastructure blocker until recently. This infrastructure limitation also limited the usage of neural networks to solve real-world problems. However, recently, the availability of a <strong class="calibre3">graphical processing unit</strong> (<strong class="calibre3">GPU</strong>) with thousands of cores enabled has exponentially powerful computation possibilities when compared to CPUs. This gave a huge push to the usage of deep learning models.</span></p>
<p class="mce-root"/>
<p class="mce-root"><span class="calibre4">Data comes in many forms, such as tables, sounds, HTML files, TXT files, and images. Linear models do not generally learn from non-linear data. Non-linear algorithms, such as decision trees and gradient-boosting machines, also do not learn well from this kind of data. One the other hand, deep learning models that create non-linear interactions among the features give better solutions with non-linear data, so they have become the preferred models in the ML community.</span></p>
<p class="mce-root"><span class="calibre4">A deep learning model consists of a chain of interconnected neurons that creates the neural architecture. Any deep learning model will have an input layer, two or more hidden layers (middle layers), and an output layer. The input layer consists of neurons equal to the number of input variables in the data. Users can decide on the number of neurons and the number of hidden layers that a deep learning network should have. Generally, it is something that is optimized by the user building the network through a cross-validation strategy. The choice of the number of neurons and the number of hidden layers represents</span> <span class="calibre4">the</span> <span class="calibre4">challenge of the researcher. The number of neurons in the output layer is decided based on the outcome of the problem. For example, one output neuron in case it is regression, for a classification problem the output neurons is equal to the number of classes involved in the problem on-hand.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convolutional Neural Networks</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">There are multiple types of deep learning algorithms, the one we generally use in computer vision is called a <strong class="calibre3">Convolutional Neural Network </strong>(<strong class="calibre3">CNN</strong>). CNNs break down images into small groups of pixels and then run calculations on them by applying filters. The result is then compared against pixel matrices they already know about. This helps CNNs to come up with a probability for the image belonging to one of the known classes.</span></p>
<p class="mce-root"><span class="calibre4">In the first few layers, the CNN identifies shapes, such as curves and rough edges, but after several convolutions, they are able to recognize objects such as animals, cars, and humans.</span></p>
<p class="mce-root"><span class="calibre4">When the CNN is first built for the available data, the filter values of the network are randomly initialized and so the predictions it produce are mostly false. But then it keeps comparing its own predictions on labeled datasets to the actual ones, updating the filter values and improving performance of the CNN with each iteration.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Layers of CNNs</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">A CNN consists of an input and an output layer; it also has various hidden layers. The following are the various hidden layers in a CNN:</span></p>
<ul class="calibre9">
<li class="calibre10"><span><strong class="calibre1">Convolution</strong>: Assume that we have an image represented as pixels, a convolution is something where we have a little matrix nearly always 3 x 3 in deep learning and multiply every element of the matrix by every element of 3 x 3 section of the image and then add them all together to get the result of that convolution at one point. The following diagram illustrates the process of convolution on a pixel:</span></li>
</ul>
<p class="CDPAlignCenter1"><img class="aligncenter65" src="assets/5357ec97-6f89-4348-92a2-26e7a6cea9b4.png"/></p>
<div class="packtfigref">Convolution application on an image</div>
<ul class="calibre9">
<li class="calibre10"><span><strong class="calibre1">Rectified Linear Unit</strong> (<strong class="calibre1">ReLU</strong>): A non-linear activation that throws away the negatives in an input matrix. For example, let's assume we have a 3 x 3 matrix with negative numbers, zeros, and positive numbers as values in the cells of the matrix. Given this matrix as input to ReLU, it transforms all negative numbers in the matrix to zeros and returns the 3 x 3 matrix. ReLU is an activation function that can be defined as part of the CNN architecture. The following diagram demonstrates the function of ReLU in CNNs:</span></li>
</ul>
<p class="CDPAlignCenter1"><img class="aligncenter66" src="assets/ad096701-f380-414d-8028-f55c77a9f905.png"/></p>
<div class="packtfigref">Rectified Linear Unit (ReLU) in CNNs</div>
<ul class="calibre9">
<li class="calibre10"><span><strong class="calibre1">Max pooling</strong>: Max pooling is something that can be set as a layer in the<span> </span>CNN architecture. It allows to identify if the specific characteristic is present in the previous level. It<span> </span>replaces the highest value in an input matrix with the maximum and gives the output. Let's consider an example, with a 2 x 2 max pooling layer, given a 4 x 4 matrix as input, the max pooling layer replaces each 2 x 2 in the input matrix with the highest value among the four cells. The output matrix thus obtained is non-overlapping and it's an image representation with a reduced resolution. The following diagram illustrates the functionality of max pooling in a CNN:</span></li>
</ul>
<p class="CDPAlignCenter1"><img class="aligncenter67" src="assets/ce2cc9f2-2ea0-4c38-9c48-f99f26af8ebc.png"/></p>
<div class="packtfigref">Functionality of max pooling layer in CNNs</div>
<p class="calibre23"><span class="calibre4">There are various reasons to apply max pooling, such as to reduce the amount of parameters and computation load, to eliminate overfitting, and, most importantly, to force the neural network to see the larger picture, as in previous layers it was focused on seeing bits and pieces of the image.<span class="calibre4"> </span></span></p>
<ul class="calibre9">
<li class="calibre10"><span><strong class="calibre1">Fully-connected layer</strong>: Also known as a <strong class="calibre1">dense layer</strong>, this involves a linear operation on the layer's input vector. The layer ensures every input is connected to every output by a weight.<span> </span></span></li>
<li class="calibre10"><span><strong class="calibre1">Softmax</strong>: An activation function that is generally applied at the last layer of the deep neural network. In a multiclass classification problem, we require the fully-connected output of a deep learning network to be interpreted as a probability. The total probability of a particular observation in data (for all classes) should add up to 1, and the probability of the observation belonging to each class should range between 0 and 1. Therefore, we transform each output of the fully-connected layer as a portion of a total sum. However, instead of simply doing the standard proportion, we apply this non-linear exponential function for a very specific reason: we would like to make our highest output as close to 1 as possible and our lower output as close to 0. Softmax<span> </span>does this by pushing the true linear proportions closer to either 1 or 0.</span></li>
</ul>
<p class="calibre23"><span class="calibre4">The following diagram illustrates the softmax activation function:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter68" src="assets/532ddd0f-24a2-41f4-bdac-293eecfdaf2e.png"/></p>
<div class="packtfigref">Softmax activation function</div>
<ul class="calibre9">
<li class="calibre10"><span><strong class="calibre1">Sigmoid</strong>: This is similar to softmax, except that it is applied to a binary classification, such as cats versus dogs. With this activation function, the class to which the observation belongs is assigned a higher probability compared to the other class. Unlike softmax, the probabilities do not have to add up to 1.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to the MXNet framework</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">MXNet is a super-powerful open source deep learning framework that is built to ease the development of deep learning algorithms. It is used to define, train, and deploy deep neural networks. MXNet is lean, flexible, and ultra-scalable, that is, it allows fast model training and supports a flexible programming model with multiple languages. The problem with existing deep learning frameworks, such as Torch7, Theano, and Caffe, is that users need to learn another system or a different programming flavor.</span></p>
<p class="mce-root"><span class="calibre4">However, MXNet resolves this issue by supporting multiple languages, such as C++, Python, R, Julia, and Perl. This eliminates the need for users to learn a new language; therefore, they can use the framework and simplify network definitions. MXNet models are able to fit in small amounts of memory and they can be trained on CPUs, GPUs, and on multiple machines with ease. The <kbd class="calibre11">mxnet</kbd> package is readily available for the R language and the details of the install can be looked up in <strong class="calibre3">Apache Incubator</strong> at <a href="https://mxnet.incubator.apache.org" class="calibre8">https://mxnet.incubator.apache.org</a>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the MNIST dataset</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4"><strong class="calibre3">Modified National Institute of Standards and Technology</strong> (<strong class="calibre3">MNIST</strong>) is a dataset that contains images of handwritten digits. This dataset is pretty popular in the ML community for implementing and testing computer vision algorithms. The MNIST dataset is an open dataset<span class="calibre4"> </span>made available by Professor Yann LeCun at <a href="http://yann.lecun.com/exdb/mnist/" class="calibre8">http://yann.lecun.com/exdb/mnist/</a>, where separate files that represent the training dataset and test dataset are available. The labels corresponding to the test and training datasets are also available as separate files.<span class="calibre4"> The training dataset has 60,000 samples and the test dataset has 10,000 samples.</span></span></p>
<p class="mce-root"><span class="calibre4">The following diagram shows some sample images from the MNIST dataset. Each of the images also comes with a label indicating the digit shown in the following screenshot:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter69" src="assets/9f8f082b-0bbb-4e47-ab65-6cd430a0b1d5.png"/></p>
<div class="packtfigref">Sample images from MNIST dataset</div>
<p class="mce-root"><span class="calibre4">The labels for the images shown in the preceding diagram are <strong class="calibre3">5</strong>, <strong class="calibre3">0</strong>, <strong class="calibre3">4</strong>, and <strong class="calibre3">1</strong>. </span><span class="calibre4">Each image in the dataset is a grayscale image and is represented in 28 x 28 pixels. A sample image represented with pixels is shown in the following screenshot:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter70" src="assets/853fd20e-35be-49ed-949c-57b05ea199fd.png"/></p>
<div class="packtfigref">Sample image from MNIST dataset represented with 28 * 28 pixels</div>
<p class="mce-root"><span class="calibre4">It is possible to flatten the 28 x 28 pixel matrix and represent it as a vector of 784 pixel values. Essentially, the training dataset is a 60,000 x<span class="calibre4"> </span>784 matrix that could be used with ML algorithms. The test dataset is a 10,000 x 784 matrix. The training and test datasets may be downloaded from the source with the following code:</span></p>
<pre class="calibre16"><span># setting the working directory where the files need to be downloaded<br class="title-page-name"/></span><span>setwd('/home/sunil/Desktop/book/chapter 6/MNIST')<br class="title-page-name"/></span><span># download the training and testing dataset from source<br class="title-page-name"/></span><span>download.file("http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz","train-images-idx3-ubyte.gz")<br class="title-page-name"/></span><span>download.file("http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz","train-labels-idx1-ubyte.gz")<br class="title-page-name"/></span><span>download.file("http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz","t10k-images-idx3-ubyte.gz")<br class="title-page-name"/></span><span>download.file("http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz","t10k-labels-idx1-ubyte.gz")<br class="title-page-name"/></span><span># unzip the training and test zip files that are downloaded<br class="title-page-name"/></span><span>R.utils::gunzip("train-images-idx3-ubyte.gz")<br class="title-page-name"/></span><span>R.utils::gunzip("train-labels-idx1-ubyte.gz")<br class="title-page-name"/></span><span>R.utils::gunzip("t10k-images-idx3-ubyte.gz")<br class="title-page-name"/></span><span>R.utils::gunzip("t10k-labels-idx1-ubyte.gz")</span></pre>
<p class="mce-root"><span class="calibre4">Once the data is downloaded and unzipped, we will see the files in our working directory. However, these files are in binary format and they cannot be directly loaded through the regular <kbd class="calibre11">read.csv</kbd> command. The following custom function code helps to read the training and test data from the binary files:</span></p>
<pre class="calibre16"><span># function to load the image files<br class="title-page-name"/></span><span>load_image_file = function(filename) {<br class="title-page-name"/></span><span><span>  </span>ret = list()<br class="title-page-name"/></span><span><span>  </span># opening the binary file in read mode<span> <br class="title-page-name"/></span></span><span><span>  </span>f = file(filename, 'rb')<br class="title-page-name"/></span><span><span>  </span></span><span># reading the binary file into a matrix called x<br class="title-page-name"/></span><span><span> </span>readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span> </span>n<span> </span>= readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span> </span>nrow = readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span> </span>ncol = readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span> </span>x = readBin(f, 'integer', n = n * nrow * ncol, size = 1, signed = </span><span>FALSE)<br class="title-page-name"/></span><span><span>  </span># closing the file<br class="title-page-name"/></span><span><span>  </span>close(f)<br class="title-page-name"/></span><span><span>  </span># converting the matrix and returning the dataframe<br class="title-page-name"/></span><span><span>  </span>data.frame(matrix(x, ncol = nrow * ncol, byrow = TRUE))<br class="title-page-name"/></span><span>}<br class="title-page-name"/></span><span># function to load label files<br class="title-page-name"/></span><span>load_label_file = function(filename) {<br class="title-page-name"/></span><span><span>  </span># reading the binary file in read mode<br class="title-page-name"/></span><span><span>  </span>f = file(filename, 'rb')<br class="title-page-name"/></span><span><span>  </span># reading the labels binary file into y vector<span> <br class="title-page-name"/></span></span><span><span>  </span>readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>n = readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>y = readBin(f, 'integer', n = n, size = 1, signed = FALSE)<br class="title-page-name"/></span><span><span>  </span># closing the file<br class="title-page-name"/></span><span><span>  </span>close(f)<br class="title-page-name"/></span><span><span>  </span># returning the y vector<br class="title-page-name"/></span><span><span>  </span>y<br class="title-page-name"/></span><span>}</span></pre>
<p class="mce-root"><span class="calibre4">The functions may be called with the following code:</span></p>
<pre class="calibre16"><span># load training images data through the load_image_file custom function<br class="title-page-name"/></span><span>train = load_image_file("train-images-idx3-ubyte")<br class="title-page-name"/></span><span># load<span>  </span>test data through the load_image_file custom function<br class="title-page-name"/></span><span>test<span>  </span>= load_image_file("t10k-images-idx3-ubyte")<br class="title-page-name"/></span><span># load the train dataset labels<br class="title-page-name"/></span><span>train.y = load_label_file("train-labels-idx1-ubyte")<br class="title-page-name"/></span><span># load the test dataset labels<br class="title-page-name"/></span><span>test.y<span>  </span>= load_label_file("t10k-labels-idx1-ubyte")</span></pre>
<p class="mce-root"><span class="calibre4">In RStudio, when we execute the code, we see <kbd class="calibre11">train</kbd> , <kbd class="calibre11">test</kbd>,<span class="calibre4"> </span> <kbd class="calibre11">train.y</kbd></span>, <span class="calibre4">and <kbd class="calibre11">test.y</kbd> displayed under the <span class="calibre4">Environment</span> tab. This confirms that the datasets are successfully loaded and the respective dataframes are created, as shown in the following screenshot:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter71" src="assets/b85709ce-90db-428b-a38a-aa7c6f57cb78.png"/></p>
<p class="mce-root"><span class="calibre4">Once the image data is loaded into the dataframe, it is in the form of a series of numbers that represent the pixel values. The following is a helper function that visualizes the pixel data as an image in RStudio:</span></p>
<pre class="calibre16"><span># helper function to visualize image given a record of pixels<br class="title-page-name"/></span><span>show_digit = function(arr784, col = gray(12:1 / 12), ...) {<br class="title-page-name"/></span><span><span>  </span>image(matrix(as.matrix(arr784), nrow = 28)[, 28:1], col = col, ...)<br class="title-page-name"/></span><span>}</span></pre>
<p class="mce-root"><span class="calibre4">The <kbd class="calibre11">show_digit()</kbd> function may be called like any other R function with the dataframe record number as a parameter. For example, the function in the following code block helps to visualize the <kbd class="calibre11">3</kbd> record in the training dataset as an image in RStudio:</span></p>
<pre class="calibre16"><span># viewing image corresponding to record 3 in the train dataset<br class="title-page-name"/></span><span>show_digit(train[3, ])</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter72" src="assets/88617ad9-3c55-44fb-9a2e-8957dae8647c.png"/></p>
<div class="packtinfobox"><span>Dr. David Robinson, in his blog on <em class="calibre22">Exploring handwritten digit classification: a tidy analysis of the MNIST dataset</em> (</span><a href="http://varianceexplained.org/r/digit-eda/" class="calibre39">http://varianceexplained.org/r/digit-eda/</a><span>), performed a beautiful exploratory data analysis of the MNIST dataset, which will help you better understand the dataset.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing a deep learning network for handwritten digit recognition</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">The <kbd class="calibre11">mxnet</kbd> library offers several functions that enable us to define the layers and activations that comprise the deep learning network. The definition of layers, the usage of activation functions, and the number of neurons to be used in each of the hidden layers is generally termed the <strong class="calibre3">network architecture</strong>. Deciding on the network architecture is more of an art than a science. Often, several iterations of experiments may be needed to decide on the right architecture for the problem. We call it an art as there are no exact rules for finding the ideal architecture. The number of layers, neurons in these layers, and the type of layers are pretty much decided through trial and error.<span class="calibre4"> </span></span></p>
<p class="mce-root"><span class="calibre4">In this section, we'll build a simple deep learning network with three hidden layers. Here is the general architecture of our network:</span></p>
<ol class="calibre12">
<li class="calibre10">The input layer is defined as the initial layer in the network. The <kbd class="calibre11">mx.symbol.Variable</kbd> MXNet function <span>defines the input layer.</span></li>
<li class="calibre10"><span>A fully-connected layer is defined, also called a dense layer, with 128 neurons as the first hidden layer in the network. </span>This can be done using the <kbd class="calibre11">mx.symbol.FullyConnected</kbd> MXNet <span>function.</span></li>
<li class="calibre10"><span>A ReLU activation function is defined as part of the network. </span>The <kbd class="calibre11">mx.symbol.Activation</kbd> <span>function helps us to define the ReLU activation function</span><span> </span><span>as part of the network.</span></li>
<li class="calibre10"><span> Define the second hidden layer; it is another dense layer with 64 neurons. </span>This can be accomplished through the <kbd class="calibre11">mx.symbol.FullyConnected</kbd> <span>function, similar to the first hidden layer.</span></li>
<li class="calibre10"><span>Apply a ReLU activation function on the second hidden layer's output. </span>This can be done through the <kbd class="calibre11">mx.symbol.Activation</kbd> <span>function.</span></li>
<li class="calibre10"><span>The final hidden layer in our network is another fully-connected layer, but with just ten outputs (equal to the number of classes). </span>This can be done through the <kbd class="calibre11">mx.symbol.FullyConnected</kbd> <span>function as well.</span></li>
<li class="calibre10"><span>The output layer needs to be defined and this should be probabilities of prediction for each class; therefore, we apply softmax at the output layer. The </span><kbd class="calibre11">mx.symbol.SoftmaxOutput</kbd> <span>function enables us to configure the softmax in the output.</span></li>
</ol>
<div class="packtinfobox"><span>We are not saying that this is the best network architecture possible for the problem, but this is the network we are going to build to demonstrate the implementation of a deep learning network with MXNet.</span></div>
<p class="mce-root"><span class="calibre4">Now that we have a blueprint in place, let's delve into coding the network using the following code block:</span></p>
<pre class="calibre16"><span># setting the working directory<br class="title-page-name"/></span><span>setwd('/home/sunil/Desktop/book/chapter 6/MNIST')<br class="title-page-name"/></span><span># function to load image files<br class="title-page-name"/></span><span>load_image_file = function(filename) {<br class="title-page-name"/></span><span><span>  </span>ret = list()<br class="title-page-name"/></span><span><span>  </span>f = file(filename, 'rb')<br class="title-page-name"/></span><span><span>  </span>readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>n<span>    </span>= readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>nrow = readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>ncol = readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>x = readBin(f, 'integer', n = n * nrow * ncol, size = 1, signed<br class="title-page-name"/>= FALSE)<br class="title-page-name"/></span><span><span>  </span>close(f)<br class="title-page-name"/></span><span><span>  </span>data.frame(matrix(x, ncol = nrow * ncol, byrow = TRUE))<br class="title-page-name"/></span><span>}<br class="title-page-name"/></span><span># function to load the label files<br class="title-page-name"/></span><span>load_label_file = function(filename) {<br class="title-page-name"/></span><span><span>  </span>f = file(filename, 'rb')<br class="title-page-name"/></span><span><span>  </span>readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>n = readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>y = readBin(f, 'integer', n = n, size = 1, signed = FALSE)<br class="title-page-name"/></span><span><span>  </span>close(f)<br class="title-page-name"/></span><span><span>  </span>y }<br class="title-page-name"/></span><span># loading the image files<br class="title-page-name"/></span><span>train = load_image_file("train-images-idx3-ubyte")<br class="title-page-name"/></span><span>test<span>  </span>= load_image_file("t10k-images-idx3-ubyte")<br class="title-page-name"/></span><span># loading the labels<br class="title-page-name"/></span><span>train.y = load_label_file("train-labels-idx1-ubyte")<br class="title-page-name"/></span><span>test.y<span>  </span>= load_label_file("t10k-labels-idx1-ubyte")<br class="title-page-name"/></span><span># lineaerly transforming the grey scale image i.e. between 0 and 255 to # 0 and 1<br class="title-page-name"/></span><span>train.x &lt;- data.matrix(train/255)<br class="title-page-name"/></span><span>test &lt;- data.matrix(test/255)<br class="title-page-name"/></span><span># verifying the distribution of the digit labels in train dataset<br class="title-page-name"/></span><span>print(table(train.y))<br class="title-page-name"/></span><span># verifying the distribution of the digit labels in test dataset<br class="title-page-name"/></span><span>print(table(test.y))</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output:<span class="calibre4"> </span></span></p>
<pre class="calibre16"><span>train.y<br class="title-page-name"/></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>   </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>5923 6742 5958 6131 5842 5421 5918 6265 5851 5949<span> <br class="title-page-name"/><br class="title-page-name"/></span></span><span>test.y<br class="title-page-name"/></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span><span> </span>980 1135 1032 1010<span>  </span>982<span>  </span>892<span>  </span>958 1028<span>  </span>974 1009<span> </span></span></pre>
<p class="mce-root">Now, define the three layers and start training the network to obtain class probabilities and ensure the results are reproducible using the following code block:</p>
<pre class="calibre16"><span># including the required mxnet library<span> <br class="title-page-name"/></span></span><span>library(mxnet)<br class="title-page-name"/></span><span># defining the input layer in the network architecture<br class="title-page-name"/></span><span>data &lt;- mx.symbol.Variable("data")<br class="title-page-name"/></span><span># defining the first hidden layer with 128 neurons and also naming the # layer as fc1<br class="title-page-name"/></span><span># passing the input data layer as input to the fc1 layer<br class="title-page-name"/></span><span>fc1 &lt;- mx.symbol.FullyConnected(data, name="fc1", num_hidden=128)<br class="title-page-name"/></span><span># defining the ReLU activation function on the fc1 output and also # naming the layer as ReLU1<br class="title-page-name"/></span><span>act1 &lt;- mx.symbol.Activation(fc1, name="ReLU1", act_type="relu")<br class="title-page-name"/></span><span># defining the second hidden layer with 64 neurons and also naming the # layer as fc2<br class="title-page-name"/></span><span># passing the previous activation layer output as input to the<br class="title-page-name"/>fc2 layer<br class="title-page-name"/></span><span>fc2 &lt;- mx.symbol.FullyConnected(act1, name="fc2", num_hidden=64)<br class="title-page-name"/></span><span># defining the ReLU activation function on the fc2 output and also <br class="title-page-name"/># naming the layer as ReLU2<br class="title-page-name"/></span><span>act2 &lt;- mx.symbol.Activation(fc2, name="ReLU2", act_type="relu")<br class="title-page-name"/></span><span># defining the third and final hidden layer in our network with 10 <br class="title-page-name"/># neurons and also naming the layer as fc3<br class="title-page-name"/></span><span># passing the previous activation layer output as input to the<br class="title-page-name"/>fc3 layer<br class="title-page-name"/></span><span>fc3 &lt;- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=10)<br class="title-page-name"/></span><span># defining the output layer with softmax activation function to obtain # class probabilities<span> <br class="title-page-name"/></span></span><span>softmax &lt;- mx.symbol.SoftmaxOutput(fc3, name="sm")<br class="title-page-name"/></span><span># defining that the experiment should run on cpu<br class="title-page-name"/></span><span>devices &lt;- mx.cpu()<br class="title-page-name"/></span><span># setting the seed for the experiment so as to ensure that the results # are reproducible<br class="title-page-name"/></span><span>mx.set.seed(0)<br class="title-page-name"/></span><span># building the model with the network architecture defined above<br class="title-page-name"/></span><span>model &lt;- mx.model.FeedForward.create(softmax, X=train.x, y=train.y,<br class="title-page-name"/></span><span>ctx=devices, num.round=10, array.batch.size=100,array.layout ="rowmajor",<br class="title-page-name"/></span><span>learning.rate=0.07, momentum=0.9,<span>  </span>eval.metric=mx.metric.accuracy,<br class="title-page-name"/></span><span>initializer=mx.init.uniform(0.07),<span> <br class="title-page-name"/></span></span><span>epoch.end.callback=mx.callback.log.train.metric(100))</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output:<span class="calibre4"> </span></span></p>
<pre class="calibre16"><span>Start training with 1 devices<br class="title-page-name"/></span><span>[1] Train-accuracy=0.885783334343384<br class="title-page-name"/></span><span>[2] Train-accuracy=0.963616671562195<br class="title-page-name"/></span><span>[3] Train-accuracy=0.97510000983874<br class="title-page-name"/></span><span>[4] Train-accuracy=0.980016676982244<br class="title-page-name"/></span><span>[5] Train-accuracy=0.984233343303204<br class="title-page-name"/></span><span>[6] Train-accuracy=0.986883342464765<br class="title-page-name"/></span><span>[7] Train-accuracy=0.98848334223032<br class="title-page-name"/></span><span>[8] Train-accuracy=0.990800007780393<br class="title-page-name"/></span><span>[9] Train-accuracy=0.991300007204215<br class="title-page-name"/></span><span>[10] Train-accuracy=0.991516673564911</span></pre>
<p class="mce-root">To make predictions on the test dataset and get the label for each observation in the test dataset, use the following code block:</p>
<pre class="calibre16"><span># making predictions on the test dataset<br class="title-page-name"/></span><span>preds &lt;- predict(model, test)<br class="title-page-name"/></span><span># verifying the predicted output<br class="title-page-name"/></span><span>print(dim(preds))<br class="title-page-name"/></span><span># getting the label for each observation in test dataset; the<br class="title-page-name"/># predicted class is the one with highest probability<br class="title-page-name"/></span><span>pred.label &lt;- max.col(t(preds)) - 1<br class="title-page-name"/></span><span># observing the distribution of predicted labels in the test dataset<br class="title-page-name"/></span><span>print(table(pred.label))</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output:</span></p>
<pre class="calibre16"><span>[1]<span>    </span>10 10000<br class="title-page-name"/></span><span>pred.label<br class="title-page-name"/></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span><span> </span>980 1149 1030 1021 1001<span>  </span>869<span>  </span>960 1001<span>  </span>964 1025<span> </span></span></pre>
<p class="mce-root">Let's check the performance of the model using the following code:</p>
<pre class="calibre16"><span># obtaining the performance of the model<br class="title-page-name"/></span><span>print(accuracy(pred.label,test.y))</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output:<span class="calibre4"> </span></span></p>
<pre class="calibre16"><span>Accuracy (PCC): 97.73%<span> <br class="title-page-name"/></span></span><span>Cohen's Kappa: 0.9748<span> <br class="title-page-name"/></span></span><span>Users accuracy:<span> <br class="title-page-name"/></span></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>98.8 99.6 98.0 97.7 98.3 96.1 97.9 96.3 96.6 97.7<span> <br class="title-page-name"/></span></span><span>Producers accuracy:<span> <br class="title-page-name"/></span></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>98.8 98.3 98.2 96.7 96.4 98.6 97.7 98.9 97.6 96.2<span> <br class="title-page-name"/></span></span><span>Confusion matrix<span> <br class="title-page-name"/></span></span><span><span>   </span>y<br class="title-page-name"/></span><span>x<span>      </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<br class="title-page-name"/></span><span><span>  </span>0<span>  </span>968<span>    </span>0<span>    </span>1<span>    </span>1<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>1<span>    </span>2<span>    </span>1<br class="title-page-name"/></span><span><span>  </span>1<span>    </span>1 1130<span>    </span>3<span>    </span>0<span>    </span>0<span>    </span>1<span>    </span>3<span>    </span>8<span>    </span>1<span>    </span>2<br class="title-page-name"/></span><span><span>  </span>2<span>    </span>0<span>    </span>1 1011<span>    </span>2<span>    </span>2<span>    </span>0<span>    </span>0 <span>  </span>11<span>    </span>3<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>3<span>    </span>1<span>    </span>2<span>    </span>6<span>  </span>987<span>    </span>0 <span>  </span>14<span>    </span>2<span>    </span>2<span>    </span>4<span>    </span>3<br class="title-page-name"/></span><span><span>  </span>4<span>    </span>1<span>    </span>0<span>    </span>2<span>    </span>1<span>  </span>965<span>    </span>2 <span>  </span>10<span>    </span>3<span>    </span>6 <span>  </span>11<br class="title-page-name"/></span><span><span>  </span>5<span>    </span>1<span>    </span>0<span>    </span>0<span>    </span>4<span>    </span>0<span>  </span>857<span>    </span>2<span>    </span>0<span>    </span>3<span>    </span>2<br class="title-page-name"/></span><span><span>  </span>6<span>    </span>5<span>    </span>2<span>    </span>3<span>    </span>0<span>    </span>4<span>    </span>5<span>  </span>938<span>    </span>0<span>    </span>3<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>7<span>    </span>0<span>    </span>0<span>    </span>2<span>    </span>2<span>    </span>1<span>    </span>1<span>    </span>0<span>  </span>990<span>    </span>3<span>    </span>2<br class="title-page-name"/></span><span><span>  </span>8<span>    </span>1<span>    </span>0<span>    </span>4<span>    </span>8<span>    </span>0<span>    </span>5<span>    </span>0<span>    </span>3<span>  </span>941<span>    </span>2<br class="title-page-name"/></span><span><span>  </span>9<span>    </span>2<span>    </span>0<span>    </span>0<span>    </span>5<span>    </span>9<span>    </span>5<span>    </span>0 <span>  </span>10<span>    </span>8<span>  </span>986</span></pre>
<p class="mce-root">To visualize the network architecture, use the following code:</p>
<pre class="calibre16"><span># Visualizing the network architecture<br class="title-page-name"/></span><span>graph.viz(model$symbol)</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output:<span class="calibre4"> </span></span></p>
<p class="CDPAlignCenter1"><img class="aligncenter73" src="assets/1b6945d7-f014-474a-b699-64cef7c3374d.png"/></p>
<p class="mce-root"><span class="calibre4">With the simple architecture running for a few minutes on a CPU-based laptop and with minimal effort, we were able to achieve an accuracy of <kbd class="calibre11">97.7%</kbd> on the test dataset. The deep learning network was able to learn to interpret the digits by seeing the images it was given as input. The accuracy of the system can be further improved by altering the architecture or by increasing the number of iterations. It may be noted that, in the earlier experiment, we ran it for 10 iterations.</span></p>
<p class="mce-root"><span class="calibre4">The number of iterations can simply be amended when model-building through the <kbd class="calibre11">num.round</kbd> parameter.<span class="calibre4"> </span>There is no hard-and-fast rule in terms of the optimal number of rounds, so this is something to be determined by trial and error. Let's build the model with 50 iterations and observe its impact on performance. The code will remain the same as the earlier project, except with the following amendment to the model-building code:</span></p>
<pre class="calibre16"><span>model &lt;- mx.model.FeedForward.create(softmax, X=train.x, y=train.y,<br class="title-page-name"/></span><span>ctx=devices, num.round=50, array.batch.size=100,array.layout ="rowmajor",<br class="title-page-name"/></span><span>learning.rate=0.07, momentum=0.9,<span> </span> eval.metric=mx.metric.accuracy,<br class="title-page-name"/></span><span>initializer=mx.init.uniform(0.07),<span> <br class="title-page-name"/></span></span><span>epoch.end.callback=mx.callback.log.train.metric(100))</span></pre>
<div class="packtinfobox"><span>Observe that the <kbd class="calibre24">num.round</kbd> parameter is now set to <kbd class="calibre24">50</kbd>, instead of the earlier value of <kbd class="calibre24">10</kbd>.</span></div>
<p class="mce-root"><span class="calibre4">This will give the following output:</span></p>
<pre class="calibre16"><span>[35] Train-accuracy=0.999933333396912<br class="title-page-name"/></span><span>[36] Train-accuracy=1<br class="title-page-name"/></span><span>[37] Train-accuracy=1<br class="title-page-name"/></span><span>[38] Train-accuracy=1<br class="title-page-name"/></span><span>[39] Train-accuracy=1<br class="title-page-name"/></span><span>[40] Train-accuracy=1<br class="title-page-name"/></span><span>[41] Train-accuracy=1<br class="title-page-name"/></span><span>[42] Train-accuracy=1<br class="title-page-name"/></span><span>[43] Train-accuracy=1<br class="title-page-name"/></span><span>[44] Train-accuracy=1<br class="title-page-name"/></span><span>[45] Train-accuracy=1<br class="title-page-name"/></span><span>[46] Train-accuracy=1<br class="title-page-name"/></span><span>[47] Train-accuracy=1<br class="title-page-name"/></span><span>[48] Train-accuracy=1<br class="title-page-name"/></span><span>[49] Train-accuracy=1<br class="title-page-name"/></span><span>[50] Train-accuracy=1<br class="title-page-name"/></span><span>[1]<span>    </span>10 10000<br class="title-page-name"/></span><span>pred.label<br class="title-page-name"/></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span><span> </span>992 1139 1029 1017<span>  </span>983<span>  </span>877<span>  </span>953 1021<span>  </span>972 1017<span> <br class="title-page-name"/></span></span><span>Accuracy (PCC): 98.21%<span> <br class="title-page-name"/></span></span><span>Cohen's Kappa: 0.9801<span> <br class="title-page-name"/></span></span><span>Users accuracy:<span> <br class="title-page-name"/></span></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>99.3 99.5 98.2 98.2 98.1 97.1 98.0 97.7 98.0 97.8<span> <br class="title-page-name"/></span></span><span>Producers accuracy:<span> <br class="title-page-name"/></span></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>98.1 99.1 98.4 97.5 98.0 98.7 98.5 98.3 98.3 97.1<span> <br class="title-page-name"/></span></span><span>Confusion matrix<span> <br class="title-page-name"/></span></span><span><span>   </span>y<br class="title-page-name"/></span><span>x<span>      </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<br class="title-page-name"/></span><span><span>  </span>0<span>  </span>973<span>    </span>0<span>    </span>2<span>    </span>2<span>    </span>1<span>    </span>3<span>    </span>5<span>    </span>1<span>    </span>3<span>    </span>2<br class="title-page-name"/></span><span><span>  </span>1<span>    </span>1 1129<span>    </span>0<span>    </span>0<span>    </span>1<span>    </span>1<span>    </span>3<span>    </span>2<span>    </span>0<span>    </span>2<br class="title-page-name"/></span><span><span>  </span>2<span>    </span>1<span>    </span>0 1013<span>    </span>1<span>    </span>3<span>    </span>0<span>    </span>0<span>    </span>9<span>    </span>2<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>3<span>    </span>0<span>    </span>1<span>    </span>5<span>  </span>992<span>    </span>0 <span>  </span>10<span>    </span>1<span>    </span>1<span>    </span>3<span>    </span>4<br class="title-page-name"/></span><span><span>  </span>4<span>    </span>0<span>    </span>0<span>    </span>2<span>    </span>0<span>  </span>963<span>    </span>2<span>    </span>7<span>    </span>1<span>    </span>1<span>    </span>7<br class="title-page-name"/></span><span><span>  </span>5<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>4<span>    </span>1<span>  </span>866<span>    </span>2<span>    </span>0<span>    </span>2<span>    </span>2<br class="title-page-name"/></span><span><span>  </span>6<span>    </span>2<span>    </span>2<span>    </span>1<span>    </span>0<span>    </span>3<span>    </span>5<span>  </span>939<span>    </span>0<span>    </span>1<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>7<span>    </span>0<span>    </span>1<span>    </span>6<span>    </span>3<span>    </span>1<span>    </span>1<span>    </span>0 1004<span>    </span>2<span>    </span>3<br class="title-page-name"/></span><span><span>  </span>8<span>    </span>1<span>    </span>1<span>    </span>3<span>    </span>4<span>    </span>0<span>    </span>2<span>    </span>1<span>    </span>3<span>  </span>955<span>    </span>2<br class="title-page-name"/></span><span><span>  </span>9<span>    </span>2<span>    </span>1<span>    </span>0<span>    </span>4<span>    </span>9<span>    </span>2<span>    </span>0<span>    </span>7<span>    </span>5<span>  </span>987</span></pre>
<p class="mce-root"><span class="calibre4">We can observe from the output that 100% accuracy was obtained with the training dataset.<span class="calibre4"> </span>However, with the test dataset, we observe the accuracy as 98%. Essentially, our model is expected to perform the same with both the training and test dataset for it to be called a good model. Unfortunately, in this case, we have encountered a situation known as <strong class="calibre3">overfitting,</strong> which means that the model we created did not generalize well. In other words, the model has trained itself with too many parameters or it got trained for too long and has become super-specialized with data in the training dataset alone; as an effect, it is not doing a good job with new data. Model generalization is something we should specifically aim for. There is a technique, known as <strong class="calibre3">dropout</strong>, that can help us to overcome the overfitting issue.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing dropout to avoid overfitting</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">Dropout is defined in the network architecture after the activation layers, and it randomly sets activations to zero. In other words, dropout randomly deletes parts of the neural network, which allows us to prevent overfitting. We can't overfit exactly to our training data when we're consistently throwing away information learned along the way. This allows our neural network to learn to generalize better.</span></p>
<p class="mce-root"><span class="calibre4">In MXNet, dropout can be easily defined as part of network architecture using the <kbd class="calibre11">mx.symbol.Dropout</kbd> function. For example, the following code defines dropouts post the first ReLU activation (<kbd class="calibre11">act1</kbd>) and second ReLU activation (<kbd class="calibre11">act2</kbd>):</span></p>
<pre class="calibre16"><span>dropout1 &lt;- mx.symbol.Dropout(data = act1, p = 0.5)<br class="title-page-name"/></span><span>dropout2 &lt;- mx.symbol.Dropout(data = act2, p = 0.</span><span>3)</span></pre>
<p class="mce-root"><span class="calibre4">The <kbd class="calibre11">data</kbd> parameter specifies the input that the dropout takes and the value of <kbd class="calibre11">p</kbd> specifies the amount of dropout to be done. In case of <kbd class="calibre11">dropout1</kbd>, we are specifying that 50% of weights are to be dropped. Again, there is no hard-and-fast rule in terms of how much dropout should be included and at what layers. This is something to be determined through trial and error.<span class="calibre4"> </span>The code with dropouts almost remains identical to the earlier project except that it now includes the dropouts after the activations:</span></p>
<pre class="calibre16"><span># code to read the dataset and transform it to train.x and train.y remains # same as earlier project, therefore that code is not shown here<br class="title-page-name"/></span><span># including the required mxnet library<span> <br class="title-page-name"/></span></span><span>library(mxnet)<br class="title-page-name"/></span><span># defining the input layer in the network architecture<br class="title-page-name"/></span><span>data &lt;- mx.symbol.Variable("data")<br class="title-page-name"/></span><span># defining the first hidden layer with 128 neurons and also naming the # layer as fc1<br class="title-page-name"/></span><span># passing the input data layer as input to the fc1 layer<br class="title-page-name"/></span><span>fc1 &lt;- mx.symbol.FullyConnected(data, name="fc1", num_hidden=128)<br class="title-page-name"/></span><span># defining the ReLU activation function on the fc1 output and also naming the layer as ReLU1<br class="title-page-name"/></span><span>act1 &lt;- mx.symbol.Activation(fc1, name="ReLU1", act_type="relu")<br class="title-page-name"/></span><span># defining a 50% dropout of weights learnt<br class="title-page-name"/></span><span>dropout1 &lt;- mx.symbol.Dropout(data = act1, p = 0.5)<br class="title-page-name"/></span><span># defining the second hidden layer with 64 neurons and also naming the layer as fc2<br class="title-page-name"/></span><span># passing the previous dropout output as input to the fc2 layer<br class="title-page-name"/></span><span>fc2 &lt;- mx.symbol.FullyConnected(dropout1, name="fc2", num_hidden=64)<br class="title-page-name"/></span><span># defining the ReLU activation function on the fc2 output and also naming the layer as ReLU2<br class="title-page-name"/></span><span>act2 &lt;- mx.symbol.Activation(fc2, name="ReLU2", act_type="relu")<br class="title-page-name"/></span><span># defining a dropout with 30% weight drop<br class="title-page-name"/></span><span>dropout2 &lt;- mx.symbol.Dropout(data = act2, p = 0.3)<br class="title-page-name"/></span><span># defining the third and final hidden layer in our network with 10 neurons and also naming the layer as fc3<br class="title-page-name"/></span><span># passing the previous dropout output as input to the fc3 layer</span><span><br class="title-page-name"/></span><span>fc3 &lt;- mx.symbol.FullyConnected(dropout2, name="fc3", num_hidden=10)<br class="title-page-name"/></span><span># defining the output layer with softmax activation function to<br class="title-page-name"/>obtain class probabilities<span> <br class="title-page-name"/></span></span><span>softmax &lt;- mx.symbol.SoftmaxOutput(fc3, name="sm")<br class="title-page-name"/></span><span># defining that the experiment should run on cpu<br class="title-page-name"/></span><span>devices &lt;- mx.cpu()<br class="title-page-name"/></span><span># setting the seed for the experiment so as to ensure that the results are reproducible<br class="title-page-name"/></span><span>mx.set.seed(0)<br class="title-page-name"/></span><span># building the model with the network architecture defined above<br class="title-page-name"/></span><span>model &lt;- mx.model.FeedForward.create(softmax, X=train.x, y=train.y, ctx=devices, num.round=50, array.batch.size=100,array.layout = "rowmajor", learning.rate=0.07, momentum=0.9,<span>  </span>eval.metric=mx.metric.accuracy, initializer=mx.init.uniform(0.07), epoch.end.callback=mx.callback.log.train.metric(100))<br class="title-page-name"/></span><span># making predictions on the test dataset<br class="title-page-name"/></span><span>preds &lt;- predict(model, test)<br class="title-page-name"/></span><span># verifying the predicted output<br class="title-page-name"/></span><span>print(dim(preds))<br class="title-page-name"/></span><span># getting the label for each observation in test dataset; the predicted class is the one with highest probability<br class="title-page-name"/></span><span>pred.label &lt;- max.col(t(preds)) - 1<br class="title-page-name"/></span><span># observing the distribution of predicted labels in the test<br class="title-page-name"/>dataset<br class="title-page-name"/></span><span>print(table(pred.label))<br class="title-page-name"/></span><span># including the rfUtilities library so as to use accuracy function<br class="title-page-name"/></span><span>library(rfUtilities)<br class="title-page-name"/></span><span># obtaining the performance of the model<br class="title-page-name"/></span><span>print(accuracy(pred.label,test.y))<br class="title-page-name"/></span><span># printing the network architecture<br class="title-page-name"/></span><span>graph.viz(model$symbol)<span> </span></span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output and the visual network architecture:</span></p>
<pre class="calibre16"><span>[35] Train-accuracy=0.958950003186862<br class="title-page-name"/></span><span>[36] Train-accuracy=0.958983335793018<br class="title-page-name"/></span><span>[37] Train-accuracy=0.958083337446054<br class="title-page-name"/></span><span>[38] Train-accuracy=0.959683336317539<br class="title-page-name"/></span><span>[39] Train-accuracy=0.95990000406901<br class="title-page-name"/></span><span>[40] Train-accuracy=0.959433337251345<br class="title-page-name"/></span><span>[41] Train-accuracy=0.959066670437654<br class="title-page-name"/></span><span>[42] Train-accuracy=0.960250004529953<br class="title-page-name"/></span><span>[43] Train-accuracy=0.959983337720235<br class="title-page-name"/></span><span>[44] Train-accuracy=0.960450003842513<br class="title-page-name"/></span><span>[45] Train-accuracy=0.960150004227956<br class="title-page-name"/></span><span>[46] Train-accuracy=0.960533337096373<br class="title-page-name"/></span><span>[47] Train-accuracy=0.962033336758614<br class="title-page-name"/></span><span>[48] Train-accuracy=0.96005000303189<br class="title-page-name"/></span><span>[49] Train-accuracy=0.961366670827071<br class="title-page-name"/></span><span>[50] Train-accuracy=0.961350003282229<br class="title-page-name"/></span><span>[1]<span>    </span>10 10000<br class="title-page-name"/></span><span>pred.label<br class="title-page-name"/></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span><span> </span>984 1143 1042 1022<span>  </span>996<span>  </span>902<span>  </span>954 1042<span>  </span>936<span>  </span>979<span> <br class="title-page-name"/></span></span><span>Accuracy (PCC): 97.3%<span> <br class="title-page-name"/></span></span><span>Cohen's Kappa: 0.97<span> <br class="title-page-name"/></span></span><span>Users accuracy:<span> <br class="title-page-name"/></span></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>98.7 98.9 98.1 97.6 98.2 97.3 97.6 97.4 94.3 94.7<span> <br class="title-page-name"/></span></span><span>Producers accuracy:<span> <br class="title-page-name"/></span></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>98.3 98.3 97.1 96.5 96.8 96.2 98.0 96.1 98.1 97.7<span> <br class="title-page-name"/></span></span><span>Confusion matrix<span> <br class="title-page-name"/></span></span><span><span>   </span>y<br class="title-page-name"/></span><span>x<span>      </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<br class="title-page-name"/></span><span><span>  </span>0<span>  </span>967<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>2<span>    </span>5<span>    </span>1<span>    </span>6<span>    </span>3<br class="title-page-name"/></span><span><span>  </span>1<span>    </span>0 1123<span>    </span>3<span>    </span>0<span>    </span>1<span>    </span>1<span>    </span>3<span>    </span>5<span>    </span>2<span>    </span>5<br class="title-page-name"/></span><span><span>  </span>2<span>    </span>1<span>    </span>2 1012<span>    </span>4<span>    </span>3<span>    </span>0<span>    </span>0 <span>  </span>14<span>    </span>4<span>    </span>2<br class="title-page-name"/></span><span><span>  </span>3<span>    </span>2<span>    </span>1<span>    </span>4<span>  </span>986<span>    </span>0<span>    </span>6<span>    </span>1<span>    </span>3 <span>  </span>12<span>    </span>7<br class="title-page-name"/></span><span><span>  </span>4<span>    </span>0<span>    </span>0<span>    </span>3<span>    </span>0<span>  </span>964<span>    </span>2<span>    </span>5<span>    </span>0<span>    </span>5 <span>  </span>17<br class="title-page-name"/></span><span><span>  </span>5<span>    </span>2<span>    </span>3<span>    </span>0<span>    </span>9<span>    </span>0<span>  </span>868<span>    </span>7<span>    </span>0<span>    </span>9<span>    </span>4<br class="title-page-name"/></span><span><span>  </span>6<span>    </span>3<span>    </span>2<span>    </span>0<span>    </span>0<span>    </span>5<span>    </span>3<span>  </span>935<span>    </span>0<span>    </span>6<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>7<span>    </span>4<span>    </span>1<span>    </span>9<span>    </span>4<span>    </span>3<span>    </span>3<span>    </span>0 1001<span>    </span>6 <span>  </span>11<br class="title-page-name"/></span><span><span>  </span>8<span>    </span>1<span>    </span>3<span>    </span>1<span>    </span>2<span>    </span>1<span>    </span>3<span>    </span>2<span>    </span>1<span>  </span>918<span>    </span>4<br class="title-page-name"/></span><span><span>  </span>9<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>5<span>    </span>5<span>    </span>4<span>    </span>0<span>    </span>3<span>    </span>6<span>  </span>956</span></pre>
<p class="CDPAlignLeft1">Take a look at the following diagram:</p>
<p class="mce-root1"><img class="aligncenter74" src="assets/0e7e2381-a190-44e2-a9cd-cb85033c0b96.png"/></p>
<p class="mce-root"><span class="calibre4">We can see from the output that dropout is now included as part of the network architecture. We also observe that this network architecture yields a lower accuracy on the test dataset when compared with our initial project. One reason could be that the dropout percentages (50% and 30%) we included are too high. We could play with these percentages and rebuild the model to determine whether the accuracy gets better. The idea, however, is to demonstrate the use of dropout as a regularization technique so as to avoid overfitting in deep neural networks.</span></p>
<p class="mce-root"><span class="calibre4">Apart from dropout, there are other techniques you could employ to avoid an overfitting situation:</span></p>
<ul class="calibre9">
<li class="calibre10"><span><strong class="calibre1">Addition of data</strong>: Adding more training data.</span></li>
<li class="calibre10"><span><strong class="calibre1">Data augmentation</strong>: Creating additional data synthetically by applying techniques such as flipping, distorting, adding random noise, and rotation. The following screenshot shows sample images created after applying data augmentation:</span></li>
</ul>
<p class="CDPAlignCenter1"><img class="aligncenter75" src="assets/cdd28deb-0725-4120-aeec-075ba07f4e98.png"/></p>
<div class="packtfigref">Sample images from applying data augmentation</div>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Reducing complexity of the network architecture</strong>: <span>Fewer</span> layers, fewer epochs, and so on.</li>
<li class="calibre10"><span><strong class="calibre1">Batch normalization</strong>: A process of ensuring that the weights generated in the network do not push very high or very low. This is generally achieved by subtracting the mean and dividing by the standard deviation of all weights at a layer from each weight in a layer. It shields against overfitting, performs regularization, and significantly improves the training speed.<span>  The </span></span><kbd class="calibre11">mx.sym.batchnorm()</kbd> <span>function enables us to define batch normalization after the activation.</span><span> </span></li>
</ul>
<p class="mce-root"><span class="calibre4">We will not focus on developing another project with batch normalization as using this function in the project is very similar to the other functions we used in our earlier projects. So far, we have focused on increasing the epochs to improve the performance of the model, another option is to try a different architecture and evaluate whether that improves the accuracy on the test dataset. On that note, let's explore LeNet, which is specifically designed for optical character recognition in documents.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing the LeNet architecture with the MXNet library</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">In their 1998 paper, <em class="calibre15">Gradient-Based Learning Applied to Document Recognition</em>, LeCun et al. introduced the LeNet architecture.</span></p>
<p class="mce-root"><span class="calibre4">The LeNet architecture consists of two sets of convolutional, activation, and pooling layers, followed by a fully-connected layer, activation, another fully-connected layer, and finally a softmax classifier. The following diagram illustrates the LeNet architecture:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter76" src="assets/3fe3623a-6aaf-4b55-b59a-1de8f19a48ea.png"/></p>
<div class="packtfigref">LeNet architecture</div>
<p class="mce-root"><span class="calibre4">Now, let's implement the LeNet architecture with the <kbd class="calibre11">mxnet</kbd> library in our project using the following code block:</span></p>
<pre class="calibre16"><span>## setting the working directory<br class="title-page-name"/></span><span>setwd('/home/sunil/Desktop/book/chapter 6/MNIST')<br class="title-page-name"/></span><span># function to load image files<br class="title-page-name"/></span><span>load_image_file = function(filename) {<br class="title-page-name"/></span><span><span>  </span>ret = list()<br class="title-page-name"/></span><span><span>  </span>f = file(filename, 'rb')<br class="title-page-name"/></span><span><span>  </span>readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>n<span>    </span>= readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>nrow = readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>ncol = readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>x = readBin(f, 'integer', n = n * nrow * ncol, size = 1, signed<br class="title-page-name"/>= FALSE)<br class="title-page-name"/></span><span><span>  </span>close(f)<br class="title-page-name"/></span><span><span>  </span>data.frame(matrix(x, ncol = nrow * ncol, byrow = TRUE))<br class="title-page-name"/></span><span>}<br class="title-page-name"/></span><span># function to load label files<br class="title-page-name"/></span><span>load_label_file = function(filename) {<br class="title-page-name"/></span><span><span>  </span>f = file(filename, 'rb')<br class="title-page-name"/></span><span><span>  </span>readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>n = readBin(f, 'integer', n = 1, size = 4, endian = 'big')<br class="title-page-name"/></span><span><span>  </span>y = readBin(f, 'integer', n = n, size = 1, signed = FALSE)<br class="title-page-name"/></span><span><span>  </span>close(f)<br class="title-page-name"/></span><span><span>  </span>y<br class="title-page-name"/></span><span>}<br class="title-page-name"/></span><span># load images<br class="title-page-name"/></span><span>train = load_image_file("train-images-idx3-ubyte")<br class="title-page-name"/></span><span>test<span>  </span>= load_image_file("t10k-images-idx3-ubyte")<br class="title-page-name"/></span><span># converting the train and test data into a format as required by LeNet<br class="title-page-name"/></span><span>train.x &lt;- t(data.matrix(train))<br class="title-page-name"/></span><span>test &lt;- t(data.matrix(test))<br class="title-page-name"/></span><span># loading the labels<br class="title-page-name"/></span><span>train.y = load_label_file("train-labels-idx1-ubyte")<br class="title-page-name"/></span><span>test.y<span>  </span>= load_label_file("t10k-labels-idx1-ubyte")<br class="title-page-name"/></span><span># linearly transforming the grey scale image i.e. between 0 and 255 to # 0 and 1<br class="title-page-name"/></span><span>train.x &lt;- train.x/255<br class="title-page-name"/></span><span>test &lt;- test/255<br class="title-page-name"/></span><span># including the required mxnet library<span> <br class="title-page-name"/></span></span><span>library(mxnet)<br class="title-page-name"/></span><span># input<br class="title-page-name"/></span><span>data &lt;- mx.symbol.Variable('data')<br class="title-page-name"/></span><span># first convolution layer<br class="title-page-name"/></span><span>conv1 &lt;- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)<br class="title-page-name"/></span><span># applying the tanh activation function<br class="title-page-name"/></span><span>tanh1 &lt;- mx.symbol.Activation(data=conv1, act_type="tanh")<br class="title-page-name"/></span><span># applying max pooling<span> <br class="title-page-name"/></span></span><span>pool1 &lt;- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))<br class="title-page-name"/></span><span># second conv<br class="title-page-name"/></span><span>conv2 &lt;- mx.symbol.Convolution(data=pool1, kernel=c(5,5), num_filter=50)<br class="title-page-name"/></span><span># applying the tanh activation function again<br class="title-page-name"/></span><span>tanh2 &lt;- mx.symbol.Activation(data=conv2, act_type="tanh")<br class="title-page-name"/></span><span>#performing max pooling again<br class="title-page-name"/></span><span>pool2 &lt;- mx.symbol.Pooling(data=tanh2, pool_type="max",<br class="title-page-name"/></span><span><span>                           </span>kernel=c(2,2), stride=c(2,2))<br class="title-page-name"/></span><span># flattening the data<br class="title-page-name"/></span><span>flatten &lt;- mx.symbol.Flatten(data=pool2)<br class="title-page-name"/></span><span># first fullconnected later<br class="title-page-name"/></span><span>fc1 &lt;- mx.symbol.FullyConnected(data=flatten, num_hidden=500)<br class="title-page-name"/></span><span># applying the tanh activation function<br class="title-page-name"/></span><span>tanh3 &lt;- mx.symbol.Activation(data=fc1, act_type="tanh")<br class="title-page-name"/></span><span># second fullconnected layer<br class="title-page-name"/></span><span>fc2 &lt;- mx.symbol.FullyConnected(data=tanh3, num_hidden=10)<br class="title-page-name"/></span><span># defining the output layer with softmax activation function to obtain # class probabilities<span> <br class="title-page-name"/></span></span><span>lenet &lt;- mx.symbol.SoftmaxOutput(data=fc2)<br class="title-page-name"/></span><span># transforming the train and test dataset into a format required by <br class="title-page-name"/># MxNet functions<br class="title-page-name"/></span><span>train.array &lt;- train.x<br class="title-page-name"/></span><span>dim(train.array) &lt;- c(28, 28, 1, ncol(train.x))<br class="title-page-name"/></span><span>test.array &lt;- test<br class="title-page-name"/></span><span>dim(test.array) &lt;- c(28, 28, 1, ncol(test))<br class="title-page-name"/></span><span># setting the seed for the experiment so as to ensure that the<br class="title-page-name"/># results are reproducible<br class="title-page-name"/></span><span>mx.set.seed(0)<br class="title-page-name"/></span><span># defining that the experiment should run on cpu<br class="title-page-name"/></span><span>devices &lt;- mx.cpu()<br class="title-page-name"/></span><span># building the model with the network architecture defined above<br class="title-page-name"/></span><span>model &lt;- mx.model.FeedForward.create(lenet, X=train.array, y=train.y,<br class="title-page-name"/></span><span>ctx=devices, num.round=3, array.batch.size=100, learning.rate=0.05,<span> <br class="title-page-name"/></span></span><span>momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy,<span> <br class="title-page-name"/></span></span><span><span>           </span>epoch.end.callback=mx.callback.log.train.metric(100))<br class="title-page-name"/></span><span># making predictions on the test dataset<br class="title-page-name"/></span><span>preds &lt;- predict(model, test.array)<br class="title-page-name"/></span><span># getting the label for each observation in test dataset; the<br class="title-page-name"/># predicted class is the one with highest probability<br class="title-page-name"/></span><span>pred.label &lt;- max.col(t(preds)) - 1<br class="title-page-name"/></span><span># including the rfUtilities library so as to use accuracy<br class="title-page-name"/>function<br class="title-page-name"/></span><span>library(rfUtilities)<br class="title-page-name"/></span><span># obtaining the performance of the model<br class="title-page-name"/></span><span>print(accuracy(pred.label,test.y))<br class="title-page-name"/></span><span># printing the network architecture<br class="title-page-name"/></span><span>graph.viz(model$symbol,direction="LR")</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output and the visual network architecture:<span class="calibre4"> </span></span></p>
<pre class="calibre16"><span>Start training with 1 devices<br class="title-page-name"/></span><span>[1] Train-accuracy=0.678916669438283<br class="title-page-name"/></span><span>[2] Train-accuracy=0.978666676680247<br class="title-page-name"/></span><span>[3] Train-accuracy=0.98676667680343<br class="title-page-name"/></span><span>Accuracy (PCC): 98.54%<span> <br class="title-page-name"/></span></span><span>Cohen's Kappa: 0.9838<span> <br class="title-page-name"/></span></span><span>Users accuracy:<span> <br class="title-page-name"/></span></span><span><span>    </span>0 <span>    </span>1 <span>    </span>2 <span>    </span>3 <span>    </span>4 <span>    </span>5 <span>    </span>6 <span>    </span>7 <span>    </span>8 <span>    </span>9<span> <br class="title-page-name"/></span></span><span><span> </span>99.8 100.0<span>  </span>97.0<span>  </span>98.4<span>  </span>98.9<span>  </span>98.2<span>  </span>98.2<span>  </span>98.7<span>  </span>98.2<span>  </span>97.8<span> <br class="title-page-name"/></span></span><span>Producers accuracy:<span> <br class="title-page-name"/></span></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>98.0 96.9 99.1 99.3 99.0 99.3 99.6 97.7 98.7 98.3 <span> <br class="title-page-name"/></span></span><span>Confusion matrix<span> <br class="title-page-name"/></span></span><span><span>   </span>y<br class="title-page-name"/></span><span>x<span>      </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<br class="title-page-name"/></span><span><span>  </span>0<span>  </span>978<span>    </span>0<span>    </span>2<span>    </span>2<span>    </span>1<span>    </span>3<span>    </span>7<span>    </span>0<span>    </span>4<span>    </span>1<br class="title-page-name"/></span><span><span>  </span>1<span>    </span>0 1135 <span>  </span>15<span>    </span>2<span>    </span>1<span>    </span>0<span>    </span>5<span>    </span>7<span>    </span>1<span>    </span>5<br class="title-page-name"/></span><span><span>  </span>2<span>    </span>0<span>    </span>0 1001<span>    </span>2<span>    </span>1<span>    </span>1<span>    </span>0<span>    </span>3<span>    </span>2<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>3<span>    </span>0<span>    </span>0<span>    </span>0<span>  </span>994<span>    </span>0<span>    </span>5<span>    </span>0<span>    </span>1<span>    </span>1<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>4<span>    </span>0<span>    </span>0<span>    </span>1<span>    </span>0<span>  </span>971<span>    </span>0<span>    </span>1<span>    </span>0<span>    </span>0<span>    </span>8<br class="title-page-name"/></span><span><span>  </span>5<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>3<span>    </span>0<span>  </span>876<span>    </span>2<span>    </span>0<span>    </span>1<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>6<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>2<span>    </span>1<span>  </span>941<span>    </span>0<span>    </span>1<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>7<span>    </span>1<span>    </span>0<span>    </span>7<span>    </span>1<span>    </span>3<span>    </span>1<span>    </span>0 1015<span>    </span>3<span>    </span>8<br class="title-page-name"/></span><span><span>  </span>8<span>    </span>1<span>    </span>0<span>    </span>6<span>    </span>1<span>    </span>1<span>    </span>1<span>    </span>2<span>    </span>1<span>  </span>956<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>9<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>5<span>    </span>2<span>    </span>4<span>    </span>0<span>    </span>1<span>    </span>5<span>  </span>987</span></pre>
<p class="mce-root">Take a look at the following diagram:</p>
<p class="CDPAlignCenter1"><img class="aligncenter77" src="assets/75a79bd5-f0a2-4b1a-a66e-25c17044489d.png"/></p>
<p class="mce-root"><span class="calibre4">The code ran for less than 5 minutes on my 4-core CPU box, but still got us a 98% accuracy on the test dataset with just three epochs. We can also see that we obtained 98% accuracy with both the training and test datasets, confirming that there is no overfitting.<span class="calibre4"> </span></span></p>
<p class="mce-root"><span class="calibre4">We see <kbd class="calibre11">tanh</kbd> is used as the activation function; let's experiment and see whether it has any impact if we change it to ReLU. The code for the project will be identical except that we need to find and replace <kbd class="calibre11">tanh</kbd> with ReLU. We will not repeat the code as the only lines that have changed from the earlier project are as follows:</span></p>
<pre class="calibre16"><span>ReLU1 &lt;- mx.symbol.Activation(data=conv1, act_type="relu")<br class="title-page-name"/></span><span>pool1 &lt;- mx.symbol.Pooling(data=ReLU1, pool_type="max",<br class="title-page-name"/></span><span><span>                           </span>kernel=c(2,2), stride=c(2,2))<br class="title-page-name"/></span><span>ReLU2 &lt;- mx.symbol.Activation(data=conv1, act_type="relu")<br class="title-page-name"/></span><span>pool2 &lt;- mx.symbol.Pooling(data=ReLU2, pool_type="max",<br class="title-page-name"/></span><span><span>                           </span>kernel=c(2,2), stride=c(2,2))<br class="title-page-name"/></span><span>ReLU3 &lt;- mx.symbol.Activation(data=conv1, act_type="relu")<br class="title-page-name"/></span><span>fc2 &lt;- mx.symbol.FullyConnected(data=ReLU3, num_hidden=10)</span></pre>
<p class="mce-root"><span class="calibre4">You will get the following output on running the code with ReLU as the activation function:<span class="calibre4"> </span></span></p>
<pre class="calibre16"><span>Start training with 1 devices<br class="title-page-name"/></span><span>[1] Train-accuracy=0.627283334874858<br class="title-page-name"/></span><span>[2] Train-accuracy=0.979916676084201<br class="title-page-name"/></span><span>[3] Train-accuracy=0.987366676231225<br class="title-page-name"/></span><span>Accuracy (PCC): 98.36%<span> <br class="title-page-name"/></span></span><span>Cohen's Kappa: 0.9818<span> <br class="title-page-name"/></span></span><span>Users accuracy:<span> <br class="title-page-name"/></span></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>99.8 99.7 97.9 99.4 98.6 96.5 97.7 98.2 97.4 97.9<span> <br class="title-page-name"/></span></span><span>Producers accuracy:<span> <br class="title-page-name"/></span></span><span><span>   </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<span> <br class="title-page-name"/></span></span><span>97.5 97.2 99.6 95.6 99.7 99.2 99.7 98.0 99.6 98.2<span> <br class="title-page-name"/></span></span><span>Confusion matrix<span> <br class="title-page-name"/></span></span><span><span>   </span>y<br class="title-page-name"/></span><span>x<span>      </span>0<span>    </span>1<span>    </span>2<span>    </span>3<span>    </span>4<span>    </span>5<span>    </span>6<span>    </span>7<span>    </span>8<span>    </span>9<br class="title-page-name"/></span><span><span>  </span>0<span>  </span>978<span>    </span>0<span>    </span>3<span>    </span>1<span>    </span>1<span>    </span>2 <span>  </span>12<span>    </span>0<span>    </span>5<span>    </span>1<br class="title-page-name"/></span><span><span>  </span>1<span>    </span>1 1132<span>    </span>6<span>    </span>0<span>    </span>2<span>    </span>1<span>    </span>5 <span>  </span>11<span>    </span>1<span>    </span>6<br class="title-page-name"/></span><span><span>  </span>2<span>    </span>0<span>    </span>0 1010<span>    </span>1<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>1<span>    </span>2<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>3<span>    </span>0<span>    </span>2<span>    </span>4 1004<span>    </span>0 <span>  </span>23<span>    </span>1<span>    </span>3<span>    </span>9<span>    </span>4<br class="title-page-name"/></span><span><span>  </span>4<span>    </span>0<span>    </span>0<span>    </span>1<span>    </span>0<span>  </span>968<span>    </span>0<span>    </span>1<span>    </span>0<span>    </span>0<span>    </span>1<br class="title-page-name"/></span><span><span>  </span>5<span>    </span>0<span>    </span>1<span>    </span>0<span>    </span>1<span>    </span>0<span>  </span>861<span>    </span>2<span>    </span>0<span>    </span>3<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>6<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>3<span>  </span>936<span>    </span>0<span>    </span>0<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>7<span>    </span>1<span>    </span>0<span>    </span>6<span>    </span>3<span>    </span>0<span>    </span>1<span>    </span>0 1010<span>    </span>1<span>    </span>9<br class="title-page-name"/></span><span><span>  </span>8<span>    </span>0<span>    </span>0<span>    </span>2<span>    </span>0<span>    </span>1<span>    </span>0<span>    </span>1<span>    </span>0<span>  </span>949<span>    </span>0<br class="title-page-name"/></span><span><span>  </span>9<span>    </span>0<span>    </span>0<span>    </span>0<span>    </span>0 <span>  </span>10<span>    </span>1<span>    </span>0<span>    </span>3<span>    </span>4<span>  </span>988</span></pre>
<p class="mce-root"><span class="calibre4">With ReLU being used as the activation function, we do not see a significant improvement in the accuracy. It stayed at 98%, which is the same as obtained with the <kbd class="calibre11">tanh</kbd> activation function.<span class="calibre4"> </span></span></p>
<p class="mce-root"><span class="calibre4">As a next step, we could try to rebuild the model with additional epochs to see whether the accuracy improves. Alternatively, we could try tweaking the number of filters and filter sizes per convolutional layer to see what happens! Further experiments could also include adding more layers of several kinds. We don't know what the result is going to be unless we experiment!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing computer vision with pretrained models</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">In</span> <a href="d8e2df34-05df-451e-88ce-62fdf17184d4.xhtml" class="calibre8">Chapter 1</a><span class="calibre4">, <em class="calibre15">Exploring the Machine Learning Landscape</em>, we touched upon a concept called</span> <strong class="calibre3">transfer learning</strong><span class="calibre4">. The idea is to take the knowledge learned in a model and apply it to another related task. Transfer learning is used on almost all computer vision tasks nowadays. It's rare to train models from scratch unless there is a huge labeled dataset available for training.</span> </p>
<p class="mce-root"><span class="calibre4">Generally, in computer vision, CNNs try to detect edges in the earlier layers, shapes in the middle layer, and some task-specific features in the later layers. Irrespective of the image to be detected by the CNNs, the function of the earlier and middle layers remains the same, which makes it possible to exploit the knowledge gained by a pretrained model. With transfer learning, we can reuse the early and middle layers and only retrain the later layers. It helps us to leverage the labeled data of the task it was initially trained on.</span></p>
<p class="mce-root"><span class="calibre4">Transfer learning offers two main advantages: it saves us training time and ensures that we have a good model even if we have a lot less labelled training data.</span></p>
<p class="mce-root"><span class="calibre4"><kbd class="calibre11">Xception</kbd>, <kbd class="calibre11">VGG16</kbd>, <kbd class="calibre11">VGG19</kbd>, <kbd class="calibre11">ResNet50</kbd>, <kbd class="calibre11">InceptionV3</kbd>, <kbd class="calibre11">InceptionResNetV2</kbd>, <kbd class="calibre11">MobileNet</kbd>, <kbd class="calibre11">DenseNet</kbd>, <kbd class="calibre11">NASNet</kbd>, <kbd class="calibre11">MobileNetV2</kbd>, <kbd class="calibre11">QuocNet</kbd>, <kbd class="calibre11">AlexNet</kbd>, <kbd class="calibre11">Inception</kbd> (GoogLeNet), and <kbd class="calibre11">BN-Inception-v2</kbd> are some widely-used pretrained models. While we won't delve into the details of each of these pretrained models, the idea of this section is to implement a project to detect the contents of images (input) by making use of a pretrained model through MXNet.<span class="calibre4"> </span></span></p>
<p class="mce-root"><span class="calibre4">In the code presented in this section, we make use of the pretrained Inception-BatchNorm network to predict the class of an image. The pretrained model needs to be downloaded to the working directory prior to running the code. The model can be downloaded from <a href="http://data.mxnet.io/mxnet/data/Inception.zip" class="calibre8">http://data.mxnet.io/mxnet/data/Inception.zip</a>. Let's explore the following code to label a few test images using the <kbd class="calibre11">inception_bn</kbd> pretrained model:</span></p>
<pre class="calibre16"><span># loading the required libraries<br class="title-page-name"/></span><span>library(mxnet)<br class="title-page-name"/></span><span>library(imager)<br class="title-page-name"/></span><span># loading the inception_bn model to memory<br class="title-page-name"/></span><span>model = mx.model.load("/home/sunil/Desktop/book/chapter 6/Inception/Inception_BN", iteration=39)<br class="title-page-name"/></span><span># loading the mean image<br class="title-page-name"/></span><span>mean.img = as.array(mx.nd.load("/home/sunil/Desktop/book/chapter 6/Inception/mean_224.nd")[["mean_img"]])<br class="title-page-name"/></span><span># loading the image that need to be classified<br class="title-page-name"/></span><span>im &lt;- load.image("/home/sunil/Desktop/book/chapter 6/image1.jpeg")<br class="title-page-name"/></span><span># displaying the image<br class="title-page-name"/></span><span>plot(im)</span></pre>
<p class="mce-root"><span class="calibre4">This will result in the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter78" src="assets/15bfe7cc-5c35-4403-b29f-14806e65f863.png"/></p>
<p class="mce-root">To process the images and predict the image IDs that have the highest probability of using the pretrained model, we use the following code:</p>
<pre class="calibre16"><span># function to pre-process the image so as to be consumed by predict function that is using inception_bn model<br class="title-page-name"/></span><span>preproc.image &lt;- function(im, mean.image) {<br class="title-page-name"/></span><span><span>  </span># crop the image<br class="title-page-name"/></span><span><span>  </span>shape &lt;- dim(im)<br class="title-page-name"/></span><span><span>  </span>short.edge &lt;- min(shape[1:2])<br class="title-page-name"/></span><span><span>  </span>xx &lt;- floor((shape[1] - short.edge) / 2)<br class="title-page-name"/></span><span><span>  </span>yy &lt;- floor((shape[2] - short.edge) / 2)<br class="title-page-name"/></span><span><span>  </span>cropped &lt;- crop.borders(im, xx, yy)<br class="title-page-name"/></span><span><span>  </span># resize to 224 x 224, needed by input of the model.<br class="title-page-name"/></span><span><span>  </span>resized &lt;- resize(cropped, 224, 224)<br class="title-page-name"/></span><span><span>  </span># convert to array (x, y, channel)<br class="title-page-name"/></span><span><span>  </span>arr &lt;- as.array(resized) * 255<br class="title-page-name"/></span><span><span>  </span>dim(arr) &lt;- c(224, 224, 3)<br class="title-page-name"/></span><span><span>  </span># subtract the mean<br class="title-page-name"/></span><span><span>  </span>normed &lt;- arr - mean.img<br class="title-page-name"/></span><span><span>  </span># Reshape to format needed by mxnet (width, height, channel,<br class="title-page-name"/>num)<br class="title-page-name"/></span><span><span>  </span>dim(normed) &lt;- c(224, 224, 3, 1)<br class="title-page-name"/></span><span><span>  </span>return(normed)<br class="title-page-name"/></span><span>}<br class="title-page-name"/></span><span># calling the image pre-processing function on the image to be classified<br class="title-page-name"/></span><span>normed &lt;- preproc.image(im, mean.img)<br class="title-page-name"/></span><span># predicting the probabilties of labels for the image using the pre-trained model<br class="title-page-name"/></span><span>prob &lt;- predict(model, X=normed)<br class="title-page-name"/></span><span># sorting and filtering the top three labels with highest<br class="title-page-name"/>probabilities<br class="title-page-name"/></span><span>max.idx &lt;- order(prob[,1], decreasing = TRUE)[1:3]<br class="title-page-name"/></span><span># printing the ids with highest probabilities<br class="title-page-name"/></span><span>print(max.idx)</span></pre>
<p class="mce-root"><span class="calibre4">This will result in the following output with the IDs of the highest probabilities:</span></p>
<pre class="calibre16"><span>[1] 471 627 863</span></pre>
<p class="mce-root">Let's print the labels that correspond to the top-three predicted IDs with the highest probabilities using the following code:</p>
<pre class="calibre16"><span># loading the pre-trained labels from inception_bn model<span> <br class="title-page-name"/></span></span><span>synsets &lt;- readLines("/home/sunil/Desktop/book/chapter<br class="title-page-name"/>6/Inception/synset.txt")<br class="title-page-name"/></span><span># printing the english labels corresponding to the top 3 ids with highest probabilities<br class="title-page-name"/></span><span>print(paste0("Predicted Top-classes: ", synsets[max.idx]))</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output:</span></p>
<pre class="calibre16"><span>[1] "Predicted Top-classes: n02948072 candle, taper, wax light" <span>       <br class="title-page-name"/></span></span><span>[2] "Predicted Top-classes: n03666591 lighter, light, igniter, ignitor"<br class="title-page-name"/></span><span>[3] "Predicted Top-classes: n04456115 torch" <span>  </span></span><span><span>   </span></span></pre>
<p class="mce-root"><span class="calibre4">From the output, we see that it has correctly labelled the image that is passed as input. We can test a few more images with the following code to confirm that the classification is done correctly:</span></p>
<pre class="calibre16"><span>im2 &lt;- load.image("/home/sunil/Desktop/book/chapter 6/image2.jpeg")<br class="title-page-name"/></span><span>plot(im2)</span><span><br class="title-page-name"/></span><span>normed &lt;- preproc.image(im2, mean.img)<br class="title-page-name"/></span><span>prob &lt;- predict(model, X=normed)<br class="title-page-name"/></span><span>max.idx &lt;- order(prob[,1], decreasing = TRUE)[1:3]<br class="title-page-name"/></span><span>print(paste0("Predicted Top-classes: ", synsets[max.idx]))</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter79" src="assets/c8595173-55f3-466a-a41e-f56c844220ad.png"/></p>
<p class="mce-root">Take a look at the following code:</p>
<pre class="calibre16"><span>[1] "Predicted Top-classes: n03529860 home theater, home theatre"<span>   <br class="title-page-name"/></span></span><span>[2] "Predicted Top-classes: n03290653 entertainment center"<span>         </span></span><span>[3] "Predicted Top-classes: n04404412 television, television system"</span></pre>
<p class="mce-root">Likewise, we can try for a third image using the following code:</p>
<pre class="calibre16"><span># getting the labels for third image<br class="title-page-name"/></span><span>im3 &lt;- load.image("/home/sunil/Desktop/book/chapter<br class="title-page-name"/>6/image3.jpeg")<br class="title-page-name"/></span><span>plot(im3)<br class="title-page-name"/></span><span>normed &lt;- preproc.image(im3, mean.img)<br class="title-page-name"/></span><span>prob &lt;- predict(model, X=normed)<br class="title-page-name"/></span><span>max.idx &lt;- order(prob[,1], decreasing = TRUE)[1:3]<br class="title-page-name"/></span><span>print(paste0("Predicted Top-classes: ", synsets[max.idx]))</span></pre>
<p class="mce-root"><span class="calibre4">This will give the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter80" src="assets/0549ed49-82c2-4ead-9f2d-8c43781f2dc1.png"/></p>
<p class="mce-root">Take a look at the following output:</p>
<pre class="calibre16"><span>[1] </span><span>"Predicted Top-classes: n04326547 stone wall"<span> <br class="title-page-name"/></span></span><span>[2] "Predicted Top-classes: n03891251 park bench"<span> <br class="title-page-name"/></span></span><span>[3] "Predicted Top-classes: n04604644 worm fence, snake fence, snake-rail fence, Virginia fence"</span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">In this chapter, we learned about computer vision and its association with deep learning. We explored a specific type of deep learning algorithm, CNNs, that is widely used in computer vision. We studied an open source deep learning framework called MXNet. After a detailed discussion of the MNIST dataset, we built models using various network architectures and successfully classified the handwritten digits in the MNIST dataset. At the end of the chapter, we delved into the concept of transfer learning and explored its association with computer vision. The last project we built in this chapter classified images using an Inception-BatchNorm pretrained model.<span class="calibre4"> </span></span></p>
<p class="mce-root"><span class="calibre4">In the next chapter, we will explore an unsupervised learning algorithm called the autoencoder neural network. I am really excited to implement a project to capture credit card fraud using autoencoders. Are you game? Let's go!</span></p>


            </article>

            
        </section>
    </body></html>