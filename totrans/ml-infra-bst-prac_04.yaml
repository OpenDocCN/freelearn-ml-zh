- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Data in Software Systems – Text, Images, Code, and Their Annotations
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件系统中的数据——文本、图像、代码及其标注
- en: '**Machine learning** (**ML**) systems are data-hungry applications, and they
    like their data well prepared for training and inference. Although it may sound
    obvious, it is more important to scrutinize the properties of data than to select
    an algorithm to process the data. The data, however, can come in many different
    formats and can be from different sources. We can consider data in its raw format
    – for example, a text document or an image file. We can also consider data in
    a format that is specific to a task at hand – for example, tokenized text (where
    words are divided into tokens) or an image with bounding boxes (where objects
    are identified and enclosed in rectangles).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）系统是数据需求大的应用，它们喜欢数据在训练和推理前已经准备妥当。尽管这听起来可能很显然，但比选择一个处理数据的算法更重要的是仔细审查数据的属性。然而，数据可以以许多不同的格式出现，并来自不同的来源。我们可以考虑数据以原始格式——例如，文本文档或图像文件。我们还可以考虑数据以特定于当前任务的手动格式——例如，分词文本（其中单词被分成标记）或带有边界框的图像（其中对象被识别并包含在矩形内）。'
- en: When considering the end user system, what we can do with the data and how we
    handle the data becomes crucial. However, identifying important elements in the
    data and transforming it into a format that is useful for ML algorithms depends
    on what our task is and which algorithm we use. Therefore, in this chapter, we
    will work both with data and with algorithms to process it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当考虑最终用户系统时，我们可以用数据做什么以及我们如何处理数据变得至关重要。然而，识别数据中的重要元素并将其转换为对机器学习算法有用的格式取决于我们的任务和使用的算法。因此，在本章中，我们将同时处理数据和算法来处理它。
- en: In this chapter, we will introduce three data types – images, text, and formatted
    text (program source code). We will explore how each of these types of data can
    be used in ML, how they should be annotated, and for what purpose.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍三种数据类型——图像、文本和格式化文本（程序源代码）。我们将探讨每种类型的数据如何在机器学习中使用，它们应该如何标注，以及用于什么目的。
- en: 'Introducing these three types of data provides us with the possibility to explore
    different ways of annotating these sources of data. Therefore, in this chapter,
    we will focus on the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍这三种类型的数据为我们提供了探索这些数据源不同标注方式的可能性。因此，在本章中，我们将重点关注以下内容：
- en: Raw data and features – what are the differences?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始数据和特征——它们之间有什么区别？
- en: Every data has its purpose – annotations and tasks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每种数据都有其用途——标注和任务
- en: Where different types of data can be used together – an outlook on multi-modal
    data models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同类型的数据可以一起使用的地方——多模态数据模型展望
- en: Raw data and features – what are the differences?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据和特征——它们之间有什么区别？
- en: ML systems are data-hungry. They rely on the data to be trained and to make
    inferences. However, not all data is equally important. Before the era of **deep
    learning** (**DL**), the data was supposed to be processed in order to be used
    in ML. Before DL, the algorithms were limited in the amount of data that could
    be used for training. The storage and memory limitations were also limited, and
    therefore, ML engineers had to prepare the data much more than for DL. For example,
    ML engineers needed to spend more effort to find a small but still representative
    sample of data for training. After the introduction of DL, ML models can find
    complex patterns in much larger datasets. Therefore, the work of ML engineers
    is now focused on finding sufficiently large, and representative, datasets.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）系统对数据的需求很大。它们依赖于数据进行训练和推理。然而，并非所有数据都同等重要。在深度学习（**DL**）时代之前，数据需要经过处理才能用于机器学习。在深度学习之前，算法在可用于训练的数据量方面受到限制。存储和内存限制也有限，因此，机器学习工程师必须为深度学习准备更多的数据。例如，机器学习工程师需要花费更多精力来找到一个既小又具有代表性的数据样本用于训练。深度学习引入后，机器学习模型可以在更大的数据集中找到复杂的模式。因此，机器学习工程师的工作现在集中在寻找足够大且具有代表性的数据集。
- en: Classical ML systems – that is, non-DL systems – require data in a tabular form
    in order to make inferences, and therefore it is important to design the right
    feature extraction mechanisms for this kind of system.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 经典机器学习系统——即非深度学习系统——需要表格形式的数据来进行推理，因此为这类系统设计正确的特征提取机制非常重要。
- en: 'DL systems, on the other hand, require minimal data processing and can learn
    patterns from data in its (almost) raw format. Minimal processing of data is needed
    as DL systems need a bit of different information about the data for different
    tasks; they also extract information from the raw data by themselves. For example,
    they can capture the context of a text without the need to manually process it.
    *Figure 3**.1* illustrates these differences between different types of data based
    on the tasks that can be performed on them. In this case, the data is in the form
    of images:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，深度学习系统需要最少的数据处理，并且可以从数据（几乎）原始格式中学习模式。由于深度学习系统需要为不同任务获取一些关于数据的不同信息，因此需要最少的数据处理；它们还可以自行从原始数据中提取信息。例如，它们可以捕捉文本的上下文，而无需手动处理。*图3.1*展示了基于可以执行的任务的不同类型数据之间的这些差异。在这种情况下，数据以图像的形式存在：
- en: '![Figure 3.1 – Types of learning systems and the data that they require for
    images](img/B19548_03_1.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – 学习系统的类型及其对图像所需的数据](img/B19548_03_1.jpg)'
- en: Figure 3.1 – Types of learning systems and the data that they require for images
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 学习系统的类型及其对图像所需的数据
- en: Raw images are often used for further processing, but they can be used in such
    tasks as image classification. The task of image classification relates to when
    the input to the algorithm is the raw image, and the output is the class of the
    image. We often see these kinds of tasks when we talk about images that contain
    “cats,” “dogs,” or “cars.”
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 原始图像通常用于进一步处理，但它们也可以用于图像分类等任务。图像分类的任务与算法的输入是原始图像，输出是图像类别相关。当我们谈论包含“猫”、“狗”或“汽车”等内容的图像时，我们经常看到这类任务。
- en: There are considerable practical applications of this task. One application
    is in insurance. Several insurance companies have changed their business model
    and digitalized their businesses. Before the mid-2010s, insurance companies required
    an initial visit to a workshop to make a first assessment of damage to cars. Today,
    that first damage is assessed automatically by image classification algorithms.
    We take a picture of the damaged part with a smartphone and send it to the insurance
    company’s software, where trained ML algorithms are used to make an assessment.
    In rare, difficult cases, the image needs to be scrutinized by a human operator.
    This kind of workflow saves money and time and provides a better experience for
    the handling of damage claims.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务有许多实际应用。一个应用是在保险领域。几家保险公司已经改变了他们的商业模式并将业务数字化。在2010年代中期之前，保险公司需要首先到车间进行一次访问以对汽车损坏进行初步评估。今天，这种初步的损坏评估是通过图像分类算法自动完成的。我们用智能手机拍摄损坏的部分并发送给保险公司的软件，在那里使用训练好的机器学习算法进行评估。在罕见且困难的情况下，图像需要由人工操作员仔细检查。这种工作流程节省了金钱和时间，并为处理索赔提供了更好的体验。
- en: Another application is medical image classification, where radiology images
    are classified automatically to provide an initial diagnosis, and therefore, reduce
    the burden on medical specialists (in this case, radiologists).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个应用是医学图像分类，其中放射学图像被自动分类以提供初步诊断，从而减轻医学专家（在这种情况下，是放射科医生）的负担。
- en: Masked images are processed using filters to emphasize aspects of interest.
    Most often, these filters are black-and-white filters or grayscale filters. They
    emphasize the differences between light and dark parts of the images to make it
    easier to recognize shapes and then to classify these shapes and trace them (in
    the case of video feeds). This kind of application is often used in perception
    systems – for example, in cars.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 遮罩图像通过使用过滤器来强调感兴趣的部分进行处理。最常见的是黑白过滤器或灰度过滤器。它们强调图像中明暗部分之间的差异，以便更容易地识别形状，然后对这些形状进行分类并追踪它们（在视频流的情况下）。这类应用通常用于感知系统——例如，在汽车中。
- en: One practical application of a perception system that uses masked images is
    the recognition of horizontal road markings, such as lane markings. The vehicle’s
    camera takes a picture of the road in front of the car, then its software masks
    the image and sends it to an ML algorithm for detection and classification. **OpenCV**
    is one of the libraries used for this kind of task. Other practical applications
    include face recognition or **optical character** **recognition** (**OCR**).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用掩码图像的感知系统的一个实际应用是识别水平道路标记，如车道标记。车辆的摄像头拍摄汽车前方的道路图像，然后其软件对图像进行掩码处理，并将其发送到机器学习算法进行检测和分类。**OpenCV**是用于此类任务的一个库。其他实际应用包括人脸识别或**光学字符识别**（**OCR**）。
- en: Semantic map images include overlays that describe what can be seen in the image,
    covering a part of an image that contains specific information such as the sky,
    a car, a person, or a building. A semantic map can cover a part of the image that
    contains a car, the road that the car is on, the surroundings, and the sky. The
    semantic map provides rich information about the image that is used for advanced
    vision perception algorithms, which, in turn, provide information for decision
    algorithms. Vision perception is particularly needed in automotive systems for
    autonomous vehicles.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 语义地图图像包括描述图像中可见内容的叠加，覆盖包含特定信息（如天空、汽车、人或建筑物）的部分图像。语义地图可以覆盖包含汽车、汽车所在的路面、周围环境和天空的图像部分。语义地图提供了关于图像的丰富信息，这些信息用于高级视觉感知算法，反过来，这些算法为决策算法提供信息。在自动驾驶汽车系统中，视觉感知尤其重要。
- en: One of the applications of semantic maps is in the active safety systems of
    vehicles. Images captured by the front camera are processed using **convolutional
    neural networks** (**CNNs**) to add a semantic map and then used in decision algorithms.
    These decision algorithms either provide feedback to the driver or take actions
    autonomously. We can see that often when a car reacts to driving too close to
    another car or when it detects an obstacle in its way.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 语义地图的一个应用领域是车辆主动安全系统。前摄像头捕捉到的图像通过**卷积神经网络**（**CNNs**）进行处理，添加语义地图，然后用于决策算法。这些决策算法要么向驾驶员提供反馈，要么自主采取行动。我们可以看到，当一辆车对另一辆车行驶过近或在其路径上检测到障碍物时，通常会有反应。
- en: Other applications of semantic maps include medical image analyses, whereby
    ML algorithms provide input to medical specialists as to what the image contains.
    An example can be brain tumor segmentation using **deep** **CNNs** (**DCNNs**).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 语义地图的其他应用包括医学图像分析，其中机器学习算法为医学专家提供有关图像内容的输入。一个例子是使用**深度****CNNs**（**DCNNs**）进行脑肿瘤分割。
- en: Finally, bounding-box images contain information about the boundaries of objects
    in images. For each shape of interest, such as a car, pedestrian, or tumor, there
    is a bounding box surrounding that part of the image, annotated with the class
    of that shape. These kinds of images are used for detecting objects and providing
    that information to other algorithms.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，边界框图像包含有关图像中物体边界的信息。对于感兴趣的每个形状，如汽车、行人或肿瘤，都有一个围绕该图像部分的边界框，并标注该形状的类别。这类图像用于检测物体并将该信息提供给其他算法。
- en: One of the applications where we use this kind of image is object recognition
    in robot coordination systems. A robot’s camera registers an image, the CNN identifies
    objects, and the robot’s decision software traces the object in order to avoid
    collisions. Tracing each object is used to change the behavior of the autonomous
    robot to reduce the risk of collisions and damage, as well as to optimize the
    operations of the robot and its environment.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这类图像的一个应用是机器人协调系统中的物体识别。机器人的摄像头捕捉到一个图像，CNN识别出物体，然后机器人的决策软件追踪该物体以避免碰撞。追踪每个物体用于改变自主机器人的行为，以降低碰撞和损坏的风险，以及优化机器人和其环境操作。
- en: Hence my first best practice in this chapter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本章的第一条最佳实践。
- en: 'Best practice #14'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #14'
- en: Design the entire software system based on the task that you need to solve,
    not only the ML model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 设计整个软件系统应基于您需要解决的问题，而不仅仅是机器学习模型。
- en: Since every kind of algorithm that we use requires different processing of the
    image and provides different kinds of information, we need to understand how to
    create the entire system around it. In the previous chapter, we discussed pipelines,
    which include only the ML data pipeline, but a software system requires much more.
    For safety-critical functionality, we need to design safety cages and signaling
    to reduce the risk of wrong classifications/detections from ML models. Therefore,
    we need to understand what we want to do – whether the information is only for
    making simple decisions (for example, damaged bumper in a car versus not) or whether
    the classification is part of complex behavior decisions (for example, should
    the robot turn to the right to avoid the obstacle or should it slow down to let
    another robot move past?).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用的每种算法都需要对图像进行不同的处理并提供不同类型的信息，因此我们需要了解如何围绕它创建整个系统。在前一章中，我们讨论了管道，它只包括机器学习数据管道，但一个软件系统需要更多。对于关键功能，我们需要设计安全笼和信号来降低机器学习模型错误分类/检测的风险。因此，我们需要了解我们想要做什么——信息是否仅用于做出简单决策（例如，汽车上的损坏保险杠与未损坏的情况）或者分类是否是复杂行为决策的一部分（例如，机器人应该向右转以避开障碍物，还是应该减速以让另一个机器人通过？）。
- en: 'Images are one type of data that we use in ML; another one is text. The use
    of text has been popularized in recent years with the introduction of **recurrent
    NNs** (**RNNs**) and transformers. These NN architectures are DL networks that
    are capable of capturing the context (and, by extension, basic semantics) of words.
    These models find statistical connections between tokens (and therefore, words)
    and so can identify similarities that classical ML models are not capable of.
    Machine translations were a popular application of these models in the beginning,
    but now, the applications are much wider than this – for example, in understanding
    programming languages. *Figure 3**.2* shows the type of text data that can be
    used with different types of models:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图像是我们用于机器学习的一种数据类型；另一种是文本。近年来，随着**循环神经网络**（**RNNs**）和转换器的引入，文本的使用变得流行。这些神经网络架构是深度学习网络，能够捕捉到词语的上下文（以及由此扩展的基本语义）。这些模型在标记（因此，词语）之间发现统计联系，因此可以识别出经典机器学习模型无法识别的相似性。机器翻译是这些模型最初的一个流行应用，但现在，应用范围比这更广——例如，在理解编程语言方面。*图3.2*展示了可以与不同类型的模型一起使用的文本数据类型：
- en: '![Figure 3.2 – Types of learning systems and the data they require for text](img/B19548_03_2.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – 学习系统的类型及其对文本数据的需求](img/B19548_03_2.jpg)'
- en: Figure 3.2 – Types of learning systems and the data they require for text
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – 学习系统的类型及其对文本数据的需求
- en: The raw text data is used today in training `word2vec` model, which translates
    text tokens into vectors of numbers – embeddings – which are distances from that
    token to other tokens in the vocabulary. We saw an example of this in [*Chapter
    2*](B19548_02.xhtml#_idTextAnchor023), where we counted the number of words in
    sentences. By using this technology, the `word2vec` model captures the context
    of tokens, also known as their similarity. This similarity can be extended to
    entire sentences or even paragraphs, depending on the size and depth of the model.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 原始文本数据目前用于训练`word2vec`模型，该模型将文本标记转换为数字向量——嵌入——这些向量是该标记与词汇表中其他标记的距离。我们在[*第2章*](B19548_02.xhtml#_idTextAnchor023)中看到了一个例子，其中我们计算了句子中的单词数量。通过使用这项技术，`word2vec`模型捕捉到标记的上下文，也称为它们的相似性。这种相似性可以扩展到整个句子或段落，这取决于模型的大小和深度。
- en: Another application of raw text, although in a structured format, is in **sentiment
    analysis** (**SA**). We use a tabular format of the text data in order to analyze
    whether the text’s sentiment is positive, negative, or neutral. An extension of
    that task is understanding the intent of the text – whether it is an explanation,
    a query, or a description.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 原始文本的另一个应用，尽管是以结构化格式，是在**情感分析**（**SA**）中。我们使用文本数据的表格格式来分析文本的情感是积极、消极还是中性。该任务的扩展是理解文本的意图——它是否是解释、查询还是描述。
- en: Masked text data refers to when we mask one or more tokens in a sequence of
    tokens, and we train the models to predict the token. This is an example of self-supervised
    training as the model is trained on data that is not annotated, but by masking
    tokens in different ways (for example, random, based on similarity, human annotations),
    the model can understand which tokens can be used in that specific context. The
    larger the model – the transformer – the more data is needed, and a more complex
    training process is needed.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码文本数据指的是在一系列标记中掩码一个或多个标记，并训练模型来预测该标记。这是一个自监督训练的例子，因为模型是在未标注的数据上训练的，但通过以不同的方式（例如，随机、基于相似性、人工标注）掩码标记，模型可以理解哪些标记可以在特定上下文中使用。模型越大——即transformer——需要的数据就越多，并且需要更复杂的训练过程。
- en: Finally, annotated text refers to when we label pieces of text with a specific
    class, just as with images. An example of such annotation is a sentiment. Then,
    the model captures patterns in the data, and therefore, can repeat these patterns.
    An example of a task in this area is sentiment recognition, where the model is
    trained to recognize whether a piece of text is positive or negative in its tone.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，标注文本指的是当我们用特定的类别标记文本片段，就像图像一样。这种标注的一个例子是情感。然后，模型捕捉数据中的模式，因此可以重复这些模式。这个领域的一个任务示例是情感识别，其中模型被训练来识别文本的语气是积极还是消极。
- en: 'A special case of textual data is programming language source code. The use
    of ML models for programming language tasks has become more popular in the last
    few years as it provides the possibility to increase the speed and quality of
    software development. *Figure 3**.3* shows types of programming language data
    and typical tasks:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据的一个特殊情况是编程语言源代码。在过去的几年里，使用ML模型进行编程语言任务变得越来越流行，因为它提供了提高软件开发速度和质量的可能。*图3.3*展示了编程语言数据类型和典型任务：
- en: '![Figure 3.3 – Types of programming language data and typical tasks](img/B19548_03_3.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3 – 编程语言数据类型和典型任务](img/B19548_03_3.jpg)'
- en: Figure 3.3 – Types of programming language data and typical tasks
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – 编程语言数据类型和典型任务
- en: Raw source code data is used for tasks that are related to programming language
    understanding – for example, translations between different programming languages,
    such as the one using the TransCoder model. This task is similar to translation
    between natural languages, although it adds additional steps to make the program
    compile and pass test cases.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 原始源代码数据用于与编程语言理解相关的任务——例如，使用TransCoder模型在不同编程语言之间的翻译。这项任务类似于自然语言之间的翻译，尽管它增加了额外的步骤来使程序编译并通过测试用例。
- en: Masked programming language code is often used for training models with the
    purpose of repairing defects – the model is trained on a set of programs that
    correct defects and then applied on programs with defects. Masked programs are
    used to train models that can identify problems and provide fixes for them. These
    tasks are quite experimental at the moment of writing this book but with very
    promising results.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码编程语言代码通常用于训练旨在修复缺陷的模型——模型是在一组纠正缺陷的程序上训练的，然后应用于有缺陷的程序。掩码程序用于训练能够识别问题并提供修复方案的模型。在撰写本书时，这些任务相当实验性，但结果非常令人鼓舞。
- en: Annotated source code is used for a variety of tasks. These tasks include defect
    predictions, code reviews, and identification of design patterns or company-specific
    design rules. ML models provide much better results than any other techniques
    for these tasks – for example, compared to static code analysis tools.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 标注源代码用于各种任务。这些任务包括缺陷预测、代码审查以及识别设计模式或公司特定的设计规则。与静态代码分析工具等其他技术相比，ML模型在这些任务上提供了更好的结果——例如，与静态代码分析工具相比。
- en: Source code is used to train models for advanced software engineering tasks,
    such as creating programs. GitHub Copilot is one such tool that has been very
    successful, both in research and in commercial applications.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码用于训练用于高级软件工程任务的模型，例如创建程序。GitHub Copilot就是这样一种工具，它在研究和商业应用中都取得了巨大的成功。
- en: Now, the aforementioned three types of data illustrate only a small number of
    applications of ML. The sky is the limit for those who want to utilize ML models
    for designing software systems. Before designing the systems, however, we need
    to understand how we work with data in more detail.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，上述三种类型的数据仅展示了ML应用的一小部分。对于那些想要利用ML模型设计软件系统的人来说，天空才是极限。然而，在设计系统之前，我们需要更详细地了解我们如何与数据打交道。
- en: Images
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像
- en: 'Raw image data is often stored in files with annotations in other files. Raw
    image data presents aspects that are relevant to the system in question. An example
    of data used for training active safety algorithms is presented in *Figure 3**.4*:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 原始图像数据通常存储在包含在其他文件中的注释的文件中。原始图像数据呈现与所讨论系统相关的方面。用于训练主动安全算法的数据示例在*图3.4*中展示：
- en: '![Figure 3.4 – Front-camera image from a vehicle](img/B19548_03_4.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图3.4 – 车辆的前置摄像头图像](img/B19548_03_4.jpg)'
- en: Figure 3.4 – Front-camera image from a vehicle
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 车辆的前置摄像头图像
- en: The image with the car is used, in this example, to train a CNN to recognize
    whether it is safe to drive (for example, whether the road ahead is free from
    obstacles). With the data annotated on the image level – that is, without masks
    and bounding boxes – the ML models can either classify the entire image or identify
    objects. When identifying objects, the models add bounding-box information to
    the images.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，使用带有汽车的图像来训练CNN以识别是否安全驾驶（例如，前方道路是否无障碍）。当在图像级别上标注数据时——即没有蒙版和边界框——机器学习模型可以分类整个图像或识别对象。在识别对象时，模型会将边界框信息添加到图像中。
- en: In order to train a CNN for images that contain many objects of significant
    size (such as high-definition resolution of 1920 x 1080 pixels), we need both
    large datasets and large computational resources. There are a few reasons for
    this.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练一个用于包含许多显著大小对象的图像（例如1920 x 1080像素的高清分辨率）的CNN，我们需要大量的数据集和计算资源。这有几个原因。
- en: First, colors require a lot of data to be recognized correctly. Although we
    humans see the color red as almost uniform, the actual pixel intensity of that
    color varies a lot, which means that we need to create a CNN so that it can understand
    that different shades of red are sometimes important to recognize braking vehicles.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，颜色需要大量数据才能正确识别。尽管我们人类将红色视为几乎均匀，但实际上该颜色的像素强度变化很大，这意味着我们需要创建一个CNN，使其能够理解不同深度的红色有时对于识别制动车辆很重要。
- en: 'Second, the large size of images contains details that are not relevant. *Figure
    3**.5* presents how a CNN is designed. This is a CNN in a LeNet style:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，图像的大尺寸包含了不相关的细节。*图3.5*展示了CNN的设计方式。这是一个LeNet风格的CNN：
- en: '![Figure 3.5 – Conceptual design of a CNN](img/B19548_03_5.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5 – CNN的概念设计](img/B19548_03_5.jpg)'
- en: Figure 3.5 – Conceptual design of a CNN
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – CNN的概念设计
- en: '*Figure 3**.5* shows that the NN takes as input an image of size 192 x 108
    pixels (10 times smaller than an HD-quality image). It then uses `MaxPool` layers
    (for example) to reduce the number of elements, and then it uses convolutions
    to identify shapes. Finally, it uses two dense layers to classify the images into
    a vector of 64 different classes. The size of the images determines the complexity
    of the network. The larger the images, the more convolutions are required, and
    the larger the first layer. Larger networks take more time to train (the difference
    may be measured in days) and require more data (the difference may be measured
    in tens of thousands of images, depending on the number of classes and quality
    of images).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.5*显示NN以192 x 108像素大小的图像（比高清图像小10倍）作为输入。然后它使用`MaxPool`层（例如）来减少元素数量，然后使用卷积来识别形状。最后，它使用两个密集层将图像分类为64个不同类别的向量。图像的大小决定了网络的复杂性。图像越大，所需的卷积就越多，第一层也越大。更大的网络需要更多的时间来训练（差异可能以天计）并且需要更多的数据（差异可能以成千上万张图像计，取决于类别的数量和图像的质量）。'
- en: 'Therefore, for many applications, we use grayscale images and downsize them
    significantly. *Figure 3**.6* shows the same image as previously but in grayscale,
    downsized to 192 x 108 pixels. The size of the image has been significantly reduced
    and so have the requirements for the first convolutional layers:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于许多应用，我们使用灰度图像并将它们显著缩小。*图3.6*显示了之前相同的图像，但以灰度显示，缩小到192 x 108像素。图像的大小已经显著减小，因此对第一卷积层的要求也减少了：
- en: '![Figure 3.6 – Black-and-white transformed image (lower-quality lossy transformation
    illustrated on purpose)](img/B19548_03_6.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图3.6 – 黑白转换图像（故意展示的低质量有损转换）](img/B19548_03_6.jpg)'
- en: Figure 3.6 – Black-and-white transformed image (lower-quality lossy transformation
    illustrated on purpose)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 – 黑白转换图像（故意展示的低质量有损转换）
- en: However, the object in the image is still perfectly visible and can be used
    for further analysis. Therefore, here is the next best practice.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，图像中的物体仍然非常清晰可见，可以用于进一步分析。因此，这里是下一个最佳实践。
- en: 'Best practice #15'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践#15
- en: Downsize the size of your images and use as few colors as possible to reduce
    the computational complexity of your system.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 缩小图像的大小并尽可能使用较少的颜色，以减少系统的计算复杂度。
- en: Before designing the system, we need to understand what kinds of images we have
    and how we can use them. Then, we can perform these kinds of transformations so
    that the system that we design can handle the tasks that it is designed for. However,
    it’s important to note that downsizing images can also result in loss of information,
    which can affect the accuracy of the ML model. It’s important to carefully balance
    the trade-offs between computational complexity and information loss when deciding
    how to preprocess images for an ML task.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计系统之前，我们需要了解我们有哪些类型的图像以及我们如何使用它们。然后，我们可以执行这些类型的转换，以便我们设计的系统能够处理其设计的目标任务。然而，需要注意的是，缩小图像也可能导致信息丢失，这可能会影响机器学习模型的准确性。在决定如何预处理图像以用于机器学习任务时，重要的是要仔细权衡计算复杂度和信息丢失之间的权衡。
- en: 'Downsizing and converting images to grayscale is a common practice in ML. In
    fact, there exist several well-known and widely used benchmark datasets that use
    this technique. One of them is the `MNIST` dataset of handwritten numbers. The
    dataset is available for download as part of the most popular ML libraries such
    as TensorFlow and Keras. Just use the following code to get hold of the images:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，缩小图像并将其转换为灰度是一个常见的做法。实际上，存在几个广为人知且广泛使用的基准数据集，它们使用了这种技术。其中一个就是手写数字的`MNIST`数据集。该数据集可以作为最受欢迎的机器学习库（如TensorFlow和Keras）的一部分下载。只需使用以下代码即可获取图像：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The code illustrates how to download the dataset, which is already split into
    `test` and `train` data, with annotations. It also shows how to visualize the
    dataset, which results in the images seen in *Figure 3**.7*:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码说明了如何下载数据集，该数据集已经分为`测试`和`训练`数据，并带有注释。它还展示了如何可视化数据集，这导致了*图3*.*7*中看到的图像：
- en: '![Figure 3.7 – Visualization of the first few images in the MNIST dataset;
    the images are rasterized on purpose to illustrate their real size](img/B19548_03_7.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图3.7 – MNIST数据集中前几个图像的可视化；有意将图像转换为位图以展示其实际大小](img/B19548_03_7.jpg)'
- en: Figure 3.7 – Visualization of the first few images in the MNIST dataset; the
    images are rasterized on purpose to illustrate their real size
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 – MNIST数据集中前几个图像的可视化；有意将图像转换为位图以展示其实际大小
- en: The size of the images in the MNIST dataset is 28 x 28 pixels, which is perfectly
    sufficient to train and test new ML models. Although the dataset is well known
    and used in ML, it is relatively small and uniform – only grayscale numbers. Therefore,
    for more advanced tasks, we should look for more diverse datasets.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST数据集中图像的大小是28 x 28像素，这对于训练和测试新的机器学习模型来说已经足够完美。尽管该数据集在机器学习中广为人知并被使用，但它相对较小且均匀——只有灰度数字。因此，对于更高级的任务，我们应该寻找更多样化的数据集。
- en: Images of handwritten numbers are naturally useful, but we often want to use
    more complex images, and therefore, the standard libraries contain images with
    more than just 10 classes (number of digits). One such dataset is the Fashion-MNIST
    dataset.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 手写数字的图像自然是有用的，但我们通常希望使用更复杂的图像，因此，标准库中包含的图像不仅仅只有10个类别（数字的数量）。其中一个这样的数据集是Fashion-MNIST数据集。
- en: 'We can download it by using the following code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码下载它：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The code, which we can use as part of the visualization shown in *Figure 3**.7*,
    produces the set of images seen in *Figure 3**.8*. The images are of the same
    size and the same number of classes, but with a larger complexity:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码可以用于生成*图3*.*7*中所示的可视化，它产生了*图3*.*8*中看到的图像集合。图像大小和类别数量相同，但复杂度更大：
- en: '![Figure 3.8 – Fashion-MNIST dataset; the images are rasterized on purpose
    to illustrate their real size](img/B19548_03_8.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图3.8 – Fashion-MNIST数据集；有意将图像转换为位图以展示其实际大小](img/B19548_03_8.jpg)'
- en: Figure 3.8 – Fashion-MNIST dataset; the images are rasterized on purpose to
    illustrate their real size
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 – Fashion-MNIST数据集；有意将图像转换为位图以展示其实际大小
- en: 'Finally, we can also use libraries that contain color images, such as the CIFAR-10
    dataset. The dataset can be accessed with the following code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还可以使用包含彩色图像的库，例如CIFAR-10数据集。可以使用以下代码访问该数据集：
- en: '[PRE2]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The dataset contains images of 10 different classes of similar size (32 x 32
    pixels), but with colors, as shown in *Figure 3**.9*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含 10 个不同类别的图像，大小相似（32 x 32 像素），但带有颜色，如图 *图 3.9* 所示。
- en: '![Figure 3.9 – CIFAR-10 dataset; the images are rasterized on purpose to illustrate
    their real size](img/B19548_03_9.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.9 – CIFAR-10 数据集；图像有意进行光栅化以展示其实际大小](img/B19548_03_9.jpg)'
- en: Figure 3.9 – CIFAR-10 dataset; the images are rasterized on purpose to illustrate
    their real size
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9 – CIFAR-10 数据集；图像有意进行光栅化以展示其实际大小
- en: This is not the end of such benchmark datasets. Some datasets contain more classes,
    larger images, or both. Therefore, it is important to take a look at these datasets
    beforehand and in connection with the task that our system has to perform.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是这些基准数据集的终点。一些数据集包含更多类别、更大的图像，或者两者都有。因此，在系统必须执行的任务之前和期间查看这些数据集是很重要的。
- en: In the majority of cases, grayscale images are perfectly fine for classification
    tasks. They provide the ability to quickly get an orientation in the data, and
    they are small enough that the classification is of good quality.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，灰度图像对于分类任务来说已经足够好了。它们能够快速让我们在数据中找到方向，而且它们足够小，以至于分类质量良好。
- en: The usual size of the benchmark datasets is about 50,000–100,000 images. This
    illustrates that even for such a small number of classes and for such small images,
    the number is significant. Just imagine annotating those 100,000 images. For more
    complex images, the size of the datasets can be significantly larger. For example,
    the BDD100K dataset used in automotive software contains over 100,000 images.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 基准数据集的通常大小约为 50,000–100,000 张图像。这表明，即使是如此小的类别数量和如此小的图像，数量也是相当大的。想象一下标注那 100,000
    张图像。对于更复杂的图像，数据集的大小可以显著更大。例如，在汽车软件中使用的 BDD100K 数据集包含超过 100,000 张图像。
- en: Therefore, here is my next best practice.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这是我的下一个最佳实践。
- en: 'Best practice #16'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #16'
- en: Use a reference dataset (such as MNIST or STL) for benchmarking whether the
    system works or not.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用参考数据集（如 MNIST 或 STL）来基准测试系统是否工作。
- en: In order to understand whether the entire system works or not, such benchmark
    datasets are very useful. They provide us with a preconfigured train/test split,
    and there are plenty of algorithms that can be used to understand the quality
    of our algorithm.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解整个系统是否工作，这样的基准数据集非常有用。它们为我们提供了一个预配置的训练/测试分割，并且有许多算法可以用来理解我们算法的质量。
- en: We should also consider the next best practice.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该考虑下一个最佳实践。
- en: 'Best practice #17'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #17'
- en: Whenever possible, use models that are already pre-trained for specific tasks
    (for example, neural models for image classification or semantic segmentation).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在可能的情况下，使用已经为特定任务预训练的模型（例如，用于图像分类或语义分割的神经网络模型）。
- en: Just as we should strive to reuse images for benchmarking, we should also strive
    to reuse models that are pre-trained. This saves previous design resources and
    reduces the risk of spending too much time to find optimal architectures of NN
    models or to find the optimal set of parameters (even if we use `GradientSearch`
    algorithms).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们应该努力重复使用图像进行基准测试一样，我们也应该努力重复使用预训练的模型。这节省了之前的设计资源，并减少了花费太多时间寻找神经网络模型的最佳架构或最佳参数集（即使我们使用
    `GradientSearch` 算法）的风险。
- en: Text
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本
- en: One of the types of analysis done on text is SA – classification of whether
    a piece of text (a sentence, for example) is positive or negative.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在对文本进行的分析类型中，SA 是其中之一——对文本片段（例如句子）是否为正面或负面的分类。
- en: '*Figure 3**.10* presents an example of data that can be used for SA. The data
    is publicly available and has been created from Amazon product reviews. Data for
    this kind of analysis is often structured in a table, where we have entities such
    as `ProductId` (I’ve truncated the `Id` columns for brevity) or `UserId`, as well
    as `Score` for reference and `Text` to classify.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.10* 展示了可用于 SA 的数据示例。这些数据是公开可用的，并且是从亚马逊产品评论中创建的。这类分析的数据通常以表格形式结构化，其中包含诸如
    `ProductId`（为了简洁，我已截断 `Id` 列）或 `UserId` 这样的实体，以及用于参考的 `Score` 和用于分类的 `Text`。'
- en: 'This data structure provides us with the possibility to quickly summarize the
    text and visualize it. The visualization can be done in several ways – for example,
    by plotting a histogram of the scores. However, the most interesting visualizations
    are the ones that are provided by the statistics of words/tokens used in the text:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '| Id | ProductId | UserId | Score | Summary | Text |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
- en: '| 1 | B001KFG0 | UHU8GW | 5 | Good Quality Dog Food | I have bought several
    of the Vitality canned dog food products and have found them all to be of good
    quality. The product looks more like a stew than a processed meat and it smells
    better. My Labrador is finicky and she appreciates this product better than most.
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
- en: '| 2 | B008GRG4 | ZCVE5NK | 1 | Not as Advertised | Product arrived labeled
    as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not
    sure if this was an error or if the vendor intended to represent the product as
    “Jumbo”. |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
- en: '| 3 | B000OCH0 | WJIXXAIN | 4 | “Delight” says it all | This is a confection
    that has been around a few centuries. It is a light, pillowy citrus gelatin with
    nuts - in this case Filberts. And it is cut into tiny squares and then liberally
    coated with powdered sugar. And it is a tiny mouthful of heaven. Not too chewy,
    and very flavorful. I highly recommend this yummy treat. If you are familiar with
    the story of C.S. Lewis’ “The Lion, The Witch, and The Wardrobe” - this is the
    treat that seduces Edmund into selling out his Brother and Sisters to the Witch.
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
- en: '| 4 | B000A0QIQ | C6FGVXV | 2 | Cough Medicine | If you are looking for the
    secret ingredient in Robitussin I believe I have found it. I got this in addition
    to the Root Beer Extract I ordered (which was good) and made some cherry soda.
    The flavor is very medicinal. |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
- en: '| 5 | B0062ZZ7K | LF8GW1T | 5 | Great taffy | Great taffy at a great price.
    There was a wide assortment of yummy taffy. Delivery was very quick. If your a
    taffy lover, this is a deal. |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
- en: Figure 3.10 – Example of data for product reviews, structured for SA; only the
    first five rows are shown
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to visualize the data is to use the word cloud visualization technique.
    A simple script for visualizing this kind of data is shown next:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The result of running this script is shown in *Figure 3**.11*. A word cloud
    shows trends in terms of frequency of the use of words – words used more frequently
    are larger than words used less frequently:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11 – Word cloud visualization of the Text column](img/B19548_03_10.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 – Word cloud visualization of the Text column
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Hence, my next best practice is as follows.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'Best practice #18'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Visualize your raw data to get an understanding of patterns in your data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Visual representation of data is important to understand the underlying patterns.
    I cannot stress that enough. I use both Python’s Matplotlib and Seaborn as well
    as visual analytics tools such as TIBCO Spotfire to plot charts and understand
    my data. Without such a visualization, and thus without such an understanding
    of the patterns, we are bound to make wrong conclusions and even design systems
    with flaws that are difficult to remove without a complete redesign.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的可视化对于理解潜在模式非常重要。这一点我无法强调得更多。我既使用Python的Matplotlib和Seaborn，也使用TIBCO Spotfire等可视化分析工具来绘制图表并理解我的数据。没有这种可视化，以及没有对模式的这种理解，我们必然会得出错误的结论，甚至设计出需要完全重新设计才能移除缺陷的系统。
- en: Visualization of output from more advanced text processing
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更高级文本处理输出的可视化
- en: Visualization of text helps us to understand what the text contains, but it
    does not capture the meaning of it. In this book, we will work with advanced text
    processing algorithms – feature extractors. Therefore, we need to understand how
    to create visualizations of the output from these algorithms.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 文本的可视化帮助我们理解文本包含的内容，但它并不捕捉其含义。在这本书中，我们将使用高级文本处理算法——特征提取器。因此，我们需要了解如何创建这些算法输出的可视化。
- en: 'One way of working with feature extraction is to use word embeddings – a method
    to convert words or sentences into vectors of numbers. `word2vec` is one model
    that can do that, but there are more powerful ones too. OpenAI’s GPT-3 model is
    one of the largest models that are openly available. Obtaining embeddings of paragraphs
    is quite straightforward. First, we connect to the OpenAI API and then query it
    for the embeddings. Here is the code that does the querying of the OpenAI API
    (in boldface):'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 与特征提取一起工作的一种方法是用词嵌入——一种将单词或句子转换为数字向量的方法。`word2vec`是能够做到这一点的模型之一，但还有更强大的模型。OpenAI的GPT-3模型是公开可用的最大模型之一。获取段落嵌入相当直接。首先，我们连接到OpenAI
    API，然后查询它以获取嵌入。以下是查询OpenAI API的代码（加粗）：
- en: '[PRE4]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'What we obtain by running this piece of code is `5` vectors (one for each row)
    of `2048` numbers, which we call embeddings. The entire vector is too large to
    be included in the page, but the first elements look something like this: `[-0.005302980076521635,
    0.018141526728868484, -0.018141526728868484,` `0.004692177753895521, …`.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行这段代码，我们获得了`5`个向量（每个行一个）的`2048`个数字，我们称之为嵌入。整个向量太大，无法包含在页面上，但前几个元素看起来像这样：`[-0.005302980076521635,
    0.018141526728868484, -0.018141526728868484, 0.004692177753895521, …]`。
- en: 'These numbers do not say much to us humans, but they have a meaning for the
    language model. The meaning is in the distance between them – words/tokens/sentences
    that are like one another are placed closer than words/tokens/sentences that are
    not similar. In order to understand these similarities, we use transformations
    that reduce the dimensions – one of them is **t-distribution Stochastic Neighbor
    Embedding** (**t-SNE**). *Figure 3**.12* presents this kind of visualization of
    the five embeddings that we obtained:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数字对我们人类来说意义不大，但对语言模型来说却有着意义。意义在于它们之间的距离——相似度高的单词/标记/句子比不相似的单词/标记/句子更接近。为了理解这些相似性，我们使用降低维度的转换——其中之一是**t分布随机邻域嵌入**（**t-SNE**）。*图3.12*展示了我们获得的五个嵌入的这种可视化：
- en: '![Figure 3.12 – t-SNE visualization of the embedding vectors for the five reviews](img/B19548_03_11.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图3.12 – 五个评论嵌入向量的t-SNE可视化](img/B19548_03_11.jpg)'
- en: Figure 3.12 – t-SNE visualization of the embedding vectors for the five reviews
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 – 五个评论嵌入向量的t-SNE可视化
- en: Each dot represents one review, and each cross represents the center of the
    cluster. The clusters are designated by the `Score` column from the original dataset.
    The screenshot shows that the text in each of the reviews is different (dots do
    not overlap) and that the clusters are separate – the crosses are positioned in
    a different part of the screenshot.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 每个点代表一条评论，每个十字代表簇的中心。簇由原始数据集中的`Score`列指定。截图显示，每条评论中的文本都不同（点不重叠），并且簇是分开的——十字在截图的不同部分。
- en: Therefore, my next best practice is about that.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我接下来的最佳实践就是关于这个。
- en: 'Best practice #19'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践#19
- en: Visualize your data when it has been turned into features to monitor whether
    the same patterns are still observable.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据被转换为特征以监控是否仍可观察到相同模式时，请可视化您的数据。
- en: Just as with the previous best practice, we need to visualize the data to check
    whether patterns that we observed in the raw data are still observable. This step
    is important as we need to know that the ML model can indeed learn these patterns.
    As these models are statistical in nature, they always capture patterns, but when
    a pattern is not there, they capture something that is not useful – even though
    it resembles a pattern.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前的最佳实践一样，我们需要可视化数据以检查我们在原始数据中观察到的模式是否仍然可观察。这一步很重要，因为我们需要知道机器学习模型确实可以学习这些模式。由于这些模型本质上是统计的，它们总是捕捉到模式，但当模式不存在时，它们捕捉到的可能是无用的东西
    – 即使它看起来像是一个模式。
- en: Structured text – source code of programs
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构化文本 – 程序的源代码
- en: The source code of programs is a special case of text data. It has the same
    type of modality – text – but it contains additional information in the form of
    the grammatical/syntactical structure of the program. Since every programming
    language is based on grammar, there are specific rules for how a program should
    be structured. For instance, in C, there should be a specific function called
    `main`, which is the entry point for the program.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的源代码是文本数据的一个特殊情况。它具有相同类型的模态 – 文本 – 但它包含程序语法/句法结构形式的附加信息。由于每种编程语言都基于语法，因此程序的结构化都有特定的规则。例如，在
    C 语言中，应该有一个名为 `main` 的特定函数，它是程序的入口点。
- en: 'These specific rules make the text structured in a specific way. They may make
    it more difficult to understand the text for a human being, but this structure
    can certainly be helpful. One of the models that uses this structure is `code2vec`
    ([https://code2vec.org/](https://code2vec.org/)). The `code2vec` model is similar
    to word2vec, but it takes as input the **Abstract Syntax Tree** (**AST**) of the
    program that it analyzes – for example, the following program:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特定的规则使得文本以特定的方式结构化。它们可能使人类理解文本变得更加困难，但这种结构确实非常有帮助。使用这种结构的一个模型是 `code2vec`
    ([https://code2vec.org/](https://code2vec.org/))。`code2vec` 模型与 word2vec 类似，但它以输入它所分析程序的
    **抽象语法树** (**AST**) – 例如，以下程序：
- en: '[PRE5]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This can be represented by the AST in *Figure 3**.13*:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过 *图 3**.13* 中的 AST 来表示：
- en: '![Figure 3.13 – AST for a simple “Hello World” program](img/B19548_03_12.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.13 – 简单“Hello World”程序的 AST](img/B19548_03_12.jpg)'
- en: Figure 3.13 – AST for a simple “Hello World” program
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13 – 简单“Hello World”程序的 AST
- en: The example program is visualized as a set of instructions with their context
    and the role that they play in the program. For example, the words `void` and
    `main` are two parts of the method declaration, together with the block statement
    (`BlockStmt`), which is the body of the method.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 示例程序被可视化为一组指令及其上下文以及它们在程序中扮演的角色。例如，`void` 和 `main` 是方法声明的一部分，与块语句（`BlockStmt`）一起，构成了方法的主体。
- en: '`code2vec` is an example of a model that uses programming language information
    (in this case, grammar) as input to the model. Tasks that the model can do include
    finding similarities between words (such as word2vec models), finding combinations,
    and identifying analogies. For example, the model can identify all combinations
    of the words `int` and `main` and provide the following answers (with probabilities):
    `realMain` (71%), `isInt` (71%), and `setIntField` (69%). These tasks, by extension,
    can be used for program repair, where the model can identify mistakes and repair
    them.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`code2vec` 是一个使用编程语言信息（在这种情况下，是语法）作为模型输入的模型的例子。模型可以执行的任务包括查找单词之间的相似性（如 word2vec
    模型）、查找组合以及识别类比。例如，模型可以识别 `int` 和 `main` 这两个单词的所有组合，并提供以下答案（带有概率）：`realMain`（71%），`isInt`（71%），和
    `setIntField`（69%）。通过扩展，这些任务可以用于程序修复，其中模型可以识别错误并修复它们。'
- en: However, using an AST or similar information has disadvantages. The main disadvantage
    is that the analyzed program must compile. This means that we cannot use these
    kinds of models in the context where we want to analyze programs that are incomplete
    – for example, in the context of **continuous integration** (**CI**) or modern
    code reviews. When we analyze only a small part of the code, the model cannot
    parse it, obtain its AST, and use it. Therefore, here’s my next best practice.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用 AST 或类似信息也有缺点。主要缺点是分析程序必须编译。这意味着我们无法在想要分析不完整程序的环境中使用这些类型的模型 – 例如，在 **持续集成**
    (**CI**) 或现代代码审查的环境中。当我们只分析代码的一小部分时，模型无法解析它，获取其 AST，并使用它。因此，这是我的下一个最佳实践。
- en: 'Best practice #20'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #20'
- en: Only use the necessary information as input to ML models. Too much information
    may require additional processing and make the training hard to converge (finish).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 只将必要的信息作为输入提供给机器学习模型。过多的信息可能需要额外的处理，并使训练难以收敛（完成）。
- en: When designing the processing pipeline, make sure that the information provided
    to the model is necessary, as every piece of information poses new requirements
    for the entire software system. As in the example of an AST, when it is necessary,
    it is powerful information, but if not available, it can be a huge hindrance to
    getting the data analysis pipeline to work.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计处理流程时，确保提供给模型的信息是必要的，因为每一条信息都对整个软件系统提出新的要求。例如，在抽象语法树（AST）的例子中，当它是必要的，它就是强大的信息，但如果不可用，它可能会成为数据分析流程工作的巨大障碍。
- en: Every data has its purpose – annotations and tasks
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 每种数据都有其目的 – 标注和任务
- en: Data in raw format is important, but only the first step in the development
    and operations of ML software. The most important part, and the costliest one,
    is the annotation of the data. To train an ML model and then use it to make inferences,
    we need to define a task. Defining a task is both conceptual and operational.
    The conceptual definition is to define what we want the software to do, but the
    operational definition is how we want to achieve that goal. The operational definition
    boils down to a definition of what we see in the data and what we want the ML
    model to identify/replicate.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 原始格式的数据很重要，但只是机器学习软件开发和运营的第一步。最重要的是数据标注，这也是成本最高的部分。为了训练机器学习模型并使用它进行推理，我们需要定义一个任务。定义任务既是概念性的也是操作性的。概念性定义是定义我们希望软件做什么，而操作性定义是我们希望如何实现这一目标。操作性定义归结为对我们在数据中看到的内容以及我们希望机器学习模型识别/复制的定义。
- en: Annotations are the mechanisms by which we direct the ML algorithms. Every piece
    of data that we use requires some sort of label to denote what it is. In the raw
    format of the data, this annotation can be a label of what the data point contains.
    For example, such a label can be that the image contains the number 1 (from the
    MNIST dataset) or a car (from the CIFAR-10 dataset). However, these simple annotations
    are important only in dedicated tasks. For more advanced tasks, the annotations
    need to be richer.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 标注是我们指导机器学习算法的机制。我们使用的每一条数据都需要某种标签来表示其内容。在数据的原始格式中，这种标注可以是数据点包含的内容的标签。例如，这样的标签可以是图像包含数字
    1（来自 MNIST 数据集）或汽车（来自 CIFAR-10 数据集）。然而，这些简单的标注在专用任务中很重要。对于更高级的任务，标注需要更丰富。
- en: 'One of the types of annotations relates to when we designate part of the data
    as interesting. In the case of images, this is done by drawing bounding boxes
    around objects of interest. *Figure 3**.14* presents such an image:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这类标注的一种类型与我们在数据中指定部分数据为有趣的部分相关。在图像的情况下，这是通过在感兴趣的对象周围绘制边界框来完成的。*图 3.14* 展示了这样的图像：
- en: '![Figure 3.14 – Image with bounding boxes](img/B19548_03_13.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.14 – 带有边界框的图像](img/B19548_03_13.jpg)'
- en: Figure 3.14 – Image with bounding boxes
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.14 – 带有边界框的图像
- en: The image contains boxes around elements that we want the model to recognize.
    In this case, we want to recognize objects that are vehicles (green boxes), other
    road users (orange boxes), and important background objects (gray boxes). These
    kinds of annotations are used for the ML model to learn shapes and to identify
    such shapes in new objects. In the case of this example, the bounding boxes identify
    elements that are important for active safety systems in cars, but this is not
    the only application.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图像包含围绕我们希望模型识别的元素的框。在这种情况下，我们希望识别车辆（绿色框）、其他道路使用者（橙色框）和重要的背景对象（灰色框）。这类标注用于使机器学习模型学习形状，并在新对象中识别这些形状。在这个例子中，边界框识别了对于汽车主动安全系统重要的元素，但这不是唯一的用途。
- en: Other applications of such bounding boxes include medical image analysis, where
    the task is to identify tissue that needs further analysis. These could also be
    systems for face recognition and object detection.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这种边界框的其他应用包括医学图像分析，其任务是识别需要进一步分析的组织。这些也可以是面部识别和物体检测的系统。
- en: Although this task, and the bounding boxes, could be seen as a special case
    of annotating raw data, it is a bit different. Every box could be seen as a separate
    image that has a label, but the challenge is that every box is of a different
    size. Therefore, using such differently shaped images would require preprocessing
    (for example, rescaling). It would also only work for the training because, in
    the inference, we would need to identify objects before they are classified –
    and that’s exactly the task we need the NN to do for us.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个任务和边界框可以被视为标注原始数据的一个特殊情况，但它略有不同。每个框都可以被视为一个带有标签的独立图像，但挑战在于每个框的大小都不同。因此，使用这种不同形状的图像将需要预处理（例如，重新缩放）。它也仅适用于训练，因为在推理中，我们需要在分类之前识别对象——这正是我们需要神经网络为我们完成的任务。
- en: My best practice for using this kind of data is set out next.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用这类数据的最佳实践将在下面列出。
- en: 'Best practice #21'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #21'
- en: Use bounding boxes in the data when the task requires the detection and tracking
    of objects.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 当任务需要检测和跟踪对象时，在数据中使用边界框。
- en: Since bounding boxes allow us to identify objects, the natural use of this data
    is in tracking systems. An example application is a system that monitors parking
    spots using a camera. It detects parking spots and tracks whether there is a vehicle
    parked in the spot or not.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 由于边界框使我们能够识别对象，因此这些数据的自然用途是在跟踪系统中。一个示例应用是使用摄像头监控停车位的系统。它检测停车位并跟踪是否有车辆停在该位置。
- en: An extension of the object detection task is a perception task, where our ML
    software needs to make decisions based on the context of the data – or a situation.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对象检测任务的扩展是感知任务，其中我们的机器学习软件需要根据数据的上下文或情况做出决策。
- en: 'For image data, this context can be described by a semantic map. *Figure 3**.15*
    shows such a map:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像数据，这种上下文可以通过语义地图来描述。*图 3.15* 展示了这样一个地图：
- en: '![Figure 3.15 – Image with a semantic map; building is one of the labels for
    the semantic map](img/B19548_03_14.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.15 – 带有语义地图的图像；建筑是语义地图的一个标签](img/B19548_03_14.jpg)'
- en: Figure 3.15 – Image with a semantic map; building is one of the labels for the
    semantic map
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.15 – 带有语义地图的图像；建筑是语义地图的一个标签
- en: The screenshot shows an overlay of different colors that cover objects of specific
    types. The orange overlay shows vehicles, while the purple one shows vulnerable
    road users, which is the pedestrian in this image. Finally, the pink color indicates
    buildings, and the red color covers the background/sky.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 截图显示了覆盖特定类型对象的多种颜色叠加。橙色叠加显示车辆，紫色叠加显示易受伤害的道路使用者，在本图中即为行人。最后，粉色表示建筑，红色覆盖背景/天空。
- en: The semantic map provides more flexibility than bounding boxes (as some objects
    are more interesting than others) and allows the ML system to get the context
    of the image. By identifying what kinds of elements are present in the image,
    the ML model can provide information about where the image was taken to the decision
    algorithm of the software system that we design.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 语义地图比边界框提供了更多的灵活性（因为某些对象比其他对象更有趣），并允许机器学习系统获取图像的上下文。通过识别图像中存在哪些类型的元素，机器学习模型可以为我们设计的软件系统的决策算法提供有关图像拍摄位置的信息。
- en: Therefore, here’s my next best practice.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这是我的下一个最佳实践。
- en: 'Best practice #22'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #22'
- en: Use semantic maps when you need to get the context of the image or you need
    details of a specific area.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要获取图像的上下文或需要特定区域的详细信息时，使用语义地图。
- en: Semantic maps require heavy computations to be used effectively; therefore,
    we should use them scarcely. We should use these maps when we have tasks related
    to the context, such as perception algorithms or image alteration – for example,
    changing the color of the sky in the image. Regarding the accuracy of the information,
    it is generally true that semantic maps require heavy computations and are therefore
    used selectively. An example of a tool that does such a semantic mapping is Segments.ai.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 语义地图需要大量计算才能有效使用；因此，我们应该很少使用它们。当我们有与上下文相关的任务时，例如感知算法或图像修改——例如，改变图像中天空的颜色——我们应该使用这些地图。关于信息的准确性，一般来说，语义地图需要大量计算，因此是选择性使用的。一个进行此类语义映射的工具示例是
    Segments.ai。
- en: Semantic maps are useful when the task requires understanding the context of
    an image or details of a specific area. For example, in autonomous driving, a
    semantic map can be used to identify objects on the road and their relationship
    to each other, allowing the vehicle to make informed decisions about its movement.
    However, specific use cases for semantic maps may vary depending on the application.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 语义地图在需要理解图像的上下文或特定区域的细节时非常有用。例如，在自动驾驶中，语义地图可以用来识别道路上的物体及其相互关系，从而使车辆能够就其移动做出明智的决定。然而，语义地图的具体应用案例可能因应用而异。
- en: Annotating text for intent recognition
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为意图识别标注文本
- en: 'SA, which we mentioned before, is only one type of annotation of textual data.
    It is useful for assessing whether the text is positive or negative. However,
    instead of annotating text with a sentiment, we can annotate the text with – for
    example – the intent and train an ML model to recognize intent from other text
    passages. The table in *Figure 3**.16* provides such an annotation, based on the
    same review data as before:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到的SA只是文本数据标注的一种类型。它有助于评估文本是正面还是负面。然而，我们不是用情感标注文本，而是可以用——例如——意图来标注文本，并训练一个机器学习模型从其他文本段落中识别意图。图*3.16*中的表格提供了这样的标注，基于之前的相同评论数据：
- en: '| **Id** | **Score** | **Summary** | **Text** | **Intent** |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| **Id** | **Score** | **Summary** | **Text** | **Intent** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1 | 5 | Good Quality Dog Food | I have bought several of the Vitality canned
    dog food products and have found them all to be of good quality. The product looks
    more like a stew than a processed meat and it smells better. My Labrador is finicky
    and she appreciates this product better than most. | Advertise |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 5 | 高质量狗粮 | 我购买了几个Vitality罐装狗粮产品，并发现它们的质量都很好。产品看起来更像炖菜而不是加工肉类，而且味道更好。我的拉布拉多很挑食，她比大多数狗更喜欢这个产品。
    | 广告 |'
- en: '| 2 | 1 | Not as Advertised | Product arrived labeled as Jumbo Salted Peanuts...the
    peanuts were actually small sized unsalted. Not sure if this was an error or if
    the vendor intended to represent the product as “Jumbo”. | Criticize |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1 | 不如广告所说 | 产品到达时标有“巨型盐味花生”……实际上花生是小型无盐的。不确定这是否是一个错误，还是卖家有意将产品标为“巨型”。
    | 批评 |'
- en: '| 3 | 4 | “Delight” says it all | This is a confection that has been around
    a few centuries. It is a light, pillowy citrus gelatin with nuts - in this case
    Filberts. And it is cut into tiny squares and then liberally coated with powdered
    sugar. And it is a tiny mouthful of heaven. Not too chewy, and very flavorful.
    I highly recommend this yummy treat. If you are familiar with the story of C.S.
    Lewis’ “The Lion, The Witch, and The Wardrobe” - this is the treat that seduces
    Edmund into selling out his Brother and Sisters to the Witch. | Describe |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4 | “快乐”一词已尽其意 | 这是一种存在了几百年的糖果。它是一种轻盈、蓬松的柑橘果冻，里面有坚果——在这种情况下是榛子。然后它被切成小块，并大量裹上糖粉。这是一口小小的天堂。不太嚼劲，非常美味。我强烈推荐这种美味的点心。如果你熟悉C.S.路易斯的《狮子、女巫和魔衣橱》的故事——这就是诱惑爱德蒙背叛他的兄弟姐妹给女巫的点心。
    | 描述 |'
- en: "| 4 | 2 | Cough\L Medicine | If you are looking for the secret ingredient in\
    \ Robitussin I believe I have found it. I got this in addition to the Root Beer\
    \ Extract I ordered (which was good) and made some cherry soda. The flavor is\
    \ very medicinal. | Criticize |"
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: "| 4 | 2 | 咳嗽\L 药品 | 如果你正在寻找Robitussin的秘诀成分，我相信我已经找到了。我除了订购的根啤酒提取物（味道不错）外，还制作了一些樱桃汽水。味道非常像药。\
    \ | 批评 |"
- en: '| 5 | 5 | Great taffy | Great taffy at a great price. There was a wide assortment
    of yummy taffy. Delivery was very quick. If your a taffy lover, this is a deal.
    | Advertise |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 5 | 优秀的太妃糖 | 价格合理的优秀太妃糖。有各种各样的美味太妃糖。送货非常快。如果你是太妃糖爱好者，这是一个划算的交易。 | 广告
    |'
- en: Figure 3.16 – Textual data annotation for intent recognition
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16 – 用于意图识别的文本数据标注
- en: 'The last column of the table shows the annotation of the text – the intent.
    Now, we can use the intent as a label to train an ML model to recognize intent
    in the new text. Usually, this task requires a two-step approach, as shown in
    *Figure 3**.17*:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 表格的最后一列显示了文本的注释——意图。现在，我们可以使用意图作为标签来训练一个机器学习模型以识别新文本中的意图。通常，这项任务需要两步方法，如图*3.17*所示：
- en: '![Figure 3.17 – A two-step approach for training models based on text](img/B19548_03_15.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图3.17 – 基于文本训练模型的两个步骤方法](img/B19548_03_15.jpg)'
- en: Figure 3.17 – A two-step approach for training models based on text
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17 – 基于文本训练模型的两个步骤方法
- en: The annotated text is organized into two parts. The first part is the text itself
    (for example, the `Text` column in our example table), and the second part is
    the annotation (e.g., the `Intent` column in our example). The text is processed
    using a model such as the word2vec model or a transformer, which encodes the text
    as a vector or a matrix. The annotations are encoded into a vector using techniques
    such as one-hot encoding so that they can be used as decision classes for the
    classification algorithm. The classification algorithm takes both the encoded
    annotations and the vectorized text. Then, it is trained to find the best fit
    of the vectorized text (*X*) to the annotation (*Y*).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 标注的文本被组织成两部分。第一部分是文本本身（例如，我们示例表中的“Text”列），第二部分是标注（例如，我们示例中的“Intent”列）。文本使用如word2vec模型或transformer等模型进行处理，将文本编码为向量或矩阵。标注使用如one-hot编码等技术编码为向量，以便它们可以作为分类算法的决策类别。分类算法接受编码的标注和向量化的文本。然后，它被训练以找到向量化文本（*X*）与标注（*Y*）的最佳匹配。
- en: Here is my best practice on how to perform that.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我的最佳实践，如何执行这项操作。
- en: 'Best practice #23'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践#23
- en: Use a pre-trained embedding model such as GPT-3 or an existing BERT model to
    vectorize your text.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练的嵌入模型，如GPT-3或现有的BERT模型来向量化您的文本。
- en: From my experience, working with text is often easier if we use a predefined
    language model to vectorize the text. The *Hugging Face* website ([www.huggingface.com](http://www.huggingface.com))
    is an excellent source of these models. Since LLMs require significant resources
    to train, the existing models are often good enough for most of the tasks. Since
    we develop the classifier model as the next step in the pipeline, we can focus
    our efforts on making that model better and align it with our task.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，如果我们使用预定义的语言模型来向量化文本，那么处理文本通常会更简单。*Hugging Face*网站([www.huggingface.com](http://www.huggingface.com))是这些模型的优秀来源。由于LLMs需要大量的资源来训练，现有的模型通常对于大多数任务来说已经足够好了。由于我们将在管道的下一步开发分类器模型，我们可以集中精力使该模型更好，并与我们的任务保持一致。
- en: 'Another type of annotation of text data is the context in terms of the **part
    of speech** (**POS**). It can be seen as the semantic map used in the image data.
    Each word is annotated, whether it is a noun, verb, or adjective, regardless of
    which part of the sentence it belongs to. An example of such an annotation can
    be presented visually, using the Allen Institute’s AllenNLP **Semantic Role Labeling**
    (**SRL**) tool ([https://demo.allennlp.org/semantic-role-labeling](https://demo.allennlp.org/semantic-role-labeling)).
    *Figure 3**.18* presents a screenshot of such labeling for a simple sentence,
    while *Figure 3**.19* presents the labeling for a more complex one:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据的另一种标注类型是关于**词性**（**POS**）的上下文。它可以被视为在图像数据中使用的语义图。每个词都被标注，无论它是名词、动词还是形容词，无论它属于句子的哪个部分。这种标注的一个示例可以通过使用艾伦研究所的AllenNLP
    **语义角色标注**（**SRL**）工具（[https://demo.allennlp.org/semantic-role-labeling](https://demo.allennlp.org/semantic-role-labeling)）进行视觉展示。*图3*.*18*展示了简单句子的此类标注截图，而*图3*.*19*展示了更复杂句子的标注：
- en: "![Figure 3.18 – SRL using \uFEFFthe AllenNLP toolset](img/B19548_03_16.jpg)"
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图3.18 – 使用AllenNLP工具集进行SRL](img/B19548_03_16.jpg)'
- en: Figure 3.18 – SRL using the AllenNLP toolset
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18 – 使用AllenNLP工具集进行SRL
- en: 'In this sentence, the role of each word is emphasized, and we see that there
    are three verbs with different associations – the last one is the main one as
    it links the other parts of the sentence:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个句子中，每个词的作用都被强调，我们可以看到有三个具有不同关联的动词——最后一个动词是主要的，因为它将句子的其他部分联系起来：
- en: '![Figure 3.19 – SRL for a more complex sentence](img/B19548_03_17.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图3.19 – 更复杂句子的SRL](img/B19548_03_17.jpg)'
- en: Figure 3.19 – SRL for a more complex sentence
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19 – 更复杂句子的SRL
- en: The complex sentence has a larger semantic role frame, as it contains two distinct
    parts of the sentence. We use this role labeling in order to extract the meaning
    of passages of text. It is particularly useful when designing software systems
    based on so-called *grounded models*, which are models that check the information
    toward a ground truth. Such models parse the text data, find the right anchor
    (for example, what the question is about), and find the relevant answer in their
    database. These are opposed to *ungrounded models*, which create answers based
    on which word fits best to finish the sentence – for example, ChatGPT.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂句子具有更大的语义角色框架，因为它包含句子的两个不同部分。我们使用这种角色标注来提取文本段落的意义。这在设计基于所谓*基于事实的模型*的软件系统时尤其有用，这些模型会检查信息是否与事实相符。这些模型解析文本数据，找到正确的锚点（例如，问题是什么），并在它们的数据库中找到相关的答案。这些与*非基于事实的模型*相对，这些模型基于哪个词最适合完成句子来创建答案——例如，ChatGPT。
- en: Therefore, my best practice is shown next.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我的最佳实践如下。
- en: 'Best practice #24'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践#24
- en: Use role labels when designing software that needs to provide grounded decisions.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计需要提供基于事实的决策的软件时，使用角色标签。
- en: Grounded decisions are often more difficult to provide, as the model needs to
    understand the context of the sentence, capture its meaning, and provide relevant
    answers. However, this is not always needed or even desired. Ungrounded models
    are often good enough for suggestions that can be later fixed by specialists.
    An example of such a software tool is ChatGPT, which provides answers that are
    sometimes incorrect and require manual intervention. However, they are a very
    good start.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 基于事实的决策通常更难提供，因为模型需要理解句子的上下文，捕捉其意义，并提供相关的答案。然而，这并不总是必需的，甚至可能不是所希望的。非基于事实的模型对于可以由专家稍后修正的建议通常已经足够好。ChatGPT这样的软件工具就是一个例子，它提供的答案有时是不正确的，需要人工干预。然而，它们是一个非常好的起点。
- en: Where different types of data can be used together – an outlook on multi-modal
    data models
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在可以使用不同类型的数据一起使用的地方——对多模态数据模型的展望
- en: This chapter introduced three types of data – images, text, and structured text.
    These three types of data are examples of data that is in a numerical form, such
    as matrices of numbers, or in forms of time series. Regardless of the form, however,
    working with data and ML systems is very similar. We need to extract the data
    from a source system, then transform it into a format that we can annotate, and
    then use this as input to an ML model.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了三种类型的数据——图像、文本和结构化文本。这三种类型的数据是数值形式的数据的例子，如数字矩阵，或时间序列的形式。然而，无论形式如何，与数据和机器学习系统一起工作是非常相似的。我们需要从源系统中提取数据，然后将其转换为我们可以注释的格式，然后将其用作机器学习模型的输入。
- en: When we consider different types of data, we could start to think about whether
    we could use two types of data in the same system. There are a few ways of doing
    that. The first one is when we use different ML systems in different pipelines,
    but we connect the pipelines. GitHub Copilot is such a system. It uses a pipeline
    for processing a natural language to find similar programs and to transform them
    so that they fit the context of the program being developed now.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑不同类型的数据时，我们可以开始思考是否可以在同一个系统中使用两种类型的数据。有几种方法可以实现这一点。第一种是在不同的管道中使用不同的机器学习系统，但我们连接了这些管道。GitHub
    Copilot就是这样一种系统。它使用一个管道来处理自然语言，以找到类似的程序并将它们转换成适合当前正在开发的程序上下文。
- en: Another example is a system that generates textual descriptions of images. It
    takes an image as an input, identifies objects in it, and then generates text
    based on these objects. The generation of text is done by a completely different
    ML model than the classification of images.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是生成图像文本描述的系统。它接受一个图像作为输入，识别其中的对象，然后基于这些对象生成文本。文本的生成是通过一个与图像分类完全不同的机器学习模型完成的。
- en: However, there are new models that use two different modalities – images and
    texts – in the same NN – for example, the Gato model. By using the input from
    two sources and using a very narrow (in terms of the number of neurons) network
    in the middle, the model is trained to generalize concepts described by two different
    modalities. In this way, the model is trained to understand that an image of a
    cat and the word “cat” should be placed in the same embedding space very close
    to one another, if not exactly in the same places. Although still experimental,
    these kinds of networks are intended to mimic the human understanding of concepts.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive a bit deeper into the understanding of data
    by making a deeper dive into the process of feature engineering.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Tao, J. et al., An object detection system based on YOLO in traffic scene.
    In 2017 6th International Conference on Computer Science and Network Technology
    (ICCSNT).* *2017\. IEEE.*'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Artan, C.T. and T. Kaya, Car Damage Analysis for Insurance Market Using Convolutional
    Neural Networks. In International Conference on Intelligent and Fuzzy Systems.*
    *2019\. Springer.*'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Nakaura, T. et al., A primer for understanding radiology articles about machine
    learning and deep learning. Diagnostic and Interventional Imaging, 2020\. 101(12):*
    *p. 765-770.*'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Bradski, G., The OpenCV Library. Dr. Dobb’s Journal: Software Tools for the
    Professional Programmer, 2000\. 25(11):* *p. 120-123.*'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Memon, J. et al., Handwritten optical character recognition (OCR): A comprehensive
    systematic literature review (SLR). IEEE Access, 2020\. 8:* *p. 142642-142668.*'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mosin, V. et al., Comparing autoencoder-based approaches for anomaly detection
    in highway driving scenario images. SN Applied Sciences, 2022\. 4(12):* *p. 1-25.*'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Zeineldin, R.A. et al., DeepSeg: deep neural network framework for automatic
    brain tumor segmentation using magnetic resonance FLAIR images. International
    journal of computer assisted radiology and surgery, 2020\. 15(6):* *p. 909-920.*'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Reid, R. et al., Cooperative multi-robot navigation, exploration, mapping
    and object detection with ROS. In 2013 IEEE Intelligent Vehicles Symposium (IV).*
    *2013\. IEEE.*'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mikolov, T. et al., Recurrent neural network based language model. In Interspeech.*
    *2010\. Makuhari.*'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Vaswani, A. et al., Attention is all you need. Advances in neural information
    processing systems,* *2017\. 30.*'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ma, L. and Y. Zhang, Using Word2Vec to process big text data. In 2015 IEEE
    International Conference on Big Data (Big Data).* *2015\. IEEE.*'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ouyang, X. et al., Sentiment analysis using convolutional neural network.
    In 2015 IEEE International Conference on Computer and Information Technology;
    ubiquitous computing and communications; dependable, autonomic and secure computing;
    pervasive intelligence and computing.* *2015\. IEEE.*'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Roziere, B. et al., Unsupervised translation of programming languages. Advances
    in Neural Information Processing Systems, 2020\. 33:* *p. 20601-20611.*'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Yasunaga, M. and P. Liang, Break-it-fix-it: Unsupervised learning for program
    repair. In International Conference on Machine Learning.* *2021\. PMLR.*'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Halali, S. et al., Improving defect localization by classifying the affected
    asset using machine learning. In International Conference on Software Quality.*
    *2019\. Springer.*'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ochodek, M. et al., Recognizing lines of code violating company-specific coding
    guidelines using machine learning. In Accelerating Digital Transformation. 2019,
    Springer.* *p. 211-251.*'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Nguyen, N. and S. Nadi, An empirical evaluation of GitHub copilot’s code suggestions.
    In Proceedings of the 19th International Conference on Mining Software* *Repositories.
    2022.*'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Zhang, C.W. et al., Pedestrian detection based on improved LeNet-5 convolutional
    neural network. Journal of Algorithms & Computational Technology, 2019\. 13:*
    *p. 1748302619873601.*'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*LeCun, Y. et al., Gradient-based learning applied to document recognition.
    Proceedings of the IEEE, 1998\. 86(11):* *p. 2278-2324.*'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Xiao, H., K. Rasul, and R. Vollgraf, Fashion-MNIST: a novel image dataset
    for benchmarking machine learning algorithms. arXiv preprint* *arXiv:1708.07747,
    2017.*'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Recht, B. et al., Do CIFAR-10 classifiers generalize to CIFAR-10? arXiv preprint*
    *arXiv:1806.00451, 2018.*'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Robert, T., N. Thome, and M. Cord, HybridNet: Classification and reconstruction
    cooperation for semi-supervised learning. In Proceedings of the European Conference
    on Computer Vision (**ECCV). 2018.*'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Yu, F. et al., Bdd100k: A diverse driving video database with scalable annotation
    tooling. arXiv preprint arXiv:1805.04687, 2018\. 2(5):* *p. 6.*'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*McAuley, J.J. and J. Leskovec, From amateurs to connoisseurs: modeling the
    evolution of user expertise through online reviews. In Proceedings of the 22nd
    International Conference on World Wide* *Web. 2013.*'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Van der Maaten, L. and G. Hinton, Visualizing data using t-SNE. Journal of
    Machine Learning Research,* *2008\. 9(11).*'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sengupta, S. et al., Automatic dense visual semantic mapping from street-level
    imagery. In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems.*
    *2012\. IEEE.*'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Palmer, M., D. Gildea, and N. Xue, Semantic role labeling. Synthesis Lectures
    on Human Language Technologies, 2010\. 3(1):* *p. 1-103.*'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Reed, S. et al., A generalist agent. arXiv preprint* *arXiv:2205.06175, 2022.*'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
