- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Vertex AI – Generative AI Tools
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Vertex AI – 生成式人工智能工具
- en: '**Generative artificial intelligence** (**GenAI)** is a rapidly evolving field
    of AI that enables machines to create new content, such as text, images, code,
    and music. GenAI models are trained on massive datasets of existing content, and
    they learn to identify patterns and relationships that underlie that content.
    Once trained, these models can be used to generate new content that is similar
    to the content they were trained on but that is also unique and creative.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成式人工智能**（**GenAI**）是人工智能的一个快速发展的领域，它使机器能够创建新的内容，如文本、图像、代码和音乐。GenAI模型在大量现有内容的数据集上进行训练，并学习识别这些内容背后的模式和关系。一旦训练完成，这些模型就可以用来生成与训练内容相似但独特且富有创意的新内容。'
- en: 'GenAI models can be used for a wide variety of applications, including the
    following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI模型可用于广泛的用途，包括以下内容：
- en: '**Text generation**: Generating text, such as news articles, blog posts, marketing
    copy, and creative content'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本生成**：生成文本，如新闻文章、博客文章、营销文案和创意内容'
- en: '**Chatbots**: Creating chatbots that can have natural conversations with users'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天机器人**：创建能够与用户进行自然对话的聊天机器人'
- en: '**Image generation**: Generating images, such as product photos, marketing
    images, and artistic images'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像生成**：生成图像，如产品照片、营销图像和艺术图像'
- en: '**Code generation**: Generating code, such as Python scripts, Java classes,
    and HTML templates'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码生成**：生成代码，如Python脚本、Java类和HTML模板'
- en: '**Text embeddings**: Creating text embeddings that can be used for tasks such
    as text classification, text search, and **natural language** **inference** (**NLI**)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本嵌入**：创建可用于文本分类、文本搜索和**自然语言推理**（**NLI**）等任务的文本嵌入'
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: GenAI Fundamentals
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GenAI基础知识
- en: GenAI with Vertex AI
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GenAI与Vertex AI
- en: Prompt engineering overview
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程概述
- en: Retrieval augmented generation approach
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索增强生成方法
- en: Model Tuning
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型调优
- en: Before we dive into the GenAI capabilities of Vertex AI, let’s first understand
    the fundamentals of GenAI.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨Vertex AI的GenAI功能之前，让我们首先了解GenAI的基础知识。
- en: GenAI fundamentals
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GenAI基础知识
- en: GenAI is a subfield of AI that focuses on developing algorithms and models capable
    of generating new, original content, such as text, images, music, or code. This
    is in contrast to traditional AI models, which typically focus on understanding
    and classifying existing data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI是人工智能的一个子领域，专注于开发能够生成新内容，如文本、图像、音乐或代码的算法和模型。这与传统的人工智能模型形成对比，后者通常专注于理解和分类现有数据。
- en: At the heart of GenAI lies the concept of **large language models** (**LLMs**).
    LLMs are a type of **artificial neural network** (**ANN**) that has been trained
    on massive amounts of text data. This training allows LLMs to learn patterns and
    structures of human language, enabling them to generate text that is often indistinguishable
    from human-written text.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI的核心概念在于**大型语言模型**（**LLMs**）。LLMs是一种在大量文本数据上训练过的**人工神经网络**（**ANN**）。这种训练使得LLMs能够学习人类语言的模式和结构，从而能够生成与人类写作难以区分的文本。
- en: GenAI versus traditional AI
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GenAI与传统AI的比较
- en: Traditional AI models are typically based on **supervised learning** (**SL**),
    where the model is trained on a dataset of labeled examples. For example, a model
    for image classification might be trained on a dataset of images that have been
    labeled with the correct object category. Once trained, the model can then be
    used to classify new images.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的人工智能模型通常基于**监督学习**（**SL**），其中模型在标记示例的数据集上进行训练。例如，一个用于图像分类的模型可能会在标记了正确对象类别的图像数据集上进行训练。一旦训练完成，该模型就可以用来对新的图像进行分类。
- en: GenAI models, on the other hand, are typically based on **unsupervised learning**
    (**UL**), where the model is trained on a dataset of unlabeled data. The model
    is then tasked with learning underlying patterns and structures in the data. In
    the case of an LLM, this might involve learning the patterns of human language.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，GenAI模型通常基于**无监督学习**（**UL**），其中模型在未标记数据集上进行训练。模型的任务是学习数据中的潜在模式和结构。在LLM的情况下，这可能涉及学习人类语言的模式。
- en: Types of GenAI models
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GenAI模型的类型
- en: 'There are several different types of GenAI models, each with its own strengths
    and weaknesses. Some of the most common types include the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI模型有多种不同类型，每种类型都有其自身的优势和劣势。其中一些最常见类型包括以下内容：
- en: '**Autoregressive models**: These models generate text one word at a time, predicting
    the next word based on the words that have already been generated'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自回归模型**：这些模型逐字生成文本，根据已经生成的单词预测下一个单词'
- en: '**Variational autoencoders (VAEs)**: These models learn a latent representation
    of the data, which can then be used to generate new samples'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变分自编码器（VAEs）**：这些模型学习数据的潜在表示，然后可以用来生成新的样本'
- en: '**Generative adversarial networks (GANs)**: These models consist of two competing
    NNs: a generator that generates new samples, and a discriminator that tries to
    distinguish between real and fake samples'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成对抗网络（GANs）**：这些模型由两个相互竞争的神经网络组成：一个生成器生成新的样本，一个判别器试图区分真实和虚假样本'
- en: Challenges of GenAI
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GenAI的挑战
- en: 'Despite its promise, GenAI still faces several challenges, including the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前景广阔，但GenAI仍然面临几个挑战，包括以下内容：
- en: '**Bias**: GenAI models can be biased, reflecting the biases in the data they
    are trained on. For example, when a model directly trained on raw content sourced
    from the internet is asked to write a story about a doctor and a nurse, the LLM
    is more likely to write a story about a male doctor and a female nurse, even if
    the prompt does not specify the gender of either character. This happens because
    the model has learned the same gender bias that is deeply embedded in our society
    and in the content shared online by members of our society.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏差**：GenAI模型可能会存在偏差，反映它们训练数据中的偏差。例如，当模型直接在来自互联网的原始内容上训练时，如果要求它写一个关于医生和护士的故事，LLM更有可能写一个关于男性医生和女性护士的故事，即使提示没有指定任何角色的性别。这是因为模型已经学会了深深嵌入在我们社会和我们社会成员在线分享的内容中的相同性别偏见。'
- en: '**Generation of fake/harmful content**: GenAI models can be used to generate
    harmful or offensive content. Issues of “deepfakes,” where AI is used to superimpose
    images of unsuspecting victims on images or videos, are already beginning to plague
    the internet.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成虚假/有害内容**：GenAI模型可以用来生成有害或冒犯性的内容。AI用于在图像或视频上叠加不知情受害者图像或视频的“深度伪造”问题已经开始困扰互联网。'
- en: '**Explainability**: It can be difficult to explain how GenAI models make decisions,
    which can make it difficult to trust them.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性**：解释GenAI模型如何做决定可能很困难，这可能会使其难以被信任。'
- en: '**Hallucinations**: The last, but also possibly the most harmful and most difficult-to-solve
    challenge of GenAI solutions and underlying LLMs is our inability to stop them
    from hallucinating. In the context of LLMs, “hallucinations” refer to instances
    where the model generates information that is not grounded in reality, is factually
    incorrect, or does not make sense given the context. This can be an issue when
    using AI for tasks that require high levels of accuracy, such as news generation
    or academic research, or in legal and medical applications. Here are a few examples
    of hallucinations we have encountered with foundation LLMs with no mitigation
    techniques applied:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**幻觉**：GenAI解决方案和底层LLM的最后一个挑战，也可能是最具破坏性和最难解决的挑战，是我们无法阻止它们产生幻觉。在LLM的背景下，“幻觉”指的是模型生成的不基于现实、事实错误或根据上下文没有意义的信息。当使用AI执行需要高精度任务时，例如新闻生成或学术研究，或在法律和医疗应用中，这可能会成为一个问题。以下是我们在没有应用缓解技术的基LLM中遇到的几个幻觉示例：'
- en: 'Example 1:'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例1：
- en: '`User: What` `is 2+2?`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`用户：2+2等于多少？`'
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`User: What? Are you giving me the wrong information? My friend told me that
    2+2` `is 5.`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`用户：什么？你给我提供错误的信息吗？我的朋友告诉我2+2等于5。`'
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now, obviously 2+2 is not 5 regardless of what my friend said. But we were easily
    able to convince the ‘all-knowing’ LLM of this being true.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，显然2+2不等于5，无论我的朋友怎么说。但我们很容易就说服了“无所不知”的LLM这是真的。
- en: 'Example 2:'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例2：
- en: '`User: Give me a summary of a whitepaper titled "Why AI Systems Are Dangerous"
    along with` `its citation.`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`用户：给我总结一下标题为“为什么AI系统是危险的”的白皮书，以及其引用。`'
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Based on the first look, it seems like the LLM model did an amazing job of providing
    the information about the paper. The only issue is that there is no such paper
    with the title “*Why AI Systems Are Dangerous*.” Our model didn’t just invent
    a paper based on our prompt; it also made up the arXiv identifier for the paper!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 根据第一印象，看起来LLM模型在提供论文信息方面做得非常出色。唯一的问题是，并没有标题为“*为什么AI系统是危险的*”的论文。我们的模型不仅根据我们的提示发明了一篇论文，而且还为这篇论文编造了arXiv标识符！
- en: Now, let’s look at some of the evaluation techniques commonly used to evaluate
    LLMs.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看一些常用的评估技术，这些技术通常用于评估LLM。
- en: LLM evaluation
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM评估
- en: 'Evaluating LLMs is crucial for assessing their performance, identifying areas
    for improvement, and ensuring their responsible development and deployment. Several
    evaluation methods are employed to assess LLMs across various dimensions, including
    the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 评估大型语言模型（LLM）对于评估其性能、确定改进领域以及确保其负责任的发展和部署至关重要。为了从多个维度评估LLM，采用了多种评估方法，包括以下内容：
- en: '**Generative metrics**:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成性指标**：'
- en: '**Perplexity**: A measure of how well an LLM predicts the next word in a sequence.
    Lower perplexity indicates better predictive ability.'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**困惑度**：衡量LLM预测序列中下一个单词的能力。困惑度越低，表示预测能力越好。'
- en: '**BLEU score**: Evaluates the similarity between generated text and human-written
    reference text. Higher BLEU scores indicate greater similarity.'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BLEU分数**：评估生成文本与人类编写的参考文本之间的相似度。BLEU分数越高，表示相似度越大。'
- en: '**Recall-Oriented Understudy for Gisting Evaluation (ROUGE)**: A set of metrics
    that assess different aspects of text similarity, such as word overlap and recall.'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用于摘要评估的召回导向的副手（ROUGE）**：一套评估文本相似性不同方面的指标，如单词重叠和召回。'
- en: '**Human evaluation**:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工评估**：'
- en: Human evaluation plays a crucial role in assessing the quality and effectiveness
    of LLMs. While automated metrics can provide valuable insights into LLM performance,
    human judgment is essential for evaluating aspects that are difficult to quantify,
    such as fluency, coherence, relevance, and creativity.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人工评估在评估LLM的质量和有效性方面发挥着至关重要的作用。虽然自动化指标可以为LLM的性能提供有价值的见解，但人类判断对于评估难以量化的方面（如流畅性、连贯性、相关性和创造性）是必不可少的。
- en: '**Benchmarking**:'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基准测试**：'
- en: '**Standard benchmarks**: Utilizing established benchmarks, such as GLUE, SuperGLUE,
    or Big-bench, to compare LLM performance across various tasks.'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准基准**：利用已建立的基准，如GLUE、SuperGLUE或Big-bench，来比较LLM在各种任务中的性能。'
- en: '**Domain-specific benchmarks**: When developing LLMs for domain-specific use
    cases, model developers should also work on developing domain-specific benchmarks
    to evaluate LLMs in specialized areas, such as medical diagnosis or legal research.
    Considering the effort that goes into developing such benchmarks, we expect to
    see an increased level of collaborative efforts by major teams within specific
    industries to publish industry standards for such benchmarks.'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特定领域基准**：当为特定领域用例开发LLM时，模型开发者还应致力于开发特定领域的基准，以评估LLM在专业领域（如医学诊断或法律研究）中的表现。考虑到开发此类基准所需的努力，我们预计特定行业的主要团队将进行更多合作，发布此类基准的行业标准。'
- en: By employing a combination of these evaluation methods, researchers and developers
    can gain a comprehensive understanding of LLM capabilities, limitations, and potential
    biases, enabling them to refine and improve these powerful language models.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合这些评估方法，研究人员和开发者可以全面了解LLM的能力、局限性和潜在偏差，使他们能够改进和提升这些强大的语言模型。
- en: Now, let’s look at the features available in Vertex AI to develop GenAI solutions.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看Vertex AI中可用于开发生成式AI解决方案的功能。
- en: GenAI with Vertex AI
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Vertex AI进行生成式AI
- en: Vertex AI provides a variety of tools and resources to help you get started
    with GenAI. You can use Vertex AI Model Garden to explore the different GenAI
    models that are available and to get help with setting up and using these models.
    You can also use Vertex AI GenAI Studio to experiment with GenAI models and to
    create your own prompts.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI提供各种工具和资源，帮助您开始使用生成式AI。您可以使用Vertex AI模型园地来探索可用的不同生成式AI模型，并获得设置和使用这些模型的帮助。您还可以使用Vertex
    AI生成式AI工作室来实验生成式AI模型，并创建您自己的提示。
- en: Understanding foundation models
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解基础模型
- en: 'Within the Vertex AI environment, you will encounter what are termed “foundation
    models.” These are essentially GenAI models defined based on the nature of the
    content they are engineered to create. The categories of models available within
    Vertex AI span across a diverse range, including, but not limited to, the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在Vertex AI环境中，您会遇到所谓的“基础模型”。这些模型本质上是基于它们被设计用来创建的内容的性质定义的生成式AI模型。Vertex AI中可用的模型类别范围广泛，包括但不限于以下内容：
- en: '**Text and chat**: For crafting textual content and facilitating chat interactions'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本和聊天**：用于创建文本内容并促进聊天交互'
- en: '**Images**: To generate visual content'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像**：用于生成视觉内容'
- en: '**Code**: Generating code, unit tests, and assisting developers'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码**：生成代码、单元测试并协助开发者'
- en: '**Embeddings**: Creating representations of text or images in a vector space'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入**：在向量空间中创建文本或图像的表示'
- en: These foundation models are accessible via publisher endpoints unique to your
    specific Google Cloud project, thus eliminating the necessity for deploying the
    foundation models separately unless customization for particular applications
    is required.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基础模型可通过您特定Google Cloud项目的发布者端点访问，从而消除了单独部署基础模型的必要性，除非需要针对特定应用进行定制。
- en: 'The Vertex AI GenAI toolset comprises of two key components:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI GenAI工具集包括两个关键组件：
- en: Vertex AI Model Garden (used for a lot more than just GenAI models)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vertex AI模型花园（不仅用于GenAI模型）
- en: Vertex AI GenAI Studio
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vertex AI GenAI Studio
- en: Let’s look next at what these components offer.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看这些组件提供了什么。
- en: Vertex AI Model Garden
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Vertex AI模型花园
- en: Vertex AI Model Garden is a repository of pre-trained **machine learning** (**ML**)
    models that you can choose from based on your requirements. It contains both Google
    proprietary models and third-party open source models.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI模型花园是一个预训练**机器学习**（**ML**）模型的存储库，您可以根据需求选择。它包含Google专有模型和第三方开源模型。
- en: Apart from being a one-stop shop for models addressing a variety of use cases,
    Model Garden also offers the same or similar Google models in varied sizes. This
    is particularly advantageous when your use case is relatively simple, and a smaller
    model is a lot more compute-efficient during inference while providing similar
    accuracy to a larger model for the particular use case.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了是一个针对各种用例的模型一站式商店外，模型花园还提供了不同大小的相同或类似Google模型。当您的用例相对简单时，这一点尤其有利，较小的模型在推理期间计算效率更高，同时为特定用例提供与较大模型相似的精度。
- en: 'The following screenshot gives you a glimpse of the large variety of models
    that are available within Vertex AI Model Garden ordered by the modalities or
    tasks they can be used for:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了Vertex AI模型花园中可用的各种模型，这些模型按其可用模式或任务进行排序：
- en: '![Figure 12.1 – Vertex AI Model Garden](img/B17792_12_1.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图12.1 – Vertex AI模型花园](img/B17792_12_1.jpg)'
- en: Figure 12.1 – Vertex AI Model Garden
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 – Vertex AI模型花园
- en: '**Naming structure denoting model sizes**: To help you distinguish between
    similar models of different sizes, the Google-published models in Vertex AI come
    with different suffixes. The four model-size labels Google has published so far,
    from largest to smallest, are unicorn, bison, otter, and gecko. Most of the models
    available today at the time of this book’s publishing are of the type bison or
    gecko, but users can expect additional models of different sizes to be included
    in the future, based on announcements from the Google Cloud team.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**命名结构表示模型大小**：为了帮助您区分不同大小的相似模型，Vertex AI中发布的Google模型带有不同的后缀。Google迄今为止发布的四个模型大小标签，从大到小分别是独角兽、野牛、水獭和壁虎。截至本书出版时，大多数可用的模型是野牛或壁虎类型，但用户可以期待根据Google
    Cloud团队的通知，未来将包含更多不同大小的模型。'
- en: Note
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The largest available LLM is not always the best choice for your solution since
    larger models incur significantly higher compute costs during inference as compared
    to models with fewer parameters. Always use the smallest possible model that meets
    your accuracy requirements to ensure your solution is compute-efficient.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 可用最大的LLM并不总是您解决方案的最佳选择，因为与参数较少的模型相比，较大的模型在推理过程中会产生显著更高的计算成本。始终使用满足您精度要求的最小模型，以确保您的解决方案计算效率高。
- en: Now, let’s look at some of the foundation models available within Model Garden.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看模型花园中可用的某些基础模型。
- en: Foundation GenAI models in Vertex AI Model Garden
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Vertex AI模型花园中的基础GenAI模型
- en: GenAI foundation models are large, powerful LLMs that form the core of all GenAI
    solutions. They are capable of generating new, original content, such as text,
    images, music, or code and are categorized by their modality (text, image. etc.)
    and by the use cases they address (general, medical, security, etc.).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI基础模型是大型、强大的LLM，构成了所有GenAI解决方案的核心。它们能够生成新的、原创的内容，如文本、图像、音乐或代码，并按其模式（文本、图像等）和使用案例（通用、医疗、安全等）进行分类。
- en: Vertex AI Model Garden is a repository of a large number of foundation models,
    both open source (for example, Llama, published by Meta) and the ones published
    by Google. Google models are built upon the core LLM models designed and trained
    by Google’s research and engineering teams. They address different key use cases
    such as chat, text generation, image generation, code assistance, and artifact
    matching.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 模型园是一个包含大量基础模型的仓库，包括开源模型（例如，Meta 发布的 Llama）和 Google 发布的模型。Google 模型建立在
    Google 研究和工程团队设计和训练的核心 LLM 模型之上。它们针对不同的关键用例，如聊天、文本生成、图像生成、代码辅助和工件匹配。
- en: 'Here’s a list of currently available Google-published models:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是当前可用的 Google 发布的模型列表：
- en: '`text-bison`:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text-bison`:'
- en: '*Description*: `text-bison` is a text generation model designed to follow natural
    language instructions, suitable for a range of language tasks. The “`bison`” suffix
    refers to the model size (see the preceding *Note* on model size labels).'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*: `text-bison` 是一个旨在遵循自然语言指令的文本生成模型，适用于各种语言任务。后缀“`bison`”表示模型大小（参见前面的 *注意*
    关于模型大小标签）。'
- en: '*Use cases*:'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Text classification
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本分类
- en: Entity extraction from given text input
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从给定文本输入中提取实体
- en: '**Extractive question** **answering** (**EQA**)'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提取式问答**（EQA）'
- en: Text summarization
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本摘要
- en: Marketing content generation
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 营销内容生成
- en: '`textembedding-gecko`:'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`textembedding-gecko`:'
- en: '*Description*: This model returns multi-dimensional vector embeddings for the
    text inputs. Once you have created an embedding database of an existing text corpus,
    you can use it to find the closest matches for any other text snippets. The “`gecko`”
    suffix refers to the model size (see the preceding *Note* on model size labels).'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*: 此模型为文本输入返回多维向量嵌入。一旦创建了现有文本语料库的嵌入数据库，您就可以使用它来查找任何其他文本片段的最近匹配。后缀“`gecko`”表示模型大小（参见前面的
    *注意* 关于模型大小标签）。'
- en: '*Use cases*:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Text matching
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本匹配
- en: Search engine backend
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索引擎后端
- en: '`textembedding-gecko-multilingual`:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`textembedding-gecko-multilingual`:'
- en: '*Description*: Similar to the aforementioned `textembedding-gecko` model, this
    model supports over 100 languages.'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*: 与上述 `textembedding-gecko` 模型类似，此模型支持超过 100 种语言。'
- en: '*Use cases*:'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Multilingual text analysis
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多语言文本分析
- en: Cross-language **natural language** **processing** (**NLP**)
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跨语言自然语言处理（NLP）
- en: Language translation applications
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言翻译应用
- en: '`chat-bison`:'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chat-bison`:'
- en: '*Description*: Optimized for multi-turn conversation scenarios. It has been
    trained with data until February 2023 and supports up to 4,096 input tokens, 1,024
    output tokens, and a maximum of 2,500 turns.'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*: 优化用于多轮对话场景。它已使用截至 2023 年 2 月的数据进行训练，支持多达 4,096 个输入标记、1,024 个输出标记和最多 2,500
    轮对话。'
- en: '*Use cases*:'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Chatbots
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人
- en: Virtual assistants
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟助手
- en: Customer service application
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户服务应用
- en: '`code-bison`:'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code-bison`:'
- en: '*Description*: Fine-tuned to generate code from natural language descriptions,
    facilitating up to 6,144 input tokens and 1,024 output tokens.'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*: 微调以从自然语言描述中生成代码，支持多达 6,144 个输入标记和 1,024 个输出标记。'
- en: '*Use cases*:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Automated code generation
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化代码生成
- en: Unit test creation
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单元测试创建
- en: '`codechat-bison`'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`codechat-bison`'
- en: '*Description*: Fine-tuned for chatbot conversations, assisting with code-related
    queries and supporting 6,144 input tokens and 1,024 output tokens.'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*: 微调用于聊天机器人对话，协助与代码相关的问题，并支持 6,144 个输入标记和 1,024 个输出标记。'
- en: '*Use cases*:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Code assistance chatbots
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码辅助聊天机器人
- en: Development support
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发支持
- en: Education and code learning platforms
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教育和代码学习平台
- en: '`code-gecko` (model tuning not supported) :'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code-gecko`（不支持模型调整）:'
- en: '*Description*: Designed to suggest code completion based on the context of
    the written code, managing up to 2,048 input tokens and 64 output tokens.'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*: 设计用于根据编写代码的上下文建议代码补全，管理多达 2,048 个输入标记和 64 个输出标记。'
- en: '*Use cases*:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Code completion tools
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码补全工具
- en: '`imagegeneration`:'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imagegeneration`:'
- en: '*Description*: This model is geared to generate high-quality visual assets
    swiftly, with specifications including a resolution of 1024x1024 pixels and allowances
    for certain requests and image size limits.'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*: 此模型旨在快速生成高质量的视觉资产，包括 1024x1024 像素的分辨率，并允许某些请求和图像大小限制。'
- en: '*Use cases*:'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Graphic design
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图形设计
- en: Content creation
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内容创作
- en: '`multimodalembedding`:'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multimodalembedding`:'
- en: '*Description*: Generates vectors from provided inputs, which can be a combination
    of image and text, within the specified token, language, and size parameters.'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*：从提供的输入生成向量，这些输入可以是图像和文本的组合，在指定的令牌、语言和大小参数内。'
- en: '*Use cases*:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Image and text analysis
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像和文本分析
- en: Multimodal data processing
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多模态数据处理
- en: Content recommendation systems
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内容推荐系统
- en: Image text (image captioning)
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像文本（图像标题）
- en: '`imagetext` (image captioning):'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imagetext`（图像标题）：'
- en: '*Description*: An image-captioning model capable of generating captions in
    several languages for a provided image, respecting certain rate and size limits.'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*：一个能够为提供的图像生成多语言标题的图像标题模型，同时遵守一定的速率和大小限制。'
- en: '*Use cases*:'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: Image captioning
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像标题
- en: Content creation
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内容创作
- en: Accessibility services
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无障碍服务
- en: Image text (**visual QA**, or **VQA**)
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像文本（**视觉问答**，或**VQA**）
- en: '`imagetext` (VQA):'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imagetext`（VQA）：'
- en: '*Description*: A model designed for VQA services, offering answers in English
    within defined rate and size restrictions.'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*描述*：一个为VQA服务设计的模型，在定义的速率和大小限制内提供英文答案。'
- en: '*Use cases*:'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例*:'
- en: VQA services
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: VQA服务
- en: Education and training modules
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教育和培训模块
- en: Interactive content creation
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交互式内容创作
- en: Since we have familiarized ourselves with the key foundation models, let’s now
    try them out through GenAI Studio.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经熟悉了关键的基础模型，现在让我们通过GenAI Studio来尝试它们。
- en: Vertex AI GenAI Studio
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Vertex AI GenAI Studio
- en: GenAI Studio is the user interface you can use to interact with most of the
    foundation models listed previously. It does not require any programming knowledge
    and is primarily built for non-programmers to be able to use the powerful GenAI
    capabilities offered through Vertex AI. Programmers, on the other hand, can use
    Vertex AI APIs to access the foundation GenAI model. We will discuss API-based
    usage later in the chapter.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI Studio是您可以用来与之前列出的大多数基础模型交互的用户界面。它不需要任何编程知识，主要是为非程序员构建，以便能够使用Vertex AI提供的强大GenAI功能。另一方面，程序员可以使用Vertex
    AI API来访问基础GenAI模型。我们将在本章后面讨论基于API的使用。
- en: 'Currently, GenAI Studio supports three modalities:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，GenAI Studio支持三种模态：
- en: Text (language)
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本（语言）
- en: Image (vision)
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像（视觉）
- en: Audio (speech)
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频（语音）
- en: GenAI Studio – language
  id: totrans-156
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: GenAI Studio – 语言
- en: 'In the **Language** section, you have the option to interact with the Vertex
    AI foundation models in two modes:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在**语言**部分，您可以选择以两种模式与Vertex AI基础模型交互：
- en: '**Prompt mode**: Uses text or code models optimized for transactional, usually
    larger responses to natural language queries around text or code generation'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示模式**：使用针对交易优化的文本或代码模型，通常对自然语言查询生成较大的响应'
- en: '**Chat mode**: Uses text or code models optimized for conversations to generate
    responses based on current input and recent conversation/chat history'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天模式**：使用针对对话优化的文本或代码模型，根据当前输入和最近的对话/聊天历史生成响应'
- en: 'The following screenshot shows the different options in GenAI Studio to interact
    with language models, including a prompt-based approach and a chat-based approach:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了GenAI Studio中与语言模型交互的不同选项，包括基于提示的方法和基于聊天的方法：
- en: '![Figure 12.2 – Vertex AI GenAI Studio (Language section)](img/B17792_12_2.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图12.2 – Vertex AI GenAI Studio（语言部分）](img/B17792_12_2.jpg)'
- en: Figure 12.2 – Vertex AI GenAI Studio (Language section)
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 – Vertex AI GenAI Studio（语言部分）
- en: Before we start experimenting with GenAI Studio, it is important we are familiar
    with basic concepts around prompt design/engineering.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用GenAI Studio进行实验之前，了解有关提示设计/工程的基本概念非常重要。
- en: What is a prompt?
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是提示？
- en: In the context of GenAI or NLP, a “prompt” refers to an input string of text
    that is fed into a language model to generate a corresponding output text. In
    this case, the prompt serves as a way to instruct or guide the model to generate
    text based on the given input. It can be a sentence, a phrase, or even a single
    word, depending on the specific requirements of the task at hand.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在GenAI或NLP的背景下，一个“提示”是指输入到语言模型中以生成相应输出文本的文本字符串。在这种情况下，提示作为指导或引导模型根据给定输入生成文本的方式。它可以是一个句子、一个短语，甚至是一个单词，具体取决于手头任务的特定要求。
- en: What is prompt design or prompt engineering?
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示设计或提示工程是什么？
- en: “Prompt design” refers to the process of crafting and optimizing the input (prompt)
    given to a language model to achieve the desired output or results. This process
    involves understanding the nuances of language and the behavior of the AI model
    to elicit responses that are aligned with the user’s expectations. Prompt design
    can be a critical aspect of working with generative LLMs.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: “提示设计”指的是为语言模型创建和优化输入（提示）的过程，以实现预期的输出或结果。这个过程涉及理解语言的细微差别和AI模型的行为，以引发与用户期望相符的响应。提示设计可能是与生成式LLM（大型语言模型）合作的关键方面。
- en: 'Here are some essential aspects of prompt design:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是提示设计的一些基本方面：
- en: '**Clarity**: Ensuring the prompt clearly conveys the desired task to the model'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**清晰性**：确保提示清楚地传达给模型所需的任务。'
- en: '**Specificity**: Making the prompt specific to avoid ambiguous or overly generalized
    responses'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**具体性**：使提示具体化，以避免模糊或过于泛化的响应。'
- en: '**Context**: Providing enough context in the prompt to facilitate a more informed
    and relevant output'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文**：在提示中提供足够的上下文，以促进更明智和相关的输出。'
- en: '**Formatting**: Structuring the prompt in a manner that encourages the desired
    format of the response'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**格式化**：以鼓励期望的响应格式的方式来结构化提示。'
- en: '**Testing and iteration**: Prompt design is often an iterative process involving
    testing various prompt strategies and fine-tuning them based on the outputs received'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试和迭代**：提示设计通常是一个迭代过程，涉及测试各种提示策略并根据收到的输出进行微调。'
- en: '**Ethical considerations**: Design prompts that are ethical and avoid encouraging
    harmful, biased, or inappropriate responses from the model'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**道德考量**：设计道德的提示，避免鼓励模型产生有害、偏见或不适当的响应。'
- en: '**Safety measures**: Implementing safety measures such as using techniques
    to limit the model to safe and appropriate responses'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全措施**：实施安全措施，例如使用技术限制模型仅对安全且适当的内容做出响应。'
- en: In practice, prompt design can involve a mixture of art and science, requiring
    both creative and analytical skills to master. It’s a key skill in the field of
    AI, especially for those working on AI-powered chatbots, virtual assistants, content
    creation tools, and other applications that rely on NLP.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，提示设计可能涉及艺术和科学的混合，需要创造性和分析技能的结合来掌握。它是AI领域的关键技能，特别是对于从事AI聊天机器人、虚拟助手、内容创作工具和其他依赖NLP（自然语言处理）的应用程序的人来说。
- en: Prompt content
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示内容
- en: 'A “prompt” can potentially be broken down into several components, depending
    on the complexity of the task at hand. Here are common parts that constitute a
    well-structured prompt:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 根据手头任务的复杂性，“提示”可以分解成几个组成部分。以下是构成良好结构化提示的常见部分：
- en: '**Instruction**: This is the part of the prompt where you provide a clear directive
    or question to guide the AI’s response. The instruction should be explicit about
    the kind of information or the format of the answer you are expecting. An instruction
    can be as simple as “What is the capital of California?” or as complicated as
    a 10-page-long list of rules to be taken into consideration by the model. This
    detailed set of instructions can overlap with the prompt “context” discussed next.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指令**：这是提示的一部分，其中你提供明确的指令或问题来引导AI的响应。指令应明确说明你期望的信息类型或答案格式。指令可以像“加利福尼亚州的首府是什么？”这样简单，也可以像考虑模型时应遵循的10页长规则列表那样复杂。这组详细的指令可以与下一节中讨论的“上下文”提示重叠。'
- en: '**Context**: If the prompt is a follow-up or is seeking detailed information,
    providing context can be essential. Context can include background information
    or data that is necessary to generate a precise and accurate response. For a chatbot,
    the context usually includes previous back-and-forth conversations with the bot
    so that the bot can keep responses contextual to the topic being discussed.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文**：如果提示是后续的或寻求详细信息，提供上下文可能是至关重要的。上下文可以包括生成精确和准确响应所需的背景信息或数据。对于一个聊天机器人，上下文通常包括与机器人之前的对话，以便机器人能够使响应与讨论的主题保持一致。'
- en: '**Examples**: In some cases, especially with more complex tasks, it might be
    beneficial to provide examples within the prompt to give a clearer picture of
    the expected output.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：在某些情况下，尤其是对于更复杂的任务，在提示中提供示例可能有益于更清晰地展示预期的输出。'
- en: 'Here’s an example of a simple prompt:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个简单提示的例子：
- en: '[PRE3]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In this prompt, we have the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个提示中，我们包含以下内容：
- en: '**Context**: Sets the stage by defining the role of the AI as a helper in finding
    a recipe based on the available ingredients'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文**：通过定义AI在根据可用食材寻找食谱中的角色来设定场景。'
- en: '**Instruction**: Clearly guides the AI to come up with a recipe that is simple
    and suitable for a beginner, using the ingredients listed'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指令**：明确指导AI提出一个简单且适合初学者的食谱，使用列出的食材。'
- en: '**Examples**: Offers a prototype recipe using a different set of ingredients,
    helping the AI understand the kind of response expected from it'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：提供了一个使用不同食材的原型食谱，帮助AI理解预期的响应类型。'
- en: This structured prompt aids in channeling the AI to craft a response that meets
    the specific needs and expectations of the user while providing a concrete example
    to work from. It encourages the AI to create a simple, beginner-friendly recipe
    using the ingredients specified in the prompt.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这种结构化的提示有助于引导AI构建一个满足用户特定需求和期望的响应，同时提供了一个具体的工作示例。它鼓励AI创建一个简单、适合初学者的食谱，使用提示中指定的食材。
- en: 'A typical response from a GenAI model to the structured prompt provided earlier
    might look something like this:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的GenAI模型对之前提供的结构化提示的响应可能看起来像这样：
- en: '[PRE4]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In this response, the following happens:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个响应中，以下情况发生了：
- en: A new recipe is created that utilizes all the ingredients mentioned in the prompt
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了一个新食谱，利用了提示中提到的所有食材。
- en: The instructions are simple and beginner-friendly, adhering to the directive
    given in the prompt
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指令简单且适合初学者，遵循提示中给出的指令。
- en: The recipe includes a list of ingredients along with their approximate quantities,
    followed by a step-by-step cooking guide to help even a beginner cook follow along
    easily
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该食谱包括食材清单及其大致数量，随后是一个逐步烹饪指南，帮助即使是初学者也能轻松跟随。
- en: The response maintains a helpful and encouraging tone, in line with the context
    set in the prompt, and it also adds a personal touch by suggesting optional garnishes
    to enhance the dish
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应保持了有帮助和鼓励的语气，与提示中设定的上下文一致，并且通过建议可选的装饰品来增强菜肴，增加了个人风格。
- en: 'In GenAI Studio, besides the input prompt, another important tool you can use
    to tweak the output is the response parameters listed next:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在GenAI Studio中，除了输入提示之外，您还可以使用以下列出的响应参数来调整输出：
- en: '**Max output tokens**: This parameter limits the highest count of tokens the
    generated response can contain. A “token” equates to about 4 characters, with
    100 tokens translating to roughly 60-80 words. To obtain shorter responses, set
    a lower value and, conversely, increase it for more verbose responses.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大输出标记数**：此参数限制了生成的响应可以包含的最高标记数。一个“标记”大约等于4个字符，100个标记大约相当于60-80个单词。为了获得更简短的响应，请设置较低的值，反之，为了获得更冗长的响应，请增加它。'
- en: '**Temperature**: This parameter defines the randomness during token selection
    in the response generation phase. A lower temperature value ensures deterministic
    and less imaginative outputs while increasing it encourages a more diversified
    and creative output.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**温度**：此参数定义了响应生成阶段中标记选择过程中的随机性。较低的温度值确保了确定性和较少的创造性输出，而增加它则鼓励更多样化和创造性的输出。'
- en: '**Top-K**: This parameter governs the token selection method by delineating
    the range of top probable tokens from which the next token is chosen, a process
    influenced by the temperature setting. The default setting is 40, but modifying
    it can control the randomness of the output, facilitating either a more deterministic
    or a more randomized response.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Top-K**：此参数通过定义从最高概率的标记中选择下一个标记的范围来控制标记选择方法，这个过程受到温度设置的影响。默认设置为40，但修改它可以控制输出的随机性，从而促进更确定性的或更随机化的响应。'
- en: '**Top-P**: Functioning somewhat similarly to **Top-K**, this parameter operates
    by setting a probability threshold for token selection. Tokens are chosen based
    on their probability, adhering to the **Top-P** value, thus guiding the randomness
    in the response.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Top-P**：与**Top-K**类似，此参数通过设置标记选择的概率阈值来操作。标记的选择基于其概率，遵循**Top-P**值，从而引导响应中的随机性。'
- en: Understanding and carefully manipulating these parameters will help you tailor
    the model’s responses to suit your requirements. Experiment with different configurations
    to master the optimal utilization of generative models.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 理解并仔细操作这些参数将有助于您调整模型响应以满足您的需求。通过尝试不同的配置来掌握生成模型的最佳利用。
- en: 'The following screenshot shows some of the different GenAI Studio response
    parameters:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – GenAI Studio settings](img/B17792_12_3.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – GenAI Studio settings
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have familiarized ourselves with the basics of prompt design, let’s
    see how you can interact with the Vertex AI foundation models using similar prompts.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Using Vertex AI GenAI models through GenAI Studio
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s look at some examples of how you can use GenAI Studio to generate
    content. In this section, we will cover four use cases:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Generating text using free-form input
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating text using structured input
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating images
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating code samples
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example 1 – using GenAI Studio language models to generate text
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we will use a Vertex AI GenAI model to generate marketing
    content for a new device and play around with some of the output configurations:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the GCP console >> **Vertex AI** >> **Generative AI Studio** >>
    **Language** >> **Text Prompt**.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the **Token limit** value to 256.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following or copy-paste (from the e-book) the following text into
    the **Prompt** field:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Click **Submit** to generate a response.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The response would look something like this:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, let’s set the **Token limit** parameter to 50 and click **Submit** again.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The new response generated by the model will now be much smaller since we reduced
    the output token limit to 50:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: So, we saw how a text generation model can be instructed to generate text content
    (marketing content in this case) and how its output size can be limited.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Example 2 – submitting examples along with the text prompt in structured format
    to get generated output in a specific format
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we will try to get the model to provide very concise answers
    to our questions:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the GCP console >> **Vertex AI** >> **Generative AI Studio** >>
    **Language** >> **Text Prompt** >> **STRUCTURED**, as shown next:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.4 – GenAI Studio structured input](img/B17792_12_4.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – GenAI Studio structured input
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: The structured format shown in the preceding screenshot allows us to submit
    a few examples as input-output pairs to show the model the desired output format
    or style. In this example, we want the model to provide concise answers, preferably
    in key-value format.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'Type the following text in the **Test** | **INPUT** section and click **Submit**:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Figure 12.5 – GenAI Studio: Model response](img/B17792_12_5.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.5 – GenAI Studio: Model response'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: You can see that the model’s response, although correct, is not a concise answer.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So now, let’s add some examples as part of the input prompt so that the model
    can see the output format/style we are expecting.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the **Examples** | **INPUT** section, add this:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the **Examples** | **OUTPUT** section, add the following text:'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Click **Submit**:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.6 – GenAI Studio: Response with structured input](img/B17792_12_6.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.6 – GenAI Studio: Response with structured input'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in the previous screenshot, the answer is now a lot more concise
    and matches the format submitted as an example with the prompt:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Although in this simple example, we just submitted a single example, for more
    complex use cases, you can submit a long list of examples to help the model better
    understand your output requirements.
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Example 3 – generating images using GenAI Studio (Vision)
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we will use a text-to-image model to generate images based
    on a text description of the image entered by us:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the GCP console >> **Vertex AI** >> **Generative AI Studio** >>
    **Vision** >> **Generate**.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the **Prompt** field at the bottom of the screen, type the following text
    and click **Submit**:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In the sidebar, select the **Digital Art** style and click **Submit**.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The image model generates the following images based on the prompt we provided:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.7 –  GenAI Studio: Generated images](img/B17792_12_7.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.7 – GenAI Studio: Generated images'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, change the style to **Photography** and click **Submit** again:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.8 – GenAI Studio: Generated images with style set to Photography](img/B17792_12_8.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.8 – GenAI Studio: Generated images with style set to Photography'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: You can see in the previous screenshot that the model is now generating images
    that are a lot more photo-realistic.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can play around with the prompt to see how you can control the generated
    images.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Example 4 – generating code samples
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we will use a Vertex AI code generation model (`codey`/`code_bison`)
    to generate a Python function:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the GCP console >> **Vertex AI** >> **Generative AI Studio** >>
    **Language** >> **Code Prompt**.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following text in the **Prompt** field:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The response should be similar to the generated code shown next:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Although in the preceding example, we used a code generation model to create
    a very simple code sample, you can modify the prompt to add more details about
    your requirements and generate significantly more complex code. Most code generation
    models available today can’t fully replace developers, even for relatively simple
    coding tasks, but they do help accelerate the coding workflow and work as great
    assistants to coders.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Building and deploying GenAI applications with Vertex AI
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let’s see how you can use Vertex AI GenAI features programmatically and
    integrate them with your apps.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Use case 1 – using GenAI models to extract key entities from scanned documents
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will use a publicly available patent document from the US Patents and Trademark
    Office as a sample document and extract the following information from the document:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: Inventor name
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Location of the inventor
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Patent number
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the notebook at [https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter12/Chapter12_Vertex_GenAI_Entity_Extraction.ipynb](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter12/Chapter12_Vertex_GenAI_Entity_Extraction.ipynb)
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 参考笔记本[https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter12/Chapter12_Vertex_GenAI_Entity_Extraction.ipynb](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter12/Chapter12_Vertex_GenAI_Entity_Extraction.ipynb)
- en: 'In this notebook, you will perform the following steps to extract the required
    information:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个笔记本中，你将执行以下步骤以提取所需信息：
- en: Extract the text from the document by using the Document AI **Optical Character
    Recognition** (**OCR**) tool.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Document AI **光学字符识别**（**OCR**）工具从文档中提取文本。
- en: Feed the text to the GenAI model (`text-bison`) along with a detailed prompt
    about the entities we need to extract from the text.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文本输入到GenAI模型（`text-bison`）中，并附带一个关于我们需要从文本中提取的实体的详细提示。
- en: Parse the response received from the model to feed it into the data warehouse
    (BigQuery).
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解析从模型接收到的响应，将其输入到数据仓库（BigQuery）中。
- en: If we use a traditional approach of training a **deep learning** (**DL**) model
    to extract this information from a scanned document, we will need a much larger
    set of annotated data and resources to train the model. With a pre-trained LLM,
    we are able to do the same task much faster, without needing any training dataset
    and without training a new model. Additionally, if later we want to extract any
    additional entities from the document, all we will need to do is modify our prompt
    to the model to include that new entity. With a non-LLM model, you will have to
    spend time annotating additional data samples and retraining the model to include
    that new label.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用传统的训练**深度学习**（**DL**）模型从扫描的文档中提取这些信息的方法，我们将需要更大的一组标注数据资源来训练模型。使用预训练的LLM，我们能够更快地完成相同的任务，无需任何训练数据集，也无需训练新模型。此外，如果我们后来想从文档中提取任何其他实体，我们只需修改模型提示以包括该新实体即可。使用非LLM模型，你将不得不花费时间标注额外的数据样本并重新训练模型以包括该新标签。
- en: Limitations of standard entity extraction approach discussed above
  id: totrans-282
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 讨论上述标准实体提取方法的局限性
- en: For our use case and document sample, this approach worked well because we were
    able to fit all the text into our LLM model’s context window (the maximum size
    of text input a model can use). But in the real world, we often run into scenarios
    where the amount of information/text we need to consider is much larger, and it
    can’t be sent to the model as part of a single prompt. For example, if you have
    a question about a story spread across a 500-page book, to get the most accurate
    answer, you need to feed all 500 pages worth of text to the LLM along with your
    question. But as of now, even the largest of the available language models can’t
    ingest that much text as an input prompt. So, in such scenarios, we use an alternative
    technique called **Retrieval Augmented Generation** (**RAG**), which we cover
    in use case 2 next.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的用例和文档样本，这种方法效果良好，因为我们能够将所有文本放入我们的LLM模型上下文窗口（模型可以使用的最大文本输入大小）。但在现实世界中，我们经常遇到需要考虑的信息/文本量远大于此的情况，并且不能作为单个提示的一部分发送给模型。例如，如果你对一个跨越500页书籍的故事有疑问，为了得到最准确的答案，你需要将所有500页的文本以及你的问题一起输入到LLM中。但截至目前，即使是可用的最大的语言模型也无法将如此多的文本作为输入提示。因此，在这种情况下，我们使用一种称为**检索增强生成**（**RAG**）的替代技术，我们将在下一个用例中介绍。
- en: Use case 2 – implementing a QA solution based on the RAG methodology using Vertex
    AI
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例2 – 使用Vertex AI实现基于RAG方法的QA解决方案
- en: The solution will also be grounded in our document corpus to mitigate hallucinations.
    Before we jump into the exercise, let’s first understand what the RAG framework
    is.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 该解决方案也将基于我们的文档语料库以减轻幻觉。在我们开始练习之前，让我们首先了解RAG框架是什么。
- en: What is RAG?
  id: totrans-286
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 什么是RAG？
- en: 'RAG is a methodology used in NLP that enhances the capabilities of language
    models by combining them with a retrieval mechanism. It’s designed to improve
    the performance of language generation models, particularly in providing more
    accurate and contextually relevant responses. Here’s a brief overview of how RAG
    works:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: RAG是一种在NLP中使用的方 法，通过结合检索机制来增强语言模型的能力。它旨在提高语言生成模型的性能，特别是在提供更准确和上下文相关的响应方面。以下是RAG工作原理的简要概述：
- en: '**Retrieval mechanism**: The first step involves retrieving relevant documents,
    passages, or text snippets from a large corpus of text. This is typically done
    using a vector retrieval system. The input query (or question) is encoded into
    a vector representation, and this vector is then used to search through a database
    of pre-encoded documents or passages to find the most relevant ones. This retrieval
    is based on the similarity of the vector representations.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索机制**：第一步涉及从大量文本语料库中检索相关文档、段落或文本片段。这通常是通过使用向量检索系统来完成的。输入查询（或问题）被编码成向量表示，然后使用这个向量在预先编码的文档或段落数据库中搜索，以找到最相关的文档。这种检索基于向量表示的相似性。'
- en: '**Augmentation**: The augmentation component of RAG combines the retrieved
    documents or passages with the initial prompt to create an augmented prompt. This
    augmented prompt provides the generative model with more context and information
    to work with, which can help to improve the quality of the generated text.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强**：RAG的增强组件将检索到的文档或段落与初始提示结合，以创建增强提示。这个增强提示为生成模型提供了更多的上下文和信息来工作，这有助于提高生成文本的质量。'
- en: '**Answer generation**: With the context from the retrieved documents, an LLM
    is used to generate a response. This model takes both the original query and the
    retrieved documents as input, allowing it to generate responses that are informed
    by the external knowledge contained in the retrieved texts.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**答案生成**：在检索到的文档的上下文中，使用一个LLM（大型语言模型）来生成响应。此模型将原始查询和检索到的文档作为输入，允许它生成由检索文本中包含的外部知识所启发的响应。'
- en: '![Figure 12.9 – Retrieval augmented generation (RAG) approach](img/B17792_12_9.jpg)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![图12.9 – 检索增强生成（RAG）方法](img/B17792_12_9.jpg)'
- en: Figure 12.9 – Retrieval augmented generation (RAG) approach
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 – 检索增强生成（RAG）方法
- en: 'The RAG system offers several significant advantages:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: RAG系统提供了几个显著的优势：
- en: '**Enhanced accuracy and relevance**: By integrating information retrieval with
    language generation, RAG systems can provide responses that are more accurate
    and relevant to the user’s query. This is particularly beneficial for questions
    that require specific, factual information.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强准确性和相关性**：通过将信息检索与语言生成相结合，RAG系统可以提供更准确、更符合用户查询的响应。这对于需要特定、事实性信息的查询尤其有益。'
- en: '**Access to up-to-date information**: Traditional language models are limited
    by the information they were trained on, which can become outdated. Constantly
    retraining these models with newer information is not viable due to the time it
    takes to train such models and the amount of compute resources required to train
    and retrain such models. RAG overcomes this by retrieving relevant information
    from up-to-date documents, ensuring that the responses include the most current
    data available.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**获取最新信息**：传统的语言模型受限于它们训练时所使用的信息，这些信息可能会过时。由于训练这些模型所需的时间和计算资源，不断用新信息重新训练这些模型并不可行。RAG通过从最新的文档中检索相关信息来克服这一点，确保响应包括最当前的数据。'
- en: '**Improved handling of niche queries**: RAG is adept at handling queries about
    niche or less common topics. Since it can pull information from a wide range of
    sources, it’s not as limited by the training data’s scope as traditional models.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**改进的窄查询处理**：RAG擅长处理关于窄或不太常见主题的查询。由于它可以从广泛的来源获取信息，因此它不像传统模型那样受限于训练数据的范围。'
- en: '**Scalability and flexibility**: RAG systems can be adapted to different domains
    and types of queries by modifying the retrieval component. This makes them scalable
    and flexible for various applications.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性和灵活性**：通过修改检索组件，RAG系统可以适应不同的领域和类型的查询。这使得它们对于各种应用都是可扩展和灵活的。'
- en: '**Contextual understanding**: The integration of external information allows
    RAG to understand and respond to queries in a more contextually nuanced way, leading
    to more sophisticated and nuanced conversations.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文理解**：外部信息的集成使得RAG能够以更细致的上下文方式理解和响应查询，从而产生更复杂和细致的对话。'
- en: '**Cost-effectiveness in training**: Since RAG systems can augment their responses
    with external information, they might require less extensive (and expensive) training
    datasets compared to traditional models that need to learn everything from the
    training data alone.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练成本效益**：由于RAG系统可以通过外部信息增强其响应，因此它们可能需要比仅从训练数据中学习一切的传统模型更少（且更昂贵）的训练数据集。'
- en: These advantages make RAG a powerful tool in the development of advanced AI
    systems, especially in areas where accuracy, recency, and depth of knowledge are
    crucial.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s get started with the hands-on exercise. In this exercise notebook,
    we will ingest a large PDF file containing **Alphabet’s** quarterly 10K filing
    containing key financial information shared by the company every quarter and then
    use Vertex AI GenAI tools to create a Q&A system we can use to ask questions about
    Alphabet’s earnings.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: 'Below are the steps we will perform:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Ingest the PDF and extract the text.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Break up extracted text into smaller text snippets or chunks so that they can
    later be matched to the questions being asked to find the relevant information.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the Vertex AI text embedding model to convert these snippets into embeddings/vectors.
    Think of this step as creating individual fingerprints for each text snippet so
    that later on, we can try to find the closest matches to the text of the question
    we want to answer.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a vector “datastore” that stores the embeddings created from text snippets
    in step 2.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the provided question into an embedding and then try to find the closest
    20 matches in the vector datastore.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an input prompt for our LLM (Vertex AI text-bison model) by combining
    the question text along with the text of the 20 close matches found in step 5.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feed the prompt to the LLM (Vertex AI text-bison model) to get a final answer
    that can be presented back to the user.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The [*Chapter 12*](B17792_12.xhtml#_idTextAnchor173) *– Vertex GenAI_RAG* notebook
    walks you through the steps described previously. ([https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter12/Chapter12_Vertex_GenAI_RAG.ipynb](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter12/Chapter12_Vertex_GenAI_RAG.ipynb))
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Since the focus of this chapter is on GenAI, we didn’t dive too deep into the
    domain of vector databases and matching algorithms used to find matching embeddings.
    The preceding exercise notebook uses a simple approach to calculate cosine similarity
    scores to find the closest matching vectors from a database within a pandas DataFrame.
    This works fine for small-scale data, but for real-world solutions requiring storage
    of billions of embeddings and matching latency of under 5ms, we suggest you use
    managed vector databases such as Vertex AI Vector Search (previously known as
    Matching Engine) or open source options such as the **pgvector extension** for
    PostgreSQL.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at how you can customize pre-trained language models in Vertex
    AI.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing GenAI performance with model tuning in Vertex AI
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Foundation pre-trained models, despite their great out-of-the-box performance
    across a variety of generic tasks, sometimes fall short for specialized tasks,
    and prompt tuning alone cannot adequately address the performance gap. To bridge
    this gap, model tuning on Vertex AI can significantly enhance a model’s task-specific
    performance and ensure adherence to specific output requirements when standard
    instructions are inadequate. This section will provide insight into model tuning
    on Vertex AI.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基础预训练模型在各种通用任务上表现出色，但有时在特定任务上表现不足，仅通过提示调优无法充分解决性能差距。为了弥合这一差距，Vertex AI 上的模型调优可以显著提高模型在特定任务上的性能，并确保在标准指令不足时遵守特定的输出要求。本节将介绍
    Vertex AI 上的模型调优。
- en: 'Several compelling reasons exist for tuning LLMs:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 存在几个令人信服的理由来调优 LLM：
- en: '**Improved performance**: Tuning can significantly improve the accuracy, fluency,
    and relevance of LLM outputs for a particular task'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**改进性能**：调优可以显著提高 LLM 输出在特定任务中的准确性、流畅性和相关性'
- en: '**Domain adaptation**: Tuning enables the specialization of LLMs for specific
    domains or types of data, ensuring that generated outputs are consistent with
    the domain’s terminology and style'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域自适应**：调优使 LLM 能够针对特定领域或数据类型进行专业化，确保生成的输出与领域的术语和风格一致'
- en: '**Bias mitigation**: Tuning can help alleviate biases inherent in pre-trained
    LLMs, promoting fairer and more equitable outcomes'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏差缓解**：调优可以帮助缓解预训练 LLM 中固有的偏差，促进更公平和更均衡的结果'
- en: Model tuning involves training the model with a dataset that extensively covers
    a unique task. This approach is particularly effective for niche tasks, as tuning
    with even a small sample dataset can lead to notable performance improvements.
    Post-tuning, the model requires fewer examples in its prompts to perform effectively.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 模型调优涉及使用广泛覆盖独特任务的数据库训练模型。这种方法对于利基任务尤其有效，因为即使使用小型样本数据库进行调优也能带来显著的性能提升。调优后，模型在提示中需要更少的示例才能有效地执行。
- en: 'Various approaches can be employed to customize LLMs for different purposes:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 可以采用各种方法来定制 LLM 以满足不同的目的：
- en: '**Prompt engineering** is a less computationally expensive approach to tuning
    LLMs. This involves crafting input prompts that guide the LLM toward generating
    desired outputs. Prompt engineering can be effective for a wide range of tasks,
    but it can be more difficult to master than fine-tuning.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示工程**是一种计算成本较低的调优 LLM 的方法。这涉及到创建输入提示，以引导 LLM 生成所需的输出。提示工程对于各种任务都可能是有效的，但它可能比微调更难掌握。'
- en: '**Fine-tuning** is the most common approach to tuning LLMs. This involves supervised
    training of LLMs on a task-specific dataset of labeled examples, which updates
    weights across all layers of the model. Fine-tuning can be very effective, but
    it can also be computationally expensive and time-consuming due to the size of
    typical LLMs nowadays.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调**是调优 LLM 最常见的方法。这涉及到在特定任务的标记示例数据集上对 LLM 进行监督训练，更新模型所有层的权重。微调可能非常有效，但由于当今典型
    LLM 的大小，它也可能计算成本高昂且耗时。'
- en: '**Parameter-efficient fine-tuning** (**PEFT**) is a technique that can be used
    to fine-tune LLMs with limited computational resources. PEFT, although similar
    to the aforementioned fine-tuning method, works by only tuning the parameters
    of certain layers in the underlying LLM while the rest of the layers remain frozen,
    thereby significantly reducing the number of parameters that need to be updated
    during training. This significantly reduces the number of required computations
    and reduces the overall cost of training.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参数高效微调**（**PEFT**）是一种可以用来使用有限的计算资源微调 LLM 的技术。尽管 PEFT 与上述微调方法类似，但它通过仅调整底层
    LLM 中某些层的参数，而其余层保持冻结，从而显著减少训练过程中需要更新的参数数量。这显著减少了所需的计算量，并降低了整体训练成本。'
- en: '**Reinforcement learning** (**RL**) can also be used to tune LLMs. This involves
    training the LLM to generate outputs that maximize a specific reward signal. RL
    can be effective for tasks that are difficult to define with labeled examples.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**（**RL**）也可以用来调优 LLM。这涉及到训练 LLM 生成最大化特定奖励信号的输出。RL 对于难以用标记示例定义的任务可能有效。'
- en: Let’s now look at how you can use Vertex AI for tuning foundation models.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用 Vertex AI 进行基础模型的调优。
- en: Using Vertex AI supervised tuning
  id: totrans-327
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Vertex AI 监督调优
- en: Vertex AI currently offers a PEFT-supervised tuning feature to tune LLMs. It
    is suitable for tasks such as classification, **sentiment analysis** (**SA**),
    entity extraction, simple content summarization, and domain-specific queries.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to the [*Chapter 12*](B17792_12.xhtml#_idTextAnchor173) *– LLM – Supervised
    Training* notebook in the accompanying GitHub repository for a hands-on end-to-end
    exercise to running an LLM tuning job in Vertex AI. Here are the key steps you
    need to follow to run a supervised tuning job:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '`input_text`: This field includes the prompt for the model'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`output_text`: This field should contain the model’s anticipated response post-tuning'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Example:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Sample dataset you can use: `input_text` field can have a maximum token length
    of 8,192 (approx. 32k English characters), and the `output_text` field can have
    a maximum token length of 1,024 (approx. 4k English characters).'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: Upload the dataset to a Google Cloud Storage bucket.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a supervised tuning job (*detailed steps are in the* *accompanying notebook*).
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following arguments are to be provided when starting a tuning job:'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here’s the Python code to kick off the tuning job:'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Load the tuned model from **Vertex AI Model Registry** to run prediction or
    evaluation jobs (*detailed steps are in the* *accompanying notebook*)
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: At the time of publication, the maximum number of samples you can use for a
    fine-tuning job is limited to 10,000.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us look at Vertex AI’s native capabilities that help ensure that the
    output of LLMs is safe and compliant for an enterprise setting.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: Safety filters for generated content
  id: totrans-346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite being extremely useful for a wide array of use cases, LLMs’ ability
    to absorb human knowledge and behavior (good and bad) through the immense datasets
    gathered from the public also creates the risk of these models being exploited
    or generating harmful content. It is not uncommon for these models to generate
    outputs that are unanticipated, encompassing offensive, insensitive, or incorrect
    content.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: It remains imperative for developers to have a profound understanding and meticulously
    test the models prior to deployment to circumvent any potential pitfalls. To help
    developers in this endeavor, GenAI Studio incorporates built-in content filtration
    systems, and the PaLM API offers safety attribute scoring, aiding clients to examine
    Google’s safety filters and establish confidence thresholds aligned with their
    individual use case and business requirements.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a full list of safety attributes offered as part of Google PaLM models:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '| **Safety Attribute** | **Description** |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
- en: '| Derogatory | Negative or harmful comments targeting identity and/or protected
    attributes. |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
- en: '| Toxic | Content that is rude, disrespectful, or profane. |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
- en: '| Sexual | Contains references to sexual acts or other lewd content. |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
- en: '| Violent | Describes scenarios depicting violence against an individual or
    a group, or general descriptions of gore. |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
- en: '| Insult | Insulting, inflammatory, or negative comment toward a person or
    a group of people. |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
- en: '| Profanity | Obscene or vulgar language such as cursing. |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
- en: '| Death, Harm, and Tragedy | Human deaths, tragedies, accidents, disasters,
    and self-harm. |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
- en: '| Firearms and Weapons | Content that mentions knives, guns, personal weapons,
    and accessories such as ammunition, holsters, etc. |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
- en: '| Public Safety | Services and organizations that provide relief and ensure
    public safety. |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
- en: '| Health | Human health, including: health conditions, diseases, and disorders,
    medical therapies, medication, vaccination, and medical practices resources for
    healing, including support groups. |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
- en: '| Religion and Belief | Belief systems that deal with the possibility of supernatural
    laws and beings; religion, faith, belief, spiritual practice, churches, and places
    of worship. Includes astrology and the occult. |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
- en: '| Illicit Drugs | Recreational and illicit drugs; drug paraphernalia and cultivation,
    headshops, etc. Includes medicinal use of drugs typically used recreationally
    (e.g. marijuana). |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
- en: '| War and Conflict | War, military conflicts, and major physical conflicts
    involving large numbers of people. Includes discussion of military services, even
    if not directly related to a war or conflict. |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
- en: '| Finance | Consumer and business financial services, such as banking, loans,
    credit, investing, insurance, etc. |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
- en: '| Politics | Political news and media; discussions of social, governmental,
    and public policy. |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
- en: '| Legal | Law-related content, including law firms, legal information, primary
    legal materials, paralegal services, legal publications and technology, expert
    witnesses, litigation consultants, and other legal service providers. |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
- en: Table 12.1 – PaLM models’ safety attributes
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: 'When you submit an API request to PaLM models, the response from the API includes
    confidence scores for each safety attribute, as shown next:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The scores in the preceding response are the risk values for each of the risk
    categories.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: Developers can then program the required safety thresholds in their applications
    to remove any harmful content returned by the API. For example, for an application
    geared toward a younger audience, developers might set stringent filters to eliminate
    any text that is above the score of 0.1 on any of the safety attributes. But if
    the requirement is to create content to be shared on forums where adults discuss
    video games and in-game weapons, then developers might relax the filters around
    the *Firearms and Weapons* safety attribute.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: Please keep in mind, right now, PaLM models do apply some initial safety filters
    before sending a response back to the customer. These filters can’t be completely
    switched off at the moment.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vertex AI GenAI is a powerful suite of tools that can be used to create a wide
    variety of GenAI applications. With its easy-to-use interface and extensive library
    of pre-trained models, Vertex AI GenAI makes it possible for developers of all
    skill levels to get started with GenAI quickly and easily.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: We hope that now, after reading this chapter, you possess foundational and practical
    knowledge about GenAI and its implementation using Vertex AI. With the skills
    to interact with and leverage foundation models, comprehension of basic prompt
    engineering, and an understanding of safety features native to Google’s GenAI
    models, you are now well-equipped to embark on practical endeavors and explore
    innovative applications using GenAI.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, [*Chapter 13*](B17792_13.xhtml#_idTextAnchor194), *Document
    AI – An End-to-End Solution for Processing Documents*, we will go over how you
    can use Google Cloud’s Document AI solution to extract information from scanned
    documents and structure it into a format that can be ingested by your data storage
    solutions.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-379
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Vertex AI* – *Responsible* *AI*: [https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai#safety_attribute_descriptions](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai#safety_attribute_descriptions)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
