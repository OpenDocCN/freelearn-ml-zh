<html><head></head><body>
			<h1 id="_idParaDest-102" class="chapter-number"><a id="_idTextAnchor102"/>9</h1>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor103"/>Building an MSA with Docker Containers</h1>
			<p>In the previous chapter, we discussed how to apply the DevOps process of building and running MSA systems, and the importance of aligning the organizational structure <span class="No-Break">with DevOps.</span></p>
			<p>We also highlighted the importance of embracing automation and adapting agile development methodologies throughout the MSA project life cycle, and throughout the <span class="No-Break">CI/CD operations.</span></p>
			<p>This chapter will cover what a <strong class="bold">container</strong> is, how to install containers, how to work with them, and how to handle the data flow between containers to build a simple project. We will use <strong class="bold">Docker</strong> as our platform since it is one of the most popular and widely used platforms in the <span class="No-Break">field today.</span></p>
			<p>The following topics will be covered in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>What are containers anyway, and why <span class="No-Break">use them?</span></li>
				<li><span class="No-Break">Installing Docker</span></li>
				<li>Creating <span class="No-Break">ABC-MSA containers</span></li>
				<li>ABC-MSA <span class="No-Break">microservices inter-communication</span></li>
			</ul>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor104"/>What are containers anyway, and why use them?</h1>
			<p>A container is defined as an<a id="_idIndexMarker467"/> operating system-level virtualization artifact, created by grouping different finite compute resources into a self-contained <span class="No-Break">execution environment.</span></p>
			<p>As shown in the following figure of a container ship, containers are self-contained units, independent from any other container in the ship. The ship is the engine that is used to carry and <span class="No-Break">transport containers:</span></p>
			<div>
				<div id="_idContainer170" class="IMG---Figure">
					<img src="image/B18934_09_1.jpg" alt="Figure 9.1: A container ship"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1: A container ship</p>
			<p>Similarly, the idea <a id="_idIndexMarker468"/>with containers is to create operating system-level virtualization. This means that, from within the kernel, you group different physical machine resources, applications, and I/O functions into a self-contained execution environment. Each of these self-contained resources forms a single container, hence the name container. The <strong class="bold">Container Engine</strong> is similar to the <a id="_idIndexMarker469"/>ship in the preceding example, where the container engine is used to carry, run, and transport <span class="No-Break">the containers.</span></p>
			<p>Containers have existed for a long<a id="_idIndexMarker470"/> time and can be traced back to Unix’s <strong class="bold">chroot</strong> in the late 1970s and early 1980s, and before we even came to learn about what we call today a <strong class="bold">hypervisor</strong>. A hypervisor is a <a id="_idIndexMarker471"/>component that enables us to spin up <strong class="bold">virtual </strong><span class="No-Break"><strong class="bold">machines</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">VMs</strong></span><span class="No-Break">).</span></p>
			<p>Unix’s chroot evolved later in the 1990s to Linux containers or what we call <strong class="bold">LXC</strong>, and then to <strong class="bold">Solaris Zones</strong> in the early 2000s. These concepts started to evolve with time from <strong class="bold">cgroups</strong> (originally developed by Google) and <strong class="bold">namespaces</strong> (developed by IBM) in to the container engines we see today, such as Docker, <strong class="bold">Rkt</strong>, <strong class="bold">CRI-O</strong>, <strong class="bold">Containers</strong>, Microsoft <strong class="bold">Hyper-V</strong> Containers, <span class="No-Break">and more.</span></p>
			<p>Although there are similarities between containers and VMs, both still have a few <span class="No-Break">fundamental differences.</span></p>
			<p>As shown in the following <a id="_idIndexMarker472"/>diagram, containers share the same kernel of the host operating system but isolate and limit the allocated resources, giving us something that feels like a VM but that’s much more lightweight in terms <span class="No-Break">of resources:</span></p>
			<div>
				<div id="_idContainer171" class="IMG---Figure">
					<img src="image/B18934_09_2.jpg" alt="Figure 9.2: VMs versus containers"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2: VMs versus containers</p>
			<p>In hypervisor virtualization, each VM will have to have its own virtual hardware and its own guest operating system. In addition to all that, there is a great deal of emulation taking place in the hypervisor. Accordingly, each VM needs much more resources compared to what a container needs. Resources include CPU cycles, memory, storage, and more. Moreover, you are likely to have duplicates of the same guest OS deployed on multiple VMs for the VM to deliver the required function, thus even more overhead and waste <span class="No-Break">of resources.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.2</em> shows the hypervisor deployed on top of a host OS. A more common hypervisor virtualization <a id="_idIndexMarker473"/>model, however, is deploying the bare-metal hypervisor on the hardware directly. In either case, the overhead is are still significantly higher than <span class="No-Break">deploying containers.</span></p>
			<p>The lightweight nature of containers enables companies to run many more virtualized environments in the data center compared to VMs. Since containers share resources much more efficiently than VMs, and with finite physical resources in data centers, containers largely increase the capacity of the data center infrastructure, which means containers become a better choice in hosting applications, especially in our case <span class="No-Break">of MSA.</span></p>
			<p>Container <a id="_idIndexMarker474"/>performance is another thing to look at. With containers, I/O virtual drivers’ communication, hardware emulation, and resources overhead are minimal, completely contrary to the case in the hypervisor virtualization environment. Accordingly, containers generally outperform VMs. Containers boot in 1-3 seconds compared to minutes in the case <span class="No-Break">of VMs.</span></p>
			<p>Applications running on a container can directly interact with and access the hardware. In the case of hypervisor virtualization, there is always a hypervisor between the application and the VM (unless a hypervisor bypass is enabled, which has its <span class="No-Break">own limitations).</span></p>
			<p>With containers, you can package the application with all of its dependencies in a contained environment that’s reusable and completely portable to any other platform. That’s one of the most important features of containers. Developers can develop an application on their development servers, ship it to the testing environment, then staging and production, and run the application without having to worry about portability and <span class="No-Break">dependency issues.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">For all the aforementioned reasons, the most popular deployment model of microservices is the container-per-service model. This is where each microservice of the MSA is deployed on a single container dedicated to running that <span class="No-Break">particular application.</span></p>
			<p>The other important difference between containers and VMs is security. Since containers use the same kernel, multiple containers may very well access the same kernel subsystem outside the boundaries of the container. This means a container could gain access to other containers running on the same physical host. A single application with root access, for example, could access any other <span class="No-Break">container data.</span></p>
			<p>There are many ways to harden the security of containers, but none of these techniques would help containers match the VM’s total <span class="No-Break">isolation security.</span></p>
			<p>There are cases, of<a id="_idIndexMarker475"/> course, where using VMs would be a better option than using containers. Or in some scenarios, a mix of both VMs and containers would be the most appropriate deployment model. It all depends on the use case, the application, or the system you are deploying in <span class="No-Break">your organization.</span></p>
			<p>In a multi-tenant environment, where complete workload isolation is necessary, using VMs would be a better choice. Or, if you are trying to build an R&amp;D environment for hosting critical intellectual capital, or highly confidential data or applications, a complete workload isolation will also be necessary. Therefore, in this case, using VMs would be the <span class="No-Break">better option.</span></p>
			<p>For our MSA example, we need a very lightweight, fast-starting, highly portable, and high-performing virtualization environment to build our MSA system. Hence, containers, with a container-per-microservice deployment model, are the better choice in our scenario. Each of the MSA system’s microservices would be deployed in its own container and would have its own development team, development cycle, QA cycle, updates, run life cycle, and <span class="No-Break">release cycle.</span></p>
			<p>The following table summarizes the differences between containers and <span class="No-Break">hypervisor virtualization:</span></p>
			<table id="table001-3" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Containers</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Hypervisor VM’s</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Resource Usage <span class="No-Break">and Overhead</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Lightweight, Please overhead, and more efficient use <span class="No-Break">of resources</span></p>
						</td>
						<td class="No-Table-Style">
							<p>High overhead <span class="No-Break">and resource-intensive</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Container and <span class="No-Break">Application Size</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Averages <span class="No-Break">5-20 MB</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Measured in 100s of MB <span class="No-Break">or GB</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Performance</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">High performance</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Lower performance</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Scalability</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Easy to scale out/high <span class="No-Break">horizontal scaling</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scaling out is harder and <span class="No-Break">consumes resources</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Bootup Time</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Very short startup time (<span class="No-Break">1-3 seconds)</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Startup time is <span class="No-Break">in minutes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Portability</span></p>
						</td>
						<td class="No-Table-Style">
							<p>System-agnostic and <span class="No-Break">highly portable</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Portability <span class="No-Break">is limited</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>DevOps and <span class="No-Break">CI/CD Suitability</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Enables more agile DevOps and <span class="No-Break">smoother CI/CD</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Could slow down <span class="No-Break">CI/CD operations</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Host <span class="No-Break">Hardware Access</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Applications access <span class="No-Break">HW directly</span></p>
						</td>
						<td class="No-Table-Style">
							<p>No direct access <span class="No-Break">to HW</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Security</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Less secure; shares the <span class="No-Break">same kernel</span></p>
						</td>
						<td class="No-Table-Style">
							<p>More secure; each VM has its own <span class="No-Break">OS kernel</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 9.1: Differences between containers and Hypervisor VMs</p>
			<p>Despite the many options<a id="_idIndexMarker476"/> we currently have in choosing a container engine, Docker is by far the most popular engine used today, to the extent that Docker today is synonymous with containers. That’s the main reason why we have chosen to work with Docker as our container’s engine in <span class="No-Break">this book.</span></p>
			<p>Docker is also ideal for agile DevOps and CI/CD operations. In a CI/CD environment, the time between building a Docker image to the time it is up and running in the production environment is usually around 1-5 minutes <span class="No-Break">in total:</span></p>
			<div>
				<div id="_idContainer172" class="IMG---Figure">
					<img src="image/B18934_09_3.jpg" alt="Figure 9.3: Docker Engine container virtualization"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3: Docker Engine container virtualization</p>
			<p><span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.3</em> shows Docker Engine installed on the host operating system to enable the containerization of microservices or applications <span class="No-Break">in general.</span></p>
			<p>Docker in itself may<a id="_idIndexMarker477"/> not be sufficient to manage all the CI/CD operations. Organizations usually complement Docker by using a clustering technology such<a id="_idIndexMarker478"/> as <strong class="bold">Kubernetes</strong> or <strong class="bold">Marathon</strong> to smoothly <a id="_idIndexMarker479"/>deploy, manage, and operate the containers within the cluster in which your system is running. However, in this book, we will focus on Docker itself and how to use Docker to build our <span class="No-Break">MSA system.</span></p>
			<p>Also, to move, test, and deploy containers, we will need to have a repository to save these containers and be able to move them to different environments. Many tools can help with <a id="_idIndexMarker480"/>that, with <strong class="bold">Docker Hub</strong> and <strong class="bold">GitHub</strong> being two <a id="_idIndexMarker481"/>of the most commonly used repositories. For our project, we will use GitHub as our <span class="No-Break">project repository.</span></p>
			<p>So far, we have covered what containers are, the difference between containers and VMs, and why we prefer to use containers in MSA. In the next section, we will explain the different components of Docker, how to install Docker, and how to work with Docker’s components to create a <span class="No-Break">system’s microservices.</span></p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor105"/>Installing Docker</h1>
			<p>We will start this section by<a id="_idIndexMarker482"/> talking about Docker installation. Then, we will cover the main components of Docker, the purpose of each component, and how these components relate to each other. This section will help us prepare the environment that we will use later for our ABC-MSA <span class="No-Break">demo project.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">To maximize your hands-on learning experience, you need to follow all of our hands-on installation steps. But before doing so, please make sure you have a physical or virtual host available for the Docker installation demo before we dive deeper into this section. A virtual host can be created using virtualization software such as VirtualBox <span class="No-Break">or VMWare.</span></p>
			<p>Although you can install Docker on Windows or Mac, in our demo, we will use an Ubuntu Server 22.x Linux<a id="_idIndexMarker483"/> environment to install Docker <strong class="bold">Community Edition</strong> (<strong class="bold">CE</strong>). We suggest you use a similar environment to be able to follow our <span class="No-Break">installation steps.</span></p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor106"/>Docker Engine installation</h2>
			<p>Now that we know the<a id="_idIndexMarker484"/> main components of Docker, let’s take a step back and learn how to install Docker and create different Docker images for the <span class="No-Break">ABC-MSA system.</span></p>
			<p>The best way to install Docker Engine is to follow Docker’s <a id="_idIndexMarker485"/>official installation guide from Docker Docs at <a href="https://docs.docker.com/engine/install/">https://docs.docker.com/engine/install/</a>. Pick your server system platform installation guide from <span class="No-Break">the list.</span></p>
			<p>You may also want to install Docker Desktop on your workstation. Docker Desktop is available for download from the same installation guide referred <span class="No-Break">to previously.</span></p>
			<p>After the installation is completed, verify Docker’s functionality by running the <span class="No-Break">following command:</span></p>
			<pre class="console">$ docker --version
Docker version 20.10.18, build b40c2f6
$</pre>
			<p><span class="No-Break">And,</span></p>
			<pre class="console">$ docker run hello-world
Hello from Docker!
This message shows that your installation appears to be working correctly.
:
:</pre>
			<p>You may need root <a id="_idIndexMarker486"/>privileges to issue the Docker <span class="No-Break">commands successfully.</span></p>
			<p>Now that we have installed Docker, let’s go over the main components of Docker and how to <span class="No-Break">use each.</span></p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor107"/>Docker components</h2>
			<p>There are four main<a id="_idIndexMarker487"/> components of Docker: the Docker file, the Docker image, the Docker container, and the Docker volume. The following is a brief description of each of <span class="No-Break">these components.</span></p>
			<h3>The Docker file</h3>
			<p>The Docker file is a text file that works as a manifest that describes how the Docker image should be built. The <a id="_idIndexMarker488"/>Docker file specifies the base image that will be used to create the Docker image. So, for example, if you were to use the latest Ubuntu version as your base Linux image for the container, you would have the following line specified at the top of your <span class="No-Break">Docker file:</span></p>
			<pre class="source-code">FROM ubuntu</pre>
			<p>Notice that <strong class="source-inline">ubuntu</strong> is not tagged with any version number, which will instruct Docker to pull the latest version available for that base image. If you prefer to use CentOS version 7.0, for example, you must then tag the base image with the version number, as shown in the <span class="No-Break">following line:</span></p>
			<pre class="source-code">FROM centos:7</pre>
			<p>The specific image tag can be found on Docker Hub. Docker Hub is a public repository that stores many free Docker official images for reuse by Docker users. Among many others, base images could be Linux, Windows, Node.js, Redis, Postgres, or other relational <span class="No-Break">DB images.</span></p>
			<p>After you specify the <a id="_idIndexMarker489"/>base operating system image, you can use the <strong class="source-inline">RUN</strong> command to run the commands that you would like to execute during the Docker image creation. These are regular shell commands that are usually issued to download and install packages and libraries that will be used in your <span class="No-Break">Docker image.</span></p>
			<p>The Docker file has to be named <strong class="source-inline">Dockerfile</strong> for Docker to be able to use it. The following is a simple <span class="No-Break">Dockerfile example:</span></p>
			<div>
				<div id="_idContainer173" class="IMG---Figure">
					<img src="image/B18934_09_4.jpg" alt="Figure 9.4: A Docker file (Dockerfile) example"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4: A Docker file (Dockerfile) example</p>
			<p>The preceding sample Dockerfile does <span class="No-Break">the following:</span></p>
			<ol>
				<li>Uses Ubuntu version 22.10 as the base image to run on the container that will be <span class="No-Break">created later.</span></li>
				<li>Fetches the latest <span class="No-Break">packages list.</span></li>
				<li>Installs Python version 3 and the PIP Python package <span class="No-Break">management system.</span></li>
				<li>Installs a package called Ansible (Ansible is an <span class="No-Break">automation tool).</span></li>
			</ol>
			<h3>The Docker image</h3>
			<p>Once you have finished <a id="_idIndexMarker490"/>composing your Dockerfile, you will need to save it as a <strong class="source-inline">Dockerfile</strong> to be able to use it to create the <span class="No-Break">Docker image.</span></p>
			<p>A Docker image is a binary file that works as a template with a set of instructions on how a Docker<a id="_idIndexMarker491"/> container should <span class="No-Break">be created.</span></p>
			<p>Please note that a Docker image can either be created from the Dockerfile, as we are explaining here, or downloaded from a public or private repository such as Docker Hub <span class="No-Break">or GitHub.</span></p>
			<p>To build a Docker image, use the following command while pointing at the <strong class="source-inline">Dockerfile</strong> location. The following example assumes the Dockerfile is located in the user’s <span class="No-Break">home directory:</span></p>
			<pre class="console">$ docker build –t packt_demo_image ~/</pre>
			<p>The preceding command will build an image called <strong class="source-inline">packt_demo_image</strong>. This image will be used later to create the container with the specs defined in <span class="No-Break">the Dockerfile.</span></p>
			<p>The <strong class="source-inline">-t</strong> option means <strong class="source-inline">tty</strong>, which attaches a terminal to <span class="No-Break">the container.</span></p>
			<p>To verify that your image has been created, use the <span class="No-Break">following command:</span></p>
			<pre class="console">$ docker image ls</pre>
			<p>You can add the <strong class="source-inline">-a</strong> option to the end of the proceeding command to show all images created on the <span class="No-Break">host machine.</span></p>
			<p>In CI/CD operations, the images that are built are usually shared in a public or private repository so that they’re available to the project team, or even the public in <span class="No-Break">some cases.</span></p>
			<h3>The Docker container</h3>
			<p>The last step is to run a <a id="_idIndexMarker492"/>container based on the Docker image you <a id="_idIndexMarker493"/>created (or pulled from the image repository). To run a container, use the <span class="No-Break">following command:</span></p>
			<pre class="console">$ docker run packt_demo_image</pre>
			<p>To verify that the container is running, use the <span class="No-Break">following command:</span></p>
			<pre class="console">$ docker container ls</pre>
			<p>The preceding command will show only the running containers. To show other containers on the host machine, add the <strong class="source-inline">-a</strong> option to the end of <span class="No-Break">the command.</span></p>
			<p>You can also use<a id="_idIndexMarker494"/> the older version of the preceding command to verify that the container <span class="No-Break">is running:</span></p>
			<pre class="console">$ docker ps</pre>
			<p>The following diagram shows the relationship between all four Docker components and summarizes the<a id="_idIndexMarker495"/> entire process of running a container. First, we create a Dockerfile. Then, we use that file to create the Docker image. The Docker image can then be used to create the Docker container(s) locally, or first uploaded to a private or public repository where others can download and create their <span class="No-Break">Docker container(s):</span></p>
			<div>
				<div id="_idContainer174" class="IMG---Figure">
					<img src="image/B18934_09_5.jpg" alt="Figure 9.5: Docker components"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5: Docker components</p>
			<p>Docker containers have a life cycle of their own – they can run for a specific task with no regard for what their previous state is, and once that specific task is completed, the Docker container <span class="No-Break">automatically terminates.</span></p>
			<p>In other cases, containers <a id="_idIndexMarker496"/>need to be aware of their previous status. If so, they <a id="_idIndexMarker497"/>will need to be persistent to preserve the container data after its termination. That’s when Docker volumes become very handy. Next, we will talk about what a Docker volume is and how it can <span class="No-Break">be created.</span></p>
			<h3>The Docker volume</h3>
			<p>Docker volumes are a form of<a id="_idIndexMarker498"/> storage that a Docker container can be attached to. Containers are attached to volumes to read and write persistent data, which are necessary for the function of <span class="No-Break">the container.</span></p>
			<p>To elaborate more, consider the Docker container for the Customer Management microservice (<strong class="source-inline">customer_management</strong>). If you need to create a new customer in the <strong class="source-inline">customer_management</strong> container, you will need to update the local data store installed in that container. If the container is not persistent, once the container terminates, all data created or changed inside that container will <span class="No-Break">be lost.</span></p>
			<p>To avoid this problem, we will need to create a Docker volume and attach the container to that volume. The container itself can then run and update whatever data it needs to update in its volume, and then terminate. When it starts the next time, it gets instantiated with all the previous statuses and data it had before the <span class="No-Break">last termination.</span></p>
			<p>To create a Docker <a id="_idIndexMarker499"/>volume for the <strong class="source-inline">customer_management</strong> container, for example, use the <span class="No-Break">following command:</span></p>
			<pre class="console">$ docker volume create customer_management_volume</pre>
			<p>The following command will list all volumes created on our host machine and verify the volume we have <span class="No-Break">just created:</span></p>
			<pre class="console">$ docker volume ls</pre>
			<p>Once we create the volume, Docker mounts a local drive space on the host machine to preserve the container’s data and its <span class="No-Break">mounted filesystem.</span></p>
			<p>To show more details about the volume, including the volume’s name, the local host and the container’s target mount locations, and the date and time of the volume’s creation, use the <strong class="source-inline">docker volume inspect</strong> or <strong class="source-inline">docker inspect</strong> command, <span class="No-Break">as follows:</span></p>
			<pre class="console">$ docker volume inspect customer_management_volume
[
    {
        "CreatedAt": "2022-10-14T22:24:46Z",
        "Driver": "local",
        "Labels": {},
        "Mountpoint": "/var/lib/docker/volumes/customer_management_volume/_data",
        "Name": "customer_management_volume",
        "Options": {},
        "Scope": "local"
    }
]</pre>
			<p>Assuming we have previously created the <strong class="source-inline">packt_demo_image</strong> image, to create the persistent <strong class="source-inline">customer_management</strong> container, we will need to attach the container to the volume we have just created <a id="_idIndexMarker500"/>using the mount points shown in the <strong class="source-inline">docker volume inspect</strong> command’s output. The following command will create the <a id="_idIndexMarker501"/>container, attach the volume to the container, and then run <span class="No-Break">the container:</span></p>
			<pre class="console">$ docker run -itd --mount source=customer_management_volume,target=/app_data --name customer_management_container packt_demo_image</pre>
			<p>The <strong class="source-inline">it</strong> option in the <strong class="source-inline">docker run</strong> command is for interactive <strong class="source-inline">tty</strong> mode, and the <strong class="source-inline">d</strong> option is for running the container in <span class="No-Break">the background.</span></p>
			<p><strong class="source-inline">/app_data</strong> is an absolute path within the container that’s mounted to the local host’s mount point. From the preceding inspect data shown, the <strong class="source-inline">/var/lib/docker/volumes/customer_management_volume/_data</strong> mount point is mapped to <strong class="source-inline">/app_data</strong> in <span class="No-Break">the container.</span></p>
			<p>To verify that the container is running, use the <span class="No-Break">following command:</span></p>
			<pre class="console">$ docker container ls</pre>
			<p>If the container<a id="_idIndexMarker502"/> terminates for whatever reason, use the <strong class="source-inline">-a</strong> option at the end of the preceding command to show the available container on the host. You can use the <strong class="source-inline">docker container start</strong> or <strong class="source-inline">docker container stop</strong> command, followed by the container’s name, to run or terminate any of the available containers you built on <span class="No-Break">that host.</span></p>
			<p>Now that we have<a id="_idIndexMarker503"/> installed Docker Engine and understand the different components of Docker, we will go over how to create the main ABC-MSA containers as microservices and provide an example of how these microservices talk to <span class="No-Break">each other.</span></p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor108"/>Creating ABC-MSA containers</h1>
			<p>In our ABC-MSA system, we are adopting a container-per-microservice approach. Therefore, we need to<a id="_idIndexMarker504"/> identify the main containers we will build, the components we need for each container in our ABC-MSA system, and then build the necessary Dockerfile(s) <span class="No-Break">to use.</span></p>
			<p>We are building our microservice applications <a id="_idIndexMarker505"/>using <strong class="bold">Flask</strong>. Flask is a <strong class="bold">Web Server Gateway Interface</strong> (<strong class="bold">WSGI</strong>) micro-framework that <a id="_idIndexMarker506"/>enables applications to respond to API calls in a simple, flexible, and scalable manner. We won’t discuss our applications’ code in this book, but the code is available on our GitHub with detailed documentation for <span class="No-Break">your reference.</span></p>
			<p>In this section, we will explain how we build our ABC-MSA Dockerfile(s), images, and microservices, how we will start to listen to API calls in each container, and how the system’s microservices will be able to communicate with <span class="No-Break">each other.</span></p>
			<p>For demo purposes, we will use port HTTP/8080 in the container to listen to HTTP API requests. The production environment should use HTTPS/443 and consider the <strong class="source-inline">tomcat</strong> server for handling all <span class="No-Break">web connections.</span></p>
			<p>The following is only part of the full system container setup. All the ABC-MSA system’s created files and Docker images <a id="_idIndexMarker507"/>can be found in our GitHub repository <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Machine-Learning-in-Microservices"><span class="No-Break">https://github.com/PacktPublishing/Machine-Learning-in-Microservices</span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor109"/>ABC-MSA containers</h2>
			<p>The following<a id="_idIndexMarker508"/> are the services we have previously identified for our <span class="No-Break">ABC-MSA system:</span></p>
			<ol>
				<li value="1"><span class="No-Break">API Gateway</span></li>
				<li>A frontend web <span class="No-Break">dashboard interface</span></li>
				<li><span class="No-Break">Customer Management</span></li>
				<li><span class="No-Break">Product Management</span></li>
				<li><span class="No-Break">Order Management</span></li>
				<li><span class="No-Break">Inventory Management</span></li>
				<li><span class="No-Break">Courier Management</span></li>
				<li><span class="No-Break">Shipping Management</span></li>
				<li><span class="No-Break">Payment Authorization</span></li>
				<li><span class="No-Break">Notification Management</span></li>
				<li>Aggregator: “Product <span class="No-Break">Ordered Qty”</span></li>
				<li>Management <span class="No-Break">and Orchestration</span></li>
			</ol>
			<p>We can code and build each of these services from scratch, but the good news is that we don’t have to. Docker Hub offers a rich library with many Docker images that we can leverage in building our microservices. Docker <a id="_idIndexMarker509"/>Hub can be accessed <span class="No-Break">at </span><a href="https://hub.docker.com/"><span class="No-Break">https://hub.docker.com/</span></a><span class="No-Break">.</span></p>
			<p>We will not go over each of these services. Instead, we will focus on the ones that provide different development and deployment approaches. Some of the services are already available through Docker Hub, and some others are similar, so one example of these will suffice. Nevertheless, all the project files will be made available in this book’s <span class="No-Break">GitHub repository.</span></p>
			<h3>API Gateway</h3>
			<p>Many open source and commercial <a id="_idIndexMarker510"/>API gateways can be pulled from different internet repositories, including Tyk, API Umbrella, WSO2, Apiman, Kong, and Fusio, to name a few. We will use Tyk in our ABC-MSA system since it is easy to use, has comprehensive features including authentication and service discovery, and is 100% an open source product with no <span class="No-Break">feature restrictions.</span></p>
			<p>To install a Tyk Docker container, just <a id="_idIndexMarker511"/>follow the instructions <span class="No-Break">at </span><a href="https://tyk.io/docs/tyk-oss/ce-docker/"><span class="No-Break">https://tyk.io/docs/tyk-oss/ce-docker/</span></a><span class="No-Break">.</span></p>
			<p>By default, the Tyk API gateway listens to TCP port <strong class="source-inline">8080</strong>. To verify your installation, issue an API call test to Tyk using the <strong class="source-inline">curl</strong> command, <span class="No-Break">as follows:</span></p>
			<pre class="console">$ curl localhost:8080/hello
{"status":"pass","version":"4.1.0","description":"Tyk GW"}</pre>
			<p>If Tyk has been successfully installed and is running on your host, you should get a dictionary output stating Tyk’s status and the current version, as shown in the preceding <span class="No-Break">command output.</span></p>
			<p>You can also verify that the Tyk Docker image and container were created successfully using the <span class="No-Break">following commands:</span></p>
			<pre class="console">$ docker images
REPOSITORY                              TAG            IMAGE ID       CREATED         SIZE
redis                                   6.2.7-alpine   48822f443672   3 days ago      25.5MB
docker.tyk.io/tyk-gateway/tyk-gateway   v4.1.0         0c21a95236de   8 weeks ago     341MB
hello-world                             latest         feb5d9fea6a5   12 months ago   13.3kB
$
$ docker container ls
CONTAINER ID   IMAGE                                          COMMAND                   CREATED          STATUS          PORTS                                        NAMES
ac3ac1802647   docker.tyk.io/tyk-gateway/tyk-gateway:v4.1.0    "/opt/tyk-gateway/ty…"   54 minutes ago   Up 54 minutes    0.0.0.0:8080-&gt;8080/tcp, :::8080-&gt;8080/tcp   tyk-gateway-docker_tyk-gateway_1
9e0f1ecfb148   redis:6.2.7-alpine                             "docker-entrypoint.s…"   54 minutes ago   Up 54 minutes   0.0.0.0:6379-&gt;6379/tcp, :::6379-&gt;6379/tcp   tyk-gateway-docker_tyk-redis_1</pre>
			<p>We can see the <strong class="source-inline">tyk</strong> image details in the preceding command output, as well as the running container and what port it is listening to. We can also see a Redis image and container. This is<a id="_idIndexMarker512"/> because Redis is a prerequisite for Tyk and is included in the Tyk <span class="No-Break">installation package.</span></p>
			<h3>The Customer Management microservice as an example</h3>
			<p>The Customer <a id="_idIndexMarker513"/>Management, Product Management, Order Management, Inventory Management, Courier Management, Shipping Management, Payment Authorization, and Notification Management microservices are all similar in terms of how we can build and deploy the container. In this section, we will learn how to create an image that we can use to create a system microservice. We have picked the Customer Management microservice as <span class="No-Break">an example.</span></p>
			<p>As mentioned earlier, for these microservices to communicate with the API gateway or any other components in the ABC-MSA system, we need to have Flask installed and running, listening to port HTTP/8080 in the <span class="No-Break">running container.</span></p>
			<p>We also need an internal data store for our application to use and manage. And since our code will be written in Python, we need to have Python installed as well. All these required components, along with some essential dependency packages, need to be specified in <span class="No-Break">our Dockerfile.</span></p>
			<p>Now, we need to write the Dockerfile required for creating the microservice image that we will use to create the microservice container. Each ABC-MSA container should have its own development cycle and be deployed either using the CI/CD cycle we discussed in <a href="B18934_08.xhtml#_idTextAnchor086"><span class="No-Break"><em class="italic">Chapter 8</em></span></a> or uploaded manually to the <span class="No-Break">team repository.</span></p>
			<p>The following is an example of<a id="_idIndexMarker514"/> the Dockerfile that’s required for creating the Customer <span class="No-Break">Management image:</span></p>
			<pre class="console"># Docker File for "customer_management" microservice
FROM ubuntu
# Install some dependencies/packages
RUN apt-get install -y apt-transport-https
RUN apt-get update
RUN apt-get install -y net-tools mysql-server python3 pip git build-essential curl wget vim software-properties-common;
# Install OpenJDK
RUN apt-get update &amp;&amp; \
    apt-get install -y default-jdk
ENV JAVA_HOME /usr/lib/jvm/java-11-openjdk-amd64/
# Install Flask to run our application and respond to API calls
RUN pip install -U flask
# Expose port TCP/8080 to listen the container's application/flask API calls
EXPOSE 8080
# Create the /app_data directory and make it the working directory in the container
RUN mkdir /app_data
WORKDIR /app_data
ENV PATH $PATH:/app_data
# Download the microservice app code from GitHub repo
ENV GIT_DISCOVERY_ACROSS_FILESYSTEM 1
RUN git config --global init.defaultBranch main
RUN git init
RUN git remote add origin https://github.com/mohameosam/abc_msa.git
RUN git config core.sparseCheckout true
RUN echo "/microservices/customer_management/" &gt; /app_data/.git/info/sparse-checkout
RUN git pull origin main
# Initialize the flask app
ENV FLASK_APP /app_data/microservices/customer_management/customer_management_ms.py
# Specify a mount point in the container
VOLUME /app_data
# Start mysql &amp; flask services and available bash sheel
RUN chmod +x /app_data/microservices/customer_management/start_services
CMD /app_data/microservices/customer_management/start_services &amp;&amp; bash</pre>
			<p>The aforementioned Dockerfile specifies what the Customer Management Docker image should look like. The<a id="_idIndexMarker515"/> following are some insights into what each of the lines in the file <span class="No-Break">will do:</span></p>
			<ol>
				<li value="1">Specify Ubuntu as the Linux operating system that will be used in the Customer <span class="No-Break">Management container.</span></li>
				<li>Install some <span class="No-Break">required packages:</span><ul><li>MySQL (required for <span class="No-Break">our application)</span></li>
<li>Python (required for <span class="No-Break">our application)</span></li>
<li>pip (required to be able to <span class="No-Break">install Flask)</span></li>
<li>The rest are some other tools needed for <span class="No-Break">troubleshooting (optional)</span></li>
</ul></li>
				<li>Install Flask (required for <span class="No-Break">our application).</span></li>
				<li>Expose TCP/HTTP port <strong class="source-inline">8080</strong> for Flask to listen to <span class="No-Break">API calls.</span></li>
				<li>Create a working directory in the container to act as the mount point for saving the <span class="No-Break">container’s data.</span></li>
				<li>Download the Customer Management application code from our <span class="No-Break">GitHub repository.</span></li>
				<li>Set an environment variable to let Flask know what application it will use when responding to <span class="No-Break">API calls.</span></li>
				<li>Use our downloaded <strong class="source-inline">start_services</strong> shell script to start Flask and MySQL in <span class="No-Break">the container.</span></li>
			</ol>
			<p>The <strong class="source-inline">start_services</strong> shell script contains the <span class="No-Break">following commands:</span></p>
			<pre class="console">flask run -h 0.0.0.0 -p 8080 &amp;
usermod -d /var/lib/mysql/ mysql
service mysql start</pre>
			<p>The first line enables Flask to listen to port <strong class="source-inline">8080</strong> on all the host network interfaces. This is OK in the development and testing environment. In the production environment, however, Flask should only be available on the localhost <strong class="source-inline">127.0.0.1</strong> network interface to limit API access to the local environment. Also, for better security, port HTTPS/443 should be used in API <span class="No-Break">calls instead.</span></p>
			<p>Assuming the Dockerfile <a id="_idIndexMarker516"/>has been placed in the current user home directory, we now need to create our Customer Management microservice/container from <span class="No-Break">the Dockerfile:</span></p>
			<pre class="console">$ docker build -t abc_msa_customer_management ~/</pre>
			<p>Docker will take a few minutes to finish creating the image. Once all the Dockerfile steps have been completed, you should see the following command as the last line of the <strong class="source-inline">docker build</strong> <span class="No-Break">command’s output:</span></p>
			<pre class="console">Successfully tagged abc_msa_customer_management:latest</pre>
			<p>This signals a successful completion. Now, we can use the <strong class="source-inline">docker image ls</strong> command to verify that the <strong class="source-inline">abc_msa_customer_management</strong> image has been <span class="No-Break">created successfully.</span></p>
			<p>The last step is creating the container. Since the application will configure and update the MySQL database, we need to create a persistent container to retain all <span class="No-Break">the changes.</span></p>
			<p>Similar to what we explained earlier, we will use the <strong class="source-inline">docker run</strong> command to create the Customer Management container, <span class="No-Break">as follows:</span></p>
			<pre class="console">$ docker run -itd -p 8003:8080 --mount source=customer_management_volume,target=/app_data --name customer_management_container abc_msa_customer_management</pre>
			<p>The <strong class="source-inline">p</strong> option is used to “publish” and map the ports that the container listens to with the ports the host machine listens to. So, the host machine will be listening to port <strong class="source-inline">8003</strong> for HTTP/8080 requests on <span class="No-Break">the container.</span></p>
			<p>We have chosen 8003 to standardize the way the host listens to the container’s API <span class="No-Break">call requests.</span></p>
			<p>Remember that each container has a TCP stack that is different from the host’s TCP stack. So, the TCP HTTP/8080 port is only local within the container itself, but outside that particular container’s environment, that TCP HTTP/8080 port is different from the TCP HTTP/8080 port available on any other container or on the host <span class="No-Break">machine itself.</span></p>
			<p>To access that port from outside the realm of the <strong class="source-inline">customer_management</strong> container, you need to map the <strong class="source-inline">customer_management</strong> container’s TCP HTTP/8080 port to a specific port on the <span class="No-Break">host machine.</span></p>
			<p>Since we need to map<a id="_idIndexMarker517"/> the local TCP HTTP/8080 port of each of the 12 containers we identified earlier, we decided to follow a specific pattern. Map the TCP/80nn port on the host machine to each local TCP HTTP/8080 of each container. Here, nn is the <span class="No-Break">container’s number.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.6</em> shows how some of the ABC-MSA container’s TCP HTTP/8080 ports are mapped on the <span class="No-Break">host machine.</span></p>
			<p>We don’t have to run all the containers on a single host. The system containers could be scattered across different hosts, depending on many factors, such as how critical the service/application running on the container is, how the system is designed, the desired overall redundancy, and <span class="No-Break">so on:</span></p>
			<div>
				<div id="_idContainer175" class="IMG---Figure">
					<img src="image/B18934_09_6.jpg" alt=" Figure 9.6: The container’s local port mappings to the host machine’s TCP stack"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 9.6: The container’s local port mappings to the host machine’s TCP stack</p>
			<p>Now, verify that the container is running using the <span class="No-Break">following command:</span></p>
			<pre class="console">$ docker container ls</pre>
			<p>The following <a id="_idIndexMarker518"/>command will allow you to connect to the container’s <strong class="source-inline">bash</strong> shell using the root privilege (a user ID of <strong class="source-inline">0</strong>, as specified in <span class="No-Break">the command):</span></p>
			<pre class="console">$ docker exec -u 0 -it customer_management_container bash</pre>
			<p>That’s all for the Customer Management microservice. In the same manner, we can create the rest of the ABC-MSA containers. We just need to make sure we use appropriate corresponding <a id="_idIndexMarker519"/>names for the other microservice’s containers and volumes and map to the right TCP/80nn port number on the <span class="No-Break">host machine.</span></p>
			<h3>The frontend web dashboard interface</h3>
			<p>The dashboard is the <a id="_idIndexMarker520"/>main component of the <strong class="bold">user interface</strong> (<strong class="bold">UI</strong>) interaction and interacts with all services offered to the user. In our ABC-MSA example, we created a simple cart application where the user can place products in the cart and place <span class="No-Break">an order.</span></p>
			<p>The Dashboard container is built the same way the <strong class="source-inline">customer_management</strong> container is built, as shown in the previous section. The main difference between both is the additional web server that we will need to have on the Dashboard microservice, and the ports to be exposed on the container. The Dashboard’s Dockerfile should be <span class="No-Break">changed accordingly.</span></p>
			<p>Like all the containers we are building, the container’s local TCP port that listens to API calls is TCP HTTP/8080, and the host-mapped TCP port in the <strong class="source-inline">dashboard</strong> container case should <span class="No-Break">be TCP/8002.</span></p>
			<p>The Dashboard container will still need to listen to HTTP/80 for user web UI requests. Unless the host machine is running another application or web page on HTTP/80 port, we should be OK to use <span class="No-Break">that port.</span></p>
			<p>Now, we need to map the HTTP/80 port on the host machine, as shown in the following <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">run</strong></span><span class="No-Break"> command:</span></p>
			<pre class="console">$ docker run -itd -p 8002:8080 -p 80:80 \
--mount source=dashboard_volume,target=/app_data \
--name dashboard_container abc_msa_dashboard</pre>
			<p>This command has an additional <strong class="source-inline">p</strong> option to map the HTTP/80 port on the container with the HTTP/80 port on the host machine. <strong class="source-inline">abc_msa_dashboard</strong> is the Dashboard <span class="No-Break">microservice image.</span></p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor110"/>Managing your system’s containers</h2>
			<p>As you saw in the preceding examples, the <strong class="source-inline">docker run</strong> command can get lengthy and messy. <strong class="bold">Docker Compose</strong> helps us<a id="_idIndexMarker521"/> manage the deployment of containers. With Docker Compose, it is much<a id="_idIndexMarker522"/> easier to manage the deployment of the containers, change deployment parameters, include all system containers in a single YAML file, and specify the order of the containers’ deployment <span class="No-Break">and dependencies.</span></p>
			<p>The following is a sample YAML file for initializing three of the ABC-MSA containers, as we did with the <strong class="source-inline">docker run</strong> commands earlier, but in a more organized and structured <span class="No-Break">YAML way:</span></p>
			<pre class="source-code"># Docker Compose File abc_msa.yaml
version: "3.9"
services:
  customer_management_container:
    image: abc_msa_customer_management
    ports:
      - "8003:8080"
    volumes:
      - customer_management_volume:/app_data
  product_management_container:
    image: abc_msa_product_management
    ports:
      - "8004:8080"
    volumes:
      - product_management_volume:/app_data
  dashboard:
    image: abc_msa_dashboard
    ports:
      - "8002:8080"
      - "80:80"
    volumes:
      - dashboard_volume:/app_data
    depends_on:
      - customer_management_container
      - product_management_container
volumes:
  customer_management_volume:
  product_management_volume:
  dashboard_volume:</pre>
			<p>The following command runs the Docker Compose <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">yaml</strong></span><span class="No-Break"> file:</span></p>
			<pre class="console">$ docker-compose -f abc_msa.yaml up &amp;</pre>
			<p>The <strong class="source-inline">f</strong> option is used to <a id="_idIndexMarker523"/>specify the YAML file’s name, and the <strong class="source-inline">&amp;</strong> option is used to run the containers in the <span class="No-Break">shell’s background.</span></p>
			<p>In this section, we showed you how to create some of the ABC-MSA images and containers. The ABC-MSA containers are now ready to communicate with each other either directly or, as we will show later in this book, through the <span class="No-Break">API Gateway.</span></p>
			<p>In the next section, we will learn how we can use the containers we created, how we can issue API calls to them, and what response we <span class="No-Break">should expect.</span></p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor111"/>ABC-MSA microservice inter-communication</h1>
			<p>In this section, we <a id="_idIndexMarker524"/>will learn how to expose APIs from containers and how containers communicate with <span class="No-Break">API consumers.</span></p>
			<p>The microservice application code for each container is available in the ABC-MSA project on GitHub. We recommend that you download the code to your local test environment to be able to get some hands-on experience when following the steps we will cover in <span class="No-Break">this section.</span></p>
			<p>There are two main ways for containers to communicate with each other. One is by using the container’s<a id="_idIndexMarker525"/> name in a <strong class="bold">Docker network</strong>, and the other is by using the container’s IP and TCP port. The following are some of the details you need to know about to be able to configure your containers to communicate with <span class="No-Break">each other.</span></p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor112"/>The Docker network</h2>
			<p>When we have<a id="_idIndexMarker526"/> containers running on the same host, containers can communicate with each other on the same host using only <a id="_idIndexMarker527"/>container names and without the need to specify the container’s IP address or <span class="No-Break">listening port.</span></p>
			<p>The concept of using only container names is programmatically very useful, especially in cases where these IPs change dynamically. The names are usually deterministic, and by only specifying the Docker’s container name, you avoid having to apply different layers of system operations to first learn about the container’s TCP/IP details before starting to communicate with the <span class="No-Break">target container.</span></p>
			<p>However, there are some prerequisites to enabling container communication through their <span class="No-Break">names only:</span></p>
			<ul>
				<li>The containers communicating with each other will all need to be on the <span class="No-Break">same host</span></li>
				<li>We will need to create a Docker network on <span class="No-Break">the host</span></li>
				<li>We will need to attach the containers to the created Docker network when running the container using the <strong class="source-inline">docker run</strong> command or by specifying the container’s instantiation details in the <strong class="source-inline">docker-compose</strong> <span class="No-Break">YAML file</span></li>
			</ul>
			<p>The following command <a id="_idIndexMarker528"/>creates a Docker network on the host machine that can be used for our ABC-MSA system’s <span class="No-Break">inter-microservice communication:</span></p>
			<pre class="console">$ docker network create abc_msa_network</pre>
			<p>The following command lists the Docker networks configured on the <span class="No-Break">host machine:</span></p>
			<pre class="console">$ docker network ls</pre>
			<p>Now, attach the ABC-MSA containers to the <strong class="source-inline">abc_msa_network</strong> network by using the <strong class="source-inline">--network</strong> option in the <strong class="source-inline">docker run</strong> command, as shown in the <span class="No-Break">following example:</span></p>
			<pre class="console">$ docker run -itd -p 8003:8080 \
--network abc_msa_network --mount \
source=customer_management_volume,target=/app_data \
--name customer_management_container abc_msa_customer_management</pre>
			<p>Using Docker networks is <a id="_idIndexMarker529"/>very useful in many cases. However, since we are designing our ABC-MSA system so that containers can run independently of their host location, we will be using the container’s <span class="No-Break">IP/TCP communication.</span></p>
			<p>In the next section, we’ll explain how the ABC-MSA microservices communicate using TCP/IP and go over some examples of how to test the communication and <span class="No-Break">data exchanges.</span></p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor113"/>TCP/IP communication between containers/microservices</h2>
			<p>So far, we have installed <a id="_idIndexMarker530"/>Docker, built our Docker images and volumes, and started the containers of all our microservices. Now, it is time to understand how these containers interact with <span class="No-Break">each other.</span></p>
			<p>Upon running Docker on the container’s host, the host automatically creates a virtual IP network and assigns an IP address to each running Docker container on that host. That virtual IP network is only internal to the host running the containers and cannot be accessed from anywhere outside <span class="No-Break">that host.</span></p>
			<p>The container’s host carries at least two IPs. There’s one inside IP that’s internal to the Docker network and that can only be recognized inside that Docker network. Then, there’s an outside IP, which is usually <a id="_idIndexMarker531"/>assigned by the <strong class="bold">Dynamic Host Configuration Protocol</strong> (<strong class="bold">DHCP</strong>) server in the organization’s network. The outside IP is necessary for the container’s host to communicate with the <span class="No-Break">outside world.</span></p>
			<p>The internal Docker network of the container’s host is not visible to any other host in the network. Therefore, for an outside host to communicate with a specific container in the container’s host<a id="_idIndexMarker532"/> machine, it will need to use the outside IP of the container’s <span class="No-Break">host machine.</span></p>
			<p>Among a lot of other information, to get the assigned IP address, as well as the inside and outside listening ports of a specific container in your system, use the <strong class="source-inline">docker inspect</strong> command, followed by the <span class="No-Break">container’s name.</span></p>
			<p>Our demo setup is shown in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer176" class="IMG---Figure">
					<img src="image/B18934_09_7.jpg" alt=" Figure 9.7: ABC-MSA container communication"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 9.7: ABC-MSA container communication</p>
			<p>As you can see, the host machine’s inside IP address is 172.17.0.100, and the outside IP address is 192.168.1.100. The container’s host is listening to the container’s mapped ports (<strong class="source-inline">8001</strong> to <strong class="source-inline">8012</strong>), as <span class="No-Break">explained earlier.</span></p>
			<p>If other hosts in the network want to send API calls to one of the ABC-MSA containers, that outside<a id="_idIndexMarker533"/> host will need to send the request to the outside IP address of the container’s host, 192.168.1.100, using the mapped port of the container it wants to <span class="No-Break">communicate with.</span></p>
			<p>To elaborate further, the preceding diagram and the following example show an outside host testing the API response of the Product <span class="No-Break">Management container:</span></p>
			<pre class="source-code"><strong class="bold">$ curl http://192.168.1.100:8004/</strong>
&lt;!DOCTYPE html&gt;
&lt;head&gt;
   &lt;title&gt;PRODUCT MANAGEMENT Microservice&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
   &lt;h3&gt;Product Management Microservice Part of ABC-MSA System&lt;/h3&gt;
&lt;/body&gt;</pre>
			<p>ABC-MSA API calls return a JSON variable for easier data handling. One of the APIs we built for ABC-MSA microservices is <strong class="source-inline">service_info</strong>. An example of an API call for <strong class="source-inline">service_info</strong> is <span class="No-Break">as follows:</span></p>
			<pre class="console">$ curl http://192.168.1.100:8004/api?func=service_info
{"service_name": "product_management", "service_descr": "ABC-MSA Product Management"}</pre>
			<p>If you are communicating internally from within the Docker network (172.17.0.0), you can communicate directly with the container’s IP and listening ports. Performing the same <strong class="source-inline">curl</strong> test on the Product Management container from the API Gateway shell would look <span class="No-Break">like this:</span></p>
			<pre class="console">$ curl http://172.17.0.4:8080/api?func=service_info
{"service_name": "product_management", "service_descr": "ABC-MSA Product Management"}</pre>
			<p>Knowing how to pass <a id="_idIndexMarker534"/>API requests and handle the API response is key to developing your MSA system. Please refer to our ABC-MSA code in this book’s GitHub repository for examples of how the API calls are issued and handled across the <span class="No-Break">entire system.</span></p>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor114"/>Summary</h1>
			<p>In this chapter, we covered the concept of containers, what they are, and how they are different from VMs. Then, we worked with Docker as one of the most popular container platforms available today. We showed you how to install Docker and create Dockerfiles, Docker images, Docker volumes, and <span class="No-Break">Docker containers.</span></p>
			<p>Then, we applied all these concepts by building some of the ABC-MSA microservices with hands-on examples. We built the containers and showed how microservices communicate with <span class="No-Break">each other.</span></p>
			<p>In the next chapter, we will focus on building an AI microservice in the MSA system. We will discuss some of the most important AI/ML/DL algorithms that should be considered and implemented in an MSA system, and how these algorithms help with a system’s overall stability, performance, <span class="No-Break">and supportability.</span></p>
</body></html>