- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Personalized Product Recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the advancements in technology and the rising amount of data being collected,
    personalization is everywhere. From streaming services, such as Netflix and Hulu,
    to marketing messages and advertisements you see on your phones, most of the content
    shown to you is personalized nowadays. In marketing, personalized or targeted
    marketing campaigns have proven to work significantly better for driving customer
    engagements and conversions compared to generic or mass marketing campaigns.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to discuss building personalized recommendation
    models with which we can better target customers with the products that interest
    them the most. We will be examining how to conduct **market basket analysis**
    in Python, which helps marketers better understand which items are frequently
    bought together, how to build **collaborative filtering** algorithms in two approaches
    for personalized product recommendations, and what other approaches are taken
    for recommending products that are personalized to individual customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Product analytics with market basket analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-based versus item-based collaborative filtering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other frequently used recommendation methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Product analytics with market basket analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The classic example of **market basket analysis** is that researchers have
    found that customers who buy diapers tend to buy beer as well. Although beer and
    diapers seem too distant items to go together, this finding shows that there are
    hidden associations between different products that we can find from data. The
    goal of market basket analysis is to find these hidden relationships between products
    and efficiently arrange for or recommend the products to customers. Market basket
    analysis helps answer questions like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Which products should be recommended to customers who are buying product X?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What products should be close together in the store so that customers can easily
    find the products that they want to buy?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To answer these questions, association rules of the market basket analysis
    should be found. An association rule, simply put, shows how confidently or significantly
    an itemset occurs in a transaction using a rule-based machine learning approach.
    An association rule has two parts: the antecedent, which is the condition of a
    rule, and the consequent, which is the result of a rule. Consider the following
    statement:'
  prefs: []
  type: TYPE_NORMAL
- en: “Customers who buy diapers are likely to buy beer.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this statement, diapers are the antecedent and beer is the consequent. Five
    metrics are used to evaluate the strengths of these association rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support**: Support signals how frequently an itemset occurs in the dataset.
    The equation to calculate the support for an itemset (*X*, *Y*) is:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B30999_07_001.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, if there are 3 transactions of diapers in all 10 transactions in
    the data, the support of diapers is 3/10 or 0.3\. If there are 2 transactions
    of diapers and beer in all 10 transactions in the data, the support of diapers
    and beer is 2/10 or 0.2.
  prefs: []
  type: TYPE_NORMAL
- en: '**Confidence**: Confidence is a conditional probability of the itemset (*X*,
    *Y*) occurring given that the antecedent *X* has occurred. The equation to calculate
    the confidence for the consequent *Y* given the antecedent *X* is:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B30999_07_002.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, if there are 3 transactions of diapers and 2 transactions of diapers
    and beer in all 10 transactions, the confidence of buying beer given diapers is
    2/3 or 0.67\. The confidence value will be 1 if the consequent always occurs with
    the antecedent.
  prefs: []
  type: TYPE_NORMAL
- en: '**Lift**: Lift is a metric to measure how much more often the itemset (X, Y)
    occurs together than if the antecedent and consequent were independent events.
    The equation for the lift for the antecedent X and consequent Y is:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B30999_07_003.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, if the confidence of diapers and beer was 2/3 and the support of
    beer was 5/10, then the lift of diapers to beer would be 2/3 divided by 5/10,
    which is 20/15 or 4/3\. If the antecedent and the consequent are independent,
    the lift score will be 1.
  prefs: []
  type: TYPE_NORMAL
- en: '**Leverage**: Leverage is a metric used to measure the difference between the
    frequency of the antecedent and the consequent occurring together and the frequency
    of the antecedent and the consequent if they were independent. The equation for
    the leverage is:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B30999_07_004.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, if diapers and beer occurred in 4 transactions out of 10 total
    transactions and the support of diapers and beer were 0.6 and 0.5 respectively,
    then the leverage will be 0.4 – (0.6 * 0.5), which is 0.1\. Leverage values range
    between –1 and 1 and if the antecedent and the consequent were independent, the
    leverage value will be 0.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conviction**: Conviction measures how much the consequent depends on the
    antecedent. The equation for the conviction is:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B30999_07_005.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, if the confidence between diapers and beer is `0.67` and the support
    of beer is `0.2`, meaning there were 2 transactions of beer in 10 total transactions,
    the conviction would have been about `2.42`. If the antecedent and the consequent
    are independent, then the conviction will be 1\. On the other hand, if the confidence
    of the antecedent and consequent is 1 or if the consequent always occurs together
    with the antecedent, then the denominator becomes 0 and the conviction value becomes
    infinite.
  prefs: []
  type: TYPE_NORMAL
- en: With this foundation, let’s dive into finding the association rules within an
    e-commerce dataset. We will be using an online retail dataset and the `mlxtend`
    package to show how market basket analysis can be performed with Python.
  prefs: []
  type: TYPE_NORMAL
- en: '**Source code and data**: [https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.7](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.7
    )'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data source**: [https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.7/data.csv](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.7/data.csv
    )'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the link for the original data source: [https://archive.ics.uci.edu/dataset/352/online+retail](https://archive.ics.uci.edu/dataset/352/online+retail)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the command for installing the `mlxtend` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Apriori algorithm – finding frequent itemsets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Apriori algorithm is used to identify and generate the association rules
    that we discussed previously. We will discuss how to run the Apriori algorithm
    for market basket analysis in Python with an example. Let’s first load the data
    into a DataFrame using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Once we run this code, we now have all the purchases that the customers made.
    If you recall what we have discussed previously about the market basket analysis,
    the two key components are finding the itemsets and finding the rules among the
    itemsets. In this section, we are going to focus on finding the itemsets, which
    are the combinations of items.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you run the `df["StockCode"].nunique()` command, you will see that there
    are 3,684 unique items or products in this data. As you can imagine, the number
    of combinations of the items you can create grows exponentially with the number
    of items. The number of all possible combinations of items is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_006.png)'
  prefs: []
  type: TYPE_IMG
- en: With over 3,000 items in our dataset, it will be unrealistic to check all the
    possible itemsets, as there are 2^(3684)-1 itemsets to check. This is where the
    **Apriori** algorithm comes in. Intuitively, the items or itemsets with low transaction
    frequency or low support are going to have less value in the findings. Thus, the
    Apriori algorithm extracts the itemsets that are considered frequent enough by
    the predefined threshold of support.
  prefs: []
  type: TYPE_NORMAL
- en: 'To find the frequent itemsets using the Apriori algorithm, we need to convert
    the DataFrame in a way that it is a matrix where each row represents the customers
    and each column represents the items or products. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are using the `pivot_table` function to create a customer-to-item
    matrix and each value will be the total quantity of each item that each customer
    bought. With this customer-to-item matrix, we can run the Apriori algorithm to
    find the frequent itemsets using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are using the `apriori` function within the
    `mlxtend` package. We have defined the minimum support required for each itemset
    to be `0.03` with the `min_support` parameter, which means we are going to ignore
    those itemsets that occur in less than 3% of the transactions. Then, we add a
    column, `n_items`, which simply counts the number of items in each itemset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final DataFrame looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: The frequent_items DataFrame'
  prefs: []
  type: TYPE_NORMAL
- en: If you recall, the total number of possible combinations of itemsets was 2^(3684)-1\.
    However, as you can see from this result of applying the Apriori algorithm, we
    now have 1,956 items, which is a manageable and reasonable amount of itemsets
    that we can examine the association rules for.
  prefs: []
  type: TYPE_NORMAL
- en: Association rules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the frequent itemsets we have built, we can now generate the association
    rules that will tell us which itemsets are frequently bought together. Take a
    look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are using the `association_rules` function in the `mlxtend` package.
    There are a few key parameters to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: '`metric`: This parameter defines which metric to use for selecting the association
    rules. Here, we are using `confidence` to choose association rules with high confidence,
    but you can also use `lift` if you are interested in finding the rules with high
    lift.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_threshold`: This parameter defines the threshold for the selection of
    association rules based on the metric you have chosen. Here, we are only interested
    in finding the rules with confidence above the 60% threshold.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`support_only`: You can set this parameter to `True` if you are only interested
    in computing the support of the rules or if other metrics cannot be computed due
    to some data missing. Here, we set this to `False` as we are interested in finding
    the rules with high confidence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The output of these rules should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.2: Association rules based on confidence above 60%'
  prefs: []
  type: TYPE_NORMAL
- en: 'The association rule output contains antecedents, consequents, and key metrics,
    such as `support`, `confidence`, and `lift`. You can sort by each metric and generate
    insights on which itemsets have close relationships. For example, you may want
    to find the top 20 itemsets that have the highest lift or the top 10 itemsets
    that have the highest confidence. You can also visualize these relationships so
    that you can easily view the relationships and the strengths of the relationships.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we first select the top 20 rules with the highest lift by using the `sort_values`
    function. Then, we pivot the table so that each row is the antecedent, each column
    is the consequent, and the value of a cell is the lift. A heatmap can be used
    to visualize the strengths of these rules easily. The following code can be used
    to visualize these 20 rules with the highest lift:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate a heatmap that looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: The top 20 association rules with the highest lift'
  prefs: []
  type: TYPE_NORMAL
- en: In this chart, the lighter the color is, the higher the lift is for a given
    rule. For example, when the antecedent itemset is `GREEN REGENCY TEACUP AND SAUCER`,
    `REGENCY TEA PLATE ROSES` and the consequent itemset is `ROSES REGENCY TEACUP
    AND SAUCER`, `REGENCY TEA PLATE GREEN`, the lift is about 26 and the highest.
    On the other hand, when the antecedent itemset is `ROSES REGENCY TEACUP AND SAUCER`,
    `REGENCY TEA PLATE ROES` and the consequent itemset is `GREEN REGENCY TEACUP AND
    SAUCER`, `REGENCY TEA PLATE GREEN`, the lift is about 20 and the lowest among
    the top 20 rules.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from this example, with the association rules, we can easily
    find out which products are bought together and their relationships with one another.
    This can be used in personalized marketing, where certain products are recommended
    based on these rules. If a customer purchased itemset A, then naturally you can
    recommend itemset B, which has high confidence or lift as the association rule
    suggests that A and B are frequently bought together with significance. This is
    one step closer to recommending individualized product sets in marketing messages
    rather than blindly recommending random product sets in the hopes that customers
    express interest in purchasing them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, if you recall, lift has a linear relationship with confidence and an
    inverse relationship with support, as lift is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_007.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This relationship can be easily shown from the rules we have found with the
    `mlxtend` package. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have lift values on the y-axis and support and confidence values on
    the x-axis. The chart will look as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: The relationships between lift and confidence and between lift
    and support'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from this chart, the top x-axis shows the confidence values and
    the scatter plot of lift against confidence shows a linear relationship, where
    the lift values increase as the confidence values increase. On the other hand,
    the bottom x-axis shows the support values and the scatter plot of lift against
    support shows an inverse relationship, where the lift values decrease as the support
    values increase.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are various approaches in building recommendation systems and often multiple
    approaches take part. Some of the frequently used AI/ML-driven approaches in building
    recommendation systems are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Collaborative filtering**: This method uses previous user behaviors, such
    as pages they viewed, products they purchased, or ratings they have given previously.
    This algorithm leverages this kind of data to find similar products or content
    to those that the users have shown interest in previously. For example, if a user
    viewed a few thriller movies on a streaming platform, some other thriller movies
    may be recommended to this user. Or, if a customer bought dress shirts and dress
    shoes on an e-commerce platform, dress pants may be recommended to this customer.
    The collaborative filtering algorithms are often built based on the similarities
    between users or items:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-based** collaborative filtering uses data to find similar users based
    on the pages viewed or products purchased previously.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Item-based** collaborative filtering uses data to find items that are often
    bought or viewed together.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Content-based filtering**: As the name suggests, this method uses the characteristics
    of products, contents, or users. Where the collaborative filtering algorithm focuses
    on user-to-user or item-to-item similarities, the content-based filtering algorithm
    focuses on characteristic similarities, such as genres, keywords, and metadata.
    For example, if you are recommending movies to watch, this approach may look at
    the descriptions, genres, or actors of movies and recommend those that match a
    user’s preferences. On the other hand, if you are recommending fashion items,
    then this approach may look at the product categories, descriptions, and brands
    to recommend certain items to users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predictive modeling**: As discussed in *Chapter 6*, predictive models can
    be built for recommendation systems as well. Previous content that the users viewed,
    products that they have purchased, or web session history can be the features
    to identify the items that the users are highly likely to be interested in seeing
    or purchasing. The probability output of these predictive models can be used to
    rank the items so that more likely items are shown to the users before other less
    likely items.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid models**: Oftentimes, recommendation systems are built with all of
    the previously mentioned approaches. Blending different approaches for recommendations
    can help improve the recommendation accuracy that single-approach recommendation
    systems may miss.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we are going to focus on the *collaborative filtering* algorithm
    as it is a frequently used backbone of lots of recommender systems, and more specifically,
    how to build recommendation systems using user-based collaborative filtering and
    item-based collaborative filtering algorithms. This technique is frequently used
    in recommendation systems as it captures the interactions among the users and
    items very well in a very intuitive way. Lots of organizations where recommendations
    are critical in their businesses, such as Netflix, Amazon, and Spotify, use collaborative
    filtering algorithms as part of their recommendation systems.
  prefs: []
  type: TYPE_NORMAL
- en: The key to the collaborative filtering algorithms is to find similar users or
    items. There can be various metrics that can be used to measure the similarities
    between users or items, such as Euclidean distance, Manhattan distance, or Jaccard
    distance. However, cosine similarity is one of the most frequently used similarity
    metrics in collaborative filtering, as it focuses more on the directional similarity
    over the magnitude of the distance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cosine similarity** is simply the cosine of the angle between two vectors.
    Here, vectors can be user vectors or item vectors in our case of collaborative
    filtering algorithms. As cosine similarity has strength in high-dimensional space,
    it is often chosen as the distance metric for collaborative filtering algorithms.
    The equation for computing the cosine similarity between two vectors looks as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_008.png)'
  prefs: []
  type: TYPE_IMG
- en: In this equation,*V*[1][i] and *V*[2][i] represent each item in each vector,
    which can be a user vector or an item vector. These cosine similarity values range
    between -1 and 1\. If the 2 vectors are similar, the cosine similarity value will
    be close to 1; if the 2 vectors are independent, then the cosine similarity value
    will be 0; if the 2 vectors are the opposite vectors, then the cosine similarity
    value will be close to -1.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build collaborative filtering algorithms, we will first need to build the
    customer-to-item matrix. We will be using the same code that we have used for
    the market basket analysis, which looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As before, this matrix shows the quantities purchased for each item (column)
    by each customer (row). Instead of using the raw quantities of items purchased,
    we are going to one-hot encode so that the values are 1 if a given customer bought
    a given item or 0 if not, as in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `customer_item_matrix` matrix should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5: The customer-to-item matrix'
  prefs: []
  type: TYPE_NORMAL
- en: As expected, each row represents whether a given user bought each item or not.
    This matrix will be the foundational matrix that we will use to build user-based
    collaborative filtering and item-based collaborative filtering algorithms in the
    following sections.
  prefs: []
  type: TYPE_NORMAL
- en: User-based collaborative filtering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step to building a user-based collaborative filtering model is to
    build a matrix of similar users. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: If you recall, the cosine similarity measure is one of the most frequently used
    similarity metrics for collaborative filtering algorithms. Here, we are using
    the scikit-learn package’s `cosine_similarity` function to compute cosine similarities
    between users. The newly created variable, `user_user_sim_matrix`, will be a matrix
    where each row and column represents a user and the similarities between two users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B30999_07_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.6: A sample of user-to-user similarities'
  prefs: []
  type: TYPE_NORMAL
- en: This example shows the user-to-user cosine similarity metrics. As expected,
    the diagonal values are 1 since they represent the similarities between a user
    and itself. For example, users `12349` and `12350` have a cosine similarity of
    about `0.057` and users `12349` and `12352` have a cosine similarity of `0.138`.
    This suggests that user `12349` is more similar to user `12352` than to user `12350`.
    This way, you can identify and rank the users by how similar they are to a target
    user.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s pick one customer and see how we may be able to build a recommendation
    system. We will select the user with ID `14806` as an example for this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we select the top 10 users that have the highest cosine similarity measures,
    by selecting `TARGET_CUSTOMER` in the `user_user_sim_matrix` matrix and sorting
    the values in descending order. The output should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.7: Similar customers to the target customer'
  prefs: []
  type: TYPE_NORMAL
- en: Here, you can see that customer `13919` is the most similar to the target customer,
    `14806`, customer `12561` comes second, and customer `13711` follows in third.
  prefs: []
  type: TYPE_NORMAL
- en: Recommending by the most similar customer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The simplest approach to recommend products to the target customer is to see
    which items the target customer has bought already and compare them against the
    most similar customer, `13919`. Then, recommend the products that the target customer
    has not bought yet that the most similar customer has bought. This is based on
    the assumption, as discussed previously, that customers similar to each other
    are likely to behave similarly or share similar interests and they are likely
    to purchase similar products.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, we can follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first find out the items that the target customer has bought already,
    using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will get all the items that the target customer has bought and store them
    in the `items_bought_by_target` variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to get all the items the most similar customer, `13919`, has
    bought. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This finds out all the items that the most similar customer, `13919`, has bought
    and stores them in the `items_bought_by_sim` variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `set` operation, it is easy to find out the items that the most similar
    customer has bought but not bought by the target customer, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, we simply subtract the `items_bought_by_target` set from the
    other set, `items_bought_by_sim`. This will get all the items that the target
    customer has not yet bought but were bought by the most similar customer and store
    them in `items_bought_by_sim_but_not_by_target`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can get the details about these items using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This output should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.8: Items to recommend to the target customer'
  prefs: []
  type: TYPE_NORMAL
- en: This is the list of items that the most similar customer, `13919`, has bought
    but have not been bought by the target customer, and their descriptions. In the
    most simple approach to recommending products, this list can be shown to the target
    customer as the recommended items.
  prefs: []
  type: TYPE_NORMAL
- en: Since these two customers have shown similar interests by having bought similar
    items in the past, it is more likely for the target customer to purchase some
    of these items rather than a random selection of products. You can apply the same
    process for each customer and build sets of products to recommend based on the
    most similar customers’ historical purchases.
  prefs: []
  type: TYPE_NORMAL
- en: Recommending by the top products bought by similar customers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another approach is to rank the products by how frequently they were bought
    by the most similar customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can start with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we first get the top 10 most similar customers by the cosine similarity.
    Then, for each similar customer, we iterate through the items that were bought
    by the similar customer but not by the target customer. We count the number of
    times similar customers bought the given product, sort by the purchase frequency
    in the reverse order, and store it in the `potential_rec_items` variable. The
    result should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.9: Top products purchased by similar customers'
  prefs: []
  type: TYPE_NORMAL
- en: 'This suggests that 7 out of 10 customers have bought the `21500` and `21499`
    products, 4 out of 10 customers have bought the `21498` and `POST` products, and
    so forth. We can query to get the product descriptions from these product IDs
    using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This output should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.10: Top products purchased by similar customers'
  prefs: []
  type: TYPE_NORMAL
- en: This approach, however, does not account for how similar or dissimilar each
    customer was to the target customer. It just counted the number of top 10 similar
    customers for each product and recommended based on the simple sum.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we have similarity measures for each of the top 10 similar customers,
    we may also want to consider that when we recommend products. Instead of simple
    counts, we can do weighted counts. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: As you may notice, the only part that is different from the previous code is
    `potential_rec_items[each_item] += cos_sim`. Instead of simply counting, we are
    now adding the cosine similarity metric that measures how similar or dissimilar
    each customer is to the target customer.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we query the top 10 items weighted by the cosine similarity, the results
    look as in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.11: Top products purchased by similar customers (weighted by cosine
    similarity)'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the output from the simple count is the same as the output
    from the weighted count. Not only can you do the weighted sum of cosine similarities
    but you can also do the weighted average. There are many other ways you can aggregate
    the scores and recommend products, so being creative is the key to building the
    final recommendation output from the cosine similarity measures.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from these examples, we can build product sets to recommend based
    on the customers who have shown similar behaviors in the past. Oftentimes, people
    with similar tastes buy similar items, so this user-based collaborative filtering
    works well when recommending products based on the similarities among your customer
    base. On top of recommending based on customer similarities, we can also recommend
    based on how similar individual items are to others. We are going to discuss how
    to build recommendation systems based on item-based collaborative filtering in
    the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Item-based collaborative filtering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As in the case of user-based collaborative filtering, the key starting point
    of building an item-based collaborative filtering algorithm is to build an item-to-item
    similarity matrix. From the customer-item matrix we built previously, we can use
    the following code to build an item-to-item similarity matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As shown in this code, we transpose the customer-item matrix, `customer_item_matrix`,
    first, which will make it an item-to-customer matrix where each row is an item,
    each column is a customer, and each value is 0 or 1 representing whether a given
    item is bought by a given column. Then, we compute cosine similarity by using
    the `cosine_similarity` function and save the results as a pandas DataFrame in
    an `item_item_sim_matrix` variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The results should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.12: Item-to-item similarity matrix'
  prefs: []
  type: TYPE_NORMAL
- en: Recommending by the most similar items
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The simplest approach to generating recommendations based on item similarities
    is to find the most similar items for a given item and recommend them. When a
    person is viewing a certain product and you want to show related or similar items,
    this approach can be used. For example, when you search for a product on Amazon
    and click on one of the products shown on the search page, Amazon will show related
    or similar items at the bottom of the page that are often bought together. This
    is where item-based collaborative filtering can be used and, more specifically,
    when you want to recommend products based on one given product.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using our example dataset, let’s assume a customer is looking at a product,
    `MEDIUM CERAMIC TOP STORAGE JAR`, which has a product code of `23166`. From the
    item-to-item matrix, `item_item_sim_matrix`, that we have just built, we can find
    the top 10 most similar items with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in this code, we are selecting the top 10 most similar items
    by ordering the items by the cosine similarity in descending order. The output
    should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.13: Top 10 similar items to product 23166'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also query the descriptions based on these product codes as in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we are excluding product `23166` as it is the target item or
    the item that the customer is currently viewing and showing the rest of the 10
    most similar items. The output should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.14: Top 10 items similar to product 23166, including itself'
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, we can show these 10 items, including itself, on the page
    while the customer is viewing the target product. This way, we are showing the
    most similar or the most frequently bought together items so that the customer
    has more options to choose from or more items to purchase.
  prefs: []
  type: TYPE_NORMAL
- en: Recommending by the purchase history
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Expanding on the previous example of recommending products based on a single
    item, we can also build an item-based collaborative filtering recommendation system
    for multiple items. Especially when you may be sending out marketing emails or
    newsletters, you may want to send product recommendations along with them. In
    this case, it will be useful to consider the purchase history of customers, such
    as what kinds of products they have purchased, what product pages they have viewed
    online, or what products they have put in the cart. Using this information, we
    can build personalized product recommendations that are different for each customer
    using the item-based collaborative filtering algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using our example dataset as an example, let’s assume a customer has bought
    three items with product codes `23166`, `22720`, and `23243`. These items on our
    dataset are `SET OF 3 CAKE TINS PANTRY DESIGN`, `MEDIUM CERAMIC TOP STORAGE JAR`,
    and `SET OF TEA COFFEE SUGAR TINS PANTRY`. You can get the top 10 most similar
    items for these items using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we query the item-to-item matrix for those three
    items that the customer has bought and take the mean of the cosine similarities.
    Then, we sort these average values in descending order to get the top 10 most
    similar items to the given 3 items. The output should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.15: Top 10 similar items to the given 3 items'
  prefs: []
  type: TYPE_NORMAL
- en: 'Excluding the items that were already bought, product `22722` comes first and
    is the most similar item to the given itemset, and `23165` follows the second.
    We can query the data to get the product descriptions of these top 10 similar
    items. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we exclude the 3 items that the customer has already bought from the
    recommendation list and retrieve the top 10 items that are the most similar or
    the most frequently bought together with these 3 items. The output of this query
    should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_07_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.16: Top 10 similar items to the given 3 items'
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, these product recommendations based on the item-based collaborative
    filtering algorithm results can be used for any marketing campaign. If you are
    building an email marketing campaign, you can run this item-based collaborative
    filtering algorithm to select the top similar products based on previous purchases,
    page views, or cart items and include them as part of the marketing emails. You
    can also have pop-up windows on web pages for when this user logs into your online
    page next time. Giving discounts or some other promotions on these items can also
    result in higher chances of conversions.
  prefs: []
  type: TYPE_NORMAL
- en: There are numerous ways you can apply user-based and item-based collaborative
    filtering for recommendation systems. It will be wise to keep track of how your
    recommendations perform and tune how you use them as you progress with your recommendation
    systems. You will most likely want to track, of those items that you have recommended,
    how many of them have converted.
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in *Chapter 2* when we discussed KPIs, tracking conversion and
    other KPIs among the recommended items can tell you the effectiveness of your
    recommendation systems and which approach works better.
  prefs: []
  type: TYPE_NORMAL
- en: Other frequently used recommendation methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have discussed the market basket analysis and collaborative filtering in
    depth for building personalized recommendation systems. However, there are various
    other ways these recommendation systems can be built. As previously mentioned,
    some of the common AI/ML-based approaches are association rules and collaborative
    filtering algorithms, which we have covered in this chapter; predictive modeling
    approaches are often used as well, and nowadays a hybrid of all these approaches
    is a typical method of building more comprehensive recommendation systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Not only are there AI/ML-driven approaches for recommendation systems but there
    can be various other ways to recommend products or content without even using
    AI/ML. The following are some common methods used for making recommendations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bestsellers or top views**: As the name suggests, recommendations based on
    the bestselling products or the most frequently viewed content are still used
    frequently. This helps new users or customers acquaint themselves with your products
    or platforms by easily viewing what others view or purchase the most on your platform.
    These can also be a great way to build your introductory marketing content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trending**: Similar to bestsellers, trending items show what is rising in
    popularity at a given moment. There can be some events, such as disasters in certain
    regions, breaking news at certain moments, or holiday events happening around
    the neighborhoods, that spike customer interest sporadically. It’s wise to adjust
    for these events as these special events trigger certain customer behaviors and
    can be great marketing opportunities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**New arrivals**: As marketers, you most likely would not want to miss an opportunity
    to promote new products. Customers, existing or new, are often attracted to new
    arrival items, and this can be a great marketing opportunity to retain existing
    customers, as well as gain new customers. By recommending new arrivals to customers
    who have shown interest in similar items, the marketing campaign can result in
    great success.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Promotions**: Not only can you recommend products or content by their popularity
    or relevance but you can also recommend products or content that are going on
    promotion. Customers are often attracted to special deals and you would want to
    expose and market special promotions as actively as possible. These are great
    ways to clear out overstocked inventories, raise brand awareness, bring in new
    customers, and retain inactive customers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, there can be various ways you can build recommendation systems
    on top of utilizing AI/ML-driven methodologies. Given the competitive landscape
    and abundance of marketing campaigns basically by all businesses around the world,
    using only one approach in recommending products or content is not going to be
    that successful. The more comprehensive recommendation system you have, the more
    successful you will be in attracting and retaining customers. When you are designing
    recommendation systems, it would be wise to consider all the approaches mentioned
    in this chapter and apply them at the right moments and places.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed building personalized product recommendation systems.
    First, we discussed how to identify interrelationships between products by analyzing
    which itemsets are frequently bought together. We covered how to conduct market
    basket analysis in Python using the Apriori algorithm and association rules. Then,
    we dove deep into one of the AI/ML-driven approaches to building recommendation
    systems. We saw how user-based and item-based collaborative filtering algorithms
    can be used to identify similar users or items and products that are frequently
    bought together. In turn, these findings can then be used to recommend certain
    products that other customers are highly likely to be interested in and purchase.
    Lastly, we discussed various other approaches that can be used for recommending
    products and content. We showed how combining non-AI/ML approaches can result
    in a more comprehensive and diverse recommendation system.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we will continue our discussion around personalized
    and targeted marketing efforts. More specifically, we are going to cover how customer
    segmentations can be done in Python and why having an in-depth understanding of
    different customer segments within your customer base helps and affects the successes
    and failures of your marketing efforts.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genai](https://packt.link/genai)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code12856128601808671.png)'
  prefs: []
  type: TYPE_IMG
