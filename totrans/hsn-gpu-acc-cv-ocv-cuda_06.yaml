- en: Basic Computer Vision Operations Using OpenCV and CUDA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last chapter described the process of working with images and videos using
    OpenCV and CUDA. We looked at the code for some basic image and video processing
    applications and compared the performance of OpenCV code with and without CUDA
    acceleration. In this chapter, we will build on this knowledge and try to develop
    some more computer vision and image processing applications using OpenCV and CUDA.
    This chapter describes the method for accessing individual pixel intensities in
    color and grayscale images. A histogram is a very useful concept for image processing.
    This chapter describes the method for calculating histograms and how histogram
    equalization can improve the visual quality of images. This chapter will also
    describe how different geometric transformations can be performed using OpenCV
    and CUDA. Image filtering is a very important concept, which is useful in image
    preprocessing and feature extraction. This is described in detail in this chapter.
    The last part of this chapter describes different morphological operations, such
    as erosion, dilation, and opening and closing images.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Accessing individual pixel intensities in OpenCV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Histogram calculation and histogram equalization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering operations on images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Morphological operations on images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter requires a basic understanding of image processing and computer
    vision. It needs familiarity with basic C or C++ programming language, CUDA, and
    all of the codes sample explained in previous chapters. All of the code used in
    this chapter can be downloaded from the following GitHub link: [https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA).
    The code can be executed on any operating system, though it has only been tested
    on Ubuntu 16.04\.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the code in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://bit.ly/2xERUDL](http://bit.ly/2xERUDL)'
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the individual pixel intensities of an image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes there is a need to access pixel intensity value at a particular location
    when we are working with images. This is very useful when we want to change the
    brightness or contrast of a group of pixels or we want to perform some other pixel-level
    operations. For an 8-bit grayscale image, this intensity value at a point will
    be in a range of 0 to 255, while for a color image there will be three different
    intensity values for the blue, green, and red channels with all having values
    between 0 to 255\.
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenCV provides a `cv::Mat::at<>` method for accessing intensity values at
    a particular location for any channel images. It needs one argument, which is
    the location of the point at which the intensity is to be accessed. The point
    is passed using the `Point` class with row and column values as arguments. For
    a grayscale image, the method will return a scalar object while, for a color image,
    it will return a vector of three intensities. The code for accessing pixel intensities
    at a particular location for a grayscale as well as a color image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The grayscale image is read first and the `at` method is called on this image
    object. The intensity value is measured at the `(100,50)` point, which indicates
    the pixel at the 100^(th) row and 50^(th) column. It returns a scalar, which is
    stored in the intensity variable. The value is printed on the console. The same
    procedure is followed for a color image but the return value for it will be a
    vector of three intensities, which is stored in the `Vec3b` object. The intensity
    values are printed on the console. The output of the above program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e89e363b-0180-4b19-8817-08d900820e44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As can be seen, pixel intensity for a grayscale image at `(100,50)` is `9`
    while for a color image it is `[175,179,177]`, which indicates the blue intensity
    is `175`, the green intensity is `179`, and red intensity is `177`. The same method
    is used to modify pixel intensity at a particular location. Suppose, you want
    to change the pixel intensity at the `(100,50)` location to `128`, then you can
    write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To summarize, in this section we have seen a method to access and change intensity
    values at a particular location. In the next section, we will see the method to
    calculate the histogram in OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: Histogram calculation and equalization in OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A histogram is a very important property of an image as it provides a global
    description of the appearance of that image. An enormous amount of information
    can be obtained from the histogram. It represents the relative frequency of occurrence
    of gray levels in an image. It is basically a plot of gray levels on the *X*-axis
    and the number of pixels in each gray level on the *Y*-axis. If the histogram
    is concentrated on the left side then the image will be very dark and if it is
    concentrated on the right side, then the image will be very bright. It should
    be evenly distributed for good visual quality of an image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image demonstrates histograms for dark, bright, and normal images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57923152-d000-474c-85e8-2fc0c884e9cc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'OpenCV provides a function to calculate the histogram of an Image. The syntax
    of the function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The function needs two arrays as an argument. The first array is the input image
    for which the histogram needs to be calculated. The second argument is an output
    array in which the histogram will be stored. The output can be plotted to get
    a histogram like what is shown in the preceding screenshot. As described earlier,
    a flat histogram improves the visual quality of an Image. OpenCV and CUDA provide
    a function to flatten the histogram, which is described in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Histogram equalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A perfect image has an equal number of pixels in all its gray levels. So a histogram
    should have a large dynamic range and an equal number of pixels in the entire
    range. This can be accomplished by a technique called histogram equalization.
    It is a very important preprocessing step in any computer vision application.
    In this section, we will see how histogram equalization can be performed for grayscale
    and color images using OpenCV and CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: Grayscale images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Grayscale images are normally 8-bit single channel images that have 256 different
    gray levels. If the histogram is not evenly distributed, the image is too dark
    or the image is too light, and histogram equalization should be performed to improve
    the visual quality of the image. The following code describes the process for
    histogram equalization on a grayscale image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The image read is uploaded to the device memory for histogram equalization.
    It is a mathematically intensive step so CUDA acceleration will help in improving
    the performance of the program. OpenCV provides the `equalizeHist` function for
    histogram equalization. It needs two arguments. The first argument is the source
    image and the second argument is the destination image. The destination image
    is downloaded back to the host and displayed on the console. The output after
    histogram equalization is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/33934253-36ec-4673-9d4e-33569c4d1aa6.png)'
  prefs: []
  type: TYPE_IMG
- en: As can be seen, the image after histogram equalization has a better visual quality
    than the original image. The same operation for color images is described next.
  prefs: []
  type: TYPE_NORMAL
- en: Color image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Histogram equalization can also be done on color images. It has to be performed
    on separate channels. So the color image has to be split into three channels.
    The histogram of each channel is equalized independently and then channels are
    merged to reconstruct the image. The code for histogram equalization on a color
    image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'A histogram is not normally equalized in the BGR color space; HSV and YCrCb
    color spaces are used for it. So, in the code, the BGR color space is converted
    in to the HSV color space. Then, it is split into three separate channels using
    the `split` function. Now, hue and saturation channels contain the color information
    so there is no point in equalizing those channels. Histogram equalization is performed
    only on the value channel. Three channels are merged back to reconstruct the color
    image using the `merge` function. The HSV color image is converted back into the
    BGR color space for display using `imshow`. The output of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/caded0d4-03be-471c-ae00-ea7b724a6b5d.png)'
  prefs: []
  type: TYPE_IMG
- en: To summarize, histogram equalization improves the visual quality of an image
    so it is a very important preprocessing step for any computer vision application.
    The next section describes the geometric transformation of images.
  prefs: []
  type: TYPE_NORMAL
- en: Geometric transformation on images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, there is a need for resizing an image, the translation of images,
    and the rotation of images for larger computer vision applications. These kinds
    of geometric transformation is explained in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Image resizing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'images need to be of specific sizes in some computer vision applications. So
    there is a need to convert the image of arbitrary size into the specific size.
    OpenCV provides a function to resize an image. The code for image resizing is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The height and width of an image can be obtained using two different functions,
    as shown in the code. The `rows` and `cols` properties of the `Mat` object describes
    the `height` and `width` of an image respectively. The `Mat` object also has the
    `size()` method, which has `height` and `width` properties which are used to find
    the size of an image. The image is resized in two ways. In the first way, the
    image is resized to a specific size of `(200,200)` and, in the second, it is resized
    to half of its original dimensions. OpenCV provides the `resize` function for
    this operation. It has four arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first two arguments are the source and destination images respectively.
    The third argument is the size of the destination image. It is defined using the
    `Size` object. When images are resized, then pixel values have to be interpolated
    on the destination image from the source image. There are various interpolation
    methods such as, bilinear interpolation, bicubic interpolation, area interpolation
    which are available for interpolating pixel values. This interpolation method
    is provided as the fourth argument to the `resize` function. It can be `cv::INTER_LINEAR
    (bilinear)`, `cv::INTER_CUBIC (bicubic)`, or `cv::INTER_AREA (Area)`. The output
    of the image resizing code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a7179ed4-cbc3-4d76-b0e2-345089955041.png)'
  prefs: []
  type: TYPE_IMG
- en: Image translation and rotation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Image translation and rotation are important geometric transformations that
    are needed in some computer vision applications. OpenCV provides an easy API to
    perform these transformations on images. The code to perform translation and rotation
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'A translation matrix needs to be created, which specifies the image translation
    in horizontal and vertical directions. It is a 2 x 3 matrix as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e728715d-0b8d-44f4-85e8-8da1dbdefd1a.png)'
  prefs: []
  type: TYPE_IMG
- en: '`tx` and `ty` are translation offset in the *x* and *y* directions. In the
    code, this matrix is created using the `Mat` object with 70 as an offsets in the
    *X*-direction and 50 as an offset in the *Y*-direction. This matrix is passed
    as an argument to the `warpAffine` function for Image translation. The other arguments
    for the `warpAffine` function are the source image, destination image, and size
    of the output image respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: A rotation matrix should be created for Image rotation at a particular degree
    centered at a particular point. OpenCV provides the `cv::getRotationMatrix2D`
    function to construct this rotation matrix. It needs three arguments. The first
    argument is the point for rotation; the center of the image is used for this.
    The second argument is the angle of rotation in degrees, which is specified as
    45 degrees. The last argument is the scale, which is specified as 1\. The constructed
    rotation matrix is again passed as an argument to the `warpAffine` function for
    Image rotation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the Image translation and Image rotation code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00396820-7bf0-4da4-84cb-7c198c24b00c.png)'
  prefs: []
  type: TYPE_IMG
- en: To summarize, this section described various geometric transformations such
    as Image resizing, image translation, and Image rotation using OpenCV and CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering operations on images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The methods described till this point worked on a single pixel intensity, and
    are called point processing methods. Sometimes it is helpful to look at the neighborhood
    of a pixel rather than only single pixel intensity. This are called neighborhood
    processing techniques. The neighborhood can be 3 x 3, 5 x 5, 7 x 7, and so on
    and are matrix-centered at a particular pixel. Image filtering is an important
    neighborhood processing technique.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering is an important concept in signal processing where we reject a certain
    band of frequencies and allow a certain band of frequency to pass. How is frequency
    measured in images? If gray levels change slowly over a region, then it is a low-frequency
    region. If gray levels changes drastically, then it is a high-frequency region.
    Normally the background of an image is considered a low-frequency region and the
    edges are high-frequency regions. Convolution is a very important mathematical
    concept for neighborhood processing and Image filtering in particular. It is explained
    in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Convolution operations on an image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The basic idea of convolutions evolved from a similar idea in biology called
    receptive fields, where it is sensitive to some parts in an image and insensitive
    to other parts. It can be mathematically represented as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*g(x,y)=f(x,y)*h(x,y)= ∑∑f(n,m)h(x-n,y-m)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In simplified form, this equation is a dot product between a filter, *h,* and
    a sub-image of the image, *f,* centered around the *(x,y)* point. The answer to
    this product is equal to the *(x,y)* point in the image, *g*. To illustrate the
    working of the convolution operation on an image, an example of a 3 x 3 filter
    applied to an image of a size of 6 x 6 is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9321074-4028-4de5-a4bd-9ad4aa78c0b8.png)'
  prefs: []
  type: TYPE_IMG
- en: A dot product is taken between the leftmost window shown in red with the filter
    to find a point in the destination image. The answer of the dot product will be
    *2 ((1*1 + 1*1 + 1*0 + 1*5 + 1*1 +1*7 +1*0 +1*1 + 1*1)/9)*. The same operation
    is repeated after moving this window by 1 pixel to the right and answer the will
    be *3*. This is repeated for all windows in an image to construct the destination
    image. Different low pass and high-pass filters can be constructed by changing
    the values of the 3 x 3 filter matrix. This is explained in the next two sections.
  prefs: []
  type: TYPE_NORMAL
- en: Low pass filtering on an image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A low pass filter removes high-frequency content from an Image. Generally,
    noise is considered high-frequency content so a low pass filter removes noise
    from an image. There are many types of noise, such as Gaussian noise, uniform
    noise, exponential noise, and salt-and-pepper noise, which can effect an image.
    Low pass filters are used to eliminate this kind of noise. There are many types
    of low pass filters available:'
  prefs: []
  type: TYPE_NORMAL
- en: Averaging or box filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaussian filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Median filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These filters and implementation of them using OpenCV is explained in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Averaging filters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An averaging filters as the name suggests, performs averaging operations on
    neighborhood pixels. If a Gaussian noise is present in an image then the low pass
    averaging filter can be used to remove the noise. It will also blur the edges
    of an Image, because of the averaging operation. The neighborhood can be 3 x 3,
    5 x 5, 7 x 7, and so on. The bigger the size of the filter window, the more blurring
    of the image will take place. The 3 x 3 and 5 x 5 averaging mask is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/394559ad-38f0-4218-bd97-5273f0a1bc4e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'OpenCV provides a simple interface to apply many kinds of filters on an image.
    The code to apply an averaging filter with a different mask is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`cv::Ptr`, which is a template class for smart pointers, is used to store a
    filter of the `cv::cuda::Filter` type. Then, the `createBoxFilter` function is
    used to create an averaging filter of different window sizes. It requires three
    mandatory and three optional arguments. The first and second arguments are datatypes
    for the source and destination images. They are taken as `CV_8UC1`, which indicates
    an 8-bit unsigned grayscale image. The third argument defines the size of the
    filter window. It can be 3 x 3, 5 x 5, 7 x 7, and so on. The fourth argument is
    the anchor point, which has a default value of (-1,-1) which indicates the anchor
    is at the center point of the kernel. The final two optional arguments are related
    to the pixel interpolation method and border value, which are omitted here.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The created filter pointer has an apply method, which is used to apply the
    created filter on any image. It has three arguments. The first argument is the
    source image, the second argument is the destination image, and the third optional
    argument is, CUDA stream, which is used for multitasking, as explained earlier
    in this book. In the code, three averaging filters of different sizes are applied
    on an Image. The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0d5c6cf0-9d19-4774-be37-edbcc634877a.png)'
  prefs: []
  type: TYPE_IMG
- en: As can be seen from the output, as the size of the filter increases, more pixels
    are used for averaging, which introduces more blurring on an image. Though a large
    filter will eliminate more noise.
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian filters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A Gaussian filter uses a mask that has a Gaussian distribution to filter an
    Image instead of a simple averaging mask. This filter also introduces smooth blurring
    on an Image and is widely used to eliminate noise from an image. A 5 x 5 Gaussian
    filter with an approximate standard deviation of 1 is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/111f7e02-3cb6-4702-919d-3f170e573560.png)'
  prefs: []
  type: TYPE_IMG
- en: 'OpenCV provides a function to implement the Gaussian filter. The code for it
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `createGaussianFilter` function is used to create a mask for the Gaussian
    filter. The datatype of the source and destination images, size of the filter,
    and standard deviation in the horizontal direction are provided as arguments to
    the function. We can also provide a standard deviation in the vertical direction
    as an argument; if it is not provided, then its default value is equal to standard
    deviation in the horizontal direction. The created Gaussian mask of a different
    size is applied to the image using an `apply` method. The output of the program
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3dcba18f-b470-4ce8-8cdc-a4e555c4a06c.png)'
  prefs: []
  type: TYPE_IMG
- en: Again as the size of the Gaussian filter increases, more blurring is introduced
    in the image. The Gaussian filter is used to eliminate noise and introduce smooth
    blurring on an image.
  prefs: []
  type: TYPE_NORMAL
- en: Median filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When an image is affected by salt and pepper noise, it will not be eliminated
    by the averaging or Gaussian filter. It needs a nonlinear filter. Median operations
    on a neighborhood instead of averaging can help in eliminating salt and pepper
    noise. In this filter, the median of 9-pixel values in the neighborhood is placed
    at the center pixel. It will eliminate extreme high or low values introduced by
    salt and pepper noise. Though OpenCV and CUDA provide a function for median filtering,
    it is slower than regular functions in OpenCV, so this function is used to implement
    median filter as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `medianBlur` function in OpenCV is used to implement a median filter. It
    needs three arguments. The first argument is the source image, the second argument
    is the destination image, and the third argument is the window size for the median
    operation. The output of the median filtering is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f692e545-d0a8-457b-8ade-e6b45c278b16.png)'
  prefs: []
  type: TYPE_IMG
- en: The source image is affected by salt and pepper noise, as can be seen in the
    screenshot. This noise is eliminated completely by the median filter of a size
    of 3x3 without introducing extreme blurring. So median filtering is a very important
    preprocessing step when images applications are affected by salt and pepper noise.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we have seen three types of low pass filter, which are widely
    used in various computer vision applications. Averaging and Gaussian filters are
    used to eliminate Gaussian noise, but they will also blur the edges of an Image.
    A median filter is used to remove salt-and-pepper noise.
  prefs: []
  type: TYPE_NORMAL
- en: High-pass filtering on an image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'High-pass filters remove low-frequency components from images and enhance high-frequency
    components. So, when a high-pass filter is applied to an Image, it will remove
    the background, as it is a low-frequency region, and enhances the edges, which
    are high-frequency components. So, high-pass filters can also be called edge detectors.
    The coefficients of the filter will change, otherwise it is similar to the filters
    seen in the last section. There are many high-pass filters available such as following:'
  prefs: []
  type: TYPE_NORMAL
- en: Sobel filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scharr filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Laplacian filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will see each one of them separately in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Sobel filters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Sobel operator or Sobel filter is a widely used image processing and computer
    vision algorithm for edge detection applications. It is a 3 x 3 filter that approximates
    the gradient of the image intensity function. It provides a separate filter to
    compute the gradient in a horizontal and vertical direction. The filter is convolved
    with the image in a similar way as described earlier in this chapter. The horizontal
    and vertical 3 x 3 Sobel filter is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/08b07763-8193-4132-9968-3c8b55ffa033.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The code for implementing this Sobel filter is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: OpenCV provides the `createSobelFilter` function for implementing a Sobel filter.
    It requires many arguments. The first two arguments are data types of the source
    and destination images. The third and fourth arguments are the order of the `x`
    and `y` derivatives respectively. For computing the `x` derivative or vertical
    edges, 1 and 0 are provided, and for computing the `y` derivative or horizontal
    edges, 0 and 1 are provided. The fifth argument which indicates the size of the
    kernel, is optional. The default value is 3\. The scale for derivatives can also
    be provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see both horizontal and vertical edges simultaneously, the result of the
    `x`-derivative and the `y`-derivative are summed. The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6a632427-fd9a-4d72-a303-501284f8c1ba.png)'
  prefs: []
  type: TYPE_IMG
- en: The Sobel operator provides a very inaccurate approximation of derivative but
    still, it is quite useful in computer vision applications for edge detection.
    It does not have rotation symmetry; to overcome that, the Scharr operator is used.
  prefs: []
  type: TYPE_NORMAL
- en: Scharr filters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As Sobel does not provide rotation symmetry, a Scharr operator is used to overcome
    that by using different filter masks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6ebcaa19-69d1-49fb-94fa-40e6cf520ee8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As can be seen from the mask, the Scharr operator gives more weight to central
    rows or central columns to find edges. The program to implement a Scharr filter
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: OpenCV provides the `createScharrFilter` function for implementing the Scharr
    filter. It requires many arguments. The first two arguments are datatypes of the
    source and destination images. The third and fourth arguments are the order of
    the `x` and `y` derivatives respectively. For computing the `x` derivative or
    vertical edges, 1 and 0 are provided, and for computing the `y` derivative or
    horizontal edges, 0 and 1 are provided. The fifth argument, which indicate the
    size of the kernel, is optional. The default value is 3\.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see both horizontal and vertical edges simultaneously, the result of the
    `x`-derivative and the `y`-derivative are summed. The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/681f64de-2f79-41eb-9d92-01acbfc9d973.png)'
  prefs: []
  type: TYPE_IMG
- en: Laplacian filters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Laplacian filters is also a derivative operator to find out edges in an
    Image. The difference is that Sobel and Scharr are first-order derivative operators,
    while Laplacian is a second-order derivative operator. It also finds out edges
    in both horizontal and vertical directions simultaneously, which is different
    than Sobel and Scharr operators. The Laplacian filter is computes the second derivative,
    so it is very sensitive to noise in an image, it is desirable to blur the image
    and remove noise before applying the Laplacian filter. The code for implementing
    a Laplacian filter is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Two Laplacian filters with kernel sizes of 1 and 3 are applied on an image
    using the `createLaplacianFilter` function. Along with the size of the kernel,
    the function also requires datatypes of the source and destination images as arguments.
    The created Laplacian filter is applied to an image using the `apply` method.
    The output of the Laplacian filter is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c9f8842c-0a03-4a11-9c52-2b3fd23a180d.png)'
  prefs: []
  type: TYPE_IMG
- en: To summarize, in this section, we have described different high-pass filters
    such as Sobel, Scharr, and Laplacian filters. Sobel and Scharr are first-order
    derivative operators used to compute edges and they are less sensitive to noise.
    Laplacian is a second-order derivative operator used to compute edges and it is
    very sensitive to noise.
  prefs: []
  type: TYPE_NORMAL
- en: Morphological operations on images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Image morphology deals with the regions and shapes of an image. It is used
    to extract image components that are useful to represent shapes and regions. Image
    morphology treats the image as an ensemble of sets unlike, other Image processing
    operations seen earlier. The image interacts with a small template, which is called
    a structuring element, and which defines the region of interest or neighborhood
    in the image morphology. There are various morphological operations that can be
    performed on images, which are explained one by one in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Erosion**: Erosion sets a center pixel to the minimum over all pixels in
    the neighborhood. The neighborhood is defined by the structuring element, which
    is a matrix of 1s and 0s. Erosion is used to enlarge holes in the object, shrink
    the boundary, eliminate the island, and get rid of narrow peninsulas that might
    exist on the image boundary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dilation**: Dilation sets a center pixel to the maximum over all pixels in
    the neighborhood. The dilation increases the size of a white block and reduces
    the size of the black region. It is used to fill holes in the object and expand
    the boundary of the object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Opening**: Image opening is basically a combination of erosion and dilation.
    Image opening is defined as erosion followed by dilation. Both operations are
    performed using the same structuring elements. It is used to smooth the contours
    of the image, break down narrow bridges and isolate objects that are touching
    one another. It is used in the analysis of wear particles in engine oils, ink
    particles in recycled paper, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Closing**: Image closing is defined as dilation followed by erosion. Both
    operations are performed using the same structuring elements. It is used to fuse
    narrow breaks and eliminate small holes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The morphological operators can be easily understood by applying them on binary
    images that only contain black and white. OpenCV and CUDA provide an easy API
    to apply a morphological transformation on images. The code for it is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: A structuring element that defines the neighborhood for the morphological operation
    needs to be created first. This can be done by using the `getStructuringElement`
    function in OpenCV. The shape and size of the structuring element need to be provided
    as an argument to this function. In the code, a rectangular structuring element
    of a size of 5 x 5 is defined.
  prefs: []
  type: TYPE_NORMAL
- en: The filter for morphological operations is created using the `createMorphologyFilter`
    function. It needs three mandatory arguments. The first argument defines the operation
    to be performed. `cv::MORPH_ERODE` is used for erosion, `cv::MORPH_DILATE` for
    dilation, `cv::MORPH_OPEN` for opening, and `cv::MORPH_CLOSE` for closing. The
    second argument is the datatype of an image, and the third argument is the structuring
    element created earlier. The `apply` method is used to apply these filters on
    an image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of morphological operations on an image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e5158d17-32b8-4f56-9c57-29242cedfb1a.png)'
  prefs: []
  type: TYPE_IMG
- en: As can be seen from the output, erosion reduces the boundary of an object while
    dilation thickens it. We consider the white part an object and the black part
    is the background. Opening smooths the contours of the image. Closing eliminates
    small holes in an image. If the size of the structuring element is increased to
    7 x 7 from 5 x 5, then the erosion of the boundary will be more pronounced in
    an erosion operation and the boundary will get thicker in a dilation operation.
    The small circles on the left side, which were visible in an eroded image of 5
    x 5, are removed when it is eroded with a size of 7 x 7.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of morphological operations using a 7 x 7 structuring element is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e8edd25-34ff-4742-8aaf-1ca95014aaa1.png)'
  prefs: []
  type: TYPE_IMG
- en: To summarize, morphological operations are important to find out components
    used to define the shape and regions of an image. It can be used to fill holes
    in an image and smoothen the contours of an image.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter described the method to access pixel intensities at a particular
    location in an image. It is very useful when we are performing a pointwise operation
    on an image. A histogram is a very important global feature used to describe an
    image. This chapter described the method to compute a histogram and the process
    of histogram equalization, which improves the visual quality of an image. Various
    geometric transformations such as image resizing, rotation, and translation were
    explained in detail. Image filtering is a useful neighborhood processing technique
    used to eliminate noise and extract edge features of an image and was described
    in detail. A low pass filter is used to remove noise but it will also blur out
    the edges of an image. A high-pass filter removes the background, which is a low-frequency
    region while enhancing edges, which are high-frequency regions. The last part
    of this chapter described different morphological operations such as erosion,
    dilation, opening, and closing, which can be used to describe the shape of an
    image and fill holes in an image. In the next chapter, we will use these concepts
    to build some useful computer vision applications using OpenCV and CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Write an OpenCV function to print pixel intensity at the location (200,200)
    of any color image on the console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write an OpenCV function to resize an image to (300,200) pixels. Use the bilinear
    interpolation method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write an OpenCV function to upsample an Image by 2\. Use the area interpolation
    method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'State true or false: blurring decreases as we increase the size of the averaging
    filter.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'State true or false: median filters can remove gaussian noise.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What steps can be taken to reduce noise sensitivity of Laplacian operator?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write an OpenCV function to implement top hat and black hat morphological operation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
