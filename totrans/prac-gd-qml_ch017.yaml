- en: Chapter 8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What Is Quantum Machine Learning?
  prefs: []
  type: TYPE_NORMAL
- en: '*Tell me and I forget. Teach me and I remember. Involve me and I* *learn.*'
  prefs: []
  type: TYPE_NORMAL
- en: — Benjamin Franklin
  prefs: []
  type: TYPE_NORMAL
- en: We now begin our journey through **Quantum Machine Learning** (**QML**). In
    this chapter, we will set the foundation for the remainder of this part of the
    book. We will begin by reviewing some general notions from classical machine learning,
    and then we will introduce the basic ideas that underlie QML as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The basics of machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do you wanna train a model?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantum-classical models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, you will learn the basic principles behind general machine
    learning, and you will understand how to construct, train, and assess some simple
    classical models using industry-standard frameworks and tools. We will also present
    a general picture of the world of QML.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 The basics of machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before discussing quantum machine learning, it may be a good idea to review
    some basic notions of Machine Learning (ML), in general. If you are familiar with
    the subject, feel free to skip this section. Please, keep in mind that the world
    of machine learning is extraordinarily vast; so much so that sometimes it is difficult
    to make general statements that can do justice to the overwhelming diversity of
    this field. For this reason, we will highlight those elements that will be more
    relevant for our purposes, while other aspects of machine learning — which are
    also of significant importance on their own — will be barely covered.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to this, please keep in mind that this will be a very condensed
    and hands-on introduction to machine learning. If you’d like to dive deeper into
    this field, we can recommend some very good books, such as the one by Abu-Mostafa,
    Magdon-Ismail, and Lin [[1](ch030.xhtml#Xabu2012learning)], or the one by Aurélien
    Géron [[104](ch030.xhtml#Xhandsonml)].
  prefs: []
  type: TYPE_NORMAL
- en: As mysterious as machine learning may seem, the ideas that underlie it are fairly
    simple. In broad terms, we could define the purpose of machine learning to be
    the design of algorithms that can make a ”computational system” aware of patterns
    in data. These patterns can be truly anything. Maybe you want to design a system
    that can distinguish pictures of cats from pictures of rabbits. Maybe you would
    like to come up with a computational model that can transcribe verbal speech in
    English spoken with an Irish accent. Maybe you want to create a model able to
    generate realistic pictures of faces of people who do not exist, but that are
    indistinguishable from the real deal. The possibilities, as you surely know, are
    endless! What will be common to all these algorithms is that they will not be
    explicitly programmed to solve those tasks; instead, they will ”learn” how to
    do it from data…hence the name ”machine learning!”
  prefs: []
  type: TYPE_NORMAL
- en: 'The cats versus rabbits example is a particular case of an interesting type
    of model: a **classifier**. As the name suggests, a classifier is any kind of
    system that assigns, to every input, one label out of a finite set of possibilities.
    In many cases, there are just two of these labels, and they are commonly represented
    by ![0](img/file12.png "0") (read as **positive**) and ![1](img/file13.png "1")
    (**negative**); in physics applications, for instance, these labels are often
    read, respectively, as **signal** and **background**. In this situation, we say
    that the classifier is **binary**. Keep this in mind, for we will use this terminology
    in a few of the coming examples!'
  prefs: []
  type: TYPE_NORMAL
- en: 'So now that we know where we are heading, we need to answer one basic question:
    how can we make machine learning a reality?'
  prefs: []
  type: TYPE_NORMAL
- en: 8.1.1 The ingredients for machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In most machine learning setups, there are three basic ingredients:'
  prefs: []
  type: TYPE_NORMAL
- en: First of all, we need some sort of computational model that is ”powerful enough”
    to tackle our problem. By this, we will often mean an algorithm that can be configured
    to solve the task at hand — at least to some level of accuracy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, if we want our model to capture patterns, we need to feed it some data
    so that it can do that. We will thus need data, preferably lots of it. The nature
    of this data will depend on the approach that we take, but, in most cases, we
    will need to transform it into numerical form. Most models expect data to be represented
    as vectors of real numbers called **attributes**, so this is what we will usually
    assume that we have.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And, lastly, we need a **training procedure** that will allow us to optimize
    the configuration of our model to make it solve the task (or, at least, come close
    to solving it!). In ML jargon, we could say that we need to find a way to make
    our model **learn** in order to identify the patterns that hide behind the data
    in our problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That is a pretty solid — yet somewhat oversimplified — wish-list. Let’s see
    how we can make more sense out of this.
  prefs: []
  type: TYPE_NORMAL
- en: '**The model** Let us first analyze that computational model that we have talked
    about. We said that it had to be ”powerful enough,” and this means that there
    should be a way to configure the model in such a way that it behaves as we intend
    it to.'
  prefs: []
  type: TYPE_NORMAL
- en: 'At first sight, this requirement may seem suspicious: how can we possibly be
    sure that such a configuration exists? In most real-life problems, we can never
    be fully sure…but we can be certain to some degree! This certainty may come from
    experience or, desirably, also from some theoretical results that justify it.
    For instance, you may have heard of **neural networks**. We will discuss them
    shortly, but, for now, you should know that they are models that have been proven
    to be **universal function approximators**. That is, any function can be approximated
    up to any given accuracy, no matter its complexity, by a large-enough neural network.
    That makes neural networks natural good choices for many problems.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will later discuss neural networks — and many other interesting models —
    in detail, but, to start with, we can consider a simplified version that, in fact,
    could be considered the grandparent of neural networks: the **perceptron**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A perceptron is a computational model that takes ![N](img/file784.png "N")
    numerical inputs and returns a single bit as output. This model depends on a collection
    of weights ![w_{i}](img/file1095.png "w_{i}") for ![i = 1,\ldots,N](img/file1096.png
    "i = 1,\ldots,N") and on a bias ![b](img/file17.png "b"), and it behaves as follows:
    for any input ![x_{1},\ldots,x_{N}](img/file1097.png "x_{1},\ldots,x_{N}"), if'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\sum\limits_{i = 1}^{N}x_{i}w_{i} + b \geq 0,](img/file1098.png "\sum\limits_{i
    = 1}^{N}x_{i}w_{i} + b \geq 0,") |'
  prefs: []
  type: TYPE_TB
- en: then the model returns ![1](img/file13.png "1"), and otherwise it returns ![0](img/file12.png
    "0").
  prefs: []
  type: TYPE_NORMAL
- en: This is a very simple computational model, but we could use it to set up a basic
    binary classifier by looking for some appropriate values for the weights and bias.
    That is, given a set of points on which we want the output to be ![1](img/file13.png
    "1") and another set of points on which the output should be ![0](img/file12.png
    "0"), we can try to search for some values for the ![w_{i}](img/file1095.png "w_{i}")
    and ![b](img/file17.png "b") coefficients that would make the perceptron return
    the desired outputs. In fact, in the dawn of the machine learning age, it was
    already proven that there is a simple learning algorithm that, under the condition
    that the problem data can be linearly separated, finds coefficients that can effectively
    classify the data.
  prefs: []
  type: TYPE_NORMAL
- en: There you have it, that could be your first baby machine learning model! Needless
    to say, a perceptron — at least on its own — is not a particularly powerful model,
    but it is, at least, a promising beginning!
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 8.1
  prefs: []
  type: TYPE_NORMAL
- en: We can all agree that perceptrons are cute models. But just to get an idea of
    their limitations, prove that they cannot implement an XOR gate. That is, if you
    are given inputs ![\{(0,1),(1,0)\}](img/file1099.png "\{(0,1),(1,0)\}") with desired
    output ![1](img/file13.png "1") and inputs ![\{(0,0),(1,1)\}](img/file1100.png
    "\{(0,0),(1,1)\}") with desired output ![0](img/file12.png "0"), there is no choice
    of perceptron weights and bias that works in this case.
  prefs: []
  type: TYPE_NORMAL
- en: '**The training procedure** Alright, so let’s say that we have a model that
    we believe is just powerful enough to approach our problem (and not too powerful
    either…more on that later!). We will restrict ourselves to assuming that the configuration
    of our model depends on some numerical parameters ![\theta](img/file89.png "\theta");
    this would mean that we would be looking for some choice ![\theta_{0}](img/file1045.png
    "\theta_{0}") of those parameters that will make our model work as well as possible.
    So, how do we find those parameters?'
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: We will only discuss models whose behavior can be adjusted and defined solely
    by tweaking some numerical parameters, as in the case of the perceptron. Nevertheless,
    there also exist **non-parametric** models that don’t behave in this manner. A
    popular example is the ![k](img/file317.png "k")-nearest neighbours algorithm;
    you can find some information in the references [[104](ch030.xhtml#Xhandsonml),
    Chapter 1].
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate all of this, we will discuss how to train a parametric model to
    implement a binary classifier. That is, we aim to build a binary classifier on
    a certain domain ![D](img/file1101.png "D") with some elements ![x](img/file269.png
    "x") that should be each classified as a certain ![y](img/file270.png "y") (where
    ![y](img/file270.png "y") can be either ![0](img/file12.png "0") or ![1](img/file13.png
    "1")). For this, we will use a model ![M](img/file704.png "M") that depends on
    some parameters in a way that, for any choice ![\theta](img/file89.png "\theta")
    of these parameters, it returns a label ![M_{\theta}(x)](img/file1102.png "M_{\theta}(x)")
    for every element ![x \in D](img/file1103.png "x \in D") in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, our goal is to look for a choice of parameters ![\theta](img/file89.png
    "\theta") that can minimize the probability that any random input ![x](img/file269.png
    "x") be misclassified. To put it in slightly more formal terms, if ![y](img/file270.png
    "y") is the correct label to be assigned to an input ![x](img/file269.png "x"),
    we want to minimize ![P(M_{\theta}(x) \neq y)](img/file1104.png "P(M_{\theta}(x)
    \neq y)"), that is, the probability of assigning an incorrect label to ![x](img/file269.png
    "x"). In this way, we have reduced the problem of training our model to the problem
    of finding some parameters ![\theta](img/file89.png "\theta") that minimize ![P(M_{\theta}(x)
    \neq y)](img/file1104.png "P(M_{\theta}(x) \neq y)"). This probability is known
    as the **generalization error** or the **true** **error**.
  prefs: []
  type: TYPE_NORMAL
- en: Now, if we had access to all the possible inputs in our domain ![D](img/file1101.png
    "D") and we knew all their expected outputs, we would simply have to minimize
    the true error…and we would be done! Nevertheless, this is neither an interesting
    situation nor a common one.
  prefs: []
  type: TYPE_NORMAL
- en: If we had a problem in which we already knew all the possible inputs and their
    outputs…why should we bother with all this machine learning business? We could
    just implement an old-school algorithm! Indeed, the whole point of ”learning”
    is being able to predict correct outputs for unseen data. Thus, when we resort
    to machine learning, we do so because we do not have full access to all the possible
    inputs and outputs in our domain — either because it is unfeasible or because
    such a domain might be infinite!
  prefs: []
  type: TYPE_NORMAL
- en: 'So now we are faced with a problem. We have a (potentially infinite) domain
    of data over which we have to minimize the true error, yet we only have access
    to a finite subset of it. But…how on earth can we compute the true error in order
    to minimize it? The answer is that, in general, we can’t, because we would need
    complete information on how all the data and the labels of our problem are distributed,
    something that we usually don’t have. Nevertheless, we still have access to a
    — presumably large — subset of data. Can we use it to our advantage? Yes, we surely
    can! The usual strategy is to divide the dataset that we have in two separate
    sets: a **training dataset** and a **test** **dataset**. The training set, usually
    much bigger than the test set, will be used to adjust the parameters of our model
    in an attempt to minimize the true error, while the test set will be used to estimate
    the true error itself.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, what we can do is just take whichever training dataset ![T](img/file74.png
    "T") we are using, and — instead of minimizing the true error, to which we simply
    don’t have access — we can try to minimize the **empirical error**: the probability
    of misclassifying an element within the training dataset. This empirical error
    would be computed as the proportion of misclassified elements in ![T](img/file74.png
    "T"):'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![R_{\text{emp}}(\theta) = \frac{1}{&#124;T&#124;}\sum\limits_{(x,y) \in
    T}1 - \delta(M_{\theta}(x),y),](img/file1105.png "R_{\text{emp}}(\theta) = \frac{1}{&#124;T&#124;}\sum\limits_{(x,y)
    \in T}1 - \delta(M_{\theta}(x),y),") |'
  prefs: []
  type: TYPE_TB
- en: where ![|T|](img/file1106.png "|T|") is the size of the training dataset and
    ![\delta(a,b)](img/file1107.png "\delta(a,b)") is ![1](img/file13.png "1") if
    ![a = b](img/file1108.png "a = b") and ![0](img/file12.png "0") otherwise (this
    ![\delta](img/file1109.png "\delta") function is known as the Kronecker delta).
    We would do all of this, of course, hoping that the real error would take similar
    values to the empirical error. Naturally, this hope will have to be justified
    and rest on some evidence, and we will soon see how the test dataset can help
    us with that. In any case, if we want all this setup to work, we will need to
    use a large enough dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our goal then is to minimize the true error, and, so far, our only strategy
    is trying to achieve it by minimizing the empirical error. Nevertheless, in practice,
    we don’t often work with these magnitudes directly. Instead, we take a more ”general”
    approach: we seek to minimize the expected value of a **loss function**, which
    is defined for every choice of parameters ![\theta](img/file89.png "\theta") and
    every possible input ![x](img/file269.png "x") and its desired output ![y](img/file270.png
    "y"). For instance, we could define the 0-1 loss function as'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![L_{01}(\theta;x,y) = 1 - \delta(M_{\theta}(x),y).](img/file1110.png "L_{01}(\theta;x,y)
    = 1 - \delta(M_{\theta}(x),y).") |'
  prefs: []
  type: TYPE_TB
- en: With this definition, it is trivial to see that the expected value, taken over
    the whole domain, of ![L_{01}](img/file1111.png "L_{01}") is exactly the true
    error; this expected value is known as the **true risk**. In the same way, the
    expected value of this loss function over the training sample is the empirical
    error.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the expected value of a loss function over a finite dataset
    will just be its average value.
  prefs: []
  type: TYPE_NORMAL
- en: So, in practice, our strategy for minimizing the true error will be minimizing
    the expected value of a suitable loss function over the training dataset. We will
    refer to this expected value as the **empirical risk**. For reasons that we will
    discuss later, we will usually consider loss functions different from ![L_{01}](img/file1111.png
    "L_{01}").
  prefs: []
  type: TYPE_NORMAL
- en: '**Assessing a trained model** We now have to address an important question.
    How can we be sure that — once we have trained a model — it will perform well
    on data outside the training dataset? For that, we cannot solely rely on ![R_{\text{emp}}(\theta)](img/file1112.png
    "R_{\text{emp}}(\theta)") because that average loss is computed on data that the
    classifier has already seen. That would be like testing a student only on problems
    that the teacher has already solved in class!'
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, there’s something that can save the day. Do you remember that test
    dataset we talked about before? This is its time to shine! In fact, we have kept
    this test set in a safe-deposit box to ensure that none of its examples were ever
    used in the training process. We can think of them as completely new problems
    that the student has never seen, so we can use them to assess their understanding
    of the subject. Thus, we can compute the average loss of ![M_{\theta}](img/file1113.png
    "M_{\theta}") on the examples of the test set — this is sometimes called the **test
    error**. Provided that they are representative of the classification problem as
    a whole and that the number of examples is big enough, we can be quite confident
    that the test error will be close to the true error of the model. This is just
    an application of some *central* theorems in statistics!
  prefs: []
  type: TYPE_NORMAL
- en: Now, if the test error is similar to the empirical risk (and if they are low
    enough), we are done. That’s it! We have successfully trained a model. Nonetheless,
    as you can imagine, things can also go wrong. Terribly wrong.
  prefs: []
  type: TYPE_NORMAL
- en: What if the test error is much bigger than the empirical error, the one computed
    on the training set? This would be similar to having a student who knows how to
    repeat the solution to problems already solved by the teacher but who is unable
    to solve new problems. In our case, this would mean having a classifier that works
    beautifully on the training dataset but makes a lot of errors on any inputs outside
    of it.
  prefs: []
  type: TYPE_NORMAL
- en: This situation is called **overfitting**, and it is one of the biggest risks
    (no pun intended) in machine learning. It occurs whenever, somehow, our model
    has learned the particularities of the data it has seen but not the general patterns;
    that is, it has fitted the training data too well, hence the name ”overfitting.”
    This problem usually occurs when the training dataset is too small or when the
    model is too powerful. In the first case, there is simply not enough information
    to extract general patterns. That is why, in this chapter, we have insisted that
    the more data we have, the better. But what about the second case? Why can having
    a very powerful model end up being something bad?
  prefs: []
  type: TYPE_NORMAL
- en: An example can be very illustrative here. Let’s say that we want to use machine
    learning to approximate some unknown real function. We haven’t discussed how this
    setup would work, but the core ideas would be analogous to the ones we have seen
    (we would seek to minimize the expected value of a loss function, and so on).
    If we have a sample of ![1000](img/file790.png "1000") points in the plane, we
    can always find a polynomial of degree ![999](img/file1114.png "999") that fits
    the data perfectly, in the same way that we can always fit a line to just two
    points. However, if the points are just samples of ![f(x) = x](img/file1115.png
    "f(x) = x") with some noise (which could result from some empirical sampling errors
    or some other reason), our polynomial will go out of its way to fit those points
    perfectly and will quickly deviate from the linear shape that it should have learned.
    In this way, being able to fit too much information can sometimes go against the
    goal of learning the general patterns of data. This is illustrated in *Figure*
    [*8.1*](#Figure8.1). In it, the degree of the ”fitting” polynomial is so big that
    it can fit the training data perfectly, including its noise, but it misses the
    implicit linear pattern and performs very badly on test data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1: A simple example of overfitting that results from using too powerful
    a model.](img/file1116.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 8.1**: A simple example of overfitting that results from using too
    powerful a model.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes a machine learning model may only work properly on its training dataset.
    This phenomenon is known as **overfitting**. It usually occurs when the training
    dataset is too small or when the model is too powerful.
  prefs: []
  type: TYPE_NORMAL
- en: If you find yourself in a situation in which your model has overfitted the data,
    you can try obtaining more data — something that is not always possible — or somehow
    reducing the power of your model. For instance, with the neural networks that
    we will be studying later in the chapter, you can try reducing their size.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: Another popular technique for avoiding overfitting is using **regularization**.
    Roughly speaking, regularization restricts the values that some of the parameters
    of your model can take, effectively making it less powerful and less prone to
    fit every single detail of the training data.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more about regularization techniques and their use in machine learning,
    we highly recommend checking the book by Aurélien Géron [[104](ch030.xhtml#Xhandsonml)].
  prefs: []
  type: TYPE_NORMAL
- en: You may also want to know that your models can exhibit a type of problem that
    is the opposite of overfitting and has been aptly named **underfitting**. If your
    model is not expressive enough, you can find yourself with both a high error rate
    on the training set and a high error rate on the test set. For instance, if you
    are using a linear function to try to fit points that come from a quadratic polynomial
    and, thus, follow a parabolic shape, you will surely experience some form of underfitting.
    To fix this problem, use a more powerful model — or reduce regularization if you
    happen to be using it.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize what we have discussed so far, remember that we want to obtain
    a model that has a low generalization error; that is, a model that works well
    even on data it has not been trained with. In order to achieve this, we consider
    a parametric model and look for those model parameters that minimize the error
    on the training set, because we cannot easily compute the true error. And to be
    sure that the model will behave well when confronted with new data, we compute
    the error on the test dataset as a way of assessing how representative the empirical
    risk is of the error on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: With this strategy, however, we may still be vulnerable to an additional problem.
    If we train a lot of different models, there is a risk that — just by pure chance!
    — one of them has great performance on the test dataset but not on the rest of
    the domain. In fact, this risk is higher the more models you train. Imagine that
    a thousand students take a test of 10 questions with 2 possible answers each.
    Even if they have not studied for the test and they answer completely at random,
    there is a very high probability that at least one of them will nail it. For this
    reason, you should never use the test dataset to select among your models, only
    to assess if their behavior is similar to the behavior they show during training.
  prefs: []
  type: TYPE_NORMAL
- en: This is definitely a problem because we usually want to train many different
    models and select the one we believe to be the best. What is more, many models
    have what are called **hyperparameters**. These are parameters that fix some property
    of the model, such as the size and number of layers in a neural network (more
    on that later), that cannot be optimized during training. Usually, we train many
    different models with different values of these hyperparameters, and then we select
    the best model from them.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where a third type of dataset comes into the equation: the **validation**
    **dataset**. This is an additional dataset that we could construct when splitting
    our global dataset; it should, of course, be fully independent of the training
    and test datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: What do we want the validation set for? Once we have trained our models with
    different choices of hyperparameters and configurations, we can compute the empirical
    risk on the validation set, and we may select the best one or maybe a handful
    of the best ones. Then, we could train those models again on the union of the
    training set and the validation set — to better extract all the information from
    our data — and then compute the error of the models on the test set, which we
    have held back until this very moment so that it remains a good estimator of the
    generalization error. In this way, we can select the best choice of hyperparameters
    or models while keeping the test dataset in pristine condition to be used in a
    final assessment process.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: You may also want to know that, instead of using a fixed validation set, a popular
    way of selecting hyperparameters is to use ![k](img/file317.png "k")**-fold**
    **cross-validation**. With this technique, the training dataset is divided into
    ![k](img/file317.png "k") subsets or **folds** of equal size. The training of
    the model is repeated ![k](img/file317.png "k") times, each one with a different
    subset acting as a validation dataset and the rest used as the training dataset.
    The performance is computed over each validation set and averaged over the ![k](img/file317.png
    "k") repetitions. Of course, the estimation obtained with cross-validation is
    better than when using a fixed validation set, but the computational cost is much
    higher — ![k](img/file317.png "k") times higher, in fact! Software libraries such
    as scikit-learn — which we will be using in the next section of this chapter —
    provide implementations of cross-validation for hyperparameter selection. Take
    a look at [the documentation of `GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)
    — where CV stands for cross validation — if you want to see a concrete implementation
    of this technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, sometimes training processes are iterative. In these cases, the
    **validation loss** (the average loss over the validation dataset) can be computed
    at the end of each iteration and compared against the training loss, just to know
    how the training is going — and to be able to stop it early should the model begin
    to overfit! It wouldn’t be a good practice to use the test set for this purpose:
    the test set should only be used once all the training is complete and we just
    want some reassurance on the validity of our results.'
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: All the informal notions that we are considering here can be formulated precisely
    using the language of probability theory. If you want to learn about the formal
    machinery behind machine learning, you should have a look at the book *Learning
    from data* [[1](ch030.xhtml#Xabu2012learning)] or at *Understanding machine learning*
    [[105](ch030.xhtml#Xunderml)].
  prefs: []
  type: TYPE_NORMAL
- en: With all of this, we now have a good understanding of all the elements needed
    for machine learning to come alive. In the following section, we will try to make
    all of this more precise by studying some of the most common approaches that are
    taken when training ML models.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1.2 Types of machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are three big categories in which most, if not all, machine learning
    techniques can fit: **supervised learning**, **unsupervised learning**, and **reinforcement
    learning**. In this book, we will work mostly with supervised learning, but we
    will also consider some unsupervised learning techniques. Let’s explain in a little
    bit more detail what each of these machine learning branches is about.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Supervised learning** The main goal of supervised learning is to learn to
    predict the values of a function on input data. These values can either be chosen
    from a finite set (the classification problems we have been talking about for
    the most part of this chapter) or be continuous values, such as the weight of
    a person or the value of some bonds a month from now. When the values we want
    to predict are continuous, we say that we are tackling a **regression** problem.'
  prefs: []
  type: TYPE_NORMAL
- en: When we train a model using supervised learning, we need to work with a dataset
    that has both a large-enough collection of valid inputs and all the expected outputs
    that our model should return for these inputs. This is known as having a **labeled**
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we were to train a cat-rabbit picture classifier using supervised
    learning, we would need to have a (large-enough) dataset with pictures of rabbits
    and cats, and we would also need to know, for each of those pictures, whether
    they are pictures of rabbits or pictures of cats.
  prefs: []
  type: TYPE_NORMAL
- en: With our labeled dataset, we would define a loss function that would depend
    on the inputs and the parameters of the model — so that we can compute the corresponding
    outputs — and the expected (correct) outputs. And, as we discussed before, then
    we would just apply an optimization algorithm to find a configuration of the model
    that could minimize the loss function on the training dataset — while ensuring
    that there is no overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: We still have to discuss how that optimization algorithm is going to work, but
    that is for later!
  prefs: []
  type: TYPE_NORMAL
- en: '**Unsupervised learning** When we work with unsupervised learning, we have
    access to **unlabeled** datasets, in which there are no expected outputs. We let
    the algorithm learn on its own by trying to identify certain patterns. For instance,
    we may want to group similar data points together (this is known as **clustering**)
    or we may want to learn something about how the data is distributed.'
  prefs: []
  type: TYPE_NORMAL
- en: In this latter case, our goal would be to train a **generative model** that
    we can use to create new data samples. An impressive example is the use of **Generative
    Adversarial Networks**, introduced by Ian Goodfellow and his collaborators in
    a highly influential paper [[46](ch030.xhtml#Xgoodfellow2014generative)] to create
    images that are similar — but completely different — to the ones used in the training
    phase. This is the kind of model that we will be working with in *Chapter* *[*12*](ch021.xhtml#x1-21200012),
    *Quantum Generative Adversarial Networks*,…in a quantum form, of course!*
  prefs: []
  type: TYPE_NORMAL
- en: '***Reinforcement learning** In reinforcement learning, the model — usually
    called the **agent** in this setting — interacts with an **environment**, trying
    to complete some task. This agent observes the **state** of the environment and
    takes some **actions** that in turn influence the state it observes. Depending
    on its performance, it receives ”rewards” and ”punishments”…and, of course, it
    wants to maximize the rewards while minimizing the punishments. To do that, it
    tries to learn a **policy** that determines what action to take for a given state
    of the environment.'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the agent may be a robot and the environment a maze it needs to
    navigate. The state can consist of its position in the maze and the open paths
    it can follow, and its actions can be rotating in some direction and moving forward.
    The goal may be finding the exit to the maze in some predefined time, for which
    the robot will get a positive reward.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of learning has been used extensively to train models designed to
    play games — AlphaGo, the computer program that in 2016 beat Go (human) grandmaster
    Lee Sedol in a five-games match, is a prominent example! To learn more about reinforcement
    learning, a good source is the book by Sutton and Barto [[93](ch030.xhtml#Xsutton2018reinforcement)].
  prefs: []
  type: TYPE_NORMAL
- en: Although there has been some interest in using quantum techniques in reinforcement
    learning (see, for instance [[91](ch030.xhtml#Xskolik2022quantum)]), this may
    very well be the machine learning branch in which quantum algorithms are less
    developed at the moment. For this reason, we will not cover this kind of learning
    in this book. Hopefully, in a few years there will be much more to tell about
    quantum reinforcement learning! Let’s now try to make everything concrete by using
    supervised learning to implement a very simple classifier. For this, we will use
    TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2 Do you wanna train a model?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is a machine learning framework developed at Google, and it is very
    widely used. You should refer to *Appendix* [*D*](ch027.xhtml#x1-240000D), *Installing
    the* *Tools*, for installation instructions. Keep in mind that we will be using
    version 2.9.1\. We will use TensorFlow in some of our quantum machine learning
    models, so it is a good idea to become familiar with it early on.
  prefs: []
  type: TYPE_NORMAL
- en: To keep things simple, we will tackle an artificial problem. We are going to
    prepare a dataset of elements belonging to one of two possible categories, and
    we will try to use machine learning to construct a classifier that can distinguish
    to which category any given input belongs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we do anything, let us quickly import NumPy and set a seed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We will later use this same seed with TensorFlow. And now, let’s generate the
    data!
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of generating a dataset by hand, we will use a function provided by
    the Python **scikit-learn** package (`sklearn`). This package is a very valuable
    resource for machine learning: not only does it include plenty of useful tools
    for everyday machine-learning-related tasks, but it also allows you to train and
    execute a wide collection of interesting models! We will use version 1.0.2 of
    `sklearn` and, as always, you should refer to *Appendix* *[*D*](ch027.xhtml#x1-240000D),
    *Installing the Tools*, for installation instructions.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*In order to generate our dataset, we will use the `make_classification` function
    from `sklearn``.``datasets`. We will ask it to generate ![2500](img/file1117.png
    "2500") samples of a dataset with two features (variables). We will also ask for
    both features to be **informative** and not redundant; the variables would be
    redundant, for example, if one of them were just a multiple of the other. Lastly,
    we will ask for the proportions of the two categories in the dataset to be ![20\,\%](img/file1118.png
    "20\,\%") to ![80\,\%](img/file1119.png "80\,\%"). We can do this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `class_sep` argument specifies how separable we want the two categories
    to be: the higher the value of this argument, the easier it is to distinguish
    them. Notice, also, that we have used the seed that we set earlier in order for
    the results to be repeatable.'
  prefs: []
  type: TYPE_NORMAL
- en: You may now be wondering why we have specified that we want the two categories
    in the dataset to be in a proportion ![20\,\%](img/file1118.png "20\,\%") to ![80\,\%](img/file1119.png
    "80\,\%"), when it would be much more natural for the two categories to be balanced.
    Indeed, it is desirable for both categories to have the same number of representatives
    in a dataset…but life is difficult, and in many practical scenarios, that is not
    a possibility! So just think of this choice of ours as our own little way of feeling
    closer to real life.
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, the `make_classification` function has returned an array `data`
    with the whole dataset (including all the elements from both categories, positive
    and negative), and an array `labels` such that the label of `data``[``i``]` will
    be `labels``[``i``]` (where ![0](img/file12.png "0") corresponds to positive and
    ![1](img/file13.png "1") to negative).
  prefs: []
  type: TYPE_NORMAL
- en: 'Just to get a feeling of what this dataset that we have created looks like,
    we can plot a simple histogram showing the distributions of the two features of
    our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Upon running this, we got the plots shown in *Figure* [*8.2*](#Figure8.2).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2: Histograms representing the distributions of the two features
    of our dataset.](img/file1120.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 8.2**: Histograms representing the distributions of the two features
    of our dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 8.2
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the data you are working with through graphs can help you gain insights
    into how to approach the problem you have at hand. We have plotted our data using
    a histogram, which is usually a good choice. What other representations could
    we have used?
  prefs: []
  type: TYPE_NORMAL
- en: Our goal now is to use machine learning to come up with a system that can solve
    the classification problem that we have created. And the first step in doing so
    will be to pick a good model to tackle our problem!
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.1 Picking a model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Not long ago, we introduced the perceptron and we showed how, *on its own*,
    it wasn’t the most powerful of models out there. We will now shed some light on
    why we emphasized ”on its own,” for we are about to introduce a very interesting
    model that can be thought of as being built by joining perceptrons together. Let’s
    dive into **neural networks**!
  prefs: []
  type: TYPE_NORMAL
- en: You may remember how a perceptron took ![N](img/file784.png "N") numerical inputs
    ![x_{i}](img/file714.png "x_{i}"), used on a collection of ![N](img/file784.png
    "N") weights ![w_{i}](img/file1095.png "w_{i}") and a bias ![b](img/file17.png
    "b"), and returned an output that depended on the value of
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\sum\limits_{i = 1}^{N}w_{i}x_{i} + b.](img/file1121.png "\sum\limits_{i
    = 1}^{N}w_{i}x_{i} + b.") |'
  prefs: []
  type: TYPE_TB
- en: 'Well, in this way, we can think of a neural network as being a collection of
    perceptrons — which we will, from now on, call **neurons** — organized in the
    following way:'
  prefs: []
  type: TYPE_NORMAL
- en: All the neurons are arranged into layers, and the output of the neurons in one
    layer is the input of the neurons in the next layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to this, the ”raw” linear output of every neuron will go through
    a (very possibly non-linear) **activation function** of our choice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That is the general idea, but let’s now make it precise.
  prefs: []
  type: TYPE_NORMAL
- en: 'A neural network with ![N_{0}](img/file1122.png "N_{0}") inputs is defined
    from the following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: An ordered sequence of **layers** (![l = 1,\ldots,L](img/file1123.png "l = 1,\ldots,L")),
    each with a fixed amount of **neurons** ![N_{l}](img/file1124.png "N_{l}").
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A bunch of **activation functions** ![h_{ln}](img/file1125.png "h_{ln}") for
    each neuron ![n](img/file244.png "n") in a layer ![l](img/file514.png "l").
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of **biases** ![b_{ln}](img/file1126.png "b_{ln}") for every neuron, and,
    for every neuron ![n](img/file244.png "n") in a layer ![l](img/file514.png "l"),
    a set of ![N_{l - 1}](img/file1127.png "N_{l - 1}") **weights** ![w_{kln}](img/file1128.png
    "w_{kln}") with ![k = 1,\ldots,N_{l - 1}](img/file1129.png "k = 1,\ldots,N_{l
    - 1}"). These biases and weights are the adjustable parameters that we would need
    to tweak in order to get the model to behave as we want it to.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In *Figure* *[*8.3*](#Figure8.3), we can see a graphical representation of a
    simple neural network.*
  prefs: []
  type: TYPE_NORMAL
- en: '*![Figure 8.3: A simple neural network with two layers taking three inputs
    (a_{0n}). We have labeled some of the weights, but none of the biases or the activation
    functions ](img/file1131.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 8.3**: A simple neural network with two layers taking three inputs
    (![a_{0n})](img/file1130.png "a_{0n})"). We have labeled some of the weights,
    but none of the biases or the activation functions'
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the ingredients that we need to set up a neural network. So, how
    does it work, then? Easy! For any choice of activation functions ![h_{ln}](img/file1125.png
    "h_{ln}"), biases ![b_{ln}](img/file1126.png "b_{ln}") and weights ![w_{kln}](img/file1128.png
    "w_{kln}"), the neural network takes some numerical inputs ![a_{0n}](img/file1132.png
    "a_{0n}") and, from there on, these inputs are propagated through the layers of
    the neural network in the following way: the values ![a_{ln}](img/file1133.png
    "a_{ln}") of the neurons ![n](img/file244.png "n") in all layers ![l](img/file514.png
    "l") are determined according to the inductive formula'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![a_{ln}: - h_{ln}\left( {b_{ln} + \sum\limits_{k = 1}^{N_{l - 1}}w_{kln}a_{l
    - 1,k}} \right).](img/file1134.png "a_{ln}: - h_{ln}\left( {b_{ln} + \sum\limits_{k
    = 1}^{N_{l - 1}}w_{kln}a_{l - 1,k}} \right).") |'
  prefs: []
  type: TYPE_TB
- en: With this procedure, we can assign a value to each neuron in the network. The
    values of the neurons in the last layer are the output of the model.
  prefs: []
  type: TYPE_NORMAL
- en: To be precise, what we have just described is known as an **artificial** **feed-forward
    dense neural network**. There are other possible architectures for neural networks,
    but this is the one that will be using for the most part of the rest of the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'That is how you can define a neural network, but there is one element in the
    definition to which we have not paid much attention: the activation function.
    We have mentioned before that this can be any function of our choice, and we have
    seen what role it plays in the behavior of a neural network, but what are some
    reasonable choices for this function? Let’s explore the most common ones:'
  prefs: []
  type: TYPE_NORMAL
- en: We may start off with a simple activation function, actually, the same one that
    we implicitly considered when we defined the perceptron. This is a **step function**
    given by
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| ![h(x) = \left\{ \begin{array}{ll} {1,\quad} & {x \geq 0} \\ {0,\quad} &
    {x < 0.} \\ \end{array} \right.](img/file1135.png "h(x) = \left\{ \begin{array}{ll}
    {1,\quad} & {x \geq 0} \\ {0,\quad} & {x < 0.} \\ \end{array} \right.") |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: We could technically use this in a neural network, but…in truth…it would not
    be a very wise choice. It is not differentiable, not even continuous. And, as
    we will soon see, that usually makes any function a terrible candidate to be an
    activation function inside a neural network. In any case, it is an example of
    historical importance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s now consider a somewhat more sophisticated and interesting example: the
    **sigmoid** activation function. This function is smooth and continuous, and it
    outputs values between ![0](img/file12.png "0") and ![1](img/file13.png "1").
    This makes it an ideal candidate for the activation function in the final layer
    of, for example, a classifier. It is defined by'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| ![S(x) = \frac{e^{x}}{e^{x} + 1}.](img/file1136.png "S(x) = \frac{e^{x}}{e^{x}
    + 1}.") |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: We have plotted it in *Figure* [*8.4a*](#Figure8.4a).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As beautiful as it may seem, when used in inner layers, the sigmoid function
    can easily lead to problems in the training process (see Aurelien’s book for more
    on this [[104](ch030.xhtml#Xhandsonml)]). In general, a better choice for inner
    layers is the **exponential linear unit** or **ELU** activation function, defined
    as
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| ![E(x) = \left\{ \begin{array}{ll} {x,\quad} & {x \geq 0} \\ {e^{x} - 1,\quad}
    & {x < 0.} \\ \end{array} \right.](img/file1137.png "E(x) = \left\{ \begin{array}{ll}
    {x,\quad} & {x \geq 0} \\ {e^{x} - 1,\quad} & {x < 0.} \\ \end{array} \right.")
    |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: You can find its plot in *Figure* [*8.4b*](#Figure8.4b).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will also discuss one last activation function: the **rectified linear unit**
    or **ReLU** function. In general, it yields worse results than the ELU function,
    but it is easier to compute and thus its use can speed up the training. It is
    defined as'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| ![R(x) = \max\{ 0,x\}.](img/file1138.png "R(x) = \max\{ 0,x\}.") |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: The plot can be found in *Figure* [*8.4c*](#Figure8.4c).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Exercise 8.3
  prefs: []
  type: TYPE_NORMAL
- en: Check that the image of the sigmoid function ![S](img/file73.png "S") is ![(0,1)](img/file305.png
    "(0,1)"). Prove that the ELU function ![E](img/file327.png "E") is smooth and
    that its image is ![( - 1,\infty)](img/file1139.png "( - 1,\infty)"). What is
    the image of the ReLU function? Is it smooth?
  prefs: []
  type: TYPE_NORMAL
- en: '![(a) Sigmoid function](img/file1140.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**(a)** Sigmoid function'
  prefs: []
  type: TYPE_NORMAL
- en: '![(b) ELU function](img/file1141.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**(b)** ELU function'
  prefs: []
  type: TYPE_NORMAL
- en: '![(c) ReLU function](img/file1142.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**(c)** ReLU function'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 8.4**: Some common activation functions in neural network'
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned at the beginning of the chapter, it has been proven that neural
    networks are universal function approximators [[107](ch030.xhtml#Xnn-universal)],
    so they are interesting models to consider in any problem involving supervised
    machine learning. And thus, they will be the model we will use to build our classifier.
    We will consider a neural network with two inputs and some layers — we will later
    decide how many of them and how many neurons each will have. The final layer,
    of course, will have a single neuron, which will be the output. We will use ELU
    activation functions all throughout the network, except for the last layer; there,
    we will use a sigmoid activation function in order to get a normalized result.
    That way, we will get a continuous value between ![0](img/file12.png "0") and
    ![1](img/file13.png "1"), and, as it is customary, we will define a threshold
    at ![\left. 1\slash 2 \right.](img/file136.png "\left. 1\slash 2 \right.") to
    assign positive (![\left. \geq 1\slash 2 \right.](img/file1143.png "\left. \geq
    1\slash 2 \right.")) or negative (![\left. < 1\slash 2 \right.](img/file1144.png
    "\left. < 1\slash 2 \right.")) to any given output.
  prefs: []
  type: TYPE_NORMAL
- en: Now that our model is ready, the next challenge that is waiting for us is finding
    a suitable loss function.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.2 Understanding loss functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to defining a loss function for supervised machine learning, with
    models that depend on some continuous parameters, we want to look for loss functions
    that are continuous and differentiable with respect to the trainable parameters
    of the model. The reason for this is the same reason why we want our activation
    functions to be differentiable, and it will become clear later on.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we discussed earlier, the most natural loss function — and the one whose
    expected value we truly want to minimize — would be the 0-1 loss function, but
    this function would not have a continuous dependence on the parameters of the
    model: it would take ”discrete jumps” as the classifier changes its behavior.
    Therefore, we need to look for alternative loss functions that are indeed continuous
    and differentiable while still measuring the loss in a manner that is reasonable
    and natural enough for classification problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Another somewhat naive yet much better choice would be to take the **mean**
    **squared error** as our loss function. For the purposes of our problem, we know
    that the neural network returns a continuous value between ![0](img/file12.png
    "0") and ![1](img/file13.png "1"), and we know that — ideally — the closer this
    value is to ![0](img/file12.png "0") or ![1](img/file13.png "1"), the more likely
    it corresponds to a negative or positive input respectively. In order to do the
    classification, we set a threshold at ![\left. 1\slash 2 \right.](img/file136.png
    "\left. 1\slash 2 \right.") and get a discrete label, but, in order to compute
    the loss function, we should actually look at that continuous output! In this
    way, if we let ![M_{\theta}(x)](img/file1102.png "M_{\theta}(x)") be the continuous
    value in ![\lbrack 0,1\rbrack](img/file1145.png "\lbrack 0,1\rbrack") returned
    by the model for a given input ![x](img/file269.png "x"), and we let ![y \in \{
    0,1\}](img/file1146.png "y \in \{ 0,1\}") be its corresponding label, we could
    take our loss function to be
  prefs: []
  type: TYPE_NORMAL
- en: '| ![L(\theta;x,y) = \left( {M_{\theta}(x) - y} \right)^{2},](img/file1147.png
    "L(\theta;x,y) = \left( {M_{\theta}(x) - y} \right)^{2},") |'
  prefs: []
  type: TYPE_TB
- en: where we have grouped in ![\theta](img/file89.png "\theta") all the parameters
    (weights and biases) on which our neural network ![M](img/file704.png "M") depends.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, in order to compute the training loss (the expected value over the
    training dataset), we would just take the average value over the training dataset,
    and analogously for the validation loss. This is usually called the **mean squared
    error** (**MSE**) because, well, it is the average of the error squared.
  prefs: []
  type: TYPE_NORMAL
- en: 'The MSE is a good loss function, but when it comes to binary classifiers, there
    is actually an even better candidate: the **binary cross-entropy**. It is computed
    as'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![H(\theta;x,y) = - y\log\left( {M_{\theta}(x)} \right) - (1 - y)\log\left(
    {1 - M_{\theta}(x)} \right).](img/file1148.png "H(\theta;x,y) = - y\log\left(
    {M_{\theta}(x)} \right) - (1 - y)\log\left( {1 - M_{\theta}(x)} \right).") |'
  prefs: []
  type: TYPE_TB
- en: Now, this may seem like a very complicated expression, but it is actually a
    very elegant and powerful loss function! For starters, if the output of the model
    is differentiable and continuous with respect to its trainable parameters, so
    is the loss (that is easy to check, just go back to Calculus 101). And that’s
    not all. The following exercise may help you realize why the binary cross-entropy
    function is a great choice function for binary classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 8.4
  prefs: []
  type: TYPE_NORMAL
- en: Show that the output of the binary cross-entropy loss function ![H(\theta;x,y)](img/file1149.png
    "H(\theta;x,y)") is ![0](img/file12.png "0") if ![M_{\theta}(x) = y](img/file1150.png
    "M_{\theta}(x) = y") and that it diverges to ![\infty](img/file1151.png "\infty")
    as ![M_{\theta}(x)](img/file1102.png "M_{\theta}(x)") approaches the opposite
    label to ![y](img/file270.png "y") (this is, as ![\left. M_{\theta}(x)\rightarrow
    1 \right.](img/file1152.png "\left. M_{\theta}(x)\rightarrow 1 \right.") if ![y_{i}
    = 0](img/file1153.png "y_{i} = 0") and as ![\left. M(x)\rightarrow 0 \right.](img/file1154.png
    "\left. M(x)\rightarrow 0 \right.") if ![y = 1](img/file769.png "y = 1")).
  prefs: []
  type: TYPE_NORMAL
- en: And, with this, our shiny new loss function is ready to be used. However, there
    is one last element we still have to take care of, one that we have so far neglected
    and ignored. Yes, in the following section, we shall give optimization algorithms
    the attention and care that they deserve!
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.3 Gradient descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You are now reading this book, probably in the comfort of your home, college
    library, or office. But life changes in the most unexpected ways, and, maybe,
    in a couple of weeks, you will find yourself at the top of a mountain, blindfolded
    (don’t ask us why) and tasked with the mission of reaching the bottom of a nearby
    valley. If this happened, what would you do?
  prefs: []
  type: TYPE_NORMAL
- en: You don’t have to be a survival expert to accomplish this task. It’s true that
    — for undisclosed reasons — you are blindfolded, so you can’t see where the valley
    is, but, hey, you can still move around, can’t you? So, you could take some small
    steps in whichever direction you feel is leading you downwards with the highest
    slope. And you could just repeat that process several times and, eventually, you
    would reach the bottom of a valley.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, as you descend, you will have to be careful with how big your steps
    are. Take steps that are too big, and you may go from the top of a mountain to
    the top of another one, skipping all the valleys in between (some medical doctors
    have suggested this might not be anatomically possible, but, well, you get what
    we mean). On the other hand, make your steps too small and it is going to take
    you forever to reach the valley. So, you will have to find a sweet spot!
  prefs: []
  type: TYPE_NORMAL
- en: Anyhow, how does this seemingly crazy thought experiment relate to machine learning?
    Let’s see.
  prefs: []
  type: TYPE_NORMAL
- en: '**Gradient descent algorithms** We now have a powerful-enough model that depends
    on some parameters. Moreover, since we have made wise life choices, we also have
    a loss function ![L](img/file1012.png "L") that depends continuously on and is
    differentiable with respect to these parameters (that is because we picked some
    smooth activation functions and the binary cross-entropy).'
  prefs: []
  type: TYPE_NORMAL
- en: 'By doing this, we have effectively reduced our machine learning problem to
    the problem of minimizing a loss function, which is a differentiable function
    on some variables (the trainable parameters). And how do we do this? Using the
    Force…Sorry, we got carried away. We meant: using calculus!'
  prefs: []
  type: TYPE_NORMAL
- en: The ”getting to the valley” problem that we discussed before is — as you may
    have very well guessed by now — a simple analogy that will help us illustrate
    the **gradient descent method**. This method is just an algorithm that will allow
    us to minimize a differentiable function, and we can think of it as the mathematical
    equivalent of taking small steps in the steepest downward direction on a mountain.
    We should warn you that the remaining content of this subsection might be somewhat
    dense. Please, don’t let technicalities overwhelm you. If this were a song, it’d
    be perfectly fine not to know its lyrics; all that would matter is for you to
    be familiar with its rhythm!
  prefs: []
  type: TYPE_NORMAL
- en: As you may remember from the sweet old days of undergraduate calculus, whenever
    you have a differentiable function ![\left. f:R^{N}\rightarrow R \right.](img/file1155.png
    "\left. f:R^{N}\rightarrow R \right.") (for those of you less familiar with mathematical
    notation, this is a fancy way of saying that ![f](img/file778.png "f") has ![N](img/file784.png
    "N") real-number inputs and returns a single real-number output), the direction
    in which it decreases more steeply at a point ![x](img/file269.png "x") is given
    by ![- \nabla f(x)](img/file1156.png "- \nabla f(x)"), where ![\nabla f(x)](img/file1157.png
    "\nabla f(x)") is the **gradient** **vector** at ![x](img/file269.png "x"), and
    is computed as
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\nabla f(x) = \left( {\left. \frac{\partial f}{\partial x_{1}} \right&#124;_{x},\ldots,\left.
    \frac{\partial f}{\partial x_{n}} \right&#124;_{x}} \right),](img/file1158.png
    "\nabla f(x) = \left( {\left. \frac{\partial f}{\partial x_{1}} \right&#124;_{x},\ldots,\left.
    \frac{\partial f}{\partial x_{n}} \right&#124;_{x}} \right),") |'
  prefs: []
  type: TYPE_TB
- en: where ![\left. \partial\slash\partial x_{i} \right.](img/file1159.png "\left.
    \partial\slash\partial x_{i} \right.") denotes the partial derivative operator
    with respect to a variable ![x_{i}](img/file714.png "x_{i}"). So, if we want to
    move towards a minimum at a given point, we will have to move in the direction
    of ![- \nabla f(x)](img/file1156.png "- \nabla f(x)"), but by what amount?
  prefs: []
  type: TYPE_NORMAL
- en: The mathematical equivalent of the size of a step is going to be a parameter
    ![\tau](img/file1160.png "\tau") known as the **learning rate**. And, in this
    way, given a learning rate ![\tau](img/file1160.png "\tau") and an initial configuration
    ![\theta_{0}](img/file1045.png "\theta_{0}") of the parameters of our model, we
    can try to find the parameters that minimize the loss function ![L](img/file1012.png
    "L") by computing, iteratively, new parameters according to the rule
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\theta_{k + 1} = \theta_{k} - \tau\nabla L(\theta_{k}).](img/file1161.png
    "\theta_{k + 1} = \theta_{k} - \tau\nabla L(\theta_{k}).") |'
  prefs: []
  type: TYPE_TB
- en: There are some algorithms that dynamically adjust this step size from an initial
    learning rate as the optimization progresses. One such algorithm is **Adam** (short
    for **Adaptive Moment Estimator**), which is one of the best gradient descents
    algorithms out there; it will actually be our go-to choice.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It is important to pick the learning rate wisely. If it is too small, the training
    will be very slow. If it is too large, you may find yourself taking huge strides
    that jump whole valleys, and the training may never be successful.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, in order for gradient descent algorithms to work, you need to be
    able to compute the gradient of the loss function. There are several ways to do
    this; for example, you could always estimate gradients numerically. But, when
    working with certain models such as neural networks, you can employ a technique
    known as **backpropagation**, which enables the efficient computation of exact
    gradients. You may learn more about the technical details in Geron’s exceptional
    book [[104](ch030.xhtml#Xhandsonml), Chapter 10].
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: The method of backpropagation has been one of the key developments leading to
    the great success of deep learning that we are experiencing today. Although this
    technique was already known in the 1960s, it was popularized for training neural
    networks by the work of Geoffrey Hinton and his collaborators. Hinton, together
    with Yoshua Bengio, Demis Hassabis, and Yann LeCun, received the 2022 Princess
    of Asturias Award for Technical and Scientific Research for outstanding work in
    the field of neural networks. You can learn a lot about the inception of backpropagation
    and about the history of neural networks research by reading the excellent *Architects
    of Intelligence*, in which Martin Ford interviews Bengio, Hassabis, Hinton, LeCun,
    and many other prominent figures in artificial intelligence [[40](ch030.xhtml#Xford2018architects)].
    By the way, Demis Hassabis is, in great part, responsible for the success of AlphaGo,
    one of the examples of reinforcement learning that we mentioned earlier in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '**Mini-batch gradient descent** When the training dataset is large, computing
    the gradient of the loss function — as a function of the optimizable parameters
    of the model — can slow down the training significantly. In order to speed up
    the training, you can resort to the technique of **mini-batch gradient descent**.
    With this optimization method, the training dataset is split into batches of a
    fixed **batch size**. The gradient of the loss function is then computed on each
    of these batches, and the results are used to approximate the gradient of the
    global loss function: this is, the loss function on the whole training dataset.
    When we use this technique, we need to be careful with the batch size that we
    use: make it too small, the training will be very unstable; make it too large,
    the training will be too slow. As with the learning rate, it’s all a matter of
    finding an equilibrium! However, in some cases, speed is of the essence, and we
    go to the extreme, using batches of just one input. This is called **stochastic
    gradient descent**. On the other hand, when the batch includes all the elements
    in the dataset, we say that we are using **batch gradient** **descent**.'
  prefs: []
  type: TYPE_NORMAL
- en: Now we do have all that we need to train our first model. We have a dataset,
    we know what our model should look like, we have picked a loss function and we
    know how to optimize it. So let’s make this work! For this, we will use TensorFlow
    and scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.4 Getting in the (Tensor)Flow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We already have our dataset ready, and we could split it manually into training,
    validation, and test datasets, but there are already some good-quality machine
    learning packages with functions that help you do that. One of these packages
    is `sklearn`, which implements a `train_test_split` function. It splits a dataset
    into a training and test dataset (it doesn’t return a validation dataset, but
    we can work our way around that). It does so by taking as arguments the dataset
    and the labels array; in addition, it has some optional arguments to specify whether
    the dataset should be shuffled and the proportions in which the dataset should
    be split. In order to get a training, validation, and test dataset with proportions
    ![0.8](img/file1162.png "0.8"), ![0.1](img/file1163.png "0.1"), and ![0.1](img/file1163.png
    "0.1") respectively, we just need to use this function twice: once to get a training
    dataset (size ![0.8](img/file1162.png "0.8")) and a test dataset (size ![0.2](img/file1091.png
    "0.2")), and once more to split the test dataset in half, yielding a validation
    dataset and a test dataset of relative size ![0.1](img/file1163.png "0.1") each.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Following convention, we will denote the datasets as variables `x` and the
    labels as variables `y`. In this way, we can run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice how the function returns four arrays in the following order: the data
    for the training dataset, the data for the test dataset, the labels for the training
    dataset, and the labels for the test dataset. One important thing about the `train_test_split`
    function is that it can use **stratification**. If we had also provided the arguments
    `stratify` `=` `labels` and `stratify` `=` `y_test`, this would have meant that,
    when splitting the data into training and test examples, it would have kept the
    exact proportion of positive and negative classes from the original data (or at
    least as close to exact as possible). This can be important, especially if we
    are working with unbalanced datasets in which one class is much more abundant
    than the other. If we are not careful, we could end up with a dataset in which
    the minority class is non-existent.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that the data is perfectly prepared, it is time for us to focus on the
    model. For our problem, we are going to use a neural network with the following
    components:'
  prefs: []
  type: TYPE_NORMAL
- en: An input layer with two inputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Three intermediate (also known as **hidden**) layers with ELU activation functions
    and with ![8](img/file506.png "8"), ![16](img/file619.png "16"), and ![8](img/file506.png
    "8") neurons respectively
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An output layer with a single neuron that uses the sigmoid activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s now try to digest this specification a little bit. Because of the nature
    of the problem, we know that our model needs two inputs and one output, hence
    the sizes of the input and output layers. What is more, we want to get an output
    normalized between ![0](img/file12.png "0") and ![1](img/file13.png "1"), so it
    makes sense to use the sigmoid activation function in the output layer. Now, we
    need to find a way to get from ![2](img/file302.png "2") neurons in the first
    layer to ![1](img/file13.png "1") neuron in the output layer. We could use hidden
    layers with ![2](img/file302.png "2") or ![1](img/file13.png "1") layers…but that
    wouldn’t yield a very powerful neural network. Thus, we have progressively scaled
    the size of the neural network: first going from ![2](img/file302.png "2") to
    ![8](img/file506.png "8"), then from ![8](img/file506.png "8") to ![16](img/file619.png
    "16"), then down from ![16](img/file619.png "16") to ![8](img/file506.png "8"),
    to finally reach the output layer with 1 neuron.'
  prefs: []
  type: TYPE_NORMAL
- en: How do we define such a model in TensorFlow? Well, after doing the necessary
    imports and setting a seed (remember that it is an important part if we want this
    to be reproducible!), all it takes is to define what is known as a **Keras** **sequential
    model**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is pretty self-explanatory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: And that is how we can create our model, storing it as an object of the `Sequential`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: Once you have defined a Keras `model`, like the sequential model that we have
    just considered, you can print a visual summary of it by running the instruction
    `print``(``model``.``summary``())`. This summary lists all the layers of the model
    together with their shape, and also displays a count of all the model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can train this model, we will need to **compile it**, associating
    it with an optimization algorithm and a loss function. This is done by calling
    the `compile` method and giving it the arguments `optimizer` and `loss`. In our
    case, we seek to use the Adam optimizer (just with its default parameters) and
    the binary cross entropy loss function. We can thus compile our model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: When we instantiate the Adam optimizer without providing any arguments, the
    learning rate is set, by default, to ![10^{- 3}](img/file1164.png "10^{- 3}").
    We may change this value — and we will very often do! — by setting a value for
    the optional argument `learning_rate`.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.5 Training the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we are ready to train our model. This will be done by calling the `fit`
    method. But before we do that, let’s explore in some detail the most important
    arguments that we have to and can pass to this method:'
  prefs: []
  type: TYPE_NORMAL
- en: The first argument that `fit` admits is the dataset `x`. It should be an array
    containing the inputs that need to be passed to the model in order to train it.
    In our case, that would be `x_tr`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second argument that we can send is the array of labels `y`. Of course,
    the dimensions of `x` and `y` need to match. In our case, we will set `y` to be
    `y_tr`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using an optimizer that relies on gradient descent, you may want
    to resort to mini-batch gradient descent. For this purpose, you can give an integer
    value to the `batch_size` argument, which defaults to ![32](img/file771.png "32")
    (thus, by default, mini-batch gradient descent is used). If you do not want to
    use mini-batch gradient descent, you should set `batch_size` to `None`; that is
    what we will do.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we discussed gradient descent, we saw how these gradient descent algorithms
    are **iterative**: they work by computing a sequence of points that, in principle,
    should converge to a (local) minimum. But this raises the question of how many
    optimization cycles the algorithm should make — how many such points in the sequence
    it should compute. You may fix how many steps, also known as **epochs**, you want
    the optimization algorithm to take. This is done by setting a value for the `epochs`
    argument, which defaults to ![1](img/file13.png "1"). In our case, we will use
    ![8](img/file506.png "8") epochs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we want to use some validation data, as it is our case, we can pass it through
    the `validation_data` argument. The value of this argument should be a tuple with
    the validation dataset in the first entry and the corresponding labels in the
    second one. Thus, in our case, we would set `validation_data` to `(``x_val``,`
    `y_val` `)`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may have noticed that the whole process of extracting a training, validation,
    and test dataset can be somewhat tiresome. Well, it turns out that TensorFlow
    can help out here. In principle, we could just have given TensorFlow a dataset
    with both the training and validation data and told it in which proportions they
    should be split by setting a value in the `validation_split` argument. This value
    must be a float between ![0](img/file12.png "0") and ![1](img/file13.png "1")
    representing the proportion of the training dataset that should be used for validation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By doing this, we would save ourselves a ”split”, but we would still have to
    extract a test dataset on our own.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: We have only covered some of the possibilities offered by TensorFlow — the ones
    that we will use most often. If you feel comfortable enough with the material
    that we have seen so far and want to explore TensorFlow in depth, you should check
    out the documentation ([https://www.tensorflow.org/api_docs/python/tf](https://www.tensorflow.org/api_docs/python/tf)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The way we will then train our model will be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'And, upon executing this instruction on an interactive shell, we will get the
    following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: When seeing this, the first thing we should do is comparing the training loss
    with the validation loss — just to stay away from overfitting! In our case, we
    see that these two are close enough and have evolved following similar decreasing
    trends during the training. That is indeed a good sign!
  prefs: []
  type: TYPE_NORMAL
- en: You may have noticed how we have saved the output of the `fit` method in an
    object that we have called `history` in which TensorFlow will store information
    about the training. For example, the training and validation losses at the end
    of each epoch is recorded in a dictionary that we could access as `history``.``history`.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 8.5
  prefs: []
  type: TYPE_NORMAL
- en: Plot on a single graph the evolution of the training and validation losses through
    the epochs, relying on the information contained in the `history` object.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we have manually set the number of epochs to ![8](img/file506.png
    "8"), but this is not always the best strategy. Ideally, we would like to fix
    a maximum number of epochs that is reasonably large, but we would want the training
    to stop as soon as the loss is not improving. This is known as **early stopping**,
    and it can be easily used in TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to use early stopping in TensorFlow, we first need to create an `EarlyStopping`
    object in which we specify how we want early stopping to behave. Let’s say that
    we want to train our model until, for three consecutive epochs, the validation
    loss doesn’t decrease more than ![0.001](img/file1165.png "0.001") after each
    epoch. To do this, we would have to invoke the following object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: And then, when calling the `fit` method, we would just have to pass the optional
    argument `callbacks` `=` `[``early_stp``]`. It’s as easy as that!
  prefs: []
  type: TYPE_NORMAL
- en: 'In any case, now we have trained our model. If we want our model to process
    any inputs, we can use the `predict` method, passing an array with any number
    of valid inputs. For example, in our case, if we wanted to get the output of the
    model on the test dataset, we could retrieve `model``.``predict``(``x_test``)`.
    However, this will give us the continuous values returned by the model (which
    will range from ![0](img/file12.png "0") to ![1](img/file13.png "1")), not a label!
    In order to get a discrete label (![0](img/file12.png "0") or ![1](img/file13.png
    "1")), we need to set a threshold. Naturally, we will set it to ![0.5](img/file1166.png
    "0.5"). Thus, if we want to get the labels that our model would predict, we would
    have to run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Of course, now we have to decide whether or not this training has been successful,
    so we should assess the performance of our model on the test dataset. In order
    to do this, we may simply compute the **accuracy** of our model on the test dataset,
    that is, we may compute the proportion of inputs in the test dataset that are
    correctly classified by our model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to do this, we can use the `accuracy_score` function from `sklearn``.``metrics`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In our case, we got ![89.2\%](img/file1167.png "89.2\%") accuracy. This seems
    like a pretty decent value, but we should always consider accuracy values in the
    context of each problem. For some tasks, ![89.2\%](img/file1167.png "89.2\%")
    can indeed be marvelous, but for others it can be simply disappointing. Imagine,
    for instance, that you have a problem in which ![99\%](img/file1168.png "99\%")
    of the examples belong to one class. Then, it is trivial to obtain at least ![99\%](img/file1168.png
    "99\%") accuracy! You just need to classify all the inputs as belonging to the
    majority class. In the next few pages, we will introduce tools to take this kind
    of situation into account and better quantify classification performance.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 8.6
  prefs: []
  type: TYPE_NORMAL
- en: 'Re-train the model under the following conditions and compute the accuracy
    of the resulting model:'
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the learning rate to ![10^{- 6}](img/file1169.png "10^{- 6}")
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing the learning rate to ![10^{- 6}](img/file1169.png "10^{- 6}") and increasing
    the number of epochs to ![1,000](img/file1170.png "1,000")
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing the size of the training dataset to ![20](img/file588.png "20")
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In which cases is the resulting model less accurate? Why?
  prefs: []
  type: TYPE_NORMAL
- en: Does overfitting occur in any of these scenarios? How could you identify it?
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have assessed the accuracy of our model just by measuring the proportion
    of elements that it would correctly classify by setting a threshold of ![0.5](img/file1166.png
    "0.5"). There are nevertheless other metrics of the performance of a binary classifier.
    We will study them in the next subsection!
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.6 Binary classifier performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Whenever you have a binary classifier, any output can belong to one of the
    four categories depicted in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Classified as positive | Classified as negative |'
  prefs: []
  type: TYPE_TB
- en: '| Actual positive | True positive | False negative |'
  prefs: []
  type: TYPE_TB
- en: '| Actual negative | False positive | True negative |'
  prefs: []
  type: TYPE_TB
- en: The abbreviations TP, FN, FP, and TN are also used to denote the number of true
    positives, false negatives, false positives, and true negatives (respectively)
    produced by a classifier over a given dataset. These quantities are used very
    often. In fact, a common way of assessing the performance of a classifier is by
    looking at its **confusion matrix** (usually over the test dataset), which is
    nothing more than the matrix
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\begin{pmatrix} \text{TP} & \text{FN} \\ \text{FP} & \text{TN} \\ \end{pmatrix}.](img/file1171.png
    "\begin{pmatrix} \text{TP} & \text{FN} \\ \text{FP} & \text{TN} \\ \end{pmatrix}.")
    |'
  prefs: []
  type: TYPE_TB
- en: 'To get started, we can now compute the confusion matrix for the binary classifier
    that we have just trained over the test dataset. For this, we can use the `confusion_matrix`
    function from `sklearn``.``metrics`, which requires two arguments: an array of
    predicted labels and an array of true labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon executing this piece of code, we get the following confusion matrix for
    our classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\begin{pmatrix} {24} & {20} \\ 7 & {199} \\ \end{pmatrix}.](img/file1172.png
    "\begin{pmatrix} {24} & {20} \\ 7 & {199} \\ \end{pmatrix}.") |'
  prefs: []
  type: TYPE_TB
- en: This matrix shows that there are very few false positives compared to the number
    of true negatives, but almost as many false negatives as true positives. This
    means that our classifier does a very good job of picking up the negative class
    but it is not so good at identifying the positive one. In a moment, we will discuss
    how to quantify this more precisely.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: Although we have focused just on binary classifiers, confusion matrices can
    also be defined for classification problems in which there are ![n](img/file244.png
    "n") classes. They have ![n](img/file244.png "n") rows and ![n](img/file244.png
    "n") columns, and the entry in row ![k](img/file317.png "k") column ![l](img/file514.png
    "l") represents the number of elements that actually belong to class ![k](img/file317.png
    "k") but that are labeled as class ![l](img/file514.png "l") by the system.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, if you fix one of the ![n](img/file244.png "n") classes as the
    positive one and consider the rest as negative, you can obtain TP, FP, TN, and
    FN for that particular class.
  prefs: []
  type: TYPE_NORMAL
- en: Confusion matrices are very informative, and the quantities in them can help
    us define several metrics of the performance of a binary classifier. For instance,
    the usual accuracy metric can be defined by
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\text{Acc} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP}
    + \text{FN}}.](img/file1173.png "\text{Acc} = \frac{\text{TP} + \text{TN}}{\text{TP}
    + \text{TN} + \text{FP} + \text{FN}}.") |'
  prefs: []
  type: TYPE_TB
- en: Other interesting metrics are the **positive predictive value** and the **sensitivity**,
    which are defined respectively as
  prefs: []
  type: TYPE_NORMAL
- en: '| ![P = \frac{\text{TP}}{\text{TP} + \text{FP}},\qquad S = \frac{\text{TP}}{\text{TP}
    + \text{FN}}.](img/file1174.png "P = \frac{\text{TP}}{\text{TP} + \text{FP}},\qquad
    S = \frac{\text{TP}}{\text{TP} + \text{FN}}.") |'
  prefs: []
  type: TYPE_TB
- en: The positive predictive value is also known as the **precision** and the sensitivity
    is also known as the **recall** of the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a trade-off between ![P](img/file1.png "P") and ![S](img/file73.png
    "S"). Obtaining a perfect recall is trivial: you just need to classify every input
    as positive. But then, you will have a low precision. Similarly, it is easy to
    obtain very good values of precision: only classify an example as positive if
    you are extremely sure that it is positive. But then the recall will be very low.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this reason, an interesting metric is the ![F_{1}](img/file1175.png "F_{1}")
    score, defined as the harmonic mean of ![P](img/file1.png "P") and ![S](img/file73.png
    "S"):'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![F_{1} = \frac{2}{\frac{1}{P} + \frac{1}{S}} = \frac{2PS}{P + S}.](img/file1176.png
    "F_{1} = \frac{2}{\frac{1}{P} + \frac{1}{S}} = \frac{2PS}{P + S}.") |'
  prefs: []
  type: TYPE_TB
- en: It is easy to see how this score can range from ![0](img/file12.png "0") (the
    score of the worst possible classifier) to ![1](img/file13.png "1") (the score
    of a perfect classifier). Moreover, a high ![F_{1}](img/file1175.png "F_{1}")
    score means that we are not favoring recall over precision or precision over recall.
  prefs: []
  type: TYPE_NORMAL
- en: If you are mathematically oriented, you may have realized that our expression
    for ![F_{1}](img/file1175.png "F_{1}") is actually undefined for ![P = S = 0](img/file1177.png
    "P = S = 0"), but we can trivially extend it by continuity to take the value ![F_{1}
    = 0](img/file1178.png "F_{1} = 0") there.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to compute these metrics, we may use the `classification_report` function
    from `sklearn``.``metrics`. In our case, we may run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: And in this table, we can see all the metrics that we have mentioned. You can
    see that the scores are returned for both the case in which ![0](img/file12.png
    "0") is the positive class and for the case when ![1](img/file13.png "1") is positive
    instead (in our case, we have considered ![0](img/file12.png "0") to be positive,
    so we would look at the first row). By the way, the **support** of a class is
    meant to represent the number of elements in the class that can be found in the
    dataset. Also, the **macro average** of each metric is just the plain average
    of the values of the metric obtained by taking each class as positive. The weighted
    average is like the macro average, but weighted by the proportion of elements
    of each class in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say that we have a binary classifier that returns a continuous output
    between ![0](img/file12.png "0") and ![1](img/file13.png "1") before cutting through
    a threshold in order to assign a label. As we saw earlier, we could just measure
    the performance of our classifier by using a bunch of metrics. But if we want
    to get a broader perspective of how our classifier could work for any threshold,
    we can take another approach.
  prefs: []
  type: TYPE_NORMAL
- en: Using the entries of the confusion matrix over a dataset, we may define the
    **true positive rate** as the proportion
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}},](img/file1179.png
    "\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}},") |'
  prefs: []
  type: TYPE_TB
- en: that is, the proportion of examples from the positive class that are actually
    classified as positive. On the other hand, we can analogously define the **false**
    **positive rate** as the quotient
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}.](img/file1180.png
    "\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}.") |'
  prefs: []
  type: TYPE_TB
- en: 'The **Receiver Operating Characteristic curve** or **ROC curve** of a classifier
    that returns continuous values is computed over a given dataset by plotting, for
    every possible choice of threshold, a point with a ![Y](img/file11.png "Y") coordinate
    given by the corresponding TPR and an ![X](img/file9.png "X") coordinate with
    the FPR for that threshold. As the threshold increases from ![0](img/file12.png
    "0") to ![1](img/file13.png "1"), this will give rise to a finite sequence of
    points. The curve is obtained by joining these through straight lines. Notice
    that we evaluate the performance of the classifier with different levels of ”demand”
    for classifying an input as positive. When the threshold is high, it will be harder
    to classify something as positive; the FPR will be low — great! — but the TPR
    will probably be also low. On the other hand, for low values of the threshold,
    it will be easier for an input to be classified as positive: the TPR will be high
    — yay! — but that can also cause the false positives to go up.'
  prefs: []
  type: TYPE_NORMAL
- en: Sounds familiar? This is the same kind of trade-off that we discussed when we
    defined precision and recall. The difference is that, in this case, we are taking
    into account the behavior of the classifier for every possible choice of threshold,
    giving us a global assessment. Plotting the ROC curve can be very informative
    because it can also help in selecting classification thresholds that are more
    suitable for our problem. For instance, if you are trying to detect whether a
    given patient has a certain serious illness, it may pay off to have some false
    positives — people that may need to undergo additional medical tests — at the
    cost of having very low false negatives. The ROC curve can help you there by identifying
    points at which the TPR is high and the FPR is acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to plot a ROC curve, we can use the `roc_curve` function from `sklearn``.``metrics`.
    It will return the ![X](img/file9.png "X") and ![Y](img/file11.png "Y") coordinates
    of the points of the curve. In our particular case, we may run the following piece
    of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Notice how we have dropped part of the output of the `roc_curve` function; in
    particular, the return object that we ignore yields an array that includes the
    thresholds at which the classifier accuracy changes (you can refer to the documentation
    at [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)
    for more information). The output that we got can be found in *Figure* [*8.5*](#Figure8.5).
    Notice that we have manually drawn a dashed line between ![(0,0)](img/file613.png
    "(0,0)") and ![(1,1)](img/file1181.png "(1,1)"). That is meant to represent the
    ROC curve that could be generated by a random classifier, one that assigns an
    input to a class with probability proportional to the size of that class, and
    it is an important visual aid. That’s because any curves above that dashed line
    are ROC curves of classifiers that have some real classification power.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5: ROC curve (solid line) for the classifier that we have trained.](img/file1182.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 8.5**: ROC curve (solid line) for the classifier that we have trained.'
  prefs: []
  type: TYPE_NORMAL
- en: There are some interesting features in this ROC curve, so let’s discuss it a
    little bit. To start with, notice that the points ![(0,0)](img/file613.png "(0,0)")
    and ![(1,1)](img/file1181.png "(1,1)") always belong to the ROC curve of any classifier
    because they are achieved with the highest and lowest thresholds, respectively.
    In the first case, no input is assigned to the positive class, so we have neither
    TPs nor FPs. In the second one, all inputs are assigned to the positive class,
    so we have neither FNs nor TNs.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to this, we can observe in our graph that, from ![(0,0)](img/file613.png
    "(0,0)"), the ROC curve starts moving horizontally, increasing the FPR without
    increasing the TPR. This means that there are some examples in the test dataset
    that the model very confidently classifies as belonging to the positive class
    but that, in fact, are negative. This is undesirable, of course. We would like
    our ROC curve to go up — increasing the TPR — without moving to the right. And
    that is exactly what happens after that first hiccup. We observe a long segment
    in which the TPR goes up without any increase in the FPR. If we need our classifier
    to have high precision, we could select the threshold that achieves TPR of about
    ![0.71](img/file1183.png "0.71") with FPR of only about ![0.02](img/file1184.png
    "0.02"). On the other hand, if we need high recall, we can select the point in
    the curve where the TPR is already ![1](img/file13.png "1") with a FPR of about
    ![0.5](img/file1166.png "0.5"). For a more balanced classifier, notice that there
    is a point in the ROC curve with TPR around ![0.91](img/file1185.png "0.91") and
    FPR below ![0.21](img/file1186.png "0.21").
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, the ideal classifier would have a ROC curve that goes all the way
    from ![(0,0)](img/file613.png "(0,0)") to ![(1,0)](img/file1187.png "(1,0)").
    That would mean that there is a threshold for which all the positive examples
    are classified as positive, while no negative example is assigned to the positive
    class. That’s just perfection! From there, the ROC curve would go straight to
    ![(1,1)](img/file1181.png "(1,1)"): we have already found all the positive examples
    so the TPR cannot increase, but by decreasing the threshold we will eventually
    increase the FPR from ![0](img/file12.png "0") to ![1](img/file13.png "1").'
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, that kind of perfect ROC curve is only achievable for extremely simple
    classification problems. However, we can still compare our actual model to that
    ideal classifier by computing the **area under the ROC curve**, often abbreviated
    as **AUC**. Since the ROC curve of the perfect classifier would have area equal
    to 1, we can consider that the closer the AUC of a classifier is to 1, the better
    its global performance is. In the same way, a random classifier would have an
    ROC curve that is a straight line from ![(0,0)](img/file613.png "(0,0)") to ![(1,1)](img/file1181.png
    "(1,1)"), so its AUC would be ![0.5](img/file1166.png "0.5"). Hence, classifiers
    whose AUC is higher than ![0.5](img/file1166.png "0.5") have some actual classification
    power beyond just random guessing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having the coordinates of the points that define the ROC curve, we can easily
    get the AUC score using the `auc` function from `sklearn``.``metrics`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In our case, we get an AUC score of approximately ![0.9271](img/file1188.png
    "0.9271"). Again, this seems like a great value, but let us stress once again
    that it all depended on the difficulty of the problem — and the one we have been
    considering is not particularly hard. Also, remember that the AUC is a global
    performance metric that takes into account every possible threshold of your classifier.
    At the end of the day, you need to commit to just one threshold value, and a high
    AUC might not mean much if, for your particular threshold choice, the accuracy,
    precision, and recall are not that great.
  prefs: []
  type: TYPE_NORMAL
- en: That was a lot of information! In any case, for most practical purposes, all
    that you will need to know is summarized in the following note.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Given a binary classifier with continuous output, we may compute its receiver
    operating characteristic curve (also known as the ROC curve) over a dataset. The
    higher the area under that curve, the higher the classifying power of the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'We refer to the area under the ROC curve of a classifier as its AUC (short
    for ”area under the curve”):'
  prefs: []
  type: TYPE_NORMAL
- en: An AUC of ![1](img/file13.png "1") corresponds to a perfect classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An AUC of ![0.5](img/file1166.png "0.5") would match that of a random classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An AUC of ![0](img/file12.png "0") corresponds to a classifier that always returns
    the wrong output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By now, we should have a decent understanding of (classical) machine learning,
    and you may be wondering where does the ”quantum” part begin? It begins now.
  prefs: []
  type: TYPE_NORMAL
- en: 8.3 Quantum-classical models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In general terms, quantum machine learning refers to the application of machine
    learning techniques — only that quantum computing is involved at same stage of
    the process. Maybe you use a quantum computer in some part a model that you wish
    to train. Maybe you wish to use data generated by some quantum process. Maybe
    you use a quantum computer to process quantum-generated data. As you can imagine,
    the subject of quantum machine learning, as a whole, is broad enough to accommodate
    for a wide range of ideas and applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In an attempt to categorize it all a little bit, we can follow the useful classification
    shown in Schuld’s and Petruccione’s book [[106](ch030.xhtml#Xschuld)] and divide
    quantum machine learning into four different flavors, which are depicted in *Figure*
    [*8.6*](#Figure8.6), according to the classical or quantum nature of the data
    and processing devices that are used:'
  prefs: []
  type: TYPE_NORMAL
- en: We could consider part of quantum machine learning all the quantum-inspired
    classical machine learning techniques; that is, all the classical machine learning
    methods that draw ideas from quantum computing. In this case, both the data and
    the computers are classical, but there is some quantum flavor involved in the
    process. This is represented as CC in the chart. Since there are no actual quantum
    computers involved in this approach, we will not study this kind of method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, we can also consider part of quantum machine learning any classical
    machine learning algorithms that rely on quantum data; for our purposes, we can
    just think of it as data generated by quantum processes, or as the application
    of classical machine learning to quantum computing. This is the QC block in the
    chart. In this approach, machine learning is a tool rather than an end, so we
    will not be covering these techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The kind of machine learning that we will focus on in this book is the one
    represented by the CQ label in the chart: machine learning that relies on classical
    data and uses quantum computing in the model or the training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lastly, there is also a very interesting QQ category. These techniques work
    on quantum data using quantum computing in the models themselves or in the training
    processes. Notice that — as opposed to CQ quantum machine learning — in this scenario,
    the quantum data need not be obtained from measurements: quantum states could
    be directly fed into a quantum model, for instance. This is an area of great promise
    (see, for instance, the recent paper by Huang et al. [[54](ch030.xhtml#Xhuang2022quantum)]),
    but the required technologies are still immature, so we will not be talking about
    this approach in much detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.6: The four big families of quantum machine learning, categorized
    according to the nature of the models and data that they use ](img/file1189.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 8.6**: The four big families of quantum machine learning, categorized
    according to the nature of the models and data that they use'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our plan, then, is to focus on CQ quantum machine learning: machine learning
    on classical data that relies on quantum computing. Now, within this category,
    there is still a fairly broad range of possibilities. We could use quantum computing
    on the model and also in the optimization process. There are already many interesting
    proposals for how quantum computing could speed up traditional machine learning
    models, but these approaches cannot, in general, be used on our current quantum
    hardware. For this reason, we will not discuss them in this book — but if you
    are interested in learning more about them, we can recommend the excellent paper
    by Biamonte et al. [[108](ch030.xhtml#Xbiamonte-qml)].'
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we will devote ourselves, heart and soul, to the study of fully quantum-oriented
    models that can be run on NISQ devices. These models will be trained on classical
    data and, in general, we will use purely classical optimization techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following chapters, we will study the following models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Quantum support vector machines**. We will soon explore what support vector
    machines are and how they can be trained using classical machine learning. We
    will also see how their quantum version is just a particular case of a general
    support vector machine in which we use quantum computers to map data into a space
    of quantum states.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quantum neural networks**. We will then explore a purely quantum model: quantum
    neural networks. This model runs fully on a quantum computer, and its behavior
    is inspired by classical neural networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid networks**. In the subsequent chapter, we will learn how to combine
    quantum neural networks with other classical models (most commonly, neural networks).
    We will refer to these models as hybrid networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quantum generative adversarial networks**. Lastly, we will study generative
    adversarial networks and cover how the components of these models can be replaced
    by quantum circuits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As in the rest of this book, our approach will be very hands-on and practical.
    If you wish to broaden your theoretical background on quantum machine learning,
    you can also have a look at the book by Maria Schuld and Francesco Petruccione
    [[106](ch030.xhtml#Xschuld)].
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have explored some basic concepts and ideas that lie at
    the foundation of machine learning. And we haven’t just explored them from a theoretical
    point of view: we have also seen them come to life.'
  prefs: []
  type: TYPE_NORMAL
- en: We have learned what machine learning is all about, and we have discussed some
    of the most common approaches used to make it a reality. In particular, we have
    learned that many machine learning problems can be reduced to the minimization
    of a loss function through some optimization algorithm on a suitable model.
  prefs: []
  type: TYPE_NORMAL
- en: We have also studied in some depth classical neural networks, and we have used
    an industry-standard machine learning framework (TensorFlow) to train one.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we have wrapped up this chapter by introducing what quantum machine
    learning is all about and having a sneak peek into the rest of the chapters of
    this part of the book.***
  prefs: []
  type: TYPE_NORMAL
