- en: 'Chapter 5: Problems with Machine Learning on Graphs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Graph **machine learning** (**ML**) approaches can be useful for a wide range
    of tasks, with applications ranging from drug design to recommender systems in
    social networks. Furthermore, given the fact that such methods are *general by
    design* (meaning that they are not tailored to a specific problem), the same algorithm
    can be used to solve different problems.
  prefs: []
  type: TYPE_NORMAL
- en: There are common problems that can be solved using graph-based learning techniques.
    In this chapter, we will mention some of the most well studied of these by providing
    details about how a specific algorithm, among the ones we have already learned
    about in [*Chapter 3*](B16069_03_Final_JM_ePub.xhtml#_idTextAnchor046), *Unsupervised
    Graph Learning,* and[*Chapter 4*](B16069_04_Final_JM_ePub.xhtml#_idTextAnchor064),
    *Supervised Graph Learning*, can be used to solve a task. After reading this chapter,
    you will be aware of the formal definition of many common problems you may encounter
    when dealing with graphs. In addition, you will learn useful ML pipelines that
    you can reuse on future real-world problems you will deal with.
  prefs: []
  type: TYPE_NORMAL
- en: 'More precisely, the following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Predicting missing links in a graph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting meaningful structures such as communities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting graph similarities and graph matching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will be using *Jupyter* Notebooks with Python 3.8 for all of our exercises.
    In the following code block, you can see a list of the Python libraries that will
    be installed for this chapter using `pip` (for example, run `pip install networkx==2.5`
    on the command line):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: All code files relevant to this chapter are available at [https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter05](https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter05).
  prefs: []
  type: TYPE_NORMAL
- en: Predicting missing links in a graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Link prediction**, also known as **graph completion**, is a common problem
    when dealing with graphs. More precisely, from a partially observed graph—a graph
    where for a certain pair of nodes it is not possible to exactly know if there
    is (or there is not) an edge between them—we want to predict whether or not edges
    exist for the unknown status node pairs, as seen in *Figure 5.1*. Formally, let
    ![](img/B16069_05_001.png) be a graph where ![](img/B16069_05_002.png) is its
    set of nodes and ![](img/B16069_05_003.png) is its set of edges. The set of edges
    ![](img/B16069_05_004.png) are known as *observed links*, while the set of edges
    ![](img/B16069_05_005.png) are known as *unknown links*. The goal of the link
    prediction problem is to exploit the information of ![](img/B16069_05_006.png)
    and ![](img/B16069_05_007.png) to estimate ![](img/B16069_05_008.png). This problem
    is also common when dealing with temporal graph data. In this setting, let ![](img/B16069_05_009.png)
    be a graph observed at a given timepoint ![](img/B16069_05_010.png), where we
    want to predict the edges of this graph at a given timepoint ![](img/B16069_05_011.png).
    The partially observed graph can be seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Partially observed graph with observed link  (solid lines) and
    unknown link  (dashed lines)](img/B16069_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Partially observed graph with observed link ![](img/B16069_05_012.png)
    (solid lines) and unknown link ![](img/B16069_05_013.png) (dashed lines)
  prefs: []
  type: TYPE_NORMAL
- en: The link prediction problem is widely used in different domains, such as a recommender
    system in order to propose friendships in social networks or items to purchase
    on e-commerce websites. It is also used in criminal network investigations in
    order to find hidden connections between criminal clusters, as well as in bioinformatics
    for the analysis of protein-protein interactions. In the next sections, we will
    discuss two families of approaches to solve the link prediction problem—namely,
    **similarity-based** and **embedding-based** methods.
  prefs: []
  type: TYPE_NORMAL
- en: Similarity-based methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this subsection, we show several simple algorithms to solve the label prediction
    problem. The main shared idea behind all these algorithms is to estimate a similarity
    function between each couple of nodes in a graph. If, according to the function,
    the nodes *look similar*, they will have a high probability of being connected
    by an edge. We will divide these algorithms into two sub-families: `networkx`
    library in the `networkx.algorithms.link_prediction` package.'
  prefs: []
  type: TYPE_NORMAL
- en: Index-based methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will show some algorithms available in `networkx` to compute
    the probability of an edge between two disconnected nodes. These algorithms are
    based on the calculation of a simple index through information obtained by analyzing
    the neighbors of the two disconnected nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Resource allocation index
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The resource allocation index method estimates the probability that two nodes
    ![](img/B16069_05_014.png) and ![](img/B16069_05_015.png) are connected by estimating
    the *resource allocation index* for all node pairs according to the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_05_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the given formula, the ![](img/B16069_05_017.png) function computes the
    neighbors of the ![](img/B16069_05_018.png) nodes and, as visible in the formula,
    ![](img/B16069_05_019.png) is a node who is a neighbor of both ![](img/B16069_05_020.png)
    and ![](img/B16069_05_021.png). This index can be computed in `networkx` using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The first parameter for the `resource_allocation_index` function is an input
    graph, while the second parameter is a list of possible edges. We want to compute
    the probability of a connection. As a result, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The output is a list containing couples of nodes such as `(1,2)`, `(2,5)`, and
    `(3,4)`, which form the resource allocation index. According to this output, the
    probability of having an edge between those couples of nodes is `0.5`.
  prefs: []
  type: TYPE_NORMAL
- en: Jaccard coefficient
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The algorithm computes the probability of a connection between two nodes ![](img/B16069_05_0201.png)
    and ![](img/B16069_05_021.png), according to the *Jaccard coefficient*, computed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_05_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/B16069_05_023.png) is used to compute the neighbors of the ![](img/B16069_05_024.png)
    node. The function can be used in `networkx` using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `resource_allocation_index` function has the same parameters as the previous
    function. The result of the code is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: According to this output, the probability of having an edge between nodes `(1,2)`
    is `0.5`, while between nodes `(2,5)` this is `0.25`, and between nodes `(3,4)`
    this is `0.333`.
  prefs: []
  type: TYPE_NORMAL
- en: In `networkx`, other methods to compute the probability of a connection between
    two nodes based on their similarity score are `nx.adamic_adar_index` and `nx.preferential_attachment`,
    based on *Adamic/Adar index* and *preferential attachment index* calculations
    respectively. Those functions have the same parameters as the others, and accept
    a graph and a list of a couple of nodes where we want to compute the score. In
    the next section, we will show another family of algorithms based on community
    detection.
  prefs: []
  type: TYPE_NORMAL
- en: Community-based methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As with index-based methods, the algorithms belonging to this family also compute
    an index representing the probability of the disconnected nodes being connected.
    The main difference between index-based and community-based methods is related
    to the logic behind them. Indeed, community-based methods, before generating the
    index, need to compute information about the community belonging to those nodes.
    In this subsection, we will show—also providing several examples—some common community-based
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: Community common neighbor
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In order to estimate the probability of two nodes being connected, this algorithm
    computes the number of common neighbors and adds to this value the number of common
    neighbors belonging to the same community. Formally, for two nodes ![](img/B16069_05_025.png)
    and ![](img/B16069_05_026.png), the community common neighbor value is computed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_05_027.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this formula, ![](img/B16069_05_028.png) is used to compute the neighbors
    of node ![](img/B16069_05_029.png), while ![](img/B16069_05_030.png) if ![](img/B16069_05_031.png)
    belongs to the same community of ![](img/B16069_05_032.png) and ![](img/B16069_05_033.png);
    otherwise, this is 0\. The function can be computed in `networkx` using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding code snippet, it is possible to see how we need to assign
    the `community` property to each node of the graph. This property is used to identify
    nodes belonging to the same community when computing the function ![](img/B16069_05_034.png)
    defined in the previous equation. The community value, as we will see in the next
    section, can also be automatically computed using specific algorithms. As we already
    saw, the `cn_soundarajan_hopcroft` function takes the input graph and a couple
    of nodes for which we want to compute the score. As a result, we get the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The main difference from the previous function is in the index value. Indeed,
    we can easily see that the output is not in the range `(0,1)`.
  prefs: []
  type: TYPE_NORMAL
- en: Community resource allocation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As with the previous method, the community resource allocation algorithm merges
    information obtained from the neighbors of the nodes with the community, as shown
    in the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_05_035.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/B16069_05_036.png) is used to compute the neighbors of node ![](img/B16069_05_037.png),
    while ![](img/B16069_05_038.png) if ![](img/B16069_05_039.png) belongs to the
    same community of ![](img/B16069_05_040.png) and ![](img/B16069_05_041.png); otherwise,
    this is 0\. The function can be computed in `networkx` using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding code snippet, it is possible to see how we need to assign
    the `community` property to each node of the graph. This property is used to identify
    nodes belonging to the same community when computing the function ![](img/B16069_05_042.png)
    defined in the previous equation. The community value, as we will see in the next
    section, can also be automatically computed using specific algorithms. As we already
    saw, the `ra_index_soundarajan_hopcroft` function takes the input graph and a
    couple of nodes for which we want to compute the score. As a result, we get the
    following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: From the preceding output, it is possible to see the influence of the community
    in the computation of the index. Since nodes `1` and `2` belong to the same community,
    they have a higher value in the index. On the contrary, edges `(2,5)` and `(3,4)`
    have a value of 0 since they belong to a different community from each other.
  prefs: []
  type: TYPE_NORMAL
- en: In `networkx`, two other methods to compute the probability of a connection
    between two nodes based on their similarity score merged with community information
    are `nx.a` `within_inter_cluster` and `nx.common_neighbor_centrality`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will describe a more complex technique based on ML plus
    edge embedding to perform prediction of unknown edges.
  prefs: []
  type: TYPE_NORMAL
- en: Embedding-based methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we describe a more advanced way to perform link prediction.
    The idea behind this approach is to solve the link prediction problem as a supervised
    classification task. More precisely, for a given graph, each couple of nodes is
    represented with a feature vector (![](img/B16069_05_043.png)), and a class label
    (![](img/B16069_05_044.png)) is assigned to each of those node couples. Formally,
    let ![](img/B16069_05_045.png) be a graph, and for each couple of nodes ![](img/B16069_05_046.png),
    we build the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_05_047.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/B16069_05_048.png) is the *feature vector* representing the couple
    of nodes ![](img/B16069_05_049.png), and ![](img/B16069_05_050.png) is their *label*.
    The value for ![](img/B16069_05_051.png) is defined as follows: ![](img/B16069_05_052.png)
    if, in the graph `G`, the edge connecting node ![](img/B16069_05_053.png) exists;
    otherwise, ![](img/B16069_05_054.png). Using the feature vector and the labels,
    we can then train an ML algorithm in order to predict if a given couple of nodes
    constitute a plausible edge for the given graph.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If it is easy to build the label vector for each couple of nodes, it is not
    so straightforward to build the feature space. In order to generate the feature
    vector for each couple of nodes, we will use some embedding techniques, such as
    `node2vec` and `edge2vec`, already discussed in [*Chapter 3*](B16069_03_Final_JM_ePub.xhtml#_idTextAnchor046),
    *Unsupervised Graph Learning*. Using those embedding algorithms, the generation
    of the feature space will be greatly simplified. Indeed, the whole process can
    be summarized in two main steps, outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: For each node of the graph `G`, its embedding vector is computed using a `node2vec`
    algorithm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For all the possible couple of nodes in the graph, the embedding is computed
    using an `edge2vec` algorithm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can apply now a generic ML algorithm to the generated feature vector in order
    to solve the classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to give you a practical explanation of this procedure, we will provide
    an example in the following code snippet. More precisely, we will describe the
    whole pipeline (from graph to link prediction) using the `networkx`, `stellargraph`,
    and `node2vec` libraries. We will split the whole process into different steps
    in order to simplify our understanding of the different parts. The link prediction
    problem was applied to the citation network dataset described in [*Chapter 1*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014),
    *Getting Started with Graphs in Python*, available at the following link: [https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz](https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz).'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, we will build a `networkx` graph using the citation dataset,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Since the dataset is represented as an edge list (see [*Chapter 1*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014),
    *Getting Started with Graphs in Python*), we used the `from_pandas_edgelist` function
    to build the graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a second step, we need to create, from the graph `G`, training and test
    sets. More precisely, our training and test sets should contain not only a subset
    of real edges of the graph `G` but also couples of nodes that do not represent
    a real edge in `G`. The couples representing real edges will be *positive instances*
    (class label 1), while the couples that do not represent real edges will be *negative
    instances* (class label 0). This process can be easily performed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We used the `EdgeSplitter` class available in `stellargraph`. The main constructor
    parameter of the `EdgeSplitter` class is the graph (`G`) we want to use to perform
    our split. The real splitting is performed using the `train_test_split` function
    that will generate the following outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`graph_test` is a subset of the original graph ![](img/B16069_05_055.png) containing
    all the nodes but just a selected subset of edges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`samples_test` is a vector containing in each position a couple of nodes. This
    vector will contain couples of nodes representing real edges (positive instance)
    but also couples of nodes that do not represent real edges (negative instance).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels_test` is a vector having the same length as `samples_test`. It contains
    only 0 or 1\. The value of 0 is present in the position representing a negative
    instance in the `samples_test` vector, while the value of 1 is present in the
    position representing a positive instance in `samples_test`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By following the same procedure used to generate the test set, it is possible
    to generate the training set, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The main difference in this part of code is related to the initialization of
    `EdgeSplitter`. In this case, we also provide `graph_test` in order to not repeat
    positive and negative instances generated for the test set.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we have our training and testing datasets with negative and
    positive instances. For each of those instances, we now need to generate their
    feature vector. In this example, we used the `node2vec` library to generate the
    node embedding. In general, every node embedding algorithm can be used to perform
    this task. For the training set, we can thus generate the feature vector with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'From the previous code snippet, it is possible to see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We generate the embedding for each node in the training graph using the `node2vec`
    library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use the `HadamardEmbedder` class to generate the embedding of each couple
    of nodes contained in the training set. Those values will be used as feature vectors
    to perform the training of our model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this example, we used the `HadamardEmbedder` algorithm, but in general, other
    embedding algorithms can be used, such as the ones described in [*Chapter 3*](B16069_03_Final_JM_ePub.xhtml#_idTextAnchor046),
    *Unsupervised Graph Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous step needs to also be performed for the test set, with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The only difference here is given by the `samples_test` array used to compute
    the edge embeddings. Indeed, in this case, we use the data generated for the test
    set. Moreover, it should be noted that the `node2vec` algorithm was not recomputed
    for the test set. Indeed, given the stochastic nature of `node2vec`, it is not
    possible to ensure that the two learned embeddings are "comparable" and therefore
    `node2vec` embeddings will change between runs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Everything is set now. We can finally train—using the `train_embeddings` feature
    space and the `train_labels` label assignment—an ML algorithm to solve the label
    prediction problem, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we used a simple `RandomForestClassifier` class, but every
    ML algorithm can be used to solve this task. We can then apply the trained model
    on the `test_embeddings` feature space in order to quantify the quality of the
    classification, as shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'As a result, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As we already mentioned, the methods we just described are just a general schema;
    each piece of the pipeline—such as the train/test split, the node/edge embedding,
    and the ML algorithm—can be changed according to the specific problem we are facing.
  prefs: []
  type: TYPE_NORMAL
- en: This method is particularly useful when dealing with link prediction in temporal
    graphs. In this case, information relating to an edge obtained at timepoint ![](img/B16069_05_056.png)
    used to train a model can be applied in order to predict edges at timepoint ![](img/B16069_05_057.png).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we introduced the label prediction problem. We enriched our
    explanation by providing a description, with several examples, of different techniques
    used to find a solution to the link prediction problem. We showed that different
    ways to tackle the problem are available, from simple index-based techniques to
    more complex embedding-based techniques. However, the scientific literature is
    full of algorithms to solve the link prediction task, and there are different
    algorithms to solve this problem. In the paper *Review on Learning and Extracting
    Graph Features for Link Prediction* ([https://arxiv.org/pdf/1901.03425.pdf](https://arxiv.org/pdf/1901.03425.pdf)),
    a good overview of different techniques used to solve the link prediction problem
    is available. In the next section, we will investigate the community detection
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting meaningful structures such as communities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One common problem data scientists face when dealing with networks is how to
    identify clusters and communities within a graph. This often arises when graphs
    are derived from social networks and communities are known to exist. However,
    the underlying algorithms and methods can also be used in other contexts, representing
    another option to perform clustering and segmentation. For example, these methods
    can effectively be used in text mining to identify emerging topics and to cluster
    documents that refer to single events/topics. A community detection task consists
    of partitioning a graph such that nodes belonging to the same community are tightly
    connected with each other and are weakly connected with nodes from other communities.
    There exist several strategies to identify communities. In general, we can define
    them as belonging to one of two categories, outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Non-overlapping** community detection algorithms that provide a one-to-one
    association between nodes and communities, thus with no overlapping nodes between
    communities'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overlapping** community detection algorithms that allow a node to be included
    in more than one community—for instance, reflecting the natural tendencies of
    social networks to develop overlapping communities (for example, friends from
    school, neighbors, playmates, people being in the same football team, and so on),
    or in biology, where a single protein can be involved in more than one process
    and bioreaction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following section, we will review some of the most used techniques in
    the context of community detection.
  prefs: []
  type: TYPE_NORMAL
- en: Embedding-based community detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One first class of methods that allow us to partition nodes into communities
    can be simply obtained by applying standard shallow clustering techniques on the
    node embeddings, computed using the methods described in [*Chapter 3*](B16069_03_Final_JM_ePub.xhtml#_idTextAnchor046),
    *Unsupervised Graph Learning*. The embedding methods in fact allow us to project
    nodes into a vector space where a distance measure that represents a similarity
    between nodes can be defined. As we have shown in [*Chapter 3*](B16069_03_Final_JM_ePub.xhtml#_idTextAnchor046),
    *Unsupervised Graph Learning*, embedding algorithms are very effective in separating
    nodes with similar neighborhood and/or connectivity properties. Then, standard
    clustering techniques can be used, such as distance-based clustering (K-means),
    connectivity clustering (hierarchical clustering), distribution clustering (Gaussian
    mixture), and density-based clustering (`networkx` utility function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then first get the reduced dense node representation using one of the
    embedding algorithms we have seen previously (for instance, `HOPE`), shown as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We can finally run a clustering algorithm on the resulting vector representation
    provided by the node embeddings, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We can plot the network with the computed communities highlighted in different
    colors, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'By doing so, you should obtain the output shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Barbell graph where the community detection algorithm has been
    applied using embedding-based methods ](img/B16069_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Barbell graph where the community detection algorithm has been
    applied using embedding-based methods
  prefs: []
  type: TYPE_NORMAL
- en: The two clusters, as well as the connecting nodes, have been correctly grouped
    into three different communities, reflecting the internal structure of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Spectral methods and matrix factorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another way to achieve a graph partition is to process the adjacency matrix
    or the Laplacian matrix that represents the connectivity properties of the graph.
    For instance, spectral clustering can be obtained by applying standard clustering
    algorithms on the eigenvectors of the Laplacian matrix. In some sense, spectral
    clustering can also be seen as a special case of an embedding-based community
    detection algorithm where the embedding technique is so-called spectral embedding,
    obtained by considering the first k-eigenvectors of the Laplacian matrix. By considering
    different definitions of the Laplacian as well as different similarity matrices,
    variations to this method can be obtained. A convenient implementation of this
    method can be found within the `communities` Python library and can be used on
    the adjacency matrix representation easily obtained from a `networkx` graph, as
    illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, the adjacency matrix (or the Laplacian) can also be decomposed using
    matrix factorization techniques other than the **singular value decomposition**
    (**SVD**) technique—such as **non-negative matrix factorization** (**NMF**)—that
    allow similar descriptions, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The threshold for belonging to the community was set in this example to 0, although
    other values can also be used to retain only the community cores. Note that these
    methods are overlapping community detection algorithms, and nodes might belong
    to more than one community.
  prefs: []
  type: TYPE_NORMAL
- en: Probability models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Community detection methods can also be derived from fitting the parameters
    of generative probabilistic graph models. Examples of generative models were already
    described in [*Chapter 1*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014), *Getting
    Started with Graphs in Python*. However, they did not assume the presence of any
    underlying community, unlike the so-called **stochastic block model** (**SBM**).
    In fact, this model is based on the assumption that nodes can be partitioned into
    *K* disjoint communities and each community has a defined probability of being
    connected to another. For a network of *n* nodes and *K* communities, the generative
    model is thus parametrized by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Membership matrix**: *M*, which is a *n x K* matrix and represents the probability
    a given node belongs to a certain class *k*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Probability matrix**: *B*, which is *K x K* matrix and represents the edge
    probability between a node belonging to community *i* and one node belonging to
    community *j*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The adjacency matrix is then generated by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_05_058.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/B16069_05_059.png) and ![](img/B16069_05_060.png) represent the
    community, and they can be obtained by sampling from a multinomial distribution
    of probabilities ![](img/B16069_05_061.png) and ![](img/B16069_05_062.png).
  prefs: []
  type: TYPE_NORMAL
- en: In the SBM, we can basically invert the formulation and reduce the community
    detection problem to posterior estimation of the membership matrix *M* from the
    matrix *A*, via maximum likelihood estimation. A version of this approach has
    recently been used together with randomized spectral clustering in order to perform
    community detection in very large graphs. Note that the SBM model in the limit
    of the constant probability matrix (that is, ![](img/B16069_05_063.png)) corresponds
    to the Erdős-Rényi model. These models have the advantage of also describing a
    relation between communities, identifying community-community relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Cost function minimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another possible way to detect communities within a graph is to optimize a given
    cost function that represents a graph structure and penalizes edges across communities
    versus edges within communities. This basically consists of building a measure
    for the quality of a community (as we will see shortly, its modularity) and then
    optimizing the node association to communities in order to maximize the overall
    quality of the partitioning.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the context of a binary associative community structure, the community association
    can be described by a dichotomic variable ![](img/B16069_05_064.png) with values
    -1 or 1, depending on whether the node belongs to one of the two communities.
    In this setting, we can define the following quantity that can indeed be used
    to effectively represent the cost associated with having a link between two nodes
    of different communities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_05_065.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Indeed, when two connected nodes, ![](img/B16069_05_066.png) belong to a different
    community ![](img/B16069_05_067.png), the contribution provided by the edge is
    positive. On the other hand, the contribution is 0, both when two nodes are not
    connected (![](img/B16069_05_068.png)) and when two connected nodes belong to
    the same community (![](img/B16069_05_069.png)). Therefore, the problem is to
    find the best community assignment (![](img/B16069_05_070.png) and ![](img/B16069_05_071.png))
    in order to minimize the preceding function. This method, however, applies only
    to binary community detection and is therefore rather limited in its application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another very popular algorithm belonging to this class is the Louvain method,
    which takes its name from the university where it was invented. This algorithm
    aims to maximize the modularity, defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16069_05_072.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/B16069_05_073.png) represents the number of edges, ![](img/B16069_05_074.png)
    and ![](img/B16069_05_075.png) represent the degree of the i-th and j-th node
    respectively, and ![](img/B16069_05_076.png) is the Kronecker delta function,
    which is 1 when ![](img/B16069_05_077.png) and ![](img/B16069_05_078.png) have
    the same value and 0 otherwise. The modularity basically represents a measure
    of how much better the community identification performs as compared to randomly
    rewiring the nodes and thus creating a random network that has the same number
    of edges and degree distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'To maximize this modularity efficiently, the Louvain methods iteratively compute
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Modularity optimization**: Nodes are swept iteratively, and for each node
    we compute the change of modularity *Q* there would be if the node were to be
    assigned to each community of its neighbors. Once all the ![](img/B16069_05_079.png)
    values are computed, the node is assigned to the community that provides the largest
    increase. If there is no increase obtained by placing the node in any other community
    than the one it is in, the node remains in its original community. This optimization
    process continues until no changes are induced.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Node aggregation**: In the second step, we build a new network by grouping
    all the nodes in the same community and connecting the communities using edges
    that result from the sum of all edges across the two communities. Edges within
    communities are accounted for as well by means of self-loops that have weights
    resulting from the sum of all edge weights belonging to the community.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A Louvain implementation can already be found in the `communities` library,
    as can be seen in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Another method to maximize the modularity is the Girvan-Newman algorithm, which
    is based on iteratively removing edges that have the highest betweenness centrality
    (and thus connect two separate clusters of nodes) to create connected component
    communities. Here is the code related to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The latter algorithm needs to compute the betweenness centrality of all edges
    to remove the edges. Such computations may be very expensive in large graphs.
    The Girvan-Newman algorithm in fact scales as ![](img/B16069_05_080.png), where
    ![](img/B16069_05_081.png) is the number of edges and ![](img/B16069_05_082.png)
    is the number of nodes, and should not be used when dealing with large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting graph similarities and graph matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning a quantitative measure of the *similarity* among graphs is considered
    a key problem. Indeed, it is a critical step for network analysis and can also
    facilitate many ML problems, such as classification, clustering, and ranking.
    Many clustering algorithms, for example, use the concept of similarity for determining
    if an object should or should not be a member of a group.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the graph domain, finding an effective similarity measure constitutes a
    crucial problem for many applications. Consider, for instance, the *role* of a
    node inside a graph. This node might be very important for spreading information
    across a network or guaranteeing network robustness: for example, it could be
    the center of a star graph or it could be a member of a clique. In this scenario,
    it would be very useful to have a powerful method for comparing nodes according
    to their roles. For example, you might be interested in searching for individuals
    showing similar roles or presenting similar unusual and anomalous behaviors. You
    might also use it for searching similar subgraphs or to determine network compatibility
    for *knowledge transfer*. For example, if you find a method for increasing the
    robustness of a network and you know that such a network is very similar to another
    one, you may apply the same solution that worked well for the first network directly
    to the second one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Example of differences between two graphs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16069_05_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.3 – Example of differences between two graphs
  prefs: []
  type: TYPE_NORMAL
- en: 'Several metrics can be used for measuring the similarity (distance) between
    two objects. Some examples include the *Euclidean distance*, *Manhattan distance*,
    *cosine similarity*, and so on. However, these metrics might fail to capture the
    specific characteristics of the data being studied, especially on non-Euclidean
    structures such as graphs. Take a look at *Figure 5.3*: how "distant" are **G1**
    and **G2**? They look pretty similar. But what if the missing connection in the
    red community of **G2** causes a severe loss of information? Do they still look
    similar?'
  prefs: []
  type: TYPE_NORMAL
- en: Several algorithmic approaches and heuristics have been proposed, based on mathematical
    concepts such as *graph isomorphisms*, *edit distance*, and *common subgraphs*
    (we suggest reading [https://link.springer.com/article/10.1007/s10044-012-0284-8](https://link.springer.com/article/10.1007/s10044-012-0284-8)
    for a detailed review). Many of these approaches are currently used in practical
    applications, even if they often require exponentially high computational time
    to provide a solution to **NP-complete** problems in general (where **NP** stands
    for **nondeterministic polynomial time**). Therefore, it is essential to find
    or learn a metric for measuring the similarity of data points involved in the
    specific task. Here is where ML comes to our aid.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many algorithms among the ones we have already seen in [*Chapter 3*](B16069_03_Final_JM_ePub.xhtml#_idTextAnchor046),
    *Unsupervised Graph Learning,* and [*Chapter 4*](B16069_04_Final_JM_ePub.xhtml#_idTextAnchor064),
    *Supervised Graph Learning* might be useful for learning an effective similarity
    metric. According to the way they are used, a precise taxonomy can be defined.
    Here, we provide a simple overview of graph similarity techniques. A more comprehensive
    list can be found in the paper *Deep Graph Similarity Learning: A Survey* ([https://arxiv.org/pdf/1912.11615.pdf](https://arxiv.org/pdf/1912.11615.pdf)).
    They can be essentially divided into three main categories, even if sophisticated
    combinations can also be developed. **Graph embedding-based methods** use embedding
    techniques to obtain an embedded representation of the graphs and exploit such
    a representation to learn the similarity function; **graph kernel-based methods**
    define the similarity between graphs by measuring the similarity of their constituting
    substructures; **graph neural network-based methods** use **graph neural networks**
    (**GNNs**) to jointly learn an embedded representation and a similarity function.
    Let''s see all of them in more detail.'
  prefs: []
  type: TYPE_NORMAL
- en: Graph embedding-based methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Such techniques seek to apply graph embedding techniques to obtain node-level
    or graph-level representations and further use the representations for similarity
    learning. For example, *DeepWalk* and *Node2Vec* can be used to extract meaningful
    embedding that can then be used to define a similarity function or to predict
    similarity scores. For example, in Tixier et al. (2015), `node2vec` was used for
    encoding node embeddings. Then, **two-dimensional** (**2D**) histograms obtained
    from those node embeddings were passed to a classical 2D **convolutional neural
    network** (**CNN**) architecture designed for images. Such a simple yet powerful
    approach enabled good results to be derived from many benchmark datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Graph kernel-based methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Graph kernel-based methods** have generated a lot of interest in terms of
    capturing the similarity between graphs. These approaches compute the similarity
    between two graphs as a function of the similarities between some of their substructures.
    Different graph kernels exist based on the substructures they use, which include
    random walks, shortest paths, and subgraphs. As an example, a method called **Deep
    Graph Kernels** (**DGK**) (Yanardag et al., 2015) decomposes graphs into substructures
    that are viewed as "words". Then, **natural language processing** (**NLP**) approaches
    such as **continuous bag of words** (**CBOW**) and **skip-gram** are used to learn
    latent representations of the substructures. This way, the kernel between two
    graphs is defined based on the similarity of the substructure space.'
  prefs: []
  type: TYPE_NORMAL
- en: GNN-based methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the emergence of **deep learning** (**DL**) techniques, GNNs have become
    a powerful new tool for learning representations on graphs. Such powerful models
    can be easily adapted to various tasks, including graph similarity learning. Furthermore,
    they present a key advantage with respect to other traditional graph embedding
    approaches. Indeed, while the latter generally learn the representation in an
    isolated stage, in this kind of approach, the representation learning and the
    target learning task are conducted jointly. Therefore, the GNN deep models can
    better leverage the graph features for the specific learning task. We have already
    seen an example of similarity learning using GNNs in [*Chapter 3*](B16069_03_Final_JM_ePub.xhtml#_idTextAnchor046),
    *Unsupervised Graph Learning*, where a two-branch network was trained to estimate
    the proximity distance between two graphs.
  prefs: []
  type: TYPE_NORMAL
- en: Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Similarity learning on graphs has already achieved promising results in many
    domains. Important applications may be found in chemistry and bioinformatics—for
    example, for finding the chemical compounds that are most similar to a query compound,
    as illustrated on the left-hand side of the following diagram. In neuroscience,
    similarity learning methods have started to be applied to measure the similarity
    of brain networks among multiple subjects, allowing the novel clinical investigation
    of brain diseases:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Example of how graphs can be useful for representing various
    objects: (a) differences between two chemical compounds; (b) differences between
    two human poses](img/B16069_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4 – Example of how graphs can be useful for representing various objects:
    (a) differences between two chemical compounds; (b) differences between two human
    poses'
  prefs: []
  type: TYPE_NORMAL
- en: Graph similarity learning has also been explored in computer security, where
    novel approaches have been proposed for the detection of vulnerabilities in software
    systems as well as hardware security problems. Recently, a trend for applying
    such solutions to solve computer vision problems has been observed. Once the challenging
    problem of converting images into graph data has been solved, interesting solutions
    can indeed be proposed for human action recognition in video sequences and object
    matching in scenes, among other areas (as shown on the right-hand side of *Figure
    5.4*).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned how graph-based ML techniques can be used to
    solve many different problems.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, we have seen that the same algorithm (or a slightly modified
    version of it) can be adapted to solve apparently very different tasks such as
    link prediction, community detection, and graph similarity learning. We have also
    seen that each problem has its own peculiarities, which have been exploited by
    researchers in order to design more sophisticated solutions.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore real-life problems that have been solved
    using ML.
  prefs: []
  type: TYPE_NORMAL
