<html><head></head><body>
		<div id="_idContainer084">
			<h1 id="_idParaDest-56" class="chapter-number"><a id="_idTextAnchor057"/>4</h1>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor058"/>Leveraging Amazon  Redshift ML</h1>
			<p>In the <a id="_idIndexMarker177"/>previous chapter, we discussed the overall benefits of <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) and how it fits into your <span class="No-Break">data warehouse.</span></p>
			<p>In this<a id="_idIndexMarker178"/> chapter, we will focus specifically on how to leverage <strong class="bold">Amazon Redshift ML</strong> to solve various use cases. These examples are designed to give you the foundation you need as you get hands-on training models, beginning in <a href="B19071_05.xhtml#_idTextAnchor068"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>. We will show the benefits of Redshift ML, such as eliminating data movement, being able to create models using simple SQL, and drastically reducing the time it takes to train a new model and make it available for inference. Additionally, you will learn how Amazon Redshift ML leverages <strong class="bold">Amazon SageMaker</strong> behind the scenes to automatically train your models as we guide you through the <a id="_idIndexMarker179"/>following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Why Amazon <span class="No-Break">Redshift ML?</span></li>
				<li>An introduction to Amazon <span class="No-Break">Redshift ML</span></li>
				<li>A <strong class="source-inline">CREATE </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> overview</span></li>
			</ul>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor059"/>Why Amazon Redshift ML?</h1>
			<p>Amazon Redshift ML<a id="_idIndexMarker180"/> gives you the ability to create and train ML models with simple SQL commands, without the need to build specialized skills. This means your data analysts, data engineers, and BI analysts can now leverage their SQL skills to do ML, which increases agility, since they no longer need to wait for an ML expert to train <span class="No-Break">their model.</span></p>
			<p>Additionally, since you use your model in the data warehouse, you no longer need to export data to be trained or import it back into the warehouse after your model is used to <span class="No-Break">make predictions.</span></p>
			<p>You do not have to worry about managing the governance of data. Data never leaves your VPC when you export data <span class="No-Break">for training.</span></p>
			<p>You can control who can create models and who can run inference queries on <span class="No-Break">those models.</span></p>
			<p>Amazon Redshift ML provides a very cost-effective solution for training and using models. The cost for Amazon SageMaker resources is based on the number of cells in your training dataset, which is the product of the number of rows times the number of columns in the <span class="No-Break">training set.</span></p>
			<p>The costs for running prediction queries using Amazon Redshift Serverless are based on the compute capacity used by <span class="No-Break">your queries.</span></p>
			<p>To learn more about Amazon Redshift Serverless costs refer <span class="No-Break">here </span><a href="https://docs.aws.amazon.com/redshift/latest/mgmt/serverless-billing.html"><span class="No-Break">https://docs.aws.amazon.com/redshift/latest/mgmt/serverless-billing.html</span></a><span class="No-Break">.</span></p>
			<p>You have the ability to control the costs of model training by limiting how much data is used to train the model, and by controlling the time for training. We will show you examples of this later in the <em class="italic">A CREATE MODEL </em><span class="No-Break"><em class="italic">overview</em></span><span class="No-Break"> section.</span></p>
			<p>When you <a id="_idIndexMarker181"/>run a prediction query, all predictions are computed locally in your Redshift data warehouse. This enables you to achieve very high throughput and <span class="No-Break">low latency.</span></p>
			<h1 id="_idParaDest-59"><a id="_idTextAnchor060"/>An introduction to Amazon Redshift ML</h1>
			<p>By leveraging Amazon Redshift ML, your<a id="_idIndexMarker182"/> organization can achieve many benefits. First of all, you eliminate unnecessary data movement, users can use familiar SQL commands, and integration with Amazon SageMaker <span class="No-Break">is transparent.</span></p>
			<p>Let’s define some of the terms that you will see throughout the <span class="No-Break">remaining chapters:</span></p>
			<ul>
				<li><strong class="bold">CREATE MODEL</strong>: This is <a id="_idIndexMarker183"/>a command that will contain the SQL that will export data to be used to train <span class="No-Break">your model.</span></li>
				<li><strong class="bold">Features</strong>: These are the <a id="_idIndexMarker184"/>attributes in your dataset that will be used as input to train <span class="No-Break">your model.</span></li>
				<li><strong class="bold">Target</strong>: This is the <a id="_idIndexMarker185"/>attribute in your dataset that you want to predict. This is also sometimes referred to as<a id="_idIndexMarker186"/> <span class="No-Break">a </span><span class="No-Break"><strong class="bold">label</strong></span><span class="No-Break">.</span></li>
				<li><strong class="bold">Inference</strong>: This is also referred <a id="_idIndexMarker187"/>to as <strong class="bold">prediction</strong>. In Amazon Redshift ML, this is the <a id="_idIndexMarker188"/>process of executing a query against a trained model to get the predicted value generated by <span class="No-Break">your model.</span></li>
			</ul>
			<p>To be able to create and access your ML models in Amazon Redshift to run prediction queries, you need to grant permissions on the model object, just like you would on other database objects such as tables, views, <span class="No-Break">or functions.</span></p>
			<p>Let’s assume you have created the following role to allow a set of users to create models, called <strong class="source-inline">analyst_cm_role</strong>. A superuser can grant permissions to this role <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
GRANT CREATE MODEL to role analyst_cm_role</pre>
			<p>Users/groups/roles with the <strong class="source-inline">CREATE MODEL</strong> privilege can create a model in any schema in your serverless endpoint or Redshift cluster if the user has the <strong class="source-inline">CREATE</strong> permission on the Schema. A Redshift ML model is part of the schema hierarchy, similar to tables, views, stored procedures, and user-defined functions. Let’s assume we have a schema called <strong class="source-inline">demo_ml</strong>. You can grant <strong class="source-inline">CREATE</strong> and <strong class="source-inline">USAGE</strong> privileges on the <strong class="source-inline">demo_ml</strong> schema to the analyst role using the following <span class="No-Break"><strong class="source-inline">GRANT</strong></span><span class="No-Break"> statement:</span></p>
			<pre class="source-code">
GRANT CREATE, USAGE ON SCHEMA demo_ml TO role analyst_cm_role</pre>
			<p>Now, let’s assume we have another role to allow a set of users access to run prediction queries called <strong class="source-inline">analyst_prediction_role</strong>. You can grant access to run predictions on models using <span class="No-Break">the following:</span></p>
			<pre class="source-code">
GRANT EXECUTE ON MODEL demo_ml.customer_churn_auto_model TO role analyts_prediction_role</pre>
			<p>The source data to create a model can be in Redshift or any other source that you can access from Redshift, including your <strong class="bold">Amazon Simple Storage Service</strong> (<strong class="bold">Amazon S3</strong>) S3 data lake via Spectrum or other sources using the Redshift federated query capability. At the time of writing, Amazon Aurora and Amazon RDS for PostgreSQL and MySQL are supported. More details are available <span class="No-Break">here: </span><a href="https://docs.aws.amazon.com/redshift/latest/dg/federated-overview.html"><span class="No-Break">https://docs.aws.amazon.com/redshift/latest/dg/federated-overview.html</span></a><span class="No-Break">.</span></p>
			<p>Amazon Redshift ML<a id="_idIndexMarker189"/> and Amazon SageMaker<a id="_idIndexMarker190"/> manage all data conversions, permissions, and resource usage. The trained model is then compiled by SageMaker Neo and made available as a user-defined function in Amazon Redshift so that users can make predictions using <span class="No-Break">simple SQL.</span></p>
			<p>Once your model is trained and available as a function in Amazon Redshift, you can run prediction queries at scale and efficiently, locally in <span class="No-Break">Amazon Redshift.</span></p>
			<p>See the process flow here in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B19071_04_001.jpg" alt="Figure 4.1 – The Redshift ML CREATE MODEL process flow"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – The Redshift ML CREATE MODEL process flow</p>
			<p>Now, let us go into more detail on how you can use the <strong class="source-inline">CREATE </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> statement.</span></p>
			<h1 id="_idParaDest-60"><a id="_idTextAnchor061"/>A CREATE MODEL overview</h1>
			<p>The <strong class="source-inline">CREATE MODEL</strong> statement <a id="_idIndexMarker191"/>allows for flexibility when addressing the various use cases you may need. There are four main types of <strong class="source-inline">CREATE </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> statements:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline">AUTO</strong></span><span class="No-Break"> everything</span></li>
				<li><strong class="source-inline">AUTO</strong> with user guidance, where a user can provide the <span class="No-Break">problem type</span></li>
				<li><strong class="source-inline">AUTO OFF</strong>, with customized options provided by <span class="No-Break">the user</span></li>
				<li><strong class="bold">Bring your own </strong><span class="No-Break"><strong class="bold">model</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">BYOM</strong></span><span class="No-Break">)</span></li>
			</ul>
			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.2</em> illustrates the flexibility available when training models with Amazon <span class="No-Break">Redshift ML:</span></p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B19071_04_002.jpg" alt="Figure 4.2 – Amazon Redshift ML flexibility"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – Amazon Redshift ML flexibility</p>
			<p>In this chapter, we will provide an overview of the various types of <strong class="source-inline">CREATE MODEL</strong> statements. Subsequent chapters will provide in-depth examples of how to create all the different types of models, load the data to Redshift, and split your data into training and <span class="No-Break">testing datasets.</span></p>
			<p>In this section, we will <a id="_idIndexMarker192"/>walk you through the options available to create models and the optional parameters available that you can specify. All of the examples in this chapter are informational to prepare you for the remaining chapters. You will create your first model in <a href="B19071_05.xhtml#_idTextAnchor068"><span class="No-Break"><em class="italic">Chapter 5</em></span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor062"/>AUTO everything</h2>
			<p>When you execute a <strong class="source-inline">CREATE MODEL</strong> command to <a id="_idIndexMarker193"/>solve a supervised learning problem using <strong class="source-inline">AUTO</strong> everything, Amazon Redshift ML and Amazon SageMaker manage all the data preprocessing, model training, and model tuning for you. Data will be exported from Amazon Redshift to Amazon S3, where SageMaker will train and tune up to 100 models. <strong class="bold">SageMaker Autopilot</strong> will <a id="_idIndexMarker194"/>automatically determine the algorithm and problem type. The best-trained model is then compiled by SageMaker Neo and made available as a user-defined function in Amazon Redshift so that users can make predictions using <span class="No-Break">simple SQL.</span></p>
			<p>See the <a id="_idIndexMarker195"/>following syntax for an <strong class="source-inline">AUTO</strong> <span class="No-Break">everything model:</span></p>
			<pre class="source-code">
CREATE MODEL model_name
    FROM { table_name | ( select_query ) }
    TARGET column_name
    FUNCTION prediction_function_name
    IAM_ROLE { default }
    SETTINGS (
      S3_BUCKET 'bucket',
      [ MAX_CELLS integer ]
    )</pre>
			<p>You simply supply a table name or SQL statement for the data you want to use in training, along with the <strong class="source-inline">TARGET</strong> column that you are trying <span class="No-Break">to predict.</span></p>
			<p>Let’s apply this to a simple example. Let’s assume we have a table called <strong class="source-inline">reservation_history</strong> that contains hotel reservation data, and we want to determine whether guests are likely to cancel an <span class="No-Break">upcoming reservation:</span></p>
			<pre class="source-code">
CREATE TABLE reservation_history (
customerid bigint ,
city character varying(50),
reservation_date timestamp without time zone,
loyalty_program character (1),
age bigint,
marital_status character (1),
cancelled character (1)
)
DISTSTYLE AUTO;</pre>
			<p>The <strong class="source-inline">CREATE MODEL</strong> statement would look like this (note that this is informational; you do not need to <span class="No-Break">run this):</span></p>
			<pre class="source-code">
CREATE MODEL predict_guest_cancellation
    FROM reservation_history
    TARGET cancelled
    FUNCTION predict_cancelled_reservation
    IAM_ROLE default
    SETTINGS (
      S3_BUCKET '&lt;&lt;your-s3-bucket&gt;&gt;'
)</pre>
			<p>In this <strong class="source-inline">CREATE MODEL</strong> statement, we only provided the minimum required parameters, which are <strong class="source-inline">IAM_ROLE</strong> and <strong class="source-inline">S3_BUCKET</strong>. The <strong class="source-inline">TARGET</strong> parameter is <strong class="source-inline">cancelled</strong>, which is what we will try to predict, based on the input we send to the <strong class="source-inline">CREATE MODEL</strong> statement. In this example, we send everything from the <strong class="source-inline">reservation_history</strong> table. The <strong class="source-inline">FUNCTION</strong> name is a description of the function that will be used later for predictions. The <strong class="source-inline">IAM_ROLE</strong> parameter will be attached to your serverless endpoint and provides access <a id="_idIndexMarker196"/>to SageMaker and <a id="_idIndexMarker197"/>an <strong class="bold">S3</strong> bucket, which will contain the artifacts generated by your <strong class="source-inline">CREATE MODEL</strong> statement. Refer to <a href="B19071_02.xhtml#_idTextAnchor027"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, where we showed how to set up an <span class="No-Break">IAM role.</span></p>
			<p>Amazon SageMaker will automatically determine that this is a binary classification model, since our <strong class="source-inline">TARGET</strong> can only be one of two possible values. Amazon SageMaker will also choose the best model type. At the time of writing, the supported model types for supervised learning are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="source-inline">XGBoost</strong>: Based on the gradient-boosted <span class="No-Break">trees algorithm</span></li>
				<li><strong class="source-inline">Linear Learner</strong>: Provides an increase in speed to solve either classification or <span class="No-Break">regression problems</span></li>
				<li><strong class="source-inline">MLP</strong>: A deep learning algorithm using a <span class="No-Break">multilayer perceptron</span></li>
			</ul>
			<p>You will create models using each of these models in <span class="No-Break">subsequent chapters.</span></p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor063"/>AUTO with user guidance</h2>
			<p>More advanced users with a<a id="_idIndexMarker198"/> good understanding of ML may wish to provide more inputs to a model, such as <strong class="source-inline">model _type</strong>, <strong class="source-inline">problem_type</strong>, <strong class="source-inline">preprocesors</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">objective</strong></span><span class="No-Break">.</span></p>
			<p>Using our reservation example, we will build on the <strong class="source-inline">AUTO</strong> capabilities and specify a few <span class="No-Break">more parameters:</span></p>
			<ul>
				<li><strong class="source-inline">MODEL_TYPE</strong>:  <span class="No-Break"><strong class="source-inline">XGBoost</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">PROBLEM_TYPE</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">binary_classification</strong></span></li>
				<li><strong class="source-inline">Objective</strong>:  <span class="No-Break"><strong class="source-inline">F1</strong></span></li>
				<li><strong class="source-inline">S3_GARBAGE_COLLECT</strong> – <strong class="source-inline">OFF</strong>: If set to <strong class="source-inline">OFF</strong>, the resulting datasets used to train the models remain in Amazon S3 and can be used for other purposes, such <span class="No-Break">as troubleshooting</span></li>
				<li><strong class="source-inline">MAX_RUNTIME</strong> – <strong class="source-inline">1800</strong>: This is one way to control the costs of model training by limiting the training time to <strong class="source-inline">1800</strong> seconds; the default is <span class="No-Break"><strong class="source-inline">5400</strong></span><span class="No-Break"> seconds</span></li>
			</ul>
			<p>By specifying <strong class="source-inline">MODEL_TYPE</strong> and/or <strong class="source-inline">PROBLEM_TYPE</strong> along with the <strong class="source-inline">Objective</strong> parameters, you can shorten the amount of time needed to train a model, since SageMaker does not have to determine these. Here is an example of the <strong class="source-inline">CREATE </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> statement:</span></p>
			<pre class="source-code">
CREATE MODEL predict_guest_cancellation
    FROM reservation_history
    TARGET cancelled
    FUNCTION predict_cancelled_reservation
    IAM_ROLE default
    MODEL_TYPE XGBoost
    PROBLEM_TYPE BINARY CLASSIFICATION
    OBJECTIVE 'F1'
    SETTINGS (
      S3_BUCKET '&lt;&lt;your-S3-bucket&gt;&gt;',
      MAX_RUNTIME 1800
);</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">Increasing <strong class="source-inline">MAX_RUNTIME</strong> and <strong class="source-inline">MAX_CELLS</strong> often improves model quality by allowing SageMaker to explore more candidates. If you want faster iteration or exploration of your dataset, reduce <strong class="source-inline">MAX_RUNTIME</strong> and <strong class="source-inline">MAX_CELLS</strong>. If you want improved accuracy of models, increase <strong class="source-inline">MAX_RUNTIME</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">MAX_CELLS</strong></span><span class="No-Break">.</span></p>
			<p>It is a good practice to specify the problem type and objective, if known, to shorten training time. To improve model accuracy, provide more data if possible and include any features (input) that can influence the <span class="No-Break">target variable.</span></p>
			<p>Additionally, you can add your own preprocessors by specifying transformers. At the time of writing, Amazon Redshift ML supports 10 transformers including <strong class="source-inline">OneHotEncoder</strong>, <strong class="source-inline">Ordinal Encoder</strong>, and <strong class="source-inline">StandardScaler</strong>. You can find the complete list <span class="No-Break">here: </span><a href="https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_user_guidance_create_model"><span class="No-Break">https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_user_guidance_create_model</span></a><span class="No-Break">.</span></p>
			<p>Amazon <a id="_idIndexMarker199"/>Redshift ML stores the trained transformers and automatically applies them as part of the prediction query. You don’t need to specify them when generating predictions from <span class="No-Break">your model.</span></p>
			<p>Let’s take, as an example, using <strong class="source-inline">OneHotEncoder</strong>, which is used to convert a categorical value such as <strong class="source-inline">country</strong> or <strong class="source-inline">gender</strong> into a numeric value (binary vector) so that ML algorithms can better do predictions. Let’s create a model using one-hot encoding for our input columns, <strong class="source-inline">marital_status</strong> and <strong class="source-inline">loyalty_program</strong>. Note that this model is an example, and you do not need to run <span class="No-Break">this statement:</span></p>
			<pre class="source-code">
 CREATE MODEL predict_guest_cancellation
    FROM reservation_history
    TARGET cancelled
    FUNCTION predict_cancelled_reservation
    IAM_ROLE default
    MODEL_TYPE XGBoost
    PROBLEM_TYPE BINARY CLASSIFICATION
    OBJECTIVE 'F1'
    PREPROCESSORS '[
      {"ColumnSet": [
        "loyalty_program",
        "marital_status"
        ],
        "Transformers" :[
           "OneHotEncoder"
            ]
         ]
        }
     ]'
    SETTINGS (
      S3_BUCKET '&lt;&lt;your-S3-bucket&gt;&gt;',
      MAX_RUNTIME 1800
);</pre>
			<p>So far, all<a id="_idIndexMarker200"/> the <strong class="source-inline">CREATE MODEL</strong> examples we showed use <strong class="source-inline">AUTO ON</strong>. This is the default if you do not specify this parameter. Now, let’s move on to how you can do your own model tuning using <strong class="source-inline">AUTO OFF</strong> <span class="No-Break">with XGBoost.</span></p>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor064"/>XGBoost (AUTO OFF)</h2>
			<p>As an ML expert, you have the option to do <a id="_idIndexMarker201"/>hyperparameter tuning by using the <strong class="source-inline">AUTO OFF</strong> option with the <strong class="source-inline">CREATE MODEL</strong> statement. This gives you full control and Amazon Redshift ML does not attempt to discover the optimal preprocessors, algorithms, <span class="No-Break">and hyperparameters.</span></p>
			<p>Let’s see what the <strong class="source-inline">CREATE MODEL</strong> syntax looks like using our example <span class="No-Break">reservation dataset.</span></p>
			<p>We will specify the <span class="No-Break">following parameters:</span></p>
			<ul>
				<li><strong class="source-inline">AUTO OFF</strong>: Turns off the automatic discovery of a preprocessor, an algorithm, <span class="No-Break">and hyperparameters</span></li>
				<li><span class="No-Break"><strong class="source-inline">MODEL_TYPE</strong></span><span class="No-Break">:- </span><span class="No-Break"><strong class="source-inline">xgboost</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">OBJECTIVE</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">'binary:logistic'</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">PREPROCESSORS</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">'none'</strong></span></li>
				<li><strong class="source-inline">HYPERPARAMETERS</strong>: <strong class="source-inline">DEFAULT </strong><span class="No-Break"><strong class="source-inline">EXCEPT(NUM_ROUND '100'/)</strong></span></li>
			</ul>
			<p>Refer here for a list of hyperparameters for <span class="No-Break">XGBoost: </span><a href="https://docs.amazonaws.cn/en_us/redshift/latest/dg/"><span class="No-Break">https://docs.amazonaws.cn/en_us/redshift/latest/dg/</span></a><span class="No-Break">:</span></p>
			<pre class="source-code">
r_create_model_use_cases.html#r_auto_off_create_model</pre>
			<p>As of this writing, <strong class="source-inline">'none'</strong> is the only available option to specify for <strong class="source-inline">PREPROCESSORS</strong> when using <strong class="source-inline">AUTO OFF</strong>.  Since we cannot specify one-hot encoding, we can use a case statement with our SQL to <span class="No-Break">apply this:</span></p>
			<pre class="source-code">
CREATE MODEL predict guest_cancellation
    FROM
        (Select customerid,
       city,
       reservation_date,
       case when loyalty_program = 'Y' then 1 else 0 end as loyalty_program_y,
       case when loyalty_program = 'N' then 1 else 0 end as loyalty_program_n,
       age,
       case when marital_status = 'Y' then 1 else 0 end as married,
       case when marital_status = 'N' then 1 else 0 end as not_married,
       cancelled
       from reservation_hitory)
    TARGET cancelled
    FUNCTION predict_cancelled_reservation
    IAM_ROLE default
    AUTO OFF
    MODEL_TYPE XGBoost
    OBJECTIVE 'binary:logistic'
    PREPROCESSORS 'none'
    HYPERPARAMETERS DEFAULT EXCEPT (NUM_ROUND '100')
    SETTINGS (
      S3_BUCKET 'bucket',
      MAX_RUNTIME 1800
);</pre>
			<p>In <a href="B19071_10.xhtml#_idTextAnchor178"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, you will build an<a id="_idIndexMarker202"/> XGBoost model using <strong class="source-inline">AUTO OFF</strong> and gain a better understanding of <span class="No-Break">this option.</span></p>
			<p>Now, let’s take a look at another <strong class="source-inline">AUTO OFF</strong> option using the <span class="No-Break">K-means algorithm.</span></p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor065"/>K-means (AUTO OFF)</h2>
			<p>The K-means algorithm is used to group<a id="_idIndexMarker203"/> data together that isn’t labeled. Since this algorithm discovers groupings in your data, it solves an “<em class="italic">unsupervised</em>” <span class="No-Break">learning problem.</span></p>
			<p>Let’s see what a sample <strong class="source-inline">CREATE MODEL</strong> looks like if we want to group our <span class="No-Break"><strong class="source-inline">reservation_history</strong></span><span class="No-Break"> data:</span></p>
			<ul>
				<li><strong class="source-inline">AUTO OFF</strong>: Turns off the automatic discovery of a preprocessor, an algorithm, <span class="No-Break">and hyperparameters</span></li>
				<li><span class="No-Break"><strong class="source-inline">MODEL_TYPE</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">KMEANS</strong></span></li>
				<li><strong class="source-inline">PREPROCESSORS</strong>: <strong class="source-inline">OPTIONAL</strong> (at the time of writing, Amazon Redshift supports <strong class="source-inline">StandScaler</strong>, <strong class="source-inline">MinMax</strong>, and <strong class="source-inline">NumericPassthrough</strong> <span class="No-Break">for </span><span class="No-Break"><strong class="source-inline">KMEANS</strong></span><span class="No-Break">)</span></li>
				<li><strong class="source-inline">HYPERPARAMETERS</strong>: <strong class="source-inline">DEFAULT EXCEPT (K 'N')</strong>, where <strong class="source-inline">N</strong> is the number of clusters you want <span class="No-Break">to create</span></li>
			</ul>
			<p>Here is an example of a <strong class="source-inline">CREATE MODE</strong><strong class="source-inline">L</strong> statement. Note that you will not run <span class="No-Break">this statement:</span></p>
			<pre class="source-code">
CREATE MODEL guest_clusters
    FROM
        (Select
        city,
        reservation_date,
        loyalty_program,
        age,
        marital_status
        from reservation_hitory)
    FUNCTION get_guest_clusters
    IAM_ROLE default
    AUTO OFF
    MODEL_TYPE KMEANS
    PREPROCESSORS 'none'
    HYPERPARAMETERS DEFAULT
    EXCEPT (K '5')
    SETTINGS (
      S3_BUCKET '&lt;&lt;your-S3-bucket&gt;&gt;'
);</pre>
			<p>Note that we are<a id="_idIndexMarker204"/> creating five clusters with this model. With the K-means algorithm, it is important to experiment with a different number of clusters. In <a href="B19071_08.xhtml#_idTextAnchor139"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, you will get to dive deep into creating K-means models and determining how to validate the <span class="No-Break">optimal clusters.</span></p>
			<p>Now, let’s take a look at how you can run prediction queries using models built outside of Amazon <span class="No-Break">Redshift ML.</span></p>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor066"/>BYOM</h2>
			<p>Additionally, you can <a id="_idIndexMarker205"/>use a model trained outside of Amazon Redshift with Amazon SageMaker for either local or remote inference<a id="_idIndexMarker206"/> in <span class="No-Break">Amazon Redshift.</span></p>
			<h3>Local inference</h3>
			<p>Local inference<a id="_idIndexMarker207"/> is used when<a id="_idIndexMarker208"/> models are trained outside of Redshift in Amazon SageMaker. This allows you to run inference queries inside of Amazon Redshift without having to retrain <span class="No-Break">a model.</span></p>
			<p>Let’s suppose our previous example of building a model to predict whether a customer will cancel a reservation was trained outside of Amazon Redshift. We can bring that model to Redshift and then run <span class="No-Break">inference queries.</span></p>
			<p>Our <strong class="source-inline">CREATE MODEL</strong> sample will look <span class="No-Break">like this:</span></p>
			<ul>
				<li><strong class="source-inline">model_name</strong>: This is the name you wish to give the local model <span class="No-Break">in Redshift</span></li>
				<li><strong class="source-inline">FROM</strong>: This is <strong class="source-inline">job_name</strong> from Amazon SageMaker – you can find this in Amazon SageMaker under <span class="No-Break"><strong class="bold">Training Jobs</strong></span></li>
				<li><strong class="source-inline">FUNCTION</strong>: The name of the function to be created along with the input <span class="No-Break">data types</span></li>
				<li><strong class="source-inline">RETURNS</strong>: The data type of the value returned by <span class="No-Break">the function:</span><pre class="source-code">
CREATE MODEL predict_guest_cancellation_local_inf</pre><pre class="source-code">
    FROM 'sagemaker_job_name'</pre><pre class="source-code">
    FUNCTION predict_cancelled_reservation_local(bigint, varchar, timestamp, char, bigint, char)</pre><pre class="source-code">
    RETURNS char</pre><pre class="source-code">
    IAM_ROLE default</pre><pre class="source-code">
    SETTINGS (</pre><pre class="source-code">
      S3_BUCKET '&lt;&lt;your-S3-bucket&gt;&gt;' );</pre></li>
			</ul>
			<p>Note that the data<a id="_idIndexMarker209"/> types in <strong class="source-inline">FUNCTION</strong> match the data types from our <strong class="source-inline">reservation_history</strong> table, and <strong class="source-inline">RETURNS</strong> matches the data type of our <strong class="source-inline">TARGET</strong> variable, which <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">cancelled</strong></span><span class="No-Break">.</span></p>
			<p>You can derive the SageMaker <strong class="source-inline">JobName</strong> by navigating to the AWS Management Console and going <span class="No-Break">to SageMaker:</span></p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B19071_04_003.jpg" alt="Figure 4.3 – Console Home"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – Console Home</p>
			<p>After clicking on<a id="_idIndexMarker210"/> <strong class="bold">Amazon SageMaker</strong>, click on <strong class="bold">Training jobs</strong>, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.4:</em></span></p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B19071_04_004.jpg" alt="Figure 4.4 – Training jobs"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.4 – Training jobs</p>
			<p>Next, note the<a id="_idIndexMarker211"/> job name of the model you wish to use for local inference, which is what you will put in your <strong class="source-inline">CREATE MODEL</strong> statement (see <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B19071_04_005.jpg" alt="Figure 4.5 – The training job name"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.5 – The training job name</p>
			<h3>Remote inference</h3>
			<p>Remote inference <a id="_idIndexMarker212"/>is useful if you have a model created in SageMaker for an algorithm that is not available natively in Amazon Redshift ML. For example, anomaly detection can be done using the Random Cut Forest algorithm from SageMaker. You can create a model that references the endpoint of the SageMaker model and then be able to run anomaly detection in <a id="_idIndexMarker213"/><span class="No-Break">Amazon Redshift.</span></p>
			<p>Our <strong class="source-inline">CREATE MODEL</strong> sample will look <span class="No-Break">like this:</span></p>
			<ul>
				<li><strong class="source-inline">model_name</strong>: The name you wish to give the local model <span class="No-Break">in Redshift</span></li>
				<li><strong class="source-inline">FUNCTION</strong>: The name of the function to be created along with the input <span class="No-Break">data types</span></li>
				<li><strong class="source-inline">RETURNS</strong>: The data type of the value returned by <span class="No-Break">the function</span></li>
				<li><strong class="source-inline">SAGEMAKER</strong>: The name of the Amazon <span class="No-Break">SageMaker endpoint:</span></li>
			</ul>
			<pre class="source-code">
CREATE MODEL random_cut_forest
FUNCTION remote_fn_rcf(int)
RETURNS decimal(10,6)
SAGEMAKER 'sagemaker_endpoint'
IAM_ROLE  default;</pre>
			<p>Note that the data types in <strong class="source-inline">FUNCTION</strong> are for the input we send, and <strong class="source-inline">RETURNS</strong> is the data type of the data we receive when invoking <span class="No-Break">the function.</span></p>
			<p>You can derive the<a id="_idIndexMarker214"/> SageMaker endpoint by navigating to the AWS Management Console, going to SageMaker, and then clicking <span class="No-Break">on </span><span class="No-Break"><strong class="bold">Endpoints</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B19071_04_006.jpg" alt="Figure 4.6 – Endpoints"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.6 – Endpoints</p>
			<p>After you click on <strong class="bold">Endpoints</strong>, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.6</em>, you can see the endpoint names, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">:</span></p>
			<p class="IMG---Figure">  </p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B19071_04_007.jpg" alt="Figure 4.7 – The endpoint names"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.7 – The endpoint names</p>
			<p>Then, note the<a id="_idIndexMarker215"/> name of the endpoint for the model you wish to use for remote inference and put it in your <strong class="source-inline">CREATE </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> statement.</span></p>
			<p>You will dive deep into BYOM in <a href="B19071_11.xhtml#_idTextAnchor192"><span class="No-Break"><em class="italic">Chapter 11</em></span></a> and get hands-on experience creating models for both local and <span class="No-Break">remote inference.</span></p>
			<h1 id="_idParaDest-66"><a id="_idTextAnchor067"/>Summary</h1>
			<p>In this chapter, we discussed why Amazon Redshift ML is a good choice to use data in your data warehouse to <span class="No-Break">make predictions.</span></p>
			<p>By bringing ML to your data warehouse, Amazon Redshift ML enables you to greatly shorten the amount of time to create and train models by putting the power of ML directly in the hands of your developers, data analysts, and <span class="No-Break">BI professionals.</span></p>
			<p>Your data remains secure; it never leaves your VPC. Plus, you can easily control access to create and <span class="No-Break">use models.</span></p>
			<p>Finally, we showed you different methods of creating models in Redshift ML, such as using <strong class="source-inline">AUTO</strong>, how to guide model training, and an advanced method to <span class="No-Break">supply hyperparameters.</span></p>
			<p>Now, you understand how ML fits into your data warehouse, how to use proper security and configuration guidelines with Redshift ML, and how a model is trained in <span class="No-Break">Amazon SageMaker.</span></p>
			<p>In the next chapter, you will get hands-on and create your first model using Amazon Redshift ML, learn how to validate the model, and learn how to run an <span class="No-Break">inference query.</span></p>
		</div>
	</body></html>