<html xml:lang="en-US" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<meta charset="utf-8"/>
<meta content="pandoc" name="generator"/>
<title>ch021.xhtml</title>
<link href="../styles/stylesheet1.css" rel="stylesheet" type="text/css"/>
<!-- kobo-style -->
<style id="koboSpanStyle" type="text/css" xmlns="http://www.w3.org/1999/xhtml">.koboSpan { -webkit-text-combine: inherit; }</style>
</head>
<body epub:type="bodymatter">
<section class="level1 chapterHead" data-number="20" id="chapter-12-quantum-generative-adversarial-networks">
<h1 class="H1---Chapter chapterHead" data-number="20"><span class="titlemark"><span class="koboSpan" id="kobo.1.1" xmlns="http://www.w3.org/1999/xhtml">Chapter 12</span></span><br/>
<span id="x1-21200012"><span class="koboSpan" id="kobo.2.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Generative Adversarial Networks</span></span></h1>
<div class="flushright">
<p><em><span class="koboSpan" id="kobo.3.1" xmlns="http://www.w3.org/1999/xhtml">Fake it ‘till you make it</span></em><br/><span class="koboSpan" id="kobo.4.1" xmlns="http://www.w3.org/1999/xhtml">
— Someone, somewhere</span></p>
</div>
<p><span class="koboSpan" id="kobo.5.1" xmlns="http://www.w3.org/1999/xhtml">So far, we have only dealt with quantum machine learning models in the context of supervised learning. </span><span class="koboSpan" id="kobo.5.2" xmlns="http://www.w3.org/1999/xhtml">In this final chapter of our QML journey, we will discuss the wonders and mysteries of a QML model that will lead us into the domain of unsupervised learning. </span><span class="koboSpan" id="kobo.5.3" xmlns="http://www.w3.org/1999/xhtml">We will discuss quantum </span><span id="dx1-212001"/><span class="koboSpan" id="kobo.6.1" xmlns="http://www.w3.org/1999/xhtml">versions of the famous </span><strong><span class="koboSpan" id="kobo.7.1" xmlns="http://www.w3.org/1999/xhtml">Generative Adversarial Networks</span></strong><span class="koboSpan" id="kobo.8.1" xmlns="http://www.w3.org/1999/xhtml"> (often abbreviated as </span><strong><span class="koboSpan" id="kobo.9.1" xmlns="http://www.w3.org/1999/xhtml">GANs</span></strong><span class="koboSpan" id="kobo.10.1" xmlns="http://www.w3.org/1999/xhtml">) that are </span><span id="dx1-212002"/><span class="koboSpan" id="kobo.11.1" xmlns="http://www.w3.org/1999/xhtml">called </span><strong><span class="koboSpan" id="kobo.12.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Generative Adversarial Networks</span></strong><span class="koboSpan" id="kobo.13.1" xmlns="http://www.w3.org/1999/xhtml">, </span><strong><span class="koboSpan" id="kobo.14.1" xmlns="http://www.w3.org/1999/xhtml">quantum GANs</span></strong><span class="koboSpan" id="kobo.15.1" xmlns="http://www.w3.org/1999/xhtml">, or </span><strong><span class="koboSpan" id="kobo.16.1" xmlns="http://www.w3.org/1999/xhtml">QGANs</span></strong><span class="koboSpan" id="kobo.17.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.18.1" xmlns="http://www.w3.org/1999/xhtml">In this chapter, you will learn what classical and quantum GANs are, what they are useful for, and how they can be used. </span><span class="koboSpan" id="kobo.18.2" xmlns="http://www.w3.org/1999/xhtml">We will begin from the basics, exploring the intuitive ideas that lead to the concept of a GAN. </span><span class="koboSpan" id="kobo.18.3" xmlns="http://www.w3.org/1999/xhtml">Then, we will get into some of the details and discuss QGANs. </span><span class="koboSpan" id="kobo.18.4" xmlns="http://www.w3.org/1999/xhtml">In particular, we will talk about the different types of QGANs out there and their (possible) advantages. </span><span class="koboSpan" id="kobo.18.5" xmlns="http://www.w3.org/1999/xhtml">You will also learn how to work with them using PennyLane (with its TensorFlow interface) and Qiskit.</span></p>
<p><span class="koboSpan" id="kobo.19.1" xmlns="http://www.w3.org/1999/xhtml">We’ll cover the following topics in this chapter:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.20.1" xmlns="http://www.w3.org/1999/xhtml">GANs and their quantum counterparts</span></p></li>
<li><p><span class="koboSpan" id="kobo.21.1" xmlns="http://www.w3.org/1999/xhtml">Quantum GANs in PennyLane</span></p></li>
<li><p><span class="koboSpan" id="kobo.22.1" xmlns="http://www.w3.org/1999/xhtml">Quantum GANs in Qiskit</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.23.1" xmlns="http://www.w3.org/1999/xhtml">Excited about this last chapter? </span><span class="koboSpan" id="kobo.23.2" xmlns="http://www.w3.org/1999/xhtml">Let’s begin by understanding what these GANs are all about.</span></p>
<section class="level2 sectionHead" data-number="20.1" id="gans-and-their-quantum-counterparts">
<h1 class="sectionHead" data-number="20.1"><span class="titlemark"><span class="koboSpan" id="kobo.24.1" xmlns="http://www.w3.org/1999/xhtml">12.1 </span></span> <span id="x1-21300012.1"><span class="koboSpan" id="kobo.25.1" xmlns="http://www.w3.org/1999/xhtml">GANs and their quantum counterparts</span></span></h1>
<p><span class="koboSpan" id="kobo.26.1" xmlns="http://www.w3.org/1999/xhtml">Quantum GANs are </span><strong><span class="koboSpan" id="kobo.27.1" xmlns="http://www.w3.org/1999/xhtml">generative models</span></strong><span class="koboSpan" id="kobo.28.1" xmlns="http://www.w3.org/1999/xhtml"> that can be </span><span id="dx1-213001"/><span class="koboSpan" id="kobo.29.1" xmlns="http://www.w3.org/1999/xhtml">trained in a perfectly unsupervised manner. </span><span class="koboSpan" id="kobo.29.2" xmlns="http://www.w3.org/1999/xhtml">By the fact that they are generative models we mean that quantum GANs will be useful for generating data that can mimic a training dataset; for instance, if you had a large dataset with pictures of people, a good generative model would be able to generate new pictures of people that would be indiscernible from those coming from the original distribution. </span><span class="koboSpan" id="kobo.29.3" xmlns="http://www.w3.org/1999/xhtml">The fact that QGANs can be trained in an unsupervised fashion simply means that our datasets will not have to be labeled; we won’t have to tell the generator whether its output is good or bad, the model will figure that out on its own. </span><span class="koboSpan" id="kobo.29.4" xmlns="http://www.w3.org/1999/xhtml">How exactly? </span><span class="koboSpan" id="kobo.29.5" xmlns="http://www.w3.org/1999/xhtml">Stay tuned!</span></p>
<p><span class="koboSpan" id="kobo.30.1" xmlns="http://www.w3.org/1999/xhtml">That’s the big picture of GANs, but, before we can explore all their details, there’s something we need to talk about. </span><span class="koboSpan" id="kobo.30.2" xmlns="http://www.w3.org/1999/xhtml">Let’s talk about how to counterfeit money.</span></p>
<section class="level3 subsectionHead" data-number="20.1.1" id="a-seemingly-unrelated-story-about-money">
<h2 class="subsectionHead" data-number="20.1.1"><span class="titlemark"><span class="koboSpan" id="kobo.31.1" xmlns="http://www.w3.org/1999/xhtml">12.1.1 </span></span> <span id="x1-21400012.1.1"><span class="koboSpan" id="kobo.32.1" xmlns="http://www.w3.org/1999/xhtml">A seemingly unrelated story about money</span></span></h2>
<p><span class="koboSpan" id="kobo.33.1" xmlns="http://www.w3.org/1999/xhtml">Of course, all of us reading these lines are law-abiding citizens — no need to call the police just now — but, for the purposes of intellectual illustration, let’s put ourselves in the place of the bad guys for one day. </span><span class="koboSpan" id="kobo.33.2" xmlns="http://www.w3.org/1999/xhtml">In the process of </span><span id="dx1-214001"/><span class="koboSpan" id="kobo.34.1" xmlns="http://www.w3.org/1999/xhtml">counterfeiting money, there are two main actors involved:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.35.1" xmlns="http://www.w3.org/1999/xhtml">We, the bad guys who create (generate) counterfeit money, trying to make it as close to the real thing as possible</span></p></li>
<li><p><span class="koboSpan" id="kobo.36.1" xmlns="http://www.w3.org/1999/xhtml">Some authority, usually a central bank, which is in charge of designing tools and techniques to discern real money from counterfeit money</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.37.1" xmlns="http://www.w3.org/1999/xhtml">This is shown in </span><em><span class="koboSpan" id="kobo.38.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.1"><em><span class="koboSpan" id="kobo.39.1" xmlns="http://www.w3.org/1999/xhtml">12.1</span></em></a><span class="koboSpan" id="kobo.40.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.40.2" xmlns="http://www.w3.org/1999/xhtml">By the way, we have drawn the fake dollar ourselves. </span><span class="koboSpan" id="kobo.40.3" xmlns="http://www.w3.org/1999/xhtml">Graphic design is our passion.</span></p>
<figure>
<span class="koboSpan" id="kobo.41.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 12.1: Schematic representation of the agents involved in the generation of counterfeit money" src="../media/file1438.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure12.1"><strong><span class="koboSpan" id="kobo.42.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.1</span></strong><span class="koboSpan" id="kobo.43.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.44.1" xmlns="http://www.w3.org/1999/xhtml">Schematic representation of the agents involved in the generation of counterfeit money</span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.45.1" xmlns="http://www.w3.org/1999/xhtml">Now that we are all set, we can imagine what our counterfeiting career could look like. </span><span class="koboSpan" id="kobo.45.2" xmlns="http://www.w3.org/1999/xhtml">Since none of us has any experience in this field, our first attempts at faking banknotes would be extremely disastrous: any of our generated banknotes would be very easily identified as fake by the central bank. </span><span class="koboSpan" id="kobo.45.3" xmlns="http://www.w3.org/1999/xhtml">However, that would just be the beginning of the story. </span><span class="koboSpan" id="kobo.45.4" xmlns="http://www.w3.org/1999/xhtml">Along the process — and assuming we didn’t get arrested — we could always try to study how the central bank is discerning real notes from counterfeit ones and use it to our advantage by trying to fool its detection mechanisms. </span><span class="koboSpan" id="kobo.45.5" xmlns="http://www.w3.org/1999/xhtml">Naturally, however, that would only be a temporary solution, for it wouldn’t take long for the central bank to notice our improved fake notes and design better detection systems, which would take us back to the drawing board, starting the process all over again.</span></p>
<p><span class="koboSpan" id="kobo.46.1" xmlns="http://www.w3.org/1999/xhtml">Banknotes have a finite </span><span id="dx1-214004"/><span class="koboSpan" id="kobo.47.1" xmlns="http://www.w3.org/1999/xhtml">amount of defining features, so, after a large enough number of iterations of this process, at some point, we would likely end up producing banknotes that would be identical to the real ones. </span><span class="koboSpan" id="kobo.47.2" xmlns="http://www.w3.org/1999/xhtml">And, thus, a beautiful equilibrium would be reached in which the central bank would no longer be able to detect our fake notes. </span><span class="koboSpan" id="kobo.47.3" xmlns="http://www.w3.org/1999/xhtml">Sadly for us, this adventure would most surely end with the central bank changing the notes completely and sending us before a judge. </span><span class="koboSpan" id="kobo.47.4" xmlns="http://www.w3.org/1999/xhtml">But let’s ignore those tiny details!</span></p>
<div class="tcolorbox important" id="tcolobox-209">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.48.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.49.1" xmlns="http://www.w3.org/1999/xhtml">Just in case it wasn’t obvious, we are joking when we talk about imagining ourselves doing counterfeiting. </span><span class="koboSpan" id="kobo.49.2" xmlns="http://www.w3.org/1999/xhtml">Counterfeiting money is, as you hopefully know, a serious criminal offense that we, of course, don’t encourage or endorse in any way. </span><span class="koboSpan" id="kobo.49.3" xmlns="http://www.w3.org/1999/xhtml">Please, don’t do illegal stuff. </span><span class="koboSpan" id="kobo.49.4" xmlns="http://www.w3.org/1999/xhtml">The editorial team thought — with good reason! </span><span class="koboSpan" id="kobo.49.5" xmlns="http://www.w3.org/1999/xhtml">— that this was worth a disclaimer; so here it is!</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.50.1" xmlns="http://www.w3.org/1999/xhtml">Now, you may wonder why we have discussed this. </span><span class="koboSpan" id="kobo.50.2" xmlns="http://www.w3.org/1999/xhtml">Well, because, as it turns out, the process of training a GAN is just like that of counterfeiting money — minus the risk of ending up in prison. </span><span class="koboSpan" id="kobo.50.3" xmlns="http://www.w3.org/1999/xhtml">Let’s see how it works!</span></p>
</section>
<section class="level3 subsectionHead" data-number="20.1.2" id="what-actually-is-a-gan">
<h2 class="subsectionHead" data-number="20.1.2"><span class="titlemark"><span class="koboSpan" id="kobo.51.1" xmlns="http://www.w3.org/1999/xhtml">12.1.2 </span></span> <span id="x1-21500012.1.2"><span class="koboSpan" id="kobo.52.1" xmlns="http://www.w3.org/1999/xhtml">What actually is a GAN?</span></span></h2>
<p><span class="koboSpan" id="kobo.53.1" xmlns="http://www.w3.org/1999/xhtml">GANs were </span><span id="dx1-215001"/><span class="koboSpan" id="kobo.54.1" xmlns="http://www.w3.org/1999/xhtml">introduced in 2014 in a very influential paper </span><span class="cite"><span class="koboSpan" id="kobo.55.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xgoodfellow2014generative"><span class="koboSpan" id="kobo.56.1" xmlns="http://www.w3.org/1999/xhtml">46</span></a><span class="koboSpan" id="kobo.57.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.58.1" xmlns="http://www.w3.org/1999/xhtml"> by Goodfellow et al. </span><span class="koboSpan" id="kobo.58.2" xmlns="http://www.w3.org/1999/xhtml">As we mentioned in the introduction, a GAN is a machine learning model that can be trained to generate data closely reassembling the patterns and properties of a given dataset. </span><span class="koboSpan" id="kobo.58.3" xmlns="http://www.w3.org/1999/xhtml">In order to accomplish this, a GAN has two main components:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.59.1" xmlns="http://www.w3.org/1999/xhtml">A ”generative” neural </span><span id="dx1-215002"/><span class="koboSpan" id="kobo.60.1" xmlns="http://www.w3.org/1999/xhtml">network (generator), which will be nothing more than a neural network taking arbitrary seeds as input and returning outputs that match the datatype of the elements in the original dataset. </span><span class="koboSpan" id="kobo.60.2" xmlns="http://www.w3.org/1999/xhtml">The goal of this neural network will be, by the end of the training, to generate new data that be indistinguishable from the data in the original dataset.</span></p></li>
<li><p><span class="koboSpan" id="kobo.61.1" xmlns="http://www.w3.org/1999/xhtml">A </span><span id="dx1-215003"/><span class="koboSpan" id="kobo.62.1" xmlns="http://www.w3.org/1999/xhtml">discriminator neural network, which will be a binary-classifier neural network taking as input the original data in the dataset and the output of the generative network. </span><span class="koboSpan" id="kobo.62.2" xmlns="http://www.w3.org/1999/xhtml">This discriminator network will be tasked with trying to discern the generated data from the original data.</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.63.1" xmlns="http://www.w3.org/1999/xhtml">These components are depicted in </span><em><span class="koboSpan" id="kobo.64.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.2"><em><span class="koboSpan" id="kobo.65.1" xmlns="http://www.w3.org/1999/xhtml">12.2</span></em></a><span class="koboSpan" id="kobo.66.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.66.2" xmlns="http://www.w3.org/1999/xhtml">By the way, we have drawn the fake tree ourselves. </span><span class="koboSpan" id="kobo.66.3" xmlns="http://www.w3.org/1999/xhtml">Graphic design is our passion.</span></p>
<figure>
<span class="koboSpan" id="kobo.67.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 12.2: Schematic representation of the agents involved in a generative adversarial network" src="../media/file1439.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure12.2"><strong><span class="koboSpan" id="kobo.68.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.2</span></strong><span class="koboSpan" id="kobo.69.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.70.1" xmlns="http://www.w3.org/1999/xhtml">Schematic representation of the agents involved in a generative adversarial network</span></figcaption>
</figure>
<div class="tcolorbox learnmore" id="tcolobox-210">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.71.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.72.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.73.1" xmlns="http://www.w3.org/1999/xhtml">GANs have been very successfully used in practical generative tasks. </span><span class="koboSpan" id="kobo.73.2" xmlns="http://www.w3.org/1999/xhtml">For instance, StyleGANs are GANs introduced by NVIDIA researchers </span><span class="cite"><span class="koboSpan" id="kobo.74.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xkarras2019style"><span class="koboSpan" id="kobo.75.1" xmlns="http://www.w3.org/1999/xhtml">57</span></a><span class="koboSpan" id="kobo.76.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.77.1" xmlns="http://www.w3.org/1999/xhtml"> that are able to generate extremely realistic human faces. </span><span class="koboSpan" id="kobo.77.2" xmlns="http://www.w3.org/1999/xhtml">Their code is open source (you can find it at </span><a class="url" href="https://github.com/NVlabs/stylegan"><span class="koboSpan" id="kobo.78.1" xmlns="http://www.w3.org/1999/xhtml">https://github.com/NVlabs/stylegan</span></a><span class="koboSpan" id="kobo.79.1" xmlns="http://www.w3.org/1999/xhtml">) and they power the mesmerizing website ”This Person Does Not Exist” (</span><a class="url" href="https://www.thispersondoesnotexist.com/"><span class="koboSpan" id="kobo.80.1" xmlns="http://www.w3.org/1999/xhtml">https://www.thispersondoesnotexist.com/</span></a><span class="koboSpan" id="kobo.81.1" xmlns="http://www.w3.org/1999/xhtml">).</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.82.1" xmlns="http://www.w3.org/1999/xhtml">This description settles the question of what a GAN is, but now we need to understand how these GANs are actually trained. </span><span class="koboSpan" id="kobo.82.2" xmlns="http://www.w3.org/1999/xhtml">In essence, this is how the whole </span><span id="dx1-215006"/><span class="koboSpan" id="kobo.83.1" xmlns="http://www.w3.org/1999/xhtml">training process works:</span></p>
<ol>
<li><div id="x1-215008x1">
<p><span class="koboSpan" id="kobo.84.1" xmlns="http://www.w3.org/1999/xhtml">You initialize the generator and the discriminator to some random configuration.</span></p>
</div></li>
<li><div id="x1-215010x2">
<p><span class="koboSpan" id="kobo.85.1" xmlns="http://www.w3.org/1999/xhtml">You train the discriminator to discern the real data from the output of the generator. </span><span class="koboSpan" id="kobo.85.2" xmlns="http://www.w3.org/1999/xhtml">At this initial stage, this should be a very easy task for the discriminator.</span></p>
</div></li>
<li><div id="x1-215012x3">
<p><span class="koboSpan" id="kobo.86.1" xmlns="http://www.w3.org/1999/xhtml">You then train the generator to fool the discriminator: you train it in a way that the discriminator — as trained in the previous step — will classify as many of the generated outputs as real. </span><span class="koboSpan" id="kobo.86.2" xmlns="http://www.w3.org/1999/xhtml">Once trained, you use it to generate a bunch of fake data.</span></p>
</div></li>
<li><div id="x1-215014x4">
<p><span class="koboSpan" id="kobo.87.1" xmlns="http://www.w3.org/1999/xhtml">And here is where the fun begins. </span><span class="koboSpan" id="kobo.87.2" xmlns="http://www.w3.org/1999/xhtml">You re-train the discriminator on the new generated dataset, and then you re-train the generator to fool the new discriminator. </span><span class="koboSpan" id="kobo.87.3" xmlns="http://www.w3.org/1999/xhtml">And you repeat this process in as many </span><span id="dx1-215015"/><span class="koboSpan" id="kobo.88.1" xmlns="http://www.w3.org/1999/xhtml">iterations as you want. </span><span class="koboSpan" id="kobo.88.2" xmlns="http://www.w3.org/1999/xhtml">Ideally, in each iteration, it will be harder for the discriminator to tell the generated data from the real data. </span><span class="koboSpan" id="kobo.88.3" xmlns="http://www.w3.org/1999/xhtml">And, eventually, an equilibrium will be reached in which the generated data will be indiscernible from the original data. </span><span class="koboSpan" id="kobo.88.4" xmlns="http://www.w3.org/1999/xhtml">Just like in our previous counterfeiting adventure — and with no legal troubles on the horizon!</span></p>
</div></li>
</ol>
<p><span class="koboSpan" id="kobo.89.1" xmlns="http://www.w3.org/1999/xhtml">This process is exemplified schematically in </span><em><span class="koboSpan" id="kobo.90.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.3"><em><span class="koboSpan" id="kobo.91.1" xmlns="http://www.w3.org/1999/xhtml">12.3</span></em></a><span class="koboSpan" id="kobo.92.1" xmlns="http://www.w3.org/1999/xhtml">, where we present a schematic illustration of the training process of a GAN meant to generate pictures of cute cats. </span><span class="koboSpan" id="kobo.92.2" xmlns="http://www.w3.org/1999/xhtml">When the GAN is initialized, the generator just produces random noise. </span><span class="koboSpan" id="kobo.92.3" xmlns="http://www.w3.org/1999/xhtml">After subsequent training iterations, the output of the generator will more closely resemble the images in the original dataset — which, in this example, should be a dataset with pictures of cats. </span><span class="koboSpan" id="kobo.92.4" xmlns="http://www.w3.org/1999/xhtml">By the way, we have drawn the fake cats ourselves. </span><span class="koboSpan" id="kobo.92.5" xmlns="http://www.w3.org/1999/xhtml">Have we mentioned that graphic design is our passion?</span></p>
<p><span class="koboSpan" id="kobo.93.1" xmlns="http://www.w3.org/1999/xhtml">We should highlight that this scheme is very oversimplified. </span><span class="koboSpan" id="kobo.93.2" xmlns="http://www.w3.org/1999/xhtml">In truth, you usually don’t ”fully” train the discriminator and the generator alternately, but you optimize them in an alternate fashion. </span><span class="koboSpan" id="kobo.93.3" xmlns="http://www.w3.org/1999/xhtml">For example, if you were using gradient descent with a given batch size, then, on each epoch and on each batch, you would optimize the weights of the discriminator in a single optimizer step, and then you would do the same for the weights of the generator.</span></p>
<figure>
<span class="koboSpan" id="kobo.94.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 12.3: Schematic illustration of the training process of a GAN meant to generate pictures of cute cats " src="../media/file1440.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure12.3"><strong><span class="koboSpan" id="kobo.95.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.3</span></strong><span class="koboSpan" id="kobo.96.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.97.1" xmlns="http://www.w3.org/1999/xhtml">Schematic illustration of the training process of a GAN meant to generate pictures of cute cats </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.98.1" xmlns="http://www.w3.org/1999/xhtml">With this description of the </span><span id="dx1-215018"/><span class="koboSpan" id="kobo.99.1" xmlns="http://www.w3.org/1999/xhtml">training process, we can now make sense of the term GAN. </span><span class="koboSpan" id="kobo.99.2" xmlns="http://www.w3.org/1999/xhtml">These models are ”generative” because they are aimed at generating data. </span><span class="koboSpan" id="kobo.99.3" xmlns="http://www.w3.org/1999/xhtml">They are ”networks” because, well, they use neural networks. </span><span class="koboSpan" id="kobo.99.4" xmlns="http://www.w3.org/1999/xhtml">And they are ”adversarial” because the whole training process consists in a competition between a generator network and a discriminator network. </span><span class="koboSpan" id="kobo.99.5" xmlns="http://www.w3.org/1999/xhtml">These networks engage in a fierce competition in which we, their programmers and creators, shall be the only true winners.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-211">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.100.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.101.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.102.1" xmlns="http://www.w3.org/1999/xhtml">All this time, we have been talking about how GANs use neural networks in both the discriminator and the generator. </span><span class="koboSpan" id="kobo.102.2" xmlns="http://www.w3.org/1999/xhtml">However, these neural networks are not always like the ones we have discussed in this book.</span></p>
<p><span class="koboSpan" id="kobo.103.1" xmlns="http://www.w3.org/1999/xhtml">The neural networks that we have studied are known as ”dense” neural networks. </span><span class="koboSpan" id="kobo.103.2" xmlns="http://www.w3.org/1999/xhtml">In these networks, all the layers are dense, which means that neurons in subsequent layers are fully connected. </span><span class="koboSpan" id="kobo.103.3" xmlns="http://www.w3.org/1999/xhtml">However, when neural networks are designed to handle images — whether it be generating them, classifying them, or manipulating them — a different kind of layer is often employed: convolutional layers. </span><span class="koboSpan" id="kobo.103.4" xmlns="http://www.w3.org/1999/xhtml">We won’t get into the details of how these layers work (check Chapter 14 in Gerón’s book </span><span class="cite"><span class="koboSpan" id="kobo.104.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xhandsonml"><span class="koboSpan" id="kobo.105.1" xmlns="http://www.w3.org/1999/xhtml">104</span></a><span class="koboSpan" id="kobo.106.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.107.1" xmlns="http://www.w3.org/1999/xhtml"> for a thorough explanation), but you should at least know that they exist.</span></p>
<p><span class="koboSpan" id="kobo.108.1" xmlns="http://www.w3.org/1999/xhtml">GANs are often used in image generation tasks, so, should you ever decide to study classical GANs, be aware that you will surely have to deal with these layers at some point. </span><span class="koboSpan" id="kobo.108.2" xmlns="http://www.w3.org/1999/xhtml">And, yes, there are quantum versions of convolutional layers and convolutional networks </span><span class="cite"><span class="koboSpan" id="kobo.109.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xquantum-conv"><span class="koboSpan" id="kobo.110.1" xmlns="http://www.w3.org/1999/xhtml">114</span></a><span class="koboSpan" id="kobo.111.1" xmlns="http://www.w3.org/1999/xhtml">, </span><a href="ch030.xhtml#Xhavlivcek2019supervised"><span class="koboSpan" id="kobo.112.1" xmlns="http://www.w3.org/1999/xhtml">52</span></a><span class="koboSpan" id="kobo.113.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.114.1" xmlns="http://www.w3.org/1999/xhtml"> that, sadly, we do not have the time to cover in this book.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.115.1" xmlns="http://www.w3.org/1999/xhtml">There are a few details that we should highlight about the </span><span id="dx1-215019"/><span class="koboSpan" id="kobo.116.1" xmlns="http://www.w3.org/1999/xhtml">training process of a GAN. </span><span class="koboSpan" id="kobo.116.2" xmlns="http://www.w3.org/1999/xhtml">The first and most important one is the fact that at no point in the training is the generator network ”exposed” to or fed the original data. </span><span class="koboSpan" id="kobo.116.3" xmlns="http://www.w3.org/1999/xhtml">The only way the generator network can learn about the data it has to replicate is through the discriminator. </span><span class="koboSpan" id="kobo.116.4" xmlns="http://www.w3.org/1999/xhtml">In this way, instead of us having to tell the generator network what its output should look like, the discriminator takes up our role as teachers and enables us to train the whole network in a fully unsupervised manner.</span></p>
<p><span class="koboSpan" id="kobo.117.1" xmlns="http://www.w3.org/1999/xhtml">Another issue to which we should pay attention is that GANs, like any other machine learning model, are vulnerable to problems in training. </span><span class="koboSpan" id="kobo.117.2" xmlns="http://www.w3.org/1999/xhtml">For instance, how could we have any guarantee that the generated outputs are not just slightly distorted copies of the original data, rather than new data elements that match the patterns in the original dataset? </span><span class="koboSpan" id="kobo.117.3" xmlns="http://www.w3.org/1999/xhtml">For instance, in the cat GAN that we considered in </span><em><span class="koboSpan" id="kobo.118.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.3"><em><span class="koboSpan" id="kobo.119.1" xmlns="http://www.w3.org/1999/xhtml">12.3</span></em></a><span class="koboSpan" id="kobo.120.1" xmlns="http://www.w3.org/1999/xhtml">, how could we have guarantees that the generated images are new cat pictures rather than, say, blurred copies of our original images that have lost any resemblance to cats but that were nevertheless able to fool the discriminator network? </span><span class="koboSpan" id="kobo.120.2" xmlns="http://www.w3.org/1999/xhtml">This could happen, for example, if our discriminator weren’t powerful enough compared to the generator.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-212">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.121.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.122.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.123.1" xmlns="http://www.w3.org/1999/xhtml">The training of a GAN can also fail if the resulting GAN is unable to generate all the possible variations (or </span><strong><span class="koboSpan" id="kobo.124.1" xmlns="http://www.w3.org/1999/xhtml">modes</span></strong><span class="koboSpan" id="kobo.125.1" xmlns="http://www.w3.org/1999/xhtml">) of data that can be found in the dataset. </span><span class="koboSpan" id="kobo.125.2" xmlns="http://www.w3.org/1999/xhtml">For instance, in the example that we have been considering, we would find this problem if our GAN were only able to generate pictures of a small selection of cats, maybe even only one! </span><span class="koboSpan" id="kobo.125.3" xmlns="http://www.w3.org/1999/xhtml">This </span><span id="dx1-215020"/><span class="koboSpan" id="kobo.126.1" xmlns="http://www.w3.org/1999/xhtml">occurrence is known as </span><strong><span class="koboSpan" id="kobo.127.1" xmlns="http://www.w3.org/1999/xhtml">mode collapse</span></strong><span class="koboSpan" id="kobo.128.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.128.2" xmlns="http://www.w3.org/1999/xhtml">To try to avoid it, several modified GANs </span><span id="dx1-215021"/><span class="koboSpan" id="kobo.129.1" xmlns="http://www.w3.org/1999/xhtml">have been proposed, including </span><strong><span class="koboSpan" id="kobo.130.1" xmlns="http://www.w3.org/1999/xhtml">Wasserstein GANs</span></strong><span class="koboSpan" id="kobo.131.1" xmlns="http://www.w3.org/1999/xhtml"> (</span><strong><span class="koboSpan" id="kobo.132.1" xmlns="http://www.w3.org/1999/xhtml">WGANs</span></strong><span class="koboSpan" id="kobo.133.1" xmlns="http://www.w3.org/1999/xhtml">) </span><span class="cite"><span class="koboSpan" id="kobo.134.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xarjovsky2017wasserstein"><span class="koboSpan" id="kobo.135.1" xmlns="http://www.w3.org/1999/xhtml">7</span></a><span class="koboSpan" id="kobo.136.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.137.1" xmlns="http://www.w3.org/1999/xhtml">, which derive their loss function from a distance called the Wasserstein metric.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.138.1" xmlns="http://www.w3.org/1999/xhtml">In the models that we considered in previous chapters, there was always a simple, straightforward way to effectively assess their performance — namely evaluating loss functions on test datasets. </span><span class="koboSpan" id="kobo.138.2" xmlns="http://www.w3.org/1999/xhtml">When working with GANs, things can be more subtle. </span><span class="koboSpan" id="kobo.138.3" xmlns="http://www.w3.org/1999/xhtml">In general, you should always take a look at the generated data and check if the results are satisfactory.</span></p>
<div class="tcolorbox important" id="tcolobox-213">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.139.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.140.1" xmlns="http://www.w3.org/1999/xhtml">A GAN consists of two neural networks: a generator and a discriminator. </span><span class="koboSpan" id="kobo.140.2" xmlns="http://www.w3.org/1999/xhtml">They compete against each other in an iterative training process. </span><span class="koboSpan" id="kobo.140.3" xmlns="http://www.w3.org/1999/xhtml">The discriminator is tasked with discerning a dataset of real data from the output of the generator network, while the generator network is tasked with generating data that the discriminator will mistakenly identify as real.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.141.1" xmlns="http://www.w3.org/1999/xhtml">Just to conclude this overview of classical GANs, let’s discuss a few technicalities about the training of the generator and discriminator networks.</span></p>
</section>
<section class="level3 subsectionHead" data-number="20.1.3" id="some-technicalities-about-gans">
<h2 class="subsectionHead" data-number="20.1.3"><span class="titlemark"><span class="koboSpan" id="kobo.142.1" xmlns="http://www.w3.org/1999/xhtml">12.1.3 </span></span> <span id="x1-21600012.1.3"><span class="koboSpan" id="kobo.143.1" xmlns="http://www.w3.org/1999/xhtml">Some technicalities about GANs</span></span></h2>
<p><span class="koboSpan" id="kobo.144.1" xmlns="http://www.w3.org/1999/xhtml">We have already mentioned how the </span><span id="dx1-216001"/><span class="koboSpan" id="kobo.145.1" xmlns="http://www.w3.org/1999/xhtml">generator and discriminator networks are ordinary neural network models — even if they may be different from the ones that we’ve discussed so far — that are constantly re-trained in an iterative process. </span><span class="koboSpan" id="kobo.145.2" xmlns="http://www.w3.org/1999/xhtml">We will now briefly talk about how this training is carried out.</span></p>
<p><span class="koboSpan" id="kobo.146.1" xmlns="http://www.w3.org/1999/xhtml">Let </span><span class="koboSpan" id="kobo.147.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="X" class="math inline" src="../media/file9.png" style="vertical-align:middle" title="X"/></span><span class="koboSpan" id="kobo.148.1" xmlns="http://www.w3.org/1999/xhtml"> be a set of real data and let </span><span class="koboSpan" id="kobo.149.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="S" class="math inline" src="../media/file73.png" style="vertical-align:middle" title="S"/></span><span class="koboSpan" id="kobo.150.1" xmlns="http://www.w3.org/1999/xhtml"> be a set of ”seeds” that we give to the generator. </span><span class="koboSpan" id="kobo.150.2" xmlns="http://www.w3.org/1999/xhtml">In the case of the discriminator neural network, we are just training a binary classifier and, as is standard, this classifier will return an output bounded between </span><span class="koboSpan" id="kobo.151.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.152.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.153.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.154.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.154.2" xmlns="http://www.w3.org/1999/xhtml">Without loss of generality, we will assume that values closer to </span><span class="koboSpan" id="kobo.155.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.156.1" xmlns="http://www.w3.org/1999/xhtml"> are meant to represent inputs from the real dataset while values closer to </span><span class="koboSpan" id="kobo.157.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.158.1" xmlns="http://www.w3.org/1999/xhtml"> are labeled as generated inputs — that’s an arbitrary choice; it could perfectly be the other way around.</span></p>
<p><span class="koboSpan" id="kobo.159.1" xmlns="http://www.w3.org/1999/xhtml">As with any other binary classifier, the most natural loss function to use will be the binary cross-entropy loss, and hence this classifier will be trained as it would in supervised learning: assigning the ”true label” </span><span class="koboSpan" id="kobo.160.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.161.1" xmlns="http://www.w3.org/1999/xhtml"> to any input from the real dataset and the ”true label” </span><span class="koboSpan" id="kobo.162.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.163.1" xmlns="http://www.w3.org/1999/xhtml"> to any generated input. </span><span class="koboSpan" id="kobo.163.2" xmlns="http://www.w3.org/1999/xhtml">In this way, if we let </span><span class="koboSpan" id="kobo.164.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="G" class="math inline" src="../media/file1441.png" style="vertical-align:middle" title="G"/></span><span class="koboSpan" id="kobo.165.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.166.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="D" class="math inline" src="../media/file1101.png" style="vertical-align:middle" title="D"/></span><span class="koboSpan" id="kobo.167.1" xmlns="http://www.w3.org/1999/xhtml"> denote the actions of the generator and the discriminator, the discriminator training loss, </span><span class="koboSpan" id="kobo.168.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="L_{D}" class="math inline" src="../media/file1442.png" style="vertical-align:middle" title="L_{D}"/></span><span class="koboSpan" id="kobo.169.1" xmlns="http://www.w3.org/1999/xhtml">, would be computed as</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.170.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="L_{D} = - \frac{1}{|X| + |S|}\left( {\sum\limits_{x \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right)," class="math display" src="../media/file1443.png" style="vertical-align:middle" title="L_{D} = - \frac{1}{|X| + |S|}\left( {\sum\limits_{x \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right),"/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.171.1" xmlns="http://www.w3.org/1999/xhtml">where we are using </span><span class="koboSpan" id="kobo.172.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="|X|" class="math inline" src="../media/file1444.png" style="vertical-align:middle" title="|X|"/></span><span class="koboSpan" id="kobo.173.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.174.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="|S|" class="math inline" src="../media/file1445.png" style="vertical-align:middle" title="|S|"/></span><span class="koboSpan" id="kobo.175.1" xmlns="http://www.w3.org/1999/xhtml"> to denote the sizes of the sets </span><span class="koboSpan" id="kobo.176.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="X" class="math inline" src="../media/file9.png" style="vertical-align:middle" title="X"/></span><span class="koboSpan" id="kobo.177.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.178.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="S" class="math inline" src="../media/file73.png" style="vertical-align:middle" title="S"/></span><span class="koboSpan" id="kobo.179.1" xmlns="http://www.w3.org/1999/xhtml">, respectively. </span><span class="koboSpan" id="kobo.179.2" xmlns="http://www.w3.org/1999/xhtml">The job of the discriminator would be to minimize this loss.</span></p>
<p><span class="koboSpan" id="kobo.180.1" xmlns="http://www.w3.org/1999/xhtml">Now, what about the generator network? </span><span class="koboSpan" id="kobo.180.2" xmlns="http://www.w3.org/1999/xhtml">What could be a good choice for the loss function that we would like to </span><span id="dx1-216002"/><span class="koboSpan" id="kobo.181.1" xmlns="http://www.w3.org/1999/xhtml">minimize in its training process? </span><span class="koboSpan" id="kobo.181.2" xmlns="http://www.w3.org/1999/xhtml">Our goal when training the generator is to fool the discriminator trying to get it to classify our generated data as real data. </span><span class="koboSpan" id="kobo.181.3" xmlns="http://www.w3.org/1999/xhtml">Hence, the goal in the training of the generator is to maximize the loss function of the discriminator, that is, to minimize</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.182.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="- L_{D} = \frac{1}{|X| + |S|}\left( {\sum\limits_{x \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right)." class="math display" src="../media/file1446.png" style="vertical-align:middle" title="- L_{D} = \frac{1}{|X| + |S|}\left( {\sum\limits_{x \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right)."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.183.1" xmlns="http://www.w3.org/1999/xhtml">Nevertheless, the contribution of the first term in the sum is necessarily constant in the generator training since it does not depend on the generator in any way. </span><span class="koboSpan" id="kobo.183.2" xmlns="http://www.w3.org/1999/xhtml">Thus, equivalently, we may consider the goal of the generator training to be the minimization of the generator loss function</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.184.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="L_{G}^{\prime} = \frac{1}{|S|}\sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)." class="math display" src="../media/file1447.png" style="vertical-align:middle" title="L_{G}^{\prime} = \frac{1}{|S|}\sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.185.1" xmlns="http://www.w3.org/1999/xhtml">That is how things are in theory. </span><span class="koboSpan" id="kobo.185.2" xmlns="http://www.w3.org/1999/xhtml">However, in practice, it has been shown </span><span class="cite"><span class="koboSpan" id="kobo.186.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xgoodfellow2014generative"><span class="koboSpan" id="kobo.187.1" xmlns="http://www.w3.org/1999/xhtml">46</span></a><span class="koboSpan" id="kobo.188.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.189.1" xmlns="http://www.w3.org/1999/xhtml"> that it is usually more stable to take the goal of the generator training to be the minimization of the loss</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.190.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="L_{G} = - \frac{1}{|S|}\sum\limits_{s \in S}\log\left( {D(G(s)} \right)." class="math display" src="../media/file1448.png" style="vertical-align:middle" title="L_{G} = - \frac{1}{|S|}\sum\limits_{s \in S}\log\left( {D(G(s)} \right)."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.191.1" xmlns="http://www.w3.org/1999/xhtml">The crucial thing here is that, with both definitions, if these generator loss functions decrease while </span><span id="dx1-216003"/><span class="koboSpan" id="kobo.192.1" xmlns="http://www.w3.org/1999/xhtml">training the generator, it will be more likely for our generated data to be (mistakenly) classified as real data by our classifier. </span><span class="koboSpan" id="kobo.192.2" xmlns="http://www.w3.org/1999/xhtml">That will mean, in turn, that our data should be gradually getting more and more similar to the data in the original dataset.</span></p>
<p><span class="koboSpan" id="kobo.193.1" xmlns="http://www.w3.org/1999/xhtml">It has also been shown that, in the optimal equilibrium between the generator and the discriminator, the discriminator assigns values </span><span class="koboSpan" id="kobo.194.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="D(x)" class="math inline" src="../media/file1449.png" style="vertical-align:middle" title="D(x)"/></span><span class="koboSpan" id="kobo.195.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.196.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="G(D(s))" class="math inline" src="../media/file1450.png" style="vertical-align:middle" title="G(D(s))"/></span><span class="koboSpan" id="kobo.197.1" xmlns="http://www.w3.org/1999/xhtml"> equal to </span><span class="koboSpan" id="kobo.198.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. 1\slash 2 \right." class="math inline" src="../media/file136.png" style="vertical-align:middle" title="\left. 1\slash 2 \right."/></span><span class="koboSpan" id="kobo.199.1" xmlns="http://www.w3.org/1999/xhtml"> (because it cannot distinguish between real and generated data), and, hence, when </span><span class="koboSpan" id="kobo.200.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. L_{D} = L_{G} = - \log 1\slash 2 = \log 2 \approx 0.6931 \right." class="math inline" src="../media/file1451.png" style="vertical-align:middle" title="\left. L_{D} = L_{G} = - \log 1\slash 2 = \log 2 \approx 0.6931 \right."/></span><span class="koboSpan" id="kobo.201.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.201.2" xmlns="http://www.w3.org/1999/xhtml">You can find the proof (with slightly different but equivalent loss functions) in the original GANs paper </span><span class="cite"><span class="koboSpan" id="kobo.202.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xgoodfellow2014generative"><span class="koboSpan" id="kobo.203.1" xmlns="http://www.w3.org/1999/xhtml">46</span></a><span class="koboSpan" id="kobo.204.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.205.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-214">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.206.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.207.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.208.1" xmlns="http://www.w3.org/1999/xhtml">It can be shown that the optimal configuration of a GAN is a Nash equilibrium of an adversarial game between the generator and the discriminator (see, for instance, the helpful tutorial given by Goodfellow at NIPS </span><span class="cite"><span class="koboSpan" id="kobo.209.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xgoodfellow2016nips"><span class="koboSpan" id="kobo.210.1" xmlns="http://www.w3.org/1999/xhtml">47</span></a><span class="koboSpan" id="kobo.211.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.212.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.212.2" xmlns="http://www.w3.org/1999/xhtml">In this equilibrium, the configuration of the GAN is a (local) minimizer of both the generator and discriminator losses.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.213.1" xmlns="http://www.w3.org/1999/xhtml">That should be enough of an introduction to classical GANs. </span><span class="koboSpan" id="kobo.213.2" xmlns="http://www.w3.org/1999/xhtml">Let’s now see what quantum GANs are and what they have to offer.</span></p>
</section>
<section class="level3 subsectionHead" data-number="20.1.4" id="quantum-gans">
<h2 class="subsectionHead" data-number="20.1.4"><span class="titlemark"><span class="koboSpan" id="kobo.214.1" xmlns="http://www.w3.org/1999/xhtml">12.1.4 </span></span> <span id="x1-21700012.1.4"><span class="koboSpan" id="kobo.215.1" xmlns="http://www.w3.org/1999/xhtml">Quantum GANs</span></span></h2>
<p><span class="koboSpan" id="kobo.216.1" xmlns="http://www.w3.org/1999/xhtml">What is a </span><span id="dx1-217001"/><span class="koboSpan" id="kobo.217.1" xmlns="http://www.w3.org/1999/xhtml">quantum GAN? </span><span class="koboSpan" id="kobo.217.2" xmlns="http://www.w3.org/1999/xhtml">It’s just a GAN, with its competing discriminator and generator, where a part of the model is implemented by a quantum model (usually some form of a quantum neural network), and it is trained just like a classical GAN. </span><span class="koboSpan" id="kobo.217.3" xmlns="http://www.w3.org/1999/xhtml">In other words, training a quantum GAN is just like counterfeiting money — but you don’t risk going to prison and you get to play with quantum stuff.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-215">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.218.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.219.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.220.1" xmlns="http://www.w3.org/1999/xhtml">By the way, did you know that there are proposals of quantum money that cannot be counterfeited at all? </span><span class="koboSpan" id="kobo.220.2" xmlns="http://www.w3.org/1999/xhtml">The original idea was proposed by Stephen Wiesner </span><span class="cite"><span class="koboSpan" id="kobo.221.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xwiesner1983conjugate"><span class="koboSpan" id="kobo.222.1" xmlns="http://www.w3.org/1999/xhtml">97</span></a><span class="koboSpan" id="kobo.223.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.224.1" xmlns="http://www.w3.org/1999/xhtml"> and it became the inspiration for unbreakable quantum cryptographical protocols such as the famous BB84 proposed by Bennett and Brassard </span><span class="cite"><span class="koboSpan" id="kobo.225.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xbennett84quantum"><span class="koboSpan" id="kobo.226.1" xmlns="http://www.w3.org/1999/xhtml">13</span></a><span class="koboSpan" id="kobo.227.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.228.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.229.1" xmlns="http://www.w3.org/1999/xhtml">In truth, that is as close to a precise definition as we can get, because the range of models that can fit into the category of QGAN is vast. </span><span class="koboSpan" id="kobo.229.2" xmlns="http://www.w3.org/1999/xhtml">Depending on the kind of problem that you want to tackle, you may want to use quantum GANs with completely different architectures which, still, will share the same core elements of a competing discriminator and generator. </span><span class="koboSpan" id="kobo.229.3" xmlns="http://www.w3.org/1999/xhtml">The examples that we will consider in the following sections will help us exemplify this.</span></p>
<p><span class="koboSpan" id="kobo.230.1" xmlns="http://www.w3.org/1999/xhtml">Broadly speaking, any quantum GAN could fit into one of the </span><span id="dx1-217002"/><span class="koboSpan" id="kobo.231.1" xmlns="http://www.w3.org/1999/xhtml">following categories:</span></p>
<ul>
<li><p><strong><span class="koboSpan" id="kobo.232.1" xmlns="http://www.w3.org/1999/xhtml">Uses quantum data and both the generator and the</span></strong> <strong><span class="koboSpan" id="kobo.233.1" xmlns="http://www.w3.org/1999/xhtml">discriminator are quantum:</span></strong><span class="koboSpan" id="kobo.234.1" xmlns="http://www.w3.org/1999/xhtml"> This quantum data will just be some quantum states, and the generator and discriminator will be implemented by quantum circuits.</span></p>
<p><span class="koboSpan" id="kobo.235.1" xmlns="http://www.w3.org/1999/xhtml">This situation allows for a very special QGAN architecture, with a fully quantum model. </span><span class="koboSpan" id="kobo.235.2" xmlns="http://www.w3.org/1999/xhtml">Since we are dealing with quantum data (states), and all the components of the GAN are quantum circuits, they can be perfectly joined together without having to resort to feature maps or measurement operations in the middle of the model.</span></p>
<p><span class="koboSpan" id="kobo.236.1" xmlns="http://www.w3.org/1999/xhtml">Later in the chapter, we will study an example of this purely quantum architecture on PennyLane.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.237.1" xmlns="http://www.w3.org/1999/xhtml">Uses quantum data and a quantum generator with a classical</span></strong> <strong><span class="koboSpan" id="kobo.238.1" xmlns="http://www.w3.org/1999/xhtml">discriminator:</span></strong><span class="koboSpan" id="kobo.239.1" xmlns="http://www.w3.org/1999/xhtml"> If the discriminator is classical, the architecture of our QGANs will be more similar to that of classical GANs. </span><span class="koboSpan" id="kobo.239.2" xmlns="http://www.w3.org/1999/xhtml">The generator will produce quantum states but, ultimately, they will be transformed into classical data by some measurement operation in order to feed them into the classifier. </span><span class="koboSpan" id="kobo.239.3" xmlns="http://www.w3.org/1999/xhtml">Of course, the original quantum data will also have to be measured.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.240.1" xmlns="http://www.w3.org/1999/xhtml">Uses classical data with a quantum generator</span></strong> <strong><span class="koboSpan" id="kobo.241.1" xmlns="http://www.w3.org/1999/xhtml">or discriminator:</span></strong><span class="koboSpan" id="kobo.242.1" xmlns="http://www.w3.org/1999/xhtml"> This is the scenario in which QGANs can best match their classical counterparts. </span><span class="koboSpan" id="kobo.242.2" xmlns="http://www.w3.org/1999/xhtml">The use of QGANs in these cases essentially mounts up to replacing the generator or the discriminator (or both) with a quantum model with classical inputs and outputs. </span><span class="koboSpan" id="kobo.242.3" xmlns="http://www.w3.org/1999/xhtml">In the case of a </span><span id="dx1-217003"/><span class="koboSpan" id="kobo.243.1" xmlns="http://www.w3.org/1999/xhtml">quantum discriminator, for example, we would have to use a feature map to load classical data into a quantum state.</span></p>
<p><span class="koboSpan" id="kobo.244.1" xmlns="http://www.w3.org/1999/xhtml">Because the availability of classical data is much bigger than that of quantum data, this is the type of architecture that has been studied more widely by the quantum computing community.</span></p>
<p><span class="koboSpan" id="kobo.245.1" xmlns="http://www.w3.org/1999/xhtml">Later in the chapter, we will consider a QGAN with classical data and a classical classifier, but with a quantum generator. </span><span class="koboSpan" id="kobo.245.2" xmlns="http://www.w3.org/1999/xhtml">That will be in our Qiskit section.</span></p></li>
</ul>
<div class="tcolorbox learnmore" id="tcolobox-216">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.246.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.247.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.248.1" xmlns="http://www.w3.org/1999/xhtml">In the literature, there are many different proposals of quantum versions of GANs. </span><span class="koboSpan" id="kobo.248.2" xmlns="http://www.w3.org/1999/xhtml">Some of the earliest ones include works by Lloyd and Weedbrook </span><span class="cite"><span class="koboSpan" id="kobo.249.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xlloyd2018quantum"><span class="koboSpan" id="kobo.250.1" xmlns="http://www.w3.org/1999/xhtml">64</span></a><span class="koboSpan" id="kobo.251.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.252.1" xmlns="http://www.w3.org/1999/xhtml">, by Dallaire-Demers and Killoran </span><span class="cite"><span class="koboSpan" id="kobo.253.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xdallaire2018quantum"><span class="koboSpan" id="kobo.254.1" xmlns="http://www.w3.org/1999/xhtml">28</span></a><span class="koboSpan" id="kobo.255.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.256.1" xmlns="http://www.w3.org/1999/xhtml">, and by Zoufal, Lucchi, and Woerner </span><span class="cite"><span class="koboSpan" id="kobo.257.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xzoufal2019quantum"><span class="koboSpan" id="kobo.258.1" xmlns="http://www.w3.org/1999/xhtml">101</span></a><span class="koboSpan" id="kobo.259.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.260.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<div class="tcolorbox questionx" id="tcolobox-217">
<span id="x1-217015x12.1.4"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.261.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 12.1</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.262.1" xmlns="http://www.w3.org/1999/xhtml">In this book, we have discussed four different QML models: quantum support vector machines, quantum neural networks, hybrid QNNs and quantum GANs. </span><span class="koboSpan" id="kobo.262.2" xmlns="http://www.w3.org/1999/xhtml">Decide which of these models would be suitable for the following tasks:</span></p>
<ol>
<li><div id="x1-217006x1">
<p><span class="koboSpan" id="kobo.263.1" xmlns="http://www.w3.org/1999/xhtml">Distinguishing cat pictures from dog pictures.</span></p>
</div></li>
<li><div id="x1-217008x2">
<p><span class="koboSpan" id="kobo.264.1" xmlns="http://www.w3.org/1999/xhtml">Generating pictures of dogs.</span></p>
</div></li>
<li><div id="x1-217010x3">
<p><span class="koboSpan" id="kobo.265.1" xmlns="http://www.w3.org/1999/xhtml">Deciding whether a financial transaction is fraudulent based on its metadata.</span></p>
</div></li>
<li><div id="x1-217012x4">
<p><span class="koboSpan" id="kobo.266.1" xmlns="http://www.w3.org/1999/xhtml">Assessing the risk of heart failure from a patients’ medical records and data from an electrocardiogram.</span></p>
</div></li>
<li><div id="x1-217014x5">
<p><span class="koboSpan" id="kobo.267.1" xmlns="http://www.w3.org/1999/xhtml">Creating a dataset of random images of electrocardiograms in order to train future doctors.</span></p>
</div></li>
</ol>
</div>
</div>
<p><span class="koboSpan" id="kobo.268.1" xmlns="http://www.w3.org/1999/xhtml">We should give you a word of caution. </span><span class="koboSpan" id="kobo.268.2" xmlns="http://www.w3.org/1999/xhtml">GANs aren’t the easiest models to train. </span><span class="koboSpan" id="kobo.268.3" xmlns="http://www.w3.org/1999/xhtml">As we mentioned previously, when you train a GAN, you don’t have a single and straightforward loss function that can measure how successful your training is. </span><span class="koboSpan" id="kobo.268.4" xmlns="http://www.w3.org/1999/xhtml">Training a GAN is not a simple optimization problem, but a more intricate process. </span><span class="koboSpan" id="kobo.268.5" xmlns="http://www.w3.org/1999/xhtml">Using quantum models, of course, only makes matters more difficult, and training quantum GANs can be…complicated.</span></p>
<p><span class="koboSpan" id="kobo.269.1" xmlns="http://www.w3.org/1999/xhtml">We will now consider a couple of interesting QGAN examples, in both PennyLane and Qiskit. </span><span class="koboSpan" id="kobo.269.2" xmlns="http://www.w3.org/1999/xhtml">Naturally, since we’ve picked them, our quantum GANs will learn smoothly. </span><span class="koboSpan" id="kobo.269.3" xmlns="http://www.w3.org/1999/xhtml">But you have been warned: quantum GANs are usually wild creatures.</span></p>
</section>
</section>
<section class="level2 sectionHead" data-number="20.2" id="quantum-gans-in-pennylane">
<h1 class="sectionHead" data-number="20.2"><span class="titlemark"><span class="koboSpan" id="kobo.270.1" xmlns="http://www.w3.org/1999/xhtml">12.2 </span></span> <span id="x1-21800012.2"><span class="koboSpan" id="kobo.271.1" xmlns="http://www.w3.org/1999/xhtml">Quantum GANs in PennyLane</span></span></h1>
<p><span class="koboSpan" id="kobo.272.1" xmlns="http://www.w3.org/1999/xhtml">In this section, we are going to train a purely quantum GAN that will learn a one-qubit state. </span><span class="koboSpan" id="kobo.272.2" xmlns="http://www.w3.org/1999/xhtml">In our </span><span id="dx1-218001"/><span class="koboSpan" id="kobo.273.1" xmlns="http://www.w3.org/1999/xhtml">previous counterfeiting example, we imagined ourselves as behaving like a GAN in order to replicate some training data (a banknote) to produce fake banknotes that, ideally, would get closer and closer to the real thing in each iteration. </span><span class="koboSpan" id="kobo.273.2" xmlns="http://www.w3.org/1999/xhtml">In this case, our training data will be a one-qubit state, characterized by some amplitudes, and the job of our QGAN will be to replicate that state without the generator having direct access to it. </span><span class="koboSpan" id="kobo.273.3" xmlns="http://www.w3.org/1999/xhtml">Our dataset, then, will consist of multiple copies of a one-qubit state, and our goal will be to train a generator able to prepare that state (or something very close to it).</span></p>
<div class="tcolorbox learnmore" id="tcolobox-218">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.274.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.275.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.276.1" xmlns="http://www.w3.org/1999/xhtml">Notice that this setting does not violate the no-cloning theorem that we proved in </span><em><span class="koboSpan" id="kobo.277.1" xmlns="http://www.w3.org/1999/xhtml">Section</span></em> <em/> <a href="ch008.xhtml#x1-320001.4.5"><em><span class="koboSpan" id="kobo.278.1" xmlns="http://www.w3.org/1999/xhtml">1.4.5</span></em></a><span class="koboSpan" id="kobo.279.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.279.2" xmlns="http://www.w3.org/1999/xhtml">We will have multiple copies of the same quantum state and we will perform operations on them, including measuring them (and, hence, collapsing their states). </span><span class="koboSpan" id="kobo.279.3" xmlns="http://www.w3.org/1999/xhtml">From that, we will learn some properties of the state that we will use to reproduce it with the generator. </span><span class="koboSpan" id="kobo.279.4" xmlns="http://www.w3.org/1999/xhtml">But we won’t be having a unitary operation (a quantum gate) that creates an additional, independent copy of a given state. </span><span class="koboSpan" id="kobo.279.5" xmlns="http://www.w3.org/1999/xhtml">In fact, we will destroy the original copies in the process!</span></p>
<p><span class="koboSpan" id="kobo.280.1" xmlns="http://www.w3.org/1999/xhtml">What we will be doing here is more similar to </span><strong><span class="koboSpan" id="kobo.281.1" xmlns="http://www.w3.org/1999/xhtml">quantum state</span></strong> <strong><span class="koboSpan" id="kobo.282.1" xmlns="http://www.w3.org/1999/xhtml">tomography</span></strong><span class="koboSpan" id="kobo.283.1" xmlns="http://www.w3.org/1999/xhtml"> (see, for instance, the review by Altepeter, James, and Kwiat </span><span class="cite"><span class="koboSpan" id="kobo.284.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xaltepeter2005photonic"><span class="koboSpan" id="kobo.285.1" xmlns="http://www.w3.org/1999/xhtml">6</span></a><span class="koboSpan" id="kobo.286.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.287.1" xmlns="http://www.w3.org/1999/xhtml">), which can be defined as the process of applying quantum operations and measurements to multiple copies of a state and, from the results, learning to reconstruct the original state.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.288.1" xmlns="http://www.w3.org/1999/xhtml">For this example, we will use the PyTorch machine learning package. </span><span class="koboSpan" id="kobo.288.2" xmlns="http://www.w3.org/1999/xhtml">Please, have a look at </span><em><span class="koboSpan" id="kobo.289.1" xmlns="http://www.w3.org/1999/xhtml">Subsection</span></em> <a href="ch020.xhtml#x1-20500011.3.1"><em><span class="koboSpan" id="kobo.290.1" xmlns="http://www.w3.org/1999/xhtml">11.3.1</span></em></a><span class="koboSpan" id="kobo.291.1" xmlns="http://www.w3.org/1999/xhtml"> if you haven’t already.</span></p>
<p><span class="koboSpan" id="kobo.292.1" xmlns="http://www.w3.org/1999/xhtml">The reason </span><span id="dx1-218002"/><span class="koboSpan" id="kobo.293.1" xmlns="http://www.w3.org/1999/xhtml">behind our choice to use PyTorch is simple. </span><span class="koboSpan" id="kobo.293.2" xmlns="http://www.w3.org/1999/xhtml">As much as we have used TensorFlow so far, we only know how to use it at a basic level, relying heavily on the Keras interface. </span><span class="koboSpan" id="kobo.293.3" xmlns="http://www.w3.org/1999/xhtml">On the other hand, we have studied PyTorch extensively in the previous chapter, which makes it a better tool for us when it comes to dealing with more complex architectures. </span><span class="koboSpan" id="kobo.293.4" xmlns="http://www.w3.org/1999/xhtml">In other words, this choice isn’t grounded in any technical superiority of any package over the other, but solely on what’s most practical given the content that we’ve covered in this book. </span><span class="koboSpan" id="kobo.293.5" xmlns="http://www.w3.org/1999/xhtml">In fact, virtually any model that can be built and trained on PyTorch can also be dealt with on TensorFlow and vice versa.</span></p>
<p><span class="koboSpan" id="kobo.294.1" xmlns="http://www.w3.org/1999/xhtml">With those preliminaries aside, let’s get to our model.</span></p>
<section class="level3 subsectionHead" data-number="20.2.1" id="preparing-a-qgan-model">
<h2 class="subsectionHead" data-number="20.2.1"><span class="titlemark"><span class="koboSpan" id="kobo.295.1" xmlns="http://www.w3.org/1999/xhtml">12.2.1 </span></span> <span id="x1-21900012.2.1"><span class="koboSpan" id="kobo.296.1" xmlns="http://www.w3.org/1999/xhtml">Preparing a QGAN model</span></span></h2>
<p><span class="koboSpan" id="kobo.297.1" xmlns="http://www.w3.org/1999/xhtml">The purely </span><span id="dx1-219001"/><span class="koboSpan" id="kobo.298.1" xmlns="http://www.w3.org/1999/xhtml">quantum GAN that we seek to implement and train will run on a device with two qubits, and it will be made up of the following components:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.299.1" xmlns="http://www.w3.org/1999/xhtml">A quantum circuit that will be able to prepare the one-qubit state </span><span class="koboSpan" id="kobo.300.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.301.1" xmlns="http://www.w3.org/1999/xhtml"> that we want our QGAN to learn. </span><span class="koboSpan" id="kobo.301.2" xmlns="http://www.w3.org/1999/xhtml">This circuit will run on the first qubit of the device. </span><span class="koboSpan" id="kobo.301.3" xmlns="http://www.w3.org/1999/xhtml">We should regard it as a black box, the inner working of which is fully opaque to our model.</span></p>
<p><span class="koboSpan" id="kobo.302.1" xmlns="http://www.w3.org/1999/xhtml">The state </span><span class="koboSpan" id="kobo.303.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.304.1" xmlns="http://www.w3.org/1999/xhtml">, which we will refer to as the ”true state,” is the quantum training data that we will use in our QGAN. </span><span class="koboSpan" id="kobo.304.2" xmlns="http://www.w3.org/1999/xhtml">This circuit will just provide us with a way of accessing the training data: as many copies of the </span><span class="koboSpan" id="kobo.305.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.306.1" xmlns="http://www.w3.org/1999/xhtml"> state as we may need in the training process. </span><span class="koboSpan" id="kobo.306.2" xmlns="http://www.w3.org/1999/xhtml">This emulates, for instance, a physics experiment that produces some quantum state that we want to learn.</span></p></li>
<li><p><span class="koboSpan" id="kobo.307.1" xmlns="http://www.w3.org/1999/xhtml">A </span><span id="dx1-219002"/><span class="koboSpan" id="kobo.308.1" xmlns="http://www.w3.org/1999/xhtml">quantum generator, which will also run on the first qubit of the device and which aims to prepare a state similar to </span><span class="koboSpan" id="kobo.309.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.310.1" xmlns="http://www.w3.org/1999/xhtml"> on the first qubit. </span><span class="koboSpan" id="kobo.310.2" xmlns="http://www.w3.org/1999/xhtml">The quantum generator will be implemented by a variational form dependent on some trainable parameters.</span></p></li>
<li><p><span class="koboSpan" id="kobo.311.1" xmlns="http://www.w3.org/1999/xhtml">A quantum discriminator, which will run on the first and second qubits of the device. </span><span class="koboSpan" id="kobo.311.2" xmlns="http://www.w3.org/1999/xhtml">Its ”input” will be the state on the first qubit, which can either be the state we want our QGAN to learn or the state prepared by the generator. </span><span class="koboSpan" id="kobo.311.3" xmlns="http://www.w3.org/1999/xhtml">Of course, the job of the discriminator will be to try to distinguish these two states. </span><span class="koboSpan" id="kobo.311.4" xmlns="http://www.w3.org/1999/xhtml">We implement it with two qubits (instead of just one) to be sure that it has enough discriminative power.</span></p>
<p><span class="koboSpan" id="kobo.312.1" xmlns="http://www.w3.org/1999/xhtml">Since this discriminator already takes a quantum input, it only needs to consist of a variational form followed by a measurement operation — there will be no need to use feature maps, as we had to do when working with classical data. </span><span class="koboSpan" id="kobo.312.2" xmlns="http://www.w3.org/1999/xhtml">As usual, we will place the measurement operation on the first qubit.</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.313.1" xmlns="http://www.w3.org/1999/xhtml">All the components that we have just described are depicted in </span><em><span class="koboSpan" id="kobo.314.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.4"><em><span class="koboSpan" id="kobo.315.1" xmlns="http://www.w3.org/1999/xhtml">12.4</span></em></a><span class="koboSpan" id="kobo.316.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.317.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(a) Circuit preparing the state  that we want our QGAN to learn." src="../media/file1453.jpg"/></span>
<figcaption aria-hidden="true"><span id="Figure12.4a"><strong><span class="koboSpan" id="kobo.318.1" xmlns="http://www.w3.org/1999/xhtml">(a)</span></strong></span><span class="koboSpan" id="kobo.319.1" xmlns="http://www.w3.org/1999/xhtml"> Circuit preparing the state </span><span class="koboSpan" id="kobo.320.1" xmlns="http://www.w3.org/1999/xhtml"><img src="../media/file1452.png" alt="img"/></span><span class="koboSpan" id="kobo.321.1" xmlns="http://www.w3.org/1999/xhtml"> that we want our QGAN to learn.</span></figcaption>
</figure>
<figure>
<span class="koboSpan" id="kobo.322.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(b) Generator circuit that outputs a state . We aim for  to be similar to  ." src="../media/file1455.jpg"/></span>
<figcaption aria-hidden="true"><span id="Figure12.4b"><strong><span class="koboSpan" id="kobo.323.1" xmlns="http://www.w3.org/1999/xhtml">(b)</span></strong></span><span class="koboSpan" id="kobo.324.1" xmlns="http://www.w3.org/1999/xhtml"> Generator circuit that outputs a state </span><span class="koboSpan" id="kobo.325.1" xmlns="http://www.w3.org/1999/xhtml"><img src="../media/file1454.png" alt="img"/></span><span class="koboSpan" id="kobo.326.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.326.2" xmlns="http://www.w3.org/1999/xhtml">We aim for </span><span class="koboSpan" id="kobo.327.1" xmlns="http://www.w3.org/1999/xhtml"><img src="../media/file1454.png" alt="img"/></span><span class="koboSpan" id="kobo.328.1" xmlns="http://www.w3.org/1999/xhtml"> to be similar to </span><span class="koboSpan" id="kobo.329.1" xmlns="http://www.w3.org/1999/xhtml"><img src="../media/file1452.png" alt="img"/></span><span class="koboSpan" id="kobo.330.1" xmlns="http://www.w3.org/1999/xhtml"> .</span></figcaption>
</figure>
<figure>
<span class="koboSpan" id="kobo.331.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(c) Discriminator circuit, tasked with deciding whether the state  is the state  or the output of the generator." src="../media/file1457.jpg"/></span>
<figcaption aria-hidden="true"><span id="Figure12.4c"><strong><span class="koboSpan" id="kobo.332.1" xmlns="http://www.w3.org/1999/xhtml">(c)</span></strong></span><span class="koboSpan" id="kobo.333.1" xmlns="http://www.w3.org/1999/xhtml"> Discriminator circuit, tasked with deciding whether the state </span><span class="koboSpan" id="kobo.334.1" xmlns="http://www.w3.org/1999/xhtml"><img src="../media/file1456.png" alt="img"/></span><span class="koboSpan" id="kobo.335.1" xmlns="http://www.w3.org/1999/xhtml"> is the state </span><span class="koboSpan" id="kobo.336.1" xmlns="http://www.w3.org/1999/xhtml"><img src="../media/file1452.png" alt="img"/></span><span class="koboSpan" id="kobo.337.1" xmlns="http://www.w3.org/1999/xhtml"> or the output of the generator.</span></figcaption>
</figure>
<p><span id="Figure12.4"><strong><span class="koboSpan" id="kobo.338.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.4</span></strong></span><span class="koboSpan" id="kobo.339.1" xmlns="http://www.w3.org/1999/xhtml">: Components of the quantum GAN that we will train to generate </span><span class="koboSpan" id="kobo.340.1" xmlns="http://www.w3.org/1999/xhtml"><img src="../media/file1452.png" alt="img"/></span></p>
<p><span class="koboSpan" id="kobo.341.1" xmlns="http://www.w3.org/1999/xhtml">Now that we have a sense of where we are heading, let’s get ready to write some code. </span><span class="koboSpan" id="kobo.341.2" xmlns="http://www.w3.org/1999/xhtml">First of all, we will do our usual imports and set some seeds to ensure the reproducibility of our results:</span></p>
<p><span id="x1-219008"/></p>
<pre class="lstlisting" id="listing-334"><span class="koboSpan" id="kobo.342.1" xmlns="http://www.w3.org/1999/xhtml">

import pennylane as qml 
 
import numpy as np 
 
 
 
import torch 
 
import torch.nn as nn 
 
 
 
seed = 1234 
 
np.random.seed(seed) 
 
torch.manual_seed(seed)
</span></pre>
<p><span class="koboSpan" id="kobo.343.1" xmlns="http://www.w3.org/1999/xhtml">We will </span><span id="dx1-219018"/><span class="koboSpan" id="kobo.344.1" xmlns="http://www.w3.org/1999/xhtml">construct the state </span><span class="koboSpan" id="kobo.345.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.346.1" xmlns="http://www.w3.org/1999/xhtml"> using the universal one-qubit gate </span><span class="koboSpan" id="kobo.347.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="U_{3}(\varphi,\theta,\delta)" class="math inline" src="../media/file1458.png" style="vertical-align:middle" title="U_{3}(\varphi,\theta,\delta)"/></span><span class="koboSpan" id="kobo.348.1" xmlns="http://www.w3.org/1999/xhtml"> since, as we learned back in </span><em><span class="koboSpan" id="kobo.349.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch008.xhtml#x1-180001"><em><span class="koboSpan" id="kobo.350.1" xmlns="http://www.w3.org/1999/xhtml">1</span></em></a><span class="koboSpan" id="kobo.351.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.352.1" xmlns="http://www.w3.org/1999/xhtml">Foundations of Quantum Computing</span></em><span class="koboSpan" id="kobo.353.1" xmlns="http://www.w3.org/1999/xhtml">, it allows us to create any one-qubit state. </span><span class="koboSpan" id="kobo.353.2" xmlns="http://www.w3.org/1999/xhtml">In particular, we will feed it the values </span><span class="koboSpan" id="kobo.354.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. \varphi = \pi\slash 3 \right." class="math inline" src="../media/file1459.png" style="vertical-align:middle" title="\left. \varphi = \pi\slash 3 \right."/></span><span class="koboSpan" id="kobo.355.1" xmlns="http://www.w3.org/1999/xhtml">, </span><span class="koboSpan" id="kobo.356.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. \theta = \pi\slash 4 \right." class="math inline" src="../media/file1460.png" style="vertical-align:middle" title="\left. \theta = \pi\slash 4 \right."/></span><span class="koboSpan" id="kobo.357.1" xmlns="http://www.w3.org/1999/xhtml">, and </span><span class="koboSpan" id="kobo.358.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. \delta = \pi\slash 5 \right." class="math inline" src="../media/file1461.png" style="vertical-align:middle" title="\left. \delta = \pi\slash 5 \right."/></span><span class="koboSpan" id="kobo.359.1" xmlns="http://www.w3.org/1999/xhtml">:</span></p>
<pre class="lstlisting" id="listing-335"><span class="koboSpan" id="kobo.360.1" xmlns="http://www.w3.org/1999/xhtml">

phi = np.pi / 3 
 
theta = np.pi / 4 
 
delta = np.pi / 5
</span></pre>
<p><span class="koboSpan" id="kobo.361.1" xmlns="http://www.w3.org/1999/xhtml">With these values set, we can define a function that will construct the circuit that will prepare </span><span class="koboSpan" id="kobo.362.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.363.1" xmlns="http://www.w3.org/1999/xhtml">:</span></p>
<pre class="lstlisting" id="listing-336"><span class="koboSpan" id="kobo.364.1" xmlns="http://www.w3.org/1999/xhtml">

def PrepareTrueState(): 
 
    qml.U3(theta, phi, delta, wires = 0)
</span></pre>
<p><span class="koboSpan" id="kobo.365.1" xmlns="http://www.w3.org/1999/xhtml">Notice that we have defined this as a function and not as a quantum node. </span><span class="koboSpan" id="kobo.365.2" xmlns="http://www.w3.org/1999/xhtml">That’s because, for the purposes of the training, we are not interested in running any of the components of the quantum GAN individually. </span><span class="koboSpan" id="kobo.365.3" xmlns="http://www.w3.org/1999/xhtml">We will instead have to run them in composition. </span><span class="koboSpan" id="kobo.365.4" xmlns="http://www.w3.org/1999/xhtml">For instance, we will have to run this circuit that we’ve just defined composed with the discriminator.</span></p>
<p><span class="koboSpan" id="kobo.366.1" xmlns="http://www.w3.org/1999/xhtml">Now that we have a circuit that can prepare </span><span class="koboSpan" id="kobo.367.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.368.1" xmlns="http://www.w3.org/1999/xhtml">, it’s time for us to think about the two core components of our QGAN: the generator and the discriminator. </span><span class="koboSpan" id="kobo.368.2" xmlns="http://www.w3.org/1999/xhtml">Specifically, we will have to find some suitable variational forms for them.</span></p>
<p><span class="koboSpan" id="kobo.369.1" xmlns="http://www.w3.org/1999/xhtml">For the generator, we will </span><span id="dx1-219024"/><span class="koboSpan" id="kobo.370.1" xmlns="http://www.w3.org/1999/xhtml">simply use a parametrized U3 gate, whereas, for the discriminator, we will use a variation of the two-local variational form. </span><span class="koboSpan" id="kobo.370.2" xmlns="http://www.w3.org/1999/xhtml">These can be implemented as follows:</span></p>
<pre class="lstlisting" id="listing-337"><span class="koboSpan" id="kobo.371.1" xmlns="http://www.w3.org/1999/xhtml">

def GeneratorVF(weights): 
 
    qml.U3(weights[0], weights[1], weights[2], wires = 0) 
 
 
 
def DiscriminatorVF(nqubits, weights, reps = 1): 
 
    par = 0 # Index for parameters. 
 
    </span><span class="koboSpan" id="kobo.371.2" xmlns="http://www.w3.org/1999/xhtml">for rep in range(reps): 
 
        for q in range(nqubits): 
 
            qml.RX(weights[par], wires = q) 
 
            par += 1 
 
            qml.RY(weights[par], wires = q) 
 
            par += 1 
 
            qml.RZ(weights[par], wires = q) 
 
            par += 1 
 
        for i in range(nqubits - 1): 
 
            qml.CNOT(wires = [i, i + 1]) 
 
 
 
    for q in range(nqubits): 
 
        qml.RX(weights[par], wires = q) 
 
        par += 1 
 
        qml.RY(weights[par], wires = q) 
 
        par += 1 
 
        qml.RZ(weights[par], wires = q) 
 
        par += 1
</span></pre>
<p><span class="koboSpan" id="kobo.372.1" xmlns="http://www.w3.org/1999/xhtml">You can see a graphical representation of the discriminator variational form in </span><em><span class="koboSpan" id="kobo.373.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.5"><em><span class="koboSpan" id="kobo.374.1" xmlns="http://www.w3.org/1999/xhtml">12.5</span></em></a><span class="koboSpan" id="kobo.375.1" xmlns="http://www.w3.org/1999/xhtml">; its implementation is mostly </span><span id="dx1-219048"/><span class="koboSpan" id="kobo.376.1" xmlns="http://www.w3.org/1999/xhtml">analogous to that of the two-local variational form with just a few small differences. </span><span class="koboSpan" id="kobo.376.2" xmlns="http://www.w3.org/1999/xhtml">On a very minor note, we have renamed the vector of optimizable parameters to </span><code><span class="koboSpan" id="kobo.377.1" xmlns="http://www.w3.org/1999/xhtml">weights</span></code><span class="koboSpan" id="kobo.378.1" xmlns="http://www.w3.org/1999/xhtml"> (instead of </span><code><span class="koboSpan" id="kobo.379.1" xmlns="http://www.w3.org/1999/xhtml">theta</span></code><span class="koboSpan" id="kobo.380.1" xmlns="http://www.w3.org/1999/xhtml">) to avoid any sort of confusion with the angle </span><code><span class="koboSpan" id="kobo.381.1" xmlns="http://www.w3.org/1999/xhtml">theta</span></code><span class="koboSpan" id="kobo.382.1" xmlns="http://www.w3.org/1999/xhtml"> that defines </span><span class="koboSpan" id="kobo.383.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.384.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.385.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 12.5: Discriminator variational form on two qubits and two repetitions" src="../media/file1462.jpg"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure12.5"><strong><span class="koboSpan" id="kobo.386.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.5</span></strong><span class="koboSpan" id="kobo.387.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.388.1" xmlns="http://www.w3.org/1999/xhtml">Discriminator variational form on two qubits and two repetitions</span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.389.1" xmlns="http://www.w3.org/1999/xhtml">Taking advantage of these newly-defined variational forms, we will define the circuits of the generator and the discriminator as follows:</span></p>
<pre class="lstlisting" id="listing-338"><span class="koboSpan" id="kobo.390.1" xmlns="http://www.w3.org/1999/xhtml">

def Generator(weights): 
 
    GeneratorVF(weights) 
 
 
 
def Discriminator(weights): 
 
    DiscriminatorVF(2, weights, reps = 3)
</span></pre>
<p><span class="koboSpan" id="kobo.391.1" xmlns="http://www.w3.org/1999/xhtml">We are now ready to define the quantum nodes that we will use in the training. </span><span class="koboSpan" id="kobo.391.2" xmlns="http://www.w3.org/1999/xhtml">In the classifier, we shall take the measurement operation to be the computation of the expectation value of </span><span class="koboSpan" id="kobo.392.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M = \left| 0 \right\rangle\left\langle 0 \right|" class="math inline" src="../media/file1388.png" style="vertical-align:middle" title="M = \left| 0 \right\rangle\left\langle 0 \right|"/></span><span class="koboSpan" id="kobo.393.1" xmlns="http://www.w3.org/1999/xhtml"> on the first qubit. </span><span class="koboSpan" id="kobo.393.2" xmlns="http://www.w3.org/1999/xhtml">For this purpose, we may construct the matrix </span><span class="koboSpan" id="kobo.394.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.395.1" xmlns="http://www.w3.org/1999/xhtml"> as follows:</span></p>
<pre class="lstlisting" id="listing-339"><span class="koboSpan" id="kobo.396.1" xmlns="http://www.w3.org/1999/xhtml">

state_0 = [[1], [0]] 
 
M = state_0 * np.conj(state_0).T
</span></pre>
<p><span class="koboSpan" id="kobo.397.1" xmlns="http://www.w3.org/1999/xhtml">And we can now define two </span><span id="dx1-219058"/><span class="koboSpan" id="kobo.398.1" xmlns="http://www.w3.org/1999/xhtml">quantum nodes: one concatenating the generation of the state </span><span class="koboSpan" id="kobo.399.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.400.1" xmlns="http://www.w3.org/1999/xhtml"> with the discriminator, and one concatenating the generator with the discriminator. </span><span class="koboSpan" id="kobo.400.2" xmlns="http://www.w3.org/1999/xhtml">We can achieve this with the following piece of code:</span></p>
<pre class="lstlisting" id="listing-340"><span class="koboSpan" id="kobo.401.1" xmlns="http://www.w3.org/1999/xhtml">

dev = qml.device(’default.qubit’, wires = 2) 
 
 
 
@qml.qnode(dev, interface="torch", diff_method = "backprop") 
 
def true_discriminator(weights_dis): 
 
    PrepareTrueState() 
 
    Discriminator(weights_dis) 
 
    return qml.expval(qml.Hermitian(M, wires = [0])) 
 
 
 
 
 
@qml.qnode(dev, interface="torch", diff_method = "backprop") 
 
def generator_discriminator(weights_gen, weights_dis): 
 
    Generator(weights_gen) 
 
    Discriminator(weights_dis) 
 
    return qml.expval(qml.Hermitian(M, wires = [0]))
</span></pre>
<p><span class="koboSpan" id="kobo.402.1" xmlns="http://www.w3.org/1999/xhtml">The measurement operation is the computation of the expectation value of </span><span class="koboSpan" id="kobo.403.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.404.1" xmlns="http://www.w3.org/1999/xhtml"> on the first qubit in both nodes; since this operation is the output of the discriminator, these measurement operations need be identical. </span><span class="koboSpan" id="kobo.404.2" xmlns="http://www.w3.org/1999/xhtml">Notice, by the way, that, since the discriminator works on the two qubits of our device, we could have also used the expectation value of </span><span class="koboSpan" id="kobo.405.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.406.1" xmlns="http://www.w3.org/1999/xhtml"> on the second qubit.</span></p>
<section class="level4 subsubsectionHead" data-number="20.2.1.1" id="the-training-process">
<h3 class="subsubsectionHead" data-number="20.2.1.1"><span id="x1-22000012.2.1"><span class="koboSpan" id="kobo.407.1" xmlns="http://www.w3.org/1999/xhtml">The training process</span></span></h3>
<p><span class="koboSpan" id="kobo.408.1" xmlns="http://www.w3.org/1999/xhtml">Now we have fully set up our model, and we have defined all the nodes that we will use in its training. </span><span class="koboSpan" id="kobo.408.2" xmlns="http://www.w3.org/1999/xhtml">But there’s </span><span id="dx1-220001"/><span class="koboSpan" id="kobo.409.1" xmlns="http://www.w3.org/1999/xhtml">something essential that we haven’t yet defined: the loss functions of the discriminator and the generator.</span></p>
<p><span class="koboSpan" id="kobo.410.1" xmlns="http://www.w3.org/1999/xhtml">As we discussed before, a reasonable choice for the loss function of the discriminator of a GAN is the binary cross-entropy. </span><span class="koboSpan" id="kobo.410.2" xmlns="http://www.w3.org/1999/xhtml">In our case, our discriminator only has to classify two data points: the true state </span><span class="koboSpan" id="kobo.411.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.412.1" xmlns="http://www.w3.org/1999/xhtml"> with intended label </span><span class="koboSpan" id="kobo.413.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.414.1" xmlns="http://www.w3.org/1999/xhtml">, and the generated state </span><span class="koboSpan" id="kobo.415.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{g} \right\rangle" class="math inline" src="../media/file1463.png" style="vertical-align:middle" title="\left| \psi_{g} \right\rangle"/></span><span class="koboSpan" id="kobo.416.1" xmlns="http://www.w3.org/1999/xhtml"> with intended label </span><span class="koboSpan" id="kobo.417.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.418.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.418.2" xmlns="http://www.w3.org/1999/xhtml">Therefore, if we let </span><span class="koboSpan" id="kobo.419.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="D" class="math inline" src="../media/file1101.png" style="vertical-align:middle" title="D"/></span><span class="koboSpan" id="kobo.420.1" xmlns="http://www.w3.org/1999/xhtml"> denote the action of the discriminator under a certain configuration, the binary cross-entropy loss would be</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.421.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="L_{D} = - \frac{1}{2}\left( {\log\left( {1 - D(\left| \psi_{g} \right\rangle)} \right) + \log\left( {D(\left| \psi_{1} \right\rangle} \right)} \right)." class="math display" src="../media/file1464.png" style="vertical-align:middle" title="L_{D} = - \frac{1}{2}\left( {\log\left( {1 - D(\left| \psi_{g} \right\rangle)} \right) + \log\left( {D(\left| \psi_{1} \right\rangle} \right)} \right)."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.422.1" xmlns="http://www.w3.org/1999/xhtml">This loss function can be implemented with our previously-defined nodes as follows:</span></p>
<pre class="lstlisting" id="listing-341"><span class="koboSpan" id="kobo.423.1" xmlns="http://www.w3.org/1999/xhtml">

def discriminator_loss(weights_gen, weights_dis): 
 
 
 
    # Outcome of the discriminator with a generated state. 
 
    </span><span class="koboSpan" id="kobo.423.2" xmlns="http://www.w3.org/1999/xhtml">out_gen = generator_discriminator(weights_gen, weights_dis) 
 
 
 
    # Outcome of the discriminator with the true state. 
 
    </span><span class="koboSpan" id="kobo.423.3" xmlns="http://www.w3.org/1999/xhtml">out_true = true_discriminator(weights_dis) 
 
 
 
    return -(torch.log(1 - out_gen) + torch.log(out_true))/2
</span></pre>
<p><span class="koboSpan" id="kobo.424.1" xmlns="http://www.w3.org/1999/xhtml">Now, what about the loss of the generator? </span><span class="koboSpan" id="kobo.424.2" xmlns="http://www.w3.org/1999/xhtml">We already know that the goal of the generator is to fool the discriminator into misclassifying the generated state as real. </span><span class="koboSpan" id="kobo.424.3" xmlns="http://www.w3.org/1999/xhtml">Moreover, we have also mentioned a reasonable generator loss function is</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.425.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="L_{G} = - \log\left( {D(\left| \psi_{g} \right\rangle)} \right)." class="math display" src="../media/file1465.png" style="vertical-align:middle" title="L_{G} = - \log\left( {D(\left| \psi_{g} \right\rangle)} \right)."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.426.1" xmlns="http://www.w3.org/1999/xhtml">This would be the binary cross-entropy loss of the discriminator if it were tasked with classifying the generated state as the true state.</span></p>
<p><span class="koboSpan" id="kobo.427.1" xmlns="http://www.w3.org/1999/xhtml">We can easily implement this loss as follows:</span></p>
<pre class="lstlisting" id="listing-342"><span class="koboSpan" id="kobo.428.1" xmlns="http://www.w3.org/1999/xhtml">

def generator_loss(weights_gen, weights_dis): 
 
    out_gen = generator_discriminator(weights_gen, weights_dis) 
 
    return -torch.log(out_gen)
</span></pre>
<p><span class="koboSpan" id="kobo.429.1" xmlns="http://www.w3.org/1999/xhtml">And that defines all our losses. </span><span class="koboSpan" id="kobo.429.2" xmlns="http://www.w3.org/1999/xhtml">Let’s now </span><span id="dx1-220014"/><span class="koboSpan" id="kobo.430.1" xmlns="http://www.w3.org/1999/xhtml">prepare ourselves for the training process. </span><span class="koboSpan" id="kobo.430.2" xmlns="http://www.w3.org/1999/xhtml">First and foremost, let’s initialize the weights of the generator and the discriminator to a tensor with random values:</span></p>
<pre class="lstlisting" id="listing-343"><span class="koboSpan" id="kobo.431.1" xmlns="http://www.w3.org/1999/xhtml">

weights_gen = torch.rand(3, requires_grad = True) 
 
weights_dis = torch.rand((3 + 1) * 2 * 3, requires_grad = True)
</span></pre>
<p><span class="koboSpan" id="kobo.432.1" xmlns="http://www.w3.org/1999/xhtml">The dimensions of these arrays are justified from the fact that the generator uses </span><span class="koboSpan" id="kobo.433.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="3" class="math inline" src="../media/file472.png" style="vertical-align:middle" title="3"/></span><span class="koboSpan" id="kobo.434.1" xmlns="http://www.w3.org/1999/xhtml"> weights and the variational form of the discriminator has </span><span class="koboSpan" id="kobo.435.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="3 + 1" class="math inline" src="../media/file1466.png" style="vertical-align:middle" title="3 + 1"/></span><span class="koboSpan" id="kobo.436.1" xmlns="http://www.w3.org/1999/xhtml"> groups of parametrized gates, with </span><span class="koboSpan" id="kobo.437.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="3" class="math inline" src="../media/file472.png" style="vertical-align:middle" title="3"/></span><span class="koboSpan" id="kobo.438.1" xmlns="http://www.w3.org/1999/xhtml"> parameters being used on each of the </span><span class="koboSpan" id="kobo.439.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2" class="math inline" src="../media/file302.png" style="vertical-align:middle" title="2"/></span><span class="koboSpan" id="kobo.440.1" xmlns="http://www.w3.org/1999/xhtml"> qubits on which the form acts. </span><span class="koboSpan" id="kobo.440.2" xmlns="http://www.w3.org/1999/xhtml">Also, remember that we need to set </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.441.1" xmlns="http://www.w3.org/1999/xhtml">requires_grad</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.442.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.443.1" xmlns="http://www.w3.org/1999/xhtml">True</span></code></span></span><span class="koboSpan" id="kobo.444.1" xmlns="http://www.w3.org/1999/xhtml"> in order for PyTorch to be able to compute gradients on these weights later on.</span></p>
<p><span class="koboSpan" id="kobo.445.1" xmlns="http://www.w3.org/1999/xhtml">Now we can define the optimizers that we will use in the training. </span><span class="koboSpan" id="kobo.445.2" xmlns="http://www.w3.org/1999/xhtml">For this problem, we will rely on the stochastic gradient descent algorithm, which is a more simple version of the Adam optimizer that we used in previous chapters (see </span><em><span class="koboSpan" id="kobo.446.1" xmlns="http://www.w3.org/1999/xhtml">Section</span></em> <a href="ch017.xhtml#x1-1520008.2.3"><em><span class="koboSpan" id="kobo.447.1" xmlns="http://www.w3.org/1999/xhtml">8.2.3</span></em></a><span class="koboSpan" id="kobo.448.1" xmlns="http://www.w3.org/1999/xhtml"> for a refresher). </span><span class="koboSpan" id="kobo.448.2" xmlns="http://www.w3.org/1999/xhtml">When invoking the optimizers, we have to provide an array or dictionary with the parameters that we want our optimizer to look after. </span><span class="koboSpan" id="kobo.448.3" xmlns="http://www.w3.org/1999/xhtml">Back when we defined PyTorch models as subclasses of </span><code><span class="koboSpan" id="kobo.449.1" xmlns="http://www.w3.org/1999/xhtml">nn</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.450.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.451.1" xmlns="http://www.w3.org/1999/xhtml">Module</span></code><span class="koboSpan" id="kobo.452.1" xmlns="http://www.w3.org/1999/xhtml">, we could just get this with the </span><code><span class="koboSpan" id="kobo.453.1" xmlns="http://www.w3.org/1999/xhtml">parameters</span></code><span class="koboSpan" id="kobo.454.1" xmlns="http://www.w3.org/1999/xhtml"> method, but in this case, we will create the list ourselves. </span><span class="koboSpan" id="kobo.454.2" xmlns="http://www.w3.org/1999/xhtml">This can be done as follows:</span></p>
<pre class="lstlisting" id="listing-344"><span class="koboSpan" id="kobo.455.1" xmlns="http://www.w3.org/1999/xhtml">

optg = torch.optim.SGD([weights_gen], lr = 0.5) 
 
optd = torch.optim.SGD([weights_dis], lr = 0.5)
</span></pre>
<p><span class="koboSpan" id="kobo.456.1" xmlns="http://www.w3.org/1999/xhtml">In this call to the optimizers, we have set their learning rate to </span><span class="koboSpan" id="kobo.457.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.5" class="math inline" src="../media/file1166.png" style="vertical-align:middle" title="0.5"/></span><span class="koboSpan" id="kobo.458.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.459.1" xmlns="http://www.w3.org/1999/xhtml">And those are all the ingredients needed to </span><span id="dx1-220019"/><span class="koboSpan" id="kobo.460.1" xmlns="http://www.w3.org/1999/xhtml">train our model. </span><span class="koboSpan" id="kobo.460.2" xmlns="http://www.w3.org/1999/xhtml">We can execute the following piece of code in order to do so:</span></p>
<pre class="lstlisting" id="listing-345"><span class="koboSpan" id="kobo.461.1" xmlns="http://www.w3.org/1999/xhtml">

dis_losses = [] # Discriminator losses. 
 
</span><span class="koboSpan" id="kobo.461.2" xmlns="http://www.w3.org/1999/xhtml">gen_losses = [] # Generator losses. 
 
</span><span class="koboSpan" id="kobo.461.3" xmlns="http://www.w3.org/1999/xhtml">log_weights = [] # Generator weights. 
 
 
 
</span><span class="koboSpan" id="kobo.461.4" xmlns="http://www.w3.org/1999/xhtml">ncycles = 150 # Number of training cycles. 
 
 
 
</span><span class="koboSpan" id="kobo.461.5" xmlns="http://www.w3.org/1999/xhtml">for i in range(ncycles): 
 
    # Train the discriminator. 
 
    </span><span class="koboSpan" id="kobo.461.6" xmlns="http://www.w3.org/1999/xhtml">optd.zero_grad() 
 
    lossd = discriminator_loss(weights_gen.detach(), weights_dis) 
 
    lossd.backward() 
 
    optd.step() 
 
 
 
    # Train the generator. 
 
    </span><span class="koboSpan" id="kobo.461.7" xmlns="http://www.w3.org/1999/xhtml">optg.zero_grad() 
 
    lossg = generator_loss(weights_gen, weights_dis.detach()) 
 
    lossg.backward() 
 
    optg.step() 
 
 
 
    # Log losses and weights. 
 
    </span><span class="koboSpan" id="kobo.461.8" xmlns="http://www.w3.org/1999/xhtml">lossd = float(lossd) 
 
    lossg = float(lossg) 
 
    dis_losses.append(lossd) 
 
    gen_losses.append(lossg) 
 
    log_weights.append(weights_gen.detach().clone().numpy()) 
 
 
 
    # Print the losses every fifteen cycles. 
 
    </span><span class="koboSpan" id="kobo.461.9" xmlns="http://www.w3.org/1999/xhtml">if (np.mod((i+1), 15) == 0): 
 
        print("Epoch", i+1, end= " ") 
 
        print("| Discriminator loss:", round(lossd, 4), end = " ") 
 
        print("| Generator loss:", round(lossg, 4))
</span></pre>
<p><span class="koboSpan" id="kobo.462.1" xmlns="http://www.w3.org/1999/xhtml">There is quite a lot to </span><span id="dx1-220051"/><span class="koboSpan" id="kobo.463.1" xmlns="http://www.w3.org/1999/xhtml">digest here. </span><span class="koboSpan" id="kobo.463.2" xmlns="http://www.w3.org/1999/xhtml">In the first few lines of code, we are simply defining some arrays in which we will store data as the training progresses. </span><span class="koboSpan" id="kobo.463.3" xmlns="http://www.w3.org/1999/xhtml">The arrays </span><code><span class="koboSpan" id="kobo.464.1" xmlns="http://www.w3.org/1999/xhtml">dis_losses</span></code><span class="koboSpan" id="kobo.465.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.466.1" xmlns="http://www.w3.org/1999/xhtml">gen_losses</span></code><span class="koboSpan" id="kobo.467.1" xmlns="http://www.w3.org/1999/xhtml"> will save the discriminator and generator losses in each training cycle, and the array </span><code><span class="koboSpan" id="kobo.468.1" xmlns="http://www.w3.org/1999/xhtml">log_weights</span></code><span class="koboSpan" id="kobo.469.1" xmlns="http://www.w3.org/1999/xhtml"> will store the generator weights obtained at the end of each training cycle. </span><span class="koboSpan" id="kobo.469.2" xmlns="http://www.w3.org/1999/xhtml">We will later use this information in order to assess the effectiveness of the training.</span></p>
<p><span class="koboSpan" id="kobo.470.1" xmlns="http://www.w3.org/1999/xhtml">We have fixed the training to run for </span><span class="koboSpan" id="kobo.471.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="150" class="math inline" src="../media/file1467.png" style="vertical-align:middle" title="150"/></span><span class="koboSpan" id="kobo.472.1" xmlns="http://www.w3.org/1999/xhtml"> optimization cycles. </span><span class="koboSpan" id="kobo.472.2" xmlns="http://www.w3.org/1999/xhtml">In each of them, we will optimize the values of the discriminator, then optimize those of the generator, and, finally, log all the results. </span><span class="koboSpan" id="kobo.472.3" xmlns="http://www.w3.org/1999/xhtml">Let’s go through it step by step:</span></p>
<ol>
<li><div id="x1-220053x1">
<p><span class="koboSpan" id="kobo.473.1" xmlns="http://www.w3.org/1999/xhtml">When we optimize the discriminator, we reset its optimizer (</span><code><span class="koboSpan" id="kobo.474.1" xmlns="http://www.w3.org/1999/xhtml">optd</span></code><span class="koboSpan" id="kobo.475.1" xmlns="http://www.w3.org/1999/xhtml">) and then compute the discriminator loss function and store it in </span><code><span class="koboSpan" id="kobo.476.1" xmlns="http://www.w3.org/1999/xhtml">lossd</span></code><span class="koboSpan" id="kobo.477.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.477.2" xmlns="http://www.w3.org/1999/xhtml">Observe that, when we send the generator weights, we pass them through the </span><code><span class="koboSpan" id="kobo.478.1" xmlns="http://www.w3.org/1999/xhtml">detach</span></code><span class="koboSpan" id="kobo.479.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.479.2" xmlns="http://www.w3.org/1999/xhtml">This method removes the need to compute gradients for these weights. </span><span class="koboSpan" id="kobo.479.3" xmlns="http://www.w3.org/1999/xhtml">The discriminator optimizer is not going to touch those weights either way, so this will save us some computation time. </span><span class="koboSpan" id="kobo.479.4" xmlns="http://www.w3.org/1999/xhtml">Once we have the loss, we just compute its gradients with the </span><code><span class="koboSpan" id="kobo.480.1" xmlns="http://www.w3.org/1999/xhtml">backward</span></code><span class="koboSpan" id="kobo.481.1" xmlns="http://www.w3.org/1999/xhtml"> method and run a step of the discriminator optimizer.</span></p>
</div></li>
<li><div id="x1-220055x2">
<p><span class="koboSpan" id="kobo.482.1" xmlns="http://www.w3.org/1999/xhtml">The optimization of the generator is fully analogous. </span><span class="koboSpan" id="kobo.482.2" xmlns="http://www.w3.org/1999/xhtml">We simply use the generator optimizer </span><code><span class="koboSpan" id="kobo.483.1" xmlns="http://www.w3.org/1999/xhtml">optg</span></code><span class="koboSpan" id="kobo.484.1" xmlns="http://www.w3.org/1999/xhtml"> on the gradients obtained from the generator loss </span><code><span class="koboSpan" id="kobo.485.1" xmlns="http://www.w3.org/1999/xhtml">lossg</span></code><span class="koboSpan" id="kobo.486.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.486.2" xmlns="http://www.w3.org/1999/xhtml">Of course, we detach the discriminator weights in the call to the generator loss function instead of the generator weights.</span></p>
</div></li>
<li><div id="x1-220057x3">
<p><span class="koboSpan" id="kobo.487.1" xmlns="http://www.w3.org/1999/xhtml">Finally, we log the values of the losses. </span><span class="koboSpan" id="kobo.487.2" xmlns="http://www.w3.org/1999/xhtml">For this purpose, we simply store the values of the losses that we computed in the training cycle. </span><span class="koboSpan" id="kobo.487.3" xmlns="http://www.w3.org/1999/xhtml">These will probably be different from the ones at the end of the cycle, but they will still be informative enough.</span></p>
<p><span class="koboSpan" id="kobo.488.1" xmlns="http://www.w3.org/1999/xhtml">After this, we store the generator weights. </span><span class="koboSpan" id="kobo.488.2" xmlns="http://www.w3.org/1999/xhtml">Please observe the call to the </span><code><span class="koboSpan" id="kobo.489.1" xmlns="http://www.w3.org/1999/xhtml">clone</span></code><span class="koboSpan" id="kobo.490.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.490.2" xmlns="http://www.w3.org/1999/xhtml">This call ensures that we are getting a copy of the weights and not a reference to the weights tensor. </span><span class="koboSpan" id="kobo.490.3" xmlns="http://www.w3.org/1999/xhtml">If we didn’t call this method, all the weight arrays in </span><code><span class="koboSpan" id="kobo.491.1" xmlns="http://www.w3.org/1999/xhtml">log_weights</span></code><span class="koboSpan" id="kobo.492.1" xmlns="http://www.w3.org/1999/xhtml"> would reference the same tensor and their values would all be the same and would change (simultaneously) as the training progresses!</span></p>
<p><span class="koboSpan" id="kobo.493.1" xmlns="http://www.w3.org/1999/xhtml">Finally, we print some information about the training. </span><span class="koboSpan" id="kobo.493.2" xmlns="http://www.w3.org/1999/xhtml">Since we are going to execute this loop for </span><span class="koboSpan" id="kobo.494.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="150" class="math inline" src="../media/file1467.png" style="vertical-align:middle" title="150"/></span><span class="koboSpan" id="kobo.495.1" xmlns="http://www.w3.org/1999/xhtml"> training cycles and the training will be fast, we shall only print information every </span><span class="koboSpan" id="kobo.496.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="15" class="math inline" src="../media/file599.png" style="vertical-align:middle" title="15"/></span><span class="koboSpan" id="kobo.497.1" xmlns="http://www.w3.org/1999/xhtml"> cycles.</span></p>
</div></li>
</ol>
<p><span class="koboSpan" id="kobo.498.1" xmlns="http://www.w3.org/1999/xhtml">Notice how, instead of fully </span><span id="dx1-220058"/><span class="koboSpan" id="kobo.499.1" xmlns="http://www.w3.org/1999/xhtml">training the discriminator and the generator in an alternating fashion, we are optimizing them in an alternating fashion in every training cycle.</span></p>
<p><span class="koboSpan" id="kobo.500.1" xmlns="http://www.w3.org/1999/xhtml">The output that we get upon running the preceding code is the following:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.501.1" xmlns="http://www.w3.org/1999/xhtml">

 
Epoch 15 | Discriminator loss: 0.6701 | Generator loss: 0.7065 
Epoch 30 | Discriminator loss: 0.6987 | Generator loss: 0.6791 
Epoch 45 | Discriminator loss: 0.6931 | Generator loss: 0.6992 
Epoch 60 | Discriminator loss: 0.6931 | Generator loss: 0.6924 
Epoch 75 | Discriminator loss: 0.6932 | Generator loss: 0.6927 
Epoch 90 | Discriminator loss: 0.6931 | Generator loss: 0.6934 
Epoch 105 | Discriminator loss: 0.6931 | Generator loss: 0.6931 
Epoch 120 | Discriminator loss: 0.6931 | Generator loss: 0.6931 
Epoch 135 | Discriminator loss: 0.6931 | Generator loss: 0.6932 
Epoch 150 | Discriminator loss: 0.6931 | Generator loss: 0.6931
    
</span></pre>
<p><span class="koboSpan" id="kobo.502.1" xmlns="http://www.w3.org/1999/xhtml">Just by looking at this raw output, we can see that there is a chance that our training may have been successful: the discriminator loss and the generator loss are both approaching </span><span class="koboSpan" id="kobo.503.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. - \log 1\slash 2 \right." class="math inline" src="../media/file1468.png" style="vertical-align:middle" title="\left. - \log 1\slash 2 \right."/></span><span class="koboSpan" id="kobo.504.1" xmlns="http://www.w3.org/1999/xhtml">, just as they should do at the optimal point. </span><span class="koboSpan" id="kobo.504.2" xmlns="http://www.w3.org/1999/xhtml">This is a good sign!</span></p>
<p><span class="koboSpan" id="kobo.505.1" xmlns="http://www.w3.org/1999/xhtml">In order to have a better insight on the evolution of these losses, we may use the </span><code><span class="koboSpan" id="kobo.506.1" xmlns="http://www.w3.org/1999/xhtml">gen_losses</span></code><span class="koboSpan" id="kobo.507.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.508.1" xmlns="http://www.w3.org/1999/xhtml">dis_losses</span></code><span class="koboSpan" id="kobo.509.1" xmlns="http://www.w3.org/1999/xhtml"> array in order to plot their evolution. </span><span class="koboSpan" id="kobo.509.2" xmlns="http://www.w3.org/1999/xhtml">This can be done as follows:</span></p>
<pre class="lstlisting" id="listing-346"><span class="koboSpan" id="kobo.510.1" xmlns="http://www.w3.org/1999/xhtml">

import matplotlib.pyplot as plt 
 
epochs = np.array(range(len(gen_losses))) + 1 
 
plt.plot(epochs, gen_losses, label = "Generator loss") 
 
plt.plot(epochs, dis_losses, label = "Discriminator loss") 
 
plt.xlabel("Epoch") 
 
plt.legend()
</span></pre>
<p><span class="koboSpan" id="kobo.511.1" xmlns="http://www.w3.org/1999/xhtml">The resulting graph can be found in </span><em><span class="koboSpan" id="kobo.512.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.6"><em><span class="koboSpan" id="kobo.513.1" xmlns="http://www.w3.org/1999/xhtml">12.6</span></em></a><span class="koboSpan" id="kobo.514.1" xmlns="http://www.w3.org/1999/xhtml"> and, indeed, we can see a nice trend from which to draw some optimism.</span></p>
<figure>
<span class="koboSpan" id="kobo.515.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 12.6: Evolution of the losses of the discriminator and the generator along the training process " src="../media/file1469.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure12.6"><strong><span class="koboSpan" id="kobo.516.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.6</span></strong><span class="koboSpan" id="kobo.517.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.518.1" xmlns="http://www.w3.org/1999/xhtml">Evolution of the losses of the discriminator and the generator along the training process </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.519.1" xmlns="http://www.w3.org/1999/xhtml">But now comes the </span><span id="dx1-220078"/><span class="koboSpan" id="kobo.520.1" xmlns="http://www.w3.org/1999/xhtml">moment of truth. </span><span class="koboSpan" id="kobo.520.2" xmlns="http://www.w3.org/1999/xhtml">Let’s see if, indeed, our model has learned as we wanted it to. </span><span class="koboSpan" id="kobo.520.3" xmlns="http://www.w3.org/1999/xhtml">We mentioned in the previous section that, when training generative adversarial networks, the best criteria for determining whether a training process was successful or not depends on the problem at hand. </span><span class="koboSpan" id="kobo.520.4" xmlns="http://www.w3.org/1999/xhtml">In our case, our training will be successful if the state returned by the generator is close to </span><span class="koboSpan" id="kobo.521.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.522.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.523.1" xmlns="http://www.w3.org/1999/xhtml">Now, how do we determine the state vector of a qubit? </span><span class="koboSpan" id="kobo.523.2" xmlns="http://www.w3.org/1999/xhtml">It turns out that the state of a qubit is fully characterized (up to an unimportant global phase, as we saw back in </span><em><span class="koboSpan" id="kobo.524.1" xmlns="http://www.w3.org/1999/xhtml">Section</span></em> <em/> <a href="ch008.xhtml#x1-250001.3.4"><em><span class="koboSpan" id="kobo.525.1" xmlns="http://www.w3.org/1999/xhtml">1.3.4</span></em></a><span class="koboSpan" id="kobo.526.1" xmlns="http://www.w3.org/1999/xhtml">) by its Bloch sphere coordinates. </span><span class="koboSpan" id="kobo.526.2" xmlns="http://www.w3.org/1999/xhtml">And now that we’ve come across these coordinates, let’s learn how to compute them with an exercise that we hope you will find interesting — although, admittedly, is slightly orthogonal to this chapter.</span></p>
<div class="tcolorbox questionx" id="tcolobox-219">
<span id="x1-220080x12.2.1"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.527.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 12.2</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.528.1" xmlns="http://www.w3.org/1999/xhtml">Prove that the Bloch sphere coordinates of a one-qubit state are the expectation values of the observables given by the three Pauli matrices </span><span class="koboSpan" id="kobo.529.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="X" class="math inline" src="../media/file9.png" style="vertical-align:middle" title="X"/></span><span class="koboSpan" id="kobo.530.1" xmlns="http://www.w3.org/1999/xhtml">, </span><span class="koboSpan" id="kobo.531.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Y" class="math inline" src="../media/file11.png" style="vertical-align:middle" title="Y"/></span><span class="koboSpan" id="kobo.532.1" xmlns="http://www.w3.org/1999/xhtml">, and </span><span class="koboSpan" id="kobo.533.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Z" class="math inline" src="../media/file8.png" style="vertical-align:middle" title="Z"/></span><span class="koboSpan" id="kobo.534.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.535.1" xmlns="http://www.w3.org/1999/xhtml">We can prepare two </span><span id="dx1-220081"/><span class="koboSpan" id="kobo.536.1" xmlns="http://www.w3.org/1999/xhtml">quantum nodes that return these expectation values for both </span><span class="koboSpan" id="kobo.537.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{1} \right\rangle" class="math inline" src="../media/file177.png" style="vertical-align:middle" title="\left| \psi_{1} \right\rangle"/></span><span class="koboSpan" id="kobo.538.1" xmlns="http://www.w3.org/1999/xhtml"> and the state returned by the generator after the training. </span><span class="koboSpan" id="kobo.538.2" xmlns="http://www.w3.org/1999/xhtml">This can be done as follows:</span></p>
<pre class="lstlisting" id="listing-347"><span class="koboSpan" id="kobo.539.1" xmlns="http://www.w3.org/1999/xhtml">

@qml.qnode(dev, interface="torch") 
 
def generated_coordinates(weights_gen): 
 
    Generator(weights_gen) 
 
    return [qml.expval(qml.PauliX(0)), qml.expval(qml.PauliY(0)), 
 
    qml.expval(qml.PauliZ(0))] 
 
 
 
@qml.qnode(dev, interface="torch") 
 
def true_coordinates(): 
 
    PrepareTrueState() 
 
    return [qml.expval(qml.PauliX(0)), 
 
            qml.expval(qml.PauliY(0)), 
 
            qml.expval(qml.PauliZ(0))] 
 
 
 
print("Bloch coordinates") 
 
print("Generated:", generated_coordinates(weights_gen)) 
 
print("True:", true_coordinates())
</span></pre>
<p><span class="koboSpan" id="kobo.540.1" xmlns="http://www.w3.org/1999/xhtml">And the output that we get is the following:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.541.1" xmlns="http://www.w3.org/1999/xhtml">

 
Bloch angles 
Bloch coordinates 
Generated: tensor([0.3536, 0.6124, 0.7071], dtype=torch.float64, 
grad_fn=&lt;MvBackward0&gt;) 
True: tensor([0.3536, 0.6124, 0.7071], dtype=torch.float64)
    
</span></pre>
<p><span class="koboSpan" id="kobo.542.1" xmlns="http://www.w3.org/1999/xhtml">The outputs are identical, so we can safely say that our training has been a huge success!</span></p>
<p><span class="koboSpan" id="kobo.543.1" xmlns="http://www.w3.org/1999/xhtml">In order to bring this section to an end, we will visually explore how the state created by the generator has evolved </span><span id="dx1-220104"/><span class="koboSpan" id="kobo.544.1" xmlns="http://www.w3.org/1999/xhtml">throughout the training. </span><span class="koboSpan" id="kobo.544.2" xmlns="http://www.w3.org/1999/xhtml">We can do this using the array of weights </span><code><span class="koboSpan" id="kobo.545.1" xmlns="http://www.w3.org/1999/xhtml">log_weights</span></code><span class="koboSpan" id="kobo.546.1" xmlns="http://www.w3.org/1999/xhtml"> and the </span><code><span class="koboSpan" id="kobo.547.1" xmlns="http://www.w3.org/1999/xhtml">generated_coordinates</span></code><span class="koboSpan" id="kobo.548.1" xmlns="http://www.w3.org/1999/xhtml"> function that we have just defined. </span><span class="koboSpan" id="kobo.548.2" xmlns="http://www.w3.org/1999/xhtml">This function takes the weights of the generator as input, so we can get the Bloch coordinates of the generated states at any point in the training using the saved weights.</span></p>
<p><span class="koboSpan" id="kobo.549.1" xmlns="http://www.w3.org/1999/xhtml">We can accomplish this as follows:</span></p>
<pre class="lstlisting" id="listing-348"><span class="koboSpan" id="kobo.550.1" xmlns="http://www.w3.org/1999/xhtml">

true_coords = true_coordinates() 
 
def plot_coordinates(cycle): 
 
 
 
    coords = generated_coordinates(log_weights[cycle - 1]) 
 
 
 
    plt.bar(["X", "Y", "Z"], true_coords, width = 1, 
 
        color = "royalblue", label = "True coordinates") 
 
    plt.bar(["X", "Y", "Z"], coords, width = 0.5, 
 
        color = "black", label = "Generated coordinates") 
 
 
 
    plt.title(f"Training cycle {cycle}") 
 
    plt.legend()
</span></pre>
<p><span class="koboSpan" id="kobo.551.1" xmlns="http://www.w3.org/1999/xhtml">This function will plot, for any training cycle, a representation of the Bloch coordinates of the generated states superposed to the coordinates of the state that we want our QGAN to learn. </span><span class="koboSpan" id="kobo.551.2" xmlns="http://www.w3.org/1999/xhtml">In </span><em><span class="koboSpan" id="kobo.552.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.7"><em><span class="koboSpan" id="kobo.553.1" xmlns="http://www.w3.org/1999/xhtml">12.7</span></em></a><span class="koboSpan" id="kobo.554.1" xmlns="http://www.w3.org/1999/xhtml"> you can see the plots corresponding to a wide range of cycles.</span></p>
<figure>
<span class="koboSpan" id="kobo.555.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 12.7: Evolution of the Bloch coordinates of the generated state as the training progresses" src="../media/file1470.png"/></span>
<figcaption aria-hidden="true"><span id="Figure12.7"><strong><span class="koboSpan" id="kobo.556.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.7</span></strong></span><span class="koboSpan" id="kobo.557.1" xmlns="http://www.w3.org/1999/xhtml">: Evolution of the Bloch coordinates of the generated state as the training progresses</span></figcaption>
</figure>
<div class="tcolorbox questionx" id="tcolobox-220">
<span id="x1-220120x12.2.1"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.558.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 12.3</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.559.1" xmlns="http://www.w3.org/1999/xhtml">Try to replicate this example on a different state (you may need to increase the number of training cycles to reach convergence in some cases).</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.560.1" xmlns="http://www.w3.org/1999/xhtml">That brings this example to an end. </span><span class="koboSpan" id="kobo.560.2" xmlns="http://www.w3.org/1999/xhtml">Let’s now consider a different QGAN, this time implemented in Qiskit.</span></p>
</section>
</section>
</section>
<section class="level2 sectionHead" data-number="20.3" id="quantum-gans-in-qiskit">
<h1 class="sectionHead" data-number="20.3"><span class="titlemark"><span class="koboSpan" id="kobo.561.1" xmlns="http://www.w3.org/1999/xhtml">12.3 </span></span> <span id="x1-22100012.3"><span class="koboSpan" id="kobo.562.1" xmlns="http://www.w3.org/1999/xhtml">Quantum GANs in Qiskit</span></span></h1>
<p><span class="koboSpan" id="kobo.563.1" xmlns="http://www.w3.org/1999/xhtml">An early </span><span id="dx1-221001"/><span class="koboSpan" id="kobo.564.1" xmlns="http://www.w3.org/1999/xhtml">proposal of a QGAN was introduced by IBM researchers Zoufal, Lucchi, and Woerner </span><span class="cite"><span class="koboSpan" id="kobo.565.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xzoufal2019quantum"><span class="koboSpan" id="kobo.566.1" xmlns="http://www.w3.org/1999/xhtml">101</span></a><span class="koboSpan" id="kobo.567.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.568.1" xmlns="http://www.w3.org/1999/xhtml"> to learn a probability distribution using a QGAN with a quantum generator and a classical discriminator. </span><span class="koboSpan" id="kobo.568.2" xmlns="http://www.w3.org/1999/xhtml">In this section, we will discuss how to implement this kind of QGAN with Qiskit, so let’s put everything in more precise terms.</span></p>
<p><span class="koboSpan" id="kobo.569.1" xmlns="http://www.w3.org/1999/xhtml">This type of quantum GAN is given a dataset of real numbers that follow a certain probability distribution. </span><span class="koboSpan" id="kobo.569.2" xmlns="http://www.w3.org/1999/xhtml">This distribution may potentially be continuous, but it could be discretized to take some values </span><span class="koboSpan" id="kobo.570.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="m,m + 1,m + 2,\ldots,M - 1,M" class="math inline" src="../media/file1471.png" style="vertical-align:middle" title="m,m + 1,m + 2,\ldots,M - 1,M"/></span><span class="koboSpan" id="kobo.571.1" xmlns="http://www.w3.org/1999/xhtml"> with </span><span class="koboSpan" id="kobo.572.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="m &lt; M" class="math inline" src="../media/file1472.png" style="vertical-align:middle" title="m &lt; M"/></span><span class="koboSpan" id="kobo.573.1" xmlns="http://www.w3.org/1999/xhtml">; this will usually be done by fixing the values </span><span class="koboSpan" id="kobo.574.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="m" class="math inline" src="../media/file259.png" style="vertical-align:middle" title="m"/></span><span class="koboSpan" id="kobo.575.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.576.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.577.1" xmlns="http://www.w3.org/1999/xhtml">, rounding the samples and ignoring those that are smaller than </span><span class="koboSpan" id="kobo.578.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="m" class="math inline" src="../media/file259.png" style="vertical-align:middle" title="m"/></span><span class="koboSpan" id="kobo.579.1" xmlns="http://www.w3.org/1999/xhtml"> or bigger than </span><span class="koboSpan" id="kobo.580.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.581.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.581.2" xmlns="http://www.w3.org/1999/xhtml">Each of the resulting labels </span><span class="koboSpan" id="kobo.582.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j = m,\ldots,M" class="math inline" src="../media/file1473.png" style="vertical-align:middle" title="j = m,\ldots,M"/></span><span class="koboSpan" id="kobo.583.1" xmlns="http://www.w3.org/1999/xhtml"> will have a certain probability </span><span class="koboSpan" id="kobo.584.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="p_{j}" class="math inline" src="../media/file1474.png" style="vertical-align:middle" title="p_{j}"/></span><span class="koboSpan" id="kobo.585.1" xmlns="http://www.w3.org/1999/xhtml"> of appearing in the dataset. </span><span class="koboSpan" id="kobo.585.2" xmlns="http://www.w3.org/1999/xhtml">That is the distribution that we want the generator in our QGAN to learn.</span></p>
<p><span class="koboSpan" id="kobo.586.1" xmlns="http://www.w3.org/1999/xhtml">And what does the generator of these QGANs look like? </span><span class="koboSpan" id="kobo.586.2" xmlns="http://www.w3.org/1999/xhtml">It is a quantum generator that is dependent on some classical parameters. </span><span class="koboSpan" id="kobo.586.3" xmlns="http://www.w3.org/1999/xhtml">It needs to be designed to have </span><span class="koboSpan" id="kobo.587.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.588.1" xmlns="http://www.w3.org/1999/xhtml"> qubits in such a way that </span><span class="koboSpan" id="kobo.589.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M - m &lt; 2^{n}" class="math inline" src="../media/file1475.png" style="vertical-align:middle" title="M - m &lt; 2^{n}"/></span><span class="koboSpan" id="kobo.590.1" xmlns="http://www.w3.org/1999/xhtml">, so that we may assign, to each possible outcome </span><span class="koboSpan" id="kobo.591.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="r" class="math inline" src="../media/file1337.png" style="vertical-align:middle" title="r"/></span><span class="koboSpan" id="kobo.592.1" xmlns="http://www.w3.org/1999/xhtml"> after a measurement in the computational basis of the generator, a label </span><span class="koboSpan" id="kobo.593.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\alpha(r)" class="math inline" src="../media/file1476.png" style="vertical-align:middle" title="\alpha(r)"/></span><span class="koboSpan" id="kobo.594.1" xmlns="http://www.w3.org/1999/xhtml"> in </span><span class="koboSpan" id="kobo.595.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="m,\ldots M" class="math inline" src="../media/file1477.png" style="vertical-align:middle" title="m,\ldots M"/></span><span class="koboSpan" id="kobo.596.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.596.2" xmlns="http://www.w3.org/1999/xhtml">Thus, the goal of the training will be for the state returned by the generator to be as close as possible to</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.597.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\sum\limits_{r}\sqrt{p_{\alpha(r)}}\left| r \right\rangle." class="math display" src="../media/file1478.png" style="vertical-align:middle" title="\sum\limits_{r}\sqrt{p_{\alpha(r)}}\left| r \right\rangle."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.598.1" xmlns="http://www.w3.org/1999/xhtml">In this way, measuring samples from the trained generator should be equivalent to extracting more data samples from the original distribution, because the probability of measuring </span><span class="koboSpan" id="kobo.599.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| r \right\rangle" class="math inline" src="../media/file1479.png" style="vertical-align:middle" title="\left| r \right\rangle"/></span><span class="koboSpan" id="kobo.600.1" xmlns="http://www.w3.org/1999/xhtml"> (which is associated to label </span><span class="koboSpan" id="kobo.601.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\alpha(r)" class="math inline" src="../media/file1476.png" style="vertical-align:middle" title="\alpha(r)"/></span><span class="koboSpan" id="kobo.602.1" xmlns="http://www.w3.org/1999/xhtml">) is exactly </span><span class="koboSpan" id="kobo.603.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \sqrt{p_{\alpha(r)}} \right|^{2} = p_{\alpha(r)}" class="math inline" src="../media/file1480.png" style="vertical-align:middle" title="\left| \sqrt{p_{\alpha(r)}} \right|^{2} = p_{\alpha(r)}"/></span><span class="koboSpan" id="kobo.604.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.605.1" xmlns="http://www.w3.org/1999/xhtml">The discriminator that enables the training of this QGAN is a classical neural network tasked with distinguishing whether an input datum belongs to the original dataset or has been generated by the discriminator.</span></p>
<p><span class="koboSpan" id="kobo.606.1" xmlns="http://www.w3.org/1999/xhtml">So that’s the QGAN that we are going to work with: a hybrid QGAN in which the generator is quantum and the discriminator is classic. </span><span class="koboSpan" id="kobo.606.2" xmlns="http://www.w3.org/1999/xhtml">Sounds interesting? </span><span class="koboSpan" id="kobo.606.3" xmlns="http://www.w3.org/1999/xhtml">Let’s see how we can implement it and train it using Qiskit.</span></p>
<p><span class="koboSpan" id="kobo.607.1" xmlns="http://www.w3.org/1999/xhtml">In order to get started, let’s import NumPy and Qiskit while setting some seeds to ensure the reproducibility of our results:</span></p>
<p><span id="x1-221002"/></p>
<pre class="lstlisting" id="listing-349"><span class="koboSpan" id="kobo.608.1" xmlns="http://www.w3.org/1999/xhtml">

import numpy as np 
 
 
 
from qiskit import * 
 
from qiskit.utils import algorithm_globals 
 
 
 
seed = 1234 
 
np.random.seed(seed) 
 
algorithm_globals.random_seed = seed
</span></pre>
<p><span class="koboSpan" id="kobo.609.1" xmlns="http://www.w3.org/1999/xhtml">We will consider a particular example of the general problem that we outlined previously. </span><span class="koboSpan" id="kobo.609.2" xmlns="http://www.w3.org/1999/xhtml">We will take a dataset with </span><span class="koboSpan" id="kobo.610.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1000" class="math inline" src="../media/file790.png" style="vertical-align:middle" title="1000"/></span><span class="koboSpan" id="kobo.611.1" xmlns="http://www.w3.org/1999/xhtml"> samples generated from the binomial distribution with </span><span class="koboSpan" id="kobo.612.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n = 3" class="math inline" src="../media/file1481.png" style="vertical-align:middle" title="n = 3"/></span><span class="koboSpan" id="kobo.613.1" xmlns="http://www.w3.org/1999/xhtml"> trials and probability </span><span class="koboSpan" id="kobo.614.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. p = 1\slash 2 \right." class="math inline" src="../media/file1482.png" style="vertical-align:middle" title="\left. p = 1\slash 2 \right."/></span><span class="koboSpan" id="kobo.615.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.615.2" xmlns="http://www.w3.org/1999/xhtml">These distributions can only take </span><span class="koboSpan" id="kobo.616.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4 = 2^{2}" class="math inline" src="../media/file1483.png" style="vertical-align:middle" title="4 = 2^{2}"/></span><span class="koboSpan" id="kobo.617.1" xmlns="http://www.w3.org/1999/xhtml"> possible values (</span><span class="koboSpan" id="kobo.618.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0,1,2,3" class="math inline" src="../media/file1484.png" style="vertical-align:middle" title="0,1,2,3"/></span><span class="koboSpan" id="kobo.619.1" xmlns="http://www.w3.org/1999/xhtml">), so will have to use </span><span class="koboSpan" id="kobo.620.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2" class="math inline" src="../media/file302.png" style="vertical-align:middle" title="2"/></span><span class="koboSpan" id="kobo.621.1" xmlns="http://www.w3.org/1999/xhtml"> qubits in our generator. </span><span class="koboSpan" id="kobo.621.2" xmlns="http://www.w3.org/1999/xhtml">We may generate the samples of our dataset using NumPy as follows:</span></p>
<pre class="lstlisting" id="listing-350"><span class="koboSpan" id="kobo.622.1" xmlns="http://www.w3.org/1999/xhtml">

N = 1000 
 
n = 3 
 
p = 0.5 
 
 
 
real_data = np.random.binomial(n, p, N)
</span></pre>
<p><span class="koboSpan" id="kobo.623.1" xmlns="http://www.w3.org/1999/xhtml">The Qiskit framework already incorporates a </span><code><span class="koboSpan" id="kobo.624.1" xmlns="http://www.w3.org/1999/xhtml">QGAN</span></code><span class="koboSpan" id="kobo.625.1" xmlns="http://www.w3.org/1999/xhtml"> class that can create and train the QGAN architecture that we discussed previously — it’s almost tailor-made for this problem! </span><span class="koboSpan" id="kobo.625.2" xmlns="http://www.w3.org/1999/xhtml">We may import the class from the </span><code><span class="koboSpan" id="kobo.626.1" xmlns="http://www.w3.org/1999/xhtml">qiskit_machine_learning</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.627.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.628.1" xmlns="http://www.w3.org/1999/xhtml">algorithms</span></code><span class="koboSpan" id="kobo.629.1" xmlns="http://www.w3.org/1999/xhtml"> module and define our QGAN as follows:</span></p>
<pre class="lstlisting" id="listing-351"><span class="koboSpan" id="kobo.630.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit_machine_learning.algorithms import QGAN 
 
from qiskit.utils import QuantumInstance 
 
 
 
ncycles = 3000 # Number of training cycles. 
 
</span><span class="koboSpan" id="kobo.630.2" xmlns="http://www.w3.org/1999/xhtml">bsize = 100 # Batch size. 
 
 
 
</span><span class="koboSpan" id="kobo.630.3" xmlns="http://www.w3.org/1999/xhtml"># Quantum instance on which the QGAN will run. 
 
</span><span class="koboSpan" id="kobo.630.4" xmlns="http://www.w3.org/1999/xhtml">quantum_instance = QuantumInstance( 
 
    backend=Aer.get_backend(’statevector_simulator’)) 
 
 
 
# Create the QGAN object. 
 
</span><span class="koboSpan" id="kobo.630.5" xmlns="http://www.w3.org/1999/xhtml">qgan = QGAN(data = real_data, 
 
            num_qubits = [2], 
 
            batch_size = bsize, 
 
            num_epochs = ncycles, 
 
            bounds = [0,3], 
 
            seed = seed, 
 
            tol_rel_ent = 0.001)
</span></pre>
<p><span class="koboSpan" id="kobo.631.1" xmlns="http://www.w3.org/1999/xhtml">In the call to the </span><code><span class="koboSpan" id="kobo.632.1" xmlns="http://www.w3.org/1999/xhtml">QGAN</span></code><span class="koboSpan" id="kobo.633.1" xmlns="http://www.w3.org/1999/xhtml"> initializer, we had to specify the dataset whose distribution we want to learn, the </span><span id="dx1-221034"/><span class="koboSpan" id="kobo.634.1" xmlns="http://www.w3.org/1999/xhtml">bounds at which we want to ”cut” the dataset (in this case, we just specified the actual bounds of our distribution), an array containing the number of qubits of the generator circuit, the batch size, the number of training cycles that we want our QGAN to run for, the quantum instance on which the QGAN will run and, lastly, an optional seed.</span></p>
<p><span class="koboSpan" id="kobo.635.1" xmlns="http://www.w3.org/1999/xhtml">You may be confused by the fact that we’ve had to send the number of qubits of the quantum generator in an array. </span><span class="koboSpan" id="kobo.635.2" xmlns="http://www.w3.org/1999/xhtml">That’s because this </span><code><span class="koboSpan" id="kobo.636.1" xmlns="http://www.w3.org/1999/xhtml">QGAN</span></code><span class="koboSpan" id="kobo.637.1" xmlns="http://www.w3.org/1999/xhtml"> class could support generating samples of any dimension </span><span class="koboSpan" id="kobo.638.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="d" class="math inline" src="../media/file1485.png" style="vertical-align:middle" title="d"/></span><span class="koboSpan" id="kobo.639.1" xmlns="http://www.w3.org/1999/xhtml"> (using </span><span class="koboSpan" id="kobo.640.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="d" class="math inline" src="../media/file1485.png" style="vertical-align:middle" title="d"/></span><span class="koboSpan" id="kobo.641.1" xmlns="http://www.w3.org/1999/xhtml"> generators); in our case, we have </span><span class="koboSpan" id="kobo.642.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="d = 1" class="math inline" src="../media/file1486.png" style="vertical-align:middle" title="d = 1"/></span><span class="koboSpan" id="kobo.643.1" xmlns="http://www.w3.org/1999/xhtml">, hence we only need to pass an array with a single element.</span></p>
<p><span class="koboSpan" id="kobo.644.1" xmlns="http://www.w3.org/1999/xhtml">This QGAN object already comes with a default implementation for the generator and the discriminator, and we will rely on them.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-221">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.645.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.646.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.647.1" xmlns="http://www.w3.org/1999/xhtml">In this default implementation, the discriminator is a dense neural network having two consecutive intermediate layers with </span><span class="koboSpan" id="kobo.648.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="50" class="math inline" src="../media/file1390.png" style="vertical-align:middle" title="50"/></span><span class="koboSpan" id="kobo.649.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.650.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="20" class="math inline" src="../media/file588.png" style="vertical-align:middle" title="20"/></span><span class="koboSpan" id="kobo.651.1" xmlns="http://www.w3.org/1999/xhtml"> neurons each; the activation function in these intermediate layers is the leaky ReLU function and that of the output layer is the sigmoid function. </span><span class="koboSpan" id="kobo.651.2" xmlns="http://www.w3.org/1999/xhtml">The generator uses a variational form consisting of a layer of Hadamard gates applied on each qubit followed by the two-local variational form with one repetition and circular entanglement.</span></p>
<p><span class="koboSpan" id="kobo.652.1" xmlns="http://www.w3.org/1999/xhtml">These details are not specified in the documentation, but they can be found in the source code.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.653.1" xmlns="http://www.w3.org/1999/xhtml">In order to train the QGAN, we may run the following instruction:</span></p>
<pre class="lstlisting" id="listing-352"><span class="koboSpan" id="kobo.654.1" xmlns="http://www.w3.org/1999/xhtml">

result = qgan.run(quantum_instance)
</span></pre>
<p><span class="koboSpan" id="kobo.655.1" xmlns="http://www.w3.org/1999/xhtml">The training will take a few </span><span id="dx1-221036"/><span class="koboSpan" id="kobo.656.1" xmlns="http://www.w3.org/1999/xhtml">minutes to complete, depending on the hardware configuration of your computer. </span><span class="koboSpan" id="kobo.656.2" xmlns="http://www.w3.org/1999/xhtml">In order to plot the evolution of the generator and discriminator losses throughout the training process, we may run the following code:</span></p>
<pre class="lstlisting" id="listing-353"><span class="koboSpan" id="kobo.657.1" xmlns="http://www.w3.org/1999/xhtml">

import matplotlib.pyplot as plt 
 
plt.title("Loss function evolution") 
 
cycles = np.array(range(len(qgan.g_loss))) + 1 
 
plt.plot(cycles, qgan.g_loss, label = "Generator") 
 
plt.plot(cycles, qgan.d_loss, label = "Discriminator") 
 
plt.xlabel("Cycle") 
 
plt.legend()
</span></pre>
<p><span class="koboSpan" id="kobo.658.1" xmlns="http://www.w3.org/1999/xhtml">This yields the plot shown in </span><em><span class="koboSpan" id="kobo.659.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.8"><em><span class="koboSpan" id="kobo.660.1" xmlns="http://www.w3.org/1999/xhtml">12.8</span></em></a><span class="koboSpan" id="kobo.661.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.661.2" xmlns="http://www.w3.org/1999/xhtml">We can see how both losses are approaching </span><span class="koboSpan" id="kobo.662.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. - \log 1\slash 2 \right." class="math inline" src="../media/file1468.png" style="vertical-align:middle" title="\left. - \log 1\slash 2 \right."/></span><span class="koboSpan" id="kobo.663.1" xmlns="http://www.w3.org/1999/xhtml">, which can give us hope for the success of our training.</span></p>
<figure>
<span class="koboSpan" id="kobo.664.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 12.8: Evolution of the generator and discriminator losses during the QGAN training, learning a distribution " src="../media/file1487.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure12.8"><strong><span class="koboSpan" id="kobo.665.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.8</span></strong><span class="koboSpan" id="kobo.666.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.667.1" xmlns="http://www.w3.org/1999/xhtml">Evolution of the generator and discriminator losses during the QGAN training, learning a distribution </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.668.1" xmlns="http://www.w3.org/1999/xhtml">In order to check if our </span><span id="dx1-221046"/><span class="koboSpan" id="kobo.669.1" xmlns="http://www.w3.org/1999/xhtml">training has been successful, we will plot the distribution of the measurement outcomes of our generator against the original distribution. </span><span class="koboSpan" id="kobo.669.2" xmlns="http://www.w3.org/1999/xhtml">We may generate the data for this plot as follows:</span></p>
<pre class="lstlisting" id="listing-354"><span class="koboSpan" id="kobo.670.1" xmlns="http://www.w3.org/1999/xhtml">

samples_g, prob_g = qgan.generator.get_output(qgan.quantum_instance, 
 
                                             shots=10000) 
 
 
 
real_distr = [] 
 
for i in range(0,3+1): 
 
    proportion = np.count_nonzero(real_data == i) / N 
 
    real_distr.append(proportion) 
 
plt.bar(range(4), real_distr, width = 0.7, color = "royalblue", 
 
        label = "Real distribution") 
 
plt.bar(range(4), prob_g, width = 0.5, color = "black", 
 
        label = "Generated distribution")
</span></pre>
<p><span class="koboSpan" id="kobo.671.1" xmlns="http://www.w3.org/1999/xhtml">In this piece of code, we have first asked our QGAN to generate a sample with the distribution it has learned. </span><span class="koboSpan" id="kobo.671.2" xmlns="http://www.w3.org/1999/xhtml">Then, we have created an array </span><code><span class="koboSpan" id="kobo.672.1" xmlns="http://www.w3.org/1999/xhtml">real_distr</span></code><span class="koboSpan" id="kobo.673.1" xmlns="http://www.w3.org/1999/xhtml"> with the relative frequencies of the values in the </span><span id="dx1-221058"/><span class="koboSpan" id="kobo.674.1" xmlns="http://www.w3.org/1999/xhtml">distribution (entry </span><code><span class="koboSpan" id="kobo.675.1" xmlns="http://www.w3.org/1999/xhtml">j</span></code><span class="koboSpan" id="kobo.676.1" xmlns="http://www.w3.org/1999/xhtml"> corresponds to the relative frequency of the value </span><span class="koboSpan" id="kobo.677.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.678.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.678.2" xmlns="http://www.w3.org/1999/xhtml">Lastly, we have plotted the real distribution against our generated distribution. </span><span class="koboSpan" id="kobo.678.3" xmlns="http://www.w3.org/1999/xhtml">The output can be found in </span><em><span class="koboSpan" id="kobo.679.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.9"><em><span class="koboSpan" id="kobo.680.1" xmlns="http://www.w3.org/1999/xhtml">12.9</span></em></a><span class="koboSpan" id="kobo.681.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.682.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 12.9: Histogram comparing the real distribution (thicker bar) with the one generated by the QGAN (thinner bar) " src="../media/file1488.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure12.9"><strong><span class="koboSpan" id="kobo.683.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.9</span></strong><span class="koboSpan" id="kobo.684.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.685.1" xmlns="http://www.w3.org/1999/xhtml">Histogram comparing the real distribution (thicker bar) with the one generated by the QGAN (thinner bar) </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.686.1" xmlns="http://www.w3.org/1999/xhtml">Of course, for the purposes of this example, this visualization is more than enough to convince us that the training, indeed, has been effective. </span><span class="koboSpan" id="kobo.686.2" xmlns="http://www.w3.org/1999/xhtml">In more sophisticated examples, one may instead want to rely on more quantitative metrics of success. </span><span class="koboSpan" id="kobo.686.3" xmlns="http://www.w3.org/1999/xhtml">One such </span><span id="dx1-221061"/><span class="koboSpan" id="kobo.687.1" xmlns="http://www.w3.org/1999/xhtml">metric is the </span><strong><span class="koboSpan" id="kobo.688.1" xmlns="http://www.w3.org/1999/xhtml">relative entropy</span></strong><span class="koboSpan" id="kobo.689.1" xmlns="http://www.w3.org/1999/xhtml"> or </span><strong><span class="koboSpan" id="kobo.690.1" xmlns="http://www.w3.org/1999/xhtml">Kullback–Leibler</span></strong> <strong><span class="koboSpan" id="kobo.691.1" xmlns="http://www.w3.org/1999/xhtml">divergence</span></strong><span class="koboSpan" id="kobo.692.1" xmlns="http://www.w3.org/1999/xhtml"> from one </span><span id="dx1-221062"/><span class="koboSpan" id="kobo.693.1" xmlns="http://www.w3.org/1999/xhtml">distribution to another. </span><span class="koboSpan" id="kobo.693.2" xmlns="http://www.w3.org/1999/xhtml">In layman’s terms, this entropy measures how ”different” two distributions are in a way that if two distributions </span><span class="koboSpan" id="kobo.694.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{0}" class="math inline" src="../media/file1489.png" style="vertical-align:middle" title="P_{0}"/></span><span class="koboSpan" id="kobo.695.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.696.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{1}" class="math inline" src="../media/file1490.png" style="vertical-align:middle" title="P_{1}"/></span><span class="koboSpan" id="kobo.697.1" xmlns="http://www.w3.org/1999/xhtml"> are identical, the relative entropy from </span><span class="koboSpan" id="kobo.698.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{0}" class="math inline" src="../media/file1489.png" style="vertical-align:middle" title="P_{0}"/></span><span class="koboSpan" id="kobo.699.1" xmlns="http://www.w3.org/1999/xhtml"> to </span><span class="koboSpan" id="kobo.700.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{1}" class="math inline" src="../media/file1490.png" style="vertical-align:middle" title="P_{1}"/></span><span class="koboSpan" id="kobo.701.1" xmlns="http://www.w3.org/1999/xhtml"> is </span><span class="koboSpan" id="kobo.702.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.703.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.703.2" xmlns="http://www.w3.org/1999/xhtml">As </span><span class="koboSpan" id="kobo.704.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{1}" class="math inline" src="../media/file1490.png" style="vertical-align:middle" title="P_{1}"/></span><span class="koboSpan" id="kobo.705.1" xmlns="http://www.w3.org/1999/xhtml"> becomes more different from </span><span class="koboSpan" id="kobo.706.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{0}" class="math inline" src="../media/file1489.png" style="vertical-align:middle" title="P_{0}"/></span><span class="koboSpan" id="kobo.707.1" xmlns="http://www.w3.org/1999/xhtml">, the relative entropy increases.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-222">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.708.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.709.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.710.1" xmlns="http://www.w3.org/1999/xhtml">When you are given two discrete probability distributions </span><span class="koboSpan" id="kobo.711.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{0}" class="math inline" src="../media/file1489.png" style="vertical-align:middle" title="P_{0}"/></span><span class="koboSpan" id="kobo.712.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.713.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{1}" class="math inline" src="../media/file1490.png" style="vertical-align:middle" title="P_{1}"/></span><span class="koboSpan" id="kobo.714.1" xmlns="http://www.w3.org/1999/xhtml"> over a space </span><span class="koboSpan" id="kobo.715.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="X" class="math inline" src="../media/file9.png" style="vertical-align:middle" title="X"/></span><span class="koboSpan" id="kobo.716.1" xmlns="http://www.w3.org/1999/xhtml">, the relative entropy from </span><span class="koboSpan" id="kobo.717.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{0}" class="math inline" src="../media/file1489.png" style="vertical-align:middle" title="P_{0}"/></span><span class="koboSpan" id="kobo.718.1" xmlns="http://www.w3.org/1999/xhtml"> to </span><span class="koboSpan" id="kobo.719.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="P_{1}" class="math inline" src="../media/file1490.png" style="vertical-align:middle" title="P_{1}"/></span><span class="koboSpan" id="kobo.720.1" xmlns="http://www.w3.org/1999/xhtml"> can be defined as</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.721.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="D(P_{1} \parallel P)0) = \sum\limits_{x \in X}P_{1}(x)\log\left( \frac{P_{1}(x)}{P_{0}(x)} \right)." class="math display" src="../media/file1491.png" style="vertical-align:middle" title="D(P_{1} \parallel P)0) = \sum\limits_{x \in X}P_{1}(x)\log\left( \frac{P_{1}(x)}{P_{0}(x)} \right)."/></span></td>
</tr>
</tbody>
</table>
</div>
</div>
<p><span class="koboSpan" id="kobo.722.1" xmlns="http://www.w3.org/1999/xhtml">Qiskit’s QGAN implementation logs the values of the relative entropy throughout the QGAN training. </span><span class="koboSpan" id="kobo.722.2" xmlns="http://www.w3.org/1999/xhtml">In this way, we may plot the evolution of the relative entropy over the training process of our QGAN with the </span><span id="dx1-221063"/><span class="koboSpan" id="kobo.723.1" xmlns="http://www.w3.org/1999/xhtml">following instructions:</span></p>
<pre class="lstlisting" id="listing-355"><span class="koboSpan" id="kobo.724.1" xmlns="http://www.w3.org/1999/xhtml">

plt.title(’Relative entropy evolution’) 
 
plt.plot(qgan.rel_entr) 
 
plt.show()
</span></pre>
<p><span class="koboSpan" id="kobo.725.1" xmlns="http://www.w3.org/1999/xhtml">The output is shown in </span><em><span class="koboSpan" id="kobo.726.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure12.10"><em><span class="koboSpan" id="kobo.727.1" xmlns="http://www.w3.org/1999/xhtml">12.10</span></em></a><span class="koboSpan" id="kobo.728.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.729.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 12.10: Evolution of the relative entropy over the training of our QGAN, learning a distribution" src="../media/file1492.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure12.10"><strong><span class="koboSpan" id="kobo.730.1" xmlns="http://www.w3.org/1999/xhtml">Figure 12.10</span></strong><span class="koboSpan" id="kobo.731.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.732.1" xmlns="http://www.w3.org/1999/xhtml">Evolution of the relative entropy over the training of our QGAN, learning a distribution</span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.733.1" xmlns="http://www.w3.org/1999/xhtml">Here it can be clearly shown that the relative entropy approaches </span><span class="koboSpan" id="kobo.734.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.735.1" xmlns="http://www.w3.org/1999/xhtml"> as the training progresses, just as we expected. </span><span class="koboSpan" id="kobo.735.2" xmlns="http://www.w3.org/1999/xhtml">This concludes our example. </span><span class="koboSpan" id="kobo.735.3" xmlns="http://www.w3.org/1999/xhtml">It’s time to wrap up!</span></p>
</section>
<section class="level2 likesectionHead" data-number="20.4" id="summary-11">
<h1 class="likesectionHead" data-number="20.4"><span id="x1-22200012.3"><span class="koboSpan" id="kobo.736.1" xmlns="http://www.w3.org/1999/xhtml">Summary</span></span></h1>
<p><span id="Q1-1-318"/></p>
<p><span class="koboSpan" id="kobo.737.1" xmlns="http://www.w3.org/1999/xhtml">In this chapter, we have explored a whole new kind of quantum machine learning models: quantum GANs. </span><span class="koboSpan" id="kobo.737.2" xmlns="http://www.w3.org/1999/xhtml">Unlike the models we had considered before, these are used primarily for generation tasks. </span><span class="koboSpan" id="kobo.737.3" xmlns="http://www.w3.org/1999/xhtml">And, unlike our previous models, they are trained in a fully unsupervised manner.</span></p>
<p><span class="koboSpan" id="kobo.738.1" xmlns="http://www.w3.org/1999/xhtml">After understanding what GANs are in general, we introduced the general notion of a QGAN, and then we learned how to implement a couple of QGAN models using PennyLane and Qiskit.</span></p>
<p><span class="koboSpan" id="kobo.739.1" xmlns="http://www.w3.org/1999/xhtml">With this, we also conclude our study of quantum machine learning for this book. </span><span class="koboSpan" id="kobo.739.2" xmlns="http://www.w3.org/1999/xhtml">We hope that you have had a good time learning about all these ways of making quantum computers learn! </span><span class="koboSpan" id="kobo.739.3" xmlns="http://www.w3.org/1999/xhtml">But your quantum journey does not need to end here. </span><span class="koboSpan" id="kobo.739.4" xmlns="http://www.w3.org/1999/xhtml">Please, keep on reading for a sneak peek of what you can expect in the near future in the quantum computing field.</span></p>
</section>
</section>
</body>
</html>
