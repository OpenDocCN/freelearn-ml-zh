- en: Chapter 6. Where's Wally? Object Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter explains how to use the different options included in the OpenCV
    object detection module. With the sample code included, it is possible to use
    Cascade and Latent SVM detectors as well as create custom cascade detectors for
    a specific object detection application. Additionally, the new Scene Text Detector
    included in OpenCV 3 is explained in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Object detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Object detection deals with the process of locating instances of a certain class
    of real-world objects, such as faces, cars, pedestrians, and buildings in images
    or videos. Detection algorithms typically start by extracting features from two
    sets of images. One of these sets contains images from the desired object and
    the other one contains background images where the searched object is not present.
    Then, the detector is trained based on these features to recognize future instances
    of the object class.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Fingerprint recognition, now included in some laptops and smartphones, or face
    detection, seen in most digital cameras, are everyday examples of object detection
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting objects with OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenCV has a number of object detection algorithms implemented in its `objdetect`
    module. In this module, Cascade and Latent SVM detectors are implemented together
    with the new Scene Text Detector added in OpenCV 3\. All of these algorithms are
    relatively efficient and obtain accurate results.
  prefs: []
  type: TYPE_NORMAL
- en: Cascades are beautiful
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most objects' detection problems, such as face/person detection or lesion detection
    in medicine, require searching for the object in many image patches. However,
    examining all image zones and computing the feature set for each zone are time-consuming
    tasks. Cascade detectors are widely used because of their high efficiency in doing
    this.
  prefs: []
  type: TYPE_NORMAL
- en: Cascade detectors consist of various boosting stages. The boosting algorithm
    selects the best feature set to create and combine a number of weak tree classifiers.
    Thus, boosting is not only a detector but also a feature selection method. Each
    stage is usually trained to detect nearly 100 percent of objects correctly and
    discard at least 50 percent of the background images. Therefore, background images,
    which represent a larger number of images, need less processing time as they are
    discarded at the early stages of the cascade. Moreover, the concluding cascade
    stages use more features than earlier stages, and even then only objects and difficult
    background images require more time to be evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: Discrete AdaBoost (Adaptive Boosting), Real AdaBoost, Gentle AdaBoost, and LogitBoost
    are all implemented in OpenCV as boosting stages. On the other hand, it is possible
    to use Haar-like, **Local Binary Patterns** (**LBP**) and **Histograms of Oriented
    Gradients** (**HOG**) features together with the different boosting algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: All these advantages and available techniques make cascades very useful for
    building practical detection applications.
  prefs: []
  type: TYPE_NORMAL
- en: Object detection using cascades
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'OpenCV comes with several pretrained cascade detectors for the most common
    detection problems. They are located under the `OPENCV_SOURCE\data` directory.
    The following is a list of some of them and their corresponding subdirectories:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Subdirectory `haarcascades`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`haarcascade_frontalface_default.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`haarcascade_eye.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`haarcascade_mcs_nose.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`haarcascade_mcs_mouth.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`haarcascade_upperbody.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`haarcascade_lowerbody.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`haarcascade_fullbody.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Subdirectory `lbpcascades`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lbpcascade_frontalface.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lbpcascade_profileface.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lbpcascade_silverware.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Subdirectory `hogcascades`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hogcascade_pedestrians.xml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following `pedestrianDetection` example serves to illustrate how to use
    a cascade detector and localize pedestrians in a video file with OpenCV:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`CascadeClassifier`: This class provides all the methods needed when working
    with cascades. An object from this class represents a trained cascade detector.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`constructor CascadeClassifier:: CascadeClassifier(const string& filename)`:
    This class initializes the object instance and loads the information of the cascade
    detector stored in the system file indicated by the variable `filename`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the method `bool CascadeClassifier::load(const string& filename)`
    is actually called implicitly after the constructor.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bool CascadeClassifier:: empty()`: This method checks if a cascade detector
    has been loaded.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cvtColor` and `equalizeHist`: These methods are required for image grayscale
    conversion and equalization. Since the cascade detector is trained with grayscale
    images and input images can be in different formats, it is necessary to convert
    them to the correct color space and equalize their histograms in order to obtain
    better results. This is done by the following code that uses the `cvtColor` and
    `equalizeHist` functions:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`void CascadeClassifier::detectMultiScale(const Mat& image, vector<Rect>& objects,
    double scaleFactor=1.1, int minNeighbors=3, int flags=0, Size minSize=Size(),
    Size maxSize=Size())`: This method examines the image in the `image` variable
    applying the loaded cascade and insert all detected objects in `objects`. Detections
    are stored in a vector of rectangles of type `Rect`. The parameters `scaleFactor`
    and `minNeighbors` indicates how much the image size is reduced at each image
    scale considered and the minimum number of neighbors that indicate a positive
    detection. Detections are bound by the minimum and maximum sizes, indicated by
    `minSize` and `maxSize`. Finally, the parameter `flags` is not used when using
    cascades created with `opencv_traincascade`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: After obtaining the vector that stores the detected objects, it is easy to show
    them over the original images by reading the coordinates of each rectangle, represented
    by objects of the class `Rect`, and drawing a polygon in the indicated zones.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The following screenshot shows the result of applying the `hogcascade_pedestrians.xml`
    pretrained HOG-based pedestrian detector over the frames of the `768x576.avi`
    video, which is stored in the `OPENCV_SCR/samples` folder.
  prefs: []
  type: TYPE_NORMAL
- en: '![Object detection using cascades](img/00038.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Pedestrian detection using the OpenCV-trained HOG cascade detector
  prefs: []
  type: TYPE_NORMAL
- en: There are several projects and contributions to the OpenCV community that solve
    other detection-related problems that involve not only detecting the object but
    also distinguishing its state. One example of this type of detectors is the smile
    detector included in OpenCV since Version 2.4.4\. The code can be found in the
    file `OPENCV_SCR/samples/c/smiledetect.cpp`, and the XML that stores the cascade
    detector, `haarcascade_smile.xml`, can be found in `OPENCV_SCR/data/haarcascades`.
    This code first detects the frontal face using the pretrained cascade stored in
    `haarcascade_frontalface_alt.xml` and then detects the smiling mouth pattern at
    the bottom part of the image. Finally, the intensity of the smile is calculated
    based on the number of neighbors detected.
  prefs: []
  type: TYPE_NORMAL
- en: Training your own cascade
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Although OpenCV provides pretrained cascades, in some cases it is necessary
    to train a cascade detector to look for a specific object. For these cases, OpenCV
    comes with tools to help train a cascade, generating all the data needed during
    the training process and the final files with the detector information. These
    are usually stored in the `OPENCV_BUILD\install\x64\mingw\bin` directory. Some
    of the applications are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`opencv_haartraining`: This application is historically the first version of
    the application for creating cascades.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`opencv_traincascade`: This application is the latest version of the application
    for creating cascades.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`opencv_createsamples`: This application is used to create the `.vec` file
    with the images that contain instances of the object. The file generated is accepted
    by both the preceding training executables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`opencv_performance`: This application may be used to evaluate a cascade trained
    with the `opencv_haartraining` tool. It uses a set of marked images to obtain
    information about the evaluation, for example, the false alarm or the detection
    rates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since `opencv_haartraining` is the older version of the program and it comes
    with fewer features than `opencv_traincascade`, only the latter will be described
    here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the cascade training process is explained using the MIT CBCL face database.
    This database contains face and background images of 19 x 19 pixels arranged as
    shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Training your own cascade](img/00039.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Image file organization
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section explains the training process on Windows. For Linux and Mac OS
    X, the process is similar but takes into account the specific aspects of the operating
    system. More information on training cascade detectors in Linux and Mac OS X can
    be found at [http://opencvuser.blogspot.co.uk/2011/08/creating-haar-cascade-classifier-aka.html](http://opencvuser.blogspot.co.uk/2011/08/creating-haar-cascade-classifier-aka.html)
    and [http://kaflurbaleen.blogspot.co.uk/2012/11/how-to-train-your-classifier-on-mac.html](http://kaflurbaleen.blogspot.co.uk/2012/11/how-to-train-your-classifier-on-mac.html)
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The training process involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Setting the current directory**: In the **Command Prompt** window, set the
    current directory to the directory in which training images are stored. For example,
    if the directory is `C:\chapter6\images`, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Creating the background images information text file**: If background images
    are stored in `C:\chapter6\images\train\non-face` and their format is `.pgm`,
    it is possible to create the text file required by OpenCV using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following screenshot shows the contents of the background image information
    file. This file contains the path of the background images:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Training your own cascade](img/00040.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Background images information file
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Creating the object images file:** This involves the following two steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating the `.dat` file with the object coordinates. In this particular database,
    object images only contain one instance of the object and it is located in the
    center of the image and scaled to occupy the entire image. Therefore, the number
    of objects per image is 1 and the object coordinates are `0 0 19 19`, which are
    the initial point and the width and height of the rectangle that contains the
    object.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If object images are stored in `C:\chapter6\images\train\face`, it is possible
    to use the following command to generate the file:'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The content of the `.dat` file can be seen in the following screenshot:'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Training your own cascade](img/00041.jpeg)'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_IMG
- en: Object images file
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After creating the `.dat` file with the object coordinates, it is necessary
    to create the `.vec` file that is needed by OpenCV. This step can be performed
    using the `opencv_createsamples` program with the arguments `–info` (`.dat` file);
    `-vec` (`.vec` output file name); `-num` (number of images); `-w` and `–h` (output
    image width and height); and `–maxxangle`, `-maxyangle`, and `-maxzangle` (image
    rotation angles). To see more options, execute `opencv_createsamples` without
    arguments. In this case, the command used is:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenCV includes a sample `.vec` file with facial images of size 24 x 24 pixels.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Training the cascade**: Finally, use the `opencv_traincascade` executable
    and train the cascade detector. The command used in this case is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The arguments indicate the output directory (`-data`), the `.vec` file (`-vec`),
    the background information file (`-bg`), the number of positive and negative images
    to train each stage (`-numPos` and `–numNeg`), the maximum number of stages (`-numStages`),
    and the width and height of the images (`-w` and `–h`).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output of the training process is:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, the XML files of the cascade are stored in the output directory. These
    files are `cascade.xml`, `params.xml`, and a set of `stageX.xml` files where `X`
    is the stage number.
  prefs: []
  type: TYPE_NORMAL
- en: Latent SVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Latent SVM is a detector that uses HOG features and a star-structured, part-based
    model consisting of a root filter and a set of part filters to represent an object
    category. HOGs are feature descriptors that are obtained by counting the occurrences
    of gradient orientations in localized portions of an image. On the other hand,
    a variant of **support vector machines** (**SVM**) classifiers are used in this
    detector to train models using partially labeled data. The basic idea of an SVM
    is constructing a hyperplane or set of hyperplanes in high-dimensional space.
    These hyperplanes are obtained to have the largest distance to the nearest training
    data point (functional margin in order to achieve low generalization errors).
    Like cascade detectors, Latent SVM uses a sliding window with different initial
    positions and scales where the algorithm is applied in order to detect if there
    is an object inside.
  prefs: []
  type: TYPE_NORMAL
- en: One of the advantages of the OpenCV Latent SVM implementation is that it allows
    the detection of multiple object categories by combining several simple pretrained
    detectors within the same multiobject detector instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `latentDetection` example illustrates how to use a Latent SVM
    detector for localizing objects from a category in an image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`LatentSvmDetector`: This class has an object that represents a Latent SVM
    detector composed of one or more pretrained detectors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`constructor LatentSvmDetector::LatentSvmDetector(const vector<String>& filenames,
    const vector<string>& classNames=vector<String>())`: This class initializes the
    object instance and loads the information of the detectors stored in the system
    paths indicated by the vector `filenames`. The second parameter, the vector `classNames`,
    contains the category names. The method `bool LatentSvmDetector::load(const vector<string>&
    filenames, const vector<string>& classNames=vector<string>())` is called implicitly
    after the constructor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void LatentSvmDetector::detect(const Mat& image, vector<ObjectDetection>&
    objectDetections, float overlapThreshold = 0.5f, int numThreads = -1)`: This method
    examines the image in the variable `image` by applying the simple or combined
    detector on it and puts all detected objects in `objectDetections`. All detections
    are stored in a vector of the `ObjectDetection` struct. This structure has the
    following three variables:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bounding box of the detection (`rect`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The confidence level (`score`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The category ID (`classID`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The parameter `overlapThreshold` is the threshold for the non-maximum suppression
    algorithm for eliminating overlapped detections. Finally, `numThreads` is the
    number of threads used in the parallel version of the algorithm.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following screenshot shows a cat detected using the previous code and the
    files `cat.xml` and `cat.png`, and cars detected using `car.xml` and `cars.png`.
    These files are included in the OpenCV extra data that can be found in the official
    repository. Thus, it is possible to run the program using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In the previous command, `xmlfile` is the Latent SVM detector and `imagefile`
    is the image that has to be examined.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenCV extra data provides more samples and test files that can be used by users
    to create and test their own projects while saving time. It can be found at [https://github.com/Itseez/opencv_extra](https://github.com/Itseez/opencv_extra).
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the car and cat detectors, OpenCV provides pretrained detectors
    for the rest of the classes defined in *The PASCAL Visual Object Classes Challenge
    2007* ([http://pascallin.ecs.soton.ac.uk/challenges/VOC/voc2007](http://pascallin.ecs.soton.ac.uk/challenges/VOC/voc2007)).
    These detectors are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`aeroplane.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bicycle.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bird.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`boat.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bottle.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bus.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`car.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cat.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`chair.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cow.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`diningtable.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dog.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`horse.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`motorbike.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`person.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pottedplant.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sheep.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sofa.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tvmonitor.xml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Latent SVM](img/00042.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The detection of a cat and some cars using Latent SVM
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The false positive rate can be adjusted by changing the value of the `overlapThreshold`
    parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Scene text detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The scene text detection algorithm builds a component tree of an image by thresholding
    it step-by-step from 0 to 255\. To enhance the results, this process is done for
    each color channel, intensity, and gradient magnitude images. After that, the
    connected components obtained from successive levels are hierarchically organized
    depending on their inclusion relationship as shown in the following diagram. This
    tree organization may contain a huge number of regions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scene text detection](img/00043.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Tree organization example
  prefs: []
  type: TYPE_NORMAL
- en: Thus, the algorithm selects some regions following two stages. Firstly, area,
    perimeter, bounding box, and Euler number descriptors are computed for each region
    and used in order to estimate the class-condition probability. External regions
    with local maximum probabilities are selected if their values are above a global
    limit and the difference between their local maximum and minimum is also above
    a specified limit.
  prefs: []
  type: TYPE_NORMAL
- en: The second stage consists of classifying the external regions selected in the
    first stage into character and non-character classes using whole area ratio, convex
    hull ratio, and the number of outer boundary inflexion points as features.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the external regions selected are grouped to obtain words, lines, or
    paragraphs. This part of the algorithm uses a perceptual-organization-based clustering
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `textDetection` example illustrates how to use the Scene Text
    Detection algorithm and localize text in an image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`void computeNMChannels(InputArray _src, OutputArrayOfArrays _channels, int
    _mode=ERFILTER_NM_RGBLGrad)`: This function computes different channels from the
    image in `_src` to be processed independently in order to obtain high localization
    recall. These channels are red (`R`), green (`G`), blue (`B`), lightness (`L`),
    and gradient magnitude (∇) by default (`_mode=ERFILTER_NM_RGBLGrad`), it is intensity
    (I), hue (H), saturation (S), and gradient magnitude (∇) if `_mode=ERFILTER_NM_IHSGrad`.
    Finally, the computed channels are saved in the `_channels` parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Ptr<ERFilter> createERFilterNM1(const Ptr<ERFilter::Callback>& cb, int thresholdDelta
    = 1, float minArea = 0.00025, float maxArea = 0.13, float minProbability = 0.4,
    bool nonMaxSuppression = true, float minProbabilityDiff = 0.1)`: This function
    creates an Extremal Region Filter for the classifier of the first stage defined
    by the algorithm. The first parameter loads the classifier by means of the function
    `loadClassifierNM1(const std::string& filename)`. The `thresholdDelta` variable
    indicates the threshold step during the component tree obtaining process. The
    parameters `minArea` and `maxArea` establish the percentages of the image size
    between which external regions are retrieved. The value of the `bool` parameter
    `nonMaxSuppression` is `true` when non-maximum suppression is applied over the
    branch probabilities, and `false` otherwise. Finally, the `minProbability` and
    `minProbabilityDiff` parameters control the minimum probability value and the
    minimum probability difference between local maxima and minima values allowed
    for retrieving an external region.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Ptr<ERFilter> createERFilterNM2(const Ptr<ERFilter::Callback>& cb, float minProbability
    = 0.3)`: This function creates an External Region Filter for the classifier of
    the second stage defined by the algorithm. The first parameter loads the classifier
    by means of the function `loadClassifierNM2(const std::string& filename)`. The
    other parameter, `minProbability`, is the minimum probability allowed for retrieved
    external regions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void ERFilter::run( InputArray image, std::vector<ERStat>& regions)`: This
    method applies the cascade classifier loaded by the filter to obtain the external
    regions either in the first or the second level. The `image` parameter is the
    channel that has to be examined and `regions` is a vector with the output of the
    first stage and also the input/output of the second one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void erGrouping(InputArrayOfArrays src, std::vector<std::vector<ERStat>>&
    regions, const std::string& filename, float minProbability, std::vector<Rect>&
    groups)`: This function groups the external regions obtained. It uses the extracted
    channels (`src`), the obtained external regions by each channel (`regions`), the
    path to the grouping classifier, and the minimum probability for accepting a group
    (`minProbability`). Final groups, which are rectangles from `Rect`, are stored
    in the vector `groups`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following group of screenshots shows the obtained image channels. These
    are red (`R`), green (`G`), blue (`B`), intensity (`I`), gradient magnitude (∇),
    inverted red (`iR`), inverted green (`iG`), inverted blue (`iB`), and inverted
    intensity (`iI`). In the first row, the `R`, `G`, and `B` channels are shown.
    The second row shows the I, ∇, and iR channels. Finally, in the third row, the
    iG, iB, and iI channels are shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scene text detection](img/00044.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Extracted image channels
  prefs: []
  type: TYPE_NORMAL
- en: 'The following group of screenshots shows it is possible to see the external
    regions extracted from each channel. Channels `R`, `G`, `B`, `L`, and ∇ produce
    more accurate results. In the first row, external regions from the `R`, `G`, and
    `B` channels are shown. The second row shows the external regions extracted from
    the I, ∇, and iR channels. Finally, in the third row, the `iG`, `iB`, and `iI`
    channels are shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scene text detection](img/00045.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: External regions obtained from each channel
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the following screenshot shows the input image with the text areas
    grouped into lines and paragraphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scene text detection](img/00046.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Groups obtained
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To reproduce these results or use the OpenCV Scene Text Detector, it is possible
    to use this code with the sample files provided by the library. The input image
    and classifier can be found in the `OPENCV_SCR/samples/cpp` directory. The image
    used here is `cenetext01.jpg`. The first and second level classifiers are `trained_classifierNM1.xml`
    and `trained_classifierNM2.xml`. Finally, the grouping classifier provided by
    OpenCV is `trained_classifier_erGrouping.xml`.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers the OpenCV `objdetect` module. It explains how to use and
    train the Cascade detectors as well as how to use Latent SVM detectors. Moreover,
    the new Scene Text Detector included in OpenCV 3 has been explained in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Methods for detecting and tracking objects in motion are explained in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: What else?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cascade detectors have been widely used in several applications such as face
    recognition and pedestrian detection because they are fast and provide good results.
    Soft cascades are a variant of the classic cascade detectors. This new type of
    cascades is implemented in OpenCV 3 in the `softcascade` module. Soft cascade
    is trained with AdaBoost but the resulting detector is composed of only one stage.
    This stage has several weak classifiers that are evaluated in sequence. After
    evaluating each weak classifier, the result is compared with the corresponding
    threshold. Similar to the evaluation process carried out in multistage cascades,
    negative non-object instances are discarded as soon as possible.
  prefs: []
  type: TYPE_NORMAL
