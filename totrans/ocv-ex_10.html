<html><head></head><body><div class="chapter" title="Chapter&#xA0;10.&#xA0;Developing Segmentation Algorithms for Text Recognition"><div class="titlepage"><div><div><h1 class="title"><a id="ch10"/>Chapter 10. Developing Segmentation Algorithms for Text Recognition</h1></div></div></div><p>In the previous chapters, we learned about a wide range of image processing techniques, such as thresholding, contour descriptors, and mathematical morphology. In this chapter, we will discuss the common problems with dealing with scanned documents, such as identifying where the text is or adjusting its rotation. We will also learn how to combine techniques presented in the previous chapters to solve these problems. Finally, we'll have segmented regions of text that can be sent to an <a id="id400" class="indexterm"/>
<span class="strong"><strong>OCR</strong></span> (<span class="strong"><strong>optical character recognition</strong></span>) library.</p><p>By the end of this chapter, you should be able to answer the following questions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">What kind of OCR applications exist?</li><li class="listitem" style="list-style-type: disc">What are the common problems while writing an OCR application?</li><li class="listitem" style="list-style-type: disc">How do we identify regions of documents?</li><li class="listitem" style="list-style-type: disc">How do we deal with problems such as skewing and other elements in the middle of the text?</li><li class="listitem" style="list-style-type: disc">How do we use Tesseract OCR to identify the text?</li></ul></div><div class="section" title="Introducing optical character recognition"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec69"/>Introducing optical character recognition</h1></div></div></div><p>Identifying text in an image is a very popular application for Computer Vision. This process is commonly called OCR and divided into the following steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Text preprocessing and segmentation</strong></span>: During this step, the computer must learn to<a id="id401" class="indexterm"/> deal with the image noise and rotation (skewing) and identify what areas are candidate text areas.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Text identification</strong></span>: This is a<a id="id402" class="indexterm"/> process used to identify each letter in a text. Although this is also a Computer Vision topic, we will not show you how to do this in this book using OpenCV. Instead, we will show you how to use the Tesseract library to do this step, since it was integrated with OpenCV 3.0. If you are interested in learning how to do what Tesseract does all by yourself, take a look at <span class="emphasis"><em>Mastering OpenCV</em></span>, <span class="emphasis"><em>Packt Publishing</em></span>, which presents a chapter about car license plate recognition.</li></ul></div><p>The <a id="id403" class="indexterm"/>preprocessing and segmentation phase can vary greatly depending on the source of the text. Let's take a look at the common situations where preprocessing is done:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Production OCR applications with a scanner, which is a very reliable source of text: In this scenario, the background of the image is usually white and the document is almost aligned with the scanner margins. The content that is being scanned basically contains text with almost no noise. This kind of application relies on simple preprocessing techniques that can adjust the text quickly and maintain a fast scanning pace. When writing production OCR software, it is common to delegate identification of important text regions to the user and create a quality pipeline for text verification and indexing.</li><li class="listitem" style="list-style-type: disc">Scanning text in a casually taken picture or in a video: This is a much more complex scenario, as there's no indication of where the text can be. This scenario is called <span class="emphasis"><em>Scene text recognition</em></span>, and OpenCV 3.0 introduces a brand new library to deal with it, which we will cover in <a class="link" href="ch11.html" title="Chapter 11. Text Recognition with Tesseract">Chapter 11</a>, <span class="emphasis"><em>Text Recognition with Tesseract</em></span>. Usually, the preprocessor will use texture analysis techniques to identify the text patterns.</li><li class="listitem" style="list-style-type: disc">Creating a production quality OCR for historical texts: Historical texts are also scanned.<p>However, they have several additional problems, such as noise created by the old paper color and usage of ink. Other common problems are decorated letters, specific text fonts, and low-contrast content created by ink that has been degraded over time. It's not uncommon to write specific OCR software for documents at hand.</p></li><li class="listitem" style="list-style-type: disc">Scanning maps, diagrams, and charts: Maps, diagrams, and charts pose a difficult scenario since the text is usually in any orientation and in the middle of an image's content. For example, city names are often clustered, and ocean names often follow country shore contour lines. Some charts are heavily colored, with text appearing in both clear and dark tones.</li></ul></div><p>OCR application strategies also vary according to the objective of the identification. Will they be used for a full text search? Or should the text be separated in a logical field to index a database with information for a structured search?</p><p>In this chapter, we <a id="id404" class="indexterm"/>will focus on preprocessing scanned text or text photographed by a camera. We'll assume that the text is the main purpose of the image, such as in a photograph, paper, or card; for example, take a look at the following parking ticket:</p><div class="mediaobject"><img src="graphics/B04283_10_01.jpg" alt="Introducing optical character recognition"/></div><p>We'll try to remove the common noise, deal with text rotation (if any), and crop the possible text regions. While most OCR APIs already do these things automatically and probably with state-of-the-art algorithms, it still worth knowing how things happen under the hood. This will allow you to better understand most OCR APIs' parameters and will give you a better knowledge of potential OCR problems that you may face.</p></div></div>
<div class="section" title="The preprocessing step"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec70"/>The preprocessing step</h1></div></div></div><p>Software<a id="id405" class="indexterm"/> that identifies letters do so by comparing text with a previously <a id="id406" class="indexterm"/>recorded data. Classification results can be improved greatly if the input text is clear, if the letters are in a vertical position, and if there are no other elements, such as images that are sent to the classification software. In this section, we'll learn how to adjust text. This stage is called <span class="strong"><strong>preprocessing</strong></span>.</p><div class="section" title="Thresholding the image"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec53"/>Thresholding the image</h2></div></div></div><p>We<a id="id407" class="indexterm"/> usually start the preprocessing stage by thresholding the image. This eliminates all the color information. Most OpenCV functions require information to be the written in white and the background to be black. So, let's start with creating a threshold function to match this criterion:</p><div class="informalexample"><pre class="programlisting">#include &lt;opencv2/opencv.hpp&gt;
#include &lt;vector&gt;

using namespace std;
using namespace cv;

Mat binarize(Mat input)
{
  //Uses otsu to threshold the input image
  Mat binaryImage;
  cvtColor(input, input, CV_BGR2GRAY);
  threshold(input, binaryImage, 0, 255, THRESH_OTSU);
  //Count the number of black and white pixels
  int white = countNonZero(binaryImage);
  int black = binaryImage.size().area() - white;
  //If the image is mostly white (white background), invert it
  return white &lt; black ? binaryImage : ~binaryImage;
}</pre></div><p>The <code class="literal">binarize</code> function applies a threshold, similar to what we did in <a class="link" href="ch04.html" title="Chapter 4. Delving into Histograms and Filters">Chapter 4</a>, <span class="emphasis"><em>Delving into Histograms and Filters</em></span>. However, we use the <code class="literal">Otsu</code> method by passing <code class="literal">THRESH_OTSU</code> to the fourth parameter of the function.</p><p>The <code class="literal">Otsu</code> method maximizes the inter-class variance. Since a threshold creates only two classes (the black and white pixels), this is the same as minimizing the intra-class variance. The method works using the image histogram. Then, it iterates through all the possible threshold values and calculates a measure of spread for the pixel values on each side of the threshold, that is, the pixels that are either in the background or in the foreground of the image. The purpose is to find the threshold value where the sum of both the spreads is at its minimum.</p><p>After the <a id="id408" class="indexterm"/>thresholding is done, the function counts the number of white pixels in the image. The black pixels are simply the total number of pixels in the image, given by the image area minus the white pixel count.</p><p>Since text is usually written on a plain background, we will check whether there are more white pixels than black. In this case, we are dealing with black text over a white background, so we invert the image for further processing.</p><p>The result of the thresholding process with the parking ticket image is shown in the following image:</p><div class="mediaobject"><img src="graphics/B04283_10_02.jpg" alt="Thresholding the image"/></div></div><div class="section" title="Text segmentation"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec54"/>Text segmentation</h2></div></div></div><p>The next<a id="id409" class="indexterm"/> step is to find where the text is located and extract it. There <a id="id410" class="indexterm"/>are two common strategies to do this, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Using the connected component analysis, we search for groups of connected pixels in the image. This is the technique that we will use in this chapter.</li><li class="listitem" style="list-style-type: disc">Use classifiers to search for a previously trained letter texture pattern. Texture features such as Haralick features and wavelet transforms are often used. The other option is to identify <a id="id411" class="indexterm"/><span class="strong"><strong>maximally stable extremal regions</strong></span> (<span class="strong"><strong>MSERs</strong></span>) in this task. This approach is more robust for text in a complex background and will be studied in the next chapter. You can read about Haralick features on his own website at <a class="ulink" href="http://haralick.org/journals/TexturalFeatures.pdf">http://haralick.org/journals/TexturalFeatures.pdf</a>.</li></ul></div><div class="section" title="Creating connected areas"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec01"/>Creating connected areas</h3></div></div></div><p>If you take a<a id="id412" class="indexterm"/> closer look at the image, you'll notice that the letters are always grouped together in blocks that are formed by each of text paragraphs. So, how do we detect and remove these blocks?</p><p>The first step is to make these blocks even more evident. We can do this using the dilation morphological operator. In <a class="link" href="ch08.html" title="Chapter 8. Video Surveillance, Background Modeling, and Morphological Operations">Chapter 8</a>, <span class="emphasis"><em>Video Surveillance, Background Modeling, and Morphological Operations</em></span>, we learned how dilation makes the image elements thicker. Let's take a look at the following code snippet that does the trick:</p><div class="informalexample"><pre class="programlisting">Mat kernel = getStructuringElement(MORPH_CROSS, Size(3,3));
Mat dilated;
dilate(input, dilated, kernel, cv::Point(-1, -1), 5);
imshow("Dilated", dilated);</pre></div><p>In this code, we start by creating a 3 x 3 cross kernel that will be used in the morphological operation. Then, we apply the dilation five times, centered on this kernel. The exact kernel size and number of times vary according to the situation. Just make sure that the values glue all the letters in the same line together.</p><p>The result of this operation is as follows:</p><div class="mediaobject"><img src="graphics/B04283_10_03.jpg" alt="Creating connected areas"/></div><p>Notice that now <a id="id413" class="indexterm"/>we have huge white blocks. They exactly match each paragraph of the text and also match other nontextual elements such as images or the border noise.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip03"/>Tip</h3><p>The ticket image that comes with the code is a low resolution image. OCR engines usually work with high resolution images (200 or 300 DPI), so it may be necessary to apply dilation more than five times.</p></div></div></div><div class="section" title="Identifying paragraph blocks"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec02"/>Identifying paragraph blocks</h3></div></div></div><p>The<a id="id414" class="indexterm"/> next step is to perform connect component analysis to find blocks that correspond to paragraphs. OpenCV has a function to do this, which we previously used in <a class="link" href="ch05.html" title="Chapter 5. Automated Optical Inspection, Object Segmentation, and Detection">Chapter 5</a>, <span class="emphasis"><em>Automated Optical Inspection, Object Segmentation, and Detection</em></span>. It's the <code class="literal">findContours</code> function:</p><div class="informalexample"><pre class="programlisting">vector&lt;vector&lt;Point&gt; &gt; contours;
findContours(dilated, contours, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE);</pre></div><p>In the first parameter, we pass our dilated image. The second parameter is the vector of detected contours. Then we use the option to retrieve only external contours and use simple approximation. The image contours are presented in the following figure. Each tone of gray represents a different contour:</p><div class="mediaobject"><img src="graphics/B04283_10_04.jpg" alt="Identifying paragraph blocks"/></div><p>The last step is to identify the minimum rotated bounding rectangle of each contour. OpenCV provides a handy function for this operation called <code class="literal">minAreaRect</code>. This function receives a vector of arbitrary points and returns a <code class="literal">RoundedRect</code> that contains the bounding box.</p><p>This is also a <a id="id415" class="indexterm"/>good opportunity to discard unwanted rectangles, that is, rectangles that are obviously <span class="strong"><strong>not</strong></span> text. Since we are making a software for OCR, we'll assume that the text contains a group of letters together. With this assumption, we'll discard text in the following situations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The rectangle width or size is too small, that is, smaller than 20 pixels. This will help you discard border noise and other small artifacts.</li><li class="listitem" style="list-style-type: disc">The rectangles of the images that have a width/height proportion smaller than two. That is, rectangles that resemble a square, such as image icons, or ones that are much taller and larger will also be discarded.</li></ul></div><p>There's a little caveat in the second condition. Since we are dealing with rotated bounding boxes, we must check whether the bounding box angle is not smaller than 45 degrees. If that's the case, the text will be vertically rotated, so the proportion that must be taken into account is the height/width. Let's take a look at this code:</p><div class="informalexample"><pre class="programlisting">//For each contour
vector&lt;RotatedRect&gt; areas;
for (auto contour : contours)
{
  //Find it's rotated rect
  auto box = minAreaRect(contour);

  //Discard very small boxes
  if (box.size.width &lt; 20 || box.size.height &lt; 20)
    continue;

  //Discard squares shaped boxes and boxes
  //higher than larger
  double proportion = box.angle &lt; -45.0 ?
    box.size.height / box.size.width :
    box.size.width / box.size.height;
  if (proportion &lt; 2)
    continue;
  //Add the box
  areas.push_back(box);
}</pre></div><p>Let's see the boxes that are selected by this algorithm:</p><div class="mediaobject"><img src="graphics/B04283_10_05.jpg" alt="Identifying paragraph blocks"/></div><p>This is certainly a good result!</p><p>Notice that <a id="id416" class="indexterm"/>the algorithm described in condition 2 will also discard single letters. This is not a big issue, since we are creating an OCR preprocessor, and single symbols are usually meaningless with the context information. One example of such a case is the page numbers. They will be discarded with this process since they usually appear alone at the bottom of the page and will definitely fail the size or proportion text. However, this will not be a problem, as after the text passes through the OCR, there will be a huge text file with no page division at all.</p><p>We'll place this code in a function with this signature:</p><div class="informalexample"><pre class="programlisting">vector&lt;RotatedRect&gt; findTextAreas(Mat input)</pre></div></div><div class="section" title="Text extraction and skew adjustment"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec03"/>Text extraction and skew adjustment</h3></div></div></div><p>Now, all <a id="id417" class="indexterm"/>we need to do is extract the text and adjust <a id="id418" class="indexterm"/>text skew. This is done by the <code class="literal">deskewAndCrop</code> function, as follows:</p><div class="informalexample"><pre class="programlisting">Mat deskewAndCrop(Mat input, const RotatedRect&amp; box)
{
  double angle = box.angle;
  Size2f size = box.size;

  //Adjust the box angle
   if (angle &lt; -45.0)
  {
        angle += 90.0;
		std::swap(size.width, size.height);
  }
  
  //Rotate the text according to the angle
  Mat transform = getRotationMatrix2D(box.center, angle, 1.0);
  Mat rotated;
  warpAffine(input, rotated, transform, input.size(), INTER_CUBIC);

  //Crop the result
  Mat cropped;
  getRectSubPix(rotated, size, box.center, cropped);
  copyMakeBorder(cropped,cropped,10,10,10,10,BORDER_CONSTANT,Scalar(0));
  return cropped;
}</pre></div><p>First, we start by reading the desired region, angle, and size. As mentioned earlier, the angle can be less than 45 degrees. This means that the text is vertically aligned, so we need to add 90 degrees to the rotation angle and switch the width and height properties.</p><p>Next, we need to rotate the text. First, we start by creating a 2D affine transformation matrix that describes the rotation. We do this using the <code class="literal">getRotationMatrix2D</code> OpenCV function. This function takes the following three parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">CENTER</code>: This is<a id="id419" class="indexterm"/> the central position of the rotation. The rotation will pivot around this center. In our case, we use the box center.</li><li class="listitem" style="list-style-type: disc"><code class="literal">ANGLE</code>: This is <a id="id420" class="indexterm"/>the rotation angle. If the angle is negative, the rotation will occur in the clockwise direction.</li><li class="listitem" style="list-style-type: disc"><code class="literal">SCALE</code>: This <a id="id421" class="indexterm"/>is an isotropic scale factor. We use 1.0 as we want to keep the box's original scale untouched.</li></ul></div><p>The rotation itself <a id="id422" class="indexterm"/>is made using the <code class="literal">warpAffine</code> function. This function<a id="id423" class="indexterm"/> takes four mandatory arguments, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">SRC</code>: This<a id="id424" class="indexterm"/> is the input <code class="literal">mat</code> array to be transformed.</li><li class="listitem" style="list-style-type: disc"><code class="literal">DST</code>: This <a id="id425" class="indexterm"/>is the destination <code class="literal">mat</code> array.</li><li class="listitem" style="list-style-type: disc"><code class="literal">M</code>: This is a <a id="id426" class="indexterm"/>transformation matrix. This matrix is a 2 x 3 affine transformation matrix. This may be a translation, scale, or rotation matrix. In our case, we just use the matrix that we recently created.</li><li class="listitem" style="list-style-type: disc"><code class="literal">SIZE</code>: This<a id="id427" class="indexterm"/> is the size of the output image. We will generate an image with the same size as that of our input image.</li></ul></div><p>The other three optional arguments are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">FLAGS</code>: This <a id="id428" class="indexterm"/>indicates how the image should be interpolated. We use <code class="literal">BICUBIC_INTERPOLATION</code> for better quality. The default value is <code class="literal">LINEAR_INTERPOLATION</code>.</li><li class="listitem" style="list-style-type: disc"><code class="literal">BORDER</code>: This is<a id="id429" class="indexterm"/> the border mode. We use the default <code class="literal">BORDER_CONSTANT</code>.</li><li class="listitem" style="list-style-type: disc"><code class="literal">BORDER VALUE</code>: This <a id="id430" class="indexterm"/>is the color of the border. We use the default value, which is black.</li></ul></div><p>Then, we use the <code class="literal">getRectSubPix</code> function. After we rotate our image, we need to crop the rectangular area of our bounding box. This function takes four mandatory arguments and one optional, and returns the cropped image:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">IMAGE</code>: This<a id="id431" class="indexterm"/> is the image to be cropped.</li><li class="listitem" style="list-style-type: disc"><code class="literal">SIZE</code>: This<a id="id432" class="indexterm"/> is a <code class="literal">cv::Size</code> object that describes the width and height of the box to be cropped.</li><li class="listitem" style="list-style-type: disc"><code class="literal">CENTER</code>: This<a id="id433" class="indexterm"/> is the central pixel of the area to be cropped. Notice that as we rotate around the center, this point remains the same.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PATCH</code>: This<a id="id434" class="indexterm"/> is the destination image.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PATCH_TYPE</code>: This is <a id="id435" class="indexterm"/>the depth of the destination image. We use the default value, representing the same depth as that of the source image.</li></ul></div><p>The final step is done by the <code class="literal">copyMakeBorder</code> function. This function adds a border around the image. This is important because the classification stage usually expects a margin around the text. The<a id="id436" class="indexterm"/> function parameters are very simple: the input and output images, the border thickness around the top, bottom, left, and right of the image, and the color of the new border.</p><p>For the card image, the following images will be generated:</p><div class="mediaobject"><img src="graphics/B04283_10_06.jpg" alt="Text extraction and skew adjustment"/></div><p>Now, it's time to put every function together. Let's present the main method that will do the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Load the ticket image</li><li class="listitem" style="list-style-type: disc">Call our <code class="literal">binarization</code> function</li><li class="listitem" style="list-style-type: disc">Find all text regions</li><li class="listitem" style="list-style-type: disc">Show each region in a window:<div class="informalexample"><pre class="programlisting">int main(int argc, char* argv[])
{
  //Loads the ticket image and binarize it
  Mat ticket = binarize(imread("ticket.png"));
  auto regions = findTextAreas(ticket);
  
  //For each region
  for (auto&amp; region : regions) {
    //Crop 
    auto cropped = deskewAndCrop(ticket, region);
    //Show
    imshow("Cropped text", cropped);
    waitKey(0);
    destroyWindow("Border Skew");
  }
}</pre></div></li></ul></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note27"/>Note</h3><p>For the complete source code, take a look at the <code class="literal">segment.cpp</code> file that comes along with this book.</p></div></div></div></div></div>
<div class="section" title="Installing Tesseract OCR on your operating system"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec71"/>Installing Tesseract OCR on your operating system</h1></div></div></div><p>Tesseract is <a id="id437" class="indexterm"/>an open source OCR engine originally developed by <span class="emphasis"><em>Hewlett-Packard Laboratories, Bristol</em></span> and <span class="emphasis"><em>Hewlett-Packard Co</em></span>. It has all the code licenses under the Apache License and is hosted on<a id="id438" class="indexterm"/> GitHub at <a class="ulink" href="https://github.com/tesseract-ocr">https://github.com/tesseract-ocr</a>.</p><p>It is <a id="id439" class="indexterm"/>considered <a id="id440" class="indexterm"/>one of the most accurate OCR engines that is available. It can read a wide variety of image formats and can convert text written in more than 60 languages.</p><p>In this session, we will teach you how to install Tesseract on Windows or Mac. Since there are lots of Linux distributions, we will not teach you how to install on this operating system.</p><p>Normally, Tesseract offers installation packages in your package repository, so before you compile Tesseract, just search there.</p><div class="section" title="Installing Tesseract on Windows"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec55"/>Installing Tesseract on Windows</h2></div></div></div><p>Although <a id="id441" class="indexterm"/>Tesseract is hosted on GitHub, its latest Windows <a id="id442" class="indexterm"/>installer is still available in the old repository on Google Code. The latest installer version is 3.02.02, and it's recommended that you use the installer. Download the <a id="id443" class="indexterm"/>installer from <a class="ulink" href="https://code.google.com/p/tesseract-ocr/downloads/list">https://code.google.com/p/tesseract-ocr/downloads/list</a>.</p><p>Once you have downloaded the installer, perform these steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Look for the <code class="literal">tesseract-ocr-setup-3.02.02.exe</code> and <code class="literal">tesseract-3.02.02-win32-lib-include-dirs.zip</code> files, and download and run the executable installer<div class="mediaobject"><img src="graphics/B04283_10_07.jpg" alt="Installing Tesseract on Windows"/></div></li><li class="listitem">To get past the <span class="strong"><strong>welcome screen</strong></span>, read and accept the license agreement.</li><li class="listitem">Choose <a id="id444" class="indexterm"/>between installing for all users in the computer or just for your user.</li><li class="listitem">Then, choose a suitable location for your installation.</li><li class="listitem">Choose the folder of the installation. Tesseract points to the <code class="literal">program files</code> folder by default, since it has a command-line interface. You can change it to a more suitable folder, if you want. Then, go to the next screen:<div class="mediaobject"><img src="graphics/B04283_10_08.jpg" alt="Installing Tesseract on Windows"/></div></li><li class="listitem">Make sure <a id="id445" class="indexterm"/>you select <span class="strong"><strong>Tesseract development files</strong></span>. This will install the <code class="literal">Leptonica</code> library files and source code. You can also choose language data for your native language. Tesseract has English selected by default.</li><li class="listitem">The installer will download and set up Tesseract dependencies.<div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip04"/>Tip</h3><p>To test the Tesseract installation, you can run it via the command line. For example, to run Tesseract on the <code class="literal">parkingTicket.png</code> file, you can run the following command:</p><div class="informalexample"><pre class="programlisting">tesseract parkingTicket.png ticket.txt</pre></div></div></div></li><li class="listitem">Now, go back to the downloaded <code class="literal">tesseract-3.02.02-win32-lib-include-dirs.zip</code> file. Unzip this file and copy the <code class="literal">lib</code> and <code class="literal">add</code> folders to your <code class="literal">tesseract</code> installation folder. There will be folders with the same name in this folder, but that's normal. This file will include <code class="literal">tesseract</code> files and libraries in the Tesseract installation. Ironically, Tesseract <code class="literal">libs</code> and <code class="literal">dlls</code> do not come with the installer.</li></ol></div><div class="section" title="Setting up Tesseract in Visual Studio"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec04"/>Setting up Tesseract in Visual Studio</h3></div></div></div><p>Since <a id="id446" class="indexterm"/>Visual Studio 2010 is the recommended IDE for Windows developers with Tesseract, it's important to set this up correctly.</p><p>The setup process is quite simple, and it's divided into the following three steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Adjust the import and library paths.</li><li class="listitem">Add the libraries to the linker input.</li><li class="listitem">Add Tesseract <code class="literal">dlls</code> to the windows path.</li></ol></div><p>Let's see each of these steps in the following sections.</p><div class="section" title="Setting the import and library paths"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl4sec01"/>Setting the import and library paths</h4></div></div></div><p>The<a id="id447" class="indexterm"/> import path tells Visual Studio where to search for the <code class="literal">.h</code> files that will be available when an <code class="literal">#include</code> directive is performed in your code.</p><p>In solution explorer, right-click on your <span class="strong"><strong>project</strong></span> and click on <span class="strong"><strong>properties</strong></span>. Then, select <span class="strong"><strong>configuration properties</strong></span> and <span class="strong"><strong>VC++ Directories</strong></span>.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note28"/>Note</h3><p>If you have created a new project from scratch, make sure you added at least one <code class="literal">c++</code> file to the project to let Visual know that this is a <code class="literal">C++</code> project.</p></div></div><p>Next, click on <span class="strong"><strong>Include Directories</strong></span>. An arrow appears. Click on this arrow and then click on <span class="strong"><strong>Edit</strong></span>:</p><div class="mediaobject"><img src="graphics/B04283_10_09.jpg" alt="Setting the import and library paths"/></div><p>You must <a id="id448" class="indexterm"/>add two directories to this list:</p><div class="informalexample"><pre class="programlisting">TesseractInstallPath\include
TesseractInstallPath\include\leptonica</pre></div><p>Replace the <code class="literal">TesseractInstallPath</code> with your Tesseract installation path; for example, <code class="literal">c:\Program Files\Tesseract-OCR</code>.</p><p>Then, click on <span class="strong"><strong>Library Directories</strong></span>, click on the arrow, and then on <code class="literal">Edit</code>, just like you did for <span class="strong"><strong>Include Directories</strong></span>. You must add one directory to the list:</p><div class="informalexample"><pre class="programlisting">TesseractInstallPath\lib</pre></div></div><div class="section" title="Configuring the linker"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl4sec02"/>Configuring the linker</h4></div></div></div><p>While <a id="id449" class="indexterm"/>still on the Property page, go to <span class="strong"><strong>Linker</strong></span> | <span class="strong"><strong>Input</strong></span>. Edit the <span class="strong"><strong>Additional Dependencies</strong></span> row and include two libraries:</p><div class="informalexample"><pre class="programlisting">liblept168.lib
libtesseract302.lib</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note29"/>Note</h3><p>Since the numbers in the <code class="literal">lib</code> name refer to the file version, the library names can change if you install a different version of Tesseract. To do this, just open the <code class="literal">lib</code> path in Windows Explorer.</p><p>Unfortunately, the debug libraries (the ones that end with a <span class="emphasis"><em>d</em></span> letter) do not work out of the box with Tesseract. If you really need to use them, you need to compile Tesseract and Leptonica yourself.</p></div></div></div><div class="section" title="Adding the libraries to the windows path"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl4sec03"/>Adding the libraries to the windows path</h4></div></div></div><p>You <a id="id450" class="indexterm"/>must add two library files to the windows path. The first is located directly in <code class="literal">TesseractInstallPath</code> and it is called <code class="literal">liblept168.dll</code>. The second one is in <code class="literal">TesseractInstallPath\lib</code> and it is called <code class="literal">libtesseract302.dll</code>. There are two ways to do this:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Copy these files to a location where Visual Studio generates your executable file. This will not add the files to the Windows path but will allow the application to run.</li><li class="listitem" style="list-style-type: disc">Copy these files to a folder that is configured in the Windows path. You can configure a new folder in the Windows path by changing the environment variables in <span class="strong"><strong>System Properties</strong></span>.<div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip05"/>Tip</h3><p>Some internet tutorials teach you to include these files in folders, such as <code class="literal">Windows\System32</code>. Do not do this. If you do this, it can be hard to change the library version in the future, since this folder has a lot of other <code class="literal">dlls</code> systems, and you may lose track of what you already placed in there. Also, you can always disable a custom path to test an installer and check whether you forgot to pack a <code class="literal">dll</code> in your installation bundle.</p></div></div></li></ul></div></div></div></div><div class="section" title="Installing Tesseract on Mac"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec56"/>Installing Tesseract on Mac</h2></div></div></div><p>The<a id="id451" class="indexterm"/> easiest <a id="id452" class="indexterm"/>way to install Tesseract OCR on Mac is using Homebrew. If you don't have Homebrew installed, just go to the Homebrew site (<a class="ulink" href="http://brew.sh/">http://brew.sh/</a>), open your console, and run the Ruby script that is on the front page. You may be required to type your administrator password.</p><p>After <code class="literal">homebrew</code> is installed, just type the following command:</p><div class="informalexample"><pre class="programlisting">brew install tesseract</pre></div><p>The English language is already included in this installation. If you want to install other language packs, just run the following command:</p><div class="informalexample"><pre class="programlisting">brew install tesseract --all-languages</pre></div><p>This will install <a id="id453" class="indexterm"/>all language packs. Then, just go to the Tesseract installation directory and delete all unwanted languages. Homebrew usually installs stuff in <code class="literal">/usr/local/</code>.</p></div></div>
<div class="section" title="Using Tesseract OCR library"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec72"/>Using Tesseract OCR library</h1></div></div></div><p>As Tesseract OCR<a id="id454" class="indexterm"/> is already integrated with OpenCV 3.0, it still worth studying its API since it allows a finer-grained control over Tesseract parameters. The integration will be studied in the next chapter.</p><div class="section" title="Creating a OCR function"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec57"/>Creating a OCR function</h2></div></div></div><p>We'll <a id="id455" class="indexterm"/>change the previous example to <a id="id456" class="indexterm"/>work with Tesseract. We will start with adding <code class="literal">baseapi</code> and <code class="literal">fstream tesseracts</code> to the list:</p><div class="informalexample"><pre class="programlisting">#include &lt;opencv2/opencv.hpp&gt;
<span class="strong"><strong>#include &lt;tesseract/baseapi.h&gt;</strong></span>

#include &lt;vector&gt;
<span class="strong"><strong>#include &lt;fstream&gt;</strong></span>
</pre></div><p>Then, we'll create a global <code class="literal">TessBaseAPI</code> object that represents our Tesseract OCR engine:</p><div class="informalexample"><pre class="programlisting">tesseract::TessBaseAPI ocr;</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip06"/>Tip</h3><p>The <code class="literal">ocr</code> engine is completely self-contained. If you want to create multithreaded OCR software, just add a different <code class="literal">TessBaseAPI</code> object to each thread, and the execution will be fairly thread-safe. You just need to guarantee that file writing is not done over the same file; otherwise, you'll need to guarantee safety for this operation.</p></div></div><p>Next, we will create a function called <code class="literal">identify</code> text that will run the OCR:</p><div class="informalexample"><pre class="programlisting">char* identifyText(Mat input, char* language = "eng") 
{
  ocr.Init(NULL, language, tesseract::OEM_TESSERACT_ONLY);
  ocr.SetPageSegMode(tesseract::PSM_SINGLE_BLOCK);
  ocr.SetImage(input.data, input.cols, input.rows, 1, input.step);
  char* text = ocr.GetUTF8Text();
  cout &lt;&lt; "Text:" &lt;&lt; endl;
  cout &lt;&lt; text &lt;&lt; endl;
  cout &lt;&lt; "Confidence: " &lt;&lt; ocr.MeanTextConf() &lt;&lt; endl &lt;&lt; endl;
  
    // Get the text    
  return text;
}</pre></div><p>Let's explain<a id="id457" class="indexterm"/> this function line by line. In the first line, we start initializing Tesseract. This is done by calling the <code class="literal">init</code> function. This function <a id="id458" class="indexterm"/>has the following signature:</p><div class="informalexample"><pre class="programlisting">int Init(const char* datapath, const char* language, OcrEngineMode oem)</pre></div><p>Let's explain each parameter:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Datapath</strong></span>: This is<a id="id459" class="indexterm"/> the path to the <code class="literal">tessdata</code> files of the root directory. The path must end with a backslash / character. The <code class="literal">tessdata</code> directory contains the language files that you installed. Passing <code class="literal">NULL</code> to this parameter will make Tesseract search in its installation directory, which is the location where this folder is normally present. It's common to change this value to <code class="literal">args[0]</code> when deploying an application and include the <code class="literal">tessdata</code> folder in your application path.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Language</strong></span>: This<a id="id460" class="indexterm"/> is a three-letter word with the language code (for example, eng for English, por for Portuguese, or hin for Hindi). Tesseract supports loading of multiple language code using the <code class="literal">+</code> sign. So, passing <span class="emphasis"><em>eng</em></span> + <span class="emphasis"><em>por</em></span> will load both English and Portuguese. Of course, you can only use languages that you have previously installed; otherwise, the loading will fail. A language <code class="literal">config</code> file can specify that two or more languages must be loaded together. To prevent this, you can use a tilde <code class="literal">~</code>. For example, you can use <code class="literal">hin+~eng</code> to guarantee that English is not loaded with Hindi, even if it is configured to do so.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>OcrEngineMode</strong></span>: These<a id="id461" class="indexterm"/> are OCR algorithms that will be used. They can have one of the following values:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">OEM_TESSERACT_ONLY</code>: This<a id="id462" class="indexterm"/> uses just Tesseract. It's the fastest method, but it also has less precision.</li><li class="listitem" style="list-style-type: disc"><code class="literal">OEM_CUBE_ONLY</code>: This <a id="id463" class="indexterm"/>uses cube engine. It's slower, but it's more precise. This will only work if your language was trained to support this engine mode. To check whether that's the case, look for <code class="literal">.cube</code> files for your language in the <code class="literal">tessdata</code> folder. The support for English is guaranteed.</li><li class="listitem" style="list-style-type: disc"><code class="literal">OEM_TESSERACT_CUBE_COMBINED</code>: This<a id="id464" class="indexterm"/> combines both Tesseract and Cube in order to achieve the best possible OCR classification. This engine has the best accuracy and the slowest execution time.</li><li class="listitem" style="list-style-type: disc"><code class="literal">OEM_DEFAULT</code>: This<a id="id465" class="indexterm"/> tries to infer the strategy based on the language <code class="literal">config</code> file and the command line <code class="literal">config</code> file, or in the absence of both, uses <code class="literal">OEM_TESSERACT_ONLY</code>.</li></ul></div></li></ul></div><p>It's<a id="id466" class="indexterm"/> important <a id="id467" class="indexterm"/>to emphasize that the <code class="literal">init</code> function <span class="emphasis"><em>can</em></span> be executed many times. If a different language or engine mode is provided, Tesseract will clear the previous configuration and start again. If the same parameters are provided, Tesseract is smart enough to simply ignore the command. The <code class="literal">init</code> function returns <code class="literal">0</code> for success and <code class="literal">-1</code> for failure.</p><p>Our program then proceeds by setting the page segmentation mode:</p><div class="informalexample"><pre class="programlisting">ocr.SetPageSegMode(tesseract::PSM_SINGLE_BLOCK);</pre></div><p>There are several segmentation modes available, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_OSD_ONLY</code>: Using<a id="id468" class="indexterm"/> this mode, Tesseract just runs its preprocessing algorithms to detect the orientation and script detection.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_AUTO_OSD</code>: This<a id="id469" class="indexterm"/> tells Tesseract to perform automatic page segmentation with orientation and script detection.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_AUTO_ONLY</code>: This <a id="id470" class="indexterm"/>does page segmentation, but avoids doing orientation, script detection, or OCR.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_AUTO</code>: This <a id="id471" class="indexterm"/>does page segmentation and OCR, but avoids doing orientation or script detection.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_SINGLE_COLUMN</code>: This<a id="id472" class="indexterm"/> assumes that the text of variable sizes is displayed in a single column.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_SINGLE_BLOCK_VERT_TEXT</code>: This<a id="id473" class="indexterm"/> treats the image as a single uniform block of a vertically aligned text.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_SINGLE_BLOCK</code>: This <a id="id474" class="indexterm"/>is a single block of text. This is the default configuration. We will use this flag since our preprocessing phase guarantees this condition.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_SINGLE_LINE</code>: This <a id="id475" class="indexterm"/>indicates that the image contains only one line of text.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_SINGLE_WORD</code>: This<a id="id476" class="indexterm"/> indicates that the image contains just one word.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_SINGLE_WORD_CIRCLE</code>: This<a id="id477" class="indexterm"/> indicates that the image is just one word that is disposed in a circle.</li><li class="listitem" style="list-style-type: disc"><code class="literal">PSM_SINGLE_CHAR</code>: This<a id="id478" class="indexterm"/> indicates that the image contains a single character.</li></ul></div><p>Notice that<a id="id479" class="indexterm"/> Tesseract has already implemented<code class="literal"> deskewing</code> and text segmentation algorithms, as most OCR libraries do. But it's interesting <a id="id480" class="indexterm"/>to know such algorithms as you can provide your own preprocessing phase for specific needs. This allows you to improve text detection is many cases. For example, if you are creating an OCR application for old documents, the default threshold used by Tesseract can create a dark background. Tesseract may also be confused by borders or severe text skewing.</p><p>Next, we call the <code class="literal">SetImage</code> method with the signature:</p><div class="informalexample"><pre class="programlisting">void SetImage(const unsigned char* imagedata, int width, int height, int bytes_per_pixel, int bytes_per_line);</pre></div><p>The parameters are almost self-explanatory, and most of them can be read directly from our <code class="literal">mat</code> object:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">data</code>: This is<a id="id481" class="indexterm"/> a raw byte array that contains the image data. OpenCV contains a function called <code class="literal">data()</code> in the <code class="literal">Mat</code> class that provides a direct pointer to the data.</li><li class="listitem" style="list-style-type: disc"><code class="literal">width</code>: This is <a id="id482" class="indexterm"/>the image width.</li><li class="listitem" style="list-style-type: disc"><code class="literal">height</code>: This<a id="id483" class="indexterm"/> is the image height.</li><li class="listitem" style="list-style-type: disc"><code class="literal">bytes_per_pixel</code>: This <a id="id484" class="indexterm"/>is the number of bytes per pixel. We use <code class="literal">1</code>, since we are dealing with a binary image. If you want to allow the code to be more generic, you can also use the <code class="literal">Mat::elemSize()</code> function that provides the same information.</li><li class="listitem" style="list-style-type: disc"><code class="literal">bytes_per_line</code>: This <a id="id485" class="indexterm"/>is the number of bytes in a single line. We use the <code class="literal">Mat::step</code> property since some images add trailing bytes.</li></ul></div><p>Then, we<a id="id486" class="indexterm"/> call <code class="literal">GetUTF8Text</code> to run the recognition itself. The recognized text is returned, encoded with UTF8 <a id="id487" class="indexterm"/>without BOM (byte order mark). Before we return it, we also print some debug information.</p><p>The <code class="literal">MeanTextConf</code> returns a confidence index, which can be a number from <code class="literal">0</code> to <code class="literal">100</code>:</p><div class="informalexample"><pre class="programlisting">  char* text = ocr.GetUTF8Text();
  cout &lt;&lt; "Text:" &lt;&lt; endl;
  cout &lt;&lt; text &lt;&lt; endl;
  cout &lt;&lt; "Confidence: " &lt;&lt; ocr.MeanTextConf() &lt;&lt; endl &lt;&lt; endl;</pre></div><div class="section" title="Sending the output to a file"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec05"/>Sending the output to a file</h3></div></div></div><p>Let's <a id="id488" class="indexterm"/>change our <code class="literal">main</code> method to send the recognized output to a file. We do this using a standard <code class="literal">ofstream</code>:</p><div class="informalexample"><pre class="programlisting">int main(int argc, char* argv[])
{
  //Loads the ticket image and binarize it
  Mat ticket = binarize(imread("ticket.png"));
  auto regions = findTextAreas(ticket);

  std::ofstream file;
  file.open("ticket.txt", std::ios::out | std::ios::binary);

  //For each region
  for (auto region : regions) {
    //Crop
    auto cropped = deskewAndCrop(ticket, region);
    char* text = identifyText(cropped, "por");
    
    file.write(text, strlen(text));
    file &lt;&lt; endl;
  }
  
  file.close();
}</pre></div><p>Notice the <a id="id489" class="indexterm"/>following line:</p><div class="informalexample"><pre class="programlisting">file.open("ticket.txt", std::ios::out | std::ios::binary);</pre></div><p>This opens the file in binary mode. This is important since Tesseract returns a text encoded in UTF-8, taking into account the special characters available in Unicode. We also write the output directly using the following command:</p><div class="informalexample"><pre class="programlisting">file.write(text, strlen(text));</pre></div><p>In this sample, we called <code class="literal">identify</code> using Portuguese as the input language (this is the language in which the ticket was written). You can use another photo, if you like.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note30"/>Note</h3><p>The complete source file is provided in the <code class="literal">segmentOcr.cpp</code> file, which comes along with this book.</p></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip07"/>Tip</h3><p>
<code class="literal">ticket.png</code> is a low resolution image, since we imagined that you would want to display a window with the image while studying this code. For this image, Tesseract results are rather poor. If you want to test it with a higher resolution image, the code is provided with a <code class="literal">ticketHigh.png</code> image. To test this image, change the dilation repetitions to 12 and the minimum box size from 20 to 60. You'll get a much higher confidence rate (about 87%) and the resulting text will be fully readable. The <code class="literal">segmentOcrHigh.cpp</code> file contains these modifications.</p></div></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec73"/>Summary</h1></div></div></div><p>In this chapter, we presented a brief introduction to OCR applications. We saw that the preprocessing phase of such systems must be adjusted according to the type of documents that we are planning to identify. We learned the common operations while preprocessing text files, such as thresholding, cropping, skewing, and text region segmentation. Finally, we learned how to install and use Tesseract OCR to convert our image to text.</p><p>In the next chapter, we'll use a more sophisticated OCR technique to identify text in a casually taken picture or video—a situation known as scene text recognition. This is a much more complex scenario, since the text can be anywhere, in any font, and with different illuminations and orientations. There can be no text at all! We'll also learn how to use the OpenCV 3.0 text contribution module, which is fully integrated with Tesseract.</p></div></body></html>