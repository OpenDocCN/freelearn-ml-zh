["```py\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nX, y = make_classification(n_samples=5000, n_features=50, \n                           n_informative=10,\n                           n_redundant=25, n_repeated=15, \n                           n_clusters_per_class=5,\n                           flip_y=0.05, class_sep=0.5, \n                           random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(X, y,   \n                           test_size=0.33, random_state=0) \n```", "```py\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import log_loss, roc_auc_score, accuracy_score\nmodel_1 = SVC(probability=True, random_state=0)\nmodel_2 = RandomForestClassifier(random_state=0)\nmodel_3 = KNeighborsClassifier() \n```", "```py\nmodel_1.fit(X_train, y_train)\nmodel_2.fit(X_train, y_train)\nmodel_3.fit(X_train, y_train) \n```", "```py\nimport numpy as np\nfrom scipy.stats import mode\npreds = np.stack([model_1.predict(X_test),\n                  model_2.predict(X_test),\n                  model_3.predict(X_test)]).T\nmax_voting = np.apply_along_axis(mode, 1, preds)[:,0] \n```", "```py\nfor i, model in enumerate(['SVC', 'RF ', 'KNN']):\n    acc = accuracy_score(y_true=y_test, y_pred=preds[:, i])\n    print(f\"Accuracy for model {model} is: {acc:0.3f}\") \n```", "```py\nmax_voting_accuray = accuracy_score(y_true=y_test, y_pred=max_voting)\nprint(f\"Accuracy for majority voting is: {max_voting_accuray:0.3f}\") \n```", "```py\nproba = np.stack([model_1.predict_proba(X_test)[:, 1],\n                  model_2.predict_proba(X_test)[:, 1],\n                  model_3.predict_proba(X_test)[:, 1]]).T\nfor i, model in enumerate(['SVC', 'RF ', 'KNN']):\n    ras = roc_auc_score(y_true=y_test, y_score=proba[:, i])\n    print(f\"ROC-AUC for model {model} is: {ras:0.5f}\") \n```", "```py\narithmetic = proba.mean(axis=1)\nras = roc_auc_score(y_true=y_test, y_score=arithmetic)\nprint(f\"Mean averaging ROC-AUC is: {ras:0.5f}\") \n```", "```py\ngeometric = proba.prod(axis=1)**(1/3)\nras = roc_auc_score(y_true=y_test, y_score=geometric)\nprint(f\"Geometric averaging ROC-AUC is: {ras:0.5f}\")\nharmonic = 1 / np.mean(1\\. / (proba + 0.00001), axis=1)\nras = roc_auc_score(y_true=y_test, y_score=harmonic)\nprint(f\"Geometric averaging ROC-AUC is: {ras:0.5f}\")\nn = 3\nmean_of_powers = np.mean(proba**n, axis=1)**(1/n)\nras = roc_auc_score(y_true=y_test, y_score=mean_of_powers)\nprint(f\"Mean of powers averaging ROC-AUC is: {ras:0.5f}\")\nlogarithmic = np.expm1(np.mean(np.log1p(proba), axis=1))\nras = roc_auc_score(y_true=y_test, y_score=logarithmic)\nprint(f\"Logarithmic averaging ROC-AUC is: {ras:0.5f}\") \n```", "```py\ncormat = np.corrcoef(proba.T)\nnp.fill_diagonal(cormat, 0.0)\nW = 1 / np.mean(cormat, axis=1)\nW = W / sum(W) # normalizing to sum==1.0\nweighted = proba.dot(W)\nras = roc_auc_score(y_true=y_test, y_score=weighted)\nprint(f\"Weighted averaging ROC-AUC is: {ras:0.5f}\") \n```", "```py\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=5, shuffle=True, random_state=0)\nscores = list()\nfor k, (train_index, test_index) in enumerate(kf.split(X_train)):\n    model_1.fit(X_train[train_index, :], y_train[train_index])\n    model_2.fit(X_train[train_index, :], y_train[train_index])\n    model_3.fit(X_train[train_index, :], y_train[train_index])\n\n    proba = np.stack(\n          [model_1.predict_proba(X_train[test_index, :])[:, 1],\n           model_2.predict_proba(X_train[test_index, :])[:, 1],\n           model_3.predict_proba(X_train[test_index, :])[:, 1]]).T\n\n    arithmetic = proba.mean(axis=1)\n    ras = roc_auc_score(y_true=y_train[test_index], \n                        y_score=arithmetic)\n    scores.append(ras)\n    print(f\"FOLD {k} Mean averaging ROC-AUC is: {ras:0.5f}\")\nprint(f\"CV Mean averaging ROC-AUC is: {np.mean(scores):0.5f}\") \n```", "```py\nfrom sklearn.preprocessing import MinMaxScaler\nproba = np.stack(\n          [model_1.predict_proba(X_train)[:, 1],\n           model_2.predict_proba(X_train)[:, 1],\n           model_3.predict_proba(X_train)[:, 1]]).T\narithmetic = MinMaxScaler().fit_transform(proba).mean(axis=1)\nras = roc_auc_score(y_true=y_test, y_score=arithmetic)\nprint(f\"Mean averaging ROC-AUC is: {ras:0.5f}\") \n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nX_blend, X_holdout, y_blend, y_holdout = train_test_split(X_train, y_train, test_size=0.25, random_state=0)\nmodel_1.fit(X_blend, y_blend)\nmodel_2.fit(X_blend, y_blend)\nmodel_3.fit(X_blend, y_blend)\nproba = np.stack([model_1.predict_proba(X_holdout)[:, 1],\n                  model_2.predict_proba(X_holdout)[:, 1],\n                  model_3.predict_proba(X_holdout)[:, 1]]).T\nscaler = StandardScaler()\nproba = scaler.fit_transform(proba) \n```", "```py\nfrom sklearn.linear_model import LogisticRegression\nblender = LogisticRegression(solver='liblinear')\nblender.fit(proba, y_holdout)\nprint(blender.coef_) \n```", "```py\n[[0.78911314 0.47202077 0.75115854]] \n```", "```py\ntest_proba = np.stack([model_1.predict_proba(X_test)[:, 1],\n                       model_2.predict_proba(X_test)[:, 1],\n                       model_3.predict_proba(X_test)[:, 1]]).T\nblending = blender.predict_proba(test_proba)[:, 1]\nras = roc_auc_score(y_true=y_test, y_score=blending)\nprint(f\"ROC-AUC for linear blending {model} is: {ras:0.5f}\") \n```", "```py\nblender = RandomForestClassifier()\nblender.fit(proba, y_holdout)\ntest_proba = np.stack([model_1.predict_proba(X_test)[:, 1],\n                       model_2.predict_proba(X_test)[:, 1],\n                       model_3.predict_proba(X_test)[:, 1]]).T\nblending = blender.predict_proba(test_proba)[:, 1]\nras = roc_auc_score(y_true=y_test, y_score=blending)\nprint(f\"ROC-AUC for non-linear blending {model} is: {ras:0.5f}\") \n```", "```py\nX_blend, X_holdout, y_blend, y_holdout = train_test_split\n    (X_train, y_train, test_size=0.5, random_state=0)\nmodel_1.fit(X_blend, y_blend)\nmodel_2.fit(X_blend, y_blend)\nmodel_3.fit(X_blend, y_blend)\nproba = np.stack([model_1.predict_proba(X_holdout)[:, 1],\n                  model_2.predict_proba(X_holdout)[:, 1],\n                  model_3.predict_proba(X_holdout)[:, 1]]).T \n```", "```py\niterations = 100\nproba = np.stack([model_1.predict_proba(X_holdout)[:, 1],\n                  model_2.predict_proba(X_holdout)[:, 1],\n                  model_3.predict_proba(X_holdout)[:, 1]]).T\nbaseline = 0.5\nprint(f\"starting baseline is {baseline:0.5f}\")\nmodels = []\nfor i in range(iterations):\n    challengers = list()\n    for j in range(proba.shape[1]):\n        new_proba = np.stack(proba[:, models + [j]])\n        score = roc_auc_score(y_true=y_holdout, \n                              y_score=np.mean(new_proba, axis=1))\n        challengers.append([score, j])\n\n    challengers = sorted(challengers, key=lambda x: x[0],\n                         reverse=True)\n    best_score, best_model = challengers[0]\n    if best_score > baseline:\n        print(f\"Adding model_{best_model+1} to the ensemble\",  \n              end=': ') \n        print(f\"ROC-AUC increases score to {best_score:0.5f}\")\n        models.append(best_model)\n        baseline = best_score\n    else:\n        print(\"Cannot improve further - Stopping\") \n```", "```py\nfrom collections import Counter\nfreqs = Counter(models)\nweights = {key: freq/len(models) for key, freq in freqs.items()}\nprint(weights) \n```", "```py\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=5, shuffle=True, random_state=0)\nscores = list()\nfirst_lvl_oof = np.zeros((len(X_train), 3))\nfist_lvl_preds = np.zeros((len(X_test), 3))\nfor k, (train_index, val_index) in enumerate(kf.split(X_train)):\n    model_1.fit(X_train[train_index, :], y_train[train_index])\n    first_lvl_oof[val_index, 0] = model_1.predict_proba(\n                                     X_train[val_index, :])[:, 1]\n\n    model_2.fit(X_train[train_index, :], y_train[train_index])\n    first_lvl_oof[val_index, 1] = model_2.predict_proba(\n                                     X_train[val_index, :])[:, 1]\n\n    model_3.fit(X_train[train_index, :], y_train[train_index])\n    first_lvl_oof[val_index, 2] = model_3.predict_proba(\n                                     X_train[val_index, :])[:, 1] \n```", "```py\nmodel_1.fit(X_train, y_train)\nfist_lvl_preds[:, 0] = model_1.predict_proba(X_test)[:, 1]\nmodel_2.fit(X_train, y_train)\nfist_lvl_preds[:, 1] = model_2.predict_proba(X_test)[:, 1]\nmodel_3.fit(X_train, y_train)\nfist_lvl_preds[:, 2] = model_3.predict_proba(X_test)[:, 1] \n```", "```py\nsecond_lvl_oof = np.zeros((len(X_train), 3))\nsecond_lvl_preds = np.zeros((len(X_test), 3))\nfor k, (train_index, val_index) in enumerate(kf.split(X_train)):\n    skip_X_train = np.hstack([X_train, first_lvl_oof])\n    model_1.fit(skip_X_train[train_index, :],\n                y_train[train_index])\n    second_lvl_oof[val_index, 0] = model_1.predict_proba(\n                          skip_X_train[val_index, :])[:, 1]\n\n    model_2.fit(skip_X_train[train_index, :],\n                y_train[train_index])\n    second_lvl_oof[val_index, 1] = model_2.predict_proba(\n                          skip_X_train[val_index, :])[:, 1]\n\n    model_3.fit(skip_X_train[train_index, :],\n                y_train[train_index])\n    second_lvl_oof[val_index, 2] = model_3.predict_proba(\n                          skip_X_train[val_index, :])[:, 1] \n```", "```py\nskip_X_test = np.hstack([X_test, fist_lvl_preds])\nmodel_1.fit(skip_X_train, y_train)\nsecond_lvl_preds[:, 0] = model_1.predict_proba(skip_X_test)[:, 1]\nmodel_2.fit(skip_X_train, y_train)\nsecond_lvl_preds[:, 1] = model_2.predict_proba(skip_X_test)[:, 1]\nmodel_3.fit(skip_X_train, y_train)\nsecond_lvl_preds[:, 2] = model_3.predict_proba(skip_X_test)[:, 1] \n```", "```py\narithmetic = second_lvl_preds.mean(axis=1)\nras = roc_auc_score(y_true=y_test, y_score=arithmetic)\nscores.append(ras)\nprint(f\"Stacking ROC-AUC is: {ras:0.5f}\") \n```"]