["```py\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv('train_loan_prediction.csv')\ndf.head().T\n```", "```py\nnumerical_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']\nz_scores = df[numerical_features].apply(lambda x: (x - np.mean(x)) / np.std(x))\n```", "```py\nthreshold = 3\noutliers = (z_scores > threshold) | (z_scores < -threshold)\noutliers['is_outlier'] = outliers.any(axis=1)\noutlier_rows = df[outliers['is_outlier']]\noutlier_rows\n```", "```py\nQ1 = df[numerical_features].quantile(0.25)\nQ3 = df[numerical_features].quantile(0.75)\nIQR = Q3 - Q1\nthreshold = 1.5\noutliers = (df[numerical_features] < (Q1 - threshold * IQR)) | (df[numerical_features] > (Q3 + threshold * IQR))\noutliers['is_outlier'] = outliers.any(axis=1)\noutlier_rows = df[outliers['is_outlier']]\noutlier_rows\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.figure(figsize=(10, 6))\nplt.subplot(2, 1, 1)\ndf.boxplot(column='ApplicantIncome')\nplt.title('Box Plot - ApplicantIncome')\nplt.subplot(2, 1, 2)\ndf.boxplot(column='LoanAmount')\nplt.title('Box Plot - LoanAmount')\nplt.tight_layout()\nplt.show()\n```", "```py\nplt.figure(figsize=(8, 6))\nplt.scatter(df['ApplicantIncome'], df['LoanAmount'])\nplt.xlabel('ApplicantIncome')\nplt.ylabel('LoanAmount')\nplt.title('Scatter Plot - ApplicantIncome vs. LoanAmount')\nplt.show()\n```", "```py\n    Import pandas as pd\n    from sklearn.ensemble import IsolationForest\n    ```", "```py\n    numerical_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']\n    ```", "```py\n    X_anomaly = df[numerical_features]\n    ```", "```py\n    X_anomaly.fillna(X_anomaly.mean(), inplace=True)\n    ```", "```py\n    Isolation_forest = IsolationForest(contamination='auto', random_state=42)\n    ```", "```py\n    anomaly_predictions = Isolation_forest.fit_predict(X_anomaly)\n    df['IsAnomaly'] = anomaly_predictions\n    anomalies = df[df['IsAnomaly'] == -1]\n    anomalies.head()\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from tensorflow.keras.layers import Input, Dense\n    from tensorflow.keras.models import Model\n    df = pd.read_csv('train_loan_prediction.csv')\n    ```", "```py\n    numerical_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']\n    ```", "```py\n    X_anomaly = df[numerical_features]\n    X_anomaly.fillna(X_anomaly.mean(), inplace=True)\n    ```", "```py\n    original_indices = X_anomaly.index\n    scaler = StandardScaler()\n    X_anomaly_scaled = scaler.fit_transform(X_anomaly)\n    ```", "```py\n    X_train, X_test, _, _ = train_test_split(X_anomaly_scaled, original_indices, test_size=0.2, random_state=42)\n    X_test_df = pd.DataFrame(X_test, columns=['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount'])\n    ```", "```py\n    input_dim = X_anomaly.shape[1]\n    encoding_dim = 2\n    input_layer = Input(shape=(input_dim,))\n    encoder_layer = Dense(encoding_dim, activation='relu')(input_layer)\n    decoder_layer = Dense(input_dim, activation='sigmoid')(encoder_layer)\n    autoencoder = Model(inputs=input_layer, outputs=decoder_layer)\n    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n    autoencoder.fit(X_anomaly_scaled, X_anomaly_scaled, epochs=50, batch_size=16)\n    ```", "```py\n    X_test_reconstructed = autoencoder.predict(X_test)\n    reconstruction_error_test = np.mean(np.square(X_test - X_test_reconstructed), axis=1)\n    ```", "```py\n    threshold = np.percentile(reconstruction_error_test, 95)\n    ```", "```py\n    anomaly_predictions = (reconstruction_error_test > threshold).astype(int)\n    ```", "```py\n    anomaly_df = pd.DataFrame({'IsAnomaly': anomaly_predictions}, index=X_test_df.index)\n    ```", "```py\n    df = df.merge(anomaly_df, how='left', left_index=True, right_index=True)\n    if 'IsAnomaly' in df.columns:\n        # Display the rows with anomalies\n        anomalies = df[df['IsAnomaly'] == 1]\n        anomalies\n    else:\n        print(\"No anomalies detected.\")\n    ```", "```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.svm import OneClassSVM\n    from sklearn.metrics import classification_report, accuracy_score\n    df = pd.read_csv('train_loan_prediction.csv')\n    ```", "```py\n    df = df.drop(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area'], axis=1)\n    df['Loan_Status'] = df['Loan_Status'].map({'Y': 0, 'N': 1})\n    df.fillna(df.mean(), inplace=True)\n    ```", "```py\n    X = df.drop('Loan_Status', axis=1)\n    y = df['Loan_Status']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    ```", "```py\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    ```", "```py\n    nu_values = [0.01, 0.05, 0.1, 0.2, 0.3]\n    mean_decision_function_values = []\n    ```", "```py\n    for nu in nu_values:\n        svm_model = OneClassSVM(nu=nu, kernel='rbf', gamma=0.1)\n        svm_model.fit(X_train_scaled)\n        decision_function_values=\n        svm_model.decision_function(X_test_scaled)\n        mean_decision_function = np.mean(decision_function_values)\n        mean_decision_function_values.append(mean_decision_function)\n    ```", "```py\n    best_nu_index = np.argmax(mean_decision_function_values)\n    best_nu = nu_values[best_nu_index]\n    ```", "```py\n    final_model = OneClassSVM(nu=best_nu, kernel='rbf', gamma=0.1)\n    final_model.fit(X_train_scaled)\n    ```", "```py\n    y_pred = final_model.predict(X_test_scaled)\n    y_pred_binary = [1 if pred == -1 else 0 for pred in y_pred]\n    test_set_df = pd.DataFrame(data=X_test_scaled, columns=X.columns, index=X_test.index)\n    test_set_df['Anomaly_Label'] = y_pred_binary\n    df_with_anomalies = pd.concat([df, test_set_df['Anomaly_Label']], axis=1, join='outer')\n    df_with_anomalies['Anomaly_Label'].fillna(0, inplace=True)\n    ```", "```py\n    print(\"Classification Report:\\n\", classification_report(y_test, y_pred_binary))print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_binary))\n    ```", "```py\n    df_with_anomalies[df_with_anomalies['Anomaly_Label'] == 1]\n    ```", "```py\n    import pandas as pd\n    from imblearn.over_sampling import SMOTE\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import classification_report\n    from sklearn.ensemble import RandomForestClassifier\n    df = pd.read_csv('train_loan_prediction.csv')\n    ```", "```py\n    df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})\n    ```", "```py\n    df.fillna(df.mean(), inplace=True)\n    ```", "```py\n    numerical_columns = df.select_dtypes(include=[float, int]).columns\n    X = df[numerical_columns].drop('Loan_Status', axis=1)\n    y = df['Loan_Status']\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    ```", "```py\n    smote = SMOTE(random_state=42)\n    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n    ```", "```py\n    clf = RandomForestClassifier(random_state=42)\n    clf.fit(X_train_resampled, y_train_resampled)\n    y_pred = clf.predict(X_test)\n    ```", "```py\n    clf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\n    clf_report = clf_report.T\n    clf_report\n    ```", "```py\nimport pandas as pd\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\ndf = pd.read_csv('train_loan_prediction.csv')\n```", "```py\ndf['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})\n```", "```py\ndf.fillna(df.mean(), inplace=True)\n```", "```py\nnumerical_columns = df.select_dtypes(include=[float, int]).columns\nX = df[numerical_columns].drop('Loan_Status', axis=1)\ny = df['Loan_Status']\n```", "```py\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```", "```py\nrus = RandomUnderSampler(random_state=42)\nX_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n```", "```py\nclf = RandomForestClassifier(random_state=42)\nclf.fit(X_train_resampled, y_train_resampled)\ny_pred = clf.predict(X_test)\nclf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\nclf_report = clf_report.T\nclf_report\n```", "```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.metrics import classification_report\n    df = pd.read_csv('train_loan_prediction.csv')\n    ```", "```py\n    df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})\n    df.fillna(df.mean(), inplace=True)\n    ```", "```py\n    numerical_columns = df.select_dtypes(include=[float, int]).columns\n    X = df[numerical_columns].drop('Loan_Status', axis=1)\n    y = df['Loan_Status']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    ```", "```py\n    class_weights = dict(1 / y_train.value_counts(normalize=True))\n    ```", "```py\n    clf = RandomForestClassifier(random_state=42, class_weight=class_weights)\n    clf.fit(X_train, y_train)\n    ```", "```py\n    y_pred = clf.predict(X_test)\n    clf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\n    clf_report = clf_report.T\n    clf_report\n    ```", "```py\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\ndf = pd.read_csv('train_loan_prediction.csv')\ndf['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})\ndf.fillna(df.mean(), inplace=True)\nnumerical_columns = df.select_dtypes(include=[float, int]).columns\nX = df[numerical_columns].drop('Loan_Status', axis=1)\ny = df['Loan_Status']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nclf = RandomForestClassifier(random_state=42)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nclf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\nclf_report = clf_report.T\nclf_report\n```", "```py\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import classification_report\ndf = pd.read_csv('train_loan_prediction.csv')\ndf['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})\ndf.fillna(df.mean(), inplace=True)\nnumerical_columns = df.select_dtypes(include=[float, int]).columns\nX = df[numerical_columns].drop('Loan_Status', axis=1)\ny = df['Loan_Status']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nclf = AdaBoostClassifier(random_state=42)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nclf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\nclf_report = clf_report.T\nclf_report\n```", "```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.metrics import classification_report\n    df = pd.read_csv('train_loan_prediction.csv')\n    ```", "```py\n    df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})\n    df.fillna(df.mean(), inplace=True)\n    ```", "```py\n    numerical_columns = df.select_dtypes(include=[float, int]).columns\n    X = df[numerical_columns].drop('Loan_Status', axis=1)\n    y = df['Loan_Status']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    ```", "```py\n    base_model_1 = RandomForestClassifier(random_state=42)\n    base_model_2 = GradientBoostingClassifier(random_state=42)\n    ```", "```py\n    base_model_1.fit(X_train, y_train)\n    base_model_2.fit(X_train, y_train)\n    pred_base_model_1 = base_model_1.predict(X_test)\n    pred_base_model_2 = base_model_2.predict(X_test)\n    ```", "```py\n    stacking_X_train = pd.DataFrame({\n        'BaseModel1': pred_base_model_1,\n        'BaseModel2': pred_base_model_2\n    })\n    ```", "```py\n    meta_model = LogisticRegression()\n    meta_model.fit(stacking_X_train, y_test)\n    ```", "```py\n    new_unseen_data = X_test.sample(frac=0.2, random_state=42)\n    new_pred_base_model_1 = base_model_1.predict(new_unseen_data)\n    new_pred_base_model_2 = base_model_2.predict(new_unseen_data)\n    ```", "```py\n    stacking_new_unseen_data = pd.DataFrame({\n        'BaseModel1': new_pred_base_model_1,\n        'BaseModel2': new_pred_base_model_2\n    })\n    ```", "```py\n    final_prediction = meta_model.predict(stacking_new_unseen_data)\n    final_prediction\n    ```"]