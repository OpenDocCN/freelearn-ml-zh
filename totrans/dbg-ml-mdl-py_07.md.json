["```py\nnp.random.seed(42)def disparate_impact_randomsample(sample_size,\n    sampling_num = 100): disparate_impact = []\n    for sam_iter in range(0, sampling_num):\n        # generating random array of 0 and 1 as two groups with different priviledges (e.g. male versus female)\n        group_category = np.random.randint(2,\n            size=sample_size)\n    # generating random array of 0 and 1 as the output labels (e.g. accepted for loan or not)\n    output_labels = np.random.randint(2, size=sample_size)\n    group0_label1 = [iter for iter in range(0, len(\n        group_category)) if group_category[iter] == 0 \n        and output_labels[iter] == 1]\n    group1_label1 = [iter for iter in range(0, len(\n        group_category)) if group_category[iter] == 1 and \n        output_labels[iter] == 1]\n    # calculating disparate impact \n    disparate_impact.append(len\n        (group1_label1)/len(group0_label1))\n    return disparate_impact\n```", "```py\nsample_size_list = [50, 100, 1000, 10000, 1000000]disparate_impact_list = []\nfor sample_size_iter in sample_size_list:\n    disparate_impact_list.append(\n        disparate_impact_randomsample(\n            sample_size = sample_size_iter,\n            sampling_num = 1000))\n```", "```py\nX_WithPred.groupby(['Sex', 'Correct Prediction']).size().unstack(fill_value=0)\n```", "```py\ncorr_features = X.corr()corr_features.style.background_gradient(cmap='coolwarm')\n```", "```py\nX_train = X_train.reset_index(drop=True)X_test = X_test.reset_index(drop=True)\n# training a model only for female category (Sex category of 0 in this dataset)\nX_train_only0 = X_train[X_train['Sex'] == 0]\nX_test_only0 = X_test[X_test['Sex'] == 0]\nX_only0 = X[X['Sex'] == 0]\ny_train_only0 = [y_train[iter] for iter in X_train.index[\n    X_train['Sex'] == 0].tolist()]\ny_test_only0 = [y_test[iter] for iter in X_test.index[\n    X_test['Sex'] == 0].tolist()]\n# initializing an XGboost model\nxgb_model = xgboost.XGBClassifier(random_state=42)\n# fitting the XGboost model with training data\nxgb_model.fit(X_train_only0, y_train_only0)\n# calculating roc-auc of predictions\nprint(\"ROC-AUC of predictions:\n    {}\".format(roc_auc_score(y_test_only0,\n        xgb_model.predict_proba(X_test_only0)[:, 1])))\n# generate the Tree explainer\nexplainer_xgb = shap.TreeExplainer(xgb_model)\n# extract SHAP values from the explainer object\nshap_values_xgb = explainer_xgb.shap_values(X_only0)\n# create a SHAP beeswarm plot (i.e. SHAP summary plot)\nshap.summary_plot(shap_values_xgb, X_only0,\n    plot_type=\"bar\")\n```", "```py\n# loading UCI adult income dataset# classification task to predict if people made over $50k in the 90s or not\nX,y = shap.datasets.adult()\n# split the data to train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size = 0.3, random_state=10)\n# making a dataframe out of y values with \"Sex\" being their indices\ny_train = pd.DataFrame({'label': y_train},\n    index = X_train['Sex'])\ny_test = pd.DataFrame({'label': y_test},\n    index = X_test['Sex'])\n```", "```py\nxgb_model = xgboost.XGBClassifier(random_state=42)# fitting the XGboost model with training data\nxgb_model.fit(X_train, y_train)\n# calculating roc-auc of predictions\nprint(\"ROC-AUC of predictions:\n    {}\".format(roc_auc_score(y_test,\n        xgb_model.predict_proba(X_test)[:, 1])))\n# generating predictions for the test set\ny_pred_train = xgb_model.predict(X_train)\ny_pred_test = xgb_model.predict(X_test)\n```", "```py\n# calculating disparate impact ratiodi_train_orig = disparate_impact_ratio(y_train,\n    prot_attr='Sex', priv_group=1, pos_label=True)\ndi_test_orig = disparate_impact_ratio(y_test,\n    prot_attr='Sex', priv_group=1, pos_label=True)\ndi_train = disparate_impact_ratio(y_train, y_pred_train,\n    prot_attr='Sex', priv_group=1, pos_label=True)\ndi_test = disparate_impact_ratio(y_test, y_pred_test,\n    prot_attr='Sex', priv_group=1, pos_label=True)\n```", "```py\n# importing Reject option classification, a post processing technique that gives favorable outcomes to unprivileged groups and unfavourable outcomes to# privileged groups in a confidence band around the decision boundary\n# with the highest uncertainty\nfrom aif360.sklearn.postprocessing import RejectOptionClassifierCV\n# importing PostProcessingMeta,  a meta-estimator which wraps a given\n# estimator with a post-processing step.\n# fetching adult dataset from aif360 library\nX, y, sample_weight = fetch_adult()\nX.index = pd.MultiIndex.from_arrays(X.index.codes,\n    names=X.index.names)\ny.index = pd.MultiIndex.from_arrays(y.index.codes,\n    names=y.index.names)\ny = pd.Series(y.factorize(sort=True)[0], index=y.index)\nX = pd.get_dummies(X)\n```", "```py\nmetric = 'disparate_impact'ppm = PostProcessingMeta(RF(n_estimators = 10,\n    random_state = 42),\n    RejectOptionClassifierCV('sex', scoring=metric,\n        step=0.02, n_jobs=-1))\nppm.fit(X, y)\n```"]