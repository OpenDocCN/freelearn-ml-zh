- en: Hands-On Examples of Machine Learning Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型的实战示例
- en: Supervised learning is the simplest way of teaching a model about how the world
    looks. Showing how a given combination of input variables leads to a certain output,
    that is, using labeled data, makes it possible for a computer to predict the output
    for another similar dataset that it has never seen. Unsupervised learning deals
    with finding patterns and useful insights into non-labeled data.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是教授模型关于世界如何看的最简单方式。展示给定输入变量的组合如何导致某个输出，即使用标记数据，使得计算机能够预测另一个类似数据集的输出，即使它从未见过这个数据集。无监督学习涉及从非标记数据中寻找模式和有用的见解。
- en: We will study different types of machine learning models, trying to understand
    the details and actually performing the necessary calculations so that the inner
    workings of these models are clear and reproducible.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究不同类型的机器学习模型，试图理解其细节并实际执行必要的计算，以便这些模型的内部工作原理清晰且可重复。
- en: 'In this chapter, the following topics will be covered:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将涵盖以下主题：
- en: Understanding supervised learning with multiple linear regression
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多元线性回归理解监督学习
- en: Understanding supervised learning with decision trees
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用决策树理解监督学习
- en: Understanding unsupervised learning with clustering
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用聚类理解无监督学习
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: There are no technical requirements for this chapter. We just need to input
    the values shown in the tables within each section in an Excel sheet in order
    to follow the explanation closely.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章没有技术要求。我们只需要在Excel表中输入每个部分表中显示的值，以便紧密跟随解释。
- en: Understanding supervised learning with multiple linear regression
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多元线性回归理解监督学习
- en: In the previous chapter, we followed an example of linear regression using two
    variables. It is interesting to see how we can apply regression to more than two
    variables (called **multiple linear regression**) and extract useful information
    from the results.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们通过使用两个变量的线性回归示例。有趣的是，我们可以看到如何将回归应用于超过两个变量（称为**多元线性回归**）并从结果中提取有用信息。
- en: Suppose that you are asked to test whether there exists a hidden policy of gender
    discrimination in a company. You could be working for a law firm that is leading
    a trial against this company, and they need data-based evidence to back up their
    claim.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你被要求测试一家公司是否存在性别歧视的隐藏政策。你可能是在一家领导该公司诉讼案的事务所工作，他们需要基于数据的证据来支持他们的主张。
- en: 'You would start by taking a sample of the company''s payroll, including several
    variables that describe each employee and the last salary increase amount. The
    following screenshot shows a set of values after they''ve been entered in an Excel
    worksheet:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从抽取公司的工资单样本开始，包括描述每位员工及其最近一次工资增长额的几个变量。以下截图显示了在Excel工作表中输入这些值后的值集：
- en: '![](img/1c0631ca-5c1a-4395-8e26-09a4274b0473.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1c0631ca-5c1a-4395-8e26-09a4274b0473.png)'
- en: 'There are four numerical features in the dataset:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中有四个数值特征：
- en: '`ID`: The employee identification, which is not relevant to our analysis'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ID`：员工识别码，与我们的分析无关'
- en: '`Score`: The result of the last employee''s performance evaluation'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Score`：最后一名员工的绩效评估结果'
- en: '`Years in company`: Years that the employee has worked in the company'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Years in company`：员工在公司工作的年数'
- en: '`Salary increase`: Amount in dollars of the last salary increase'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Salary increase`：最近一次工资增长的金额（美元）'
- en: 'The remaining two are categorical:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的两个是分类的：
- en: '`Gender`: Male (`M`) or Female (`F`)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Gender`：男性（`M`）或女性（`F`）'
- en: '`Division`: In which part of the company the employee works'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Division`：员工在公司工作的部门'
- en: 'Categorical values need to be encoded before being used in a model. The final
    data table is as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 分类值在使用模型之前需要编码。最终的数据表如下：
- en: '![](img/4a60e2c4-eb38-4adf-9357-2283b2bcc6a2.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a60e2c4-eb38-4adf-9357-2283b2bcc6a2.png)'
- en: The one-hot encoding is easily obtained by applying standard Excel functions.
    Assuming *B2* is the first cell containing the gender classification, we can enter *=IF(B2="F";1;0) *in
    cell *B21* and copy this value to all cells down to *B37*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用标准的Excel函数，可以轻松获得独热编码。假设*B2*是包含性别分类的第一个单元格，我们可以在*B21*单元格中输入*=IF(B2="F";1;0)*，并将此值复制到*B37*单元格以下的所有单元格。
- en: Depending on which character is defined in the Windows list separator option,
    you should either use a comma (*,*) or a semi-colon (*;*) in formulas.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Windows列表分隔符选项中定义的字符，你应在公式中使用逗号（*，*）或分号（*；*）。
- en: To encode the employee's division, we use one-hot encoding (refer to [Chapter
    1](b0dde0bb-32ef-4535-9e19-7999e8e9a631.xhtml), *Implementing Machine Learning
    Algorithms*, for a detailed explanation) and create three new variables: `IsProduction?`,
    `IsResearch?`*,* and `IsSales?`*.* We can use Excel functions to calculate the
    encoding if *E2* is the first row containing the `Division` data, then we can
    use the *=IF(E2="Production";1;0)*, *=IF(E2="Research";1;0),* and *=IF(E2="Sales";1;0)* functions in
    cells *E21*, *F21,* and *G21*, respectively, and then copy them column-wise down
    to cells *E37*, *F37,* and *G37*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对员工部门进行编码，我们使用独热编码（有关详细说明，请参阅[第一章](b0dde0bb-32ef-4535-9e19-7999e8e9a631.xhtml)，*实现机器学习算法*）并创建三个新变量：`IsProduction?`、`IsResearch?`和`IsSales?`。如果*E2*是包含`Division`数据的第一个行，那么我们可以使用单元格*E21*、*F21*和*G21*中的函数*=IF(E2="Production";1;0)*、*=IF(E2="Research";1;0)*和*=IF(E2="Sales";1;0)*，然后将它们按列复制到单元格*E37*、*F37*和*G37*。
- en: Before trying to use regression on the full dataset, we can try some feature
    engineering. Let's see how well we can predict the salary increase based on which `Division` each
    employee works. This will give us an idea of how much the `Salary Increase`target
    variable correlates with `Division` (there will be more details about correlations
    between variables in [Chapter 5](0da64bd8-0bc9-491b-875c-7ec7c35c6165.xhtml),
    *Correlations and the Importance of Variables*).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试对整个数据集进行回归之前，我们可以尝试一些特征工程。让我们看看我们能够根据每个员工所在的哪个部门来预测薪资增长的效果。这将给我们一个关于“薪资增长”目标变量与“部门”之间相关性的概念（关于变量之间相关性的更多细节将在[第五章](0da64bd8-0bc9-491b-875c-7ec7c35c6165.xhtml)，*相关性与变量的重要性*中介绍）。
- en: 'Let''s follow some simple steps to use the built-in regression tool:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们遵循一些简单的步骤来使用内置的回归工具：
- en: Navigate to Data.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到数据。
- en: 'Click on Data Analysis, as shown in the following screenshot:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击数据分析，如下面的截图所示：
- en: '![](img/40602c2b-0444-4e3e-b685-20b98aa69cb3.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/40602c2b-0444-4e3e-b685-20b98aa69cb3.png)'
- en: 'Select Regression, as shown in the following screenshot:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择回归，如下面的截图所示：
- en: '![](img/423d05a3-7725-42f1-816e-ff01211cc34e.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/423d05a3-7725-42f1-816e-ff01211cc34e.png)'
- en: 'As the Input Y Range, select the `Salary` data and as the Input X Range, select
    the three `Division` columns:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为输入Y范围，选择“薪资”数据，作为输入X范围，选择三个“部门”列：
- en: '![](img/11bab1bf-9e2d-4ccb-8054-15419abf959b.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/11bab1bf-9e2d-4ccb-8054-15419abf959b.png)'
- en: The results show *R**²** = 0.1*, meaning that only 10% of the salary increase
    is related or can be explained by the fact that the employee belongs to a given
    division. We can therefore discard these columns as input and concentrate on the
    rest.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示 *R² = 0.1*，这意味着只有10%的薪资增长与员工属于某个特定部门有关或可以由此解释。因此，我们可以丢弃这些列作为输入，并专注于其余部分。
- en: We repeat the regression, now choosing the X values as the columns `Gender`,
    `Score`, and `Years in company`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复进行回归，这次选择X值为列“性别”、“得分”和“在公司工作年限”。
- en: The results are quite different now, with R² close to 0.85, meaning that 85%
    of the salary increase values are explained by the chosen variables.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 结果现在大不相同，R²接近0.85，这意味着85%的薪资增长值可以通过所选变量来解释。
- en: 'How important is `Gender`? Taking a look at the P-value coefficients that Excel
    gives us, in the following table, we can see that, according to the P-value associated
    with the input variables, the most important one is gender, followed by the score
    and the number of years in the company. It is then clear that gender plays an
    important role when deciding a salary increase, and we have evidence to prove
    that the company policy is not gender neutral:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: “性别”的重要性如何？通过查看Excel给出的P值系数，如下表所示，我们可以看到，根据与输入变量相关的P值，最重要的是性别，其次是得分和公司工作年限。因此，很明显，性别在决定薪资增长时起着重要作用，我们有证据证明公司政策并非性别中立：
- en: '|  | **Coefficients** | **P-value** |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|  | **系数** | **P值** |'
- en: '| **Intercept** | 141.72775 | 0.083481944 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| **截距** | 141.72775 | 0.083481944 |'
- en: '| **Gender** | -221.9209346 | 6.47796E-05 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| **性别** | -221.9209346 | 6.47796E-05 |'
- en: '| **Score** | 2.697512241 | 0.004201513 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| **得分** | 2.697512241 | 0.004201513 |'
- en: '| **Years in company** | 8.118352407 | 0.332588988 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| **在公司工作年限** | 8.118352407 | 0.332588988 |'
- en: 'The output results of the regression tell us how well we can explain the data
    sample, but cannot give us an accurate measure of how the model will predict a
    salary increase. To explore this, we should do the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析的结果告诉我们我们能够多好地解释数据样本，但不能给我们一个准确的度量，即模型将如何预测薪资增长。为了探索这一点，我们应该做以下事情：
- en: Obtain a different sample of the payroll (in our case, we could generate new
    data by hand)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取工资单的不同样本（在我们的例子中，我们可以手动生成新数据）
- en: Use the coefficients in the previous table to build an expression and calculate
    the predicted salary increase given the input variables
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用前表中列出的系数构建一个表达式，并计算给定输入变量的预测薪资增长
- en: Compare the predicted and real values using root mean square error, as explained
    in [Chapter 1](b0dde0bb-32ef-4535-9e19-7999e8e9a631.xhtml), *Implementing Machine
    Learning Algorithms*
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用如[第1章](b0dde0bb-32ef-4535-9e19-7999e8e9a631.xhtml)中所述的均方根误差来比较预测值和实际值，*实现机器学习算法*
- en: Let's see if you can finish this exercise; I am hoping that the basic information
    that's been provided to you carry this out has been understood.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看你是否能完成这个练习；我希望能提供的基本信息帮助你完成这项任务已经理解。
- en: 'We have shown how to perform a multiple linear regression in data to extract
    interesting insights from them. Let''s continue with another important machine
    learning model: decision trees.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经展示了如何在数据中执行多重线性回归以从中提取有趣的见解。让我们继续探讨另一个重要的机器学习模型：决策树。
- en: Understanding supervised learning with decision trees
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过决策树理解监督学习
- en: The decision tree algorithm uses a tree-like model of decisions. Its name is
    derived from the graphical representation of the cascading process that partitions
    the records. The algorithm chooses the input variables that better split the dataset
    into subsets that are more pure in terms of the target variable, ideally a subset
    that contains only one value of this variable. Decision trees are some of the
    most widely used and easy to understand classification algorithms.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树算法使用决策的树形模型。其名称来源于分割记录的级联过程的图形表示。算法选择更好的输入变量来将数据集分割成更纯的子集，从目标变量的角度来看，理想情况下是一个只包含该变量一个值的子集。决策树是一些最广泛使用且易于理解的分类算法。
- en: The outcome of the tree algorithm calculation is a set of simple rules that
    explain which values or intervals of the input values split the original data
    better. The fact that the results and the path followed to get to them can be
    clearly shown gives decision trees an advantage over other algorithms. **Explainability**
    is a serious problem for some machine learning and artificial intelligence systems
    – which are mostly used as black boxes – and is a study subject in itself.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 树算法计算的结果是一组简单的规则，这些规则解释了哪些输入值的值或区间可以更好地分割原始数据。结果和得到这些结果所遵循的路径可以清晰地展示出来，这使得决策树在与其他算法相比时具有优势。"可解释性"是某些机器学习和人工智能系统的一个严重问题——这些系统大多被用作黑盒——并且本身就是一个研究课题。
- en: In complex problems, we need to decide when to stop the tree development. A
    large number of features can lead to a very large and complex tree, so the number
    of branches and the length of the tree are usually limited by the user.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在复杂问题中，我们需要决定何时停止树的发展。大量的特征可能导致一个非常大且复杂的树，因此树的分支数量和长度通常由用户限制。
- en: Entropy is a very important concept in decision trees and the way of quantifying
    the purity of each subsample. It measures the amount of information contained
    in each leaf of the tree. The lower the entropy, the larger the amount of information.
    Zero entropy means that a subset contains only one value of the target variable,
    while a value of one represents a subset that contains the same amount of both
    values. This concept will be explained later with examples.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 熵是决策树中一个非常重要的概念，以及量化每个子样本纯度的方法。它衡量树中每个叶子的信息量。熵越低，信息量越大。零熵意味着一个子集只包含目标变量的一个值，而值为一表示一个子集包含相同数量的两个值。这个概念将在后面的例子中解释。
- en: Entropy is an indicator of how messy your data is.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 熵是衡量你的数据混乱程度的一个指标。
- en: Using the entropy that's calculated in every step, the algorithm chooses the
    best variable to split the data and recursively repeats the same procedure. The
    user can decide how to stop the calculation, either when all subsets have an entropy
    of zero, when there are no more features to split by, or a minimum entropy level.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用在每一步计算的熵，算法选择最佳变量来分割数据，并递归地重复相同的程序。用户可以决定何时停止计算，要么当所有子集的熵为零，要么没有更多特征可以分割，或者达到一个最小熵水平。
- en: The input features that are best suited for use in a decision tree are the categorical
    ones. In case of a continuous, numerical variable, it should be first converted
    into categories by dividing it into ranges; for example, A > 0.5 would be A1 and
    A ≤ 0.5 would be A2.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在决策树中使用最适合的特征是分类特征。在连续的数值变量情况下，应首先将其转换为类别，通过将其分为范围来实现；例如，A > 0.5将是A1，A ≤ 0.5将是A2。
- en: Let's look at an example that explains the concept of the decision tree algorithm.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个解释决策树算法概念的例子。
- en: Deciding whether to train outdoors depending on the weather
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 根据天气决定是否在户外训练
- en: Let's suppose we have historical data on the decisions made by an experienced
    football trainer about training outdoors (outside the gym) or not with her team,
    including the weather conditions on the days when the decisions were made.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组关于经验足球教练关于是否带球队在户外（健身房外）训练的历史数据，包括在做出决策的日子上的天气条件。
- en: 'A typical dataset could look as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的数据集可能如下所示：
- en: '![](img/978298f2-c1f8-4e2d-8e85-1de0fc8e7e74.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/978298f2-c1f8-4e2d-8e85-1de0fc8e7e74.png)'
- en: The dataset was specifically created for this example and, of course, might
    not represent any real decisions.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集是专门为这个例子创建的，当然可能不代表任何真实的决策。
- en: In this example, the target variable is `Train outside` and the rest of the
    variables are the model features.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，目标变量是`Train outside`，其余变量是模型特征。
- en: 'According to the data table, a possible decision tree would be as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据表，可能的一个决策树如下所示：
- en: '![](img/7e2f36c5-6565-43d4-9a5a-d1b35c0e7724.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7e2f36c5-6565-43d4-9a5a-d1b35c0e7724.png)'
- en: We choose to start splitting the data by the value of the **Outlook **feature.We
    can see that if the value is **Overcast**,then the decision to train outside is
    always **Yes**and does not depend on the values of the other features. **Sunny**
    and **Rainy** can be further split to get an answer.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择根据**展望**特征的值来开始分割数据。我们可以看到，如果值是**多云**，那么训练在户外的决定总是**是**，并且不依赖于其他特征的值。**晴天**和**雨天**可以进一步分割以得到答案。
- en: How can we decide which feature to use first and how to continue? We will use
    the value of the entropy*,* measuring how much its value changes when considering
    different input features.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何决定首先使用哪个特征以及如何继续？我们将使用熵*值*来衡量考虑不同输入特征时其值的变化程度。
- en: Entropy of the target variable
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标变量的熵
- en: 'The definition of entropy when looking at a single attribute is as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当查看单个属性时，熵的定义如下：
- en: '![](img/f157814c-737c-458d-9303-4c13687692c9.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f157814c-737c-458d-9303-4c13687692c9.png)'
- en: 'Here, *c* is the total number of possible values of the feature *f*, *p[i]*
    is the probability of each value, and *log*[*2*]*(p[i])*is the base two logarithm
    of the same probability. The calculation details are as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*c*是特征*f*的可能值的总数，*p[i]*是每个值的概率，*log*[*2*]*(p[i])*是相同概率的以2为底的对数。计算细节如下：
- en: 'We need to count the number of Yes and No decisions in the dataset. In our
    simple example, they can be counted by hand, but if the dataset is larger, we
    can use Excel functions:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要在数据集中计算是和否决策的数量。在我们的简单例子中，它们可以手动计算，但如果数据集更大，我们可以使用Excel函数：
- en: '*COUNTIF(F2:F15;"Yes")* and *COUNTIF(F2:F15;"No")*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*COUNTIF(F2:F15;"Yes")* 和 *COUNTIF(F2:F15;"No")*'
- en: We then get the calculation that *Yes = 9* and *No = 5*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们得到计算结果，*是 = 9* 和 *否 = 5*。
- en: 'When applying the entropy formula to the target variable, we get the following:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当将熵公式应用于目标变量时，我们得到以下结果：
- en: '![](img/4efa2635-4bc5-4980-89eb-b009696db614.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4efa2635-4bc5-4980-89eb-b009696db614.png)'
- en: Here, the probabilities are calculated as the number of *Yes* (*9*) or *No* (*5*)
    over the total number (*14*).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，概率是计算为 *是* (*9*) 或 *否* (*5*) 占总数 (*14*) 的比例。
- en: This calculation can also be easily performed in the Excel sheet using *I3/(I3+J3)*LOG(I3/(I3+J3);2)-J3/(I3+J3)*LOG(J3/(I3+J3);2)*
    with *I3=9* and *J3=5*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 此计算也可以很容易地在Excel表中使用 *I3/(I3+J3)*LOG(I3/(I3+J3);2)-J3/(I3+J3)*LOG(J3/(I3+J3);2)*
    来执行，其中 *I3=9* 和 *J3=5*。
- en: Entropy of each feature with respect to the target variable
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 各个特征相对于目标变量的熵
- en: 'The entropy of two variables *f*[*1* ]and *f[2]* is defined as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 两个变量*f[1]*和*f[2]*的熵定义为以下：
- en: '![](img/0b6434d3-d2fb-4a52-820d-e3b14870dc30.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0b6434d3-d2fb-4a52-820d-e3b14870dc30.png)'
- en: Here, *v* represents each possible value of *f[2]*, *P(v)* is the probability
    of each value, and *S(v)* was defined in the previous equation.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*v*代表*f[2]*的每个可能值，*P(v)*是每个值的概率，*S(v)*在之前的方程中定义。
- en: Frequency table
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 频率表
- en: 'Let''s build a frequency table, which is the usual way of counting the total
    number of combinations between variables. In our case, we use it to decide which
    variable choice leads to a larger reduction of the entropy:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个频率表，这是计算变量之间组合总数通常的方法。在我们的例子中，我们用它来决定哪个变量选择会导致熵的更大减少：
- en: Count the different combinations of feature values, taking each feature compared
    to the `Train outside` target variable. You can count them manually in this particular
    example, but it is useful to have a general method to do this in case we are working
    with a larger dataset.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算特征值的各种组合，将每个特征与`Train outside`目标变量进行比较。在这个特定例子中，您可以手动计数，但如果我们处理更大的数据集，有一个一般的方法来做这件事是有用的。
- en: To count the number of feature combinations, we start by concatenating the values
    in the data table in pairs. For example, *CONCATENATE(B2;"_";F2)* gives us `Hot_No`.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要计算特征组合的数量，我们首先将数据表中的值成对连接。例如，*CONCATENATE(B2;"_";F2)* 给我们 `Hot_No`。
- en: If we copy the formula down to complete the total number of rows, we get all
    possible combinations of the `Temperature` and `Train outside` variables.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们将公式向下复制以完成总行数，我们将得到`Temperature`和`Train outside`变量的所有可能组合。
- en: 'If we repeat the same calculation with the rest of the features, the results
    will be as follows:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们用其余的特征重复相同的计算，结果将如下所示：
- en: '![](img/6c8884f8-2fee-4191-aa34-c46ccf88f197.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6c8884f8-2fee-4191-aa34-c46ccf88f197.png)'
- en: 'Create pivot tables to count the number of unique values in each column, that
    is, the number of unique combinations. This can be done by selecting the full
    range in the column, right-clicking anywhere in the selection, and left-clicking
    on Quick Analysis. The following dialogue will pop up:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建交叉表来计算每列中唯一值的数量，即唯一组合的数量。这可以通过选择列中的整个范围，在所选区域的任何位置右键单击，然后左键单击快速分析来完成。以下对话框将弹出：
- en: '![](img/05e68fd4-4daf-4008-b468-7fe4b4ea5b14.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/05e68fd4-4daf-4008-b468-7fe4b4ea5b14.png)'
- en: 'Select Tables | PivotTableto create a table like the following:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 表格 | 交叉表创建如下表格：
- en: '![](img/df9d5cee-2ee6-4af7-b19a-3e7fb08a59d3.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/df9d5cee-2ee6-4af7-b19a-3e7fb08a59d3.png)'
- en: Repeat the same procedure with all columns and build all frequency tables and
    the two-variable entropy. The resulting tables and the entropy calculations are
    shown in the following subsection.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对所有列重复相同的程序，构建所有频率表和双变量熵。结果表和熵计算在以下小节中展示。
- en: Entropy calculation
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 熵计算
- en: 'The frequency table for the combination Outlook-Train outside is as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Outlook-户外训练组合的频率表如下：
- en: '| **Outlook** | **Train outside** |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| **晴朗** | **户外训练** |'
- en: '|  | Yes | No |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|  | 是 | 否 |'
- en: '| Sunny | 3 | 2 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 晴朗 | 3 | 2 |'
- en: '| Overcast | 4 | 0 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 阴天 | 4 | 0 |'
- en: '| Rainy | 2 | 3 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 雨天 | 2 | 3 |'
- en: 'Using these values, we get the entropy of two variables, as shown here in detail:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些值，我们得到两个变量的熵，如下所示：
- en: '![](img/376672c9-2d09-4c28-8fab-67e9601dc316.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/376672c9-2d09-4c28-8fab-67e9601dc316.png)'
- en: '*p(Sunny).S(Sunny)+p(Overcast).S(Overcast)+p(Rainy)*S(Rainy)=*'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*p(Sunny).S(Sunny)+p(Overcast).S(Overcast)+p(Rainy)*S(Rainy)=*'
- en: '*5/14*(-3/5*log2(3/5)-2/5*log2(2/5)) +*'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*5/14*(-3/5*log2(3/5)-2/5*log2(2/5)) +*'
- en: '*4/14*(-4/4*log2(4/4)-0/4*log2(0/4))+*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*4/14*(-4/4*log2(4/4)-0/4*log2(0/4))+*'
- en: '*5/14*(-2/5*log2(2/5)-3/5*log2(3/5))=*'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*5/14*(-2/5*log2(2/5)-3/5*log2(3/5))=*'
- en: '*0.693*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '*0.693*'
- en: Here, *p(Sunny) = (#Yes+#No)/Total entries = (2+3)/14, p(Overcast) = (#Yes+#No)/Total
    entries = (4+0)/14,* and *p(Rainy) = (#Yes+#No)/Total entries = (2+3)/14*. The
    entropy values *S(v)* are calculated using the corresponding probabilities, that
    is, *#Yes* or *#No* over the total *#Yes+#No*.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*p(Sunny) = (#Yes+#No)/Total entries = (2+3)/14, p(Overcast) = (#Yes+#No)/Total
    entries = (4+0)/14, p(Rainy) = (#Yes+#No)/Total entries = (2+3)/14*. 熵值 *S(v)*
    是使用相应的概率计算的，即 *#Yes* 或 *#No* 除以总 *#Yes+#No*。
- en: 'The frequency table for the combination Temperature-Train outside is as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 温度-户外训练组合的频率表如下：
- en: '| **Temperature** |  | **Train Outside** |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| **温度** |  | **户外训练** |'
- en: '|  | **Yes** | **No** |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|  | **是** | **否** |'
- en: '| **Hot** | 2 | 2 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| **热** | 2 | 2 |'
- en: '| **Mild** | 4 | 2 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **温和** | 4 | 2 |'
- en: '| **Cool** | 3 | 1 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| **凉爽** | 3 | 1 |'
- en: 'Using these values and an analogous calculation, the entropy is shown in detail
    here:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些值和类似的计算，熵的详细情况如下所示：
- en: '![](img/eff7388b-ac6d-4b8c-95fa-5d057e97fd1d.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eff7388b-ac6d-4b8c-95fa-5d057e97fd1d.png)'
- en: '*p(Hot).S(Hot)+p(Mild).S(Mild)+p(Cool)*S(Cool)=*'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*p(Hot).S(Hot)+p(Mild).S(Mild)+p(Cool)*S(Cool)=*'
- en: '*4/14*(-2/4*log[2](2/4)-2/4*log[2](2/4)) +*'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*4/14*(-2/4*log[2](2/4)-2/4*log[2](2/4)) +*'
- en: '*6/14*(-4/6*log[2](4/6)-2/6*log[2](2/6))+*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '*6/14*(-4/6*log[2](4/6)-2/6*log[2](2/6))+*'
- en: '*4/14*(-3/4*log[2](3/4)-1/4*log[2](1/4)) =*'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*4/14*(-3/4*log[2](3/4)-1/4*log[2](1/4)) =*'
- en: '*0,911*'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*0,911*'
- en: 'The frequency table for the combination Humidity-Train outside is as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 组合Humidity-Train outside的频率表如下：
- en: '| **Humidity** |  | **Train Outside** |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| **Humidity** |  | **Train Outside** |'
- en: '| **Yes** | **No** |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| **Yes** | **No** |'
- en: '| **High** | 3 | 4 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| **High** | 3 | 4 |'
- en: '| **Normal** | 6 | 1 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| **Normal** | 6 | 1 |'
- en: 'Using these values, we get the entropy as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些值，我们得到以下熵：
- en: '![](img/91f2ee7e-5fee-497d-8b8a-3a42b9d21d98.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/91f2ee7e-5fee-497d-8b8a-3a42b9d21d98.png)'
- en: '*p(High).S(High)+p(Normal).S(Normal)=*'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*p(High).S(High)+p(Normal).S(Normal)=*'
- en: '*7/14*(-3/7*log[2](3/7)-4/7*log[2](4/7)) +*'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '*7/14*(-3/7*log[2](3/7)-4/7*log[2](4/7)) +*'
- en: '*7/14*(-6/7*log[2](6/7)-1/7*log[2](1/7))=*'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*7/14*(-6/7*log[2](6/7)-1/7*log[2](1/7))=*'
- en: '*0,788*'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*0,788*'
- en: 'The frequency table for the combination Windy-Train outside is as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Windy-Train outside组合的频率表如下：
- en: '| **Windy** |  | **Train Outside** |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| **Windy** |  | **Train Outside** |'
- en: '|  | **Yes** | **No** |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '|  | **Yes** | **No** |'
- en: '| **TRUE** | 6 | 2 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| **TRUE** | 6 | 2 |'
- en: '| **FALSE** | 3 | 3 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| **FALSE** | 3 | 3 |'
- en: 'Using these values, we get the entropy as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些值，我们得到以下熵：
- en: '![](img/ae116dfd-9968-47ba-ad17-fbd5ec08073e.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ae116dfd-9968-47ba-ad17-fbd5ec08073e.png)'
- en: '*p(True).S(True)+p(False).S(False)=*'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*p(True).S(True)+p(False).S(False)=*'
- en: '*8/14*(-6/8*log[2](6/8)-2/8*log[2](2/8)) +*'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*8/14*(-6/8*log[2](6/8)-2/8*log[2](2/8)) +*'
- en: '*6/14*(-3/6*log[2](3/6)-3/6*log[2](3/6))*'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*6/14*(-3/6*log[2](3/6)-3/6*log[2](3/6))*'
- en: '*=0,892*'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '*=0,892*'
- en: Comparing the entropy differences (information gain)
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较熵差（信息增益）
- en: 'To know which variable to choose for the first split, we calculate the information
    gain *G* when going from the original data to the corresponding subset as the
    difference between the entropy values:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 要知道选择哪个变量作为第一次分割，我们计算从原始数据到相应子集的信息增益*G*，即熵值之差：
- en: '![](img/35fbfbaa-4a17-4a9b-9029-0e8732cf6118.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35fbfbaa-4a17-4a9b-9029-0e8732cf6118.png)'
- en: 'Here, *S(f[1])* is the entropy of the target variable and *S(f[1],f2)* is the
    entropy of each feature with respect to the target variable. The entropy values
    were calculated in the previous subsections, so we use them here:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*S(f[1])*是目标变量的熵，而*S(f[1],f2)*是每个特征相对于目标变量的熵。熵值已在之前的子节中计算，因此我们在此使用它们：
- en: 'If we choose *Outlook* as the first variable to split the tree, the information
    gain is as follows:'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们选择*Outlook*作为第一次分割树的变量，信息增益如下：
- en: '*G(Train outside,Outlook) = S(Train outside) - S(Train outside,Outlook)* * 
                                                   = 0.94-0.693=0.247*'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*G(Train outside,Outlook) = S(Train outside) - S(Train outside,Outlook)* * 
                                                   = 0.94-0.693=0.247*'
- en: 'If we choose *Temperature*, the information gain is as follows:'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们选择*Temperature*，信息增益如下：
- en: '*G(Train outside,Temperature) = S(Train outside) - S(Train outside,Temperature)*
    *                                                           = 0.94-0.911=0.029*'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '*G(Train outside,Temperature) = S(Train outside) - S(Train outside,Temperature)*
    *                                                           = 0.94-0.911=0.029*'
- en: 'If we choose *Humidity*, the information gain is as follows:'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们选择*Humidity*，信息增益如下：
- en: '*G(Train outside,Humidity) = S(Train outside) - S(Train outside,Humidity)*
    *                                                     = 0.94-0.788=0.152*'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*G(Train outside,Humidity) = S(Train outside) - S(Train outside,Humidity)*
    *                                                     = 0.94-0.788=0.152*'
- en: 'Finally, choosing *Windy* gives the following information gain:'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，选择*Windy*给出以下信息增益：
- en: '*G(Train outside,Windy) = S(Train outside) - S(Train outside,Windy)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*G(Train outside,Windy) = S(Train outside) - S(Train outside,Windy)*'
- en: = 0.94-0.892=0.048*
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: = 0.94-0.892=0.048*
- en: All these calculations are easily performed in a worksheet using Excel formulas.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些计算都可以使用Excel公式在电子表格中轻松完成。
- en: The variable to choose for the first splitting of the tree is the one showing
    the largest information gain, that is, *Outlook*. If we do this, we will notice
    that one of the resulting subsets after the splitting has zero entropy, so we
    don't need to split it further.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 树第一次分割时选择的变量是显示最大信息增益的变量，即*Outlook*。如果我们这样做，我们会注意到分割后产生的其中一个子集具有零熵，因此我们不需要进一步分割它。
- en: 'To continue building the tree following a similar procedure, the steps to take
    are as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 要继续按照类似程序构建树，需要采取的步骤如下：
- en: Calculate *S(Sunny)*, *S(Sunny,Temperature)*, *S(Sunny,Humidity),* and *S(Sunny,Windy).*
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算*S(Sunny)*, *S(Sunny,Temperature)*, *S(Sunny,Humidity)*, 和 *S(Sunny,Windy)*。
- en: Calculate *G**(Sunny,Temperature)*, *G(Sunny,Humidity),* and *G(Sunny,Windy).*
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算*G**(Sunny,Temperature)*, *G(Sunny,Humidity)*, 和 *G(Sunny,Windy)*。
- en: The larger value will tell us what feature to use to split *Sunny.*
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 较大的值将告诉我们使用哪个特征来分割*Sunny*。
- en: Calculate other gains, using *S(Rainy)*, *S(Rainy,Temperature)*, *S(Rainy,Humidity),*
    and *S(Rainy,Windy).*
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*S(Rainy)*, *S(Rainy,Temperature)*, *S(Rainy,Humidity)*, 和 *S(Rainy,Windy)*来计算其他增益。
- en: The larger value will tell us what feature to use to split *Rainy.*
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 较大的值将告诉我们使用哪个特征来分割*Rainy*。
- en: Continue iterating until there are no features left to use.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续迭代，直到没有可用的特征为止。
- en: As we will see later in this book, trees are never built by hand. It is important
    to understand how they work and which calculations are involved. Using Excel,
    it is easy to follow the full process and each step. Following the same principle,
    we will work through an unsupervised learning example in the next section.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在本书后面看到的那样，树永远不会手工构建。理解它们的工作原理和涉及的计算非常重要。使用Excel，可以轻松地跟随整个流程和每一步。遵循同样的原则，我们将在下一节中通过一个无监督学习示例进行操作。
- en: Understanding unsupervised learning with clustering
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过聚类理解无监督学习
- en: Clustering is a statistical method that attempts to group the points in a dataset
    according to a distance measure, usually the Euclidean distance, which calculates
    the root of the squared differences between coordinates of a pair of points. To
    put this simply, those points that are classified within the same cluster are
    closer (in terms of the distance defined) to each other than they are to the points
    belonging to other clusters. At the same time, the larger the distance between
    two clusters, the better we can distinguish them. This is similar to saying that
    we try to build groups in which members are more alike and are more different
    to members of other groups.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是一种统计方法，试图根据距离度量将数据集中的点分组，通常是欧几里得距离，它计算一对点坐标之间平方差的平方根。简单来说，那些被分类在同一聚类内的点，在定义的距离意义上彼此更近，比属于其他聚类的点更近。同时，两个聚类之间的距离越大，我们就能更好地区分它们。这类似于说，我们试图构建成员之间更相似、与其他群体成员差异更大的群体。
- en: It is clear that the most important part of a clustering algorithm is to define
    and calculate the distance between two given points and to iteratively assign
    the points to the defined clusters, until there is no change in the cluster composition.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，聚类算法最重要的部分是定义和计算两个给定点之间的距离，并迭代地将点分配到定义的聚类中，直到聚类组成没有变化。
- en: There are a few points to consider before trying a clustering analysis. Not
    every type of data is adequate for clustering. For example, we cannot use binary
    data since it is not possible to define distances. The values are either `1` or
    `0`, and there is no value in-between. This excludes the type of data generated
    by one-hot encoding. Only data that shows some ordering or scale is useful for
    clustering. Even if the data values are real (such as, for example, a client's
    expenditure amounts or annual income), it is better to group them in a scale of
    ranges.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试聚类分析之前，有几个要点需要考虑。并非每种类型的数据都适合聚类。例如，我们不能使用二进制数据，因为无法定义距离。值要么是`1`，要么是`0`，中间没有值。这排除了由one-hot编码生成的那种类型的数据。只有显示某种顺序或尺度的数据对聚类有用。即使数据值是真实的（例如，例如客户的支出金额或年收入），最好将它们分组在范围尺度上。
- en: 'Some examples of clustering use cases are as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类用例的几个例子如下：
- en: Automatic grouping of IT alerts to assign priorities and solve them accordingly
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动分组IT警报以分配优先级并相应地解决它们
- en: Analysis of customer communication through different channels (segmentation
    in time periods)
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过不同渠道分析客户沟通（按时间段细分）
- en: Criminal profiling
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 犯罪画像
- en: Urban mobility analysis
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 城市流动性分析
- en: Fraud detection (looking for outliers)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欺诈检测（寻找异常值）
- en: Analysis of athletes' performances
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运动员表现分析
- en: Crime analysis by geography
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 地理犯罪分析
- en: Delivery logistics
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配送物流
- en: Classification of documents
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档分类
- en: Now, let's go through some examples that explains the concept of clustering
    algorithms.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一些例子来解释聚类算法的概念。
- en: Grouping customers by monthly purchase amount
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按月购买金额分组客户
- en: We will now follow the full calculation and analysis necessary to generate clusters
    from customer data. This is a simplified version of what would be a typical clustering
    algorithm, showing all the steps but reducing the number of iterations to make
    it understandable. Clustering is usually done automatically, but it is important
    to understand the logic behind the calculation.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将跟随从客户数据生成聚类的全部计算和分析。这是一个典型的聚类算法的简化版本，展示了所有步骤但减少了迭代次数以便理解。聚类通常自动进行，但理解计算背后的逻辑很重要。
- en: 'The dataset to be used contains the total monthly amount spent by 20 different
    customers in an online store, corresponding to `May`, `June`, and `July` in a
    given year. Once typed in an Excel sheet, the data looks like this:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用的数据集包含20个不同客户在一个网店中每月花费的总金额，对应于给定年份的`五月`、`六月`和`七月`。一旦在Excel表中输入，数据看起来是这样的：
- en: '![](img/c1b1a2e3-cefe-4bb3-8fbd-bdc9e5a4e9e9.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c1b1a2e3-cefe-4bb3-8fbd-bdc9e5a4e9e9.png)'
- en: 'For each month, we can calculate the main parameters that describe the data:
    minimum, maximum, median, and average:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个月，我们可以计算描述数据的几个主要参数：最小值、最大值、中位数和平均值：
- en: '|  | **May** | **June** | **July** |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '|  | **五月** | **六月** | **七月** |'
- en: '| **Minimum** | 316.89 | 500.66 | 185.63 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| **最小值** | 316.89 | 500.66 | 185.63 |'
- en: '| **Maximum** | 11889.66 | 12214.41 | 11982.64 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| **最大值** | 11889.66 | 12214.41 | 11982.64 |'
- en: '| **Median** | 8388.63 | 8156.16 | 7708.27 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| **中位数** | 8388.63 | 8156.16 | 7708.27 |'
- en: '| **Average** | 6182.20 | 6229.24 | 6227.81 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| **平均值** | 6182.20 | 6229.24 | 6227.81 |'
- en: We simply use the Excel built-in functions *MIN()*, *MAX()*, *MEDIAN()*, and
    *AVERAGE()*, including the full range of each column.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简单地使用Excel内置函数 *MIN()*, *MAX()*, *MEDIAN()*, 和 *AVERAGE()*，包括每个列的完整范围。
- en: In cluster analysis, it is useful to *normalize* the dataset, that is, to convert
    all values so that they fall in to the interval [0,1]. This helps us deal with
    the **outlier** data points, whose value is very different from the majority of
    points, which can affect the cluster definition. After normalization, those points
    are not so far away from the rest and can be easily grouped. Clearly, if the goal
    of the clustering analysis is to find those outliers, it is a better idea to leave
    the dataset as it is and highlight the difference between the outliers and the
    rest of the set.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在聚类分析中，对数据集进行*归一化*是有用的，也就是说，将所有值转换为落在区间 [0,1] 内。这有助于我们处理那些与大多数点值差异很大的**异常值**，这些值可能会影响簇的定义。归一化后，这些点与其他点之间的距离就不那么远了，并且可以很容易地分组。显然，如果聚类分析的目标是找到这些异常值，那么保持数据集原样并突出异常值与数据集其他部分之间的差异是一个更好的主意。
- en: 'The easiest way to normalize the data is to divide each value by the maximum
    in the corresponding column. To do this, follow these steps:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化数据的最简单方法是将每个值除以对应列的最大值。为此，请按照以下步骤操作：
- en: In cell *G2,* type `=B2/$B$24`. We are assuming that *B2* is the first value
    in the `May` column and that the maximum value is in *B24*.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在单元格 *G2* 中，输入 `=B2/$B$24`。 我们假设 *B2* 是`五月`列的第一个值，并且最大值在 *B24*。
- en: 'Copy this formula into the whole column. Recall that adding *$* to the cell
    ID in Excel fixes that value when copying the contents into another cell. The
    normalized table is then as follows:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此公式复制到整个列中。记住，在Excel中，在单元格ID前添加 *$* 可以在复制内容到另一个单元格时固定该值。归一化后的表格如下所示：
- en: '![](img/eea879ef-2c9f-4b03-a40d-fc677dd1804d.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eea879ef-2c9f-4b03-a40d-fc677dd1804d.png)'
- en: 'Let''s take a moment to visualize the data and understand it a little more.
    If we take the columns in pairs, then it is possible to generate scatter plots
    and try to find clusters visually by following these steps:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花点时间可视化数据并更深入地理解它。如果我们成对地考虑列，那么可以生成散点图，并按照以下步骤尝试通过视觉方式找到簇：
- en: Select `May` and `June` data.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`五月`和`六月`数据。
- en: Click Insert | Scatter.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 插入 | 散点图。
- en: 'The resulting diagram is as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表如下所示：
- en: '![](img/11c7e4a0-ca9a-4662-9d35-a7249965949a.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](img/11c7e4a0-ca9a-4662-9d35-a7249965949a.png)'
- en: Three clusters can be identified, and are circled in the preceding screenshot.
    They correspond to groups of customers who spend similar amounts of money monthly.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 可以识别出三个簇，并在前面的屏幕截图中被圈出。它们对应于每月花费相似金额的客户群体。
- en: 'Doing the same with `May` and `July`, we get the following diagram:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用相同的方法处理`五月`和`七月`，我们得到以下图表：
- en: '![](img/c7005221-b01b-49e0-864e-ca94affdd0da.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7005221-b01b-49e0-864e-ca94affdd0da.png)'
- en: In this case, we could either say that there are two big clusters or that one
    of them can be further split in two. The separation is not so clear and the choice
    will depend on other variables (remember that the best model is always the one
    that best suits the business' needs).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以说有两个大簇，或者其中一个簇可以进一步分为两个。分离并不那么清晰，选择将取决于其他变量（记住，最好的模型总是最适合业务需求的模型）。
- en: 'Finally, we plot `June` and `July`:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们绘制了`六月`和`七月`的数据：
- en: '![](img/b4ef4a9d-7137-44d7-a37e-37f4a22b7078.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b4ef4a9d-7137-44d7-a37e-37f4a22b7078.png)'
- en: The division of clusters seems even more clear here, and we can circle three
    sets of points.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，簇的划分似乎更加清晰，我们可以圈出三组点。
- en: 'What if we want to consider all three months at the same time? There is an
    iterative process to accomplish this, which is the base of the clustering algorithm
    known as **K-means**. Let''s follow the steps of this algorithm in detail:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想同时考虑三个月怎么办？有一个迭代过程可以完成这个任务，这是称为**K-means**的聚类算法的基础。让我们详细遵循这个算法的步骤：
- en: Decide how many clusters you want to split the data into. This is not an easy
    decision in general. It will strongly depend on the dataset and, in some cases,
    will be a matter of testing different values until you get a number of clusters
    that gives useful insights on the data.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决定你想要将数据分成多少个簇。这通常不是一个容易的决定。它将强烈依赖于数据集，在某些情况下，可能需要测试不同的值，直到你得到一个能够对数据提供有用见解的簇数。
- en: Taking into account the previous visual analysis, we decide to choose three
    as the number of clusters.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到之前的视觉分析，我们决定选择三个作为簇的数量。
- en: 'Take any three points as the center of the clusters. The choice of the starting
    points is not relevant, as we will repeat the whole process until there is no
    change in the resulting cluster members. We then choose the first three points
    in the list, as shown in the following table:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以任意三个点作为簇的中心。起始点的选择并不重要，因为我们将会重复整个过程，直到结果簇成员没有变化。然后我们选择列表中的前三个点，如下表所示：
- en: '|  | **May** | **June** | **July** |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|  | **May** | **June** | **July** |'
- en: '| **Random1** | 0.055568104 | 0.043735522 | 0.15581034 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| **Random1** | 0.055568104 | 0.043735522 | 0.15581034 |'
- en: '| **Random2** | 0.07079235 | 0.067065974 | 0.079319396 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| **Random2** | 0.07079235 | 0.067065974 | 0.079319396 |'
- en: '| **Random3** | 0.026652635 | 0.040988882 | 0.171590079 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| **Random3** | 0.026652635 | 0.040988882 | 0.171590079 |'
- en: 'Find the points that are closer to them, computing the distance from all other
    points to these cluster centers. The Euclidean distance between two points, *P[1]
    =(x[1],y[1]**,z[1])* and *P[2] = (x[2],y[2]**,z[2]),* is defined as follows:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到离它们更近的点，计算所有其他点到这些簇中心的距离。两点之间的欧几里得距离，*P[1] =(x[1],y[1]**,z[1])* 和 *P[2] = (x[2],y[2]**,z[2]),*
    定义如下：
- en: '![](img/93758e1f-101e-412e-bf3e-023268aa23e2.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/93758e1f-101e-412e-bf3e-023268aa23e2.png)'
- en: Use Excel's built-in *SUMXMY2([array1];[array2})* function to calculate *(DE)²*
    for each point with respect to the cluster centers.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Excel的内置 *SUMXMY2([array1];[array2})* 函数计算每个点到簇中心的 *(DE)²*。
- en: 'For each data point, you will get three distance values. Pick the smallest
    one to decide which cluster the point belongs to. For example, for customer ID
    = 4, we get the following information:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个数据点，你将得到三个距离值。选择最小的一个来决定点属于哪个簇。例如，对于客户ID = 4，我们得到以下信息：
- en: '| **D1** | **D2** | **D3** | **Cluster** |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| **D1** | **D2** | **D3** | **Cluster** |'
- en: '| 0.019689391 | 0.004847815 | 0.025218271 | 2 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 0.019689391 | 0.004847815 | 0.025218271 | 2 |'
- en: Here, *D1*, *D1,* and *D3* are the distances from the point to the respective
    cluster centers. The smallest distance tells us that this point belongs to cluster
    two. As an example, *D1* for customer ID = 4 is calculated as *=SUMXMY2(B5:D5;$B$23:$D$23)*,
    assuming that Random1 `May` and Random1 `June` are in cells *$B$23* and *$D$23*,
    respectively.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*D1*，*D1*，和 *D3* 是点到相应簇中心的距离。最小的距离告诉我们这个点属于第二个簇。例如，对于客户ID = 4的 *D1* 计算如下 *=SUMXMY2(B5:D5;$B$23:$D$23)*，假设Random1的`五月`和Random1的`六月`分别位于单元格*$B$23*和*$D$23*。
- en: 'The complete resulting data table is as follows:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完整的结果数据表如下：
- en: '![](img/9934f1dc-2e42-47c0-aadb-b636e379059c.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9934f1dc-2e42-47c0-aadb-b636e379059c.png)'
- en: The last column can be created by typing the following formula into the first
    row and then copying it down: *=IF(E2=MIN(E2:G2);1;IF(F2=MIN(E2:G2);2;3))*.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过在第一行输入以下公式然后向下复制来创建最后一列：*=IF(E2=MIN(E2:G2);1;IF(F2=MIN(E2:G2);2;3))*。
- en: 'According to the table, our first result is really unbalanced. Most of the
    points fall in cluster one, a few in cluster two, and only one in cluster three.
    We need to continue the calculations and see how the result evolves. Follow these
    steps:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 根据表格，我们的第一个结果确实不平衡。大多数点落在簇一，少数在簇二，只有一个在簇三。我们需要继续计算，看看结果如何演变。遵循以下步骤：
- en: Instead of choosing random points, we will now use the mean values of the clusters
    we obtained.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将使用我们获得的簇的平均值而不是选择随机点。
- en: 'Order the table by cluster number. The resulting table is a little different
    now, as follows:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按簇编号对表格进行排序。结果表格现在略有不同，如下所示：
- en: '![](img/e0519ae9-bd12-4c5b-947f-4d17857df7ed.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0519ae9-bd12-4c5b-947f-4d17857df7ed.png)'
- en: 'Use the *MEAN()* function to calculate the average value per cluster for each
    month. You should get the same results that are shown in the following table:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 *MEAN()* 函数计算每个月每个聚类的平均值。你应该得到以下表格中显示的相同结果：
- en: '|  | **May** | **June** | **July** |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '|  | **五月** | **六月** | **七月** |'
- en: '| **Mean1** | 0.618762809 | 0.605805489 | 0.618056642 |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| **Mean1** | 0.618762809 | 0.605805489 | 0.618056642 |'
- en: '| **Mean2** | 0.157477363 | 0.155314048 | 0.111411008 |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| **Mean2** | 0.157477363 | 0.155314048 | 0.111411008 |'
- en: '| **Mean3** | 0.026652635 | 0.040988882 | 0.171590079 |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| **Mean3** | 0.026652635 | 0.040988882 | 0.171590079 |'
- en: As an example, **Mean1** corresponding to `May` is calculated as *AVERAGE(B2:B17)*.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对应于 `五月` 的 **Mean1** 是通过 *AVERAGE(B2:B17)* 计算得出的。
- en: 'Using the same formulas as before and calculating the distances from all other
    points to the mean values, you get a table similar to this:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用与之前相同的公式，并计算所有其他点到平均值之间的距离，你会得到一个类似于这个表格的表格：
- en: '![](img/4f669d09-d40e-4b33-8f05-dab4a8ce8214.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4f669d09-d40e-4b33-8f05-dab4a8ce8214.png)'
- en: After the second iteration, a few more points, which, when moved away from cluster
    one, now belong to cluster two and three.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次迭代后，一些点被移动到从聚类一移开的位置，现在它们属于聚类二和三。
- en: 'Repeat the calculation one more time. The new mean values, according to the
    preceding table, are as follows:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再进行一次计算。根据前面的表格，新的平均值如下：
- en: '|  | **May** | **June** | **July** |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|  | **五月** | **六月** | **七月** |'
- en: '| **Mean1** | 0.843481911 | 0.832289469 | 0.810799822 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| **Mean1** | 0.843481911 | 0.832289469 | 0.810799822 |'
- en: '| **Mean2** | 0.292624962 | 0.280240044 | 0.310753303 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| **Mean2** | 0.292624962 | 0.280240044 | 0.310753303 |'
- en: '| **Mean3** | 0.052180197 | 0.048870976 | 0.105552835 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| **Mean3** | 0.052180197 | 0.048870976 | 0.105552835 |'
- en: 'The table containing the distances and cluster numbers can be given as follows:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以将包含距离和聚类编号的表格表示如下：
- en: '![](img/8722ed23-eb6b-4609-b9d8-b8fe2d37ff99.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8722ed23-eb6b-4609-b9d8-b8fe2d37ff99.png)'
- en: After the third iteration, only one point changed cluster, from two to three;
    so, we are getting close to the final result. You should be able to perform one
    more iteration, following the same steps, proving that it does not change the
    clustering labels and meaning that the calculations converged to a stable number
    of clusters.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三次迭代后，只有一个点改变了聚类，从二变为三；因此，我们正在接近最终结果。你应该能够再进行一次迭代，按照相同的步骤，证明它不会改变聚类标签，这意味着计算收敛到了一个稳定的聚类数量。
- en: Real-life datasets might not converge so fast. What we have shown is a simplified
    example, good enough to show every step of the iteration, understand them, and
    get to a reasonable result. Clustering is not usually calculated manually, but
    performed by pre-built algorithms.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现实生活中的数据集可能不会那么快收敛。我们展示的是一个简化的例子，足以展示迭代的每一步，理解它们，并得到一个合理的结果。聚类通常不是手动计算的，而是通过预构建的算法执行。
- en: In the following chapter, you will learn how to import data from different sources
    to Excel, so you don't need to type in the values manually. This will give you
    a starting point to analyze real data, usually containing many more variables
    and values than the examples shown in this chapter.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何将数据从不同的来源导入Excel，这样你就不需要手动输入值。这将为你分析真实数据提供一个起点，通常比本章中展示的例子包含更多的变量和值。
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have described real life examples of supervised and unsupervised
    machine learning models that have been applied to solving problems. We covered
    multiple regression, decision trees, and clustering. We have also shown how to
    choose and transform the input variables or features to be ingested by the models.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们描述了将监督学习和无监督机器学习模型应用于解决问题的实际例子。我们涵盖了多元回归、决策树和聚类。我们还展示了如何选择和转换模型要摄入的输入变量或特征。
- en: This chapter only shows the basic principles of each algorithm. In real data
    analysis and prediction using machine learning, models are already programmed
    and can be used as black boxes. It is, therefore, extremely important to understand
    the basics of each model and know whether we are using it correctly.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 本章仅展示了每个算法的基本原理。在现实数据分析和预测中使用机器学习时，模型已经编程，可以用作黑盒。因此，了解每个模型的基本原理并知道我们是否正确使用它非常重要。
- en: In the following chapters, we will focus on how to extract the data from different
    sources, transform it according to our needs, and use previously built models
    for analysis.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将关注如何从不同的来源提取数据，根据我们的需求对其进行转换，并使用先前构建的模型进行分析。
- en: Questions
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why is it important to encode categorical features?
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么对分类特征进行编码很重要？
- en: What are the different ways to stop a decision tree calculation?
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有哪些不同的方法可以停止决策树计算？
- en: '`Temperature_hot` has an entropy value of one in the example. Why?'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在示例中，`Temperature_hot` 的熵值为一。为什么？
- en: Following the diagram of the decision tree at the beginning of the *Understanding
    supervised learning with decision trees* section, what would be the path to decide
    whether or not to train outside? Consider using `IF` statements.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照第 *Understanding supervised learning with decision trees* 节开始处的决策树图，决定是否进行外部训练的路径是什么？可以考虑使用
    `IF` 语句。
- en: Would the cluster distribution change if we choose different starting points?
    You can read about this in the recommended articles.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们选择不同的起始点，聚类分布会改变吗？你可以阅读推荐的文章了解这一点。
- en: Is the clustering that's obtained with iterative analysis the same as the one
    that's determined visually? Why?
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过迭代分析获得的聚类与通过视觉确定的聚类是否相同？为什么？
- en: Further reading
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*How to Interpret Regression Analysis Results: P-values and Coefficients*: [http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-interpret-regression-analysis-results-p-values-and-coefficients](http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-interpret-regression-analysis-results-p-values-and-coefficients)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如何解释回归分析结果：P值和系数*：[http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-interpret-regression-analysis-results-p-values-and-coefficients](http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-interpret-regression-analysis-results-p-values-and-coefficients)'
- en: '*Teaching Decision Tree Classification Using Microsoft Excel INFORMS Transactions
    on Education* 11(3), pp. 123–131, by Kaan Ataman, George Kulick, Thaddeus Sim:
    [https://pubsonline.informs.org/doi/10.1287/ited.1100.0060](https://pubsonline.informs.org/doi/10.1287/ited.1100.0060)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 Microsoft Excel 教学决策树分类*，发表于《INFORMS Transactions on Education》第 11 卷第
    3 期，第 123–131 页，作者：Kaan Ataman, George Kulick, Thaddeus Sim: [https://pubsonline.informs.org/doi/10.1287/ited.1100.0060](https://pubsonline.informs.org/doi/10.1287/ited.1100.0060)'
- en: '*A Review of K-mean Algorithm*, International Journal of Engineering Trends
    and Technology (IJETT) – Volume 4 Issue 7- July 2013: [http://www.ijettjournal.org/volume-4/issue-7/IJETT-V4I7P139.pdf](http://www.ijettjournal.org/volume-4/issue-7/IJETT-V4I7P139.pdf)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*K均值算法综述*，发表于《International Journal of Engineering Trends and Technology (IJETT)》第
    4 卷第 7 期，2013 年 7 月：[http://www.ijettjournal.org/volume-4/issue-7/IJETT-V4I7P139.pdf](http://www.ijettjournal.org/volume-4/issue-7/IJETT-V4I7P139.pdf)'
