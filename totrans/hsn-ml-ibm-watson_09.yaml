- en: Deep Learning Using TensorFlow on the IBM Cloud
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will provide an introduction to the concepts of deep learning
    and neural networks on the IBM Cloud. An overview of how to use the TensorFlow
    framework to implement deep learning models on the cloud will be provided as well.
    This chapter is designed to be a balance between theory and practical implementation.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to deep learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow basics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks using TensorFlow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow and image classifications
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additional preparation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to deep learning
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning (also known as **deep structured learning** or **hierarchical
    learning**) is part of a larger group of machine learning approaches based on
    learning data representations, as opposed to task-specific algorithms.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Learning can be supervised (which we covered in [Chapter 3](b2822c69-13f0-4943-9e66-f9ef04898b60.xhtml),
    *Supervised Machine Learning Models and Your Data*), semi-supervised, or unsupervised
    (covered in [Chapter 4](f131f753-1d77-478c-9c0d-1e799330eed8.xhtml), *Implementing
    Unsupervised Algorithms*).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning algorithms are at work in exciting areas such as image classification
    (categorizing every pixels in a digital image into one of several land cover classes,
    or themes), object detection (the process of finding instances of real-world objects
    such as faces, cars, and buildings in images or videos), image restoration (to
    compensate for, or undo, defects caused by motion blur, noise, and camera misfocus,
    which degrade an image) and image segmentation (the process of partitioning a
    digital image into multiple segments of pixels, also known as **super-pixels**,
    to simplify and/or change the representation of an image into something that is
    more meaningful and easier to analyze).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning using enormous neural networks is teaching machines to automate
    the tasks performed by human visual systems.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning models are vaguely inspired by information processing and communication
    patterns in biological nervous systems, yet they do differ from the structural
    and functional properties of biological brains, which make them incompatible with
    neuroscience evidences.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'Enough theory. While the preceding explanation of machine/deep learning may
    be high-level, it is sufficient enough for us to move on to the next section,
    where we start thinking about the means of deep learning implementation, specifically
    using a toolset developed by the Google Brain team for internal Google use, under
    the Apache 2.0 open source license on November 9, 2015: TensorFlow.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow basics
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tensors can be thought to be generalized matrixes or, more specifically, mathematical
    entities living in structures and interacting with other mathematical entities.
    If the other entities in the structure are transformed in any way, then the tensor
    must also be transformed by that transformation rule.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: 'What does the preceding definition mean? Perhaps thinking of a **Tensor** as
    multidimensional array is easier to grasp, or consider the following, comparing
    **Scalar**, **Vector**, **Matrix**, and **Tensor**:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的定义意味着什么？也许将**张量**视为多维数组更容易理解，或者考虑以下内容，比较**标量**、**向量**、**矩阵**和**张量**：
- en: '![](img/6aa4e189-4fb1-4e5d-84b3-2ad53319d2b2.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6aa4e189-4fb1-4e5d-84b3-2ad53319d2b2.png)'
- en: Building on the topic of TensorFlow, TensorFlow is an open source software library
    (also called a **framework**) originally created by Google for creating deep learning
    models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 基于TensorFlow的主题，TensorFlow是一个由Google最初创建的开源软件库（也称为**框架**），用于创建深度学习模型。
- en: You can visit [https://www.tensorflow.org/](https://www.tensorflow.org/) for
    more details on TensorFlow.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以访问[https://www.tensorflow.org/](https://www.tensorflow.org/)获取有关TensorFlow的更多详细信息。
- en: In the next section, we will talk about the connection between deep learning,
    neural networks, and TensorFlow.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论深度学习、神经网络和TensorFlow之间的关系。
- en: Neural networks and TensorFlow
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络和TensorFlow
- en: Deep learning models typically employ algorithms known as **neural networks**,
    which are said to be inspired by the way actual biological nervous systems (such
    as the brain) process information. It enables computers to recognize all data
    points as to what each represents and learn patterns.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型通常采用被称为**神经网络**的算法，这些算法据说受到了实际生物神经系统（如大脑）处理信息方式的影响。这使得计算机能够识别所有数据点所代表的内容，并学习模式。
- en: Today, the principal software tool for deep learning models is TensorFlow as
    it permits developers to create large-scale neural networks with numerous layers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，深度学习模型的主要软件工具是TensorFlow，因为它允许开发者创建具有多个层的庞大神经网络。
- en: 'TensorFlow is mainly used for the following purposes:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow主要用于以下目的：
- en: Classification
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类
- en: Perception
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感知
- en: Understanding
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解
- en: Discovering
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现
- en: Prediction
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测
- en: Creation
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建
- en: As noted in the Watson documentation, the challenge with deploying complex machine
    learning models such as a TensorFlow model is that these models are very computationally
    expensive and time-consuming to train. Some solutions (to this challenge) include
    GPU acceleration, distributed computing, or a combination of both. The IBM Cloud
    platform and Watson Studio offers both of these.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如Watson文档中所述，部署复杂机器学习模型（如TensorFlow模型）的挑战在于这些模型在训练时非常计算密集和时间消耗。一些解决方案（针对这一挑战）包括GPU加速、分布式计算或两者的结合。IBM云平台和Watson
    Studio都提供了这两种解决方案。
- en: 'It also points: IBM Watson Studio permits one to leverage the computational
    power available on the cloud to speed up the training time of the more complex
    machine learning models, and thus reduce the time from hours or days, down to
    minutes.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 它还指出：IBM Watson Studio允许用户利用云上可用的计算能力来加速更复杂机器学习模型的训练时间，从而将时间从数小时或数天缩短到几分钟。
- en: In the next sections, we will explore several exercises demonstrating various
    ways of using TensorFlow with IBM Watson Studio.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨几个练习，展示使用IBM Watson Studio和TensorFlow的各种方法。
- en: An example
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个例子
- en: In this section, we will start by stepping through a Watson Community ([https://dataplatform.cloud.ibm.com/community](https://dataplatform.cloud.ibm.com/community))
    tutorial, designed to demonstrate how easy it is to deploy a deep neural network
    using the TensorFlow libraries on IBM Watson Studio.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将首先通过一个Watson社区([https://dataplatform.cloud.ibm.com/community](https://dataplatform.cloud.ibm.com/community))教程，展示如何使用IBM
    Watson Studio上的TensorFlow库轻松部署深度神经网络。
- en: The tutorial is available on GitHub for download, but we won't provide the URL
    here because we will demonstrate how easy it is to simply import content from
    external sources (such as GitHub) from directly within a IBM Watson Studio project.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 该教程可在GitHub上下载，但在此我们不会提供URL，因为我们将展示如何直接在IBM Watson Studio项目中从外部来源（如GitHub）导入内容变得多么简单。
- en: This exercise's key point is that complex machine learning models can be computationally
    thirsty, but IBM Watson Studio gives you the opportunity to easily and efficiently
    (pay as you go) use the computational power available on the cloud to speed up
    processing time and reduce the time it takes to learn from hours, or days, down
    to minutes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的关键点是复杂的机器学习模型可能非常计算密集，但IBM Watson Studio为您提供了轻松高效（按使用付费）使用云上计算能力来加速处理时间并缩短从数小时或数天到数分钟的学习时间的机遇。
- en: Additionally, IBM Watson Studio provides all the tools essential to develop
    a data-centric solution in the cloud. It makes use of Apache Spark clusters (for
    computational power) and lets you create assets in Python, Scala, and R, and leverage
    open source frameworks (such as TensorFlow), all of which are already installed
    on Watson Studio.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: If you take the time to read through the details of the tutorial, you will see
    that it explains how to create a new IBM Cloud account and sign up for IBM Watson
    Studio (which we already covered in [Chapter 1](07c92a06-635f-41ef-b2be-3654ba90b790.xhtml),
    *Introduction to IBM Cloud*).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: The tutorial then goes on to show how to navigate to IBM's Watson Studio (once
    on the IBM Cloud platform), create a new project, and then import a notebook to
    the project.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Although, in earlier chapters, we showed how to create a new project in Watson
    Studio and create new notebooks, this will be the first time we do a notebook
    import (directly from an external URL), so the next sections will focus on how
    that process works.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: The notebook that is to be imported will already contain the TensorFlow libraries
    and example code, so this exercise should be both quick and super easy for us,
    so let's not waste any more time!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Creating the new project
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Taking the same steps that we followed in earlier chapters, we can create a
    new deep learning IBM Watson Studio project (see the following screenshot) and
    give it a name:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab396f17-1f49-4b85-aa27-166db71fb636.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: Notebook asset type
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the new project is created, from the project dashboard, you can click
    the Add to project option and select Notebook, as shown in the following screenshot:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4ae4435-6b3f-47e4-a4f5-ef618a9f6793.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: As we have done in preceding chapters, we could create a new, empty notebook.
    But for this exercise we want to import an existing notebook.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: IBM Watson Studio allows you to import notebooks from either a file or directly
    from a known and accessible URL.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we will choose to import from a URL. To do that, you select the
    From URL option and type or paste in the following line:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/aounlutfi/building-first-dl-model/blob/master/first-dl-model.ipynb](https://github.com/aounlutfi/building-first-dl-model/blob/master/first-dl-model.ipynb)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: The preceding link will be the (external) URL of the notebook to be imported
    into your Watson Studio project.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click on Create Notebook to begin the import (it should only take a few
    seconds, providing you have access to the URL), as shown in the following screenshot:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0793073b-1eea-4389-b611-fe74e691b61f.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
- en: 'After a few seconds, the notebook opens and is ready for review and execution:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/01d88983-414f-4ffd-9100-de56f3c23d4d.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: Running the imported notebook
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run the imported notebook, click on Cell from the commands ribbon, and then
    click Run All:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e080b2d-d4f3-44a1-b2b7-e0c7c1e3cec4.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: After clicking Run All, IBM Watson Studio will then run all the cells within
    the notebook, which should take (about) fifteen minutes or so to complete, since
    the data set is made up of 20,000 images.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: You can also run each cell individually, if you want to better understand what
    is going on.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the notebook
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you take the time (and you should) to look through the cells contained in
    the notebook, you will notice that there are plenty of markdown cells that explicitly
    describe the steps within the notebook.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, you should take note of the markdown cell labeled Imports (as
    shown in the following screenshot) where it clearly states In order to be able
    to build, test, and run a NN in TensorFlow, the following imports have to be used.
    This also imports the MNIST data set (each point in the data set is a handwritten
    representation of the digits 0-9 in 784 pixels):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/338b3dd5-be69-473b-9969-6823826befeb.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: The tutorial also makes a point by challenging you to attempt to set up Python
    and TensorFlow on a local computer (not on the cloud using IBM Watson Studio)
    and run the example so that you can compare the results, noting that it may take
    hours, maybe even days to train, depending on the performance of the machine,
    and that is after you have assembled the required environment!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: In the next example, we will cover using IBM Watson Studio with Watson services
    and the TensorFlow API to perform image classifications and object detection.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow and image classifications
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The IBM Watson Visual Recognition service uses deep learning algorithms to identify
    features like scenes, objects, and faces within images you upload to the service.
    You can also create and train custom classifiers to identify subjects that meet
    your requirements, using the Visual Recognition service, IBM Watson Studio, and
    related Python modules.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: To get started with Visual Recognition, we'll need to use the usual procedure
    to create a Watson Studio project and define a new Python 3.5 Notebook, but we
    will also need to associate an IBM Watson Visual Recognition service instance
    with the project (a pretty easy thing to do as it turns out).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Adding the service
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To add the Watson Visual Recognition service, you need to go to the IBM Cloud
    Dashboard and select Watson Services, then Browse Services, where you can then
    find and select the Visual Recognition service:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2f3c736d-6d73-4ee5-9dd4-925f4fa61f6c.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: 'Next, from the Visual Recognition page (which is shown in the following screenshot),
    you can choose a location and resource group for the service instance and then
    click on Create to actually create the instance of the service that you can use
    in your project:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7fac7444-0a3b-4002-acee-a22511d01131.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: A Visual Recognition service instance may only be associated with one project
    at a time.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have created the Visual Recognition service instance, it will be listed
    on your cloud dashboard:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/76a53786-2282-468a-8ca4-61171883a0a6.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
- en: After creating the service instance, you should be able to create what is referred
    to as Service Credentials (or the API key) by clicking on New Credentials or View
    Credentials in the Service credentials section.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建服务实例后，您应该能够通过在服务凭据部分点击“新建凭据”或“查看凭据”来创建所谓的服务凭据（或API密钥）。
- en: You will need this API key to refer to and use the instance within the project.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 您将需要这个API密钥来引用和使用项目中的实例。
- en: 'The following screenshot shows the Service credentials page:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了服务凭据页面：
- en: '![](img/e779fd2e-0867-413b-8977-8719feab630c.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e779fd2e-0867-413b-8977-8719feab630c.png)'
- en: We will need to refer to this API key in the next few sections of this chapter,
    so keep it handy!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的下一节中，我们需要引用这个API密钥，所以请将其保留在手边！
- en: Now we are ready to get going with the actual Visual Recognition project. In
    this example (a version is available on GitHub), the Watson Visual Recognition
    service is used to perform object detection using the TensorFlow object detection
    API.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好开始实际的视觉识别项目。在这个例子中（GitHub上有可用的版本），我们使用Watson视觉识别服务通过TensorFlow对象检测API进行对象检测。
- en: Required modules
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 必需的模块
- en: 'Although many pre-installed libraries and modules are already included as part
    of an IBM Watson Notebook environment (depending upon the type of notebook selected),
    various other modules and frameworks may still need to be installed for a particular
    project to work correctly, so the first thing we should do in our notebook is
    to type the following command to see the list of pre-installed libraries:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多预安装的库和模块已经作为IBM Watson笔记本环境的一部分包含在内（取决于选择的笔记本类型），但为了使特定项目正确运行，可能还需要安装各种其他模块和框架，因此在我们笔记本中的第一件事就是输入以下命令以查看预安装库的列表：
- en: '[PRE0]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It is a very good idea to always begin a new project by using this command to
    gain an understanding of your notebook's environment; it may save time later.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 总是以这个命令开始一个新的项目是一个非常好的主意，以了解您的笔记本环境；这可能会节省您以后的时间。
- en: 'You can then use the Python `!pip install` command to install each of this
    project''s required modules line by line, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用Python的`!pip install`命令逐行安装此项目所需的每个模块，如下所示：
- en: '[PRE1]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'An alternative and more efficient way to install the required modules with
    one command is to reference the provided `requirements.txt` file:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个命令安装所需的模块的另一种更高效的方法是参考提供的`requirements.txt`文件：
- en: '[PRE2]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Using the API key in code
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在代码中使用API密钥
- en: The IBM Watson Visual Recognition service comes with built-in models that you
    can use to analyze images for scenes, objects, faces, and many other categories
    without any training. We have already created an instance of the Visual Recognition
    service, so it is available to our project. For this to work, you need to have
    that valid key (our actual API key).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: IBM Watson视觉识别服务内置了模型，您可以使用这些模型来分析图像，以识别场景、对象、面部以及许多其他类别，而无需任何训练。我们已创建了一个视觉识别服务的实例，因此它可用于我们的项目。为了使其工作，您需要拥有那个有效的密钥（我们的实际API密钥）。
- en: Even though you have working Python code in the Watson Notebook, you need to
    now use your established API key with it, so it will validate with the Watson
    service (and actually work).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您在Watson笔记本中有可工作的Python代码，您现在也需要使用您已建立的API密钥，这样它就可以与Watson服务进行验证（并且实际上可以工作）。
- en: 'If you look through the Python project code (which we will load in the next
    section), you will find the following code statement:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看Python项目代码（我们将在下一节中加载），您将找到以下代码语句：
- en: '[PRE3]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This line of code is where the Watson Visual Recognition service is initialized
    as an object we can use within our code. You will replace the `API_KEY` phrase
    with your actual API key (the one you created in the previous section).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这行代码是Watson视觉识别服务初始化为我们代码中可用的对象的地方。您需要将`API_KEY`短语替换为您实际的API密钥（您在上一节中创建的）。
- en: Additional preparation
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 额外的准备
- en: In this section, we will take care of a bit more housekeeping that is required
    before we can successfully run the project.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将处理一些在成功运行项目之前所需的额外家务。
- en: Pillow is a **Python Imaging Library** (**PIL**), which provides support for
    opening, manipulating, and saving images. The current version identifies and reads
    a large number of formats.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Pillow是**Python图像库**（**PIL**），它提供了打开、操作和保存图像的支持。当前版本可以识别和读取大量格式。
- en: 'This project utilizes `pillow` and requires at least version 5.3.0 to be installed.
    To ensure that the notebook uses this version, we need to run the following commands:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目使用`pillow`，并要求至少安装5.3.0版本。为了确保笔记本使用这个版本，我们需要运行以下命令：
- en: '[PRE4]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The code uninstalls the currently installed version of Pillow, installs version
    5.3.0, imports it into the project, and then prints the (now) currently installed
    version.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 代码卸载了当前安装的Pillow版本，安装了5.3.0版本，将其导入到项目中，然后打印出（现在）当前安装的版本。
- en: 'As the final line of code indicates, if the output of the `print` command does
    not indicate that the `pillow` version installed is 5.3.0, you will need to stop
    and then restart your kernel (click on Kernel, then restart within your notebook),
    then again execute the `print` command, and you should be ready to go:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如最后一行代码所示，如果`print`命令的输出没有显示安装的`pillow`版本是5.3.0，你需要停止并重新启动你的内核（在笔记本中点击“内核”，然后重启），然后再次执行`print`命令，你应该就可以继续了：
- en: '![](img/a1874dbc-70a5-4042-b240-6dfb3913ccf3.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a1874dbc-70a5-4042-b240-6dfb3913ccf3.png)'
- en: Upgrading Watson
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级Watson
- en: When I first started experimenting with this project I ran into several difficulties
    with using the Visual Recognition service. After much debugging and some much
    appreciated help from IBM Cloud support, it was determined that the project code
    that I was using was using an older version of the cloud API.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始尝试这个项目时，在使用Visual Recognition服务时遇到了几个困难。经过大量的调试和一些来自IBM Cloud支持的宝贵帮助，确定我使用的项目代码正在使用较旧的云API版本。
- en: 'To resolve the issues I was seeing, it was necessary to upgrade the Watson
    service to the latest version using the following command:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决我看到的问题，我需要使用以下命令将Watson服务升级到最新版本：
- en: '[PRE5]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding command generates the following output:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令生成了以下输出：
- en: '![](img/9cbeb948-5a03-4c36-a9b0-8d8f44a23ecb.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9cbeb948-5a03-4c36-a9b0-8d8f44a23ecb.png)'
- en: 'To validate that the service was upgraded, you should see the following message:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证服务已升级，你应该看到以下消息：
- en: '[PRE6]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Once the service was upgraded, all of the issues I was previously experiencing
    were resolved.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦服务升级，我之前遇到的所有问题都得到了解决。
- en: At the time of writing, 2.8.0 is the latest release. It is advisable to always
    check for and use the latest available version.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，2.8.0是最新版本。建议始终检查并使用最新可用的版本。
- en: Images
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图片
- en: One last setup task to perform is to provide an image file for our solution
    to detect objects within.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行的最后一项设置任务是提供一个图像文件供我们的解决方案检测其中的对象。
- en: The sample project code offers a picture of four dogs that you can use, but
    it's more fun to provide one or more of your own. The README notes of this project
    indicate that the code will expect the file to be located in `test_image/image1.jpg`,
    but you can simply upload it as a data asset using the same steps we did in previous
    chapters and then update the code, so it finds the file (you can change the filename
    as well).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 示例项目代码提供了一个四只狗的图片，你可以使用它，但提供你自己的图片会更有趣。这个项目的README说明指出，代码期望文件位于`test_image/image1.jpg`，但你可以简单地使用我们在前几章中使用的相同步骤上传它作为数据资产，然后更新代码，以便找到文件（你还可以更改文件名）。
- en: 'I chose to use the following three different images:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了以下三张不同的图片：
- en: '![](img/f2450e5f-fefe-4018-991d-603cdc52aad6.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f2450e5f-fefe-4018-991d-603cdc52aad6.png)'
- en: Code examination
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码审查
- en: At this point, our environment should be ready for the main code section. Let's
    now look at each section of that code to understand its purpose.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的环境应该已经准备好进行主代码部分。现在让我们看看代码的每个部分，以了解其目的。
- en: 'The first section performs various additional imports. Take specific note of
    the line of code that imports the Visual Recognition service (`VisualRecognitionV3`)
    from the (now upgraded) `watson_developer_cloud`:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 第一部分执行了各种额外的导入操作。请注意导入Visual Recognition服务（`VisualRecognitionV3`）的代码行，该服务来自（现已升级的）`watson_developer_cloud`：
- en: '[PRE7]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following are the commands:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些命令：
- en: '[PRE8]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The next line of code uses our previously mentioned API key (you''ll use your
    own):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 下一条代码使用了我们之前提到的API密钥（你将使用自己的）：
- en: '[PRE9]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The next section contains variables that you can experiment with when you run
    the notebook. Look at the results and adjust the variables to see the effects:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分包含了一些变量，当你在运行笔记本时可以对其进行实验。查看结果并调整变量以观察效果：
- en: '[PRE10]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'From the preceding commands, let''s explore each of the three variables defined:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的命令中，让我们探索定义的三个变量中的每一个：
- en: '`MAX_NUMBER_OF_BOXES`: This variable represents the maximum number of objects
    to locate within you test image; I used `9` because it can get ugly if there are
    a lot of them.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MAX_NUMBER_OF_BOXES`：这个变量代表在测试图像中要定位的最大对象数量；我使用了`9`，因为如果有很多，可能会变得很难看。'
- en: '`MINIMUM_CONFIDENCE`: This variable represents the minimum confidence score
    that a box can have. If this value is too low, you may end up with boxes around
    nothing.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MINIMUM_CONFIDENCE`：这个变量代表一个框可以有的最小置信度分数。如果这个值太低，你可能会在没有任何东西的地方得到框。'
- en: '`COLORS`: This variable sets the resulting identification boxes'' attributes.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`COLORS`：这个变量设置结果识别框的属性。'
- en: Accessing the model
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问模型
- en: 'The next sections of the code will download the Visual Recognition model to
    be used and then load it into memory. Downloading the model may take a few minutes
    the first time, but it only needs to be downloaded on the first run:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的下一部分将下载要使用的视觉识别模型并将其加载到内存中。第一次下载模型可能需要几分钟，但只需要在第一次运行时下载：
- en: '[PRE11]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Detection
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测
- en: 'The next part of the code runs the image using the TensorFlow object detection
    API. It will provide the coordinates of the box as an array of the edge positions
    (top, left, bottom, and right). It will then crop and save the images based on
    the boxes. In order for us to crop the correct area we need to transform the coordinates
    from percentages to pixels by multiplying the values by the width and height:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的下一部分运行图像使用TensorFlow对象检测API。它将提供边框位置的坐标作为边缘位置的数组（顶部、左侧、底部和右侧）。然后根据这些框裁剪并保存图像。为了我们能够裁剪正确的区域，我们需要通过乘以宽度和高度将坐标从百分比转换为像素：
- en: '[PRE12]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: After we have saved the image portions, we can pass each of them to Watson for
    classification.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们保存图像部分之后，我们可以将每个部分传递给Watson进行分类。
- en: 'Notice the use of the variables we set previously (`MAX_NUMBER_OF_BOXES` and
    `MINIMUM_CONFIDENCE`) in the following code:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 注意以下代码中使用了我们之前设置的变量（`MAX_NUMBER_OF_BOXES`和`MINIMUM_CONFIDENCE`）：
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Classification and output
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类和输出
- en: Assuming you perform the previously outlined environmental checks and setups
    outlined earlier in this chapter, all of the code up to this point should run
    flawlessly without producing any errors. The next section of code was updated
    from the original version of the project offered on GitHub due to changes IBM
    made to the newer version of the API.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你执行了本章前面概述的环境检查和设置，到目前为止的所有代码应该能够完美运行，不会产生任何错误。下一部分代码是从GitHub上提供的项目的原始版本更新的，因为IBM对API的新版本进行了更改。
- en: If you use the notebook code provided with this book, the updates have already
    been made for you.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用这本书提供的笔记本代码，更新已经为你做好了。
- en: Finally, the next code section receives the results or the classifications back
    from the Watson Visual Recognition service into an object named `results`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，下一段代码接收从Watson视觉识别服务返回的结果或分类，并将其存储在名为`results`的对象中。
- en: 'From that information, a label is then constructed, and a rectangle shape is
    drawn around each object that was detected within the source image file:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 从那个信息中，构建了一个标签，并在源图像文件中检测到的每个对象周围绘制了一个矩形形状：
- en: '[PRE14]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: If you examine the `results` object more closely (try using the Python `type`
    command on it), you will see that the results object is a Python dictionary object.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更仔细地检查`results`对象（尝试使用Python的`type`命令），你会看到结果对象是一个Python字典对象。
- en: A Python dictionary object is similar to a list in that it is a collection of
    objects.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Python字典对象与列表类似，因为它是一个对象的集合。
- en: Now try adding `print(results)` to the notebook code and you'll get a glimpse
    of the raw output returned in results.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试在笔记本代码中添加`print(results)`，你将看到结果中返回的原始输出的一瞥。
- en: 'Using the `print(results)` command, the actual output is shown in the following
    screenshot:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`print(results)`命令，实际输出显示在以下屏幕截图：
- en: '![](img/b7b06b27-feff-47a6-82bc-e7ae5082476b.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b7b06b27-feff-47a6-82bc-e7ae5082476b.png)'
- en: Objects detected
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测到的对象
- en: 'Finally we are ready to use, `matplotlib`, `plt.show()` to display the current
    image that we are working on:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们准备好使用`matplotlib`，`plt.show()`来显示我们正在工作的当前图像：
- en: '[PRE15]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can now finally see the output of the project. In this example, our image
    was of a horse, and we can see that the Watson Visual Recognition service correctly
    detected and labeled the object as a pinto horse:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在终于可以看到项目的输出了。在这个例子中，我们的图像是一匹马，我们可以看到Watson视觉识别服务正确地检测并标记了这个对象为斑点马：
- en: '![](img/71d2361b-c83c-4c62-add9-cee100a4e2ac.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/71d2361b-c83c-4c62-add9-cee100a4e2ac.png)'
- en: Now the fun part
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现在是好玩的部分
- en: Now comes the fun part. You can download any number of files from almost anywhere
    to test the application (or create your own). I used several images and found
    that Watson was pretty accurate.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是最好玩的部分。你可以从几乎任何地方下载任意数量的文件来测试应用程序（或创建你自己的）。我使用了几个图像，发现沃森相当准确。
- en: The first image used was correctly detected as a motorcycle, the second (an
    image showing two vintage cars) was close in that Watson detected one of the cars
    as a car but the other was detected as a light truck.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的第一张图像被正确地检测为摩托车，第二张（显示两辆复古汽车的图像）在沃森检测到其中一辆汽车为汽车，而另一辆被检测为轻型卡车方面很接近。
- en: 'The results of the final image we already mentioned: Watson not only correctly
    detected a horse but also labeled its breed: pinto.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到的最后一张图像的结果：沃森不仅正确地检测到一匹马，而且还标记了它的品种：斑马。
- en: 'The following screenshot shows the three different images and their respective
    results:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了三张不同的图像及其相应的结果：
- en: '![](img/11d3605d-8eed-4e7f-af0e-79b35559d38c.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/11d3605d-8eed-4e7f-af0e-79b35559d38c.png)'
- en: Save and share your work
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存并分享你的工作
- en: 'As always, once you have a working project notebook, you can click on File
    then Save to save your work. The next step is to share your notebook by clicking
    on the Share icon, as shown in the following screenshot):'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，一旦你有一个可工作的项目笔记本，你可以点击文件然后保存来保存你的工作。下一步是通过点击共享图标来共享你的笔记本，如下面的截图所示）：
- en: '![](img/175a785c-318a-4faa-9a0a-8f43d52c38ca.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/175a785c-318a-4faa-9a0a-8f43d52c38ca.png)'
- en: 'From there, you can select the way you want to share your notebook:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，你可以选择你想要分享笔记本的方式：
- en: '![](img/426faef0-dc94-41ef-90b1-1cde9e209233.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/426faef0-dc94-41ef-90b1-1cde9e209233.png)'
- en: You should get into the habit of documenting your notebooks with Markdown cell
    content before sharing it. You will be surprised how much better your work will
    be received if you add commentary and perspective to each cell.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该养成在分享之前用Markdown单元格内容记录你的笔记本的习惯。你会发现，如果你为每个单元格添加注释和观点，你的工作将得到更好的接受。
- en: 'Finally, when you view your project notebooks (see the following screenshot),
    note the SHARED and STATUS icons. You can publish your notebook to various target
    environments, such as GitHub:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当你查看你的项目笔记本（见下面的截图）时，注意SHARED和STATUS图标。你可以将你的笔记本发布到各种目标环境中，例如GitHub：
- en: '![](img/d53062b6-b401-4d3e-ba45-7f0b8e9f37d8.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d53062b6-b401-4d3e-ba45-7f0b8e9f37d8.png)'
- en: Summary
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we started with an introduction to the concepts of deep learning
    and looked at the basics of using TensorFlow libraries and neural networks.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们从一个关于深度学习概念的介绍开始，然后探讨了使用TensorFlow库和神经网络的基礎。
- en: We then walked through two IBM Watson Studio projects to illustrate how to build
    both a neural network and an object detection project using the tools and services
    provided on IBM Cloud.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着浏览了两个IBM Watson Studio项目，以展示如何使用IBM云上提供的工具和服务构建神经网络和对象检测项目。
- en: In the next chapter, we will create a facial expression platform on IBM Cloud.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将在IBM云上创建一个面部表情平台。
