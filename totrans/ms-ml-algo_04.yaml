- en: Bayesian Networks and Hidden Markov Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯网络和隐马尔可夫模型
- en: In this chapter, we're going to introduce the basic concepts of Bayesian models,
    which allow working with several scenarios where it's necessary to consider uncertainty
    as a structural part of the system. The discussion will focus on static (time-invariant)
    and dynamic methods that can be employed where necessary to model time sequences.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍贝叶斯模型的基本概念，这些概念允许在需要将不确定性作为系统结构部分考虑的多个场景中工作。讨论将集中在静态（时间不变）和动态方法，这些方法在必要时可以用来建模时间序列。
- en: 'In particular, the chapter covers the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，本章涵盖了以下主题：
- en: Bayes' theorem and its applications
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯定理及其应用
- en: Bayesian networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯网络
- en: Sampling from a Bayesian network using direct methods and **Markov chain Monte
    Carlo** (**MCMC**) ones (Gibbs and Metropolis-Hastings samplers)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用直接方法和**马尔可夫链蒙特卡洛**（**MCMC**）（Gibbs和Metropolis-Hastings采样器）从贝叶斯网络中采样
- en: Modeling a Bayesian network with PyMC3
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyMC3建模贝叶斯网络
- en: '**Hidden Markov Models** (**HMMs**)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐马尔可夫模型**（**HMMs**）'
- en: Examples with hmmlearn
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用hmmlearn的示例
- en: Conditional probabilities and Bayes' theorem
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件概率和贝叶斯定理
- en: 'If we have a probability space *S* and two events *A* and *B*, the probability
    of *A* given *B* is called **conditional probability**, and it''s defined as:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个概率空间 *S* 和两个事件 *A* 和 *B*，事件 *A* 在给定 *B* 的概率被称为**条件概率**，其定义为：
- en: '![](img/352da6fc-79b9-478c-acef-eac9462996be.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/352da6fc-79b9-478c-acef-eac9462996be.png)'
- en: 'As *P(A, B)* = *P(B, A)*, it''s possible to derive **Bayes'' theorem**:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 *P(A, B)* = *P(B, A)*，可以推导出**贝叶斯定理**：
- en: '![](img/c34fa3ad-5cf8-4d3d-80f1-768034c0d1a3.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c34fa3ad-5cf8-4d3d-80f1-768034c0d1a3.png)'
- en: 'This theorem allows expressing a conditional probability as a function of the
    opposite one and the two marginal probabilities *P(A)* and *P(B)*. This result
    is fundamental to many machine learning problems, because, as we''re going to
    see in this and in the next chapters, normally it''s easier to work with a conditional
    probability in order to get the opposite, but it''s hard to work directly from
    the latter. A common form of this theorem can be expressed as:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定理允许将条件概率表示为对立概率和两个边缘概率 *P(A)* 和 *P(B)* 的函数。这个结果对于许多机器学习问题来说是基本的，因为我们将在本章和下一章中看到，通常更容易通过条件概率来获取对立概率，但直接从后者开始工作却很困难。这个定理的常见形式可以表示为：
- en: '![](img/d7d71973-5b65-4bbc-8eef-433b4cd5950d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d7d71973-5b65-4bbc-8eef-433b4cd5950d.png)'
- en: Let's suppose that we need to estimate the probability of an event *A* given
    some observations *B*, or using the standard notation, **the posterior probability
    of A**; the previous formula expresses this value as proportional to the term
    *P(A)*, which is the marginal probability of *A*, called **prior probability**,
    and the conditional probability of the observations *B* given the event *A*. *P(B|A)*
    is called **likelihood**, and defines how event *A* is likely to determine *B*.
    Therefore, we can summarize the relation as *posterior probability ∝ likelihood ·
    prior probability*. The proportion is not a limitation, because the term *P(B)*
    is always a normalizing constant that can be omitted. Of course, the reader must
    remember to normalize *P(A|B)* so that its terms always sum up to one.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '假设我们需要估计给定一些观察结果 *B* 的事件 *A* 的概率，或者使用标准符号，**A的后验概率**；前面的公式将这个值表示为与项 *P(A)*
    成比例，这是 *A* 的边缘概率，称为**先验概率**，以及观察结果 *B* 在事件 *A* 给定下的条件概率。*P(B|A)* 被称为**似然函数**，它定义了事件
    *A* 如何可能决定 *B*。因此，我们可以总结关系为*后验概率 ∝ 似然函数 · 先验概率*。比例不是一个限制，因为项 *P(B)* 总是一个归一化常数，可以省略。当然，读者必须记住归一化
    *P(A|B)*，使其项总是加起来等于一。 '
- en: 'This is a key concept of Bayesian statistics, where we don''t directly trust
    the prior probability, but we reweight it using the likelihood of some observations.
    As an example, we can think to toss a coin 10 times (event *A*). We know that
    *P(A) = 0.5* if the coin is fair. If we''d like to know what the probability is
    to get 10 heads, we could employ the Binomial distribution obtaining *P(10 heads)
    = 0.5^k*; however, let''s suppose that we don''t know whether the coin is fair
    or not, but we suspect it''s loaded with a prior probability *P(Loaded) = 0.7*
    in favor of tails. We can define a complete prior probability *P(Coin status)*
    using the indicator functions:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d017c7ab-85b8-4687-8cea-ce1f6222e7c9.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: Where *P(Fair) = 0.5* and *P(Loaded) = 0.7*, the indicator *I[Coin=Fair]* is
    equal to 1 only if the coin is fair, and 0 otherwise. The same happens with *I[Coin=Loaded]* when
    the coin is loaded. Our goal now is to determine the posterior probability *P(Coin
    status|B[1], B[2], ..., **B[n])* to be able to confirm or to reject our hypothesis.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s imagine to observe *n = 10* events with *B[1] = Head* and *B[2], ..., B[n] =
    Tail*. We can express the probability using the binomial distribution:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/845c235e-2666-4685-88fe-65cdb967a8ba.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
- en: 'After simplifying the expression, we get:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/48d546d0-7d6d-4bb8-8824-202451d938da.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: We still need to normalize by dividing both terms by 0.083 (the sum of the two
    terms), so we get the final posterior probability *P(Coin status|B[1], B[2], ..., **Bn)
    = 0.04I[Fair] + 0.96I[Loaded]*. This result confirms and strengthens our hypothesis.
    The probability of a loaded coin is now about 96%, thanks to the sequence of nine
    tail observations after one head.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: This example was presented to show how the data (observations) is plugged into
    the Bayesian framework. If the reader is interested in studying these concepts
    in more detail, in *Introduction to Statistical Decision Theory*, *Pratt J.*,
    *Raiffa H.*, *Schlaifer R.*, *The MIT Press*,it's possible to find many interesting
    examples and explanations; however, before introducing Bayesian networks, it's
    useful to define two other essential concepts.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'The first concept is called **conditional independence**, and it can be formalized
    considering two variables *A* and *B*, which are conditioned to a third one, *C*.
    We say that *A* and *B* are conditionally independent given *C* if:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36bb9203-b429-4355-a8dc-85614c716870.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s suppose we have an event *A* that is conditioned to a series of
    causes *C[1], C[2], ..., C[n]*; the conditional probability is, therefore, *P(A|C[1],
    C[2], ..., C[n])*. Applying Bayes'' theorem, we get:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe21f59c-5b35-43b8-8e36-a87618f446de.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: 'If there is conditional independence, the previous expression can be simplified
    and rewritten as:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/981fd6f3-7f95-411f-8c54-81cb045249d8.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
- en: This property is fundamental in Naive Bayes classifiers, where we assume that
    the effect produced by a cause does not influence the other causes. For example,
    in a spam detector, we could say that the length of the mail and the presence
    of some particular keywords are independent events, and we only need to compute
    *P(Length|Spam)* and *P(Keywords|Spam)* without considering the joint probability
    *P(Length, Keywords|Spam)*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个属性在朴素贝叶斯分类器中是基本的，我们假设原因产生的效果不会影响其他原因。例如，在垃圾邮件检测器中，我们可以说邮件的长度和某些特定关键词的存在是独立事件，我们只需要计算
    *P(Length|Spam)* 和 *P(Keywords|Spam)*，而不需要考虑联合概率 *P(Length, Keywords|Spam)*。
- en: 'Another important element is the **chain rule** of probabilities. Let''s suppose
    we have the joint probability *P(X[1], X[2], ..., X[n])*. It can be expressed
    as:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要元素是概率的 **链式法则**。假设我们有一个联合概率 *P(X[1], X[2], ..., X[n])*。它可以表示为：
- en: '![](img/107285da-ab3d-4be3-a4b0-d680ff35d2cd.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/107285da-ab3d-4be3-a4b0-d680ff35d2cd.png)'
- en: 'Repeating the procedure with the joint probability on the right side, we get:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 重复使用右侧联合概率的步骤，我们得到：
- en: '![](img/2fe5a7d2-8909-4da8-9322-2582f45b29a0.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2fe5a7d2-8909-4da8-9322-2582f45b29a0.png)'
- en: In this way, it's possible to express a full joint probability as the product
    of hierarchical conditional probabilities, until the last term, which is a marginal
    distribution. We are going to use this concept extensively in the next paragraph
    when exploring Bayesian networks.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式，我们可以将完整的联合概率表示为分层条件概率的乘积，直到最后一个项，它是一个边缘分布。在下一段探索贝叶斯网络时，我们将广泛使用这个概念。
- en: Bayesian networks
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯网络
- en: 'A **Bayesian network** is a probabilistic model represented by a direct acyclic
    graph *G = {V, E}*, where the vertices are random variables *X[i]*, and the edges
    determine a conditional dependence among them. In the following diagram, there''s
    an example of simple Bayesian networks with four variables:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**贝叶斯网络** 是一个由直接无环图 *G = {V, E}* 表示的概率模型，其中顶点是随机变量 *X[i]*，边确定它们之间的条件依赖关系。在下面的图中，有一个包含四个变量的简单贝叶斯网络的例子：'
- en: '![](img/cae2f7b1-4b9f-4cc2-b225-0e12772b4866.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/cae2f7b1-4b9f-4cc2-b225-0e12772b4866.png)'
- en: Example of Bayesian network
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯网络示例
- en: 'The variable *x[4]* is dependent on *x[3]*, which is dependent on *x[1]* and *x[2]*. To
    describe the network, we need the marginal probabilities *P(x[1])* and *P(x[2])*
    and the conditional probabilities *P(x[3]|x[1],x[2])* and *P(x[4]|x[3])*. In fact,
    using the chain rule, we can derive the full joint probability as:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 *x[4]* 依赖于 *x[3]*，而 *x[3]* 依赖于 *x[1]* 和 *x[2]*。为了描述这个网络，我们需要边缘概率 *P(x[1])*
    和 *P(x[2])* 以及条件概率 *P(x[3]|x[1],x[2])* 和 *P(x[4]|x[3])*。实际上，使用链式法则，我们可以推导出完整的联合概率如下：
- en: '![](img/c97c045a-48c4-48c0-88f0-bd904ce463c6.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c97c045a-48c4-48c0-88f0-bd904ce463c6.png)'
- en: 'The previous expression shows an important concept: as the graph is direct
    and acyclic, each variable is conditionally independent of all other variables
    that are not successors given its predecessors. To formalize this concept, we
    can define the function *Predecessors(x[i])*, which returns the set of nodes that
    influence *x[i]* directly, for example, *Predecessors(x[3]) = {x[1],x[2]}* (we
    are using lowercase letters, but we are considering the random variable, not a
    sample). Using this function, it''s possible to write a general expression for
    the full joint probability of a Bayesian network with *N* nodes:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的表达式展示了一个重要的概念：由于图是直接且无环的，每个变量在给定其前驱的情况下，条件独立于所有其他非后继变量。为了形式化这个概念，我们可以定义函数
    *Predecessors(x[i])*，该函数返回直接影响 *x[i]* 的节点集合，例如，*Predecessors(x[3]) = {x[1],x[2]}*（我们使用小写字母，但考虑的是随机变量，而不是样本）。使用这个函数，我们可以为具有
    *N* 个节点的贝叶斯网络的完整联合概率写出一个通用表达式：
- en: '![](img/303e7bb6-83c4-48be-afea-573888168eef.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/303e7bb6-83c4-48be-afea-573888168eef.png)'
- en: The general procedure to build a Bayesian network should always start with the
    first causes, adding their effects one by one, until the last nodes are inserted
    into the graph. If this rule is not respected, the resulting graph can contain
    useless relations that can increase the complexity of the model. For example,
    if *x[4]* is caused indirectly by both *x[1]* and *x[2]*, therefore adding the
    edges *x[1] → x[4]* and *x[2] → x[4]* could seem a good modeling choice; however,
    we know that the final influence on *x[4]* is determined only by the values of
    *x*[*3*, ]whose probability must be conditioned on *x[1]* and *x[2]*, hence we
    can remove the spurious edges. I suggest reading *Introduction to Statistical
    Decision Theory, Pratt J., Raiffa H., Schlaifer R., The MIT Press*to learn many
    best practices that should be employed in this procedure.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Sampling from a Bayesian network
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performing a direct inference on a Bayesian network can be a very complex operation
    when the number of variables and edges is high. For this reason, several sampling
    methods have been proposed. In this paragraph, we are going to show how to determine
    the full joint probability sampling from a network using a direct approach, and
    two MCMC algorithms.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start considering the previous network and, for simplicity, let''s assume
    to have only *Bernoulli* distributions. *X[1]* and *X[2]* are modeled as:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb8c8451-da95-42e4-923a-d096f4041bc0.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: 'The conditional distribution *X[3]* is defined as:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/789d0fe3-5573-429b-a2e3-37a4043b7fed.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: 'While the conditional distribution *X[4]* is defined as:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c964debc-3b61-4b6d-9b5a-7d68f7f4a514.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: We can now use a direct sampling to estimate the full joint probability *P(x[1],
    x[2], x[3], x[4])* using the chain rule previously introduced.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Direct sampling
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With **direct sampling**, our goal is to approximate the full joint probability
    through a sequence of samples drawn from each conditional distribution. If we
    assume that the graph is well-structured (without unnecessary edges) and we have
    *N* variables, the algorithm is made up of the following steps:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the variable *N[Samples]*.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize a vector *S* with shape *(N, N[Samples])*.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize a frequency vector *F[Samples]* with shape *(N, N[Samples])*. In
    Python, it's better to employ a dictionary where the key is a combination *(x[1],
    x[2], x[3], ..., x[N])*.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For *t=1* to *N*[*Samples*:]
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sample from *P(X[i]|Predecessors(X[i]))*
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Store the sample in *S[i, t]*
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If *F[Samples]* contains the sampled tuple *S[:, t]*:'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**F[Samples][S[:, t]] += 1**'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Else:'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '*F[Samples][**S[:, t]] = 1* (both these operations are immediate with Python
    dictionaries)'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a vector *P[Sampled]* with shape *(**N, 1)*.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *P[Sampled][i, 0] = F[Samples][**i]/N*.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From a mathematical viewpoint, we are first creating a frequency vector *F[Samples](x[1],
    x[2], x[3], ..., x[N]; N[Samples]**)* and then we approximate the full joint probability
    considering *N[Samples] → ∞*:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66ba24b0-7188-465c-925c-17d0b4d179e2.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: Example of direct sampling
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can now implement this algorithm in Python. Let''s start by defining the
    sample methods using the NumPy function `np.random.binomial(1, p)`, which draws
    a sample from a *Bernoulli* distribution with probability `p`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'At this point, we can implement the main cycle. As the variables are Boolean,
    the total number of probabilities is 16, so we set `Nsamples` to `5000` (smaller
    values are also acceptable):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When the sampling is complete, it''s possible to extract the full joint probability:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can also query the model. For example, we could be interested in *P(X[4]=True)*.
    We can do this by looking for all the elements where *X[4]=True*, and summing
    up the relative probabilities:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This value is coherent with the definition of *X[4]*, which is always *p >=
    0.5*. The reader can try to change the values and repeat the simulation.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: A gentle introduction to Markov chains
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to discuss the MCMC algorithms, it's necessary to introduce the concept
    of Markov chains. In fact, while the direct sample method draws samples without
    any particular order, the MCMC strategies draw a sequence of samples according
    to a precise transition probability from a sample to the following one.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider a time-dependent random variable *X(t)*, and let''s assume
    a discrete time sequence **X[1]**, **X[2]**, ..., **X[t]**, **X[t+1]**, ... where
    **X[t]** represents the value assumed at time *t*. In the following diagram, there''s
    a schematic representation of this sequence:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/69b55183-7574-40b2-9b1e-96e2d4cf5a3e.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
- en: Structure of a generic Markov chain
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'We can suppose to have *N* different states *s[i]* for *i=1..N*, therefore
    it''s possible to consider the probability *P(X[t]=s[i]|X[t-1]=s[j], ..., X[1]=s[p])*.
    *X(t)* is defined as a **first-order Markov process** if:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4414956f-285c-4f5d-bf7a-7de1a5f60c52.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
- en: 'In other words, in a Markov process (from now on, we omit *first-order*, even
    if there are cases when it''s useful to consider more previous states), the probability
    that *X(t)* is in a certain state depends only on the state assumed in the previous
    time instant. Therefore, we can define a **transition probability **for every
    couple *i*, *j*:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a16ad93b-a206-445b-9ffb-42f3407edb16.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
- en: 'Considering all the couples *(i, j)*, it''s also possible to build a transition
    probability matrix *T(i, j) = P(i → j)*. The marginal probability that *X[t]=s[i]*
    using a standard notation is defined as:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/17cc4835-7ef7-4686-a2e4-124c42e4a982.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: 'At this point, it''s easy to prove (**Chapman-Kolmogorov** equation) that:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee16d959-98d0-4b92-9ceb-7a345491283c.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
- en: 'In the previous expression, in order to compute *π[i](t+1)*, we need to sum
    over all possible previous states, considering the relative transition probability.
    This operation can be rewritten in matrix form, using a vector *π(t)* containing
    all states and the transition probability matrix *T* (the uppercase superscript
    *T* means that the matrix is transposed). The evolution of the chain can be computed
    recursively:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的表达式中，为了计算 *π[i](t+1)*，我们需要对所有可能的前一个状态进行求和，考虑相对转移概率。这个操作可以用矩阵形式重写，使用包含所有状态的向量
    *π(t)* 和转移概率矩阵 *T*（大写上标 *T* 表示矩阵是转置的）。链的演变可以通过递归计算：
- en: '![](img/d9526323-5850-4106-aa9d-b2bddc9343fa.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d9526323-5850-4106-aa9d-b2bddc9343fa.png)'
- en: 'For our purposes, it''s important to consider Markov chains that are able to
    reach a *stationary distribution* *π[s]*:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的来说，考虑能够达到 *stationary distribution* *π[s]* 的马尔可夫链是很重要的：
- en: '![](img/66b29160-1d3f-4c7c-ae04-157fcd2ef634.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/66b29160-1d3f-4c7c-ae04-157fcd2ef634.png)'
- en: In other words, the state does not depend on the initial condition *π(1)*, and
    it's no longer able to change. The stationary distribution is unique if the underlying
    Markov process is *ergodic*. This concept means that the process has the same
    properties if averaged over time (which is often impossible), or averaged vertically (freezing
    the time) over the states (which is simpler in the majority of cases).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，状态不依赖于初始条件 *π(1)*，并且它不再能够改变。如果基础马尔可夫过程是 *ergodic* 的，那么稳态分布是唯一的。这个概念意味着，如果平均时间（这通常是不可能的）或垂直平均（冻结时间）在状态上（在大多数情况下这更简单），过程具有相同的属性。
- en: 'The process of ergodicity for Markov chains is assured by two conditions. The
    first is aperiodicityfor all states, which means that it is impossible to find
    a positive number *p* so that the chain returns in the same state sequence after
    a number of instants equal to a multiple of *p*. The second condition is that
    all states must be positive recurrent: this means that, given a random variable *N[instants]**(i)*,
    describing the number of time instants needed to return to the state *s[i]*, *E[N[instants](i)]
    < ∞*; therefore, potentially, all the states can be revisited in a finite time.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链的遍历过程由两个条件保证。第一个条件是所有状态都是非周期的，这意味着不可能找到一个正数 *p*，使得链在经过等于 *p* 的倍数个瞬间后回到相同的状态序列。第二个条件是所有状态都必须是正
    recurrent 的：这意味着，给定一个随机变量 *N[instants]**(i)*，描述了返回到状态 *s[i]* 所需的时间瞬间数，*E[N[instants](i)]
    < ∞*；因此，理论上，所有状态都可以在有限的时间内重新访问。
- en: 'The reason why we need the ergodicity condition, and hence the existence of
    a unique stationary distribution, is that we are considering the sampling processes
    modeled as Markov chains, where the next value is sampled according to the current
    state. The transition from one state to another is done in order to find better
    samples, as we''re going to see in the Metropolis-Hastings sampler, where we can
    also decide to reject a sample and keep the chain in the same state. For this
    reason, we need to be sure that the algorithms converge to the unique stable distribution
    (that approximates the real full joint distribution of our Bayesian network).
    It''s possible to prove that a chain always reaches a stationary distribution
    if:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要遍历性条件，以及因此存在唯一稳态分布的原因，是因为我们正在考虑将采样过程建模为马尔可夫链，其中下一个值是根据当前状态采样的。从一个状态到另一个状态的转换是为了找到更好的样本，正如我们将在
    Metropolis-Hastings 采样器中看到的那样，我们也可以选择拒绝一个样本并保持链处于相同的状态。因此，我们需要确保算法收敛到唯一的稳定分布（该分布近似于我们的贝叶斯网络的真实完整联合分布）。可以证明，如果：
- en: '![](img/ec1e6164-4511-457d-9598-93c25d184f80.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ec1e6164-4511-457d-9598-93c25d184f80.png)'
- en: The previous equation is called detailed balance, and implies the reversibility
    of the chain. Intuitively, it means that the probability of finding the chain
    in the state *A* times the probability of a transition to the state *B* is equal
    to the probability of finding the chain in the state *B* times the probability
    of a transition to *A*.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的方程被称为详细平衡，它意味着链的可逆性。直观地说，这意味着链处于状态 *A* 的概率乘以转移到状态 *B* 的概率等于链处于状态 *B* 的概率乘以转移到
    *A* 的概率。
- en: For both methods that we are going to discuss, it's possible to prove that they
    satisfy the previous condition, and therefore their convergence is assured.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们将要讨论的两种方法，可以证明它们满足上述条件，因此它们的收敛性得到保证。
- en: Gibbs sampling
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 吉布斯抽样
- en: 'Let''s suppose that we want to obtain the full joint probability for a Bayesian
    network *P(x[1], x[2], x[3], ..., x[N]**)*; however, the number of variables is
    large and there''s no way to solve this problem easily in a closed form. Moreover,
    imagine that we would like to get some marginal distribution, such as *P(x[2])*,
    but to do so we should integrate the full joint probability, and this task is
    even harder. Gibbs sampling allows approximating of all marginal distributions
    with an iterative process. If we have *N* variables, the algorithm proceeds with
    the following steps:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the variable *N[Iterations]*
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize a vector *S* with shape *(N, N[Iterations])*
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Randomly initialize *x[1]^((0)), x[2]^((0)), ..., x[N]^((0))* (the superscript
    index is referred to the iteration)
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *t=1* to *N[Iterations]*:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sample *x[1]^((t))* from *p(x[1]|x[2]^((t-1)), x[3]^((t-1)), ..., x[N]^((t-1)))*
    and store it in *S[0, t]*
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sample *x[2]^((t))* from *p(**x[2]|x[1]^((t)), x[3]^((t-1)), ..., x[N]^((t-1))**)* and
    store it in *S[1, t]*
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sample *x[3]^((t))* from *p(**x[3]|x[1]^((t)), x[2]^((t)), ..., x[N]^((t-1))**)* and
    store it in *S[2, t]*
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '...'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sample *x[N]^((t))* from *p(**x[N]|x[1]^((t)), x[2]^((t)), ..., x[N-1]^((t))**)* and
    store it in *S[N-1, t]*
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: At the end of the iterations, vector *S* will contain *N*[*Iterations* ]samples
    for each distribution. As we need to determine the probabilities, it's necessary
    to proceed like in the direct sampling algorithm, counting the number of single
    occurrences and normalizing dividing by *N[Iterations]*. If the variables are
    continuous, it's possible to consider intervals, counting how many samples are
    contained in each of them.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: For small networks, this procedure is very similar to direct sampling, except
    that when working with very large networks, the sampling process could become
    slow; however, the algorithm can be simplified after introducing the concept of
    the Markov blanket of *X[i]*, which is the set of random variables that are predecessors,
    successors, and successors' predecessors of *X[i]* (in some books, they use the
    terms *parents* and *children*). In a Bayesian network, a variable *X[i]* is a
    conditional independent of all other variables given its Markov blanket. Therefore,
    if we define the function *MB(X[i])*, which returns the set of variables in the
    blanket, the generic sampling step can be rewritten as *p(x[i]|MB(X[i]))*, and
    there's no more need to consider all the other variables.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this concept, let''s consider the network shown in the following
    diagram:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f40b1fa-6e12-401a-a769-3bd4b0438600.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
- en: Bayesian network for the Gibbs sampling example
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'The Markov blankets are:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '*MB(X[1])* = *{ X[2], X[3] }*'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MB(X[2])* = *{ X[1, ]X[3], X[4] }*'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MB(X[3])* = *{ X[1, ]X[2], X[4], X[5] }*'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MB(X[4])* = *{ X[3] }*'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MB(X[5])* = *{ X[3] }*'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MB(X[6])* = *{ X[2] }*'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In general, if *N* is very large, the cardinality of *|MB(X[i])| << N*, thus
    simplifying the process (the *vanilla* Gibbs sampling needs *N-1* conditions for
    each variable). We can prove that the Gibbs sampling generates samples from a
    Markov chain that is in detailed balance:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，如果 *N* 非常大，那么 *|MB(X[i])|* 的基数远小于 *N*，从而简化了过程（*vanilla* 吉布斯采样需要对每个变量有
    *N-1* 个条件）。我们可以证明吉布斯采样生成的样本来自一个处于详细平衡状态的马尔可夫链：
- en: '![](img/30105cca-76a4-4cad-bf32-b2c541feed6f.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/30105cca-76a4-4cad-bf32-b2c541feed6f.png)'
- en: 'Therefore, the procedure converges to the unique stationary distribution. This
    algorithm is quite simple; however, its performance is not excellent, because
    the random walks are not tuned up in order to explore the right regions of the
    state-space, where the probability to find good samples is high. Moreover, the
    trajectory can also return to bad states, slowing down the whole process. An alternative
    (also implemented by PyMC3 for continuous random variables) is the **No-U-Turn**
    algorithm, which we don''t discuss in this book. The reader interested in this
    topic can find a full description in *The* *No-U-Turn Sampler: Adaptively Setting
    Path Lengths in Hamiltonian Monte Carlo*, *Hoffmann M. D.*, *Gelman A.*, *arXiv:1111.4246*.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，该过程收敛到唯一的平稳分布。这个算法相当简单；然而，其性能并不出色，因为随机游走没有被调整以探索状态空间中的正确区域，在这些区域找到好样本的概率很高。此外，轨迹也可能返回到不良状态，从而减慢整个过程。一个替代方案（也被
    PyMC3 用于连续随机变量）是 **No-U-Turn** 算法，我们在这本书中不讨论。对这一主题感兴趣的读者可以在 *The No-U-Turn Sampler:
    Adaptively Setting Path Lengths in Hamiltonian Monte Carlo* 一书中找到完整的描述，作者为 *Hoffmann
    M. D.*，*Gelman A.*，*arXiv:1111.4246*。'
- en: Metropolis-Hastings sampling
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Metropolis-Hastings 采样
- en: We have seen that the full joint probability distribution of a Bayesian network
    *P(x[1], x[2], x[3], ..., x[N]**)* can become intractable when the number of variables
    is large. The problem can become even harder when it's needed to marginalize it
    in order to obtain, for example, *P(x[i])*, because it's necessary to integrate
    a very complex function. The same problem happens when applying the Bayes' theorem
    in simple cases. Let's suppose we have the expression *p(A|B) = K · P(B|A)P(A)*.
    I've expressly inserted the normalizing constant *K*, because if we know it, we
    can immediately obtain the posterior probability; however, finding it normally
    requires integrating *P(B|A)P(A)*, and this operation can be impossible in closed
    form.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，当变量数量很大时，贝叶斯网络的完整联合概率分布 *P(x[1], x[2], x[3], ..., x[N]*) 可能变得难以处理。当需要对其进行边缘化以获得，例如，*P(x[i]*)
    时，问题可能变得更加困难，因为这需要积分一个非常复杂的功能。在简单情况下应用贝叶斯定理时也会出现相同的问题。假设我们有表达式 *p(A|B) = K · P(B|A)P(A)*。我明确地插入了归一化常数
    *K*，因为我们知道它，我们可以立即获得后验概率；然而，通常需要找到它需要积分 *P(B|A)P(A)*，而这个操作可能是无法用封闭形式表示的。
- en: The Metropolis-Hastings algorithm can help us in solving this problem. Let's
    imagine that we need to sample from *P(x[1], x[2], x[3], ..., x[N]**)*, but we
    know this distribution up to a normalizing constant, so *P(x[1], x[2], x[3], ...,
    x[N]) ∝ g(x[1], x[2], x[3], ..., x[N])*. For simplicity, from now on we collapse
    all variables into a single vector, so *P(x) ∝ g(x)*.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Metropolis-Hastings 算法可以帮助我们解决这个问题。让我们想象一下，我们需要从 *P(x[1], x[2], x[3], ..., x[N]*)
    中采样，但我们只知道这个分布直到归一化常数，所以 *P(x[1], x[2], x[3], ..., x[N]) ∝ g(x[1], x[2], x[3],
    ..., x[N]*)。为了简化，从现在开始我们将所有变量合并成一个单向量，所以 *P(x) ∝ g(x)*。
- en: Let's take another distribution *q(x'|x^((i-1)))*, which is called **candidate-generating
    distribution**. There are no particular restrictions on this choice, only that
    *q* is easy to sample. In some situations, *q* can be chosen as a function very
    similar to the distribution *p(x)*, which is our target, while in other cases,
    it's possible to use a normal distribution with mean equal to *x^((i-1))*. As
    we're going to see, this function acts as a proposal-generator, but we're not
    obliged to accept all the samples drawn from it therefore, potentially any distribution
    with the same domain of *P(X)* can be employed. When a sample is accepted, the
    Markov chain transitions to the next state, otherwise it remains in the current
    one. This decisional process is based on the idea that the sampler must explore
    the most important state-space regions and discard the ones where the probability
    to find good samples is low.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm proceeds with the following steps:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the variable *N[Iterations]*
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize *x^((0))* randomly
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *t=1* to *N**[Iterations]*:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw a candidate sample *x'* from *q(x'|x^((i-1))**)*
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the following value:![](img/e2dfa594-aaac-4af2-a7b0-133f55e1fd30.png)
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If *α ≥ 1*:'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Accept the sample *x^((t)) = x'*
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Else if *0 < α < 1*:'
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Accept the sample *x^((t))** = x'* with probability *α*; or
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Reject the sample *x'* setting *x^((t)) = x^((t-1))* with probability *1 - **α*
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It's possible to prove (the proof will be omitted, but it's available in *Markov
    Chain Monte Carlo and Gibbs Sampling, **Walsh B., Lecture Notes for EEB 596z*)
    that the transition probability of the Metropolis-Hastings algorithm satisfies
    the detailed balance equation, and therefore the algorithm converges to the true
    posterior distribution.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Example of Metropolis-Hastings sampling
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can implement this algorithm to find the posterior distribution *P(A|B)*
    given the product of *P(B|A)* and *P(A)*, without considering the normalizing
    constant that requires a complex integration.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s suppose that:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/54a4353b-48d1-4357-90cd-01824204939f.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, the resulting *g(x)* is:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c55f8193-4471-4ed9-907c-e98992b1a0f5.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: To solve this problem, we adopt the random walk Metropolis-Hastings, which consists
    of choosing *q ∼ Normal(μ=x^((t-1)))*. This choice allows simplifying the value
    *α*, because the two terms *q(x^((t-1))|x')* and *q(x'|x^((t-1)))* are equal (thanks
    to the symmetry around the vertical axis passing through *x[mean]*) and can be
    canceled out, so *α* becomes the ratio between *g(x')* and *g(x^((t-1))*).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing is defining the functions:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we can start our sampling process with 100,000 iterations and *x^((0))
    = 1.0*:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To get a representation of the posterior distribution, we need to create a
    histogram through the NumPy function `np.histogram()`, which accepts an array
    of values and the number of desired intervals (`bins`); in our case, we set `100`
    intervals:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The resulting plot of *p(x)* is shown in the following graph:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d6fb2c3-0a41-45e3-93e8-2ca302dbbf90.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
- en: Sampled probability density function
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Sampling example using PyMC3
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**PyMC3** is a powerful Python Bayesian framework that relies on Theano to
    perform high-speed computations (see the information box at the end of this paragraph
    for the installation instructions). It implements all the most important continuous
    and discrete distributions, and performs the sampling process mainly using the
    No-U-Turn and Metropolis-Hastings algorithms. For all the details about the API
    (distributions, functions, and plotting utilities), I suggest visiting the documentation
    home page [http://docs.pymc.io/index.html](http://docs.pymc.io/index.html), where
    it''s also possible to find some very intuitive tutorials.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'The example we want to model and simulate is based on this scenario: a daily
    flight from London to Rome has a scheduled departure time at 12:00 am, and a standard
    flight time of two hours. We need to organize the operations at the destination
    airport, but we don''t want to allocate resources when the plane hasn''t landed
    yet. Therefore, we want to model the process using a Bayesian network and considering
    some common factors that can influence the arrival time. In particular, we know
    that the onboarding process can be longer than expected, as well as the refueling
    one, even if they are carried out in parallel. London air traffic control can
    also impose a delay, and the same can happen when the plane is approaching Rome.
    We also know that the presence of rough weather can cause another delay due to
    a change of route. We can summarize this analysis with the following plot:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/db234ff4-d869-4c51-80bb-7d28a56e0783.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: Bayesian network representing the air traffic control problem
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering our experience, we decide to model the random variables using the
    following distributions:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '*Passenger onboarding ∼ Wald(μ=0.5, λ=0.2)*'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Refueling ∼ Wald(μ=0.25, λ=0.5)*'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Departure traffic delay ∼ Wald(μ=0.1, λ=0.2)*'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Arrival traffic delay ∼ Wald(μ=0.1, λ=0.2)*'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Departure time = 12 + Departure traffic delay + max(Passenger onboarding,
    Refueling)*'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Rough weather ∼ Bernoulli(p=0.35)*'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Flight time ∼ Exponential(λ=0.5 - (0.1 · Rough weather))* (The output of a
    Bernoulli distribution is *0* or *1* corresponding to False and True)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Arrival time = Departure time + Flight time + Arrival traffic delay*'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The probability density functions are:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b14d7f2-e3a1-4226-b874-59a38946bbd5.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
- en: '`Departure Time` and `Arrival Time` are functions of random variables, and
    the parameter λ of `Flight Time` is also a function of `Rough Weather`.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Even if the model is not very complex, the direct inference is rather inefficient,
    and therefore we want to simulate the process using PyMC3.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to create a `model` instance:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'From now on, all operations must be performed using the context manager provided
    by the `model` variable. We can now set up all the random variables of our Bayesian
    network:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We have imported two namespaces, `pymc3.distributions.continuous` and `pymc3.distributions.discrete`,
    because we are using both kinds of variable. Wald and exponential are continuous
    distributions, while `Bernoulli` is discrete. In the first three rows, we declare
    the variables `passenger_onboarding`, `refueling`, and `departure_traffic_delay`.
    The structure is always the same: we need to specify the class corresponding to
    the desired distribution, passing the name of the variable and all the required
    parameters.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: The `departure_time` variable is declared as `pm.Deterministic`. In PyMC3, this
    means that, once all the random elements have been set, its value becomes completely
    determined. Indeed, if we sample from `departure_traffic_delay`, `passenger_onboarding`,
    and `refueling`, we get a determined value for `departure_time`. In this declaration,
    we've also used the utility function `pmm.switch`, which operates a binary choice
    based on its first parameter (for example, if *A > B*, return *A*, else return
    *B*).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: The other variables are very similar, except for `flight_time`, which is an
    exponential variable with a parameter *λ*, which is a function of another variable
    (`rough_weather`). As a Bernoulli variable outputs *1* with probability *p* and
    *0* with probability *1 - p*, *λ = 0.4* if there's rough weather, and *0.5* otherwise.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the model has been set up, it''s possible to simulate it through a sampling
    process. PyMC3 picks the best sampler automatically, according to the type of
    variables. As the model is not very complex, we can limit the process to `500`
    samples:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output can be analyzed using the built-in `pm.traceplot()` function, which
    generates the plots for each of the sample''s variables. The following graph shows
    the detail of one of them:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a2fae86-4a34-4d33-8fcb-d95901ceb486.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
- en: Distribution and samples for the arrival time random variable
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'The right column shown the samples generated for the random variable (in this
    case, the arrival time), while the left column shows the relative frequencies.
    This plot can be useful to have a visual confirmation of our initial ideas; in
    fact, the arrival time has the majority of its mass concentrated in the interval
    14:00 to 16:00 (the numbers are always decimal, so it''s necessary to convert
    the times); however, we should integrate to get the probabilities. Instead, through
    the `pm.summary()` function, PyMC3 provides a statistical summary that can help
    us in making the right decisions. In the following snippet, the output containing
    the summary of a single variable is shown:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For each variable, it contains mean, standard deviation, Monte Carlo error,
    95% highest posterior density interval, and the posterior quantiles. In our case,
    we know that the plane will land at about 15:10 (`15.174`).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: This is only a very simple example to show the power of Bayesian networks. For
    deep insight, I suggest the book *Introduction to Statistical Decision Theory*,
    *Pratt J.*, *Raiffa H.*, *Schlaifer R.*, *The MIT Press*, where it's possible
    to study different Bayesian applications that are out of the scope of this book.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: PyMC3 ([http://docs.pymc.io/index.html](http://docs.pymc.io/index.html)) can
    be installed using the `pip install -U pymc3` command. As it requires Theano (which
    is installed automatically), it's also necessary to provide it with a C/C++ compiler.
    I suggest using distributions such as Anaconda ([https://www.anaconda.com/download/](https://www.anaconda.com/download/)),
    which allows installing MinGW through the `conda install -c anaconda mingw` command.
    For any problems, on the website you can find detailed installation instructions.
    For further information on how to configure Theano to work with GPU support (the
    default installation is based on CPU NumPy algorithms), please visit this page: [http://deeplearning.net/software/theano/](http://deeplearning.net/software/theano/).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Hidden Markov Models (HMMs)
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s consider a stochastic process *X(t)* that can assume *N* different states:
    *s[1], s[2], ..., s[N]* with first-order Markov chain dynamics. Let''s also suppose
    that we cannot observe the state of *X(t)*, but we have access to another process
    *O(t)*, connected to *X(t)*, which produces observable outputs (often known as
    **emissions**). The resulting process is called a **Hidden Markov Model** (**HMM**),
    and a generic schema is shown in the following diagram:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f054b58-c9c5-4832-b900-76d03dd95007.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
- en: Structure of a generic Hidden Markov Model
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'For each hidden state *s[i]*, we need to define a transition probability *P(i →
    j)*, normally represented as a matrix if the variable is discrete. For the Markov
    assumption, we have:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ae2d037e-d1ac-4fbf-a67a-6fd10b65dcf1.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: 'Moreover, given a sequence of observations *o[1], o[2], ..., o[M]*, we also
    assume the following assumption about the independence of the **emission probability**:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/592ba42f-5436-4409-8576-8f415fd3cb99.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
- en: In other words, the probability of the observation *o[i]* (in this case, we
    mean the value at time *i*) is conditioned only by the state of the hidden variable
    at time *i (x[i])*. Conventionally, the first state *x[0]* and the last one *x[Ending]*
    are never emittied, and therefore all the sequences start with the index *1* and
    end with an extra timestep corresponding to the final state.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: HMMs can be employed in all those contexts where it's impossible to measure
    the state of a system (we can only model it as a stochastic variable with a known
    transition probability), but it's possible to access some data connected to it.
    An example can be a complex engine that is made up of a large number of parts.
    We can define some internal states and learn a transition probability matrix (we're
    going to learn how to do that), but we can only receive measures provided by specific
    sensors.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, even if not extremely realistic, but it's useful to include the Markov
    assumption and the emission probability independence into our model. The latter
    can be justified considering that we can sample all the *peak* emissions corresponding
    to precise states and, as the random process *O(t)* is implicitly dependent on
    *X(t)*, it's not unreasonable to think of it like a *pursuer* of *X(t)*.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: The Markov assumption holds for many real-life processes if either they are
    naturally first-order Markov ones, or if the states contain all the history needed
    to justify a transition. In other words, in many cases, if the state is *A*, then
    there's a transit to *B* and finally to *C*. We assume that when in *C*, the system
    moved from a state *(B)* that carries a part of the information provided by *A*.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we are filling a tank, we can measure the level (the state of
    our system) at time *t*, *t+1*, ... If the water flow is modeled by a random variable
    because we don't have a stabilizer, we can find the probability that the water
    has reached a certain level at time *t*, *p(L[t]=x|L[t-1])*. Of course, it doesn't
    make sense to condition over all the previous states, because if the level is,
    for example, 80 m at time t-1, all the information needed to determine the probability
    of a new level (state) at time *t* is already contained in this state (80 m).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we can start analyzing how to train a hidden Markov model, and
    how to determine the most likely hidden states given a sequence of observations.
    For simplicity, we call *A* the transition probability matrix, and *B* the matrix
    containing all *P(o[i]|x[t])*. The resulting model can be determined by the knowledge
    of those elements: *HMM = { A, B }*.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Forward-backward algorithm
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **forward-backward algorithm** is a simple but effective method to find
    the transition probability matrix *T* given a sequence of observations *o[1],
    o[2], ..., o[t]*. The first step is called the *forward phase*, and consists of
    determining the probability of a sequence of observations *P(o[1], o[2], ...,
    o[Sequence Length]|A, B)*. This piece of information can be directly useful if
    we need to know the likelihood of a sequence and it's necessary, together with
    the *backward phase*, to estimate the structure (*A* and *B*) of the underlying
    HMM.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Both algorithms are based on the concept of dynamic programming, which consists
    of splitting a complex problem into sub-problems that can be easily solved, and
    reusing the solutions to solve more complex steps in a recursive/iterative fashion.
    For further information on this, please refer to *Dynamic Programming and Markov
    Process, Ronald A. Howard, The MIT Press*.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Forward phase
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we call *p[ij]* the transition probability *P(i → j)*, we define a recursive
    procedure considering the following probability:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aa938322-d572-4c1e-98fc-f027a2787715.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
- en: 'The variable *f[t]^i* represents the probability that the HMM is in the state
    *i* (at time *t*) after *t* observations (from *1* to *t*). Considering the HMM
    assumptions, we can state that *f[t]*^(*i* )depends on all possible *f[t-1]^j*.
    More precisely, we have:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e46b6f9b-3b8a-4129-b8fb-c0ceb4d53ece.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: With this process, we are considering that the HMM can reach any of the states
    at time *t-1* (with the first *t-1* observations), and transition to the state *i*
    at time *t* with probability *p[ji]*. We need also to consider the emission probability
    for the final state *o[t]* conditioned to each of the possible previous states.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'For definition, the initial and ending states are not emitting. It means that
    we can write any sequence of observations as *0, o[1], o[2], ..., o[Sequence Length],
    0*, where the first and the final values are null. The procedure starts with computing
    the forward message at time *1*:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f825279c-c495-40c8-866c-4a7279c157a2.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
- en: 'The non-emitting ending state must be also considered:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c62826ee-9eab-404a-b9b6-e3656e23da6f.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
- en: The expression for the last state *x*[*Ending* ]is interpreted here as the index
    of the ending state in both *A* and *B* matrices. For example, we indicate *p[ij]*
    as *A[i, j]*, meaning the transition probability at a generic time instant from
    the state *x[t] = i* to the state *x[t+1] = j*. In the same way, *p[i][Ending]*
    is represented as *A[i, x[Ending]]*, meaning the transition probability from the
    penultimate state *x[Sequence Length-1] = i* to the ending one*x[Sequence Length]
    = Ending State*.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'The Forward algorithm can, therefore, be summarized in the following steps
    (we assume to have *N* states, hence we need to allocate *N+2* positions, considering
    the initial and the ending states):'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Initialization of a *Forward* vector with shape (*N + 2*, *Sequence Length*).
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialization of *A* (transition probability matrix) with shape (*N, N*). Each
    element is *P(x[i]|x[j]**)*.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialization of *B* with shape (*Sequence Length*, *N*). Each element is *P(o[i]|x[j]**)*.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *Forward[i, 1]* = *A[0, i] · B[1, i]*
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *t=2* to *Sequence Length-1*:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *S = 0*
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *j=1* to *N*:'
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *S = S + Forward[j, t-1] · A[j, i] · B[t, i]*
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *Forward[i, t] = S*
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *S = 0*.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *S = S + Forward[i, Sequence Length] · A[i, x[Ending]]*
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *Forward[x[Ending], Sequence Length] = S*.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now it should be clear that the name **forward** derives from the procedure
    to propagate the information from the previous step to the next one, until the
    ending state, which is not emittied.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Backward phase
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'During the **backward phase**, we need to compute the probability of a sequence
    starting at time *t+1: o[t+1], o[t+2], ..., o[Sequence Length]*, given that the
    state at time *t* is *i*. Just like we have done before, we define the following
    probability:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c024525-9838-4223-a54f-c158fb18e0fd.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
- en: 'The backward algorithm is very similar to the forward one, but in this case,
    we need to move in the opposite direction, assuming we know that the state at
    time *t* is *i*. The first state to consider is the last one *x[Ending]*, which
    is not emitting, like the initial state; therefore we have:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9cae7840-24b7-4382-aad0-91eb97efa387.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
- en: 'We terminate the recursion with the initial state:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d62d9350-f901-4766-a303-43d0ec77f12c.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
- en: 'The steps are the following ones:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: Initialization of a vector *Backward* with shape *(N + 2, Sequence Length)*.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialization of *A* (transition probability matrix) with shape *(N, N)*. Each
    element is *P(x[i]|x[j]**)*.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialization of *B* with shape *(Sequence Length, N)*. Each element is* P(o[i]|x[j]**)*.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *Backward[x[Endind], Sequence Length] = A[i, x[Endind]]*
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *t=Sequence Length-1* to *1*:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *S = 0*
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For *j=1* to *N*
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *S = S + Backward[j, t+1] · A[j, i] · B[t+1, i]*
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *Backward[i, t] = S*
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *S = 0*.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *S = S + Backward[i, 1] · A[0, i] · B[1, i]*
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *Backward[0, 1] = S*.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: HMM parameter estimation
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have defined both the forward and the backward algorithms, we can
    use them to estimate the structure of the underlying HMM. The procedure is an
    application of the Expectation-Maximization algorithm, which will be discussed
    in the next chapter, [Chapter 5](8d541a43-8790-4a91-a79b-e48496f75d90.xhtml), *EM
    Algorithm and Applications*, and its goal can be summarized as defining how we
    want to estimate the values of *A* and *B*. If we define *N(i, j)* as the number
    of transitions from the state *i* to the state *j*, and *N(i)* the total number
    of transitions from the state *i*, we can approximate the transition probability
    *P(i → j)* with:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/599b50d2-75d5-4c85-bc1f-e36280247077.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
- en: 'In the same way, if we define *M(i, p)* the number of times we have observed
    the emission *o[p]* in the state *i*, we can approximate the emission probability *P(o[p]|x[i])*
    with:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0efa14ed-4579-43c4-8458-49df67a3689a.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
- en: 'Let''s start with the estimation of the transition probability matrix *A*.
    If we consider the probability that the HMM is in the state *i* at time *t*, and
    in the state *j* at time *t+1* given the observations, we have:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c0c449d-33da-43c9-b894-c5c211bf45c5.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
- en: 'We can compute this probability using the forward and backward algorithms,
    given a sequence of observations *o[1], o[2], ..., o[Sequence Length]*. In fact,
    we can use both the forward message *f[t]^i*, which is the probability that the
    HMM is in the state *i* after *t* observations, and the backward message *b[t+1]^j*,
    which is the probability of a sequence *o[t+1], o[t+1], ..., o[Sequence Length]*
    starting at time *t+1*, given that the HMM is in state *j* at time *t+1*. Of course,
    we need also to include the emission probability and the transition probability
    *p[ij]*, which is what we are estimating. The algorithm, in fact, starts with
    a random hypothesis and iterates until the values of *A* become stable. The estimation *α[ij]*
    at time *t* is equal to:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/24edfb52-1fa3-405e-a9a3-768e2ef640c7.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
- en: In this context, we are omitting the full proof due to its complexity; however,
    the reader can find it in *A tutorial on hidden Markov models and selected applications
    in speech recognition,* *Rabiner L. R., Proceedings of the IEEE 77.2**.*
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute the emission probabilities, it''s easier to start with the probability
    of being in the state *i* at time *t* given the sequence of observations:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d28be2d-6fc3-499d-86af-6ee4523a4625.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
- en: 'In this case, the computation is immediate, because we can multiply the forward
    and backward messages computed at the same time *t* and state *i* (remember that
    considering the observations, the backward message is conditioned to *x[t] = i*,
    while the forward message computes the probability of the observations joined
    with *x[t] = i*. Hence, the multiplication is the unnormalized probability of
    being in the state *i* at time *t*). Therefore, we have:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/75ac8487-2059-47de-9904-5f7f0e9ed4fc.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
- en: 'The proof of how the normalizing constant is obtained can be found in the aforementioned
    paper. We can now plug these expressions to the estimation of *a[ij]* and *b[ip]*:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4f1a3d0a-b4f0-4249-b65a-07c68b0a4ccf.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
- en: In the numerator of the second formula, we adopted the indicator function (it's
    *1* only if the condition is true, *0* otherwise) to limit the sum only where
    those elements are *o[t] = p*. During an iteration *k*, *p[ij]* is the estimated
    value *a[ij]* found in the previous iteration *k-1*.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm is based on the following steps:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Randomly initialize the matrices *A* and *B*
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize a tolerance variable *Tol* (for example, *Tol = 0.001*)
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'While *Norm(A^k - A^(k-1)) > Tol* and *Norm(B^k - B^(k-1)**) > Tol* (*k* is
    the iteration index):'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *t=1* to *Sequence Length-1*:'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *j=1* to *N*:'
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute *α^t*[*ij*]
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute *β^t[i]*
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the estimations of *a[ij]* and *b[ip]* and store them in *A^k*
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Alternatively, it's possible to fix the number of iterations, even if the best
    solution is using both a tolerance and a maximum number of iterations, to terminate
    the process when the first condition is met.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Example of HMM training with hmmlearn
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this example, we are going to use hmmlearn, which is a package for HMM computations
    (see the information box at the end of this section for further details). For
    simplicity, let's consider the airport example discussed in the paragraph about
    the Bayesian networks, and let's suppose we have a single hidden variable that
    represents the weather (of course, this is not a real hidden variable!), modeled
    as a multinomial distribution with two components (good and rough).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: We observe the arrival time of our flight London-Rome (which partially depends
    on the weather conditions), and we want to train an HMM to infer future states
    and compute the posterior probability of hidden states corresponding to a given
    sequence.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'The schema for our example is shown in the following diagram:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f88ad311-0701-48b9-9f86-024a2edf0510.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
- en: HMM for the weather-arrival delay problem
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by defining our observation vector. As we have two states, its
    values will be `0` and `1`. Let''s assume that `0` means **On-time** and `1` means **Delay**:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We have 35 consecutive observations whose values are either `0` or `1`.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: To build the HMM, we are going to use the `MultinomialHMM` class, with `n_components=2`, `n_iter=100`,
    and `random_state=1000` (it's important to always use the same seed to avoid differences
    in the results). The number of iterations is sometimes hard to determine; for
    this reason, hmmlearn provides a utility `ConvergenceMonitor` class which can
    be checked to be sure that the algorithm has successfully converged.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can train our model using the `fit()` method, passing as argument the
    list of observations (the array must be always bidimensional with shape *Sequence
    Length × N[Components]*):'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The process is very fast, and the monitor (available as instance variable `monitor`)
    has confirmed the convergence. If the model is very big and needs to be retrained,
    it''s also possible to check smaller values of `n_iter`). Once the model is trained,
    we can immediately visualize the transition probability matrix, which is available
    as an instance variable `transmat_`:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can interpret these values as saying that the probability to transition from
    `0` (good weather) to `1` (rough weather) is higher (*p[01]* is close to *1*)
    than the opposite, and it's more likely to remain in state `1` than in state `0`
    (*p[00]* is almost null). We could deduce that the observations have been collected
    during the winter period! After explaining the Viterbi algorithmin the next paragraph,
    we can also check, given some observations, what the most likely hidden state
    sequence is.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: hmmlearn ([http://hmmlearn.readthedocs.io/en/latest/index.html](http://hmmlearn.readthedocs.io/en/latest/index.html))
    is a framework originally built to be a part of Scikit-Learn. It supports multinomial
    and Gaussian HMM, and allows training and inferring using the most common algorithms.
    It can be installed using the `pip install hmmlearn` command.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Viterbi algorithm
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Viterbi algorithm** is one of most common decoding algorithms for HMM.
    Its goal is to find the most likely hidden state sequence corresponding to a series
    of observations. The structure is very similar to the forward algorithm, but instead
    of computing the probability of a sequence of observations joined with the state
    at the last time instant, this algorithm looks for:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ba7094a-03d5-4453-9755-557392e2bffd.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
- en: 'The variable *v[t]^i* represents that maximum probability of the given observation
    sequence joint with *x[t] = i*, considering all possible hidden state paths (from
    time instant *1* to *t-1*). We can compute *v[t]^i* recursively by evaluating
    all the *v[t-1]^j* multiplied by the corresponding transition probabilities *p[ji]*
    and emission probability *P(o[t]|x[i])*, and always picking the maximum overall possible
    values of *j*:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09735a93-2d90-4f2f-b9fe-125a6626c989.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
- en: 'The algorithm is based on a backtracking approach, using a backpointer *bp[t]^i*
    whose recursive expression is the same as *v[t]^i*, but with the *argmax* function
    instead of *max*:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/613be74e-74c1-4af3-b1ce-a250c35c1a21.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
- en: Therefore, *bp[t]*^(*i* )represents the partial sequence of hidden states *x**[1],
    x[2], ..., x*[*t-1* ]that maximizes* v[t]^i*. During the recursion, we add the
    timesteps one by one, so the previous path could be invalidated by the last observation.
    That's why we need to backtrack the partial result and replace the sequence built
    at time *t* that doesn't maximize *v[t+1]^i* anymore.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm is based on the following steps (like in the other cases, the
    initial and ending states are not emitting):'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: Initialization of a vector *V* with shape *(N + 2, Sequence Length)*.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialization of a vector *BP* with shape *(N + 2, Sequence Length)*.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialization of *A* (transition probability matrix) with shape *(N, N)*. Each
    element is *P(x[i]|x[j]**)*.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialization of *B* with shape *(Sequence Length, N)*. Each element is *P(o[i]|x[j]**)*.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *V[i, 1]* = *A[i, 0] **· B[1, i]*
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '*BP[i, 1]* = Null (or any other value that cannot be interpreted as a state)'
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *t=1* to *Sequence Length*:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For *i=1* to *N*:'
  id: totrans-328
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *V[i, t] = max[j] V[j, t-1] · A[j, i] · B[t, i]*
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *BP[i, t] = argmax[j] V[j, t-1] · A[j, i] · B[t, i]*
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *V[x[Endind], Sequence Length] = max[j] V[j, Sequence Length] **· A[j, x[Endind]]*.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set *BP**[x[Endind], Sequence Length] = argmax[j] V[j, Sequence Length] **·
    A[j, x[Endind]]*.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reverse *BP*.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The output of the Viterbi algorithm is a tuple with the most likely sequence
    *BP*, and the corresponding probabilities *V*.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: Finding the most likely hidden state sequence with hmmlearn
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point, we can continue with the previous example, using our model to
    find the most likely hidden state sequence given a set of possible observations.
    We can use either the `decode()` method or the `predict()` method. The first one
    returns the log probability of the whole sequence and the sequence itself; however,
    they all use the Viterbi algorithm as a default decoder:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The sequence is coherent with the transition probability matrix; in fact, it''s
    more likely the persistence of rough weather (`1`) than the opposite. As a consequence,
    the transition from `1` to X is less likely than the one from `0` to `1`. The
    choice of state is made by selecting the highest probability; however, in some
    cases, the differences are minimal (in our example, it can happen to have *p =
    [0.49, 0.51]*, meaning that there''s a high error chance), so it''s useful to
    check the posterior probabilities for all the states in the sequence:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In our case, there are a couple of states that have *p ∼ [0.495, 0.505]*, so
    even if the output state is *1* (rough weather), it's also useful to consider
    a moderate probability to observe good weather. In general, if a sequence is coherent
    with the transition probability previously learned (or manually input), those
    cases are not very common. I suggest trying different configurations and observations
    sequences, and to also assess the probabilities for the *strangest* situations
    (like a sequence of zero second). At that point, it's possible to retrain the
    model and recheck the new evidence has been correctly processed.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have introduced Bayesian networks, describing their structure
    and relations. We have seen how it's possible to build a network to model a probabilistic
    scenario where some elements can influence the probability of others. We have
    also described how to obtain the full joint probability using the most common
    sampling methods, which allow reducing the computational complexity through an
    approximation.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: The most common sampling methods belong to the family of MCMC algorithms, which
    model the transition probability from a sample to another one as a first-order
    Markov chain. In particular, the Gibbs sampler is based on the assumption that
    it's easier to sample from conditional distribution than work directly with the
    full joint probability. The method is very easy to implement, but it has some
    performance drawbacks that can be avoided by adopting more complex strategies.
    The Metropolis-Hastings sampler, instead, works with a candidate-generating distribution
    and a criterion to accept or reject the samples. Both methods satisfy the detailed
    balance equation, which guarantees the convergence (the underlying Markov chain
    will reach the unique stationary distribution).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: In the last part of the chapter, we introduced HMMs, which allow modeling time
    sequences based on observations corresponding to a series of hidden states. The
    main concept of such models, in fact, is the presence of unobservable states that
    condition the emission of a particular observation (which is observable). We have
    discussed the main assumptions and how to build, train, and infer from a model.
    In particular, the Forward-Backward algorithm can be employed when it's necessary
    to learn the transition probability matrix and the emission probabilities, while
    the Viterbi algorithm is adopted to find the most likely hidden state sequence
    given a set of consecutive observations.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, [Chapter 5](8d541a43-8790-4a91-a79b-e48496f75d90.xhtml), *EM
    Algorithm and Applications*, we're going to briefly discuss the Expectation-Maximization
    algorithm, focusing on some important applications based on the **Maximum Likelihood
    Estimation** (**MLE**) approach.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
