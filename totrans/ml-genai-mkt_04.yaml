- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Harnessing Seasonality and Trends for Strategic Planning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unless it is a one-time marketing event, such as opening pop-up stores or occasional
    celebratory product sales, there will always be impacts on the marketing outcomes
    from time components. For example, companies selling umbrellas will naturally
    see significant sales increases during rainy seasons. Not only can there be seasonal
    impacts on businesses but there can also be general trends in businesses. For
    example, businesses selling landline phones will see a gradual decline in their
    sales as people use mobile phones more and more.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter discusses in depth the temporal impacts on marketing campaigns
    and how to utilize them for the most efficient marketing strategies. We will introduce
    the basics of time-series analysis, such as some of the common approaches to identifying
    overall trends and anomalies and visualizing time-series data. We’ll then move
    on to exploring how time-series data can be decomposed into trends and seasonalities,
    which will inform us of the contribution of breakdowns of certain events based
    on these factors and how this decomposition helps with building more efficient
    marketing strategies. We’ll end by learning how to build time-series forecasting
    models and understanding how these forecasts can be utilized for proper marketing
    campaigns. We will use a product sales dataset as an example and discuss how to
    conduct time-series analysis and modeling in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Time series analysis basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trend and seasonality decomposition in time-series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series forecasting models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series analysis basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding natural trends within businesses is critical, not only for marketers
    but also for operators, sales, and most other business units. Without a good grasp
    of how a business and its products are evolving and how customers are reacting
    and behaving around the services and products that you provide, it is very easy
    to fall behind, resulting in suboptimal revenue growth or even business growth
    slowing to a halt.
  prefs: []
  type: TYPE_NORMAL
- en: It is easy to find how businesses build their product strategies around this
    temporal component of the business cycle. In the fashion industry, clothing businesses
    typically market spring and summer clothes from late winter to early spring, while
    fall and winter clothes are advertised from early summer to early fall, as customers
    tend to shop before the actual season comes as a preparation. Then, spring and
    summer clothes typically go on sale during the summer, typically from mid-July,
    as the demand for these clothes is low during the actual season. This illustrates
    how businesses can optimize their business cycles for different seasons based
    on the customer demands that naturally form and how they can maximize sales while
    minimizing the excess inventory.
  prefs: []
  type: TYPE_NORMAL
- en: '**Time series analysis** comes in handy when we try to understand these natural
    temporal components within businesses. Time series analysis, in short, is a way
    of analyzing a series of data points over time and how **time** affects the changes
    in data values. In this chapter, we will be using a historical sales dataset as
    an example to discuss how to conduct time series analysis and modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Source code and data**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.4](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.4
    )'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data source**: [https://community.tableau.com/s/question/0D54T00000CWeX8SAL/sample-superstore-sales-excelxls](https://community.tableau.com/s/question/0D54T00000CWeX8SAL/sample-superstore-sales-excelxls)'
  prefs: []
  type: TYPE_NORMAL
- en: Basic time series trends
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s look at overall monthly product sales using our example dataset. We will
    first need to load this data into a DataFrame and aggregate the data per month.
    Take a look at the following code (note that the CSV file used here is included
    in the book GitHub repository):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are loading the data into a `pandas` DataFrame. One thing that is different
    from previous chapters is the encoding parameter. This dataset contains non-UTF
    characters, so we are using `latin` encoding to load the data. Then, we convert
    the values in the `OrderDate` column into a datetime type and copy the key columns
    into a new `DataFrame`, `ts_df`. Lastly, for ease of use, we remove spaces in
    the column names by replacing all spaces with empty strings.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to resample and aggregate the data into monthly frequency is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We are using the `resample` function within `pandas` with the argument `MS`,
    which will resample the data into a monthly timeframe, and then counting the number
    of unique `OrderID` values using the `nunique` function, which will give us monthly
    unique order count data. We then compute month-over-month changes in percentages
    by subtracting the previous month’s value from the current month’s value and dividing
    it by the previous month’s value. The `shift` function will move the data by one
    period, resulting in giving us the previous month’s value.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can apply the same to compute monthly order quantities and sales, as in
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The simplest approach to visualizing time-series data is using line charts.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code, we are creating three line charts. The first one is for the monthly
    unique order, the second one is for the monthly order quantities, and the last
    one is for the monthly sales. This code generates the following charts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1: Visualization of monthly time-series data'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive into these charts deeper. As you may notice, all three charts show
    clear repeating patterns. They spike in March, September, and November-December.
    This can be confirmed by both looking at the solid lines, which are overall monthly
    values, and looking at the dotted lines, which are month-over-month changes in
    the values. This suggests that this business is cyclical with a larger volume
    of sales in those corresponding months. Marketers should turn this insight into
    actions by marketing more heavily slightly before the peak seasons to capture
    the greatest amount of sales potential. Also, marketers can offer discounts during
    the months that show weaker sales volumes in an effort to manage the inventory,
    as well as boost off-season sales.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, visualizing time-series data itself gives great insight into
    the business cycles and how to prepare for the peak and trough seasons. Another
    thing you may notice from these charts is they are overall in an uptrend, meaning
    the values are typically rising year over year. This overall trend is more easily
    identifiable when we look at the moving averages in the time-series charts.
  prefs: []
  type: TYPE_NORMAL
- en: You can not only sample time-series data by monthly frequency but also by daily,
    weekly, or yearly frequencies. There are many options you can resample by, so
    try different resample frequencies and see what other trends you can observe!
  prefs: []
  type: TYPE_NORMAL
- en: '**Reference**: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling'
  prefs: []
  type: TYPE_NORMAL
- en: Moving averages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Moving averages**, which are the averages over specific time periods, are
    good at smoothing out spiky or noisy time-series data and showing overall trends.
    They are essential tools to answer questions like “Are our product sales in an
    overall uptrend or downtrend?”. Within our example data, we can do the following
    to compute moving averages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, you can use the `rolling` function within `pandas`
    and apply the `mean` function to get the moving average of monthly sales. The
    input into the `rolling` function defines how many periods you would like to average
    the values for. Here, we have computed the 6-period moving average and the 12-period
    moving average of monthly sales.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following code to visualize the moving averages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting chart will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: Monthly sales with 6-month and 12-month moving averages'
  prefs: []
  type: TYPE_NORMAL
- en: As expected, the 12-month moving average chart is smoother than the 6-month
    moving average chart. However, the 6-month moving average chart is more responsive
    or captures the monthly trends more closely than the 12-month moving average chart
    while still smoothing out the spikes in the monthly sales chart. As you may notice,
    the moving average charts show a general uptrend in the monthly sales data, which
    may have been harder to notice due to spikes and noises when we were only looking
    at the monthly chart.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving averages can also help you understand whether the spikes in certain
    months are within the normal range or are abnormal. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This code calculates the moving standard deviations (which is the same as moving
    averages but measuring standard deviations over a certain period of time in the
    past) over a 6-month period by using the `std` function and visualizes data with
    the bands where the upper boundary is one standard deviation above the 6-month
    moving average and the lower boundary is one standard deviation below the 6-month
    moving average. The chart will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3: Monthly sales with 6-month moving average and 1-std boundaries'
  prefs: []
  type: TYPE_NORMAL
- en: This chart shows how the monthly sales volumes look compared to the moving averages
    and one standard deviation boundaries. Depending on your preference, you may want
    to consider values within one standard deviation as normal or within two standard
    deviations as normal. Using this example, if we assume values within one standard
    deviation to be normal, we can see that the months of February, September, November,
    and December are abnormal months and went beyond the defined boundaries, where
    the sales in February dropped significantly lower than expected and the sales
    in September, November, and December increased significantly higher than expected.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the overall trend of a business is equally as important as understanding
    the seasonal or cycles within a business. Depending on the general trend, you
    can be better informed as to whether to expect higher or lower sales and marketing
    potential than last year. If the overall trend is in an uptrend, you should expect
    the demand for a given month is likely to be higher than the demand for the same
    month in the previous year. Also, having a good grasp of the sales that go above
    or below the normal ranges, such as during Black Fridays or the Christmas season,
    can help to build efficient marketing strategies to overcome the shortages and
    the abundance of marketing potential. Moving averages and moving standard deviations
    are handy tools for identifying overall trends and normal expected ranges.
  prefs: []
  type: TYPE_NORMAL
- en: Autocorrelation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another basic time-series analysis that comes in handy is **autocorrelation**.
    Autocorrelation represents the correlation with lagged versions of itself. It
    will be easier to discuss with an example. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are utilizing the `statsmodels` package, which you can install using
    the `pip install statsmodels` command. The `plot_acf` function will plot the autocorrelation
    of a given series for you. Here, we are plotting the autocorrelation of the monthly
    sales for the past 25 periods. The chart should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.4: Autocorrelation plot of monthly sales data'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s analyze this chart more closely. The x-axis represents the number of lags
    and the y-axis is the degree of correlation. This chart shows the correlation
    between the current point of time against one period before, two periods before,
    and up to 25 periods before. Here, in the monthly sales data, we have relatively
    strong positive correlations up to three lagged periods and slight negative correlations
    with the fourth and fifth periods. This suggests that if there were increases
    in sales for the past 3 months, it is likely that the current month’s sales will
    increase, and vice versa. Also, this means that observing an increase in sales
    4–5 months ago likely results in a decrease in sales during the current month.
    As this example shows, autocorrelation is a way to see how different time periods
    may have affected the current time period’s result. In the *Time series forecasting
    models* section of this chapter, we will experiment with the **autoregressive
    integrated moving average** (**ARIMA**) model, and the autoregression part of
    it uses these lagged variables for time-series forecast modeling.
  prefs: []
  type: TYPE_NORMAL
- en: '**Partial autocorrelation**, in contrast to autocorrelation, ignores the influences
    of intermediate lags. Unlike autocorrelation, partial autocorrelation measures
    the direct impact and correlation at each lag. The `plot_pacf` function can be
    used to plot partial autocorrelations, as in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are plotting partial autocorrelations up to period 15\. The chart
    should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.5: Partial autocorrelation plot of monthly sales data'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the degrees of correlations at each lag are different compared
    to the previous autoregression chart. This is due to the fact that partial autoregression
    measures the direct correlation at each lag, whereas autoregression includes the
    influence of intermediate lags. In this example, we can see that there is a significant
    positive partial autocorrelation at lag 1 and a negative partial autocorrelation
    at lag 4\. This suggests that the prior month’s increase or decrease in sales
    is likely to result in an increase and decrease in the current month’s sales,
    respectively, whereas the increase in sales 4 months ago is likely to result in
    a decrease in the current month’s sales, excluding the influences of the sales
    results in the months between. Intuitively, these can be a result of natural business
    cycles, where, if your business cycle is quarterly, then you will likely see negative
    autocorrelations at lags 3–4, and for semi-annual cycles, you are likely to see
    negative autocorrelations at lags 6–7.
  prefs: []
  type: TYPE_NORMAL
- en: Product trends
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All of the analysis and visualizations we have discussed so far can be applied
    to more granular levels. We have only looked at the overall monthly sales time-series
    data. However, we can dissect it by different products and discover how each product
    may have different overall trends and cyclical nature in the demands. We can also
    look at how different states or geographic regions show trends and business cycles
    that may be different from the overall sales trends.
  prefs: []
  type: TYPE_NORMAL
- en: 'For illustration purposes, we will dissect the trends by different product
    categories. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we create time-series records for each product category. Largely, we
    are creating three time series of monthly `Furniture`, `Office Supplies`, and
    `Technology` sales, and then showing these charts side by side. The resulting
    charts look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.6: Visualization of monthly sales data for Furniture, Office Supplies,
    and Technology products'
  prefs: []
  type: TYPE_NORMAL
- en: The overall trends are similar across these three product lines, where the sales
    spike in September and November/December. However, the spike in March sales is
    the most prominent in Technology sales and there was a rapid growth in Furniture
    sales from January 2017\. Also, Office Supplies sales seem to spike more frequently
    than the other two product lines; they seem to spike every quarter or so, which
    may be a result of quarterly restocking of office supplies. As these results show,
    different product lines tend to show slightly different behaviors across time.
  prefs: []
  type: TYPE_NORMAL
- en: Try diving deeper into segmentation and how time-series data differs by different
    segmentations. Try dissecting different variables, such as region, city, and sub-category!
  prefs: []
  type: TYPE_NORMAL
- en: Trend and seasonality decomposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have seen how there are natural trends and cycles that are shown from the
    time-series data. By visualizing charts and utilizing moving averages, we were
    able to identify overall trends and seasonalities. However, there are more statistical
    approaches to decomposing time-series data into trend and seasonality components.
    Largely, there are two main ways to do time-series decomposition:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Additive**: As the name suggests, the **additive** time-series decomposition
    method decomposes the data into trend, seasonality, and error (which is the component
    that cannot be explained by the overall trend and seasonality) so that when they
    are summed together, it can reconstruct the original time-series data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Y*[t] = *Trend*[t] + *Seasonality*[t] + *Error*[t]'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiplicative**: On the other hand, the **multiplicative** time-series decomposition
    method decomposes the data into trend, seasonality, and error in a way that when
    they are multiplied together, the original time-series data can be reconstructed.
    The equation looks as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Y*[t] = *Trend*[t] * *Seasonality*[t] * *Error*[t]'
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s look at these methods in greater detail.
  prefs: []
  type: TYPE_NORMAL
- en: Additive time series decomposition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Conveniently, the `statsmodels` package provides a function for easy trend
    and seasonality decomposition. As an example, we will decompose monthly `Furniture`
    sales data and see what trends and seasonality it has. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As this code suggests, we are using the `seasonal_decompose` function for the
    time-series decomposition of monthly `Furniture` sales data, which is in the variable
    with the name `furniture_monthly_sales`. Another thing to note is the `model`
    parameter to the `seasonal_decompose` function, with which you can decide whether
    to use additive or multiplicative approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'This time-series decomposition can easily be visualized using the `plot` function
    of the output of the `seasonal_decompose` function. The chart should look something
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.7: Time-series decomposition plot of monthly furniture sales data'
  prefs: []
  type: TYPE_NORMAL
- en: The top chart shows the original time-series data, which, in our case, is the
    monthly `Furniture` data. The second chart from the top shows the decomposed trend.
    As expected, there is a clear uptrend, where the sales grow year over year. The
    third chart is the decomposed seasonality chart. Here, it shows clear spikes in
    sales during September, November, and December and drops in sales during February.
    Lastly, the bottom chart shows the residuals or the error terms when this data
    is decomposed into trend and seasonality. According to the equation discussed
    in the previous section, these bottom three charts correspond to each decomposed
    component of the original time-series data.
  prefs: []
  type: TYPE_NORMAL
- en: 'When properly decomposed, the error terms should be stationary, meaning there
    should not be a noticeable pattern in the residuals that are dependent on time.
    In our example, there is no noticeable pattern across time in the residuals, so
    the decomposed series seems reasonable. We can examine how well the decomposed
    series captures the original series by reconstructing the time-series data based
    on the trend and seasonality decomposition and how big a gap there is between
    the original series and the reconstructed series. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The first line shows how we can reconstruct the time-series data using the decomposed
    trend and seasonality. Since we have used the additive approach for time-series
    decomposition in this example, we simply sum the trend and seasonality components
    together to get the reconstructed series.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three metrics that we are using to measure the similarity or dissimilarity
    between the original series and the reconstructed series:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Correlation**: Using the `numpy` package’s `corrcoef` function, this metric
    measures the similarity between the original and reconstructed series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Euclidean distance**: This is the square root of the sum of the squared errors.
    This metric measures how big of a gap there is between the original and reconstructed
    series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Root mean squared error** (**RMSE**): This is the square root of the mean
    of the squared errors. This metric measures the degree of error between the original
    and reconstructed series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The result should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also visually compare the reconstructed series against the original
    series with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The chart should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.8: Monthly furniture sales data along with decomposed trend and reconstructed
    series'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from this chart and as expected from the previous metrics, the
    reconstructed series does not capture 100% of the original series. However, they
    move closely together and the reconstructed series has a high degree of similarity
    with the original series.
  prefs: []
  type: TYPE_NORMAL
- en: Multiplicative time series decomposition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will compare the results of the additive approach against the results of
    the multiplicative approach results to see which one captures the original time
    series more closely. As you may have guessed, you can replace the `model` parameter
    of the `seasonal_decompose` function with `multiplicative`, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting chart should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.9: Time-series decomposition plot of monthly furniture sales data
    with the multiplicative approach'
  prefs: []
  type: TYPE_NORMAL
- en: 'This should look very similar to the chart with the additive approach. However,
    there are two key things that are noticeably different:'
  prefs: []
  type: TYPE_NORMAL
- en: The y-axis of the *Seasonal chart*, which is the second chart from the bottom,
    ranges from **0** to about **2.0**, whereas the y-axis of the Seasonal component
    of the additive chart ranges from about – 10,000 to 35,000.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, the y-axis of the *Residual chart*, which is the bottom chart, ranges
    from **0** to about **1.5**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you may have guessed, this is because we used the multiplicative approach
    in this example as opposed to the additive approach. In order to reconstruct the
    original series from the decomposed trend and seasonality components, we need
    to multiply these two components together, as in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to before, we can measure the degree of similarity between the reconstructed
    series from the multiplicative approach and the original series based on the three
    metrics we have used before (correlation, Euclidean distance, and RMSE) using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The similarity measures can be viewed using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: If you compare these results against the previous results with the additive
    approach, you will notice that the Euclidean distance and RMSE are much lower
    with the multiplicative approach, while the correlation measure is similar. The
    Euclidean distance with the multiplicative approach is about **700** less than
    it is with the additive approach, and the RMSE with the multiplicative approach
    is about **100** less than it is with the additive approach. This suggests that
    the multiplicative decomposition approach may capture the original time-series
    data better in this case than the additive approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we can visually inspect the multiplicative approach’s reconstruction
    results with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting chart should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.10: Monthly furniture sales plot with the decomposed trend and reconstructed
    series with the multiplicative approach'
  prefs: []
  type: TYPE_NORMAL
- en: We have seen how we can decompose time-series data statistically with the `statsmodels`
    package in this section. As previously mentioned, having an in-depth understanding
    of general trends as well as seasonal trends is critical in formulating product
    and target marketing strategies as the alignments of the marketing strategies
    with these trends and the timing of the actions ahead of the expected trends dictate
    the successes and failures of marketing campaigns. You do not want to be too late
    in the trend but you also do not want to be too early in the trend. This time-series
    decomposition technique should be a handy tool to strategize and time your marketing
    campaigns.
  prefs: []
  type: TYPE_NORMAL
- en: Time series forecasting models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The overall trends and the seasonalities bring valuable insights for efficient
    and timely marketing campaigns. We have discussed how time-series decomposition
    can help marketers put out timely promotions in order to capture the maximum sales
    and marketing potential when the demands are expected to rise, as well as minimize
    the dips and excess inventory when the demands are expected to fall via out-of-season
    sales promotions or focusing on the products that have different peak and trough
    cycles.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can take a step further with **machine learning** (**ML**) and **artificial
    intelligence** (**AI**) and build time-series forecasting models. The future forecasts
    with these AI/ML models can play a pivotal role not only for marketing but also
    for various other business units, including sales, operations, finance, supply
    chain, procurement, and many others. By utilizing time-series forecasts, marketers
    can optimize their marketing goals in numerous ways:'
  prefs: []
  type: TYPE_NORMAL
- en: If a marketing goal is to promote a *new product*, then the time-series forecast
    model output can inform the marketer when will be the best time to start promoting
    based on the expected demand rises or falls of similar product categories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a marketing goal is to promote an *off-season sales* increase, then the time-series
    model can be built to forecast the types of off-season promotions that may result
    in the highest sales.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a marketing goal is to clean out the *excess inventory*, a time-series model
    that forecasts the different demands in different regions or demographics can
    help the marketer target certain regions or demographics for maximum efficiency
    in reducing the excess inventory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are numerous time-series forecasting algorithms that can be used to build
    forecast models. Ranging from traditional statistical time-series models to more
    modern deep learning-based time-series models, there are various algorithms that
    can be used to forecast time-series data. In this section, we will experiment
    with the two most frequently used time-series models: ARIMA and Prophet.'
  prefs: []
  type: TYPE_NORMAL
- en: ARIMA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **ARIMA** model is a statistical model that is often used to predict future
    time-series data based on past values. ARIMA is a form of regression analysis
    that we discussed in *Chapter 3*, but there are three key components that the
    ARIMA model is composed of:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Autoregression**: The **AR** part of the ARIMA model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similar to what we discussed for autocorrelation, autoregression is a regression
    on its own lagged variables, where each lagged variable is a feature of the forecasting
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Integrated**: The **I** part of the ARIMA model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the difference between the values and their previous values to achieve
    stationarity that, as discussed previously, means the errors do not depend on
    the time component.
  prefs: []
  type: TYPE_NORMAL
- en: '**Moving Average**: The **MA** part of the ARIMA model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As discussed previously, the moving average is an average over a rolling window
    and the ARIMA model regresses on these moving averages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of these three components – **Autoregression** (**AR**), **Integrated**
    (**I**), and **Moving Average** (**MA**) – in the ARIMA model has its own parameter.
    Typically, these parameters have notations of *p*, *d*, and *q*, and are defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*: The number of lag periods in the model for the AR component'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*d*: The number of times data are differenced for the I component'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*q*: The rolling window of the moving average for the MA component'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training the ARIMA model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `statsmodels` package in Python has a module that makes it easy for us
    to build ARIMA models. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We recommend you try various combinations when you actually build a forecasting
    model with ARIMA to find the most optimal set of parameters. Here, we are training
    our ARIMA model up to June 2017 and we will test our predictions for July to December
    2017.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the following command, we can view the trained model results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The model summary looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.11: Summary of the ARIMA model fit'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the key things to note in this model summary output are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ar**: These are the AR components within the ARIMA model. As we have given
    12 for the AR component, there are 12 lagged variables that this model regresses
    on and each `coef` shows the coefficient of each lag variable with the target
    variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ma**: These are the MA components within the ARIMA model. We have given 3
    for our example for the MA component, so there are three variables that the model
    regresses on and each `coef` shows the coefficient of each MA variable with the
    target variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AIC/BIC**: We won’t go into too much detail about these metrics, but the
    **Akaike information criterion** (**AIC**) and the **Bayes information criterion**
    (**BIC**) are the metrics that can be used to evaluate the model fit and compare
    among different models. The lower the values, the better the model fit is without
    overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To find an optimal set of parameters, you will have to run numerous simulations
    with different sets of `(p, q, d)` parameters. Or, you can also use a package,
    such as `pmdarima`, to automatically discover the optimal parameters for the ARIMA
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reference: [https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html)'
  prefs: []
  type: TYPE_NORMAL
- en: ARIMA model diagnostics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `statsmodels` package provides a handy way of diagnosing the trained ARIMA
    model. The `plot_diagnostics` function of the `ARIMA` model can be used to visualize
    the key diagnostic plots, as in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The chart should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.12: ARIMA model diagnostics plots'
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in this chart, there are four components in this diagnostic plot.
    Let’s dive deeper into each of these:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Standardized residuals over time (top-left chart)**: This chart shows the
    residuals or the errors across time. For a perfect model, we would expect it to
    be completely random without any noticeable pattern. However, in our case, there
    still are some minor seasonal patterns that are noticeable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Histogram and estimated density of standardized residuals (top-right chart)**:
    This chart shows the distribution of the standardized residuals. For a perfect
    model, we would expect it to show a Gaussian or normal curve with a mean of 0
    and a standard deviation of 1\. Our model is very close to the theoretical normal
    curve, which suggests that the residuals are nearly normally distributed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Normal Q-Q plot (bottom-left chart)**: This chart shows theoretical quantile
    distributions against the actual quantile distributions of the fitted model. It
    suggests that the residuals are normal when the dots are closely aligned with
    the straight line. In our case, it is not perfect but somewhat closely aligned
    with the straight line, which suggests that the residuals are nearly normally
    distributed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Correlogram (bottom-right chart)**: This chart shows the autocorrelation
    of residual terms across lag periods. The smaller the correlation values, the
    more random the residuals are. Our example shows minimal correlations that suggest
    that the residuals are not correlated with each other.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, these diagnostic plots tell us that the residuals are generally
    normally distributed in our case.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting with the ARIMA model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now it is finally the time to make predictions with the ARIMA model that we
    have trained. Take a look at the following code first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The `statsmodels` package’s `ARIMA` model provides a function named `get_forecast`.
    The `steps` parameter is used to define how many steps into the future you would
    like to make predictions for. It also provides a function named `conf_int`, which
    gives a confidence band of the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can easily plot the prediction results with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'When you run this code, you should get a chart similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.13: ARIMA model prediction plot'
  prefs: []
  type: TYPE_NORMAL
- en: This chart shows previous monthly furniture sales data as well as the predictions
    and confidence band or interval for the predictions. As you may remember, we have
    trained the model with data up to June 2017 and we have made predictions for six
    steps from July 2017, which is from July to December 2017.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see from these predictions, the predictions from the ARIMA model
    are directionally well aligned with the actual observed data. Also, the actual
    values fall within the confidence bands, suggesting the reliability of the usage
    of the predictions based on the confidence intervals. One of the frequently used
    metrics for measuring the accuracy of time-series forecasts is RMSE, using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This gives us the result `5913.227463714012`.
  prefs: []
  type: TYPE_NORMAL
- en: Here, the RMSE of our predictions for the next 6 months was about 5913\. We
    will compare this value against other time-series forecasting models’ values that
    we will experiment with in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: There are many other metrics that can be used to measure the time-series model
    performance, aside from RMSE. Some other commonly used metrics are **mean absolute
    error** (**MAE**), **mean absolute percentage error** (**MAPE**), and **mean absolute
    scaled error** (**MASE**). Try some other regression metrics and see how they
    differ from each other!
  prefs: []
  type: TYPE_NORMAL
- en: Prophet time-series modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Prophet** is an open-source package from Meta (formerly Facebook) for time-series
    forecasting. Similar to the ARIMA model we have just discussed, the Prophet model
    also takes trend and seasonality into consideration, except there is more flexibility
    and more parameters you can fine-tune the time-series models with, and holiday
    effects are also included. So, there are largely three components in the Prophet
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Growth (or trend)**: Prophet models overall growth or trend. There are three
    assumptions you can make for your growth factor of the time-series data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Linear**: This is the default assumption of Prophet and is used when the
    overall trend is expected to be linear.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logistic**: This should be used when there is a cap or floor in the trend
    of your time-series data.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flat**: This is when you assume there is no growth over time.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Seasonality**: By default, this is set to *auto*, but depending on your observations
    within your time-series data, you can set it to model daily, weekly, or yearly
    seasonalities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Holidays**: One of the key differentiators the Prophet has is its notion
    of holidays. As holidays have significant impacts on time-series outcomes, it
    is beneficial to be able to model holiday effects on your time-series data with
    Prophet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we are going to experiment with modeling the monthly furniture
    sales with Prophet.
  prefs: []
  type: TYPE_NORMAL
- en: For more detailed information on the parameters that you can fine-tune with
    Prophet, we suggest you visit their official site ([https://facebook.github.io/prophet/docs/quick_start.html](https://facebook.github.io/prophet/docs/quick_start.html))
    or their GitHub page ([https://github.com/facebook/prophet/blob/main/python/prophet/forecaster.py](https://github.com/facebook/prophet/blob/main/python/prophet/forecaster.py)).
  prefs: []
  type: TYPE_NORMAL
- en: Training a Prophet model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order to train a Prophet model, make sure you have the package installed
    first. You can use the following command to have the package installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step to training a Prophet model is to prepare the data that it expects.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are using monthly furniture data up to December
    2016 as our train set. The requirements for the Prophet model for the train set
    are the columns `ds` and `y`, where `ds` is for the dates and times of a given
    record and `y` is for the time-series values.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this train set, we can easily train a Prophet model using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are initializing the model with the `Prophet` class and with the default
    parameters, which essentially instructs the model to assume linear growth trends
    and seasonality with no holiday effects. Then, we use the `fit` function with
    the train set DataFrame that we have prepared previously to train the model.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting with a Prophet model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have a trained Prophet model, it is time to make some predictions.
    One thing we need to do for a Prophet model to make predictions is to generate
    a series of dates it should make predictions for. Prophet provides a handy function
    to do this, as shown in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are using the `make_future_dataframe` function. The `periods` parameter
    defines how many future dates or periods we would like to make predictions for
    and the `freq` parameter defines what the frequency of each future date or period
    should be, where we define it to be monthly with `'MS'` as an input for the parameter.
  prefs: []
  type: TYPE_NORMAL
- en: The newly created variable should now have dates ranging from January 2014 to
    December 2018\. As you may remember, we have used monthly series up to December
    2016 as our train set, so from January 2017 to December 2018 is essentially what
    we would like to make predictions for as out-of-sample predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following code for generating predictions with the trained
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The `predict` function generates a DataFrame, `forecast`, which contains predicted
    data for each period, such as predicted value, upper and lower bound, modeled
    trend, and so forth. Some of the key fields within the `forecast` DataFrame that
    are the most relevant to us are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.14: Prediction results of a Prophet model'
  prefs: []
  type: TYPE_NORMAL
- en: The `yhat` column is the predicted value for a given period and `yhat_lower`
    and `yhat_upper` are the lower and upper boundaries of the predicted confidence
    intervals.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can easily visualize these predictions and prediction confidence intervals
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a closer look at this code. The Prophet model object has the `plot`
    function, which generates a plot with predictions as a line chart, prediction
    intervals as an area chart, and actual values as a scatter chart. Then, we add
    out-of-sample data points as a scatter plot with the marker `x`. This chart should
    look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.15: Prophet model prediction plot'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to what we have done with the ARIMA model, we can also look at the
    RMSE of the Prophet model predictions using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Compared to the RMSE of the ARIMA model, which was around 5913, the Prophet
    model with an RMSE of about 4295 seems to have predictions that are closer to
    the actuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, Prophet also models trend and seasonality decompositions and provides
    an easy way to visualize them, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting chart should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_04_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.16: Prophet model time-series decomposition plot'
  prefs: []
  type: TYPE_NORMAL
- en: Similar to what we have seen previously when we decomposed the time-series data
    into trend and seasonality, the Prophet model also identified an overall uptrend
    and spikes in December and drops in January. As we have seen so far, Prophet provides
    handy and reliable tools for modeling time-series data.
  prefs: []
  type: TYPE_NORMAL
- en: With this knowledge, we will look at another way of modeling time-series data
    with a deep learning approach in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Other time-series models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have discussed time-series modeling with ARIMA and Prophet in this chapter.
    However, there are various other algorithms and models that can be used to model
    time-series data. There are largely three types of approaches to time-series modeling:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Statistical models**: The statistical approaches to modeling time-series
    data have been around for decades. The ARIMA model is one of the most frequently
    used statistical models and was developed in the 1970s and is still used to date.
    To name a few other statistical models that are often used:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Exponential smoothing**: One of the oldest time-series forecasting methods,
    which gives more weight to recent observations for averaging time-series data
    points'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalized AutoRegressive Conditional Heteroskedasticity (GARCH)**: A frequently
    used model in finance that models the variance of the error terms that is dependent
    on time, such as increasing or decreasing volatility or variance over time'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Seasonal ARIMA (SARIMA)**: An extension of the ARIMA model that incorporates
    the seasonality component on top of the ARIMA components'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ML models**: Although not as frequently used as other statistical models
    and deep learning models, ML models are still used for time-series forecasting
    and for quick checks for predictability in time series. The advantage of ML models
    over statistical models is the ability to use various features when building forecasting
    models, whereas statistical models for time-series forecasting typically are univariate
    in nature. Here are some commonly used ML models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Linear regression**: One of the most basic regression models in ML that can
    be used to model time-series data with various features. Feature engineering is
    the key to making a linear regression model powerful.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tree-based models**: XGBoost, which learns the data by sequentially building
    decision trees that learn from previous trees’ errors, or random forest, which
    learns the data by building a bag of decision trees that each learn subparts of
    the data, can be used for time-series forecasting. The ability to model interactions
    and relationships among various features provides an advantage in modeling time-series
    data that has complex intercorrelations among the features.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Support vector machine (SVM)**: SVM does not perform when the dataset is
    noisy or the dimensionality of the dataset is large as it learns the data by finding
    a hyperplane that maximally separates different categories, and building such
    an effective hyperplane in high-dimensional space is difficult, but SVM is still
    used for time-series forecasting.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Deep learning (DL) models**: With the rising accessibility and availability
    of compute resources, there have been lots of developments in DL-driven time-series
    modeling. Similar to other tasks, such as image recognition and **Natural Language
    Processing** (**NLP**), DL models are used more and more often to make accurate
    time-series forecasts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Recurrent neural network (RNN) models**: RNN is a type of neural network
    that is designed to process sequential data. Because RNN models “remember” the
    previous inputs for future predictions, they work well for sequential data, such
    as speech and time-series data. DeepAR, ESRNN, and AR-Net are some of the RNN-based
    models for time-series forecasting.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Multilayer perceptron (MLP) models**: MLP is a type of neural network where
    there are multiple layers of neurons, where each of the layers learns the data
    and extracts features. MLP-based models, such as N-BEATS, NHiTs, and TSMixer,
    typically have a deep stack of fully connected layers. This group of models is
    proven to work well in practice.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Transformer-based models**: With the success of transformer-based models
    in NLP that use a multi-head attention mechanism that allows capturing different
    relationships and dependencies within the input, transformer-based time-series
    models and architectures are also actively being developed. **Temporal Fusion
    Transformer** (**TFT**) is an example of a transformer-based time-series forecasting
    model and is useful for multi-horizon and multivariate time-series forecasting.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**How to build a DL model for time-series data**'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'There is no shortage of Python packages that help you build time-series models.
    Darts, Kats, PyCaret, and PyTorch Forecasting are some of the frequently used
    Python packages that have easy-to-use implementations of DL models for time-series
    forecasting. If you’d like to see an example of N-BEATS model applications for
    this chapter, visit the following GitHub repository:'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[https://github.com/yoonhwang/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.4/TimeSeriesAnalysis.ipynb](https://github.com/yoonhwang/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.4/TimeSeriesAnalysis.ipynb)'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have discussed the importance of time-series analysis and
    its applications for marketing. From fundamental analyses of how data progresses
    over time and what stories and insights can be gathered from such analyses to
    the development of advanced time-series forecasting models, we have touched on
    a wide range of topics in time-series analysis. We have seen how moving averages
    and autocorrelations and visualizations of them play a critical role in understanding
    the big picture of events happening over time. We have also covered how time-series
    data can be decomposed into trends and seasonalities that uncover the hidden insights
    of cycles within businesses and different product lines. Lastly, we have experimented
    with two of the frequently used statistical methods of modeling the time-series
    data and how to make forecasts for the future that can then be used for more efficient
    and timely marketing campaigns. Although not discussed in depth in this chapter,
    we have shared some of the other AI/ML models that are used and are in development.
    Make sure you check out this chapter’s GitHub repository for an example of building
    a DL model for time-series forecasting. We will also go deeper into DL and Generative
    AI later, in Part IV of this book.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we are going to explore language modeling and how
    you can benefit from it for your next marketing initiatives. We will be discussing
    how to use and apply some of the NLP techniques using sentiment analysis as an
    example and how it can equip marketers to gauge the public perception of the brand
    or products and monitor and refine the marketing messages for better alignment
    with customer preferences.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genai](https://packt.link/genai)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code12856128601808671.png)'
  prefs: []
  type: TYPE_IMG
