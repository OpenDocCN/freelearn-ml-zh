["```py\n    image = image_uris.retrieve(region=region, \n                      framework='xgboost', version='1.3-1')\n    xgb = sagemaker.estimator.Estimator(...)\n    xgb.set_hyperparameters(objective='reg:squarederror', num_round=20)\n    data_channels={'train': train_input, 'validation': val_input}\n    xgb.fit(inputs=data_channels, ...)\n    ```", "```py\n    data_capture_config = DataCaptureConfig(enable_capture=True, \n               sampling_percentage=100,                                         \n               destination_s3_uri=s3_capture_upload_path)\n    ```", "```py\n    predictor = xgb.deploy(...,\n                   data_capture_config=data_capture_config)\n    ```", "```py\n    pred=predictor.predict(df_val[columns_no_target].values)\n    pred_f = [float(i) for i in pred[0]]\n    df_val['Prediction']=pred_f\n    model_quality_baseline_suffix = 'abalone/abalone_val_model_quality_baseline.csv'\n    df_val[['Rings', 'Prediction']].to_csv(model_quality_baseline_suffix, index=False)\n    model_quality_baseline_s3 = sagemaker.s3.S3Uploader.upload(\n            local_path=model_quality_baseline_suffix,\n            desired_s3_uri=desired_s3_uri,\n            sagemaker_session=sess)\n    ```", "```py\n    def generate_load_and_ground_truth():\n        gt_records=[]\n        for i, row in df_test.iterrows():\n            suffix = uuid.uuid1().hex\n            inference_id = f'{i}-{suffix}'\n\n            gt = row['Rings']\n            data = row[columns_no_target].values\n            new_data = drop_random(add_randomness(data))\n            new_data = convert_nparray_to_string(new_data)\n            out = predictor.predict(data = new_data, \n                           inference_id = inference_id)\n            gt_data = {'groundTruthData': {\n                                'data': str(gt), \n                                'encoding': 'CSV',\n                            },\n                       'eventMetadata': {\n                                'eventId': inference_id,\n                            },\n                       'eventVersion': '0',\n                       }\n            gt_records.append(gt_data)\n        upload_ground_truth(gt_records, ground_truth_upload_path, datetime.utcnow()) \n    ```", "```py\ndef generate_load_and_ground_truth_forever():\n    while True:\n        generate_load_and_ground_truth()\nfrom threading import Thread\nthread = Thread(target=generate_load_and_ground_truth_forever)\nthread.start()\n```", "```py\n    capture_file = get_obj_body(capture_files[-1])\n    print(json.dumps(json.loads(capture_file.split('\\n')[-2]), indent=2))\n    {\n      \"captureData\": {\n        \"endpointInput\": {\n          \"observedContentType\": \"text/csv\",\n          \"mode\": \"INPUT\",\n          \"data\": \"1.0,0.54,0.42,0.14,0.805,0.369,0.1725,0.21\",\n          \"encoding\": \"CSV\"\n        },\n        \"endpointOutput\": {\n          \"observedContentType\": \"text/csv; charset=utf-8\",\n          \"mode\": \"OUTPUT\",\n          \"data\": \"9.223058700561523\",\n          \"encoding\": \"CSV\"\n        }\n      },\n      \"eventMetadata\": {\n        \"eventId\": \"a9d22bac-094a-4610-8dde-689c6aa8189b\",\n        \"inferenceId\": \"846-01234f26730011ecbb8b139195a02686\",\n        \"inferenceTime\": \"2022-01-11T17:00:39Z\"\n      },\n      \"eventVersion\": \"0\"\n    }\n    ```"]