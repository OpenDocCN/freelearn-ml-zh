<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Machine Learning for Recommender Systems</h1>
                </header>
            
            <article>
                
<p class="calibre2">I hope that you are now excited about the amazing possibilities offered by the recommender systems that we've built. The techniques we've learned will provide you with a tremendous amount of data-taming prowess and practical abilities that you can already apply in your projects.</p>
<p class="calibre2">However, there is more to recommendation systems than that. Due to their large-scale applications in recent years, as an efficient solution to the information overload caused by the abundance of offerings on online platforms, recommenders have received a lot of attention, with new algorithms being developed at a rapid pace. In fact, all the algorithms that we studied in the previous chapter are part of a single category, called <strong class="calibre4">memory-based</strong> <strong class="calibre4">recommenders</strong>. Besides these, there's another very important class or recommender, which is known as<strong class="calibre4"> model-based</strong>.</p>
<p class="calibre2">In this chapter, we'll learn about them. We will discuss the following topics:</p>
<ul class="calibre10">
<li class="calibre11">Memory-based versus model-based recommendation systems</li>
<li class="calibre11">Data processing for training a model-based recommender</li>
<li class="calibre11">Building a model-based recommender</li>
<li class="calibre11">Hybrid recommendation systems</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p class="calibre2">The Julia package ecosystem is under continuous development and new package versions are released on a daily basis. Most of the times this is great news, as new releases bring new features and bug fixes. However, since many of the packages are still in beta (version 0.x), any new release can introduce breaking changes. As a result, the code presented in the book can stop working. In order to ensure that your code will produce the same results as described in the book, it is recommended to use the same package versions. Here are the external packages used in this chapter and their specific versions:</p>
<pre class="calibre17">CSV@v.0.4.3<br class="title-page-name"/>DataFrames@v0.15.2<br class="title-page-name"/>Gadfly@v1.0.1<br class="title-page-name"/>IJulia@v1.14.1<br class="title-page-name"/>Recommendation@v0.1.0+</pre>
<p class="calibre2">In order to install a specific version of a package you need to run:</p>
<pre class="calibre17"><strong class="calibre1">pkg&gt; add PackageName@vX.Y.Z</strong> </pre>
<p class="calibre2">For example:</p>
<pre class="calibre17"><strong class="calibre1">pkg&gt; add IJulia@v1.14.1</strong></pre>
<p class="calibre2">Alternatively you can install all the used packages by downloading the <kbd class="calibre12">Project.toml</kbd> file provided with the chapter and using <kbd class="calibre12">pkg&gt;</kbd> instantiate as follows:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; download("https://raw.githubusercontent.com/PacktPublishing/Julia-Projects/master/Chapter07/Project.toml", "Project.toml")</strong><br class="title-page-name"/><strong class="calibre1">pkg&gt; activate . </strong><br class="title-page-name"/><strong class="calibre1">pkg&gt; instantiate</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Comparing the memory-based versus model-based recommenders</h1>
                </header>
            
            <article>
                
<p class="calibre2">It is important to understand the strengths and weaknesses of both memory-based and model-based recommenders so that we can make the right choice according to the available data and the busi<span class="calibre5">ness requirements. As we saw in the previous chapter, we can classify recommender systems according to the data t</span><span class="calibre5">hey are using and the algorithms that are employed.</span></p>
<p class="calibre2">First, we can talk about non-personalized versus personalized recommenders. Non-personalized recommenders do not take into account user preferences, but that doesn't make them less useful. They are successfully employed when the relevant data is missing, for example, for a user that is new to the system or just not logged in. Such recommendations can include the best apps of the week on the <span class="calibre5">Apple App Store</span>, trending movies on Netflix, songs of the day on Spotify, NY Times bestsellers, Billboard Top 10, and so on.</p>
<p class="calibre2">Moving on to personalized recommender systems, these can be further split into content-based and collaborative system. A content-based system makes recommendations by matching an item, specifications. A famous example of this category is Pandora and its Music Genome Project. The Music Genome Project, which powers Pandora, is the most comprehensive analysis of music ever undertaken. They worked with trained musicologists who listened to music across all genres and decades, studying and collecting musical details on every track—450 musical attributes altogether. Pandora makes recommendations by picking other songs from its catalog that closely match the features (<em class="calibre16">features</em> is data-science language for attributes, properties, or tags) of the tracks that the user previously liked.</p>
<p class="calibre2">As for collaborative filtering, the idea behind it is that we can identify a metric that correctly reflects a user's tastes and then exploit it in combination with a dataset of other users, whose preferences were already collected. The underlying supposition is that if we have a pool of users that enjoy many of the same things, we can recommend to one of them some items from another's user list, which were not yet discovered by the targeted user. Any item in the list of options that is not part of the targeted user's list can readily be offered as a recommendation because similar preferences will lead to other similar choices.</p>
<p class="calibre2">This specific type of collaborative filtering was named user-based since the primary focus of the algorithm is the similarity between the target user and other users.</p>
<p class="calibre2">Another variation of the collaborative algorithm is <strong class="calibre4">item-based filtering</strong>. The main difference between this and user-based filtering is that the focus is on similar items. Which approach is the best depends on the specific use case—item-based recommendations are more efficient when the product catalog is considerably smaller and changes less often than the number of users and their preferences.</p>
<p class="calibre2">The last of the commonly accepted typologies divides the recommender systems into memory-based and model-based. <em class="calibre16">Memory-based</em> refers to the fact that the system requires the whole dataset to be loaded into working memory (the RAM). The algorithms rely on mapping to and from memory to consequently calculate the similarity between two users or items, and produce a prediction for the user by taking the weighted average of all the ratings. A few ways of computing the correlation can be used, such as <em class="calibre16">Pearson's r</em>. There are certain advantages to this approach, like the simplicity of the implementation, the easy facilitation of new data, or the fact that the results can be easily explained. But, unsurprisingly, it does come with significant performance downsides, creating problems when the data is sparse and the datasets are large.</p>
<p class="calibre2">Because of the limitations of the memory-based recommender systems, alternative solutions were needed, mainly driven by the continuous growth of online businesses and their underlying data. These were characterized by large volumes of users and an increasing number of products. The most famous example is Netflix's one million dollar competition—in 2006, Netflix offered a one million dollar prize to the individual or team that could improve their existing recommendations algorithm, called <strong class="calibre4">Cinematch</strong>, by at least 10%. It took three years for this feat to be achieved, and it was done by a joint team of initial competitors, who ultimately decided to join forces to grab the prize.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Learning about the model-based approach</h1>
                </header>
            
            <article>
                
<p class="calibre2">This innovative approach to recommender systems was named <em class="calibre16">model-based</em>, and it made extensive use of matrix factorization techniques. In this approach, models are developed using different machine learning algorithms to predict a user's ratings. In a way, the model-based approach can be seen as a complementary technique to improve memory-based recommendations. They address the matrix sparsity problem by guessing how much a user will like a new item. Machine learning algorithms are used to train on the existing vector of ratings of a specific user, and then build a model that can predict the user's score for an item that the user hasn't tried yet. Popular model-based techniques are Bayesian Networks, <strong class="calibre4">singular value decomposition</strong> (<strong class="calibre4">SVD</strong>), and <strong class="calibre4">Probabilistic Latent Semantic Analysis</strong> (<strong class="calibre4">PLSA</strong>) or <strong class="calibre4">Probabilistic Latent Semantic Indexing</strong> (<strong class="calibre4">PLSI</strong>).</p>
<p class="calibre2">There are a number of popular approaches for building the models:</p>
<ul class="calibre10">
<li class="calibre11"><strong class="calibre1">Probability</strong>: Making a recommendation is framed as a problem of predicting the probability of a rating being of a particular value. Bayesian networks are often used with this implementation.</li>
</ul>
<ul class="calibre10">
<li class="calibre11"><strong class="calibre1">Enhanced </strong><strong class="calibre1">memory-based</strong><span>: This uses a model to represent the similarities between users or items and then predicts the ratings. The Netflix prize-winning ALS-WR algorithm represents this type of implementation.</span></li>
<li class="calibre11"><strong class="calibre1">Linear algebra</strong><span>: Finally, recommendations can be made by performing linear algebra operations on the matrices of users and ratings. A commonly used algorithm is</span> SVD<span>.</span></li>
</ul>
<p class="calibre2">In the following sections, we'll implement a model-based recommender. We'll use a third-party Julia package and code our business logic around it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding our data</h1>
                </header>
            
            <article>
                
<p class="calibre2">To get conclusive results from our <strong class="calibre4">Machine Learning</strong> (<strong class="calibre4">ML</strong>) models, we need data—and plenty of it. There are many open source datasets available online. Kaggle, for example, provides a large collection of high quality and anonymized data dumps that can be used for training and experimenting, and is available for download at <a href="https://www.kaggle.com/datasets" class="calibre9"><span>https://www.kaggle.com/datasets</span></a>. Another famous data repository is provided by FiveThirtyEight, at <a href="https://github.com/fivethirtyeight/data" class="calibre9"><span>https://github.com/fivethirtyeight/data</span></a>. Buzzfeed also makes a large treasure of data public at <a href="https://github.com/BuzzFeedNews" class="calibre9"><span>https://github.com/BuzzFeedNews</span></a>. </p>
<p class="calibre2">For our project, we'll create a book recommendation system. We'll use the <em class="calibre16">Book-Crossing Dataset</em>, which is available for download at <a href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/" class="calibre9"><span>http://www2.informatik.uni-freiburg.de/~cziegler/BX/</span></a>. This data was collected during the months of August and September 2004, under permission, from the Book-Crossing community (<a href="https://www.bookcrossing.com/" class="calibre9"><span>https://www.bookcrossing.com/</span></a>). It includes over 1.1 million book ratings, for more than 270,000 books, from 278,000 users. The user data is anonymized, but still includes demographic information (location and age, where available). We'll use this data to train our recommendation system and then ask it for interesting new books for our users.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A first look at the data</h1>
                </header>
            
            <article>
                
<p class="calibre2">The dataset is composed of three tables—one for users, one for books, and one for ratings. The <kbd class="calibre12">BX-Users</kbd> table contains the users' data. The <kbd class="calibre12">User-ID</kbd> is a sequential integer value, as the original user ID has been anonymized. The <kbd class="calibre12">Location</kbd> and <kbd class="calibre12">Age</kbd> columns contain the corresponding demographic information. This is not available for all the users and in these cases, we'll encounter the <kbd class="calibre12">NULL</kbd> value (as the <kbd class="calibre12">NULL</kbd> string).</p>
<p class="calibre2">The <kbd class="calibre12">BX-Books</kbd> table stores the information about the books. For the unique identifier, we have the standard ISBN book code. Besides this, we are also provided with the book's title (the <kbd class="calibre12">Book-Title</kbd> column), author (<kbd class="calibre12">Book-Author</kbd>), publishing year (<kbd class="calibre12">Year-of-Publication</kbd>), and the publisher (<kbd class="calibre12">Publisher</kbd>). URLs of thumbnail cover images are also provided, corresponding to three sizes—small (<kbd class="calibre12">Image-URL-S</kbd>), medium (<kbd class="calibre12">Image-URL-M</kbd>), and large (<kbd class="calibre12">Image-URL-L</kbd>).</p>
<p class="calibre2">Finally, the <kbd class="calibre12">BX-Book-Ratings</kbd> table contains the actual ratings. The table has a simple structure, with three columns—<kbd class="calibre12">User-ID</kbd>, for the user making the rating; the ISBN of the book; and <kbd class="calibre12">Book-Rating</kbd>, which is the score. The ratings are expressed on a scale from 1 to 10, where higher is better. The value <kbd class="calibre12">0</kbd> signifies an implicit rating.</p>
<p class="calibre2">This dataset is available in SQL and CSV formats, packaged as ZIP archives. Please download the CSV version from <a href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip" class="calibre9"><span>http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip</span></a>.</p>
<p class="calibre2">Unzip the file somewhere on your computer.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loading the data</h1>
                </header>
            
            <article>
                
<p class="calibre2">Loading this dataset is going to be a bit more challenging, as we have to work with three distinct files, and due to the particularities of the data itself. Here is the head of the <kbd class="calibre12">BX-Users.csv</kbd> file, in a plain text editor:</p>
<p class="CDPAlignCenter"><img src="assets/9ffff291-6cef-498c-b11d-dac6f092589e.png" class="calibre88"/></p>
<p class="calibre2">We have to explicitly handle the following formatting particularities, which will otherwise cause the import to fail:</p>
<ul class="calibre10">
<li class="calibre11">The columns are separated by <kbd class="calibre12">;</kbd> instead of the more customary comma or <em class="calibre55">Tab</em></li>
<li class="calibre11">Missing values are represented by the string <kbd class="calibre12">NULL</kbd></li>
<li class="calibre11">The first row is the header, representing the column names</li>
<li class="calibre11">The data is enclosed in double quotes <kbd class="calibre12">" "</kbd>, and double quotes within the data itself are escaped by backslashes, for example, <kbd class="calibre12">"1273";"valladolid, \"n/a\", spain";"27"</kbd></li>
</ul>
<p class="calibre2">Fortunately, the CSV package provides additional options for passing in all of this information when reading in the file:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">users = CSV.read("BX-Users.csv", header = 1, delim = ';', missingstring = "NULL", escapechar = '\\')</strong> </pre>
<p class="calibre2">It might take a bit of time to load the table, but eventually, we'll get the sweet taste of success—<kbd class="calibre12">278858</kbd> rows loaded into memory!</p>
<p class="CDPAlignCenter"><img src="assets/585c070e-919b-4120-8947-7a9ebd932893.png" class="calibre89"/></p>
<p class="calibre2">We'll use the same approach to load the books and rankings tables:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; books = CSV.read("BX-Books.csv", header = 1, delim = ';', missingstring = "NULL", escapechar = '\\') 
271379×8 DataFrames.DataFrame 
# output omitted # 
 
julia&gt; books_ratings = CSV.read("BX-Book-Ratings.csv", header = 1, delim = ';', missingstring = "NULL", escapechar = '\\') 
1149780×3 DataFrames.DataFrame 
# output omitted #</strong> </pre>
<p class="calibre2">Excellent! We now have all three tables loaded into memory as <kbd class="calibre12">DataFrames</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Handling missing data</h1>
                </header>
            
            <article>
                
<p class="calibre2">In data science, missing values occur when no data value is stored for a field in a record—<span class="calibre5">i</span>n other words, when we don't have a value for a column in a row. It is a common scenario, but nonetheless, it can have a significant negative effect on the usefulness of the data, so it needs to be explicitly handled.</p>
<p class="calibre2">The approach in <kbd class="calibre12"><span>DataFrames</span></kbd> is to mark the missing value by using the <kbd class="calibre12"><span>Missing</span></kbd> type. The default behavior is the propagation of the <span class="calibre5">missing</span> values, thus <em class="calibre16">poisoning</em> the data operations that involve <kbd class="calibre12">missing</kbd>—that is, operations involving valid input, and <kbd class="calibre12">missing</kbd> will return <kbd class="calibre12">missing</kbd> or <kbd class="calibre12">fail</kbd>. Hence, in most cases, the missing values need to be addressed in the data-cleaning phase.</p>
<p class="calibre2">The most common techniques for handling missing values are as follows:</p>
<ul class="calibre10">
<li class="calibre11"><strong class="calibre1">Deletion</strong>: The rows containing the missing variables are deleted (also called <strong class="calibre1">listwise deletion</strong>). The downside of this approach is that it leads to loss of information. However, if we have plenty of data and not many incomplete records (say, under 10%), this is the simplest approach and the most commonly used.</li>
<li class="calibre11"><strong class="calibre1">Imputation</strong><span>: The <kbd class="calibre12">missing</kbd> values are inferred using some technique, usually</span> <kbd class="calibre12">mean</kbd><span>,</span> <kbd class="calibre12">median</kbd>, <span>or</span> <kbd class="calibre12">mode</kbd><span>. However, you need to be careful, as this artificially reduces the variation of the dataset. As an alternative, a predictive model could be used to infer the missing value by applying statistical methods.</span></li>
</ul>
<div class="packtinfobox">You can read more about Julia's treatment of missing values in the documentation at <a href="https://docs.julialang.org/en/v1.0/manual/missing/" class="calibre19"><span>https://docs.julialang.org/en/v1.0/manual/missing/</span></a>, while a more advanced discussion of the theoretical aspects of handling missing data can be found at <span><a href="https://datascience.ibm.com/blog/missing-data-conundrum-exploration-and-imputation-techniques/" class="calibre19">https://datascience.ibm.com/blog/missing-data-conundrum-exploration-and-imputation-techniques/</a>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data analysis and preparation</h1>
                </header>
            
            <article>
                
<p class="calibre2">Let's get a feel of the data, starting with the users:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; using DataFrames 
julia&gt; describe(users, stats = [:min, :max, :nmissing, :nunique, :eltype])  </strong></pre>
<p class="calibre2">The output is as follows:</p>
<p class="CDPAlignCenter"><img src="assets/70cbc219-b188-4fc6-a176-9ab636781edb.png" class="calibre90"/></p>
<p class="calibre2">We chose a few key stats—the minimum and maximum values, the number of missing and unique values, and the type of data. Unsurprisingly, the <kbd class="calibre12">User-ID</kbd> column, which is the table's primary key, starts at <kbd class="calibre12">1</kbd> and goes all the way up to <kbd class="calibre12">278858</kbd> with no missing values. However, the <kbd class="calibre12">Age</kbd> column shows a clear sign of data errors—the maximum age is <kbd class="calibre12">244</kbd> years! Let's see what we have there by plotting the data with <kbd class="calibre12">Gadfly</kbd>:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; using Gadfly <br class="title-page-name"/>julia&gt; </strong><strong class="calibre1">plot(users, x = :Age, Geom.histogram(bincount = 15))</strong> </pre>
<p class="calibre2">The output is as follows:</p>
<p class="CDPAlignCenter"><img src="assets/498825bb-b25d-4f9e-99d9-78c129837a0f.png" class="calibre91"/></p>
<p class="calibre2">We rendered a histogram of the ages, splitting the data into 15 intervals. We have some outliers indicating incorrect ages, but most of the data is distributed within the expected range, up to 80-90 years old. Since anything after <strong class="calibre4">100</strong> years old is highly unlikely to be correct, let's get rid of it. The simplest way is to filter out all the rows where the age is greater than <strong class="calibre4">100</strong>:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; users = users[users[:Age] .&lt; 100, :] <br class="title-page-name"/>ERROR: ArgumentError: unable to check bounds for indices of type Missing </strong></pre>
<p class="calibre2">Oops! Our <kbd class="calibre12">Age</kbd> column has <kbd class="calibre12">missing</kbd> values that cannot be compared. We could remove these as well, but in this case, the missing age seems to be more of a symptom of the user not disclosing the information, rather than a data error. Therefore, I'm more inclined to keep the rows while replacing the missing data with valid values. The question is, what values? Imputation using the <kbd class="calibre12">mean</kbd> seems like a good option. Let's compute it:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; using Statistics 
julia&gt; mean(skipmissing(users[:Age])) 
34.75143370454978</strong> </pre>
<p class="calibre2">We used the <kbd class="calibre12">skipmissing</kbd> function to iterate over all the non-missing <kbd class="calibre12">Age</kbd> values and compute the <kbd class="calibre12">mean</kbd>. Now, we can use this in conjunction with <kbd class="calibre12">coalesce</kbd> to replace the missing values:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; users[:Age] = coalesce.(users[:Age], mean(skipmissing(users[:Age]))) 
278858-element Array{Real,1}: 
 34.75143370454978 
 18 
 34.75143370454978 
 17 
 34.75143370454978 
# output omitted #</strong> </pre>
<p class="calibre2">We are effectively replacing the <kbd class="calibre12">Age</kbd> column of the <kbd class="calibre12">users</kbd> <kbd class="calibre12">DataFrame</kbd> with a new array, resulting from the application of <kbd class="calibre12">coalesce</kbd> to the same <kbd class="calibre12">Age</kbd> column. Please notice the dot in the invocation of <kbd class="calibre12">coalesce</kbd>, indicating that it is applied element-wise.</p>
<p class="calibre2">Great—finally, we need to get rid of those erroneous ages:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; users = users[users[:Age] .&lt; 100, :] 
278485×3 DataFrame</strong><br class="title-page-name"/><strong class="calibre1"> # output omitted # 
 
julia&gt; </strong><strong class="calibre1">head(users)</strong> </pre>
<p class="calibre2">The output is as follows:</p>
<p class="CDPAlignCenter"><img src="assets/0f902d24-567b-478f-a590-6b8cf26c6159.png" class="calibre92"/></p>
<p class="calibre2">Looking good!</p>
<p class="calibre2">We're done with the users, so let's move on to the books data:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; describe(books, stats = [:nmissing, :nunique, :eltype])</strong> </pre>
<p class="calibre2"><span class="calibre5">The output is as follows:</span></p>
<p class="CDPAlignCenter"><img src="assets/3de5518e-aeda-441a-bd2c-7b1db4d01217.png" class="calibre93"/></p>
<p class="calibre2">The data looks much cleaner—first of all, there's no missing values. Then, looking at the counts for <kbd class="calibre12">nunique</kbd>, we can tell that some of the books have identical titles and that there's a considerable amount of authors that have published more than one book. Finally, the books come from almost 17,000 publishers.</p>
<p class="calibre2">So far, so good, but let's take a look at the <kbd class="calibre12">Year-Of-Publication</kbd>:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; maximum(skipmissing(books[Symbol("Year-Of-Publication")])) 
2050 
 
julia&gt; minimum(skipmissing(books[Symbol("Year-Of-Publication")])) 
0</strong> </pre>
<p class="calibre2">Something's not right here—we have some publishing years that don't make sense. Some are too far in the past, while others are way in the future. I wonder what the distribution looks like. Let's render another histogram:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">plot(books, x = Symbol("Year-Of-Publication"), Geom.histogram)</strong> </pre>
<p class="calibre2"><span class="calibre5">The output is as follows:</span></p>
<p class="CDPAlignCenter"><img src="assets/be6a1974-795e-4fbe-9b19-bd91a4adbf8d.png" class="calibre94"/></p>
<p class="calibre2">Most of the data seems to be correct, but there are some faulty outliers. We can take a look at the values:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; unique(books[Symbol("Year-Of-Publication")]) |&gt; sort 
116-element Array{Union{Missing, Int64},1}: 
    0 
 1376 
 1378 
# output omitted # 
 2037 
 2038 
 2050</strong> </pre>
<p class="calibre2">At first sight, we can get rid of the rows that have the publishing year equal to <kbd class="calibre12">0</kbd>. We can also safely assume that all the rows where the publishing date is greater than the year when the data was collected (<kbd class="calibre12">2004</kbd>) are also wrong<span class="calibre5">, and so they can be removed. It's difficult to say what to do about the rest, but still, it's hard to believe that people have ranked books that were published</span><span class="calibre5"> in the Middle Ages. Let's just keep the books that were published between <kbd class="calibre12">1970</kbd> and <kbd class="calibre12">2004</kbd>:</span></p>
<pre class="calibre17"><strong class="calibre1">julia&gt; books = books[books[Symbol("Year-Of-Publication")] .&gt;= 1970, :] 
264071×8 DataFrame 
# output omitted # 
 
julia&gt; books = books[books[Symbol("Year-Of-Publication")] .&lt;= 2004, :] 
263999×8 DataFrame 
# output omitted # 
 
julia&gt; plot(books, x = Symbol("Year-Of-Publication"), Geom.histogram)</strong> </pre>
<p class="calibre2"><span class="calibre5">The output is as follows:</span></p>
<p class="CDPAlignCenter"><img src="assets/ab4f1089-c149-4fb8-9722-682870fa0892.png" class="calibre95"/></p>
<p class="calibre2">This is much better and entirely plausible.</p>
<p class="calibre2">Finally, let's check the ratings:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">describe(books_ratings)</strong> </pre>
<p class="calibre2"><span class="calibre5">The output is as follows:</span></p>
<p class="CDPAlignCenter"><span class="calibre5"><img src="assets/66b8603b-1bbb-49e5-9f74-efe4af383200.png" class="calibre96"/></span></p>
<p class="calibre2">There's no missing values, which is great. The <kbd class="calibre12">Book-Rating</kbd> values are between <kbd class="calibre12">0</kbd> (implicit rating) and <kbd class="calibre12">10</kbd>, where <kbd class="calibre12">1</kbd> to <kbd class="calibre12">10</kbd> represent explicit ratings. The median of <kbd class="calibre12">0.0</kbd> is a bit of a concern though, so let's take a look:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; plot(books_ratings, x = Symbol("Book-Rating"), Geom.histogram) </strong></pre>
<p class="calibre2"><span class="calibre5">The output is as follows:</span></p>
<p class="CDPAlignCenter"><img src="assets/48211541-9958-405a-808a-a6ab7b121f2e.png" class="calibre97"/></p>
<p class="calibre2">It turns out that most of the ratings are implicit, thus set to <kbd class="calibre12">0</kbd>. These are not relevant to our recommender, so let's get rid of them:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; books_ratings = books_ratings[books_ratings[Symbol("Book-Rating")] .&gt; 0, :] 
433671×3 DataFrame 
# output omitted # 
 
julia&gt; plot(books_ratings, x = Symbol("Book-Rating"), Geom.histogram)</strong> </pre>
<p class="calibre2">Here is the output:</p>
<p class="CDPAlignCenter"><img src="assets/617829d8-33c4-4844-ba12-cda577faf730.png" class="calibre98"/></p>
<p class="calibre2">We're doing great! There's one more step in our <strong class="calibre4">extract, transform, load</strong> (<strong class="calibre4">ETL</strong>) process—let's put the three <kbd class="calibre12">DataFrames</kbd> together by joining them on the matching columns, thus removing the various orphan entries (the ones that don't have corresponding rows in all the other tables).</p>
<p class="calibre2">First, we'll join book ratings and books:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; books_ratings_books = join(books_ratings, books, on = :ISBN, kind = :inner) 
374896×10 DataFrame 
# output omitted #</strong> </pre>
<p class="calibre2">We're using the <kbd class="calibre12">join</kbd> method, indicating the two <kbd class="calibre12">DataFrames</kbd> we want to join, plus the join column and the kind of join we want. An inner join requires that the result contains rows for values of the key that exist in both the first and second <kbd class="calibre12">DataFrame</kbd>.</p>
<p class="calibre2">Now, let's join with the user's data:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; books_ratings_books_users = join(books_ratings_books, users, on = Symbol("User-ID"), kind = :inner) 
374120×12 DataFrame 
# output omitted #</strong> </pre>
<p class="calibre2">Our dataset now contains only the valid data, nicely packed in a single <kbd class="calibre12">DataFrame</kbd>.</p>
<p class="calibre2">As our ratings are on a scale between <kbd class="calibre12">1</kbd> and <kbd class="calibre12">10</kbd>, not all of these ratings can be considered an endorsement for the book. It's true that the vast majority of the rankings are above <kbd class="calibre12">5</kbd>, but a <kbd class="calibre12">5</kbd> is still not good enough for a useful recommendation. Let's simplify our data a bit to make the computations faster by assuming that any ranking starting with <kbd class="calibre12">8</kbd> represents a positive review and would make for a strong recommendation. Therefore, we'll keep only these rows and discard the rest:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; top_ratings = books_ratings_books_users[books_ratings_books_users[Symbol("Book-Rating")] .&gt;= 8, :] 
217991×12 DataFrame 
# output omitted #</strong> </pre>
<p class="calibre2">This is looking good, but it will look even better with just a small tweak to make the column names more Julia-friendly:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">for n in names(top_ratings) rename!(top_ratings, n =&gt; Symbol(replace(string(n), "-"=&gt;""))) end</strong> </pre>
<p class="calibre2">We will iterate over each column name and remove the dashes. This way, we'll be able to use the names without having to explicitly use the <kbd class="calibre12">Symbol</kbd> constructor every time. We'll end up with the following names:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; names(top_ratings) 
12-element Array{Symbol,1}: 
 :UserID 
 :ISBN 
 :BookRating 
 :BookTitle 
 :BookAuthor 
 :YearOfPublication 
 :Publisher 
 :ImageURLS 
 :ImageURLM 
 :ImageURLL 
 :Location 
 :Age</strong> </pre>
<p class="calibre2">We're getting closer—the last step in our data processing workflow is to check the number of reviews per user. The more reviews we have from a user, the better the preference profile we can create, leading to more relevant and better quality recommendations. Basically, we want to get a count of ratings, per user, and then get a count of each count (that is, how many rating of ones, twos, threes, and so on, up to ten ratings we have):</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">ratings_count = by(top_ratings, :UserID, df -&gt; size(df[:UserID])[1])</strong> </pre>
<p class="calibre2">Here, we group the <kbd class="calibre12">top_ratings</kbd> data by <kbd class="calibre12">UserID</kbd> and use the <kbd class="calibre12">size</kbd> function as our <kbd class="calibre12">aggregation</kbd> function, which returns a tuple of dimensions—out of which we retrieve just its first dimension. We'll get the following result, where the <kbd class="calibre12">x1</kbd> column contains the number of ratings provided by the corresponding user:</p>
<p class="calibre2"><span class="calibre5">The output is as follows:</span></p>
<p class="CDPAlignCenter"><img src="assets/b094b39c-89ef-45ac-b617-8929f72888a1.png" class="calibre99"/></p>
<p class="calibre2">Wondering what this data will reveal? Let's find out:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">describe(ratings_count)</strong> </pre>
<p class="calibre2"><span class="calibre5">Here is the output:</span></p>
<p class="CDPAlignCenter"><img src="assets/fc620be1-d226-4a70-a555-d4685ad1e86d.png" class="calibre100"/></p>
<p class="calibre2">The minimum number of ratings is <kbd class="calibre12">1</kbd>, while the most productive user has provided no less than <kbd class="calibre12">5491</kbd>, with a mean of around <kbd class="calibre12">5</kbd> reviews per user. Considering that the recommendations for a user with less than <kbd class="calibre12">5</kbd> reviews would be pretty weak anyway, we're better off removing the users without enough data:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; ratings_count = ratings_count[ratings_count[:x1] .&gt;= 5, :] 
7296×2 DataFrame 
# output omitted #</strong> </pre>
<p class="calibre2">We're only keeping the users that have at least <kbd class="calibre12">5</kbd> ratings. Let's see how the number of ratings is distributed now:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; plot(ratings_count, x = :x1, Geom.histogram(maxbincount = 6))</strong> </pre>
<p class="calibre2"><span class="calibre5">The output is as follows:</span></p>
<p class="CDPAlignCenter"><img src="assets/f96dcf0d-a017-4ebe-a612-878a4f3104bc.png" class="calibre101"/></p>
<p class="calibre2">Looks like the vast majority of users have up to <kbd class="calibre12">1000</kbd> ratings. What about the outliers with lots of reviews?</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">ratings_count[ratings_count[:x1] .&gt; 1000, :]</strong> </pre>
<p class="calibre2"><span class="calibre5">The output is as follows:</span></p>
<p class="CDPAlignCenter"><img src="assets/6075a11b-184a-4e9e-9e64-d846bbfacbf4.png" class="calibre102"/></p>
<p class="calibre2">There's only <kbd class="calibre12">3</kbd> users. We'd better remove them so that they don't skew our results:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; ratings_count = ratings_count[ratings_count[:x1] .&lt;= 1000, :] 
7293×2 DataFrame 
# output omitted #</strong> </pre>
<p class="calibre2">Now that we have the list of final users, the next step is to remove all the others from the <kbd class="calibre12">top_ratings</kbd> <kbd class="calibre12">DataFrame</kbd>. Again, let's use an inner join—it's pretty straightforward:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; top_ratings = join(top_ratings, ratings_count, on = :UserID, kind = :inner) 
150888×13 DataFrame 
# output omitted #</strong> </pre>
<p class="calibre2">That's it, our data is ready. Great job!</p>
<p class="calibre2">If you want, you can save this data to file by using <kbd class="calibre12">CSV.write</kbd>:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">CSV.write("top_ratings.csv", top_ratings)</strong> </pre>
<div class="packtinfobox">If you've had problems following along, don't worry. In a few paragraphs, I'll explain how you can load a ready-made dataset, which is provided in this chapter's support files.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training our data models</h1>
                </header>
            
            <article>
                
<p class="calibre2">Machine learning can be divided into four main types, depending on the methodology and the type of data that is used:</p>
<ul class="calibre10">
<li class="calibre11">Supervised</li>
<li class="calibre11">Unsupervised</li>
<li class="calibre11">Semi-supervised</li>
<li class="calibre11">Reinforcement</li>
</ul>
<p class="calibre2">In supervised learning, we start with a dataset that contains training (or teaching) data, where each record is labeled, representing both input (let's call it <em class="calibre16"><span class="calibre5">X</span></em>), and output values (named <em class="calibre16">Y</em>). Then, the algorithm's job is to identify a function <em class="calibre16">f</em> from input to output, so that <em class="calibre16">Y = f(X)</em>. Once this function is identified, it can be used on new data (that is, new inputs that are not labeled) to predict the output. Depending on the type of output that needs to be computed, if the output has to be assigned to a certain class of entities (as in, it represents categorical data), then a classification algorithm will be used. Alternatively, if the type of output is a numeric value, we'll be dealing with a regression problem.</p>
<p class="calibre2">With unsupervised machine learning, we have the inputs, but not the outputs. In such a scenario, once we use the learning dataset to train our system, the main goal will be data clustering, that is, generating different clusters of inputs and being able to assign new data to the most appropriate cluster.</p>
<p class="calibre2">Semi-supervised, as the name suggests, represents a mixture of the two previously described approaches, both of which are applicable when our data contains both labeled and unlabeled records.</p>
<p class="calibre2">In reinforcement learning, the algorithm is informed about the success of its previous decisions. Based on this, the algorithm modifies its strategy in order to maximize the outcome.</p>
<p class="calibre2">Depending on the learning style and the specific problem that's meant to be solved, there are a multitude of algorithms that can be applied. For supervised learning, we can use regression (linear or logistic), decision trees, or neural networks, to name just a few. With unsupervised learning, we could choose k-means clustering or <kbd class="calibre12">Apriori</kbd> algorithms.</p>
<p class="calibre2">Since our data is tagged (we have the rating for each user), we are dealing with a supervised machine learning problem. For our test case, since our data is represented as a matrix, we'll employ an algorithm called <strong class="calibre4">Matrix Factorization</strong> (<strong class="calibre4">MF</strong>).</p>
<div class="packtinfobox">You can read more about the various types of ML algorithms and how to choose them at the following links:<br class="title-page-name"/>
<a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice" class="calibre19"><span>https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice<br class="title-page-name"/></span></a><a href="https://blog.statsbot.co/machine-learning-algorithms-183cc73197c" class="calibre19"><span>https://blog.statsbot.co/machine-learning-algorithms-183cc73197c<br class="title-page-name"/></span></a><a href="https://elitedatascience.com/machine-learning-algorithms" class="calibre19"><span>https://elitedatascience.com/machine-learning-algorithms<br class="title-page-name"/></span></a><a href="https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/" class="calibre19"><span>https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/</span></a></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Scaling down our dataset</h1>
                </header>
            
            <article>
                
<p class="calibre2">Training machine learning models at scale usually requires (lots of) powerful computers and plenty of time. If you have neither of these while reading this book, I have prepared a smaller dataset so that you can go through our project.</p>
<p class="calibre2">Training the recommender on the full <kbd class="calibre12">top_ratings</kbd> data took over 24 hours on my quad-core, 16 GB RAM laptop. If you're so inclined, feel free to try it. It is also available for download at <a href="https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/large/top_ratings.csv.zip" target="_blank" class="calibre9">https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/large/top_ratings.csv.zip</a>.</p>
<p class="calibre2">However, if you'd like to follow through the code while reading this chapter, please download the <kbd class="calibre12">top_ratings.csv</kbd> file that's provided with this chapter's support files at <a href="https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/top_ratings.csv" target="_blank" class="calibre9">https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/top_ratings.csv</a>. I will be using the data from this smaller file for the remainder of this chapter.</p>
<p class="calibre2">Once you've downloaded the file, you can load its content into the <kbd class="calibre12">top_ratings</kbd> variable by using the <kbd class="calibre12">CSV.read</kbd> function:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; top_ratings = CSV.read("top_ratings.csv")  
11061×13 DataFrame 
# output omitted #</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training versus testing data</h1>
                </header>
            
            <article>
                
<p class="calibre2">A common strategy in machine learning implementations is to split the data into training (some 80-90%) and testing (the remaining 10-20%) datasets. First, we'll initialize two empty <kbd class="calibre12"><span>DataFrames</span></kbd> to store this data:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; training_data = DataFrame(UserID = Int[], ISBN = String[], Rating = Int[]) 
0×3 DataFrame 
 
julia&gt; test_data = DataFrame(UserID = Int[], ISBN = String[], Rating = Int[]) 
0×3 DataFrame</strong> </pre>
<p class="calibre2">Next, we'll iterate through our <kbd class="calibre12"><span>top_ratings</span></kbd> and put the contents into the corresponding <kbd class="calibre12"><span>DataFrame</span></kbd>. We'll go with 10% of data for testing—so with each iteration, we'll generate a random integer between <kbd class="calibre12">1</kbd> and <kbd class="calibre12">10</kbd>. The chances of getting a <kbd class="calibre12">10</kbd> are, obviously, one in ten, so when we get it, we put the corresponding row into the test dataset. Otherwise, it goes into the training one, as follows:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">for row in eachrow(top_ratings)</strong><br class="title-page-name"/><strong class="calibre1"> rand(1:10) == 10 ? </strong><br class="title-page-name"/><strong class="calibre1"> push!(test_data, convert(Array, row[[:UserID, :ISBN, :BookRating]])) :</strong><br class="title-page-name"/><strong class="calibre1"> push!(training_data, convert(Array, row[[:UserID, :ISBN, :BookRating]]))</strong><br class="title-page-name"/><strong class="calibre1"> end </strong> </pre>
<p class="calibre2">There's no canonical way for pushing a <kbd class="calibre12"><span>DataFrameRow</span></kbd> onto another <span class="calibre5"><kbd class="calibre12">DataFrame</kbd>,</span> so we're using one of the recommended approaches, which is to convert the row into an <kbd class="calibre12"><span>Array</span></kbd> and <kbd class="calibre12"><span>push!</span></kbd> it to the <kbd class="calibre12">DataFrame</kbd>. Our training and testing datasets are now ready.</p>
<p class="calibre2">For me, they look like this, but since the data was generated randomly, it will be different for you:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; test_data 
1056×3 DataFrame</strong><br class="title-page-name"/><strong class="calibre1"> # output omitted # 
 
julia&gt; training_data 
10005×3 DataFrame 
# output omitted #</strong> </pre>
<p class="calibre2">If you prefer for us to work with the same datasets, you can download the data dump from this chapter's support files (available at <a href="https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/training_data.csv" target="_blank" class="calibre9">https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/training_data.csv</a> and <a href="https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/test_data.csv" target="_blank" class="calibre9">https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/test_data.csv</a>, respectively) and read them in as follows:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; test_data = CSV.read("data/test_data.csv") 
julia&gt; </strong><strong class="calibre1">training_data = CSV.read("data/training_data.csv")</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Machine learning-based recommendations</h1>
                </header>
            
            <article>
                
<p class="calibre2">Julia's ecosystem provides access to <kbd class="calibre12"><span>Recommendation.jl</span></kbd>, a package that implements a multitude of algorithms for both personalized and non-personalized recommendations. For model-based recommenders, it has support for SVD, MF, and content-based recommendations using TF-IDF scoring algorithms.</p>
<p class="calibre2">There's also another very good alternative—the <kbd class="calibre12"><span>ScikitLearn.jl</span></kbd> package (<a href="https://github.com/cstjean/ScikitLearn.jl" class="calibre9"><span>https://github.com/cstjean/ScikitLearn.jl</span></a>). This implements Python's very popular scikit-learn interface and algorithms in Julia, supporting both models from the Julia ecosystem and those of the scikit-learn library (via <span class="calibre5"><kbd class="calibre12">PyCall.jl</kbd>)</span>. The Scikit website and documentation can be found at <a href="http://scikit-learn.org/stable/" class="calibre9"><span>http://scikit-learn.org/stable/</span></a>. It is very powerful and definitely worth keeping in mind, especially for building highly efficient recommenders for production usage. For learning purposes, we'll stick to <kbd class="calibre12"><span>Recommendation</span></kbd>, as it provides for a simpler implementation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Making recommendations with Recommendation</h1>
                </header>
            
            <article>
                
<p class="calibre2">For our learning example, we'll use <kbd class="calibre12"><span>Recommendation</span></kbd>. It is the simplest of the available options, and it's a good teaching device, as it will allow us to further experiment with its plug-and-play algorithms and configurable model generators.</p>
<p class="calibre2">Before we can do anything interesting, though, we need to make sure that we have the package installed:</p>
<pre class="calibre17"><strong class="calibre1"> pkg&gt; add Recommendation#master  
 julia&gt; </strong><strong class="calibre1">using Recommendation</strong> </pre>
<div class="packttip">Please note that I'm using the <kbd class="calibre24">#master</kbd> version, because the tagged version, at the time of writing this book, was not yet fully updated for Julia 1.0.</div>
<p class="calibre2">The workflow for setting up a recommender with <kbd class="calibre12"><span>Recommendation</span></kbd> involves three steps:</p>
<ol class="calibre13">
<li class="calibre11">
<p class="calibre2">Setting up the training data</p>
</li>
<li class="calibre11">
<p class="calibre2">Instantiating and training a recommender using one of the available algorithms</p>
</li>
<li class="calibre11">
<p class="calibre2">Once the training is complete, asking for recommendations</p>
</li>
</ol>
<p class="calibre2">Let's implement these steps.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up the training data</h1>
                </header>
            
            <article>
                
<p class="calibre2"><kbd class="calibre12"><span>Recommendation</span></kbd> uses a <kbd class="calibre12"><span>DataAccessor</span></kbd> object to set up the training data. This can be instantiated with a set of <kbd class="calibre12"><span>Event</span></kbd> objects. A <kbd class="calibre12"><span>Recommendation.Event</span></kbd> is an object that represents a user-item interaction. It is defined like this:</p>
<pre class="calibre17">struct Event 
    user::Int 
    item::Int 
    value::Float64 
end </pre>
<p class="calibre2">In our case, the <kbd class="calibre12"><span>user</span></kbd> field will represent the <kbd class="calibre12"><span>UserID</span></kbd>, the <kbd class="calibre12"><span>item</span></kbd> field will map to the <span class="calibre5">ISBN,</span> and the <kbd class="calibre12"><span>value</span></kbd> field will store the <kbd class="calibre12"><span>Rating</span></kbd>. However, a bit more work is needed to bring our data in the format required by <kbd class="calibre12">Recommendation</kbd>:</p>
<ol class="calibre13">
<li class="calibre11">First of all, our ISBN data is stored as a string and not as an integer.</li>
<li class="calibre11">Second, internally, <kbd class="calibre12"><span>Recommendation</span></kbd> <span>builds a sparse matrix of</span> <kbd class="calibre12">user</kbd> * <kbd class="calibre12"> item</kbd> <span>and stores the corresponding values, setting up the matrix using sequential IDs. However, our actual user IDs are large numbers, and</span> <kbd class="calibre12"><span>Recommendation</span></kbd> <span>will set up a very large, sparse matrix, going all the way from the minimum to the maximum user IDs.</span></li>
</ol>
<p class="calibre2">What this means is that, for example, we only have 69 users in our dataset (as confirmed by <kbd class="calibre12">unique(training_data[:UserID]) |&gt; size</kbd>), with the largest ID being 277,427, while for books we have 9,055 unique ISBNs. If we go with this, <kbd class="calibre12"><span>Recommendation</span></kbd> will create a 277,427 x 9,055 matrix instead of a 69 x 9,055 matrix. This matrix would be very large, sparse, and inefficient.</p>
<p class="calibre2">Therefore, we'll need to do a bit more data processing to map the original user IDs and the ISBNs to sequential integer IDs, starting from 1.</p>
<p class="calibre2">We'll use two <kbd class="calibre12"><span>Dict</span></kbd> objects that will store the mappings from the <span class="calibre5"><kbd class="calibre12">UserID</kbd></span> and <kbd class="calibre12"><span>ISBN</span></kbd> columns to the recommender's sequential user and book IDs. Each entry will be of the form <kbd class="calibre12"><span>dict[original_id] = sequential_id</span></kbd>:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">user_mappings, book_mappings = Dict{Int,Int}(), Dict{String,Int}()</strong> </pre>
<p class="calibre2">We'll also need two counters to keep track of, and increment, the sequential IDs:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">user_counter, book_counter = 0, 0</strong> </pre>
<p class="calibre2">We can now prepare the <kbd class="calibre12"><span>Event</span></kbd> objects for our training data:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; events = Event[] </strong><br class="title-page-name"/><strong class="calibre1">julia&gt; </strong><strong class="calibre1">for row in eachrow(training_data) </strong><br class="title-page-name"/><strong class="calibre1"> global user_counter, book_counter user_id, book_id, rating = row[:UserID], row[:ISBN], row[:Rating] haskey(user_mappings, user_id) || (user_mappings[user_id] = (user_counter += 1)) haskey(book_mappings, book_id) || (book_mappings[book_id] = (book_counter += 1)) push!(events, Event(user_mappings[user_id], book_mappings[book_id], rating)) end</strong></pre>
<p class="calibre2">This will fill up the <span class="calibre5">events</span> array with instances of <kbd class="calibre12"><span>Recommendation.Event</span></kbd>, which represent a unique <kbd class="calibre12"><span>UserID</span></kbd>, <kbd class="calibre12"><span>ISBN</span></kbd>, and <kbd class="calibre12"><span>Rating</span></kbd> combination. To give you an idea, it will look like this:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; events 
10005-element Array{Event,1}: 
 Event(1, 1, 10.0) 
 Event(1, 2, 8.0) 
 Event(1, 3, 9.0) 
 Event(1, 4, 8.0) 
 Event(1, 5, 8.0) </strong><br class="title-page-name"/><strong class="calibre1"> # output omitted #</strong></pre>
<div class="packtinfobox">Please remember this very important aspect—in Julia, the <kbd class="calibre24">for</kbd> loop defines a new scope. This means that variables defined outside the <kbd class="calibre24">for</kbd> loop are not accessible inside it. To make them visible within the loop's body, we need to declare them as <kbd class="calibre24">global</kbd>.</div>
<p class="calibre2">Now, we are ready to set up our <span class="calibre5"><kbd class="calibre12">DataAccessor</kbd>:</span></p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">da = DataAccessor(events, user_counter, book_counter)</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building and training the recommender</h1>
                </header>
            
            <article>
                
<p class="calibre2">At this point, we have all that we need to instantiate our recommender. A very efficient and common implementation uses MF—unsurprisingly, this is one of the options provided by the <kbd class="calibre12"><span>Recommendation</span></kbd> package, so we'll use it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Matrix Factorization</h1>
                </header>
            
            <article>
                
<p class="calibre2">The idea behind MF is that, if we're starting with a large sparse matrix like the one used to represent <em class="calibre16">user x profile</em> ratings, then we can represent it as the product of multiple smaller and denser matrices. The challenge is to find these smaller matrices so that their product is as close to our original matrix as possible. Once we have these, we can fill in the blanks in the original matrix so that the predicted values will be consistent with the existing ratings in the matrix:</p>
<p class="CDPAlignCenter"><img src="assets/c67372c9-cbfd-4365-af58-5a1ba2baf472.png" class="calibre103"/></p>
<p class="calibre2">Our <em class="calibre16">user x books</em> rating matrix can be represented as the product between smaller and denser users and books matrices.</p>
<p class="calibre2">To perform the matrix factorization, we can use a couple of algorithms, among which the most popular are SVD and <strong class="calibre4">Stochastic Gradient Descent</strong> (<strong class="calibre4">SGD</strong>). <kbd class="calibre12"><span>Recommendation</span></kbd> uses SGD to perform matrix factorization.</p>
<p class="calibre2">The code for this looks as follows:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; recommender = MF(da) 
julia&gt; build(recommender)</strong> </pre>
<p class="calibre2">We instantiate a new <span class="calibre5">MF</span> recommender and then we <span class="calibre5">build</span> it—that is, train it. The build step might take a while (a few minutes on a high-end computer using the small dataset that's provided in this chapter's support files).</p>
<p class="calibre2">If we want to tweak the training process, since SGD implements an iterative approach for matrix factorization, we can pass a <kbd class="calibre12"><span>max_iter</span></kbd> argument to the <span class="calibre5">build</span> function, asking it for a maximum number of iterations. The more iterations we do, in theory, the better the recommendations—but the longer it will take to train the model. If you want to speed things up, you can invoke the <span class="calibre5">build</span> function with a <kbd class="calibre12">max_iter</kbd> of <kbd class="calibre12">30</kbd> or less—<kbd class="calibre12"><span>build(recommender, max_iter = 30)</span></kbd>.</p>
<p class="calibre2">We can pass another optional argument for the learning rate, for example, <kbd class="calibre12"><span>build (recommender, learning_rate=15e-4, max_iter=100)</span></kbd>. The learning rate specifies how aggressively the optimization technique should vary between each iteration. If the learning rate is too small, the optimization will need to be run a lot of times. If it's too big, then the optimization might fail, generating worse results than the previous iterations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Making recommendations</h1>
                </header>
            
            <article>
                
<p class="calibre2">Now that we have successfully built and trained our model, we can ask it for recommendations. These are provided by the <kbd class="calibre12"><span>recommend</span></kbd> function, which takes an instance of a recommender, a user ID (from the ones available in the training matrix), the number of recommendations, and an array of books ID from which to make recommendations as its arguments:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">recommend(recommender, 1, 20, [1:book_counter...])</strong> </pre>
<p class="calibre2">With this line of code, we retrieve the recommendations for the user with the recommender ID <kbd class="calibre12">1</kbd>, which corresponds to the <kbd class="calibre12">UserID</kbd> <kbd class="calibre12">277427</kbd> in the original dataset. We're asking for up to <kbd class="calibre12">20</kbd> recommendations that have been picked from all the available books.</p>
<p class="calibre2">We get back an array of a <kbd class="calibre12"><span>Pair</span></kbd> of book IDs and recommendation scores:</p>
<pre class="calibre17">20-element Array{Pair{Int64,Float64},1}: 
 5081 =&gt; 19.1974 
 5079 =&gt; 19.1948 
 5078 =&gt; 19.1946 
 5077 =&gt; 17.1253 
 5080 =&gt; 17.1246 
 # output omitted # </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Testing the recommendations</h1>
                </header>
            
            <article>
                
<p class="calibre2">Finally, our machine learning-based recommender system is ready. It will provide a significant boost in user experience for any bookshop, for sure. But before we start advertising it, we should make sure that it's reliable. Remember that we put aside 10% of our dataset for testing purposes. The idea is to compare the recommendations with actual ratings from the test data to see what degree of similarity exists between the two; that is, how many of the actual ratings from the dataset were in fact recommended. Depending on the data that's used for the training, you may want to test that both correct recommendations are made, but also that bad recommendations are not included (that is, the recommender does not suggest items that got low ratings, indicating a dislike). Since we only used ratings of 8, 9, and 10, we won't check if low-ranked recommendations were provided. We'll just focus on checking how many of the recommendations are actually part of the user's data.</p>
<p class="calibre2">Because the test data uses the original user and profile IDs, and our recommender uses the normalized, sequential IDs, we'll need a way to convert the data between the two. We already have the <kbd class="calibre12"><span>user_mappings</span></kbd> and <kbd class="calibre12"><span>book_mappings</span></kbd> dictionaries, which map from the original IDs to recommender IDs. However, we'll also need the reverse. So, let's start by defining a helper function for reversing a dictionary:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; </strong><strong class="calibre1">function reverse_dict(d) Dict(value =&gt; key for (key, value) in d) end</strong> </pre>
<p class="calibre2">This is simple, but very useful—we can now use this function to look up the original IDs based on the recommender IDs. For instance, if we want to test the recommendations for user <kbd class="calibre12">1</kbd>, we'll need to retrieve this user's actual ratings, so we'll need the original ID. We can easily get it with the following code:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; reverse_dict(user_mappings)[1] 
277427</strong> </pre>
<p class="calibre2">The same applies to the books mappings—for instance, the recommendation with ID <kbd class="calibre12">5081</kbd> corresponds to ISBN <kbd class="calibre12">981013004X</kbd> from the original dataset:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; reverse_dict(book_mappings)[5081] 
"981013004X"</strong> </pre>
<p class="calibre2">All right, let's check the test data that we put aside for <kbd class="calibre12">UserID</kbd> <kbd class="calibre12">277427</kbd> (recommender user <kbd class="calibre12">1</kbd>):</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; user_testing_data = test_data[test_data[:UserID] .== reverse_dict(user_mappings)[1], :] 
8×3 DataFrame</strong> </pre>
<p class="calibre2">The output is as follows:</p>
<p class="CDPAlignCenter"><img src="assets/21d47dc0-094c-4399-9181-b28e96e92e49.png" class="calibre104"/></p>
<p class="calibre2">The snippet filters the <span class="calibre5"><kbd class="calibre12">testing_data</kbd> </span><kbd class="calibre12"><span>DataFrame</span></kbd> by doing an element-wise comparison—for each row, it checks if the <kbd class="calibre12"><span>UserID</span></kbd> column equals <kbd class="calibre12">277427</kbd> (which is the ID returned by <kbd class="calibre12">reverse_dict(user_mappings)[1]</kbd>, remember?). If yes, then the  whole row is added to <kbd class="calibre12"><span>user_testing_data</span></kbd>.</p>
<p class="calibre2">To check for recommended versus actually rated profiles, the easiest approach is to intersect the vector of recommendations with the vector of ratings. So, the first thing to do is put the test ratings into a vector, out of the <kbd class="calibre12"><span>DataFrame</span></kbd>:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; test_profile_ids = user_testing_data[:, :ISBN] 
8-element Array{Union{Missing, String},1}: 
 "0060006641" 
 "0441627404" 
 "0446600415" 
 "0671727079" 
 "0671740504" 
 "0671749897" 
 "0836218817" 
 "0842370668"</strong> </pre>
<p class="calibre2">We just select the <span class="calibre5">ISBN</span> column data, for all the rows, as an <kbd class="calibre12"><span>Array</span></kbd>.</p>
<p class="calibre2">Doing the same for the recommendations is a bit more involved. Also, since I expect we'll want to test with various recommender settings and with different numbers of recommendations, it's best to define a function that converts the recommendations to a vector of ISBNs, so that we can easily reuse the code:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; function recommendations_to_books(recommendations) 
           [reverse_dict(book_mappings)[r[1]] for r in recommendations] 
       end</strong> </pre>
<p class="calibre2">The <kbd class="calibre12"><span>recommendations_to_books</span></kbd> function takes the vector of <kbd class="calibre12"><span>id =&gt; score</span></kbd> pairs generated by the recommender as its only argument and converts it into a vector of original ISBNs:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; recommendations_to_books(recommend(recommender, 1, 20, [1:book_counter...])) 
20-element Array{String,1}: 
 "981013004X" 
 "1856972097" 
 "1853263656" 
 "1853263133" 
 "1857231791"</strong><br class="title-page-name"/><strong class="calibre1"> # output omitted #</strong></pre>
<p class="calibre2">The <kbd class="calibre12"><span>recommendations_to_books</span></kbd> function outputs the ISBNs for the <kbd class="calibre12">20</kbd> recommended books.</p>
<p class="calibre2">Now, we have all of the pieces to check recommendations versus ratings:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; intersect(test_profile_ids, recommendations_to_books(recommend(recommender, 1, 500, [1:book_counter...]))) 
1-element Array{Union{Missing, String},1}: 
 "0441627404"</strong>  </pre>
<p class="calibre2">We use the <span class="calibre5">intersect</span> function to check what elements from the first vector—the list of books we put away for testing—also show up in the second vector, that is, the recommendations. We had to ask for <kbd class="calibre12">500</kbd> recommendations as the chances of hitting one of the eight test books in a pool of 9,055 books were very slim. This is due to the fact that we worked with very little data, but in a production environment and potentially billions of rows, we would get a lot more overlapping data.</p>
<p class="calibre2">Let's see what the top five recommendations were:</p>
<pre class="calibre17"><strong class="calibre1">julia&gt; for i in recommendations_to_books(recommend(recommender, 1, 20, [1:book_counter...])) top_ratings[top_ratings.ISBN .== i, :BookTitle] |&gt; println end  
 
Union{Missing, String}["Fun With Chinese Characters Volume 1"] 
Union{Missing, String}["Fantasy Stories (Story Library)"] 
Union{Missing, String}["The Wordsworth Complete Guide to Heraldry (Wordsworth Reference)"] 
Union{Missing, String}["The Savoy Operas (Wordsworth Collection)"] 
Union{Missing, String}["Against a Dark Background"]</strong> </pre>
<p class="calibre2">In an IJulia Notebook, we can even look at the covers, thus rendering a small piece of HTML using the cover's URLs:</p>
<pre class="calibre17">thumbs = DataFrame(Thumb = String[]) 
 
for i in recommendations_to_profiles(recommend(recommender, 1, 20, [1:book_counter...])) 
    push!(thumbs, top_ratings[top_ratings.ISBN .== i, :ImageURLL]) 
end 
 
for img in thumbs[:, :Thumb] 
    HTML("""&lt;img src="$(img)"&gt;""") |&gt; display 
end </pre>
<p class="calibre2">The output will be as follows:</p>
<div class="CDPAlignCenter1"><img src="assets/60e8823b-ff1e-4113-b583-1d6a9e89ca3c.png" class="calibre105"/></div>
<p class="calibre2">Excellent! We did a great job. We tamed a very complex dataset, performed advanced analysis, and then we optimized it for usage in our recommender. We then successfully trained our recommender and used it to generate book recommendations for our users.</p>
<p class="calibre2">Deploying and working with the <kbd class="calibre12">Recommendation</kbd> package is very straightforward, as I'm sure you've come to appreciate. Again, as in most data science projects, the ETL step was the most involved.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Learning about hybrid recommender systems</h1>
                </header>
            
            <article>
                
<p class="calibre2">There are some clear advantages when using model-based recommenders. As mentioned already, scalability is one of the most important. Usually, the models are much smaller than the initial dataset, so that even for very large data samples, the models are small enough to allow efficient usage. Another benefit is the speed. The time required to query the model, as opposed to querying the whole dataset, is usually considerably smaller.</p>
<p class="calibre2">These advantages stem from the fact that the models are generally prepared offline, allowing for almost instantaneous recommendations. But since there's no such thing as free performance, this approach also comes with a few significant negatives—on one hand, it is less flexible, because building the models takes considerable time and resources, making the updates difficult and costly; on the other hand, because it does not use the whole dataset, the predictions can be less accurate.</p>
<p class="calibre2"><span class="calibre5">As with everything, there's no silver bullet, and the best approach depends on the data you have at hand and the problem you need to solve. However, it doesn't always have to be memory-based versus model-based. Even more, it doesn't have to be just one recommender system. It turns out that multiple algorithms and approaches can be efficiently combined to compensate for the limitations of one type of recommender. Such architectures are called <strong class="calibre4">hybrid</strong>. Due to space limitations, we won't cover any implementations of hybrid recommender systems, but I want to give you an idea of the possible approaches. I'm just going to refer you to Robin Burke's classification from <em class="calibre16">Chapter 12</em> of <em class="calibre16">The Adaptive Web</em>, entitled <em class="calibre16">Hybrid Web Recommender Systems</em>. The whole chapter is available online for free at </span><a href="https://www.researchgate.net/publication/200121024_Hybrid_Web_Recommender_Systems" class="calibre9"><span>https://www.researchgate.net/publication/200121024_Hybrid_Web_Recommender_Systems</span></a><span class="calibre5">. If you're interested in this topic, I highly recommended it.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="calibre2">Recommender systems represent a very active and dynamic field of study. They started initially as a marginal application of machine learning algorithms and techniques, but due to their practical business value, they have become mainstream in recent years. These days, almost all major programming languages provide powerful recommendations systems libraries—and all major online businesses employ recommenders in one form or another.</p>
<p class="calibre2">Julia is a great language for building recommenders due to its excellent performance. Despite the fact that the language is still young, we already have a couple of interesting packages to choose from.</p>
<p class="calibre2">Now, you have a solid understanding of the model-based recommendation systems and of their implementation workflow—both on a theoretical and practical level. Plus, throughout our journey, we've also been exposed to more advanced data wrangling using <kbd class="calibre12"><span>DataFrames</span></kbd>, an invaluable tool in Julia's data science arsenal.</p>
<p class="calibre2">In the next chapter, we'll further improve our mastery of <span class="calibre5"><kbd class="calibre12">DataFrames</kbd>,</span> as we'll learn the secrets of metaprogramming in Julia, while developing an unsupervised machine learning system.</p>


            </article>

            
        </section>
    </body></html>