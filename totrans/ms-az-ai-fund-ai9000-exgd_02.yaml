- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Identify the Guiding Principles for Responsible AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定负责任人工智能的指导原则
- en: While AI can do some amazing things, it also has the potential to be part of
    truly terrible things—which is exactly what this chapter will try to address.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然人工智能可以做些惊人的事情，但它也有可能成为真正可怕事物的组成部分——这正是本章将试图解决的问题。
- en: How do we (as practitioners, developers, and consumers) protect against either
    intentional or unintentional malicious manipulation? Microsoft, for its part,
    has developed a set of six principles for the responsible development and implementation
    of AI-based solutions.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们（作为从业者、开发者和消费者）如何防止有意或无意的恶意操纵？微软在其部分，已经制定了一套六项原则，用于负责任地开发和实施基于人工智能的解决方案。
- en: Microsoft has termed these principles its **guiding principles for** **responsible
    AI**.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 微软将这些原则称为其**负责任人工智能的指导原则**。
- en: 'The objectives and skills we’ll cover in this chapter include the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖的目标和技能包括以下内容：
- en: Describe considerations for accountability
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述问责制的考虑因素
- en: Describe considerations for inclusiveness
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述包容性的考虑因素
- en: Describe considerations for reliability and safety
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述可靠性和安全的考虑因素
- en: Describe considerations for fairness
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述公平性的考虑因素
- en: Describe considerations for transparency
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述透明度的考虑因素
- en: Describe considerations for privacy and security
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述隐私和安全的考虑因素
- en: 'These principles are divided into two categories or perspectives: **ethical**
    and **explainable**. We’ll examine these two categories and how the principles
    fit into them. By the end of this chapter, you should be able to articulate how
    AI can be developed and implemented in a responsible manner.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些原则分为两个类别或视角：**伦理**和**可解释**。我们将探讨这两个类别以及原则如何融入其中。到本章结束时，你应该能够阐述人工智能如何以负责任的方式进行开发和实施。
- en: Understanding ethical principles
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解伦理原则
- en: 'The first category or perspective on responsible AI usage and development is
    that of ethical principles. From an ethical perspective, AI implementations should
    include the following considerations:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 负责任的人工智能使用和发展的第一个类别或视角是伦理原则。从伦理角度来看，人工智能的实施应包括以下考虑因素：
- en: Require accountability for designers and implementers
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要求设计者和实施者承担问责制
- en: Exhibit inclusivity
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展现包容性
- en: Ensure the output doesn’t cause harm
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保输出不会造成伤害
- en: Let’s look at how those ethical considerations map to Microsoft’s principles.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些伦理考量如何映射到微软的原则上。
- en: Describe considerations for accountability
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述问责制的考虑因素
- en: Microsoft’s accountability principle in responsible AI development emphasizes
    the importance of transparency, fairness, and oversight throughout the AI development
    lifecycle. This principle underscores the need for individuals and organizations
    involved in designing and deploying AI systems to be accountable for the actions
    and decisions of these systems, particularly as they evolve toward greater autonomy.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 微软在负责任的人工智能开发中的问责制原则强调在整个人工智能开发生命周期中透明度、公平性和监督的重要性。这一原则强调了设计者和部署人工智能系统的个人和组织对这些系统的行为和决策负责的必要性，尤其是在它们向更大自主性发展的过程中。
- en: To achieve accountability, Microsoft advocates for the establishment of internal
    review bodies within organizations to provide oversight, insights, and guidance
    on AI development and deployment. These bodies play a crucial role in ensuring
    that AI systems meet ethical and legal standards, and that they align with the
    organization’s governance and organizational principles.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现问责制，微软提倡在组织内部建立内部审查机构，以提供对人工智能开发和部署的监督、见解和指导。这些机构在确保人工智能系统符合伦理和法律标准，以及与组织的治理和组织原则保持一致方面发挥着关键作用。
- en: Central to Microsoft’s accountability principle is the requirement for organizations
    to assess the impact of AI systems on people, organizations, and society. This
    involves completing impact assessments early in the development process to evaluate
    potential risks and ethical considerations associated with the system’s intended
    uses. Regular reviews and updates of these assessments are also mandated to ensure
    ongoing compliance and adherence to responsible AI principles.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的问责制原则的核心是要求组织评估人工智能系统对个人、组织和社会的影响。这包括在开发早期完成影响评估，以评估与系统预期用途相关的潜在风险和伦理考量。还强制要求定期审查和更新这些评估，以确保持续遵守负责任的人工智能原则。
- en: Microsoft emphasizes the importance of transparency and communication with stakeholders
    regarding the capabilities and limitations of AI systems. This includes providing
    documentation to customers about the intended uses of the system as well as evidence
    demonstrating its fitness for purpose. In cases where evidence is lacking or refutes
    the system’s suitability for a particular use, Microsoft advocates for prompt
    action to rectify the issue and communicate transparently with customers.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 微软强调与利益相关者就人工智能系统的能力和局限性进行透明度和沟通的重要性。这包括向客户提供关于系统预期用途的文档以及证明其适用性的证据。在缺乏证据或证据反驳系统适用于特定用途的情况下，微软主张采取及时行动纠正问题并与客户进行透明沟通。
- en: The accountability principle encompasses a comprehensive framework for ensuring
    transparency, fairness, and ethical oversight throughout the AI lifecycle. By
    adhering to these principles, Microsoft aims to build trust with stakeholders
    and promote the responsible use of AI technologies for the benefit of society.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 责任原则涵盖了确保人工智能生命周期中透明度、公平性和道德监督的全面框架。通过遵守这些原则，微软旨在与利益相关者建立信任，并促进人工智能技术的负责任使用，以造福社会。
- en: Describe considerations for inclusiveness
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述包容性的考虑因素
- en: Inclusive AI mandates the consideration of all peoples’ experiences across the
    breadth of humanity. Adopting inclusive design practices enables developers to
    proactively identify and address potential barriers that might otherwise inadvertently
    exclude people.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 包容性人工智能要求考虑全人类的所有经验。采用包容性设计实践使开发者能够主动识别和解决可能无意中排除人们的潜在障碍。
- en: AI systems are meant to empower and engage everyone, bringing benefits to all
    sectors of society, irrespective of physical ability, gender, sexual orientation,
    ethnicity, or other factors. Microsoft’s commitment to inclusiveness in responsible
    AI development underscores the imperative of designing and deploying AI technologies
    in a manner that fosters diversity, equity, and inclusion. This principle reflects
    Microsoft’s dedication to creating AI systems that are accessible and advantageous
    to all individuals, regardless of their background, identity, or abilities. Examples
    of inclusivity might include leveraging speech-to-text, text-to-speech, and visual
    recognition technologies to empower individuals with hearing, visual, and other
    sensory impairments. Actively seeking ways to include others commonly overlooked
    is a key component of inclusive design.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统的目的是赋权并激发每个人，为社会的所有部门带来利益，无论其身体能力、性别、性取向、种族或其他因素。微软对负责任的人工智能发展中包容性的承诺强调了设计和部署人工智能技术以促进多样性、公平性和包容性的必要性。这一原则反映了微软致力于创建对所有人（无论其背景、身份或能力）都易于使用且有益的人工智能系统的承诺。包容性的例子可能包括利用语音转文本、文本转语音和视觉识别技术来赋权有听力、视觉和其他感官障碍的人。积极寻求包括其他通常被忽视的人的方法是包容性设计的关键组成部分。
- en: Central to Microsoft’s inclusiveness principle is the acknowledgment of AI’s
    potential to either exacerbate or mitigate existing inequalities. By prioritizing
    inclusivity in AI development, Microsoft aims to counter historical biases and
    promote fair and equitable outcomes for all users. This involves considering the
    diverse needs and perspectives of different demographic groups throughout the
    AI lifecycle.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的包容性原则的核心是承认人工智能有可能加剧或缓解现有的不平等。通过在人工智能开发中优先考虑包容性，微软旨在对抗历史偏见，并促进对所有用户公平和公正的结果。这涉及到在整个人工智能生命周期中考虑不同人口群体的多样性和观点。
- en: A pivotal aspect of Microsoft’s approach to inclusiveness in AI development
    is the promotion of diversity within the teams responsible for creating AI technologies.
    By fostering diverse teams representing various backgrounds, experiences, and
    viewpoints, Microsoft seeks to mitigate bias risks and ensure that AI systems
    are designed with inclusivity in mind. This diversity enables teams to identify
    and address potential biases and blind spots that might otherwise be overlooked.
    This same type of inclusivity exhibited in the design of the core technology should
    be extended to organizations leveraging AI to create solutions to ensure multiple
    viewpoints are considered.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 微软在人工智能开发中实现包容性的关键方面是促进负责创建人工智能技术的团队内部的多样性。通过培养代表各种背景、经验和观点的多元化团队，微软旨在减轻偏见风险，并确保人工智能系统在设计时考虑到包容性。这种多样性使团队能够识别和解决可能被忽视的潜在偏见和盲点。在设计核心技术时展现的这种包容性类型应扩展到利用人工智能创造解决方案的组织中，以确保考虑多个观点。
- en: Additionally, Microsoft advocates for inclusive design practices prioritizing
    accessibility and usability for all individuals, including those with disabilities
    or special needs. This entails integrating features such as alternative input
    methods, voice recognition, and screen readers into AI systems to ensure accessibility
    for individuals with diverse abilities.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，微软倡导包容性设计实践，优先考虑所有个体的可访问性和可用性，包括那些有残疾或特殊需求的个体。这包括将替代输入方法、语音识别和屏幕阅读器等特性集成到人工智能系统中，以确保具有不同能力的个体的可访问性。
- en: Moreover, Microsoft emphasizes engaging with diverse stakeholders throughout
    the AI development process, including community organizations, advocacy groups,
    and individuals from marginalized communities. This collaboration facilitates
    gathering feedback and insights to inform the design and deployment of AI technologies,
    ensuring responsiveness to the needs and concerns of all users.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，微软强调在整个人工智能开发过程中与多元化的利益相关者进行互动，包括社区组织、倡导团体以及来自边缘化社区的个体。这种合作有助于收集反馈和洞察，以指导人工智能技术的设计和部署，确保对所有用户的需要和担忧做出响应。
- en: Microsoft’s commitment to inclusiveness in responsible AI development underscores
    its dedication to building AI technologies that are inclusive, equitable, and
    accessible to all individuals. By prioritizing diversity, equity, and inclusion
    across the AI lifecycle, Microsoft aims to leverage AI’s potential to drive positive
    social change and create a more inclusive future for everyone.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 微软对负责任人工智能发展中包容性的承诺强调了其致力于构建包容、公平且对所有个体可访问的人工智能技术的承诺。通过在人工智能生命周期中优先考虑多样性、公平性和包容性，微软旨在利用人工智能的潜力推动积极的社会变革，并为所有人创造一个更加包容的未来。
- en: Describe considerations for reliability and safety
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述可靠性和安全性的考虑因素
- en: Microsoft’s responsible AI principle of reliability and safety is foundational
    to ensuring that AI technologies are not only dependable but also safe for users
    and society at large. This principle emphasizes the necessity of developing AI
    systems that consistently deliver accurate results while minimizing the potential
    for harm or unintended consequences. At its core, it reflects Microsoft’s commitment
    to building AI technologies that users can trust and rely on with confidence.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 微软关于负责任人工智能的可靠性原则和安全原则是确保人工智能技术不仅可靠，而且对用户和社会整体来说是安全的基石。这一原则强调开发能够持续提供准确结果并最大限度地减少潜在伤害或意外后果的人工智能系统的必要性。其核心反映了微软致力于构建用户可以信任并自信依赖的人工智能技术的承诺。
- en: A crucial aspect of this principle is the rigorous testing and validation processes
    that organizations must establish to ensure that AI systems operate safely across
    a wide range of scenarios and conditions. By integrating methods such as A/B testing
    and champion/challenger approaches, organizations can effectively evaluate the
    performance of their AI systems and identify and address potential safety hazards
    or biases before deployment.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这一原则的关键方面是组织必须建立的严格测试和验证流程，以确保人工智能系统在各种场景和条件下安全运行。通过整合A/B测试和冠军/挑战者方法等方法，组织可以有效地评估其人工智能系统的性能，并在部署前识别和解决潜在的安全隐患或偏见。
- en: Microsoft underscores the importance of prioritizing safety within AI systems
    and mitigating risks to users and society. This involves proactive identification
    and mitigation of safety hazards, including biases, errors, or security vulnerabilities,
    to enhance user trust and confidence in AI-driven solutions. By promoting safety,
    Microsoft aims to build AI technologies that not only perform as intended but
    also prioritize the well-being of users.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 微软强调了在人工智能系统中优先考虑安全性和减轻对用户和社会风险的重要性。这包括积极主动地识别和缓解安全风险，包括偏见、错误或安全漏洞，以增强用户对人工智能驱动解决方案的信任和信心。通过推广安全性，微软旨在构建不仅按预期运行，而且优先考虑用户福祉的人工智能技术。
- en: By prioritizing transparency and accountability, Microsoft strongly promotes
    documenting the decision-making process, data sources, and algorithmic logic behind
    AI systems. This transparency enables effective oversight and auditability, empowering
    users and regulators to hold AI systems (and their creators) accountable for their
    actions and decisions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 通过优先考虑透明度和问责制，微软强烈倡导记录人工智能系统背后的决策过程、数据来源和算法逻辑。这种透明度使得有效的监督和可审计性成为可能，使用户和监管机构能够对人工智能系统（及其创造者）的行为和决策负责。
- en: Continuous monitoring and evaluation are essential components of Microsoft’s
    strategy to maintain reliability and safety in AI systems. By implementing feedback
    mechanisms and continuous improvement processes, organizations can detect and
    address potential issues or failures in real time, ensuring that AI systems remain
    reliable and safe throughout their lifecycle. This proactive approach fosters
    a culture of continuous learning and adaptation, further enhancing the reliability
    and safety of AI technologies over time.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 持续监控和评估是微软维护人工智能系统可靠性和安全性的战略的关键组成部分。通过实施反馈机制和持续改进流程，组织可以实时检测和解决潜在的问题或故障，确保人工智能系统在其整个生命周期中保持可靠和安全。这种积极主动的方法培养了一种持续学习和适应的文化，从而随着时间的推移进一步增强了人工智能技术的可靠性和安全性。
- en: The commitment to reliability and safety in AI development underscores the importance
    in building trustworthy and dependable AI systems. By prioritizing transparency,
    accountability, and continuous improvement, Microsoft and other organizations
    can enhance user trust and confidence in AI-driven solutions while minimizing
    the risk of harm or unintended consequences.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能开发中致力于可靠性和安全性强调了构建值得信赖和可靠的AI系统的重要性。通过优先考虑透明度、问责制和持续改进，微软和其他组织可以增强用户对人工智能驱动解决方案的信任和信心，同时最大限度地减少伤害或意外后果的风险。
- en: These principles help ensure that AI solutions are developed in a way that is
    ethical, prioritizing inclusiveness and harm avoidance to benefit the people using
    the systems. In the next section, we’ll look at principles that help people understand
    how an AI solution arrived at its conclusion.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些原则有助于确保人工智能解决方案以符合伦理的方式开发，优先考虑包容性和避免伤害，以造福使用这些系统的人们。在下一节中，我们将探讨有助于人们理解人工智能解决方案如何得出结论的原则。
- en: Understand explainable principles
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解可解释的原则
- en: 'The concept of explainability in AI is crucial for data scientists, auditors,
    and business decision makers. It enables these stakeholders to understand and
    justify the decisions made by AI systems and the reasoning behind them. In terms
    of Microsoft’s responsible AI principles, explainability covers three principles:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能领域，可解释性的概念对于数据科学家、审计员和商业决策者至关重要。它使这些利益相关者能够理解和证明人工智能系统做出的决策及其背后的推理。在微软的负责任人工智能原则中，可解释性涵盖了以下三个原则：
- en: Fairness, or the ability for the system to make decisions that don’t discriminate
    or apply a bias toward groups or individuals based on identifiers such as gender,
    race, religion, or sexual orientation
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公平性，即系统做出不歧视或基于性别、种族、宗教或性取向等标识符对群体或个人施加偏见的决策能力
- en: Transparency in understanding how a model arrived at its result
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解模型如何得出其结果的透明度
- en: Securing the data inputs and outputs to protect the privacy of both organization
    and personal data
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护数据输入和输出以保护组织和个人数据的隐私
- en: Explainability is vital for ensuring compliance with company policies, industry
    standards, and government regulations. For data scientists, it involves being
    able to explain how they achieved specific levels of accuracy and what factors
    influenced the outcome. Auditors require tools that can validate AI models to
    comply with company policies, while business decision makers aim to build trust
    by providing transparent models.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性对于确保遵守公司政策、行业标准和国家法规至关重要。对于数据科学家来说，它涉及能够解释他们如何达到特定的准确度水平以及哪些因素影响了结果。审计员需要能够验证AI模型以符合公司政策的工具，而商业决策者则通过提供透明的模型来建立信任。
- en: Describe considerations for fairness
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述公平性的考虑因素
- en: Microsoft’s fairness principle in responsible AI development is crucial to ensure
    that AI systems do not discriminate or express bias against individuals based
    on gender, race, sexual orientation, or religion. To achieve this, Microsoft provides
    an AI fairness checklist that offers guidance across various stages of AI system
    development, including envisioning, prototyping, building, launching, and evolving.
    This checklist includes recommended due-diligence activities to minimize the impact
    of unfairness in the system.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在负责任的人工智能开发中，微软的公平性原则对于确保AI系统不会基于性别、种族、性取向或宗教歧视或对个人表现出偏见至关重要。为了实现这一点，微软提供了一份AI公平性清单，为AI系统开发的各个阶段提供指导，包括构思、原型设计、构建、发布和演进。此清单包括建议的尽职调查活动，以最大限度地减少系统中的不公平性影响。
- en: Further reading
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Organizations are encouraged to use the Fairlearn toolkit to closely assess
    the fairness of their models throughout the development process, making fairness
    assessment an integral part of data science workflows. You can learn more about
    Fairlearn at [https://fairlearn.org/](https://fairlearn.org/) and read the original
    Microsoft Fairlearn research paper at [https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/](https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 组织被鼓励在整个开发过程中使用Fairlearn工具包来仔细评估其模型的公平性，使公平性评估成为数据科学工作流程的一个组成部分。您可以在[https://fairlearn.org/](https://fairlearn.org/)了解更多关于Fairlearn的信息，并阅读微软Fairlearn原始研究论文[https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/](https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/)。
- en: Microsoft’s fairness principle highlights the importance it places on promoting
    equal opportunities and outcomes for all individuals, irrespective of their background
    or identity. It emphasizes the need to mitigate biases and ensure that AI technologies
    do not exacerbate existing inequalities within society. This involves proactive
    measures to identify, mitigate, and monitor biases throughout the AI lifecycle,
    including implementing fairness-aware algorithms and conducting bias assessments.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的公平性原则强调了其对促进所有个体，无论其背景或身份如何，都享有平等机会和结果的重要性。它强调需要减轻偏见并确保人工智能技术不会加剧社会中的现有不平等。这包括在整个AI生命周期内采取主动措施来识别、减轻和监控偏见，包括实施公平感知算法和进行偏见评估。
- en: Ongoing monitoring and evaluation play a vital role in detecting and addressing
    potential biases or unfairness in real-time. In its Responsible AI Standard, Microsoft
    emphasizes the importance of feedback mechanisms, reporting, and continuous improvement
    to ensure that AI systems remain fair and equitable throughout their lifecycle.
    By fostering a culture of continuous learning and adaptation, Microsoft aims to
    enhance the fairness and equity of AI technologies over time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 持续的监控和评估在实时检测和解决潜在的偏见或不公平性方面发挥着至关重要的作用。在其负责任AI标准中，微软强调了反馈机制、报告和持续改进的重要性，以确保AI系统在其整个生命周期内保持公平和公正。通过培养持续学习和适应的文化，微软旨在随着时间的推移提高人工智能技术的公平性和公正性。
- en: Further reading
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: You can read Microsoft’s Responsible AI Standard document at [https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl)阅读微软的负责任AI标准文档。
- en: Transparency and accountability are essential components of Microsoft’s approach
    to ensuring fairness in AI systems. Microsoft advocates for documenting data sources,
    decision-making processes, and algorithmic logic to enable effective oversight
    and auditability. By promoting transparency in understanding the algorithms for
    fairness, adopting Microsoft’s responsible AI principles provides users and regulators
    the means to hold AI systems accountable for their actions and decisions.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 透明度和问责制是微软确保人工智能系统公平性的基本组成部分。微软倡导记录数据来源、决策过程和算法逻辑，以实现有效的监督和可审计性。通过促进对公平性算法的理解，采用微软的负责任人工智能原则为用户和监管机构提供了对人工智能系统行动和决策进行问责的手段。
- en: Describe considerations for transparency
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述透明度的考虑因素
- en: Up to this point, you’ve seen the concept of transparency woven throughout several
    of Microsoft’s responsible AI principles. Microsoft’s responsible AI principle
    of transparency is key to ensuring that AI systems are accountable, understandable,
    and trustworthy. It involves providing visibility into the inner workings of AI
    systems, including their data sources, decision-making processes, and algorithmic
    logic. By promoting transparency, Microsoft aims to empower users, regulators,
    and stakeholders to comprehend and scrutinize AI systems, thereby fostering trust
    and accountability in their operation.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经看到透明度的概念贯穿于微软的几个负责任的人工智能原则中。微软的负责任人工智能原则中的透明度原则对于确保人工智能系统具有问责性、可理解性和可信度至关重要。它涉及提供对人工智能系统内部运作的可见性，包括其数据来源、决策过程和算法逻辑。通过促进透明度，微软旨在赋予用户、监管机构和利益相关者理解和审查人工智能系统的能力，从而在它们的运作中培养信任和问责制。
- en: At its core, Microsoft’s transparency principle acknowledges users’ rights to
    understand how AI systems make decisions that impact them. This encompasses comprehending
    the factors influencing recommendations, predictions, and outcomes generated by
    AI models—as well as the fact that AI models are being used to deliver those results.
    Transparency enables users to make informed decisions and assess the reliability
    and fairness of AI-driven solutions.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，微软的透明度原则承认用户了解人工智能系统如何影响他们的决策的权利。这包括理解影响人工智能模型推荐、预测和结果的因素，以及人工智能模型被用来产生这些结果的事实。透明度使用户能够做出明智的决定并评估人工智能驱动解决方案的可靠性和公平性。
- en: Transparency extends to documenting the data used to train AI models, ensuring
    its quality, diversity, and representativeness. This enables users to evaluate
    the robustness and generalizability of AI systems across different demographics
    and use cases. Additionally, transparency encompasses the methods employed for
    data collection, labeling, and processing, ensuring accountability and fairness
    in handling sensitive information.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 透明度扩展到记录用于训练人工智能模型的数据，确保其质量、多样性和代表性。这使用户能够评估人工智能系统在不同人口统计和用例中的鲁棒性和泛化能力。此外，透明度还包括用于数据收集、标注和处理的手段，确保在处理敏感信息时的问责性和公平性。
- en: Microsoft advocates for clear and accessible communication about AI systems
    to facilitate understanding among diverse audiences. This includes providing documentation,
    explanations, and user interfaces that are easy to comprehend and navigate. By
    demystifying AI technologies, Microsoft aims to bridge the gap between technical
    experts and non-experts, promoting transparency and inclusivity in the AI ecosystem.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 微软倡导关于人工智能系统的清晰和易于理解的沟通，以促进不同受众之间的理解。这包括提供易于理解和导航的文档、解释和用户界面。通过消除人工智能技术的神秘感，微软旨在弥合技术专家和非专家之间的差距，促进人工智能生态系统的透明度和包容性。
- en: Microsoft’s transparency principle reaffirms the company’s dedication to building
    AI systems that are transparent, accountable, and understandable to users and
    stakeholders. By prioritizing transparency throughout the AI lifecycle, Microsoft
    seeks to enhance trust, foster collaboration, and promote responsible AI development.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的透明度原则重申了公司致力于构建对用户和利益相关者透明、问责和可理解的人工智能系统的承诺。通过在整个人工智能生命周期中优先考虑透明度，微软寻求增强信任、促进合作并推动负责任的人工智能发展。
- en: Describe considerations for privacy and security
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述隐私和安全的考虑因素
- en: As both our personal and business lives move more online, data (and being assured
    of its security and our privacy) becomes an increasingly important commodity.
    Microsoft’s responsible AI principle of privacy and security is important to ensuring
    that AI systems uphold individuals’ rights to privacy and safeguard sensitive
    information from unauthorized access or misuse. This principle emphasizes the
    importance of protecting personal data throughout the AI lifecycle, from data
    collection to processing and storage. By prioritizing privacy and security, Microsoft
    aims to build AI systems that inspire trust and confidence among users and stakeholders.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们的个人和商业生活越来越在线化，数据（以及确保其安全和我们的隐私）变得越来越重要的商品。微软的负责任AI原则中的隐私和安全至关重要，确保AI系统能够维护个人隐私权，并保护敏感信息免受未经授权的访问或滥用。这一原则强调在整个AI生命周期中保护个人数据的重要性，从数据收集到处理和存储。通过优先考虑隐私和安全，微软旨在构建能够赢得用户和利益相关者信任和信心的AI系统。
- en: The principle of privacy and security acknowledges the significance of preserving
    individuals’ privacy rights in the digital age. This entails implementing robust
    security measures to prevent data breaches, unauthorized access, and other security
    threats that could compromise personal information. By protecting privacy, Microsoft
    seeks to uphold both ethical standards and legal obligations.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 隐私和安全原则承认在数字时代保护个人隐私权利的重要性。这包括实施强大的安全措施以防止数据泄露、未经授权的访问和其他可能损害个人信息的网络安全威胁。通过保护隐私，微软旨在维护道德标准和法律义务。
- en: Microsoft supports privacy-preserving technologies and practices that enable
    AI systems to analyze and derive insights from data without compromising individuals’
    privacy. This includes techniques such as **differential privacy**, **federated
    learning**, and **homomorphic encryption**, which enable data analysis while preserving
    the confidentiality of sensitive information. By integrating privacy-preserving
    technologies, Microsoft aims to mitigate privacy risks and enhance user confidence
    in AI-driven solutions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 微软支持隐私保护技术和实践，这些技术和实践使AI系统能够在不损害个人隐私的情况下分析和从数据中提取见解。这包括**差分隐私**、**联邦学习**和**同态加密**等技术，这些技术能够在保护敏感信息机密性的同时进行数据分析。通过整合隐私保护技术，微软旨在减轻隐私风险并增强用户对AI驱动解决方案的信心。
- en: What is homomorphic encryption?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 同态加密是什么？
- en: Homomorphic encryption is a new type of encryption technology that allows computations
    and calculations to be performed on encrypted data without actually decrypting
    the data first. Because the data isn’t decrypted, potentially sensitive data isn’t
    exposed.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 同态加密是一种新型加密技术，允许在不对数据进行实际解密的情况下对加密数据进行计算和计算。由于数据没有解密，潜在的敏感数据不会暴露。
- en: Privacy and security considerations extend beyond technical measures to encompass
    organizational policies, governance frameworks, and regulatory compliance. Microsoft
    emphasizes the importance of adopting a privacy-by-design approach, where privacy
    considerations are embedded into the design and development of AI systems from
    the outset. This involves conducting privacy impact assessments, implementing
    privacy-enhancing controls, and ensuring transparency about data practices and
    usage.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 隐私和安全考虑不仅限于技术措施，还包括组织政策、治理框架和法规遵从。微软强调采用隐私设计方法的重要性，即在AI系统的设计和开发之初就将隐私考虑因素嵌入其中。这包括进行隐私影响评估、实施增强隐私的控制措施，并确保数据实践和使用的透明度。
- en: What is differential privacy?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私是什么？
- en: Differential privacy is an obfuscation technique that introduces statistical
    noise into each result to mask data points—typically, data points that could be
    used to identify an individual or group of people. The noise is small enough to
    protect individuals but not large enough to make a statistical impact. For more
    information on differential privacy concepts, see [https://cloudblogs.microsoft.com/opensource/2020/05/19/new-differential-privacy-platform-microsoft-harvard-opendp/](https://cloudblogs.microsoft.com/opensource/2020/05/19/new-differential-privacy-platform-microsoft-harvard-opendp/).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私是一种混淆技术，它将统计噪声引入每个结果以掩盖数据点——通常是可能用于识别个人或群体的人的数据点。噪声足够小以保护个人，但又不至于对统计产生重大影响。有关差分隐私概念的更多信息，请参阅[https://cloudblogs.microsoft.com/opensource/2020/05/19/new-differential-privacy-platform-microsoft-harvard-opendp/](https://cloudblogs.microsoft.com/opensource/2020/05/19/new-differential-privacy-platform-microsoft-harvard-opendp/)。
- en: Transparency and accountability also play an important role in the privacy and
    security space. Transparency is necessary in all phases of data handling practices,
    including clear communication about data collection, processing purposes, and
    user rights.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about Microsoft’s guiding principles for responsible
    AI development and usage, including accountability, inclusiveness, fairness, and
    transparency. In order to live up to the vision of empowering individuals, AI
    and AI-based solutions must be developed in a way that benefits society.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you’ll discover common machine learning techniques.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Exam Readiness Drill – Chapter Review Questions
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apart from a solid understanding of key concepts, being able to think quickly
    under time pressure is a skill that will help you ace your certification exam.
    That is why working on these skills early on in your learning journey is key.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Chapter review questions are designed to improve your test-taking skills progressively
    with each chapter you learn and review your understanding of key concepts in the
    chapter at the same time. You’ll find these at the end of each chapter.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Before You Proceeds
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have a Packt Library subscription or you haven't purchased this
    book from the Packt store, you will need to unlock the online resources to access
    the exam readiness drills. Unlocking is free and needs to be done only once. To
    learn how to do that, head over to the chapter titled [*Chapter 12*](B22207_12.xhtml#_idTextAnchor228)*,
    Accessing the* *Online Resources*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'To open the Chapter Review Questions for this chapter, perform the following
    steps:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Click the link – [https://packt.link/AI-900_CH02](https://packt.link/AI-900_CH02).
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, you can scan the following QR code (*Figure 2**.1*):'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.1– QR code that opens Chapter Review Questions for logged-in users](img/B22207_02_01.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1– QR code that opens Chapter Review Questions for logged-in users
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you log in, you’ll see a page similar to the one shown in *Figure 2**.2*:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Chapter Review Questions for Chapter 2](img/B22207_02_02.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Chapter Review Questions for Chapter 2
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Once ready, start the following practice drills, re-attempting the quiz multiple
    times.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exam Readiness Drill
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the first three attempts, don’t worry about the time limit.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 1
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first time, aim for at least **40%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix your learning gaps.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 2
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The second time, aim for at least **60%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix any remaining learning
    gaps.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: ATTEMPT 3
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The third time, aim for at least **75%**. Once you score 75% or more, you start
    working on your timing.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: You may take more than **three** attempts to reach 75%. That’s okay. Just review
    the relevant sections in the chapter till you get there.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Working On Timing
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your aim is to keep the score the same while trying to answer these questions
    as quickly as possible. Here’s an example of how your next attempts should look
    like:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你的目标是保持得分不变，同时尽可能快地回答这些问题。以下是你下一次尝试应该看起来像的例子：
- en: '| **Attempt** | **Score** | **Time Taken** |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| **尝试** | **得分** | **用时** |'
- en: '| --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Attempt 5 | 77% | 21 mins 30 seconds |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 尝试5 | 77% | 21分30秒 |'
- en: '| Attempt 6 | 78% | 18 mins 34 seconds |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 尝试6 | 78% | 18分34秒 |'
- en: '| Attempt 7 | 76% | 14 mins 44 seconds |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 尝试7 | 76% | 14分44秒 |'
- en: Table 2.1 – Sample timing practice drills on the online platform
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.1 – 在线平台上的样本时间练习练习
- en: Note
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The time limits shown in the above table are just examples. Set your own time
    limits with each attempt based on the time limit of the quiz on the website.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 上表中显示的时间限制只是示例。根据网站上的测验时间限制，每次尝试时自行设定时间限制。
- en: With each new attempt, your score should stay above **75%** while your “time
    taken” to complete should “decrease”. Repeat as many attempts as you want till
    you feel confident dealing with the time pressure.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 每次新的尝试，你的得分应保持在**75%**以上，同时完成所需的时间“应减少”。重复尝试，直到你觉得自己能够自信地应对时间压力。
- en: 'Part 2: Describe the Fundamental Principles of Machine Learning on Azure'
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分：描述Azure机器学习的根本原理
- en: After learning about some of the foundational concepts and workloads of AI,
    it’s time to delve into the principles behind machine learning—and, more specifically,
    machine learning on Azure. You’ll learn about machine learning concepts and capabilities.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了一些AI的基础概念和工作负载之后，现在是时候深入研究机器学习背后的原理——更具体地说，是Azure上的机器学习。你将了解机器学习概念和能力。
- en: 'This part includes the following chapters:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 3*](B22207_03.xhtml#_idTextAnchor042), *Identify Common Machine Learning
    Techniques*'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第3章*](B22207_03.xhtml#_idTextAnchor042), *识别常见的机器学习技术*'
- en: '[*Chapter 4*](B22207_04.xhtml#_idTextAnchor065), *Describe Core Machine Learning
    Concepts*'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第4章*](B22207_04.xhtml#_idTextAnchor065), *描述核心机器学习概念*'
- en: '[*Chapter 5*](B22207_05.xhtml#_idTextAnchor077), *Describe Azure Machine Learning
    Capabilities*'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B22207_05.xhtml#_idTextAnchor077), *描述Azure机器学习功能*'
