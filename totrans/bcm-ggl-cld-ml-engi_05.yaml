- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding Neural Networks and Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since its debut in 2012, **Deep Learning** (**DL**) has made a huge breakthrough
    and has been applied in many research and industrial areas including computer
    vision, **Natural Language Processing** (**NLP**), and so on. In this chapter,
    we will introduce basic concepts, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks and DL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cost function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The optimizer algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The activation functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After we master the concepts, we will discuss several neural network models
    and their business use cases, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Convolutional Neural Networks** (**CNNs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recurrent Neural Networks** (**RNNs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L****ong Short-Term Memory** (**LSTM**) networks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generative Adversarial Networks** (**GANs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding neural networks and DL concepts, common models, and business use
    cases is extremely important in our cloud ML journey. Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks and DL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the history of us human beings, there are many interesting milestones, from
    vision development and language development to making and using tools. How did
    humans evolve and how can we train a computer to *see*, *speak*, and *use* tools?
    Looking for answers to these questions has led us to the modern AI arena.
  prefs: []
  type: TYPE_NORMAL
- en: 'How do our brains work? Modern science reveals that in the brain, there is
    a layered neural network consisting of a set of neurons. A typical neuron collects
    electrical signals from others through a fine structure called **dendrites** and
    sends out spikes of signals through a conducting structure called an **axon**,
    which splits into many branches. At the end of each branch, a synapse converts
    the signals from the axon into electrical effects to excite activity on the target
    neuron. *Figure 5.1* shows the working mechanism of a biological neuron:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – How a biological neuron works ](img/Figure_5.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – How a biological neuron works
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspired by the biological neural network model, an **Artificial Neural Network**
    (**ANN**) model consists of artificial neurons called **perceptrons**. A perceptron
    receives weighted inputs from the other perceptrons, applies the transfer function,
    which is the sum of the weighted inputs, and the activation function, which adds
    nonlinear activation to the sum, and outputs to excite the next perceptron. *Figure
    5.2* shows the working mechanism of an artificial neuron (perceptron):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – How an artificial neuron (perceptron) works ](img/Figure_5.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – How an artificial neuron (perceptron) works
  prefs: []
  type: TYPE_NORMAL
- en: 'ANNs consist of perceptrons working together via layers. *Figure 5.3* shows
    the structure of a multilayer ANN where each circular node represents a perceptron,
    and a line represents the connection from the output of one perceptron to the
    input of another. There are three types of layers in a neural network: an input
    layer, one or more hidden layers, and an output layer. The neural network in *Figure
    5.3* has one input layer, two hidden layers, and an output layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – A multilayer ANN ](img/Figure_5.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – A multilayer ANN
  prefs: []
  type: TYPE_NORMAL
- en: 'Using neural networks to perform ML model training, the data flows in the network
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A dataset (*x*1*, x*2*, x*3*, ..., x*n) is prepared and sent to the input layer,
    which has the same amount of perceptrons as the number of features of the dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The data then moves through to the hidden layers. At each hidden layer, the
    perceptron processes the weighted inputs (sum and activate, as described earlier),
    and sends the output to the neurons at the next hidden layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After the hidden layers, the data finally moves to the output layer, which provides
    the outputs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The objective of the neural network is to determine the weights that minimize
    the cost function (average prediction error for the dataset). Similar to the regression
    model training process we discussed in the previous chapters, DL model training
    is implemented by iterations of a two-part process, forward propagation and backpropagation,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Forward propagation** is the path that information flows from the input layer
    to the output layer, through the hidden layers. At the beginning of the training
    process, data arrives at the input layer where they are multiplied with the weights
    randomly initialized, then passed to the first hidden layer. Since the input layer
    has multiple nodes, each one is connected to each node in the first hidden layer;
    a node in the hidden layer sums up the weighted values to it and applies an activation
    function (adds nonlinearity). It then sends the output to the nodes of the next
    layer, where the nodes do the same, till the output of the last hidden layer is
    multiplied by the weights and becomes the input to the final output layer, where
    further functions are applied to generate the output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backpropagation** is the path information flows from the output layer all
    the way back to the input layer. During this process, the neural network compares
    the predicted output to the actual output as the first step of backpropagation
    and calculates the cost function or prediction error. If the cost function is
    not good enough, it moves back to adjust the weights based on algorithms such
    as **Gradient Descent** (**GD**) and then starts the forward propagation again
    with the new weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forward propagation and backpropagation are repeated multiple times—each time
    the network adjusts the weights, trying to get a better cost function value—until
    the network gets a good cost function (an acceptable accuracy) at the output layer.
    At this time, the model training is completed and we have got the optimized weights,
    which are the results of the training.
  prefs: []
  type: TYPE_NORMAL
- en: DL is training ML models with neural networks. If you compare the preceding
    DL model training process using neural networks with the ML model training process
    we discussed in the *Training the model* section in [*Chapter 4*](B18333_04.xhtml#_idTextAnchor094),
    *Developing and Deploying ML Models*, you will find that the concepts of ML and
    DL are very similar. Via iterative forward propagation and backward propagation,
    both are trying to minimize the cost function of the model—ML is more about computers
    learning from data with traditional algorithms, while DL is more about computers
    learning from data mimicking the human brain and neural networks. Relatively speaking,
    ML requires less computing power and DL needs less human intervention. In the
    following sections, we will take a close look at the cost function, the optimizer
    algorithm, and the activation function for DL with neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: The cost function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We introduced the concept of the cost function in the *Linear regression* section
    in [*Chapter 4*](B18333_04.xhtml#_idTextAnchor094). The cost function gives us
    a mathematical way of determining how much error the current model has—it assigns
    a cost for making an incorrect prediction and provides a way to measure the model
    performance. The cost function is a key metric in ML model training—choosing the
    right cost function can improve model performance dramatically.
  prefs: []
  type: TYPE_NORMAL
- en: The common cost functions for regression models are MAE and MSE. As we have
    discussed in previous chapters, MAE defines a summation of the absolute differences
    between the prediction values and the label values. MSE defines the summation
    of squares of the differences between the prediction values and the label values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The cost functions for classification models are quite different. Conceptually,
    the cost function for a classification model is the difference between the probability
    distributions for different classes. For binary classification models where the
    model outputs are binary, 1 for yes or 0 for no, we use **binary cross entropy**.
    For multi-class classification models, depending on the dataset labels, we use
    **categorical cross entropy** and **sparse categorical cross entropy** as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: If the labels are integers, for example, to classify an image of a dog, a cat,
    or a cow, then we use sparse categorical cross entropy since the output is one
    exclusive class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Otherwise, if the labels are encoded as a series of zeros and ones for each
    class (same for the one-hot-encoding format that we have discussed in the previous
    chapters), we’ll use categorical cross entropy. For example, given an image, you
    need to detect whether there exists a driver’s license, a passport, or a social
    security card, we will use categorical cross entropy as cost functions since the
    output has a combination of classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cost function is a way of measuring our models so we can adjust the model
    parameters to minimize them—the model optimization process. In the following section,
    we’ll talk about the optimizer algorithms that minimize the cost function.
  prefs: []
  type: TYPE_NORMAL
- en: The optimizer algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the *Linear regression* section in [*Chapter 4*](B18333_04.xhtml#_idTextAnchor094),
    we discussed the **GD** algorithm, which optimizes the linear regression cost
    function. In neural networks, the optimizer is an algorithm used to minimize the
    cost function in model training. The commonly used optimizers are **Stochastic
    Gradient Descent** (**SGD**), **RMSprop**, and **Adam** as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**SGD** is useful for very large datasets. Instead of GD, which runs through
    all of the samples in your training dataset to update parameters, SGD uses one
    or a subset of training samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RMSprop** improves SGD by introducing variable learning rates. The learning
    rate, as we discussed in [*Chapter 4*](B18333_04.xhtml#_idTextAnchor094), impacts
    model performances—larger learning rates can reduce training time but may lead
    to model oscillation and may miss the optimal model parameter values. Lower learning
    rates can make the training process longer. In SGD, the learning rate is fixed.
    RMSprop adapts the learning rate as training progresses, and thus it allows you
    to start with big learning rates when the model has a high cost function, but
    it gradually reduces the learning rate when the cost function decreases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adam** stands for **Adaptive Moment Estimation** and is one of the most widely
    used optimizers. Adam adds momentum to the adaptive learning rate from RMSprop,
    and thus it allows changes to the model to accelerate while moving in the same
    direction during training, making the model training process quicker and better.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the right cost function and optimizer algorithms is very important
    for model performance and training speed. Google’s TensorFlow framework provides
    many optimizer algorithms. For further details, please refer to [https://www.tensorflow.org/api_docs/python/tf/keras/optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers).
  prefs: []
  type: TYPE_NORMAL
- en: Other important features for neural networks are non-linearity and output normalization,
    which are provided by the activation functions. We will examine them in the following
    section.
  prefs: []
  type: TYPE_NORMAL
- en: The activation functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you can see from the preceding section, the activation function is part
    of the training process. The purpose of the activation function is to transform
    the weighted-sum input to the nodes: non-linearize and change the output range.
    There are many activation functions in neural networks. We will discuss some of
    the most used ones: the sigmoid function, the tanh activation function, the ReLu
    function, and the LeakyReLU function. *Figure 5.4* shows the curves of these functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Activation functions ](img/Figure_5.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Activation functions
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s inspect each of the preceding activation functions as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The sigmoid activation function was discussed earlier ithe T*he cost function*
    section. We use the sigmoid function to change continuous values to a range between
    0 and 1, which fits the models to predict the probability as an output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tanh activation function is very similar to sigmoid, but the output is from
    -1 to +1 and thus it is preferred to sigmoid due to the output being zero-centered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ReLU activation function stands for Rectified Linear Unit. It is widely
    used since it converts the negative values to 0 and keeps the positive values
    as such. Its range is between 0 and infinity. Because the gradient value is 0
    in the negative area, the weights and biases for some neurons may not be updated
    during the training process, causing dead neurons that never get activated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The LeakyReLU is an improved version of the ReLU function to solve the dying
    ReLU problem as it has a small positive slope in the negative area. The advantages
    of LeakyReLU are the same as that of the ReLU, in addition to the fact that it
    enables training even for negative input values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another activation function is the *softmax* function, which is often used in
    the output layer for multi-class classifications. The softmax activation function
    converts the output layer values into probabilities summing up to 1 and thus outputs
    probabilities for each class in multi-class classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: Among all of these activation functions, which shall we choose? The answer depends
    on factors such as the type of predictions, the architecture of the network, the
    number of layers, the current layer in the network, and so on. For example, sigmoid
    is more used for binary classification use cases, whereas softmax is often applied
    for multi-classifications, and regression problems may or may not use activation
    functions. While there will be trial and error involved at the beginning, experience
    will build up good practices.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have introduced the concepts of neural networks and activation functions,
    let’s examine some neural networks that are commonly used in computer vision,
    **Natural Language Processing** (**NLP**), and other areas.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have learned about neural networks and DL, let’s look at some business
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: The first case is image recognition. How can we teach a computer to recognize
    an image? It is an easy task for a human being but a very difficult one for a
    computer. The first thing we need to do, since computers are only good at working
    with 1s and 0s, is to transform the image into a numerical matrix using pixels.
    As an example, *Figure 5.5* shows a black and white image for a single digit number,
    *8*, represented by a 28x28 pixel matrix. While human beings can easily recognize
    the image as a number *8* by some *magic sensors* in our eyes, a computer needs
    to input all of the 28x28=784 pixels, each having a **pixel value—a** single number
    representing the brightness of the pixel. The pixel value has possible values
    from 0 to 255, with 0 as black and 255 as white. Values in between make up the
    different shades of gray. If we have a color image, the pixel will have three
    numerical RGB values (red, green, and blue) to represent its color instead of
    one black value.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Representing the number 8 with pixel values ](img/Figure_5.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Representing the number 8 with pixel values
  prefs: []
  type: TYPE_NORMAL
- en: After we have a pixel matrix representation of the image, we can start developing
    a **Multi-Layer Perceptron** (**MLP**) network for training. We will construct
    the input layer with 784 nodes and input 784 pixel values, one for each. Each
    node from the input layer will then output to each node in the next layer (a hidden
    layer), and so on. When the number of layers increases, the total number of calculations
    will be huge for the entire network. To decrease the total calculations, the idea
    of feature filtering comes into play and leads to the concept of a **CNN**.
  prefs: []
  type: TYPE_NORMAL
- en: 'CNNs are widely used in computer vision, especially in image recognition and
    processing. A CNN consists of three layers: the convolutional layer, the pooling
    layer, and the fully connected layer. The convolutional layer convolutes the inputs
    and filters the image features, the pooling layer compresses the filtered features,
    and the fully connected layer, which is basically an MLP, does the model training.
    Let’s examine each of these layers in detail.'
  prefs: []
  type: TYPE_NORMAL
- en: The convolutional layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A **convolutional layer** performs convolution, which is applied to the input
    data to filter the information and produce a feature map. The filter is used as
    a sliding window to scan the entire image and autonomously recognize features
    in the images. As shown in *Figure 5.6*, a 3x3 filter, which is also called the
    **Kernel** (**K**), scans the whole **Image** (**I**) and generates a feature
    map, denoted as *I*K* since its element comes from the product of *I* and *K*
    (in the example of *Figure 5.6*: *1x1+0x0+1x0+0x1+1x1+0x0+1x1+0x1+1x1=4*).'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 5.6 – The convolution operation ](img/Figure_5.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – The convolution operation
  prefs: []
  type: TYPE_NORMAL
- en: Going through the convolution process extracts the image features and generates
    a feature map that still has a large amount of data and makes it hard to train
    the neural network. To compress the data, we go through the pooling layer.
  prefs: []
  type: TYPE_NORMAL
- en: The pooling layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **pooling layer** receives the results from a convolutional layer, the feature
    map, and compresses it using a filter. Depending on the function used for calculation,
    it can either be maximum pooling or average pooling. As shown in *Figure 5.7*,
    a 2x2 filter patch scans the feature map and compresses it. With max pooling,
    it takes the maximum value from the scanning windows, *max(15,8,20,9) = 20*, and
    so on. With average pooling, it takes the average value, *average(15,8,20,9) =
    13*. As you can see, the filter of a pooling layer is always smaller than a feature
    map.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – The pooling layer ](img/Figure_5.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – The pooling layer
  prefs: []
  type: TYPE_NORMAL
- en: From the input image, the process of convolution and pooling iterates, and the
    final result is input to a fully connected layer (MLP) to process.
  prefs: []
  type: TYPE_NORMAL
- en: The fully connected layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After the convolution and pooling layers, we need to flatten the result and
    pass it to an MLP, a fully connected neural network, for classification. The final
    result will then be activated with the softmax activation function to yield the
    final output – an understanding of the image.
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The second type of neural network is an RNN. RNNs are widely used in time series
    analysis, such as NLP. The concept of an RNN came about in the 1980s, but it’s
    not until recently that it gained its momentum in DL.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, in traditional feedforward neural networks such as CNNs, a node
    in the neural network only counts the current input and does not memorize the
    precious inputs. Therefore, it cannot handle time series data, which needs the
    previous inputs. For example, to predict the next word of a sentence, the previous
    words will be required to do the inference. By introducing a hidden state, which
    remembers some information about the sequence, RNNs solved this issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Different from feedforward networks, RNNs are a type of neural network where
    the output from the previous step is fed as the input to the current step; using
    a loop structure to keep the information allows the neural network to take the
    sequence of input. As shown in *Figure 5.8*, a loop for node *A* is unfolded to
    explain its process; first, node *A* takes *X*0 from the sequence of input, and
    then it outputs *h*0, which, together with *X*1, is the input for the next step.
    Similarly, *h*1 and *X*2 are inputs for the next step, and so on and so forth.
    Using the loop, the network keeps remembering the context while training:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – The RNN unrolled loop (source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
    ](img/Figure_5.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.8 – The RNN unrolled loop (source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/)'
  prefs: []
  type: TYPE_NORMAL
- en: The drawback for a simple RNN model is the vanishing gradient problem, which
    is caused by the fact that the same weights are used to calculate a node’s output
    at each time step during training and also done during backpropagation. When we
    move backward further, the error signal becomes bigger or smaller, thus causing
    difficulty in memorizing the contexts that are further away in the sequence. To
    overcome this drawback, the **LSTM** neural network was developed.
  prefs: []
  type: TYPE_NORMAL
- en: Long Short-Term Memory Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An LSTM network was designed to overcome the vanishing gradient problem. LSTMs
    have feedback connections, and the key to LSTMs is the cell state—a horizontal
    line running through the entire chain with only minor linear interactions, which
    persists the context information. LSTM adds or removes information to the cell
    state by gates, which are composed of activation functions, such as sigmoid or
    tanh, and a pointwise multiplication operation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – An LSTM model (source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
    ](img/Figure_5.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.9 – An LSTM model (source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5.9* shows an LSTM that has the gates to protect and control the cell
    state. Using the cell state, LSTM solves the issue of vanishing gradients and
    thus is particularly good at processing time series sequences of data, such as
    text and speech inference.'
  prefs: []
  type: TYPE_NORMAL
- en: Generative Adversarial networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GANs** are algorithmic architectures that are used to generate new synthetic
    instances of data that can pass for real data. As shown in *Figure 5.10*, GAN
    is a generative model that trains the following two models simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: A **Generative** (**G**) model that captures the data distribution to generate
    plausible data. The latent space input and random noise can be sampled and fed
    into the generator network to generate samples that become the negative training
    examples for the discriminator.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **Discriminative** (**D**) model that compares the generated image with a
    real image and tries to identify whether the given image is fake or real. It estimates
    the probability that a sample came from the training data rather than the real
    data to distinguish the generator’s fake data from real data. The discriminator
    penalizes the generator for producing implausible results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.10 – The GAN (source: https://developers.google.com/machine-learning/recommendation)
    ](img/Figure_5.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.10 – The GAN (source: https://developers.google.com/machine-learning/recommendation)'
  prefs: []
  type: TYPE_NORMAL
- en: The model training starts with the generator generating fake data and the discriminator
    learns to tell that it’s false by comparing it with real samples. The GAN then
    sends the results to the generator and the discriminator to update the model.
    This fine tuning training process iterates and finally produces some extremely
    real-looking data. GANs can be used to generate text, images, and video, and color
    or denoise images.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks and DL have added the modern color to the traditional ML spectrum.
    In this chapter, we started by learning the concepts of neural networks and DL
    by examining the cost functions, optimizer algorithms, and activation functions.
    Then, we introduced advanced neural networks, including CNN, RNN, LSTM, and GAN.
    As we can see, by introducing neural networks, DL extended ML concepts and made
    a breakthrough in many applications such as computer vision, NLP, and others.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter concludes part two of the book: *Machine Learning and Deep Learning*.
    In part three, we will focus on *Machine Learning the Google Way*, where we will
    talk about how Google does ML and DL in Google Cloud. We will start part three
    with learning about BQML, Google TensorFlow, and Keras in the following chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For further insights on the topics learned in this chapter, you can refer to
    the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/anatomy](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/anatomy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks](https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/what-is/neural-network/](https://aws.amazon.com/what-is/neural-network/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://developers.google.com/machine-learning/gan](https://developers.google.com/machine-learning/gan)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 3: Mastering ML in GCP'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this part, we learn how Google does ML in the Google Cloud Platform. First,
    we discover Google’s BigQuery ML for structured data, and then we look at Google’s
    ML frameworks, TensorFlow and Keras. We examine Google’s end-to-end ML suite,
    Vertex AI, and the ML services it provides. We then look at the Google pre-trained
    model APIs for ML development: GCP ML APIs. We end this part with a summary of
    the ML implementation best practices in Google Cloud.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This part comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18333_06.xhtml#_idTextAnchor133), Learning BQML, TensorFlow,
    and Keras'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18333_07.xhtml#_idTextAnchor143), Exploring Google Cloud Vertex
    AI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18333_08.xhtml#_idTextAnchor159), Discovering Google Cloud ML
    API'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B18333_09.xhtml#_idTextAnchor168), Using Google Cloud ML Best
    Practices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
