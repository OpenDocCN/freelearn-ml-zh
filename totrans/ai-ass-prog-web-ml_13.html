<html><head></head><body>
  <div class="calibre1" id="_idContainer131">
    <h1 class="chapternumber">13</h1>
    <h1 class="chaptertitle" id="_idParaDest-275">Building a Regression Model for Customer Spend with ChatGPT</h1>
    <h1 class="heading" id="_idParaDest-276">Introduction</h1>
    <p class="normal">In the realm of data-driven decision making, understanding customer behavior is pivotal for optimizing business strategies. Building on our exploration of classification techniques, this chapter shifts focus to regression analysis, specifically linear regression, to predict numerical values such as a customer’s annual spending. Linear regression helps us discover relationships within data, enabling predictions based on observed patterns.</p>
    <p class="normal1">This chapter will guide you through the process of building a predictive model that estimates annual spending by customers based on their interactions with a digital platform. We aim to deepen your understanding of linear regression, demonstrating how to prepare, process, and utilize datasets to construct accurate and reliable models.</p>
    <p class="normal1">As we progress, we will explore various techniques to enhance model accuracy and handle complex data scenarios:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Utilizing advanced regularization techniques</strong> to improve model stability and performance.</li>
      <li class="bulletlist1"><strong class="screentext">Generating synthetic datasets</strong> to better understand model behaviors under different data conditions.</li>
      <li class="bulletlist1"><strong class="screentext">Streamlining model development</strong> with comprehensive, end-to-end coding examples.</li>
    </ul>
    <p class="normal1">By the end of this chapter, you will be well equipped with the knowledge and skills necessary to utilize linear regression for data-driven decision-making in your business. Let’s embark on this journey into regression analysis to optimize customer engagement and revenue generation on our app or website.</p>
    <p class="normal1">In this chapter, we will:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Build a regression model with ChatGPT: </strong>Readers will learn how ChatGPT can assist in generating Python code for building a regression model to predict the yearly amount spent by customers on our app or website using the dataset we have, offering a hands-on approach to understanding and interacting with datasets.</li>
      <li class="bulletlist1"><strong class="screentext">Apply prompting techniques: </strong>Effective techniques will be introduced to craft prompts that guide ChatGPT in providing the most useful code snippets and insights for regression tasks.</li>
    </ul>
    <h1 class="heading" id="_idParaDest-277">Business problem</h1>
    <p class="normal">An e-commerce<a id="_idIndexMarker482" class="calibre3"/> store seeks to optimize customer engagement and increase revenue by gaining deeper insights into customer behavior and preferences. By analyzing various customer attributes and their purchasing patterns, the store aims to tailor its marketing strategies, improve customer retention, and enhance the overall shopping experience.</p>
    <h1 class="heading" id="_idParaDest-278">Problem and data domain </h1>
    <p class="normal">We will employ <a id="_idIndexMarker483" class="calibre3"/>regression techniques to understand the relationship between yearly spending and other parameters. <strong class="screentext">Regression</strong> is a way to find out whether and how <a id="_idIndexMarker484" class="calibre3"/>different factors (like time spent on an app or website) relate to how much customers spend in the online store. It helps us understand and predict customer behavior. By understanding which factors are most influential in driving sales, an e-commerce store can tailor its strategies to enhance these areas and potentially increase revenue.</p>
    <h2 class="heading1" id="_idParaDest-279">Dataset overview</h2>
    <p class="normal">The e-commerce store collects the following information from the customer:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Email: </strong>This is the <a id="_idIndexMarker485" class="calibre3"/>customer’s email address. It is a unique identifier for each customer and can be used for communication, such as sending order confirmations, newsletters, or personalized marketing offers.</li>
      <li class="bulletlist1"><strong class="screentext">Address: </strong>This refers to the physical address of the customer. It’s crucial for delivering products they have purchased. Additionally, address data can sometimes provide insights into geographical trends in sales and preferences.</li>
      <li class="bulletlist1"><strong class="screentext">Avatar: </strong>This could be a digital representation or image chosen by the user. It might not directly impact sales or customer behavior, but it can be part of customer engagement strategies, adding a personal touch to user profiles.</li>
      <li class="bulletlist1"><strong class="screentext">Avg Session Length: </strong>This is the average duration of all sessions combined, in minutes. This is like measuring how long a customer spends in your store each time they visit. Imagine someone walking around, looking at products for, say, 33 minutes on average.</li>
      <li class="bulletlist1"><strong class="screentext">Time on App: </strong>This the duration of presence on the store’s application, in minutes. Think of it as how long they are browsing through your app, maybe while they are on the bus or waiting in line at the coffee shop.</li>
      <li class="bulletlist1"><strong class="screentext">Time on Website: </strong>This is similar to the time on the app, but this is for your website. If they’re using a computer at home or work to look at your store, how long do they stay?</li>
      <li class="bulletlist1"><strong class="screentext">Length of Membership: </strong>This is how long these customers have been with your store. Some might be new, while others have been shopping with you for years.</li>
      <li class="bulletlist1"><strong class="screentext">Yearly Amount Spent: </strong>This is the total amount of money each customer spends at your store in a year, in dollars.</li>
    </ul>
    <p class="normal1">In the context of our dataset:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Email and address</strong>: These should be used primarily for transactional purposes unless the customer has agreed to receive marketing communications. We will not use them for analysis.</li>
      <li class="bulletlist1"><strong class="screentext">Avatar</strong>: This can be used to personalize the user experience but does not hold significant analytical value for sales predictions.</li>
      <li class="bulletlist1"><strong class="screentext">Other data</strong>: Variables like “Time on App” and “Time on Website” can be analyzed to improve user experience and business strategies without infringing on personal <a id="_idIndexMarker486" class="calibre3"/>privacy.</li>
    </ul>
    <p class="normal1">In summary, while data like email, address, and avatar can be valuable for business operations and customer engagement, they must be handled with a high degree of responsibility, prioritizing the privacy and preferences of the customers.</p>
    <p class="normal1">Note that the data used is not a real dataset and hence the emails, addresses, and so on are all made up.</p>
    <h1 class="heading" id="_idParaDest-280">Breaking the problem down into features</h1>
    <p class="normal">Given the nature of our<a id="_idIndexMarker487" class="calibre3"/> dataset, which includes both independent variables (like “Avg. Session Length,” “Time on App,” “Time on Website,” and “Length of Membership”) and a dependent variable (“Yearly Amount Spent”), we will start with a simple regression technique with both ChatGPT and ChatGPT Plus or GPT-4. This will include the following high-level steps:</p>
    <ol class="calibre16">
      <li class="bulletlist1" value="1"><strong class="screentext">Building the model step by step</strong>: Users will understand the process of building a machine learning model step by step, including loading the dataset, splitting it into training and testing sets, training the model, making predictions, and evaluating its performance.</li>
      <li class="bulletlist1"><strong class="screentext">Apply regularization techniques</strong>: Users will learn how to apply regularization techniques such as Ridge regression and Lasso regression with cross-validation to improve the performance of a linear regression model. This includes initializing the models, training them using the training data, and evaluating their performance.</li>
      <li class="bulletlist1"><strong class="screentext">Generate a synthetic dataset to add complexity</strong>: Users will discover how to generate a synthetic dataset with added complexity using the <code class="inlinecode">make_regression</code> function from the <code class="inlinecode">sklearn.datasets</code> module. This involves specifying the number of samples, features, and noise levels to mimic real-world data.</li>
      <li class="bulletlist1"><strong class="screentext">Generating code to develop a model in a single step for a synthetic dataset</strong>: Users will see how to write end-to-end code in a single step to load the synthetic dataset, split it into training and testing sets, train a linear regression model, evaluate its performance, and print the evaluation metrics. This allows for a streamlined approach to model development and evaluation.</li>
    </ol>
    <h1 class="heading" id="_idParaDest-281">Prompting strategy</h1>
    <p class="normal">To leverage ChatGPT for machine learning, we need to have a clear understanding of how to implement the prompting strategies specifically for code generation for machine learning.</p>
    <p class="normal1">Let’s brainstorm what we would like to achieve in this task to get a better understanding of what needs to go into the initial prompt.</p>
    <h2 class="heading1" id="_idParaDest-282">Strategy 1: Task-Actions-Guidelines (TAG) prompt strategy</h2>
    <p class="normal"><strong class="screentext">1.1 – Task</strong>: The<a id="_idIndexMarker488" class="calibre3"/> specific task or goal is to create a simple linear regression model to predict the “<strong class="screentext">Yearly Amount Spent</strong>” by<em class="italic"> </em>dataset based on various attributes in the dataset.</p>
    <p class="normal1"><strong class="screentext">1.2 – Actions</strong>: In this case, the strategy is to let ChatGPT decide the steps, hence no specific steps are provided.</p>
    <p class="normal1"><strong class="screentext">1.3 – Guidelines</strong>: We will provide the following guidelines to ChatGPT in our prompt:</p>
    <ul class="calibre15">
      <li class="bulletlist">The code should be compatible with Jupyter Notebook</li>
      <li class="bulletlist1">Ensure that there are detailed comments for each line of code. </li>
      <li class="bulletlist1">You have to explain each line of code, which will be then copied into the text block of the notebook in detail for each method used in the code before providing the code.</li>
    </ul>
    <h2 class="heading1" id="_idParaDest-283">Strategy 2: Persona-Instructions-Context (PIC) prompt strategy</h2>
    <p class="normal"><strong class="screentext">2.1 – Persona</strong>: We will <a id="_idIndexMarker489" class="calibre3"/>adopt the persona of a beginner who needs to learn the different steps of model creation; hence the code should be generated step by step.</p>
    <p class="normal1"><strong class="screentext">2.2 – Instructions</strong>: We have included the step to mount Google Drive explicitly since it’s a common oversight.</p>
    <p class="normal1"><strong class="screentext">2.3 – Context</strong>: The most important part is to provide the context of the dataset and exact field names to generate the code that can be executed directly, or to provide the dataset itself in the case of ChatGPT Plus.</p>
    <h2 class="heading1" id="_idParaDest-284">Strategy 3: Learn-Improvise-Feedback-Evaluate (LIFE) prompt strategy </h2>
    <p class="normal"><strong class="screentext">3.1 – Learn</strong>:</p>
    <ul class="calibre15">
      <li class="bulletlist">We <a id="_idIndexMarker490" class="calibre3"/>want to learn about linear regression and how it works.</li>
      <li class="bulletlist1">Understand feature engineering techniques and model evaluation metrics.</li>
      <li class="bulletlist1">We want to learn how to create a synthetic dataset.</li>
    </ul>
    <p class="normal1"><strong class="screentext">3.2 – Improvise</strong>: </p>
    <ul class="calibre15">
      <li class="bulletlist">We will use it later while applying regularization techniques.</li>
    </ul>
    <p class="normal1"><strong class="screentext">3.3 – Feedback</strong>: </p>
    <ul class="calibre15">
      <li class="bulletlist">If the code provided results in any errors, then feedback should be provided back to ChatGPT. We applied it in the Lasso and Ridge code execution using ChatGPT Plus.</li>
    </ul>
    <p class="normal1"><strong class="screentext">3.4 – Evaluate</strong>: </p>
    <ul class="calibre15">
      <li class="bulletlist">Execute the code provided by ChatGPT to ensure accuracy and validity. This is used throughout the chapter.</li>
    </ul>
    <h1 class="heading" id="_idParaDest-285">Building a simple linear regression model to predict the “Yearly Amount Spent” by customers using the free version of ChatGPT</h1>
    <p class="normal">When using the<a id="_idIndexMarker491" class="calibre3"/> free version, it’s important to give ChatGPT a clear description of the dataset first, which serves as an effective approach to generating code, followed by user evaluation. ChatGPT is already trained very well on Python and a machine learning algorithm; hence, we do not need to provide specific steps here. To verify that the generated code functions correctly, we will be using Google Colab.</p>
    <h2 class="heading1" id="_idParaDest-286">Feature 1: Building the model step by step</h2>
    <p class="normal">Let’s craft<a id="_idIndexMarker492" class="calibre3"/> our initial prompt for the classification model.</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">I <a id="_idIndexMarker493" class="calibre3"/>want to create a simple linear regression model to predict the “Yearly Amount Spent” (TAG 1.1) by customers for the e-commerce customers dataset which consists of the following columns (PIC 2.3):</p>
    <ol class="calibre16">
      <li class="bulletlist1" value="1"><strong class="screentext">Email</strong>: The electronic mail unique to each customer, used here as an identification.</li>
      <li class="bulletlist1"><strong class="screentext">Address</strong>: The physical geographical location of each customer.</li>
      <li class="bulletlist1"><strong class="screentext">Avatar</strong>: This is the visual anonymity representation of the customers in the database.</li>
      <li class="bulletlist1"><strong class="screentext">Avg. Session Length</strong>: The average duration of all session combined in minutes.</li>
      <li class="bulletlist1"><strong class="screentext">Time on App</strong>: This the duration of presence on the stores’ application, in minutes.</li>
      <li class="bulletlist1"><strong class="screentext">Time on Website</strong>: This is the time duration on the website of the store, in minutes.</li>
      <li class="bulletlist1"><strong class="screentext">Length of Membership</strong>: This is the amount of time a customer remains a registered user of the store’s online resources.</li>
      <li class="bulletlist1"><strong class="screentext">Yearly Amount Spent</strong>: This is the cost implication of accessing the store’s online resources, paid by the customers, in dollars.</li>
    </ol>
    <p class="normal1">I am a beginner user (PIC 2.1), so please provide step by step code and strictly follow following instructions (PIC 2.2):</p>
    <ul class="calibre15">
      <li class="bulletlist">Code should be compatible with Jupyter notebook </li>
      <li class="bulletlist1">Ensure that there are detailed comments for each line of code. </li>
      <li class="bulletlist1">You have to explain each line of code, which will be then copied in the text block of the notebook in detail for each method used in code before providing the code. </li>
      <li class="bulletlist1">Also note that the dataset is placed in Google Drive at this path <code class="inlinecode">'/content/drive/My Drive/Chapter05/Ecommerce Customers.csv '</code> (TAG 1.2).</li>
      <li class="bulletlist1">So, add the code to mount the drive, load the dataset, provide one step at a time, and wait for users feedback.</li>
    </ul>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">You should receive a response similar to the following.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_13_01.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 13.1: The initial response from ChatGPT</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure, let’s <a id="_idIndexMarker494" class="calibre3"/>proceed step by step. First, we need to mount Google Drive in our Jupyter Notebook environment so we can access the dataset.</p>
    <p class="normal1">Here’s how you can do it:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive
<span class="hljs-comment"># Mount Google Drive</span>
drive.mount(<span class="hljs-string">'/content/drive'</span>)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">from google.colab import drive</code>: This line imports the <code class="inlinecode">drive</code> module from the <code class="inlinecode">google.colab</code> package.</li>
      <li class="bulletlist1"><code class="inlinecode">drive.mount('/content/drive')</code>: This command mounts your Google Drive at the specified path <code class="inlinecode">/content/drive</code>. When you run this cell, it will prompt you to authenticate and give you a link to follow to get an authorization code. Once you enter the code, your Google Drive will be mounted.</li>
    </ul>
    <p class="normal1">Let me know<a id="_idIndexMarker495" class="calibre3"/> if you have any questions before we proceed.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will now apply the evaluate prompting strategy and validate the code by executing the code in Google Colab for every step. The code runs perfectly fine and mounts Google Drive.</p>
    <p class="normal1">Please note that it requires permission to access the drive and would prompt the user.</p>
    <p class="normal1">Please refer to the notebook <code class="inlinecode">Learning simple regression with ChatGPT.ipynb</code> for the executable code snippets or copy the code from the prompt response.</p>
    <p class="normal1">Running your cell, you should see a message that says “Mounted at /content/drive as a result of calling drive.mount.”</p>
    <p class="normal1">We will now instruct ChatGPT to proceed to the next step:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following to load the dataset into the notebook:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Great! Now that we have mounted Google Drive, we can load the dataset into our notebook.</p>
    <p class="normal1">Here’s how you can load the dataset:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-comment"># Define the file path</span>
file_path = <span class="hljs-string">'/content/drive/My Drive/Chapter05/Ecommerce Customers.csv'</span>
<span class="hljs-comment"># Load the dataset into a DataFrame</span>
ecommerce_data = pd.read_csv(file_path)
<span class="hljs-comment"># Display the first few rows of the DataFrame</span>
<span class="hljs-built_in">print</span>(ecommerce_data.head())
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">import pandas as pd</code>: This line<a id="_idIndexMarker496" class="calibre3"/> imports the pandas library and aliases it as <code class="inlinecode">pd</code>, which is a common convention.</li>
      <li class="bulletlist1"><code class="inlinecode">file_path = '/content/drive/My Drive/Chapter05/Ecommerce Customers.csv'</code>: This line defines the file path where the dataset is located in your Google Drive.</li>
      <li class="bulletlist1"><code class="inlinecode">pd.read_csv(file_path)</code>: This function reads the CSV file located at the specified path and creates a DataFrame from it.</li>
      <li class="bulletlist1"><code class="inlinecode">print(ecommerce_data.head())</code>: This line prints the first few rows of the DataFrame to verify that the dataset has been loaded correctly.</li>
    </ul>
    <p class="normal1">Let me know if you have any questions or if you’d like to proceed to the next step!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We executed the code provided by ChatGPT in the notebook and it loads the dataset from the defined path and prints the first few rows. As we had given the path of the file in the initial prompt, we don’t need to change anything in the code and it runs perfectly fine. The takeaway is that we need to be specific with file paths and locations where required.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer" src="../Images/B21232_13_02.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 13.2: Loading the dataset</p>
    <p class="normal1">Next, we’ll <a id="_idIndexMarker497" class="calibre3"/>provide the output to ChatGPT and then proceed to <em class="italic">Step 1</em>. In this instance, we’ve employed the strategy of providing additional context to ChatGPT by presenting the output textually. </p>
    <p class="normal1">It is important to note that since we are utilizing GPT-3.5, which lacks the capability to execute code or process images, we are limited to providing textual outputs from the notebook:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <pre class="programlisting"><code class="hljs-code">Here is the output -                         Email  \
0      mstephenson@fernandez.com   
1              hduke@hotmail.com   
2               pallen@yahoo.com   
3        riverarebecca@gmail.com   
4  mstephens@davidson-herman.com   
                                             Address            Avatar  \
0       835 Frank Tunnel\nWrightmouth, MI 82180-9605            Violet   
1     4547 Archer Common\nDiazchester, CA 06566-8576         DarkGreen   
2  24645 Valerie Unions Suite 582\nCobbborough, D...            Bisque   
3   1414 David Throughway\nPort Jason, OH 22070-1220       SaddleBrown   
4  14023 Rodriguez Passage\nPort Jacobville, PR 3...  MediumAquaMarine   
   Avg. Session Length  Time on App  Time on Website  Length of Membership  \
0            34.497268    12.655651        39.577668              4.082621   
1            31.926272    11.109461        37.268959              2.664034   
2            33.000915    11.330278        37.110597              4.104543   
3            34.305557    13.717514        36.721283              3.120179   
4            33.330673    12.795189        37.536653              4.446308   
   Yearly Amount Spent  
0           587.951054  
1           392.204933  
2           487.547505  
3           581.852344  
4           599.406092
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We <a id="_idIndexMarker498" class="calibre3"/>anticipate receiving a response similar to the following, wherein ChatGPT will offer guidance on the subsequent steps. Initially, we refrained from specifying any particular steps in the initial prompt, opting instead to allow ChatGPT to determine the subsequent course of action: </p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Great! The <a id="_idIndexMarker499" class="calibre3"/>dataset has been loaded successfully. Now, we can proceed with building our linear regression model to predict the “Yearly Amount Spent” by customers.</p>
    <p class="normal1">The steps involved in building a simple linear regression model are as follows:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Data Preparation</strong>: Split the dataset into input features (<code class="inlinecode">X</code>) and the target variable (<code class="inlinecode">y</code>).</li>
      <li class="bulletlist1"><strong class="screentext">Split Data</strong>: Split the dataset into training and testing sets.</li>
      <li class="bulletlist1"><strong class="screentext">Model Initialization</strong>: Create a linear regression model object.</li>
      <li class="bulletlist1"><strong class="screentext">Model Training</strong>: Fit the model to the training data.</li>
      <li class="bulletlist1"><strong class="screentext">Model Evaluation</strong>: Evaluate the model’s performance using the testing data.</li>
    </ul>
    <p class="normal1">Let’s start with <em class="italic">step 1</em>:</p>
    <p class="normal1">Step 1: Data Preparation:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Extract input features (X) and target variable (y)</span>
X = ecommerce_data[[<span class="hljs-string">'Avg. Session Length'</span>, <span class="hljs-string">'Time on App'</span>, <span class="hljs-string">'Time on Website'</span>, <span class="hljs-string">'Length of Membership'</span>]]
y = ecommerce_data[<span class="hljs-string">'Yearly Amount Spent'</span>]
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">X = ecommerce_data[['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']]</code>: This line selects the input features (<code class="inlinecode">'Avg. Session Length'</code>, <code class="inlinecode">'Time on App'</code>, <code class="inlinecode">'Time on Website'</code>, <code class="inlinecode">'Length of Membership'</code>) from the dataset and assigns them to the variable <code class="inlinecode">X</code>.</li>
      <li class="bulletlist1"><code class="inlinecode">y = ecommerce_data['Yearly Amount Spent']</code>: This line selects the target variable <code class="inlinecode">'Yearly Amount Spent'</code> from the dataset and assigns it to the variable <code class="inlinecode">y</code>.</li>
    </ul>
    <p class="normal1">Let me know if you have any questions or if you’d like to proceed to the next step!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">ChatGPT has outlined the steps it will adhere to for code generation. Furthermore, it has furnished the code for the initial step, data preparation, wherein the dataset is divided into features and the target variable. Notably, it adeptly discerned the features by excluding email addresses, avatars, and addresses. Additionally, it precisely employed the column names as stipulated in the description provided in the initial prompt. The strategy employed here involves including the dataset column names in the prompt to ensure compatibility with the generated code. Hence, the code executes without any modifications or errors.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B21232_13_03.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 13.3: Step 1 – data preparation</p>
    <p class="normal1">Next, we will <a id="_idIndexMarker500" class="calibre3"/>instruct ChatGPT to proceed:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed to the next step.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following to split the data along with the explanation:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Great! Now that we have prepared our data by separating the input features (<code class="inlinecode">X</code>) and the target variable (<code class="inlinecode">y</code>), we can proceed to the next step, which is splitting the data into training and testing sets.</p>
    <p class="normal1">Step 2: Split Data:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-comment"># Split the data into training and testing sets (80% train, 20% test)</span>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-attr">0.2</span>, random_state=<span class="hljs-attr">42</span>)
<span class="hljs-comment"># Display the shapes of the training and testing sets</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Training set shape - X_train:"</span>, X_train.shape, <span class="hljs-string">"y_train:"</span>, y_train.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Testing set shape - X_test:"</span>, X_test.shape, <span class="hljs-string">"y_test:"</span>, y_test.shape)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">from sklearn.model_selection import train_test_split</code>: This line imports <a id="_idIndexMarker501" class="calibre3"/>the <code class="inlinecode">train_test_split</code> function from the <code class="inlinecode">sklearn.model_selection</code> module, which is used to split the dataset into training and testing sets.</li>
      <li class="bulletlist1"><code class="inlinecode">train_test_split(X, y, test_size=0.2, random_state=42)</code>: This function splits the input features (<code class="inlinecode">X</code>) and the target variable (<code class="inlinecode">y</code>) into training and testing sets. The <code class="inlinecode">test_size</code> parameter specifies the proportion of the dataset to include in the testing set (in this case, 20% for testing). The <code class="inlinecode">random_state</code> parameter is used for reproducibility, ensuring that the same random split is generated each time the code is run.</li>
      <li class="bulletlist1"><code class="inlinecode">X_train, X_test, y_train, y_test</code>: These variables hold the training and testing sets for the input features (<code class="inlinecode">X</code>) and the target variable (<code class="inlinecode">y</code>), respectively.</li>
      <li class="bulletlist1"><code class="inlinecode">print("Training set shape - X_train:", X_train.shape, "y_train:", y_train.shape)</code>: This line prints the shapes of the training set input features (<code class="inlinecode">X_train</code>) and target variable (<code class="inlinecode">y_train</code>).</li>
      <li class="bulletlist1"><code class="inlinecode">print("Testing set shape - X_test:", X_test.shape, "y_test:", y_test.shape)</code>: This line prints the shapes of the testing set input features (<code class="inlinecode">X_test</code>) and target variable (<code class="inlinecode">y_test</code>).</li>
    </ul>
    <p class="normal1">Let me know if you have any questions or if you’d like to proceed to the next step!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">The code executed successfully, and the data was split into training and testing sets with the expected 80-20 ratio. Notably, we did not explicitly specify the ratio, yet ChatGPT defaulted to the standard 80-20 split.</p>
    <figure class="mediaobject"><img alt="A white screen with text  Description automatically generated with medium confidence" src="../Images/B21232_13_04.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 13.4: Step 2 – split the data</p>
    <p class="normal1">Next, we<a id="_idIndexMarker502" class="calibre3"/> will provide the output of the previous step to ChatGPT, which should let ChatGPT know about the shape and it should also provide us the code for the next step:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <pre class="programlisting"><code class="hljs-code">Training <span class="hljs-built_in">set</span> shape - X_train: (<span class="hljs-attr">400</span>, <span class="hljs-attr">4</span>) y_train: (<span class="hljs-attr">400</span>,)
Testing <span class="hljs-built_in">set</span> shape - X_test: (<span class="hljs-attr">100</span>, <span class="hljs-attr">4</span>) y_test: (<span class="hljs-attr">100</span>,)
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following where the model is initialized:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Perfect! We have successfully split our dataset into training and testing sets. The training set contains 400 samples, while the testing set contains 100 samples. Each sample consists of four input features and one target variable.</p>
    <p class="normal1">Now, let’s proceed to the next step, which is initializing our linear regression model.</p>
    <p class="normal1">Step 3: Model Initialization:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression
<span class="hljs-comment"># Initialize the linear regression model</span>
model = LinearRegression()
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">from sklearn.linear_model import LinearRegression</code>: This line imports the <code class="inlinecode">LinearRegression</code> class from the <code class="inlinecode">sklearn.linear_model</code> module, which is used to create a linear regression model.</li>
      <li class="bulletlist1"><code class="inlinecode">model = LinearRegression()</code>: This line initializes a linear regression model object and assigns it to the variable model.</li>
    </ul>
    <p class="normal1">Let me know if you have any questions or if you’d like to proceed to the next step!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">The code is executed perfectly fine without any errors. Necessary imports are also provided by ChatGPT.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_13_05.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 13.5: Step 3 – model initialization</p>
    <p class="normal1">We’ll <a id="_idIndexMarker503" class="calibre3"/>simply direct ChatGPT to continue. It’s worth noting that because our initial prompt included the instruction to provide step-by-step code, we don’t need to tailor our subsequent prompts to each individual step or task. Instead, we’ll allow ChatGPT to lead us, providing it with the outputs from the preceding steps as necessary:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following to train the model:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Great! Now that we have initialized our linear regression model, we can move on to the next step, which is training the model using the training data.</p>
    <p class="normal1">Step 4: Model Training:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Train the linear regression model using the training data</span>
model.fit(X_train, y_train)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">model.fit(X_train, y_train)</code>: This line fits (or trains) the linear regression model using the training data. The <code class="inlinecode">fit</code> method takes the input features (<code class="inlinecode">X_train</code>) and the corresponding target variable (<code class="inlinecode">y_train</code>) as arguments and adjusts the model’s parameters to minimize the difference between the actual and predicted values.</li>
    </ul>
    <p class="normal1">Now that our model has been trained, we can proceed to the final step, which is evaluating the model’s performance using the testing data.</p>
    <p class="normal1">Let me know if you have any questions or if you’d like to proceed!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will <a id="_idIndexMarker504" class="calibre3"/>execute the code and that should train the model.</p>
    <figure class="mediaobject"><img alt="A computer screen shot of a computer code  Description automatically generated" src="../Images/B21232_13_06.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 13.6: Step 4 – model training</p>
    <p class="normal1">We will instruct ChatGPT to proceed:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s proceed</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following to evaluate the performance of the model using test data:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Great! Now that our linear regression model has been trained, we can evaluate its performance using the testing data.</p>
    <p class="normal1">Step 5: Model Evaluation:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Make predictions on the testing data</span>
y_pred = model.predict(X_test)
<span class="hljs-comment"># Evaluate the model's performance</span>
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error, r2_score
<span class="hljs-comment"># Calculate Mean Squared Error (MSE)</span>
mse = mean_squared_error(y_test, y_pred)
<span class="hljs-comment"># Calculate R-squared (coefficient of determination)</span>
r_squared = r2_score(y_test, y_pred)
<span class="hljs-comment"># Print the evaluation metrics</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Mean Squared Error (MSE):"</span>, mse)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"</span><span class="hljs-string">R-squared (Coefficient of Determination):"</span>, r_squared)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">model.predict(X_test)</code>: This line uses the trained model to make <a id="_idIndexMarker505" class="calibre3"/>predictions on the input features (<code class="inlinecode">X_test</code>), which generates the predicted values of the target variable.</li>
      <li class="bulletlist1"><code class="inlinecode">from sklearn.metrics import mean_squared_error, r2_score</code>: This line imports the <code class="inlinecode">mean_squared_error</code> and <code class="inlinecode">r2_score</code> functions from the <code class="inlinecode">sklearn.metrics</code> module, which are used to evaluate the model’s performance.</li>
      <li class="bulletlist1"><code class="inlinecode">mean_squared_error(y_test, y_pred)</code>: This function calculates the mean squared error (<code class="inlinecode">MSE</code>) between the actual target variable (<code class="inlinecode">y_test</code>) and the predicted values (<code class="inlinecode">y_pred</code>).</li>
      <li class="bulletlist1"><code class="inlinecode">r2_score(y_test, y_pred)</code>: This function calculates the R-squared (coefficient of determination) between the actual target variable (<code class="inlinecode">y_test</code>) and the predicted values (<code class="inlinecode">y_pred</code>).</li>
      <li class="bulletlist1"><code class="inlinecode">print("Mean Squared Error (MSE):", mse)</code>: This line prints the mean squared error (<code class="inlinecode">MSE</code>), which measures the average squared difference between the actual and predicted values. A lower MSE indicates better model performance.</li>
      <li class="bulletlist1"><code class="inlinecode">print("R-squared (Coefficient of Determination):", r_squared)</code>: This line prints the R-squared value, which represents the proportion of the variance in the target variable that is explained by the model. A higher R-squared value (closer to 1) indicates better fit.</li>
    </ul>
    <p class="normal1">These evaluation metrics will help us assess how well our linear regression model is performing in predicting the “Yearly Amount Spent” by customers.</p>
    <p class="normal1">Let me know if you have any questions or if you’d like further explanation on any part!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We <a id="_idIndexMarker506" class="calibre3"/>execute the code and it runs perfectly fine without any errors and prints the <strong class="screentext">mean-squared error</strong> (<strong class="screentext">MSE</strong>) and the coefficient of determination (<code class="inlinecode">R-squared</code>).</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B21232_13_07.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 13.7: Model evaluation output</p>
    <p class="normal1">For those new to machine learning, it’s crucial to assess whether the model performance meets acceptable standards. Once more, we’ll seek assistance from ChatGPT and furnish it with the output for evaluation:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <pre class="programlisting"><code class="hljs-code">Mean Squared Error (MSE): 109.8637411839399
R-squared (Coefficient of Determination): 0.9778130629184127
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response from ChatGPT explaining the results, which suggests that our model is actually performing very well given that R-squared is very close to 1:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">The evaluation metrics indicate that our linear regression model performs quite well on the testing data:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Mean Squared Error (MSE)</strong>: The MSE value is approximately 109.86. This indicates that, on average, the<a id="_idIndexMarker507" class="calibre3"/> squared difference between the actual and predicted values of the “Yearly Amount Spent” is around 109.86. Lower MSE values are desirable, indicating better model performance.</li>
      <li class="bulletlist1"><strong class="screentext">R-squared (Coefficient of Determination)</strong>: The R-squared value<a id="_idIndexMarker508" class="calibre3"/> is approximately 0.978. This indicates that approximately 97.8% of the variance in the “Yearly Amount Spent” can be explained by the linear regression model. A higher R-squared value closer to 1 suggests that the model provides a better fit to the data.</li>
    </ul>
    <p class="normal1">Overall, these<a id="_idIndexMarker509" class="calibre3"/> evaluation metrics suggest that our linear regression model is performing well in predicting the “Yearly Amount Spent” by customers based on the provided input features.</p>
    <p class="normal1">If you have any further questions or need additional assistance, feel free to ask!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">Having now acquired proficiency in utilizing ChatGPT to construct a linear regression model incrementally, we’ll transition to the second feature and delve into the application of regularization techniques. While our current model exhibits satisfactory performance, regularization can prove invaluable, particularly in scenarios where the model is either underfitted or overfitted.</p>
    <h2 class="heading1" id="_idParaDest-287">Feature 2: Applying regularization techniques</h2>
    <p class="normal">We will <a id="_idIndexMarker510" class="calibre3"/>use the learn and improvise prompting strategy (LIFE 3.1 and 3.2) with ChatGPT to understand whether the model could be overfitted and what should be done in such a case:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Could the model be overfitting?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We receive the response from ChatGPT indicating that it is unlikely that our model is overfitted but it does suggest some things to consider such as regularization techniques and cross-validation:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">It’s <a id="_idIndexMarker511" class="calibre3"/>essential to consider the possibility of overfitting when interpreting the model’s performance. Overfitting occurs when the model learns to capture noise or random fluctuations in the training data, rather than the underlying relationships between the input features and the target variable. This can result in a model that performs well on the training data but generalizes poorly to unseen data.</p>
    <p class="normal1">Here are a few indicators that suggest overfitting may be occurring:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Large Discrepancy Between Training and Testing Performance</strong>: If the model performs significantly better on the training data compared to the testing data, it may be overfitting. In our case, if the MSE and R-squared values are much better on the training set than on the testing set, it could indicate overfitting.</li>
      <li class="bulletlist1"><strong class="screentext">Complexity of the Model</strong>: Overly complex models with a large number of parameters relative to the size of the training data are more prone to overfitting. Linear regression is relatively simple, but if you were using a more complex model (e.g., polynomial regression with high-degree polynomials), it could increase the risk of overfitting.</li>
      <li class="bulletlist1"><strong class="screentext">Regularization Techniques</strong>: Regularization techniques like Lasso or Ridge regression can be applied to mitigate overfitting by penalizing large coefficients. If overfitting is suspected, applying regularization may help improve the model’s generalization performance.</li>
      <li class="bulletlist1"><strong class="screentext">Cross-Validation</strong>: Using cross-validation techniques, such as k-fold cross-validation, can provide a more robust estimate of the model’s performance by evaluating it on multiple train-test splits of the data. If the model’s performance varies significantly across different splits, it could indicate overfitting.</li>
    </ul>
    <p class="normal1">In our case, with a high R-squared value and a relatively low MSE on the testing data, it’s less likely that the model is overfitting. However, it’s always a good practice to explore these indicators and consider additional steps to ensure the model’s generalization performance. If you suspect overfitting, you could try simplifying the model, applying regularization techniques, or using cross-validation to further evaluate its performance.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will ask ChatGPT to apply regularization and cross-validation techniques:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Let’s try<a id="_idIndexMarker512" class="calibre3"/> applying regularization techniques first and then cross-validation</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">ChatGPT should provide us with the code to apply either Lasso or Ridge along with cross-validation and also the explanation:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure! Let’s start by applying regularization techniques to our linear regression model. Two common regularization techniques are Lasso regression (L1 regularization) and Ridge regression (L2 regularization). These techniques add a penalty term to the loss function, which helps prevent overfitting by penalizing large coefficients.</p>
    <p class="normal1">We’ll begin by trying Ridge regression, which adds the squared sum of the coefficients (L2 norm) to the loss function.</p>
    <p class="normal1">Here’s how you can implement Ridge regression with cross-validation:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> RidgeCV
<span class="hljs-comment"># Initialize the Ridge regression model with cross-validation</span>
ridge_model = RidgeCV(alphas=[<span class="hljs-attr">0.1</span>, <span class="hljs-attr">1.0</span>, <span class="hljs-attr">10.0</span>], cv=<span class="hljs-attr">5</span>)
<span class="hljs-comment"># Train the Ridge regression model</span>
ridge_model.fit(X_train, y_train)
<span class="hljs-comment"># Make predictions on the testing data</span>
ridge_y_pred = ridge_model.predict(X_test)
<span class="hljs-comment"># Evaluate the model's performance</span>
ridge_mse = mean_squared_error(y_test, ridge_y_pred)
ridge_r_squared = ridge_model.score(X_test, y_test)
<span class="hljs-comment"># Print the evaluation metrics</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Ridge Regression - Mean Squared Error (MSE):"</span>, ridge_mse)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Ridge Regression - R-squared (Coefficient of Determination):"</span>, ridge_r_squared)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Ridge Regression - Best Alpha:"</span>, ridge_model.alpha_)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">RidgeCV(alphas=[0.1, 1.0, 10.0], cv=5)</code>: This initializes a Ridge regression model with cross-validation. The <code class="inlinecode">alphas</code> parameter specifies the regularization strength (alpha values) to be tested, and <code class="inlinecode">cv</code> specifies the number of folds for cross-validation.</li>
      <li class="bulletlist1"><code class="inlinecode">ridge_model.fit(X_train, y_train)</code>: This trains the Ridge regression model using the training data.</li>
      <li class="bulletlist1"><code class="inlinecode">ridge_model.predict(X_test)</code>: This makes predictions on the testing data using the trained Ridge regression model.</li>
      <li class="bulletlist1"><code class="inlinecode">ridge_mse = mean_squared_error(y_test, ridge_y_pred)</code>: This calculates the mean squared error (<code class="inlinecode">MSE</code>) between the actual and predicted values using Ridge regression.</li>
      <li class="bulletlist1"><code class="inlinecode">ridge_model.score(X_test, y_test)</code>: This calculates the R-squared value (coefficient of determination) using Ridge regression.</li>
      <li class="bulletlist1"><code class="inlinecode">ridge_model.alpha_</code>: This attribute returns the best alpha (regularization strength) selected by cross-validation.</li>
    </ul>
    <p class="normal1">Let me <a id="_idIndexMarker513" class="calibre3"/>know if you’d like to proceed with Ridge regression or if you have any questions!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">Let’s try executing the code and see whether it works and shows any improvement.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_13_08.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 13.8: Ridge regression</p>
    <p class="normal1">The code is <a id="_idIndexMarker514" class="calibre3"/>compatible with previously provided code and the output is very similar to the linear regression code. But note that ChatGPT doesn’t need any specific instructions and it could generate a perfectly fine executable code. Next, we will provide ChatGPT with the output and see what it suggests:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <pre class="programlisting"><code class="hljs-code">Ridge Regression - Mean Squared Error (MSE): 109.82024999312038
Ridge Regression - R-squared (Coefficient of Determination): 0.9778218459464064
Ridge Regression - Best Alpha: 0.1
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">In this case, ChatGPT has interpreted the results and also provided the code for Lasso regression with cross-validation. The response may vary depending on the suggestions provided by ChatGPT in previous interactions:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">It looks like the Ridge regression model with cross-validation performed quite similarly to the standard linear regression model. The <strong class="screentext">Mean Squared Error</strong> (<strong class="screentext">MSE</strong>) and R-squared values are very close to those obtained from the standard linear regression model.</p>
    <p class="normal1">The best alpha selected by cross-validation for the Ridge regression model is 0.1, indicating that a small amount of regularization was applied to the model.</p>
    <p class="normal1">Since the performance of Ridge regression with cross-validation is comparable to that of the standard linear regression model, we can conclude that regularization did not significantly improve the model’s performance in this case.</p>
    <p class="normal1">Next, let’s <a id="_idIndexMarker515" class="calibre3"/>try using Lasso regression (L1 regularization) with cross-validation to see if it yields any improvement:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LassoCV
<span class="hljs-comment"># Initialize the Lasso regression model with cross-validation</span>
lasso_model = LassoCV(alphas=[<span class="hljs-attr">0.1</span>, <span class="hljs-attr">1.0</span>, <span class="hljs-attr">10.0</span>], cv=<span class="hljs-attr">5</span>)
<span class="hljs-comment"># Train the Lasso regression model</span>
lasso_model.fit(X_train, y_train)
<span class="hljs-comment"># Make predictions on the testing data</span>
lasso_y_pred = lasso_model.predict(X_test)
<span class="hljs-comment"># Evaluate the model's performance</span>
lasso_mse = mean_squared_error(y_test, lasso_y_pred)
lasso_r_squared = lasso_model.score(X_test, y_test)
<span class="hljs-comment"># Print the evaluation metrics</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Lasso Regression - Mean Squared Error (MSE):"</span>, lasso_mse)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Lasso Regression - R-squared (Coefficient of Determination):"</span>, lasso_r_squared)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Lasso Regression - Best Alpha:"</span>, lasso_model.alpha_)
</code></pre>
    <p class="normal1">Let me know if you’d like to proceed with Lasso regression or if you have any questions!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will execute the code and see whether it works and produces any different results than Ridge regression.</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer program  Description automatically generated" src="../Images/B21232_13_09.png" class="calibre19"/></figure>
    <p class="packt_figref">Figure 13.9: Lasso regression</p>
    <p class="normal1">Lasso regression with cross-validation also produced similar results to both the standard linear regression and Ridge regression models. The MSE and R-squared values are very close to those obtained previously.</p>
    <p class="normal1">However, it’s<a id="_idIndexMarker516" class="calibre3"/> important to note that the dataset used here may not be complex enough to benefit significantly from regularization techniques. In cases where the dataset is larger or more complex, regularization may play a more crucial role in preventing overfitting and improving model generalization.</p>
    <p class="normal1">Let’s move to the next feature to generate a synthetic dataset for our problem to add complexity.</p>
    <h2 class="heading1" id="_idParaDest-288">Feature 3: Generating a synthetic dataset to add complexity</h2>
    <p class="normal">We will use<a id="_idIndexMarker517" class="calibre3"/> the conversation style with ChatGPT and ask it to provide code to generate a synthetic dataset:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you please provide me a code to generate the synthetic dataset for it to add complexity?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">You may receive a variant of the following response. However, you may notice that this is generic code and is not suitable for generating the code specific to our dataset. Hence, we will need to refine the prompt by providing feedback to ChatGPT:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure! We can generate a synthetic dataset with additional complexity using the <code class="inlinecode">make_regression</code> function from the <code class="inlinecode">sklearn.datasets</code> module. This function generates a random regression problem with specified characteristics, such as the number of samples, the number of features, and the noise level.</p>
    <p class="normal1">Here’s how you can generate a synthetic dataset with added complexity:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_regression
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-comment"># Generate synthetic dataset with 500 samples, 10 features, and increased noise</span>
X_synthetic, y_synthetic = make_regression(n_samples=<span class="hljs-attr">500</span>, n_features=<span class="hljs-attr">10</span>, noise=<span class="hljs-attr">50</span>, random_state=<span class="hljs-attr">42</span>)
<span class="hljs-comment"># Create a DataFrame from the synthetic dataset</span>
synthetic_data = pd.DataFrame(X_synthetic, columns=[<span class="hljs-string">f'Feature_</span><span class="hljs-name">{i}</span><span class="hljs-string">'</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-attr">1</span>, <span class="hljs-attr">11</span>)])
synthetic_data[<span class="hljs-string">'Target'</span>] = y_synthetic
<span class="hljs-comment"># Display the first few rows of the synthetic dataset</span>
<span class="hljs-built_in">print</span>(synthetic_data.head())
<span class="hljs-comment"># Save the synthetic dataset to a CSV file</span>
synthetic_data.to_csv(<span class="hljs-string">'synthetic_dataset.csv'</span>, index=<span class="hljs-literal">False</span>)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist"><code class="inlinecode">make_regression(n_samples=500, n_features=10, noise=50, random_state=42)</code>: This<a id="_idIndexMarker518" class="calibre3"/> function generates a synthetic regression dataset with 500 samples, 10 features, and increased noise level (specified by the noise parameter). The <code class="inlinecode">random_state</code> parameter ensures reproducibility.</li>
      <li class="bulletlist1"><code class="inlinecode">pd.DataFrame(X_synthetic, columns=[f'Feature_{i}' for i in range(1, 11)])</code>: This creates a DataFrame from the synthetic input features (<code class="inlinecode">X_synthetic</code>) and assigns column names <code class="inlinecode">'Feature_1'</code> to <code class="inlinecode">'Feature_10'</code>.</li>
      <li class="bulletlist1"><code class="inlinecode">synthetic_data['Target'] = y_synthetic</code>: This adds the synthetic target variable (<code class="inlinecode">y_synthetic</code>) to the DataFrame with the column name <code class="inlinecode">'Target'</code>.</li>
      <li class="bulletlist1"><code class="inlinecode">synthetic_data.to_csv('synthetic_dataset.csv', index=False)</code>: This saves the synthetic dataset to a CSV file named <code class="inlinecode">'synthetic_dataset.csv'</code> without including the <code class="inlinecode">index</code> column.</li>
    </ul>
    <p class="normal1">You can adjust the parameters of the <code class="inlinecode">make_regression</code> function to control the complexity of the synthetic dataset, such as the number of samples, the number of features, and the noise level.</p>
    <p class="normal1">Let me know if you need further assistance!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will simply instruct ChatGPT that we need the code for our dataset:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">No, I meant for our problem.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">Let’s see what ChatGPT suggests and whether it really works:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Got it! We can create a synthetic dataset for our problem by using the same input features as the original dataset but with added complexity. We’ll generate additional features that are nonlinear combinations of the original features and add noise to mimic real-world data.</p>
    <p class="normal1">Here’s how <a id="_idIndexMarker519" class="calibre3"/>you can generate a synthetic dataset with added complexity for our problem:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-comment"># Set random seed for reproducibility</span>
np.random.seed(<span class="hljs-attr">42</span>)
<span class="hljs-comment"># Number of samples</span>
n_samples = <span class="hljs-attr">500</span>
<span class="hljs-comment"># Generate synthetic input features</span>
avg_session_length = np.random.normal(loc=<span class="hljs-attr">30</span>, scale=<span class="hljs-attr">5</span>, size=n_samples)
time_on_app = np.random.normal(loc=<span class="hljs-attr">15</span>, scale=<span class="hljs-attr">5</span>, size=n_samples)
time_on_website = np.random.normal(loc=<span class="hljs-attr">20</span>, scale=<span class="hljs-attr">7</span>, size=n_samples)
length_of_membership = np.random.normal(loc=<span class="hljs-attr">3</span>, scale=<span class="hljs-attr">1</span>, size=n_samples)
<span class="hljs-comment"># Generate synthetic target variable (linear combination of input features with noise)</span>
yearly_amount_spent = <span class="hljs-attr">100</span> + (avg_session_length * <span class="hljs-attr">10</span>) + (time_on_app * <span class="hljs-attr">20</span>) + (time_on_website * <span class="hljs-attr">15</span>) + (length_of_membership * <span class="hljs-attr">30</span>) + np.random.normal(loc=<span class="hljs-attr">0</span>, scale=<span class="hljs-attr">50</span>, size=n_samples)
<span class="hljs-comment"># Create a DataFrame from the synthetic dataset</span>
synthetic_data = pd.DataFrame({
    <span class="hljs-string">'Avg. Session Length'</span>: avg_session_length,
    <span class="hljs-string">'Time on App'</span>: time_on_app,
    <span class="hljs-string">'Time on Website'</span>: time_on_website,
    <span class="hljs-string">'Length of Membership'</span>: length_of_membership,
    <span class="hljs-string">'Yearly Amount Spent'</span>: yearly_amount_spent
})
<span class="hljs-comment"># Display the first few rows of the synthetic dataset</span>
<span class="hljs-built_in">print</span>(synthetic_data.head())
<span class="hljs-comment"># Save the synthetic dataset to a CSV file</span>
synthetic_data.to_csv(<span class="hljs-string">'synthetic_ecommerce_data.csv'</span>, index=<span class="hljs-literal">False</span>)
</code></pre>
    <p class="normal1">Explanation:</p>
    <ul class="calibre15">
      <li class="bulletlist">We generate synthetic input features (<code class="inlinecode">avg_session_length</code>, <code class="inlinecode">time_on_app</code>, <code class="inlinecode">time_on_website</code>, <code class="inlinecode">length_of_membership</code>) using normal distributions with specified mean and standard deviation to mimic the characteristics of the original dataset.</li>
      <li class="bulletlist1">We generate the synthetic target variable (<code class="inlinecode">yearly_amount_spent</code>) as a linear combination of the input features with added noise.</li>
      <li class="bulletlist1">Finally, we create a DataFrame from the synthetic dataset and save it to a CSV file.</li>
    </ul>
    <p class="normal1">This synthetic <a id="_idIndexMarker520" class="calibre3"/>dataset will have similar characteristics to the original dataset but with added complexity, which can be useful for testing models and understanding their performance in more challenging scenarios.</p>
    <p class="normal1">Let me know if you need further clarification or assistance!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">The code looks impressive and is adapted to our dataset. On executing, it runs without any errors and generates a CSV file named <code class="inlinecode">synthetic_ecommerce_data.csv</code> and stores it in the runtime environment of the notebook. It also prints the first few rows. You can also download it for future use.</p>
    <p class="normal1">Next, we will request ChatGPT to generate the complete code and evaluate model performance with the added noise in the synthetic dataset. Let’s move to our next feature.</p>
    <h2 class="heading1" id="_idParaDest-289">Feature 4: Generating code to develop a model in a single step for a synthetic dataset</h2>
    <p class="normal">We <a id="_idIndexMarker521" class="calibre3"/>have learned how to create a regression model step by step in previous features, hence we will now request ChatGPT to provide the entire code in a single step for the synthetic dataset:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Now provide me the end-to-end code in a single step to run using the generated synthetic dataset.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We <a id="_idIndexMarker522" class="calibre3"/>should receive a response similar to the following where complete code is provided, including loading the dataset, splitting the dataset, model training, and model evaluation:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Certainly! Below is the end-to-end code that loads the synthetic dataset, splits it into training and testing sets, trains a linear regression model, evaluates its performance, and prints the evaluation metrics.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error, r2_score
<span class="hljs-comment"># Load the synthetic dataset</span>
synthetic_data = pd.read_csv(<span class="hljs-string">'synthetic_ecommerce_data.csv'</span>)
<span class="hljs-comment"># Extract input features (X) and target variable (y)</span>
X = synthetic_data[[<span class="hljs-string">'Avg. Session Length'</span>, <span class="hljs-string">'Time on App'</span>, <span class="hljs-string">'Time on Website'</span>, <span class="hljs-string">'Length of Membership'</span>]]
y = synthetic_data[<span class="hljs-string">'Yearly Amount Spent'</span>]
<span class="hljs-comment"># Split the dataset into training and testing sets (80% train, 20% test)</span>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-attr">0.2</span>, random_state=<span class="hljs-attr">42</span>)
<span class="hljs-comment"># Initialize the linear regression model</span>
model = LinearRegression()
<span class="hljs-comment"># Train the linear regression model using the training data</span>
model.fit(X_train, y_train)
<span class="hljs-comment"># Make predictions on the testing data</span>
y_pred = model.predict(X_test)
<span class="hljs-comment"># Evaluate the model's performance</span>
mse = mean_squared_error(y_test, y_pred)
r_squared = r2_score(y_test, y_pred)
<span class="hljs-comment"># Print the evaluation metrics</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Mean Squared Error (MSE):"</span>, mse)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"R-squared (Coefficient of Determination):"</span>, r_squared)
</code></pre>
    <p class="normal1">This code <a id="_idIndexMarker523" class="calibre3"/>will load the synthetic dataset from the CSV file, split it into training and testing sets, train a linear regression model using the training data, make predictions on the testing data, evaluate the model’s performance using Mean Squared Error (MSE) and R-squared (Coefficient of Determination), and print the evaluation metrics.</p>
    <p class="normal1">You can simply run this code in your Python environment, assuming you have the pandas library installed to work with DataFrames and the scikit-learn library installed for machine learning functionalities.</p>
    <p class="normal1">Let me know if you have any questions or if there’s anything else I can assist you with!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We execute the code and it runs seamlessly.</p>
    <p class="normal1">The evaluation<a id="_idIndexMarker524" class="calibre3"/> metrics for the linear regression model trained on the synthetic dataset are as follows:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">MSE</strong>: Approximately 2103.19</li>
      <li class="bulletlist1"><strong class="screentext">R-squared (coefficient of determination)</strong>: Approximately 0.9197</li>
    </ul>
    <p class="normal1">These metrics provide insight into the model’s performance:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">MSE</strong>: The <a id="_idIndexMarker525" class="calibre3"/>MSE measures the average squared difference between the actual and predicted values. In this case, the MSE indicates that, on average, the squared difference between the actual and predicted yearly amount spent is approximately 2103.19. Lower MSE values are desirable, indicating better model performance.</li>
      <li class="bulletlist1"><strong class="screentext">R-squared (coefficient of determination)</strong>: The R-squared value<a id="_idIndexMarker526" class="calibre3"/> represents the proportion of the variance in the target variable (<code class="inlinecode">Yearly Amount Spent</code>) that is explained by the model. In this case, the R-squared value of approximately 0.9197 suggests that approximately 91.97% of the variance in the yearly amount spent can be explained by the linear regression model. A higher R-squared value closer to 1 indicates a better fit.</li>
    </ul>
    <p class="normal1">Overall, these <a id="_idIndexMarker527" class="calibre3"/>evaluation metrics suggest that the linear regression model performs reasonably well on the synthetic dataset.</p>
    <p class="normal1">In the context of the online e-commerce store, the insights from these models can be used for various purposes:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Customer segmentation</strong>: The models can help identify high-value customers based on their predicted <code class="inlinecode">Yearly Amount Spent</code>, allowing for targeted marketing efforts.</li>
      <li class="bulletlist1"><strong class="screentext">Recommendation systems</strong>: Understanding the factors that influence spending can be used to improve product recommendations and enhance the customer shopping experience.</li>
      <li class="bulletlist1"><strong class="screentext">Retention strategies</strong>: <code class="inlinecode">Length of Membership</code> appears to be an important factor. Strategies to increase customer retention and loyalty can be developed based on this insight.</li>
      <li class="bulletlist1"><strong class="screentext">Optimizing website and app</strong>: Insights into the impact of <code class="inlinecode">Average Session Length</code>, <code class="inlinecode">Time on App</code>, and <code class="inlinecode">Time on Website</code> can guide decisions on website and app optimization.</li>
    </ul>
    <p class="normal1">This concludes our learning with ChatGPT 3.5. Now, let’s see how prompting and learning differ with ChatGPT Plus.</p>
    <h1 class="heading" id="_idParaDest-290">Learning simple linear regression using ChatGPT Plus</h1>
    <p class="normal">Now<a id="_idIndexMarker528" class="calibre3"/> that we have learned about simple linear regression while using ChatGPT, let’s learn about linear regression while using ChatGPT Plus. ChatGPT Plus, or GPT-4, includes the ability to upload datasets, analyze the dataset, and produce results if using simple libraries such as Python and Matplotlib. At the time of writing this chapter, it had a GPT assistant <a id="_idIndexMarker529" class="calibre3"/>named <strong class="screentext">Data Analysis</strong>, provided by <a id="_idIndexMarker530" class="calibre3"/>OpenAI when using the mobile app. You could also select GPT-4 if using the browser version. </p>
    <p class="normal1">Note that you can also achieve the same using the free version but would need to execute the code yourself and modify the prompt.</p>
    <h2 class="heading1" id="_idParaDest-291">Feature 1: Building a simple linear regression model step by step</h2>
    <p class="normal">We <a id="_idIndexMarker531" class="calibre3"/>have learned how to create a regression model step by step using the free version of ChatGPT where we had to provide the dataset description, instructions on from where to load, and code compatible with Jupyter Notebook. In the case of ChatGPT Plus, all of that is taken care of by ChatGPT Plus and it also provides a runtime environment to execute the code. </p>
    <p class="normal1">Note that it cannot run TensorFlow, Keras, or deep learning libraries:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">I want to create a simple linear regression model to predict the “Yearly Amount Spent” (TAG 1.1) by customers for the attached e-commerce customers dataset (PIC 2.3)</p>
    <p class="normal1">I am a beginner user (PIC 2.1), so please provide step-by-step code and strictly follow the following instructions (PIC 2.2): </p>
    <ul class="calibre15">
      <li class="bulletlist">Ensure that there are detailed comments for each line of code. </li>
      <li class="bulletlist1">You have to explain each line of code and provide one step at a time and wait for users feedback</li>
    </ul>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We <a id="_idIndexMarker532" class="calibre3"/>should receive a response similar to the following where the complete code is provided, including loading the dataset, splitting the dataset, model training, and model evaluation:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Great! Let’s start building a simple linear regression model using Python. We’ll be using libraries such as <code class="inlinecode">pandas</code> for handling the data and <code class="inlinecode">sklearn</code> for creating the regression model.</p>
    <p class="normal1">Step 1: Import Libraries and Load Data</p>
    <p class="normal1">First, we’ll import necessary libraries and load your dataset. We’ll also take a look at the first few rows of the dataset to understand its structure.</p>
    <p class="normal1">Here’s the code for this step:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Import necessary libraries</span>
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd  <span class="hljs-comment"># pandas is used for data manipulation and analysis</span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split  <span class="hljs-comment"># This function is used to split data into training and testing sets</span>
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression  <span class="hljs-comment"># This class is used to perform linear regression</span>
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_absolute_error, mean_squared_error  <span class="hljs-comment"># These functions are used to evaluate the model</span>
<span class="hljs-comment"># Load the dataset</span>
data = pd.read_csv(<span class="hljs-string">'/mnt/data/Ecommerce Customers (1).csv'</span>)  <span class="hljs-comment"># Reading the CSV file into a pandas DataFrame</span>
<span class="hljs-comment"># Display the first few rows of the dataset to understand its structure</span>
<span class="hljs-built_in">print</span>(data.head())
</code></pre>
    <p class="normal1">This block of code does the following:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Imports libraries</strong>: We load <code class="inlinecode">pandas</code> for data handling, and several modules from <code class="inlinecode">sklearn</code> for splitting the data and performing linear regression.</li>
      <li class="bulletlist1"><strong class="screentext">Loads the data</strong>: The <code class="inlinecode">pd.read_csv</code> function reads the CSV file into a DataFrame, which is a 2-dimensional labeled data structure with columns of potentially different types.</li>
      <li class="bulletlist1"><strong class="screentext">Prints the first few rows</strong>: This helps us see the initial rows of our dataset to understand the available data and its format.</li>
    </ul>
    <p class="normal1">Let’s <a id="_idIndexMarker533" class="calibre3"/>execute this step and check the output to ensure everything is loaded correctly and to understand what your data looks like. Shall we proceed?</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will instruct ChatGPT to proceed:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Yes, please.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should <a id="_idIndexMarker534" class="calibre3"/>receive a response similar to the following, where ChatGPT has executed the code and printed the first few rows.</p>
    <p class="normal1">Note that the file is loaded in ChatGPT’s run time environment; if you need to execute code in your local environment or Jupyter Colab, you would be required to modify the step to read CSV:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Here’s the snapshot of the first few rows of your dataset:</p>
    <table class="table-container" id="table001">
      <thead class="calibre22">
        <tr class="calibre23">
          <td class="table-cell">
            <p class="normal2">Email</p>
          </td>
          <td class="table-cell">
            <p class="normal2">Address</p>
          </td>
          <td class="table-cell">
            <p class="normal2">Avatar</p>
          </td>
          <td class="table-cell">
            <p class="normal2">Avg. Session Length</p>
          </td>
          <td class="table-cell">
            <p class="normal2">Time on App</p>
          </td>
          <td class="table-cell">
            <p class="normal2">Time on Website</p>
          </td>
          <td class="table-cell">
            <p class="normal2">Length of Membership</p>
          </td>
          <td class="table-cell">
            <p class="normal2">Yearly Amount Spent</p>
          </td>
        </tr>
      </thead>
      <tbody class="calibre24">
        <tr class="calibre23">
          <td class="table-cell">
            <p class="normal2">mstephenson@fernandez.com</p>
          </td>
          <td class="table-cell">
            <p class="normal2">835 Frank Tunnel Wrightmouth, MI 82180-9605</p>
          </td>
          <td class="table-cell">
            <p class="normal2">Violet</p>
          </td>
          <td class="table-cell">
            <p class="normal2">34.497268</p>
          </td>
          <td class="table-cell">
            <p class="normal2">12.655651</p>
          </td>
          <td class="table-cell">
            <p class="normal2">39.577668</p>
          </td>
          <td class="table-cell">
            <p class="normal2">4.082621</p>
          </td>
          <td class="table-cell">
            <p class="normal2">587.951054</p>
          </td>
        </tr>
        <tr class="calibre23">
          <td class="table-cell">
            <p class="normal2">hduke@hotmail.com</p>
          </td>
          <td class="table-cell">
            <p class="normal2">4547 Archer Common Diazchester, CA 06566-8576</p>
          </td>
          <td class="table-cell">
            <p class="normal2">DarkGreen</p>
          </td>
          <td class="table-cell">
            <p class="normal2">31.926272</p>
          </td>
          <td class="table-cell">
            <p class="normal2">11.109461</p>
          </td>
          <td class="table-cell">
            <p class="normal2">37.268959</p>
          </td>
          <td class="table-cell">
            <p class="normal2">2.664034</p>
          </td>
          <td class="table-cell">
            <p class="normal2">392.204933</p>
          </td>
        </tr>
        <tr class="calibre23">
          <td class="table-cell">
            <p class="normal2">pallen@yahoo.com</p>
          </td>
          <td class="table-cell">
            <p class="normal2">24645 Valerie Unions Suite 582 Cobbborough, ...</p>
          </td>
          <td class="table-cell">
            <p class="normal2">Bisque</p>
          </td>
          <td class="table-cell">
            <p class="normal2">33.000915</p>
          </td>
          <td class="table-cell">
            <p class="normal2">11.330278</p>
          </td>
          <td class="table-cell">
            <p class="normal2">37.110597</p>
          </td>
          <td class="table-cell">
            <p class="normal2">4.104543</p>
          </td>
          <td class="table-cell">
            <p class="normal2">487.547505</p>
          </td>
        </tr>
        <tr class="calibre23">
          <td class="table-cell">
            <p class="normal2">riverarebecca@gmail.com</p>
          </td>
          <td class="table-cell">
            <p class="normal2">1414 David Throughway Port Jason, OH 22070-1220</p>
          </td>
          <td class="table-cell">
            <p class="normal2">SaddleBrown</p>
          </td>
          <td class="table-cell">
            <p class="normal2">34.305557</p>
          </td>
          <td class="table-cell">
            <p class="normal2">13.717514</p>
          </td>
          <td class="table-cell">
            <p class="normal2">36.721283</p>
          </td>
          <td class="table-cell">
            <p class="normal2">3.120179</p>
          </td>
          <td class="table-cell">
            <p class="normal2">581.852344</p>
          </td>
        </tr>
        <tr class="calibre23">
          <td class="table-cell">
            <p class="normal2">mstephens@davidson-herman.com</p>
          </td>
          <td class="table-cell">
            <p class="normal2">14023 Rodriguez Passage Port Jacobville, PR 3...</p>
          </td>
          <td class="table-cell">
            <p class="normal2">MediumAquaMarine</p>
          </td>
          <td class="table-cell">
            <p class="normal2">33.330673</p>
          </td>
          <td class="table-cell">
            <p class="normal2">12.795189</p>
          </td>
          <td class="table-cell">
            <p class="normal2">37.536653</p>
          </td>
          <td class="table-cell">
            <p class="normal2">4.446308</p>
          </td>
          <td class="table-cell">
            <p class="normal2">599.406092</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal1">The <a id="_idIndexMarker535" class="calibre3"/>dataset includes both customer contact information (like <code class="inlinecode">Email</code> and <code class="inlinecode">Address</code>) and numerical data related to their interaction with the e-commerce platform (like “Avg. Session Length”, “Time on App”, “Time on Website”, and “Length of Membership”).</p>
    <p class="normal1">Step 2: Data Preparation</p>
    <p class="normal1">The next step will involve preparing the data for our linear regression model. This includes:</p>
    <ul class="calibre15">
      <li class="bulletlist">Selecting the relevant numerical columns for the prediction.</li>
      <li class="bulletlist1">Splitting the data into a training set and a testing set.</li>
    </ul>
    <p class="normal1">Do you have any specific columns you want to use for predicting “Yearly Amount Spent”, or should I proceed with a general approach using all numerical columns?</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will instruct ChatGPT to proceed using numerical columns:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Please use only numerical columns.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should<a id="_idIndexMarker536" class="calibre3"/> receive a response similar to the following, where ChatGPT has provided code for selecting the features, splitting the dataset, and printing the shape:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Step 2: Data Preparation</p>
    <p class="normal1">We’ll now proceed with the following steps in preparing the data:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Selecting the relevant columns</strong>: We’ll include the columns that are numerical and directly relate to customer behavior.</li>
      <li class="bulletlist1"><strong class="screentext">Splitting the data into training and testing sets</strong>: This helps us evaluate our model on unseen data to ensure it performs well generally.</li>
    </ul>
    <p class="normal1">Here’s the code to perform these steps:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Selecting only the numerical columns for features</span>
features = data[[<span class="hljs-string">'Avg. Session Length'</span>, <span class="hljs-string">'Time on App'</span>, <span class="hljs-string">'Time on Website'</span>, <span class="hljs-string">'Length of Membership'</span>]]
<span class="hljs-comment"># Selecting the target column which is 'Yearly Amount Spent'</span>
target = data[<span class="hljs-string">'Yearly Amount Spent'</span>]
<span class="hljs-comment"># Splitting the dataset into training and testing sets</span>
<span class="hljs-comment"># We allocate 80% of the data for training and 20% for testing</span>
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=<span class="hljs-attr">0.2</span>, random_state=<span class="hljs-attr">42</span>)
<span class="hljs-comment"># Printing the shapes of the training and testing sets to verify the split</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Training features shape: </span><span class="hljs-name">{X_train.shape}</span><span class="hljs-string">'</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Testing features shape: </span><span class="hljs-name">{X_test.shape}</span><span class="hljs-string">'</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Training labels shape: </span><span class="hljs-name">{y_train.shape}</span><span class="hljs-string">'</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Testing labels shape: </span><span class="hljs-name">{y_test.shape}</span><span class="hljs-string">'</span>)
</code></pre>
    <p class="normal1">This <a id="_idIndexMarker537" class="calibre3"/>block of code:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Selects features and target</strong>: We separate the columns for the features and the target variable which is what we aim to predict.</li>
      <li class="bulletlist1"><strong class="screentext">Splits the data</strong>: Using <code class="inlinecode">train_test_split</code>, we divide the data into training and testing sets. The <code class="inlinecode">test_size=0.2</code> means 20% of the data is reserved for testing. <code class="inlinecode">random_state</code> is set for reproducibility of results.</li>
      <li class="bulletlist1"><strong class="screentext">Prints shapes</strong>: We print the shapes of our training and testing sets to confirm the split was successful.</li>
    </ul>
    <p class="normal1">Should we run this part of the code to prepare the data and check the split?</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will instruct ChatGPT to proceed with code execution:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Yes, please.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following, where ChatGPT has executed the code and printed the shape of features and labels:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">The data has been successfully split into training and testing sets. Here’s the breakdown:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Training features shape</strong>: 400 rows and 4 columns</li>
      <li class="bulletlist1"><strong class="screentext">Testing features shape</strong>: 100 rows and 4 columns</li>
      <li class="bulletlist1"><strong class="screentext">Training labels shape</strong>: 400 values</li>
      <li class="bulletlist1"><strong class="screentext">Testing labels shape</strong>: 100 values</li>
    </ul>
    <p class="normal1">This indicates that 80% of the data is used for training the model, and 20% is reserved for testing the model’s performance.</p>
    <p class="normal1">Step 3: Building the Linear Regression Model</p>
    <p class="normal1">Now, we’ll<a id="_idIndexMarker538" class="calibre3"/> create and train the linear regression model using the training data. Here’s the plan:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Initialize the linear regression model</strong>: This involves setting up our model ready to be fitted to the data.</li>
      <li class="bulletlist1"><strong class="screentext">Fit the model to the training data</strong>: This is where the model learns the relationship between the features and the target from the training data.</li>
      <li class="bulletlist1"><strong class="screentext">Evaluate the model on the training data</strong>: This step is to get a quick check on how well our model has learned from the training data.</li>
    </ul>
    <p class="normal1">Shall I proceed with this next step and show you the code to build and evaluate the model on the training data?</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will instruct ChatGPT to proceed to the next steps:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Yes, Please.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following, where ChatGPT has provided the code:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Let’s move on to building and training the linear regression model.</p>
    <p class="normal1">Step 3: Building the Linear Regression Model</p>
    <p class="normal1">Here’s the code to <a id="_idIndexMarker539" class="calibre3"/>create, train, and initially evaluate the linear regression model:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Initialize the Linear Regression model</span>
model = LinearRegression()
<span class="hljs-comment"># Fit the model to the training data</span>
<span class="hljs-comment"># This involves finding the best fitting line to the provided data points</span>
model.fit(X_train, y_train)
<span class="hljs-comment"># Evaluate the model by predicting on the training set</span>
train_predictions = model.predict(X_train)
<span class="hljs-comment"># Calculate the Mean Absolute Error (MAE) on the training set</span>
<span class="hljs-comment"># MAE measures the average magnitude of the errors in a set of predictions, without considering their direction</span>
train_mae = mean_absolute_error(y_train, train_predictions)
<span class="hljs-comment"># Calculate the Mean Squared Error (MSE) on the training set</span>
<span class="hljs-comment"># MSE measures the average of the squares of the errors—that is, the average squared difference between the estimated values and the actual value</span>
train_mse = mean_squared_error(y_train, train_predictions)
<span class="hljs-comment"># Printing the errors to understand model performance on the training data</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Mean Absolute Error on training data: </span><span class="hljs-name">{train_mae}</span><span class="hljs-string">'</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Mean Squared Error on training data: </span><span class="hljs-name">{train_mse}</span><span class="hljs-string">'</span>)
</code></pre>
    <p class="normal1">This <a id="_idIndexMarker540" class="calibre3"/>code does the following:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Initializes the model</strong>: <code class="inlinecode">LinearRegression()</code> is called to create a linear regression model.</li>
      <li class="bulletlist1"><strong class="screentext">Fits the model</strong>: <code class="inlinecode">model.fit(X_train, y_train)</code> adjusts weights on the regression line to fit the input features and the target output.</li>
      <li class="bulletlist1"><strong class="screentext">Makes predictions</strong>: <code class="inlinecode">model.predict(X_train)</code> is used to see how well the model has learned to predict the training data.</li>
      <li class="bulletlist1"><strong class="screentext">Calculates errors</strong>: <code class="inlinecode">mean_absolute_error</code> and <code class="inlinecode">mean_squared_error</code> provide metrics to gauge the model’s accuracy and performance by comparing the predicted values against the actual values.</li>
    </ul>
    <p class="normal1">Would you like me to run this code now to see how the model performs on the training data?</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will instruct ChatGPT to proceed:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Yes, Please.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following, where ChatGPT has executed the code and printed the results:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">The linear regression model has been successfully trained on the dataset, and here are the performance metrics on the training data:</p>
    <p class="normal1"><strong class="screentext">Mean Absolute Error (MAE) on training data</strong>: 7.727</p>
    <p class="normal1"><strong class="screentext">Mean Squared Error (MSE) on training data</strong>: 95.823</p>
    <p class="normal1">These metrics help us understand the average errors made by the model in predictions:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">MAE</strong> tells <a id="_idIndexMarker541" class="calibre3"/>us that, on average, the model’s predictions are approximately 7.73 units away from the actual values.</li>
      <li class="bulletlist1"><strong class="screentext">MSE</strong> indicates <a id="_idIndexMarker542" class="calibre3"/>a slightly larger error in the predictions, considering it squares the errors, emphasizing larger discrepancies.</li>
    </ul>
    <p class="normal1">Next Steps:</p>
    <p class="normal1">Now, the <a id="_idIndexMarker543" class="calibre3"/>model is trained and preliminarily evaluated on the training set. We should now test its performance on the unseen testing set to truly evaluate its effectiveness.</p>
    <p class="normal1">Would you like to proceed with testing the model on the testing set and seeing how it performs with new data?</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will instruct ChatGPT to proceed with testing the model performance on the test set:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Yes, please.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following, where ChatGPT has executed the code and printed the results:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">The evaluation of the model on the testing set yielded the following results:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Mean Absolute Error (MAE) on testing data</strong>: 8.558</li>
      <li class="bulletlist1"><strong class="screentext">Mean Squared Error (MSE) on testing data</strong>: 109.864</li>
    </ul>
    <p class="normal1">These results tell us the following:</p>
    <ul class="calibre15">
      <li class="bulletlist">The <strong class="screentext">MAE</strong> of 8.558 <a id="_idIndexMarker544" class="calibre3"/>suggests that the model’s predictions on the testing data are, on average, about 8.56 units away from the actual values. This is slightly worse than the training MAE, which is to be expected as the model is now predicting data it hasn’t seen before.</li>
      <li class="bulletlist1">The <strong class="screentext">MSE</strong> of<a id="_idIndexMarker545" class="calibre3"/> 109.864 is also higher than the training MSE, indicating that some predictions have larger errors.</li>
    </ul>
    <p class="normal1">Summary:</p>
    <p class="normal1">The model <a id="_idIndexMarker546" class="calibre3"/>performs reasonably well but shows a typical behavior of slightly reduced performance on the testing data compared to the training data. This is normal and indicates that the model is generalizing as expected without significant overfitting or underfitting.</p>
    <p class="normal1">Final Steps:</p>
    <p class="normal1">You now have a functioning linear regression model that can predict the “Yearly Amount Spent” based on customer behavior metrics. Depending on your goals, you might want to explore further:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Improving the model</strong>: You could look into more sophisticated modelling techniques or feature engineering.</li>
      <li class="bulletlist1"><strong class="screentext">Model interpretation</strong>: Analyse the coefficients of the model to understand the impact of each feature.</li>
    </ul>
    <p class="normal1">Would you like to explore any of these additional steps or need further assistance with something else?</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We have seen that similar to the free version, ChatGPT Plus does a pretty good job in creating a simple linear regression model step by step, by providing the code as well as executing it for us. Next, we will see whether the Plus version can apply the regularization techniques.</p>
    <h2 class="heading1" id="_idParaDest-292">Feature 2: Applying regularization techniques</h2>
    <p class="normal">We <a id="_idIndexMarker547" class="calibre3"/>will ask ChatGPT Plus to apply regularization techniques:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you <a id="_idIndexMarker548" class="calibre3"/>please apply Lasso, Ridge, and cross-validation to check whether it leads to any improvement? </p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following, where ChatGPT has provided the code for Lasso and Ridge, along with cross-validation:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Step 5: Applying Lasso and Ridge Regression with Cross-Validation</p>
    <p class="normal1">Lasso Regression:</p>
    <ul class="calibre15">
      <li class="bulletlist">Lasso regression not only helps in reducing overfitting but can also be used for feature selection since it can shrink the coefficients of less important features to zero.</li>
    </ul>
    <p class="normal1">Ridge Regression:</p>
    <ul class="calibre15">
      <li class="bulletlist">Ridge regression reduces the model complexity by imposing a penalty on the size of coefficients.</li>
    </ul>
    <p class="normal1">We’ll use the scikit-learn library, which provides convenient functions to perform these analyses.</p>
    <p class="normal1">Here’s the code to apply Lasso and Ridge with cross-validation:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LassoCV, RidgeCV
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_val_score
<span class="hljs-comment"># Lasso Regression with Cross-Validation</span>
lasso_cv = LassoCV(alphas=[<span class="hljs-attr">0.1</span>, <span class="hljs-attr">1.0</span>, <span class="hljs-attr">10.0</span>], cv=<span class="hljs-attr">5</span>)  <span class="hljs-comment"># cv=5 means 5-fold cross-validation</span>
lasso_cv.fit(X_train, y_train)
lasso_cv_score = lasso_cv.score(X_test, y_test)
lasso_cv_mae = mean_absolute_error(y_test, lasso_cv.predict(X_test))
<span class="hljs-comment"># Ridge Regression with Cross-Validation</span>
ridge_cv = RidgeCV(alphas=[<span class="hljs-attr">0.1</span>, <span class="hljs-attr">1.0</span>, <span class="hljs-attr">10.0</span>], cv=<span class="hljs-attr">5</span>)
ridge_cv.fit(X_train, y_train)
ridge_cv_score = ridge_cv.score(X_test, y_test)
ridge_cv_mae = mean_absolute_error(y_test, ridge_cv.predict(X_test))
<span class="hljs-comment"># Printing results</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Lasso CV Score: </span><span class="hljs-name">{lasso_cv_score}</span><span class="hljs-string">, MAE: </span><span class="hljs-name">{lasso_cv_mae}</span><span class="hljs-string">'</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Ridge CV Score: </span><span class="hljs-name">{ridge_cv_score}</span><span class="hljs-string">, MAE: </span><span class="hljs-name">{ridge_cv_mae}</span><span class="hljs-string">'</span>)
</code></pre>
    <p class="normal1">This <a id="_idIndexMarker549" class="calibre3"/>code performs the following:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">LassoCV and RidgeCV</strong>: These are Lasso and Ridge regression methods with built-in cross-validation of the alpha parameter.</li>
      <li class="bulletlist1"><strong class="screentext">Cross-validation scores</strong>: The <code class="inlinecode">.score()</code> method returns the R<sup class="superscript">2</sup> score that indicates the proportion of variance in the dependent variable that is predictable from the independent variables.</li>
      <li class="bulletlist1"><strong class="screentext">Mean Absolute Error</strong>: This provides an absolute measure of fit quality on the testing set.</li>
    </ul>
    <p class="normal1">Let’s run this code to see if the regularization and cross-validation can enhance the model’s performance. Shall we proceed?</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will instruct ChatGPT to execute the code:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Yes, please.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1"><strong class="screentext">[Prompt response]</strong></p>
    <p class="normal1">In our scenario, ChatGPT encountered an internal error and was unable to execute the code. Such errors can occur due to various reasons, including unavailability of services at the time of execution, memory issues, or the absence of required libraries or dependencies in its runtime environment. It’s important to note that you might receive a different response that executes the code flawlessly, as errors like these are sporadic. However, we’ve included this scenario to troubleshoot and illustrate how to proceed in such cases. Here, we have applied the prompting strategy to get feedback from the AI assistant (LIFE 3.3).</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will now take the <a id="_idIndexMarker550" class="calibre3"/>suggestion from ChatGPT and execute the code locally using Jupyter Colab, and since we are loading the dataset from Google Drive, we will provide the instructions in the prompt:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Ok, give me complete code to run locally and note that the file needs to be mounted from Google Drive from path <code class="inlinecode">'/content/drive/My Drive/Chapter05/Ecommerce Customers.csv'</code> in the Jupyter notebook.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following, where ChatGPT has provided the complete code:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Certainly! Below is the <a id="_idIndexMarker551" class="calibre3"/>complete code that you can run locally in a Jupyter Notebook. This script includes steps for importing the dataset directly from Google Drive, preprocessing the data, fitting both Lasso and Ridge regression models with cross-validation, and then evaluating them.</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-comment"># Import necessary libraries</span>
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression, LassoCV, RidgeCV
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_absolute_error, mean_squared_error
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler
<span class="hljs-comment"># Mount Google Drive (specific to Google Colab)</span>
<span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive
drive.mount(<span class="hljs-string">'/content/drive'</span>)
<span class="hljs-comment"># Load the dataset from Google Drive</span>
file_path = <span class="hljs-string">'/content/drive/My Drive/Chapter05/Ecommerce Customers.csv'</span>
data = pd.read_csv(file_path)
<span class="hljs-comment"># Select only the numerical columns for features and the target column</span>
features = data[[<span class="hljs-string">'Avg. Session Length'</span>, <span class="hljs-string">'</span><span class="hljs-string">Time on App'</span>, <span class="hljs-string">'Time on Website'</span>, <span class="hljs-string">'Length of Membership'</span>]]
target = data[<span class="hljs-string">'Yearly Amount Spent'</span>]
<span class="hljs-comment"># Splitting the dataset into training and testing sets (80% train, 20% test)</span>
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=<span class="hljs-attr">0.2</span>, random_state=<span class="hljs-attr">42</span>)
<span class="hljs-comment"># Standardizing the data</span>
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
<span class="hljs-comment"># Initialize and fit the Linear Regression model</span>
model = LinearRegression()
model.fit(X_train_scaled, y_train)
<span class="hljs-comment"># Lasso Regression with Cross-Validation</span>
lasso_cv = LassoCV(alphas=[<span class="hljs-attr">0.01</span>, <span class="hljs-attr">0.1</span>, <span class="hljs-attr">1.0</span>, <span class="hljs-attr">10.0</span>], cv=<span class="hljs-attr">5</span>)
lasso_cv.fit(X_train_scaled, y_train)
lasso_cv_score = lasso_cv.score(X_test_scaled, y_test)
lasso_cv_mae = mean_absolute_error(y_test, lasso_cv.predict(X_test_scaled))
<span class="hljs-comment"># Ridge Regression with Cross-Validation</span>
ridge_cv = RidgeCV(alphas=[<span class="hljs-attr">0.01</span>, <span class="hljs-attr">0.1</span>, <span class="hljs-attr">1.0</span>, <span class="hljs-attr">10.0</span>], cv=<span class="hljs-attr">5</span>)
ridge_cv.fit(X_train_scaled, y_train)
ridge_cv_score = ridge_cv.score(X_test_scaled, y_test)
ridge_cv_mae = mean_absolute_error(y_test, ridge_cv.predict(X_test_scaled))
<span class="hljs-comment"># Print results</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Linear Regression Test MAE: </span><span class="hljs-name">{mean_absolute_error(y_test, model.predict(X_test_scaled))}</span><span class="hljs-string">'</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Lasso CV Score: </span><span class="hljs-name">{lasso_cv_score}</span><span class="hljs-string">, MAE: </span><span class="hljs-name">{lasso_cv_mae}</span><span class="hljs-string">'</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Ridge CV Score: </span><span class="hljs-name">{ridge_cv_score}</span><span class="hljs-string">, MAE: </span><span class="hljs-name">{ridge_cv_mae}</span><span class="hljs-string">'</span>)
</code></pre>
    <p class="normal1">Instructions for<a id="_idIndexMarker552" class="calibre3"/> Running the Code:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Google Colab Specifics</strong>: The <code class="inlinecode">drive.mount()</code> function is specific to Google Colab and allows you to access files on your Google Drive. If you are not using Google Colab, you will need to adjust the file loading method according to your development environment.</li>
      <li class="bulletlist1"><strong class="screentext">Dependencies</strong>: Ensure you have all required libraries installed. You can install them using <code class="inlinecode">pip</code> (e.g., <code class="inlinecode">pip install pandas scikit-learn google-colab</code>).</li>
      <li class="bulletlist1"><strong class="screentext">Data Path</strong>: Adjust the <code class="inlinecode">file_path</code> if your file is located in a different directory on your Google Drive.</li>
    </ul>
    <p class="normal1">Run this code in your Jupyter Notebook environment to see how the models perform with your data. If you encounter any errors or need further assistance, feel free to reach out!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We execute the<a id="_idIndexMarker553" class="calibre3"/> code and it runs perfectly fine without any modifications or errors. Here, we learned that we can use the hybrid approach of running code within ChatGPT Plus or request<a id="_idIndexMarker554" class="calibre3"/> it to provide the code to execute locally in case of any issues.</p>
    <p class="normal1">Next, we will move on to Feature 3 of generating a synthetic dataset using ChatGPT Plus.</p>
    <h2 class="heading1" id="_idParaDest-293">Feature 3: Generating a synthetic dataset to add complexity</h2>
    <p class="normal">Now, let’s<a id="_idIndexMarker555" class="calibre3"/> try, if we are able, to generate a synthetic dataset using ChatGPT Plus for our dataset. For this purpose, we will use the Data Analyst GPT and start a fresh conversation. </p>
    <p class="normal1">Note that specific GPTs can be invoked by providing <code class="inlinecode">@&lt;GPT Name&gt;</code> in the message prompt:</p>
    <figure class="mediaobject"><img alt="A white background with black text  Description automatically generated" src="../Images/B21232_13_10.png" class="calibre19"/></figure>
    <figure class="mediaobject">Figure 13.10: Invoking the Data Analyst GPT</figure>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">@Data Analyst – Provide me the code to generate the synthetic dataset for the above dataset from the perspective of predicting <code class="inlinecode">Yearly Amount Spent</code>, along with the code to generate it. &lt;Attach the dataset file here&gt;</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following, where ChatGPT has provided the code and printed the first few rows:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">To help you generate a synthetic dataset for predicting yearly amount spent, I’ll first need to take a look at the structure and content of your provided dataset. Let’s start by loading and examining the data from your file. I’ll display the first few rows and summary statistics to understand what kind of features we’re dealing with. Then, I’ll assist you in creating a synthetic dataset based on this structure. Let’s get started with loading the data.</p>
    <p class="normal1">The dataset <a id="_idIndexMarker556" class="calibre3"/>consists of 500 entries with the following features:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Email</strong>: The customer’s email address (string).</li>
      <li class="bulletlist1"><strong class="screentext">Address</strong>: The customer’s address (string).</li>
      <li class="bulletlist1"><strong class="screentext">Avatar</strong>: The avatar color (string).</li>
      <li class="bulletlist1"><strong class="screentext">Avg. Session Length</strong>: Average session length in minutes (numeric).</li>
      <li class="bulletlist1"><strong class="screentext">Time on App</strong>: Time spent on the app in minutes (numeric).</li>
      <li class="bulletlist1"><strong class="screentext">Time on Website</strong>: Time spent on the website in minutes (numeric).</li>
      <li class="bulletlist1"><strong class="screentext">Length of Membership</strong>: Length of membership in years (numeric).</li>
      <li class="bulletlist1"><strong class="screentext">Yearly Amount Spent</strong>: Yearly amount spent in dollars (numeric).</li>
    </ul>
    <p class="normal1">To create a synthetic dataset for the purpose of modeling and predicting “Yearly Amount Spent”, we can use a technique <a id="_idIndexMarker557" class="calibre3"/>called <strong class="screentext">bootstrapping</strong>, which involves sampling with replacement from the existing dataset to create a new synthetic dataset that has a similar distribution. However, to add some variability and simulate a realistic dataset, we can also introduce random noise into the numeric fields.</p>
    <p class="normal1">Here’s a Python code snippet to generate a synthetic dataset using bootstrapping and adding noise to the numeric columns:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-comment"># Number of samples for the synthetic dataset</span>
num_samples = <span class="hljs-attr">500</span>
<span class="hljs-comment"># Bootstrap the original dataset</span>
synthetic_data = data.sample(n=num_samples, replace=<span class="hljs-literal">True</span>)
<span class="hljs-comment"># Add random noise to numeric columns</span>
numeric_columns = [<span class="hljs-string">'Avg. Session Length'</span>, <span class="hljs-string">'Time on App'</span>, <span class="hljs-string">'Time on Website'</span>, <span class="hljs-string">'Length of Membership'</span>, <span class="hljs-string">'Yearly Amount Spent'</span>]
noise_factor = <span class="hljs-attr">0.05</span>  <span class="hljs-comment"># 5% noise</span>
<span class="hljs-keyword">for</span> column <span class="hljs-keyword">in</span> numeric_columns:
    noise = np.random.normal(loc=<span class="hljs-attr">0.0</span>, scale=noise_factor * synthetic_data[column].std(), size=num_samples)
    synthetic_data[column] += noise
<span class="hljs-comment"># Optionally save the synthetic dataset to a new CSV file</span>
synthetic_data.to_csv(<span class="hljs-string">'/mnt/data/Synthetic_Ecommerce_Customers.csv'</span>, index=<span class="hljs-literal">False</span>)
synthetic_data.head()
</code></pre>
    <p class="normal1">This code will:</p>
    <ul class="calibre15">
      <li class="bulletlist">Sample 500 entries from the original dataset, allowing replacements (bootstrapping).</li>
      <li class="bulletlist1">Add Gaussian noise to each numeric column based on 5% of the standard deviation of that column.</li>
      <li class="bulletlist1">Optionally, the new synthetic dataset can be saved to a CSV file.</li>
    </ul>
    <p class="normal1">Would you<a id="_idIndexMarker558" class="calibre3"/> like to proceed with generating this synthetic dataset? Or do you have any modifications or specific requirements to include in the synthesis process?</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">Next, we will instruct ChatGPT to generate the code and provide us with the file to download the dataset:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Please generate the dataset and make it available to download.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following, where ChatGPT has executed the code and provided the link to download the synthetic dataset:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">The synthetic dataset has been generated and saved. You can download it using the link below:</p>
    <pre class="programlisting"><code class="hljs-code">[Download Synthetic Ecommerce Customers Dataset](sandbox:/mnt/data/Synthetic_Ecommerce_Customers.csv)
</code></pre>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">Here, we learned that ChatGPT Plus can provide the code, execute the code, and also generate CSV files available to download.</p>
    <p class="normal1">Next, we will request ChatGPT Plus to generate the complete code and evaluate model performance with the added noise in the synthetic dataset. Let’s move to our next feature.</p>
    <h2 class="heading1" id="_idParaDest-294">Feature 4: Generating code to develop a model in a single step for a synthetic dataset</h2>
    <p class="normal">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you<a id="_idIndexMarker559" class="calibre3"/> please generate the complete code to perform linear regression, apply Lasso and Ridge regularization techniques on our synthetic dataset, and evaluate the model performance?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">We should receive a response similar to the following, where ChatGPT has provided the complete code:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">Sure, I can provide you with a Python script that performs linear regression, as well as Lasso and Ridge regression, on the synthetic dataset we just created. We will also evaluate the model performance using metrics like the R-squared score, mean squared error (MSE), and mean absolute error (MAE).</p>
    <p class="normal1">Here is a complete Python code snippet for the whole process:</p>
    <pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression, Lasso, Ridge
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error, mean_absolute_error, r2_score
<span class="hljs-comment"># Load the synthetic dataset</span>
data = pd.read_csv(<span class="hljs-string">'/path/to/your/Synthetic_Ecommerce_Customers.csv'</span>)
<span class="hljs-comment"># Feature selection: Using numerical columns as features</span>
features = data[[<span class="hljs-string">'Avg. Session Length'</span>, <span class="hljs-string">'Time on App'</span>, <span class="hljs-string">'</span><span class="hljs-string">Time on Website'</span>, <span class="hljs-string">'Length of Membership'</span>]]
target = data[<span class="hljs-string">'Yearly Amount Spent'</span>]
<span class="hljs-comment"># Split the data into training and testing sets</span>
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=<span class="hljs-attr">0.2</span>, random_state=<span class="hljs-attr">42</span>)
<span class="hljs-comment"># Initialize the models</span>
linear_model = LinearRegression()
lasso_model = Lasso(alpha=<span class="hljs-attr">0.1</span>)  <span class="hljs-comment"># alpha is the regularization strength</span>
ridge_model = Ridge(alpha=<span class="hljs-attr">1.0</span>)  <span class="hljs-comment"># alpha is the regularization strength</span>
<span class="hljs-comment"># Train the models</span>
linear_model.fit(X_train, y_train)
lasso_model.fit(X_train, y_train)
ridge_model.fit(X_train, y_train)
<span class="hljs-comment"># Predictions</span>
linear_predictions = linear_model.predict(X_test)
lasso_predictions = lasso_model.predict(X_test)
ridge_predictions = ridge_model.predict(X_test)
<span class="hljs-comment"># Evaluations</span>
<span class="hljs-keyword">def</span> <span class="hljs-meta">evaluate_model</span>(<span>predictions, actual</span>):
    mse = mean_squared_error(actual, predictions)
    mae = mean_absolute_error(actual, predictions)
    r2 = r2_score(actual, predictions)
    <span class="hljs-keyword">return</span> mse, mae, r2
linear_mse, linear_mae, linear_r2 = evaluate_model(linear_predictions, y_test)
lasso_mse, lasso_mae, lasso_r2 = evaluate_model(lasso_predictions, y_test)
ridge_mse, ridge_mae, ridge_r2 = evaluate_model(ridge_predictions, y_test)
<span class="hljs-comment"># Print out the metrics</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"</span><span class="hljs-string">Linear Regression - MSE: {:.2f}, MAE: {:.2f}, R2: {:.2f}"</span>.<span class="hljs-built_in">format</span>(linear_mse, linear_mae, linear_r2))
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Lasso Regression - MSE: {:.2f}, MAE: {:.2f}, R2: {:.2f}"</span>.<span class="hljs-built_in">format</span>(lasso_mse, lasso_mae, lasso_r2))
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Ridge Regression - MSE: {:.2f}, MAE: {:.2f}, R2: {:.2f}"</span>.<span class="hljs-built_in">format</span>(ridge_mse, ridge_mae, ridge_r2))
</code></pre>
    <p class="normal1">Make sure to <a id="_idIndexMarker560" class="calibre3"/>replace <code class="inlinecode">'/path/to/your/Synthetic_Ecommerce_Customers.csv'</code> with the actual path where your synthetic dataset is stored when running the script in your local environment.</p>
    <p class="normal1">This <a id="_idIndexMarker561" class="calibre3"/>script will:</p>
    <ul class="calibre15">
      <li class="bulletlist">Load your synthetic dataset.</li>
      <li class="bulletlist1">Select appropriate features and split the data into training and test sets.</li>
      <li class="bulletlist1">Initialize and train Linear, Lasso, and Ridge regression models.</li>
      <li class="bulletlist1">Evaluate and print out the performance metrics for each model.</li>
    </ul>
    <p class="normal1">This should help you understand the performance differences and impacts of regularization in your predictive models!</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">We will instruct ChatGPT Plus to execute the code for us:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Please execute the code.</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <p class="normal1">ChatGPT Plus should have executed the code and we should receive a response similar to the following:</p>
    <p class="normal1">[P<strong class="screentext">rompt response]</strong></p>
    <p class="normal1">The models have been trained and evaluated. Here are the performance metrics for each:</p>
    <p class="normal1">Linear Regression:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Mean Squared Error (MSE)</strong>: 133.01</li>
      <li class="bulletlist1"><strong class="screentext">Mean Absolute Error (MAE)</strong>: 8.79</li>
      <li class="bulletlist1"><strong class="screentext">R-squared (R2)</strong>: 0.977</li>
    </ul>
    <p class="normal1">Lasso Regression:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Mean Squared Error (MSE)</strong>: 133.04</li>
      <li class="bulletlist1"><strong class="screentext">Mean Absolute Error (MAE)</strong>: 8.79</li>
      <li class="bulletlist1"><strong class="screentext">R-squared (R2)</strong>: 0.977</li>
    </ul>
    <p class="normal1">Ridge Regression:</p>
    <ul class="calibre15">
      <li class="bulletlist"><strong class="screentext">Mean Squared Error (MSE)</strong>: 133.08</li>
      <li class="bulletlist1"><strong class="screentext">Mean Absolute Error (MAE)</strong>: 8.79</li>
      <li class="bulletlist1"><strong class="screentext">R-squared (R2)</strong>: 0.977</li>
    </ul>
    <p class="normal1">All three <a id="_idIndexMarker562" class="calibre3"/>models show very similar performance metrics, with high R2 scores close to 0.977, indicating that each model explains about 97.7% of the variance in the Yearly Amount Spent. The slight differences in MSE and MAE across models are minimal, suggesting that regularization (both Lasso and Ridge) does not significantly alter the performance in this particular case, possibly due to the absence of multicollinearity or other issues that these techniques help address.</p>
    <p class="normal1">[E<strong class="screentext">nd of response]</strong></p>
    <p class="normal1">By working through this exercise, you’ve not only learned how to perform a regression analysis using the free version of ChatGPT and ChatGPT Plus but also how to create a linear regression model step by step using your own dataset, apply regularization techniques, and generate synthetic datasets.</p>
    <h1 class="heading" id="_idParaDest-295">Assignment</h1>
    <p class="normal">Generate a single-step code for our dataset and execute it in Google Colab for the random forest algorithm.</p>
    <h1 class="heading" id="_idParaDest-296">Challenge</h1>
    <p class="normal">Can you enhance the following prompt by incorporating prompting strategies to ensure the retrieval of a specific dataset, rather than a random one that may not exist or may have an incorrect path, ensuring it’s fit for the intended use?</p>
    <p class="normal1">Provide the output from the current prompt as well as the improved prompt:</p>
    <p class="normal1">[P<strong class="screentext">rompt]</strong></p>
    <p class="normal1">Can you please provide me with the complete end-to-end Python code for a publicly available advertising dataset along with a detailed explanation that it is compatible with the Jupyter Notebook?</p>
    <p class="normal1">[E<strong class="screentext">nd of prompt]</strong></p>
    <h1 class="heading" id="_idParaDest-297">Summary</h1>
    <p class="normal">We explored the application of TAG, PIC, and LIFE prompting strategies in crafting regression models, employing both ChatGPT and ChatGPT Plus for rapid analysis and predictive tasks. This approach is particularly valuable in the early stages of machine learning development, offering immediate insights and the flexibility to experiment with different models or algorithms without the burden of managing execution environments or programming instances. Additionally, we learned how to effectively utilize single prompts for generating comprehensive code. While it’s possible to craft prompts for discrete tasks or steps, many of these require only succinct lines of code and were not the focus here. Providing feedback is instrumental in this process, and validating the output is crucial to ensure the code’s functionality.</p>
    <p class="normal1">In the next chapter, we will learn how to use ChatGPT to generate the code for the <strong class="screentext">multilayer perceptron</strong> (<strong class="screentext">MLP</strong>) model with the help of the Fashion-MNIST dataset.</p>
    <h1 class="heading" id="_idParaDest-298">Join our community on Discord </h1>
    <p class="normal">Join our community’s Discord space for discussions with the author and other readers: </p>
    <p class="normal1"><a href="https://packt.link/aicode" class="calibre3"><span class="calibre3">https://packt.link/aicode</span></a></p>
    <p class="normal1"><span class="calibre3"><img alt="" src="../Images/QR_Code510410532445718281.png" class="calibre4"/></span></p>
  </div>
</body></html>