- en: Chapter 7. Working with Graph Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 使用图算法
- en: In this chapter, I'll delve into graph libraries and algorithm implementations
    in Scala. In particular, I will introduce Graph for Scala ([http://www.scala-graph.org](http://www.scala-graph.org)),
    an open source project that was started in 2011 in the EPFL Scala incubator. Graph
    for Scala does not support distributed computing yet—the distributed computing
    aspects of popular graph algorithms is available in GraphX, which is a part of
    MLlib library that is part of Spark project ([http://spark.apache.org/docs/latest/mllib-guide.html](http://spark.apache.org/docs/latest/mllib-guide.html)).
    Both, Spark and MLlib were started as class projects at UC Berkeley around or
    after 2009\. I considered Spark in [Chapter 3](ch03.xhtml "Chapter 3. Working
    with Spark and MLlib"), *Working with Spark and MLlib* and introduced an RDD.
    In GraphX, a graph is a pair of RDDs, each of which is partitioned among executors
    and tasks, represents vertices and edges in a graph.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将深入探讨Scala中的图库和算法实现。特别是，我将介绍Graph for Scala ([http://www.scala-graph.org](http://www.scala-graph.org))，这是一个始于2011年的EPFL
    Scala孵化器的开源项目。Graph for Scala目前不支持分布式计算——流行的图算法的分布式计算方面可在GraphX中找到，它是Spark项目（[http://spark.apache.org/docs/latest/mllib-guide.html](http://spark.apache.org/docs/latest/mllib-guide.html)）的一部分，Spark和MLlib都始于2009年左右在加州大学伯克利分校的课堂项目。我在[第3章](ch03.xhtml
    "第3章. 使用Spark和MLlib") *使用Spark和MLlib* 中考虑了Spark，并介绍了RDD。在GraphX中，图是RDD的对，每个RDD在executors和tasks之间分区，代表图中的顶点和边。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Configuring **Simple Build Tool** (**SBT**) to use the material in this chapter
    interactively
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置**简单构建工具**（**SBT**）以交互式地使用本章中的材料
- en: Learning basic operations on graphs supported by Graph for Scala
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习Graph for Scala支持的图上的基本操作
- en: Learning how to enforce graph constraints
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何强制执行图约束
- en: Learning how to import/export graphs in JSON
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何导入/导出JSON格式的图
- en: Performing connected components, triangle count, and strongly connected components
    running on Enron e-mail data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Enron电子邮件数据上执行连通分量、三角形计数和强连通分量
- en: Performing PageRank computations on Enron e-mail data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Enron电子邮件数据上执行PageRank计算
- en: Learning how to use SVD++
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何使用SVD++
- en: A quick introduction to graphs
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图的快速介绍
- en: What is a graph? A graph is a set of **vertices** where some pairs of these
    vertices are linked with **edges**. If every vertex is linked with every other
    vertex, we say the graph is a complete graph. On the contrary, if it has no edges,
    the graph is said to be empty. These are, of course, extremes that are rarely
    encountered in practice, as graphs have varying degrees of density; the more edges
    it has proportional to the number of vertices, the more dense we say it is.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是图？图是一组**顶点**，其中一些顶点对通过**边**相互连接。如果每个顶点都与每个其他顶点连接，我们称该图为完全图。相反，如果没有边，则称该图为空图。当然，这些是实践中很少遇到的极端情况，因为图的密度各不相同；边的数量与顶点数量的比例越高，我们说它越密集。
- en: Depending on what algorithms we intend to run on a graph and how dense is it
    expected to be, we can choose how to appropriately represent the graph in memory.
    If the graph is really dense, it pays off to store it as a square *N x N* matrix,
    where *0* in the *n*th row and *m*th column means that the *n* vertex is not connected
    to the *m* vertex. A diagonal entry expresses a node connection to itself. This
    representation is called the adjacency matrix.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们打算在图上运行哪些算法以及预期的密度如何，我们可以选择如何在内存中适当地表示图。如果图非常密集，将其存储为平方的 *N x N* 矩阵是有利的，其中
    *0* 在第 *n* 行和第 *m* 列表示第 *n* 个顶点没有连接到第 *m* 个顶点。对角线条目表示节点与其自身的连接。这种表示方法称为邻接矩阵。
- en: If there are not many edges and we need to traverse the whole edge set without
    distinction, often it pays off to store it as a simple container of pairs. This
    structure is called an **edge list**.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果边的数量不多，并且我们需要无差别地遍历整个边集，通常将其存储为对偶的简单容器会更有利。这种结构被称为**边表**。
- en: In practice, we can model many real-life situations and events as graphs. We
    could imagine cities as vertices and plane routes as edges. If there is no flight
    between two cities, there is no edge between them. Moreover, if we add the numerical
    costs of plane tickets to the edges, we say that the graph is **weighted**. If
    there are some edges where only travels in one direction exist, we can represent
    that by making a graph directed as opposed to an undirected graph. So, for an
    undirected graph, it is true that the graph is symmetric, that is, if *A* is connected
    to *B*, then *B* is also connected to *A*—that is not necessarily true for a directed
    graph.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们可以将许多现实生活中的情况和事件建模为图。我们可以想象城市作为顶点，平面航线作为边。如果两个城市之间没有航班，它们之间就没有边。此外，如果我们将飞机票的数值成本添加到边中，我们可以说该图是**加权的**。如果有些边只存在单向旅行，我们可以通过使图有向而不是无向图来表示这一点。因此，对于一个无向图，它确实是对称的，即如果*A*连接到*B*，那么*B*也连接到*A*——这不一定适用于有向图。
- en: Graphs without cycles are called acyclic. Multigraph can contain multiple edges,
    potentially of different type, between the nodes. Hyperedges can connect arbitrary
    number of nodes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 没有环的图称为无环图。多重图可以在节点之间包含多条边，这些边可能是不同类型的。超边可以连接任意数量的节点。
- en: The most popular algorithm on the undirected graphs is probably **connected
    components**, or partitioning of a graph into subgraph, in which any two vertices
    are connected to each other by paths. Partitioning is important to parallelize
    the operations on the graphs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在无向图中最受欢迎的算法可能是**连通分量**，或者将图划分为子图，其中任何两个顶点都通过路径相互连接。划分对于并行化图上的操作非常重要。
- en: Google and other search engines made PageRank popular. According to Google,
    PageRank estimates of how important the website is by counting the number and
    quality of links to a page. The underlying assumption is that more important websites
    are likely to receive more links from other websites, especially more highly ranked
    ones. PageRank can be applied to many problems outside of websites ranking and
    is equivalent to finding eigenvectors and the most significant eigenvalue of the
    connectivity matrix.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌和其他搜索引擎使PageRank流行起来。根据谷歌的说法，PageRank通过计算指向页面的链接数量和质量来估计网站的重要性。基本假设是，更重要的网站更有可能从其他网站（尤其是排名更高的网站）那里获得更多链接。PageRank可以应用于网站排名之外的许多问题，并且等同于找到连接矩阵的特征向量和最重要的特征值。
- en: The most basic, nontrivial subgraph, consists of three nodes. Triangle counting
    finds all the possible fully connected (or complete) triples of nodes and is another
    well-known algorithm used in community detection and CAD.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的、非平凡的子图由三个节点组成。三角形计数找出所有可能的完全连接（或完整）的节点三元组，这是社区检测和CAD中使用的另一个众所周知算法。
- en: 'A **clique** is a fully connected subgraph. A strongly connected component
    is an analogous notion for a directed graph: every vertex in a subgraph is reachable
    from every other vertex. GraphX provides an implementation for both.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**团**是一个完全连接的子图。强连通分量是有向图的一个类似概念：子图中的每个顶点都可以从其他每个顶点到达。GraphX为两者提供了实现。'
- en: 'Finally, a recommender graph is a graph connecting two types of nodes: users
    and items. The edges can additionally contain the strength of a recommendation
    or a measure of satisfaction. The goal of a recommender is to predict the satisfaction
    for potentially missing edges. Multiple algorithms have been developed for a recommendation
    engine, such as SVD and SVD++, which are considered at the end of this chapter.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，推荐图是连接两种类型节点的图：用户和物品。边可以包含推荐的强度或满意度的度量。推荐的目标是预测可能缺失的边的满意度。已经为推荐引擎开发了多种算法，例如SVD和SVD++，这些将在本章末尾讨论。
- en: SBT
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SBT
- en: Everyone likes Scala REPL. REPL is the command line for Scala. It allows you
    to type Scala expressions that are evaluated immediately and try and explore things.
    As you saw in the previous chapters, one can simply type `scala` at the command
    prompt and start developing complex data pipelines. What is even more convenient
    is that one can press *tab* to have auto-completion, a required feature of any
    fully developed modern IDE (such as Eclipse or IntelliJ, *Ctrl +*. or *Ctrl +
    Space*) by keeping track of the namespace and using reflection mechanisms. Why
    would we need one extra tool or framework for builds, particularly that other
    builds management frameworks such as Ant, Maven, and Gradle exist in addition
    to IDEs? As the SBT authors argue, even though one might compile Scala using the
    preceding tools, all of them have inefficiencies, as it comes to interactivity
    and reproducibility of Scala builds (*SBT in Action* by *Joshua Suereth* and *Matthew
    Farwell*, Nov 2015).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人都喜欢Scala REPL。REPL是Scala的命令行。它允许您输入Scala表达式，这些表达式会立即被评估，并尝试探索事物。正如您在前几章中看到的，您只需在命令提示符中输入`scala`即可开始开发复杂的数据管道。更方便的是，您可以按*tab*键进行自动完成，这是任何成熟现代IDE（如Eclipse或IntelliJ，*Ctrl
    +*. 或 *Ctrl + Space*）的必备功能，通过跟踪命名空间和使用反射机制来实现。为什么我们还需要一个额外的构建工具或框架，尤其是当Ant、Maven和Gradle等构建管理框架已经存在于IDE之外时？正如SBT的作者所争论的，尽管一个人可能使用前面的工具编译Scala，但所有这些工具在交互性和Scala构建的可重复性方面都有效率低下的问题（*Joshua
    Suereth*和*Matthew Farwell*的《SBT in Action》，2015年11月）。
- en: One of the main SBT features for me is interactivity and the ability to seamlessly
    work with multiple versions of Scala and dependent libraries. In the end, what
    is critical for software development is the speed with which one can prototype
    and test new ideas. I used to work on mainframes using punch cards, where the
    programmers were waiting to execute their programs and ideas, sometimes for hours
    and days. The efficiency of the computers mattered more, as this was the bottleneck.
    These days are gone, and a personal laptop is probably having more computing power
    than rooms full of servers a few decades back. To take advantage of this efficiency,
    we need to utilize human time more efficiently by speeding up the program development
    cycle, which also means interactivity and more versions in the repositories.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我来说，SBT的一个主要特性是交互性和能够无缝地与多个版本的Scala和依赖库一起工作。最终，对于软件开发来说，关键的是能够快速原型化和测试新想法的速度。我过去在大型机使用穿孔卡片工作，程序员们等待执行他们的程序和想法，有时需要几个小时甚至几天。计算机的效率更为重要，因为这是瓶颈。那些日子已经过去了，现在个人笔记本电脑的计算能力可能比几十年前满屋的服务器还要强大。为了利用这种效率，我们需要通过加快程序开发周期来更有效地利用人的时间，这也意味着交互性和仓库中的更多版本。
- en: 'Apart from the ability to handle multiple versions and REPL, SBT''s main features
    are as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 除了处理多个版本和REPL的能力之外，SBT的主要特性如下：
- en: Native support for compiling Scala code and integrating with many test frameworks,
    including JUnit, ScalaTest, and Selenium
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原生支持编译Scala代码，并集成许多测试框架，包括JUnit、ScalaTest和Selenium
- en: Build descriptions written in Scala using a DSL
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Scala DSL编写的构建描述
- en: Dependency management using Ivy (which also supports Maven-format repositories)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Ivy进行依赖管理（Ivy也支持Maven格式的仓库）
- en: Continuous execution, compilation, testing, and deployment
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续执行、编译、测试和部署
- en: Integration with the Scala interpreter for rapid iteration and debugging
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与Scala解释器集成，以实现快速迭代和调试
- en: Support for mixed Java/Scala projects
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持混合Java/Scala项目
- en: Support for testing and deployment frameworks
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持测试和部署框架
- en: Ability to complement the tool with custom plugins
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够通过自定义插件来补充工具
- en: Parallel execution of tasks
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务并行执行
- en: SBT is written in Scala and uses SBT to build itself (bootstrapping or dogfooding).
    SBT became the de facto build tool for the Scala community, and is used by the
    **Lift** and **Play** frameworks.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: SBT是用Scala编写的，并使用SBT来构建自身（自举或自用）。SBT已成为Scala社区的默认构建工具，并被Lift和Play框架使用。
- en: 'While you can download SBT directly from [http://www.scala-sbt.org/download](http://www.scala-sbt.org/download),
    the easiest way to install SBT on Mac is to run MacPorts:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以直接从[http://www.scala-sbt.org/download](http://www.scala-sbt.org/download)下载SBT，但在Mac上安装SBT最简单的方法是运行MacPorts：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can also run Homebrew:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以运行Homebrew：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'While other tools exist to create SBT projects, the most straightforward way
    is to run the `bin/create_project.sh` script in the GitHub book project repository
    provided for each chapter:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在其他创建SBT项目的工具，但最直接的方法是运行GitHub书项目仓库中提供的`bin/create_project.sh`脚本：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will create main and test source subdirectories (but not the code). The
    project directory contains project-wide settings (refer to `project/build.properties`).
    The target will contain compiled classes and build packages (the directory will
    contain different subdirectories for different versions of Scala, for example,
    2.10 and 2.11). Finally, any jars or libraries put into the `lib` directory will
    be available across the project (I personally recommend using the `libraryDependencies`
    mechanism in the `build.sbt` file, but not all libraries are available via centralized
    repositories). This is the minimal setup, and the directory structure may potentially
    contain multiple subprojects. The Scalastyle plugin will even check the syntax
    for you ([http://www.scalastyle.org/sbt.html](http://www.scalastyle.org/sbt.html)).
    Just add `project/plugin.sbt`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建主和测试源子目录（但不包括代码）。项目目录包含项目范围内的设置（参考`project/build.properties`）。目标将包含编译后的类和构建包（目录将包含不同版本的Scala的不同子目录，例如2.10和2.11）。最后，任何放入`lib`目录的jar或库都将在整个项目中可用（我个人推荐在`build.sbt`文件中使用`libraryDependencies`机制，但并非所有库都可通过集中式仓库获得）。这是最小设置，目录结构可能包含多个子项目。Scalastyle插件甚至会为您检查语法（[http://www.scalastyle.org/sbt.html](http://www.scalastyle.org/sbt.html)）。只需添加`project/plugin.sbt`：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Finally, the SBT creates Scaladoc documentation with the `sdbt doc` command.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用`sdbt doc`命令，SBT会创建Scaladoc文档。
- en: Note
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Blank lines and other settings in build.sbt**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**build.sbt中的空白行和其他设置**'
- en: 'Probably most of the `build.sbt` files out there are double spaced: this is
    a remnant of old versions. You no longer need them. As of version 0.13.7, the
    definitions do not require extra lines.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 可能大多数`build.sbt`文件都是双倍空格：这是旧版本的残留。您不再需要它们。从版本0.13.7开始，定义不需要额外的行。
- en: There are many other settings that you can use on `build.sbt` or `build.properties`,
    the up-to-date documentation is available at [http://www.scala-sbt.org/documentation.html](http://www.scala-sbt.org/documentation.html).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在`build.sbt`或`build.properties`中，你可以使用许多其他设置，最新的文档可在[http://www.scala-sbt.org/documentation.html](http://www.scala-sbt.org/documentation.html)找到。
- en: When run from the command line, the tool will automatically download and use
    the dependencies, in this case, `graph-{core,constrained,json}` and `lift-json`.
    In order to run the project, simply type `sbt run`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当从命令行运行时，工具将自动下载并使用依赖项，在这种情况下，是`graph-{core,constrained,json}`和`lift-json`。为了运行项目，只需输入`sbt
    run`。
- en: In continuous mode, SBT will automatically detect changes to the source file
    and rerun the command(s). In order to continuously compile and run the code, type
    `~~ run` after starting REPL with `sbt`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在连续模式下，SBT将自动检测源文件的变化并重新运行命令。为了在启动REPL后连续编译和运行代码，请在`sbt`后输入`~~ run`。
- en: 'To get help on the commands, run the following command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取命令的帮助，请运行以下命令：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: While SBT will be sufficient for our use even with a simple editor such as **vi**
    or **Emacs**, the `sbteclipse` project at [https://github.com/typesafehub/sbteclipse](https://github.com/typesafehub/sbteclipse)
    will create the necessary project files to work with your Eclipse IDE.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用简单的编辑器如**vi**或**Emacs**，SBT也足以满足我们的需求，但[https://github.com/typesafehub/sbteclipse](https://github.com/typesafehub/sbteclipse)的`sbteclipse`项目将创建与您的Eclipse
    IDE一起工作的必要项目文件。
- en: Graph for Scala
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala图
- en: 'For this project, I will create a `src/main/scala/InfluenceDiagram.scala` file.
    For demo purpose, I will just recreate the graph from [Chapter 2](ch02.xhtml "Chapter 2. Data
    Pipelines and Modeling"), *Data Pipelines and Modeling*:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，我将创建一个`src/main/scala/InfluenceDiagram.scala`文件。为了演示目的，我将仅重新创建来自[第2章](ch02.xhtml
    "第2章。数据管道和建模") *数据管道和建模*的图表：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `~+>` operator is used to create a directed labeled edge between two nodes
    defined in `scalax/collection/edge/Implicits.scala`, which, in our case, are of
    the `String` type. The list of other edge types and operators is provided in the
    following table:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`~+>`运算符用于在`scalax/collection/edge/Implicits.scala`中定义的两个节点之间创建一个有向标签边，在我们的例子中，它们是`String`类型。其他边类型和运算符的列表如下表所示：'
- en: '*The following table shows* graph edges from `scalax.collection.edge.Implicits`
    (from [http://www.scala-graph.org/guides/core-initializing.html](http://www.scala-graph.org/guides/core-initializing.html))'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*以下表格显示了*来自`scalax.collection.edge.Implicits`（来自[http://www.scala-graph.org/guides/core-initializing.html](http://www.scala-graph.org/guides/core-initializing.html)）的图边'
- en: '| Edge Class | Shortcut/Operator | Description |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 边类 | 快捷键/操作符 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Hyperedges** |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| **超边** |'
- en: '| `HyperEdge` | `~` | hyperedge |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| `HyperEdge` | `~` | 超边 |'
- en: '| `WHyperEdge` | `~%` | weighted hyperedge |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| `WHyperEdge` | `~%` | 加权超边 |'
- en: '| `WkHyperEdge` | `~%#` | key-weighted hyperedge |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| `WkHyperEdge` | `~%#` | 键加权超边 |'
- en: '| `LHyperEdge` | `~+` | labeled hyperedge |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| `LHyperEdge` | `~+` | 标签超边 |'
- en: '| `LkHyperEdge` | `~+#` | key-labeled hyperedge |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `LkHyperEdge` | `~+#` | 键标签超边 |'
- en: '| `WLHyperEdge` | `~%+` | weighted labeled hyperedge |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| `WLHyperEdge` | `~%+` | 加权标签超边 |'
- en: '| `WkLHyperEdge` | `~%#+` | key-weighted labeled hyperedge |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| `WkLHyperEdge` | `~%#+` | 键加权标签超边 |'
- en: '| `WLkHyperEdge` | `~%+#` | weighted key-labeled hyperedge |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| `WLkHyperEdge` | `~%+#` | 加权键标签超边 |'
- en: '| `WkLkHyperEdge` | `~%#+#` | key-weighted key-labeled hyperedge |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| `WkLkHyperEdge` | `~%#+#` | 键加权键标签超边 |'
- en: '| **Directed hyperedges** |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| **有向超边** |'
- en: '| `DiHyperEdge` | `~>` | directed hyperedge |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| `DiHyperEdge` | `~>` | 有向超边 |'
- en: '| `WDiHyperEdge` | `~%>` | weighted directed hyperedge |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| `WDiHyperEdge` | `~%>` | 加权有向超边 |'
- en: '| `WkDiHyperEdge` | `~%#>` | key-weighted directed hyperedge |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| `WkDiHyperEdge` | `~%#>` | 键加权有向超边 |'
- en: '| `LDiHyperEdge` | `~+>` | labeled directed hyperedge |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| `LDiHyperEdge` | `~+>` | 标签有向超边 |'
- en: '| `LkDiHyperEdge` | `~+#>` | key-labeled directed hyperedge |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| `LkDiHyperEdge` | `~+#>` | 键标签有向超边 |'
- en: '| `WLDiHyperEdge` | `~%+>` | weighted labeled directed hyperedge |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| `WLDiHyperEdge` | `~%+>` | 加权标签有向超边 |'
- en: '| `WkLDiHyperEdge` | `~%#+>` | key-weighted labeled directed hyperedge |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| `WkLDiHyperEdge` | `~%#+>` | 键加权标签有向超边 |'
- en: '| `WLkDiHyperEdge` | `~%+#>` | weighted key-labeled directed hyperedge |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| `WLkDiHyperEdge` | `~%+#>` | 加权键标签有向边 |'
- en: '| `WkLkDiHyperEdge` | `~%#+#>` | key-weighted key-labeled directed hyperedge
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| `WkLkDiHyperEdge` | `~%#+#>` | 键加权键标签有向超边 |'
- en: '| **Undirected edges** |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| **无向边** |'
- en: '| `UnDiEdge` | `~` | undirected edge |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `UnDiEdge` | `~` | 无向边 |'
- en: '| `WUnDiEdge` | `~%` | weighted undirected edge |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `WUnDiEdge` | `~%` | 加权无向边 |'
- en: '| `WkUnDiEdge` | `~%#` | key-weighted undirected edge |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `WkUnDiEdge` | `~%#` | 键加权无向边 |'
- en: '| `LUnDiEdge` | `~+` | labeled undirected edge |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `LUnDiEdge` | `~+` | 标签无向边 |'
- en: '| `LkUnDiEdge` | `~+#` | key-labeled undirected edge |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `LkUnDiEdge` | `~+#` | 键标签无向边 |'
- en: '| `WLUnDiEdge` | `~%+` | weighted labeled undirected edge |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| `WLUnDiEdge` | `~%+` | 加权标签无向边 |'
- en: '| `WkLUnDiEdge` | `~%#+` | key-weighted labeled undirected edge |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `WkLUnDiEdge` | `~%#+` | 键加权标签无向边 |'
- en: '| `WLkUnDiEdge` | `~%+#` | weighted key-labeled undirected edge |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `WLkUnDiEdge` | `~%+#` | 加权键标签无向边 |'
- en: '| `WkLkUnDiEdge` | `~%#+#` | key-weighted key-labeled undirected edge |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `WkLkUnDiEdge` | `~%#+#` | 键加权键标签无向边 |'
- en: '| **Directed edges** |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| **有向边** |'
- en: '| `DiEdge` | `~>` | directed edge |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `DiEdge` | `~>` | 有向边 |'
- en: '| `WDiEdge` | `~%>` | weighted directed edge |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `WDiEdge` | `~%>` | 加权有向边 |'
- en: '| `WkDiEdge` | `~%#>` | key-weighted directed edge |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `WkDiEdge` | `~%#>` | 键加权有向边 |'
- en: '| `LDiEdge` | `~+>` | labeled directed edge |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| `LDiEdge` | `~+>` | 标签有向边 |'
- en: '| `LkDiEdge` | `~+#>` | key-labeled directed edge |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| `LkDiEdge` | `~+#>` | 键标签有向边 |'
- en: '| `WLDiEdge` | `~%+>` | weighted labeled directed edge |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| `WLDiEdge` | `~%+>` | 加权标签有向边 |'
- en: '| `WkLDiEdge` | `~%#+>` | key-weighted labeled directed edge |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| `WkLDiEdge` | `~%#+>` | 键加权标签有向边 |'
- en: '| `WLkDiEdge` | `~%+#>` | weighted key-labeled directed edge |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `WLkDiEdge` | `~%+#>` | 加权键标签有向边 |'
- en: '| `WkLkDiEdge` | `~%#+#>` | key-weighted key-labeled directed edge |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `WkLkDiEdge` | `~%#+#>` | 键加权键标签有向边 |'
- en: 'You saw the power of graph for Scala: the edges can be weighted and we may
    potentially construct a multigraph (key-labeled edges allow multiple edges for
    a pair of source and destination nodes).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到了Scala中图的力量：边可以是加权的，我们可能可以构建一个多重图（键标签边允许源节点和目标节点对有多个边）。
- en: 'If you run SBT on the preceding project with the Scala file in the `src/main/scala`
    directory, the output will be as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在`src/main/scala`目录中的Scala文件上运行SBT，输出将如下所示：
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If continuous compilation is enabled, the main method will be run as soon as
    SBT detects that the file has changed (in the case of multiple classes having
    the main method, SBT will ask you which one to run, which is not great for interactivity;
    so you might want to limit the number of executable classes).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用了连续编译，主方法将在SBT检测到文件已更改时立即运行（如果有多个类具有主方法，SBT将询问您要运行哪一个，这对交互性来说不是很好；因此，您可能希望限制可执行类的数量）。
- en: I will cover different output formats in a short while, but let's first see
    how to perform simple operations on the graph.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在稍后介绍不同的输出格式，但首先让我们看看如何对图执行简单操作。
- en: Adding nodes and edges
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加节点和边
- en: 'First, we already know that the graph is directed and acyclic, which is a required
    property for all decision diagrams so that we know we did not make a mistake.
    Let''s say that I want to make the graph more complex and add a node that will
    indicate the likelihood of me recommending a vacation in Portland, Oregon to another
    person. The only thing I need to add is the following line:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们已经知道该图是有向无环的，这是所有决策图所需的一个属性，这样我们就可以知道我们没有犯错误。假设我想使图更复杂，并添加一个节点来表示我向另一个人推荐俄勒冈州波特兰度假的可能性。我需要添加的只是以下这一行：
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you have continuous compilation/run enabled, you will immediately see the
    changes after pressing the **Save File** button:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您启用了连续编译/运行，则在按下**保存文件**按钮后，您将立即看到更改：
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, if we want to know the parents of the newly introduced node, we can simply
    run the following code:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们想知道新引入节点的父节点，我们可以简单地运行以下代码：
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This will give us a set of parents for a specific node—and thus drive the decision
    making process. If we add a cycle, the acyclic method will automatically detect
    it:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们提供一个特定节点的父节点集——从而驱动决策过程。如果我们添加一个环，无环方法将自动检测到：
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Note that you can create the graphs completely programmatically:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，您可以通过完全编程的方式创建图：
- en: '[PRE11]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, the element computation provided as the second parameter to the fill method
    is repeated `45` times (the first parameter). The graph connects every node to
    all of its predecessors, which is also known as a clique in the graph theory.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，提供给fill方法的第二个参数（元素计算）被重复`45`次（第一个参数）。图将每个节点连接到其所有前驱节点，这在图论中也称为团。
- en: Graph constraints
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图约束
- en: 'Graph for Scala enables us to set constraints that cannot be violated by any
    future graph update. This comes in handy when we want to preserve some detail
    in the graph structure. For example, a **Directed Acyclic Graph** (**DAG**) should
    not contain cycles. Two constraints are currently implemented as a part of the
    `scalax.collection.constrained.constraints` package—connected and acyclic, as
    follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Graph for Scala使我们能够设置任何未来的图更新都不能违反的约束。当我们想要保留图结构中的某些细节时，这非常有用。例如，**有向无环图**（**DAG**）不应包含环。目前，有两个约束作为`scalax.collection.constrained.constraints`包的一部分实现——连通和无环，如下所示：
- en: '[PRE12]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is the command to run the program that tries to add or remove nodes that
    violate the constraints:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是运行尝试添加或删除违反约束的节点的命令：
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Adding or subtracting nodes that violate one of the constraints is rejected.
    The programmer can also specify a side effect if an attempt to add or subtract
    a node that violates the condition is made.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 添加或减去违反约束之一的节点将被拒绝。如果尝试添加或减去违反条件的节点，程序员还可以指定副作用。
- en: JSON
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JSON
- en: 'Graph for Scala supports importing/exporting graphs to JSON, as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Graph for Scala支持将图导入/导出到JSON，如下所示：
- en: '[PRE14]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To produce a JSON representation for a sample graph, run:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要为示例图生成JSON表示，请运行：
- en: '[PRE15]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: For more complex structures, one might need to write custom descriptors, serializers,
    and deserializers (refer to [http://www.scala-graph.org/api/json/api/#scalax.collection.io.json.package](http://www.scala-graph.org/api/json/api/#scalax.collection.io.json.package)).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更复杂的结构，可能需要编写自定义描述符、序列化和反序列化程序（参考[http://www.scala-graph.org/api/json/api/#scalax.collection.io.json.package](http://www.scala-graph.org/api/json/api/#scalax.collection.io.json.package)）。
- en: GraphX
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GraphX
- en: 'While graph for Scala may be considered a DSL for graph operations and querying,
    one should go to GraphX for scalability. GraphX is build on top of a powerful
    Spark framework. As an example of Spark/GraphX operations, I''ll use the CMU Enron
    e-mail dataset (about 2 GB). The actual semantic analysis of the e-mail content
    is not going to be important to us until the next chapters. The dataset can be
    downloaded from the CMU site. It has e-mail from mailboxes of 150 users, primarily
    Enron managers, and about 517,401 e-mails between them. The e-mails may be considered
    as an indication of a relation (edge) between two people: Each email is an edge
    between a source (`From:`) and a destination (`To:`) vertices.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Scala的Graph可能被视为图操作和查询的领域特定语言（DSL），但应该使用GraphX来考虑可扩展性。GraphX建立在强大的Spark框架之上。作为一个Spark/GraphX操作的例子，我将使用CMU
    Enron电子邮件数据集（大约2 GB）。实际上，对电子邮件内容的语义分析对我们来说并不重要，直到下一章。数据集可以从CMU网站下载。它包含150个用户（主要是Enron经理）的电子邮件，他们之间大约有517,401封电子邮件。这些电子邮件可以被视为两个人之间关系（边）的指示：每封电子邮件都是一个源（`From:`）和目标（`To:`）顶点的边。
- en: 'Since GraphX requires the data in RDD format, I''ll have to do some preprocessing.
    Luckily, it is extremely easy with Scala—this is why Scala is the perfect language
    for semi-structured data. Here is the code:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GraphX需要以RDD格式存储数据，我不得不进行一些预处理。幸运的是，使用Scala来做这一点极其简单——这也是为什么Scala是处理半结构化数据的完美语言。以下是代码：
- en: '[PRE16]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: First, we use the `MurmurHash3` class to generate node IDs, which are of type
    `Long`, as they are required for each node in GraphX. The `emailRe` and `messageRe`
    are used to match the file content to find the required content. Scala allows
    you to parallelize the programs without much work.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用`MurmurHash3`类生成节点ID，它们是`Long`类型的，因为GraphX中的每个节点都需要它们。`emailRe`和`messageRe`用于将文件内容与所需内容匹配。Scala允许您在不费太多功夫的情况下并行化程序。
- en: Note the `par` call on line 50, `getFileTree(new File(args(0))).par.map`. This
    will make the loop parallel. If processing the whole Enron dataset can take up
    to an hour even on 3 GHz processor, adding parallelization reduces it by about
    8 minutes on a 32-core Intel Xeon E5-2630 2.4 GHz CPU Linux machine (it took 15
    minutes on an Apple MacBook Pro with 2.3 GHz Intel Core i7).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注意第50行的`par`调用，`getFileTree(new File(args(0))).par.map`。这将使循环并行化。即使是在3 GHz的处理器上处理整个Enron数据集也可能需要一个小时，但添加并行化可以在一个32核心的Intel
    Xeon E5-2630 2.4 GHz CPU Linux机器上减少大约8分钟（在2.3 GHz的Intel Core i7的Apple MacBook
    Pro上只需要15分钟）。
- en: 'Running the code will produce a set of JSON records that can be loaded into
    Spark (to run it, you''ll need to put **joda-time** and **lift-json** library
    jars on the classpath), as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码将生成一组可以加载到Spark中的JSON记录（要运行它，您需要在类路径上放置**joda-time**和**lift-json**库jar文件），如下所示：
- en: '[PRE17]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Nice! Spark was able to figure out the fields and types on it''s own. If Spark
    was not able to parse all the records, one would have a `_corrupt_record` field
    containing the unparsed records (one of them is the `[success]` line at the end
    of the dataset, which can be filtered out with a `grep -Fv [success]`). You can
    see them with the following command:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！Spark能够自己找出字段和类型。如果Spark无法解析所有记录，就会有一个`_corrupt_record`字段包含未解析的记录（其中一个是数据集末尾的`[success]`行，可以使用`grep
    -Fv [success]`过滤掉）。您可以使用以下命令查看它们：
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The nodes (people) and edges (relations) datasets can be extracted with the
    following commands:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 节点（人）和边（关系）数据集可以使用以下命令提取：
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Node IDs in GraphX**'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**GraphX中的节点ID**'
- en: As we saw in Graph for Scala, specifying the edges is sufficient for defining
    the nodes and the graph. In Spark/GraphX, nodes need to be extracted explicitly,
    and each node needs to be associated with *n* id of the `Long` type. While this
    potentially limits the flexibility and the number of unique nodes, it enhances
    the efficiency. In this particular example, generating node ID as a hash of the
    e-mail string was sufficient as no collisions were detected, but the generation
    of unique IDs is usually a hard problem to parallelize.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在Graph for Scala中看到的，指定边就足以定义节点和图。在Spark/GraphX中，需要显式提取节点，并且每个节点都需要与一个`Long`类型的*n*
    ID相关联。虽然这可能会限制灵活性和唯一节点的数量，但它提高了效率。在这个特定的例子中，将电子邮件字符串的哈希值作为节点ID生成是足够的，因为没有检测到冲突，但生成唯一ID通常是一个难以并行化的难题。
- en: 'The first GraphX graph is ready!! It took a bit more work than Scala for Graph,
    but now it''s totally ready for distributed processing. A few things to note:
    first, we needed to explicitly convert the fields to `Long` and `String` as the
    `Edge` constructor needed help in figuring out the types. Second, Spark might
    need to optimize the number of partitions (likely, it created too many):'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个GraphX图已经准备好了！！它比Graph的Scala版本需要更多的工作，但现在它完全准备好进行分布式处理了。需要注意几点：首先，我们需要明确地将字段转换为`Long`和`String`，因为`Edge`构造函数需要帮助来确定类型。其次，Spark可能需要优化分区数量（很可能它创建了太多的分区）：
- en: '[PRE20]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To repartition, there are two calls: repartition and coalesce. The latter tries
    to avoid shuffle, as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 要重新分区，有两个调用：repartition和coalesce。后者试图避免shuffle，如下所示：
- en: '[PRE21]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'However, this might limit parallelism if one performs computations over a large
    cluster. Finally, it''s a good idea to use `cache` method that pins the data structure
    in memory:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果在一个大型集群上执行计算，这可能会限制并行性。最后，使用将数据结构固定在内存中的`cache`方法是个好主意：
- en: '[PRE22]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'It took a few more commands to construct a graph in Spark, but four is not
    too bad. Let''s compute some statistics (and show the power of Spark/GraphX, in
    the following table:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark中构建一个图需要更多的命令，但四个不是太多。让我们计算一些统计数据（并展示Spark/GraphX的力量，如下表所示：
- en: Computing basic statistics on Enron e-mail graph.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在Enron电子邮件图上计算基本统计数据。
- en: '| Statistics | Spark command | Value for Enron |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 统计信息 | Spark命令 | Enron的值 |'
- en: '| --- | --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Total # of relations (pairwise communications) | `graph.numEdges` | 3,035,021
    |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 关系总数（成对通信） | `graph.numEdges` | 3,035,021 |'
- en: '| Number of e-mails (message IDs) | `graph.edges.map( e => e.attr._1 ).distinct.count`
    | 371,135 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 电子邮件数量（消息ID） | `graph.edges.map( e => e.attr._1 ).distinct.count` | 371,135
    |'
- en: '| Number of connected pairs | `graph.edges.flatMap( e => List((e.srcId, e.dstId),
    (e.dstId, e.srcId))).distinct.count / 2` | 217,867 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 连接对数量 | `graph.edges.flatMap( e => List((e.srcId, e.dstId), (e.dstId, e.srcId))).distinct.count
    / 2` | 217,867 |'
- en: '| Number of one-way communications | `graph.edges.flatMap( e => List((e.srcId,
    e.dstId), (e.dstId, e.srcId))).distinct.count - graph.edges.map( e => (e.srcId,
    e.dstId)).distinct.count` | 193,183 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 单向通信数量 | `graph.edges.flatMap( e => List((e.srcId, e.dstId), (e.dstId, e.srcId))).distinct.count
    - graph.edges.map( e => (e.srcId, e.dstId)).distinct.count` | 193,183 |'
- en: '| Number of distinct subject lines | `graph.edges.map( e => e.attr._2 ).distinct.count`
    | 110,273 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 不同的主题行数量 | `graph.edges.map( e => e.attr._2 ).distinct.count` | 110,273 |'
- en: '| Total # of nodes | `graph.numVertices` | 23,607 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 节点总数 | `graph.numVertices` | 23,607 |'
- en: '| Number of destination-only nodes | `graph. numVertices - graph.edges.map(
    e => e.srcId).distinct.count` | 17,264 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 仅目标节点数量 | `graph. numVertices - graph.edges.map( e => e.srcId).distinct.count`
    | 17,264 |'
- en: '| Number of source-only nodes | `graph. numVertices - graph.edges.map( e =>
    e.dstId).distinct.count` | 611 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 仅源节点数量 | `graph.numVertices - graph.edges.map( e => e.dstId).distinct.count`
    | 611 |'
- en: Who is getting e-mails?
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谁在接收电子邮件？
- en: 'One of the most straightforward ways to estimate people''s importance in an
    organization is to look at the number of connections or the number of incoming
    and outgoing communicates. The GraphX graph has built-in `inDegrees` and `outDegrees`
    methods. To rank the emails with respect to the number of incoming emails, run:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 估计人在组织中的重要性最直接的方法之一是查看连接数或传入和传出的通信数量。GraphX图内置了`inDegrees`和`outDegrees`方法。要按传入电子邮件数量对电子邮件进行排名，请运行：
- en: '[PRE23]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To rank the emails with respect to the number of egressing emails, run:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要根据出站电子邮件数量对电子邮件进行排名，请运行：
- en: '[PRE24]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Let's apply some more complex algorithms to the Enron dataset.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在Enron数据集上应用一些更复杂的算法。
- en: Connected components
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接组件
- en: 'Connected components determine whether the graph is naturally partitioned into
    several parts. In the Enron relationship graph, this would mean that two or several
    groups communicate mostly between each other:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 连接组件确定图是否自然地分为几个部分。在Enron关系图中，这意味着两个或多个组主要相互通信：
- en: '[PRE25]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We see 18 groups. Each one of the groups can be counted and extracted by filtering
    the ID. For instance, the group associated with `<[etc.survey@enron.com](mailto:etc.survey@enron.com)>`
    can be found by running a SQL query on DataFrame:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到18个组。每个组都可以通过过滤ID来计数和提取。例如，与`<[etc.survey@enron.com](mailto:etc.survey@enron.com)>`关联的组可以通过在DataFrame上运行SQL查询来找到：
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This group is based on a single e-mail sent on September 19, 2000, from `<[survey.test@enron.com](mailto:survey.test@enron.com)>`
    to `<[etc.survey@enron](mailto:etc.survey@enron)>`. The e-mail is listed twice,
    only because it ended up in two different folders (and has two distinct message
    IDs). Only the first group, the largest subgraph, contains more than two e-mail
    addresses in the organization.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这个组基于2000年9月19日发送的单封电子邮件，从`<[survey.test@enron.com](mailto:survey.test@enron.com)>`发送到`<[etc.survey@enron](mailto:etc.survey@enron)>`。电子邮件被列出了两次，仅仅是因为它最终落入了两个不同的文件夹（并且有两个不同的消息ID）。只有第一个组，最大的子图，包含组织中的超过两个电子邮件地址。
- en: Triangle counting
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 三角形计数
- en: 'The triangle counting algorithm is relatively straightforward and can be computed
    in the following three steps:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 三角形计数算法相对简单，可以按以下三个步骤计算：
- en: Compute the set of neighbors for each vertex.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个顶点的邻居集合。
- en: For each edge, compute the intersection of the sets and send the count to both
    vertices.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每条边，计算集合的交集并将计数发送到两个顶点。
- en: Compute the sum at each vertex and divide by two, as each triangle is counted
    twice.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个顶点计算总和，然后除以二，因为每个三角形被计算了两次。
- en: 'We need to convert the multigraph to an undirected graph with `srcId < dstId`,
    which is a precondition for the algorithm:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将多重图转换为具有`srcId < dstId`的无向图，这是算法的一个先决条件：
- en: '[PRE27]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: While there is no direct relationship between the triangle count and the importance
    of people in the organization, the people with higher triangle count arguably
    are more social—even though a clique or a strongly connected component count might
    be a better measure.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然三角形计数与组织中人们的重要性之间没有直接关系，但具有更高三角形计数的那些人可能更社交——尽管 clique 或强连通分量计数可能是一个更好的衡量标准。
- en: Strongly connected components
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强连通分量
- en: In the mathematical theory of directed graphs, a subgraph is said to be strongly
    connected if every vertex is reachable from every other vertex. It could happen
    that the whole graph is just one strongly connected component, but on the other
    end of the spectrum, each vertex could be its own connected component.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在有向图的数学理论中，如果一个子图中的每个顶点都可以从另一个顶点到达，那么这个子图被称为强连通。可能整个图只是一个强连通分量，但在另一端，每个顶点可能就是它自己的连通分量。
- en: If you contract each connected component to a single vertex, you get a new directed
    graph that has a property to be without cycles—acyclic.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将每个连通分量收缩为一个单顶点，你会得到一个新的有向图，它具有一个没有环的性质——无环。
- en: 'The algorithm for SCC detection is already built into GraphX:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: SCC检测的算法已经内置到GraphX中：
- en: '[PRE28]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: There are 18,200 strongly connected components with only an average 23,787/18,200
    = 1.3 users per group.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 有18,200个强连通分量，平均每个组有23,787/18,200 = 1.3个用户。
- en: PageRank
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PageRank
- en: 'The PageRank algorithm gives us an estimate of how important a person by analysing
    the links, which are the emails in this case. For example, let''s run PageRank
    on Enron email graph:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: PageRank算法通过分析链接（在这种情况下是电子邮件）来估计一个人的重要性。例如，让我们在Enron电子邮件图上运行PageRank：
- en: '[PRE29]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Ostensibly, these are the go-to people. PageRank tends to emphasize the incoming
    edges, and Tana Jones returns to the top of the list compared to the 9th place
    in the triangle counting.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上，这些是首选的人选。PageRank倾向于强调入边，与三角形计数中的第9位相比，Tana Jones回到了列表的顶端。
- en: SVD++
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SVD++
- en: 'SVD++ is a recommendation engine algorithm, developed specifically for Netflix
    competition by Yahuda Koren and team in 2008—the original paper is still out there
    in the public domain and can be Googled as `kdd08koren.pdf`. The specific implementation
    comes from the .NET *MyMediaLite* library by ZenoGarther ([https://github.com/zenogantner/MyMediaLite](https://github.com/zenogantner/MyMediaLite)),
    who granted Apache 2 license to the Apache Foundation. Let''s assume I have a
    set of users (on the left) and items (on the right):'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: SVD++是一种推荐引擎算法，由Yahuda Koren及其团队在2008年专门为Netflix竞赛开发——原始论文仍在公共领域，可以通过搜索`kdd08koren.pdf`在Google上找到。具体的实现来自ZenoGarther的.NET
    *MyMediaLite*库（[https://github.com/zenogantner/MyMediaLite](https://github.com/zenogantner/MyMediaLite)），他已将Apache
    2许可证授予Apache基金会。假设我有一组用户（在左侧）和物品（在右侧）：
- en: '![SVD++](img/B04935_07_01.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![SVD++](img/B04935_07_01.jpg)'
- en: Figure 07-1\. A graphical representation of a recommendation problem as a bipartite
    graph.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图07-1。将推荐问题作为二分图进行图形表示。
- en: The preceding diagram is a graphical representation of the recommendation problem.
    The nodes on the left represent users. The nodes on the right represent items.
    User **1** recommends items **A** and **C**, while users **2** and **3** recommend
    only a single item **A**. The rest of the edges are missing. The common question
    is to find recommendation ranking of the rest of the items, the edges may also
    have a weight or recommendation strength attached to them. The graph is usually
    sparse. Such graph is also often called bipartite, as the edges only go from one
    set of nodes to another set of nodes (the user does not recommend another user).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表是推荐问题的图形表示。左侧的节点代表用户。右侧的节点代表物品。用户**1**推荐物品**A**和**C**，而用户**2**和**3**只推荐单个物品**A**。其余的边缺失。常见的问题是找到其余物品的推荐排名，边也可能附有权重或推荐强度。该图通常是稀疏的。这种图也常被称为二分图，因为边只从一个节点集到另一个节点集（用户不会推荐其他用户）。
- en: 'For the recommendation engine, we typically need two types of nodes—users and
    items. The recommendations are based on the rating matrix of (user, item, and
    rating) tuples. One of the implementation of the recommendation algorithm is based
    on **Singular Value Decomposition** (**SVD**) of the preceding matrix. The final
    scoring has four components: the baseline, which is the sum of average for the
    whole matrix, average for the users, and average for the items, as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 对于推荐引擎，我们通常需要两种类型的节点——用户和物品。推荐基于（用户、物品和评分）元组的评分矩阵。推荐算法的一种实现是基于前述矩阵的**奇异值分解**（**SVD**）。最终的评分有四个组成部分：基线，即整个矩阵的平均值，用户平均和物品平均，如下所示：
- en: '![SVD++](img/B04935_07_01F.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![SVD++](img/B04935_07_01F.jpg)'
- en: 'Here, the ![SVD++](img/B04935_07_02F.jpg), ![SVD++](img/B04935_07_03F.jpg),
    and ![SVD++](img/B04935_07_04F.jpg) can be understood as the averages for the
    whole population, user (among all user recommendations), and item (among all the
    users). The final part is the Cartesian product of two rows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![SVD++](img/B04935_07_02F.jpg)、![SVD++](img/B04935_07_03F.jpg)和![SVD++](img/B04935_07_04F.jpg)可以理解为整个群体的平均值、用户（在所有用户推荐中）和物品（在所有用户中）。最后一部分是两行的笛卡尔积：
- en: '![SVD++](img/B04935_07_05F.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![SVD++](img/B04935_07_05F.jpg)'
- en: 'The problem is posed as a minimization problem (refer to [Chapter 4](ch04.xhtml
    "Chapter 4. Supervised and Unsupervised Learning"), *Supervised and Unsupervised
    Learning*):'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 问题被设定为一个最小化问题（参考[第4章](ch04.xhtml "第4章. 监督学习和无监督学习")，*监督学习和无监督学习*）：
- en: '![SVD++](img/B04935_07_06F.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![SVD++](img/B04935_07_06F.jpg)'
- en: 'Here, ![SVD++](img/B04935_07_07F.jpg) is a regularization coefficient also
    discussed in [Chapter 4](ch04.xhtml "Chapter 4. Supervised and Unsupervised Learning"),
    *Supervised and Unsupervised Learning*. So, each user is associated with a set
    of numbers (![SVD++](img/B04935_07_08F.jpg), and each item with ![SVD++](img/B04935_07_09F.jpg),
    ![SVD++](img/B04935_07_10F.jpg). In this particlar implementation, the optimal
    coefficients are found by gradient descent. This is the basic of SVD optimization.
    In linear algebra, SVD takes an arbitrary ![SVD++](img/B04935_07_11F.jpg) matrix
    *A* and represents it as a product of an orthogonal ![SVD++](img/B04935_07_11F.jpg)
    matrix *U*, a diagonal ![SVD++](img/B04935_07_11F.jpg) matrix ![SVD++](img/B04935_07_12F.jpg),
    and a ![SVD++](img/B04935_07_11F.jpg) unitary matrix *V*, for example, the columns
    are mutually orthogonal. Arguably, if one takes the largest ![SVD++](img/B04935_07_13F.jpg)
    entries of the ![SVD++](img/B04935_07_12F.jpg) matrix, the product is reduced
    to the product of a very tall ![SVD++](img/B04935_07_14F.jpg) matrix and a wide
    ![SVD++](img/B04935_07_15F.jpg) matric, where ![SVD++](img/B04935_07_13F.jpg)
    is called the rank of decomposition. If the remaining values are small, the new
    ![SVD++](img/B04935_07_17F.jpg) numbers approximate the original ![SVD++](img/B04935_07_11F.jpg)
    numbers for the relation, *A*. If *m* and *n* are large to start with, and in
    practical online shopping situations, *m* is the items and can be in hundreds
    of thousands, and *n* is the users and can be hundreds of millions, the saving
    can be substantial. For example, for *r=10*, *m=100,000*, and *n=100,000,000*,
    the savings are as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![SVD++](img/B04935_07_07F.jpg)是一个正则化系数，也在[第4章](ch04.xhtml "第4章。监督学习和无监督学习")中进行了讨论，*监督学习和无监督学习*。因此，每个用户都与一组数字相关联（![SVD++](img/B04935_07_08F.jpg)，每个项目与![SVD++](img/B04935_07_09F.jpg)，![SVD++](img/B04935_07_10F.jpg)相关联。在这个特定的实现中，最优系数是通过梯度下降找到的。这是SVD优化的基础。在线性代数中，SVD将一个任意的![SVD++](img/B04935_07_11F.jpg)矩阵*A*表示为一个正交![SVD++](img/B04935_07_11F.jpg)矩阵*U*、一个对角![SVD++](img/B04935_07_11F.jpg)矩阵![SVD++](img/B04935_07_12F.jpg)和一个![SVD++](img/B04935_07_11F.jpg)单位矩阵*V*的乘积，例如，列是相互正交的。可以说，如果取![SVD++](img/B04935_07_12F.jpg)矩阵中最大的![SVD++](img/B04935_07_13F.jpg)个条目，乘积就简化为一个非常高![SVD++](img/B04935_07_14F.jpg)矩阵和一个很宽![SVD++](img/B04935_07_15F.jpg)矩阵的乘积，其中![SVD++](img/B04935_07_13F.jpg)被称为分解的秩。如果剩余的值很小，新的![SVD++](img/B04935_07_17F.jpg)数字近似于原始![SVD++](img/B04935_07_11F.jpg)数字的关系，*A*。如果*m*和*n*一开始就很大，在实际情况的在线购物中，*m*是商品，可能有数十万，而*n*是用户，可能有数亿，这种节省可能是巨大的。例如，对于*r=10*，*m=100,000*，和*n=100,000,000*，节省如下：
- en: '![SVD++](img/B04935_07_18F.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![SVD++](img/B04935_07_18F.jpg)'
- en: 'SVD can also be viewed as PCA for matrices with ![SVD++](img/B04935_07_19F.jpg).
    In the Enron case, we can treat senders as users and recipients as items (we''ll
    need to reassign the node IDs), as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: SVD也可以被视为![SVD++](img/B04935_07_19F.jpg)矩阵的PCA。在Enron案例中，我们可以将发件人视为用户，收件人视为项目（我们需要重新分配节点ID），如下所示：
- en: '[PRE30]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `svdRanks` is the user-part of the ![SVD++](img/B04935_07_20F.jpg) prediction.
    The distribution lists take a priority as this is usually used for mass e-mailing.
    To get the user-specific part, we need to provide the user ID:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`svdRanks`是![SVD++](img/B04935_07_20F.jpg)预测的用户部分。分布列表具有优先级，因为这通常用于群发电子邮件。要获取特定于用户的部分，我们需要提供用户ID：'
- en: '[PRE31]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here, we computed the top five recommended e-mail-to list for top in-degree
    and out-degree users.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们计算了针对度数最高的用户的前五个推荐电子邮件列表。
- en: SVD has only 159 lines of code in Scala and can be the basis for some further
    improvements. SVD++ includes a part based on implicit user feedback and item similarity
    information. Finally, the Netflix winning solution had also taken into consideration
    the fact that user preferences are time-dependent, but this part has not been
    implemented in GraphX yet.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: SVD在Scala中只有159行代码，可以成为一些进一步改进的基础。SVD++包括基于隐式用户反馈和项目相似性信息的一部分。最后，Netflix获奖方案也考虑到了用户偏好随时间变化的事实，但这一部分在GraphX中尚未实现。
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: While one can easily create their own data structures for graph problems, Scala's
    support for graphs comes from both semantic layer—Graph for Scala is effectively
    a convenient, interactive, and expressive language for working with graphs—and
    scalability via Spark and distributed computing. I hope that some of the material
    exposed in this chapter will be useful for implementing algorithms on top of Scala,
    Spark, and GraphX. It is worth mentioning that bot libraries are still under active
    development.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然人们可以轻松地为图问题创建自己的数据结构，但Scala对图的支持既来自语义层——对于Scala来说，Graph实际上是一种方便、交互式且表达性强的语言，用于处理图——也来自通过Spark和分布式计算的可扩展性。我希望本章中暴露的一些材料将对在Scala、Spark和GraphX之上实现算法有所帮助。值得一提的是，这些库仍在积极开发中。
- en: In the next chapter, we'll step down from from our flight in the the skies and
    look at Scala integration with traditional data analysis frameworks such as statistical
    language R and Python, which are often used for data munching. Later, in [Chapter
    9](ch09.xhtml "Chapter 9. NLP in Scala"), *NLP in Scala*. I'll look at NLP Scala
    tools, which leverage complex data structures extensively.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将从天空中我们的飞行中降级，看看Scala与传统的数据分析框架（如统计语言R和Python）的集成，这些框架通常用于数据处理。稍后，在[第9章](ch09.xhtml
    "第9章。Scala中的NLP")中，我将探讨Scala中的NLP工具，这些工具广泛利用复杂的数据结构。
