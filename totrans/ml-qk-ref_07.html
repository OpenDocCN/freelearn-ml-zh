<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Temporal and Sequential Pattern Discovery</h1>
                </header>
            
            <article>
                
<p>Many of us have visited retail shops such as Reliance and Walmart for our household needs. Let's say that we are planning to buy an iPhoneX from Reliance Digital. What we would typically do is search for the model by visiting the mobile section of the store, and then select the product and head toward the billing counter.</p>
<p>But, in today's world, the goal of the organization is to increase revenue. Can this be done by pitching just one product at a time to the customer? The answer is a clear <strong>no</strong>. Hence, organizations began mining data relating to <span>frequently bought </span>items. They try to find out associations between different items and products that can be sold together, which gives assisting in right product placement. Typically, it figures out what products are being bought together and organizations can place products in a similar manner.</p>
<p>This is what we are going to talk about in this chapter. How do we come up with such rules by means of machine learning? We will discuss number of techniques here.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Association rules</li>
<li><span>Frequent pattern growth</span></li>
<li><span>Validation</span></li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Association rules</h1>
                </header>
            
            <article>
                
<p>Association rule mining is a technique that focuses upon observing frequently occurring patterns and associations from datasets found in databases such as relational and transactional databases. These rules do not say anything about the preferences of an individual; rather, they rely chiefly on the items within transactions to deduce a certain association. Every transaction is identified by a primary key (distinct ID) called, <strong>transaction ID</strong>. All these transactions are studied as a group and patterns are mined.</p>
<p>Association rules can be thought of as an <strong>if—then</strong> relationship. Just to elaborate on that, we have to come up with a rule: <strong>if</strong> an item <strong>A</strong> is being bought by the customer, <strong>then</strong> the chances of item <strong>B</strong> being picked by the customer too under the same transaction ID (along with item <strong>A</strong>) is found out. You needs to understand here that it's not a causality, rather, it is co-occurrence pattern that comes to the fore.</p>
<p>There are two elements of these rules:</p>
<ul>
<li><strong>Antecedent (if)</strong>: This is an item/group of items that are typically found in the itemsets or datasets</li>
<li><strong>Consequent (then)</strong>: This comes along as an item with an antecedent/group of antecedents</li>
</ul>
<p>Have a look at the following rule:</p>
<p class="CDPAlignCenter CDPAlign"><em>{Bread, milk} ⇒ {Butter}</em></p>
<p>The first part of this rule is called <strong>antecedent</strong> and the second part (after the arrow) is <strong>consequent</strong>. It is able to convey that there is a chance of <em>Butter</em> being picked in a transaction if <em>Bread</em> <span><span>and </span></span> <em>Milk</em> are picked earlier. However, the percentage chance for the consequent to be present in an itemset, given the antecedent, is not clear.</p>
<p>Let's look at a few metrics that will help us in getting there:</p>
<ol>
<li><strong>Support</strong>: This is a measure of the frequency of the itemset in all the transactions. For example, there are two itemsets popping up through the number of transactions for a retail outlet such as Walmart: itemset <em>A = {Milk}</em>, itemset <em>B = {laptop}</em>. Given that support is how frequent the itemset is in all the transactions, we are asked to find out which itemset has got the higher support. We know that itemset <em>A</em> will have higher support because <em>Milk</em> features in everyday grocery lists (and, in turn, the transaction) at a greater probability than <em>laptop</em>. Let's add another level of association and study with two new itemsets: itemset <em>A= {milk, cornflakes}</em>, itemset <em>B= {milk, USB Drive}</em>. The purchasing frequency of <em>milk</em> and <em>cornflakes</em> together will be higher than <em>milk and USB Drive</em>. It will make the support metric higher for <em>A</em>.</li>
</ol>
<p style="padding-left: 60px">Let's translate this into mathematics:</p>
<p class="CDPAlignCenter CDPAlign"><em>Support(A, B) = Transactions comprising A and B/Total number of transactions</em></p>
<p style="padding-left: 60px">Here's an example:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li>The total number of transactions is 10,000</li>
<li>Transactions comprising <em>A</em> and <em>B = 500</em></li>
<li>Then support <em>(A, B) = 500/10000= 0.05</em></li>
<li>5% of transactions contain <em>A</em> and <em>B</em> together</li>
</ul>
</li>
</ul>
<ol start="2">
<li><strong>Confidence</strong>: This indicates how likely item 1 is to be purchased/picked when item 2 is already picked. In other words, it measures the likelihood of the occurrence of consequent transactions given that the antecedent is already there in the transaction. In other words, it is the probability of the occurrence of <em>Butter</em> in the transaction if <em>Bread</em> has already been part of that transaction. It is quite clear that it is a conditional probability of the occurrence of the consequent while having the antecedent:</li>
</ol>
<ul>
<li style="list-style-type: none">
<ul>
<li><em>Confidence(A ⇒ B) = Transactions comprising A and B/Transactions comprising A</em></li>
<li><em>Confidence can be transformed in terms of support</em></li>
<li><em>Confidence(A ⇒ B) = Support(A, B)/Support(A)</em></li>
</ul>
</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">Here's an example:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li class="mce-root"><span>Transactions with the itemset as <em>milk = 50</em></span></li>
<li>Transactions with the itemset as <em>cereal = 30</em></li>
<li>Transactions comprising <em>milk</em> and <em>cereal = 10</em></li>
<li>Total number of transactions = 100</li>
<li><em>Confidence(milk ⇒ Cereal) = 10/(50 +10) = 0.167</em></li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">It means that there is 16.7% probability of that event taking place.</p>
<p style="padding-left: 60px">A drawback of the confidence is it only accounts for how popular item 1 is, but not item 2. If item 2 is equally frequent, there will be a higher chance that a transaction containing item 1 will also contain item 2. Hence, it will result in an inflated outcome. To account for the frequency of both constituent items, we use a third measure called <strong>lift</strong>.</p>
<ol start="3">
<li><strong>Lift</strong>: This is an indicator of how likely it is that item B will be picked in the cart/transaction, given that item <em>A</em> is already picked, while keeping a tab on the frequency of item <em>B.</em> A lift value greater than 1 says that there is a great association between item <em>A</em> and item <em>B,</em> which implies that there is a good chance that item <em>B</em> will be picked if item <em>A</em> is already in the cart. A lift value of less than 1 means that the chances are slim that item <em>B</em> will be picked if item <em>A</em> is already present. If the lift value hits zero, it means no association can be established here.</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><em>Lift(A⇒B) = (Transactions comprising A and B/(Transactions comprising A))/fraction of Transaction comprising B</em></p>
<p style="padding-left: 60px">Implies:</p>
<p class="CDPAlignCenter CDPAlign"><em>= Support(A, B)/(Support(A) * Support(B))</em></p>
<p class="CDPAlignCenter CDPAlign"><em>Lift(milk⇒cereal) = ( 10/(50+10))/0.4</em></p>
<p class="CDPAlignCenter CDPAlign"><em>= 0.416</em></p>
<p>We will see this in a better format here. The probability of having cereal in the cart with the knowledge that milk is already in the cart (which is called <strong>confidence</strong>) = <em>10/(50+10) = 0.167.</em></p>
<p>The probability of having cereal in the cart without the knowledge that milk is in the <em>cart = (30+10)/100 = 0.4</em>.</p>
<p class="mce-root"/>
<p>It means that having knowledge that milk is already in the cart reduces the chance of picking cereal from <em>0.4</em> to <em>0.167</em>. It is a lift of <em>0.167/0.4= 0.416</em> and is less than <em>1</em>. Hence, the chances of picking cereal while milk is already in the cart are very small.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Apriori algorithm</h1>
                </header>
            
            <article>
                
<p>Apriori is a classical algorithm that is used to mine frequent itemsets to derive various association rules. It will help set up a retail store in a much better way, which will aid revenue generation.</p>
<p>The anti-monotonicity of the support measure is one of the prime concepts around which Apriori revolves. It assumes the following:</p>
<ul>
<li>All subsets of a frequent itemset must be frequent</li>
<li>Similarly, for any infrequent itemset, all its supersets must be infrequent too</li>
</ul>
<p>Let's look at an example and explain it:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td style="width: 17%">
<p><strong>Transaction ID</strong></p>
</td>
<td style="width: 10%">
<p><strong>Milk</strong></p>
</td>
<td style="width: 10%">
<p><strong>Butter</strong></p>
</td>
<td style="width: 12%">
<p><strong>Cereal</strong></p>
</td>
<td style="width: 13.3581%">
<p><strong>Bread</strong></p>
</td>
<td style="width: 24.6419%">
<p><strong>Book</strong></p>
</td>
</tr>
<tr>
<td style="width: 17%">
<p>t1</p>
</td>
<td style="width: 10%">
<p>1</p>
</td>
<td style="width: 10%">
<p>1</p>
</td>
<td style="width: 12%">
<p>1</p>
</td>
<td style="width: 13.3581%">
<p>0</p>
</td>
<td style="width: 24.6419%">
<p>0</p>
</td>
</tr>
<tr>
<td style="width: 17%">
<p>t2</p>
</td>
<td style="width: 10%">
<p>0</p>
</td>
<td style="width: 10%">
<p>1</p>
</td>
<td style="width: 12%">
<p>1</p>
</td>
<td style="width: 13.3581%">
<p>1</p>
</td>
<td style="width: 24.6419%">
<p>0</p>
</td>
</tr>
<tr>
<td style="width: 17%">
<p>t3</p>
</td>
<td style="width: 10%">
<p>0</p>
</td>
<td style="width: 10%">
<p>0</p>
</td>
<td style="width: 12%">
<p>0</p>
</td>
<td style="width: 13.3581%">
<p>1</p>
</td>
<td style="width: 24.6419%">
<p>1</p>
</td>
</tr>
<tr>
<td style="width: 17%">
<p>t4</p>
</td>
<td style="width: 10%">
<p>1</p>
</td>
<td style="width: 10%">
<p>1</p>
</td>
<td style="width: 12%">
<p>0</p>
</td>
<td style="width: 13.3581%">
<p>1</p>
</td>
<td style="width: 24.6419%">
<p>0</p>
</td>
</tr>
<tr>
<td style="width: 17%">
<p>t5</p>
</td>
<td style="width: 10%">
<p>1</p>
</td>
<td style="width: 10%">
<p>1</p>
</td>
<td style="width: 12%">
<p>1</p>
</td>
<td style="width: 13.3581%">
<p>0</p>
</td>
<td style="width: 24.6419%">
<p>1</p>
</td>
</tr>
<tr>
<td style="width: 17%">
<p>t6</p>
</td>
<td style="width: 10%">
<p>1</p>
</td>
<td style="width: 10%">
<p>1</p>
</td>
<td style="width: 12%">
<p>1</p>
</td>
<td style="width: 13.3581%">
<p>1</p>
</td>
<td style="width: 24.6419%">
<p>1</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>We have got the transaction ID and items such as milk, butter, cereal, bread, and book. 1 denotes that item is part of the transaction and 0 means that it is not.</p>
<ul>
<li>We came up with a frequency table for all the items along, with support (division by 6):</li>
</ul>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>Items</strong></p>
</td>
<td>
<p><strong>Number of transactions</strong></p>
</td>
<td>
<p><strong>Support</strong></p>
</td>
</tr>
<tr>
<td>
<p>Milk</p>
</td>
<td>
<p>4</p>
</td>
<td>
<p>67%</p>
</td>
</tr>
<tr>
<td>
<p>Butter</p>
</td>
<td>
<p>5</p>
</td>
<td>
<p>83%</p>
</td>
</tr>
<tr>
<td>
<p>Cereal</p>
</td>
<td>
<p>4</p>
</td>
<td>
<p>67%</p>
</td>
</tr>
<tr>
<td>
<p>Bread</p>
</td>
<td>
<p>4</p>
</td>
<td>
<p>67%</p>
</td>
</tr>
<tr>
<td>
<p>Book</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>50%</p>
</td>
</tr>
</tbody>
</table>
<ul>
<li>We will put a threshold of support at 60%, which will filter out the items by frequency as these are the ones that can be addressed as frequent itemsets in this scenario:</li>
</ul>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>Items</strong></p>
</td>
<td>
<p><strong>Number of transactions</strong></p>
</td>
</tr>
<tr>
<td>
<p>Milk</p>
</td>
<td>
<p>4</p>
</td>
</tr>
<tr>
<td>
<p>Butter</p>
</td>
<td>
<p>5</p>
</td>
</tr>
<tr>
<td>
<p>Cereal</p>
</td>
<td>
<p>4</p>
</td>
</tr>
<tr>
<td>
<p>Bread</p>
</td>
<td>
<p>4</p>
</td>
</tr>
</tbody>
</table>
<ul>
<li>Similarly, we form the number of combinations (two at a time, three at a time, and four at a time) with these items and find out frequencies:</li>
</ul>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>Items</strong></p>
</td>
<td>
<p><strong>Number of transactions</strong></p>
</td>
</tr>
<tr>
<td>
<p>Milk, Butter</p>
</td>
<td>
<p>4</p>
</td>
</tr>
<tr>
<td>
<p>Milk, Cereal</p>
</td>
<td>
<p>3</p>
</td>
</tr>
<tr>
<td>
<p>Milk, Bread</p>
</td>
<td>
<p>2</p>
</td>
</tr>
<tr>
<td>
<p>Butter, Bread</p>
</td>
<td>
<p>3</p>
</td>
</tr>
<tr>
<td>
<p>Butter, Cereal</p>
</td>
<td>
<p>4</p>
</td>
</tr>
<tr>
<td>
<p>Cereal, Bread</p>
</td>
<td>
<p>2</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Now, again, we have to find out the support for the preceding examples and filter them by threshold, which is support at 60%</p>
<p>Similarly, the combinations have to be formed with three items at a time (for example, Milk, Butter, and Bread) and support needs to be calculated for them. And, finally, we will filter them out by threshold. The same process needs to be done by doing four items at a time. The step that we have done till now is called <strong>frequent itemset generation</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Finding association rules</h1>
                </header>
            
            <article>
                
<p>In order to find the association rules, we have to first search for all of the rules that have support greater than the threshold support. But the question arises: how do we find these? A possible way to find this is by brute force, which means to list all the possible association rules <span>and calculate the support and confidence for each rule. Later, remove all the rules that fail the confidence and support thresholds.</span></p>
<p>Given there are <em>n</em> items in the set<em> I</em>, the total number of possible association rules is <em>3<sup>n</sup> - 2<sup>n+1</sup> + 1</em>.</p>
<p>If <em>X</em> is a frequent itemset with <em>k</em> elements, then there are <em>2<sup>k</sup> - 2</em> association rules.</p>
<p>Let's see how to execute association rules in Python:</p>
<pre>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/><br/><span><span class="cm-variable">data</span> = <span class="cm-variable">pd</span>.<span class="cm-property">read_csv</span>(<span class="cm-string">'association_mining.csv'</span>, <span class="cm-variable">header</span> = <span class="cm-keyword">None</span>)<br/><br/></span>transactions = []<br/>for i in range(0, 7501):<br/> transactions.append([str(data.values[i,j]) for j in range(0, 20)])</pre>
<p>If we are asking for an item to appear three times in a day for seven days' time, the support will be <em>3 x 7/7051</em>. <em>7051</em> is the total number of transactions. We will keep the confidence as 20% in the beginning:</p>
<pre>from apyori import apriori<br/>rules = apriori(transactions, min_support = 0.003, min_confidence = 0.2, min_lift = 3, min_length = 2)<br/><br/>results = list(rules)<br/>results</pre>
<p>We can visualize the output by running the <kbd>results</kbd> command from the preceding code:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-588 image-border" src="assets/fc03af0b-27fb-4b45-b579-87be6c9ecb77.png" style="width:42.25em;height:23.75em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Frequent pattern growth</h1>
                </header>
            
            <article>
                
<p><strong>Frequent pattern growth</strong> (<strong>FP-growth</strong>) is a frequent itemset generation technique (similar to Apriori). FP-Growth builds a compact-tree structure and uses the tree for frequent itemset mining and generating rules. It is faster than Apriori and can throw results with large datasets.</p>
<p>Let's go through the steps of FP-Growth:</p>
<ol>
<li><strong>Setting up the transactions</strong>: This step sets up the items by frequency. However, the items are set up vertically, not horizontally. That means transforming input from transaction to items:</li>
</ol>
<table border="1" style="border-collapse: collapse;width: 98.3494%">
<tbody>
<tr>
<td style="width: 33%">
<p class="CDPAlignLeft CDPAlign"><strong>t_id</strong></p>
</td>
<td style="width: 79.6486%">
<p><strong>Items</strong></p>
</td>
</tr>
<tr>
<td>
<p>1</p>
</td>
<td style="width: 79.6486%">
<p>(B, C, D, A)</p>
</td>
</tr>
<tr>
<td>
<p>2</p>
</td>
<td>
<p>(B, C, D)</p>
</td>
</tr>
<tr>
<td>
<p>3</p>
</td>
<td>
<p>(D, A)</p>
</td>
</tr>
<tr>
<td>
<p>4</p>
</td>
<td>
<p>(A, B)</p>
</td>
</tr>
<tr>
<td>
<p>5</p>
</td>
<td>
<p>(A, C, B)</p>
</td>
</tr>
</tbody>
</table>
<ol start="2">
<li class="mce-root"><strong>Finding the frequency</strong><span>: Now we have to find out the frequency of each item individually:</span></li>
</ol>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p class="CDPAlignLeft CDPAlign"><strong>Items</strong></p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign"><strong>Frequency</strong></p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignLeft CDPAlign">A</p>
</td>
<td class="CDPAlignRight CDPAlign">
<p class="CDPAlignLeft CDPAlign">4</p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign">
<p>B</p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p>4</p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign">
<p>C</p>
</td>
<td class="CDPAlignRight CDPAlign">
<p class="CDPAlignLeft CDPAlign">3</p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign">
<p>D</p>
</td>
<td class="CDPAlignRight CDPAlign">
<p class="CDPAlignLeft CDPAlign">3</p>
</td>
</tr>
</tbody>
</table>
<p style="padding-left: 60px">Let's set up the minimum threshold or minimum support as 50%:</p>
<ul>
<li style="list-style-type: none">
<ul style="padding-left: 1px">
<li>Min Support = (5*50/100) = 2.5</li>
<li>Ceiling of minimum support = 2.5 ~ 3</li>
</ul>
</li>
</ul>
<ol start="3">
<li><strong>Prioritize the items by frequency</strong>: Since all the items have a frequency greater than or equal to minimum support, all the items will be part of it. Also, based on their frequency, priority or rank will be assigned to the items:</li>
</ol>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr style="height: 69.1875px">
<td>
<p class="CDPAlignLeft CDPAlign"><strong>Items</strong></p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign"><strong>Frequency</strong></p>
</td>
<td>
<p><strong>Rank</strong></p>
</td>
</tr>
<tr style="height: 68px">
<td>
<p>A</p>
</td>
<td>
<p>4</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td>
<p>B</p>
</td>
<td>
<p>4</p>
</td>
<td>
<p>2</p>
</td>
</tr>
<tr style="height: 69px">
<td>
<p>C</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>3</p>
</td>
</tr>
<tr style="height: 69px">
<td>
<p>D</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>4</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p style="padding-left: 60px">The order of the items is: A, B, C, and D (by frequency in descending order)</p>
<ol start="4">
<li><strong>Ordering the items by priority</strong>: Now the order of items will be set according to the priority given to various items based on frequency. Currently, the order is A, B, C, and D:</li>
</ol>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>t_id</strong></p>
</td>
<td>
<p><strong>Items</strong></p>
</td>
<td>
<p><strong>Order by priority</strong></p>
</td>
</tr>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>(B, C, D, A)</p>
</td>
<td>
<p>(A, B, C, D)</p>
</td>
</tr>
<tr>
<td>
<p>2</p>
</td>
<td>
<p>(B, C, D)</p>
</td>
<td>
<p>(B, C, D)</p>
</td>
</tr>
<tr>
<td>
<p>3</p>
</td>
<td>
<p>(D, A)</p>
</td>
<td>
<p>(A, D)</p>
</td>
</tr>
<tr>
<td>
<p>4</p>
</td>
<td>
<p>(A, B)</p>
</td>
<td>
<p>(A, B)</p>
</td>
</tr>
<tr>
<td>
<p>5</p>
</td>
<td>
<p>(A, C, B)</p>
</td>
<td>
<p>(A, B, C)</p>
</td>
</tr>
</tbody>
</table>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Frequent pattern tree growth</h1>
                </header>
            
            <article>
                
<p>We will study the different frequent pattern tree growth from the following rows:</p>
<ul>
<li><strong>Row 1</strong><span>: Every FP-Tree starts with a null node as a root node. Let's draw the first row of the tree order along with their frequency:</span></li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-587 image-border" src="assets/6018c3aa-74dd-46d3-97ba-c8cfb4792d04.png" style="width:11.33em;height:21.50em;"/></p>
<ul>
<li class="CDPAlignLeft CDPAlign"><span><strong>Row 2</strong>: It has got <em>{B,C,D}</em>. <em>A</em> is missing, so we can not merge it with the earlier node. Hence, we will have to create another node, altogether as shown here:</span></li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-586 image-border" src="assets/64811bcc-9002-4203-a764-0e28f7b0d86b.png" style="width:22.08em;height:18.17em;"/></p>
<ul>
<li class="CDPAlignLeft CDPAlign"><strong>Row 3</strong>: It has got <em>{A,D}</em>. <em>B</em> and <em>C</em> are missing, but we can tie it with the earlier node. <em>A</em> encounters a repetition, so frequency will change. It becomes <em>2</em> now:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-589 image-border" src="assets/7e0a0970-2717-4b76-ba4a-722a683fa292.png" style="width:49.42em;height:26.17em;"/></p>
<ul>
<li class="CDPAlignLeft CDPAlign"><strong>Row 4</strong>: It has got <em>{A,B}</em>. We can tie it with the earlier node and will traverse on the previous node. <em>A</em> and <em>B</em> encounters a repetition, so frequency will change for it. It becomes 3 and 2 respectively:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-583 image-border" src="assets/bbb3d66b-ce39-4fff-bcdf-9af564cfb132.png" style="width:36.33em;height:18.75em;"/></p>
<ul>
<li class="CDPAlignLeft CDPAlign"><span><strong>Row 5</strong></span><span>: It has got <em>{A,B,C}</em>. Again, it can be tied with the earlier node and A, B, and C see a repetition, so the frequency will change for them. It becomes 4, 3, and 2 respectively:</span></li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-584 image-border" src="assets/53cfa7ef-1d4e-48a0-83bc-52cf57af72bc.png" style="width:35.67em;height:18.92em;"/></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Validation </h1>
                </header>
            
            <article>
                
<p>Now, let's count the frequency of the final tree that we have got and compare the frequency of each item with the table to ensure that we have got the correct frequencies in the table:</p>
<ul>
<li><strong>A:4</strong></li>
<li><strong>B:4</strong></li>
<li><strong>C:3</strong></li>
<li><strong>D:3</strong></li>
</ul>
<p> </p>
<p>Now we will go from bottom to top. We will find out the branches where D appears:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-585 image-border" src="assets/613380ab-1fe4-4529-8db5-b1527163ee34.png" style="width:53.42em;height:32.25em;"/></p>
<p>We can see that there are three branches where D appears:</p>
<ul>
<li>BC: 1</li>
<li>ABC: 1</li>
<li>A: 1</li>
</ul>
<p>These branches are termed as conditional pattern base for D. While we do this, there are points to be kept in mind:</p>
<ul>
<li>Even if we traverse from bottom to top, we write the branches in a top-to-bottom manner</li>
<li>D is not part of it</li>
<li>1 represents the frequency of occurrence of D in each branch</li>
</ul>
<p>Now, the conditional pattern for D results in the conditional frequencies for A, B, and C, which are 2, 2, and 2. All are less than the minimum support (3). Hence, there can't be any conditional FP- Tree for it.</p>
<p>Now, let's do it for C. C is appears in the following branches:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-582 image-border" src="assets/c42a910a-7183-4359-a62e-77209960285c.png" style="width:53.42em;height:29.08em;"/></p>
<p>The branches end up like this:</p>
<ul>
<li>B:1</li>
<li>AB:2</li>
</ul>
<p>It results in A:2 and B:3. So, B fit with the bill in accordance with the minimum support. Now the conditional tree ends up like this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-581 image-border" src="assets/ede86a39-0990-469c-96e9-89dac495cb1b.png" style="width:12.50em;height:8.83em;"/></p>
<p>Similarly, conditional pattern finding is done for different combinations. Thus, it sets up the frequent item dataset.</p>
<p>Let's see how it can be done in Python. We will be using a library called <kbd>pyfpgrowth</kbd>. Also, we shall create an itemset in the following section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing the library</h1>
                </header>
            
            <article>
                
<p>In order to perform validation we will import the library and build the transactions as shown here:</p>
<pre>import pyfpgrowth</pre>
<p>We build our transactions like so:</p>
<pre>transaction = [["bread", "butter", "cereal"],<br/> ["butter", "milk"],<br/> ["bread", "milk"],<br/> ["butter", "cereal", "milk"],<br/> ["egg", "bread"],<br/> ["egg", "butter"],<br/> ["cereal", "milk"],<br/> ["bread", "butter", "cereal", "egg"],<br/> ["cereal", "bread", "butter"]]</pre>
<p class="mce-root">Minimum support is defined now to find the pattern. <kbd>find_frequent_patterns()</kbd><em>,</em> where <kbd>transactions</kbd> are the list of items bought at each transaction, and <kbd>2</kbd> is the minimum threshold set for support count:</p>
<pre>patterns = pyfpgrowth.find_frequent_patterns(transaction, 2)</pre>
<p class="mce-root"/>
<p>Finally, we have to define the confidence to get the rules. <span>Rules are generated based on the patterns and <kbd>0.5</kbd> is the minimum threshold set for confidence. Then, we store the rules in a dataframe named <kbd>rules</kbd>. <kbd>rules</kbd> initially consists of an antecedent, a consequent, and the confidence value:</span></p>
<pre>rules = pyfpgrowth.generate_association_rules(patterns, 0.5)<br/>print(rules)</pre>
<p>We get the output as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/af558284-73fa-4c72-a90e-b8fcf6389188.png" style="width:33.25em;height:8.50em;"/></p>
<p>This is how we get the rules. FP-growth tends to have the edge over Apriori as it is faster and more efficient.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have studied association rules. We also discussed the Apriori algorithm, which is used for mining frequent itemsets to derive various association rules. We also learned about frequent pattern growth (FP-growth), which is similar to Apriori and about the <span>frequent itemset generation technique, which is similar to the Apriori algorithm. Finally, we saw how FP-growth tends to have an edge over Apriori, as it is faster and more efficient, using an example. </span></p>
<p>In the next chapter, we will study p<span>robabilistic graphical models. We will learn in depth about the Bayesian rules and Bayesian networks.</span></p>


            </article>

            
        </section>
    </body></html>