<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Credit Card Fraud Detection Using Autoencoders</h1>
                </header>
            
            <article>
                
<p class="mce-root">Fraud management has been known to be a very painful problem for banking and finance firms. Card-related frauds have proven to be especially difficult for firms to combat. Technologies such as chip and PIN are available and are already used by most credit card system vendors, such as Visa and MasterCard. However, the available technology is unable to curtail 100% of credit card fraud. Unfortunately, scammers come up with newer ways of phishing to obtain passwords from credit card users. Also, devices such as skimmers make stealing credit card data a cake walk!</p>
<p class="mce-root">Despite the availability of some technical abilities to combat credit card fraud, <em class="calibre15">The Nilson Report</em>, a leading publication covering payment systems worldwide, estimated that credit card fraud is going to soar to $32 billion in 2020 (<a href="https://nilsonreport.com/upload/content_promo/The_Nilson_Report_10-17-2017.pdf" class="calibre8">https://nilsonreport.com/upload/content_promo/The_Nilson_Report_10-17-2017.pdf</a>). To get a perspective on the estimated loss, it is more than the recent profits posted by companies such as Coca-Cola ($2 billion), Warren Buffet’s Berkshire Hathaway ($24 billion), and JP Morgan Chase ($23.5 billion)!</p>
<p class="mce-root">While credit card chip technology-providing companies have been investing hugely to advance the technology to counter credit card fraud, in this chapter, we are going to examine whether and how far machine learning can help deal with the credit card fraud problem. We will cover the following topics as we progress through this chapter:</p>
<ul class="calibre9">
<li class="calibre10">Machine learning in credit card fraud detection</li>
<li class="calibre10">Autoencoders and the various types</li>
<li class="calibre10">The credit card fraud dataset</li>
<li class="calibre10">Building AEs with the H2O library in R</li>
<li class="calibre10">Implementation of auto encoder for credit card fraud detection</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Machine learning in credit card fraud detection</h1>
                </header>
            
            <article>
                
<p class="mce-root">The task of fraud detection often boils down to outlier detection, in which a dataset is verified to find potential anomalies in the data. Traditionally, this task was deemed a manual task, where risk experts checked all transactions manually. Even though there is a technical layer, it is purely based on a rules base that scans through each transaction, and then those shortlisted as suspicious are sent through for a manual review to make a final decision on the transaction. However, there are some major drawbacks to this system:</p>
<ul class="calibre9">
<li class="calibre10">Organizations need substantial fraud management budgets for manual review staff.</li>
<li class="calibre10">Extensive training is required to train the employees working as manual review staff.</li>
<li class="calibre10">Training the personnel to manually review transactions is time consuming and expensive.</li>
<li class="calibre10">Even the most highly trained manual review staff carry certain biases, therefore making the whole review system inaccurate.</li>
<li class="calibre10">Manual reviews increase the time required to fulfill a transaction. The customers might get frustrated with the long wait times required to pass a credit card transaction. This may impact the loyalty of customers.</li>
<li class="calibre10">Manual reviews may yield false positives. A false positive not only affects the sale in the process but also lifetime value generated from the customer.</li>
</ul>
<p class="mce-root">Fortunately, with the rise of <strong class="calibre3">machine learning</strong> (<strong class="calibre3">ML</strong>), <strong class="calibre3">artificial intelligence</strong> (<strong class="calibre3">AI</strong>), and deep learning, it became feasible to automate the manual credit card transaction review process to a large extent. This not only saves an intensive amount of labor but also yields better detection of credit card fraud, which otherwise is impacted due to biases that human reviewers carry.</p>
<p class="mce-root">ML-based fraud detection strategies generally can be accomplished using both supervised ML and unsupervised ML techniques.</p>
<p class="mce-root">Supervised ML models <span class="calibre4">are</span><span class="calibre4"> </span><span class="calibre4">generally used when large amounts of transaction data tagged as</span> <strong class="calibre3">genuine </strong><span class="calibre4">or</span> <strong class="calibre3">fraud </strong><span class="calibre4">are available. A model is trained on the labeled dataset and the resultant model is then used for classifying any new credit card transactions into one of the two possible classes.</span></p>
<p class="mce-root">With most organizations, the problem is that labeled data is unavailable, or very little labeled data is available. This makes supervised learning models less feasible. This is where unsupervised models come into play. They are designed to spot anomalous behavior in transactions and they do not need explicit pre-labeled data to identify the anomalous behavior. The general idea in unsupervised fraud detection is to detect behavior anomalies by identifying transactions that do not conform to the majority.</p>
<p class="mce-root">Another thing to keep in mind is that fraud events are rare, and are not as common as genuine transactions. Due to the rarity of fraud, severe class imbalance problem may be seen in datasets related to credit card fraud. In other words, one would observe that 95% or more of the data in the dataset is of genuine transactions, and less than 5% of the data belongs to fraudulent transactions. Also, even if you learn about a fraudulent transaction today, the model is likely to face an anomaly tomorrow with different features. So, the problem space of genuine transactions is well known and it is pretty much stagnant; however, the problem space for fraudulent transactions is not well known and it is not constant. Due to these reasons, it make sense to deal with the fraud detection problem with unsupervised learning rather than supervised learning.</p>
<p class="mce-root">Anomaly detection is an unsupervised learning algorithm that is also termed a <strong class="calibre3">one-class classification</strong> algorithm. It distinguishes between <strong class="calibre3">normal</strong> and <strong class="calibre3">anomalous</strong> observations. The key principle on which the algorithm is built is that anomalous observations do not conform to the expected pattern of other common observations in a dataset. It is called a one-class classification as it learns the pattern of genuine transactions, and anything that shows non-conformance to this pattern is termed as an <strong class="calibre3">anomaly</strong>, and therefore as a fraudulent <strong class="calibre3">transaction</strong>. The following figure is an illustration showing anomaly detection in a two-dimensional space:</p>
<p class="CDPAlignCenter1"><img class="aligncenter81" src="assets/a74dd4da-4def-42ae-aa44-3d2cf811cb62.png"/></p>
<div class="packtfigref">Anomaly detection illustrated in 2D space</div>
<p class="mce-root">A simple example of an anomaly is the identification of data points that are too far from the mean (standard deviation) in a time series. The following figure is an illustration displaying the data points that are identified as anomalies in a time series:</p>
<p class="CDPAlignCenter1"><img class="aligncenter82" src="assets/9a73590b-e9ae-403e-86b8-b13ce39d2a66.png"/></p>
<div class="packtfigref">Anomaly in time series—identified through standard deviation</div>
<p class="mce-root">In this chapter, we will focus our efforts on a type of unsupervised deep learning application known as <strong class="calibre3">AEs</strong>. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Autoencoders explained</h1>
                </header>
            
            <article>
                
<p class="mce-root"><strong class="calibre3">Autoencoders</strong> (<strong class="calibre3">AEs</strong>) are neural networks that are of a feedforward and non-recurrent type. They aim to copy the given inputs to the outputs. An AE works by compressing the input into a lower dimensional summary. This summary is often referred as latent space representation. An AE attempts to reconstruct the output from the latent space representation. An <strong class="calibre3">Encoder</strong>, a <strong class="calibre3">Latent Space Representation</strong>, and a <strong class="calibre3">Decoder</strong> are the three parts that make up the AEs. The following figure is an illustration showing the application of an AE on a sample picked from <span class="calibre4">the </span>MNIST dataset:</p>
<p class="CDPAlignCenter1"><img class="aligncenter83" src="assets/1ec6a118-78cf-4d2c-9747-e56c5f0a31fb.png"/></p>
<div class="packtfigref">Application of AE on MNIST dataset sample</div>
<p class="mce-root">The encoder and decoder components of AEs are fully-connected feedforward networks. The number of neurons in a latent space representation is a hyperparameter that needs to be passed as part of building the AE. The number of neurons or nodes that is decided in the latent semantic space dictates the amount of compression that is attained while compressing the actual input image into a latent space representation. The general architecture of an AE is shown in the following figure:</p>
<p class="CDPAlignCenter1"><img class="aligncenter84" src="assets/bfd126a4-2ff5-4855-860e-3fbf58cf59e0.png"/></p>
<div class="packtfigref">General architecture of a AE</div>
<p class="mce-root">The given input first passes through an <strong class="calibre3">Encoder</strong>, which is a fully-connected <strong class="calibre3">artificial neural network</strong> (<strong class="calibre3">ANN</strong>). The <strong class="calibre3">Encoder</strong> acts upon the <strong class="calibre3">Input</strong> and reduces its dimensions, as specified in the hyperparameter. The <strong class="calibre3">Decoder</strong> is another fully-connected ANN that picks up this reduced <strong class="calibre3">Input</strong> (latent space representation) and then reconstructs the <strong class="calibre3">Output</strong>. The goal is to get the <strong class="calibre3">Output</strong> identical to that of the <strong class="calibre3">Input</strong>. In general, the architectures of the <strong class="calibre3">Encoder</strong> and the <strong class="calibre3">Decoder</strong> are mirror images. Although there is no such requirement that mandates that the <strong class="calibre3">Encoder</strong> and <strong class="calibre3">Decoder</strong> architectures should be the same, it is generally practiced that way. In fact, the only requirement of the AE is to obtain identical output from that of the given input. Anything in between can be customized to the whims and fancies of the individual building the AE.</p>
<p class="mce-root">Mathematically, <span class="calibre4">the </span>encoder can be represented as:</p>
<p class="CDPAlignCenter1"><sub class="calibre40"><img class="fm-editor-equation7" src="assets/f0867ffa-839a-4d32-b873-572ef7961eb2.png"/></sub></p>
<p class="mce-root">where <em class="calibre15">x</em> is the input and <em class="calibre15">h</em> is the function that acts on the input to represent it in a concise summary format. A decoder, on the other hand, can be represented as:</p>
<p class="CDPAlignCenter1"><sub class="calibre40"><img class="fm-editor-equation8" src="assets/f8c2a45f-0bf3-4960-bc5b-5d66df7ad3a2.png"/>.</sub></p>
<p class="mce-root">While the expectation is to obtain <img class="fm-editor-equation9" src="assets/7eed3d3e-b794-4999-a444-e13c99a809a8.png"/>, this is not always the case as the reconstruction is done from a compact summary representation; therefore, there is occurrence of certain error. The error <em class="calibre15">e</em> is computed from the original input <em class="calibre15">x</em> and reconstructed output <em class="calibre15">r</em>, <img class="fm-editor-equation10" src="assets/71b0ef36-ab8e-44a8-9243-cfb52997e5e1.png"/> .</p>
<p class="mce-root">The AE network then learns by reducing the <strong class="calibre3">Mean Squared Error</strong> (<strong class="calibre3">MSE</strong>), and the error is propagated back to the hidden layers for adjustment. The weights of <span class="calibre4">the </span>decoder and encoder are transposes of each other, which makes it faster to learn training parameters. The mirrored architectures of <span class="calibre4">the </span>encoder and decoder make it possible to learn the training parameters faster. In different architectures, the weights cannot be simply transposed; therefore, the computation time will increase. This is the reason for keeping the mirrored architectures for <span class="calibre4">the </span>encoder and decoder.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Types of AEs based on hidden layers</h1>
                </header>
            
            <article>
                
<p class="mce-root">Based on the size of the hidden layer, AEs can be classified into two types, <strong class="calibre3">undercomplete AEs</strong> and <strong class="calibre3">overcomplete AEs</strong>:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Undercomplete AE</strong>: If the AE simply learns to copy the input to <span>the </span>output, then it is not useful. The idea is to produce a concise representation as the output of <span>the </span>encoder, and this concise representation should consist of the most useful features of the input. The amount of conciseness achieved by the input layer is governed by the number of neurons or nodes that we use in the latent space representation. This can be set as a parameter while building the AE. If the number of neurons is set to fewer dimensions than that of the input features, then the AE is forced to learn most of the key features of the input data. The architecture where the number of neurons in latent space is less than that of input dimensions is called an undercomplete AE.</li>
<li class="calibre10"><strong class="calibre1">Overcomplete AE</strong>: It is possible to represent the number of neurons in latent space as equal to or more than that of the input dimensions. This kind of architecture is termed an overcomplete AE.  In this case, the AE does not learn anything and simply copies the input to the latent space, which in turn is propagated through to the decoder.</li>
</ul>
<p class="mce-root">Apart from the number of neurons in the latent space, the following are some of the other parameters that can be used in an AE architecture:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Number of layers in the encoder and decoder</strong>: The depth of the encoder and decoder can be set to any number. Generally, in a mirrored architecture of encoder and decoder, the number of layers is set as the same number. The last figure is an illustration showing the AE with two layers, excluding the input and output, in both the encoder and decoder.</li>
<li class="calibre10"><strong class="calibre1">Number of neurons per layer in encoder and decoder</strong>: The number of neurons decreases with each layer in an encoder and it increases with each layer in a decoder. The neurons in layers of encoders and decoders are symmetric.</li>
<li class="calibre10"><strong class="calibre1">Loss function</strong>: Loss functions such as MSE or cross-entropy are used by AEs to learn the weights during backpropagation. If the input is in the range of (0,1), then cross-entropy is used as metric, otherwise MSE is used.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Types of AEs based on restrictions</h1>
                </header>
            
            <article>
                
<p class="mce-root">Based on the restrictions imposed on the loss, AEs can be grouped into the following types:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Plain Vanilla AEs</strong>: This is the simplest AE architecture possible, with a fully-connected neural layer as the encoder and decoder.</li>
<li class="calibre10"><strong class="calibre1">Sparse AEs</strong><span>: Sparse AEs are an alternative method for introducing an information bottleneck, without requiring a reduction in the number of nodes in our hidden layers. Rather than preferring an undercomplete AE, the loss function is constructed in a way that it penalizes the activations within a layer. For any given observation, the network is encouraged to learn encoding and decoding, which only relies on activating a small number of neurons.</span></li>
<li class="calibre10"><strong class="calibre1">Denoising AEs</strong><span>: This is a type of overcomplete AE that experiences the risk of learning the <strong class="calibre1">identity function</strong> or <strong class="calibre1">null function</strong>. Essentially, the AE learns the output that is equal to the input, therefore making the AE useless. </span>Denoising AEs avoid this problem of learning the identity function by randomly initializing some of the inputs to 0. During the computation of <span>the </span>loss function, the noise-induced input is not considered; therefore, the network still learns the correct weights without the risk of learning the identity function. At the same time, the AE is trained to learn to reconstruct the output, even from the corrupted input.</li>
</ul>
<p class="calibre23">The following figure is a example of denoising AEs on sample images from <span class="calibre4">the </span>MNIST dataset:</p>
<p class="CDPAlignCenter1"><img class="aligncenter85" src="assets/d7a07b41-c689-4e55-a083-f06fe8654b83.png"/></p>
<div class="packtfigref">Application of denoising AEs on MNIST samples</div>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Convolutional AEs</strong>: When dealing with images as inputs, one can use convolutional layers as part of the encoder and decoder networks. Such kinds of AEs that use convolutional layers are termed <strong class="calibre1">convolutional AEs</strong>. The following figure is an illustration showing the use of convolutions in AEs:</li>
</ul>
<p class="CDPAlignCenter1"><img src="assets/cad4e496-083e-4442-9e06-9dfba7e17d0c.png" class="calibre41"/></p>
<div class="packtfigref">Convolutional AEs</div>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Stacked AEs</strong><span><span>: Stacked AEs are ones that have multiple layers in the encoder as well as the decoder. You can refer to the general</span> architecture<span> of an AE as an example illustration of a stacked AE architecture, with the encoder and decoder having two layers (excluding the input and output layers).</span></span>
<ul class="calibre38">
<li class="calibre10"><strong class="calibre1">Variational AEs</strong><span>: A <strong class="calibre1">variational AE</strong> (<strong class="calibre1">VAE</strong>), rather than building an encoder that outputs a singl</span></li>
</ul>
</li>
<li class="calibre10"><span>e value to describe each latent state attribute, describes a probability distribution for each latent attribute. This makes it possible to design complex generative models of data and also generate fictional celebrity images and digital artwork. The following figure is an illustration depicting the representation of data in VAEs:</span></li>
</ul>
<p class="CDPAlignCenter1"><span class="calibre4"><img src="assets/f0cf2cf0-7185-44d1-a669-4a7522e025b3.png" class="calibre42"/><br class="calibre5"/></span></p>
<p class="calibre23">In a VAE, the encoder model is sometimes referred to as the recognition model, whereas the decoder model is sometimes referred to as the generative model. The encoder outputs a range of statistical distributions for the latent features. These features are randomly sampled and used by <span class="calibre4">the </span>decoder to reconstruct the input. For any sampling of the latent distributions, the decoder is expected to be able to accurately reconstruct the input. Thus, values that are nearby to one another in latent space should correspond with very similar reconstructions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applications of AEs</h1>
                </header>
            
            <article>
                
<p class="mce-root">The following are some of the practical applications where AEs may be used:</p>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Image coloring</strong>: Given a grayscale image as input, AEs can auto color the image and return the colored image as output.</li>
<li class="calibre10"><strong class="calibre1">Noise removal</strong><span>: Denoising AEs are able to remove noise from images and reconstruct images without noise. Tasks such as watermark removal from videos and images can be accomplished.</span></li>
<li class="calibre10"><strong class="calibre1">Dimensionality reduction</strong><span>: AEs represent the input data in a compressed form, but with a focus on key features alone. Therefore, things like images can be represented with reduced pixels, without much loss of information during image reconstruction.</span></li>
<li class="calibre10"><strong class="calibre1">Image search</strong>: This is used to identify similar images based on a given input.</li>
</ul>
<ul class="calibre9">
<li class="calibre10"><strong class="calibre1">Information retrieval</strong>: When retrieving information from a corpus, AEs may be used to group together all the documents that belong to a given input.</li>
<li class="calibre10"><strong class="calibre1">Topic modeling</strong>: Variational AEs are used to approximate the posterior distribution, and it has become a promising alternative for inferring latent topic distributions of text documents.</li>
</ul>
<p class="mce-root"><span class="calibre4">We have covered the fundamentals that are needed for us to understand AEs and their applications. Let us understand, at a high level, the solution we are going to employ using AEs on the credit card fraud detection problem.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The credit card fraud dataset</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">Generally in a fraud dataset, we have sufficient data for the negative class (non-fraud/genuine transactions) and very few or no data for the positive class (fraudulent transactions). This is termed a <strong class="calibre3">class imbalance problem</strong> in the ML world. We train an AE on the non-fraud data and learn features using the encoder. The decoder is then used to compute the reconstruction error on the training set to find a threshold. This threshold will be used on the unseen data (test dataset or otherwise). We use the threshold to identify those test instances whose values are greater than the threshold as fraud instances.</span></p>
<p class="mce-root">For the project in this chapter, we will be using a dataset that is sourced from this URL: <a href="https://essentials.togaware.com/data/" class="calibre8">https://essentials.togaware.com/data/</a>. This is a public dataset of credit card transactions. This dataset is originally made available through the research paper <em class="calibre15">Calibrating Probability with Undersampling for Unbalanced Classification</em>, A. Dal Pozzolo, O. Caelen, R. A Johnson and G. Bontempi, IEEE <strong class="calibre3">Symposium Series on Computational Intelligence</strong> (<strong class="calibre3">SSCI</strong>), Cape Town, South Africa, 2015. The dataset is also available at this URL: <a href="http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.Rdata" class="calibre8">http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.Rdata</a>. The dataset was collected and analyzed during a research collaboration of Worldline and the Machine Learning Group (<a href="http://mlg.ulb.ac.be/" class="calibre8">http://mlg.ulb.ac.be</a>) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection.</p>
<p class="mce-root">The following are the characteristics of the dataset:</p>
<ul class="calibre9">
<li class="calibre10">The paper made the dataset available as an Rdata file. There is a CSV converted version of this dataset available on Kaggle as well as other sites.</li>
<li class="calibre10">It contains transactions made by credit cards in September 2013 by European cardholders.</li>
<li class="calibre10">The transactions occurred on two days are recorded and is presented as the dataset.</li>
</ul>
<ul class="calibre9">
<li class="calibre10">There are a total of 284,807 transactions in the dataset.</li>
<li class="calibre10">The dataset suffers from a severe class imbalance problem. Only 0.172% of all transactions are fraudulent transactions (492 fraudulent transactions).</li>
<li class="calibre10">There are a total thirty features in the dataset, namely <kbd class="calibre11">V1</kbd>, <kbd class="calibre11">V2</kbd>, ...,<kbd class="calibre11">V28</kbd>, <kbd class="calibre11">Time</kbd>, and <kbd class="calibre11">Amount</kbd>.</li>
<li class="calibre10">The variables <kbd class="calibre11">V1</kbd>, <kbd class="calibre11">V2</kbd>, ...,<kbd class="calibre11">V28</kbd> are the principal components obtained with PCA from <span>the </span>original set of variables.</li>
<li class="calibre10">Due to confidentiality, the original set of variables that yielded the principal components are not revealed.</li>
<li class="calibre10">The<span> <kbd class="calibre11">Time</kbd></span> feature contains the seconds elapsed between each transaction and the first transaction in the dataset.</li>
<li class="calibre10">The <kbd class="calibre11"><span>Amount</span></kbd> feature is the transaction amount.</li>
<li class="calibre10">The dependent variable is named <kbd class="calibre11">Class</kbd>. The fraudulent transactions are represented as 1 in the class and genuine transactions are represented as 0.</li>
</ul>
<p class="mce-root">We <span class="calibre4">will now jump into using AEs for the credit card fraud detection.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building AEs with the H2O library in R</h1>
                </header>
            
            <article>
                
<p class="mce-root">We will be using <span class="calibre4">the </span>AE implementation available in H2O for our project. H2O is a fully open source, distributed, in-memory ML platform with linear scalability. It offers parallelized implementations of some of the most widely used ML algorithms. It supports an easy to use, unsupervised, and non-linear AE as part of its deep learning model. The DL AE of H2O is based on the multilayer neural net architecture, where the entire network is trained together, instead of being stacked layer by layer.</p>
<p class="mce-root">The <kbd class="calibre11">h2o</kbd> package can be installed in R with the following command:</p>
<pre class="calibre16"><strong class="calibre1">install.packages("h2o")</strong></pre>
<div class="packtinfobox">Additional details on the installation and dependencies of H2O in R are available at this URL: <a href="https://cran.r-project.org/web/packages/h2o/index.html" class="calibre39">https://cran.r-project.org/web/packages/h2o/index.html</a>.</div>
<p class="mce-root">Once the package is installed successfully, the functions offered by the <kbd class="calibre11">h2o</kbd> package, including <span class="calibre4">the </span>AE, can simply <span class="calibre4">be</span><span class="calibre4"> </span><span class="calibre4">used by including the following line in R code:</span></p>
<pre class="calibre16">library(h2o)</pre>
<p class="mce-root">This is all we need to do prior to coding our credit card fraud detection system with <span class="calibre4">the </span>AE. Without waiting any longer, let's start building our code to explore and prepare our dataset, as well as to implement the AE that captures fraudulent credit card transactions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Autoencoder code implementation for credit card fraud detection</h1>
                </header>
            
            <article>
                
<p class="mce-root">As usual, like all other projects, let's first load the data into an R dataframe and then perform EDA to understand the dataset better. Please note the inclusion of <kbd class="calibre11">h2o</kbd> as well as the <kbd class="calibre11">doParallel</kbd> library in the code. These inclusions enable us to use the AE that is part of the <kbd class="calibre11">h2o</kbd> library, as well as to utilize the multiple CPU cores that are present in the laptop/desktop as follows:</p>
<pre class="calibre16"># including the required libraries<br class="title-page-name"/>library(tidyverse)<br class="title-page-name"/>library(h2o)<br class="title-page-name"/>library(rio)<br class="title-page-name"/>library(doParallel)<br class="title-page-name"/>library(viridis)<br class="title-page-name"/>library(RColorBrewer)<br class="title-page-name"/>library(ggthemes)<br class="title-page-name"/>library(knitr)<br class="title-page-name"/>library(caret)<br class="title-page-name"/>library(caretEnsemble)<br class="title-page-name"/>library(plotly)<br class="title-page-name"/>library(lime)<br class="title-page-name"/>library(plotROC)<br class="title-page-name"/>library(pROC)</pre>
<p class="mce-root">Initializing the H2O cluster in localhost under the port <kbd class="calibre11">54321</kbd>. The <kbd class="calibre11">nthreads</kbd> defines the number of thread pools to be used, this is close to the number of cpus to be used. In our case, we are saying use all CPUs, we are also specifying the maximum memory to use by H2O cluster as <kbd class="calibre11">8G</kbd>:</p>
<pre class="calibre16">localH2O = h2o.init(ip = 'localhost', port = 54321, nthreads = -1,max_mem_size = "8G")<br class="title-page-name"/># Detecting the available number of cores<br class="title-page-name"/>no_cores &lt;- detectCores() - 1<br class="title-page-name"/># utilizing all available cores<br class="title-page-name"/>cl&lt;-makeCluster(no_cores)<br class="title-page-name"/>registerDoParallel(cl)</pre>
<p class="mce-root">You will get a similar output to that shown in the following code block:</p>
<pre class="calibre16">H2O is not running yet, starting it now...<br class="title-page-name"/>Note:  In case of errors look at the following log files:<br class="title-page-name"/>    /tmp/RtmpKZvQ3m/h2o_sunil_started_from_r.out<br class="title-page-name"/>    /tmp/RtmpKZvQ3m/h2o_sunil_started_from_r.err<br class="title-page-name"/>java version "1.8.0_191"<br class="title-page-name"/>Java(TM) SE Runtime Environment (build 1.8.0_191-b12)<br class="title-page-name"/>Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)<br class="title-page-name"/>Starting H2O JVM and connecting: ..... Connection successful!<br class="title-page-name"/>R is connected to the H2O cluster:<br class="title-page-name"/>    H2O cluster uptime:         4 seconds 583 milliseconds<br class="title-page-name"/>    H2O cluster timezone:       Asia/Kolkata<br class="title-page-name"/>    H2O data parsing timezone:  UTC<br class="title-page-name"/>    H2O cluster version:        3.20.0.8<br class="title-page-name"/>    H2O cluster version age:    2 months and 27 days <br class="title-page-name"/>    H2O cluster name:           H2O_started_from_R_sunil_jgw200<br class="title-page-name"/>    H2O cluster total nodes:    1<br class="title-page-name"/>    H2O cluster total memory:   7.11 GB<br class="title-page-name"/>    H2O cluster total cores:    4<br class="title-page-name"/>    H2O cluster allowed cores:  4<br class="title-page-name"/>    H2O cluster healthy:        TRUE<br class="title-page-name"/>    H2O Connection ip:          localhost<br class="title-page-name"/>    H2O Connection port:        54321<br class="title-page-name"/>    H2O Connection proxy:       NA<br class="title-page-name"/>    H2O Internal Security:      FALSE<br class="title-page-name"/>    H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4<br class="title-page-name"/>    R Version:                  R version 3.5.1 (2018-07-02)</pre>
<p class="mce-root">Now, to set the working directory of the data file location, load Rdata and read it into the dataframe, and view the dataframe using the following code:</p>
<pre class="calibre16"># setting the working directory where the data file is location<br class="title-page-name"/>setwd("/home/sunil/Desktop/book/chapter 7")<br class="title-page-name"/># loading the Rdata file and reading it into the dataframe called cc_fraud<br class="title-page-name"/>cc_fraud&lt;-get(load("creditcard.Rdata"))<br class="title-page-name"/># performing basic EDA on the dataset<br class="title-page-name"/># Viewing the dataframe to confirm successful load of the dataset<br class="title-page-name"/>View(cc_fraud)</pre>
<p class="mce-root">The will give the following output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter86" src="assets/3e302731-40c7-43f1-9350-8c3cb93e9608.png"/></p>
<p class="mce-root">Let's now print the dataframe structure using the following code:</p>
<pre class="calibre16">print(str(cc_fraud))</pre>
<p class="mce-root">This will give the following output:</p>
<pre class="calibre16">'data.frame':     284807 obs. of  31 variables:<br class="title-page-name"/> $ Time  : num  0 0 1 1 2 2 4 7 7 9 ...<br class="title-page-name"/> $ V1    : num  -1.36 1.192 -1.358 -0.966 -1.158 ...<br class="title-page-name"/> $ V2    : num  -0.0728 0.2662 -1.3402 -0.1852 0.8777 ...<br class="title-page-name"/> $ V3    : num  2.536 0.166 1.773 1.793 1.549 ...<br class="title-page-name"/> $ V4    : num  1.378 0.448 0.38 -0.863 0.403 ...<br class="title-page-name"/> $ V5    : num  -0.3383 0.06 -0.5032 -0.0103 -0.4072 ...<br class="title-page-name"/> $ V6    : num  0.4624 -0.0824 1.8005 1.2472 0.0959 ...<br class="title-page-name"/> $ V7    : num  0.2396 -0.0788 0.7915 0.2376 0.5929 ...<br class="title-page-name"/> $ V8    : num  0.0987 0.0851 0.2477 0.3774 -0.2705 ...<br class="title-page-name"/> $ V9    : num  0.364 -0.255 -1.515 -1.387 0.818 ...<br class="title-page-name"/> $ V10   : num  0.0908 -0.167 0.2076 -0.055 0.7531 ...<br class="title-page-name"/> $ V11   : num  -0.552 1.613 0.625 -0.226 -0.823 ...<br class="title-page-name"/> $ V12   : num  -0.6178 1.0652 0.0661 0.1782 0.5382 ...<br class="title-page-name"/> $ V13   : num  -0.991 0.489 0.717 0.508 1.346 ...<br class="title-page-name"/> $ V14   : num  -0.311 -0.144 -0.166 -0.288 -1.12 ...<br class="title-page-name"/> $ V15   : num  1.468 0.636 2.346 -0.631 0.175 ...<br class="title-page-name"/> $ V16   : num  -0.47 0.464 -2.89 -1.06 -0.451 ...<br class="title-page-name"/> $ V17   : num  0.208 -0.115 1.11 -0.684 -0.237 ...<br class="title-page-name"/> $ V18   : num  0.0258 -0.1834 -0.1214 1.9658 -0.0382 ...<br class="title-page-name"/> $ V19   : num  0.404 -0.146 -2.262 -1.233 0.803 ...<br class="title-page-name"/> $ V20   : num  0.2514 -0.0691 0.525 -0.208 0.4085 ...<br class="title-page-name"/> $ V21   : num  -0.01831 -0.22578 0.248 -0.1083 -0.00943 ...<br class="title-page-name"/> $ V22   : num  0.27784 -0.63867 0.77168 0.00527 0.79828 ...<br class="title-page-name"/> $ V23   : num  -0.11 0.101 0.909 -0.19 -0.137 ...<br class="title-page-name"/> $ V24   : num  0.0669 -0.3398 -0.6893 -1.1756 0.1413 ...<br class="title-page-name"/> $ V25   : num  0.129 0.167 -0.328 0.647 -0.206 ...<br class="title-page-name"/> $ V26   : num  -0.189 0.126 -0.139 -0.222 0.502 ...<br class="title-page-name"/> $ V27   : num  0.13356 -0.00898 -0.05535 0.06272 0.21942 ...<br class="title-page-name"/> $ V28   : num  -0.0211 0.0147 -0.0598 0.0615 0.2152 ...<br class="title-page-name"/> $ Amount: num  149.62 2.69 378.66 123.5 69.99 ...<br class="title-page-name"/> $ Class : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...</pre>
<p class="mce-root">Now, to view the class distribution, use the following code:</p>
<pre class="calibre16">print(table(cc_fraud$Class))</pre>
<p class="mce-root">You will get the following output:</p>
<pre class="calibre16">     0      1<br class="title-page-name"/>284315    492</pre>
<p class="mce-root">To view the relationship between the <kbd class="calibre11">V1</kbd> and <kbd class="calibre11">Class</kbd><span class="calibre4"> </span><span class="calibre4">variables</span><span class="calibre4">, use the following code:</span></p>
<pre class="calibre16"># Printing the Histograms for Multivariate analysis<br class="title-page-name"/>theme_set(theme_economist_white())<br class="title-page-name"/># visualization showing the relationship between variable V1 and the class<br class="title-page-name"/>ggplot(cc_fraud,aes(x="",y=V1,fill=Class))+geom_boxplot()+labs(x="V1",y="")</pre>
<p class="mce-root">This will give the following output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter87" src="assets/75981835-0fdf-4ffd-807e-6cceab13ec32.png"/></p>
<p class="mce-root">To visualize the distribution of transaction amounts with respect to class, use the following code:</p>
<pre class="calibre16"># visualization showing the distribution of transaction amount with<br class="title-page-name"/># respect to the class, it may be observed that the amount are discretized<br class="title-page-name"/># into 50 bins for plotting purposes<br class="title-page-name"/>ggplot(cc_fraud,aes(x = Amount)) + geom_histogram(color = "#D53E4F", fill = "#D53E4F", bins = 50) + facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">This will give the following output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter88" src="assets/95ac410b-3790-435f-a980-d0f89f27af11.png"/></p>
<p class="mce-root">To visualize the distribution of transaction times with respect to class, use the following code:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x =Time,fill = Class))+ geom_histogram(bins = 30)+<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">This will give the following output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter89" src="assets/cc9a994e-1e30-440c-9f0e-80c79e7ae4ba.png"/></p>
<p class="mce-root">Use the following code to visualize the <kbd class="calibre11">V2</kbd> variable with respect to <kbd class="calibre11">Class</kbd>:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x =V2, fill=Class))+ geom_histogram(bins = 30)+<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">You will get the following as the output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter90" src="assets/1c891040-a5e6-4568-a669-bfa9307f150e.png"/></p>
<p class="mce-root">Use the following code to visualize <kbd class="calibre11">V3</kbd> with respect to <kbd class="calibre11">Class</kbd>:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x =V3, fill=Class))+ geom_histogram(bins = 30)+<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">The following graph is the resultant output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter91" src="assets/084bee5f-c39d-4cd7-a4ef-f3654ca44992.png"/></p>
<p class="mce-root">To visualize the <kbd class="calibre11">V3</kbd> variable with respect to <kbd class="calibre11">Class</kbd>, use the following code:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x =V4,fill=Class))+ geom_histogram(bins = 30)+<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root">The following graph is the resultant output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter92" src="assets/312d60a0-e11b-4ec9-ac1a-5b5a2fb77cc3.png"/></p>
<p class="mce-root">Use the following code to visualize the <kbd class="calibre11">V6</kbd> variable with respect to <kbd class="calibre11">Class</kbd>:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x=V6, fill=Class)) + geom_density(alpha=1/3) + scale_fill_hue()</pre>
<p class="mce-root">The following graph is the resultant output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter93" src="assets/0ec1dc19-0116-4bae-b1f4-72f520de15f8.png"/></p>
<p class="mce-root">Use the following code to visualize the <kbd class="calibre11">V7</kbd> <span class="calibre4">variable</span><span class="calibre4"> </span><span class="calibre4">with respect to</span> <kbd class="calibre11">Class</kbd><span class="calibre4">:</span></p>
<pre class="calibre16">ggplot(cc_fraud, aes(x=V7, fill=Class)) + geom_density(alpha=1/3) + scale_fill_hue()</pre>
<p class="mce-root">The following graph is the resultant output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter94" src="assets/9b97b5a5-1b06-4151-adde-1b85b632f657.png"/></p>
<p class="mce-root">Use the following code to visualize the <kbd class="calibre11">V8</kbd> variable with respect to <kbd class="calibre11">Class</kbd>:</p>
<pre class="calibre16">ggplot(cc_fraud, aes(x=V8, fill=Class)) + geom_density(alpha=1/3) + scale_fill_hue()</pre>
<p class="mce-root">The following graph is the resultant output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter95" src="assets/7c471bfc-a6ff-4867-96cc-30da7a810d47.png"/></p>
<p class="mce-root">To visualize the <kbd class="calibre11">V9</kbd> variable with respect to <kbd class="calibre11">Class</kbd>, use the following code:</p>
<pre class="calibre16"># visualizationshowing the V7 variable with respect to the class<br class="title-page-name"/>ggplot(cc_fraud, aes(x=V9, fill=Class)) + geom_density(alpha=1/3) + scale_fill_hue()</pre>
<p class="mce-root">The following graph is the resultant output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter96" src="assets/b82a52f6-7fe5-4983-b56f-9c9d92dfeed7.png"/></p>
<p class="mce-root">To visualize the <kbd class="calibre11">V10</kbd> <span class="calibre4">variable</span><span class="calibre4"> </span><span class="calibre4">with respect to</span> <kbd class="calibre11">Class</kbd><span class="calibre4">, use the following code:</span></p>
<pre class="calibre16"># observe we are plotting the data quantiles<br class="title-page-name"/>ggplot(cc_fraud, aes(x ="",y=V10, fill=Class))+ geom_violin(adjust = .5,draw_quantiles = c(0.25, 0.5, 0.75))+labs(x="V10",y="")</pre>
<p class="mce-root">The following graph is the resultant output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter97" src="assets/aeee5f93-f562-4bd6-944f-e2cfb1936b0c.png"/></p>
<p class="mce-root">From all the visualizations related to variables with respect to class, we can infer that most of the principal components are centered on <kbd class="calibre11">0</kbd>. Now, to plot the distribution of classes in the data, use the following code:</p>
<pre class="calibre16">cc_fraud %&gt;%<br class="title-page-name"/>  ggplot(aes(x = Class)) +<br class="title-page-name"/>  geom_bar(color = "chocolate", fill = "chocolate", width = 0.2) +<br class="title-page-name"/>  theme_bw()</pre>
<p class="mce-root">The following bar graph is the resultant output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter98" src="assets/1ab03c79-8eea-4c65-94a7-ba90deedae22.png"/></p>
<p class="mce-root">We observe that the distribution of classes is very imbalanced. The representation of <span class="calibre4">the </span>major class (non-fraudulent transactions, represented by <kbd class="calibre11">0</kbd>) in the dataset is too heavy when compared to <span class="calibre4">the </span>minority class (fraudulent transactions: <kbd class="calibre11">1</kbd>). In the traditional supervised ML way of dealing with this kind of problem, we would have treated the class imbalance problem with techniques such as <strong class="calibre3"><span class="calibre4">Synthetic Minority Over-Sampling Technique</span></strong> (<strong class="calibre3">SMORT</strong>). However, with AEs, we do not treat the class imbalance during data preprocessing; rather, we feed the data as is to the AE for learning. In fact, the AE is learning the thresholds and the characteristics of the data from the majority class; this is the reason we call it a one-class classification problem.</p>
<p class="mce-root">We will need to do some feature engineering prior to training our AE. Let's first focus on the <kbd class="calibre11">Time</kbd> variable in the data. Currently, it is in the seconds format, but we may better represent it as days. Run the following code to see the current form of time in the dataset:</p>
<pre class="calibre16">print(summary(cc_fraud$Time))</pre>
<p class="mce-root">You will get the following output:</p>
<pre class="calibre16">   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>      0   54202   84692   94814  139320  172792</pre>
<p class="mce-root">We know that there are 86,400 seconds in a given day (60 seconds per minute * 60 minutes per hour * 24 hours per day). We will convert the <kbd class="calibre11">Time</kbd> variable into <kbd class="calibre11">Day</kbd> by considering the value in <kbd class="calibre11">Time</kbd> and representing it as <kbd class="calibre11">day1</kbd> if the number of seconds is less than or equal to 86,400, and anything over 86,400 becomes <kbd class="calibre11">day2.</kbd> There are only two days possible, as we can see from the summary that the maximum value represented by the time variable is <kbd class="calibre11">172792</kbd> seconds:</p>
<pre class="calibre16"># creating a new variable called day based on the seconds <br class="title-page-name"/># represented in Time variable<br class="title-page-name"/> cc_fraud=cc_fraud %&gt;% mutate(Day = case_when(.$Time &gt; 3600 * 24 ~ "day2",.$Time &lt; 3600 * 24 ~ "day1"))<br class="title-page-name"/>#visualizing the dataset post creating the new variable<br class="title-page-name"/>View(cc_fraud%&gt;%head())</pre>
<p class="mce-root">The following is the resultant output of the first six rows after the conversion:</p>
<p class="CDPAlignCenter1"><img class="aligncenter99" src="assets/a810fdad-2a9b-4045-a5ba-92635cd881ac.png"/></p>
<p class="mce-root">Now, use the following code to view the last six rows:</p>
<pre class="calibre16">View(cc_fraud%&gt;%tail())</pre>
<p class="mce-root">The following is the resultant output of the last six rows after the conversion:</p>
<p class="CDPAlignCenter1"><img class="aligncenter100" src="assets/5506a84a-a119-421a-be3c-1284e371c32a.png"/></p>
<p class="mce-root">Now, let's print the distribution of transactions by the day in which the transaction falls, using the following code:</p>
<pre class="calibre16">print(table(cc_fraud[,"Day"]))</pre>
<p class="mce-root">You will get the following as the output:</p>
<pre class="calibre16">  day1   day2<br class="title-page-name"/>144786 140020</pre>
<p class="mce-root">Let's create a new variable, <kbd class="calibre11">Time_day</kbd>, based on the seconds represented in the <kbd class="calibre11">Time</kbd> variable, and summarize the <kbd class="calibre11">Time_day</kbd> variable with respect to <kbd class="calibre11">Day</kbd> using the following code:</p>
<pre class="calibre16">cc_fraud$Time_day &lt;- if_else(cc_fraud$Day == "day2", cc_fraud$Time - 86400, cc_fraud$Time)<br class="title-page-name"/>print(tapply(cc_fraud$Time_day,cc_fraud$Day,summary,simplify = FALSE))</pre>
<p class="mce-root">We get the following as the resultant output:</p>
<pre class="calibre16">$day1<br class="title-page-name"/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>      0   38432   54689   52948   70976   86398<br class="title-page-name"/><br class="title-page-name"/>$day2<br class="title-page-name"/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>      1   37843   53425   51705   68182   86392</pre>
<p class="mce-root">Use the following code the convert all character variables in the dataset to factors:</p>
<pre class="calibre16">cc_fraud&lt;-cc_fraud%&gt;%mutate_if(is.character,as.factor)</pre>
<p class="mce-root">We can further fine-tune the <kbd class="calibre11">Time_day</kbd> variable by converting the variable into a factor. The factors represents the time of day at which the transaction happened, for example, <kbd class="calibre11">morning</kbd>, <kbd class="calibre11">afternoon</kbd>, <kbd class="calibre11">evening</kbd>, and <kbd class="calibre11">night</kbd>. We can create a new variable called <kbd class="calibre11">Time_Group</kbd>, based on the various buckets of the day, using the following code:</p>
<pre class="calibre16">cc_fraud=cc_fraud %&gt;% <br class="title-page-name"/>  mutate(Time_Group = case_when(.$Time_day &lt;= 38138~ "morning" ,<br class="title-page-name"/>                                .$Time_day &lt;= 52327~  "afternoon",<br class="title-page-name"/>                                .$Time_day &lt;= 69580~"evening",<br class="title-page-name"/>                                .$Time_day &gt; 69580~"night"))<br class="title-page-name"/>#Visualizing the data post creating the new variable<br class="title-page-name"/>View(head(cc_fraud))</pre>
<p class="mce-root">The following is the resultant output of the first six rows:</p>
<p class="CDPAlignCenter1"><img class="alignnone1" src="assets/26eb4e24-39aa-4069-8b8b-b62b16d185af.png"/></p>
<p class="mce-root">Use the following code to view and confirm the last six rows:</p>
<pre class="calibre16">View(tail(cc_fraud))</pre>
<p class="mce-root">This will give the following output, and we see that we have successfully converted the data which represent the various time of the day:</p>
<p class="CDPAlignCenter1"><img class="aligncenter101" src="assets/4bf537f3-165f-47c8-a6b2-b04cd963ba4e.png"/></p>
<p class="mce-root">Take a look at the following code:</p>
<pre class="calibre16">#visualizing the transaction count by day<br class="title-page-name"/>cc_fraud %&gt;%drop_na()%&gt;%<br class="title-page-name"/>  ggplot(aes(x = Day)) +<br class="title-page-name"/>  geom_bar(fill = "chocolate",width = 0.3,color="chocolate") +<br class="title-page-name"/>  theme_economist_white()</pre>
<p class="mce-root">The preceding code will generate the following output:</p>
<p class="CDPAlignCenter1"><img class="aligncenter102" src="assets/8c44ad84-e7fe-4871-a9b6-b0a84d54b8d1.png"/></p>
<p class="mce-root">We can infer from the visualization that there is no difference in the count of transactions that happened on day 1 and day 2. Both remain close to 150,000 transactions. </p>
<p class="mce-root">Now we will convert the <kbd class="calibre11">Class</kbd> variable as a factor and then visualize the data by <kbd class="calibre11">Time_Group</kbd> variable using the following code:</p>
<pre class="calibre16">cc_fraud$Class &lt;- factor(cc_fraud$Class)<br class="title-page-name"/>cc_fraud %&gt;%drop_na()%&gt;%<br class="title-page-name"/>  ggplot(aes(x = Time_Group)) +<br class="title-page-name"/>  geom_bar(color = "#238B45", fill = "#238B45") +<br class="title-page-name"/>  theme_bw() +<br class="title-page-name"/>  facet_wrap( ~ Class, scales = "free", ncol = 2)</pre>
<p class="mce-root"><span class="calibre4">This will generate the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter103" src="assets/e186689d-e77c-4cde-b52d-5ed9c1d5707c.png"/></p>
<p class="mce-root">The inference obtained from this visualization is that the number of non-fraudulent transactions remains almost the same across all time periods of the day, whereas we see a huge rise in the number of fraudulent transactions during the morning <kbd class="calibre11">Time</kbd> group.</p>
<p class="mce-root">Let's do a last bit of exploration of the transaction amount with respect to class:</p>
<pre class="calibre16"># getting the summary of amount with respect to the class<br class="title-page-name"/>print(tapply(cc_fraud$Amount  ,cc_fraud$Class,summary))</pre>
<p class="mce-root"><span class="calibre4">The preceding code will generate the following output:</span></p>
<pre class="calibre16">$`0`<br class="title-page-name"/>    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.<br class="title-page-name"/>    0.00     5.65    22.00    88.29    77.05 25691.16<br class="title-page-name"/>$`1`<br class="title-page-name"/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br class="title-page-name"/>   0.00    1.00    9.25  122.21 105.89 2125.87</pre>
<p class="mce-root">One interesting insight from the summary is that the mean amount in fraudulent transactions is higher compared to genuine transactions. However, the maximum transaction amount that we see in fraudulent transactions is much lower than the genuine transactions. It can also be seen that genuine transactions have a higher median amount.</p>
<p class="mce-root">Now, let's convert our R dataframe to an H2O dataframe to apply the AE to it. This is a requirement in order to use the functions from the <kbd class="calibre11">h2o</kbd> library:</p>
<pre class="calibre16"># converting R dataframe to H2O dataframe<br class="title-page-name"/>cc_fraud_h2o &lt;- as.h2o(cc_fraud)<br class="title-page-name"/>#splitting the data into 60%, 20%, 20% chunks to use them as training,<br class="title-page-name"/>#vaidation and test datasets<br class="title-page-name"/>splits &lt;- h2o.splitFrame(cc_fraud_h2o,ratios = c(0.6, 0.2), seed = 148)  <br class="title-page-name"/># creating new train, validation and test h2o dataframes<br class="title-page-name"/>train &lt;- splits[[1]]<br class="title-page-name"/>validation &lt;- splits[[2]]<br class="title-page-name"/>test &lt;- splits[[3]]<br class="title-page-name"/># getting the target and features name in vectors<br class="title-page-name"/>target &lt;- "Class"<br class="title-page-name"/>features &lt;- setdiff(colnames(train), target)</pre>
<p class="mce-root">The <kbd class="calibre11">tanh</kbd> activation function is a rescaled and shifted logistic function. Other functions, such as ReLu and Maxout, are also provided by the <kbd class="calibre11">h2o</kbd> library and they can also be used.  In the first AE model, let's use the <kbd class="calibre11">tanh</kbd> activation function. This choice is arbitrary and other activation functions may also be tried as desired.</p>
<p class="mce-root">The <kbd class="calibre11">h2o.deeplearning</kbd> function has a parameter AE and this should be set to <kbd class="calibre11">TRUE</kbd> to train a AE model. Let's build our AE model now:</p>
<pre class="calibre16">model_one = h2o.deeplearning(x = features, training_frame = train,<br class="title-page-name"/>                             AE = TRUE,<br class="title-page-name"/>                             reproducible = TRUE,<br class="title-page-name"/>                             seed = 148,<br class="title-page-name"/>                             hidden = c(10,10,10), epochs = 100,<br class="title-page-name"/> activation = "Tanh",<br class="title-page-name"/>                             validation_frame = test)</pre>
<p class="mce-root">The preceding code generates the following output:</p>
<pre class="calibre16"> |===========================================================================================================================| 100%</pre>
<p class="mce-root">We will save the model so we do not have to retrain t again and again. Then load the model that is persisted on the disk and print the model to verify the AE learning using the following code:</p>
<pre class="calibre16">h2o.saveModel(model_one, path="model_one", force = TRUE)<br class="title-page-name"/>model_one&lt;-h2o.loadModel("/home/sunil/model_one/DeepLearning_model_R_1544970545051_1")<br class="title-page-name"/>print(model_one)</pre>
<p class="mce-root">This will generate the following output:</p>
<pre class="calibre16">Model Details:<br class="title-page-name"/>==============<br class="title-page-name"/>H2OAutoEncoderModel: deeplearning<br class="title-page-name"/>Model ID:  DeepLearning_model_R_1544970545051_1<br class="title-page-name"/>Status of Neuron Layers: auto-encoder, gaussian distribution, Quadratic loss, 944 weights/biases, 20.1 KB, 2,739,472 training samples, mini-batch size 1<br class="title-page-name"/>  layer units  type dropout       l1       l2 mean_rate rate_rms momentum mean_weight weight_rms mean_bias bias_rms<br class="title-page-name"/>1     1    34 Input  0.00 %       NA       NA        NA       NA       NA          NA         NA        NA       NA<br class="title-page-name"/>2     2    10  Tanh  0.00 % 0.000000 0.000000  0.610547 0.305915 0.000000   -0.000347   0.309377 -0.028166 0.148318<br class="title-page-name"/>3     3    10  Tanh  0.00 % 0.000000 0.000000  0.181705 0.103598 0.000000    0.022774   0.262611 -0.056455 0.099918<br class="title-page-name"/>4     4    10  Tanh  0.00 % 0.000000 0.000000  0.133090 0.079663 0.000000    0.000808   0.337259  0.032588 0.101952<br class="title-page-name"/>5     5    34  Tanh      NA 0.000000 0.000000  0.116252 0.129859 0.000000    0.006941   0.357547  0.167973 0.688510<br class="title-page-name"/>H2OAutoEncoderMetrics: deeplearning<br class="title-page-name"/><strong class="calibre1"> Reported on training data.<br class="title-page-name"/></strong> Training Set Metrics:<br class="title-page-name"/>=====================<br class="title-page-name"/>MSE: (Extract with `h2o.mse`) 0.0003654009<br class="title-page-name"/>RMSE: (Extract with `h2o.rmse`) 0.01911546<br class="title-page-name"/>H2OAutoEncoderMetrics: deeplearning<br class="title-page-name"/><strong class="calibre1"> Reported on validation data.<br class="title-page-name"/></strong> Validation Set Metrics:<br class="title-page-name"/>=====================<br class="title-page-name"/>MSE: (Extract with `h2o.mse`) 0.0003508435<br class="title-page-name"/>RMSE: (Extract with `h2o.rmse`) 0.01873082</pre>
<p class="mce-root">We will now make predictions on test dataset using the AE model that is built, using the following code:</p>
<pre class="calibre16">test_autoencoder &lt;- h2o.predict(model_one, test)</pre>
<p class="mce-root"><span class="calibre4">This will generate the following output:</span></p>
<pre class="calibre16">|===========================================================================================================================| 100%</pre>
<p class="mce-root">It is possible to visualize the encoder representing the data in a conscious manner in the inner layers through the <kbd class="calibre11">h2o.deepfeatures</kbd> function. Let's try visualizing the reduced data in a second layer:</p>
<pre class="calibre16">train_features &lt;- h2o.deepfeatures(model_one, train, layer = 2) %&gt;%<br class="title-page-name"/>  as.data.frame() %&gt;%<br class="title-page-name"/>  mutate(Class = as.vector(train[, 31]))<br class="title-page-name"/># printing the reduced data represented in layer2<br class="title-page-name"/>print(train_features%&gt;%head(3))</pre>
<p class="mce-root"><span class="calibre4">The preceding code will generate the following output:</span></p>
<pre class="calibre16">DF.L2.C1  DF.L2.C2     DF.L2.C3    DF.L2.C4   DF.L2.C5 <br class="title-page-name"/>-0.12899115 0.1312075  0.115971952 -0.12997648 0.23081912<br class="title-page-name"/>-0.10437942 0.1832959  0.006427409 -0.08018725 0.05575977<br class="title-page-name"/>-0.07135827 0.1705700 -0.023808057 -0.11383244 0.10800857<br class="title-page-name"/>DF.L2.C6   DF.L2.C7    DF.L2.C8  DF.L2.C9  DF.L2.C10  Class0.1791547 0.10325721  0.05589069 0.5607497 -0.9038150     0<br class="title-page-name"/>0.1588236 0.11009450 -0.04071038 0.5895413 -0.8949729     0<br class="title-page-name"/>0.1676358 0.10703990 -0.03263755 0.5762191 -0.8989759     0</pre>
<p class="mce-root">Let us now plot the data of <kbd class="calibre11"><span>DF.L2.C1</span></kbd> with respect to <kbd class="calibre11"><span>DF.L2.C2</span></kbd> to verify if the encoder has detected the fraudulent transactions, using the following code:</p>
<pre class="calibre16">ggplot(train_features, aes(x = DF.L2.C1, y = DF.L2.C2, color = Class)) +<br class="title-page-name"/>  geom_point(alpha = 0.1,size=1.5)+theme_bw()+<br class="title-page-name"/>  scale_fill_brewer(palette = "Accent")</pre>
<p class="mce-root"><span class="calibre4">This will generate the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter104" src="assets/1d57f16e-1bf6-47eb-94e4-83557dbb69eb.png"/></p>
<p class="mce-root">Again we plot the data of <kbd class="calibre11"><span>DF.L2.C3</span></kbd> with respect to <kbd class="calibre11"><span>DF.L2.C4</span></kbd> to verify the if the encoder have detected any fraud transaction, using the following code:</p>
<pre class="calibre16">ggplot(train_features, aes(x = DF.L2.C3, y = DF.L2.C4, color = Class)) +<br class="title-page-name"/>  geom_point(alpha = 0.1,size=1.5)+theme_bw()+<br class="title-page-name"/>  scale_fill_brewer(palette = "Accent")</pre>
<p class="mce-root"><span class="calibre4">The preceding code will generate the following output:</span></p>
<p class="CDPAlignCenter1"><img class="aligncenter105" src="assets/3bcd6f63-b386-415a-a650-87cf67b96e22.png"/></p>
<p class="mce-root">We see from the two visualizations that the fraudulent transactions are indeed detected by the dimensionality reduction approach with our AE model. Those few scattered dots (represented by <kbd class="calibre11">1</kbd>) depicts the fraud transactions that are detected. We can also train a new model with the other hidden layers, using our first model. This results in 10 columns, since the third layer has 10 nodes. We are just attempting to slice out one layer where some level of reduction was done and use that to build a new model:</p>
<pre class="calibre16"># let's consider the third hidden layer. This is again a random choice<br class="title-page-name"/># in fact we could have taken any layer among the 10 inner layers<br class="title-page-name"/>train_features &lt;- h2o.deepfeatures(model_one, validation, layer = 3) %&gt;%<br class="title-page-name"/>  as.data.frame() %&gt;%<br class="title-page-name"/>  mutate(Class = as.factor(as.vector(validation[, 31]))) %&gt;%<br class="title-page-name"/>  as.h2o()</pre>
<p class="mce-root"><span class="calibre4">The preceding code will generate the following output:</span></p>
<pre class="calibre16">|===========================================================================================================================| 100% |===========================================================================================================================| 100%</pre>
<p class="mce-root">As we can see, the training models and data are successfully created. We will now go ahead <span class="calibre4">and train the new model, save it and the print it. First, we will get the feature names from the sliced encoder layer:</span></p>
<pre class="calibre16">features_two &lt;- setdiff(colnames(train_features), target)</pre>
<p class="mce-root">Then we will training a new model:</p>
<pre class="calibre16">model_two &lt;- h2o.deeplearning(y = target,<br class="title-page-name"/>                              x = features_two,<br class="title-page-name"/>                              training_frame = train_features,<br class="title-page-name"/>                              reproducible = TRUE,<br class="title-page-name"/>                              balance_classes = TRUE,<br class="title-page-name"/>                              ignore_const_cols = FALSE,<br class="title-page-name"/>                              seed = 148,<br class="title-page-name"/>                              hidden = c(10, 5, 10),<br class="title-page-name"/>                              epochs = 100,<br class="title-page-name"/>                              activation = "Tanh")</pre>
<p class="mce-root">We will then save the model to avoid retraining again, then retrieve the model and print it using the following code:</p>
<pre class="calibre16">h2o.saveModel(model_two, path="model_two", force = TRUE)<br class="title-page-name"/>model_two &lt;- h2o.loadModel("/home/sunil/model_two/DeepLearning_model_R_1544970545051_2")<br class="title-page-name"/>print(model_two)</pre>
<p class="mce-root"><span class="calibre4">This will generate the following output:</span></p>
<pre class="calibre16">Model Details:<br class="title-page-name"/>==============<br class="title-page-name"/>H2OBinomialModel: deeplearning<br class="title-page-name"/>Model ID:  DeepLearning_model_R_1544970545051_2<br class="title-page-name"/>Status of Neuron Layers: predicting Class, 2-class classification, bernoulli distribution, CrossEntropy loss, 247 weights/biases, 8.0 KB, 2,383,962 training samples, mini-batch size 1<br class="title-page-name"/>  layer units    type dropout       l1       l2 mean_rate rate_rms momentum mean_weight weight_rms mean_bias bias_rms<br class="title-page-name"/>1     1    10   Input  0.00 %       NA       NA        NA       NA       NA          NA         NA        NA       NA<br class="title-page-name"/>2     2    10    Tanh  0.00 % 0.000000 0.000000  0.001515 0.001883 0.000000   -0.149216   0.768610 -0.038682 0.891455<br class="title-page-name"/>3     3     5    Tanh  0.00 % 0.000000 0.000000  0.003293 0.004916 0.000000   -0.251950   0.885017 -0.307971 0.531144<br class="title-page-name"/>4     4    10    Tanh  0.00 % 0.000000 0.000000  0.002252 0.001780 0.000000    0.073398   1.217405 -0.354956 0.887678<br class="title-page-name"/>5     5     2 Softmax      NA 0.000000 0.000000  0.007459 0.007915 0.000000   -0.095975   3.579932  0.223286 1.172508<br class="title-page-name"/>H2OBinomialMetrics: deeplearning<br class="title-page-name"/><strong class="calibre1"> Reported on training data.<br class="title-page-name"/>  Metrics reported on temporary training frame with 9892 samples<br class="title-page-name"/></strong> MSE:  0.1129424<br class="title-page-name"/>RMSE:  0.336069<br class="title-page-name"/>LogLoss:  0.336795<br class="title-page-name"/>Mean Per-Class Error:  0.006234916<br class="title-page-name"/>AUC:  0.9983688<br class="title-page-name"/>Gini:  0.9967377<br class="title-page-name"/>Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:<br class="title-page-name"/>          0    1    Error      Rate<br class="title-page-name"/>0      4910   62 0.012470  =62/4972<br class="title-page-name"/>1         0 4920 0.000000   =0/4920<br class="title-page-name"/>Totals 4910 4982 0.006268  =62/9892<br class="title-page-name"/>Maximum Metrics: Maximum metrics at their respective thresholds<br class="title-page-name"/>                        metric threshold    value idx<br class="title-page-name"/>1                       max f1  0.009908 0.993739 153<br class="title-page-name"/>2                       max f2  0.009908 0.997486 153<br class="title-page-name"/>3                 max f0point5  0.019214 0.990107 142<br class="title-page-name"/>4                 max accuracy  0.009908 0.993732 153<br class="title-page-name"/>5                max precision  1.000000 1.000000   0<br class="title-page-name"/>6                   max recall  0.009908 1.000000 153<br class="title-page-name"/>7              max specificity  1.000000 1.000000   0<br class="title-page-name"/>8             max absolute_mcc  0.009908 0.987543 153<br class="title-page-name"/>9   max min_per_class_accuracy  0.019214 0.989541 142<br class="title-page-name"/>10 max mean_per_class_accuracy  0.009908 0.993765 153<br class="title-page-name"/>Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)</pre>
<p class="mce-root">For measuring model performance on test data, we need to convert the test data to the same reduced dimensions as the training data:</p>
<pre class="calibre16">test_3 &lt;- h2o.deepfeatures(model_one, test, layer = 3)<br class="title-page-name"/>print(test_3%&gt;%head())</pre>
<p class="mce-root"><span class="calibre4">The preceding code will generate the following output:</span></p>
<pre class="calibre16">|===========================================================================================================================| 100%</pre>
<p class="mce-root">We see, the data has been converted successfully. Now, to make predictions on the test dataset with <kbd class="calibre11"><span>model_two</span></kbd>, we will use the following code:</p>
<pre class="calibre16">test_pred=h2o.predict(model_two, test_3,type="response")%&gt;%<br class="title-page-name"/>  as.data.frame() %&gt;%<br class="title-page-name"/>  mutate(actual = as.vector(test[, 31]))</pre>
<p class="mce-root"><span class="calibre4">This will generate the following output:</span></p>
<pre class="calibre16">|===========================================================================================================================| 100%</pre>
<p class="mce-root">As we can see, from the output, predictions has been successfully completed and now let us visualize the predictions using the following code:</p>
<pre class="calibre16">test_pred%&gt;%head()<br class="title-page-name"/>  predict        p0           p1 actual<br class="title-page-name"/>1       0 1.0000000 1.468655e-23      0<br class="title-page-name"/>2       0 1.0000000 2.354664e-23      0<br class="title-page-name"/>3       0 1.0000000 5.987218e-09      0<br class="title-page-name"/>4       0 1.0000000 2.888583e-23      0<br class="title-page-name"/>5       0 0.9999988 1.226122e-06      0<br class="title-page-name"/>6       0 1.0000000 2.927614e-23      0<br class="title-page-name"/># summarizing the predictions<br class="title-page-name"/>print(h2o.predict(model_two, test_3) %&gt;%<br class="title-page-name"/>  as.data.frame() %&gt;%<br class="title-page-name"/>  dplyr::mutate(actual = as.vector(test[, 31])) %&gt;%<br class="title-page-name"/>  group_by(actual, predict) %&gt;%<br class="title-page-name"/>  dplyr::summarise(n = n()) %&gt;%<br class="title-page-name"/>  mutate(freq = n / sum(n)))</pre>
<p class="mce-root"><span class="calibre4">This will generate the following output:</span></p>
<pre class="calibre16">|===========================================================================================================================| 100%<br class="title-page-name"/># A tibble: 4 x 4<br class="title-page-name"/># Groups:   actual [2]<br class="title-page-name"/>  actual predict     n   freq<br class="title-page-name"/>  &lt;chr&gt;  &lt;fct&gt;   &lt;int&gt;  &lt;dbl&gt;<br class="title-page-name"/>1 0      0       55811 0.986<br class="title-page-name"/>2 0      1         817 0.0144<br class="title-page-name"/>3 1      0          41 0.414<br class="title-page-name"/>4 1      1          58 0.586</pre>
<p class="mce-root">We see that our AE is able to correctly predict non-fraudulent transactions with 98% accuracy, which is good. However, it is yielding only 58% accuracy when predicting fraudulent transactions. This is definitely something to focus on. Our model needs some improvement, and this can be accomplished through the following options: </p>
<ul class="calibre9">
<li class="calibre10">Using other layers' latent space representations as input to build <kbd class="calibre11">model_two</kbd> (recollect that we currently use the layer 3 representation)</li>
<li class="calibre10">Using ReLu or Maxout activation functions instead of <kbd class="calibre11">Tanh</kbd></li>
<li class="calibre10">Checking the misclassified instances through the <kbd class="calibre11">h2o.anomaly</kbd> function and increasing or decreasing the cutoff threshold MSE values, which separates the fraudulent transactions from non-fraudulent transactions</li>
<li class="calibre10">Trying out a more complex architecture in <span>the </span>encoder and decoder</li>
</ul>
<p class="mce-root">We are not going to be attempting these options in this chapter as they are experimental in nature. However, interested readers may try and improve the accuracy of the model by trying these options.</p>
<p class="mce-root">Finally, one best practice is to explicitly shut down the <kbd class="calibre11">h2o</kbd> cluster. This can be accomplished with the following command:</p>
<pre class="calibre16"><strong class="calibre1">h2o.shutdown()</strong></pre>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we learned about an unsupervised deep learning technique called AEs. We covered the definition, working principle, types, and applications of AEs. H2O, an open source library that enables us to create deep learning models, including AEs, was explored. We then discussed a credit card fraud open dataset and implemented a project with an AE to detect fraudulent credit card transactions.</p>
<p class="mce-root">Can deep neural networks help with creative tasks such as prose generation, story writing, caption generation for images, and poem writing? Not sure?! Let's explore RNNs, in the next chapter, a special type of deep neural network that enables us to accomplish creative tasks. Turn the page to explore the world of RNNs for prose generation.</p>


            </article>

            
        </section>
    </body></html>