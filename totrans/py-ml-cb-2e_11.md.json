["```py\nimport cv2 \n```", "```py\n# Initialize video capture object \ncap = cv2.VideoCapture(0) \n```", "```py\nscaling_factor = 0.5 \n```", "```py\n# Loop until you hit the Esc key \nwhile True: \n    # Capture the current frame \n    ret, frame = cap.read() \n```", "```py\n    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor,  \n            interpolation=cv2.INTER_AREA) \n```", "```py\n    cv2.imshow('Webcam', frame)\n```", "```py\n    c = cv2.waitKey(1) \n    if c == 27: \n        break \n```", "```py\ncap.release() \n```", "```py\ncv2.destroyAllWindows() \n```", "```py\nimport cv2 \nimport numpy as np  \n```", "```py\nface_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')\n```", "```py\nif face_cascade.empty(): \n    raise IOError('Unable to load the face cascade classifier xml file')\n```", "```py\ncap = cv2.VideoCapture(0) \n```", "```py\nscaling_factor = 0.5 \n```", "```py\n# Loop until you hit the Esc key \nwhile True: \n    # Capture the current frame and resize it \n    ret, frame = cap.read() \n```", "```py\n    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor,  \n            interpolation=cv2.INTER_AREA) \n```", "```py\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n```", "```py\n    face_rects = face_cascade.detectMultiScale(gray, 1.3, 5) \n```", "```py\n    for (x,y,w,h) in face_rects: \n        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3) \n```", "```py\n    cv2.imshow('Face Detector', frame)\n```", "```py\n    c = cv2.waitKey(1) \n    if c == 27: \n        break\n```", "```py\ncap.release() \ncv2.destroyAllWindows() \n```", "```py\nimport cv2 \nimport numpy as np \n```", "```py\n# Load face, eye, and nose cascade files \nface_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml') \neye_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_eye.xml') \nnose_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_mcs_nose.xml')\n```", "```py\n# Check if face cascade file has been loaded \nif face_cascade.empty(): \n    raise IOError('Unable to load the face cascade classifier xml file') \n\n# Check if eye cascade file has been loaded \nif eye_cascade.empty(): \n    raise IOError('Unable to load the eye cascade classifier xml file') \n\n# Check if nose cascade file has been loaded \nif nose_cascade.empty(): \n    raise IOError('Unable to load the nose cascade classifier xml file') \n```", "```py\n# Initialize video capture object and define scaling factor \ncap = cv2.VideoCapture(0) \n```", "```py\nscaling_factor = 0.5 \n```", "```py\nwhile True: \n    # Read current frame, resize it, and convert it to grayscale \n    ret, frame = cap.read() \n```", "```py\n    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor,  \n            interpolation=cv2.INTER_AREA) \n```", "```py\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n```", "```py\n    # Run face detector on the grayscale image \n    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n```", "```py\n    # Run eye and nose detectors within each face rectangle \n    for (x,y,w,h) in faces: \n```", "```py\n        # Grab the current ROI in both color and grayscale images \n        roi_gray = gray[y:y+h, x:x+w] \n        roi_color = frame[y:y+h, x:x+w] \n```", "```py\n        # Run eye detector in the grayscale ROI \n        eye_rects = eye_cascade.detectMultiScale(roi_gray) \n```", "```py\n        # Run nose detector in the grayscale ROI \n        nose_rects = nose_cascade.detectMultiScale(roi_gray, 1.3, 5) \n```", "```py\n        # Draw green circles around the eyes \n        for (x_eye, y_eye, w_eye, h_eye) in eye_rects: \n            center = (int(x_eye + 0.5*w_eye), int(y_eye + 0.5*h_eye)) \n            radius = int(0.3 * (w_eye + h_eye)) \n            color = (0, 255, 0) \n            thickness = 3 \n            cv2.circle(roi_color, center, radius, color, thickness) \n```", "```py\n        for (x_nose, y_nose, w_nose, h_nose) in nose_rects: \n            cv2.rectangle(roi_color, (x_nose, y_nose), (x_nose+w_nose,  \n                y_nose+h_nose), (0,255,0), 3) \n            break \n```", "```py\n    # Display the image \n    cv2.imshow('Eye and nose detector', frame)\n```", "```py\n    # Check if Esc key has been pressed \n    c = cv2.waitKey(1) \n    if c == 27: \n        break \n```", "```py\n# Release video capture object and close all windows \ncap.release() \ncv2.destroyAllWindows() \n```", "```py\nimport numpy as np \nfrom sklearn import decomposition  \n```", "```py\n# Define individual features \nx1 = np.random.normal(size=250) \nx2 = np.random.normal(size=250) \nx3 = 3*x1 + 2*x2\nx4 = 6*x1 - 2*x2\nx5 = 3*x3 + x4\n```", "```py\n# Create dataset with the above features \nX = np.c_[x1, x3, x2, x5, x4] \n```", "```py\n# Perform Principal Component Analysis \npca = decomposition.PCA() \n```", "```py\npca.fit(X) \n```", "```py\n# Print variances \nvariances = pca.explained_variance_ \nprint('Variances in decreasing order:\\n', variances)\n```", "```py\n# Find the number of useful dimensions \nthresh_variance = 0.8 \nnum_useful_dims = len(np.where(variances > thresh_variance)[0]) \nprint('Number of useful dimensions:', num_useful_dims)\n```", "```py\n# As we can see, only the 2 first components are useful \npca.n_components = num_useful_dims \n```", "```py\nXNew = pca.fit_transform(X)\nprint('Shape before:', X.shape)\nprint('Shape after:', XNew.shape)\n```", "```py\nVariances in decreasing order:\n[2.77392134e+02 1.51557851e+01 9.54279881e-30 7.73588070e-32 9.89435444e-33]\n Number of useful dimensions: 2\nShape before: (250, 5)\nShape after: (250, 2) \n```", "```py\nimport numpy as np \nimport matplotlib.pyplot as plt \n\nfrom sklearn.decomposition import PCA, KernelPCA \nfrom sklearn.datasets import make_circles \n```", "```py\n# Set the seed for random number generator \nnp.random.seed(7) \n```", "```py\n# Generate samples \nX, y = make_circles(n_samples=500, factor=0.2, noise=0.04)\n```", "```py\n# Perform PCA \npca = PCA() \nX_pca = pca.fit_transform(X) \n```", "```py\n# Perform Kernel PCA \nkernel_pca = KernelPCA(kernel=\"rbf\", fit_inverse_transform=True, gamma=10) \nX_kernel_pca = kernel_pca.fit_transform(X) \nX_inverse = kernel_pca.inverse_transform(X_kernel_pca) \n```", "```py\n# Plot original data \nclass_0 = np.where(y == 0) \nclass_1 = np.where(y == 1) \nplt.figure() \nplt.title(\"Original data\") \nplt.plot(X[class_0, 0], X[class_0, 1], \"ko\", mfc='none') \nplt.plot(X[class_1, 0], X[class_1, 1], \"kx\") \nplt.xlabel(\"1st dimension\") \nplt.ylabel(\"2nd dimension\") \n```", "```py\n# Plot PCA projection of the data \nplt.figure() \nplt.plot(X_pca[class_0, 0], X_pca[class_0, 1], \"ko\", mfc='none') \nplt.plot(X_pca[class_1, 0], X_pca[class_1, 1], \"kx\") \nplt.title(\"Data transformed using PCA\") \nplt.xlabel(\"1st principal component\") \nplt.ylabel(\"2nd principal component\") \n```", "```py\n# Plot Kernel PCA projection of the data \nplt.figure() \nplt.plot(X_kernel_pca[class_0, 0], X_kernel_pca[class_0, 1], \"ko\", mfc='none') \nplt.plot(X_kernel_pca[class_1, 0], X_kernel_pca[class_1, 1], \"kx\") \nplt.title(\"Data transformed using Kernel PCA\") \nplt.xlabel(\"1st principal component\") \nplt.ylabel(\"2nd principal component\")\n```", "```py\n# Transform the data back to original space \nplt.figure() \nplt.plot(X_inverse[class_0, 0], X_inverse[class_0, 1], \"ko\", mfc='none') \nplt.plot(X_inverse[class_1, 0], X_inverse[class_1, 1], \"kx\") \nplt.title(\"Inverse transform\") \nplt.xlabel(\"1st dimension\") \nplt.ylabel(\"2nd dimension\") \n\nplt.show() \n```", "```py\nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA, FastICA  \n```", "```py\n# Load data \ninput_file = 'mixture_of_signals.txt' \nX = np.loadtxt(input_file) \n```", "```py\n# Compute ICA \nica = FastICA(n_components=4) \n```", "```py\n# Reconstruct the signals \nsignals_ica = ica.fit_transform(X) \n```", "```py\n# Get estimated mixing matrix \nmixing_mat = ica.mixing_   \n```", "```py\n# Perform PCA  \npca = PCA(n_components=4) \n# Reconstruct signals based on orthogonal components \nsignals_pca = pca.fit_transform(X)\n```", "```py\n# Specify parameters for output plots  \nmodels = [X, signals_ica, signals_pca] \n```", "```py\ncolors = ['blue', 'red', 'black', 'green'] \n```", "```py\n# Plotting input signal \nplt.figure() \nplt.title('Input signal (mixture)') \nfor i, (sig, color) in enumerate(zip(X.T, colors), 1): \n    plt.plot(sig, color=color) \n```", "```py\n# Plotting ICA signals  \nplt.figure() \nplt.title('ICA separated signals') \nplt.subplots_adjust(left=0.1, bottom=0.05, right=0.94,  \n        top=0.94, wspace=0.25, hspace=0.45) \n```", "```py\nfor i, (sig, color) in enumerate(zip(signals_ica.T, colors), 1): \n    plt.subplot(4, 1, i) \n    plt.title('Signal ' + str(i)) \n    plt.plot(sig, color=color) \n```", "```py\n# Plotting PCA signals   \nplt.figure() \nplt.title('PCA separated signals') \nplt.subplots_adjust(left=0.1, bottom=0.05, right=0.94,  \n        top=0.94, wspace=0.25, hspace=0.45) \n```", "```py\nfor i, (sig, color) in enumerate(zip(signals_pca.T, colors), 1): \n    plt.subplot(4, 1, i) \n    plt.title('Signal ' + str(i)) \n    plt.plot(sig, color=color) \n\nplt.show() \n```", "```py\nimport os \n\nimport cv2 \nimport numpy as np \nfrom sklearn import preprocessing  \n```", "```py\n# Class to handle tasks related to label encoding \nclass LabelEncoder(object): \n```", "```py\n    # Method to encode labels from words to numbers \n    def encode_labels(self, label_words): \n        self.le = preprocessing.LabelEncoder() \n        self.le.fit(label_words) \n```", "```py\n    # Convert input label from word to number \n    def word_to_num(self, label_word): \n        return int(self.le.transform([label_word])[0]) \n```", "```py\n    # Convert input label from number to word \n    def num_to_word(self, label_num): \n        return self.le.inverse_transform([label_num])[0] \n```", "```py\n# Extract images and labels from input path \ndef get_images_and_labels(input_path): \n    label_words = [] \n```", "```py\n    # Iterate through the input path and append files \n    for root, dirs, files in os.walk(input_path): \n        for filename in (x for x in files if x.endswith('.jpg')): \n            filepath = os.path.join(root, filename) \n            label_words.append(filepath.split('/')[-2])\n```", "```py\n    # Initialize variables \n    images = [] \n    le = LabelEncoder() \n    le.encode_labels(label_words) \n    labels = [] \n```", "```py\n    # Parse the input directory \n    for root, dirs, files in os.walk(input_path): \n        for filename in (x for x in files if x.endswith('.jpg')): \n            filepath = os.path.join(root, filename) \n```", "```py\n            # Read the image in grayscale format \n            image = cv2.imread(filepath, 0)  \n```", "```py\n            # Extract the label \n            name = filepath.split('/')[-2] \n```", "```py\n            # Perform face detection \n            faces = faceCascade.detectMultiScale(image, 1.1, 2, minSize=(100,100)) \n```", "```py\n            # Iterate through face rectangles \n            for (x, y, w, h) in faces: \n                images.append(image[y:y+h, x:x+w]) \n                labels.append(le.word_to_num(name)) \n\n    return images, labels, le \n```", "```py\nif __name__=='__main__': \n    cascade_path = \"cascade_files/haarcascade_frontalface_alt.xml\" \n    path_train = 'faces_dataset/train' \n    path_test = 'faces_dataset/test'\n```", "```py\n    # Load face cascade file \n    faceCascade = cv2.CascadeClassifier(cascade_path) \n```", "```py\n    # Initialize Local Binary Patterns Histogram face recognizer \n    recognizer = cv2.face.createLBPHFaceRecognizer() \n```", "```py\n    # Extract images, labels, and label encoder from training dataset \n    images, labels, le = get_images_and_labels(path_train) \n```", "```py\n    # Train the face recognizer  \n    print \"\\nTraining...\" \n    recognizer.train(images, np.array(labels)) \n```", "```py\n    # Test the recognizer on unknown images \n    print '\\nPerforming prediction on test images...' \n    stop_flag = False \n    for root, dirs, files in os.walk(path_test): \n        for filename in (x for x in files if x.endswith('.jpg')): \n            filepath = os.path.join(root, filename) \n```", "```py\n            # Read the image \n            predict_image = cv2.imread(filepath, 0) \n```", "```py\n            # Detect faces \n            faces = faceCascade.detectMultiScale(predict_image, 1.1,  \n                    2, minSize=(100,100)) \n```", "```py\n            # Iterate through face rectangles \n            for (x, y, w, h) in faces: \n                # Predict the output \n                predicted_index, conf = recognizer.predict( \n                        predict_image[y:y+h, x:x+w])\n```", "```py\n                # Convert to word label \n                predicted_person = le.num_to_word(predicted_index) \n```", "```py\n                # Overlay text on the output image and display it \n                cv2.putText(predict_image, 'Prediction: ' + predicted_person,  \n                        (10,60), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 6) \n                cv2.imshow(\"Recognizing face\", predict_image) \n```", "```py\n            c = cv2.waitKey(0) \n            if c == 27: \n                stop_flag = True \n                break \n\n        if stop_flag: \n            break \n```", "```py\nfrom PIL import Image\nimport face_recognition\n```", "```py\nimage = face_recognition.load_image_file(\"family.jpg\")\n```", "```py\nface_locations = face_recognition.face_locations(image) \n```", "```py\nprint(\"Number {} face(s) recognized in this image.\".format(len(face_locations)))\n```", "```py\nfor face_location in face_locations:\n\n    top, right, bottom, left = face_location\n    print(\"Face location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n```", "```py\n    face_image = image[top:bottom, left:right]\n    pil_image = Image.fromarray(face_image)\n    pil_image.show()\n```", "```py\nfrom PIL import Image, ImageDraw\nimport face_recognition\n```", "```py\nimage = face_recognition.load_image_file(\"ciaburro.jpg\")\n```", "```py\nFaceLandmarksList = face_recognition.face_landmarks(image)\n```", "```py\nprint(\"Number {} face(s) recognized in this image.\".format(len(FaceLandmarksList)))\n```", "```py\nNumber 1 face(s) recognized in this image\n```", "```py\nPilImage = Image.fromarray(image)\nDrawPilImage = ImageDraw.Draw(PilImage)\n```", "```py\nfor face_landmarks in FaceLandmarksList:\n```", "```py\n    for facial_feature in face_landmarks.keys():\n        print(\"{} points: {}\".format(facial_feature, face_landmarks[facial_feature]))\n```", "```py\n    for facial_feature in face_landmarks.keys():\n        DrawPilImage.line(face_landmarks[facial_feature], width=5)\n```", "```py\nPilImage.show()\n```", "```py\nimport face_recognition\n```", "```py\nImage1 = face_recognition.load_image_file(\"giuseppe.jpg\")\nImage2 = face_recognition.load_image_file(\"tiziana.jpg\")\nUnknownImage = face_recognition.load_image_file(\"tiziana2.jpg\")\n```", "```py\ntry:\n    Image1Encoding = face_recognition.face_encodings(Image1)[0]\n    Image2Encoding = face_recognition.face_encodings(Image2)[0]\n    UnknownImageEncoding = face_recognition.face_encodings(UnknownImage)[0]\nexcept IndexError:\n    print(\"Any face was located. Check the image files..\")\n    quit()\n```", "```py\nknown_faces = [\n    Image1Encoding,\n    Image2Encoding\n]\n```", "```py\nresults = face_recognition.compare_faces(known_faces, UnknownImageEncoding)\n```", "```py\nprint(\"Is the unknown face a picture of Giuseppe? {}\".format(results[0]))\nprint(\"Is the unknown face a picture of Tiziana? {}\".format(results[1]))\nprint(\"Is the unknown face a new person that we've never seen before? {}\".format(not True in results))\n```", "```py\nIs the unknown face a picture of Giuseppe? False\nIs the unknown face a picture of Tiziana? True\nIs the unknown face a new person that we've never seen before? False\n```"]