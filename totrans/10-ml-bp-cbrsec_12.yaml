- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Protecting User Privacy with Federated Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In recent times, the issue of user privacy has gained traction in the information
    technology world. Privacy means that the user is in complete control of their
    data – they can choose how the data is collected, stored, and used. Often, this
    also implies that data cannot be shared with other entities. Apart from this,
    there may be other reasons why companies may not want to share data, such as confidentiality,
    lack of trust, and protecting intellectual property. This can be a huge impediment
    to **machine learning** (**ML**) models; large models, particularly deep neural
    networks, cannot train properly without adequate data.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn about a privacy-preserving technique for ML known
    as **federated machine learning** (**FML**). Many kinds of fraud data are sensitive;
    they have user-specific information and also reveal weaknesses in the company’s
    detection measures. Therefore, companies may not want to share them with one another.
    FML makes it possible to learn from data without having access to the data by
    sharing just the learned model itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to federated machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing federated averaging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing the privacy-utility trade-off in **federated** **learning** (**FL**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have a detailed understanding of federated
    machine learning, and be able to implement any task (security or non-security
    related) as a federated learning task.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%201](https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%2010)1.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to federated machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us first look at what federated learning is and why it is a valuable tool.
    We will first look at privacy challenges that are faced while applying machine
    learning, followed by how and why we apply federated learning.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy challenges in machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Traditional ML involves a series of steps that we have discussed multiple times
    so far: data preprocessing, feature extraction, model training, and tuning the
    model for best performance. However, this involves the data being exposed to the
    model and, therefore, is based on the premise of the availability of data. The
    more data we have available, the more accurate the model will be.'
  prefs: []
  type: TYPE_NORMAL
- en: However, there is often a scarcity of data in the real world. Labels are hard
    to come by, and there is no centrally aggregated data source. Rather, data is
    collected and processed by multiple entities who may not want to share it.
  prefs: []
  type: TYPE_NORMAL
- en: This is true more often than not in the security space. Because the data involved
    is sensitive and the stakes are high, entities who collect the data may not want
    to share it with others or post it publicly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are examples of this:'
  prefs: []
  type: TYPE_NORMAL
- en: Consider a credit card company. The company has labeled data on transactions
    that were reported to be fraud. However, it may not want to share the data, as
    exposing the data may unintentionally expose implementation details or intellectual
    property. User-level information in the data may also be personally identifying,
    and there may be privacy risks associated with sharing it. Therefore, every credit
    card company has access to a small set of data – but no company will share it
    with other companies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider a network security or antivirus company that uses statistics and ML
    to detect malware. It will have examples of applications that it has analyzed
    and manually labeled as malware. However, sharing the data may leak information
    about attacks and undermine the company’s public image. It also may give away
    clues to attackers on how to circumvent detection. Thus, all antivirus companies
    will have data but do not share it publicly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can draw similar parallels in almost all areas of cybersecurity: click
    fraud detection, identification of fake news, flagging abusive and hate speech
    content on social media, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Entities that own the data are not thrilled about sharing it, which makes training
    ML models harder. Additionally, no entity can learn from the data acquired by
    other entities. Valuable knowledge and signals may be lost in the process, and
    models built on subsets of data will have inherent biases.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, it is extremely challenging, if not impossible, to construct a dataset
    that is good enough to train an ML model while maintaining privacy. Federated
    learning is an approach used to overcome this challenge.
  prefs: []
  type: TYPE_NORMAL
- en: How federated machine learning works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: FML (or simply FL) is a type of ML that allows multiple devices or organizations
    to collaborate on building a shared ML model without sharing their data. In traditional
    ML, all data is aggregated and processed in a central location, but in FML, the
    data remains distributed across multiple devices or locations, and the model is
    trained in a decentralized manner.
  prefs: []
  type: TYPE_NORMAL
- en: The fundamental concept in federated learning is to share the learned model
    instead of sharing the data. Because of this, individual entities can share knowledge
    about patterns and parameters without having to disclose the data. We will now
    see how this is achieved in a step-by-step manner.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – data partitioning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The data is partitioned across multiple devices or locations, where each one
    is known as a client. Each client has its own local data that is not shared with
    other devices. For example, in a medical setting, each hospital may have patient
    data that it is not willing to share with other hospitals. In the case of fraud
    detection, each credit card company will have examples of fraud. Note that every
    client will have data in varying sizes and distributions; however, all clients
    must preprocess their data in the same way to produce a uniform input vector of
    data. An example scenario is shown in *Figure 11**.1*; there are multiple clients
    shown, and each client draws data from different sources (a USB drive, a cloud
    server, a local file, a database, and so on). At each client, however, data is
    processed into the same standard form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Every client processes the data into a standard form](img/B19327_11_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – Every client processes the data into a standard form
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – global model initialization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A central server or client, known as an aggregator, initializes a global model.
    In this step, the model is initialized randomly, with parameters and weights drawn
    from a uniform normal distribution. The global model defines the structure and
    architecture that will be used by each client. The global model is distributed
    to each client for training, as shown in *Figure 11**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Global model distributed to clients](img/B19327_11_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 – Global model distributed to clients
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – local training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After receiving the global model, each client trains the local model on the
    data they have. The local model is trained using standard ML techniques, such
    as stochastic gradient descent, and updates are made to the local model using
    the data available on that device. Up until now, the steps we have followed are
    similar to what an individual client would do in traditional ML. Each client will
    train and produce its own local model, as shown in *Figure 11**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – Local model training by clients](img/B19327_11_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.3 – Local model training by clients
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – model aggregation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The updated local models are then sent back to the central server or cloud,
    where they are aggregated to create an updated global model. This aggregation
    process can take different forms, such as averaging the local models or using
    more complex methods. To calculate the updated aggregated model, the received
    parameters are averaged and assigned to the new model. Recall that we distribute
    the global model to each client; thus, each client will have the same structure
    of the underlying model, which makes aggregation possible. In most cases, the
    strategy known as **federated averaging** is used. We calculate the average weighted
    by the size of the data; clients with more data are likely to produce a better
    model, and so their weights are assigned more importance in the average; this
    process is demonstrated in *Figure 11**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – Model aggregation](img/B19327_11_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.4 – Model aggregation
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – model distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The aggregated model calculated in the previous step is distributed to each
    client. The client now takes this model and fine-tunes it using the local client
    data, thus updating it again. This time, however, the initialization is not random.
    The model parameters are the aggregated ones, meaning that they incorporate the
    learnings of all client nodes. After updating the model, it is sent back to the
    central server for aggregation. This continues for a fixed number of communication
    rounds.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, federated machine learning enables multiple devices or organizations
    to collaborate on building a shared ML model without sharing their data. This
    approach can improve data privacy, security, and efficiency, while still providing
    accurate and useful models.
  prefs: []
  type: TYPE_NORMAL
- en: The benefits of federated learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will discuss the key advantages of federated learning.
  prefs: []
  type: TYPE_NORMAL
- en: Data privacy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data privacy is one of the most significant advantages of federated ML. In traditional
    ML approaches, data is collected and stored in a central location, and this can
    lead to concerns about data privacy and security. In federated learning, however,
    data remains on local devices or servers, and models are trained without ever
    sharing the raw data with a central server. This means that data remains secure
    and there is no risk of a data breach. Additionally, data owners retain control
    over their data, which is especially important in sensitive industries such as
    healthcare or finance, where privacy is of utmost importance.
  prefs: []
  type: TYPE_NORMAL
- en: Lower cost
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Federated machine learning can be a cost-effective solution for organizations
    as it allows them to leverage the computational power of multiple devices or servers
    without having to invest in expensive hardware or cloud computing services. This
    is because the devices or servers that are used to train the models already exist,
    and there is no need to purchase additional infrastructure. Additionally, the
    costs associated with transferring large amounts of data to a central server for
    analysis are also reduced as data remains on local devices or servers.
  prefs: []
  type: TYPE_NORMAL
- en: Speed
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Federated machine learning can also speed up the training process as each device
    or server can contribute to the training process. This is because models are trained
    locally on each device or server, and the updates are sent back to the central
    server, where they are combined to create a global model. Since each device or
    server is responsible for training only a subset of the data, the training process
    can be faster than traditional ML approaches. Additionally, because data remains
    on local devices or servers, there is no need to transfer large amounts of data
    to a central server, reducing network latency and speeding up the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: FML allows models to be trained on more diverse datasets, leading to improved
    model accuracy. This is because data is distributed across multiple devices or
    servers, and each device or server may have slightly different data characteristics.
    By training models on a diverse set of data, models become more robust and can
    better generalize to new data. Additionally, models trained using FL can better
    account for the variability in the data and perform better in real-world scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges in federated learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although federated machine learning offers significant benefits, such as preserving
    data privacy, there are several challenges that must be addressed to make it practical
    and effective.
  prefs: []
  type: TYPE_NORMAL
- en: Communication and network latency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Federated machine learning involves multiple parties collaborating to train
    a model without sharing their data with each other. However, this requires frequent
    communication and exchange of large amounts of data and model updates between
    parties. The communication overhead and network latency can be significant, especially
    when the parties are located in different geographical locations and have limited
    bandwidth. This can slow down the training process and make it difficult to coordinate
    the training of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Data heterogeneity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Federated machine learning involves different parties using their own data and
    hardware to train the model. This can lead to heterogeneity in the data and hardware,
    making it difficult to design a model that can effectively leverage the strengths
    of each party while mitigating the weaknesses. For example, some parties may have
    high-quality data, while others may have noisy data. Some parties may have powerful
    hardware, while others may have limited processing capabilities. It is important
    to design a model that can accommodate these differences and ensure that the training
    process is fair and unbiased.
  prefs: []
  type: TYPE_NORMAL
- en: Data imbalance and distribution shift
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In federated learning, the data used by different parties may be highly imbalanced
    and may have different statistical properties. This can lead to distributional
    shifts and bias in the model, making it difficult to ensure that the model is
    fair and unbiased. For example, if one party has significantly more data than
    the other parties, the model may be biased toward that party’s data. It is important
    to address these issues by carefully selecting the data used for training and
    by using techniques such as data augmentation and sample weighting to mitigate
    the effects of data imbalance and distributional shifts.
  prefs: []
  type: TYPE_NORMAL
- en: Free riders and rogue clients
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Federated learning is designed to preserve the privacy of the data owned by
    different parties. However, this also makes it challenging to ensure the security
    and privacy of the model and the data during training. For example, it may be
    difficult to ensure that the model updates sent by each party are genuine and
    have not been tampered with or corrupted. Additionally, it may be difficult to
    ensure that the data owned by each party remains private and secure, especially
    when parties are not fully trusted. It is important to develop secure and privacy-preserving
    techniques for federated learning to mitigate these risks.
  prefs: []
  type: TYPE_NORMAL
- en: Federated optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Federated machine learning requires the use of novel optimization techniques
    that can handle the distributed nature of the training process. These techniques
    must be able to aggregate the model updates from multiple parties while preserving
    the privacy and security of the data. This can be challenging, especially when
    dealing with large-scale datasets. Additionally, the optimization techniques used
    in federated learning must be efficient and scalable, as the training process
    can involve a large number of parties and a large amount of data.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, addressing these challenges requires a combination of advanced algorithms,
    techniques, and infrastructure. Despite these challenges, federated machine learning
    has the potential to enable a new era of collaborative ML while preserving privacy
    and security.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our discussion of federated learning theory. Now that you have
    a good understanding of how the process works and what the pitfalls involved are,
    let us implement it practically.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing federated averaging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will implement federated averaging with a practical use
    case in Python. Note that while we are using the MNIST dataset here as an example,
    this can easily be replicated for any dataset of your choosing.
  prefs: []
  type: TYPE_NORMAL
- en: Importing libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We begin by importing the necessary libraries. We will need our standard Python
    libraries, along with some libraries from Keras, which will allow us to create
    our deep learning model. The following code snippet imports these libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Let us now turn to the data we are using.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset we will be using is the MNIST dataset. The MNIST dataset is a popular
    benchmark dataset used in ML research. It is a collection of 70,000 grayscale
    images of handwritten digits, with each image being 28 x 28 pixels in size. The
    images are split into a training set of 60,000 examples and a test set of 10,000
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of the dataset is to train an ML model to correctly classify each
    image into the corresponding digit from 0 to 9\. The dataset has been widely used
    for training and testing various ML algorithms such as neural networks, support
    vector machines, and decision trees. The MNIST dataset has become a standard benchmark
    for evaluating the performance of image recognition algorithms, and it has been
    used as a starting point for many new ML researchers. It has also been used in
    many tutorials and online courses to teach the basics of image recognition and
    ML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This completes the code to load and preprocess data.
  prefs: []
  type: TYPE_NORMAL
- en: Client setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we need to write a function that will initialize our client nodes. Note
    that in the real world, each client or entity will have its own data. However,
    as we are simulating this scenario, we will implement this manually. The function
    takes in the data and labels it as input, and returns partitioned data as output.
    It will break the data into roughly equal chunks and assign each chunk to one
    client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also write a helper function that, when given a chunk of data, will
    shuffle it, prepare it into tensors as needed, and return it to us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It is now time to turn to the modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Model implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we will write a function that creates our actual classification model.
    This function takes in the hidden layer sizes as a parameter in the form of an
    array. At a high level, this function will perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize a sequential Keras model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the input layer based on the shape of the input data. Here, it is known
    to be `784`, as we are using the MNIST data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the activation function of the input layer to be a **rectified linear**
    **unit** (**ReLU**).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Parse the list of hidden layer sizes passed in as a parameter, and create hidden
    layers one by one. For example, the `[200, 200, 200]` parameter means that there
    are three hidden layers, each with 200 neurons.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the final layer. This will have the number of nodes equal to the number
    of classes, which, in this case, is `10`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the activation of the final layer as `softmax` so it returns normalized
    output probabilities.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here is an implementation of these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This function will initialize and return a model of the desired structure.
  prefs: []
  type: TYPE_NORMAL
- en: Weight scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we will write a function that scales the weights. Note that as part of
    federated learning, we will aggregate the weights. If there is a wide disparity
    between the data sizes, it will reflect in the model performance. A model with
    smaller training data must contribute less to the aggregate. Therefore, we calculate
    a scaling factor for each client or node. This factor is simply the proportion
    of the global training data this client has access to. If there are 1,000 records
    globally, and client A has 210 records, the scaling factor is 0.21:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Global model initialization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let us initialize the global model. This will be the shared central model
    that will hold the updated parameters in every communication round:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show you the structure of the created model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Model structure](img/B19327_11_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5 – Model structure
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have written functions to help us with the data and model. Now it
    is time to put them into action!
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the experiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now use the function we defined earlier to load the training data.
    After binarizing the labels (that is, converting them into one-hot-encoding form),
    we will split the data into training and test sets. We will reserve 20% of the
    data for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We will see the function we defined earlier to assign data to clients. This
    will return us a dictionary of client and data pairs, on which we will apply the
    chunk-collapsing function we wrote:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will set a few parameters for our experiment. Note that as we have
    a multi-class classification problem, the choice of categorical cross-entropy
    as the loss is obvious. The learning rate and the number of communication rounds
    are hyperparameters – you can experiment with them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have everything set up, we can actually carry out federated learning.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we will actually carry out the federated learning process in multiple communication
    rounds. At a high level, here is what we are doing in each communication round:'
  prefs: []
  type: TYPE_NORMAL
- en: Obtain the weights from the global model and shuffle client chunks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For every client:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize a local model for training.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the weights of the local model to the current global model.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the local model with data from this client.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on the amount of data available in this client, obtain scaled weights
    from this newly trained model.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For memory management purposes, clear the local Keras session.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the average of all the weights obtained in *step 2*. As these are scaled
    weights, the average is a weighted one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the average weights to be the weights for the new global model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the accuracy of this model (new global model with the newly assigned
    weights).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print information about loss and accuracy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *steps 1–7* for each communication round. In every round, the global
    model is gradually updated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s the code to implement these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The result here will be a series of statements that show how the loss and accuracy
    changed from round to round. Here is what the first 10 rounds look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – First 10 rounds in the training loop](img/B19327_11_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.6 – First 10 rounds in the training loop
  prefs: []
  type: TYPE_NORMAL
- en: 'And this is how the last 10 rounds look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Last 10 rounds in the training loop](img/B19327_11_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.7 – Last 10 rounds in the training loop
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Due to the random initialization of initial weights and shuffling, the results
    will change every time we run this. Therefore, the numbers you obtain when you
    try to recreate this will be different than what is shown here. This is expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can visualize these trends with a plot that will show us the loss over the
    rounds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The output would be something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Loss trend over rounds](img/B19327_11_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.8 – Loss trend over rounds
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we can plot the accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Accuracy trend over rounds](img/B19327_11_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 – Accuracy trend over rounds
  prefs: []
  type: TYPE_NORMAL
- en: Thus, with federated machine learning, we were able to improve the accuracy
    of the global model from around 72% to over 92%. Interestingly, you can see that
    the accuracy somewhat drops around round 25 or 0\. This is probably because of
    overfitting the data on some particular client’s local training data.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the privacy-utility trade-off in federated learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, we examined the effectiveness of federated learning
    and looked at the model performance over multiple communication rounds. However,
    to quantify the effectiveness, we need to compare this against two benchmarks:'
  prefs: []
  type: TYPE_NORMAL
- en: A model trained on the entire data with no federation involved
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A local model trained on its own data only
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The differences in accuracy in these three cases (federated, global only, and
    local only) will indicate the trade-offs we are making and the gains we achieve.
    In the previous section, we looked at the accuracy we obtain via federated learning.
    To understand the utility-privacy trade-off, let us discuss two extreme cases
    – a fully global and a fully local model.
  prefs: []
  type: TYPE_NORMAL
- en: Global model (no privacy)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we train a global model directly, we use all the data to train a single
    model. Thus, all parties involved would be publicly sharing their data with each
    other. The central aggregator would have access to all of the data. In this case,
    as the data is shared, there is no privacy afforded to clients.
  prefs: []
  type: TYPE_NORMAL
- en: 'To train the global model on the entire data, we will re-initialize the global
    model and fit it with the entire training data (instead of individual client data).
    Here is the code snippet for that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see output as follows, which shows the accuracy and loss through
    each epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Global model training](img/B19327_11_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 – Global model training
  prefs: []
  type: TYPE_NORMAL
- en: We see that the fully global model performs much better (it starts at 92% and
    finishes at 95%) in just a few epochs. This means that it is more powerful than
    the federated model. This is the trade-off we make in the federated learning;
    we have to sacrifice performance and accuracy for privacy.
  prefs: []
  type: TYPE_NORMAL
- en: Local model (full privacy)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, to evaluate the performance of our local model, we will pick a random
    client (say client 8) and train a model only on that client’s data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – Local model training](img/B19327_11_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 – Local model training
  prefs: []
  type: TYPE_NORMAL
- en: Here, we see that the model started off really poorly (an accuracy of less than
    20%, which is worse even than a random guessing classifier). Over the epochs,
    the model performance improved. However, the accuracy at the end was a little
    above 48%, which is worse than the federated model.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the trade-off
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The results we have obtained from the previous two subsections show us two
    things:'
  prefs: []
  type: TYPE_NORMAL
- en: A model that performs federated learning performs better than a model trained
    only on a client’s local data. Thus, a client is able to benefit from the model
    learned by other clients through parameter sharing and aggregation, which can
    be achieved without sharing data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A global model trained on the entire data performs better than the federated
    learning model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This clearly demonstrates the privacy-utility trade-off. As we increase the
    privacy (apply federated learning), the utility of the data decreases, as reflected
    in the model performance. At no privacy (all clients share data and use it to
    train a global model), utility is the highest.
  prefs: []
  type: TYPE_NORMAL
- en: While the trade-off may be harder to understand given the dataset we have used
    here (after all, what privacy concerns do we face in sharing images of handwritten
    digits?), it becomes more obvious as we enter the security domain. Recall that
    in the very first chapter, we discussed how ML in the security domain is different
    than in other domains, such as image recognition or advertisement targeting, as
    the stakes are higher here.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of image recognition, consider this to be a credit card fraud detection
    scenario. The client nodes are various banks and credit card companies. Every
    company has labeled examples of fraud that they do not want to share.
  prefs: []
  type: TYPE_NORMAL
- en: If the companies share all of the data with each other, it will allow them to
    train a global model. As different companies will have different patterns and
    examples of fraud, the model generated will be able to detect multiple attack
    patterns. This will benefit each company involved; company *A* will be able to
    detect a certain kind of fraud even if it has never seen it before if another
    company, *B*, has ever observed it. However, at the same time, companies risk
    their proprietary data being leaked and personally identifying user data being
    exposed. There also may be reputational harm if the occurrence of fraud comes
    to light. Therefore, the high performance and generalizability come at the cost
    of a loss of privacy.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, consider that the companies do not share any data at all.
    Thus, each company will be able to train a model on the data it has access to.
    In this case, company *A* will not be able to detect out-of-distribution fraud
    or novel attack patterns that it has not seen before. This will result in a low
    recall in detecting fraud and might cause severe losses to the company. Therefore,
    the high privacy and confidentiality come at the cost of reduced performance and
    potential financial loss.
  prefs: []
  type: TYPE_NORMAL
- en: Federated learning is able to solve both of these issues and provide us with
    the perfect middle ground between privacy and utility. Because federated learning
    involves sharing model parameters and not data, privacy can be maintained, and
    personal information will not be released. At the same time, because the models
    are shared and aggregated, learnings from one client will be beneficial to others
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the MNIST dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we chose the MNIST dataset for our experiments. While MNIST
    is a popular benchmark for image processing, it is not ideal for security applications.
    However, we chose it for two reasons. First, it is a fairly large and well-distributed
    dataset that makes federated learning simpler. Other public datasets are relatively
    small, which means that when sharded, clients have only a small amount of data
    that is not enough to produce a reasonable model. Second, being an image dataset,
    it is naturally suited to be processed by neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The applications of federated learning are not limited to images. You are encouraged
    to explore all of the problems we have looked at in this book so far (malware,
    fake news, and intrusion detection) and implement them in a federated manner.
    To do so, only two changes are required:'
  prefs: []
  type: TYPE_NORMAL
- en: Change the data loading mechanism to read from the appropriate data source instead
    of MNIST
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the deep learning model structure to reflect the input and output dimensions
    specific to the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rest of the steps (initializing the model, sharding the data, communication
    rounds, and so on) all remain the same. You should implement federated learning
    in various cybersecurity areas and observe the privacy-utility trade-off.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about a privacy preservation mechanism for ML known
    as federated learning. In traditional ML, all data is aggregated and processed
    in a central location, but in FML, the data remains distributed across multiple
    devices or locations, and the model is trained in a decentralized manner. In FML,
    we share the model and not the data.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed the core concepts and working of FML, followed by an implementation
    in Python. We also benchmarked the performance of federated learning against traditional
    ML approaches to examine the privacy-utility trade-off. This chapter provided
    an introduction to an important aspect of ML and one that is gaining rapid traction
    in today’s privacy-centric technology world.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will go a step further and look at the hottest topic
    in ML privacy today – differential privacy.
  prefs: []
  type: TYPE_NORMAL
