- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Protecting User Privacy with Federated Machine Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用联邦机器学习保护用户隐私
- en: In recent times, the issue of user privacy has gained traction in the information
    technology world. Privacy means that the user is in complete control of their
    data – they can choose how the data is collected, stored, and used. Often, this
    also implies that data cannot be shared with other entities. Apart from this,
    there may be other reasons why companies may not want to share data, such as confidentiality,
    lack of trust, and protecting intellectual property. This can be a huge impediment
    to **machine learning** (**ML**) models; large models, particularly deep neural
    networks, cannot train properly without adequate data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，用户隐私问题在信息技术领域引起了广泛关注。隐私意味着用户对其数据拥有完全的控制权——他们可以选择如何收集、存储和使用数据。通常，这也意味着数据不能与其他实体共享。除此之外，公司可能还有其他不愿共享数据的原因，例如保密性、缺乏信任和保护知识产权。这可能会对机器学习模型造成巨大的障碍；大型模型，尤其是深度神经网络，如果没有足够的数据，就无法进行适当的训练。
- en: In this chapter, we will learn about a privacy-preserving technique for ML known
    as **federated machine learning** (**FML**). Many kinds of fraud data are sensitive;
    they have user-specific information and also reveal weaknesses in the company’s
    detection measures. Therefore, companies may not want to share them with one another.
    FML makes it possible to learn from data without having access to the data by
    sharing just the learned model itself.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将了解一种名为**联邦机器学习**（**FML**）的隐私保护机器学习技术。许多类型的欺诈数据是敏感的；它们包含用户特定的信息，同时也揭示了公司在检测措施中的弱点。因此，公司可能不愿意相互分享这些数据。FML使得仅通过共享学习到的模型本身，就可以从数据中学习，而无需访问数据。
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主要内容：
- en: An introduction to federated machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联邦机器学习的介绍
- en: Implementing federated averaging
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现联邦平均
- en: Reviewing the privacy-utility trade-off in **federated** **learning** (**FL**)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回顾联邦学习中的隐私-效用权衡**（联邦** **学习** **（FL**））
- en: By the end of this chapter, you will have a detailed understanding of federated
    machine learning, and be able to implement any task (security or non-security
    related) as a federated learning task.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将详细理解联邦机器学习，并能够将任何任务（安全或非安全相关）作为联邦学习任务来实施。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%201](https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%2010)1.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub上找到本章的代码文件，网址为[https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%201](https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%2010)1。
- en: An introduction to federated machine learning
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联邦机器学习的介绍
- en: Let us first look at what federated learning is and why it is a valuable tool.
    We will first look at privacy challenges that are faced while applying machine
    learning, followed by how and why we apply federated learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看联邦学习是什么以及为什么它是一个有价值的工具。我们将首先探讨在应用机器学习时面临的隐私挑战，然后讨论我们如何以及为什么应用联邦学习。
- en: Privacy challenges in machine learning
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习中的隐私挑战
- en: 'Traditional ML involves a series of steps that we have discussed multiple times
    so far: data preprocessing, feature extraction, model training, and tuning the
    model for best performance. However, this involves the data being exposed to the
    model and, therefore, is based on the premise of the availability of data. The
    more data we have available, the more accurate the model will be.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 传统机器学习涉及一系列我们之前多次讨论的步骤：数据预处理、特征提取、模型训练以及调整模型以获得最佳性能。然而，这涉及到数据暴露给模型，因此基于数据可用的前提。我们拥有的数据越多，模型就越准确。
- en: However, there is often a scarcity of data in the real world. Labels are hard
    to come by, and there is no centrally aggregated data source. Rather, data is
    collected and processed by multiple entities who may not want to share it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在现实世界中，数据往往很稀缺。标签难以获得，也没有集中聚合的数据源。相反，数据是由多个实体收集和处理的，而这些实体可能不愿意共享它们。
- en: This is true more often than not in the security space. Because the data involved
    is sensitive and the stakes are high, entities who collect the data may not want
    to share it with others or post it publicly.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在安全领域，这种情况更为常见。因为涉及的数据是敏感的，风险很高，收集数据的实体可能不愿意与他人分享它或公开发布。
- en: 'The following are examples of this:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些例子：
- en: Consider a credit card company. The company has labeled data on transactions
    that were reported to be fraud. However, it may not want to share the data, as
    exposing the data may unintentionally expose implementation details or intellectual
    property. User-level information in the data may also be personally identifying,
    and there may be privacy risks associated with sharing it. Therefore, every credit
    card company has access to a small set of data – but no company will share it
    with other companies.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑一家信用卡公司。该公司对已报告为欺诈的交易进行了标记。然而，它可能不想分享数据，因为暴露数据可能会无意中暴露实施细节或知识产权。数据中的用户级信息也可能是个人身份信息，与分享它相关的隐私风险可能存在。因此，每家信用卡公司都能访问一小部分数据——但没有公司愿意与其他公司分享。
- en: Consider a network security or antivirus company that uses statistics and ML
    to detect malware. It will have examples of applications that it has analyzed
    and manually labeled as malware. However, sharing the data may leak information
    about attacks and undermine the company’s public image. It also may give away
    clues to attackers on how to circumvent detection. Thus, all antivirus companies
    will have data but do not share it publicly.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑一个网络安全或杀毒公司，它使用统计和机器学习来检测恶意软件。它将拥有它已分析并手动标记为恶意软件的应用程序示例。然而，共享数据可能会泄露有关攻击的信息，损害公司的公众形象。它也可能向攻击者提供绕过检测的线索。因此，所有杀毒公司都会有数据，但不会公开分享。
- en: 'You can draw similar parallels in almost all areas of cybersecurity: click
    fraud detection, identification of fake news, flagging abusive and hate speech
    content on social media, and so on.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你几乎可以在网络安全的所有领域找到类似的平行关系：点击欺诈检测、识别虚假新闻、在社交媒体上标记滥用和仇恨言论内容，等等。
- en: Entities that own the data are not thrilled about sharing it, which makes training
    ML models harder. Additionally, no entity can learn from the data acquired by
    other entities. Valuable knowledge and signals may be lost in the process, and
    models built on subsets of data will have inherent biases.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有数据的实体并不愿意分享数据，这使得训练机器学习模型变得更加困难。此外，没有任何实体可以从其他实体获取的数据中学习。在这个过程中，可能会丢失有价值的知识和信号，建立在数据子集上的模型将具有固有的偏差。
- en: Thus, it is extremely challenging, if not impossible, to construct a dataset
    that is good enough to train an ML model while maintaining privacy. Federated
    learning is an approach used to overcome this challenge.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在保持隐私的同时构建一个足够好的数据集来训练机器学习模型，这极具挑战性，甚至可能是不可能的。联邦学习是一种用来克服这一挑战的方法。
- en: How federated machine learning works
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 联邦机器学习是如何工作的
- en: FML (or simply FL) is a type of ML that allows multiple devices or organizations
    to collaborate on building a shared ML model without sharing their data. In traditional
    ML, all data is aggregated and processed in a central location, but in FML, the
    data remains distributed across multiple devices or locations, and the model is
    trained in a decentralized manner.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: FML（或简称FL）是一种机器学习方法，它允许多个设备或组织在不需要共享数据的情况下协作构建共享的机器学习模型。在传统的机器学习中，所有数据都集中在中央位置进行聚合和处理，但在FML中，数据分布在多个设备或位置，模型以去中心化的方式进行训练。
- en: The fundamental concept in federated learning is to share the learned model
    instead of sharing the data. Because of this, individual entities can share knowledge
    about patterns and parameters without having to disclose the data. We will now
    see how this is achieved in a step-by-step manner.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习的基本概念是共享学习到的模型，而不是共享数据。正因为如此，各个实体可以共享关于模式和参数的知识，而无需披露数据。我们现在将逐步了解这是如何实现的。
- en: Step 1 – data partitioning
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第1步 - 数据分区
- en: 'The data is partitioned across multiple devices or locations, where each one
    is known as a client. Each client has its own local data that is not shared with
    other devices. For example, in a medical setting, each hospital may have patient
    data that it is not willing to share with other hospitals. In the case of fraud
    detection, each credit card company will have examples of fraud. Note that every
    client will have data in varying sizes and distributions; however, all clients
    must preprocess their data in the same way to produce a uniform input vector of
    data. An example scenario is shown in *Figure 11**.1*; there are multiple clients
    shown, and each client draws data from different sources (a USB drive, a cloud
    server, a local file, a database, and so on). At each client, however, data is
    processed into the same standard form:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据被分配到多个设备或位置，每个设备或位置被称为一个客户端。每个客户端都有自己的本地数据，这些数据不会与其他设备共享。例如，在医疗环境中，每家医院可能都有不愿意与其他医院共享的患者数据。在欺诈检测的情况下，每家信用卡公司都会有欺诈的例子。请注意，每个客户端将具有不同大小和分布的数据；然而，所有客户端必须以相同的方式进行数据预处理，以生成统一的数据输入向量。一个示例场景如图*图11.1*所示；显示了多个客户端，每个客户端从不同的来源（U盘、云服务器、本地文件、数据库等）获取数据。然而，在每个客户端，数据都被处理成相同的标准形式：
- en: '![Figure 11.1 – Every client processes the data into a standard form](img/B19327_11_01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图11.1 – 每个客户端将数据处理成标准形式](img/B19327_11_01.jpg)'
- en: Figure 11.1 – Every client processes the data into a standard form
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 – 每个客户端将数据处理成标准形式
- en: Step 2 – global model initialization
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第2步 – 全局模型初始化
- en: 'A central server or client, known as an aggregator, initializes a global model.
    In this step, the model is initialized randomly, with parameters and weights drawn
    from a uniform normal distribution. The global model defines the structure and
    architecture that will be used by each client. The global model is distributed
    to each client for training, as shown in *Figure 11**.2*:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一个中央服务器或客户端，称为聚合器，初始化一个全局模型。在这一步中，模型以随机方式初始化，参数和权重来自均匀正态分布。全局模型定义了每个客户端将使用的结构和架构。全局模型被分发到每个客户端进行训练，如图*图11.2*所示：
- en: '![Figure 11.2 – Global model distributed to clients](img/B19327_11_02.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图11.2 – 全局模型分发至客户端](img/B19327_11_02.jpg)'
- en: Figure 11.2 – Global model distributed to clients
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 – 全局模型分发至客户端
- en: Step 3 – local training
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3步 – 本地训练
- en: 'After receiving the global model, each client trains the local model on the
    data they have. The local model is trained using standard ML techniques, such
    as stochastic gradient descent, and updates are made to the local model using
    the data available on that device. Up until now, the steps we have followed are
    similar to what an individual client would do in traditional ML. Each client will
    train and produce its own local model, as shown in *Figure 11**.3*:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在接收到全局模型后，每个客户端将使用他们拥有的数据进行本地模型训练。本地模型使用标准的机器学习技术进行训练，例如随机梯度下降，并使用该设备上可用的数据进行本地模型的更新。到目前为止，我们遵循的步骤与传统机器学习中的单个客户端所做的工作类似。每个客户端将训练并生成自己的本地模型，如图*图11.3*所示：
- en: '![Figure 11.3 – Local model training by clients](img/B19327_11_03.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图11.3 – 客户端进行本地模型训练](img/B19327_11_03.jpg)'
- en: Figure 11.3 – Local model training by clients
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 – 客户端进行本地模型训练
- en: Step 4 – model aggregation
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第4步 – 模型聚合
- en: 'The updated local models are then sent back to the central server or cloud,
    where they are aggregated to create an updated global model. This aggregation
    process can take different forms, such as averaging the local models or using
    more complex methods. To calculate the updated aggregated model, the received
    parameters are averaged and assigned to the new model. Recall that we distribute
    the global model to each client; thus, each client will have the same structure
    of the underlying model, which makes aggregation possible. In most cases, the
    strategy known as **federated averaging** is used. We calculate the average weighted
    by the size of the data; clients with more data are likely to produce a better
    model, and so their weights are assigned more importance in the average; this
    process is demonstrated in *Figure 11**.4*:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 更新的本地模型随后被发送回中央服务器或云端，在那里它们被聚合以创建更新的全局模型。这个聚合过程可以采取不同的形式，例如平均本地模型或使用更复杂的方法。为了计算更新的聚合模型，接收到的参数被平均并分配给新的模型。回想一下，我们将全局模型分发给每个客户端；因此，每个客户端都将具有底层模型的相同结构，这使得聚合成为可能。在大多数情况下，使用的是被称为**联邦平均**的策略。我们根据数据的大小计算加权平均值；数据量更多的客户端更有可能产生更好的模型，因此它们的权重在平均中分配得更加重要；这个过程在*图
    11**.4*中得到了演示：
- en: '![Figure 11.4 – Model aggregation](img/B19327_11_04.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.4 – 模型聚合](img/B19327_11_04.jpg)'
- en: Figure 11.4 – Model aggregation
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – 模型聚合
- en: Step 5 – model distribution
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 5 步 – 模型分发
- en: The aggregated model calculated in the previous step is distributed to each
    client. The client now takes this model and fine-tunes it using the local client
    data, thus updating it again. This time, however, the initialization is not random.
    The model parameters are the aggregated ones, meaning that they incorporate the
    learnings of all client nodes. After updating the model, it is sent back to the
    central server for aggregation. This continues for a fixed number of communication
    rounds.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一步计算出的聚合模型被分发给每个客户端。客户端现在使用本地客户端数据对这个模型进行微调，从而再次更新它。然而，这次初始化不是随机的。模型参数是聚合的，这意味着它们包含了所有客户端节点的学习成果。更新模型后，将其发送回中央服务器进行聚合。这个过程会持续进行固定数量的通信轮次。
- en: In summary, federated machine learning enables multiple devices or organizations
    to collaborate on building a shared ML model without sharing their data. This
    approach can improve data privacy, security, and efficiency, while still providing
    accurate and useful models.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，联邦机器学习允许多个设备或组织在不共享数据的情况下协作构建共享的机器学习模型。这种方法可以提高数据隐私、安全和效率，同时仍然提供准确和有用的模型。
- en: The benefits of federated learning
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 联邦学习的优势
- en: In this section, we will discuss the key advantages of federated learning.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论联邦学习的关键优势。
- en: Data privacy
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据隐私
- en: Data privacy is one of the most significant advantages of federated ML. In traditional
    ML approaches, data is collected and stored in a central location, and this can
    lead to concerns about data privacy and security. In federated learning, however,
    data remains on local devices or servers, and models are trained without ever
    sharing the raw data with a central server. This means that data remains secure
    and there is no risk of a data breach. Additionally, data owners retain control
    over their data, which is especially important in sensitive industries such as
    healthcare or finance, where privacy is of utmost importance.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据隐私是联邦机器学习最显著的优势之一。在传统的机器学习方法中，数据被收集并存储在中央位置，这可能导致对数据隐私和安全的担忧。然而，在联邦学习中，数据保留在本地设备或服务器上，模型训练过程中从未将原始数据与中央服务器共享。这意味着数据保持安全，没有数据泄露的风险。此外，数据所有者保留对其数据的控制权，这在医疗保健或金融等敏感行业中尤为重要，在这些行业中，隐私至关重要。
- en: Lower cost
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成本降低
- en: Federated machine learning can be a cost-effective solution for organizations
    as it allows them to leverage the computational power of multiple devices or servers
    without having to invest in expensive hardware or cloud computing services. This
    is because the devices or servers that are used to train the models already exist,
    and there is no need to purchase additional infrastructure. Additionally, the
    costs associated with transferring large amounts of data to a central server for
    analysis are also reduced as data remains on local devices or servers.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦机器学习可以成为组织的一种经济有效的解决方案，因为它允许它们利用多个设备或服务器的计算能力，而无需投资昂贵的硬件或云计算服务。这是因为用于训练模型的设备或服务器已经存在，且无需购买额外的基础设施。此外，将大量数据传输到中央服务器进行分析的相关成本也降低了，因为数据保留在本地设备或服务器上。
- en: Speed
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 速度
- en: Federated machine learning can also speed up the training process as each device
    or server can contribute to the training process. This is because models are trained
    locally on each device or server, and the updates are sent back to the central
    server, where they are combined to create a global model. Since each device or
    server is responsible for training only a subset of the data, the training process
    can be faster than traditional ML approaches. Additionally, because data remains
    on local devices or servers, there is no need to transfer large amounts of data
    to a central server, reducing network latency and speeding up the training process.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦机器学习还可以加快训练过程，因为每个设备或服务器都可以为训练过程做出贡献。这是因为模型在每个设备或服务器上本地训练，然后将更新发送回中央服务器，在那里它们被合并以创建全局模型。由于每个设备或服务器只负责训练数据的一个子集，因此训练过程可能比传统的机器学习方法更快。此外，由于数据保留在本地设备或服务器上，因此无需将大量数据传输到中央服务器，从而减少了网络延迟并加快了训练过程。
- en: Performance
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 性能
- en: FML allows models to be trained on more diverse datasets, leading to improved
    model accuracy. This is because data is distributed across multiple devices or
    servers, and each device or server may have slightly different data characteristics.
    By training models on a diverse set of data, models become more robust and can
    better generalize to new data. Additionally, models trained using FL can better
    account for the variability in the data and perform better in real-world scenarios.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: FML 允许模型在更多样化的数据集上训练，从而提高模型精度。这是因为数据分布在多个设备或服务器上，每个设备或服务器可能具有略微不同的数据特征。通过在多样化的数据集上训练模型，模型变得更加健壮，并能更好地泛化到新的数据。此外，使用
    FL 训练的模型可以更好地解释数据的可变性，并在实际场景中表现更佳。
- en: Challenges in federated learning
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 联邦学习的挑战
- en: Although federated machine learning offers significant benefits, such as preserving
    data privacy, there are several challenges that must be addressed to make it practical
    and effective.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管联邦机器学习提供了显著的益处，例如保护数据隐私，但必须解决一些挑战，才能使其实用且有效。
- en: Communication and network latency
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通信和网络延迟
- en: Federated machine learning involves multiple parties collaborating to train
    a model without sharing their data with each other. However, this requires frequent
    communication and exchange of large amounts of data and model updates between
    parties. The communication overhead and network latency can be significant, especially
    when the parties are located in different geographical locations and have limited
    bandwidth. This can slow down the training process and make it difficult to coordinate
    the training of the model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦机器学习涉及多个参与者协作训练一个模型，而无需相互共享数据。然而，这需要参与者之间频繁的通信和大量数据及模型更新的交换。通信开销和网络延迟可能很大，尤其是在参与者位于不同地理位置且带宽有限的情况下。这可能会减慢训练过程，并使协调模型训练变得困难。
- en: Data heterogeneity
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据异构性
- en: Federated machine learning involves different parties using their own data and
    hardware to train the model. This can lead to heterogeneity in the data and hardware,
    making it difficult to design a model that can effectively leverage the strengths
    of each party while mitigating the weaknesses. For example, some parties may have
    high-quality data, while others may have noisy data. Some parties may have powerful
    hardware, while others may have limited processing capabilities. It is important
    to design a model that can accommodate these differences and ensure that the training
    process is fair and unbiased.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦机器学习涉及不同方使用自己的数据和硬件来训练模型。这可能导致数据和硬件的异质性，使得设计一个能够有效利用各方的优势同时减轻弱点的模型变得困难。例如，一些方可能拥有高质量的数据，而其他方可能拥有噪声数据。一些方可能拥有强大的硬件，而其他方可能处理能力有限。设计一个能够适应这些差异并确保训练过程公平无偏的模型是重要的。
- en: Data imbalance and distribution shift
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据不平衡和分布偏移
- en: In federated learning, the data used by different parties may be highly imbalanced
    and may have different statistical properties. This can lead to distributional
    shifts and bias in the model, making it difficult to ensure that the model is
    fair and unbiased. For example, if one party has significantly more data than
    the other parties, the model may be biased toward that party’s data. It is important
    to address these issues by carefully selecting the data used for training and
    by using techniques such as data augmentation and sample weighting to mitigate
    the effects of data imbalance and distributional shifts.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在联邦学习中，不同方使用的数据可能高度不平衡，并且可能具有不同的统计特性。这可能导致分布偏移和模型偏差，使得确保模型公平和无偏变得困难。例如，如果一个方比其他方拥有显著更多的数据，模型可能会偏向该方的数据。通过仔细选择用于训练的数据以及使用数据增强和样本加权等技术来减轻数据不平衡和分布偏移的影响，这些问题是重要的。
- en: Free riders and rogue clients
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 免费搭车者和恶意客户端
- en: Federated learning is designed to preserve the privacy of the data owned by
    different parties. However, this also makes it challenging to ensure the security
    and privacy of the model and the data during training. For example, it may be
    difficult to ensure that the model updates sent by each party are genuine and
    have not been tampered with or corrupted. Additionally, it may be difficult to
    ensure that the data owned by each party remains private and secure, especially
    when parties are not fully trusted. It is important to develop secure and privacy-preserving
    techniques for federated learning to mitigate these risks.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习旨在保护不同方拥有的数据的隐私。然而，这也使得在训练过程中确保模型和数据的安全和隐私变得具有挑战性。例如，可能难以确保每个方发送的模型更新是真实的且未被篡改或损坏。此外，可能难以确保每个方拥有的数据保持私有和安全，尤其是在各方不完全信任的情况下。开发用于联邦学习的安全且隐私保护的技术以减轻这些风险是重要的。
- en: Federated optimization
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 联邦优化
- en: Federated machine learning requires the use of novel optimization techniques
    that can handle the distributed nature of the training process. These techniques
    must be able to aggregate the model updates from multiple parties while preserving
    the privacy and security of the data. This can be challenging, especially when
    dealing with large-scale datasets. Additionally, the optimization techniques used
    in federated learning must be efficient and scalable, as the training process
    can involve a large number of parties and a large amount of data.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦机器学习需要使用能够处理训练过程分布式特性的新颖优化技术。这些技术必须能够聚合来自多个方的模型更新，同时保护数据的隐私和安全。这可能会很具挑战性，尤其是在处理大规模数据集时。此外，联邦学习中使用的优化技术必须高效且可扩展，因为训练过程可能涉及大量方和大量数据。
- en: Overall, addressing these challenges requires a combination of advanced algorithms,
    techniques, and infrastructure. Despite these challenges, federated machine learning
    has the potential to enable a new era of collaborative ML while preserving privacy
    and security.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，解决这些挑战需要结合高级算法、技术和基础设施。尽管存在这些挑战，联邦机器学习仍有潜力开启一个协作机器学习的新时代，同时保护隐私和安全。
- en: This concludes our discussion of federated learning theory. Now that you have
    a good understanding of how the process works and what the pitfalls involved are,
    let us implement it practically.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了我们对联邦学习理论的讨论。现在，你已经很好地理解了该过程是如何工作的以及涉及到的陷阱，让我们来实际实施它。
- en: Implementing federated averaging
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施联邦平均化
- en: In this section, we will implement federated averaging with a practical use
    case in Python. Note that while we are using the MNIST dataset here as an example,
    this can easily be replicated for any dataset of your choosing.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Importing libraries
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We begin by importing the necessary libraries. We will need our standard Python
    libraries, along with some libraries from Keras, which will allow us to create
    our deep learning model. The following code snippet imports these libraries:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Let us now turn to the data we are using.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Dataset setup
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset we will be using is the MNIST dataset. The MNIST dataset is a popular
    benchmark dataset used in ML research. It is a collection of 70,000 grayscale
    images of handwritten digits, with each image being 28 x 28 pixels in size. The
    images are split into a training set of 60,000 examples and a test set of 10,000
    examples.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of the dataset is to train an ML model to correctly classify each
    image into the corresponding digit from 0 to 9\. The dataset has been widely used
    for training and testing various ML algorithms such as neural networks, support
    vector machines, and decision trees. The MNIST dataset has become a standard benchmark
    for evaluating the performance of image recognition algorithms, and it has been
    used as a starting point for many new ML researchers. It has also been used in
    many tutorials and online courses to teach the basics of image recognition and
    ML:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This completes the code to load and preprocess data.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Client setup
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we need to write a function that will initialize our client nodes. Note
    that in the real world, each client or entity will have its own data. However,
    as we are simulating this scenario, we will implement this manually. The function
    takes in the data and labels it as input, and returns partitioned data as output.
    It will break the data into roughly equal chunks and assign each chunk to one
    client:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will also write a helper function that, when given a chunk of data, will
    shuffle it, prepare it into tensors as needed, and return it to us:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It is now time to turn to the modeling.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Model implementation
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we will write a function that creates our actual classification model.
    This function takes in the hidden layer sizes as a parameter in the form of an
    array. At a high level, this function will perform the following steps:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Initialize a sequential Keras model.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the input layer based on the shape of the input data. Here, it is known
    to be `784`, as we are using the MNIST data.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the activation function of the input layer to be a **rectified linear**
    **unit** (**ReLU**).
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Parse the list of hidden layer sizes passed in as a parameter, and create hidden
    layers one by one. For example, the `[200, 200, 200]` parameter means that there
    are three hidden layers, each with 200 neurons.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the final layer. This will have the number of nodes equal to the number
    of classes, which, in this case, is `10`.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the activation of the final layer as `softmax` so it returns normalized
    output probabilities.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here is an implementation of these steps:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This function will initialize and return a model of the desired structure.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Weight scaling
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we will write a function that scales the weights. Note that as part of
    federated learning, we will aggregate the weights. If there is a wide disparity
    between the data sizes, it will reflect in the model performance. A model with
    smaller training data must contribute less to the aggregate. Therefore, we calculate
    a scaling factor for each client or node. This factor is simply the proportion
    of the global training data this client has access to. If there are 1,000 records
    globally, and client A has 210 records, the scaling factor is 0.21:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Global model initialization
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let us initialize the global model. This will be the shared central model
    that will hold the updated parameters in every communication round:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will show you the structure of the created model:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Model structure](img/B19327_11_05.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5 – Model structure
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have written functions to help us with the data and model. Now it
    is time to put them into action!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the experiment
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now use the function we defined earlier to load the training data.
    After binarizing the labels (that is, converting them into one-hot-encoding form),
    we will split the data into training and test sets. We will reserve 20% of the
    data for testing:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We will see the function we defined earlier to assign data to clients. This
    will return us a dictionary of client and data pairs, on which we will apply the
    chunk-collapsing function we wrote:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we will set a few parameters for our experiment. Note that as we have
    a multi-class classification problem, the choice of categorical cross-entropy
    as the loss is obvious. The learning rate and the number of communication rounds
    are hyperparameters – you can experiment with them:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now that we have everything set up, we can actually carry out federated learning.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we will actually carry out the federated learning process in multiple communication
    rounds. At a high level, here is what we are doing in each communication round:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Obtain the weights from the global model and shuffle client chunks.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For every client:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize a local model for training.
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the weights of the local model to the current global model.
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the local model with data from this client.
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on the amount of data available in this client, obtain scaled weights
    from this newly trained model.
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For memory management purposes, clear the local Keras session.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the average of all the weights obtained in *step 2*. As these are scaled
    weights, the average is a weighted one.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the average weights to be the weights for the new global model.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the accuracy of this model (new global model with the newly assigned
    weights).
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print information about loss and accuracy.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *steps 1–7* for each communication round. In every round, the global
    model is gradually updated.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s the code to implement these steps:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The result here will be a series of statements that show how the loss and accuracy
    changed from round to round. Here is what the first 10 rounds look like:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – First 10 rounds in the training loop](img/B19327_11_06.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: Figure 11.6 – First 10 rounds in the training loop
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'And this is how the last 10 rounds look:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Last 10 rounds in the training loop](img/B19327_11_07.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
- en: Figure 11.7 – Last 10 rounds in the training loop
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Due to the random initialization of initial weights and shuffling, the results
    will change every time we run this. Therefore, the numbers you obtain when you
    try to recreate this will be different than what is shown here. This is expected.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'We can visualize these trends with a plot that will show us the loss over the
    rounds:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output would be something like this:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Loss trend over rounds](img/B19327_11_08.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
- en: Figure 11.8 – Loss trend over rounds
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we can plot the accuracy:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This will produce the following plot:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Accuracy trend over rounds](img/B19327_11_09.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 – Accuracy trend over rounds
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Thus, with federated machine learning, we were able to improve the accuracy
    of the global model from around 72% to over 92%. Interestingly, you can see that
    the accuracy somewhat drops around round 25 or 0\. This is probably because of
    overfitting the data on some particular client’s local training data.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the privacy-utility trade-off in federated learning
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous section, we examined the effectiveness of federated learning
    and looked at the model performance over multiple communication rounds. However,
    to quantify the effectiveness, we need to compare this against two benchmarks:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: A model trained on the entire data with no federation involved
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A local model trained on its own data only
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The differences in accuracy in these three cases (federated, global only, and
    local only) will indicate the trade-offs we are making and the gains we achieve.
    In the previous section, we looked at the accuracy we obtain via federated learning.
    To understand the utility-privacy trade-off, let us discuss two extreme cases
    – a fully global and a fully local model.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Global model (no privacy)
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we train a global model directly, we use all the data to train a single
    model. Thus, all parties involved would be publicly sharing their data with each
    other. The central aggregator would have access to all of the data. In this case,
    as the data is shared, there is no privacy afforded to clients.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'To train the global model on the entire data, we will re-initialize the global
    model and fit it with the entire training data (instead of individual client data).
    Here is the code snippet for that:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You should see output as follows, which shows the accuracy and loss through
    each epoch:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Global model training](img/B19327_11_10.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 – Global model training
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: We see that the fully global model performs much better (it starts at 92% and
    finishes at 95%) in just a few epochs. This means that it is more powerful than
    the federated model. This is the trade-off we make in the federated learning;
    we have to sacrifice performance and accuracy for privacy.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Local model (full privacy)
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, to evaluate the performance of our local model, we will pick a random
    client (say client 8) and train a model only on that client’s data:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The result is as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – Local model training](img/B19327_11_11.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 – Local model training
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Here, we see that the model started off really poorly (an accuracy of less than
    20%, which is worse even than a random guessing classifier). Over the epochs,
    the model performance improved. However, the accuracy at the end was a little
    above 48%, which is worse than the federated model.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the trade-off
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The results we have obtained from the previous two subsections show us two
    things:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: A model that performs federated learning performs better than a model trained
    only on a client’s local data. Thus, a client is able to benefit from the model
    learned by other clients through parameter sharing and aggregation, which can
    be achieved without sharing data.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A global model trained on the entire data performs better than the federated
    learning model.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This clearly demonstrates the privacy-utility trade-off. As we increase the
    privacy (apply federated learning), the utility of the data decreases, as reflected
    in the model performance. At no privacy (all clients share data and use it to
    train a global model), utility is the highest.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: While the trade-off may be harder to understand given the dataset we have used
    here (after all, what privacy concerns do we face in sharing images of handwritten
    digits?), it becomes more obvious as we enter the security domain. Recall that
    in the very first chapter, we discussed how ML in the security domain is different
    than in other domains, such as image recognition or advertisement targeting, as
    the stakes are higher here.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Instead of image recognition, consider this to be a credit card fraud detection
    scenario. The client nodes are various banks and credit card companies. Every
    company has labeled examples of fraud that they do not want to share.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: If the companies share all of the data with each other, it will allow them to
    train a global model. As different companies will have different patterns and
    examples of fraud, the model generated will be able to detect multiple attack
    patterns. This will benefit each company involved; company *A* will be able to
    detect a certain kind of fraud even if it has never seen it before if another
    company, *B*, has ever observed it. However, at the same time, companies risk
    their proprietary data being leaked and personally identifying user data being
    exposed. There also may be reputational harm if the occurrence of fraud comes
    to light. Therefore, the high performance and generalizability come at the cost
    of a loss of privacy.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, consider that the companies do not share any data at all.
    Thus, each company will be able to train a model on the data it has access to.
    In this case, company *A* will not be able to detect out-of-distribution fraud
    or novel attack patterns that it has not seen before. This will result in a low
    recall in detecting fraud and might cause severe losses to the company. Therefore,
    the high privacy and confidentiality come at the cost of reduced performance and
    potential financial loss.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Federated learning is able to solve both of these issues and provide us with
    the perfect middle ground between privacy and utility. Because federated learning
    involves sharing model parameters and not data, privacy can be maintained, and
    personal information will not be released. At the same time, because the models
    are shared and aggregated, learnings from one client will be beneficial to others
    as well.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the MNIST dataset
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we chose the MNIST dataset for our experiments. While MNIST
    is a popular benchmark for image processing, it is not ideal for security applications.
    However, we chose it for two reasons. First, it is a fairly large and well-distributed
    dataset that makes federated learning simpler. Other public datasets are relatively
    small, which means that when sharded, clients have only a small amount of data
    that is not enough to produce a reasonable model. Second, being an image dataset,
    it is naturally suited to be processed by neural networks.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'The applications of federated learning are not limited to images. You are encouraged
    to explore all of the problems we have looked at in this book so far (malware,
    fake news, and intrusion detection) and implement them in a federated manner.
    To do so, only two changes are required:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Change the data loading mechanism to read from the appropriate data source instead
    of MNIST
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the deep learning model structure to reflect the input and output dimensions
    specific to the dataset
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rest of the steps (initializing the model, sharding the data, communication
    rounds, and so on) all remain the same. You should implement federated learning
    in various cybersecurity areas and observe the privacy-utility trade-off.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about a privacy preservation mechanism for ML known
    as federated learning. In traditional ML, all data is aggregated and processed
    in a central location, but in FML, the data remains distributed across multiple
    devices or locations, and the model is trained in a decentralized manner. In FML,
    we share the model and not the data.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: We discussed the core concepts and working of FML, followed by an implementation
    in Python. We also benchmarked the performance of federated learning against traditional
    ML approaches to examine the privacy-utility trade-off. This chapter provided
    an introduction to an important aspect of ML and one that is gaining rapid traction
    in today’s privacy-centric technology world.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will go a step further and look at the hottest topic
    in ML privacy today – differential privacy.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
