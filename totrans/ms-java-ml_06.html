<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Probabilistic Graph Modeling"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Probabilistic Graph Modeling</h1></div></div></div><p>
<span class="strong"><strong>Probabilistic graph models</strong></span> (<span class="strong"><strong>PGMs</strong></span>), also known as graph models, capture the relationship <a id="id1168" class="indexterm"/>between different variables and represent the probability distributions. PGMs capture joint probability distributions and can be used to answer different queries and make inferences that allow us to make predictions on unseen data. PGMs have the great advantage of capturing domain knowledge of experts and the causal relationship between variables to model systems. PGMs represent the structure and they can capture knowledge in a representational framework that makes it easier to share and understand the domain and models. PGMs capture the uncertainty or the probabilistic nature very well and are thus very useful in applications that need scoring or uncertainty-based approaches. PGMs are used in a wide variety of applications that use machine learning such as applications to domains of language processing, text mining and information extraction, computer vision, disease diagnosis, and DNA structure predictions. </p><p>Judea Pearl is the pioneer in the area of PGMs and was the first to introduce the topic of Bayesian Networks (<span class="emphasis"><em>References</em></span> [2] and [7]). Although covering all there is to know about PGMs is beyond the scope of this chapter, our goal is to cover the most important aspects of PGMs—Bayes network and directed PGMs—in some detail. We will divide the subject into the areas of representation, inference, and learning and will discuss specific algorithms and sub-topics in each of these areas. We will cover Markov Networks and undirected PGMs, summarizing some differences and similarities with PGMs, and addressing related areas such as inference and learning. Finally, we will discuss <a id="id1169" class="indexterm"/>specialized networks such as <span class="strong"><strong>tree augmented </strong></span>
<a id="id1170" class="indexterm"/>
<span class="strong"><strong>networks</strong></span> (<span class="strong"><strong>TAN</strong></span>), Markov chains and <span class="strong"><strong>hidden Markov models</strong></span> (<span class="strong"><strong>HMM</strong></span>). For an in-depth treatment of the subject, see <span class="emphasis"><em>Probabilistic Graphical Models</em></span>, by Koller and Friedman (<span class="emphasis"><em>References</em></span> [1]).</p><div class="section" title="Probability revisited"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec51"/>Probability revisited</h1></div></div></div><p>Many basic concepts of <a id="id1171" class="indexterm"/>probability are detailed in <a class="link" href="apb.html" title="Appendix B. Probability">Appendix B</a>, <span class="emphasis"><em>Probability</em></span>. Some of the key ideas in probability theory form the building blocks of probabilistic graph models. A good grasp of the relevant theory can help a great deal in understanding PGMs <a id="id1172" class="indexterm"/>and how they are used to make inferences from data.</p><div class="section" title="Concepts in probability"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec86"/>Concepts in probability</h2></div></div></div><p>In this section, we will discuss <a id="id1173" class="indexterm"/>important concepts related to probability theory that will be used in the discussion later in this chapter.</p><div class="section" title="Conditional probability"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec97"/>Conditional probability</h3></div></div></div><p>The essence of conditional <a id="id1174" class="indexterm"/>probability, given two related events a and ß, is to capture how we assign a value for one of the events when the other is known to have occurred. The conditional probability, or the conditional distribution, is represented by <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>a </em></span>| <span class="emphasis"><em>ß</em></span>), that is, the probability of event <span class="emphasis"><em>a</em></span> happening given that the event <span class="emphasis"><em>ß</em></span> has occurred (equivalently, given that <span class="emphasis"><em>ß</em></span> is true) and is formally defined as:</p><div class="mediaobject"><img src="graphics/B05137_06_018.jpg" alt="Conditional probability"/></div><p>The <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>a</em></span> n <span class="emphasis"><em>ß</em></span>) captures the events where both a and ß occur.</p></div><div class="section" title="Chain rule and Bayes' theorem"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec98"/>Chain rule and Bayes' theorem</h3></div></div></div><p>The conditional <a id="id1175" class="indexterm"/>probability definition gives rise to the chain rule of conditional probabilities that says that when there are multiple events α<sub>1</sub>, α<sub>2</sub>….α<sub>n</sub> then:</p><p>
<span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>α</em></span><sub>1</sub> ∩ <span class="emphasis"><em>α</em></span><sub>2</sub> ∩….∩ <span class="emphasis"><em>α</em></span><sub>n</sub> ) = <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>α</em></span><sub>1</sub> )<span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>α</em></span><sub>2</sub> ¦ <span class="emphasis"><em>α</em></span><sub>1</sub>)<span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>α</em></span><sub>3</sub> | <span class="emphasis"><em>α</em></span><sub>1</sub> ∩ <span class="emphasis"><em>α</em></span><sub>2</sub>)..<span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>α</em></span><sub>∩</sub> |<span class="emphasis"><em>α</em></span><sub>1</sub> ∩ <span class="emphasis"><em>α</em></span><sub>2</sub> ∩….∩ <span class="emphasis"><em>α</em></span><sub>n-1</sub>)</p><p>The probability of several events can be expressed as the probability of the first times the probability of the second given the first, and so on. Thus, the probability of <span class="emphasis"><em>α</em></span><sub>n</sub> depends on everything α<sub>1</sub> to α<sub>n</sub> and is independent of the order of the events.</p><p>Bayes rule also follows from the conditional probability rule and can be given formally as:</p><div class="mediaobject"><img src="graphics/B05137_06_024.jpg" alt="Chain rule and Bayes' theorem"/></div></div><div class="section" title="Random variables, joint, and marginal distributions"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec99"/>Random variables, joint, and marginal distributions</h3></div></div></div><p>It is natural to <a id="id1176" class="indexterm"/>map the event spaces and outcomes by considering them as <a id="id1177" class="indexterm"/>attributes and values. Random variables are defined as <a id="id1178" class="indexterm"/>attributes with different known specific values. For example, if <span class="emphasis"><em>Grade</em></span> is an attribute associated with <span class="emphasis"><em>Student</em></span>, and has values <span class="emphasis"><em>{A, B, C}</em></span>, then <span class="emphasis"><em>P(Grade = A)</em></span> represents a random variable with an outcome. </p><p>Random variables are generally denoted by capital letters, such as <span class="emphasis"><em>X</em></span>, <span class="emphasis"><em>Y</em></span>, and <span class="emphasis"><em>Z</em></span> and values taken by them are denoted by <span class="emphasis"><em>Val(X) = x</em></span>. In this chapter, we will primarily discuss values that are categorical in nature, that is, that take a fixed number of discrete values. In the real world, the variables can have continuous representations too. The distribution of a variable with categories {x<sup>1</sup>, x<sup>2</sup> …x<sup>n</sup>} can be represented as:</p><div class="mediaobject"><img src="graphics/B05137_06_030.jpg" alt="Random variables, joint, and marginal distributions"/></div><p>Such a distribution <a id="id1179" class="indexterm"/>over many categories is called a <span class="strong"><strong>multinomial distribution</strong></span>. In the special case when there are only two categories, the distribution is <a id="id1180" class="indexterm"/>said to be the <span class="strong"><strong>Bernoulli distribution</strong></span>.</p><p>Given a random variable, a probability distribution over all the events described by that variable is known as <a id="id1181" class="indexterm"/>the marginal distribution. For example, if Grade is the random variable, the marginal distribution can be defined as <span class="emphasis"><em>(Grade = A) = 0.25, P(Grade = b) = 0.37 and P(Grade = C) = 0.38</em></span>.</p><p>In many real-world models, there are more than one random variables and the distribution that considers all of these random variable is called the <span class="strong"><strong>joint distribution</strong></span>. For example, if <span class="emphasis"><em>Intelligence</em></span> of student is <a id="id1182" class="indexterm"/>considered as another variable and denoted by <span class="emphasis"><em>P(Intelligence)</em></span> or <span class="emphasis"><em>P(I)</em></span> and has binary outcomes <span class="emphasis"><em>{low, high}</em></span>, then the distribution considering <span class="emphasis"><em>Intelligence</em></span> and <span class="emphasis"><em>Grade</em></span> represented as <span class="emphasis"><em>P(Intelligence, Grade)</em></span> or <span class="emphasis"><em>P(I, G)</em></span>, is the joint distribution.</p><p>Marginal distribution of one random variable can be computed from the joint distribution by summing up the values over all of the other variables. The marginal distribution over grade can be obtained by summing over all the rows as shown in <span class="emphasis"><em>Table 1</em></span> and that over the intelligence can be obtained by summation over the columns.</p><div class="mediaobject"><img src="graphics/B05137_06_037.jpg" alt="Random variables, joint, and marginal distributions"/><div class="caption"><p> Table 1. Marginal distributions over I and G </p></div></div></div><div class="section" title="Marginal independence and conditional independence"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec100"/>Marginal independence and conditional independence</h3></div></div></div><p>Marginal <a id="id1183" class="indexterm"/>Independence is defined as follows. Consider two <a id="id1184" class="indexterm"/>random variables <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span>; then <span class="emphasis"><em>P(X|Y) = P(X)</em></span> means random variable <span class="emphasis"><em>X</em></span> is independent of <span class="emphasis"><em>Y</em></span>. It is formally represented as <span class="inlinemediaobject"><img src="graphics/B05137_06_042.jpg" alt="Marginal independence and conditional independence"/></span> (<span class="emphasis"><em>P</em></span> satisfies <span class="emphasis"><em>X</em></span> is independent of <span class="emphasis"><em>Y</em></span>).</p><p>This means the joint distribution can be given as:</p><p>
<span class="emphasis"><em>P(X, Y) = P(X)P(Y)</em></span>
</p><p>If the difficulty level of the exam (<span class="emphasis"><em>D</em></span>) and the intelligence of the student (<span class="emphasis"><em>I</em></span>) determine the grade (<span class="emphasis"><em>G</em></span>), we know that the difficulty level of the exam is independent of the intelligence of the student and (<span class="emphasis"><em>D</em></span> ⊥ <span class="emphasis"><em>I</em></span>) also implies <span class="emphasis"><em>P(D, I) = P(D)P(I)</em></span>.</p><p>When two random variables are independent given a third variable, the independence is called conditional independence. Given a set of three random variables <span class="emphasis"><em>X</em></span>, <span class="emphasis"><em>Y</em></span>, and <span class="emphasis"><em>Z</em></span>, we can say that <span class="inlinemediaobject"><img src="graphics/B05137_06_051.jpg" alt="Marginal independence and conditional independence"/></span>; that is, variable <span class="emphasis"><em>X</em></span> is independent of <span class="emphasis"><em>Y</em></span> given <span class="emphasis"><em>Z</em></span>. The necessary condition for conditional independence is </p><div class="mediaobject"><img src="graphics/B05137_06_052.jpg" alt="Marginal independence and conditional independence"/></div></div><div class="section" title="Factors"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec101"/>Factors</h3></div></div></div><p>Factors are the basic building <a id="id1185" class="indexterm"/>blocks for defining the probability distributions in high-dimensional (large number of variables) spaces. They give basic operations that help in manipulating the probability distributions. </p><p>A "factor" is defined as a function that takes as input the random variables known as "scope" and gives a real-value output. </p><p>Formally, a factor is represented as <span class="inlinemediaobject"><img src="graphics/B05137_06_053.jpg" alt="Factors"/></span> where scope is (X<sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>, ….<span class="emphasis"><em>X</em></span><sub>k</sub> ).</p><div class="section" title="Factor types"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec159"/>Factor types</h4></div></div></div><p>Different types <a id="id1186" class="indexterm"/>of factors are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Joint distribution</strong></span>: For <a id="id1187" class="indexterm"/>every combination of variables, you get a real-valued output.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Unnormalized measure</strong></span>: When, in a joint distribution, one of the variables is constant, the <a id="id1188" class="indexterm"/>output is also real-valued, but it is unnormalized as it doesn't sum to one. However, it is still a factor. </li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Conditional probability distribution</strong></span>: A probability distribution of the form <span class="emphasis"><em>P(G|I)</em></span> is <a id="id1189" class="indexterm"/>also a factor. </li></ul></div><p>Various operations are performed on factors, such as:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Factor product</strong></span>: If two factors <span class="emphasis"><em>ϕ</em></span><sub>1</sub> (<span class="emphasis"><em>X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>) and <span class="emphasis"><em>ϕ</em></span><sub>2</sub> (<span class="emphasis"><em>X</em></span><sub>2</sub>, <span class="emphasis"><em>X</em></span><sub>3</sub>) are multiplied, it gives rise to <span class="emphasis"><em>ϕ</em></span><sub>3</sub> (<span class="emphasis"><em>X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>, <span class="emphasis"><em>X</em></span><sub>3</sub>). In effect, it is taking tables corresponding to <span class="emphasis"><em>ϕ</em></span><sub>1</sub> and multiplying it with <span class="emphasis"><em>ϕ</em></span><sub>2</sub></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Factor marginalization</strong></span>: This is the same as marginalization, where <span class="emphasis"><em>ϕ</em></span><sub>1</sub> (<span class="emphasis"><em>X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>, <span class="emphasis"><em>X</em></span><sub>3</sub>) can be marginalized over a variable, say <span class="emphasis"><em>X</em></span><sub>2</sub>, to give <span class="emphasis"><em>ϕ</em></span><sub>2</sub> (<span class="emphasis"><em>X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>3</sub>).</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Factor reduction</strong></span>: This is only taking the values of other variables when one of the variables is constant.</li></ul></div></div></div><div class="section" title="Distribution queries"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec102"/>Distribution queries</h3></div></div></div><p>Given the probability <a id="id1190" class="indexterm"/>over random variables, many queries can be performed to answer certain questions. Some common types of queries are explained in the subsequent sections.</p><div class="section" title="Probabilistic queries"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec160"/>Probabilistic queries</h4></div></div></div><p>This is one of the <a id="id1191" class="indexterm"/>most common types of query and it has two parts:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Evidence</strong></span>: A subset of variables with a well-known outcome or category. For example, a random variable <span class="strong"><strong>E = e</strong></span>.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Query</strong></span>: A random variable from the rest of the variables. For example, a random variable <span class="strong"><strong>X</strong></span>.<p>
<span class="emphasis"><em>P</em></span>(<span class="strong"><strong>X</strong></span>|<span class="strong"><strong>E</strong></span> = <span class="strong"><strong>e</strong></span>)</p></li></ul></div><p>Examples of probabilistic queries are posterior marginal estimations such as <span class="emphasis"><em>P(I = high|L = bad, S = low) = ?</em></span> and evidential probability such as <span class="emphasis"><em>P(L = bad, S = low) = ?</em></span>.</p></div><div class="section" title="MAP queries and marginal MAP queries"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec161"/>MAP queries and marginal MAP queries</h4></div></div></div><p>MAP queries are <a id="id1192" class="indexterm"/>used to find the probability assignment to the <a id="id1193" class="indexterm"/>subset of variables that are most likely and hence <a id="id1194" class="indexterm"/>are also called <span class="strong"><strong>most probable explanation</strong></span> (<span class="strong"><strong>MPE</strong></span>). The difference between these and probabilistic queries is that, instead of getting the probability, we get the most likely values for all the variables. </p><p>Formally, if we have variables <span class="emphasis"><em>W= X – E</em></span>, where we have <span class="emphasis"><em>E = e</em></span> as the evidence and are interested in finding the most likely assignment to the variables in <span class="emphasis"><em>W</em></span>, </p><p>
<span class="emphasis"><em>MAP</em></span>(<span class="strong"><strong>W</strong></span>|<span class="strong"><strong>e</strong></span>) = <span class="emphasis"><em>argmax</em></span><sub>w</sub><span class="emphasis"><em>P</em></span>(<span class="strong"><strong>w</strong></span>,<span class="strong"><strong>e</strong></span>)</p><p>A much more general form of marginal query is when we have a subset of variables, say given by <span class="emphasis"><em>Y</em></span> that forms our query and with evidence of <span class="emphasis"><em>E = e</em></span>, we are interested in finding most likely assignments to the variables in <span class="emphasis"><em>Y</em></span>. Using the MAP definition, we get:</p><p>
<span class="emphasis"><em>MAP</em></span>(<span class="strong"><strong>Y</strong></span>|<span class="strong"><strong>e</strong></span>) = <span class="emphasis"><em>argmax</em></span><sub>y</sub><span class="emphasis"><em>P</em></span>(<span class="strong"><strong>y</strong></span>|<span class="strong"><strong>e</strong></span>)</p><p>Let's say, <span class="emphasis"><em>Z= X – Y – E</em></span>, then the marginal MAP query is:</p><div class="mediaobject"><img src="graphics/B05137_06_424a.jpg" alt="MAP queries and marginal MAP queries"/></div></div></div></div></div></div>
<div class="section" title="Graph concepts"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec52"/>Graph concepts</h1></div></div></div><p>Next, we will briefly <a id="id1195" class="indexterm"/>revisit the concepts from graph theory and some of the definitions that we will use in this chapter. </p><div class="section" title="Graph structure and properties"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec87"/>Graph structure and properties</h2></div></div></div><p>A graph is defined as a <a id="id1196" class="indexterm"/>data structure containing nodes and edges connecting these nodes. In the context of this chapter, the random variables are represented as nodes,  and edges show connections between the random variables. </p><p>Formally, if <span class="emphasis"><em>X = {X</em></span><sub>1</sub><span class="emphasis"><em>, X</em></span><sub>2</sub><span class="emphasis"><em>,….X</em></span><sub>k</sub><span class="emphasis"><em>}</em></span> where <span class="emphasis"><em>X</em></span><sub>1</sub><span class="emphasis"><em>, X</em></span><sub>2</sub><span class="emphasis"><em>,….X</em></span><sub>k</sub> are random variables representing the nodes, then there can either be a directed edge belonging to the set e, for example, between the nodes given by <span class="inlinemediaobject"><img src="graphics/B05137_06_079.jpg" alt="Graph structure and properties"/></span> or an <span class="strong"><strong>undirected edge</strong></span> <span class="inlinemediaobject"><img src="graphics/B05137_06_079.jpg" alt="Graph structure and properties"/></span>, and the graph is defined as a data structure <span class="inlinemediaobject"><img src="graphics/B05137_06_081.jpg" alt="Graph structure and properties"/></span>. A graph is said to be a <span class="strong"><strong>directed graph</strong></span> when every edge in the set e between nodes from set <span class="strong"><strong>X</strong></span> is directed and similarly an <span class="strong"><strong>undirected graph</strong></span> is one where every edge between the nodes is undirected as shown in <span class="emphasis"><em>Figure 1</em></span>. Also, if there is a graph that has both directed and undirected edges, the notation of <span class="inlinemediaobject"><img src="graphics/B05137_06_084.jpg" alt="Graph structure and properties"/></span> represents an edge that may be directed or undirected.</p><div class="mediaobject"><img src="graphics/B05137_06_086.jpg" alt="Graph structure and properties"/><div class="caption"><p>Figure 1. Directed, undirected, and partially-directed graphs</p></div></div><p>If a directed edge <span class="inlinemediaobject"><img src="graphics/B05137_06_087.jpg" alt="Graph structure and properties"/></span> exists in the graph, the node <span class="emphasis"><em>X</em></span><sub>i</sub> is called the <span class="emphasis"><em>parent</em></span> node and the node <span class="emphasis"><em>X</em></span><sub>j</sub> is called the <span class="emphasis"><em>child</em></span> node.</p><p>In the case of an undirected graph, if there is an edge <span class="emphasis"><em>X</em></span><sub>i</sub><span class="emphasis"><em> – X</em></span><sub>j</sub>, the nodes <span class="emphasis"><em>X</em></span><sub>i</sub> and <span class="emphasis"><em>X</em></span><sub>j</sub> are said to be neighbors. </p><p>The set of parents of node <span class="emphasis"><em>X</em></span> in a directed graph is called the boundary of the node <span class="emphasis"><em>X</em></span> and similarly, adjacent nodes in an undirected graph form each other's boundary. The degree of the node <span class="emphasis"><em>X</em></span> is the number of edges it participates in. The indegree of the node <span class="emphasis"><em>X</em></span> is the number of edges in the directed graph that have a relationship to node <span class="emphasis"><em>X</em></span> such that the edge is between node <span class="emphasis"><em>Y</em></span> and node <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>X</em></span> → <span class="emphasis"><em>Y</em></span>. The degree of the graph is the maximal degree of the node in that graph.</p></div><div class="section" title="Subgraphs and cliques"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec88"/>Subgraphs and cliques</h2></div></div></div><p>A subgraph is part <a id="id1197" class="indexterm"/>of the graph that represents some of the nodes from the entire set. A <span class="strong"><strong>clique</strong></span> is a subset of vertices in an undirected graph such that every two distinct vertices are adjacent.</p></div><div class="section" title="Path, trail, and cycles"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec89"/>Path, trail, and cycles</h2></div></div></div><p>If there are <a id="id1198" class="indexterm"/>variables <span class="emphasis"><em>X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>, …. <span class="emphasis"><em>X</em></span><sub>k</sub> in the graph <span class="emphasis"><em>K = (X, E)</em></span>, it forms a path if, for every <span class="emphasis"><em>i</em></span> = 1, 2 ... <span class="emphasis"><em>k</em></span> – 1, we have either <span class="inlinemediaobject"><img src="graphics/B05137_06_093.jpg" alt="Path, trail, and cycles"/></span> or <span class="emphasis"><em>X</em></span><sub>i</sub><span class="emphasis"><em> –X</em></span><sub>j</sub>; that is, there is either a directed edge <a id="id1199" class="indexterm"/>or an undirected edge between the variables—recall this can be <a id="id1200" class="indexterm"/>depicted as <span class="emphasis"><em>X</em></span><sub>i</sub> ? <span class="emphasis"><em>X</em></span><sub>j</sub>. A directed path has at least one directed edge: <span class="inlinemediaobject"><img src="graphics/B05137_06_093.jpg" alt="Path, trail, and cycles"/></span>. </p><p>If there are variables <span class="emphasis"><em>X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>, …. <span class="emphasis"><em>X</em></span><sub>k</sub> in the graph <span class="emphasis"><em>K = (X, E)</em></span> it forms a <span class="emphasis"><em>trail</em></span> if for every <span class="emphasis"><em>i</em></span> = 1, 2 ... <span class="emphasis"><em>k</em></span> – 1, we have either <span class="inlinemediaobject"><img src="graphics/B05137_06_094.jpg" alt="Path, trail, and cycles"/></span>.</p><p>A graph is called a <span class="strong"><strong>connected</strong></span> graph, if for every <span class="emphasis"><em>X</em></span><sub>i</sub>, ….<span class="emphasis"><em>X</em></span><sub>j</sub> there is a trail between <span class="emphasis"><em>X</em></span><sub>i</sub> and<span class="emphasis"><em> X</em></span><sub>j</sub>.</p><p>In a graph <span class="emphasis"><em>K = (X, e)</em></span>, if there is a directed path between nodes <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span>, <span class="emphasis"><em>X</em></span> is called the ancestor of <span class="emphasis"><em>Y</em></span> and <span class="emphasis"><em>Y</em></span> is called the <span class="emphasis"><em>descendant</em></span> of <span class="emphasis"><em>X</em></span>.</p><p>If a graph <span class="emphasis"><em>K</em></span> has a directed path <span class="emphasis"><em>X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>, …. <span class="emphasis"><em>X</em></span><sub>k</sub> where<span class="emphasis"><em> X</em></span><sub>1</sub> ? <span class="emphasis"><em>X</em></span><sub>k</sub>, the path is called a <span class="strong"><strong>cycle</strong></span>. Conversely, a graph with no cycles is called an <span class="strong"><strong>acyclic</strong></span> graph. </p></div></div>
<div class="section" title="Bayesian networks"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec53"/>Bayesian networks</h1></div></div></div><p>Generally, all Probabilistic <a id="id1201" class="indexterm"/>Graphical Models have three basic elements that form the important sections:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Representation</strong></span>: This answers the question of what does the model mean or represent. The <a id="id1202" class="indexterm"/>idea is how to represent and store the probability distribution of <span class="emphasis"><em>P(X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>, …. <span class="emphasis"><em>X</em></span><sub>n</sub><span class="emphasis"><em>)</em></span>.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Inference</strong></span>: This answers the question: given the model, how do we perform queries and <a id="id1203" class="indexterm"/>get answers. This gives us the ability to infer the values of the unknown from the known evidence given the structure of the models. Motivating the main discussion points are various forms of inferences involving trade-offs between computational and correctness concerns.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Learning</strong></span>: This <a id="id1204" class="indexterm"/>answers the question of what model is right given the data. Learning is divided into two main parts:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Learning the parameters given the structure and data</li><li class="listitem" style="list-style-type: disc">Learning the structure with parameters given the data</li></ul></div></li></ul></div><p>We will use the well-known student network as an example of a Bayesian network in our discussions to illustrate the concepts and theory. The student network has five random variables capturing the relationship between various attributes defined as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Difficulty of the exam (<span class="emphasis"><em>D</em></span>) </li><li class="listitem" style="list-style-type: disc">Intelligence of the student (<span class="emphasis"><em>I</em></span>) </li><li class="listitem" style="list-style-type: disc">Grade the student gets (<span class="emphasis"><em>G</em></span>)</li><li class="listitem" style="list-style-type: disc">SAT score of the student (<span class="emphasis"><em>S</em></span>)</li><li class="listitem" style="list-style-type: disc">Recommendation Letter the student gets based on grade (<span class="emphasis"><em>L</em></span>).</li></ul></div><p>Each of these attributes has binary categorical values, for example, the variable <span class="emphasis"><em>Difficulty</em></span> (<span class="emphasis"><em>D</em></span>) has two categories (<span class="emphasis"><em>d</em></span>0, <span class="emphasis"><em>d</em></span>1) corresponding to low and high, respectively. <span class="emphasis"><em>Grades</em></span> (<span class="emphasis"><em>G</em></span>) has three categorical values corresponding to the grades <span class="emphasis"><em>(A, B, C)</em></span>. The arrows as indicated in the section on <a id="id1205" class="indexterm"/>graphs indicate the dependencies encoded from the domain knowledge—for example, <span class="emphasis"><em>Grade</em></span> can be determined given that we know the <span class="emphasis"><em>Difficulty</em></span> of the exam and <span class="emphasis"><em>Intelligence</em></span> of the student while the <span class="emphasis"><em>Recommendation Letter</em></span> is completely determined if we know just the <span class="emphasis"><em>Grade</em></span> (<span class="emphasis"><em>Figure 2</em></span>). It can be further observed that no explicit edge between the variables indicates that they are independent of each other—for example, the <span class="emphasis"><em>Difficulty</em></span> of the exam and <span class="emphasis"><em>Intelligence</em></span> of the student are independent variables.</p><div class="mediaobject"><img src="graphics/B05137_06_107.jpg" alt="Bayesian networks"/></div><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>Figure 2. The "Student" network</em></span></p></blockquote></div><div class="section" title="Representation"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec90"/>Representation</h2></div></div></div><p>A graph compactly <a id="id1206" class="indexterm"/>represents the complex relationships between <a id="id1207" class="indexterm"/>random variables, allowing fast algorithms to make queries where a full enumeration would be prohibitive. In the concepts defined here, we show how directed acyclic graph structures and conditional independence make problems involving large numbers of variables tractable.  </p><div class="section" title="Definition"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec103"/>Definition</h3></div></div></div><p>A Bayesian <a id="id1208" class="indexterm"/>network is defined as a model of a system with: </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A number of random variables {<span class="emphasis"><em>X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>, …. <span class="emphasis"><em>X</em></span><sub>k</sub>}</li><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>Directed </strong></span><a id="id1209" class="indexterm"/><span class="strong"><strong>Acyclic Graph</strong></span> (<span class="strong"><strong>DAG</strong></span>) with nodes representing random variables. </li><li class="listitem" style="list-style-type: disc">A local <a id="id1210" class="indexterm"/><span class="strong"><strong>conditional probability distribution</strong></span> (<span class="strong"><strong>CPD</strong></span>) for each node with dependence to its parent nodes <span class="emphasis"><em>P(X</em></span><sub>i</sub><span class="emphasis"><em> | parent(X</em></span><sub>i</sub><span class="emphasis"><em>))</em></span>.</li><li class="listitem" style="list-style-type: disc">A joint probability <a id="id1211" class="indexterm"/>distribution obtained using the chain rule of distribution is a factor given as:<div class="mediaobject"><img src="graphics/B05137_06_110.jpg" alt="Definition"/></div></li><li class="listitem" style="list-style-type: disc">For the student network defined, the joint distribution capturing all nodes can be represented as:<p>
<span class="emphasis"><em>P(D,I,G,S,L)=P(D)P(I)P(G¦D,I)P(S¦I)P(L¦G)</em></span>
</p></li></ul></div></div><div class="section" title="Reasoning patterns"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec104"/>Reasoning patterns</h3></div></div></div><p>The Bayesian <a id="id1212" class="indexterm"/>networks help in answering various queries given some data and facts, and these reasoning patterns are discussed here. </p><div class="section" title="Causal or predictive reasoning"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec162"/>Causal or predictive reasoning</h4></div></div></div><p>If evidence is <a id="id1213" class="indexterm"/>given as, for example, "low intelligence", then what would be the chances of getting a "good letter" as shown in <span class="emphasis"><em>Figure 3</em></span>, in the top right quadrant? This is addressed by causal reasoning. As shown in the first quadrant, causal reasoning flows from the top down.</p></div><div class="section" title="Evidential or diagnostic reasoning"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec163"/>Evidential or diagnostic reasoning</h4></div></div></div><p>If evidence <a id="id1214" class="indexterm"/>such as a "bad letter" is given, what would be the chances that the student got a "good grade"? This question, as shown in <span class="emphasis"><em>Figure 3</em></span> in the top left quadrant, is addressed by evidential reasoning. As shown in the second quadrant, evidential reasoning flows from the bottom up.</p></div><div class="section" title="Intercausal reasoning"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec164"/>Intercausal reasoning</h4></div></div></div><p>Obtaining <a id="id1215" class="indexterm"/>interesting patterns from finding a "related cause" is the objective of intercausal reasoning. If evidence of "grade C" and "high intelligence" is given, then what would be the chance of course difficulty being "high"? This type of reasoning is also called "explaining away" as one cause explains the reason for another cause and this is illustrated in the third quadrant, in the bottom-left of <span class="emphasis"><em>Figure 3</em></span>.</p></div><div class="section" title="Combined reasoning"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec165"/>Combined reasoning</h4></div></div></div><p>If a student <a id="id1216" class="indexterm"/>takes an "easy" course and has a "bad letter", what would be the chances of him getting a "grade C" ? This is explained by queries with combined reasoning patterns. Note that it has mixed information and does not a flow in a single fixed direction as in the case of other reasoning patterns and is shown in the bottom-right of the figure, in quadrant 4:</p><div class="mediaobject"><img src="graphics/B05137_06_112.jpg" alt="Combined reasoning"/></div><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>Figure 3. Reasoning patterns</em></span></p></blockquote></div></div></div><div class="section" title="Independencies, flow of influence, D-Separation, I-Map"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec105"/>Independencies, flow of influence, D-Separation, I-Map</h3></div></div></div><p>The conditional independencies between the nodes can be exploited to reduce the computations when performing queries. In this section, we will discuss some of the important concepts that are associated with independencies. </p><div class="section" title="Flow of influence"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec166"/>Flow of influence</h4></div></div></div><p>
<span class="strong"><strong>Influence</strong></span> <a id="id1217" class="indexterm"/>is the effect of how the condition or outcome of one variable changes the value or the belief associated with another variable. We have seen this from the reasoning patterns that influence flows from variables in direct relationships (parent/child), causal/evidential (parent and child with intermediates) and in combined structures. </p><p>The only case where the influence doesn't flow is when there is a "v-structure". That is, given edges <a id="id1218" class="indexterm"/>between three variables <span class="inlinemediaobject"><img src="graphics/B05137_06_113.jpg" alt="Flow of influence"/></span> there is a v-structure and no influence flows between <span class="emphasis"><em>X</em></span><sub>i - 1</sub> and <span class="emphasis"><em>X</em></span><sub>i + 1</sub>. For example, no influence flows between the Difficulty of the course and the Intelligence of the student. </p></div><div class="section" title="D-Separation"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec167"/>D-Separation</h4></div></div></div><p>Random <a id="id1219" class="indexterm"/>variables <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span> are said to be d-separated in the graph <span class="strong"><strong>G</strong></span>, given there is no active trail between <span class="strong"><strong>X</strong></span> and <span class="strong"><strong>Y</strong></span> in <span class="strong"><strong>G</strong></span> given <span class="strong"><strong>Z</strong></span>. It is formally denoted by:</p><p>
<span class="emphasis"><em>dsep</em></span><sub>G</sub><span class="emphasis"><em> (X,Y|Z)</em></span>
</p><p>The point of d-separation is that it maps perfectly to the conditional independence between the points. This gives to an interesting property that in a Bayesian network any variable is independent of its non-descendants given the parents of the node. </p><p>In the Student network example, the node/variable Letter is d-separated from Difficulty, Intelligence, and SAT given the grade.</p></div><div class="section" title="I-Map"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec168"/>I-Map</h4></div></div></div><p>From the d-separation, in graph <span class="strong"><strong>G</strong></span>, we can collect all the independencies from the d-separations and <a id="id1220" class="indexterm"/>these independencies are formally represented as:</p><div class="mediaobject"><img src="graphics/B05137_06_117.jpg" alt="I-Map"/></div><p>If <span class="emphasis"><em>P</em></span> satisfies <span class="emphasis"><em>I</em></span>(<span class="strong"><strong>G</strong></span>) then we say the <span class="strong"><strong>G</strong></span> is an independency-map or I-Map of <span class="emphasis"><em>P</em></span>.</p><p>The main point of I-Map is it can be formally proven that a factorization relationship to the independency holds. The converse can also be proved.</p><p>In simple terms, one can read in the Bayesian network graph G, all the independencies that hold in the distribution P regardless of any parameters!</p><p>Consider the student network—its whole distribution can be shown as: </p><p>
<span class="emphasis"><em>P(D,I,G,S,L) = P(D)P(I|D)P(G¦D,I)P(S¦D,I,G)P(L¦D,I,G,S)</em></span>
</p><p>Now, consider the independence from I-Maps: </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Variables <span class="emphasis"><em>I</em></span> and <span class="emphasis"><em>D</em></span> are non-descendants and not conditional on parents so <span class="emphasis"><em>P(I|D) = P(I)</em></span></li><li class="listitem" style="list-style-type: disc">Variable <span class="emphasis"><em>S</em></span> is independent of its non-descendants <span class="emphasis"><em>D</em></span> and <span class="emphasis"><em>G</em></span>, given its parent <span class="emphasis"><em>I</em></span>. <span class="emphasis"><em>P(S¦D,I,G)=P(S|I)</em></span></li><li class="listitem" style="list-style-type: disc">Variable <span class="emphasis"><em>L</em></span> is independent of its non-descendants <span class="emphasis"><em>D</em></span>, <span class="emphasis"><em>I</em></span>, and <span class="emphasis"><em>S</em></span>, given its parent <span class="emphasis"><em>G</em></span>. <span class="emphasis"><em>P(L¦D,I,G,S)=P(L|G)</em></span><p>
<span class="emphasis"><em>(D,I,G,S,L)=P(D)P(I)P(G¦D,I)P(S¦I)P(L¦G)</em></span>
</p></li></ul></div><p>Thus, we have <a id="id1221" class="indexterm"/>shown that I-Map helps in factorization given just the graph network!</p></div></div></div><div class="section" title="Inference"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec91"/>Inference</h2></div></div></div><p>The biggest advantage of <a id="id1222" class="indexterm"/>probabilistic graph models is their <a id="id1223" class="indexterm"/>ability to answer probability queries in the form of conditional or MAP or marginal MAP, given some evidence. </p><p>Formally, the probability of evidence <span class="strong"><strong>E = e</strong></span> is given by:</p><div class="mediaobject"><img src="graphics/B05137_06_126.jpg" alt="Inference"/></div><p>But the problem has been shown to be NP-Hard (<span class="emphasis"><em>Reference</em></span> [3]) or specifically, #P-complete. This means that it is intractable when there are a large number of trees or variables. Even for a tree-width (number of variables in the largest clique) of 25, the problem seems to be intractable—most real-world models have tree-widths larger than this. </p><p>So if the exact inference discussed before is intractable, can some approximations be used so that within some bounds of the error, we can make the problem tractable? It has been shown that even an approximate algorithm to compute inferences with an error <span class="emphasis"><em>?</em></span> &lt; 0.5, so that we find a number <span class="emphasis"><em>p</em></span> such that |<span class="emphasis"><em>P</em></span>(<span class="strong"><strong>E</strong></span> = <span class="strong"><strong>e</strong></span>) – <span class="emphasis"><em>p</em></span>|&lt; <span class="emphasis"><em>?</em></span>, is also NP-Hard. </p><p>But the good news is that this is among the "worst case" results that show exponential time complexity. In the "general case" there can be heuristics applied to reduce the computation time both for exact and approximate algorithms.</p><p>Some of the <a id="id1224" class="indexterm"/>well-known techniques for performing exact and approximate inferencing are depicted in <span class="emphasis"><em>Figure 4</em></span>, which covers most probabilistic graph models in addition to Bayesian networks. </p><div class="mediaobject"><img src="graphics/B05137_06_130.jpg" alt="Inference"/><div class="caption"><p>Figure 4. Exact and approximate inference techniques</p></div></div><p>It is beyond the scope of this chapter to discuss each of these in detail. We will explain a few of the algorithms <a id="id1225" class="indexterm"/>in some detail accompanied by references to give the reader a better understanding. </p><div class="section" title="Elimination-based inference"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec106"/>Elimination-based inference</h3></div></div></div><p>Here <a id="id1226" class="indexterm"/>we will describe two <a id="id1227" class="indexterm"/>techniques, the variable elimination algorithm and the clique-tree or junction-tree algorithm.</p><div class="section" title="Variable elimination algorithm"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec169"/>Variable elimination algorithm</h4></div></div></div><p>The <a id="id1228" class="indexterm"/>basics of <a id="id1229" class="indexterm"/>the <span class="strong"><strong>Variable elimination</strong></span> (<span class="strong"><strong>VE</strong></span>) algorithm lie in the distributive property as shown:</p><p>
<span class="emphasis"><em>(ab+ac+ad)= a (b+c+d)</em></span>
</p><p>In other words, five arithmetic operations of three multiplications and two additions can be reduced to four arithmetic operations of one multiplication and three additions by taking a common factor <span class="emphasis"><em>a</em></span> out.</p><p>Let us understand the reduction of the computations by taking a simple example in the student network. If we have to compute a probability query such as the difficulty of the exam given the letter was good, that is, <span class="emphasis"><em>P(D¦L=good)=?</em></span>.</p><p>Using Bayes theorem:</p><div class="mediaobject"><img src="graphics/B05137_06_134.jpg" alt="Variable elimination algorithm"/></div><p>To compute <span class="emphasis"><em>P(D¦L=good)=?</em></span> we can use the chain rule and joint probability:</p><div class="mediaobject"><img src="graphics/B05137_06_136.jpg" alt="Variable elimination algorithm"/></div><p>If we rearrange the terms on the right-hand side:</p><div class="mediaobject"><img src="graphics/B05137_06_137.jpg" alt="Variable elimination algorithm"/></div><p>If we now replace <span class="inlinemediaobject"><img src="graphics/B05137_06_138.jpg" alt="Variable elimination algorithm"/></span> since the factor is independent of the variable <span class="emphasis"><em>I</em></span> that <span class="emphasis"><em>S</em></span> is conditioned on, we get:</p><div class="mediaobject"><img src="graphics/B05137_06_140.jpg" alt="Variable elimination algorithm"/></div><p>Thus, if we proceed carefully, eliminating one variable at a time, we have effectively converted <span class="emphasis"><em>O(2</em></span><sup>n</sup><span class="emphasis"><em>)</em></span> factors to <span class="emphasis"><em>O(nk</em></span><sup>2</sup><span class="emphasis"><em>)</em></span> factors where <span class="emphasis"><em>n</em></span> is the number of variables and <span class="emphasis"><em>k</em></span> is the number of observed values for each.</p><p>Thus, the main idea of the VE algorithm is to impose an order on the variables such that the query variable comes last. A list of factors is maintained over the ordered list of variables and summation is performed. Generally, we use dynamic programming in the implementation <a id="id1230" class="indexterm"/>of the VE algorithm (<span class="emphasis"><em>References</em></span> [4]).</p><div class="section" title="Input and output"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec57"/>Input and output</h5></div></div></div><p>Inputs:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">List of <a id="id1231" class="indexterm"/>Condition Probability Distribution/Table <span class="strong"><strong>F</strong></span></li><li class="listitem" style="list-style-type: disc">List of query variables <span class="strong"><strong>Q</strong></span></li><li class="listitem" style="list-style-type: disc">List of observed variables <span class="strong"><strong>E</strong></span> and the observed value <span class="strong"><strong>e</strong></span></li></ul></div><p>Output:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>P</em></span>(<span class="strong"><strong>Q</strong></span>|<span class="strong"><strong>E</strong></span> = <span class="emphasis"><em>e</em></span>)</li></ul></div></div><div class="section" title="How does it work?"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec58"/>How does it work?</h5></div></div></div><p>The algorithm calls the <code class="literal">eliminate</code> function in a loop, as shown here:</p><p>
<span class="emphasis"><em>VariableElimination</em></span>:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">While <span class="emphasis"><em>?</em></span>, the set of all random variables in the Bayesian network is not empty<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Remove the first variable <span class="strong"><strong>Z</strong></span> from <span class="emphasis"><em>?</em></span></li><li class="listitem"><span class="emphasis"><em>eliminate</em></span>(<span class="emphasis"><em>F</em></span>, <span class="strong"><strong>Z</strong></span>)</li></ol></div></li><li class="listitem">end loop.</li><li class="listitem">Set <span class="emphasis"><em>?</em></span> product of all factors in <span class="emphasis"><em>F</em></span> </li><li class="listitem">Instantiate observed variables in <span class="emphasis"><em>?</em></span> to their observed values.</li><li class="listitem">
return <span class="inlinemediaobject"><img src="graphics/B05137_06_155.jpg" alt="How does it work?"/></span> (renormalization)
</li></ol></div><p>
<span class="emphasis"><em>eliminate</em></span> (<span class="emphasis"><em>F</em></span>, <span class="strong"><strong>Z</strong></span>)</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Remove from the <span class="emphasis"><em>F</em></span> all functions, for example, <span class="emphasis"><em>X</em></span><sub>1</sub>, <span class="emphasis"><em>X</em></span><sub>2</sub>, …. <span class="emphasis"><em>X</em></span><sub>k</sub> that involve <span class="strong"><strong>Z</strong></span>.</li><li class="listitem">
Compute new function <span class="inlinemediaobject"><img src="graphics/B05137_06_429.jpg" alt="How does it work?"/></span></li><li class="listitem">
Compute new function <span class="inlinemediaobject"><img src="graphics/B05137_06_425.jpg" alt="How does it work?"/></span></li><li class="listitem">Add new function <span class="emphasis"><em>?</em></span> to <span class="emphasis"><em>F</em></span></li><li class="listitem">Return <span class="emphasis"><em>F</em></span></li></ol></div><p>Consider the same example of the student network with <span class="emphasis"><em>P(D, L = good)</em></span> as the goal.</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Pick a variable ordering list: <span class="emphasis"><em>S</em></span>, <span class="emphasis"><em>I</em></span>, <span class="emphasis"><em>L</em></span>, <span class="emphasis"><em>G</em></span>, and <span class="emphasis"><em>D</em></span> </li><li class="listitem">Initialize the active factor list and introduce the evidence:<p>List: <span class="emphasis"><em>P(S¦I)P(I)P(D)P(G¦I,D)P(L¦G)d(L = good)</em></span>
</p></li><li class="listitem">Eliminate the variable SAT or <span class="strong"><strong>S</strong></span> off the list <div class="mediaobject"><img src="graphics/B05137_06_161.jpg" alt="How does it work?"/></div><p>List: <span class="emphasis"><em>P(I)P(D)P(G¦I,D)P(L¦G)d(L = good)</em></span>
<span class="emphasis"><em>?</em></span>1<span class="emphasis"><em> (I)</em></span>
</p></li><li class="listitem">Eliminate the variable Intelligence or <span class="emphasis"><em>I</em></span><div class="mediaobject"><img src="graphics/B05137_06_163.jpg" alt="How does it work?"/></div><p>List: <span class="emphasis"><em>P(D)P(L¦G)d(L = good)</em></span>
<span class="emphasis"><em>?</em></span>2<span class="emphasis"><em> (G,D)</em></span> </p></li><li class="listitem">Eliminate the variable Letter or <span class="emphasis"><em>L</em></span><div class="mediaobject"><img src="graphics/B05137_06_166.jpg" alt="How does it work?"/></div><p>List: <span class="emphasis"><em>P(D) </em></span>
<span class="emphasis"><em>?</em></span><sub>3</sub><span class="emphasis"><em> (G) </em></span>
<span class="emphasis"><em>?</em></span><sub>2</sub><span class="emphasis"><em> (G,D)</em></span> </p></li><li class="listitem">Eliminate the variable Grade or <span class="emphasis"><em>G</em></span><div class="mediaobject"><img src="graphics/B05137_06_169.jpg" alt="How does it work?"/></div><p>List: <span class="emphasis"><em>P(D) </em></span>
<span class="emphasis"><em>?</em></span><sub>4</sub><span class="emphasis"><em> (D)</em></span>
</p></li></ol></div><p>Thus with two values, <span class="emphasis"><em>P(D=high) </em></span>
<span class="emphasis"><em>?</em></span><sub>4</sub><span class="emphasis"><em> (D=high)</em></span> and <span class="emphasis"><em>P(D=low) </em></span>
<span class="emphasis"><em>?</em></span><sub>4</sub><span class="emphasis"><em> (D=low)</em></span>, we get the answer.</p></div><div class="section" title="Advantages and limitations"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec59"/>Advantages and limitations</h5></div></div></div><p>The advantages and limitations are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <a id="id1232" class="indexterm"/>main advantage of the VE algorithm is its simplicity and generality that can be applied to many networks.</li><li class="listitem" style="list-style-type: disc">The computational reduction advantage of VE seems to go away when there are many connections in the network.</li><li class="listitem" style="list-style-type: disc">The choice <a id="id1233" class="indexterm"/>of optimal ordering of variables is very important for the computational benefit.</li></ul></div></div></div><div class="section" title="Clique tree or junction tree algorithm"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec170"/>Clique tree or junction tree algorithm</h4></div></div></div><p>Junction tree or <a id="id1234" class="indexterm"/>Clique Trees are more efficient forms of variable elimination-based techniques.</p><div class="section" title="Input and output"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec60"/>Input and output</h5></div></div></div><p>Inputs:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">List of <a id="id1235" class="indexterm"/>Condition Probability Distribution/Table <span class="strong"><strong>F</strong></span></li><li class="listitem" style="list-style-type: disc">List of query variables <span class="strong"><strong>Q</strong></span></li><li class="listitem" style="list-style-type: disc">List of observed variables <span class="strong"><strong>E</strong></span> and the observed value <span class="strong"><strong>e</strong></span></li></ul></div><p>Output:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>P</em></span>(<span class="strong"><strong>Q|</strong></span>E = <span class="emphasis"><em>e</em></span>)</li></ul></div></div><div class="section" title="How does it work?"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec61"/>How does it work?</h5></div></div></div><p>The steps involved are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem"><span class="strong"><strong>Moralization</strong></span>: This is a process of converting a directed graph into an undirected graph with the following two steps:<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Replace directed edges with undirected edges between the nodes.</li><li class="listitem">If there are two nodes or vertices that are not connected but have a common child, add an edge connecting them. (Note the edge between <span class="emphasis"><em>V</em></span><sub>4</sub> and <span class="emphasis"><em>V</em></span><sub>5</sub> and <span class="emphasis"><em>V</em></span><sub>2</sub> and <span class="emphasis"><em>V</em></span><sub>3</sub> in <span class="emphasis"><em>Figure</em></span> 5):</li></ol></div><div class="mediaobject"><img src="graphics/B05137_06_178.jpg" alt="How does it work?"/><div class="caption"><p>Figure 5. Graph moralization of DAG showing in green how the directional edges are changed and red edges showing new additions.</p></div></div></li><li class="listitem"><span class="strong"><strong>Triangulation</strong></span>: For understanding triangulation, chords must be formed. The chord of a cycle is a pair of vertices <span class="emphasis"><em>V</em></span><sub>i</sub> and <span class="emphasis"><em>V</em></span><sub>j</sub> of non-consecutive vertices that have an edge between them. A graph is called a <span class="strong"><strong>chordal or triangulated graph</strong></span> if every cycle of length ≥ 4 has chords. Note the edge between <span class="emphasis"><em>V</em></span><sub>1</sub> and <span class="emphasis"><em>V</em></span><sub>5</sub> in <span class="emphasis"><em>Figure 6</em></span> forming chords to make the moralized graph a chordal/triangulated graph:<div class="mediaobject"><img src="graphics/B05137_06_184.jpg" alt="How does it work?"/><div class="caption"><p>Figure 6. Graph triangulation with blue edge addition to convert a moralized graph to a chordal graph.</p></div></div></li><li class="listitem"><span class="strong"><strong>Junction Tree</strong></span>: From the chordal graphs a junction tree is formed using the following steps: <div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Find all the cliques in the graph and make them nodes with the cluster of all vertices. A clique is a subgraph where an edge exists between each pair of nodes. If two nodes have one or more common vertices create an edge consisting of the intersecting vertices as a separator or sepset. For example, the cycle with edges <span class="emphasis"><em>V</em></span><sub>1</sub>, <span class="emphasis"><em>V</em></span><sub>4</sub>, <span class="emphasis"><em>V</em></span><sub>5</sub> and <span class="emphasis"><em>V</em></span><sub>6</sub>, <span class="emphasis"><em>V</em></span><sub>4</sub>, <span class="emphasis"><em>V</em></span><sub>5</sub> that have a common edge between <span class="emphasis"><em>V</em></span><sub>4</sub>, <span class="emphasis"><em>V</em></span><sub>5</sub> can <a id="id1236" class="indexterm"/>be reduced to a clique as shown with the common edge as separator.</li></ol></div><p>If the preceding graph contains a cycle, all separators in the cycle contain the same variable. Remove the cycle in the graph by creating a minimum spanning tree, while including maximum separators. The entire transformation process is shown in Figure 7: </p><div class="mediaobject"><img src="graphics/B05137_06_189.jpg" alt="How does it work?"/><div class="caption"><p>Figure 7. Formation of a Junction Tree</p></div></div></li><li class="listitem"><span class="strong"><strong>Run the Message Passing algorithm on Junction Tree</strong></span>: Junction tree can be used to compute the joint distribution using factorization of cliques and separators as<div class="mediaobject"><img src="graphics/B05137_06_190.jpg" alt="How does it work?"/></div></li><li class="listitem"><span class="strong"><strong>Compute the parameters of Junction Tree</strong></span>: The junction tree parameters can be obtained per node using the parent nodes in the original Bayesian network and are called clique potentials, as shown here:<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">
(<span class="emphasis"><em>?</em></span><sub>1</sub> (<span class="emphasis"><em>V</em></span><sub>2</sub>,<span class="emphasis"><em>V</em></span><sub>3</sub>,<span class="emphasis"><em>V</em></span><sub>5</sub>) = <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>V</em></span><sub>5</sub> |<span class="emphasis"><em>V</em></span><sub>2</sub>,<span class="emphasis"><em>V</em></span><sub>3</sub>)<span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>V</em></span><sub>3</sub>)(Note in the original Bayesian network edge <span class="emphasis"><em>V</em></span><sub>5</sub> is dependent on <span class="emphasis"><em>V</em></span><sub>2</sub>, <span class="emphasis"><em>V</em></span><sub>3</sub>, whereas <span class="emphasis"><em>V</em></span><sub>3</sub> is independent)
</li><li class="listitem"><span class="inlinemediaobject"><img src="graphics/B05137_06_194.jpg" alt="How does it work?"/></span></li><li class="listitem"><span class="inlinemediaobject"><img src="graphics/B05137_06_196.jpg" alt="How does it work?"/></span></li><li class="listitem"><span class="inlinemediaobject"><img src="graphics/B05137_06_197.jpg" alt="How does it work?"/></span></li></ol></div></li><li class="listitem"><span class="strong"><strong>Message Passing between nodes/cliques in Junction Tree</strong></span>: A node in the junction <a id="id1237" class="indexterm"/>tree, represented by clique <span class="emphasis"><em>C</em></span><sub>i</sub>, multiplies all incoming messages from its neighbors with its own clique potential, resulting in a factor <span class="inlinemediaobject"><img src="graphics/B05137_06_199.jpg" alt="How does it work?"/></span> whose scope is the clique. It then sums out all the variables except the ones on sepset or separators <span class="emphasis"><em>S</em></span><sub>i,j</sub> between <span class="emphasis"><em>C</em></span><sub>i</sub> and <span class="emphasis"><em>C</em></span><sub>j</sub> and then sends the resulting factor as a message to <span class="emphasis"><em>C</em></span><sub>j</sub>.
<div class="mediaobject"><img src="graphics/B05137_06_202.jpg" alt="How does it work?"/><div class="caption"><p>Figure 8. Message passing between nodes/cliques in Junction Tree</p></div></div><div class="mediaobject"><img src="graphics/B05137_06_203.jpg" alt="How does it work?"/></div></li></ol></div><p>Thus, when the message passing reaches the tree root, the joint probability distribution is completed.</p></div><div class="section" title="Advantages and limitations"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec62"/>Advantages and limitations</h5></div></div></div><p>The advantages and limitaions are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <a id="id1238" class="indexterm"/>algorithm has a theoretical upper bound on the computations that are related to the tree width in the junction tree. </li><li class="listitem" style="list-style-type: disc">Multiplication of each potential in the cliques can result in numeric overflow and underflow.</li></ul></div></div></div></div><div class="section" title="Propagation-based techniques"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec107"/>Propagation-based techniques</h3></div></div></div><p>Here we <a id="id1239" class="indexterm"/>discuss belief <a id="id1240" class="indexterm"/>propagation, a commonly used message passing algorithm for doing inference by introducing factor graphs and the messages that can flow in these graphs.</p><div class="section" title="Belief propagation"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec171"/>Belief propagation</h4></div></div></div><p>Belief <a id="id1241" class="indexterm"/>propagation is one of the most practical inference techniques that has applicability across most probabilistic graph models including directed, undirected, chain-based, and temporal graphs. To understand the belief propagation algorithm, we need to first define factor graphs.</p><div class="section" title="Factor graph"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec63"/>Factor graph</h5></div></div></div><p>We know from basic <a id="id1242" class="indexterm"/>probability theory that the entire joint distribution can be represented as a factor over a subset of variables as</p><div class="mediaobject"><img src="graphics/B05137_06_205.jpg" alt="Factor graph"/></div><p>In DAG or Bayesian networks <span class="emphasis"><em>f</em></span><sub>s</sub>(<span class="strong"><strong>X</strong></span><sub>s</sub>) is a conditional distribution. Thus, there is a great advantage in expressing the joint distribution over factors over the subset of variables.</p><p>Factor graph is a representation of the network where the variables and the factors involving the variables are both made into explicit nodes (<span class="emphasis"><em>References</em></span> [11]). In a simplified student network from the previous section, the factor graph is shown in <span class="emphasis"><em>Figure 9</em></span>.</p><div class="mediaobject"><img src="graphics/B05137_06_208.jpg" alt="Factor graph"/><div class="caption"><p>Figure 9. Factor graph of simplified "Student" network</p></div></div><p>A factor graph is a bipartite graph, that is, it has two types of nodes, variables and factors.</p><p>The edges flow between two opposite types, that is, from variables to factors and vice versa.</p><p>Converting the <a id="id1243" class="indexterm"/>Bayesian network to a factor graph is a straightforward procedure as shown previously where you start adding variable nodes and conditional probability distributions as factor nodes. The relationship between the Bayesian network and factor graphs is one-to-many, that is, the same Bayesian network can be represented in many factor graphs and is not unique.</p></div><div class="section" title="Messaging in factor graph"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec64"/>Messaging in factor graph</h5></div></div></div><p>There are two <a id="id1244" class="indexterm"/>distinct messages that flow in these factor graphs that form the bulk of all computations through communication.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Message from factor nodes to variable nodes</strong></span>: The message that is sent from a factor node to the variable node can be mathematically represented as follows:<div class="mediaobject"><img src="graphics/B05137_06_209.jpg" alt="Messaging in factor graph"/></div><div class="mediaobject"><img src="graphics/B05137_06_426.jpg" alt="Messaging in factor graph"/></div><span class="inlinemediaobject"><img src="graphics/B05137_06_213.jpg" alt="Messaging in factor graph"/></span> where <span class="inlinemediaobject"><img src="graphics/B05137_06_214.jpg" alt="Messaging in factor graph"/></span>
Thus, <span class="inlinemediaobject"><img src="graphics/B05137_06_215.jpg" alt="Messaging in factor graph"/></span> is the message from factor node <span class="emphasis"><em>f</em></span><sub>s</sub> to <span class="emphasis"><em>x</em></span> and the product of all such <a id="id1245" class="indexterm"/>messages from neighbors of <span class="emphasis"><em>x</em></span> to <span class="emphasis"><em>x</em></span> gives the combined probability to <span class="emphasis"><em>x:</em></span><div class="mediaobject"><img src="graphics/B05137_06_218.jpg" alt="Messaging in factor graph"/><div class="caption"><p>Figure 10. Message-passing from factor node to variable node</p></div></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Message from variable nodes to factor nodes</strong></span>: Similar to the previous example, messages from variable to factor can be shown to be <div class="mediaobject"><img src="graphics/B05137_06_219.jpg" alt="Messaging in factor graph"/></div><div class="mediaobject"><img src="graphics/B05137_06_220.jpg" alt="Messaging in factor graph"/></div></li></ul></div><p>Thus, all the factors coming to the node <span class="emphasis"><em>x</em></span><sub>m</sub> are multiplied except for the factor it is sending to.</p><div class="mediaobject"><img src="graphics/B05137_06_222.jpg" alt="Messaging in factor graph"/><div class="caption"><p>Figure 11. Message-passing from variable node to factor node</p></div></div></div><div class="section" title="Input and output"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec65"/>Input and output</h5></div></div></div><p>Inputs:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">List of <a id="id1246" class="indexterm"/>Condition Probability Distribution/Table (CPD/CPT) <span class="emphasis"><em>F</em></span></li><li class="listitem" style="list-style-type: disc">List of query variables <span class="strong"><strong>Q</strong></span></li><li class="listitem" style="list-style-type: disc">List of observed variables <span class="strong"><strong>E</strong></span> and the observed value <span class="strong"><strong>e</strong></span></li></ul></div><p>Output:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>P</em></span>(<span class="strong"><strong>Q|</strong></span>E = <span class="emphasis"><em>e</em></span>)</li></ul></div></div><div class="section" title="How does it work?"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec66"/>How does it work?</h5></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a factor graph from the Bayesian network as discussed previously.</li><li class="listitem">View the node <span class="strong"><strong>Q</strong></span> as the root of the graph.</li><li class="listitem">
Initialize all the leaf nodes, that is:
<span class="inlinemediaobject"><img src="graphics/B05137_06_223.jpg" alt="How does it work?"/></span>
 and
 <span class="inlinemediaobject"><img src="graphics/B05137_06_224.jpg" alt="How does it work?"/></span></li><li class="listitem">Apply message passing from a leaf to the next node in a recursive manner.</li><li class="listitem">Move to the next node, until root is reached.</li><li class="listitem">Marginal <a id="id1247" class="indexterm"/>at the root node gives the result.</li></ol></div></div><div class="section" title="Advantages and limitations"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec67"/>Advantages and limitations</h5></div></div></div><p>The advantages and limitaions are as follows: </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">This <a id="id1248" class="indexterm"/>algorithm as discussed is very generic and can be used for most graph models. This algorithm gives exact inference in directed trees when there are no cycles. </li><li class="listitem" style="list-style-type: disc">This can be easily implemented in parallel and helps in scalability. Based on connectivity, the memory requirement can be very high. </li></ul></div></div></div></div><div class="section" title="Sampling-based techniques"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec108"/>Sampling-based techniques</h3></div></div></div><p>We <a id="id1249" class="indexterm"/>will discuss a simple <a id="id1250" class="indexterm"/>approach using particles and sampling to illustrate the process of generating the distribution <span class="emphasis"><em>P(X)</em></span> from the random variables. The idea is to repeatedly sample from the Bayesian network and use the samples with counts to approximate the inferences. </p><div class="section" title="Forward sampling with rejection"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec172"/>Forward sampling with rejection</h4></div></div></div><p>The key <a id="id1251" class="indexterm"/>idea is to generate i.i.d. samples iterating over the variables using a topological order. In case of some evidence, for example, <span class="emphasis"><em>P(X|E = e)</em></span> that contradicts the sample generated, the easiest way is to reject the sample and proceed. </p><div class="section" title="Input and output"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec68"/>Input and output</h5></div></div></div><p>Inputs:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">List of Condition Probability Distribution/Table <span class="emphasis"><em>F</em></span></li><li class="listitem" style="list-style-type: disc">List of query variables <span class="strong"><strong>Q</strong></span></li><li class="listitem" style="list-style-type: disc">List of observed variables <span class="strong"><strong>E</strong></span> and the observed value <span class="strong"><strong>e</strong></span></li></ul></div><p>Output:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>P</em></span>(<span class="strong"><strong>Q|</strong></span>E = <span class="emphasis"><em>e</em></span>)</li></ul></div></div><div class="section" title="How does it work?"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec69"/>How does it work?</h5></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">For <span class="emphasis"><em>j</em></span> = 1 to <span class="emphasis"><em>m</em></span> //number of samples<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a topological order of variables, say <span class="strong"><strong>X</strong></span><sub>1</sub>, <span class="strong"><strong>X</strong></span><sub>2</sub>,<span class="strong"><strong> … X</strong></span><sub>n</sub>.</li><li class="listitem">For <span class="emphasis"><em>i</em></span> = 1 to <span class="emphasis"><em>n</em></span> <div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem"><span class="strong"><strong>u</strong></span><sub>i</sub> ? <span class="strong"><strong>X</strong></span><span class="emphasis"><em>(parent</em></span>(<span class="strong"><strong>X</strong></span><sub>i</sub>)) //assign <span class="emphasis"><em>parent</em></span>(<span class="strong"><strong>X</strong></span><sub>i</sub>) to variables</li><li class="listitem"><span class="emphasis"><em>sample</em></span>(<span class="strong"><strong>x</strong></span><sub>i</sub>, <span class="emphasis"><em>P</em></span>(<span class="strong"><strong>X</strong></span><sub>i</sub> | <span class="strong"><strong>u</strong></span><sub>i</sub>) //sample <span class="strong"><strong>X</strong></span><sub>i</sub> given parent assignments</li><li class="listitem">if(<span class="strong"><strong>x</strong></span><sub>i</sub> ?, <span class="emphasis"><em>P</em></span>(<span class="strong"><strong>X</strong></span><sub>i</sub> | <span class="strong"><strong>E </strong></span>= <span class="strong"><strong>e</strong></span>) reject and go to 1.1.2. //reject sample if it doesn't agree with the evidence.</li></ol></div></li><li class="listitem">Return (<span class="strong"><strong>X</strong></span><sub>1</sub>, <span class="strong"><strong>X</strong></span><sub>2</sub>,….<span class="strong"><strong>X</strong></span><sub>n</sub>) as sample.</li></ol></div></li><li class="listitem">Compute <span class="emphasis"><em>P</em></span>(<span class="strong"><strong>Q</strong></span> | <span class="strong"><strong>E</strong></span> = e) using counts from the samples.</li></ol></div><p>An example of one sample generated for the student network can be by sampling Difficulty and getting Low, next, sampling Intelligence and getting High, next, sampling grade using <a id="id1252" class="indexterm"/>the CPD table for Difficulty=low and Intelligence=High and getting Grade=A, sampling SAT using CPD for Intelligence=High and getting SAT=good and finally, using Grade=A to sample from Letter and getting Letter=Good. Thus, we get first sample (Difficulty=low, Intelligence=High, Grade=A, SAT=good, Letter=Good)</p></div><div class="section" title="Advantages and limitations"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec70"/>Advantages and limitations</h5></div></div></div><p>The advantages and limitations are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">This technique is fairly simple to implement and execute. It requires a large number of samples to be approximate within the bounds.</li><li class="listitem" style="list-style-type: disc">When evidence set is large, the rejection process becomes costly. </li></ul></div></div></div></div></div><div class="section" title="Learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec92"/>Learning</h2></div></div></div><p>The idea behind <a id="id1253" class="indexterm"/>learning is to generate either a structure or find parameters or both, given the data and the domain experts. </p><p>The goals of learning are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">To facilitate <a id="id1254" class="indexterm"/>inference in Bayesian networks. The pre-requisite of inferencing is that the structure and parameters are known, which are the output of learning.</li><li class="listitem" style="list-style-type: disc">To facilitate prediction using Bayesian networks. Given observed variables <span class="strong"><strong>X</strong></span>, predict the target variables <span class="strong"><strong>Y</strong></span>.</li><li class="listitem" style="list-style-type: disc">To facilitate knowledge discovery using Bayesian networks. This means understanding causality, relationships, and other features from the data.</li></ul></div><p>Learning, in general, can <a id="id1255" class="indexterm"/>be characterized by <span class="emphasis"><em>Figure 12</em></span>. The assumption is that there is a known probability distribution <span class="emphasis"><em>P<sup>*</sup></em></span> that may or may not have been generated from a Bayesian network <span class="emphasis"><em>G<sup>*</sup></em></span>. The observed data samples are assumed to be generated or sampled from that known probability distribution <span class="emphasis"><em>P<sup>*</sup></em></span>. The domain expert may or may not be present to include the knowledge or prior beliefs about the structure. Bayesian <a id="id1256" class="indexterm"/>networks are one of the few techniques where domain experts' inputs in terms of relationships in variables or prior probabilities can be used directly, in contrast to other machine learning algorithms. At the end of the process of knowledge elicitation and learning from data, we get as an output a Bayesian network with defined structure and parameters (CPTs). </p><div class="mediaobject"><img src="graphics/B05137_06_237.jpg" alt="Learning"/><div class="caption"><p>Figure 12. Elements of learning with Bayesian networks</p></div></div><p>Based on data quality (missing data or complete data) and knowledge of structure from the expert (unknown and known), the <a id="id1257" class="indexterm"/>following are four classes that Learning in Bayesian networks fall into, as shown in <span class="emphasis"><em>Table 2</em></span>:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td rowspan="2" style="text-align: left" valign="top">
<p>Data</p>
</td><td colspan="2" style="text-align: center" valign="top">
<p>Structure</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Known Structure </p>
<p>(Learn Parameters)</p>
</td><td style="text-align: left" valign="top">
<p>Unknown Structure</p>
<p>(Learn Structure and Parameters)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Complete Data</p>
</td><td style="text-align: left" valign="top">
<p>Parameter Estimation</p>
<p>(Maximum Likelihood, Bayesian Estimation)</p>
</td><td style="text-align: left" valign="top">
<p>Optimization </p>
<p>(Search and Scoring Techniques)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Incomplete Data</p>
</td><td style="text-align: left" valign="top">
<p>Non-Linear <a id="id1258" class="indexterm"/>Parametric Optimization </p>
<p>(Expectation Maximization, Gradient Descent)</p>
</td><td style="text-align: left" valign="top">
<p>Structure and Parameter Optimization</p>
<p>(Structural EM, Mixture Models)</p>
</td></tr></tbody></table></div><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em> Table 2. Classes of Bayesian network learning </em></span></p></blockquote></div><div class="section" title="Learning parameters"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec109"/>Learning parameters</h3></div></div></div><p>In this section, we <a id="id1259" class="indexterm"/>will discuss two broadly used methodologies to estimate parameters given the structure. We will discuss only with the complete data and readers can refer to the discussion in (<span class="emphasis"><em>References</em></span> [8]) for incomplete data parameter estimation. </p><div class="section" title="Maximum likelihood estimation for Bayesian networks"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec173"/>Maximum likelihood estimation for Bayesian networks</h4></div></div></div><p>
<span class="strong"><strong>Maximum </strong></span>
<a id="id1260" class="indexterm"/>
<span class="strong"><strong>likelihood estimation</strong></span> (<span class="strong"><strong>MLE</strong></span>) is a very generic method and it can be defined as: given a data <a id="id1261" class="indexterm"/>set <span class="emphasis"><em>D</em></span>, choose parameters <span class="inlinemediaobject"><img src="graphics/B05137_06_239.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span> that satisfy:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="inlinemediaobject"><img src="graphics/B05137_06_240.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span></li><li class="listitem" style="list-style-type: disc"><span class="inlinemediaobject"><img src="graphics/B05137_06_241.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span></li><li class="listitem" style="list-style-type: disc"><span class="inlinemediaobject"><img src="graphics/B05137_06_242.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span></li></ul></div><p>Maximum likelihood is the technique of choosing parameters of the Bayesian network given the training data. For a detailed discussion, see (<span class="emphasis"><em>References</em></span> [6]).</p><p>Given the known Bayesian network structure of graph <span class="emphasis"><em>G</em></span> and training data <span class="inlinemediaobject"><img src="graphics/B05137_06_243.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span>, we want to learn the parameters or CPDs—or CPTs to be precise. This can be formulated as:</p><div class="mediaobject"><img src="graphics/B05137_06_244.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></div><p>Now each example or instance <span class="inlinemediaobject"><img src="graphics/B05137_06_245.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span> can be written in terms of variables. If there are <span class="emphasis"><em>i</em></span> variables represented by <span class="emphasis"><em>x</em></span><sub>i</sub> and the parents of each is given by <span class="emphasis"><em>parent</em></span><sub>Xi</sub> then:</p><div class="mediaobject"><img src="graphics/B05137_06_249.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></div><p>Interchanging the variables and instances:</p><div class="mediaobject"><img src="graphics/B05137_06_250.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></div><p>The term is:</p><div class="mediaobject"><img src="graphics/B05137_06_251.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></div><p>This is the <a id="id1262" class="indexterm"/>conditional likelihood of a particular variable <span class="emphasis"><em>x</em></span>
<span class="emphasis"><em><sub>i</sub></em></span> given its parents <span class="emphasis"><em>parent</em></span><sub>Xi</sub>. Thus, parameters for these conditional likelihoods are a subset of parameters given by <span class="inlinemediaobject"><img src="graphics/B05137_06_252.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span>. Thus:</p><div class="mediaobject"><img src="graphics/B05137_06_253.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></div><p>Here, <span class="inlinemediaobject"><img src="graphics/B05137_06_254.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span> is called the local likelihood function. This becomes very important as the total likelihood decomposes into independent terms of local likelihood and is known as the global decomposition property of the likelihood function. The idea is that these local likelihood functions can be further decomposed for a tabular CPD by simply using the count of different outcomes from the training data.</p><p>Let <span class="emphasis"><em>N</em></span><sub>ijk</sub> be the number of times we observe variable or node <span class="emphasis"><em>i</em></span> in the state <span class="emphasis"><em>k</em></span><sub>,</sub> given the parent node configuration <span class="emphasis"><em>j</em></span>:</p><div class="mediaobject"><img src="graphics/B05137_06_257.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></div><div class="mediaobject"><img src="graphics/B05137_06_258.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></div><p>For example, we can have a simple entry corresponding to <span class="emphasis"><em>X</em></span><sub>i</sub><span class="emphasis"><em> = a</em></span> and <span class="emphasis"><em>parent</em></span><sub>Xi</sub><span class="emphasis"><em> = b</em></span> by estimating the likelihood function from the training data as:</p><div class="mediaobject"><img src="graphics/B05137_06_261.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></div><p>Consider two cases, as an example. In the first, <span class="inlinemediaobject"><img src="graphics/B05137_06_262.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span> is satisfied by 10 instances with <span class="emphasis"><em>parent</em></span><sub>Xi</sub><span class="emphasis"><em> = b</em></span> =100. In the second, <span class="inlinemediaobject"><img src="graphics/B05137_06_262.jpg" alt="Maximum likelihood estimation for Bayesian networks"/></span> is satisfied by 100 when <span class="emphasis"><em>parent</em></span><sub>Xi</sub><span class="emphasis"><em> = b</em></span> =1000. Notice both probabilities come to the same value, whereas the second has 10 times more data and is the "more likely" estimate! Similarly, familiarity with domain or prior knowledge, or lack of it due to uncertainty, is not captured by <a id="id1263" class="indexterm"/>MLE. Thus, when the number of samples are limited or when the domain experts are aware of the priors, then this method suffers from serious issues. </p></div><div class="section" title="Bayesian parameter estimation for Bayesian network"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec174"/>Bayesian parameter estimation for Bayesian network</h4></div></div></div><p>This <a id="id1264" class="indexterm"/>technique overcomes the issue of MLE by encoding prior knowledge about the parameter <span class="emphasis"><em>?</em></span> with a probability distribution. Thus, we can encode our beliefs or prior knowledge about the parameter space as a probability distribution and then the joint distribution of variables and parameters are used in estimation. </p><p>Let us consider single variable parameter learning where we have instances <span class="emphasis"><em>x</em></span>[1], <span class="emphasis"><em>x</em></span>[2] … <span class="emphasis"><em>x</em></span>[M] and they all have parameter <span class="strong"><strong>?</strong></span><sub>X</sub>.</p><div class="mediaobject"><img src="graphics/B05137_06_267.jpg" alt="Bayesian parameter estimation for Bayesian network"/><div class="caption"><p>Figure 13. Single variable parameter learning</p></div></div><div class="mediaobject"><img src="graphics/B05137_06_268.jpg" alt="Bayesian parameter estimation for Bayesian network"/></div><div class="mediaobject"><img src="graphics/B05137_06_269.jpg" alt="Bayesian parameter estimation for Bayesian network"/></div><p>Thus, the network is a joint probability model over parameters and data. The advantage is we can use it for the posterior distribution:</p><div class="mediaobject"><img src="graphics/B05137_06_270.jpg" alt="Bayesian parameter estimation for Bayesian network"/></div><p>
</p><div class="mediaobject"><img src="graphics/B05137_06_271.jpg" alt="Bayesian parameter estimation for Bayesian network"/></div><p>, <span class="emphasis"><em>P(?) = prior</em></span>,</p><p>
<span class="inlinemediaobject"><img src="graphics/B05137_06_273.jpg" alt="Bayesian parameter estimation for Bayesian network"/></span> Thus, the difference between the maximum <a id="id1265" class="indexterm"/>likelihood and Bayesian estimation is the use of the priors. </p><p>Generalizing it to a Bayesian network <span class="emphasis"><em>G</em></span> given the dataset <span class="emphasis"><em>D</em></span>:</p><div class="mediaobject"><img src="graphics/B05137_06_274.jpg" alt="Bayesian parameter estimation for Bayesian network"/></div><div class="mediaobject"><img src="graphics/B05137_06_275.jpg" alt="Bayesian parameter estimation for Bayesian network"/></div><p>If we assume global independence of parameters </p><div class="mediaobject"><img src="graphics/B05137_06_276.jpg" alt="Bayesian parameter estimation for Bayesian network"/></div><p>Thus, we get </p><div class="mediaobject"><img src="graphics/B05137_06_277.jpg" alt="Bayesian parameter estimation for Bayesian network"/></div><p>Again, as <a id="id1266" class="indexterm"/>before, subset <span class="strong"><strong>?</strong></span><sub>Xi</sub> | <span class="emphasis"><em>parent</em></span><sub>Xi</sub> of <span class="strong"><strong>?</strong></span> is local and thus the entire posterior can be computed in local terms!</p><div class="section" title="Prior and posterior using the Dirichlet distribution"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec71"/>Prior and posterior using the Dirichlet distribution</h5></div></div></div><p>Often, in <a id="id1267" class="indexterm"/>practice, a continuous probability distribution known as Dirichlet distribution—which is a Beta distribution—is used <a id="id1268" class="indexterm"/>to represent priors over the parameters. </p><div class="mediaobject"><img src="graphics/B05137_06_279.jpg" alt="Prior and posterior using the Dirichlet distribution"/></div><p>Probability Density Function: </p><div class="mediaobject"><img src="graphics/B05137_06_280.jpg" alt="Prior and posterior using the Dirichlet distribution"/></div><p>Here, <span class="inlinemediaobject"><img src="graphics/B05137_06_281.jpg" alt="Prior and posterior using the Dirichlet distribution"/></span>, <span class="inlinemediaobject"><img src="graphics/B05137_06_282.jpg" alt="Prior and posterior using the Dirichlet distribution"/></span> The alpha terms are known as hyperparameters and <span class="emphasis"><em>a</em></span><sub>ijri</sub> &gt; 0. The <span class="inlinemediaobject"><img src="graphics/B05137_06_284.jpg" alt="Prior and posterior using the Dirichlet distribution"/></span> is the pseudo count, also known as equivalent sample size and it gives us a measure of the prior.</p><p>The Beta function, <span class="emphasis"><em>B(a</em></span><sub>ij</sub><span class="emphasis"><em>)</em></span> is normally expressed in terms of gamma function as follows</p><div class="mediaobject"><img src="graphics/B05137_06_286.jpg" alt="Prior and posterior using the Dirichlet distribution"/></div><p>The advantage of using Dirichlet distribution is it is conjugate in nature, that is, irrespective of the likelihood, the posterior is also a Dirichlet if the prior is Dirichlet! </p><p>It can be shown that the posterior distribution for the parameters <span class="emphasis"><em>?</em></span><sub>ijk</sub> is a Dirichlet with updated hyperparameters and has a closed form solution!</p><p>
<span class="emphasis"><em>a</em></span><sub>ijk</sub> = <span class="emphasis"><em>a</em></span><sub>ijk</sub> + <span class="emphasis"><em>N</em></span><sub>ijk</sub></p><p>If we use <a id="id1269" class="indexterm"/>maximum a posteriori estimate and <a id="id1270" class="indexterm"/>posterior means they can be shown to be:</p><div class="mediaobject"><img src="graphics/B05137_06_289.jpg" alt="Prior and posterior using the Dirichlet distribution"/></div><div class="mediaobject"><img src="graphics/B05137_06_290.jpg" alt="Prior and posterior using the Dirichlet distribution"/></div></div></div></div><div class="section" title="Learning structures"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec110"/>Learning structures</h3></div></div></div><p>Learning Bayesian <a id="id1271" class="indexterm"/>network without any domain knowledge or understanding of structures includes learning the structure and the parameters. We will first discuss some measures that are used for evaluating the network structures and then discuss a few well-known algorithms for building optimal structures.</p><div class="section" title="Measures to evaluate structures"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec175"/>Measures to evaluate structures</h4></div></div></div><p>The measures used to <a id="id1272" class="indexterm"/>evaluate a Bayes network structure, given the dataset, can be broadly divided into the following categories and details of many are available here (<span class="emphasis"><em>References</em></span> [14]).</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Deviance-Threshold Measure</strong></span>: The two common techniques to measure deviance <a id="id1273" class="indexterm"/>between two variables used in the network and structure are Pearson's chi-squared statistic and the Kullback-Leibler distance. <p>Given the dataset <span class="emphasis"><em>D</em></span> of <span class="emphasis"><em>M</em></span> samples, consider two variables <span class="emphasis"><em>X</em></span><sub>i</sub> and <span class="emphasis"><em>X</em></span><sub>j</sub>, the Pearson's chi-squared statistic measuring divergence is </p><div class="mediaobject"><img src="graphics/B05137_06_292.jpg" alt="Measures to evaluate structures"/></div><div class="mediaobject"><img src="graphics/B05137_06_424.jpg" alt="Measures to evaluate structures"/></div><div class="mediaobject"><img src="graphics/B05137_06_294.jpg" alt="Measures to evaluate structures"/></div><div class="mediaobject"><img src="graphics/B05137_06_295.jpg" alt="Measures to evaluate structures"/></div><p>
<span class="emphasis"><em>d</em></span><sub>?2</sub><span class="emphasis"><em>(D)</em></span> is 0; when the variables are independent and larger values indicate there is dependency between the variables.</p><p>Kullback-Leibler divergence is: </p><div class="mediaobject"><img src="graphics/B05137_06_297.jpg" alt="Measures to evaluate structures"/></div><p>
<span class="emphasis"><em>d</em></span><sub>I</sub><span class="emphasis"><em>(D)</em></span> is again 0, it shows independence and the larger values indicates dependency. Using various statistical hypothesis tests, a threshold can be used to determine the significance. </p></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Structure Score Measure</strong></span>: There are various measures to give scores to a structure in a <a id="id1274" class="indexterm"/>Bayes <a id="id1275" class="indexterm"/>network. We will discuss the most commonly used measures here. A log-likelihood score discussed in parameter learning can be used as a score for the structure: <div class="mediaobject"><img src="graphics/B05137_06_299.jpg" alt="Measures to evaluate structures"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Bayesian information score</strong></span> (<span class="strong"><strong>BIC</strong></span>) is also quite a popular scoring technique as it avoids <a id="id1276" class="indexterm"/>overfitting by taking into consideration the penalty for complex structures, as shown in the following equation <div class="mediaobject"><img src="graphics/B05137_06_300.jpg" alt="Measures to evaluate structures"/></div><div class="mediaobject"><img src="graphics/B05137_06_301.jpg" alt="Measures to evaluate structures"/></div></li></ul></div><p>The penalty function is logarithmic in <span class="emphasis"><em>M</em></span>, so, as it increases, the penalty is less severe for complex structures.</p><p>The Akaike information score (AIC), similar to BIC, has similar penalty based scoring and is:</p><div class="mediaobject"><img src="graphics/B05137_06_302.jpg" alt="Measures to evaluate structures"/></div><p>Bayesian <a id="id1277" class="indexterm"/>scores discussed in parameter learning are also employed as scoring measures.</p></div><div class="section" title="Methods for learning structures"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec176"/>Methods for learning structures</h4></div></div></div><p>We will <a id="id1278" class="indexterm"/>discuss a few algorithms that are used for learning structures in this section; details can be found here (<span class="emphasis"><em>References</em></span> [15]). </p><div class="section" title="Constraint-based techniques"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec72"/>Constraint-based techniques</h5></div></div></div><p>Constraint-based algorithms use independence tests of various variables, trying to find different <a id="id1279" class="indexterm"/>structural dependencies that we discussed in previous sections such as the d-separation, v-structure, and so on, by following the step-by-step process discussed here.</p><div class="section" title="Inputs and outputs"><div class="titlepage"><div><div><h6 class="title"><a id="ch06lvl6sec03"/>Inputs and outputs</h6></div></div></div><p>The input is the dataset <span class="emphasis"><em>D</em></span> with all the variables <span class="emphasis"><em>{X,Y..}</em></span> known for every instance {1,2, ... <span class="emphasis"><em>m</em></span>}, and no missing values. The output is a Bayesian network graph <span class="emphasis"><em>G</em></span> with all edges, directions known in <span class="strong"><strong>E</strong></span> and the CPT table.</p></div><div class="section" title="How does it work?"><div class="titlepage"><div><div><h6 class="title"><a id="ch06lvl6sec04"/>How does it work?</h6></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create an empty set of undirected edge <span class="strong"><strong>E</strong></span>.</li><li class="listitem">Test for conditional independence between two variables independent of directions to have an edge.<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">If for all subset <span class="strong"><strong>S</strong></span> = <span class="emphasis"><em>U</em></span> – {<span class="emphasis"><em>X, Y</em></span>}, if <span class="emphasis"><em>X</em></span> is independent of <span class="emphasis"><em>Y</em></span>, then add it to the set of undirected edge <span class="strong"><strong>E</strong></span><span class="emphasis"><em>'</em></span>.</li></ol></div></li><li class="listitem">Once all potential undirected edges are identified, directionality of the edge is inferred from the set <span class="strong"><strong>E</strong></span><span class="emphasis"><em>'</em></span>.<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">
Considering a triplet <span class="emphasis"><em>{X, Y, Z}</em></span>, if there is an edge <span class="emphasis"><em>X – Z</em></span> and <span class="emphasis"><em>Y – Z</em></span>, but no edge between <span class="emphasis"><em>X – Y</em></span> using all variables in the set, and further, if <span class="emphasis"><em>X</em></span> is not independent of <span class="emphasis"><em>Y</em></span> given all the edges <span class="strong"><strong>S</strong></span> = <span class="emphasis"><em>U</em></span> – {<span class="emphasis"><em>X, Y, Z</em></span>}, this implies the direction of <span class="inlinemediaobject"><img src="graphics/B05137_06_312.jpg" alt="How does it work?"/></span> and <span class="inlinemediaobject"><img src="graphics/B05137_06_313.jpg" alt="How does it work?"/></span>. 
</li><li class="listitem">
Add the edges <span class="inlinemediaobject"><img src="graphics/B05137_06_312.jpg" alt="How does it work?"/></span> and <span class="inlinemediaobject"><img src="graphics/B05137_06_313.jpg" alt="How does it work?"/></span> to set <span class="strong"><strong>E</strong></span>.
</li><li class="listitem">Update the CPT table using local calculations.</li></ol></div></li><li class="listitem">Return the Bayes network <span class="emphasis"><em>G</em></span>, edges <span class="strong"><strong>E</strong></span>, and the CPT tables. </li></ol></div></div><div class="section" title="Advantages and limitations"><div class="titlepage"><div><div><h6 class="title"><a id="ch06lvl6sec05"/>Advantages and limitations</h6></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Lack of <a id="id1280" class="indexterm"/>robustness is one of the biggest drawbacks of this method. A small error in data can cause a big impact on the structure due to the assumptions of independence that will creep into the individual independence tests.</li><li class="listitem" style="list-style-type: disc">Scalability and computation time is a major concern as every subset of variables are tested and is <a id="id1281" class="indexterm"/>approximately 2<sup>n</sup>. As the number of variables increase to the 100s, this method fails due to computation time. </li></ul></div></div></div><div class="section" title="Search and score-based techniques"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec73"/>Search and score-based techniques</h5></div></div></div><p>The search <a id="id1282" class="indexterm"/>and score method can be seen as a heuristic optimization method where iteratively, structure is changed through small perturbations, and measures such as BIC or MLE are used to give score to the structures to find the optimal score and structure. Hill climbing, depth-first search, genetic algorithms, and so on, have all been used to search and score.</p><div class="section" title="Inputs and outputs"><div class="titlepage"><div><div><h6 class="title"><a id="ch06lvl6sec06"/>Inputs and outputs</h6></div></div></div><p>Input is dataset <span class="emphasis"><em>D</em></span> with all the variables <span class="emphasis"><em>{X,Y..}</em></span> known for every instance {1,2, ... <span class="emphasis"><em>m</em></span>} and no missing values. The output is a Bayesian network graph <span class="emphasis"><em>G</em></span> with all edges and directions known in <span class="strong"><strong>E</strong></span>.</p></div><div class="section" title="How does it work?"><div class="titlepage"><div><div><h6 class="title"><a id="ch06lvl6sec07"/>How does it work?</h6></div></div></div><div class="mediaobject"><img src="graphics/B05137_06_316.jpg" alt="How does it work?"/><div class="caption"><p>Figure 14. Search and Score</p></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Initialize <a id="id1283" class="indexterm"/>the Graph <span class="emphasis"><em>G</em></span>, either based on domain knowledge or empty or full. Initialize the Edge set <span class="strong"><strong>E</strong></span> based on the graph and initialize the CPT tables <span class="emphasis"><em>T</em></span> based on the graph <span class="emphasis"><em>G</em></span>, <span class="strong"><strong>E</strong></span>, and the data <span class="emphasis"><em>D</em></span>. Normally terminating conditions are also mentioned such as <span class="emphasis"><em>maxIterations</em></span>:</li><li class="listitem"><span class="emphasis"><em>maxScore= -8, score=computeScore(G,</em></span><span class="strong"><strong>E</strong></span><span class="emphasis"><em>, T)</em></span></li><li class="listitem">Do<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem"><span class="emphasis"><em>maxScore=score</em></span></li><li class="listitem">
For each variable pair <span class="emphasis"><em>(X, Y)</em></span><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">
For each <span class="inlinemediaobject"><img src="graphics/B05137_06_324.jpg" alt="How does it work?"/></span></li><li class="listitem">New Graph G' based on parents and variables with edge changes.</li><li class="listitem">Compute new CPTs <span class="emphasis"><em>T' ? computeCPT(G',E',D)</em></span>.</li><li class="listitem"><span class="emphasis"><em>currentScore = computeScore(G',</em></span><span class="strong"><strong>E</strong></span><span class="emphasis"><em>',T')</em></span></li><li class="listitem">If <span class="emphasis"><em>currentScore &gt; score</em></span>:<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem"><span class="emphasis"><em>score = currentScore</em></span></li><li class="listitem"><span class="emphasis"><em>G' = G</em></span>, <span class="strong"><strong>E</strong></span><span class="emphasis"><em>'</em></span> = <span class="strong"><strong>E</strong></span></li></ol></div></li></ol></div></li></ol></div></li><li class="listitem">
Repeat 3 while (<span class="inlinemediaobject"><img src="graphics/B05137_06_332.jpg" alt="How does it work?"/></span></li></ol></div></div><div class="section" title="Advantages and limitations"><div class="titlepage"><div><div><h6 class="title"><a id="ch06lvl6sec08"/>Advantages and limitations</h6></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Getting <a id="id1284" class="indexterm"/>stuck in a local optimum, which is the drawback of most of these heuristic search methods, is one of the biggest disadvantages. </li><li class="listitem" style="list-style-type: disc">Convergence or theoretical guarantees are not available in heuristic search, so searching for termination is very much by guess work.</li></ul></div></div></div></div></div></div></div>
<div class="section" title="Markov networks and conditional random fields"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec54"/>Markov networks and conditional random fields</h1></div></div></div><p>So far, we have covered directed acyclic graphs in the area of probabilistic graph models, including every aspect of representation, inference, and learning. When the graphs are undirected, they <a id="id1285" class="indexterm"/>are known as <span class="strong"><strong>Markov networks</strong></span> (<span class="strong"><strong>MN</strong></span>) or <span class="strong"><strong>Markov random </strong></span>
<a id="id1286" class="indexterm"/>
<span class="strong"><strong>field</strong></span> (<span class="strong"><strong>MRF</strong></span>). We will discuss some aspects of Markov networks in this section covering areas of representation, inference, and learning, as before. Markov networks or MRF are very popular in various areas of computer vision such as segmentation, de-noising, stereo, recognition, and so on. For further reading, see (<span class="emphasis"><em>References</em></span> [10]).</p><div class="section" title="Representation"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec93"/>Representation</h2></div></div></div><p>Even though a Markov <a id="id1287" class="indexterm"/>network, like Bayesian networks, has undirected edges, it still has local interactions and distributions. We will first discuss the concept of parameterization, which is a way to capture these interactions, and then the independencies in MN.</p><div class="section" title="Parameterization"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec111"/>Parameterization</h3></div></div></div><p>The affinities <a id="id1288" class="indexterm"/>between the variables in MN are captured through three alternative parameterization techniques discussed in the following sections.</p><div class="section" title="Gibbs parameterization"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec177"/>Gibbs parameterization </h4></div></div></div><p>The probability <a id="id1289" class="indexterm"/>distribution function is said to <a id="id1290" class="indexterm"/>be in Gibb's distribution or parameterized by Gibb's distribution if </p><div class="mediaobject"><img src="graphics/B05137_06_333.jpg" alt="Gibbs parameterization"/></div><p>
<span class="emphasis"><em>Z</em></span> is called the partitioning function defined as:</p><div class="mediaobject"><img src="graphics/B05137_06_334.jpg" alt="Gibbs parameterization"/></div><p>Note that interaction between variables are captured by factors <span class="inlinemediaobject"><img src="graphics/B05137_06_335.jpg" alt="Gibbs parameterization"/></span> and are not the marginal probabilities, but contribute to the joint probability. The factors that parameterize a Markov network are called clique potentials. By choosing factors over maximal cliques in the graph, the number of parameters are reduced substantially. </p></div><div class="section" title="Factor graphs"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec178"/>Factor graphs</h4></div></div></div><p>Graph structure of <a id="id1291" class="indexterm"/>Markov network does not reveal properties such as whether the factors involve maximal cliques or their subsets when using Gibbs parameterization. Factor graphs discussed in the section of inferencing in Bayesian networks have a step to recognize maximal cliques and thus can capture these parameterizations. Please refer to the section on factor graphs in BN. </p></div><div class="section" title="Log-linear models"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec179"/>Log-linear models</h4></div></div></div><p>Another form of <a id="id1292" class="indexterm"/>parameterization is to use the energy model representation from statistical physics. </p><p>The potential is represented as a set of features and a potential table is generally represented by features with weights associated with them. </p><p>If <span class="emphasis"><em>D</em></span> is a set of variables, <span class="inlinemediaobject"><img src="graphics/B05137_06_337.jpg" alt="Log-linear models"/></span> is a factor then:</p><div class="mediaobject"><img src="graphics/B05137_06_338.jpg" alt="Log-linear models"/></div><p>Thus, as the energy increases, the probability decreases and vice versa. The logarithmic cell frequencies <a id="id1293" class="indexterm"/>captured in <span class="inlinemediaobject"><img src="graphics/B05137_06_337.jpg" alt="Log-linear models"/></span> are known as log-linear in statistical physics. The joint probability can be represented as:</p><div class="mediaobject"><img src="graphics/B05137_06_339.jpg" alt="Log-linear models"/></div><p>
<span class="inlinemediaobject"><img src="graphics/B05137_06_340.jpg" alt="Log-linear models"/></span> is the feature function defined over the variables in <span class="strong"><strong>D</strong></span><sub>i</sub>.</p></div></div><div class="section" title="Independencies"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec112"/>Independencies</h3></div></div></div><p>Like Bayesian <a id="id1294" class="indexterm"/>networks, Markov networks also encode a set of independence assumptions governing the flow of influence in undirected graphs.</p><div class="section" title="Global"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec180"/>Global </h4></div></div></div><p>A set of nodes <span class="strong"><strong>Z</strong></span> <a id="id1295" class="indexterm"/>separates sets of nodes <span class="strong"><strong>X</strong></span> and <span class="strong"><strong>Y</strong></span>, if there is no active path between any node in <span class="emphasis"><em>X</em></span> ? <span class="strong"><strong>X</strong></span> and <span class="emphasis"><em>Y</em></span> ? <span class="strong"><strong>Y</strong></span> given <span class="strong"><strong>Z</strong></span>. Independence in graph <span class="emphasis"><em>G</em></span> is:</p><div class="mediaobject"><img src="graphics/B05137_06_345.jpg" alt="Global"/></div></div><div class="section" title="Pairwise Markov"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec181"/>Pairwise Markov</h4></div></div></div><p>Two nodes, <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span>, are <a id="id1296" class="indexterm"/>independent given all other nodes if there is no direct edge between them. This property is of local independence and is weakest of all:</p><div class="mediaobject"><img src="graphics/B05137_06_346.jpg" alt="Pairwise Markov"/></div><div class="section" title="Markov blanket"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl5sec74"/>Markov blanket</h5></div></div></div><p>A node is independent <a id="id1297" class="indexterm"/>of all other nodes in the <a id="id1298" class="indexterm"/>graph, given its Markov blanket, which is an important concept in Markov networks:</p><div class="mediaobject"><img src="graphics/B05137_06_347.jpg" alt="Markov blanket"/></div><p>Here <span class="strong"><strong>U</strong></span>
<span class="emphasis"><em> = markov blanket of X</em></span>.</p><p>
<span class="emphasis"><em>Figure 15</em></span> shows a <a id="id1299" class="indexterm"/>Markov blanket for variable <span class="emphasis"><em>X</em></span> as its <a id="id1300" class="indexterm"/>parents, children, and children's parents:</p><div class="mediaobject"><img src="graphics/B05137_06_349.jpg" alt="Markov blanket"/><div class="caption"><p>Figure 15. Markov blanket for Node X - its Parents, Children, and Children's Parents.</p></div></div></div></div></div></div><div class="section" title="Inference"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec94"/>Inference </h2></div></div></div><p>Inference in MNs is <a id="id1301" class="indexterm"/>similarly #P-complete problem and hence similar approximations or heuristics get applied. Most exact and approximate inferencing techniques, such as variable elimination method, junction tree method, belief propagation method, and so on, which were discussed in Bayes network, are directly applicable to Markov networks. The marginals and conditionals remain similar and computed over the potential functions over the cliques as</p><div class="mediaobject"><img src="graphics/B05137_06_350.jpg" alt="Inference"/></div><div class="mediaobject"><img src="graphics/B05137_06_351.jpg" alt="Inference"/></div><p>Markov blankets simplify some of the computations.</p></div><div class="section" title="Learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec95"/>Learning</h2></div></div></div><p>Learning the <a id="id1302" class="indexterm"/>parameters in Markov networks is complex and computationally expensive due to the entanglement of all the parameters in the partitioning function. The advantageous step of decomposing the computations into local distributions cannot be done because of the partitioning function needing the factor coupling of all the variables in the network. </p><p>Maximum likelihood estimation in MN does not have a closed–form solution and hence incremental techniques such as gradient descent are used for optimizing over the entire parameter space. The optimization function can be shown to be a concave function, thus ensuring a global optimum, but each step of the iterations in gradient descent requires inferencing over the entire network, making it computationally expensive and sometimes intractable. </p><p>Bayesian parameter estimation requires integration over the entire space of parameters, which again has no closed-form solution and is even harder. Thus, most often, approximate learning methods such as <span class="strong"><strong>Markov Chain Monte Carlo</strong></span> (<span class="strong"><strong>MCMC</strong></span>) are used for MNs.</p><p>Structure learning in the MNs is similar or even harder than parameter learning and has been shown to be NP-hard. In the constraint-based approach, for a given dataset, conditional independence between the variables is tested. In MNs, each pair of variables is tested for conditional independence using mutual information between the pair. Then, based on a threshold, an edge is either considered to be existing between the pair or not. One disadvantage of this is it requires extremely large numbers of samples to refute any noise present in the data. Complexity of the network due to occurrence of pairwise edges is another limitation. </p><p>In search and score-based learning, the goal is similar to BNs, where search is done for structures and scoring—based on various techniques—is computed to help and adjust the search. In the case of MNs, we use features described in the log-linear models rather than the potentials. The weighting of the features is considered during optimization and scoring. </p></div><div class="section" title="Conditional random fields"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec96"/>Conditional random fields</h2></div></div></div><p>
<span class="strong"><strong>Conditional </strong></span>
<a id="id1303" class="indexterm"/>
<span class="strong"><strong>random fields</strong></span> (<span class="strong"><strong>CRFs</strong></span>) are a specialized form of Markov network where the hidden and observables are <a id="id1304" class="indexterm"/>mostly modeled for labeled sequence prediction problems (<span class="emphasis"><em>References</em></span> [16]). Sequence prediction problems manifest in many text mining areas such as next word/letter predictions, <span class="strong"><strong>Part of speech</strong></span> (<span class="strong"><strong>POS</strong></span>) tagging, and so on, and in bioinformatics domain for DNA or protein sequence predictions. </p><p>The idea behind CRFs is the conditional distribution of sequence is modeled as feature functions and the labeled data is used to learn using optimization the empirical distribution, as shown in the following figure.</p><p>The conditional <a id="id1305" class="indexterm"/>distribution is expressed as follows where <span class="emphasis"><em>Z</em></span>(<span class="strong"><strong>x</strong></span>) is the normalizing constant. Maximum likelihood is used for parameter estimation for <span class="emphasis"><em>?</em></span> and is generally a convex function in log-linear obtained through iterative optimization methods such as gradient descent.</p><div class="mediaobject"><img src="graphics/B05137_06_354.jpg" alt="Conditional random fields"/></div><div class="mediaobject"><img src="graphics/B05137_06_355.jpg" alt="Conditional random fields"/><div class="caption"><p>Figure 16: Conditional random fields mapped to the area of sequence prediction in the POS tagging domain.</p></div></div></div></div>
<div class="section" title="Specialized networks"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec55"/>Specialized networks</h1></div></div></div><p>In this section, we will cover some basic specialized probabilistic graph models that are very useful in different machine learning applications. </p><div class="section" title="Tree augmented network"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec97"/>Tree augmented network</h2></div></div></div><p>In <a class="link" href="ch02.html" title="Chapter 2. Practical Approach to Real-World Supervised Learning">Chapter 2</a>, <span class="emphasis"><em>Practical Approach to Real-World Supervised Learning</em></span>, we discussed the Naïve Bayes <a id="id1306" class="indexterm"/>network, which makes the simplified assumption that all variables are independent of each other and only have dependency on the target or the class variable. This is the simplest Bayesian network derived or assumed from the dataset. As we saw in the previous sections, learning complex structures and parameters in Bayesian networks can be difficult or sometimes intractable. The <span class="strong"><strong>tree augmented network</strong></span> or <span class="strong"><strong>TAN</strong></span> (<span class="emphasis"><em>References</em></span> [9]) can be considered somewhere in the middle, introducing constraints on how the trees are connected. TAN puts a constraint on features or variable relationships. A feature can have only one other feature as parent in addition to the target variable, as illustrated in the following figure:</p><div class="mediaobject"><img src="graphics/B05137_06_356.jpg" alt="Tree augmented network"/><div class="caption"><p>Figure 17. Tree augmented network showing comparison with Naïve Bayes and Bayes network and the constraint of one parent per node.</p></div></div><div class="section" title="Input and output"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec113"/>Input and output</h3></div></div></div><p>Inputs are the <a id="id1307" class="indexterm"/>training dataset <span class="emphasis"><em>D</em></span> with all the features as variables <span class="emphasis"><em>{X, Y..}</em></span>. The features have discrete outcomes, if they don't need to be discretized as a pre-processing step. </p><p>Outputs are TAN as Bayesian network with CPTs.</p></div><div class="section" title="How does it work?"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec114"/>How does it work?</h3></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Compute <a id="id1308" class="indexterm"/>mutual information between every pair of variables from the training dataset.</li><li class="listitem">Build an undirected graph with each node being the variable and edge being the mutual information between them.</li><li class="listitem">Create a maximum weighted spanning tree.</li><li class="listitem">Transform the spanning tree to a directed graph by selecting the outcome or the target variable as the root and having all the edges flowing in the outwards direction.</li><li class="listitem">If there is no directed edge between the class variable and other features, add it.</li><li class="listitem">Compute the CPTs based on the DAG or TAN constructed previously.</li></ol></div></div><div class="section" title="Advantages and limitations"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec115"/>Advantages and limitations</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">It is more accurate <a id="id1309" class="indexterm"/>than Naïve Bayes in many practical models. It is less complex and faster to build and compute than complete Bayes networks.</li></ul></div></div></div><div class="section" title="Markov chains"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec98"/>Markov chains</h2></div></div></div><p>Markov <a id="id1310" class="indexterm"/>Chains are specialized probabilistic graph models, with directed graphs containing loops. Markov chains can be seen as extensions of automata where the weights are probabilities of transition. Markov chains are useful to model temporal or sequence of changes that are directly observable. See (<span class="emphasis"><em>References</em></span> [12]) for further study.</p><p>
<span class="emphasis"><em>Figure 17</em></span> represents a Markov chain (first order) and the general definition can be given as a stochastic process consisting of </p><p>Nodes as states, <span class="inlinemediaobject"><img src="graphics/B05137_06_357.jpg" alt="Markov chains"/></span>.</p><p>Edges representing transition probabilities between the states or nodes. It is generally represented as a matrix <span class="inlinemediaobject"><img src="graphics/B05137_06_358.jpg" alt="Markov chains"/></span>, which is a <span class="emphasis"><em>N</em></span> X <span class="emphasis"><em>N</em></span>  matrix where <span class="emphasis"><em>N</em></span> is the number of nodes or states. The value of <span class="inlinemediaobject"><img src="graphics/B05137_06_361.jpg" alt="Markov chains"/></span> captures the transition probability to node <span class="emphasis"><em>q</em></span><sub>l</sub> given the state <span class="emphasis"><em>q</em></span><sub>k</sub>. The rows of matrix add to 1 and the values of <span class="inlinemediaobject"><img src="graphics/B05137_06_364.jpg" alt="Markov chains"/></span>.</p><p>Initial probabilities of being in the state, <span class="emphasis"><em>p</em></span> = {<span class="emphasis"><em>p</em></span><sub>1</sub>, <span class="emphasis"><em>p</em></span><sub>2</sub>, … <span class="emphasis"><em>p</em></span><sub>N</sub>}.</p><p>Thus, it can be written as a triple <span class="emphasis"><em>M</em></span>= (Q, <span class="strong"><strong>A</strong></span>, <span class="emphasis"><em>p</em></span>) and the probability of being in any state only depends on the last state (first order):</p><div class="mediaobject"><img src="graphics/B05137_06_367.jpg" alt="Markov chains"/></div><p>The joint <a id="id1311" class="indexterm"/>probability:</p><div class="mediaobject"><img src="graphics/B05137_06_368.jpg" alt="Markov chains"/></div><div class="mediaobject"><img src="graphics/B05137_06_369.jpg" alt="Markov chains"/><div class="caption"><p>Figure 18. First-order Markov chain</p></div></div><div class="section" title="Hidden Markov models"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec116"/>Hidden Markov models</h3></div></div></div><p>In many <a id="id1312" class="indexterm"/>real-world situations, the events we are interested in are not directly observable. For example, the words in sentences are observable, but the part-of-speech that generated the sentence is not. <span class="strong"><strong>Hidden Markov </strong></span>
<a id="id1313" class="indexterm"/>
<span class="strong"><strong>models</strong></span> (<span class="strong"><strong>HMM</strong></span>) help us in modeling such states where there are observable events and hidden states (<span class="emphasis"><em>References</em></span> [13]). HMM are widely used in various modeling applications for speech recognition, language modeling, time series analysis, and bioinformatics applications such as DNA/protein sequence predictions, to name a few.</p><div class="mediaobject"><img src="graphics/B05137_06_370.jpg" alt="Hidden Markov models"/><div class="caption"><p>Figure 19. Hidden Markov model showing hidden variables and the observables.</p></div></div><p>Hidden <a id="id1314" class="indexterm"/>Markov models can be defined again as a triple <span class="inlinemediaobject"><img src="graphics/B05137_06_371.jpg" alt="Hidden Markov models"/></span>, where: </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">
 is a set of finite states or symbols that are observed. <span class="inlinemediaobject"><img src="graphics/B05137_06_373.jpg" alt="Hidden Markov models"/></span></li><li class="listitem" style="list-style-type: disc">
Q is a set of finite states that are not observed <span class="inlinemediaobject"><img src="graphics/B05137_06_375.jpg" alt="Hidden Markov models"/></span>.
</li><li class="listitem" style="list-style-type: disc">T are the parameters. </li></ul></div><p>The state transition matrix, given as <span class="inlinemediaobject"><img src="graphics/B05137_06_377.jpg" alt="Hidden Markov models"/></span> captures the probability of transition from state <span class="emphasis"><em>q</em></span><sub>k</sub> to <span class="emphasis"><em>q</em></span><sub>l</sub>.</p><p>Emission probabilities capturing relationships between the hidden and observed state, given as <span class="inlinemediaobject"><img src="graphics/B05137_06_379.jpg" alt="Hidden Markov models"/></span> and <span class="emphasis"><em>b</em></span> ? ?. <span class="inlinemediaobject"><img src="graphics/B05137_06_381.jpg" alt="Hidden Markov models"/></span>.</p><p>Initial state distribution <span class="emphasis"><em>p</em></span> = {<span class="emphasis"><em>p</em></span><sub>1</sub>, <span class="emphasis"><em>p</em></span><sub>2</sub>, … <span class="emphasis"><em>p</em></span><sub>N</sub>}.</p><p>Thus, a path in HMM consisting of a sequence of hidden states Q = {<span class="emphasis"><em>q</em></span><sub>1</sub>, <span class="emphasis"><em>q</em></span><sub>2</sub>, … <span class="emphasis"><em>q</em></span><sub>L</sub>}  is a first order Markov chain<span class="emphasis"><em> M</em></span>= (Q, <span class="strong"><strong>A</strong></span>, <span class="emphasis"><em>p</em></span>). This path in HMM emits a sequence of symbols, <span class="emphasis"><em>x</em></span><sub>1</sub>, <span class="emphasis"><em>x</em></span><sub>2</sub>, <span class="emphasis"><em>x</em></span><sub>L</sub>, referred to as the observations. Thus, knowing both the observations and hidden states the joint probability is:</p><div class="mediaobject"><img src="graphics/B05137_06_384.jpg" alt="Hidden Markov models"/></div><p>In real-world situations, we only know the observations <span class="emphasis"><em>x</em></span> and do not know the hidden states <span class="emphasis"><em>q</em></span>. HMM helps us to answer the following questions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">What is the most likely path that could have generated the observation <span class="emphasis"><em>x</em></span>?</li><li class="listitem" style="list-style-type: disc">What is the probability of <span class="emphasis"><em>x</em></span>?</li><li class="listitem" style="list-style-type: disc">What is the <a id="id1315" class="indexterm"/>probability of being in state <span class="emphasis"><em>q</em></span>i<span class="emphasis"><em> = k</em></span> given the observation ?</li></ul></div></div><div class="section" title="Most probable path in HMM"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec117"/>Most probable path in HMM</h3></div></div></div><p>Let us <a id="id1316" class="indexterm"/>assume the observations <span class="emphasis"><em>x</em></span> = <span class="emphasis"><em>x</em></span><sub>1</sub>, <span class="emphasis"><em>x</em></span><sub>2</sub>, <span class="emphasis"><em>x</em></span><sub>L</sub> and we want to find the path <span class="inlinemediaobject"><img src="graphics/B05137_06_388.jpg" alt="Most probable path in HMM"/></span> that generated the observations. This can be given as:</p><div class="mediaobject"><img src="graphics/B05137_06_389.jpg" alt="Most probable path in HMM"/></div><p>The path <span class="emphasis"><em>q*</em></span> need not be unique, but for computation and explanation the assumption of the unique path is often made. In a naïve way, we can compute all possible paths of length <span class="emphasis"><em>L</em></span> of <span class="emphasis"><em>q</em></span> and chose the one(s) with the highest probability giving exponential computing terms or speed. More efficient is using Viterbi's algorithm using the concept of dynamic programming and recursion. It works on the simple principle of breaking the equation into simpler terms as:</p><div class="mediaobject"><img src="graphics/B05137_06_391.jpg" alt="Most probable path in HMM"/></div><div class="mediaobject"><img src="graphics/B05137_06_392.jpg" alt="Most probable path in HMM"/></div><div class="mediaobject"><img src="graphics/B05137_06_393.jpg" alt="Most probable path in HMM"/></div><p>Here, <span class="inlinemediaobject"><img src="graphics/B05137_06_394.jpg" alt="Most probable path in HMM"/></span> and <span class="inlinemediaobject"><img src="graphics/B05137_06_395.jpg" alt="Most probable path in HMM"/></span> Given the initial condition <span class="inlinemediaobject"><img src="graphics/B05137_06_396.jpg" alt="Most probable path in HMM"/></span> and using dynamic programming with keeping pointer to the path, we can efficiently compute the answer.</p></div><div class="section" title="Posterior decoding in HMM"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec118"/>Posterior decoding in HMM</h3></div></div></div><p>The <a id="id1317" class="indexterm"/>probability of being in a state <span class="emphasis"><em>q</em></span><sub>i</sub><span class="emphasis"><em> = k</em></span> given the observation <span class="emphasis"><em>x</em></span> can be written using Bayes theorem as:</p><div class="mediaobject"><img src="graphics/B05137_06_397.jpg" alt="Posterior decoding in HMM"/></div><p>The numerator can be rewritten as:</p><div class="mediaobject"><img src="graphics/B05137_06_398.jpg" alt="Posterior decoding in HMM"/></div><div class="mediaobject"><img src="graphics/B05137_06_399.jpg" alt="Posterior decoding in HMM"/></div><div class="mediaobject"><img src="graphics/B05137_06_400.jpg" alt="Posterior decoding in HMM"/></div><div class="mediaobject"><img src="graphics/B05137_06_428.jpg" alt="Posterior decoding in HMM"/></div><p>Where <span class="inlinemediaobject"><img src="graphics/B05137_06_402.jpg" alt="Posterior decoding in HMM"/></span> is called a Forward variable and <span class="inlinemediaobject"><img src="graphics/B05137_06_403.jpg" alt="Posterior decoding in HMM"/></span> is called a Backward variable.</p><p>The <a id="id1318" class="indexterm"/>computation of the forward variable is similar to Viterbi's algorithm using dynamic programming and recursion where summation is done instead:</p><div class="mediaobject"><img src="graphics/B05137_06_404.jpg" alt="Posterior decoding in HMM"/></div><div class="mediaobject"><img src="graphics/B05137_06_405.jpg" alt="Posterior decoding in HMM"/></div><div class="mediaobject"><img src="graphics/B05137_06_406.jpg" alt="Posterior decoding in HMM"/></div><p>The probability of observing <span class="emphasis"><em>x</em></span> can be, then</p><div class="mediaobject"><img src="graphics/B05137_06_407.jpg" alt="Posterior decoding in HMM"/></div><p>The forward variable is the joint probability and the backward variable is a conditional probability:</p><div class="mediaobject"><img src="graphics/B05137_06_403.jpg" alt="Posterior decoding in HMM"/></div><div class="mediaobject"><img src="graphics/B05137_06_408.jpg" alt="Posterior decoding in HMM"/></div><div class="mediaobject"><img src="graphics/B05137_06_409.jpg" alt="Posterior decoding in HMM"/></div><p>It is called <a id="id1319" class="indexterm"/>a backward variable as the dynamic programming table is filled starting with the <span class="emphasis"><em>L</em></span><sup>th</sup> column to the first in a backward manner. The backward probabilities can also be used to compute the probability of observing <span class="emphasis"><em>x</em></span> as: </p><div class="mediaobject"><img src="graphics/B05137_06_411.jpg" alt="Posterior decoding in HMM"/></div></div></div></div>
<div class="section" title="Tools and usage"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec56"/>Tools and usage</h1></div></div></div><p>In this section, we will introduce two tools in Java that are very popular for probabilistic graph modeling. </p><div class="section" title="OpenMarkov"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec99"/>OpenMarkov</h2></div></div></div><p>OpenMarkov is a <a id="id1320" class="indexterm"/>Java-based tool for PGMs and here is the description from <a class="ulink" href="http://www.openmarkov.org">www.openmarkov.org</a>:</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note16"/>Note</h3><p>OpenMarkov is a software tool for probabilistic graphical models (PGMs) developed by the Research Centre for Intelligent Decision-Support Systems of the UNED in Madrid, Spain.</p><p>It has been designed for: editing and evaluating several types of PGMs, such as Bayesian networks, influence diagrams, factored Markov models, and so on, learning Bayesian networks from data interactively, and cost-effectiveness analysis.</p></div></div><p>OpenMarkov is very good in performing interactive and automated learning from the data. It has capabilities to preprocess the data (discretization using frequency and value) and perform structure and parameter learning using a few search algorithms such as search-based Hill Climbing and score-based PC. OpenMarkov stores the models in a format known as pgmx. To apply the models in most traditional packages there may be a need to convert the pgmx models to XMLBIF format. Various open source tools provide these conversions.</p><p>Here we have some screenshots illustrating the usage of OpenMarkov to learn the structure and parameters from the data. </p><p>In <span class="emphasis"><em>Figure 20</em></span>, we see the screen for interactive learning where you select the data file and algorithm to use:</p><div class="mediaobject"><img src="graphics/B05137_06_412.jpg" alt="OpenMarkov"/><div class="caption"><p>Figure 20. OpenMarkov GUI – Interactive learning, algorithm selection</p></div></div><p>The next step is the <a id="id1321" class="indexterm"/>
<span class="strong"><strong>Preprocessing</strong></span> tab (<span class="emphasis"><em>Figure 21</em></span>) where we can select how discretization is done:</p><div class="mediaobject"><img src="graphics/B05137_06_413.jpg" alt="OpenMarkov"/><div class="caption"><p>Figure 21. OpenMarkov GUI – Preprocessing screen</p></div></div><p>Finally, in <span class="emphasis"><em>Figure 22</em></span>, we <a id="id1322" class="indexterm"/>see the display of the learned Bayes network structure:</p><div class="mediaobject"><img src="graphics/B05137_06_414.jpg" alt="OpenMarkov"/><div class="caption"><p>Figure 22. OpenMarkov GUI – Structure output</p></div></div></div><div class="section" title="Weka Bayesian Network GUI"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec100"/>Weka Bayesian Network GUI</h2></div></div></div><p>Weka's Bayes Network <a id="id1323" class="indexterm"/>editor for interactive and automated learning has a large number of options for Bayes network representation, inference and learning as compared to OpenMarkov. The advantage in using Weka is the availability of a number of well-integrated preprocessing and transformation filters, algorithms, evaluation, and experimental metrics.</p><p>In <span class="emphasis"><em>Figure 23</em></span>, we <a id="id1324" class="indexterm"/>see the Bayes Network Editor where the search algorithm is selected and various options can be configured:</p><div class="mediaobject"><img src="graphics/B05137_06_415.jpg" alt="Weka Bayesian Network GUI"/><div class="caption"><p>Figure 23. WEKA Bayes Network – configuring search algorithm</p></div></div><p>The learned structure and parameters of the BayesNet are shown in the output screen in <span class="emphasis"><em>Figure 24</em></span>:</p><div class="mediaobject"><img src="graphics/B05137_06_416.jpg" alt="Weka Bayesian Network GUI"/><div class="caption"><p>Figure 24. WEKA Bayes Network – Learned parameter and structure </p></div></div></div></div>
<div class="section" title="Case study"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec57"/>Case study</h1></div></div></div><p>In this section, we will <a id="id1325" class="indexterm"/>perform a case study with real-world machine learning datasets to illustrate some of the concepts from Bayesian networks. </p><p>We will use the UCI Adult dataset, also known as the <span class="emphasis"><em>Census Income</em></span> dataset (<a class="ulink" href="http://archive.ics.uci.edu/ml/datasets/Census+Income">http://archive.ics.uci.edu/ml/datasets/Census+Income</a>). This dataset was extracted from the United States Census Bureau's 1994 census data. The donors of the data is Ronny Kohavi and Barry Becker, who were with Silicon Graphics at the time. The dataset consists of 48,842 instances with 14 attributes, with a mix of categorical and continuous types. The target class is binary.</p><div class="section" title="Business problem"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec101"/>Business problem</h2></div></div></div><p>The problem <a id="id1326" class="indexterm"/>consists of predicting the income of members of a population based on census data, specifically, whether their income is greater than $50,000.</p></div><div class="section" title="Machine learning mapping"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec102"/>Machine learning mapping</h2></div></div></div><p>This is a problem of <a id="id1327" class="indexterm"/>classification and this time around we will be training Bayesian graph networks to develop predictive models. We will be using linear, non-linear, and ensemble algorithms, as we have done in experiments in previous chapters.</p></div><div class="section" title="Data sampling and transformation"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec103"/>Data sampling and transformation</h2></div></div></div><p>In the <a id="id1328" class="indexterm"/>original dataset, there are 3,620 examples with missing values and six duplicate or conflicting instances. Here we include only examples with no missing values. This set, without unknowns, is divided into 30,162 training instances and 15,060 test instances. </p></div><div class="section" title="Feature analysis"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec104"/>Feature analysis</h2></div></div></div><p>The features and <a id="id1329" class="indexterm"/>their descriptions are given in <span class="emphasis"><em>Table 3</em></span>:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Feature</p>
</th><th style="text-align: left" valign="bottom">
<p>Type information</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>age</p>
</td><td style="text-align: left" valign="top">
<p>continuous.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>workclass</p>
</td><td style="text-align: left" valign="top">
<p>Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>fnlwgt</p>
</td><td style="text-align: left" valign="top">
<p>continuous.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>education</p>
</td><td style="text-align: left" valign="top">
<p>Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>education-num</p>
</td><td style="text-align: left" valign="top">
<p>continuous.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>marital-status</p>
</td><td style="text-align: left" valign="top">
<p>Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>occupation</p>
</td><td style="text-align: left" valign="top">
<p>Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>relationship</p>
</td><td style="text-align: left" valign="top">
<p>Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>race</p>
</td><td style="text-align: left" valign="top">
<p>White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>sex</p>
</td><td style="text-align: left" valign="top">
<p>Female, Male.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>capital-gain</p>
</td><td style="text-align: left" valign="top">
<p>continuous.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>capital-loss</p>
</td><td style="text-align: left" valign="top">
<p>continuous.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>hours-per-week</p>
</td><td style="text-align: left" valign="top">
<p>continuous.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>native-country</p>
</td><td style="text-align: left" valign="top">
<p> United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, <a id="id1330" class="indexterm"/>France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&amp;Tobago, Peru, Hong, Holand-Netherlands.</p>
</td></tr></tbody></table></div><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em> Table 3. UCI Adult dataset – features </em></span></p></blockquote></div><p>The dataset is split by label as 24.78% (&gt;50K) to 75.22% (&lt;= 50K). Summary statistics of key features are given in <span class="emphasis"><em>Figure 25</em></span>: </p><div class="mediaobject"><img src="graphics/B05137_06_417.jpg" alt="Feature analysis"/></div><div class="mediaobject"><img src="graphics/B05137_06_418.jpg" alt="Feature analysis"/><div class="caption"><p>Figure 25. Feature summary statistics</p></div></div></div><div class="section" title="Models, results, and evaluation"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec105"/>Models, results, and evaluation</h2></div></div></div><p>We will <a id="id1331" class="indexterm"/>perform detailed analysis on the Adult dataset using different flavors of Bayes network structures and with regular linear, non-linear, and ensemble algorithms. Weka also has an option to visualize the graph model on the trained dataset using the menu item, as shown in <span class="emphasis"><em>Figure 26</em></span>. This is very useful when the domain expert wants to understand the assumptions and the structure of the graph model. If the domain expert wants to change or alter the network, it can be done easily and saved using the Bayes Network editor. </p><div class="mediaobject"><img src="graphics/B05137_06_419.jpg" alt="Models, results, and evaluation"/><div class="caption"><p>Figure 26. Weka Explorer – visualization menu</p></div></div><p>
<span class="emphasis"><em>Figure 27</em></span> shows <a id="id1332" class="indexterm"/>the visualization of the trained Bayes Network model's graph structure:</p><div class="mediaobject"><img src="graphics/B05137_06_420.jpg" alt="Models, results, and evaluation"/><div class="caption"><p>Figure 27: Visualization of learned structure of the Bayesian network.</p></div></div><p>The <a id="id1333" class="indexterm"/>algorithms used for experiments are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Bayesian network Classifiers</li><li class="listitem" style="list-style-type: disc">Naïve Bayes with default Kernel estimation on continuous data</li><li class="listitem" style="list-style-type: disc">Naïve Bayes with supervised discretization on continuous data</li><li class="listitem" style="list-style-type: disc">Tree augmented network (TAN) with search-score structure parameter learning using the K2 algorithm and a choice of three parents per node</li><li class="listitem" style="list-style-type: disc">Bayesian network with search and score</li><li class="listitem" style="list-style-type: disc">Searching using Hill Climbing and K2</li><li class="listitem" style="list-style-type: disc">Scoring using Simple Estimation</li><li class="listitem" style="list-style-type: disc">Choice of parents changed from two to three to illustrate the effect on metrics</li><li class="listitem" style="list-style-type: disc">Non-Bayesian algorithms</li><li class="listitem" style="list-style-type: disc">Logistic Regression (default parameters)</li><li class="listitem" style="list-style-type: disc">KNN (IBK with 10 Neighbors)</li><li class="listitem" style="list-style-type: disc">Decision Tree (J48, default parameters)</li><li class="listitem" style="list-style-type: disc">AdaBoostM1 (DecisionStump and default parameters)</li><li class="listitem" style="list-style-type: disc">Random Forest (default parameters)</li></ul></div><p>
<span class="emphasis"><em>Table 4</em></span> <a id="id1334" class="indexterm"/>presents the evaluation metrics for all the learners used in the experiments, including Bayesian network classifiers as well as the non-Bayesian algorithms:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Algorithms</p>
</th><th style="text-align: left" valign="bottom">
<p>TP Rate </p>
</th><th style="text-align: left" valign="bottom">
<p>FP Rate </p>
</th><th style="text-align: left" valign="bottom">
<p>Precision </p>
</th><th style="text-align: left" valign="bottom">
<p>Recall  </p>
</th><th style="text-align: left" valign="bottom">
<p>F-Measure </p>
</th><th style="text-align: left" valign="bottom">
<p>MCC </p>
</th><th style="text-align: left" valign="bottom">
<p>ROC Area </p>
</th><th style="text-align: left" valign="bottom">
<p>PRC Area </p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Naïve Bayes (Kernel Estimator)</p>
</td><td style="text-align: left" valign="top">
<p>0.831</p>
</td><td style="text-align: left" valign="top">
<p>0.391</p>
</td><td style="text-align: left" valign="top">
<p>0.821</p>
</td><td style="text-align: left" valign="top">
<p>0.831</p>
</td><td style="text-align: left" valign="top">
<p>0.822</p>
</td><td style="text-align: left" valign="top">
<p>0.494</p>
</td><td style="text-align: left" valign="top">
<p>0.891</p>
</td><td style="text-align: left" valign="top">
<p>0.906</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Naïve Bayes (Discretized)</p>
</td><td style="text-align: left" valign="top">
<p>0.843</p>
</td><td style="text-align: left" valign="top">
<p>0.191</p>
</td><td style="text-align: left" valign="top">
<p>0.861</p>
</td><td style="text-align: left" valign="top">
<p>0.843</p>
</td><td style="text-align: left" valign="top">
<p>0.848</p>
</td><td style="text-align: left" valign="top">
<p>0.6</p>
</td><td style="text-align: left" valign="top">
<p>0.917</p>
</td><td style="text-align: left" valign="top">
<p>0.93</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>TAN (K2, 3 Parents, Simple Estimator)</p>
</td><td style="text-align: left" valign="top">
<p>0.859</p>
</td><td style="text-align: left" valign="top">
<p>0.273</p>
</td><td style="text-align: left" valign="top">
<p>0.856</p>
</td><td style="text-align: left" valign="top">
<p>0.859</p>
</td><td style="text-align: left" valign="top">
<p>0.857</p>
</td><td style="text-align: left" valign="top">
<p>0.6</p>
</td><td style="text-align: left" valign="top">
<p>0.916</p>
</td><td style="text-align: left" valign="top">
<p>0.931</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>BayesNet (K2, 3 Parents, Simple Estimator)</p>
</td><td style="text-align: left" valign="top">
<p>0.863</p>
</td><td style="text-align: left" valign="top">
<p>0.283</p>
</td><td style="text-align: left" valign="top">
<p>0.858</p>
</td><td style="text-align: left" valign="top">
<p>0.863</p>
</td><td style="text-align: left" valign="top">
<p>0.86</p>
</td><td style="text-align: left" valign="top">
<p>0.605</p>
</td><td style="text-align: left" valign="top">
<p>0.934</p>
</td><td style="text-align: left" valign="top">
<p>0.919</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>BayesNet (K2, 2 Parents, Simple Estimator)</p>
</td><td style="text-align: left" valign="top">
<p>0.858</p>
</td><td style="text-align: left" valign="top">
<p>0.283</p>
</td><td style="text-align: left" valign="top">
<p>0.854</p>
</td><td style="text-align: left" valign="top">
<p>0.858</p>
</td><td style="text-align: left" valign="top">
<p>0.855</p>
</td><td style="text-align: left" valign="top">
<p>0.594</p>
</td><td style="text-align: left" valign="top">
<p>0.917</p>
</td><td style="text-align: left" valign="top">
<p>0.932</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>BayesNet (Hill Climbing, 3 Parents, Simple Estimator)</p>
</td><td style="text-align: left" valign="top">
<p>0.862</p>
</td><td style="text-align: left" valign="top">
<p>0.293</p>
</td><td style="text-align: left" valign="top">
<p>0.857</p>
</td><td style="text-align: left" valign="top">
<p>0.862</p>
</td><td style="text-align: left" valign="top">
<p>0.859</p>
</td><td style="text-align: left" valign="top">
<p>0.602</p>
</td><td style="text-align: left" valign="top">
<p>0.918</p>
</td><td style="text-align: left" valign="top">
<p>0.933</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Logistic Regression</p>
</td><td style="text-align: left" valign="top">
<p>0.851</p>
</td><td style="text-align: left" valign="top">
<p>0.332</p>
</td><td style="text-align: left" valign="top">
<p>0.844</p>
</td><td style="text-align: left" valign="top">
<p>0.851</p>
</td><td style="text-align: left" valign="top">
<p>0.845</p>
</td><td style="text-align: left" valign="top">
<p>0.561</p>
</td><td style="text-align: left" valign="top">
<p>0.903</p>
</td><td style="text-align: left" valign="top">
<p>0.917</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>KNN (10)</p>
</td><td style="text-align: left" valign="top">
<p>0.834</p>
</td><td style="text-align: left" valign="top">
<p>0.375</p>
</td><td style="text-align: left" valign="top">
<p>0.824</p>
</td><td style="text-align: left" valign="top">
<p>0.834</p>
</td><td style="text-align: left" valign="top">
<p>0.826</p>
</td><td style="text-align: left" valign="top">
<p>0.506</p>
</td><td style="text-align: left" valign="top">
<p>0.867</p>
</td><td style="text-align: left" valign="top">
<p>0.874</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Decision Tree (J48)</p>
</td><td style="text-align: left" valign="top">
<p>0.858</p>
</td><td style="text-align: left" valign="top">
<p>0.300</p>
</td><td style="text-align: left" valign="top">
<p>0.853</p>
</td><td style="text-align: left" valign="top">
<p>0.858</p>
</td><td style="text-align: left" valign="top">
<p>0.855</p>
</td><td style="text-align: left" valign="top">
<p>0.590</p>
</td><td style="text-align: left" valign="top">
<p>0.890 </p>
</td><td style="text-align: left" valign="top">
<p>0.904</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>AdaBoostM1</p>
</td><td style="text-align: left" valign="top">
<p>0.841</p>
</td><td style="text-align: left" valign="top">
<p>0.415</p>
</td><td style="text-align: left" valign="top">
<p>0.833</p>
</td><td style="text-align: left" valign="top">
<p>0.841</p>
</td><td style="text-align: left" valign="top">
<p>0.826</p>
</td><td style="text-align: left" valign="top">
<p>0.513</p>
</td><td style="text-align: left" valign="top">
<p>0.872</p>
</td><td style="text-align: left" valign="top">
<p>0.873</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Random Forest</p>
</td><td style="text-align: left" valign="top">
<p>0.848</p>
</td><td style="text-align: left" valign="top">
<p>0.333</p>
</td><td style="text-align: left" valign="top">
<p>0.841</p>
</td><td style="text-align: left" valign="top">
<p>0.848</p>
</td><td style="text-align: left" valign="top">
<p>0.843</p>
</td><td style="text-align: left" valign="top">
<p>0.555</p>
</td><td style="text-align: left" valign="top">
<p>0.896</p>
</td><td style="text-align: left" valign="top">
<p>0.913</p>
</td></tr></tbody></table></div><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em> Table 4. Classifier performance metrics </em></span></p></blockquote></div></div><div class="section" title="Analysis of results"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec106"/>Analysis of results</h2></div></div></div><p>Naïve <a id="id1335" class="indexterm"/>Bayes with supervised discretization shows relatively better performance than kernel estimation. This gives a useful hint that discretization, which is needed in most Bayes networks, will play an important role.</p><p>The results in the table show continuous improvement when Bayes network complexity is increased. For example, Naïve Bayes with discretization assumes independence from all features and shows a TP rate of 84.3, the TAN algorithm where there can be one more parent shows a TP rate of 85.9, and BN with three parents shows the best TP rate of 86.2. This clearly indicates that a complex BN with some nodes having no more than three parents can capture the domain knowledge and encode it well to predict on unseen test data.</p><p>Bayes network where structure is learned using search and score (with K2 search with three parents and scoring using Bayes score) and estimation is done using simple estimation, performs the best in almost all the metrics of the evaluation, as shown in the highlighted values.</p><p>There is a very small difference between Bayes Networks—where structure is learned using search and score of Hill Climbing—and K2, showing that even local search algorithms can find an optimum.</p><p>Bayes network with a three-parent structure beats most linear, non-linear, and ensemble methods such as AdaBoostM1 and Random Forest on almost all the metrics on unseen test data. This shows the strength of BNs in not only learning the structure and parameters on small datasets with large number of missing values as well as predicting well on unseen data, but in beating other sophisticated algorithms too. </p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec58"/>Summary</h1></div></div></div><p>PGMs capture domain knowledge as relationships between variables and represent joint probabilities. They are used in a range of applications.</p><p>Probability maps an event to a real value between 0 and 1 and can be interpreted as a measure of the frequency of occurrence (frequentist view) or as a degree of belief in that occurrence (Bayesian view). Concepts of random variables, conditional probabilities, Bayes' theorem, chain rule, marginal and conditional independence and factors form the foundations to understanding PGMs. MAP and Marginal Map queries are ways to ask questions about the variables and relationships in the graph.</p><p>The structure of graphs and their properties such as paths, trails, cycles, sub-graphs, and cliques are vital to the understanding of Bayesian networks. Representation, Inference, and Learning form the core elements of networks that help us capture, extract, and make predictions using these methods. From the representation of graphs, we can reason about the flow of influence and detect independencies that help reduce the computational load when querying the model. Junction trees, variable elimination, and belief propagation methods likewise make inference from queries more tractable by reductive steps. Learning from Bayesian networks involves generating the structure and model parameters from the data. We discussed several methods of learning parameters and structure.</p><p>
<span class="strong"><strong>Markov networks</strong></span> (<span class="strong"><strong>MN</strong></span>), which have undirected edges, also contain interactions that can be captured using parameterization techniques such as Gibbs parameterization, Factor Graphs, and Log-Linear Models. Independencies in MN govern flows of influence, as in Bayesian networks. Inference techniques are also similar. Learning of parameters and structure in MN is hard, and approximate methods are used. Specialized networks such as <span class="strong"><strong>Tree augmented networks</strong></span> (<span class="strong"><strong>TAN</strong></span>) make assumptions of independence amongst nodes and are very useful in some applications. Markov Chains and hidden Markov models are other specialty networks that also find application in a range of fields.</p><p>Open Markov and Weka Bayesian Network GUI are introduced as Java-based tools for PGMs. The case study in this chapter used Bayesian Networks to learn from the UCI Adult census dataset and its performance was compared to other (non-PGM) classifiers.</p></div>
<div class="section" title="References"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec59"/>References</h1></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Daphne Koller and Nir Friedman (2009). <span class="emphasis"><em>Probabilistic Graphical Models</em></span>. MIT Press. ISBN 0-262-01319-3.</li><li class="listitem">T. Verma and J. Pearl (1988), In proceedings for fourth workshop on Uncertainty in Artificial Intelligence, Montana, Pages 352-359. Causal Networks- Semantics and expressiveness.</li><li class="listitem">Dagum, P., and Luby, M. (1993). <span class="emphasis"><em>Approximating probabilistic inference in Bayesian belief networks is NP hard</em></span>. Artificial Intelligence 60(1):141–153.</li><li class="listitem">U. Bertele and F. Brioschi, <span class="emphasis"><em>Nonserial Dynamic Programming</em></span>, Academic Press. New York, 1972.</li><li class="listitem">Shenoy, P. P. and G. Shafer (1990). <span class="emphasis"><em>Axioms for probability and belief-function propagation</em></span>, in Uncertainty in Artificial Intelligence, 4, 169-198, North-Holland, Amsterdam</li><li class="listitem">Bayarri, M.J. and DeGroot, M.H. (1989). <span class="emphasis"><em>Information in Selection Models</em></span>. Probability and Bayesian Statistics, (R. Viertl, ed.), Plenum Press, New York.</li><li class="listitem">Spiegelhalter and Lauritzen (1990). <span class="emphasis"><em>Sequential updating of conditional probabilities on directed graphical structures</em></span>. Networks 20. Pages 579-605.</li><li class="listitem">David Heckerman, Dan Geiger, David M Chickering (1995). In journal of Machine Learning. <span class="emphasis"><em>Learning Bayesian networks: The combination of knowledge and statistical data</em></span>.</li><li class="listitem">Friedman, N., Geiger, D., &amp; Goldszmidt, M. (1997). <span class="emphasis"><em>Bayesian network classifiers</em></span>. Machine Learning, 29, 131– 163.</li><li class="listitem">Isham, V. (1981). <span class="emphasis"><em>An introduction to spatial point processes and Markov random fields</em></span>. International Statistical Rewview, 49(1):21–43</li><li class="listitem">Frank R. Kschischang, Brendan J. Frey, and Hans-Andrea Loeliger, <span class="emphasis"><em>Factor graphs and sum-product algorithm</em></span>, IEEE Trans. Info. Theory, vol. 47, pp. 498–519, Feb. 2001. </li><li class="listitem">Kemeny, J. G. and Snell, J. L. <span class="emphasis"><em>Finite Markov Chains</em></span>. New York: Springer-Verlag, 1976.</li><li class="listitem">Baum, L. E.; Petrie, T. (1966). <span class="emphasis"><em>Statistical Inference for Probabilistic Functions of Finite State Markov Chains</em></span>. The Annals of Mathematical Statistics. 37 (6): 1554–1563. </li><li class="listitem">Gelman, A., Hwang, J. and Vehtar, A. (2004). <span class="emphasis"><em>Understanding predictive information criteria for Bayesian models</em></span>. Statistics and Computing Journal 24: 997. doi:10.1007/s11222-013-9416-2</li><li class="listitem">Dimitris. Margaritis (2003). <span class="emphasis"><em>Learning Bayesian Network Model Structure From Data</em></span>. Ph.D Thesis Carnegie Mellon University. </li><li class="listitem">John Lafferty, Andrew McCallum, Fernando C.N. Pereira (2001). <span class="emphasis"><em>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</em></span>, International Conference on Machine Learning 2001 (ICML 2001), pages 282-289.</li></ol></div></div></body></html>