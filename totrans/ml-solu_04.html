<html><head></head><body><div id="sbo-rt-content"><div class="chapter" title="Chapter 4. Recommendation Systems for E-Commerce"><div class="titlepage"><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Recommendation Systems for E-Commerce</h1></div></div></div><p>In the previous three chapters, we have covered a lot of tips and tricks that can be used to build various types of analytics products. In this chapter, we are going to build a recommendation engine for the e-commerce domain. Let's go over some background of recommendation systems. Then, we will discuss the problem statement that we are trying to solve in this chapter.</p><p>Let's take a relatable example from real life. We surf videos on YouTube almost every day, right? Suppose you saw some videos related to rock music on YouTube last night. This morning, when you open your YouTube, you may find that there are a couple of suggested YouTube channels with good videos on rock music. YouTube actually changes its suggestions based on your watching habits. Do you want to know how that algorithm works? Let's take another example that might be useful to us in this chapter. Most of us buy stuff from various e-commerce sites. Suppose you are trying to purchase a book from Amazon. When you search for a book there is a section that suggests other books in the same genre. The title of this section is <span class="emphasis"><em>Customers who bought this item also bought</em></span>; you may find these suggestions useful and buy another book as well. Take a look at the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_01.jpg" alt="Recommendation Systems for E-Commerce" width="596" height="337"/><div class="caption"><p>Figure 4.1: Book suggestions on Amazon</p></div></div><p>All these suggestions you find on e-commerce websites use a specific algorithm, and this algorithm is referred to as the recommendation algorithm. This chapter is all about how to build the recommendation system using different types of Machine Learning (ML) algorithms. Other than e-commerce, there are many domains in which the recommendation system has been used; for example, Netflix and YouTube use the recommendation algorithm to suggest videos we may like, Airbnb provides a recommendation based on our activities on their website. The retail banking domain too uses the logic of the recommendation engine to offer various types of credit cards and offers to their customers. The list is never-ending, so now let's learn how to build a recommendation system.</p><p>In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Introducing the problem statement</li><li class="listitem" style="list-style-type: disc">Understanding the datasets</li><li class="listitem" style="list-style-type: disc">Building the baseline approach:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding the basic concepts</li><li class="listitem" style="list-style-type: disc">Implementing the baseline approach</li><li class="listitem" style="list-style-type: disc">Understanding the testing matrix</li><li class="listitem" style="list-style-type: disc">Testing the result of the baseline approach</li><li class="listitem" style="list-style-type: disc">Problems with the baseline approach</li><li class="listitem" style="list-style-type: disc">Optimizing the baseline approach  </li></ul></div></li><li class="listitem" style="list-style-type: disc">Building the revised approach:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Implementing the revised approach</li><li class="listitem" style="list-style-type: disc">Testing the revised approach</li><li class="listitem" style="list-style-type: disc">Problems with the revised approach</li><li class="listitem" style="list-style-type: disc">Understanding how to improve the revised approach</li></ul></div></li><li class="listitem" style="list-style-type: disc">The best approach:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding the key concepts</li><li class="listitem" style="list-style-type: disc">Implementing the best approach</li></ul></div></li><li class="listitem" style="list-style-type: disc">Summary</li></ul></div><p>So let's discuss the problem statement as well as start with the basic concepts of the recommendation system.</p><div class="section" title="Introducing the problem statement"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec43"/>Introducing the problem statement</h1></div></div></div><p>As you know, in this chapter, we are trying to build a recommendation system. A domain that mainly uses the recommendation system is e-commerce. So, in our basic version of the recommendation engine specifically, we will be building an algorithm that can suggest the name of the products based on the category of the product. Once we know the basic concepts of the recommendation engine, we will build a recommendation engine that can suggest books in the same way as the Amazon website.</p><p>We will be building three versions of the recommendation algorithm. The baseline approach is simple but intuitive so that readers can learn what exactly the recommendation algorithm is capable of doing. Baseline is easy to implement. In the second and third approach, we will be building the book recommendation engine using ML algorithms.</p><p>Let's look at the basic methods or approaches that are used to build the recommendation system. There are two main approaches, which you can find in the following figure:</p><div class="mediaobject"><img src="Images/B08394_04_02.jpg" alt="Introducing the problem statement" width="737" height="381"/><div class="caption"><p>Figure 4.2: Approaches for the recommendation engine</p></div></div><p>We will be using these two approaches although there are other approaches as well, such as a knowledge-based approach or a hybrid approach. But in this chapter, we will be focusing on the given two approaches.</p><p>Now let's look at the dataset that we are going to use.</p></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Understanding the datasets"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec44"/>Understanding the datasets</h1></div></div></div><p>In this <a id="id429" class="indexterm"/>chapter, we are using two datasets, as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">E-commerce item data</li><li class="listitem" style="list-style-type: disc">Book-Crossing dataset</li></ul></div><div class="section" title="e-commerce Item Data"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec61"/>e-commerce Item Data</h2></div></div></div><p>This dataset <a id="id430" class="indexterm"/>contains data items taken from actual <a id="id431" class="indexterm"/>stock keeping units (SKUs). It is from an outdoor apparel brand's product catalog. We are building the recommendation engine for this outdoor <a id="id432" class="indexterm"/>apparel brand's product catalog. You can access the dataset by using this link: <a class="ulink" href="https://www.kaggle.com/cclark/product-item-data/data">https://www.kaggle.com/cclark/product-item-data/data</a>.</p><p>This dataset contains 500 data items. There are two columns in the dataset.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>ID</strong></span>: This column indicates the indexing of the data item. In layman's terms, it is the serial number of the dataset.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Description</strong></span>: This column has all the necessary descriptions about the products, and we need to use this data to build the recommendation engine.</li></ul></div><p>You can refer to the following figure:</p><div class="mediaobject"><img src="Images/B08394_04_03.jpg" alt="e-commerce Item Data" width="1000" height="712"/><div class="caption"><p>Figure 4.3: Snippet of the e-commerce item data</p></div></div><p>As you <a id="id433" class="indexterm"/>can see, the description column has textual data, and we <a id="id434" class="indexterm"/>need to process this textual dataset in order to build the recommendation engine. Now let's move to the next dataset.</p></div><div class="section" title="The Book-Crossing dataset"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec62"/>The Book-Crossing dataset</h2></div></div></div><p>The Book-Crossing <a id="id435" class="indexterm"/>dataset is widely used to build recommendation <a id="id436" class="indexterm"/>systems. You can access it at <a class="ulink" href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/">http://www2.informatik.uni-freiburg.de/~cziegler/BX/</a>. This dataset is available <a id="id437" class="indexterm"/>in two formats, as follows: </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"> SQL dump</li><li class="listitem" style="list-style-type: disc">CSV dump</li></ul></div><p>We are using the CSV dump of the dataset. Both formats have three tables with different <a id="id438" class="indexterm"/>data attributes. The names of these three <a id="id439" class="indexterm"/>files are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">BX-Book-Ratings.csv</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">BX-Books.csv</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">BX-Users.csv</code></li></ul></div><p>Let's explore the data given in each of the data tables.</p><div class="section" title="BX-Book-Ratings.csv"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec36"/>BX-Book-Ratings.csv</h3></div></div></div><p>This CSV file <a id="id440" class="indexterm"/>contains data related to the <a id="id441" class="indexterm"/>rating of the book. This table contains three data attributes, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>User-ID</strong></span>: This data <a id="id442" class="indexterm"/>attribute indicates the unique user ID. This column has a numeric value. The length of the user ID is six.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>ISBN</strong></span>: The full <a id="id443" class="indexterm"/>form of ISBN is International Standard Book Number. This data attribute indicates the unique identification number of the book.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Book rating</strong></span>: This data <a id="id444" class="indexterm"/>attribute indicates the user rating for the book. The rating of the book varies from 0 to 10. 0, with 0 indicating less appreciation and 10.0 indicating the highest appreciation.</li></ul></div></div><div class="section" title="BX-Books.csv"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec37"/>BX-Books.csv</h3></div></div></div><p>This file <a id="id445" class="indexterm"/>contains all the details regarding the books. The table <a id="id446" class="indexterm"/>contains the following data attributes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>ISBN</strong></span>: The ISBN is provided to identify the book. All invalid ISBNs have already <a id="id447" class="indexterm"/>been deleted. This data table contains only valid ISBNs.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Book-Title</strong></span>: This data <a id="id448" class="indexterm"/>attribute contains the name of the book.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Book-Author</strong></span>: This data <a id="id449" class="indexterm"/>attribute contains the name of the author of the book.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Year-Of-Publication</strong></span>: This indicates <a id="id450" class="indexterm"/>the year of publication of the book and is in the YYYY format.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Publisher</strong></span>: This data <a id="id451" class="indexterm"/>column has the name of the publisher who has published the book.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Image-URL-S</strong></span>: This data <a id="id452" class="indexterm"/>attribute has the URL for the image of the book's cover page. S indicates a small size of cover page image.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Image-URL-M</strong></span>: This data <a id="id453" class="indexterm"/>attribute has the URL for the image of the book's cover page. M indicates a medium size of cover image.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Image-URL-L</strong></span>: This data <a id="id454" class="indexterm"/>attribute has the URL for the image of the book's cover page. L indicates a large size of cover image.</li></ul></div><p>Now let's look at the details of the previous data table.</p></div><div class="section" title="BX-Users.csv"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec38"/>BX-Users.csv</h3></div></div></div><p>This is the third data table of the Book-Crossing <a id="id455" class="indexterm"/>dataset. This file contains information about the users.</p><p>This particular data file contains the following data attributes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>User-ID</strong></span>: This data <a id="id456" class="indexterm"/>column indicates the user ID, which is a six-digit integer number.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Location</strong></span>: This data <a id="id457" class="indexterm"/>is the part of the demographic details regarding the user. The location indicates the name and abbreviation of the city. The location details for all users are not available, so you will find the <code class="literal">null </code>value for those users whose locations haven't been found.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Age</strong></span>: This is also <a id="id458" class="indexterm"/>a demographic data point. If the user's age is tracked, then it is present in the dataset; if not, then the value of the age is <code class="literal">null</code>.</li></ul></div><p>We have gathered basic information about the two datasets. We will be moving toward building the basic version of the recommendation engine.</p></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Building the baseline approach"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec45"/>Building the baseline approach</h1></div></div></div><p>From this <a id="id459" class="indexterm"/>section onward, we will focus on how to build the basic version of the recommendation engine (which means the recommendation system in the context of this chapter). In order to develop the baseline approach, we will be using the content-based approach. These are the topics that we will be covering:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding the basic concepts</li><li class="listitem" style="list-style-type: disc">Implementing the baseline approach</li><li class="listitem" style="list-style-type: disc">Understanding the testing matrix</li><li class="listitem" style="list-style-type: disc">Testing the result of the baseline approach</li><li class="listitem" style="list-style-type: disc">Problems with the baseline approach</li><li class="listitem" style="list-style-type: disc">Learning optimization tricks for the baseline approach</li></ul></div><p>Without wasting any time, let's look at how the content-based approach has been used to build the recommendation engine.</p><div class="section" title="Understanding the basic concepts"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec63"/>Understanding the basic concepts</h2></div></div></div><p>As I've <a id="id460" class="indexterm"/>specified earlier, we are using the content-based approach. You must be wondering what this approach is and how I have decided to use it. In order to find the answers to these questions, we need to understand the approach first, and then we can discuss why I chose it.</p><div class="section" title="Understanding the content-based approach"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec39"/>Understanding the content-based approach</h3></div></div></div><p>The intuition <a id="id461" class="indexterm"/>behind this algorithm is simple. If you are buying or are interested in one type of item, then you will probably like a similar product(s) as well. Let's take an example. If you are buying a pair of jeans, then there is a high chance that you will also like to buy t-shirts or tops, as well as formal trousers or other types of trousers. Basically, the recommendation for the products is based on the content that you have explored, bought, or are interested in. This approach works well when the context and properties of each of the item can be determined easily. This kind of recommendation system is used to recommend video and audio content to users.</p><p>When you watch a comedy video on YouTube you might notice there are suggestions for other funny clips and comedy videos. This is because there is a high chance that you will like similar kinds of content based on your watching and browsing history. You can understand this example with the help of the following figure:</p><div class="mediaobject"><img src="Images/B08394_04_04.jpg" alt="Understanding the content-based approach" width="709" height="510"/><div class="caption"><p>Figure 4.4: Pictorial representation of the idea of the content-based approach</p></div></div><p>So, when we need to build a system that can recommend items or products that are similar to the user's buying pattern or browsing pattern, we use this approach. The reason for <a id="id462" class="indexterm"/>choosing this approach is that this type of recommendation is not influenced by choices of other users. This will provide a personalized experience for users. A recommendation is totally based on the items and its features that users like. This approach helps the e-commerce company increase their sales with less effort. It needs less manual work, which is a good point to note here. We can also use products that have been newly introduced by e-commerce platforms.</p><p>In order to implement this approach, we need to focus on the architecture part of it as well as look at basic concepts, such as TF-IDF and cosine similarity. We will explore all these topics in the next section.</p></div></div><div class="section" title="Implementing the baseline approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec64"/>Implementing the baseline approach</h2></div></div></div><p>In this <a id="id463" class="indexterm"/>section, we will be designing the architecture of the content-based recommendation system. After that, we will look at how we can build a simple recommendation system. So, there are two subtopics that we will be covering here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Architecture of the recommendation system</li><li class="listitem" style="list-style-type: disc">Steps for implementing the baseline approach</li></ul></div><div class="section" title="Architecture of the recommendation system"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec40"/>Architecture of the recommendation system</h3></div></div></div><p>In this <a id="id464" class="indexterm"/>section, we will cover the basic architecture for the content-based recommendation system. Refer to the following figure, which explains the components in more detail:</p><div class="mediaobject"><img src="Images/B08394_04_05.jpg" alt="Architecture of the recommendation system" width="683" height="937"/><div class="caption"><p>Figure 4.5: Architecture of the content-based recommendation system</p></div></div><p>As you can see, there are a number of components that we need to use in order to build the recommendation system. We are using the data source or the information source to store details <a id="id465" class="indexterm"/>about the items or products. The content analyzer converts the item description into a certain format so that the recommendation engine can consume this information. We have all the products or item-related information with us. Now we need to know what the user is browsing, buying, or searching for on the e-commerce platform. This user-related information is used as a training example for the recommendation system. These training examples are the input of the profile learning module that actual analyzes the age, gender, time spent on website, as well as other demographics and user-activity-based information.</p><p>This collective information will be passed on to the filtering component. Based on the information of the products available on the e-commerce platform and user's activities, we will recommend the list of items to the customer.</p><p>The logic of the recommendation engine comes into picture here. We will push the recommendations to the active users of the e-commerce platform. Here, active users are those who have bought the product in last month or who have browsed the platform more frequently. We need to track the activity of the users, which acts as the feedback for our recommendation engine.</p><p>In the feedback, we can track the number of items the user clicked on from the list of recommendations. Did they buy any items that were a part of the recommendation list? This kind of feedback is useful because based on this feedback, we can fine-tune the logic of the recommendation engine. We will send the feedback to the profile learner, and using that, we will update the interest area for each user so that in future we can give them more suggestions regarding sport clothes, if the person previously browsed sport shoes. Now that you understand the components and their workings, let's take a look at the step-by-step implementation of the baseline approach.</p></div><div class="section" title="Steps for implementing the baseline approach"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec41"/>Steps for implementing the baseline approach</h3></div></div></div><p>In this <a id="id466" class="indexterm"/>section, we will cover the coding of the basic recommendation engine. You can refer to the code by using this GitHub link: <a class="ulink" href="https://github.com/jalajthanaki/Basic_Ecommerce_Recomendation_System">https://github.com/jalajthanaki/Basic_Ecommerce_Recomendation_System</a> </p><p>These are the steps that we need to follow:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Loading the dataset</li><li class="listitem">Generating the feature using TF-IDF the cosine similarity matrix</li><li class="listitem">Generating the prediction</li></ol></div><p>
</p><div class="section" title="Loading the dataset"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec37"/>Loading the dataset</h4></div></div></div><p>We are <a id="id467" class="indexterm"/>using the e-commerce item dataset here. In this dataset, there is an item description that we need to use. We will use the <code class="literal">pandas </code>library to load the dataset. You can refer to the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_06.jpg" alt="Loading the dataset" width="427" height="56"/><div class="caption"><p>Figure 4.6: Code snippet for loading the dataset</p></div></div></div><div class="section" title="Generating features using TF-IDF"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec38"/>Generating features using TF-IDF</h4></div></div></div><p>We will <a id="id468" class="indexterm"/>be using the concept of TF-IDF, which is a simple but effective statistical feature technique. TF-IDF stands for Term Frequency-Inverse Document Frequency. I will explain this briefly.</p><p>TF-IDF has two parts: Term Frequency and Inverse Document Frequency. Let's begin with term frequency. The term is self-explanatory, but we will walk through the concept anyway. Term frequency indicates the frequency of each of the words present in the document or dataset. The equation for TF is given in the following formula:</p><div class="mediaobject"><img src="Images/B08394_04_07.jpg" alt="Generating features using TF-IDF" width="434" height="57"/><div class="caption"><p>Figure 4.7: Equation for TF</p></div></div><p>Now let's talk about inverse document frequency. IDF indicates how important the word is to the document. This is because when we calculate TF, we give equal importance to every single word. If the word <span class="emphasis"><em>the</em></span> appears in the dataset more frequently, then its term frequency (TF) value is high but that word does not carry much importance for the document. If the <a id="id469" class="indexterm"/>word <span class="emphasis"><em>the</em></span> appears in the document 100 times, then it means that it does not carry that much information compared to words that are less frequent in the dataset. Thus, we need to define some weighing down of frequent terms while scaling up the rare ones, which is what decides the importance of each word. We will achieve this by using the equation given in the following formula:</p><div class="mediaobject"><img src="Images/B08394_04_08.jpg" alt="Generating features using TF-IDF" width="424" height="57"/><div class="caption"><p>Figure 4.8: Equation for IDF</p></div></div><p>So, the final equation to calculate TF-IDF is given in the following formula:</p><p> </p><div class="mediaobject"><img src="Images/B08394_04_09.jpg" alt="Generating features using TF-IDF" width="892" height="67"/><div class="caption"><p>Figure 4.9: Equation for TF-IDF</p></div></div><p>
</p><p>If you want to read this in detail, then I would recommend that you read this topic from  this book: <a class="link" href="ch05.xhtml" title="Chapter 5. Sentiment Analysis">Chapter 5</a>, <span class="emphasis"><em>Python Natural Language Processing</em></span>. For that, you can refer
to this link:
<a class="ulink" href="https://www.packtpub.com/big-data-and-business-intelligence/python-natural-language-processing">https://www.packtpub.com/big-data-and-business-intelligence/python-natural-language-processing</a>
</p><p>The practical implementation of this concept is quite easy. We use the scikit-learn library to code this up. You can refer to the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_10.jpg" alt="Generating features using TF-IDF" width="877" height="64"/><div class="caption"><p>Figure 4.10: Code snippet for generating features using TF-IDF</p></div></div><p>Here, we have used the <code class="literal">TfidfVectorizer </code>API and generated the TF-IDF vectors for the item <a id="id470" class="indexterm"/>description. We have removed the English stop words using the <code class="literal">stop_words</code> parameter. Here, we have provided <code class="literal">ngram_range</code> from 1 to 3. Now let's build the cosine similarity matrix.</p></div><div class="section" title="Building the cosine similarity matrix"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec39"/>Building the cosine similarity matrix</h4></div></div></div><p>In this section, we will build the cosine similarity matrix, which is actually the main step required <a id="id471" class="indexterm"/>in order to build the content-based recommendation engine. This matrix indicates how similar the description of one product is to the other product. Here, we will check the cosine similarity between the TF-IDF vectors of all the products. We need to find the angle between two TF-IDF vectors. This angle represents how close or how far apart the TF-IDF vectors are. For that, we need to obtain the dot product between TF-IDF vectors by using the following equation:</p><div class="mediaobject"><img src="Images/B08394_04_11.jpg" alt="Building the cosine similarity matrix" width="295" height="57"/><div class="caption"><p>Figure 4.11: Equation for the dot product</p></div></div><p>Now, with the help of the given cosine equation, we can generate the angle between these vectors. You can refer to the equations in the following formula:</p><div class="mediaobject"><img src="Images/B08394_04_12.jpg" alt="Building the cosine similarity matrix" width="228" height="150"/><div class="caption"><p>Figure 4.12: Equation for cosine similarity and norm for vectors</p></div></div><p>Now let's look <a id="id472" class="indexterm"/>at a basic example so that you can understand the basic math behind it. For that, you need to refer to the following equation:</p><div class="mediaobject"><img src="Images/B08394_04_13.jpg" alt="Building the cosine similarity matrix" width="514" height="337"/><div class="caption"><p>Figure 4.13: Basic cosine similarity example</p></div></div><p>As you can see in the preceding figure, there are two vectors; each of them has three elements. First, we calculated their norms and then we performed the dot product on them. After that, we used the cosine similarity formula and found the angle between these vectors. Note that we can measure the cosine similarity for two nonzero vectors. The interval for the cosine angle is <span class="emphasis"><em>[0,2π)</em></span>.</p><p>The coding implementation for this is pretty easy. You can refer to the code snippet shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_14.jpg" alt="Building the cosine similarity matrix" width="719" height="238"/><div class="caption"><p>Figure 4.14: Code snippet for generating the cosine similarity</p></div></div><p>Here, we have <a id="id473" class="indexterm"/>stored all the recommendations in a dictionary, where each item and its corresponding recommendation have been stored. There are 500 items in our dataset, and for each and every item, we have generated a list of items that can be recommended to the users. Now it's time to generate the prediction.</p></div><div class="section" title="Generating the prediction"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec40"/>Generating the prediction</h4></div></div></div><p>In this section, we will be generating the recommendation list for the given <code class="literal">item_id</code>. We need <a id="id474" class="indexterm"/>to pass any <code class="literal">item_id</code> from 1 to 500. The system will obtain five different suggestions, which are referred to as recommended items. These recommended items are similar to the item whose <code class="literal">item_id</code> we have passed to the algorithm. You can see the code snippet in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_15.jpg" alt="Generating the prediction" width="791" height="444"/><div class="caption"><p>Figure 4.15: Code snippet for generating prediction</p></div></div><p>As you can see, we retrieve the results from the dictionary. We have printed the value of cos θ as our scoring values. If the score is close to one, then it can be said that these items are <a id="id475" class="indexterm"/>more similar and there is a higher chance that the user will like the recommendation. If the score is closer to 0 or –1, then items appear less attractive to the users. So just note that here, the score indicates the value of cos θ and not the angle directly.</p><p>Now let's look at the testing matrix, which can help us evaluate this approach as well as other approaches that we will be implementing in this chapter.</p></div></div></div><div class="section" title="Understanding the testing matrix"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec65"/>Understanding the testing matrix</h2></div></div></div><p>In this section, we will <a id="id476" class="indexterm"/>be exploring the testing or evolution matrix for the content-based recommendation engine. Here, the cosine similarity score is the biggest testing score for us. That is because with the help of that score, we can easily come to learn whether the algorithm can suggest the items whose cosine similarity score is close to 1 close to 0.</p><p>For some items, we will obtain a score that is close to 1, and for other items, we obtain a score that is close to 0. So, we need to focus on this cosine score in order to get an idea of how well or badly the recommendation engine is doing. You can refer to the following figure:</p><div class="mediaobject"><img src="Images/B08394_04_16.jpg" alt="Understanding the testing matrix" width="700" height="731"/><div class="caption"><p>Figure 4.16: Understanding of the cosine similarity score and angle</p></div></div><p>As we can <a id="id477" class="indexterm"/>see in the preceding figure, we need to use the cosine score in order to test this approach. We can perform the following steps for testing. We need to count the number of items with more than a certain score, which means that we can decide the threshold value for the cosine similarity score and count how many items the recommendation engine is suggesting above that threshold value. Let me give you an example. Suppose we decide a cut-off score of 0.15. In this case, all items whose <a id="id478" class="indexterm"/>cosine score is above 0.15 are considered a good recommendation. Here, the trick is that you need to experiment with this threshold value because based on the user's activity, you may change it later on. This parameter will be a tunable parameter for us. In the next section, we will look at the code for the testing.</p></div><div class="section" title="Testing the result of the baseline approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec66"/>Testing the result of the baseline approach</h2></div></div></div><p>In this section, we will <a id="id479" class="indexterm"/>see how we can implement the logic of the threshold value. After that, we will compare the results for different items. You can refer to the code snippet shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_17.jpg" alt="Testing the result of the baseline approach" width="781" height="787"/><div class="caption"><p>Figure 4.17: Code snippet for testing</p></div></div><p>Now you <a id="id480" class="indexterm"/>can see the results for different <code class="literal">item_ids</code>. You can find the result of the three items. I have picked up <code class="literal">item_id</code> randomly. Take a look at the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_18.jpg" alt="Testing the result of the baseline approach" width="608" height="668"/><div class="caption"><p>Figure 4.18: Result of items</p></div></div><p>Take a <a id="id481" class="indexterm"/>look at the following code snippet:
</p><div class="mediaobject"><img src="Images/B08394_04_19.jpg" alt="Testing the result of the baseline approach" width="261" height="115"/><div class="caption"><p>Figure 4.19: Analysis based on useful recommendations</p></div></div><p>As you can see in the preceding figure, this approach gives us useful recommendations 69.8% of the time, and it provides four useful suggestions 7.2% of the time. After looking at <a id="id482" class="indexterm"/>the analysis of the result, we can say that the baseline approach is doing well, and we can definitely improve the results with the help of the other approach.</p><p>In the next section, we will discuss the problems this baseline approach has and how we can solve them.</p></div><div class="section" title="Problems with the baseline approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec67"/>Problems with the baseline approach</h2></div></div></div><p>In this <a id="id483" class="indexterm"/>section, we will be discussing the problems that are a part of the baseline approach. We need to understand the problems so that we can take care of them in the revised approach. The problems with this approach are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Limited content analysis</strong></span>: If we <a id="id484" class="indexterm"/>do not have enough information in order to differentiate the items more accurately, then the recommendation engine won't be giving useful or more precise suggestions.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Over-specialization</strong></span>: Content-based systems are based on the user profile and the <a id="id485" class="indexterm"/>items they are browsing, so the user will get the same kind of suggestion if they are browsing the same thing again and again. There is no different or novel item that the user can find. This is bad because if we provide the same recommendation more often, then there is no element of surprise for the user and they won't be motivated to buy things. This problem is called over-specialization.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>New-user</strong></span>: If there <a id="id486" class="indexterm"/>is a new user who is exploring the e-commerce platform and we have a very limited amount of information about the user, then we cannot give them a good recommendation initially. This situation occurs due to the lack of a solid profile.</li></ul></div><p>All the preceding problems are well known for their content-based recommendation engine. In order to solve these problems, we can try out some other approach. The details <a id="id487" class="indexterm"/>related to this are given in the next section.</p></div><div class="section" title="Optimizing the baseline approach "><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec68"/>Optimizing the baseline approach </h2></div></div></div><p>Here, we will <a id="id488" class="indexterm"/>have an overview of how we can resolve the problems that we encountered in the previous section. In the baseline approach, we are basically dependent on the user profile and the item description, but this approach did not turn out well. In order to improve that we will be using two approaches. In the revised approach, we will be using the correction-based approach. After that, we will try the collaborative-filtering-based approach.</p><p>This correlation-based approach depends on the users' activities and is not dependent on the content or the description of the item. This helps us resolve the issues of new users, over-specialization, and limited content analysis. We are using a correlation coefficient to build the recommendation engine. This is a simple statistical technique that can be quite helpful. The basic concepts that are important for implementation will be described as and when we start building the revised approach.</p><p> So let's build the revised approach.</p></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Building the revised approach"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec46"/>Building the revised approach</h1></div></div></div><p>In this <a id="id489" class="indexterm"/>iteration, we will be building the recommendation engine using a statistical concept called correlation. We will be looking at how users' activities and choices are correlated to one another. We try to find out the pattern from the users' activities and behavior on the e-commerce platform.</p><p>Here, we will be using the Book-Crossing dataset. One of the critical parameters for building the recommendation system is the book rating attribute. I will explain the concepts along with the implementation part, so it will be easy for you to understand.</p><div class="section" title="Implementing the revised approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec69"/>Implementing the revised approach</h2></div></div></div><p> In order <a id="id490" class="indexterm"/>to implement the revised approach, we will need to perform the following steps. You can refer to the code on GitHub at: <a class="ulink" href="https://github.com/jalajthanaki/Book_recommendation_system/blob/master/correlation_based_recommendation_system.ipynb">https://github.com/jalajthanaki/Book_recommendation_system/blob/master/correlation_based_recommendation_system.ipynb</a>
</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Loading <a id="id491" class="indexterm"/>the dataset</li><li class="listitem"><span class="strong"><strong>Exploratory Data Analysis</strong></span> (<span class="strong"><strong>EDA</strong></span>) of book-rating datafile</li><li class="listitem">Exploring the book datafile</li><li class="listitem">EDA of user datafile</li><li class="listitem">Implementing the logic of correlation for the recommendation engine</li></ol></div><p>
</p><div class="section" title="Loading dataset"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec42"/>Loading dataset</h3></div></div></div><p>As a first <a id="id492" class="indexterm"/>step, we will use the <code class="literal">pandas </code>library to load our Book-Crossing dataset. As you already know, this dataset has three datafiles. We are loading all of them. You can refer to the following code snippet:</p><div class="mediaobject"><img src="Images/B08394_04_20.jpg" alt="Loading dataset" width="1000" height="183"/><div class="caption"><p>Figure 4.20: Code snippet for loading the data</p></div></div><p>Our data separator is a semicolon, and we are using latin-1 as encoding. We have defined three <code class="literal">pandas </code>dataframes.</p><p>Now let's jump to the next step, which is the EDA step for all three datafiles.</p></div><div class="section" title="EDA of the book-rating datafile"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec43"/>EDA of the book-rating datafile</h3></div></div></div><p>For this datafile, we have <a id="id493" class="indexterm"/>generated the ratings dataframe. We need to know what kind of data distribution this datafile has. That means we need to check how many books are getting a 10 out of 10 score, how many books are getting a 5 out of 10 score, and how many books do not have any rating at all. Refer to the following code snippet to generate this information for us:</p><div class="mediaobject"><img src="Images/B08394_04_21.jpg" alt="EDA of the book-rating datafile" width="597" height="735"/><div class="caption"><p>Figure 4.21: Code snippet for EDA of book-rating datafile </p></div></div><p>You can find the bar chart for this in the following figure:</p><div class="mediaobject"><img src="Images/B08394_04_22.jpg" alt="EDA of the book-rating datafile" width="599" height="444"/><div class="caption"><p>Figure 4.22: Bar chart for book-rating score distribution</p></div></div><p>As we <a id="id494" class="indexterm"/>can see, there are 7,16,109 books with a zero rating, whereas 1,03,736 books have a rating of eight. Based on this analysis, we can deduce that there are many books whose rating is zero, so the data distribution is biased here. We need to keep this point in mind.</p></div><div class="section" title="Exploring the book datafile"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec44"/>Exploring the book datafile</h3></div></div></div><p>In this <a id="id495" class="indexterm"/>section, we will perform the EDA of the book datafile. We also need to check the data attributes and format the data. No other trick needs to be applied for this datafile. Take a look at the code snippet shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_23.jpg" alt="Exploring the book datafile" width="1000" height="343"/><div class="caption"><p>Figure 4.23: Code snippet for exploring the book datafile</p></div></div><p>You can <a id="id496" class="indexterm"/>see that we have checked the shape and columns list for the book datafile. There is nothing that critical we need to consider in order to build the recommendation engine.</p></div><div class="section" title="EDA of the user datafile"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec45"/>EDA of the user datafile</h3></div></div></div><p>Here, we need <a id="id497" class="indexterm"/>to perform an analysis of the users' datafile. This datafile is important as we will be using it often to derive some important facts for this approach. First, we need to obtain the age distribution. The age distribution is one of the critical data points when we are building a recommendation system because users of a similar age group have similar reading patterns, and if we obtain this pattern, then we can generate more effective recommendations for our users. You can refer to the code snippet shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_24.jpg" alt="EDA of the user datafile" width="493" height="489"/><div class="caption"><p>Figure 4.24: Code snippet for generating the age distribution</p></div></div><p>You can <a id="id498" class="indexterm"/>refer to the box chart, which indicates the age distribution shown in the following figure:</p><div class="mediaobject"><img src="Images/B08394_04_25.jpg" alt="EDA of the user datafile" width="428" height="315"/><div class="caption"><p>Figure 4.25: Box graph for the age distribution</p></div></div><p>Based on the distribution, we can derive the fact that we have a majority of the users whose <a id="id499" class="indexterm"/>age falls between 20 and 40. So if we focus on their reading and browsing pattern, then our work will get easier.</p></div><div class="section" title="Implementing the logic of correlation for the recommendation engine"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec46"/>Implementing the logic of correlation for the recommendation engine</h3></div></div></div><p>In this section, we <a id="id500" class="indexterm"/>will cover the core logic of the recommendation engine. The logic can <a id="id501" class="indexterm"/>be divided into two parts: </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Recommendations based on the rating of the books</li><li class="listitem" style="list-style-type: disc">Recommendations based on correlations</li></ul></div><p>So let's start!</p><div class="section" title="Recommendations based on the rating of the books"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec41"/>Recommendations based on the rating of the books</h4></div></div></div><p>In order to <a id="id502" class="indexterm"/>build a book recommendation system that is based on the rating of the book, all the ratings are provided by the readers. So, for the implementation of this approach, we will be extracting the top five books with the highest ratings, which means we need to obtain a list of the books with the most ratings from the reader. The code snippet for that is shown in the following figure:</p><div class="mediaobject"><img src="Images/B08394_04_26.jpg" alt="Recommendations based on the rating of the books" width="750" height="264"/><div class="caption"><p>Figure 4.26: Code snippet for generating the top five books based on book rating</p></div></div><p>We have generated the ISBN of the top five books on the book rating count, but we also need to <a id="id503" class="indexterm"/>check what those books' names are and what the average rating for each of them is. You can find the name of the books by merging the book and book-rating data frame. You can see the code for this in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_27.jpg" alt="Recommendations based on the rating of the books" width="833" height="170"/><div class="caption"><p>Figure 4.27: Code snippet for generating the names of the top 5 books</p></div></div><p>Now, you may wonder what the benefit of this approach is. Let me tell you, we have a list of the books in descending order based on the book rating. If a user buys the book based on the rating of the book, then we can suggest other books that have the same rating. This way, users get suggestions that are more accurate than the previous approach.</p><p>If you look at the results of the top five books, then you will learn that the maximum rating is for Rich Shapero's book <code class="literal">Wild Animus</code>. All five books are novels. If someone wants to buy <code class="literal">Wild Animus</code>, then the user may also buy <code class="literal">The Lovely Bones: A Novel</code>. That is the <a id="id504" class="indexterm"/>reason this approach makes sense.</p><p>Now let's see the correlation-based recommendation engine.</p></div><div class="section" title="Recommendations based on correlations"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec42"/>Recommendations based on correlations</h4></div></div></div><p>We are <a id="id505" class="indexterm"/>using the bivariant correlation and the <span class="strong"><strong>Pearson correlation coefficient</strong></span> (<span class="strong"><strong>PCC</strong></span>). This is also referred to as <code class="literal">Person's r</code>. This correlation <a id="id506" class="indexterm"/>provides a measure of the linear correction between the two variables <code class="literal">a and b</code>. Here, we are considering the rating of two books and applying the PCC technique to them. The value of Person's <code class="literal">r </code>is in the range of <code class="literal">+1 </code>to<code class="literal"> –1</code>. The interpretation for this correlation value is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>+1</strong></span>: This value indicates the total positive linear correlation. This means that if there is an increment in the value of the variable 1, then variable 2 is incremented as well.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>0</strong></span>: This value indicates that there is no linear correlation. This means that the two variables are not related.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>-1</strong></span>: This value indicates that there is a total negative linear correlation. This means that if there is an increment in the value of variable 1, then variable 2 is decremented.</li></ul></div><p>The equation for the PCC is shown in the following equation:</p><div class="mediaobject"><img src="Images/B08394_04_28.jpg" alt="Recommendations based on correlations" width="625" height="140"/><div class="caption"><p>Figure 4.28: Equation for PCC or Person's r</p></div></div><p>Let's consider a simple math example so you know how we have calculated Person's r. Take a <a id="id507" class="indexterm"/>look at the following equation:</p><div class="mediaobject"><img src="Images/B08394_04_29.jpg" alt="Recommendations based on correlations" width="622" height="697"/><div class="caption"><p>Figure 4.29: Math example for Person's r</p></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note07"/>Note</h3><p>Note: we are considering the ratings of the two books in order to find the correlation between them.</p></div></div><p>First of all, we need to obtain the average rating for all books. The code snippet is given in the <a id="id508" class="indexterm"/>following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_30.jpg" alt="Recommendations based on correlations" width="892" height="280"/><div class="caption"><p>Figure 4.30: Code snippet for generating an average book rating</p></div></div><p>Note that the books that received the most rating counts are not the ones that are highly rated. This means there are some books for which readers share their feedback more often, but that doesn't mean those books are highly rated. Maybe some books were rated by 100 users but the score for the book is 4.3. This is the most important point that I need to highlight because this is where mistakes can happen. For making a better system, we need to consider the book-rating count and the book-rating score.</p><p>Here, we will be excluding users who have provided less than 200 ratings as well as books that have received less than 100 ratings. This means we are setting up a threshold so that we can make a better system. We can achieve this by using the code snippet given in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_31.jpg" alt="Recommendations based on correlations" width="753" height="128"/><div class="caption"><p>Figure 4.31: Code snippet for setting up threshold for considering users and books</p></div></div><p>Now we <a id="id509" class="indexterm"/>are converting the ratings dataframe into a 2D matrix. This matrix is a sparse matrix because not every user has provided a rating for every book. You can see the code in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_32.jpg" alt="Recommendations based on correlations" width="775" height="376"/><div class="caption"><p> Figure 4.32: Code snippet for generating a sparse matrix for rating</p></div></div><p>We have completed some basic work, now it's time to find out about books that correlate with the second most-rated book, <span class="emphasis"><em>The Lovely Bones: A Novel.</em></span> I want to quote the summary of this book, which is taken from Wikipedia: <a class="ulink" href="https://en.wikipedia.org/wiki/The_Lovely_Bones">https://en.wikipedia.org/wiki/The_Lovely_Bones</a> </p><div class="blockquote"><blockquote class="blockquote"><p>"It is the story of a teenage girl who, after being raped and murdered, watches from her personal Heaven as her family and friends struggle to move on with their lives while she comes to terms with her own death".</p></blockquote></div><p>Now we <a id="id510" class="indexterm"/>need to obtain a book that can be recommended to a user if they are trying to buy this book. The code that can help us get the recommendation is given in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_33.jpg" alt="Recommendations based on correlations" width="942" height="568"/><div class="caption"><p>Figure 4.33: Code snippet for generating a correlation-based recommendation</p></div></div><p>Here, you can see that we are using a sparse matrix and have applied the <code class="literal">corrwith </code>API to generate a correlation. There may be some runtime warnings. They are related to the float data type. Apart from that, we have coded the condition we need in order to recommend books that have received more than or equal to 300 user-rating counts. We have obtained the ISBN using the preceding code. So, we need to obtain the names of the books as well. For that, we need to use the code snippet given in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_34.jpg" alt="Recommendations based on correlations" width="1000" height="450"/><div class="caption"><p>Figure 4.34: Code snippet for generating the name of the book</p></div></div><p>Let's select <a id="id511" class="indexterm"/>the top three recommendations for the book, which are, <span class="emphasis"><em>The Nanny Diaries: A Novel</em></span>,<span class="emphasis"><em> The Pilot's Wife: A Novel</em></span>,<span class="emphasis"><em> and 1st to Die: A Novel</em></span>. The Nanny Diaries criticizes the upper-class society of Manhattan as seen through the eyes of their children's caregivers. The Pilot's Wife: A Novel is written by the same author who wrote The Lovely Bones. 1st to Die is the first book of a women's murder club series.</p><p>If you actually look at the content of these three books, then we can see that all these recommendations make sense.</p></div></div></div><div class="section" title="Testing the revised approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec70"/>Testing the revised approach</h2></div></div></div><p>We have <a id="id512" class="indexterm"/>already obtained the recommendation, and if we check the suggested books using this revised approach, then we see that this simple correlation-based approach works rather well. We performed manual testing and evaluated the quality of the recommendations and the suggestions were surprisingly more sensible and useful for the users.</p><p>In the next section, we will be discussing the problems with this approach and how we can improvise <a id="id513" class="indexterm"/>the approach further. Before implementing optimization, we need to discuss the points on which we will be focusing. So, let's list down all the problems or areas of improvements.</p></div><div class="section" title="Problems with the revised approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec71"/>Problems with the revised approach</h2></div></div></div><p>In this <a id="id514" class="indexterm"/>section, we need to list down the problems or areas of improvement so that we can improve the revised approach. Here are the points for areas of improvement:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The correlation-based approach is not generalized for all kinds of situations, so we need a more sophisticated approach. Basically, the correlation-based approach performs really well if the model has seen a similar kind of data example during training. For unseen data examples, it may not generate good results.</li><li class="listitem" style="list-style-type: disc">We can't always do manual testing, so we need a recommendation engine that is easy to develop, build, and test. The new approach can also adopt future changes, which means new approaches should be easy for us to change or modify as and when required.</li></ul></div><p>Now let's see how we can improve this revised approach.</p><div class="section" title="Understanding how to improve the revised approach"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec47"/>Understanding how to improve the revised approach</h3></div></div></div><p>In order <a id="id515" class="indexterm"/>to improve the revised approach, we will be using the well-known recommendation algorithm, collaborative filtering (CF). We will be using the Machine Learning (ML) algorithm K-nearest neighbors (KNN). This is a basic outline for how we can improve the revised approach.</p><p>With the help of the CF algorithm and the ML algorithm, it will be easy for us to test the algorithm as well as modify the algorithm based on our requirements. You may know how KNN works, so we are not going to dive into the KNN algorithm in detail, but we will definitely try to understand the intuition behind the KNN algorithm. We will also understand how the CF-based recommendation engine works in detail so that all your concepts <a id="id516" class="indexterm"/>are clear during the implementation. With the help of these algorithms, we will build the best possible book recommendation system. We will compare the results of our algorithm with Amazon.</p><p>In the next section, we will cover the algorithms first and then start implementing our approach.</p></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="The best approach"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec47"/>The best approach</h1></div></div></div><p>In this <a id="id517" class="indexterm"/>section, we are trying to build the best possible recommendation engine. There are two parts to this section: </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding the key concepts</li><li class="listitem" style="list-style-type: disc">Implementing the best approach</li></ul></div><p>Our first part covers the basic concepts, such as how the CF and KNN algorithms work, what kind of features we need to choose, and so on. In the second part, we will be implementing the recommendation engine using the KNN and CF algorithm. We will generate the accuracy score as well as the recommendation for books. So let's begin!</p><div class="section" title="Understanding the key concepts"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec72"/>Understanding the key concepts</h2></div></div></div><p>In this <a id="id518" class="indexterm"/>section, we will understand the concepts of collaborative filtering. This covers a lot of aspects of the recommendation system. So, let's explore CF.</p><div class="section" title="Collaborative filtering"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec48"/>Collaborative filtering</h3></div></div></div><p>There are <a id="id519" class="indexterm"/>two main types <a id="id520" class="indexterm"/>of collaborative filtering, as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Memory-based CF:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">User-user collaborative filtering</li><li class="listitem" style="list-style-type: disc">Item-item collaborative filtering</li></ul></div></li><li class="listitem" style="list-style-type: disc">Model-based CF:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Matrix-factorization-based algorithms</li><li class="listitem" style="list-style-type: disc">Deep learning</li></ul></div></li></ul></div><p>We will <a id="id521" class="indexterm"/>begin with memory-based CF <a id="id522" class="indexterm"/>and then move on to the model-based CF.</p><div class="section" title="Memory-based CF"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec43"/>Memory-based CF</h4></div></div></div><p>Memory-based CF is <a id="id523" class="indexterm"/>further divided into two sections. I have <a id="id524" class="indexterm"/>defined these sections earlier. Refer to the <span class="emphasis"><em>Introducing the problem statement</em></span> section. Here, we need to understand the concepts. We will begin with user-user CF and then look into item-item CF.</p><div class="section" title="User-user collaborative filtering"><div class="titlepage"><div><div><h5 class="title"><a id="ch04lvl5sec14"/>User-user collaborative filtering</h5></div></div></div><p>In user-user CF, we consider a particular user. Now we need to find users that are similar to <a id="id525" class="indexterm"/>our particular user. We find similar users by observing their buying pattern and rating pattern for the items. Based on the similarity in the ratings and buying patterns, we recommend products to similar types of users. In order to understand user-user CF, you can refer to the following figure:</p><div class="mediaobject"><img src="Images/B08394_04_35.jpg" alt="User-user collaborative filtering" width="673" height="529"/><div class="caption"><p>Figure 4.35: Pictorial representation of user-user CF</p></div></div><p>Item-item CF works differently, however.</p></div><div class="section" title="Item-item collaborative filtering"><div class="titlepage"><div><div><h5 class="title"><a id="ch04lvl5sec15"/>Item-item collaborative filtering</h5></div></div></div><p>In item-item CF, we consider items. We find users who like a particular item and other items that <a id="id526" class="indexterm"/>the user or similar users also liked and bought. So, we recommend the item along with the particular item the user is looking for. Here, we need to take items as the input and generate the list of items as a recommendation. You can refer to the following figure:</p><div class="mediaobject"><img src="Images/B08394_04_36.jpg" alt="Item-item collaborative filtering" width="699" height="610"/><div class="caption"><p>Figure 4.36: Image representing item-item CF</p></div></div><p>These two approaches can be summarized as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Item-item CF</strong></span>: We consider users who have liked x item as well as y</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>User-user CF</strong></span>: We consider users who, similar to you, also liked x and y items</li></ul></div><p>Memory-based <a id="id527" class="indexterm"/>models use similarity-based techniques. In this approach, there are no optimization techniques, such as a gradient descent, involved so it will be easy to implement. We can use the KNN ML algorithm as it doesn't use a gradient descent-based optimization strategy. So, during the implementation, we will be using the KNN algorithm.</p><p>The idea behind the KNN algorithm is simple. We need to obtain the weight for each user or item. We can generate this weight by a cosine similarity or a person's correlation coefficient. We use the similarity values, but we need to limit the number of similar users <a id="id528" class="indexterm"/>because we cannot consider all users to be similar. This number is denoted by K. Here, K indicates the number <a id="id529" class="indexterm"/>of similar neighbors or users we need to consider. This is the reason why the algorithm is called K-nearest neighbors (KNN). If you <a id="id530" class="indexterm"/>want more details on the KNN algorithm, then you can refer to this article:  <a class="ulink" href="https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/">https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/</a>
</p></div></div><div class="section" title="Model-based CF"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec44"/>Model-based CF</h4></div></div></div><p>In this <a id="id531" class="indexterm"/>approach, we will be using ML-based <a id="id532" class="indexterm"/>techniques to predict the recommendation for users, especially for those items that are unrated. For that, we can use the matrix factorization method or the Deep-Learning-based approach. We will focus on the matrix factorization method here.</p><p>So, let's look at matrix factorization.</p><div class="section" title="Matrix-factorization-based algorithms"><div class="titlepage"><div><div><h5 class="title"><a id="ch04lvl5sec16"/>Matrix-factorization-based algorithms</h5></div></div></div><p>The main <a id="id533" class="indexterm"/>idea behind the matrix-factorization-based algorithm is that preferences of the user can be determined by the matrix operation. We need to define the small number of hidden or latent factors. We can refer to this matrix as factors or embeddings. Let's take an example to understand it better.</p><p>We need to define the embedding matrix. Here, the values are randomly initialized and then we perform a dot product of this embedding matrix and the book embedding matrix. The resultant matrix is generated in such a way that we can predict which book can be recommended to which user. For matrix factorization, we need nonnegative elements in our resultant matrix. We will use singular value decomposition (SVD) models to identify latent factors. There are some other techniques that can be used as well, such as probabilistic matrix factorization, nonnegative matrix factorization, and so on. We will <a id="id534" class="indexterm"/>implement this matrix factorization technique.</p></div><div class="section" title="Difference between memory-based CF and model-based CF"><div class="titlepage"><div><div><h5 class="title"><a id="ch04lvl5sec17"/>Difference between memory-based CF and model-based CF</h5></div></div></div><p>The main <a id="id535" class="indexterm"/>difference between memory-based CF and model-based CF is that in the memory-based approach, there are no optimization techniques involved, whereas in the model-based approach, there is an optimization strategy and other optimization functions involved that improve accuracy of the model over a period of time. Now we will implement the CF-based approach.</p></div></div></div></div><div class="section" title="Implementing the best approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec73"/>Implementing the best approach</h2></div></div></div><p>We will <a id="id536" class="indexterm"/>be implementing this approach by using the following steps. You can refer to the code on GitHub at: <a class="ulink" href="https://github.com/jalajthanaki/Book_recommendation_system/blob/master/KNN_based_recommendation_system.ipynb">https://github.com/jalajthanaki/Book_recommendation_system/blob/master/KNN_based_recommendation_system.ipynb</a>.</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Loading the aset</li><li class="listitem">Merging the data frames</li><li class="listitem">EDA for the merged data frame</li><li class="listitem">Filtering data based on geolocation</li><li class="listitem">Applying the KNN algorithm</li><li class="listitem">Recommendation using the KNN algorithm</li><li class="listitem">Applying matrix factorization</li><li class="listitem">Recommendation using matrix factorization</li></ol></div><p>
</p><div class="section" title="Loading the dataset"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec49"/>Loading the dataset</h3></div></div></div><p>Just like we <a id="id537" class="indexterm"/>loaded the dataset <a id="id538" class="indexterm"/>in the revised approach, we need to implement it here as well. Take a look at the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_37.jpg" alt="Loading the dataset" width="1000" height="226"/><div class="caption"><p>Figure 4.37: Code snippet for loading the dataset</p></div></div></div><div class="section" title="Merging the data frames"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec50"/>Merging the data frames</h3></div></div></div><p>We need to <a id="id539" class="indexterm"/>merge the books <a id="id540" class="indexterm"/>and ratings data frames. We will be generating the total rating each book has received to date. The code snippet for this is as follows:</p><p> </p><div class="mediaobject"><img src="Images/B08394_04_38.jpg" alt="Merging the data frames" width="770" height="634"/><div class="caption"><p>Figure 4.38: Code snippet for generating the rating count</p></div></div><p>
</p><p>After that, we <a id="id541" class="indexterm"/>will be generating <a id="id542" class="indexterm"/>the book-rating score as well. Refer to the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_39.jpg" alt="Merging the data frames" width="651" height="294"/><div class="caption"><p>Figure 4.39: Code snippet for generating the book-rating score</p></div></div></div><div class="section" title="EDA for the merged data frames"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec51"/>EDA for the merged data frames</h3></div></div></div><p>Here, we <a id="id543" class="indexterm"/>will perform data analysis for the total rating count. After that, we need to obtain the quantile value <a id="id544" class="indexterm"/>for the rating of the book. That quantile value gives us a good idea about the data distribution. You can refer to the code snippet shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_40.jpg" alt="EDA for the merged data frames" width="807" height="700"/><div class="caption"><p>Figure 4.40: Code snippet for EDA on total-book-rating</p></div></div><p>As you <a id="id545" class="indexterm"/>can see, only 1% of <a id="id546" class="indexterm"/>the books received a user rating of 50 or more. There are many books in this dataset, but we will consider only 1% of these books. The total number of unique books is 2,713.</p></div><div class="section" title="Filtering data based on geolocation"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec52"/>Filtering data based on geolocation</h3></div></div></div><p>We will <a id="id547" class="indexterm"/>limit our <a id="id548" class="indexterm"/>user data to the USA and Canada regions. This filter speeds up the computation. We need to combine the user data and the total book-rating count data. For that, the code is shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_41.jpg" alt="Filtering data based on geolocation" width="1000" height="374"/><div class="caption"><p>Figure 4.41: Code snippet for geolocation-based filtering</p></div></div><p>As you <a id="id549" class="indexterm"/>can see, now we <a id="id550" class="indexterm"/>have users that are from the USA and Canada.</p></div><div class="section" title="Applying the KNN algorithm"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec53"/>Applying the KNN algorithm</h3></div></div></div><p>It's time <a id="id551" class="indexterm"/>to apply the main logic. We will <a id="id552" class="indexterm"/>be applying the KNN algorithm using the <code class="literal">sklearn </code>library. Our main goal is to determine the closeness of the data instances. You can take a look at the code snippet shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_42.jpg" alt="Applying the KNN algorithm" width="583" height="144"/><div class="caption"><p>Figure 4.42: Code snippet for implementing the KNN algorithm</p></div></div><p>We have used cosine similarity as the KNN matric parameter and we are considering the five <a id="id553" class="indexterm"/>nearest neighbors. This means that the <a id="id554" class="indexterm"/>value for K=5. After the model is trained, we need to obtain the recommendation using them.</p></div><div class="section" title="Recommendation using the KNN algorithm"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec54"/>Recommendation using the KNN algorithm</h3></div></div></div><p>Here, we need <a id="id555" class="indexterm"/>to obtain the recommendation using the KNN algorithm that has been trained <a id="id556" class="indexterm"/>just now. The code is shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_43.jpg" alt="Recommendation using the KNN algorithm" width="1000" height="278"/><div class="caption"><p>Figure 4.43: Code snippet for obtaining a recommendation using KNN</p></div></div><p>For recommendation purposes, we have chosen the value of K = 6, which means we are considering the six nearest neighbors to recommend the book to any user. Here, we have chosen the book randomly from the <code class="literal">us_canada_user_rating_pivot</code> data frame.</p><p>The suggestions look great. All of The Green Mile series books are recommended here.</p></div><div class="section" title="Applying matrix factorization"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec55"/>Applying matrix factorization</h3></div></div></div><p>Now let's <a id="id557" class="indexterm"/>implement the <a id="id558" class="indexterm"/>matrix factorization method. We will convert the USA and Canada user rating data frame into a 2D matrix. This matrix is also referred to as a utility matrix. We have replaced the missing value with 0. You can refer to the code given in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_44.jpg" alt="Applying matrix factorization" width="1000" height="277"/><div class="caption"><p>Figure 4.44: Code snippet for generating the utility matrix</p></div></div><p>Now we <a id="id559" class="indexterm"/>need to transpose the utility matrix. The <code class="literal">bookTitles </code>become rows and <code class="literal">userID </code>is converted <a id="id560" class="indexterm"/>into columns. After that, we will apply <code class="literal">TruncatedSVD </code>for dimensionality reduction. This operation is performed on columns—on <code class="literal">userID</code>—because we need to use the book's title afterward. You can refer to the code shown in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_45.jpg" alt="Applying matrix factorization" width="424" height="328"/><div class="caption"><p>Figure 4.45: Code snippet for SVD dimensionality reduction</p></div></div><p>Here, we have chosen the value of <code class="literal">n_components</code> as 12. So as you can see, the dimensionality of our data frame has reduced a lot. Earlier, the dimensions of the data frame <a id="id561" class="indexterm"/>were 40017 x 2442, which has now become 2442 x 12.</p><p>Now we <a id="id562" class="indexterm"/>perform Pearson's correlation coefficient for every book pair in our final matrix. We will compare the results with the KNN algorithm. Basically, we should get the suggestion we got previously using the KNN algorithm for this approach as well.</p></div><div class="section" title="Recommendation using matrix factorization"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec56"/>Recommendation using matrix factorization</h3></div></div></div><p>Here, we need <a id="id563" class="indexterm"/>to generate a recommendation using the matrix <a id="id564" class="indexterm"/>factorization technique. We will list down all the recommendations for The Green Mile: Night Journey (Green Mile Series). The algorithm should suggest highly correlated books. We have applied a threshold for the correlation. Only those books that have a correlation score of more than 0.9 to less than 1 are listed using this approach. You can refer to the code snippet given in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_46.jpg" alt="Recommendation using matrix factorization" width="743" height="543"/><div class="caption"><p>Figure 4.46: Code snippet for generating a recommendation using matrix factorization</p></div></div><p>As you <a id="id565" class="indexterm"/>can see, the <a id="id566" class="indexterm"/>recommendation for all the books that have been recommended using the KNN-based approach appear here as well. So, this CF-based recommendation system works in the best manner. You can find the same kind of recommendations on Amazon as well. Refer to the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_04_47.jpg" alt="Recommendation using matrix factorization" width="593" height="367"/><div class="caption"><p>Figure 4.47: Recommendation on Amazon</p></div></div><p>We <a id="id567" class="indexterm"/>can confirm <a id="id568" class="indexterm"/>that our recommendation engine works well.</p></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec48"/>Summary</h1></div></div></div><p>This is the last chapter of the analytics domain. So far, you have learned a lot of concepts that can help us build amazing analytics applications. In this chapter, you learned how to make a recommendation engine for an e-commerce product. In the baseline approach, we used the concept of TF-IDF and cosine similarity. In the revised approach, we built a book recommendation system that used the concept of correlation. In the best approach, we used the KNN algorithm to build a recommendation engine that used a collaborative-filtering-based approach. We looked at the advantages and disadvantages of all the approaches. You also learned about the architecture of the recommendation system. All these topics will help you understand and build your own recommendation system. You can also build a computer vision-based recommendation engine. This kind of recommendation engine really changes the way content is recommended to the users. So don't hesitate to build new types of recommendation systems.</p><p>From the next chapter onward, we will be addressing the applications that belong to the natural language processing domain or the natural language generation domain. The next chapter is all about sentiment analysis, which is a well-known and simple NLP application. We will be using a variety of Machine Learning algorithms to achieve the best possible result.</p></div></div>



  </body></html>