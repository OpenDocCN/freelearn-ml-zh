["```py\nusing DataType = double;\ntemplate <size_t Cols>\nusing Sample = std::array<DataType, Cols>;\ntemplate <size_t Cols>\nusing Dataset = std::vector<Sample<Cols>>;\n...\ntemplate <size_t Cols>\nstruct DatasetRange {\n  DatasetRange(std::vector<size_t>&& indices,\n               const Dataset<Cols>* dataset)\n    : indices(std::move(indices)), dataset(dataset) {}\n  size_t size() const { return indices.size(); }\n  DataType at(size_t row, size_t col) const {\n    return (*dataset)[indices[row]][col];\n  }\n  std::vector<size_t> indices;\n  const Dataset<Cols>* dataset;\n};\n```", "```py\nstruct Node {\n  Node() {}\n  Node(const Node&) = delete;\n  Node& operator=(const Node&) = delete;\n  Node(std::unique_ptr<Node> left,\n     std::unique_ptr<Node> right, size_t split_col,\n     DataType split_value)\n    : left(std::move(left)),\n      right(std::move(right)),\n      split_col(split_col),\n      split_value(split_value) {}\n  Node(size_t size) : size(size), is_external(true) {}\n  std::unique_ptr<Node> left;\n  std::unique_ptr<Node> right;\n  size_t split_col{0};\n  DataType split_value{0};\n  size_t size{0};\n  bool is_external{false};\n};\n```", "```py\ntemplate <size_t Cols>\nclass IsolationTree {\n public:\n  using Data = DatasetRange<Cols>;\n  IsolationTree(const IsolationTree&) = delete;\n  IsolationTree& operator=(const IsolationTree&) = delete;\n  IsolationTree(std::mt19937* rand_engine, Data data, size_t hlim)\n      : rand_engine(rand_engine) {\n    root = MakeIsolationTree(data, 0, hlim);\n  }\n  IsolationTree(IsolationTree&& tree) {\n    rand_engine = std::move(tree.rand_engine);\n    root = td::move(tree.root);\n  }\n  double PathLength(const Sample<Cols>& sample) {\n    return PathLength(sample, root.get(), 0);\n  }\n private:\n  std::unique_ptr<Node> MakeIsolationTree(const Data& data,\n                                          size_t height,\n                                          size_t hlim);\n  double PathLength(const Sample<Cols>& sample,\n                    const Node* node, double height);\n private:\n  std::mt19937* rand_engine;\n  std::unique_ptr<Node> root;\n};\n```", "```py\nstd::unique_ptr<Node> MakeIsolationTree(const Data& data,\n                                        size_t height, size_t hlim) {\n  auto len = data.size();\n  if (height >= hlim || len <= 1) {\n    return std::make_unique<Node>(len);\n  } else {\n    std::uniform_int_distribution<size_t> cols_dist(0, Cols - 1);\n    auto rand_col = cols_dist(*rand_engine);\n    std::unordered_set<DataType> values;\n    for (size_t i = 0; i < len; ++i) {\n      auto value = data.at(i, rand_col);\n      values.insert(value);\n    }\n    auto min_max = std::minmax_element(values.begin(), values.end());\n    std::uniform_real_distribution<DataType> value_dist(\n      *min_max.first, *min_max.second);\n    auto split_value = value_dist(*rand_engine);\n    std::vector<size_t> indices_left;\n    std::vector<size_t> indices_right;\n    for (size_t i = 0; i < len; ++i) {\n      auto value = data.at(i, rand_col);\n      if (value < split_value) {\n        indices_left.push_back(data.indices[i]);\n      } else {\n        indices_right.push_back(data.indices[i]);\n      }\n    }\n    return std::make_unique<Node>(\n      MakeIsolationTree(\n        Data{std::move(indices_left), data.dataset},\n        height + 1, hlim),\n      MakeIsolationTree(\n        Data{std::move(indices_right), data.dataset},\n        height + 1, hlim),\n      rand_col, split_value);\n  }\n}\n```", "```py\ndouble PathLength(const Sample<Cols>& sample, const Node* node,\n                  double height) {\n  assert(node != nullptr);\n  if (node->is_external) {\n    return height + CalcC(node->size);\n  } else {\n    auto col = node->split_col;\n    if (sample[col] < node->split_value) {\n      return PathLength(sample, node->left.get(), height + 1);\n    } else {\n      return PathLength(sample, node->right.get(), height + 1);\n    }\n  }\n}\n```", "```py\ndouble CalcC(size_t n) {\n  double c = 0;\n  if (n > 1)\n  c = 2 * (log(n - 1) + 0.5772156649) - (\n    2 * (n - 1) / n);\n  return c;\n}\n```", "```py\ntemplate <size_t Cols>\nclass IsolationForest {\n public:\n  using Data = DatasetRange<Cols>;\n  IsolationForest(const IsolationForest&) = delete;\n  IsolationForest& operator=(const IsolationForest&) = delete;\n  IsolationForest(const Dataset<Cols>& dataset,\n                  size_t num_trees, size_t sample_size)\n      : rand_engine(2325) {\n    std::vector<size_t> indices(dataset.size());\n    std::iota(indices.begin(), indices.end(), 0);\n    size_t hlim = static_cast<size_t>(ceil(log2(sample_size)));\n    for (size_t i = 0; i < num_trees; ++i) {\n      std::vector<size_t> sample_indices;\n      std::sample(indices.begin(), indices.end(),\n                  std::back_insert_iterator(sample_indices),\n                  sample_size, rand_engine);\n      trees.emplace_back(\n          &rand_engine,\n          Data(std::move(sample_indices), &dataset), hlim);\n    }\n    double n = dataset.size();\n    c = CalcC(n);\n  }\n  double AnomalyScore(const Sample<Cols>& sample) {\n    double avg_path_length = 0;\n    for (auto& tree : trees) {\n      avg_path_length += tree.PathLength(sample);\n    }\n    avg_path_length /= trees.size();\n    double anomaly_score = pow(2, -avg_path_length / c);\n    return anomaly_score;\n  }\n private:\n  std::mt19937 rand_engine;\n  std::vector<IsolationTree<Cols>> trees;\n  double c{0};\n};\n}\n```", "```py\nvoid IsolationForest(const Matrix& normal, const Matrix& test) {\n  iforest::Dataset<2> dataset;\n  auto put_to_dataset = [&](const Matrix& samples) {\n    for (long r = 0; r < samples.nr(); ++r) {\n      auto row = dlib::rowm(samples, r);\n      double x = row(0, 0);\n      double y = row(0, 1);\n      dataset.push_back({x, y});\n    }\n  };\n  put_to_dataset(normal);\n  put_to_dataset(test);\n  iforest::IsolationForest iforest(dataset, 300, 50);\n  double threshold = 0.6;  // change this value to see isolation \n                          //boundary\n  for (auto& s : dataset) {\n    auto anomaly_score = iforest.AnomalyScore(s);\n    // std::cout << anomaly_score << \" \" << s[0] << \" \" << s[1]\n    // << std::endl;\n    if (anomaly_score < threshold) {\n      // Do something with normal\n    } else {\n      // Do something with anomalies\n    }\n  }\n}\n```", "```py\nvoid OneClassSvm(const Matrix& normal, const Matrix& test) {\n  typedef matrix<double, 0, 1> sample_type;\n  typedef radial_basis_kernel<sample_type> kernel_type;\n  svm_one_class_trainer<kernel_type> trainer;\n  trainer.set_nu(0.5);  // control smoothness of the solution\n  trainer.set_kernel(kernel_type(0.5));  // kernel bandwidth\n  std::vector<sample_type> samples;\n  for (long r = 0; r < normal.nr(); ++r) {\n    auto row = rowm(normal, r);\n    samples.push_back(row);\n  }\n  decision_function<kernel_type> df = trainer.train(samples);\n  Clusters clusters;\n  double dist_threshold = -2.0;\n  auto detect = [&](auto samples) {\n    for (long r = 0; r < samples.nr(); ++r) {\n      auto row = dlib::rowm(samples, r);\n      auto dist = df(row);\n      if (p > dist_threshold) {\n        // Do something with anomalies\n      } else {\n        // Do something with normal\n      }\n    }\n  };\n  detect(normal);\n  detect(test);\n}\n```", "```py\nvoid multivariateGaussianDist(const Matrix& normal,\n                              const Matrix& test) {\n  // assume that rows are samples and columns are features\n  // calculate per feature mean\n  dlib::matrix<double> mu(1, normal.nc());\n  dlib::set_all_elements(mu, 0);\n  for (long c = 0; c < normal.nc(); ++c) {\n    auto col_mean = dlib::mean(dlib::colm(normal, c));\n    dlib::set_colm(mu, c) = col_mean;\n  }\n  // calculate covariance matrix\n  dlib::matrix<double> cov(normal.nc(), normal.nc());\n  dlib::set_all_elements(cov, 0);\n  for (long r = 0; r < normal.nr(); ++r) {\n    auto row = dlib::rowm(normal, r);\n    cov += dlib::trans(row - mu) * (row - mu);\n  }\n  cov *= 1.0 / normal.nr();\n  double cov_det = dlib::det(cov);  // matrix determinant\n  dlib::matrix<double> cov_inv = dlib::inv(cov);  // inverse matrix\n  //  define probability function\n  auto first_part = 1\\. / std::pow(2\\. * M_PI, normal.nc() / 2.) /\n                    std::sqrt(cov_det);\n  auto prob = [&](const dlib::matrix<double>& sample) {\n    dlib::matrix<double> s = sample - mu;\n    dlib::matrix<double> exp_val_m =\n        s * (cov_inv * dlib::trans(s));\n    double exp_val = -0.5 * exp_val_m(0, 0);\n    double p = first_part * std::exp(exp_val);\n    return p;\n  };\n  // change this parameter to see the decision boundary\n  double prob_threshold = 0.001;\n  auto detect = [&](auto samples) {\n    for (long r = 0; r < samples.nr(); ++r) {\n      auto row = dlib::rowm(samples, r);\n      auto p = prob(row);\n      if (p >= prob_threshold) {\n        // Do something with anomalies\n      } else {\n        // Do something with normal\n      }\n    }\n  };\n  detect(normal);\n  detect(test);\n}\n```", "```py\nGMM gmm(/*gaussians*/ 1, /*dimensionality*/ 2);\n```", "```py\nKMeans<> kmeans;\nsize_t max_iterations = 250;\ndouble tolerance = 1e-10;\nEMFit<KMeans<>, NoConstraint> em(max_iterations,\n                                 tolerance,\n                                 kmeans);\ngmm.Train(normal,\n          /*trials*/ 3,\n          /*use_existing_model*/ false,\n          em);\n```", "```py\ndouble prob_threshold = 0.001;\n```", "```py\nauto detect = [&](const arma::mat& samples) {\n  for (size_t c = 0; c < samples.n_cols; ++c) {\n    auto sample = samples.col(c);\n    double x = sample.at(0, 0);\n    double y = sample.at(1, 0);\n    auto p = gmm.Probability(sample);\n    if (p >= prob_threshold) {\n      plot_clusters[0].first.push_back(x);\n      plot_clusters[0].second.push_back(y);\n    } else {\n      plot_clusters[1].first.push_back(x);\n      plot_clusters[1].second.push_back(y);\n    }\n  }\n};\n```", "```py\narma::mat normal;\narma::mat test;\nClusters plot_clusters;\ndetect(normal);\ndetect(test);\nPlotClusters(plot_clusters, \"Density Estimation Tree\", file_name);\n```", "```py\nusing namespace mlpack;\n...\nKDE<GaussianKernel,\n    EuclideanDistance,\n    arma::mat,\n    KDTree>\n  kde(/*rel error*/ 0.0, /*abs error*/ 0.01, GaussianKernel());\n```", "```py\narma::mat normal;\n...\nkde.Train(normal);\n```", "```py\ndouble density_threshold = 0.1;\nClusters plot_clusters;\nauto detect = [&](const arma::mat& samples) {\n  arma::vec estimations;\n  kde.Evaluate(samples, estimations);\n  for (size_t c = 0; c < samples.n_cols; ++c) {\n    auto sample = samples.col(c);\n    double x = sample.at(0, 0);\n    double y = sample.at(1, 0);\n    auto p = estimations.at(c);\n    if (p >= density_threshold) {\n      plot_clusters[0].first.push_back(x);\n      plot_clusters[0].second.push_back(y);\n    } else {\n      plot_clusters[1].first.push_back(x);\n      plot_clusters[1].second.push_back(y);\n    }\n  }\n};\n```", "```py\narma::mat normal;\narma::mat test;\ndetect(normal);\ndetect(test);\nPlotClusters(plot_clusters, \"Density Estimation Tree\", file_name);\n```", "```py\narma::mat data_copy = normal;\nDTree<> det(data_copy);\n```", "```py\narma::Col<size_t> data_indices(data_copy.n_cols);\nfor (size_t i = 0; i < data_copy.n_cols; i++) {\n  data_indices[i] = i;\n}\n```", "```py\nsize_t max_leaf_size = 5;\nsize_t min_leaf_size = 1;\ndet.Grow(data_copy, data_indices, false, max_leaf_size, \n  min_leaf_size);\n```", "```py\ndouble density_threshold = 0.01;\nClusters plot_clusters;\nauto detect = [&](const arma::mat& samples) {\n  for (size_t c = 0; c < samples.n_cols; ++c) {\n    auto sample = samples.col(c);\n    double x = sample.at(0, 0);\n    double y = sample.at(1, 0);\n    auto p = det.ComputeValue(sample);\n    if (p >= density_threshold) {\n      plot_clusters[0].first.push_back(x);\n      plot_clusters[0].second.push_back(y);\n    } else {\n      plot_clusters[1].first.push_back(x);\n      plot_clusters[1].second.push_back(y);\n    }\n  }\n};\n```", "```py\ndetect(normal);\ndetect(test);\nPlotClusters(plot_clusters, \"Density Estimation Tree\", file_name);\n```"]