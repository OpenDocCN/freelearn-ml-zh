<html><head></head><body>
		<div id="_idContainer760">
			<h1 class="chapter-number" id="_idParaDest-189"><a id="_idTextAnchor496"/>9</h1>
			<h1 id="_idParaDest-190"><a id="_idTextAnchor497"/>Ensemble Learning</h1>
			<p>Anyone who works with data analysis and machine learning will understand that no method is ideal or universal. This is why there are so many methods. Researchers and enthusiasts have been searching for years for a compromise between the accuracy, simplicity, and interpretability of various models. Moreover, how can we increase the accuracy of the model, preferably without changing its essence? One way to improve the accuracy of models is to create <a id="_idIndexMarker1032"/>and train model <strong class="bold">ensembles</strong>—that is, sets of models used to solve the same problem. The ensemble training methodology is the training of a final set of simple classifiers, with a subsequent merging of the results of their predictions into a single forecast of the <span class="No-Break">aggregated algorithm.</span></p>
			<p>This chapter describes what ensemble learning is, what types of ensembles exist, and how they can help to obtain better predictive performance. In this chapter, we will also implement examples of these approaches with different <span class="No-Break">C++ libraries.</span></p>
			<p>The following topics will be covered in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>An overview of <span class="No-Break">ensemble learning</span></li>
				<li>Learning about decision trees and <span class="No-Break">random forests</span></li>
				<li>Examples of using C++ libraries for <span class="No-Break">creating ensemble<a id="_idTextAnchor498"/>s</span><a id="_idTextAnchor499"/></li>
			</ul>
			<h1 id="_idParaDest-191"><a id="_idTextAnchor500"/>Technical requirements</h1>
			<p>The technologies and installations required in the chapter are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>The <span class="No-Break"><strong class="source-inline">Dlib</strong></span><span class="No-Break"> library</span></li>
				<li>The <span class="No-Break"><strong class="source-inline">mlpack</strong></span><span class="No-Break"> library</span></li>
				<li>A modern C++ compiler with <span class="No-Break">C++20 support</span></li>
				<li>A CMake build system version &gt;= <span class="No-Break">3.22</span></li>
			</ul>
			<p>The code files for this chapter can be found at the following GitHub <span class="No-Break">repo: </span><a href="https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition/tree/main/Chapter09"><span class="No-Break">https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition/tree/main/Chapter0<span id="_idTextAnchor501"/>9</span></a><span class="P---URL"><a id="_idTextAnchor502"/></span></p>
			<h1 id="_idParaDest-192"><a id="_idTextAnchor503"/>An overview of ensemble learning</h1>
			<p>The training of an ensemble of models is understood to be the procedure of training a final set of elementary<a id="_idIndexMarker1033"/> algorithms whose results are then combined to form the forecast of an aggregated classifier. The model ensemble’s purpose is to improve the accuracy of the prediction of the aggregated classifier, particularly when compared with the accuracy of every single elementary classifier. It is intuitively clear that combining simple classifiers can give a more accurate result than each simple classifier separately. Despite that, simple classifiers can be sufficiently accurate on particular datasets, but at the same time, they can make mistakes on <span class="No-Break">different datasets.</span></p>
			<p>An example of ensembles is <strong class="bold">Condorcet’s jury theorem</strong> (1784). A jury must come to a correct or incorrect consensus, and each juror has an independent opinion. If the probability of the correct <a id="_idIndexMarker1034"/>decision of each juror is more than 0.5, then the probability of a correct decision from the jury as a whole (tending toward 1) increases with the size of the jury. If the probability of making the correct decision is less than 0.5 for each juror, then the probability of making the right decision monotonically decreases (tending toward zero) as the jury <span class="No-Break">size increases.</span></p>
			<p>The theorem is <span class="No-Break">as follows:</span></p>
			<ul>
				<li><em class="italic">N</em>: The number of <span class="No-Break">jury members</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_001.png"/>: The probability of the jury member making the <span class="No-Break">right decision</span></li>
				<li><em class="italic">μ</em>: The probability of the entire jury making the <span class="No-Break">correct decision</span></li>
				<li><em class="italic">m</em>: The minimum majority of <span class="No-Break">jury members:</span></li>
			</ul>
			<div>
				<div class="IMG---Figure" id="_idContainer655">
					<img alt="" role="presentation" src="image/B22503_Formula_002.jpg"/>
				</div>
			</div>
			<ul>
				<li><img alt="" role="presentation" src="image/B22503_Formula_003.png"/>: The number of combinations of <em class="italic">N</em> <span class="No-Break">by </span><span class="No-Break"><em class="italic">i</em></span><span class="No-Break">:</span></li>
			</ul>
			<div>
				<div class="IMG---Figure" id="_idContainer657">
					<img alt="" role="presentation" src="image/B22503_Formula_004.jpg"/>
				</div>
			</div>
			<p class="list-inset">If <img alt="" role="presentation" src="image/B22503_Formula_005.png"/> <span class="No-Break">then <img alt="" role="presentation" src="image/B22503_Formula_006.png"/></span></p>
			<p class="list-inset">If <img alt="" role="presentation" src="image/B22503_Formula_007.png"/> <span class="No-Break">then <img alt="" role="presentation" src="image/B22503_Formula_008.png"/></span></p>
			<p>Therefore, based on general reasoning, three reasons why ensembles of classifiers can be successful can be distinguished, <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Statistical</strong>: The classification algorithm can be viewed as a search procedure in the space of the <strong class="bold">H hypothesis</strong>, concerned <a id="_idIndexMarker1035"/>with the distribution of data in order to find the best hypothesis. By learning from the final dataset, the algorithm can find <a id="_idIndexMarker1036"/>many different hypotheses that describe the training sample equally well. By building an ensemble of models, we <em class="italic">average out</em> the error of each hypothesis and reduce<a id="_idIndexMarker1037"/> the influence of instabilities and randomness in the formation of a <span class="No-Break">new hypothesis.</span></li>
				<li><strong class="bold">Computational</strong>: Most learning<a id="_idIndexMarker1038"/> algorithms use methods for finding the extremum of a specific objective function. For example, neural <a id="_idIndexMarker1039"/>networks use <strong class="bold">gradient descent</strong> (<strong class="bold">GD</strong>) methods to minimize prediction errors. Decision trees use greedy algorithms that minimize data entropy. These optimization algorithms can become stuck at a local extremum point, which is a problem because their goal is to find a global optimum. The ensembles of models combining the results of the prediction of simple classifiers, trained on different subsets of the source data, have a higher chance of finding a global optimum since they start a search for the optimum from different points in the initial set <span class="No-Break">of hypotheses.</span></li>
				<li><strong class="bold">Representative</strong>: A combined <a id="_idIndexMarker1040"/>hypothesis may not be in the set of possible hypotheses for simple classifiers. Therefore, by building a combined hypothesis, we expand the set of <span class="No-Break">possible hypotheses.</span></li>
			</ul>
			<p>Condorcet’s jury theorem and the reasons provided previously are not entirely suitable for real, practical situations because the algorithms are not independent (they solve one problem, they learn on one target vector, and can only use one model, or a small number <span class="No-Break">of models).</span></p>
			<p>Therefore, the majority of techniques in applied ensemble development are aimed at ensuring that the ensemble is diverse. This allows the errors of individual algorithms in individual objects to be compensated for by the correct operations of other algorithms. Overall, building the ensemble results in an improvement in both the quality and variety of simple algorithms. The goal is to create a diverse set of predictions that complement each other and reduce the overall variance and bias of the <span class="No-Break">ensemble’s predictions.</span></p>
			<p>The simplest type of ensemble is model averaging, whereby each member of the ensemble makes an equal contribution to the final forecast. The fact that each model has an equal contribution to the final ensemble’s forecast is a limitation of this approach. The problem is in <a id="_idIndexMarker1041"/>unbalanced contributions. Despite that, there is a requirement that all members of the ensemble have prediction skills higher than <span class="No-Break">random chance.</span></p>
			<p>However, it is known that some models work much better or much worse than other models. Some improvements can be made to solve this problem, using a weighted ensemble in which the contribution of each member to the final forecast is weighted by the performance of the model. When the weight of the model is a small positive value and the sum of all weights equals 1, the weights can indicate the percentage of confidence in (or expected performance from) <span class="No-Break">each model.</span></p>
			<p>At this time, the most common approaches to ensemble construction are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Bagging</strong>: This is an ensemble of <a id="_idIndexMarker1042"/>models studying in parallel on different random samples from the same training set. The final result is <a id="_idIndexMarker1043"/>determined by the voting of the algorithms of the ensemble. For example, in classification, the class that is predicted by the most classifiers <span class="No-Break">is chosen.</span></li>
				<li><strong class="bold">Boosting</strong>: This is an <a id="_idIndexMarker1044"/>ensemble of models trained sequentially, with each successive algorithm being trained on samples in which the previous<a id="_idIndexMarker1045"/> algorithm made <span class="No-Break">a mistake.</span></li>
				<li><strong class="bold">Stacking</strong>: This is an approach whereby a training set is divided into <em class="italic">N</em> blocks, and a set of simple <a id="_idIndexMarker1046"/>models is trained on <em class="italic">N-1</em> of them. An <em class="italic">N-th</em> model is then trained on the remaining block, but the outputs of the underlying <a id="_idIndexMarker1047"/>algorithms (forming the so-called <strong class="bold">meta-attribute</strong>) are used <a id="_idIndexMarker1048"/>as the <span class="No-Break">target variable.</span></li>
				<li><strong class="bold">Random forest</strong>: This is a set <a id="_idIndexMarker1049"/>of decision trees built independently, and whose answers are averaged and decided by a<a id="_idIndexMarker1050"/> <span class="No-Break">majority vote.</span></li>
			</ul>
			<p>The following sections discuss the previously described approaches<a id="_idTextAnchor504"/> <a id="_idTextAnchor505"/><span class="No-Break">in detail.</span></p>
			<h2 id="_idParaDest-193"><a id="_idTextAnchor506"/>Using a bagging approach for creating ensembles</h2>
			<p>Bagging (from the bootstrap aggregation) is one of the earliest and most straightforward types of ensembles. Bagging is <a id="_idIndexMarker1051"/>based on the statistical bootstrap method, which aims to obtain the most accurate sample estimates and to <a id="_idIndexMarker1052"/>extend the results to the entire population. The bootstrap method is <span class="No-Break">as follows.</span></p>
			<p>Suppose there is an <em class="italic">X</em> dataset of size <em class="italic">M</em>. Evenly select from the dataset <em class="italic">N</em> objects and return each object back to the dataset after selection. Before selecting the next one, we can generate <em class="italic">N</em> sub-datasets. This procedure means that <em class="italic">N</em> times, we select an arbitrary sample object (we assume that each object is <em class="italic">picked up</em> with the same probability <img alt="" role="presentation" src="image/B22503_Formula_009.png"/>), and each time, we choose from all the original <em class="italic">M</em> objects. Also, this procedure is called sampling with replacement, and it means that each element in the dataset has an equal chance of being selected <span class="No-Break">multiple times.</span></p>
			<p>We can imagine this as a bag from which balls are taken. The ball selected at a given step is returned to the bag following its selection, and the next choice is again made with equal probability from the same number of balls. Note that due to the ball being returned each time, there <span class="No-Break">are repetitions.</span></p>
			<p>Each new selection is denoted as <em class="italic">X</em><span class="subscript">1</span>. Repeating the procedure <em class="italic">k</em> times, we generate <em class="italic">k</em> sub-datasets. Now, we have a reasonably large number of samples, and we can evaluate various statistics of the <span class="No-Break">original distribution.</span></p>
			<p>The main descriptive statistics are the sample mean, median, and standard deviation. Summary statistics—for example, the sample mean, median, and correlation—can vary from sample to sample. The bootstrap idea is to use sampling results as a fictitious population to determine the sample distribution of statistics. The bootstrap method analyzes a large number of <a id="_idIndexMarker1053"/>phantom samples, called <strong class="bold">bootstrap samples</strong>. For each sample, an estimate of the target statistics is calculated, then the estimates are averaged. The bootstrap<a id="_idIndexMarker1054"/> method can be viewed as a modification of the <strong class="bold">Monte </strong><span class="No-Break"><strong class="bold">Carlo method</strong></span><span class="No-Break">.</span></p>
			<p>Suppose there is the <em class="italic">X</em> training dataset. With the help of the bootstrap method, we can generate <img alt="" role="presentation" src="image/B22503_Formula_010.png"/> sub-datasets. Now, on each sub-dataset, we can train our <img alt="" role="presentation" src="image/B22503_Formula_011.png"/> classifier. The final classifier averages <a id="_idIndexMarker1055"/>these classifier responses (in the case of classification, this corresponds to a vote), as follows: <img alt="" role="presentation" src="image/B22503_Formula_012.png"/>. The following diagram shows <span class="No-Break">this scheme:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer666">
					<img alt="Figure 9.1 – Bagging approach scheme" src="image/B19849_09_1.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – Bagging approach scheme</p>
			<p>Consider the regression problem by using simple algorithms <img alt="" role="presentation" src="image/B22503_Formula_013.png"/>. Suppose that there is a true <a id="_idIndexMarker1056"/>answer function for all <em class="italic">y(x)</em> objects, and there is also a distribution on <img alt="" role="presentation" src="image/B22503_Formula_014.png"/> objects. In this case, we can write the error of each regression function <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer669">
					<img alt="" role="presentation" src="image/B22503_Formula_015.jpg"/>
				</div>
			</div>
			<p>We can also write the<a id="_idIndexMarker1057"/> expectation of the <strong class="bold">mean squared error</strong> (<strong class="bold">MSE</strong>) <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer670">
					<img alt="" role="presentation" src="image/B22503_Formula_016.jpg"/>
				</div>
			</div>
			<p>The average error of the constructed regression functions is <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer671">
					<img alt="" role="presentation" src="image/B22503_Formula_017.jpg"/>
				</div>
			</div>
			<p>Now, suppose the errors are unbiased and uncorrelated, as <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer672">
					<img alt="" role="presentation" src="image/B22503_Formula_018.jpg"/>
				</div>
			</div>
			<p>Now we can write a<a id="_idIndexMarker1058"/> new regression function that averages the responses of the functions we have constructed, <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer673">
					<img alt="" role="presentation" src="image/B22503_Formula_019.jpg"/>
				</div>
			</div>
			<p>Let’s find its <strong class="bold">root MSE</strong> (<strong class="bold">RMSE</strong>) to see the <a id="_idIndexMarker1059"/>effect of averaging, <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer674">
					<img alt="" role="presentation" src="image/B22503_Formula_020.jpg"/>
				</div>
			</div>
			<p>Thus, averaging the<a id="_idIndexMarker1060"/> answers has allowed us to reduce the average square of the error by <span class="No-Break"><em class="italic">n</em></span><span class="No-Break"> times.</span></p>
			<p>Bagging also allows us to reduce the variance of the trained algorithm and prevent overfitting. The effectiveness of bagging is based on the underlying algorithms, which are trained on various sub-datasets that are quite different, and their errors are mutually compensated during voting. Also, outlying objects may not fall into some of the training sub-datasets, which also increases the effectiveness of the <span class="No-Break">bagging approach.</span></p>
			<p>Bagging is useful with small datasets when the exclusion of even a small number of training objects leads to the construction of substantially different simple algorithms. In the case of large datasets, sub-datasets that are significantly smaller than the original ones are <span class="No-Break">usually generated.</span></p>
			<p>Notice that the assumption about uncorrelated errors is rarely satisfied. If this assumption is incorrect, then the error reduction is not as significant as we might <span class="No-Break">have assumed.</span></p>
			<p>In practice, bagging provides a <a id="_idIndexMarker1061"/>good improvement to the accuracy of results when compared to simple individual algorithms, particularly if a simple algorithm is sufficiently accurate but unstable. Improving the accuracy of the forecast occurs by reducing the spread of the error-prone forecasts of individual algorithms. The advantage of the bagging algorithm is its ease of implementation, as well as the possibility of paralleling the calculations for training each elementary algorithm on different <span class="No-Break">computation<a id="_idTextAnchor507"/>a<a id="_idTextAnchor508"/>l nodes.</span></p>
			<h2 id="_idParaDest-194"><a id="_idTextAnchor509"/>Using a gradient boosting method for creating ensembles</h2>
			<p>The main idea of <a id="_idIndexMarker1062"/>boosting is that the elementary algorithms are not built independently. We build every sequential algorithm so that it corrects the mistakes of the <a id="_idIndexMarker1063"/>previous ones and therefore improves the quality of the whole ensemble. The first successful version of boosting was <strong class="bold">Adaptive Boosting</strong> (<strong class="bold">AdaBoost</strong>). It is now rarely used since <a id="_idIndexMarker1064"/>gradient boosting has <span class="No-Break">supplanted it.</span></p>
			<p>Suppose that we have a set of pairs, where each pair consists of attribute <em class="italic">x</em> and target <span class="No-Break">variable </span><span class="No-Break"><em class="italic">y</em></span><span class="No-Break">,</span>
 <img alt="" role="presentation" src="image/B22503_Formula_021.png"/>. On this set, we restore the dependence of the form <img alt="" role="presentation" src="image/B22503_Formula_022.png"/>. We restore it by the approximation <img alt="" role="presentation" src="image/B22503_Formula_023.png"/>. To select the best approximation solution, we use a specific loss function of the form <img alt="" role="presentation" src="image/B22503_Formula_024.png"/>, which we should optimize <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer679">
					<img alt="" role="presentation" src="image/B22503_Formula_025.jpg"/>
				</div>
			</div>
			<p>We also can rewrite the expression in terms of mathematical expectations, since the amount of data available for learning is limited, <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer680">
					<img alt="" role="presentation" src="image/B22503_Formula_026.jpg"/>
				</div>
			</div>
			<p>Our approximation is inaccurate. However, the idea behind boosting is that such an approximation can be improved by adding to the model with the result of another model that corrects its errors, as <span class="No-Break">illustrated here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer681">
					<img alt="" role="presentation" src="image/B22503_Formula_027.jpg"/>
				</div>
			</div>
			<p>The following equation shows the ideal error <span class="No-Break">correction model:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer682">
					<img alt="" role="presentation" src="image/B22503_Formula_028.jpg"/>
				</div>
			</div>
			<p>We can rewrite this formula in the following form, which is more suitable for the <span class="No-Break">corrective model:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer683">
					<img alt="" role="presentation" src="image/B22503_Formula_029.jpg"/>
				</div>
			</div>
			<p>Based on the preceding <a id="_idIndexMarker1065"/>assumptions listed, the goal of boosting is to approximate <img alt="" role="presentation" src="image/B22503_Formula_030.png"/> to make its results correspond as closely as possible to the <em class="italic">residuals</em> <img alt="" role="presentation" src="image/B22503_Formula_031.png"/>. Such an operation is performed sequentially—that is, <img alt="" role="presentation" src="image/B22503_Formula_032.png"/> improves the results of the previous <img alt="" role="presentation" src="image/B22503_Formula_033.png"/> <span class="No-Break">function.</span></p>
			<p>A further generalization of this approach allows us to consider the residuals as a negative gradient of the loss function, specifically of the form <img alt="" role="presentation" src="image/B22503_Formula_034.png"/>. In other words, gradient boosting is a method of GD with the loss function and its <span class="No-Break">gradient replacement.</span></p>
			<p>Now, knowing the expression <a id="_idIndexMarker1066"/>of the loss function gradient, we can calculate its values on our data. Therefore, we can train models so that our predictions are better correlated with this gradient (with a minus sign). Hence, we will solve the regression problem, trying to correct the predictions for these residuals. For classification, regression, and ranking, we always minimize the squared difference between the residuals and <span class="No-Break">our predictions.</span></p>
			<p>In the gradient boosting method, an approximation of the function of the following form <span class="No-Break">is used:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer689">
					<img alt="" role="presentation" src="image/B22503_Formula_035.jpg"/>
				</div>
			</div>
			<p>This is the sum of <img alt="" role="presentation" src="image/B22503_Formula_036.png"/> functions of the <img alt="" role="presentation" src="image/B22503_Formula_037.png"/> class; they are <a id="_idIndexMarker1067"/>collectively called <strong class="bold">weak models</strong> (algorithms). Such an approximation is carried out sequentially, starting from the initial approximation, which is a certain constant, <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer692">
					<img alt="" role="presentation" src="image/B22503_Formula_038.jpg"/>
				</div>
			</div>
			<p>Unfortunately, the choice of the <img alt="" role="presentation" src="image/B22503_Formula_039.png"/> optimal function at each step for an arbitrary loss function is extremely difficult, so a more straightforward approach is used. The idea is to use the GD method by using differentiable <img alt="" role="presentation" src="image/B22503_Formula_040.png"/> functions and a differentiable loss function, as <span class="No-Break">illustrated here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer695">
					<img alt="" role="presentation" src="image/B22503_Formula_041.jpg"/>
				</div>
			</div>
			<p>The boosting algorithm<a id="_idIndexMarker1068"/> is then formed <span class="No-Break">as follows:</span></p>
			<ol>
				<li>Initialize the<a id="_idIndexMarker1069"/> model with constant values, <span class="No-Break">like this:</span><div class="IMG---Figure" id="_idContainer696"><img alt="" role="presentation" src="image/B22503_Formula_042.jpg"/></div></li>
			</ol>
			<ol>
				<li value="2">Repeat the specified number of iterations and do <span class="No-Break">the following:</span><ol><li class="upper-roman">Calculate the pseudo-residuals, <span class="No-Break">as follows:</span></li></ol></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer697">
					<img alt="" role="presentation" src="image/B22503_Formula_043.jpg"/>
				</div>
			</div>
			<p class="list-inset">Here, <em class="italic">n</em> is the number of training samples, <em class="italic">m</em> is the iteration number, and <em class="italic">L</em> is the <span class="No-Break">loss function.</span></p>
			<ol>
				<li class="upper-roman" value="2">Train the elementary algorithm (regression model) <img alt="" role="presentation" src="image/B22503_Formula_044.png"/> on pseudo-residuals with data of the <span class="No-Break">form </span><span class="No-Break"><img alt="" role="presentation" src="image/B22503_Formula_045.png"/>.</span></li>
				<li class="upper-roman">Calculate the <img alt="" role="presentation" src="image/B22503_Formula_046.png"/> coefficient by solving a one-dimensional optimization problem <span class="No-Break">as follows:</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer701">
					<img alt="" role="presentation" src="image/B22503_Formula_047.jpg"/>
				</div>
			</div>
			<ol>
				<li class="upper-roman" value="4">Update the model, <span class="No-Break">as follows:</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer702">
					<img alt="" role="presentation" src="image/B22503_Formula_048.jpg"/>
				</div>
			</div>
			<p>The inputs to this algorithm are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>The <img alt="" role="presentation" src="image/B22503_Formula_049.png"/> <span class="No-Break">dataset</span></li>
				<li>The number of <span class="No-Break"><em class="italic">M</em></span><span class="No-Break"> iterations</span></li>
				<li>The <em class="italic">L( y, f )</em> loss function with an analytically written gradient (such a form of gradient allows us to reduce the number of <span class="No-Break">numerical calculations)</span></li>
				<li>The choice of the family<a id="_idIndexMarker1070"/> of functions of the <em class="italic">h (x)</em> elementary algorithms, with the procedure of their training <span class="No-Break">and hyperparameters</span></li>
			</ul>
			<p>The constant for the initial approximation, as well as the <img alt="" role="presentation" src="image/B22503_Formula_050.png"/>-optimal coefficient, can be found by a binary search, or by another line search algorithm relative to the initial loss function (rather than <span class="No-Break">the gradient).</span></p>
			<p>Examples of loss functions for regression are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><img alt="" role="presentation" src="image/B22503_Formula_051.png"/>: An <em class="italic">L</em><span class="subscript">2</span> loss, also called <strong class="bold">Gaussian loss</strong>. This formula is the classic conditional mean and the most<a id="_idIndexMarker1071"/> common and simple option. If there are no additional information or model sustainability requirements, it should <span class="No-Break">be used.</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_052.png"/>: An <em class="italic">L</em><span class="subscript">1</span> loss, also called <strong class="bold">Laplacian loss</strong>. This formula, at first glance, is not very differentiable and <a id="_idIndexMarker1072"/>determines the conditional median. The median, as we know, is more resistant to outliers. Therefore, in some problems, this loss function is preferable since it does not penalize large deviations as much as a <span class="No-Break">quadratic</span><span class="No-Break"><a id="_idIndexMarker1073"/></span><span class="No-Break"> function.</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_053.png"/> : An <em class="italic">L</em><span class="subscript">q</span> loss, also called <strong class="bold">Quantile loss</strong>. If we don’t want a conditional median but do want a<a id="_idIndexMarker1074"/> conditional 75% quantile, we would use this option with <img alt="" role="presentation" src="image/B22503_Formula_054.png"/>. This function is asymmetric and penalizes more observations that turn out to be on the side of the quantile <span class="No-Break">we need.</span></li>
			</ul>
			<p>Examples of loss functions for <a id="_idIndexMarker1075"/>classification are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><img alt="" role="presentation" src="image/B22503_Formula_055.png"/>: Logistic loss, also known as <strong class="bold">Bernoulli loss</strong>. An interesting property of this loss<a id="_idIndexMarker1076"/> function is that we penalize even correctly predicted class labels. By optimizing this loss function, we can continue to distance classes and improve the classifier even if all observations are correctly predicted. This function is the most standard and frequently used loss function in a binary <span class="No-Break">classification task.</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_056.png"/>: <strong class="bold">AdaBoost loss</strong>. It so happens that the classic AdaBoost algorithm that uses this loss function (different<a id="_idIndexMarker1077"/> loss functions can also be used in the AdaBoost algorithm) is equivalent to gradient boosting. Conceptually, this loss function is very similar to logistic loss, but it has a stronger exponential penalty for classification errors and is used <span class="No-Break">less frequently.</span></li>
			</ul>
			<p>The idea of bagging is that it can be used with a gradient boosting approach too, which is known as <strong class="bold">stochastic gradient boosting</strong>. In this way, a new algorithm is trained on a sub-sample of the training set. This<a id="_idIndexMarker1078"/> approach can help us to improve the quality of the ensemble and reduce the time it takes to build elementary algorithms (whereby each is trained on a reduced number of <span class="No-Break">training samples).</span></p>
			<p>Although boosting itself is an ensemble, other ensemble schemes can be applied to it—for example, by averaging several boosting methods. Even if we average boosts with the same parameters, they<a id="_idIndexMarker1079"/> will differ due to the stochastic nature of the implementation. This randomness comes from the choice of random sub-datasets at each step or selecting different features when we are building decision trees (if they are chosen as <span class="No-Break">elementary algorithms).</span></p>
			<p>Currently, the base <strong class="bold">gradient boosting machine</strong> (<strong class="bold">GBM</strong>) has many extensions for different statistical tasks. These <a id="_idIndexMarker1080"/>are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>GLMBoost and GAMBoost as an <a id="_idIndexMarker1081"/>enhancement of the existing <strong class="bold">generalized additive </strong><span class="No-Break"><strong class="bold">model</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">GAM</strong></span><span class="No-Break">)</span></li>
				<li>CoxBoost for <span class="No-Break">survival curves</span></li>
				<li>RankBoost and LambdaMART <span class="No-Break">for ranking</span></li>
			</ul>
			<p>Additionally, there are many<a id="_idIndexMarker1082"/> implementations of the same GBM <a id="_idIndexMarker1083"/>under different names and different platforms, such <span class="No-Break">as these:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Stochastic GBM</strong></span></li>
				<li><strong class="bold">Gradient boosted decision </strong><span class="No-Break"><strong class="bold">trees</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">GBDT</strong></span><span class="No-Break">)</span></li>
				<li><strong class="bold">Gradient boosted regression </strong><span class="No-Break"><strong class="bold">trees</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">GBRT</strong></span><span class="No-Break">)</span></li>
				<li><strong class="bold">Multiple additive regression </strong><span class="No-Break"><strong class="bold">trees</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">MART</strong></span><span class="No-Break">)</span></li>
				<li><strong class="bold">Generalized boosting </strong><span class="No-Break"><strong class="bold">machine</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">GBM</strong></span><span class="No-Break">)</span></li>
			</ul>
			<p>Furthermore, boosting can be <a id="_idIndexMarker1084"/>applied and used over a long<a id="_idIndexMarker1085"/> period of time in the ranking<a id="_idIndexMarker1086"/> tasks undertaken by search engines. The task<a id="_idIndexMarker1087"/> is written based on a loss function, which is penalized for errors in the order of search results; therefore, it becomes convenient to insert it into <span class="No-Break">a GBM.</span></p>
			<h2 id="_idParaDest-195"><a id="_idTextAnchor510"/>U<a id="_idTextAnchor511"/>sing a stacking approach for creating ensembles</h2>
			<p>The purpose of stacking is to use different algorithms trained on the same data as elementary models. A meta-classifier is<a id="_idIndexMarker1088"/> then trained on the results of the elementary algorithms or source data, also supplemented by the results of the elementary algorithms themselves. Sometimes, a meta-classifier uses the estimates of distribution parameters that it receives (for example, estimates of the probabilities<a id="_idIndexMarker1089"/> of each class for classification) for its training, rather than the results of <span class="No-Break">elementary algorithms.</span></p>
			<p>The most straightforward stacking scheme is blending. For this scheme, we divide the training set into two parts. The first part is used to teach a set of elementary algorithms. Their results can be considered new features (meta-features). We then use them as complementary features with the second part of the dataset and train the new meta-algorithm. The problem with such a blending scheme is that neither the elementary algorithms nor the meta-algorithm use the entire set of data for training. To improve the quality of blending, you can average the results of several blends trained at different partitions in <span class="No-Break">the data.</span></p>
			<p>A second way to implement stacking is to use the entire training set. In some sources, this is known as <em class="italic">generalization</em>. The entire set is <a id="_idIndexMarker1090"/>divided into parts (folds), then the algorithm sequentially goes through the folds and teaches elementary algorithms on all the folds except the one randomly chosen fold. The remaining fold is used for the inference of the elementary algorithms. The output values of elementary algorithms are interpreted as the new meta-attributes (or new features) calculated from the folds. In this approach, it is also desirable to implement several different partitions into folds, and then average the corresponding <a id="_idIndexMarker1091"/>meta-attributes. For a meta-algorithm, it makes sense to apply regularization or add some normal noise to the meta-attributes. The coefficient with which this addition occurs is analogous to the regularization coefficient. We can summarize that the basic idea behind the described approach is to use a set of base algorithms; then, using another meta-algorithm, we combine their predictions with the aim of reducing the <span class="No-Break">generalization error.</span></p>
			<p>Unlike boosting and traditional bagging, you can use algorithms of a different nature (for example, a ridge regression in combination with a random forest) in stacking. However, it is essential to remember that for different algorithms, different feature spaces are needed. For example, if categorical features are used as target variables, then the random forest algorithm can be used as-is, but for the regression algorithms, you must first run <span class="No-Break">one-hot encoding.</span></p>
			<p>Since meta-features are the results of already trained algorithms, they strongly correlate. This fact is <em class="italic">a priori</em> one of the <a id="_idIndexMarker1092"/>disadvantages of this approach; the elementary algorithms are often under-optimized during training to combat correlation. Sometimes, to combat this drawback, the<a id="_idIndexMarker1093"/> training of elementary algorithms is used not on the target feature, but on the differences between a feature and <span class="No-Break">the ta<a id="_idTextAnchor512"/>r<a id="_idTextAnchor513"/>get.</span></p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor514"/>Using the random forest method for creating ensembles</h2>
			<p>Before we move to the <a id="_idIndexMarker1094"/>random forest method, we need to familiarize<a id="_idIndexMarker1095"/> ourselves with the decision tree algorithm, which is the basis for the random forest <span class="No-Break">ensemble alg<a id="_idTextAnchor515"/>o<a id="_idTextAnchor516"/>rithm.</span></p>
			<h3>Decision tree algorithm overview</h3>
			<p>A decision tree is a supervised machine learning algorithm based on how a human solves the task of forecasting or <a id="_idIndexMarker1096"/>classification. Generally, this is a <em class="italic">k</em>-dimensional tree with decision rules in the nodes and a prediction of the objective function at the leaf nodes. The decision rule is a function that allows you to determine which of the child nodes should be used as a parent for the considered object. There can be different types of objects in the decision tree leaf—namely, the class label assigned to the object (in the classification tasks), the probability of the class (in the classification tasks), and the value of the objective function (in the <span class="No-Break">regression task).</span></p>
			<p>In practice, binary decision trees are used more often than trees with an arbitrary number of <span class="No-Break">child nodes.</span></p>
			<p>The algorithm for constructing a decision tree in its general form is formed <span class="No-Break">as follows:</span></p>
			<ol>
				<li>Firstly, check the criterion for stopping the algorithm. If this criterion is executed, select the prediction issued for the node. Otherwise, we have to split the training set into several non-intersecting <span class="No-Break">smaller sets.</span></li>
				<li>In the general case, a <img alt="" role="presentation" src="image/B22503_Formula_057.png"/> decision rule is defined at the <em class="italic">t</em> node, which takes into account a certain range of values. This range is divided into <em class="italic">R</em><span class="subscript">t</span> disjoint sets of objects: <img alt="" role="presentation" src="image/B22503_Formula_058.png"/>, where <em class="italic">R</em><span class="subscript">t</span> is the number of descendants of the node, and each <img alt="" role="presentation" src="image/B22503_Formula_059.png"/>is a set of objects that fall into <span class="No-Break">the <img alt="" role="presentation" src="image/B22503_Formula_060.png"/>descendant.</span></li>
				<li>Divide the set in the node according to the selected rule, and repeat the algorithm recursively for <span class="No-Break">each node.</span></li>
			</ol>
			<p>Most often, the <img alt="" role="presentation" src="image/B22503_Formula_061.png"/> decision <a id="_idIndexMarker1097"/>rule is simply the feature—that is, <img alt="" role="presentation" src="image/B22503_Formula_062.png"/>. For partitioning, we can use the <span class="No-Break">following rules:</span></p>
			<ul>
				<li><img alt="" role="presentation" src="image/B22503_Formula_063.png"/> for chosen boundary <span class="No-Break">values </span><span class="No-Break"><img alt="" role="presentation" src="image/B22503_Formula_064.png"/>.</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_065.png"/>, where <img alt="" role="presentation" src="image/B22503_Formula_066.png"/>is a vector’s scalar product. In fact, it is a corner <span class="No-Break">value check.</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_067.png"/>, where the distance <img alt="" role="presentation" src="image/B22503_Formula_068.png"/> is defined in some metric space (for <span class="No-Break">example, <img alt="" role="presentation" src="image/B22503_Formula_069.png"/>).</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_070.png"/>, where <img alt="" role="presentation" src="image/B22503_Formula_071.png"/> is <span class="No-Break">a predicate.</span></li>
			</ul>
			<p>In general, you can use any decision rules, but those that are easiest to interpret are better since they are easier to configure. There is no particular point in taking something more complicated than predicates since you can create a tree with 100% accuracy on the training set with the help of <span class="No-Break">the predicates.</span></p>
			<p>Usually, a set of decision rules is chosen to build a tree. To find the optimal one among them for each particular node, we need to introduce a criterion for measuring optimality. The <img alt="" role="presentation" src="image/B22503_Formula_072.png"/> measure is introduced for this and is used to measure how objects are scattered (regression) or how the classes are mixed (classification) in a specific <img alt="" role="presentation" src="image/B22503_Formula_073.png"/> node. This measure is <a id="_idIndexMarker1098"/>called the <strong class="bold">impurity function</strong>. It is required for finding a maximum of <img alt="" role="presentation" src="image/B22503_Formula_074.png"/> according to all features and parameters from a set of decision rules, in order to select a decision <a id="_idIndexMarker1099"/>rule. With this choice, we can generate the optimal partition for the set of objects in the <span class="No-Break">current node.</span></p>
			<p>Information gain, <img alt="" role="presentation" src="image/B22503_Formula_075.png"/>, is how much information we can get for the selected split, and is calculated <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer730">
					<img alt="" role="presentation" src="image/B22503_Formula_076.jpg"/>
				</div>
			</div>
			<p>In the preceding equation, the <span class="No-Break">following applies:</span></p>
			<ul>
				<li><em class="italic">R</em> is the number of sub-nodes the current node is <span class="No-Break">broken into</span></li>
				<li><em class="italic">t</em> is the <span class="No-Break">current node</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_077.png"/> are the descendant nodes that are obtained with the <span class="No-Break">selected partition</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_078.png"/> is the number of objects in the training sample that fall into the <span class="No-Break">child </span><span class="No-Break"><em class="italic">i</em></span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_079.png"/> is the number of <a id="_idIndexMarker1100"/>objects trapped in the <span class="No-Break">current node</span></li>
				<li><img alt="" role="presentation" src="image/B22503_Formula_080.png"/> are the objects trapped in the <span class="No-Break"><em class="italic">t</em></span><span class="No-Break"><span class="subscript">i</span></span><span class="No-Break"><span class="superscript">th</span></span><span class="No-Break"> vertex</span></li>
			</ul>
			<p>We can use the MSE or the <strong class="bold">mean absolute error</strong> (<strong class="bold">MAE</strong>) as the <img alt="" role="presentation" src="image/B22503_Formula_081.png"/> impurity function for regression tasks. For<a id="_idIndexMarker1101"/> classification tasks, we can use the <span class="No-Break">following functions:</span></p>
			<ul>
				<li>Gini criterion <img alt="" role="presentation" src="image/B22503_Formula_082.png"/> as the probability of misclassification, specifically if we predict classes with probabilities of their occurrence in a <span class="No-Break">given node</span></li>
				<li>Entropy <img alt="" role="presentation" src="image/B22503_Formula_083.png"/> as a measure of the uncertainty of a <span class="No-Break">random variable</span></li>
				<li>Classification error <img alt="" role="presentation" src="image/B22503_Formula_084.png"/> as the error rate in the classification of the most <span class="No-Break">potent class</span></li>
			</ul>
			<p>In the functions described previously, <img alt="" role="presentation" src="image/B22503_Formula_085.png"/> is an <em class="italic">a priori</em> probability of encountering an object of class <em class="italic">i</em> in a node <em class="italic">t</em>—that is, the<a id="_idIndexMarker1102"/> number of objects in the training sample with labels of class <em class="italic">i</em> falling into <em class="italic">t</em> divided by the total number of objects in <span class="No-Break"><em class="italic">t</em></span><span class="No-Break"> (<img alt="" role="presentation" src="image/B22503_Formula_086.png"/>).</span></p>
			<p>The following rules can be applied as stopping criteria for building a <span class="No-Break">decision tree:</span></p>
			<ul>
				<li>Limiting the maximum depth of <span class="No-Break">the tree</span></li>
				<li>Limiting the minimum number of objects in <span class="No-Break">the sheet</span></li>
				<li>Limiting the maximum number of leaves in <span class="No-Break">a tree</span></li>
				<li>Stopping if all objects in the node belong to the <span class="No-Break">same class</span></li>
				<li>Requiring that information gain is improved by at least 8% <span class="No-Break">during splitting</span></li>
			</ul>
			<p>There is an error-free tree for any training set, which leads to the problem of overfitting. Finding the right stopping criterion to solve this problem is challenging. One solution is <strong class="bold">pruning</strong>—after the whole tree is <a id="_idIndexMarker1103"/>constructed, we can cut some nodes. Such an operation can be performed using a test or validation set. Pruning can reduce the complexity of the final classifier <a id="_idIndexMarker1104"/>and improve predictive accuracy by <span class="No-Break">reducing overfitting.</span></p>
			<p>The pruning algorithm is formed <span class="No-Break">as follows:</span></p>
			<ol>
				<li>We build a tree for the <span class="No-Break">training set.</span></li>
				<li>Then, we pass a validation set through the constructed tree and consider any internal node <em class="italic">t</em> and its left and right sub-nodes <img alt="" role="presentation" src="image/B22503_Formula_087.png"/>, <img alt="" role="presentation" src="image/B22503_Formula_088.png"/>.</li>
				<li>If no one object from the validation sample has reached <em class="italic">t</em>, then we can say that this node (and all its subtrees) is insignificant, and make <em class="italic">t</em> the leaf (set the predicate’s value for this node equal to the set of the majority class using the <span class="No-Break">training set).</span></li>
				<li>If objects from the validation set have reached <em class="italic">t</em>, then we have to consider the following <span class="No-Break">three values:</span><ul><li>The number of classification errors from a subtree <span class="No-Break">of </span><span class="No-Break"><em class="italic">t</em></span></li><li>The number of classification errors from the <img alt="" role="presentation" src="image/B22503_Formula_089.png"/> <span class="No-Break">subtree</span></li><li>The number of classification errors from the <img alt="" role="presentation" src="image/B22503_Formula_090.png"/> <span class="No-Break">subtree</span></li></ul></li>
			</ol>
			<p>If the value for the first case is<a id="_idIndexMarker1105"/> zero, then we make node <em class="italic">t</em> as a leaf node with the corresponding prediction for the class. Otherwise, we choose the minimum of these values. Depending on which of them is minimal, we do the <span class="No-Break">following, respectively:</span></p>
			<ul>
				<li>If the first is minimal, <span class="No-Break">do nothing</span></li>
				<li>If the second is minimal, replace the tree from node <em class="italic">t </em>with a subtree from <span class="No-Break">node <img alt="" role="presentation" src="image/B22503_Formula_091.png"/></span></li>
				<li>If the third is minimal, replace the tree from node <em class="italic">t</em> with a subtree from <span class="No-Break">node <img alt="" role="presentation" src="image/B22503_Formula_092.png"/></span></li>
			</ul>
			<p>Such a procedure regularizes the algorithm to beat overfitting and increase the ability to generalize. In the case of a <em class="italic">k</em>-dimensional tree, different approaches can be used to select the forecast in the leaf. We can take the most common class among the objects of the training that fall under this leaf for classification. Alternatively, we can calculate the average of the objective functions of these objects <span class="No-Break">for regression.</span></p>
			<p>We apply a decision rule to a <a id="_idIndexMarker1106"/>new object starting from the tree root to predict or classify new data. Thus, it is determined which subtree the object should go into. We recursively repeat this process until we reach some leaf node and, finally, we return the value of the leaf node we found as the result of classification <span class="No-Break">or regression.</span></p>
			<h3>Random forest met<a id="_idTextAnchor517"/>h<a id="_idTextAnchor518"/>od overview</h3>
			<p>Decision trees are a suitable family of elementary <a id="_idIndexMarker1107"/>algorithms for bagging since they are quite complicated and can ultimately achieve zero errors on any training set. We can use a method that uses random subspaces (such as bagging) to reduce the correlation between trees and avoid overfitting. The elementary algorithms are trained on different subsets of the feature space, which are also randomly selected. An ensemble of decision tree models using the random subspace method <a id="_idIndexMarker1108"/>can be constructed using the <span class="No-Break">following algorithm.</span></p>
			<p>Where the number of objects for training is <em class="italic">N</em> and the number of features is <img alt="" role="presentation" src="image/B22503_Formula_093.png"/>, proceed <span class="No-Break">as follows:</span></p>
			<ol>
				<li>Select <img alt="" role="presentation" src="image/B22503_Formula_094.png"/> as the number of individual trees in <span class="No-Break">the ensemble.</span></li>
				<li>For each individual <img alt="" role="presentation" src="image/B22503_Formula_095.png"/> tree, select <img alt="" role="presentation" src="image/B22503_Formula_096.png"/> as the number of features for <img alt="" role="presentation" src="image/B22503_Formula_097.png"/>. Typically, only one value is used for <span class="No-Break">all trees.</span></li>
				<li>For each tree, create an <img alt="" role="presentation" src="image/B22503_Formula_098.png"/> training subset using the <span class="No-Break">bootstrap method.</span></li>
			</ol>
			<p>Now, build decision trees from <img alt="" role="presentation" src="image/B22503_Formula_098.png"/> samples <span class="No-Break">as follows:</span></p>
			<ol>
				<li>Select <img alt="" role="presentation" src="image/B22503_Formula_100.png"/> random features from the source, then the optimal division of the training set will limit its search <span class="No-Break">to them.</span></li>
				<li>According to a given criterion, we choose the best attribute and make a split in the tree according <span class="No-Break">to it.</span></li>
				<li>The tree is built until no more than <img alt="" role="presentation" src="image/B22503_Formula_101.png"/> objects remain in each leaf, until we reach a certain height of the tree, or until the training set <span class="No-Break">is exhausted.</span></li>
			</ol>
			<p>Now, to apply the ensemble model to a new object, it is necessary to combine the results of individual models by majority <a id="_idIndexMarker1109"/>voting or by combining <em class="italic">a posteriori</em> probabilities. An example of a final classifier is <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer756">
					<img alt="" role="presentation" src="image/B22503_Formula_102.jpg"/>
				</div>
			</div>
			<p>Consider the following fundamental parameters of the algorithm and <span class="No-Break">their properties:</span></p>
			<ul>
				<li><strong class="bold">The number of trees</strong>: The more trees, the better the quality, but the training time and the algorithm’s workload also increase proportionally. Often, with an increasing number of trees, the quality of the training set rises (it can even go up to 100% accuracy), but the quality of the test set is asymptotic (so you can estimate the minimum required number <span class="No-Break">of trees).</span></li>
				<li><strong class="bold">The number of features for the splitting selection</strong>: With an increasing number of features, the forest’s construction time increases too, and the trees become more uniform than before. Often, in classification problems, the number of attributes is chosen equal to <img alt="" role="presentation" src="image/B22503_Formula_103.png"/> and <img alt="" role="presentation" src="image/B22503_Formula_104.png"/> for <span class="No-Break">regression problems.</span></li>
				<li><strong class="bold">Maximum tree depth</strong>: The smaller the depth, the faster the algorithm is built and will work. As the depth increases, the quality during training increases dramatically. The quality<a id="_idIndexMarker1110"/> may also increase on the test set. It is recommended to use the maximum depth (except when there are too many training objects and we obtain very deep trees, the construction of which takes considerable time). When using shallow trees, changing the parameters associated with limiting the number of objects in the leaf and for splitting does not lead to a significant effect (the leaves are already large). Using shallow trees is recommended in tasks with a large number of noisy <span class="No-Break">objects (outliers).</span></li>
				<li><strong class="bold">The impurity function</strong>: This is a criterion<a id="_idIndexMarker1111"/> for choosing a feature (decision rule) for branching. It is usually MSE/MAE for regression problems. For classification problems, it is the Gini criterion, the entropy, or the classification error. The balance and depth of trees may vary depending on the specific impurity function <span class="No-Break">we choose.</span></li>
			</ul>
			<p>We can consider a random forest as bagging decision trees, and during these trees’ training, we use features from a random subset of features for each partition. This approach is a universal algorithm since random forests exist for solving problems of classification, regression, clustering, anomaly search, and feature selection, among <span class="No-Break">other tasks.</span></p>
			<p>In the following section, we will see how to use different C++ libraries for developing machine learning <span class="No-Break">model ensembles.</span></p>
			<h1 id="_idParaDest-197">Examples of using C++ li<a id="_idTextAnchor519"/>b<a id="_idTextAnchor520"/>raries for creating ensembles</h1>
			<p>The following sections will show how to use ensembles within the <strong class="source-inline">Dlib</strong> and <strong class="source-inline">mlpack</strong> libraries. There are out-of-the-box implementations of random forest and gradient boosting algorithms in these libraries; we <a id="_idIndexMarker1112"/>will show how to use their <strong class="bold">application programming interfaces</strong> (<strong class="bold">APIs</strong>) to work with these<a id="_idIndexMarker1113"/> algorithms. Also, we will implement a stacking ensemble technique from scratch, using primitives from the <span class="No-Break"><strong class="source-inline">mlpack</strong></span><span class="No-Break"> library.</span></p>
			<h2 id="_idParaDest-198"><a id="_idTextAnchor521"/>Ensembles with Dlib</h2>
			<p>Th<a id="_idTextAnchor522"/>e<a id="_idTextAnchor523"/>re is only the random forest algorithm implementation in the <strong class="source-inline">Dlib</strong> library, and in this section, we will show the <a id="_idIndexMarker1114"/>specific API for using it <span class="No-Break">in practice.</span></p>
			<p>To show the random fo<a id="_idTextAnchor524"/><a id="_idTextAnchor525"/>rest algorithm application, we need to have some dataset for this task. Let’s create an artificial dataset that models the cosine function. First, we define datatypes to represent samples and label items. The following code sample shows how it <span class="No-Break">is done:</span></p>
			<pre class="source-code">
using DataType = double;
using SampleType = dlib::matrix&lt;DataType, 0, 1&gt;;
using Samples = std::vector&lt;SampleType&gt;;
using Labels = std::vector&lt;DataType&gt;;</pre>			<p>Then we define the <span class="No-Break"><strong class="source-inline">GenerateData</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
std::pair&lt;Samples, Labels&gt; GenerateData(DataType start,
                                        DataType end,
                                        size_t n) {
  Samples x;
  x.resize(n);
  Labels y;
  y.resize(n);
  auto step = (end - start) / (n - 1);
  auto x_val = start;
  size_t i = 0;
  for (auto&amp; x_item : x) {
    x_item = SampleType({x_val});
    auto y_val = std::cos(M_PI * x_val);
    y[i] = y_val;
    x_val += step;
    ++i;
  }
  return {x, y};
}</pre>			<p>The <strong class="source-inline">GenerateData</strong> function<a id="_idIndexMarker1115"/> takes three parameters: the <strong class="source-inline">start</strong> and <strong class="source-inline">end</strong> values of the generation range and the <strong class="source-inline">n</strong> numbers of points to generate. The implementation simply calculates cosine values in the loop. The function returns a pair of <strong class="source-inline">std::vector</strong> type objects containing the <strong class="source-inline">double</strong> values. The result of this function will be used <span class="No-Break">for testing.</span></p>
			<p>To show that the random forest algorithm really can approximate values, we will add some noise to the original data. The following code snippet shows the <strong class="source-inline">GenerateNoiseData</strong> <span class="No-Break">function</span><span class="No-Break"><a id="_idIndexMarker1116"/></span><span class="No-Break"> implementation:</span></p>
			<pre class="source-code">
std::pair&lt;Samples, Labels&gt; GenerateNoiseData(DataType start,
                                             DataType end,
                                             size_t n) {
  Samples x;
  x.resize(n);
  Labels y;
  y.resize(n);
  std::mt19937 re(3467);
  std::uniform_real_distribution&lt;DataType&gt; dist(start, end);
  std::normal_distribution&lt;DataType&gt; noise_dist;
  for (size_t i = 0; i &lt; n; ++i) {
    auto x_val = dist(re);
    auto y_val =
        std::cos(M_PI * x_val) + (noise_dist(re) * 0.3);
    x[i] = SampleType({x_val});
    y[i] = y_val;
  }
  return {x, y};
}</pre>			<p>The <strong class="source-inline">GenerateNoiseData</strong> function also calculates cosine values in the simple loop. It takes the same input parameters as the <strong class="source-inline">GenerateData</strong> function. However, instead of the sequential value generation, this function samples a random value from the specified range on each iteration. For<a id="_idIndexMarker1117"/> each sample, it calculates the cosine value and also adds the noise samples. The noise is generated by random distribution. The function also returns two <strong class="source-inline">std::vector</strong> type objects containing the <strong class="source-inline">double</strong> values, the first one for training inputs and the second one for <span class="No-Break">target values.</span></p>
			<p>Using these data generation functions, we can create the training and the test datasets <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
auto [train_samples, train_lables] =
  GenerateNoiseData(start, end, num_samples);
auto [test_samples, test_lables] =
  GenerateData(start, end, num_samples);</pre>			<p>Now, the usage of the Dlib random forest implementation is very simple. The following code snippet <span class="No-Break">shows it:</span></p>
			<pre class="source-code">
#include &lt;dlib/random_forest.h&gt;
... 
dlib::random_forest_regression_trainer&lt;
  dlib::dense_feature_extractor&gt; trainer;
constexpr size_t num_trees = 1000;
trainer.set_num_trees(num_trees);
auto random_forest = trainer.train(train_samples, train_lables);
for (const auto&amp; sample : test_samples) {
  auto prediction = random_forest(sample);
  …
}</pre>			<p>Here, we used the instance of the <strong class="source-inline">random_forest_regression_trainer</strong> class named <strong class="source-inline">trainer</strong> to create<a id="_idIndexMarker1118"/> the <strong class="source-inline">random_forest</strong> object with the <strong class="source-inline">train</strong> method. The <strong class="source-inline">trainer</strong> object was configured with the number of trees to use. The <strong class="source-inline">random_forest_regression_trainer</strong> class was parametrized with the <strong class="source-inline">dense_feature_extractor</strong> class—this is the only feature extractor class provided now by the <strong class="source-inline">Dlib</strong> library, but you can create a custom one. The <strong class="source-inline">train</strong> method simply takes two <strong class="source-inline">std::vector</strong> type objects, the first one for the input data values and the second one for the target <span class="No-Break">data values.</span></p>
			<p>After the training, the <strong class="source-inline">random_forest</strong> object was created, and it was used as a functional object to make a prediction for a <span class="No-Break">single value.</span></p>
			<p>The following figure shows the result of applying the random forest algorithm from the <strong class="source-inline">Dlib</strong> library. The original data is shown as stars and the predicted data is shown <span class="No-Break">as lines:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer759">
					<img alt="Figure 9.2 – Regression with random forest and Dlib" src="image/B19849_09_2.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Regression with random forest and Dlib</p>
			<p>Note that this method is not <a id="_idIndexMarker1119"/>very applicable to the regression task on this dataset. You can see that global trends were learned successfully but there are a lot of errors in <span class="No-Break">small details.</span></p>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor526"/>Ensembles with mlpack</h2>
			<p>There are two ensemble learning algorithms <a id="_idIndexMarker1120"/>in the <strong class="source-inline">mlpack</strong> library: the random forest and AdaBoost algorithms. For this set of samples, we will use the <em class="italic">Breast Cancer Wisconsin (Diagnostic)</em> dataset located at <a href="https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic">https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic</a>. It is taken from <em class="italic">D</em>. <em class="italic">Dua, and C. Graff (2019), UCI Machine Learning </em><span class="No-Break"><em class="italic">Repository </em></span><span class="No-Break">(</span><a href="http://archive.ics.uci.edu/ml"><span class="No-Break">http://archive.ics.uci.edu/ml</span></a><span class="No-Break">).</span></p>
			<p>There are 569 instances in this dataset, and each instance has 32 attributes: the ID, the diagnosis, and 30 real-value input features. The diagnosis can have two values: <em class="italic">M =</em> malignant, and <em class="italic">B =</em> benign. Other <a id="_idIndexMarker1121"/>attributes have 10 real-value features computed for each cell nucleus, <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Radius (mean distance from the center to <span class="No-Break">the perimeter)</span></li>
				<li>Texture (standard deviation of <span class="No-Break">grayscale values)</span></li>
				<li><span class="No-Break">Perimeter</span></li>
				<li><span class="No-Break">Area</span></li>
				<li>Smoothness (local variation in <span class="No-Break">radius lengths)</span></li>
				<li><span class="No-Break">Compactness</span></li>
				<li>Concavity (severity of concave portions of <span class="No-Break">the contour)</span></li>
				<li>Concave points (number of concave portions of <span class="No-Break">the contour)</span></li>
				<li><span class="No-Break">Symmetry</span></li>
				<li>Fractal dimension (<span class="No-Break"><em class="italic">coastline approximation</em></span><span class="No-Break">—1)</span></li>
			</ul>
			<p>This dataset can be used for a binary <span class="No-Break">classification task.</span></p>
			<h3>Data preparatio<a id="_idTextAnchor527"/>n for mlpack</h3>
			<p>There is the <strong class="source-inline">DatasetInfo</strong> class in <strong class="source-inline">mlpack</strong> to describe a dataset. An instance of this class can be used with different algorithms. Also, there is the <strong class="source-inline">data::Load</strong> function in <strong class="source-inline">mlpack</strong> that can automatically load datasets from the <strong class="source-inline">.csv</strong>, <strong class="source-inline">.tsv</strong>, and <strong class="source-inline">.txt</strong> files. However, this function assumes<a id="_idIndexMarker1122"/> that there is only numerical data in such files that can be interpreted as a matrix. In our case, the data is in the <strong class="source-inline">.csv</strong> format but the <strong class="source-inline">Diagnosis</strong> column contains the string values <strong class="source-inline">M</strong> and <strong class="source-inline">B</strong>. So, we simply convert them into <strong class="source-inline">0</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">1</strong></span><span class="No-Break">.</span></p>
			<p>When we have the correct <strong class="source-inline">.csv</strong> file, the data can be loaded in the <span class="No-Break">following way:</span></p>
			<pre class="source-code">
arma::mat data;
mlpack::data::DatasetInfo info;
data::Load(dataset_name, data, info, /*fail with error*/ true);</pre>			<p>We passed into the <strong class="source-inline">Load</strong> function the dataset filename and references to the <strong class="source-inline">data</strong> matrix object and the <strong class="source-inline">info</strong> object. Also, notice that we asked the function to generate an exception in the fail case by passing the last parameter <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">true</strong></span><span class="No-Break">.</span></p>
			<p>Then we split the data into the<a id="_idIndexMarker1123"/> input and target parts <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
// extract the labels row
arma::Row&lt;size_t&gt; labels;
 labels = arma::conv_to&lt;arma::Row&lt;size_t&gt;&gt;::from( data.row(0));
// remove the labels row
data.shed_row(0);</pre>			<p>Here, we used the <strong class="source-inline">row</strong> method of the matrix object to get the particular row. Then we converted its values into the <strong class="source-inline">site_t</strong> type with the <strong class="source-inline">arma::conv_to</strong> function because the first row in our dataset consists of labels. Finally, we removed the first row from the <strong class="source-inline">data</strong> object to make it usable as <span class="No-Break">input data.</span></p>
			<p>Having input data and labels matrices, we can split them into the training and testing parts <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
// split dataset into the train and test parts - make views
size_t train_num = 500;
arma::Row&lt;size_t&gt; train_labels = labels.head_cols( train_num); arma::mat test_input = data.tail_cols( num_samples - train_num); arma::Row&lt;size_t&gt; test_labels = 
  labels.tail_cols( num_samples - train_num);</pre>			<p>We used the <strong class="source-inline">head_cols</strong> method of the matrix object to take the first <strong class="source-inline">train_num</strong> columns from the input data and label them as the train values, and we used the <strong class="source-inline">tail_cols</strong> method of the <a id="_idIndexMarker1124"/>matrix object to take the last columns as the <span class="No-Break">test values.</span></p>
			<h3>Using random <a id="_idTextAnchor528"/>forest with mlpack</h3>
			<p>The random forest <a id="_idIndexMarker1125"/>algorithm in the <strong class="source-inline">mlpack</strong> library is located in the <strong class="source-inline">RandomForest</strong> class. This <a id="_idIndexMarker1126"/>class has two main methods: <strong class="source-inline">Train</strong> and <strong class="source-inline">Classify</strong>. The <strong class="source-inline">Train</strong> method can be used <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
using namespace mlpack;
RandomForest&lt;&gt; rf;
rf.Train(train_input,
         train_labels,
         num_classes,
         /*numTrees=*/100,
         /*minimumLeafSize=*/10,
         /*minimumGainSplit=*/1e-7,
         /*maximumDepth=*/10);</pre>			<p>The first f<a id="_idTextAnchor529"/>our parameters are self-descriptive. The last ones are more algorithm-specific. The <strong class="source-inline">minimumLeafSize</strong> parameter is the minimum number of points in each tree’s leaf nodes. The <strong class="source-inline">minimumGainSplit</strong> parameter is the minimum gain for splitting a decision tree node. The <strong class="source-inline">maximumDepth</strong> parameter is the maximum allowed <span class="No-Break">tree depth.</span></p>
			<p>After the use of the <strong class="source-inline">Train</strong> method with the<a id="_idIndexMarker1127"/> training data, the <strong class="source-inline">rf</strong> object can be used for the classification with the <strong class="source-inline">Classify</strong> method. This method takes as its first parameter the single value or the row matrix as input, and the second parameter is the reference to the single prediction value or the vector of predictions that will be filled by <span class="No-Break">this method.</span></p>
			<p>There is the <strong class="source-inline">Accuracy</strong> class in <strong class="source-inline">mlpack</strong> that can be used to estimate an algorithm’s accuracy. It can work with different algorithm objects and have a unified interface. We can use it <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
Accuracy acc;
auto acc_value = acc.Evaluate(rf, test_input, test_labels);
std::cout &lt;&lt; "Random Forest accuracy = " &lt;&lt; acc_value &lt;&lt; std::endl;</pre>			<p>We used the <strong class="source-inline">Evaluate</strong> method to get the accuracy value for the random forest algorithm trained with our data. The<a id="_idIndexMarker1128"/> printed value is <strong class="source-inline">Random Forest accuracy = </strong><span class="No-Break"><strong class="source-inline">0.971014</strong></span><span class="No-Break">.</span></p>
			<h3>Using Ada<a id="_idTextAnchor530"/>Boost with mlpack</h3>
			<p>Another ensemble-based <a id="_idIndexMarker1129"/>algorithm in the <strong class="source-inline">mlpack</strong> library is AdaBoost. It is based on an <a id="_idIndexMarker1130"/>ensemble of weak learners that is used to produce a strong learner. Let’s define an AdaBoost algorithm object based on simple perceptrons as weak learners, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
using namespace mlpack;
Perceptron&lt;&gt; p;
AdaBoost&lt;Perceptron&lt;&gt;&gt; ab;</pre>			<p>We parametrized the <strong class="source-inline">AdaBoost</strong> class with the <strong class="source-inline">Perceptron</strong> class as the template parameter. After the <strong class="source-inline">AdaBoost</strong> object is instantiated, we can use the <strong class="source-inline">Train</strong> method to train it with our dataset. The following code snippet shows how to use the <span class="No-Break"><strong class="source-inline">Train</strong></span><span class="No-Break"> method:</span></p>
			<pre class="source-code">
ab.Train(train_input,
         train_labels,
         num_classes,
         p,
         /*iterations*/ 1000,
         /*tolerance*/ 1e-10);</pre>			<p>The first three input parameters are pretty obvious—the input data, labels, and number of classes for classification. Then we passed the <strong class="source-inline">p</strong> object; it’s the instance of the <strong class="source-inline">Perceptron</strong> class, our weak <a id="_idIndexMarker1131"/>learner. After the weak learner object, we passed into the <strong class="source-inline">Train</strong> method the number of iterations to learn and the accuracy tolerance to stop <span class="No-Break">learning early.</span></p>
			<p>After the strong learner <strong class="source-inline">ab</strong> is trained, we can use the <strong class="source-inline">Classify</strong> method to get classification for a new data value. Also, we <a id="_idIndexMarker1132"/>can use an object of the <strong class="source-inline">Accuracy</strong> class to estimate the accuracy of the trained algorithm. We already saw how to use <strong class="source-inline">Accuracy</strong> in the previous chapter. Its API is the same for all algorithms in <strong class="source-inline">mlpack</strong>. For <strong class="source-inline">AdaBoost</strong>, we can use it <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
Accuracy acc;
auto acc_value = acc.Evaluate(ab, test_input, test_labels);
std::cout &lt;&lt; "AdaBoost accuracy = " &lt;&lt; acc_value &lt;&lt; std::endl;</pre>			<p>For the <strong class="source-inline">AdaBoost</strong> algorithm with the same dataset, we got the following output: <strong class="source-inline">AdaBoost accuracy = 0.985507</strong>. The accuracy is slightly better than we got with the random <span class="No-Break">forest algorithm.</span></p>
			<h3>Using<a id="_idTextAnchor531"/> a stacking ensemble with mlpack</h3>
			<p>To show the implementation of more<a id="_idIndexMarker1133"/> ensemble learning techniques, we can develop the stacking approach manually. This is not hard with the <strong class="source-inline">mlpack</strong> library, or indeed any <span class="No-Break">other library.</span></p>
			<p>The stacking approach is based on learning a set of weak learners. Usually, the k-fold technique is used to implement this. It <a id="_idIndexMarker1134"/>means that we learn a weak model on <strong class="source-inline">k-1</strong> folds and use the last fold for predictions. Let’s see how we can create k-fold-splitting using <strong class="source-inline">mlpack</strong>. We will use the same dataset as we did for the previous subsections. The main idea is to repeat the dataset to be able to get different folds just by using indices. The following code snippet defines the <strong class="source-inline">KfoldDataSet</strong> structure with just one method <span class="No-Break">and constructor:</span></p>
			<pre class="source-code">
struct KFoldDataSet {
  KFoldDataSet(const arma::mat&amp; train_input,
               const arma::Row&lt;size_ t&gt;&amp; train_labels,
               size_t k);
  std::tuple&lt;arma::mat, arma::Row&lt;size_t&gt;, arma::mat,
             arma::Row&lt;size_t&gt;&gt;
  get_fold(const size_t i);
  size_t k{0};
  size_t bin_size{0};
  size_t last_bin_size{0};
  arma::mat inputs;
  arma::Row&lt;size_t&gt; labels;
};</pre>			<p>The constructor takes the input data, labels, and <a id="_idIndexMarker1135"/>number of folds for splitting. The <strong class="source-inline">get_fold</strong> method takes an index of a fold and returns <span class="No-Break">four values:</span></p>
			<ul>
				<li>The matrix contains <strong class="source-inline">k-1</strong> folds of the <span class="No-Break">input data</span></li>
				<li>The row matrix contains <strong class="source-inline">k-1</strong> folds <span class="No-Break">of labels</span></li>
				<li>The matrix contains the last fold of the <span class="No-Break">input data</span></li>
				<li>The row matrix contains the last fold <span class="No-Break">of labels</span></li>
			</ul>
			<p>Constructor implementation <a id="_idIndexMarker1136"/>can be <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
KFoldDataSet(const arma::mat&amp; train_input,
             const arma::Row&lt;size_t&gt;&amp; train_labels, size_t k)
  : k(k) {
  fold_size = train_input.n_cols / k;
  last_fold_size = train_input.n_cols - ((k - 1) * fold_size);
  inputs = arma::join_rows(
    train_input, train_input.cols(0, train_input.n_cols -
                                   last_fold_size - 1));
  labels = arma::join_rows(
    train_labels,
    train_labels.cols(
      0, train_labels.n_cols - last_fold_size - 1));
}</pre>			<p>Here, we calculated the <strong class="source-inline">fold_size</strong> values by dividing the total number of samples in the input data by the number of folds. The total number of samples can be unaligned with the number of folds, so the last fold size can be different. That is why we additionally calculated the <strong class="source-inline">last_fold_size</strong> value to be able to make a correct splitting later. Having the fold size values, we used the <strong class="source-inline">arma::join_rows</strong> function to repeat training samples. This function<a id="_idIndexMarker1137"/> joins two matrices; for the first parameter, we used the original sample matrices, and for the second, we used reduced ones. We took just the <strong class="source-inline">k-1</strong> columns for the second parameter using the <strong class="source-inline">cols</strong> method of the <span class="No-Break">matrix object.</span></p>
			<p>When we have the<a id="_idIndexMarker1138"/> repeated data samples, the <strong class="source-inline">get_fold</strong> method implementation can be <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
std::tuple&lt;arma::mat, arma::Row&lt;size_t&gt;, arma::mat,
           arma::Row&lt;size_t&gt;&gt;
get_fold(const size_t i) {
  const size_t subset_size =
    (i != 0) ? last_fold_size + (k - 2) * fold_size
             : (k - 1) * fold_size;
  const size_t last_subset_size =
    (i == k - 1) ? last_fold_size : fold_size;
  // take k-1
  auto input_fold =
    arma::mat(inputs.colptr(fold_size * i), inputs.n_rows,
              subset_size, false, true);
  auto labels_fold = arma::Row&lt;size_t&gt;(
    labels.colptr(fold_size * i), subset_size, false, true);
  // take last k-th
  auto last_input_fold =
    arma::mat(inputs.colptr(fold_size * (i + k - 1)),
              inputs.n_rows, last_subset_size, false, true);
  auto last_labels_fold =
    arma::Row&lt;size_t&gt;(labels.colptr(fold_size * (i + k - 1)),
                      last_subset_size, false, true);
  return {input_fold, labels_fold, last_input_fold,
          last_labels_fold};
}</pre>			<p>The most important part of the <strong class="source-inline">get_fold</strong> method is to get the correct number of samples that belong to the <strong class="source-inline">k-1</strong> subset and the last fold subset. So, at first, we checked whether the required fold to be split is last or not because the last fold may contain a different size of samples. Having this information, we just multiplied the <strong class="source-inline">k-1</strong> or <strong class="source-inline">k-2</strong> numbers by the fold size, and conditionally added the last fold size to have the sample subsets. For the last fold, we also <a id="_idIndexMarker1139"/>conditionally got the fold size <a id="_idIndexMarker1140"/>depending on the required <span class="No-Break">fold-splitting index.</span></p>
			<p>Having the correct subset sizes, we used the <strong class="source-inline">colptr</strong> method to get the pointer to the starting column sample from the repeated data. We used such a pointer and the subset size to initialize the <strong class="source-inline">arma::mat</strong> object pointing to the existing data without copying by setting the <strong class="source-inline">copy_aux_mem</strong> constructor parameter to <strong class="source-inline">false</strong>. Using such an approach, we initialized matrices for the <strong class="source-inline">k-1</strong> fold samples and the last fold samples and returned them as <span class="No-Break">a tuple.</span></p>
			<p>Having the <strong class="source-inline">KfoldDataSet</strong> class, we can move further and implement the <strong class="source-inline">StackingClassification</strong> function. Its declaration can be <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
void StackingClassification(
  size_t num_classes,
  const arma::mat&amp; raw_train_input,
  const arma::Row&lt;size_t&gt;&amp; raw_train_labels,
  const arma::mat&amp; test_input,
  const arma::Row&lt;size_t&gt;&amp; test_labels);</pre>			<p>It will take the number of classification<a id="_idIndexMarker1141"/> classes, the train input and label data, and the test input and label data to estimate the accuracy of <span class="No-Break">the algorithm.</span></p>
			<p>The <strong class="source-inline">StackingClassification</strong> function implementation can be split into the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>Prepare <span class="No-Break">training dataset.</span></li>
				<li><span class="No-Break">Create meta-datasets.</span></li>
				<li><span class="No-Break">Train meta-model.</span></li>
				<li>Train <span class="No-Break">weak models.</span></li>
				<li>Evaluate the <span class="No-Break">test data.</span></li>
			</ol>
			<p>Let’s take a look at each of them, one by one. The dataset preparation can be implemented <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
using namespace mlpack;
// Shuffle data
arma::mat train_input;
arma::Row&lt;size_t&gt; train_labels;
ShuffleData(raw_train_input, raw_train_labels, train_input,
            train_labels);
// Normalize data
data::StandardScaler sample_scaler;
sample_scaler.Fit(train_input);
arma::mat scaled_train_input(train_input.n_rows,
                             train_input.n_cols);
sample_scaler.Transform(train_input, scaled_train_input);</pre>			<p>We used the <strong class="source-inline">ShuffleData</strong> function to randomize the training and the testing data, and we used the <strong class="source-inline">sample_scaler</strong> object of the <strong class="source-inline">StandardScaler</strong> class to scale our train and test data to the zero mean<a id="_idIndexMarker1142"/> and unit variance. Notice that we fitted a scaler object on the train data and then used it with the <strong class="source-inline">Transform</strong> method. We will use this scaler object later for the test <span class="No-Break">data too.</span></p>
			<p>Having the prepared dataset, we <a id="_idIndexMarker1143"/>can create a meta-dataset using weak (or elementary) algorithms that will be used for the stacking. It will be three weak <span class="No-Break">algorithms’ models:</span></p>
			<ul>
				<li><span class="No-Break">Softmax regression</span></li>
				<li><span class="No-Break">Decision tree</span></li>
				<li><span class="No-Break">Linear SVM</span></li>
			</ul>
			<p>The meta-dataset generation is based on the training and the evaluation of the weak models on the k-fold splits prepared from<a id="_idIndexMarker1144"/> the original dataset. We already created the <strong class="source-inline">KFoldDataset</strong> class for this purpose and its usage will be <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
size_t k = 30;
KFoldDataSet meta_train(scaled_train_input, train_labels, k);</pre>			<p>Here, we instantiated the <strong class="source-inline">meta_train</strong> dataset object for the 30-fold split. The following code snippet shows how the meta dataset can be generated using three <span class="No-Break">weak models:</span></p>
			<pre class="source-code">
for (size_t i = 0; i &lt; k; ++i) {
  auto [fold_train_inputs, fold_train_labels, fold_valid_inputs,
        fold_valid_labels] = meta_train.get_fold(i);
  arma::Row&lt;size_t&gt; predictions;
  auto [fold_train_inputs, fold_train_labels, fold_valid_inputs,
        fold_valid_labels] = meta_train.get_fold(i);
  arma::Row&lt;size_t&gt; predictions;
  arma::mat meta_feature;
  LinearSVM&lt;&gt; local_weak0;
  local_weak0.Train(fold_train_inputs, fold_train_labels,
                    num_classes);
  local_weak0.Classify(fold_valid_inputs, predictions);
  meta_feature = arma::join_cols(
      meta_feature,
      arma::conv_to&lt;arma::mat&gt;::from(predictions));
  SoftmaxRegression local_weak1(fold_train_inputs.n_cols,
                                num_classes);
  local_weak1.Train(fold_train_inputs, fold_train_labels,
                    num_classes);
  local_weak1.Classify(fold_valid_inputs, predictions);
  meta_feature = arma::join_cols(
      meta_feature,
      arma::conv_to&lt;arma::mat&gt;::from(predictions));
  DecisionTree&lt;&gt; local_weak2;
  local_weak2.Train(fold_train_inputs, fold_train_labels,
                    num_classes);
  local_weak2.Classify(fold_valid_inputs, predictions);
  meta_feature = arma::join_cols(
      meta_feature,
      arma::conv_to&lt;arma::mat&gt;::from(predictions));
  meta_train_inputs =
      arma::join_rows(meta_train_inputs, meta_feature);
  meta_train_labels =
      arma::join_rows(meta_train_labels, fold_valid_labels);
}</pre>			<p>The meta-dataset was stored in the <strong class="source-inline">meta_train_inputs</strong> and <strong class="source-inline">meta_train_labels</strong> matrix objects. Using the loop, we iterated the 30-fold indices and for each index, we called the <strong class="source-inline">get_fold</strong> method of the <strong class="source-inline">meta_train</strong> object. This call gave us the <em class="italic">k</em><span class="superscript">th</span> fold split, which contained the four matrices for the training and the evaluation. Then we trained the local <a id="_idIndexMarker1145"/>weak objects, which, in our case, were instances of the <strong class="source-inline">LinearSVM</strong>, <strong class="source-inline">SoftmaxRegression</strong>, and <strong class="source-inline">DecisionTree</strong> <span class="No-Break">class objects.</span></p>
			<p>For their training, we used the fold’s training inputs and labels. Having - trained weak models(the <strong class="source-inline">LinearSVM</strong>, <strong class="source-inline">SoftmaxRegression</strong>, and <strong class="source-inline">DecisionTree models</strong>), we evaluated them using the <strong class="source-inline">Classify</strong> method on the fold’s test input located in the <strong class="source-inline">fold_valid_input</strong> object. The <a id="_idIndexMarker1146"/>classification result was placed in the <strong class="source-inline">predictions</strong> object. All three classification results were stacked into the new <strong class="source-inline">meta_feature</strong> matrix object using the <strong class="source-inline">join_cols</strong> function. So, we replaced the original dataset features with new meta-features. This <strong class="source-inline">meta_feature</strong> object was added to the <strong class="source-inline">meta_train_inputs</strong> object using the <strong class="source-inline">join_rows</strong> method. The fold’s test labels located in <strong class="source-inline">fold_valid_labels</strong> were added to <a id="_idIndexMarker1147"/>the meta-dataset using the <strong class="source-inline">join_rows</strong> function on the <span class="No-Break"><strong class="source-inline">meta_train_labels</strong></span><span class="No-Break"> object.</span></p>
			<p>After the meta-dataset was created, we used the <strong class="source-inline">DecisionTree</strong> instance to train the meta-model <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
DecisionTree&lt;&gt; meta_model;
meta_model.Train(meta_train_inputs,
                 meta_train_labels,
                 num_classes);</pre>			<p>To be able to use this meta-model, we have to create a weak model again. It will be used to generate meta-input features for this meta-model. It can be done <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
LinearSVM&lt;&gt; weak0;
weak0.Train(scaled_train_input, train_labels, num_classes);
SoftmaxRegression weak1(scaled_train_input.n_cols, num_classes);
weak1.Train(scaled_train_input, train_labels, num_classes);
DecisionTree&lt;&gt; weak2;
weak2.Train(scaled_train_input, train_labels, num_classes);</pre>			<p>Here, we used the whole training dataset for training each of the <span class="No-Break">weak models.</span></p>
			<p>Having trained the ensemble, we can evaluate it on the test dataset. Since we used data preprocessing, we should also<a id="_idIndexMarker1148"/> transform our test data in the same way as we transformed our training data. We scale the testing data <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
arma::mat scaled_test_input(test_input.n_rows,
                            test_input.n_cols);
sample_scaler.Transform(test_input, scaled_test_input);</pre>			<p>The ensemble evaluation starts by predicting meta-features, using the weak models we trained before. We will store <a id="_idIndexMarker1149"/>predictions from every weak model in the <span class="No-Break">following objects:</span></p>
			<pre class="source-code">
arma::mat meta_eval_inputs;
arma::Row&lt;size_t&gt; meta_eval_labes;
The next code snippet shows how we get the meta-features from the weak models:
weak0.Classify(scaled_test_input, predictions);
meta_eval_inputs = arma::join_cols(meta_eval_inputs,
      arma::conv_to&lt;arma::mat&gt;::from(predictions));
weak1.Classify(scaled_test_input, predictions);
meta_eval_inputs = arma::join_cols(meta_eval_inputs,
      arma::conv_to&lt;arma::mat&gt;::from(predictions));
weak2.Classify(scaled_test_input, predictions);
meta_eval_inputs = arma::join_cols(meta_eval_inputs,
      arma::conv_to&lt;arma::mat&gt;::from(predictions));</pre>			<p>Here, we stacked predictions from each of the weak models into the <strong class="source-inline">meta_eval_inputs</strong> object as we did for the <span class="No-Break">meta-dataset creation.</span></p>
			<p>After we have created the meta-features, we<a id="_idIndexMarker1150"/> can pass them as input to the <strong class="source-inline">Classify</strong> method of the <strong class="source-inline">meta_model</strong> object to generate the real predictions. We can also calculate the accuracy, <span class="No-Break">like this:</span></p>
			<pre class="source-code">
Accuracy acc;
auto acc_value =
      acc.Evaluate(meta_model, meta_eval_inputs, test_labels);
std::cout &lt;&lt; "Stacking ensemble accuracy = " &lt;&lt; acc_value &lt;&lt; std::endl;</pre>			<p>The output of this code is <strong class="source-inline">Stacking ensemble accuracy = 0.985507</strong>. You can see that this ensemble<a id="_idIndexMarker1151"/> performs better than the random forest implementation, even with default settings. In the case of some additional tuning, it could give even <span class="No-Break">b<a id="_idTextAnchor532"/>e<a id="_idTextAnchor533"/>tter results.</span></p>
			<h1 id="_idParaDest-200"><a id="_idTextAnchor534"/>Summary</h1>
			<p>In this chapter, we examined various methods for constructing ensembles of machine learning algorithms. The main purposes of creating ensembles are to reduce the error of the elementary algorithms, expand the set of possible hypotheses, and increase the probability of reaching the global optimum <span class="No-Break">during optimization.</span></p>
			<p>We saw that there are three main approaches to building ensembles: training elementary algorithms on various datasets and averaging the errors (bagging), consistently improving the results of the previous, weaker algorithms (boosting), and learning the meta-algorithm from the results of elementary algorithms (stacking). Note that the methods of building ensembles that we’ve covered, except stacking, require that the elementary algorithms belong to the same class, and this is one of the main requirements for ensembles. It is also believed that boosting gives more accurate results than bagging but, at the same time, is more prone to overfitting. The main disadvantage of stacking is that it begins to significantly improve the results of elementary algorithms only with a relatively large number of <span class="No-Break">training samples.</span></p>
			<p>In the next chapter, we will discuss the fundamentals of <strong class="bold">artificial neural networks</strong> (<strong class="bold">ANNs</strong>). We’ll look at the historical aspect of their creation, go through the basic mathematical concepts used in ANNs, implement a <strong class="bold">multilayer perceptron</strong> (<strong class="bold">MLP</strong>) network and a simple <strong class="bold">convolutional neural network</strong> (<strong class="bold">CNN</strong>), and discuss what deep learning is and why it<a id="_idTextAnchor535"/> <a id="_idTextAnchor536"/>is <span class="No-Break">so trendy.</span></p>
			<h1 id="_idParaDest-201"><a id="_idTextAnchor537"/>Further reading</h1>
			<ul>
				<li><em class="italic">Ensemble methods: Bagging &amp; </em><span class="No-Break"><em class="italic">Boosting</em></span><span class="No-Break">: </span><a href="mailto:https://medium.com/@sainikhilesh/difference-between-bagging-and-boosting-f996253acd22"><span class="No-Break">https://medium.com/@sainikhilesh/difference-between-bagging-and-boosting-f996253acd22</span></a></li>
				<li><em class="italic">How to explain gradient </em><span class="No-Break"><em class="italic">boosting</em></span><span class="No-Break">: </span><a href="https://explained.ai/gradient-boosting/"><span class="No-Break">https://explained.ai/gradient-boosting/</span></a></li>
				<li>Original article by Jerome Friedman called <em class="italic">Greedy Function Approximation: A Gradient Boosting </em><span class="No-Break"><em class="italic">Machine</em></span><span class="No-Break">: </span><a href="https://jerryfriedman.su.domains/ftp/trebst.pdf"><span class="No-Break">https://jerryfriedman.su.domains/ftp/trebst.pdf</span></a></li>
				<li>Ensemble Learning to Improve Machine Learning <span class="No-Break">Results: </span><a href="https://www.kdnuggets.com/2017/09/ensemble-learning-improve-machine-learning-results.html"><span class="No-Break">https://www.kdnuggets.com/2017/09/ensemble-learning-improve-machine-learning-results.html</span></a></li>
				<li>Introduction to decision <span class="No-Break">trees: </span><a href="https://www.analyticsvidhya.com/blog/2021/08/decision-tree-algorithm/"><span class="No-Break">https://www.analyticsvidhya.com/blog/2021/08/decision-tree-algorithm/</span></a></li>
				<li>How to visualize decision <span class="No-Break">trees: </span><a href="https://explained.ai/decision-tree-viz/"><span class="No-Break">https://explained.ai/decision-tree-viz/</span></a></li>
				<li><em class="italic">Understanding Random </em><span class="No-Break"><em class="italic">Forest</em></span><span class="No-Break">: </span><a href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2"><span class="No-Break">https://towardsdatascience.com/understanding-random-forest-58381e0602d2</span></a></li>
			</ul>
		</div>
	

		<div class="Content" id="_idContainer761">
			<h1 id="_idParaDest-202" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor538"/>Part 3: Advanced Examples</h1>
			<p>In this part, we’ll describe what neural networks are and how they can be applied to solving image classification tasks. We’ll also describe what modern <strong class="bold">large language models</strong> (<strong class="bold">LLMs</strong>) are and how they assist in solving neural processing tasks such as <span class="No-Break">sentiment analysis.</span></p>
			<p>This part comprises the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B19849_10.xhtml#_idTextAnchor539"><em class="italic">Chapter 10</em></a>, <em class="italic">Neural Networks for Image Classification</em></li>
				<li><a href="B19849_11.xhtml#_idTextAnchor642"><em class="italic">Chapter 11</em></a>, <em class="italic">Sentiment Analysis with BERT and Transfer Learning</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer762">
			</div>
		</div>
		<div>
			<div class="Basic-Graphics-Frame" id="_idContainer763">
			</div>
		</div>
	</body></html>