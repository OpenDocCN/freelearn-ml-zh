- en: Implementing Unsupervised Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](b2822c69-13f0-4943-9e66-f9ef04898b60.xhtml), *Supervised Machine
    Learning Models for Your Data*, we focused on *supervised* machine learning algorithms.
    This chapter will build on the previous chapters in that we will continue the
    tour of the machine learning paradigm offered in IBM Cloud. The chapter will cover
    **supervised** versus **unsupervised** as well as **semi-supervised** learning.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning problems are usually categorized into **regression** and
    **classification** problems, and we saw the ways that using IBM Watson Studio
    and its model builder feature can help solve for those sort of problems.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning, on the other hand, allows us to approach problems when
    we might have little or no idea what the results should or would look like. Here,
    in these types of problems, we can attempt to derive structure from the data itself
    by **clustering** (the data) based upon relationships identified among the variables
    within the data, even if we don't necessarily know the effect of those variables.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will focus on the concept of unsupervised machine learning and
    its related topics.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, this chapter will discuss some common clustering algorithms. And finally,
    this chapter will conclude by discussing online versus batch learning concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will divide this chapter into the following areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomaly detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online and/or batch learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in the last chapter, supervised learning is the machine learning
    process of leveraging a function that maps an input to an output based on example
    input-output pairs, inferring a function from labeled training data comprising
    a set of training samples.
  prefs: []
  type: TYPE_NORMAL
- en: Again, in the last chapter, we saw how, when using the model builder, we could
    set a **label column** for a predictive model to predict. Recall that, in one
    example, we chose the column `IS_TENT` from within the training data for the model
    to predict.
  prefs: []
  type: TYPE_NORMAL
- en: Now, in this section of this chapter, we want to examine scenarios where we
    have no label data defined in our data, or in other words, unsupervised learning
    problems. To reiterate, in these cases, we have no feedback (or label) based on
    the prior prediction results available; we expect to solve these cases without
    indicating or setting a desired label.
  prefs: []
  type: TYPE_NORMAL
- en: 'To further understand what unsupervised learning really is, you can head on
    to the following link: [https://www.datasciencecentral.com/profiles/blogs/what-is-unsupervised-learning](https://www.datasciencecentral.com/profiles/blogs/what-is-unsupervised-learning).'
  prefs: []
  type: TYPE_NORMAL
- en: Why not always use supervised learning (and labeled data)? To understand why
    you might find yourself using an unsupervised learning model, consider the fact
    that it is usually easier to find unlabeled data (it's cheaper), and polishing
    unlabeled data and adding labels typically requires subject matter experts and
    can be a complex process in itself.
  prefs: []
  type: TYPE_NORMAL
- en: One way to accomplish the goal of unsupervised learning is through the use of
    a **clustering** algorithm. Clustering uses only data to determine patterns, anomalies
    (more on anomalies in a later section of this chapter), or similarities in the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering organizes data by identifying data that is similar within different
    clusters as well as data that isn’t similar across clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering is popular within the field of statistical data analysis as different
    clusters expose different details about the objects within data, which is different
    from classification or regression, where you have some previous information on
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: A popular type of clustering algorithm is the **K-means clustering algorithm**.
    This algorithm is used to classify or to group objects based on attributes or
    features into *K number of groups* (indicating how the methodology got its name).
  prefs: []
  type: TYPE_NORMAL
- en: In this method, *K* will be a positive integer number and is simply the number
    of clusters or distinct groups the data is classified into, without the use of
    a labeled or target field. K-means tries to uncover patterns in the set of input
    fields within data rather than predicting an outcome.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section of this chapter, we will look at a working example showing
    the use of the K-means algorithm to create clusters from data in Watson Studio
    in an effort to produce a prediction, without having knowledge of what the predictor(s)
    may be.
  prefs: []
  type: TYPE_NORMAL
- en: Watson Studio, machine learning flows, and KMeans
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **flow** editor in Watson Studio presents a very cool graphical view of
    a model while you build it by combining various types of nodes representing objects
    or actions. The flow editor has three palettes that you can choose from: SPSS
    modeler nodes, Spark ML algorithm nodes, and neural network nodes. In this example,
    we’ll create an SPSS modeler flow.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: SPSS is the abbreviation of Statistical Package for Social Sciences and
    it is used by researchers to perform statistical analysis. The technology was
    acquired by IBM in 2009\. The current versions (2015) are named IBM SPSS Statistics.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By now, we know that you need to create a Watson project and include or add
    data to it. Since we've gone through this before, we'll skip over that and get
    into how to use the Flow Editor offered by Watson Studio.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an SPSS modeler flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create an SPSS modeler flow by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create an SPSS modeler flow, first we must go to Add to project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/693eab51-d2e8-45a8-9000-1c088f0408e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can then use the Assets tab (as shown in the following screenshot) and click
    on the Modeler Flow icon:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e43eb739-0249-4293-925a-207f05fc6e0b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, type a name and description for the flow and select the IBM SPSS Modeler
    runtime (on the lower left) then click on the Create button (on the lower right):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/251d4418-da71-40cb-bb44-e6f3f1602735.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we are ready to create our machine learning modeler flow using the following
    flow editor canvas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/03dbf455-29bc-4921-8890-c727174accd5.png)'
  prefs: []
  type: TYPE_IMG
- en: The flow editor palette empowers you to use machine learning, **artificial intelligence**
    (**AI**), and statistics modeling methods to derive new information from your
    data without the need for programming.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are ready to add our data, so we can drag a Data Asset node (found under
    Import) onto the canvas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2f52b91f-0a80-4aba-95bb-2879ad96f64d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once you have a Data Asset node, you can double-click it, select Change data
    asset, select your preferred (training) file, and then click on OK. If you now
    right-click on the node, you can select Preview (shown in the following screenshot)
    to see your data (in read-only mode):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/84e94674-ce77-45cc-8188-9754a007c86b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To generate a profile of the data, you can add the Data Audit node (found under
    Outputs) by dragging it onto the canvas, connecting it to the Data Asset node
    and then clicking the VCR-type run icon:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/517e21d5-f22c-4930-8fd9-8e21590fe566.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can see that the Data Audit node shows 25 Fields that it automatically
    found in the Data Asset node. Again, if you double-click on the Data Audit node,
    you''ll be able to view and update various parameters, such as a name for the
    node (you can have multiple Data Audit nodes in a flow), as well as what to include
    in the output summarizations (graphs, basic and/or advanced statistics, and so
    on):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/290867bf-f4d4-4d6a-b05e-e88b9019356f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The outputs from the Data Audit node provides a detailed profile of your data.
    You can change parameters, rerun your flow, and recheck the results to become
    comfortable with the outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b6a151b-d87d-4bdb-a39c-9f585f9dbc59.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The bottom page of the preceding screenshot is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/03b2d648-f414-4b76-a458-fcea94ac4327.png)'
  prefs: []
  type: TYPE_IMG
- en: Additional node work
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before moving onto actually building a classification model, it should be noted
    that there are numerous nodes available on the pallet to help with or actually
    perform almost any operation or process that you need to perform without having
    to code anything!
  prefs: []
  type: TYPE_NORMAL
- en: 'If you take a moment to look over on the left-hand side panel (called the Nodes
    Palette), you''ll see different types of nodes available for you to use while
    working on your data. These nodes are organized into the following six basic categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Record operations**: This can be used to perform operations such as selecting,
    appending, and sorting on the record (row) level.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Field operations**: These nodes are helpful in the data preparation phase.
    You can filter data, rename features, and choose the type of your attributes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graphs**: Nodes in this section will help you with basic data exploration
    and understanding distribution or relationship between features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modeling**: These nodes provide different modeling algorithms for different
    types of problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outputs**: These nodes are helpful in understanding your data and model.
    You can display results in table format or get a report on evaluation parameters
    of your model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Export**: After processing and modeling, this node will help you export data
    from the flow editor to your DSX project**.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s try one out. They all are implemented in pretty much the same way: drag
    and drop the selected node on to the canvas and right-click to take further actions
    such as open, preview, or run.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s look at the Filter node found under Field Operations. The
    following screenshot shows the Filter node added to the canvas and connected to
    our Data Asset node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/41ee05d2-fbe6-4732-bab0-0931827f6cb9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can use the Filter node to rename columns, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d6e38972-e908-4acc-8830-f0927574ca14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also filter out or retain only selected fields of data from your original
    Data Asset node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/767fd991-6319-4c5b-9ea8-77aaadcba84d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once you are happy with your data, you can set a variable to be the model''s
    Target variable using the Type node. This will help the model to distinguish between
    input and target features. For example, you can do the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Drag and drop the Type node on the canvas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the Type node to the Filter node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click on the Type node and click on Open to open the node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on Read Values, then select the column name class and change the role
    of the variable to Target, and finally click on Save:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e183188a-7fe1-4af8-a419-be28b7cc024f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To see what the distribution of the Target variable (ours is set to class)
    is, you can use the Distribution node (from the Graphs section of the node palette).
    Again, just drag the node onto the canvas and open and provide information such
    as Plot (select the class field under Field (discrete)) and under Color (discrete)
    (use class) and click on Save. After you run the flow, the output looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1dabfba2-769f-4da0-82fb-c2749a6e9f44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this data, we see that there are more **cronic cases** (**ckd**) than **non-cronic
    cases** (**notckd**). This is our current flow displayed on the canvas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47f1ec63-39ef-4726-99c9-e650f255e43b.png)'
  prefs: []
  type: TYPE_IMG
- en: Training and testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another useful function in the SPSS modeler flow is the ability to easily divide
    data into training and testing sets. This can be accomplished using the Partition
    node. To train, test, and validate the stages of model building, the Partition
    nodes are used to produce a partition field that splits the data into separate
    subsets or samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a sample to generate the model and a separate sample to test it will
    get you a good hint of how well the model will generalize to larger datasets that
    are corresponding to the current data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/718bbbbb-f139-4cec-97ae-a25511cce565.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we add a Partition node to our flow, open it and adjust the settings as
    shown in the preceding screenshot, we are instructing the modeler to add a new
    field (`PartionMyData`) to our data, which will designate the record split (based
    upon 75/25). To see the results of this node, we can add a Table node to the flow
    and provide the following settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/568be8c2-b10a-4547-b80a-2b6f94d56002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding screenshot indicates that we want to query our data and generate
    a table based upon the values in our derived field that are equal to `1_Training`;
    in other words, all of the records that the Partition node has designated as members
    of our training data. Our flow now looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/af998dba-cfb7-4451-9fc7-1b2f6889ede2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Running the flow now generates the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c8a6fecf-a939-4dd3-a48f-2e1ed40d7279.png)'
  prefs: []
  type: TYPE_IMG
- en: SPSS flow and K-means
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned earlier in this chapter, a popular type of clustering algorithm
    is the **K-means clustering** algorithm**.** Again, without the use of a labeled
    or target field, rather than trying to predict an outcome, K-means tries to uncover
    patterns and find structure in the data, by grouping and/or clustering data points
    in the set of input fields within data.
  prefs: []
  type: TYPE_NORMAL
- en: Using the sample data that we have been working with in this chapter, let's
    say that we don't know whether a person has chronic kidney disease or not and
    would like to use the K-means algorithm to build an unsupervised model to see
    whether we can identify any pattern for chronic kidney disease.
  prefs: []
  type: TYPE_NORMAL
- en: We'll choose the K-Means node in our flow to accomplish this task.
  prefs: []
  type: TYPE_NORMAL
- en: 'The K-Means node offers a method of cluster analysis which you can refer to
    *Chapter 11* in the documentation of IBM SPSS Modeller 15 from the following link:
    [http://public.dhe.ibm.com/software/analytics/spss/documentation/modeler/15.0/en/ModelingNodes.pdf](http://public.dhe.ibm.com/software/analytics/spss/documentation/modeler/15.0/en/ModelingNodes.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following steps to learn how to learn about the K-means
    algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: From the left, under Modeling, we can select the K-Means node and drop it onto
    the canvas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, connect the node to the Type node as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/14313503-6087-452e-87e0-c8b248bc9693.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that I have disconnected the Partition node that we used earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have added the K-Class node, right-click and open it to change its
    settings (on the right-hand side of the canvas). Specifically, under BUILD OPTIONS,
    we''ll set Number of clusters to `2` based upon the idea that we would want to
    organize our data into two groups (or clusters): those with chronic kidney disease
    and those who do not have chronic kidney disease. All of the other settings can
    remain defaults. Finally, click on Save.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, after you run the flow, a golden K-Means node will appear (shown in the
    following screenshot) on which you can right-click and select View Model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c935f58c-959e-47c0-937b-a30726038fab.png)'
  prefs: []
  type: TYPE_IMG
- en: 'SPSS visualizations offer interactive tables and charts to help evaluate a
    predictive model. These visualizations provide a single all-inclusive set of output
    so that you don''t need to create multiple charts and tables to determine the
    model’s performance. Depending on the algorithm, you''ll see a set of visualizations
    that are related to your specific data set and model. The following is the output
    from our K-means model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9f3de051-6746-40b7-aa9f-d2c59f63f00b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The output includes information on Cluster Quality (shown in the preceding
    screenshot) as well as Predictor Importance (shown in the following screenshot):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66e65a16-fde7-43fd-aadc-1eb9a3a5ceff.png)**Cluster Quality Evaluation**
    is a complex subject and is beyond the scope of this chapter, however IBM Watson
    Studio provides the typical Cluster Quality details such as the Cluster Sizes
    Chart which is a horizontal bar chart displaying the relative sizes of the clustering
    in descending order. Hovering over a bar shows the precise percentage of the total
    number of instances in that cluster based on the K-Means model. All of the clustering
    information should be reviewed and evaluated in respect to various project options
    and outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'And finally (although there are other informational visualizations generated),
    it shows the basic Model Information (as shown below):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8eff363e-59fb-4cde-b052-d0290948b17f.png)'
  prefs: []
  type: TYPE_IMG
- en: An awesome feature of the SPSS modeler flow is that you can build multiple,
    different models within the same canvas!
  prefs: []
  type: TYPE_NORMAL
- en: It is literally so easily to make changes to the nodes, rerun (the flow), and
    then re-evaluate the results to determine the best algorithm and parameters, that
    you should just assume multiple iterations as part of the process.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting model results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once you are comfortable with your model, you can export the results using
    another handy node named the Data Asset Export node. As with other nodes, you
    can drag and drop it onto the canvas, connect it to the golden K-Means node and
    open it to edit its settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4ba6ab73-1f13-4829-ab50-32b6eb96e28e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For the node settings, all you really need to do is type a name to your file
    (I have typed `Lovely`) under the Target path section in the Data Asset Export
    settings as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0163c418-6f68-487b-9205-d29134184718.png)'
  prefs: []
  type: TYPE_IMG
- en: You might also select Replace the data set as the option under the If the data
    set already exists* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, when you run the flow, the data will be exported to your project storage,
    where you can see and access it from the Assets tab in the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/504757ca-596c-4a51-a608-5e03c300114a.png)'
  prefs: []
  type: TYPE_IMG
- en: Semi-supervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Semi-supervised** learning is another class of machine learning process and
    technique that also makes use of unlabeled data for training (as does unsupervised
    learning) but, typically, a small amount of labeled data with a large amount of
    unlabeled data is present and used by the model. This is usually referred to as
    **partly labeled data**.'
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning falls somewhere between unsupervised learning (without
    any labeled training data) and supervised learning (with completely labeled training
    data).
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning programs do attempt to use certain standard assumptions
    to help them make use of unlabeled data. These standard assumptions are continuity,
    cluster, and manifold.
  prefs: []
  type: TYPE_NORMAL
- en: 'Without going too deep into describing these assumptions, loose definitions
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Continuity**: This assumption implies that close data points also tends to
    share a label.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster**: This assumption says that the data that tends to form discrete
    clusters, and points in the same cluster end up sharing a label.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manifold**: This assumption assumes that the data lies approximately on what
    is referred to as a manifold of much lower dimensionality than the original data,
    and with this assumption, there is an attempt to understand the manifold using
    both labeled and unlabeled data to reduce dimensionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomaly detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Anomalies** also referred to as outliers, novelties, noise, deviations, and
    exceptions are typically defined as the identification of rare items, events,
    or observations within a pool or set of data that raise suspicions by differing
    significantly from the majority of the data.'
  prefs: []
  type: TYPE_NORMAL
- en: Why should so much importance be placed on anomalies and their detection?
  prefs: []
  type: TYPE_NORMAL
- en: Because anomalies in data will almost always translate to some kind of problem,
    such as fraud, a defect, medical problems, or errors in a text.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection is a technique used to recognize unusual patterns that do
    not conform to expected behavior, called **outliers**. In order to locate anomalies,
    you need to understand that can fall into several broad categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, we consider anomalies to be either point, contextual, or collective
    in nature. Point anomalies are what you may guess: a single point of data that
    is very different from the rest. Contextual anomalies are when seemingly good
    data is only good within a certain context. Collective anomalies are where you
    consider data in a collective set an anomaly.'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning based approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Of course, there are a number of generally accepted machine learning based
    approaches to the process of anomaly detection. These currently include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Density-based anomaly detection**:This approach is based on the KNN algorithm;
    the nearest set of data points are evaluated using a scoring method dependent
    on the type of the data (categorical or numerical).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustering-based anomaly detection**: One of the most desired concepts in
    the domain of unsupervised learning for anomaly detection is Clustering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Support vector machine based anomaly detection**:This algorithm uses a training
    set to learn soft boundaries in order to cluster the normal data instances then,
    using the testing instance, it calibrates itself to locate the abnormalities that
    fall outside the learned region.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online or batch learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Think of online and batch machine learning concepts as basically the difference
    between performing multiple iterations of updating predictor values from new chunks
    of data compared to churning through all of the available data first, and then
    setting the predictor values:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Online machine learning: This is a technique of machine learning where data
    are made available in sequential order and is used to streamline the best predictor
    for future data at each step or iteration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Batch learning: Batch machine learning is a method that will generate the best
    predictor by learning on the entire training dataset at once.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started out by providing brief descriptions of unsupervised
    learning, semi-supervised learning, anomaly detection, and finally online and
    batch learning.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will use Python as the programming language on notebooks
    that we will learn to create. We will also learn how to create various machine
    learning projects with Watson Studio.
  prefs: []
  type: TYPE_NORMAL
