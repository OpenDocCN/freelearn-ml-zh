["```py\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport numpy as np\nmu, sigma = 0, 1.1\nnormally_distributed = np.random.normal(mu, sigma, 1000)\n```", "```py\nfrom scipy import stats\nimport numpy as np\nmu, sigma = 0, 1\nnormally_distributed = np.random.normal(mu, sigma, 1000)\n```", "```py\nstats.kstest(normally_distributed,\n             stats.norm.cdf)\n```", "```py\nstats.kstest(np.exp(normally_distributed), stats.norm.cdf)\n```", "```py\nmu, sigma = 100, 2\nnormally_distributed = np.random.normal(mu, sigma, 1000)\nnormally_distributed_scaled = (\n    normally_distributed-normally_distributed.mean()) /\n    normally_distributed.std()\n```", "```py\nstats.kstest(normally_distributed_scaled, stats.norm.cdf)\n```", "```py\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nmu, sigma = 19, 1.7\nnormally_distributed = np.random.normal(mu, sigma, 1000)\nnot_normally_distributed = np.exp(normally_distributed);\n```", "```py\nfrom scipy import stats\nimport pandas as pd\nimport numpy as np\ndef anderson_test(data):\ndata = np.array(data)\n    test_statistic, critical_values, significance_levels = stats.anderson(normally_distributed, dist='norm')\n    df_anderson = pd.DataFrame({'Test Statistic':np.repeat(test_statistic, len(critical_values)), 'Critical Value':critical_values, 'Significance Level': significance_levels})\ndf_anderson.loc[df_anderson['Test Statistic'] >= df_anderson['Critical Value'], 'Normally Distributed'] = 'No'\n    df_anderson.loc[df_anderson['Test Statistic'] <df_anderson['Critical Value'], 'Normally Distributed'] = 'Yes'\n    return df_anderson;\nmu, sigma = 19, 1.7\nnormally_distributed = np.random.normal(mu, sigma, 1000)\nanderson_test(normally_distributed)\n```", "```py\nnot_normally_distributed = np.exp(normally_distributed)\nanderson_test(not_normally_distributed)\n```", "```py\nmu, sigma = 19, 1.7\nnormally_distributed = np.random.normal(mu, sigma, 1000)\nstats.shapiro(normally_distributed)\n```", "```py\nnot_normally_distributed = np.exp(normally_distributed)\nstats.shapiro(not_normally_distributed)\n```", "```py\nfrom statsmodels.stats.stattools import durbin_watson\nimport matplotlib.pyplot as plt\nimport numpy as np\nmu, sigma = 0, 1.1\nindependent_samples = np.random.normal(mu, sigma, 1000)\ncorrelated_samples = np.linspace(-np.pi, np.pi, num=1000)\nfig, ax = plt.subplots(1,2, figsize=(10,5))\nax[0].plot(correlated_samples, np.sin(correlated_samples))\nax[0].set_title('Durbin Watson = {}'.format(\n    durbin_watson(correlated_samples)))\nax[1].plot(independent_samples)\nax[1].set_title('Durbin Watson = {}'.format(\n    durbin_watson(independent_samples)))\n```", "```py\nfrom scipy.stats import levene\nnp.random.seed(26)\nmu1, sigma1, mu2, sigma2, mu3, sigma3 = 0,0.9,0,1.1,0,2\ndistro1, distro2, distro3 = pd.DataFrame(), pd.DataFrame(),\n    pd.DataFrame()\ndistro1['x'] = np.random.normal(mu1, sigma1, 100)\ndistro2['x'] = np.random.normal(mu2, sigma2, 100)\ndistro3['x'] = np.random.normal(mu3, sigma3, 100)\n```", "```py\nf_statistic, p_value = levene(distro1['x'], distro2['x'], distro3['x'])\nif p_value <= 0.05:\n    print('The distributions do not have homogenous variance. P-value = %.4f, F-statistic = %.4f'%(p_value, f_statistic))\nelse:\n    print('The distributions have homogenous variance.P-value = %.4f, F-statistic = %.4f'%(p_value, f_statistic))\n```", "```py\nfrom scipy.stats import f\ndef f_test(inputA, inputB):\n    group1 = np.array(inputA)\n    group2 = np.array(inputB)\n    if np.var(group1) > np.var(group2):\n        f_statistic = np.var(group1) / np.var(group2)\n        numeratorDegreesOfFreedom = group1.shape[0] - 1\n        denominatorDegreesOfFreedom = group2.shape[0] - 1\n    else:\n        f_statistic = np.var(group2)/np.var(group1)\n        numeratorDegreesOfFreedom = group2.shape[0] - 1\n        denominatorDegreesOfFreedom = group1.shape[0] - 1\n    p_value = 1 - f.cdf(f_statistic,numeratorDegreesOfFreedom, denominatorDegreesOfFreedom)\n    if p_value <= 0.05:\nprint('The distributions do not have homogenous variance. P-value = %.4f, F-statistic = %.4f'%(p_value, f_statistic))\n    else:\n        print('The distributions have homogenous variance. P-value = %.4f, F-statistic = %.4f'%(p_value, f_statistic))\nf_test(distro3['x'], distro1['x'])\n```", "```py\n# libraries\nimport numpy as np\nimport scipy.stats as stats\n# creating normal distribution\nx =np.linspace(-5, 5, 1000) #create 1000 point from -5 to 5\ny = stats.norm.pdf(x) # create probability density for each point x  - normal distribution\n# creating Student t distributions for 2 sample sizes n =3 and n =15\ndegree_freedom1 = 2\nt_dis1 = stats.t.pdf(x, degree_freedom1)\ndegree_freedom2 = 15\nt_dis2 = stats.t.pdf(x, degree_freedom2)\n```", "```py\nscipy.stats.t.sf(abs(x), df)\n```", "```py\nimport scipy.stats\nround(scipy.stats.t.sf(abs(1.9), df=14),4)\n```", "```py\nscipy.stats.t.sf(abs(t), df)*2\n```", "```py\nscipy.stats.t.ppf(q, df)\n```", "```py\nimport scipy.stats as stats\nalpha = 0.05 # level of significance\ndf= 15 # degree of freedom\n#find t critical value for left-tailed test\nprint(f\" The critical value is {stats.t.ppf(q= alpha, df =df)}\")\n#find t critical value for right-tailed test\nprint(f\" The critical value is {stats.t.ppf(q= 1-alpha, df =df)}\")\n##find t critical value for two-tailed test\nprint(f\" The critical values are {-stats.t.ppf(q= 1-alpha/2, df =df)} and {stats.t.ppf(q= 1-alpha/2, df =df)}\")\n```", "```py\nIQscores = [113, 107, 106, 115, 103, 103, 107, 102, 108, 107, 104, 104, 99, 102, 102, 105, 109, 97, 109, 103, 103, 100, 97, 107,116, 117, 105, 107, 104, 107]\n```", "```py\nscipy.stats.ttest_1samp(data, popmean, alternative='greater')\n```", "```py\nimport scipy.stats as stats\n#perform one sample t-test\nt_statistic, p_value = stats.ttest_1samp(IQscores, popmean =100, axis=0,  alternative='greater')\nprint(f\"The test statistic is {t_statistic} and the corresponding p-value is {p_value}.\")\n```", "```py\nIQmean = np.array(IQscores).mean() # sample mean\nIQsd = np.array(IQscores).std() # sample standard deviation\nsample_size = len(np.array(IQscores)) # sample size\ndf = sample_size-1 # degree of freedom\nalpha = 0.05 # level of significance\nt_crit = stats.t.ppf(q=1-alpha, df =df) # critical\nconfidence_interval = (IQmean-IQsd*t_crit/np.sqrt(sample_size), IQmean+IQsd*t_crit/np.sqrt(sample_size))\n```", "```py\nIQscoresA=[113, 107, 106, 115, 103, 103, 107, 102,108, 107,\n            104, 104, 99, 102, 102, 105, 109, 97, 109, 103,\n            103, 100, 97, 107, 116, 117, 105, 107, 104, 107]\nIQscoresB = [102, 108, 110, 101, 98, 98, 97, 102, 102, 103,\n             100, 99, 97, 97, 94, 100, 104, 98, 92, 104,\n            98, 95, 92, 111, 102, 112, 100, 103, 103, 100]\n```", "```py\n# F-test\nimport numpy as np\nimport scipy.stats as stats\nIQscoresA = np.array(IQscoresA)\nIQscoresB = np.array(IQscoresB)\nf = np.var(IQscoresA, ddof=1)/np.var(IQscoresB, ddof=1) # F statistic\ndfA = IQscoresA.size-1 #degrees of freedom A\ndfB = IQscoresB.size-1 #degrees of freedom B\np = 1-stats.f.cdf(f, dfA, dfB) #p-value\n```", "```py\nfrom statsmodels.stats.weightstats import ttest_ind as ttest\nt_statistic, p_value, degree_freedom = ttest(IQscoresA,\n    IQscoresB, alternative='two-sided', usevar='pooled')\n```", "```py\nsample1 = np.array([2,3,4,2,3,4,2,3,5,8,7,10])\nsample2 = np.array([30,26,32,34,28,29,31,35,36,33,32,27])\n```", "```py\nimport scipy.stats as stats\nt_statistic, p_value = stats.ttest_ind(sample1, sample2,\n    equal_var = False)\n```", "```py\nfrom scipy import stats\nIQ_pre = [95, 98, 90, 115, 112]\nIQ_pos = [95, 110, 97, 112, 117]\nt_statistic, p_value = stats.ttest_rel(IQ_pos, IQ_pre, alternative = 'greater')\n```", "```py\nanova = anova_oneway(data.mpg, data.origin, use_var='equal')\nprint(anova)\n# statistic = 98.54179491075868\n# pvalue = 1.915486418412936e-35\n```", "```py\nfrom scipy.stats import pearsonr\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nmu1, sigma1 = 0, 1.1\nnormally_distributed_1 = np.random.normal(mu1, sigma1, 1000)\nmu2, sigma2 = 0, 0.7\nnormally_distributed_2 = np.random.normal(mu2, sigma2,\n    1000)\ndf_norm = pd.DataFrame({'Distribution':['Distribution 1' for i in range(len(normally_distributed_1))] + ['Distribution 2' for i in range(len(normally_distributed_2))], 'X':np.concatenate([normally_distributed_1, normally_distributed_2])})\n```", "```py\np, r = pearsonr(df_norm.loc[df_norm['Distribution'] == 'Distribution 1', 'X'], df_norm.loc[df_norm['Distribution'] == 'Distribution 2', 'X'])\nprint(\"p-value = %.4f\"%p)\nprint(\"Correlation coefficient = %.4f\"%r)\n```", "```py\nimport statsmodels.api as sm\ndf_cars = sm.datasets.get_rdataset(\"mtcars\",\"datasets\").data\n```", "```py\nsns.set_theme(style=\"white\")\ncorr = df_cars.corr()\nf, ax = plt.subplots(figsize=(15, 10))\ncmap = sns.diverging_palette(250, 20, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, vmax=.4, center=0,\n            square=True, linewidths=.5, annot=True)\n```", "```py\nfrom statsmodels.stats.power import TTestPower\nimport numpy as np\n# Difference of distribution mean and the value to be assessed divided by the distribution standard deviation\neffect_size = abs(100000-90000) / 2800\npowersTT = TTestPower()\nresult = powersTT.solve_power(effect_size, nobs=3, alpha=0.05, alternative='two-sided')\nprint('Power based on sample size:{}'.format(round(result,2)))\n# Power based on sample size: 0.85\n```"]