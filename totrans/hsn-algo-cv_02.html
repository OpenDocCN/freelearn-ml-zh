<html><head></head><body>
        

                            
                    <h1 class="header-title" id="calibre_pb_0">Getting Started with OpenCV</h1>
                
            
            
                
<p class="calibre2">In the previous chapter, we were presented with an introduction to computer vision, with some examples of the industries that use it extensively to improve their services and products. Then, we learned about the most basic concepts used in this field, such as images and pixels. We learned about color spaces and finished the chapter with a brief discussion of computer vision libraries and frameworks. We're going to continue from where we left off, which is with introducing you to one of the most powerful and widely used computer vision libraries, called <strong class="calibre4">OpenCV</strong>.</p>
<p class="calibre2">OpenCV is a huge collection of classes, functions, modules, and other related resources used to build cross-platform computer vision applications. In this chapter, we will learn about the structure of OpenCV, the modules that it contains and their purposes, and the programming languages that it supports. We will learn how and where to get OpenCV and briefly go through the possible tools you can use to build applications with it. Then, we'll learn how to use the power of CMake to easily create projects that use OpenCV. Even though this means that our main focus will be on C++ classes and functions, we'll also cover Python equivalents of them wherever it makes sense so that developers familiar with both languages can follow the topics that are presented here in this chapter.</p>
<p class="calibre2">After learning about the initial stages of using the OpenCV library, we'll move on to learn about the <kbd class="calibre13">Mat</kbd> class. We'll see how all of the concepts that we covered in the previous chapter about images are embedded into the structure of the <kbd class="calibre13">Mat</kbd> class in OpenCV. We'll also talk about the various other classes that are compatible with (or closely related to) the <kbd class="calibre13">Mat</kbd> class. OpenCV's method of handling input and output parameters in its functions is a very important subject that we'll be covering in the later sections of this chapter. Finally, we'll learn how OpenCV is used to apply the three steps of input, process, and output in computer vision applications. This will require learning about accessing (and writing into) images and video files using OpenCV.</p>
<p class="calibre2">This chapter, as a direct connection to the previous introductory chapter, will lay out the foundations of learning computer vision algorithms using hands-on and practical examples.</p>
<p class="calibre2">In this chapter, we'll look at the following:</p>
<ul class="calibre10">
<li class="calibre11">What OpenCV is, where to get it, and how to use it?</li>
<li class="calibre11">How to use CMake to create OpenCV projects?</li>
<li class="calibre11">Understanding the <kbd class="calibre13">Mat</kbd> class and how it is used to access pixels</li>
<li class="calibre11">How to use the <kbd class="calibre13">Mat_</kbd>, <kbd class="calibre13">Matx</kbd>, and <kbd class="calibre13">UMat</kbd> classes?</li>
<li class="calibre11">How to use the <kbd class="calibre13">imread</kbd> and <kbd class="calibre13">imwrite</kbd> functions to read and write images?</li>
<li class="calibre11">How to use the <kbd class="calibre13">VideoCapture</kbd> and <kbd class="calibre13">VideoWriter</kbd> classes to read and write videos?</li>
<li class="calibre11">How to access cameras and video feeds from a network (using <strong class="calibre1">Real Time Streaming Protocol</strong> (<strong class="calibre1">RTSP</strong>))?</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Technical requirements</h1>
                
            
            
                
<ul class="calibre10">
<li class="calibre11">Microsoft Visual Studio, Xcode, or any IDE that can be used to develop C++ programs</li>
<li class="calibre11">Visual Studio Code or any other code editor that can be used to edit CMake files, Python source files, and so on</li>
<li class="calibre11">Python 3.X</li>
<li class="calibre11">CMake 3.X</li>
<li class="calibre11">OpenCV 3.X</li>
</ul>
<p>It is always best to try to use a more recent version of the technologies and software that you are trying to learn. The topics covered in this book, and computer vision in general, are no exception, so make sure to download and install the latest versions of the mentioned software.</p>
<p class="calibre2">Wherever necessary, a brief set of instructions are provided for the installation and configuration. You can use the following URL to download the source codes and examples for this chapter:</p>
<p class="calibre2"><a href="https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter02" class="calibre9">https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter02</a></p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Introduction to OpenCV</h1>
                
            
            
                
<p class="calibre2"><strong class="calibre4">OpenCV</strong>, or <strong class="calibre4">Open Source Computer Vision</strong>, is a set of libraries, tools, and modules that contain classes and functions required for building computer vision applications. Downloaded millions of times by computer vision developers around the world, the OpenCV library is fast and optimized to be used in real-life projects (including commercial). As of the time of writing this book, the most recent version of OpenCV is 3.4.1, which is also the version we'll be using in all of the examples in this book. OpenCV supports the C/C++, Python, and Java languages, and it can be used to build computer vision applications for desktop and mobile operating systems alike, including Windows, Linux, macOS, Android, and iOS.</p>
<p>It's important to note that the OpenCV library and OpenCV framework are both used to refer to OpenCV, and in the computer vision community the terms are used interchangeably most of the time. For the same reason, we will also use the terms interchangeably throughout this book. However, strictly speaking, framework is usually the term that is used to refer to sets of related libraries and tools working toward achieving a common goal, such as OpenCV.</p>
<p class="calibre2">OpenCV consists of the following two types of modules:</p>
<ul class="calibre10">
<li class="calibre11"><strong class="calibre1">Main modules</strong>: These modules are included in OpenCV release versions by default, and they contain all of the core OpenCV functionality along with modules that are used for image-processing tasks, filtering, transformation, and many more capabilities that we'll talk about in this section.</li>
<li class="calibre11"><strong class="calibre1">Extra modules</strong>: These modules include all of the OpenCV functionalities that are not included in the OpenCV library by default and they mostly include additional computer vision-related functionalities. For instance, the Extra modules include libraries used for text recognition and non-free feature detectors. Note that our focus will be on the Main module and covering the functionalities included in it but, wherever it might be helpful, we'll try to also refer to possible options in the extra modules for you to research on your own.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">The Main modules in OpenCV</h1>
                
            
            
                
<p class="calibre2">As mentioned, OpenCV contains a number of Main modules that contain all of its core and default functionalities. Here is a list of those modules:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">core</kbd>: This contains all of the core OpenCV functionalities. For instance, all basic structures, including the <kbd class="calibre13">Mat</kbd> class (which we'll learn about in detail later) and matrix operations are some of the functionalities embedded into this module.</li>
<li class="calibre11"><kbd class="calibre13">imgproc</kbd>: This module contains all image-processing functionalities, such as filtering, transformations, and histograms.</li>
<li class="calibre11"><kbd class="calibre13">imgcodecs</kbd>: This module includes functions that are used for reading and writing images.</li>
<li class="calibre11"><kbd class="calibre13">videoio</kbd>: This is similar to the <kbd class="calibre13">imgcodecs</kbd> module, but this one is used to work with videos, as the name implies.</li>
<li class="calibre11"><kbd class="calibre13">highgui</kbd>: This module, which we'll use extensively throughout the book, contains all of the functionalities used for displaying results and GUI creation in general. Note that even though the <kbd class="calibre13">highgui</kbd> module is enough for the purpose of this book and learning about computer vision algorithms while visualizing the results as we move forward, it's still not meant for full-scale applications. Refer to the <em class="calibre26">Further reading</em> section at the end of this chapter for more references about proper GUI creation tools for full-scale computer vision applications.</li>
<li class="calibre11"><kbd class="calibre13">video</kbd>: Contains video analysis functionalities of OpenCV, such as motion detection and tracking, the Kalman filter, and the infamous CAM Shift algorithm (used for object tracking).</li>
<li class="calibre11"><kbd class="calibre13">calib3d</kbd>: This module includes calibration and 3D reconstruction functionalities. A well-known example of the capabilities of this module is the estimation of transformation between two images.</li>
<li class="calibre11"><kbd class="calibre13">features2d</kbd>: Supported keypoint-detection and descriptor-extraction algorithms are included in this module. As we'll learn in the upcoming chapters, this module contains some of the most widely used object detection and categorization algorithms.</li>
<li class="calibre11"><kbd class="calibre13">objdetect</kbd>: As the name implies, this module is used for object detection using OpenCV. We'll learn about the functionalities contained within this module in the final chapters of this book.</li>
<li class="calibre11"><kbd class="calibre13">dnn</kbd>: Similar to the <kbd class="calibre13">objdetect</kbd> module, this module is also used for object detection and classification purposes, among others. The <kbd class="calibre13">dnn</kbd> module is relatively new in the list of the Main modules of OpenCV, and it contains all of the capabilities related to deep learning.</li>
<li class="calibre11"><kbd class="calibre13">ml</kbd>: This machine learning module contains the classes and functions used to handle classification and regression. Simply put, all strictly machine learning-related capabilities are included in this module.</li>
<li class="calibre11"><kbd class="calibre13">flann</kbd>: This is OpenCV's interface to <strong class="calibre1">Fast Library for Approximate Nearest Neighbors</strong> (<strong class="calibre1">FLANN</strong>). FLANN contains a wide set of optimized algorithms that are used to deal with the nearest neighbor search of high-dimensional features in large datasets. The algorithms mentioned here are mostly used in conjunction with algorithms in other modules, such as <kbd class="calibre13">features2d</kbd>.</li>
<li class="calibre11"><kbd class="calibre13">photo</kbd>: An interesting module for photography-related computer vision, it contains classes and functions that are used to deal with tasks such as denoising, HDR imaging, and restoring a region in a photo using its neighborhood.</li>
<li class="calibre11"><kbd class="calibre13">stitching</kbd>: This module contains classes and functions used for image stitching. Note that stitching in itself is a very complex task and it requires functions for rotation estimation and image warping, all of which are also part of this very interesting OpenCV module.</li>
<li class="calibre11"><kbd class="calibre13">shape</kbd>: This module is used to deal with shape transformation, matching, and distance-related topics.</li>
<li class="calibre11"><kbd class="calibre13">superres</kbd>: Algorithms that fall into the category of resolution enhancement are included in the super-resolution module.</li>
<li class="calibre11"><kbd class="calibre13">videostab</kbd>: This module contains algorithms used for video stabilization.</li>
<li class="calibre11"><kbd class="calibre13">viz</kbd>: Otherwise known as the 3D Visualizer module, it contains classes and functions that are used to deal with displaying widgets on the 3D visualization window. This module will not be part of the topics discussed in this book, but we'll just mention it.</li>
</ul>
<p class="calibre2">Apart from the modules that we just covered, OpenCV also contains a number of Main modules that are based on CUDA (an API created by Nvidia). These modules are easily distinguished by their names, which start with the word <kbd class="calibre13">cuda</kbd>. Since the availability of these modules totally depends on a specific type of hardware, and almost all of the functionalities inside those modules are covered, one way or another, by other modules, we're going to skip them for now. But it's worth noting that using the OpenCV <kbd class="calibre13">cuda</kbd> modules can significantly improve the performance of your applications, provided that the algorithms you need are implemented in them, and that your hardware meets the minimum requirements for them.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Downloading and building/installing OpenCV</h1>
                
            
            
                
<p class="calibre2">OpenCV, for the most part, does not have a prebuilt and ready-to-use version (there are some exceptions we'll cover in this section) and similar to most of the open source libraries, it needs to be configured and built from sources. In this section, we'll quickly describe how OpenCV is built (and installed) on a computer. But first, you need to get the OpenCV source codes in your computer. You can use the following link for this:<br class="calibre5"/>
<a href="https://opencv.org/releases.html" class="calibre9">https://opencv.org/releases.html</a></p>
<p class="calibre2">On this page, you can find release versions of OpenCV. The latest version, as of the time of writing this book, is 3.4.1 so you should download it, or if there is a higher version then just go with that.</p>
<p class="calibre2">As seen in the following screenshot, for each version of the OpenCV release, there are various downloadable entries, such as the Win, iOS, and Android packs, but you should download Sources and build OpenCV yourself based on the platform you want to work with:</p>
<div><img src="img/00013.jpeg" class="calibre27"/></div>
<p>OpenCV 3.4.1, by default, provides prebuilt versions of the Android, iOS, and 64-bit MSVC14 and MSVC15 (the same as Microsoft Visual C++ 2015 and Microsoft Visual C++ 2017) libraries. So, if you want to build applications for any of these platforms, you can download the relevant pack and skip the OpenCV build process altogether.</p>
<p class="calibre2">To build OpenCV from sources, you need the following tools on your computer:</p>
<ul class="calibre10">
<li class="calibre11"><strong class="calibre1">C/C++ compiler with C++11 support</strong>: On Windows, this means any of the more recent Microsoft Visual C++ compilers, such as MSVC15 (2017) or MSVC14 (2015). On Linux operating systems, you can use an up-to-date GCC and, on macOS, you can use the command-line tools for Xcode that contain all the required tools.</li>
<li class="calibre11"><strong class="calibre1">CMake</strong>: Make sure you use the latest version of CMake, such as 3.10, to be on the safe side with more recent versions of OpenCV, although you can use CMake 3.1 and later.</li>
<li class="calibre11"><strong class="calibre1">Python</strong>: This is especially important if you are aiming to use the Python programming language.</li>
</ul>
<p>OpenCV contains a large number of tools and libraries and it's possible to customize your build in many different ways. For instance, you can use the Qt Framework, Intel <strong class="calibre28">Threading Building Blocks</strong> (<strong class="calibre28">TBB</strong>), <strong class="calibre28">Intel Integrated Performance Primitives</strong> (<strong class="calibre28">IPP</strong>), and other third-party libraries to further enhance and customize your OpenCV build, but since we'll be using OpenCV with the default settings and set of tools, we're ignoring the aforementioned third-party tools in the list of requirements.</p>
<p class="calibre2">After getting all of the prerequisites we just mentioned, you can configure and build OpenCV by using CMake and the corresponding compilers, depending on your operating system and desired platforms.</p>
<p class="calibre2">The following screenshot depicts the CMake tool with a default set of configurations visible. Usually, you don't need to make any change to the configurations unless you want to apply your own set of customizations to the OpenCV build:</p>
<div><img src="img/00014.jpeg" class="calibre20"/></div>
<p class="calibre2">Note that when CMake is first opened, you need to set the source and build folders, which are visible in the preceding screenshot, as Where is the source code: and Where to build the binaries:, respectively. After hitting the Configure button, you need to set a generator and apply the settings, then press Generate.</p>
<p class="calibre2">After generation, you can simply switch to the CMake output folder using a Terminal or Command Prompt instance and execute the following commands:</p>
<pre class="calibre15">    <strong class="calibre1">make</strong>
    <strong class="calibre1">make install</strong></pre>
<p>Be aware that running each one of these commands can take some time depending on your computer's speed and configurations. Also note that the <kbd class="calibre29">make</kbd> commands can be different depending on the set of tools you are aiming to use. For instance, if you are using Microsoft Visual Studio, then you need to replace <kbd class="calibre29">make</kbd> with <kbd class="calibre29">nmake</kbd>, or if you are using MinGW then you have to replace <kbd class="calibre29">make</kbd> with <kbd class="calibre29">mingw32-make</kbd>.</p>
<p class="calibre2">After the build process is completed, you can start using OpenCV. The only thing you need to take care of is configuring your C++ projects so that they can use your set of OpenCV libraries and installation.</p>
<p>On Windows operating systems, you need to make sure OpenCV DLL files are accessible by the applications you are building. This can be done either by copying all of the required DLLs to the same folder where your applications are being built or simply by adding the path of the OpenCV DLL files to the PATH environment variable. Make sure to take care of this before proceeding further, otherwise your applications will crash when they are executed, even though they might build successfully and not report any issues at compile time.</p>
<p class="calibre2">If you are going to use Python to build computer vision applications, then things are going to be extremely simple for you since you can use <kbd class="calibre13">pip</kbd> (package manager) to install OpenCV for Python, using the following command:</p>
<pre class="calibre15">    <strong class="calibre1">pip install opencv-python</strong></pre>
<p class="calibre2">This will automatically get you the latest OpenCV version and all of its dependencies (such as <kbd class="calibre13">numpy</kbd>) or, if you have already installed OpenCV, you can use the following command to make sure it's upgraded to the latest version:</p>
<pre class="calibre15">    <strong class="calibre1">pip install --upgrade opencv-python</strong></pre>
<p class="calibre2">It goes without saying that you need a working internet connection for these commands to work.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Using OpenCV with C++ or Python</h1>
                
            
            
                
<p class="calibre2">In this section, we'll demonstrate how you can use OpenCV in your C++ or Python projects with a very simple example that we'll call <kbd class="calibre13">HelloOpenCV</kbd>. You might already know that the purpose of such a project is either one of the following:</p>
<ul class="calibre10">
<li class="calibre11">To get started with a new library, such as OpenCV, that you've never used before</li>
<li class="calibre11">To make sure your OpenCV installation is functional and works fine</li>
</ul>
<p class="calibre2">So, even if you are not an OpenCV beginner, it's still worth going through the following instructions and running the simple example in this section to test your OpenCV build or installation.</p>
<p class="calibre2">We'll start with the required steps for using OpenCV in a C++ project:</p>
<ol class="calibre14">
<li value="1" class="calibre11">Create a new folder named <kbd class="calibre13">HelloOpenCV</kbd></li>
<li value="2" class="calibre11">Create two new text files inside this folder and name them <kbd class="calibre13">CMakeLists.txt</kbd> and <kbd class="calibre13">main.cpp</kbd></li>
<li value="3" class="calibre11">Make sure the <kbd class="calibre13">CMakeLists.txt</kbd> file contains the following:</li>
</ol>
<pre class="calibre30">cmake_minimum_required(VERSION 3.1) 
 
project(HelloOpenCV) 
 
set(OpenCV_DIR "path_to_opencv") 
find_package(OpenCV REQUIRED) 
include_directories(${OpenCV_INCLUDE_DIRS}) 
 
add_executable(${PROJECT_NAME} "main.cpp") 
 
target_link_libraries(${PROJECT_NAME} ${OpenCV_LIBS}) </pre>
<p>In the preceding code, you need to replace <kbd class="calibre29">"path_to_opencv"</kbd> with the path to the folder containing the <kbd class="calibre29">OpenCVConfig.cmake</kbd> and <kbd class="calibre29">OpenCVConfig-version.cmake</kbd> files, which is the same folder where you have installed your OpenCV libraries. If you are using the Linux operating system and the prebuilt OpenCV libraries, you might not need an exact path to the <kbd class="calibre29">OpenCV</kbd> folder.</p>
<ol start="4" class="calibre14">
<li value="4" class="calibre11">As for the <kbd class="calibre13">main.cpp</kbd> file, make sure it contains the following, which is the actual C++ code we'll be running:</li>
</ol>
<pre class="calibre30">#include &lt;iostream&gt; 
#include &lt;opencv2/opencv.hpp&gt; 
 
using namespace std; 
using namespace cv; 
 
int main() 
{ 
    Mat image = imread("MyImage.png"); 
    if(!image.empty()) 
    { 
        imshow("image", image); 
        waitKey(); 
    } 
    else 
    { 
        cout &lt;&lt; "Empty image!" &lt;&lt; endl; 
    } 
 
    return 0; 
} </pre>
<p class="calibre31">We'll be covering the functions used in the preceding code individually later on, in this and the upcoming chapters, however, for now it's worth noting that this program is trying to open and display an image saved on disk. If it succeeds, the image will be displayed until any key is pressed, otherwise the <kbd class="calibre13">Empty image!</kbd> message will be displayed. Note that this program, under normal circumstances, should not crash at all and it should build successfully. So, if the opposite happens to you, then you'll need to go through the topics discussed previously in this chapter.</p>
<ol start="5" class="calibre14">
<li value="5" class="calibre11">Our C++ project is ready. Now, we can use CMake to generate Visual Studio or any other type of project that we want (depending on the platform, compiler, and IDE we're going to use) and then build and run it. Note that CMake is simply used to make sure a cross-platform and IDE-independent C++ project is created.</li>
</ol>
<p class="calibre32">By running this example project, your input image (in this case <kbd class="calibre13">MyImage.png</kbd>) will be read and displayed until any key on the keyboard is pressed. If any problems occur during the reading of the image, then the <kbd class="calibre13">Empty image!</kbd> message will be displayed.</p>
<p class="calibre32">We can create and run the same project in Python by using the following code:</p>
<pre class="calibre30">import cv2 
 
image = cv2.imread("MyImage.png") 
if image is not None : 
    cv2.imshow("image", image) 
    cv2.waitKey() 
 
else: 
    print("Empty image!") </pre>
<p class="calibre2">The resemblance is quite unmistakable here. The exact same <kbd class="calibre13">imshow</kbd> and <kbd class="calibre13">waitKey</kbd> functions are also used in the Python version of the same code. As was mentioned before, for now don't bother with the exact way of using any of the functions and just focus on making sure that you are able to run these programs, either in C++ or Python, or both, and that you are able to see the image displayed.</p>
<p class="calibre2">If you were able to successfully run the <kbd class="calibre13">HelloOpenCV</kbd> example project in this section, then you are ready to take on the next sections of this chapter and the next chapters of this book without any problems. If you still face problems with the topics discussed so far, or you feel that you need a stronger understanding of those topics, you can go through them once again from the start of the chapter, or even better, you can refer to the additional books mentioned in the <em class="calibre7">Further reading</em> section at the end of this chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Understanding the Mat class</h1>
                
            
            
                
<p class="calibre2">Refer back to the description that was provided for an image in computer vision from the previous chapter, and that any image is in fact a matrix with a given width, height, number of channels, and depth. With this description in mind, we can say that the OpenCV <kbd class="calibre13">Mat</kbd> class can be used to handle image data and it supports all properties required by an image, such as width and height. In fact, the <kbd class="calibre13">Mat</kbd> class is an n-dimensional array that can be used to store single or multiple channels of data with any given data type, and it contains a number of members and methods to create, modify, or manipulate it in many ways.</p>
<p class="calibre2">In this section, we're going to learn about some of the most important members and methods of the <kbd class="calibre13">Mat</kbd> class with example use cases and code samples.</p>
<p>The equivalent of the OpenCV C++ <kbd class="calibre29">Mat</kbd> class in Python is not originally an OpenCV class, and it is represented by the <kbd class="calibre29">numpy.ndarray</kbd> type. NumPy is a Python library that contains a wide set of numerical algorithms and mathematical operations, and it supports working with large multi-dimensional arrays and matrices. The reason why the <kbd class="calibre29">numpy.ndarray</kbd> type in Python is used as <kbd class="calibre29">Mat</kbd> is that it offers the best (if not the same) set of members and methods required by the OpenCV <kbd class="calibre29">Mat</kbd> class in C++. For a complete list of members and methods supported by <kbd class="calibre29">numpy.ndarray</kbd>, you can refer to NumPy documentation.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Constructing a Mat object</h1>
                
            
            
                
<p class="calibre2"><kbd class="calibre13">Mat</kbd> contains about 20 different constructors that can be used to create instances of it, based on what kind of initialization is needed. Let's see some of the most commonly used constructors with some examples.</p>
<p class="calibre2">Creating a <kbd class="calibre13">Mat</kbd> object (or class instance) that has a width of <kbd class="calibre13">1920</kbd> and height of <kbd class="calibre13">1080</kbd>, with three channels that contain 32-bit floating-point values looks as follows:</p>
<pre class="calibre15">Mat image(1080, 1920, CV_32FC3); </pre>
<p class="calibre2">Note that the <kbd class="calibre13">type</kbd> parameter in the <kbd class="calibre13">Mat</kbd> constructors accepts a special type of parameter, that is, a constant value that contains the depth, type, and number of channels. The pattern is seen here:</p>
<pre class="calibre33">CV_&lt;depth&gt;&lt;type&gt;C&lt;channels&gt; </pre>
<p class="calibre2"><kbd class="calibre13">&lt;depth&gt;</kbd> can be replaced by 8, 16, 32, or 64, which represent the number of bits used to store each element in the pixels. The actual number of bits needed for each pixel can be calculated by multiplying this number with the number of channels, or in other words, <kbd class="calibre13">&lt;channels&gt;</kbd>. Finally, <kbd class="calibre13">&lt;type&gt;</kbd> needs to be replaced with <kbd class="calibre13">U</kbd>, <kbd class="calibre13">S</kbd>, or <kbd class="calibre13">F</kbd> for the unsigned integer, signed integer, and floating-point values, respectively. For example, you can use the following to create standard grayscale and colored images with a width of <kbd class="calibre13">800</kbd> and height of <kbd class="calibre13">600</kbd> pixels. Notice that only the number of channels is different, and that the depth and type parameters represent 8-bit unsigned integers:</p>
<pre class="calibre33">Mat grayscaleImage(600, 800, CV_8UC1); 
Mat colorImage(600, 800, CV_8UC3); </pre>
<p class="calibre2">You can use the following constructor to create a three-channel RGB image with a width of <kbd class="calibre13">W</kbd>, height of <kbd class="calibre13">H</kbd>, and 8-bit unsigned integer elements, and then initialize all elements with the <kbd class="calibre13">R</kbd>, <kbd class="calibre13">G</kbd>, and <kbd class="calibre13">B</kbd> color value:</p>
<pre class="calibre33">int W = 800, H = 600, R = 50, G = 150, B = 200; 
Mat image(H, W, CV_8UC3, Scalar(R, G, B));</pre>
<p>It's important to note that the default order of colors in OpenCV is BGR (instead of RGB), which means a swapped <kbd class="calibre29">B</kbd> and <kbd class="calibre29">R</kbd> value. This is especially important if we're aiming to display our processed images at some point during the application run time.</p>
<p class="calibre2">So, the correct way of the scalar initializer in the preceding code would be as follows:</p>
<pre class="calibre33">Scalar(B, G, R) </pre>
<p class="calibre2">If we need a <kbd class="calibre13">Mat</kbd> object with higher dimensions, we can use the following. Note that in the following example, a <kbd class="calibre13">Mat</kbd> object of seven dimensions is created. The size of each dimension is provided in the <kbd class="calibre13">sizes</kbd> array and each element in the high dimensional <kbd class="calibre13">Mat</kbd>, which is called <kbd class="calibre13">hdm</kbd>, contains two channels of 32-bit floating-point values:</p>
<pre class="calibre33">const int dimensions = 7; 
const int sizes[dimensions] = {800, 600, 3, 2, 1, 1, 1}; 
Mat hdm(7, sizes, CV_32FC2); </pre>
<p class="calibre2">Another way of achieving the same thing would be using C++ vectors, as seen in the following example:</p>
<pre class="calibre33">vector&lt;int&gt; sizes = {800, 600, 3, 2, 1, 1, 1}; 
Mat hdm(sizes, CV_32FC2); </pre>
<p class="calibre2">Similarly, you can provide an additional <kbd class="calibre13">Scalar</kbd> parameter to initialize all of the values in <kbd class="calibre13">Mat</kbd>. Note that the number of values in <kbd class="calibre13">Scalar</kbd> must match the number of channels. For instance, to initialize all of the elements in the previous seven-dimensional <kbd class="calibre13">Mat</kbd>, we can use the following constructor:</p>
<pre class="calibre33">Mat hdm(sizes, CV_32FC2, Scalar(1.25, 3.5)); </pre>
<p class="calibre2">The <kbd class="calibre13">Mat</kbd> class allows us to use already-stored image data to initialize it. Using this constructor, you can make your <kbd class="calibre13">Mat</kbd> class contain the same data that the <kbd class="calibre13">data</kbd> pointer is pointing to. Note that this constructor does not create a completely new copy of the original data, and it only makes this newly created <kbd class="calibre13">Mat</kbd> object point to it. This allows very efficient initialization and construction of the <kbd class="calibre13">Mat</kbd> classes, but has the obvious downside of not taking care of the memory cleanup when it is not needed, so you need to be extra careful when using this constructor:</p>
<pre class="calibre33">Mat image(1080, 1920, CV_8UC3, data);</pre>
<p class="calibre2">Note that, unlike the previous constructors and their initializers, <kbd class="calibre13">data</kbd> here is not a <kbd class="calibre13">Scalar</kbd> but a pointer to a chunk of memory that contains a <kbd class="calibre13">1920</kbd> by <kbd class="calibre13">1080</kbd> pixel, three-channel image data. This method of initializing a <kbd class="calibre13">Mat</kbd> object with a pointer to a memory space can also be used with higher dimensionalities of the <kbd class="calibre13">Mat</kbd> class.</p>
<p class="calibre2">One last constructor type, which is also one of the most important constructors of the <kbd class="calibre13">Mat</kbd> class, is the <strong class="calibre4">region of interest</strong> (<strong class="calibre4">ROI</strong>) constructor. This constructor is used to initialize a <kbd class="calibre13">Mat</kbd> object with a region inside another <kbd class="calibre13">Mat</kbd> object. Let's break this down with an example. Imagine you have an image and you want to apply some modifications to a specific region inside that image, or in other words to the ROI. You can use the following constructor to create a <kbd class="calibre13">Mat</kbd> class that has access to the ROI, and any changes applied to it will affect the same region of the original image. Here's how you can do that:</p>
<pre class="calibre33">Mat roi(image, Rect(240, 140, 300, 300)); </pre>
<p class="calibre2">If the preceding constructor is used while <kbd class="calibre13">image</kbd> (which itself is a <kbd class="calibre13">Mat</kbd> object) contains the picture on the left side of the following image, then <kbd class="calibre13">roi</kbd> will have access to the region highlighted in that image, and it will contain the image seen on the right side:</p>
<div><img src="img/00015.jpeg" class="calibre34"/></div>
<p class="calibre2">The <kbd class="calibre13">Rect</kbd> class in OpenCV is used to represent a rectangle that has a top-left point, width, and height. For instance, the <kbd class="calibre13">Rect</kbd> class that was used in the preceding code example has a top-left point of <kbd class="calibre13">240</kbd> and <kbd class="calibre13">140</kbd>, width of <kbd class="calibre13">300</kbd>, and height of <kbd class="calibre13">300</kbd> pixels, as seen here:</p>
<pre class="calibre33">Rect(240, 140, 300, 300)</pre>
<p class="calibre2">As was mentioned earlier, modifying the ROI in any way will result in the original image being modified. For instance, we can apply something similar to the following image-processing algorithm to <kbd class="calibre13">roi</kbd> (for now don't bother with the nature of the following algorithm, as we'll learn more about it in the upcoming chapters, and just focus on the concept of ROIs):</p>
<pre class="calibre33">dilate(roi, roi, Mat(), Point(-1,-1), 5); </pre>
<p class="calibre2">If we attempt to display the image, the result would be similar to the following. Notice the area that was highlighted in the previous image is modified (dilated) in the following image, even though we applied the change to <kbd class="calibre13">roi</kbd>, and not the image itself:</p>
<div><img src="img/00016.jpeg" class="calibre35"/></div>
<p class="calibre2">Similar to constructing an ROI <kbd class="calibre13">Mat</kbd> object using a <kbd class="calibre13">Rect</kbd> class that corresponds to a rectangular region of an image, you can also create an ROI that corresponds to a range of columns and rows in the original <kbd class="calibre13">Mat</kbd> object. For instance, the same region in the preceding example can also be accessed with the ranges seen in the following constructor:</p>
<pre class="calibre33">Mat roi(image, Range(140, 440), Range(240, 540)); </pre>
<p class="calibre2">The <kbd class="calibre13">Range</kbd> class in OpenCV represents a range that has <kbd class="calibre13">start</kbd> and <kbd class="calibre13">end</kbd>. Depending on the values of <kbd class="calibre13">start</kbd> and <kbd class="calibre13">end</kbd>, <kbd class="calibre13">Range</kbd> class can be checked to see whether it's empty or not. In the preceding constructor, the first <kbd class="calibre13">Range</kbd> class corresponds to the rows of the original image, from row <kbd class="calibre13">140</kbd> to row <kbd class="calibre13">440</kbd>. The second <kbd class="calibre13">Range</kbd> corresponds to the columns of the original image, from column <kbd class="calibre13">240</kbd> to column <kbd class="calibre13">540</kbd>. The shared space of the provided two ranges is considered to be the resulting ROI.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Deleting a Mat object</h1>
                
            
            
                
<p class="calibre2">A <kbd class="calibre13">Mat</kbd> object can be cleaned up by using its <kbd class="calibre13">release</kbd> function, however, since <kbd class="calibre13">release</kbd> is called in the destructor of the <kbd class="calibre13">Mat</kbd> class, there is usually no need to call this function at all. It's important to note that the <kbd class="calibre13">Mat</kbd> class shares the same data between multiple objects that point to it. This has the advantage of less data copying and less memory usage, and since all of the reference counting is done automatically, you don't usually need to take care of anything.</p>
<p class="calibre2">The only scenario in which you need to take extra care of how and when your objects and data are cleaned up is when you use a data pointer to construct a <kbd class="calibre13">Mat</kbd> object, as mentioned in the previous section. In such cases, calling the <kbd class="calibre13">release</kbd> function of the <kbd class="calibre13">Mat</kbd> class, or its destructor, will have nothing to do with the external data you have used to construct it, and the cleanup will be completely on your shoulders.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Accessing pixels</h1>
                
            
            
                
<p class="calibre2">Apart from using an ROI to access the pixels in a rectangular region of an image, as we did in the previous sections, there are a few other methods for achieving the same goal or even for accessing individual pixels of an image. To be able to access any single pixel in an image (in other words, a <kbd class="calibre13">Mat</kbd> object), you can use the <kbd class="calibre13">at</kbd> function, as seen in the following example:</p>
<pre class="calibre33">image.at&lt;TYPE&gt;(R, C) </pre>
<p class="calibre2">In the preceding example, in the usage of the <kbd class="calibre13">at</kbd> function, <kbd class="calibre13">TYPE</kbd> must be replaced with a valid type name that is in accordance with the number of channels and depth of the image. <kbd class="calibre13">R</kbd> must be replaced with the row number, and <kbd class="calibre13">C</kbd> with the column number of the pixels we want to have access to. Notice that this is slightly different from the usual pixel-access methods in many libraries, in which the first parameter is <em class="calibre7">X</em> (or left) and the second parameter is <em class="calibre7">Y</em> (or top). So basically, the parameters appear reversed here. Here are some examples of accessing individual pixels in different types of <kbd class="calibre13">Mat</kbd> objects.</p>
<p class="calibre2">Accessing a pixel in a single-channel <kbd class="calibre13">Mat</kbd> object with 8-bit integer elements (grayscale images) is done as follows:</p>
<pre class="calibre33">image.at&lt;uchar&gt;(R, C)</pre>
<p class="calibre2">Accessing a pixel in a single-channel <kbd class="calibre13">Mat</kbd> object with floating-point elements is done as follows:</p>
<pre class="calibre33">image.at&lt;float&gt;(R, C) </pre>
<p class="calibre2">Access a pixel in a three-channel <kbd class="calibre13">Mat</kbd> object with 8-bit integer elements as follows:</p>
<pre class="calibre33">image.at&lt;Vec3b&gt;(R, C) </pre>
<p class="calibre2">In the preceding code, the <kbd class="calibre13">Vec3b</kbd> (vector of 3 bytes) type is used. This and various other similar vector types are defined in OpenCV for convenience. Here is the pattern of the OpenCV <kbd class="calibre13">Vec</kbd> types that you can use with the <kbd class="calibre13">at</kbd> function, or for any other purposes:</p>
<pre class="calibre33">Vec&lt;N&gt;&lt;Type&gt; </pre>
<p class="calibre2"><kbd class="calibre13">&lt;N&gt;</kbd> can be replaced with 2, 3, 4, 6, or 8 (or omitted in the case of 1) and it corresponds to the number of channels in a <kbd class="calibre13">Mat</kbd> object. <kbd class="calibre13">&lt;Type&gt;</kbd>, on the other hand, can be one of the following, which represent the type of the data stored in each channel of each pixel:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">b</kbd> for <kbd class="calibre13">uchar</kbd> (unsigned char)</li>
<li class="calibre11"><kbd class="calibre13">s</kbd> for <kbd class="calibre13">short</kbd> (signed word)</li>
<li class="calibre11"><kbd class="calibre13">w</kbd> for <kbd class="calibre13">ushort</kbd> (unsigned word)</li>
<li class="calibre11"><kbd class="calibre13">i</kbd> for <kbd class="calibre13">int</kbd></li>
<li class="calibre11"><kbd class="calibre13">f</kbd> for <kbd class="calibre13">float</kbd></li>
<li class="calibre11"><kbd class="calibre13">d</kbd> for <kbd class="calibre13">double</kbd></li>
</ul>
<p class="calibre2">For instance, <kbd class="calibre13">Vec4b</kbd> can be used to access the pixels of a four-channel <kbd class="calibre13">Mat</kbd> object with the <kbd class="calibre13">uchar</kbd> elements, and <kbd class="calibre13">Vec6f</kbd> can be used to access the pixels of a six-channel <kbd class="calibre13">Mat</kbd> object with the <kbd class="calibre13">float</kbd> elements. It's important to note that the <kbd class="calibre13">Vec</kbd> type can be treated like an array to access individual channels too. Here's an example of how to access the second channel of a three-channel <kbd class="calibre13">Mat</kbd> object with the <kbd class="calibre13">uchar</kbd> elements:</p>
<pre class="calibre33">image.at&lt;Vec3b&gt;(R, C)[1]</pre>
<p class="calibre2">It's important to note that by access we mean both reading and writing to a pixel and its individual channels. For instance, the following example is one way to apply a sepia filter to an image:</p>
<pre class="calibre33">for(int i=0; i&lt;image.rows; i++) 
{ 
    for(int j=0; j&lt;image.cols; j++) 
    { 
        int inputBlue = image.at&lt;Vec3b&gt;(i,j)[0]; 
        int inputGreen = image.at&lt;Vec3b&gt;(i,j)[1]; 
        int inputRed = image.at&lt;Vec3b&gt;(i,j)[2]; 
 
        int red = 
                inputRed * 0.393 + 
                inputGreen * 0.769 + 
                inputBlue * 0.189; 
 
        if(red &gt; 255 ) red = 255; 
 
        int green = 
                inputRed * 0.349 + 
                inputGreen * 0.686 + 
                inputBlue * 0.168; 
 
        if(green &gt; 255) green = 255; 
 
        int blue = 
                inputRed * 0.272 + 
                inputGreen * 0.534 + 
                inputBlue * 0.131; 
 
        if(blue &gt; 255) blue = 255; 
 
        image.at&lt;Vec3b&gt;(i,j)[0] = blue; 
        image.at&lt;Vec3b&gt;(i,j)[1] = green; 
        image.at&lt;Vec3b&gt;(i,j)[2] = red; 
    } 
} </pre>
<p class="calibre2">First, a few things to note here are the <kbd class="calibre13">rows</kbd> and <kbd class="calibre13">cols</kbd> members of the image, which basically represent the number of rows (or height) and the number of columns (or width) in it. Also notice how the <kbd class="calibre13">at</kbd> function is used both to extract the values of channels and to write updated values into them. Don't worry about the values used in this example to multiply and get the correct sepia tone, as they are specific to the tone itself, and essentially any type of operation can be applied to the individual pixels to change them.</p>
<p class="calibre2">The following image depicts the result of applying the preceding example code on a three-channel color image (left—original image, right—filtered image):</p>
<div><img src="img/00017.jpeg" class="calibre36"/></div>
<p class="calibre2">Another method of accessing the pixels in an image is by using the <kbd class="calibre13">forEach</kbd> function of the <kbd class="calibre13">Mat</kbd> class. <kbd class="calibre13">forEach</kbd> can be used to apply an operation on all pixels in parallel, instead of looping through them one by one. Here's a simple example that shows how <kbd class="calibre13">forEach</kbd> is used to divide the value of all pixels by <kbd class="calibre13">5</kbd>, which would result in a darker image if it is executed on a grayscale image:</p>
<pre class="calibre33">image.forEach&lt;uchar&gt;([](uchar &amp;p, const int *) 
{ 
    p /= 5; 
}); </pre>
<p class="calibre2">In the preceding code, the second parameter, or the position parameter (which is not needed and therefore omitted here) is the pointer to the position of the pixel.</p>
<p class="calibre2">Using the previous <kbd class="calibre13">for</kbd> loop, we would need to write the following:</p>
<pre class="calibre33">for(int i=0; i&lt;image.rows; i++) 
    for(int j=0; j&lt;image.cols; j++) 
        image.at&lt;uchar&gt;(i,j) /= 5; </pre>
<p class="calibre2">OpenCV also allows the use of STL-like iterators to access or modify individual pixels in an image. Here's the same example but written using STL-like iterators:</p>
<pre class="calibre33">MatIterator_&lt;uchar&gt; it_begin = image.begin&lt;uchar&gt;(); 
MatIterator_&lt;uchar&gt; it_end = image.end&lt;uchar&gt;(); 
for( ; it_begin != it_end; it_begin++) 
{ 
    *it_begin /= 5; 
}</pre>
<p class="calibre2">It's interesting to note that the same operation in all of the preceding three examples can also be done by using the following simple statement:</p>
<pre class="calibre33">image /= 5; </pre>
<p class="calibre2">This is because the <kbd class="calibre13">Mat</kbd> object in OpenCV treats this statement as an element-wise divide operation, which we'll learn more about it in the upcoming chapters. The following image depicts the result of applying the preceding examples to a grayscale image (left—original image, right—modified image):</p>
<div><img src="img/00018.gif" class="calibre37"/></div>
<p class="calibre2">Obviously, <kbd class="calibre13">forEach</kbd>, the C++ <kbd class="calibre13">for</kbd> loop, and STL-like iterators can all be used to access and modify the pixels within a <kbd class="calibre13">Mat</kbd> object. We'll suffice to the functions and members discussed in this section about the <kbd class="calibre13">Mat</kbd> class, but make sure to explore the huge set of functionalities it provides to work with images and their underlying properties in an efficient way.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Reading and writing images</h1>
                
            
            
                
<p class="calibre2">OpenCV allows reading an image from a disk into a <kbd class="calibre13">Mat</kbd> object using the <kbd class="calibre13">imread</kbd> function, which we briefly used in this chapter in a previous example. The <kbd class="calibre13">imread</kbd> function accepts an input image file name and a <kbd class="calibre13">flag</kbd> parameter, and returns a <kbd class="calibre13">Mat</kbd> object filled with the input image. The input image file must have one of the image formats supported by OpenCV. Here are some of the most popular supported formats:</p>
<ul class="calibre10">
<li class="calibre11"><strong class="calibre1">Windows bitmaps</strong>: <kbd class="calibre13">*.bmp</kbd>, <kbd class="calibre13">*.dib</kbd></li>
<li class="calibre11"><strong class="calibre1">JPEG files</strong>: <kbd class="calibre13">*.jpeg</kbd>, <kbd class="calibre13">*.jpg</kbd>, <kbd class="calibre13">*.jpe</kbd></li>
<li class="calibre11"><strong class="calibre1">Portable Network Graphics</strong>: <kbd class="calibre13">*.png</kbd></li>
<li class="calibre11"><strong class="calibre1">Portable Image Format</strong>: <kbd class="calibre13">*.pbm</kbd>, <kbd class="calibre13">*.pgm</kbd>, <kbd class="calibre13">*.ppm</kbd>, <kbd class="calibre13">*.pxm</kbd>, <kbd class="calibre13">*.pnm</kbd></li>
<li class="calibre11"><strong class="calibre1">TIFF files</strong>: <kbd class="calibre13">*.tiff</kbd>, <kbd class="calibre13">*.tif</kbd></li>
</ul>
<p class="calibre2">Make sure to always check the OpenCV documentation for a complete and updated list, and especially for exception cases and notes that might apply to some formats on some operating systems. As for the</p>
<p class="calibre2"><kbd class="calibre13">flag</kbd> parameter, it can be one or a combination of the values from the <kbd class="calibre13">ImreadModes</kbd> enum, which is defined in OpenCV. Here are a few of the most widely used and self-explanatory entries:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">IMREAD_UNCHANGED</kbd></li>
<li class="calibre11"><kbd class="calibre13">IMREAD_GRAYSCALE</kbd></li>
<li class="calibre11"><kbd class="calibre13">IMREAD_COLOR</kbd></li>
<li class="calibre11"><kbd class="calibre13">IMREAD_IGNORE_ORIENTATION</kbd></li>
</ul>
<p class="calibre2">For example, the following code can be used to read an image from a disk, without taking the orientation value stored in the EXIF data of the image and also converted to grayscale:</p>
<pre class="calibre33">Mat image = imread("MyImage.png", 
    IMREAD_GRAYSCALE | IMREAD_IGNORE_ORIENTATION);</pre>
<div><strong class="calibre28">Exchangeable Image File Format</strong> (<strong class="calibre28">EXIF</strong>) is a standard for adding tags and additional data (or metadata) to images taken by digital cameras. These tags might include the manufacturer and camera model and the orientation of the camera while the photo was taken. OpenCV is capable of reading certain tags (such as orientation) and interpreting them, or in the case of the preceding sample code, ignoring them.</div>
<p class="calibre2">After the image is read, you can call <kbd class="calibre13">empty</kbd> to see whether it was read successfully or not. You can also use <kbd class="calibre13">channels</kbd> to get the number of channels, <kbd class="calibre13">depth</kbd> to get the depth, <kbd class="calibre13">type</kbd> to get the type of the image, and so on. Alternatively, you can call the <kbd class="calibre13">imshow</kbd> function to display it, as we saw previously in this chapter.</p>
<p class="calibre2">Similarly, the <kbd class="calibre13">imreadmulti</kbd> function can be used to read a multipage image into a vector of <kbd class="calibre13">Mat</kbd> objects. The obvious difference here is that <kbd class="calibre13">imreadmulti</kbd> returns a <kbd class="calibre13">bool</kbd> value that can be checked for successful reading of the pages and fills the <kbd class="calibre13">vector&lt;Mat&gt;</kbd> object passed to it by reference.</p>
<p class="calibre2">To be able to write an image to a file on disk, you can use the <kbd class="calibre13">imwrite</kbd> function. <kbd class="calibre13">imwrite</kbd> takes the file name that will be written to, a <kbd class="calibre13">Mat</kbd> object, and a <kbd class="calibre13">vector</kbd> of <kbd class="calibre13">int</kbd> values containing the write parameters, which can be ignored in the case of default parameters. See the following enums in OpenCV for a complete list of parameters that can be used with the <kbd class="calibre13">imwrite</kbd> function to alter the behavior of the write process:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">ImwriteFlags</kbd></li>
<li class="calibre11"><kbd class="calibre13">ImwriteEXRTypeFlags</kbd></li>
<li class="calibre11"><kbd class="calibre13">ImwritePNGFlags</kbd></li>
<li class="calibre11"><kbd class="calibre13">ImwritePAMFlags</kbd></li>
</ul>
<p class="calibre2">The following is an example code that depicts how to write a <kbd class="calibre13">Mat</kbd> object into an image file on disk using the <kbd class="calibre13">imwrite</kbd> function. Note that the format of the image is derived from the extension provided, in this case <kbd class="calibre13">png</kbd>:</p>
<pre class="calibre33">bool success = imwrite("c:/my_images/image1.png", image); 
cout &lt;&lt; (success ? 
            "Image was saved successfully!" 
          : 
            "Image could not be saved!") 
     &lt;&lt; endl; </pre>
<p class="calibre2">Besides the <kbd class="calibre13">imread</kbd> and <kbd class="calibre13">imwrite</kbd> functions, which are used to read and write images from and into image files on disk, you can also use the <kbd class="calibre13">imdecode</kbd> and <kbd class="calibre13">imencode</kbd> functions to read images stored in a buffer in memory or write into them. We'll leave those two functions for you to discover, and move on to the next topic, which is accessing videos using OpenCV.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Reading and writing videos</h1>
                
            
            
                
<p class="calibre2">OpenCV, using its <kbd class="calibre13">videoio</kbd> module or, to be precise, using the <kbd class="calibre13">VideoCapture</kbd> and <kbd class="calibre13">VideoWriter</kbd> classes, allows us to read and write video files. The obvious difference in the case of videos, is that they contain a consecutive set of images (or better yet, frames) as opposed to just a single image. So, they are usually read and processed or written in a loop that covers the whole or any desired number of the frames in a video. Let's start with example code that shows how to read and play a video using the OpenCV <kbd class="calibre13">VideoCapture</kbd> class:</p>
<pre class="calibre33">VideoCapture vid("MyVideo.mov"); 
// check if video file was opened correctly 
if(!vid.isOpened()) 
{ 
    cout &lt;&lt; "Can't read the video file"; 
    return -1; 
} 
// get frame rate per second of the video file 
double fps = vid.get(CAP_PROP_FPS); 
if(fps == 0) 
{ 
    cout &lt;&lt; "Can't get video FPS"; 
    return -1; 
} 
// required delay between frames in milliseconds 
int delay_ms = 1000.0 / fps; 
// infinite loop 
while(true) 
{ 
    Mat frame; 
    vid &gt;&gt; frame; 
    if(frame.empty()) 
        break; 
    // process the frame if necessary ... 
    // display the frame 
    imshow("Video", frame); 
    // stop playing if space is pressed 
    if(waitKey(delay_ms) == ' ') 
        break; 
} 
// release the video file 
vid.release(); </pre>
<p class="calibre2">As seen in the preceding code, the video file name is passed to the <kbd class="calibre13">VideoCapture</kbd> class when it is constructed. This automatically leads to the opening of the video file, if it exists and if the format is supported by your computer (and OpenCV). Consequently, you can check whether the video file was successfully opened or not using the <kbd class="calibre13">isOpened</kbd> function. Right after that, the <kbd class="calibre13">get</kbd> function of the <kbd class="calibre13">VideoCapture</kbd> class is used to retrieve the <strong class="calibre4">framerate per second</strong> (<strong class="calibre4">FPS</strong>) of the video file that has been opened. <kbd class="calibre13">get</kbd> is an extremely important function of <kbd class="calibre13">VideoCapture</kbd> and it allows us to retrieve a wide range of properties of an opened video file. Here are some example parameters that can be provided to the <kbd class="calibre13">get</kbd> function to get the desired result:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">CAP_PROP_POS_FRAMES</kbd>: <em class="calibre26">0</em>-based index of the frame to be decoded or captured next</li>
<li class="calibre11"><kbd class="calibre13">CAP_PROP_FRAME_WIDTH</kbd>: Width of the frames in the video stream</li>
<li class="calibre11"><kbd class="calibre13">CAP_PROP_FRAME_HEIGHT</kbd>: Height of the frames in the video stream</li>
<li class="calibre11"><kbd class="calibre13">CAP_PROP_FPS</kbd>: Frame rate of the video</li>
<li class="calibre11"><kbd class="calibre13">CAP_PROP_FRAME_COUNT</kbd>: Number of frames in the video file</li>
</ul>
<p class="calibre2">For a complete list, you can refer to the <kbd class="calibre13">VideoCaptureProperties</kbd> enum documentation in OpenCV. Back to the preceding example code, after the frame rate is retrieved using the <kbd class="calibre13">get</kbd> function, it is used to calculate the delay needed in between two frames, so that it is not too fast or slow when played back. Then, inside an infinite loop, the frames are read using the <kbd class="calibre13">&gt;&gt;</kbd> operator and displayed. Note that this operator is essentially the simplified and convenient way of using the <kbd class="calibre13">VideoCapture</kbd> functions, such as <kbd class="calibre13">read</kbd>, <kbd class="calibre13">grab</kbd>, and <kbd class="calibre13">retrieve</kbd>. We are already familiar with the <kbd class="calibre13">imshow</kbd> function and how it's used. <kbd class="calibre13">waitKey</kbd>, on the other hand, which is used slightly differently from what we saw before, can be used to insert delays and wait for key presses at the same time. In this case, the desired delay (in milliseconds), which was previously calculated, is inserted between displayed frames and if the space key is pressed, the loop will break. The <kbd class="calibre13">release</kbd> function in the end is pretty much self-explanatory.</p>
<p class="calibre2">Apart from the way we used the <kbd class="calibre13">VideoCapture</kbd> class and its methods, we can also call its <kbd class="calibre13">open</kbd> function to open the video file, if we do not want to pass the file name to the constructor, or if the video file is not present at the <kbd class="calibre13">VideoCapture</kbd> construction time. Another important function of <kbd class="calibre13">VideoCapture</kbd> is the <kbd class="calibre13">set</kbd> function. Think of <kbd class="calibre13">set</kbd> as the exact opposite of the <kbd class="calibre13">get</kbd> function, in the sense that it allows setting the parameters of <kbd class="calibre13">VideoCapture</kbd> and the opened video file. Try experimenting with it for yourself with different parameters, mentioned before in the <kbd class="calibre13">VideoCaptureProperties</kbd> enum.</p>
<p class="calibre2">To be able to write into a video file, you can use the <kbd class="calibre13">VideoWriter</kbd> class in a very similar way. Here's an example that shows how a <kbd class="calibre13">VideoWriter</kbd> object is created:</p>
<pre class="calibre33">VideoWriter wrt("C:/output.avi", 
                VideoWriter::fourcc('M','J','P','G'), 
                30, Size(1920, 1080)); </pre>
<p class="calibre2">This will create a video file at <kbd class="calibre13">"C:/output.avi"</kbd> with a width of <kbd class="calibre13">1920</kbd> and height of <kbd class="calibre13">1080</kbd> pixels at <kbd class="calibre13">30</kbd> frames per second, ready to be filled with frames. But what is <kbd class="calibre13">fourcc</kbd>? <strong class="calibre4">Four Character Code</strong> (<strong class="calibre4">FourCC</strong>) is simply a four-byte code of the format (or the codec, to be precise) that will be used to record the video file. In this example, we have used one of the most common FourCC values, but you can check online for a more comprehensive list of FourCC values and their specifications.</p>
<p class="calibre2">After a <kbd class="calibre13">VideoWriter</kbd> object is created, you can use the <kbd class="calibre13">&lt;&lt;</kbd> operator or the <kbd class="calibre13">write</kbd> function to write an image (of the exact same size as the video) into the video file:</p>
<pre class="calibre33">wrt &lt;&lt; image; </pre>
<p class="calibre2">Or you can also use the following code:</p>
<pre class="calibre33">vid.write(frame); </pre>
<p class="calibre2">Finally, you can call the <kbd class="calibre13">release</kbd> function to make sure the video file is released, and all of your changes are written into it.</p>
<p>Apart from the aforementioned methods of using the <kbd class="calibre29">VideoCapture</kbd> and <kbd class="calibre29">VideoWriter</kbd> classes, you can also set the preferred backend used by them. For more information about this, refer to the <kbd class="calibre29">VideoCaptureAPIs</kbd> enum in the OpenCV documentation. When omitted, which was the case in our examples, the default backend supported by your computer is used.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Accessing cameras</h1>
                
            
            
                
<p class="calibre2">OpenCV supports accessing cameras that are available on a system by using the same <kbd class="calibre13">VideoCapture</kbd> class we used for accessing the video files. The only difference is that instead of passing a file name to the constructor of the <kbd class="calibre13">VideoCapture</kbd> class or its open function, you must provide a <em class="calibre7">0</em>-based index number that corresponds to each available camera. For instance, the default webcam on a computer can be accessed and displayed by using the following example code:</p>
<pre class="calibre33">VideoCapture cam(0); 
// check if camera was opened correctly 
if(!cam.isOpened()) 
    return -1; 
 
// infinite loop 
while(true) 
{ 
    Mat frame; 
    cam &gt;&gt; frame; 
    if(frame.empty()) 
        break; 
 
    // process the frame if necessary ... 
 
    // display the frame 
    imshow("Camera", frame); 
 
    // stop camera if space is pressed 
    if(waitKey(10) == ' ') 
        break; 
} 
 
cam.release(); </pre>
<p class="calibre2">As you can see, the only difference is in the constructor. This implementation of the <kbd class="calibre13">VideoCapture</kbd> class allows users to treat any type of video source the same way, thus writing almost the exact same code to deal with cameras instead of video files. This is also the case with network feeds, as described in the next section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Accessing RTSP and network feeds</h1>
                
            
            
                
<p class="calibre2">OpenCV allows users to read video frames from a network feed or, to be precise, from an RTSP stream located on a network, such as the local network or even the internet. To be able to do this, you need to pass the URL of the RTSP stream to the <kbd class="calibre13">VideoCapture</kbd> constructor or its open function, exactly the same way as if it were a file on a local hard disk. Here's the most common pattern and an example URL that can be used:</p>
<pre class="calibre15">rtsp://user:password@website.com/somevideo </pre>
<p class="calibre2">In this URL, <kbd class="calibre13">user</kbd> is replaced by the actual username, <kbd class="calibre13">password</kbd> with the password of that user, and so on. In the event that the network feed does not require a username and password, they can be omitted.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Mat-like classes</h1>
                
            
            
                
<p class="calibre2">Besides the <kbd class="calibre13">Mat</kbd> class, OpenCV provides a number of other classes that are quite similar to <kbd class="calibre13">Mat</kbd>, but different in how and when they are used. Here are the most important <kbd class="calibre13">Mat</kbd>-like classes that can be used instead of, or together with, the <kbd class="calibre13">Mat</kbd> class:</p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre13">Mat_</kbd>: This is a subclass of the <kbd class="calibre13">Mat</kbd> class, but it provides a better access method than the <kbd class="calibre13">at</kbd> function, that is, using <kbd class="calibre13">().Mat_</kbd> is a template class and obviously needs to be provided with the type of the elements at compile time, something that can be avoided with the <kbd class="calibre13">Mat</kbd> class itself.</li>
<li class="calibre11"><kbd class="calibre13">Matx</kbd>: This is best used with matrices that have a small size, or to be precise, a known and small size at compile time.</li>
<li class="calibre11"><kbd class="calibre13">UMat</kbd>: This is a more recent implementation of the <kbd class="calibre13">Mat</kbd> class, which allows us to use OpenCL for faster matrix operations.</li>
</ul>
<p>Using <kbd class="calibre29">UMat</kbd> can significantly increase the performance of your computer vision applications, but since it is used in exactly the same way as the <kbd class="calibre29">Mat</kbd> class, we'll ignore it throughout the chapters of this book; however, in practice and especially in real-time computer vision applications, you must always make sure to use classes and functions that are better optimized and more performant, such as <kbd class="calibre29">UMat</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            
                
<p class="calibre2">We're through all the crucial topics that are needed to easily take on computer vision algorithms using hands-on examples and real-life scenarios. We started this chapter by learning about OpenCV and its overall structure, including its modules and main building blocks. This helped us gain a perspective of the computer vision library that we'll be working on, but, more importantly, this gave us an overview of what's possible and what to expect when dealing with computer vision algorithms in general. We moved on to learn where and how to get OpenCV and how to install or build it on our own. We also learned how to create, build, and run C++ and Python projects that use the OpenCV library. Then, by learning all about the <kbd class="calibre13">Mat</kbd> class and dealing with pixels in an image, we learned how to alter and display an image. The final sections of this chapter included everything we need to know about reading and writing images from files saved on disk, whether they are single (or multi-page) images or videos files, and also cameras and network feeds. We finished the chapter by learning about a few other types from the OpenCV Mat family that can help improve our applications.</p>
<p class="calibre2">Now that we are aware of the real nature of an image (that it is, in essence, a matrix), we can start with possible operations on matrices and matrix-like entities. In the next chapter, we're going to learn all about the matrix and array operations that fall into the realm of computer vision. By the end of the next chapter, we'll be able to perform tons of pixel-wise and image-wise operations and transformations using OpenCV.</p>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Questions</h1>
                
            
            
                
<ol class="calibre14">
<li value="1" class="calibre11">Name three Extra OpenCV modules along with their usages.</li>
<li value="2" class="calibre11">What is the effect of building OpenCV 3 with the <kbd class="calibre13">BUILD_opencv_world</kbd> flag turned on?</li>
<li value="3" class="calibre11">Using the ROI pixel-access method described in this chapter, how can we construct a <kbd class="calibre13">Mat</kbd> class that can access the middle pixel, plus all of its neighboring pixels (the middle nine pixels) in another image?</li>
<li value="4" class="calibre11">Name another pixel-access method of the <kbd class="calibre13">Mat</kbd> class besides the ones mentioned in this chapter.</li>
<li value="5" class="calibre11">Write a program only using the <kbd class="calibre13">at</kbd> method and a <kbd class="calibre13">for</kbd> loop, which creates three separate color images, each one containing only one channel of an RGB image read from disk.</li>
<li value="6" class="calibre11">Using STL-like iterators, calculate the average pixel value of a grayscale image.</li>
<li value="7" class="calibre11">Write a program using <kbd class="calibre13">VideoCapture</kbd>, <kbd class="calibre13">waitKey</kbd>, and <kbd class="calibre13">imwrite</kbd>, that displays your webcam and saves the visible image when the <em class="calibre26">S</em> key is pressed. This program will stop the webcam and exit if the spacebar key is pressed.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title" id="calibre_pb_0">Further reading</h1>
                
            
            
                
<ul class="calibre10">
<li class="calibre11"><em class="calibre26">Computer Vision with OpenCV 3 and Qt5</em>: <a href="https://www.packtpub.com/application-development/computer-vision-opencv-3-and-qt5" class="calibre9">https://www.packtpub.com/application-development/computer-vision-opencv-3-and-qt5</a></li>
<li class="calibre11"><em class="calibre26">Learn Qt5</em>: <a href="https://www.packtpub.com/web-development/learn-qt-5" class="calibre9">https://www.packtpub.com/web-development/learn-qt-5</a></li>
<li class="calibre11"><em class="calibre26">Qt5 Projects</em>: <a href="https://www.packtpub.com/application-development/qt-5-projects" class="calibre9">https://www.packtpub.com/application-development/qt-5-projects</a></li>
</ul>


            

            
        
    </body></html>