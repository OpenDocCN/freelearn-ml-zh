<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Customer Segmentation</h1>
                
            
            <article>
                
<p class="calibre2">In this chapter, we are going to learn about unsupervised learning models and how they can be used to extract insights from the data. Up until now, we have been focusing on supervised learning, where our <strong class="calibre4">machine learning</strong> (<strong class="calibre4">ML</strong>) models have known target variables that they try to predict. We have built classification models for spam email filtering and Twitter sentiment analysis. We have also built regression models for foreign exchange rate forecasting and predicting the fair value of house prices. All of these ML models that we have built so far are supervised learning algorithms, where the models learn to map the given input to expected outcomes. However, there are cases where we are more interested in finding hidden insights and drawing inferences from datasets, and we can use unsupervised learning algorithms for such tasks.</p>
<p class="calibre2">In this chapter, we are going to use an online retail dataset that contains information about the prices and quantities of items that customers bought. We will explore the data by looking at how the distributions of item prices and quantities for purchase orders differ from those of cancel orders. We will also look at how online store activities are spread across different countries. Then, we are going to take this transaction-level data and transform and aggregate it into customer-level data. As we transform this data to have a customer-centric view, we are going to discuss ways to build scale-independent features for unsupervised learning algorithms. With this feature set, we are going to use a k-means clustering algorithm to build customer segments and extract insights on the customer behaviors within each segment. We will introduce a new validation metric, Silhouette Coefficient, to evaluate the clustering results.</p>
<p class="calibre2">In this chapter, we will cover the following topics:</p>
<ul class="calibre10">
<li class="calibre11">Problem definition for a customer segmentation project</li>
<li class="calibre11">Data analysis for an online retail dataset</li>
<li class="calibre11">Feature engineering and aggregation</li>
<li class="calibre11">Unsupervised learning using a k-means clustering algorithm</li>
<li class="calibre11">Clustering model validations using the Silhouette Coefficient</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Problem definition</h1>
                
            
            <article>
                
<p class="calibre2">Let's discuss in more detail what problems we are going to solve and build clustering models for. Whether you are trying to send marketing emails to your customers or you simply want to better understand your customers and their behaviors on your online store, you will want to analyze and identify different types and segments of your customers. Some customers might buy lots of items at once (bulk buyers), some might primarily buy expensive or luxury items (luxury product buyers), or some might have bought one or two items and never come back (unengaged customers). Depending on these behavioral patterns, your marketing campaigns should vary. For example, sending out emails with promotions on luxury items is likely to provoke luxury product buyers to log in to the online store and purchase certain items, but such an email campaign is not going to work well for bulk buyers. On the other hand, sending out emails with promotions on items that are frequently bought in bulk, such as pens and notepads for office supplies, is likely to make bulk buyers log in to the online store and place purchase orders, but it might not be attractive for luxury product buyers. By identifying customer segments based on their behavioral patterns and using customized marketing campaigns, you can optimize your marketing channels.</p>
<p class="calibre2">In order to build models for customer segmentation, we are going to use an online retail dataset that contains all the transactions that occurred between Jan. 12th 2010 and Sep. 12th 2011 for a UK-based online retail store. This dataset is available in the UCI Machine Learning Repository and can be downloaded from this link: <a href="http://archive.ics.uci.edu/ml/datasets/online+retail#" class="calibre9">http://archive.ics.uci.edu/ml/datasets/online+retail#</a>. With this data, we are going to build features that contain information about the net revenue, average item price, and average purchase quantity per customer. Using these features, we are going to build a clustering model using a <strong class="calibre4">k-means clustering algorithm</strong> that clusters the customer base into different segments. We will be using <strong class="calibre4">Silhouette Coefficient</strong> metrics to evaluate the quality of the clusters and deduce the optimal number of customer segments to build.</p>
<p class="calibre2"><span class="calibre5">To summarize our problem definition for the customer segmentation project:</span></p>
<ul class="calibre10">
<li class="calibre11">What is the problem? We need a clustering model that segments customers into different clusters, so that we can understand and draw insights about the behavioral patterns of the customers better.</li>
<li class="calibre11">Why is it a problem? There is no one-fits-all marketing campaign that works for all different types of customers. We will need to build custom-tailored marketing campaigns for bulk buyers and luxury product buyers separately. Also, we will have to target unengaged customers differently from the other customer types to have them re-engage with the products. The more customized the marketing messages are, the more likely customers will engage. It will be a big advantage if we have an ML model that clusters our customer base into different segments based on their behavioral patterns on the online store.</li>
<li class="calibre11">What are some of the approaches to solving this problem?<strong class="calibre1"> </strong>We are going to use the online retail dataset that contains all transactions from 2010 to mid-2011 to aggregate the key features, such as net revenue, average unit price, and average purchase quantity for each customer. Then, we will use a k-means clustering algorithm to build a clustering model and use the Silhouette Coefficient to evaluate the quality of clusters and choose the optimal number of clusters.</li>
<li class="calibre11">What are the success criteria? We do not want too many clusters, as this would make it more difficult to explain and understand different patterns of customers. We will use the Silhouette Coefficient score to tell us the best number of clusters to use for customer segmentation.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Data analysis for the online retail dataset</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">It is now time to look into the dataset. You can follow this link: <a href="http://archive.ics.uci.edu/ml/datasets/online+retail#" target="_blank" class="calibre9">http://archive.ics.uci.edu/ml/datasets/online+retail#</a>, click on the <kbd class="calibre12">Data Folder</kbd> link in the top left corner, and download the <kbd class="calibre12">Online Retail.xlsx</kbd> file. You can save the file as a CSV format and load it into a Deedle data frame.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Handling missing values</h1>
                
            
            <article>
                
<p class="calibre2">Since we will be aggregating the transaction data for each customer, we need to check whether there are any missing values in the <kbd class="calibre12">CustomerID</kbd> column. The following screenshot shows a few records with no <kbd class="calibre12">CustomerID</kbd>:</p>
<div class="mce-root"><img class="alignnone23" src="../images/00082.gif"/></div>
<p class="calibre2"><span class="calibre5">We are going to drop those records with missing values from the <kbd class="calibre12">CustomerID</kbd>, <kbd class="calibre12">Description</kbd>, <kbd class="calibre12">Quantity</kbd>, <kbd class="calibre12">UnitPrice</kbd>, and <kbd class="calibre12">Country</kbd> columns. The following code snippet shows how we can drop records with missing values for those columns:</span></p>
<pre class="calibre19">// 1. Missing CustomerID Values<br class="title-page-name"/>ecommerceDF<br class="title-page-name"/>    .Columns[new string[] { "CustomerID", "InvoiceNo", "StockCode", "Quantity", "UnitPrice", "Country" }]<br class="title-page-name"/>    .GetRowsAt(new int[] { 1440, 1441, 1442, 1443, 1444, 1445, 1446 })<br class="title-page-name"/>    .Print();<br class="title-page-name"/>Console.WriteLine("\n\n* # of values in CustomerID column: {0}", ecommerceDF["CustomerID"].ValueCount);<br class="title-page-name"/><br class="title-page-name"/>// Drop missing values<br class="title-page-name"/>ecommerceDF = ecommerceDF<br class="title-page-name"/>    .Columns[new string[] { "CustomerID", "Description", "Quantity", "UnitPrice", "Country" }]<br class="title-page-name"/>    .DropSparseRows();<br class="title-page-name"/><br class="title-page-name"/>// Per-Transaction Purchase Amount = Quantity * UnitPrice<br class="title-page-name"/>ecommerceDF.AddColumn("Amount", ecommerceDF["Quantity"] * ecommerceDF["UnitPrice"]);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("\n\n* Shape (After dropping missing values): {0}, {1}\n", ecommerceDF.RowCount, ecommerceDF.ColumnCount);<br class="title-page-name"/>Console.WriteLine("* After dropping missing values and unnecessary columns:");<br class="title-page-name"/>ecommerceDF.GetRowsAt(new int[] { 0, 1, 2, 3, 4 }).Print();<br class="title-page-name"/>// Export Data<br class="title-page-name"/>ecommerceDF.SaveCsv(Path.Combine(dataDirPath, "data-clean.csv"));</pre>
<p class="calibre2">We use the <kbd class="calibre12">DropSparseRows</kbd> method of the Deedle data frame to drop all the records with missing values in the columns of our interest. Then, we append the data frame with an additional column <kbd class="calibre12">Amount</kbd>, which is the total price for the given transaction. We can calculate this value by multiplying the unit price with the quantity.</p>
<p class="calibre2">As you can see from the previous image, we had 541,909 records before we dropped the missing values. After dropping the records with missing values from the columns of our interest, the number of records in the data frame ends up being 406,829. Now, we have a data frame that contains the information about <span class="calibre5"><kbd class="calibre12">CustomerID</kbd>, <kbd class="calibre12">Description</kbd>, <kbd class="calibre12">Quantity</kbd>, <kbd class="calibre12">UnitPrice</kbd>, and <kbd class="calibre12">Country</kbd></span> for all the transactions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Variable distributions</h1>
                
            
            <article>
                
<p class="calibre2">Let's start looking at the distributions in our dataset. First, we will take a look at the top five countries by the volume of transactions. The code we used to aggregate the records by the countries and count the number of transactions that occurred in each country is as follows:</p>
<pre class="calibre19">// 2. Number of transactions by country<br class="title-page-name"/>var numTransactionsByCountry = ecommerceDF<br class="title-page-name"/>    .AggregateRowsBy&lt;string, int&gt;(<br class="title-page-name"/>        new string[] { "Country" },<br class="title-page-name"/>        new string[] { "CustomerID" },<br class="title-page-name"/>        x =&gt; x.ValueCount<br class="title-page-name"/>    ).SortRows("CustomerID");<br class="title-page-name"/><br class="title-page-name"/>var top5 = numTransactionsByCountry<br class="title-page-name"/>    .GetRowsAt(new int[] {<br class="title-page-name"/>        numTransactionsByCountry.RowCount-1, numTransactionsByCountry.RowCount-2,<br class="title-page-name"/>        numTransactionsByCountry.RowCount-3, numTransactionsByCountry.RowCount-4,<br class="title-page-name"/>        numTransactionsByCountry.RowCount-5 });<br class="title-page-name"/>top5.Print();<br class="title-page-name"/><br class="title-page-name"/>var topTransactionByCountryBarChart = DataBarBox.Show(<br class="title-page-name"/>    top5.GetColumn&lt;string&gt;("Country").Values.ToArray().Select(x =&gt; x.Equals("United Kingdom") ? "UK" : x),<br class="title-page-name"/>    top5["CustomerID"].Values.ToArray()<br class="title-page-name"/>);<br class="title-page-name"/>topTransactionByCountryBarChart.SetTitle(<br class="title-page-name"/>    "Top 5 Countries with the most number of transactions"<br class="title-page-name"/> );</pre>
<p class="calibre2"><span class="calibre5">As you can see from this code snippet, we are using the <kbd class="calibre12">AggregateRowsBy</kbd> method in the Deedle data frame to group the records by country and count the total number of transactions for each country. Then, we sort the resulting data frame using the <kbd class="calibre12">SortRows</kbd> method and take the top five countries. When you run this code, you will see the following bar chart:</span></p>
<div class="mce-root"><img src="../images/00083.jpeg" class="calibre80"/></div>
<p class="calibre2"><span class="calibre5">The number of transactions for each of the top five countries looks as follows:</span></p>
<div class="mce-root"><img class="alignnone24" src="../images/00084.gif"/></div>
<p class="calibre2"><span class="calibre5">As expected, the largest number of transactions occurred in the United Kingdom. Germany and France come in as the countries with the second and third most transactions.</span></p>
<p class="calibre2">Let's start looking at the distributions of the features that we will be using for our clustering model—purchase quantity, unit price, and net amount. We will be looking at these distributions in three ways. First, we will get the overall distribution of each feature, regardless of whether the transaction was for purchase or cancellation. Second, we will take a look at the purchase orders only, excluding the cancel orders. Third, we will look at the distributions for cancel orders only.</p>
<p class="calibre2">The code to get distributions of transaction quantity is as follows:</p>
<pre class="calibre19">// 3. Per-Transaction Quantity Distributions<br class="title-page-name"/>Console.WriteLine("\n\n-- Per-Transaction Order Quantity Distribution-- ");<br class="title-page-name"/>double[] quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>    ecommerceDF["Quantity"].ValuesAll.ToArray(),<br class="title-page-name"/>    new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>);<br class="title-page-name"/>Console.WriteLine(<br class="title-page-name"/>    "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>    quantiles[0], quantiles[1], quantiles[2], quantiles[3], quantiles[4]<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("\n\n-- Per-Transaction Purchase-Order Quantity Distribution-- ");<br class="title-page-name"/>quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>    ecommerceDF["Quantity"].Where(x =&gt; x.Value &gt;= 0).ValuesAll.ToArray(),<br class="title-page-name"/>    new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>);<br class="title-page-name"/>Console.WriteLine(<br class="title-page-name"/>    "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>    quantiles[0], quantiles[1], quantiles[2], quantiles[3], quantiles[4]<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("\n\n-- Per-Transaction Cancel-Order Quantity Distribution-- ");<br class="title-page-name"/>quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>    ecommerceDF["Quantity"].Where(x =&gt; x.Value &lt; 0).ValuesAll.ToArray(),<br class="title-page-name"/>    new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>);<br class="title-page-name"/>Console.WriteLine(<br class="title-page-name"/>    "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>    quantiles[0], quantiles[1], quantiles[2], quantiles[3], quantiles[4]<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">As in the previous chapter, we are using the <kbd class="calibre12">Quantiles</kbd> method to compute <kbd class="calibre12">quartiles</kbd>—min, 25% percentile, median, 75% percentile, and max. Once we get the overall distribution of order quantities per transaction, we then look at the distribution for purchase orders and cancel orders. In our dataset, cancel orders are encoded with negative numbers in the <kbd class="calibre12">Quantity</kbd> column. In order to separate cancel orders from purchase orders, we can simply filter out positive and negative quantities from our data fame as in the following code:</span></p>
<pre class="calibre19">// Filtering out cancel orders to get purchase orders only<br class="title-page-name"/>ecommerceDF["Quantity"].Where(x =&gt; x.Value &gt;= 0)<br class="title-page-name"/>// Filtering out purchase orders to get cancel orders only<br class="title-page-name"/>ecommerceDF["Quantity"].Where(x =&gt; x.Value &lt; 0)</pre>
<p class="calibre2">In order to get the <kbd class="calibre12">quartiles</kbd> of per-transaction unit prices, we use the following code:</p>
<pre class="calibre19">// 4. Per-Transaction Unit Price Distributions<br class="title-page-name"/>Console.WriteLine("\n\n-- Per-Transaction Unit Price Distribution-- ");<br class="title-page-name"/>quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>    ecommerceDF["UnitPrice"].ValuesAll.ToArray(),<br class="title-page-name"/>    new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>);<br class="title-page-name"/>Console.WriteLine(<br class="title-page-name"/>    "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>    quantiles[0], quantiles[1], quantiles[2], quantiles[3], quantiles[4]<br class="title-page-name"/>);</pre>
<p class="calibre2">Similarly, we can compute the <kbd class="calibre12">quartiles</kbd> of the per-transaction total amount using the following code:</p>
<pre class="calibre19">// 5. Per-Transaction Purchase Price Distributions<br class="title-page-name"/>Console.WriteLine("\n\n-- Per-Transaction Total Amount Distribution-- ");<br class="title-page-name"/>quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>    ecommerceDF["Amount"].ValuesAll.ToArray(),<br class="title-page-name"/>    new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>);<br class="title-page-name"/>Console.WriteLine(<br class="title-page-name"/>    "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>    quantiles[0], quantiles[1], quantiles[2], quantiles[3], quantiles[4]<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("\n\n-- Per-Transaction Purchase-Order Total Amount Distribution-- ");<br class="title-page-name"/>quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>    ecommerceDF["Amount"].Where(x =&gt; x.Value &gt;= 0).ValuesAll.ToArray(),<br class="title-page-name"/>    new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>);<br class="title-page-name"/>Console.WriteLine(<br class="title-page-name"/>    "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>    quantiles[0], quantiles[1], quantiles[2], quantiles[3], quantiles[4]<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("\n\n-- Per-Transaction Cancel-Order Total Amount Distribution-- ");<br class="title-page-name"/>quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>    ecommerceDF["Amount"].Where(x =&gt; x.Value &lt; 0).ValuesAll.ToArray(),<br class="title-page-name"/>    new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>);<br class="title-page-name"/>Console.WriteLine(<br class="title-page-name"/>    "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>    quantiles[0], quantiles[1], quantiles[2], quantiles[3], quantiles[4]<br class="title-page-name"/>);</pre>
<p class="calibre2">When you run the code, you will see the following output for the distributions of per-transaction order quantity, unit price, and total amount:</p>
<div class="mce-root"><img class="alignnone25" src="../images/00085.gif"/></div>
<p class="calibre2">If you look at the distribution of the overall order quantities in this output, you will notice that from the first quartile (25% percentile), the quantities are positive. This suggests that there are far less cancel orders than purchase orders, which is actually a good thing for an online retail store. Let's look at how the purchase orders and cancel orders are divided in our dataset.</p>
<p class="calibre2">Using the following code, you can draw a bar chart to compare the number of purchase orders against cancel orders:</p>
<pre class="calibre19">// 6. # of Purchase vs. Cancelled Transactions<br class="title-page-name"/>var purchaseVSCancelBarChart = DataBarBox.Show(<br class="title-page-name"/>    new string[] { "Purchase", "Cancel" },<br class="title-page-name"/>    new double[] {<br class="title-page-name"/>        ecommerceDF["Quantity"].Where(x =&gt; x.Value &gt;= 0).ValueCount ,<br class="title-page-name"/>        ecommerceDF["Quantity"].Where(x =&gt; x.Value &lt; 0).ValueCount<br class="title-page-name"/>    }<br class="title-page-name"/>);<br class="title-page-name"/>purchaseVSCancelBarChart.SetTitle(<br class="title-page-name"/>    "Purchase vs. Cancel"<br class="title-page-name"/> );</pre>
<p class="calibre2">When you run this code, you will see the following bar chart:</p>
<div class="mce-root"><img src="../images/00086.jpeg" class="calibre81"/></div>
<p class="calibre2"><span class="calibre5">As expected and shown in the previous distribution output, the number of cancel orders is much less than the number of purchase orders. With these analysis results, we are going to start building features for our clustering model for customer segmentation in the next section.</span></p>
<p class="calibre2">The full code for this data analysis step can be found by following this link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.6/DataAnalyzer.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.6/DataAnalyzer.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Feature engineering and data aggregation</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">The records in the dataset we have now represent individual transactions. However, we want to build a clustering model that clusters customers into different segments. In order to do that, we need to transform and aggregate our data by customer. In other words, we will need to group our data by <kbd class="calibre12">CustomerID</kbd> and <kbd class="calibre12">aggregate</kbd> all the transactions that belong to each customer by summing, counting, or taking averages of the values. Let's look at an example first. The following code groups the transaction-level data by <kbd class="calibre12">CustomerID</kbd> and computes the net revenue, total number of transactions, total number of cancel orders, average unit price, and average order quantity:</span></p>
<pre class="calibre19">// 1. Net Revenue per Customer<br class="title-page-name"/>var revPerCustomerDF = ecommerceDF.AggregateRowsBy&lt;double, double&gt;(<br class="title-page-name"/>    new string[] { "CustomerID" },<br class="title-page-name"/>    new string[] { "Amount" },<br class="title-page-name"/>    x =&gt; x.Sum()<br class="title-page-name"/>);<br class="title-page-name"/>// 2. # of Total Transactions per Customer<br class="title-page-name"/>var numTransactionsPerCustomerDF = ecommerceDF.AggregateRowsBy&lt;double, double&gt;(<br class="title-page-name"/>    new string[] { "CustomerID" },<br class="title-page-name"/>    new string[] { "Quantity" },<br class="title-page-name"/>    x =&gt; x.ValueCount<br class="title-page-name"/>);<br class="title-page-name"/>// 3. # of Cancelled Transactions per Customer<br class="title-page-name"/>var numCancelledPerCustomerDF = ecommerceDF.AggregateRowsBy&lt;double, double&gt;(<br class="title-page-name"/>    new string[] { "CustomerID" },<br class="title-page-name"/>    new string[] { "Quantity" },<br class="title-page-name"/>    x =&gt; x.Select(y =&gt; y.Value &gt;= 0 ? 0.0 : 1.0).Sum()<br class="title-page-name"/>);<br class="title-page-name"/>// 4. Average UnitPrice per Customer<br class="title-page-name"/>var avgUnitPricePerCustomerDF = ecommerceDF.AggregateRowsBy&lt;double, double&gt;(<br class="title-page-name"/>    new string[] { "CustomerID" },<br class="title-page-name"/>    new string[] { "UnitPrice" },<br class="title-page-name"/>    x =&gt; x.Sum() / x.ValueCount<br class="title-page-name"/>);<br class="title-page-name"/>// 5. Average Quantity per Customer<br class="title-page-name"/>var avgQuantityPerCustomerDF = ecommerceDF.AggregateRowsBy&lt;double, double&gt;(<br class="title-page-name"/>    new string[] { "CustomerID" },<br class="title-page-name"/>    new string[] { "Quantity" },<br class="title-page-name"/>    x =&gt; x.Sum() / x.ValueCount<br class="title-page-name"/>);</pre>
<p class="calibre2">As you may see from this code, we are using the <kbd class="calibre12">AggregateRowsBy</kbd> method in the Deedle data frame and passing a custom <kbd class="calibre12">aggFunc</kbd> for each aggregation. In the first example, where we compute the net revenue per customer, we sum all the purchase amounts for each customer. For the second feature, we count the number of transactions to compute the total number of orders for each customer. In order to compute the average order quantity for each customer, we sum up all the order quantities and divide it by the number of transactions. As you can see from this case, the <span class="calibre5"><kbd class="calibre12">AggregateRowsBy</kbd> </span>method comes in handy when you need to transform and aggregate a data frame with a custom <kbd class="calibre12">aggregation</kbd> function.</p>
<p class="calibre2">Once we have computed all these features, we need to combine all the data into one place. We created a new empty data frame and added each of these aggregated features as separate columns to the new data frame. The following code shows how we created a features data frame:</p>
<pre class="calibre19">// Aggregate all results<br class="title-page-name"/>var featuresDF = Frame.CreateEmpty&lt;int, string&gt;();<br class="title-page-name"/>featuresDF.AddColumn("CustomerID", revPerCustomerDF.GetColumn&lt;double&gt;("CustomerID"));<br class="title-page-name"/>featuresDF.AddColumn("Description", ecommerceDF.GetColumn&lt;string&gt;("Description"));<br class="title-page-name"/>featuresDF.AddColumn("NetRevenue", revPerCustomerDF.GetColumn&lt;double&gt;("Amount"));<br class="title-page-name"/>featuresDF.AddColumn("NumTransactions", numTransactionsPerCustomerDF.GetColumn&lt;double&gt;("Quantity"));<br class="title-page-name"/>featuresDF.AddColumn("NumCancelled", numCancelledPerCustomerDF.GetColumn&lt;double&gt;("Quantity"));<br class="title-page-name"/>featuresDF.AddColumn("AvgUnitPrice", avgUnitPricePerCustomerDF.GetColumn&lt;double&gt;("UnitPrice"));<br class="title-page-name"/>featuresDF.AddColumn("AvgQuantity", avgQuantityPerCustomerDF.GetColumn&lt;double&gt;("Quantity"));<br class="title-page-name"/>featuresDF.AddColumn("PercentageCancelled", featuresDF["NumCancelled"] / featuresDF["NumTransactions"]);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("\n\n* Feature Set:");<br class="title-page-name"/>featuresDF.Print();</pre>
<p class="calibre2">As you can see from this code snippet, we created one additional feature, <kbd class="calibre12">PercentageCancelled</kbd>, while we were appending those aggregated features to the new data frame. The <kbd class="calibre12">PercentageCancelled</kbd> feature simply holds information about how many of the transactions or orders were cancelled.</p>
<p class="calibre2">To take a closer look at the distributions of these features, we wrote a helper function that computes the <kbd class="calibre12">quartiles</kbd> of a given feature and prints out the results. The code for this helper function is as follows:</p>
<pre class="calibre19">private static void PrintQuartiles(Frame&lt;int, string&gt; df, string colname)<br class="title-page-name"/>{<br class="title-page-name"/>    Console.WriteLine("\n\n-- {0} Distribution-- ", colname);<br class="title-page-name"/>    double[] quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>        df[colname].ValuesAll.ToArray(),<br class="title-page-name"/>        new double[] { 0, 0.25, 0.5, 0.75, 1.0 }<br class="title-page-name"/>    );<br class="title-page-name"/>    Console.WriteLine(<br class="title-page-name"/>        "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}",<br class="title-page-name"/>        quantiles[0], quantiles[1], quantiles[2], quantiles[3], quantiles[4]<br class="title-page-name"/>    );<br class="title-page-name"/>}</pre>
<p class="calibre2">Using this helper function, <kbd class="calibre12">PrintQuartiles</kbd>, the following code snippet shows how we computed and displayed <kbd class="calibre12">quartiles</kbd> for the features we just created:</p>
<pre class="calibre19">// NetRevenue feature distribution<br class="title-page-name"/>PrintQuartiles(featuresDF, "NetRevenue");<br class="title-page-name"/>// NumTransactions feature distribution<br class="title-page-name"/>PrintQuartiles(featuresDF, "NumTransactions");<br class="title-page-name"/>// AvgUnitPrice feature distribution<br class="title-page-name"/>PrintQuartiles(featuresDF, "AvgUnitPrice");<br class="title-page-name"/>// AvgQuantity feature distribution<br class="title-page-name"/>PrintQuartiles(featuresDF, "AvgQuantity");<br class="title-page-name"/>// PercentageCancelled feature distribution<br class="title-page-name"/>PrintQuartiles(featuresDF, "PercentageCancelled");</pre>
<p class="calibre2">The output of this code looks like the following:</p>
<div class="mce-root"><img class="alignnone26" src="../images/00087.gif"/></div>
<p class="calibre2"><span class="calibre5">If you look closely, there is one thing that is concerning. There is a small number of customers that have negative net revenue and negative average quantity. This suggests some customers have more cancel orders than purchase orders. However, this is odd. To cancel an order, there needs to be a purchase order first. This suggests that our dataset is not complete and there are some orphan cancel orders that do not have matching previous purchase orders. Since we cannot go back in time and pull out more data for those customers with orphan cancel orders, the simplest way to handle this problem is to drop those customers with orphan cancel orders. The following code shows some criteria we can use to drop such customers:</span></p>
<pre class="calibre19">// 1. Drop Customers with Negative NetRevenue<br class="title-page-name"/>featuresDF = featuresDF.Rows[<br class="title-page-name"/>    featuresDF["NetRevenue"].Where(x =&gt; x.Value &gt;= 0.0).Keys<br class="title-page-name"/>];<br class="title-page-name"/>// 2. Drop Customers with Negative AvgQuantity<br class="title-page-name"/>featuresDF = featuresDF.Rows[<br class="title-page-name"/>    featuresDF["AvgQuantity"].Where(x =&gt; x.Value &gt;= 0.0).Keys<br class="title-page-name"/>];<br class="title-page-name"/>// 3. Drop Customers who have more cancel orders than purchase orders<br class="title-page-name"/>featuresDF = featuresDF.Rows[<br class="title-page-name"/>    featuresDF["PercentageCancelled"].Where(x =&gt; x.Value &lt; 0.5).Keys<br class="title-page-name"/>];</pre>
<p class="calibre2">As you can see from this code snippet, we drop any customer who has a negative net revenue, negative average quantity, and percentage of cancel orders more than 50%. After dropping these customers, the resulting distributions look like the following:</p>
<div class="mce-root"><img class="alignnone27" src="../images/00088.gif"/></div>
<p class="calibre2"><span class="calibre5">As you can see from these distributions, the scales for each feature are very different. <kbd class="calibre12">NetRevenue</kbd> rages from 0 to 279,489.02, while <kbd class="calibre12">PercentageCancelled</kbd> ranges from 0 to 0.45. We are going to transform these features into percentiles, so that we can have all of our features on the same scale of 0 to 1. The following code shows how to compute percentiles for each feature:</span></p>
<pre class="calibre19">// Create Percentile Features<br class="title-page-name"/>featuresDF.AddColumn(<br class="title-page-name"/>    "NetRevenuePercentile",<br class="title-page-name"/>    featuresDF["NetRevenue"].Select(<br class="title-page-name"/>        x =&gt; StatsFunctions.PercentileRank(featuresDF["NetRevenue"].Values.ToArray(), x.Value)<br class="title-page-name"/>    )<br class="title-page-name"/>);<br class="title-page-name"/>featuresDF.AddColumn(<br class="title-page-name"/>    "NumTransactionsPercentile",<br class="title-page-name"/>    featuresDF["NumTransactions"].Select(<br class="title-page-name"/>        x =&gt; StatsFunctions.PercentileRank(featuresDF["NumTransactions"].Values.ToArray(), x.Value)<br class="title-page-name"/>    )<br class="title-page-name"/>);<br class="title-page-name"/>featuresDF.AddColumn(<br class="title-page-name"/>    "AvgUnitPricePercentile",<br class="title-page-name"/>    featuresDF["AvgUnitPrice"].Select(<br class="title-page-name"/>        x =&gt; StatsFunctions.PercentileRank(featuresDF["AvgUnitPrice"].Values.ToArray(), x.Value)<br class="title-page-name"/>    )<br class="title-page-name"/>);<br class="title-page-name"/>featuresDF.AddColumn(<br class="title-page-name"/>    "AvgQuantityPercentile",<br class="title-page-name"/>    featuresDF["AvgQuantity"].Select(<br class="title-page-name"/>        x =&gt; StatsFunctions.PercentileRank(featuresDF["AvgQuantity"].Values.ToArray(), x.Value)<br class="title-page-name"/>    )<br class="title-page-name"/>);<br class="title-page-name"/>featuresDF.AddColumn(<br class="title-page-name"/>    "PercentageCancelledPercentile",<br class="title-page-name"/>    featuresDF["PercentageCancelled"].Select(<br class="title-page-name"/>        x =&gt; StatsFunctions.PercentileRank(featuresDF["PercentageCancelled"].Values.ToArray(), x.Value)<br class="title-page-name"/>    )<br class="title-page-name"/>);<br class="title-page-name"/>Console.WriteLine("\n\n\n* Percentile Features:");<br class="title-page-name"/>featuresDF.Columns[<br class="title-page-name"/>    new string[] { "NetRevenue", "NetRevenuePercentile", "NumTransactions", "NumTransactionsPercentile" }<br class="title-page-name"/>].Print();</pre>
<p class="calibre2">As you can notice from this code snippet, we are using the <kbd class="calibre12">StatsFunctions.PercentileRank</kbd> method, which is part of the <span class="calibre5"><kbd class="calibre12">CenterSpace.NMath.Stats</kbd> package. You can easily install this package using the following command in the <strong class="calibre4">Package Manager</strong> console:</span></p>
<pre class="calibre19">Install-Package CenterSpace.NMath.Stats</pre>
<p class="calibre2">Using the <span class="calibre5"><kbd class="calibre12">StatsFunctions.PercentileRank</kbd> method, we can compute the percentile for each record. The following output shows the results for the <kbd class="calibre12">NetRevenue</kbd> and <kbd class="calibre12">NumTransactions</kbd> features:</span></p>
<div class="mce-root"><img class="alignnone28" src="../images/00089.gif"/></div>
<p class="calibre2"><span class="calibre5">As you can see from this output, instead of a wide range, the values for both features now range between 0 and 1. We will use these percentile features when we build our clustering model in the following section.</span></p>
<p class="calibre2">The full code for this feature engineering step can be found at this link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.6/FeatureEngineering.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.6/FeatureEngineering.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Unsupervised learning – k-means clustering</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">It is now time to start building our clustering models. In this project, we are going to try clustering customers into different segments based on the following three features: <kbd class="calibre12">NetRevenuePercentile</kbd>, <kbd class="calibre12">AvgUnitPricePercentile</kbd>, and <kbd class="calibre12">AvgQuantityPercentile</kbd>, so that we can analyze the item selections based on the spending habits of the customers. Before we start fitting a k-means clustering algorithm to our feature set, there is an important step we need to take. We need to normalize our features, so that our clustering model does not put more weight on certain features over the others. If variances of features are different, then a clustering algorithm can put more weight on those with small variances and can tend to cluster them together. The following code shows how you can normalize each feature:</span></p>
<pre class="calibre19">string[] features = new string[] { "NetRevenuePercentile", "AvgUnitPricePercentile", "AvgQuantityPercentile" };<br class="title-page-name"/>Console.WriteLine("* Features: {0}\n\n", String.Join(", ", features));<br class="title-page-name"/><br class="title-page-name"/>var normalizedDf = Frame.CreateEmpty&lt;int, string&gt;();<br class="title-page-name"/>var average = ecommerceDF.Columns[features].Sum() / ecommerceDF.RowCount;<br class="title-page-name"/>foreach(string feature in features)<br class="title-page-name"/>{<br class="title-page-name"/>    normalizedDf.AddColumn(feature, (ecommerceDF[feature] - average[feature]) / ecommerceDF[feature].StdDev());<br class="title-page-name"/>}</pre>
<p class="calibre2">Now that we have normalized our variables, let's start building clustering models. In order to build a k-means clustering model, we need to know the number of clusters we want in advance. Since we do not know what the best number of clusters is, we are going to try a few different numbers of clusters and rely on the validation metrics, the Silhouette Score, to tell us what the optimal number of clusters is. The following code shows how to build clustering models that use a k-means clustering algorithm:</p>
<pre class="calibre19">int[] numClusters = new int[] { 4, 5, 6, 7, 8 };<br class="title-page-name"/>List&lt;string&gt; clusterNames = new List&lt;string&gt;();<br class="title-page-name"/>List&lt;double&gt; silhouetteScores = new List&lt;double&gt;();<br class="title-page-name"/>for(int i = 0; i &lt; numClusters.Length; i++)<br class="title-page-name"/>{<br class="title-page-name"/>    KMeans kmeans = new KMeans(numClusters[i]);<br class="title-page-name"/>    KMeansClusterCollection clusters = kmeans.Learn(sampleSet);<br class="title-page-name"/>    int[] labels = clusters.Decide(sampleSet);<br class="title-page-name"/><br class="title-page-name"/>    string colname = String.Format("Cluster-{0}", numClusters[i]);<br class="title-page-name"/>    clusterNames.Add(colname);<br class="title-page-name"/><br class="title-page-name"/>    normalizedDf.AddColumn(colname, labels);<br class="title-page-name"/>    ecommerceDF.AddColumn(colname, labels);<br class="title-page-name"/><br class="title-page-name"/>    Console.WriteLine("\n\n\n##################### {0} ###########################", colname);<br class="title-page-name"/><br class="title-page-name"/>    Console.WriteLine("\n\n* Centroids for {0} clusters:", numClusters[i]);<br class="title-page-name"/><br class="title-page-name"/>    PrintCentroidsInfo(clusters.Centroids, features);<br class="title-page-name"/>    Console.WriteLine("\n");<br class="title-page-name"/><br class="title-page-name"/>    VisualizeClusters(normalizedDf, colname, "NetRevenuePercentile", "AvgUnitPricePercentile");<br class="title-page-name"/>    VisualizeClusters(normalizedDf, colname, "AvgUnitPricePercentile", "AvgQuantityPercentile");<br class="title-page-name"/>    VisualizeClusters(normalizedDf, colname, "NetRevenuePercentile", "AvgQuantityPercentile");<br class="title-page-name"/><br class="title-page-name"/>    for (int j = 0; j &lt; numClusters[i]; j++)<br class="title-page-name"/>    {<br class="title-page-name"/>        GetTopNItemsPerCluster(ecommerceDF, j, colname);<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    double silhouetteScore = CalculateSilhouetteScore(normalizedDf, features, numClusters[i], colname);<br class="title-page-name"/>    Console.WriteLine("\n\n* Silhouette Score: {0}", silhouetteScore.ToString("0.0000"));<br class="title-page-name"/><br class="title-page-name"/>    silhouetteScores.Add(silhouetteScore);<br class="title-page-name"/>    Console.WriteLine("\n\n##############################################################\n\n\n");<br class="title-page-name"/>}</pre>
<p class="calibre2">As you can see from this code snippet, we are going to try building clustering models with <kbd class="calibre12">4</kbd>, <kbd class="calibre12">5</kbd>, <kbd class="calibre12">6</kbd>, <kbd class="calibre12">7</kbd>, and <kbd class="calibre12">8</kbd> clusters. We can instantiate a k-means clustering algorithm object using the <kbd class="calibre12">KMeans</kbd> class in the <kbd class="calibre12">Accord.NET</kbd> framework. Using the <kbd class="calibre12">Learn</kbd> method, we can train a k-means clustering model with the feature set we have. Then, we can use the <kbd class="calibre12">Decide</kbd> method to get the cluster labels for each record.</p>
<p class="calibre2">When you run this code, it will output the centroids for each cluster. The following is an output of cluster centroids from a 4-cluster clustering model:</p>
<div class="mce-root"><img class="alignnone29" src="../images/00090.gif"/></div>
<p class="calibre2">As you can see from this output, the cluster with label 3 is a cluster of customers who have high net revenue, middle-high average unit price, and middle-high average quantity. So, these customers are high value customers who bring in the most revenue and buy items with prices above average in above-average quantities. In contrast, the cluster labeled as 1 is a cluster of customers who have low net revenue, high average unit price and middle-low average quantity. So, these customers buy expensive items in average quantities and do not bring in that much revenue for the online store. As you may notice from this example, you can already see some patterns among different clusters. Let's now look at which customers in each segment buy the most. The following is the top 10 items bought for each segment of the 4-cluster clustering model:</p>
<div class="mce-root"><img class="alignnone30" src="../images/00091.gif"/></div>
<p class="calibre2">This top 10 item list for each segment gives you a rough idea of what kinds of items the customers in each segment buy the most. This is out of scope for this chapter, but you can take a step further and analyze individual words in the item description and use word frequency analysis, such as we did in <a target="_blank" href="part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 2</a>, <em class="calibre13"><span class="calibre5">Spam Email Filtering</span></em> and <a target="_blank" href="part0036.html#12AK80-5ebdf09927b7492888e31e8436526470" class="calibre9">Chapter 3</a>, <em class="calibre13"><span class="calibre5"><span class="calibre5">Twitter Sentiment Analysis</span></span></em>. Another way to visualize the clustering results is to draw scatter plots for the segments. The following chart shows a scatter plot of <kbd class="calibre12">NetRevenuePercentile</kbd> versus <kbd class="calibre12">AvgQuantityPercentile</kbd> for the 4-cluster clustering model:</p>
<div class="mce-root"><img src="../images/00092.jpeg" class="calibre82"/></div>
<p class="calibre2"><span class="calibre5">The following chart shows a scatter plot of </span><kbd class="calibre12">AvgUnitPricePercentile </kbd><span class="calibre5"> versus </span> <kbd class="calibre12">AvgQuantityPercentile</kbd><span class="calibre5"> for the 4-cluster clustering model:</span></p>
<div class="mce-root"><img src="../images/00093.jpeg" class="calibre83"/></div>
<p class="calibre2"><span class="calibre5">The following chart shows a scatter plot of </span><kbd class="calibre12">NetRevenuePercentile</kbd><span class="calibre5"> versus</span> <kbd class="calibre12">AvgUnitPricePercentile</kbd><span class="calibre5"> for the 4-cluster clustering model:</span></p>
<div class="mce-root"><img src="../images/00094.jpeg" class="calibre84"/></div>
<p class="calibre2"><span class="calibre5">As you can see from these plots, a scatter plot is a good way to visualize how each cluster is formed and what the boundaries look like</span> <span class="calibre5">for each cluster. For example, if you look at the scatter plot of <kbd class="calibre12">NetRevenuePercentile</kbd> versus <kbd class="calibre12">AvgUnitPricePercentile</kbd>, cluster 1 has high average unit price and low net revenue. This corresponds to the findings we have from looking at the cluster centroids. For higher dimensions and larger number of clusters, it gets more difficult to visualize using scatter plots. However, very often, visualizing in charts helps draw insights more easily from these clustering analyses. Let's start looking at how we can evaluate the cluster quality and choose the optimal number of clusters using the Silhouette Coefficient.</span></p>
<p class="calibre2">The full code that was used in this k-means clustering step can be found at this link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.6/Clustering.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.6/Clustering.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Clustering model validations using the Silhouette Coefficient</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">The<strong class="calibre4"> Silhouette Coefficient</strong> or <strong class="calibre4">Silhouette Score</strong> provides an easy way to evaluate the quality of clusters. The Silhouette Coefficient measures how closely related an object is to its own cluster against the other clusters. The way to compute the Silhouette Coefficient is as follows; for each record, <kbd class="calibre12">i</kbd>, calculate the average distance between the record and all the other records in the same cluster and call this number, <kbd class="calibre12">a<sub class="calibre65">i</sub></kbd>. Then, calculate the average distances between the record and all the records in each other cluster for all the other clusters, take the lowest average distance, and call this number, <kbd class="calibre12">b<sub class="calibre65">i</sub></kbd>. Once you have these two numbers, subtract <kbd class="calibre12">a<sub class="calibre65">i</sub></kbd> from <kbd class="calibre12">b<sub class="calibre65">i</sub></kbd> and divide it by the maximum number between <kbd class="calibre12">a<sub class="calibre65">i</sub></kbd> and <kbd class="calibre12">b<sub class="calibre65">i</sub></kbd>. You iterate this process for all the records in the dataset and calculate the average value to get the Silhouette Coefficient. The following is a formula to calculate the Silhouette Coefficient for a single data point:</span></p>
<div class="mce-root3"><img src="../images/00095.jpeg" class="calibre85"/></div>
<p class="calibre2">In order to get the final Silhouette value, you will need to iterate through the data points and take the average of Silhouette values. The Silhouette Coefficient ranges between -1 and 1. The closer to 1, the better the cluster qualities are. The following code shows how we implemented this formula:</p>
<pre class="calibre19">private static double CalculateSilhouetteScore(Frame&lt;int, string&gt; df, string[] features, int numCluster, string clusterColname)<br class="title-page-name"/>{<br class="title-page-name"/>    double[][] data = BuildJaggedArray(df.Columns[features].ToArray2D&lt;double&gt;(), df.RowCount, features.Length);<br class="title-page-name"/><br class="title-page-name"/>    double total = 0.0;<br class="title-page-name"/>    for(int i = 0; i &lt; df.RowCount; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        double sameClusterAverageDistance = 0.0;<br class="title-page-name"/>        double differentClusterDistance = 1000000.0;<br class="title-page-name"/><br class="title-page-name"/>        double[] point = df.Columns[features].GetRowAt&lt;double&gt;(i).Values.ToArray();<br class="title-page-name"/>        double cluster = df[clusterColname].GetAt(i);<br class="title-page-name"/><br class="title-page-name"/>        for(int j = 0; j &lt; numCluster; j++)<br class="title-page-name"/>        {<br class="title-page-name"/>            double averageDistance = CalculateAverageDistance(df, features, clusterColname, j, point);<br class="title-page-name"/><br class="title-page-name"/>            if (cluster == j)<br class="title-page-name"/>            {<br class="title-page-name"/>                sameClusterAverageDistance = averageDistance;<br class="title-page-name"/>            } else<br class="title-page-name"/>            {<br class="title-page-name"/>                differentClusterDistance = Math.Min(averageDistance, differentClusterDistance);<br class="title-page-name"/>            }<br class="title-page-name"/>        }<br class="title-page-name"/><br class="title-page-name"/>        total += (differentClusterDistance - sameClusterAverageDistance) / Math.Max(sameClusterAverageDistance, differentClusterDistance);<br class="title-page-name"/>    }<br class="title-page-name"/><br class="title-page-name"/>    return total / df.RowCount;<br class="title-page-name"/>}</pre>
<p class="calibre2">A helper function to calculate the average distance between a data point and all the points in a cluster is as follows:</p>
<pre class="calibre19">private static double CalculateAverageDistance(Frame&lt;int, string&gt; df, string[] features, string clusterColname, int cluster, double[] point)<br class="title-page-name"/>{<br class="title-page-name"/>    var clusterDF = df.Rows[<br class="title-page-name"/>        df[clusterColname].Where(x =&gt; (int)x.Value == cluster).Keys<br class="title-page-name"/>    ];<br class="title-page-name"/>    double[][] clusterData = BuildJaggedArray(<br class="title-page-name"/>        clusterDF.Columns[features].ToArray2D&lt;double&gt;(),<br class="title-page-name"/>        clusterDF.RowCount,<br class="title-page-name"/>        features.Length<br class="title-page-name"/>    );<br class="title-page-name"/><br class="title-page-name"/>    double averageDistance = 0.0;<br class="title-page-name"/>    for (int i = 0; i &lt; clusterData.Length; i++)<br class="title-page-name"/>    {<br class="title-page-name"/>        averageDistance += Math.Sqrt(<br class="title-page-name"/>            point.Select((x, j) =&gt; Math.Pow(x - clusterData[i][j], 2)).Sum()<br class="title-page-name"/>        );<br class="title-page-name"/>    }<br class="title-page-name"/>    averageDistance /= (float)clusterData.Length;<br class="title-page-name"/><br class="title-page-name"/>    return averageDistance;<br class="title-page-name"/>}</pre>
<p class="calibre2">As you can see from the code, we iterate through each data point and start calculating the average distances between the given data point and all the other records in different clusters. Then, we take the difference between the lowest average distance to different clusters and the average distance within the same cluster and divide it by the maximum of those two numbers. Once we have iterated through all the data points, we take the average of this Silhouette value and return it as the Silhouette Coefficient for the clustering model.</p>
<p class="calibre2">When you run this code for the clustering models with different numbers of clusters, you will see an output similar to the following:</p>
<div class="mce-root"><img class="alignnone31" src="../images/00096.gif"/></div>
<p class="calibre2">As you can see from this output, the Silhouette Score increased as we increased the number of clusters to a certain point and then it dropped. In our case, a k-means clustering model with six clusters performed the best and six clusters seem to be the best choice for our dataset.</p>
<p class="calibre2">Oftentimes, just looking at the Silhouette Coefficient is not enough to make a decision on the best number of clusters. For example, a clustering model with a really large number of clusters can have a great Silhouette Score, but it would not help us draw any insights from such a clustering model. As clustering analysis is primarily used for explanatory analysis to draw insights and identify hidden patterns from the data, it is important that the clustering results can be explained. Pairing the Silhouette Score with two-dimensional or three-dimensional scatter plots will help you come up with the best number of clusters to choose and decide what makes the most sense to your dataset and project.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2">In this chapter, we explored unsupervised learning and how it can be used to draw insights and identify hidden patterns in the data. Unlike other projects we have worked on so far, we did not have specific target variables that our ML models can learn from. We just had a raw online retail dataset, in which we had information about the items, quantities, and unit prices that customers bought on the online store. With this given dataset, we transformed transaction-level data into customer-level data and created numerous aggregate features. We learned how we can utilize the <kbd class="calibre12">AggregateRowsBy</kbd> method in Deedle's data frame to create aggregate features and transform the dataset to have a customer-centric view. We then briefly discussed a new library, <kbd class="calibre12">CenterSpace.NMath.Stats</kbd>, which we can use for various statistical computations. More specifically, we used the <kbd class="calibre12">StatsFunctions.PercentileRank</kbd> method to compute the percentiles of each record for a given feature.</p>
<p class="calibre2">We covered how we can fit a k-means clustering algorithm using the <kbd class="calibre12">Accord.NET</kbd> framework. Using the k-means clustering algorithm, we were able to build a few clustering models with different numbers of clusters. We discussed how we can draw insights using the 4-cluster clustering model as an example and how we can cluster customers into different customer segments, where one segment's customer characteristics were <span class="calibre5">high net revenue, above-average unit price, and above-average quantity, the other segment's customer characteristics were low net revenue, high average unit price, and below-average quantity, and so forth. We then looked at the top 10 items each customer segment purchased the most frequently and created scatter plots of different segments on our feature space.</span></p>
<p class="calibre2"><span class="calibre5">Lastly, we used the</span> <strong class="calibre4">S</strong><span class="calibre5"><strong class="calibre4">ilhouette Coefficient</strong> to evaluate the cluster qualities, and learned how we can use this as one of the criteria for choosing the optimal number of clusters.</span></p>
<p class="calibre2">From the next chapter, we are going to start building models for audio and image datasets. In the next chapter, we are going to discuss how to build a music genre recommendation model using a music audio dataset. We will learn how to build a ranking system where the output is the ranks of likelihood of individual categories. We will also learn what types of metrics to use to evaluate such a ranking model.</p>


            </article>

            
        </section>
    </body></html>