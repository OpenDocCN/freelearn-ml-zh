<html><head></head><body>
		<div id="_idContainer188">
			<h1 id="_idParaDest-239"><em class="italic"><a id="_idTextAnchor241"/>Chapter 13</em>: Introducing H2O AI Cloud</h1>
			<p>In the previous sections of this book, we explored in great detail how to build accurate and trustworthy <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) models on massive data volumes using H2O technology, and how to deploy these models for scoring on a diversity of enterprise systems. In doing so, we became familiar with the technologies of H2O Core (H2O-3 and H2O Sparkling Water) and its distributed in-memory architecture to perform model building steps in a horizontally scalable way, using familiar IDEs and languages. We got to know H2O Enterprise Steam as a tool for data scientists to easily provision H2O environments and for administrators to manage users. We learned the technical nature of the H2O MOJO, the ready-to-deploy scoring artifact generated and exported from built models, and we learned a great diversity of patterns for scoring MOJOs on diverse target systems, whether real-time, batch, or streaming. We also learned how enterprise stakeholders beyond data scientists view and interact with H2O at scale technology.</p>
			<p>In this chapter, we will expand our knowledge by learning that H2O offers a larger end-to-end ML platform called H2O AI Cloud that includes multiple specialized model building engines, an MLOps platform to deploy and monitor models, a feature store to share features for model building and scoring, and a technology layer often not considered in the context of ML platforms – a low-code SDK to easily build AI applications on top of rest of the platform and an App Store to host them. </p>
			<p>Importantly, we will see that the technologies and skills we have learned up until now are actually a subset of the larger H2O AI Cloud.</p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>An H2O AI Cloud overview</li>
				<li>An H2O AI Cloud component breakdown</li>
				<li>H2O AI Cloud architecture</li>
			</ul>
			<h1 id="_idParaDest-240"><a id="_idTextAnchor242"/>Technical requirements</h1>
			<p>You can sign up for a 90-day trial to the H2O AI Cloud by visiting <a href="https://h2o.ai/freetrial">https://h2o.ai/freetrial</a>. This will allow you to use the components of the platform with your own data or with trial data supplied by H2O. </p>
			<p>We will see that part of the H2O AI Cloud is the ability of data scientists to build AI applications using an open source low-code SDK called H2O Wave. You can start building your own H2O Wave AI applications on your local machine by visiting here: <a href="https://wave.h2o.ai/docs/installation">https://wave.h2o.ai/docs/installation</a>.</p>
			<h1 id="_idParaDest-241"><a id="_idTextAnchor243"/>An H2O AI Cloud overview</h1>
			<p>The H2O AI Cloud<a id="_idIndexMarker1022"/> is an end-to-end ML platform designed to enable teams to seamlessly work through building models, trusting models, and deploying, monitoring, and governing models. In addition, the H2O AI Cloud includes an AI application development and hosting layer to allow various personas to interact with all steps in an ML life cycle – from applications expressing sophisticated visualizations to user interactions and workflows. The application SDK allows data scientists and ML engineers (and traditional software developers) to quickly prototype, finalize, and publish AI applications in a purpose-built way. For example, applications can be built for business users to view dashboards of customer churn predictions with analytics on reason codes and then respond to high churn candidates. Data scientists, on the other hand, can use an AI application to interactively validate model predictions against subsequent ground truth and track analytics around that. Alternatively, data scientists and ML engineers can use an AI application to automate retraining pipelines by orchestrating data drift alerts with model retraining and redeployment while tracking analytics and auditing.</p>
			<p>This simplified ML life cycle with an AI application layer is shown in the following diagram, and the H2O AI Cloud is organized around these layers:</p>
			<div>
				<div id="_idContainer185" class="IMG---Figure">
					<img src="image/B16721_13_001.jpg" alt="Figure 13.1 – A simplified ML life cycle with an AI app layer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.1 – A simplified ML life cycle with an AI app layer</p>
			<p>H2O has built a modular, flexible, and fully<a id="_idIndexMarker1023"/> capable end-to-end ML platform around this representation. The following diagram delineates the components of the H2O AI Cloud mapped to this life cycle:</p>
			<div>
				<div id="_idContainer186" class="IMG---Figure">
					<img src="image/B16721_13_002.jpg" alt="Figure 13.2 – An H2O hybrid cloud end-to-end ML platform (the H2O at scale components shown in gray)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.2 – An H2O hybrid cloud end-to-end ML platform (the H2O at scale components shown in gray)</p>
			<p>Before diving into each component and its capabilities, let's first get a high-level understanding:</p>
			<ul>
				<li><strong class="bold">Model building</strong>: There are four separate<a id="_idIndexMarker1024"/> and specialized model building engines and a tool<a id="_idIndexMarker1025"/> for data scientists to self-service provision their environments and for administrators to manage and govern users. Each model building engine generates a ready-to-deploy scoring artifact for models that are built.</li>
				<li><strong class="bold">Model deployment</strong>: An MLOps component<a id="_idIndexMarker1026"/> is used to deploy, monitor, manage, and <a id="_idIndexMarker1027"/>govern models.</li>
				<li><strong class="bold">Feature store</strong>: A feature store is available<a id="_idIndexMarker1028"/> to reuse features both<a id="_idIndexMarker1029"/> across teams during model building and across models during scoring.</li>
				<li><strong class="bold">AI applications</strong>: A low-code SDK is available<a id="_idIndexMarker1030"/> to rapidly build, prototype, and then<a id="_idIndexMarker1031"/> publish AI applications. The SDK includes widgets and templates to build sophisticated and interactive visualizations and workflows. Data scientists and ML engineers build the application in a familiar code-based way, focusing mostly on organizing and feeding data to templates and widgets while ignoring the complexities of web applications.</li>
				<li><strong class="bold">AI App Store</strong>: AI applications are developed locally<a id="_idIndexMarker1032"/> and then published to an AI App Store <a id="_idIndexMarker1033"/>component for consumption by business, data science, and other enterprise stakeholders. Clinicians in healthcare, for example, may use an application to prevent patients from being discharged from the hospital prematurely, while business analysts use a different part of the application to understand how frequent this is predicted to happen and why.</li>
				<li><strong class="bold">UI and API access to components</strong>: Users can interact<a id="_idIndexMarker1034"/> with H2O AI components<a id="_idIndexMarker1035"/> interactively<a id="_idIndexMarker1036"/> from both the UI and through APIs. Component APIs allow programmatic and automated approaches to interacting<a id="_idIndexMarker1037"/> with the platform and stitching<a id="_idIndexMarker1038"/> components together<a id="_idIndexMarker1039"/> in unique ways.</li>
			</ul>
			<p>In the next section, we will understand each H2O AI Cloud component more fully. Before doing so, however, let's introduce ourselves to the components with a table overview to get our bearings:</p>
			<div>
				<div id="_idContainer187" class="IMG---Figure">
					<img src="image/B16721_13_003.jpg" alt="Figure 13.3 – A table summarizing H2O AI Cloud components&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.3 – A table summarizing H2O AI Cloud components</p>
			<p>Finally, we need<a id="_idIndexMarker1040"/> to relate H2O AI Cloud components to the focus of this book, which we will do in the following note.</p>
			<p class="callout-heading">How the Focus of This Book Relates to H2O AI Cloud</p>
			<p class="callout">The focus of this book<a id="_idIndexMarker1041"/> has been <em class="italic">ML at scale with H2O</em>, which alternatively has been called <em class="italic">H2O at scale</em>. We have focused<a id="_idIndexMarker1042"/> on building ML models against massive datasets and deploying models to a diversity of enterprise scoring environments. </p>
			<p class="callout">From a component standpoint, the focus has been on H2O Core (H2O-3 and H2O Sparkling Water), H2O Enterprise Steam, and the H2O MOJO. These components can be deployed either as (a) separate from H2O AI Cloud, or (b) as members of H2O AI Cloud, as shown in <em class="italic">Figure 13.2</em>. See <a href="B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226"><em class="italic">Chapter 12</em></a>, <em class="italic">The Enterprise Architect and Security Views</em>, for an elaboration of this point. </p>
			<p>Now that we understand the fundamentals of H2O AI Cloud, its components, and how they relate to the focus of this book, let's expand our view and ML capabilities by elaborating further on each component.</p>
			<h1 id="_idParaDest-242"><a id="_idTextAnchor244"/>H2O AI Cloud component breakdown</h1>
			<p>Let's take a deeper dive into each of the components. </p>
			<h2 id="_idParaDest-243"><a id="_idTextAnchor245"/>DistributedML (H2O-3 and H2O Sparkling Water)</h2>
			<p>DistributedML has been<a id="_idIndexMarker1043"/> the focus of model building<a id="_idIndexMarker1044"/> for this book, where it is called H2O Core to represent either H2O-3 or Sparkling Water in that context. Fundamentally, you use H2O Core to build models on massive datasets. </p>
			<p>For the purposes of this chapter, the main features and capabilities are presented in the upcoming subsection For more details, see <a href="B16721_02_Final_SK_ePub.xhtml#_idTextAnchor024"><em class="italic">Chapter 2</em></a>, <em class="italic">Platform Components and Key Concepts</em>, to review the distributed in-memory architecture that enables model building on a massive scale. See <a href="B16721_04_Final_SK_ePub.xhtml#_idTextAnchor064"><em class="italic">Chapter 4</em></a>, <em class="italic">H2O Model Building at Scale – Capability Articulation</em>, to review its main capabilities in greater detail.</p>
			<h3>Key features and capabilities</h3>
			<p>The key features and capabilities<a id="_idIndexMarker1045"/> of H2O Core (H2O-3 and Sparkling Water) are as follows:</p>
			<ul>
				<li><strong class="bold">Model building on massive data volumes</strong>: H2O Core has an architecture that partitions and distributes data into memory across multiple servers. Model building computation is done in parallel against this architecture, thus achieving scaling needs for massive datasets. The larger the dataset, the more horizontally scaled the architecture will be. </li>
				<li><strong class="bold">Familiar data science experience</strong>: Data scientists build H2O models using familiar IDEs and languages (for example, Python in Jupyter notebooks) to express the H2O model building API. The API hides the complexities of the H2O scalable architecture from the user. To a data scientist, the experience fundamentally is that of writing code against data frames.</li>
				<li><strong class="bold">Flexible data ingest</strong>: H2O Core has connectors to access diverse data sources and data formats. Data is transferred directly from source to H2O Core-distributed memory.</li>
				<li><strong class="bold">Scalable data manipulation</strong>: Data is manipulated in the distributed architecture and thus is done at scale. The H2O API makes data manipulation steps concise. Sparkling Water specifically allows data manipulation using Spark APIs (for example, Spark SQL) and the conversion of Spark DataFrames to H2OFrames in the same coding workflow.</li>
				<li><strong class="bold">State-of-the-art algorithms</strong>: H2O Core implements state-of-the-art ML algorithms for supervised and unsupervised<a id="_idIndexMarker1046"/> problems, including, for example, XGBoost, a <strong class="bold">Gradient Boosting Machine</strong> (<strong class="bold">GBM</strong>), <strong class="bold">Generalized Linear Model </strong>(<strong class="bold">GLM</strong>), and <strong class="bold">Cox Proportional-Hazards</strong> (<strong class="bold">CoxPH</strong>), to name a few. These algorithms are run<a id="_idIndexMarker1047"/> on the distributed<a id="_idIndexMarker1048"/> architecture to scale to massive datasets.</li>
				<li><strong class="bold">AutoML</strong>: H2O can build models using an AutoML framework that explores algorithm and hyperparameter space to build a leaderboard of best models. The AutoML framework is controllable through numerous settings. </li>
				<li><strong class="bold">Explainability and auto-documentation</strong>: H2O Core implements extensive explainability capabilities and can generate auto-documentation to thoroughly describe model building and explain the resulting models.</li>
				<li><strong class="bold">MOJO</strong>: Models built on H2O Core generate a ready-to-deploy and low-latency scoring artifact called<a id="_idIndexMarker1049"/> a MOJO that can be flexibly deployed to diverse target environments. This was discussed in great detail in <a href="B16721_09_Final_SK_ePub.xhtml#_idTextAnchor159"><em class="italic">Chapter 9</em></a>, <em class="italic">Production Scoring and the H2O MOJO</em>.</li>
			</ul>
			<p>Let's move on to H2O AI Cloud's next model building engine.</p>
			<h2 id="_idParaDest-244"><a id="_idTextAnchor246"/>H2O AutoML (H2O Driverless AI)</h2>
			<p>H2O Driverless AI is a highly<a id="_idIndexMarker1050"/> automated AutoML tool built<a id="_idIndexMarker1051"/> in part by Kaggle Grandmaster data scientists to incorporate data science best practices and AI heuristics to find highly accurate models in short amounts of time. Some of its key capabilities are rich explainability features, a genetic algorithm to iterate to the best model, and exhaustive feature engineering and selection to derive and use new features. Let's investigate these key features and capabilities.</p>
			<h3>Key features and capabilities</h3>
			<p>The H2O Driverless AI key features and capabilities<a id="_idIndexMarker1052"/> are as follows:</p>
			<ul>
				<li><strong class="bold">Problem types</strong>: H2O Driverless AI builds both <em class="italic">supervised</em> and <em class="italic">unsupervised</em> models: <ul><li><strong class="bold">Supervised learning</strong>: For supervised learning<a id="_idIndexMarker1053"/> on tabular data, H2O Driverless AI addresses regression, binary and multiclass classification, and time-series forecasting problems. For supervised learning on images, Driverless AI addresses image classification, and for <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>), it addresses text classification<a id="_idIndexMarker1054"/> and context<a id="_idIndexMarker1055"/> tagging problems.</li><li><strong class="bold">Unsupervised learning</strong>: For unsupervised learning, Driverless AI tackles anomaly detection, clustering, and <a id="_idIndexMarker1056"/>dimensionality reduction problems.</li></ul></li>
				<li><strong class="bold">GPU support</strong>: Driverless AI can leverage GPUs for image and NLP problems, which run TensorFlow and PyTorch algorithms.</li>
				<li><strong class="bold">Genetic algorithm</strong>: Driverless AI uses a proprietary genetic algorithm to iterate across dozens<a id="_idIndexMarker1057"/> of models, each of which<a id="_idIndexMarker1058"/> varies in its algorithm (for example, XGBoost, Generalized Linear Model, and LightGBM), its exploration of hyperparameter space, and its exploration of feature engineering space. The best models are promoted to the next iteration and new model variations are introduced during each iteration. This continues until it cannot find a better model based on the settings that users make.</li>
				<li><strong class="bold">Feature engineering</strong>: During the genetic algorithm, Driverless AI applies dozens of transformers in exhaustive ways to engineer new features from those in the original dataset and determine which ones to include in the final model. These transformers<a id="_idIndexMarker1059"/> are categorized as follows:<ul><li><strong class="bold">Numeric</strong>: These are mathematical operations among two or more original features – for example, subtracting two features or clustering multiple features for the dataset and measuring the distance to a specific cluster for each observation.</li><li><strong class="bold">Categorical</strong>: These are transformations of category labels to numbers – for example, taking the average or frequency of the target variable for each category and assigning it to the category represented for each observation.</li><li><strong class="bold">Time and date</strong>: These are transformations of time and date fields to alternative time and date representations – for example, converting the date to the day of the week.</li><li><strong class="bold">Time series</strong>: These transformations<a id="_idIndexMarker1060"/> derive new features useful for time-series problems – for example, using a lag time for a feature value.</li><li><strong class="bold">Text</strong>: These transformations convert<a id="_idIndexMarker1061"/> strings to alternative representations – for example, using pre-trained <strong class="bold">Bidirectional Encoder Representations from Transformers</strong> (<strong class="bold">BERT</strong>) models to generate new language representations.</li></ul></li>
				<li><strong class="bold">Bring your own recipes</strong>: In addition to access to extensive expert settings, data scientists can control<a id="_idIndexMarker1062"/> the automated ML process<a id="_idIndexMarker1063"/> by importing their own code, which H2O calls recipes. These custom recipes can take the following form – <em class="italic">scorer</em> (your own performance metric used to optimize models in the genetic algorithm), <em class="italic">feature engineering</em> (your own engineered feature), or <em class="italic">algorithm</em> (your choice of ML algorithm to supplement familiar Driverless AI out-of-the-box algorithms).</li>
				<li><strong class="bold">Interpretability (Explainability)</strong>: Users can interact with diverse and full-featured interpretability techniques to explain the resulting models. These techniques can be applied at the <em class="italic">global</em> (entire model) or <em class="italic">local</em> (individual record) levels. These techniques include <em class="italic">surrogate</em> and <em class="italic">actual model </em>techniques, including K-Lime and Shapley, Decision Tree, Disparate Impact Analysis, Sensitivity Analysis, and Partial Dependence Plots. There are also explainers for time-series and NLP problems specifically.</li>
				<li><strong class="bold">Auto-documentation</strong>: Each final model generated by the genetic algorithm creates extensively standardized (typically over 60 pages) auto-documentation that describes in great detail experiment overview, data overview, methodology, validation strategy, model tuning, feature transformations and evolution, a final model, and explainability. The document is in paragraph, tabular, and graphic form.</li>
				<li><strong class="bold">MOJO</strong>: Each final model generated by the genetic algorithm creates a ready-to-deploy and low-latency MOJO that is flexibly deployed to diverse target environments. This is a similar technology to that discussed in <a href="B16721_09_Final_SK_ePub.xhtml#_idTextAnchor159"><em class="italic">Chapter 9</em></a>, <em class="italic">Production Scoring and the H2O MOJO,</em> for H2O at scale (H2O-3 and Sparkling Water). <p class="callout-heading">Important Note </p><p class="callout">The MOJO for Driverless AI performs the feature<a id="_idIndexMarker1064"/> engineering for features derived during the automated model <a id="_idIndexMarker1065"/>building process.</p></li>
			</ul>
			<p>Let's now move on to the DeepLearningML engine.</p>
			<h2 id="_idParaDest-245"><a id="_idTextAnchor247"/>DeepLearningML (H2O Hydrogen Torch)</h2>
			<p>H2O Hydrogen Torch<a id="_idIndexMarker1066"/> is a UI-based deep learning<a id="_idIndexMarker1067"/> engine that empowers data scientists of all skill levels (and perhaps analysts for some use cases) to easily build state-of-the-art computer vision and NLP models. The key features and capabilities are as follows.</p>
			<h3>Key features and capabilities</h3>
			<p>The H2O Hydrogen Torch features and capabilities<a id="_idIndexMarker1068"/> are as follows:</p>
			<ul>
				<li><strong class="bold">Problem types</strong>: Currently, Hydrogen<a id="_idIndexMarker1069"/> Torch addresses six <strong class="bold">computer vision</strong> (<strong class="bold">CV</strong>) and five NLP problem types, described briefly as follows:<ul><li><strong class="bold">Image classification (CV)</strong>: Images are classified into one or more sets of classes – for example, an image is classified as car versus truck.</li><li><strong class="bold">Image regression (CV)</strong>: A continuous value is predicted from an image – for example, the steering angle from a self-driving car image is positive 20 degrees from the center line. </li><li><strong class="bold">Object detection (CV)</strong>: An object (or objects) is classified from an image and its position coordinates are identified as a bounding box – for example, multiple cars are identified, each with a rectangle defined around it. </li><li><strong class="bold">Semantic segmentation (CV)</strong>: An object (or objects) is classified as well as its exact shape, defined<a id="_idIndexMarker1070"/> by pixel positions – for example, the exact outline of a person or all people in an image.</li><li><strong class="bold">Instance segmentation (CV)</strong>: This is the same as semantic segmentation, but when multiple objects of the same class are identified in instance segmentation, they are treated separately, whereas in semantic segmentation, they are treated as one object.</li><li><strong class="bold">Image metric learning (CV)</strong>: Predicts the similarity between images – for example, for a picture<a id="_idIndexMarker1071"/> of a retail product, it will find the likelihood that a new picture is the same product. </li><li><strong class="bold">Text classification (NLP)</strong>: Classifies text (document, page, and snippet) into a class – for example, classifying the sentiment or intent of text.</li><li><strong class="bold">Text regression (NLP)</strong>: Predicts a continuous value from text – for example, prediction of a person's salary from a resume.</li><li><strong class="bold">Text sequence to sequence (NLP)</strong>: Converts text sequences in one context to text sequences in another context – for example, converting a document into a summary.</li><li><strong class="bold">Text token classification (NLP)</strong>: Classifies each word in a text to a label – for example, identifying the United Nations<a id="_idIndexMarker1072"/> as an organization (an example of <strong class="bold">Named Entity Recognition</strong> (<strong class="bold">NER</strong>)) or identifying a word <a id="_idIndexMarker1073"/>as a noun or verb (example of <strong class="bold">Part-of-Speech</strong> (<strong class="bold">POS</strong>) tagging).</li><li><strong class="bold">Text metric learning (NLP)</strong>: Predicts the similarity between two sets of text – for example, identifying duplicate information or similar documents.</li></ul></li>
				<li><strong class="bold">Ease of building deep learning models</strong>: Hydrogen Torch is a no-code approach to building<a id="_idIndexMarker1074"/> deep learning models. The user interacts with a UI that has extensive controls on hyperparameter tuning and a rich interface to quickly iterate, understand, and evaluate model outcomes. Models can be exported for deployment to Python or H2O MLOps environments.</li>
				<li><strong class="bold">Modes for user skill set</strong>: The Hydrogen Torch training UI adapts to the user skill level by exposing fewer or more model building settings, according to whether the user is a novice, skilled, an expert, or a master.</li>
			</ul>
			<p>Now, let's move on to a model building engine that focuses on documents.</p>
			<h2 id="_idParaDest-246"><a id="_idTextAnchor248"/>DocumentML (H2O Document AI)</h2>
			<p>Documents typically<a id="_idIndexMarker1075"/> represent a vast untapped data source<a id="_idIndexMarker1076"/> for enterprises to apply ML techniques to automate processing steps, and thus save large amounts of time and money compared to manual processing. H2O's Document AI engine learns from documents to accomplish this automation. </p>
			<p>Document AI goes beyond simple <strong class="bold">Optical Character Recognition</strong> (<strong class="bold">OCR</strong>) and NLP by learning to recognize information<a id="_idIndexMarker1077"/> structures of documents such as tables, forms, logos, and sections. The Document AI model is trained to extract text entities from documents using these capabilities. Documents can thus be processed to extract specific information from medical lab results, financial statements, loan applications, and so on. This output can then drive analytics and workflows from these documents, which become increasingly more valuable as the volume of document processing grows. Document AI can also classify an entire document to further automation of document processing pipelines.</p>
			<h3>Key features and capabilities</h3>
			<p>Let's breakdown these<a id="_idIndexMarker1078"/> capabilities further:</p>
			<ul>
				<li><strong class="bold">Document ingest</strong>: Ingests documents such as PDFs, images, Word, HTML, CSV files, text files, emails, and others.</li>
				<li><strong class="bold">Preprocessing</strong>: Document AI uses OCR and NLP capabilities to perform multiple preprocessing steps, such as handling embedded text (for example, PDF metadata) and logos, and orientating, deskewing, and cropping pages.</li>
				<li><strong class="bold">Apply document labels</strong>: Users access a UI to apply labels to document text. Models will be trained to recognize these labeled entities. For example, on a medical lab document, the user applies labels to the patient name, the lab name, the lab address, the test name, the test result value, the test result unit, the test result normal range, and so on.</li>
				<li><strong class="bold">Train models</strong>: Document AI trains against a labeled document set. It learns to associate text with labels in the larger context of the structure of the document – for example, lab results are reported from rows in a table. Note that models are trained against a known document set and afterward will be able to pull information from documents they have never seen before. For example, each lab produces its own report (its own design, the styling of tables, number of pages, the position of the patient name in the document, and so on). Even though the model is trained on a small set of lab reports (typically 100 or so), it can then pull information from documents sent from a lab it has not been trained on.</li>
				<li><strong class="bold">Post-processing</strong>: Document AI allows users to customize and standardize how results are outputted. For example, users can define an output JSON structure with date output formats standardized.</li>
				<li><strong class="bold">Model deployment</strong>: Models can be exported and deployed to H2O MLOps or a Python environment of your choice.</li>
			</ul>
			<p>Now that we have explored<a id="_idIndexMarker1079"/> the four specialized model<a id="_idIndexMarker1080"/> building engines on H2O AI Cloud, let's see how features for those engines can be shared and operationalized.</p>
			<h2 id="_idParaDest-247"><a id="_idTextAnchor249"/>A self-provisioning service (H2O Enterprise Steam)</h2>
			<p>H2O Enterprise Steam<a id="_idIndexMarker1081"/> allows users to self-provision<a id="_idIndexMarker1082"/> model building environments and administrators to govern users and their resource consumption. As with H2O Core and the scoring artifact it generates called the MOJO, Enterprise Steam is considered a key component of H2O ML at scale and was introduced in <a href="B16721_02_Final_SK_ePub.xhtml#_idTextAnchor024"><em class="italic">Chapter 2</em></a>, <em class="italic">Platform Components and Key Concepts</em>, and then explored in detail in <a href="B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207"><em class="italic">Chapter 11</em></a>, <em class="italic">The Administrator and Operations View</em>. </p>
			<p>Note that in that context, Enterprise Steam was used to self-provision and manage H2O Core environments only, but in the context of the H2O AI Cloud, it is used to manage all H2O model building engines. Let's review its key capabilities.</p>
			<h3>Key features and capabilities</h3>
			<p>The key capabilities of H2O Enterprise Steam<a id="_idIndexMarker1083"/> are listed briefly as follows:</p>
			<ul>
				<li><strong class="bold">Easy self-provisioning of H2O model building environments</strong>: Data scientists can define, launch, and manage their H2O model building environments from the Enterprise Steam UI or API. Note that, currently, this is true for DistributedML (H2O Core) and AutoML (Driverless AI) environments. Hydrogen Torch and Document AI environments currently are launched as applications, but they are road-mapped to consolidate into the Enterprise Steam self-provisioning framework.</li>
				<li><strong class="bold">Administrator management and governance of users</strong>: Administrators manage users and define the amount of resources (CPU and memory) they can use when provisioning<a id="_idIndexMarker1084"/> environments, including how long those environments sit idle before spinning down.</li>
			</ul>
			<p>Let's move on now to the Feature Store component.</p>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor250"/>Feature Store (H2O AI Feature Store)</h2>
			<p>H2O AI Feature Store<a id="_idIndexMarker1085"/> is a system to organize, govern, share, and operationalize<a id="_idIndexMarker1086"/> predictive ML features across the enterprise in both the model building and live scoring contexts. This saves significant time for data scientists to discover features and for both data scientists and ML engineers to transform raw data into these features. Let's explore the capabilities further.  </p>
			<h3>Key features and capabilities</h3>
			<p>Here are some key features<a id="_idIndexMarker1087"/> of the H2O AI Feature Store:</p>
			<ul>
				<li><strong class="bold">Versatile feature publishing and search workflow</strong>: Data scientists and engineers engineer feature pipelines using pre-built integrations into Snowflake, Databricks, H2O Sparkling Water, and other technologies. The resulting features are outputted to the H2O AI Feature Store with over 40 metadata attributes associated with the feature. This cataloging of features and their attributes allows other data scientists to search for relevant features and for the Feature Store's built-in AI to recommend features.</li>
				<li><strong class="bold">Scalable and timely feature consumption</strong>: Each feature in the Feature Store has a defined duration until it is refreshed. Features can be stored offline for training and batch scoring or stored online for low-latency real-time scoring. </li>
				<li><strong class="bold">Automatic feature drift and bias detection</strong>: Features are automatically checked for data drift and users are alerted when drift is detected. This can be essential in deciding to retrain models with more recent data. Features are also automatically checked for bias and alert users when bias is detected. This can be essential in retraining models to remove bias.</li>
				<li><strong class="bold">Access management and governance</strong>: H2O AI Feature Store integrates with the enterprise identity provider to authenticate users and authorize access to features. Features and their metadata are versioned for regulatory compliance and to backtest models against ground truth.</li>
			</ul>
			<p>H2O AI Cloud<a id="_idIndexMarker1088"/> has a fully capable model <a id="_idIndexMarker1089"/>operations component. Let's learn more about that next.</p>
			<h2 id="_idParaDest-249"><a id="_idTextAnchor251"/>MLOps (H2O MLOps)</h2>
			<p>H2O MLOps is a platform<a id="_idIndexMarker1090"/> to deploy, manage, monitor, and govern <a id="_idIndexMarker1091"/>models. These can be either models generated from any of the H2O model building engines (DistributedML, AutoML, DeepLearningML, or DocumentML) or models from non-H2O software (for example, scikit-learn or MLflow). Note that H2O MLOps<a id="_idIndexMarker1092"/> workflows can be completed using the UI or API, with the latter essential for integrating into <strong class="bold">continuous integration and continuous deployment (CI/CD)</strong> workflows. Major capabilities are elaborated as follows.</p>
			<h3>Key features and capabilities</h3>
			<p>Here are the key features<a id="_idIndexMarker1093"/> of H2O MLOps:</p>
			<ul>
				<li><strong class="bold">Model deployment</strong>: Easy deployment of H2O and non-H2O models. Scoring is available as a REST endpoint for both real-time and batch scoring. Models are deployed as either a single model (simple deployment), champion/challenger (compare a new model to current model where the only current model is live), or an A/B test (multiple live models with live data are routed among them in configured proportions). Models are deployed to defined environments, typically development and production, but you may add more.</li>
				<li><strong class="bold">Model monitoring</strong>: Models are monitored for health, scoring latency, data drift, fairness (bias) degradation, and performance degradation. Alerts are presented on the monitoring dashboard and sent to configured recipients. Alerts can be used to trigger model retraining and deployment.</li>
				<li><strong class="bold">Model management</strong>: Models can be compared and evaluated, promoted to a registry, and then deployed. Models are associated with extensive metadata, allowing traceability to model building details and evaluation against other models. Models in the registry (and subsequent deployment) are versioned. Deployed models can be rolled back to previous versions.</li>
				<li><strong class="bold">Model governance</strong>: The versioning and traceability achieved through model management create a lineage of model history. Users have role-based access with actions that are audited. Administrators have a dedicated dashboard to provide visibility across all users, models, and audit logs. These capabilities combine a result in an overall governance process that minimizes model risk and facilitates regulatory compliance.</li>
			</ul>
			<p>We started this chapter by recognizing<a id="_idIndexMarker1094"/> an application layer that integrates<a id="_idIndexMarker1095"/> the rest of the H2O AI Cloud platform. Let's learn more about that.</p>
			<h2 id="_idParaDest-250"><a id="_idTextAnchor252"/>Low-code SDK for AI applications (H2O Wave)</h2>
			<p>H2O Wave<a id="_idIndexMarker1096"/> is an open source and low-code Python SDK to build real-time AI applications with sophisticated visualizations. Low code<a id="_idIndexMarker1097"/> is achieved by abstracting the complexities of web application coding away from the application developer while exposing higher-level UI components as templates, themes, and widgets. Data scientists and ML engineers are intended as developers (as well as software developers themselves). </p>
			<p>Examples of H2O Wave applications have been built by H2O data scientists as capability demonstrators. These can<a id="_idIndexMarker1098"/> be found on the H2O AI Cloud 90-day evaluation site at <a href="https://h2o.ai/freetrial">https://h2o.ai/freetrial</a>. Additional examples are on the H2O public<a id="_idIndexMarker1099"/> GitHub repository at <a href="https://github.com/h2oai/wave-apps">https://github.com/h2oai/wave-apps</a>. </p>
			<p class="callout-heading">How Do I Try Building Wave Applications?</p>
			<p class="callout">Instructions to download the Wave server and SDK to build your<a id="_idIndexMarker1100"/> own applications can be found at <a href="https://wave.h2o.ai/docs/installation">https://wave.h2o.ai/docs/installation</a>.</p>
			<h3>Key features and capabilities</h3>
			<p>The following<a id="_idIndexMarker1101"/> are the key features and capabilities of H2O Wave:</p>
			<ul>
				<li><strong class="bold">Low-code SDK</strong>: Data scientists and ML engineers focus on specifying templates and widgets and feeding data into them to create sophisticated visualizations, dashboards, and workflows. The complexities of web application code are abstracted away from the developer.</li>
				<li><strong class="bold">Extensive native data connectors</strong>: You have access to over 160 connectors to data sources and sinks from the SDK.</li>
				<li><strong class="bold">Native H2O APIs</strong>: The SDK includes H2O APIs that integrate other H2O AI Cloud components. This enables data scientists and ML engineers to integrate aspects of the ML life cycle as a backend to the application visualizations and workflows.</li>
				<li><strong class="bold">Use any Python package</strong>: Applications are isolated as containers, thus allowing any Python package to be used by the application – for example, NumPy and pandas for data manipulation and Bokeh and Matplotlib for data visualizations, to name just a few.</li>
				<li><strong class="bold">Integrate non-H2O technology</strong>: When Python packages in your application represent public APIs such as the Twitter API, AWS service APIs, or your own private Python APIs, Wave applications can integrate non-H2O technology into its visualizations and workflows. Wave applications can thus be built as single panes of glass across multiple technologies.</li>
				<li><strong class="bold">Publish to H2O App Store</strong>: Wave applications are developed locally and then published<a id="_idIndexMarker1102"/> to the H2O AI Cloud App Store for enterprise consumption.</li>
			</ul>
			<p>Let's now take a look at the H2O App Store.</p>
			<h2 id="_idParaDest-251"><a id="_idTextAnchor253"/>App Store (H2O AI App Store)</h2>
			<p>The H2O AI App Store <a id="_idIndexMarker1103"/>hosts your H2O Wave applications<a id="_idIndexMarker1104"/> in your H2O AI Cloud instance. H2O Wave applications are hosted in a searchable and role-based way. Users logged in to the App Store see only the applications they are allowed to use and can find them by custom-defined categories or by search. Wave application developers publish to the App Store, and administrators manage the App Store.</p>
			<p>Application consumers thus access and use Wave applications through the App Store, though data scientists and ML engineer developers may prototype with consumers locally before publishing to the App Store.</p>
			<p>Let's now get a high-level understanding of the H2O AI Cloud architecture.</p>
			<h1 id="_idParaDest-252"><a id="_idTextAnchor254"/>H2O AI Cloud architecture</h1>
			<p>We will not dive deep into H2O AI Cloud Architecture but will review three important architecture points:</p>
			<ul>
				<li><strong class="bold">Components are modular and open</strong>: The platform's modular architecture allows enterprises<a id="_idIndexMarker1105"/> or groups to use the components they need and to hide and ignore the ones they do not. H2O AI Cloud is also open – its components can coexist and interact with the larger enterprise ecosystem, including non-H2O AI/ML components. The MLOps component, for example, can host non-H2O models, such as scikit-learn models, and the AI application Wave SDK can integrate non-H2O APIs with its own.</li>
				<li><strong class="bold">Cloud-native architecture</strong>: H2O AI Cloud is built on a modern Kubernetes architecture that achieves<a id="_idIndexMarker1106"/> efficient resource consumption among cloud servers. In addition, H2O workloads on the AI Cloud are ephemeral – they spin up when needed, spin down when not in use, and retain state when spinning up again. The H2O AI Cloud also leverages the cloud service providers' managed services – for example, using the cloud-managed Kubernetes service and maintaining state in a managed PostgreSQL database.</li>
				<li><strong class="bold">Flexible deployment</strong>: H2O AI Cloud can be deployed<a id="_idIndexMarker1107"/> in an enterprise's cloud, on-premises, or in a hybrid environment. Alternatively, it can be consumed as a managed service where H2O hosts and manages the enterprise's H2O AI Cloud platform in H2O's cloud environment.</li>
			</ul>
			<p>These architecture points combined with the capabilities of each component mean that enterprises can fit the H2O AI Cloud to their specific environment, use case needs, and stage of their AI transformation journey.</p>
			<p>Let's summarize what we've learned in this chapter.</p>
			<h1 id="_idParaDest-253"><a id="_idTextAnchor255"/>Summary</h1>
			<p>In this chapter, we expanded our view beyond <em class="italic">H2O ML at scale</em>, which has been the focus of this book to this point. We did this by introducing H2O's end-to-end ML platform called H2O AI Cloud. This platform has a broad set of components in the model building and model deployment steps of the ML life cycle and introduces a lesser-considered layer to this flow – easy-to-build AI applications and an App Store to serve them. We learned that H2O AI Cloud has four specialized engines for building ML models – DistributedML, AutoML, DeepLearningML, and DocumentML. We learned that MLOps has a full capability set around deploying, monitoring, managing, and governing models for scoring. We also learned that a Feature Store is available to centralize and reuse features for model building and model scoring. </p>
			<p>Importantly, we learned that the focus of this book, building ML models on massive datasets and deploying to enterprise systems for scoring (what we have called H2O at scale), uses technology (H2O Core, H2O Enterprise Steam, and H2O MOJO) that is actually a subset of the larger H2O AI Cloud platform. </p>
			<p>We made the point thatH2O at scale technology can be deployed separately from H2O AI Cloud or as a part of the larger platform. In the next chapter, we are going to see additional capabilities that H2O at scale takes on by being a member of the H2O AI Cloud.</p>
		</div>
	</body></html>