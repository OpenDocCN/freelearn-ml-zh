<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer329">
    <h1 class="chapterNumber">10</h1>
    <h1 class="chapterTitle" id="_idParaDest-219">Enhancing Brand Presence with Few-Shot Learning and Transfer Learning</h1>
    <p class="normal">This chapter explores the capabilities<a id="_idIndexMarker810"/> of <strong class="keyWord">few-shot learning</strong> (<strong class="keyWord">FSL</strong>) and its value in enhancing brand presence through tailored marketing strategies. Building on the insights<a id="_idIndexMarker811"/> from <strong class="keyWord">zero-shot learning</strong> (<strong class="keyWord">ZSL</strong>) covered in the previous chapter, we now focus on how FSL, by utilizing a limited set of examples, enables rapid and effective adaptation of AI models to new tasks. This approach is particularly valuable in marketing, where the ability to swiftly adjust content to align with evolving consumer preferences and market trends is crucial.</p>
    <p class="normal">Initially, we will introduce some of the fundamental concepts of FSL in the context of meta-learning as an underlying technique that facilitates quick learning from small datasets. We will then explore the synergy between FSL and transfer learning using practical examples; while FSL is effective at quickly adapting to new tasks with few examples, transfer learning complements this by utilizing pre-trained models that are fine-tuned for specific tasks, reducing the need for extensive model retraining.</p>
    <p class="normal">This chapter highlights how combining FSL with related strategies can optimize marketing efforts, making them more responsive and efficient. This chapter equips you with the understanding to:</p>
    <ul>
      <li class="bulletList">Grasp the core concepts of FSL and its similarities to and differences from transfer learning</li>
      <li class="bulletList">Recognize the practical benefits of employing FSL to adapt quickly to new marketing conditions with limited data</li>
      <li class="bulletList">Apply FSL and transfer learning techniques to real-world marketing scenarios to enhance brand messaging and consumer engagement</li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-220">Navigating FSL</h1>
    <p class="normal">In the marketing <a id="_idIndexMarker812"/>domain, the agility to quickly tune content strategies to meet the evolving needs of a brand is invaluable. FSL stands out for its capacity to effectively learn and perform tasks with limited input data. While ZSL is designed to work without any specific examples of the new classes during inference, relying on a generalized, abstract understanding of the task derived from previously learned tasks, FSL uses a small number of examples to adapt to new tasks. This adaptation often relies on a more direct application of learned patterns and can be fine-tuned with data, making it particularly effective when some example data is available. This efficiency enables marketers to rapidly test new strategies, such as personalizing email campaigns for different customer segments or quickly adapting social media content to reflect emerging trends, without the long lead times associated with gathering and training on extensive datasets. For instance, a marketing manager might use FSL to generate tailored marketing copy that aligns with a company’s rebranding initiative, as we will discuss in the <em class="italic">Applying FSL to improve brand consistency section</em>, even when there are limited examples of such rebranded content available.</p>
    <p class="normal">As we further explore the utility of FSL for enhancing brand presence, it’s essential to build on our conceptual understanding<a id="_idIndexMarker813"/> of <strong class="keyWord">Generative AI</strong> (<strong class="keyWord">GenAI</strong>) introduced in the previous chapter. FSL hinges on the idea that intelligent systems can learn new concepts or tasks with only a small number of training examples, drawing heavily from prior knowledge and the application of sophisticated meta-learning algorithms. This discussion will extend your foundational knowledge of this concept, bridging the gap between high-level concepts and practical applications that are useful for understanding the hands-on examples given later in this chapter.</p>
    <p class="normal">At its core, FSL is often facilitated<a id="_idIndexMarker814"/> by <strong class="keyWord">meta-learning</strong>, an approach that enables models to quickly adapt to new tasks by using learnings from a variety of prior tasks. However, meta-learning is just one possible approach, and others such as metric-based learning, whereby models are trained to compare new instances against a few labeled examples using a learned metric or distance function, can also be used. Given its broad applicability and effectiveness <a id="_idIndexMarker815"/>as an FSL approach, let’s explore meta-learning further in the next section.</p>
    <h2 class="heading-2" id="_idParaDest-221">Understanding FSL through meta-learning</h2>
    <p class="normal">FSL often involves<a id="_idIndexMarker816"/> meta-learning, or “learning to learn,” whereby <a id="_idIndexMarker817"/>models are designed to quickly adapt to new tasks based on learnings from a wide array of previous tasks. </p>
    <p class="normal">This is particularly crucial in marketing, where consumer behavior and preferences can be dynamic, requiring models that can pivot quickly without extensive retraining. Meta-learning frameworks in FSL train models on a variety of tasks, enabling them to develop a generalized understanding or an internal representation that can efficiently map to new tasks with minimal additional input. Some of the key components of meta-learning are:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Task variety</strong>: Meta-learning <a id="_idIndexMarker818"/>algorithms are exposed to a wide variety of learning tasks during the training phase. This exposure helps the model learn more robust features that are not overly specific to one task but are general enough to be applicable across a spectrum of future tasks. This is analogous to a marketing team working across different campaign types like email or social media and learning to identify core elements that predict success regardless of the specific product or audience.</li>
      <li class="bulletList"><strong class="keyWord">Rapid adaptation</strong>: The primary goal of meta-learning is to enable rapid learning on new tasks. This is achieved through the model’s ability to fine-tune itself to new conditions with minimal training data. For instance, if a model trained in a meta-learning framework is faced with a new product launch, it can quickly adjust its parameters to optimize marketing content for the product’s target demographic based on its prior knowledge of similar products.</li>
      <li class="bulletList"><strong class="keyWord">Optimization techniques</strong>: Meta-learning involves special training schemes such as episodic training, whereby the model undergoes simulated training episodes. Each episode involves learning from a small set of data and then testing on a new set of data from the same task. This trains the model to generalize well from small data samples.</li>
    </ul>
    <p class="normal">Now let’s look at these fundamentals in action in the following example.</p>
    <h2 class="heading-2" id="_idParaDest-222">Implementing model-agnostic meta-learning in marketing</h2>
    <p class="normal">Let’s consider an example<a id="_idIndexMarker819"/> meta-learning<a id="_idIndexMarker820"/> model using a simple adaptation of <strong class="keyWord">model-agnostic meta-learning</strong> (<strong class="keyWord">MAML</strong>) and how it can be applied to optimize marketing strategies. MAML works by optimizing a model’s parameters so that a small number of gradient updates will lead to fast learning on a new task.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Learn more about MAML</strong></p>
      <p class="normal">MAML is a widely recognized meta-learning algorithm introduced by Finn et al. in 2017 in the paper <em class="italic">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</em>. For a deeper dive into the topic, including interactive examples, check out the resource: <span class="url">https://interactive-maml.github.io/</span>.</p>
    </div>
    <p class="normal">In this simplified implementation, we’ll simulate a single marketing task as a training input as a proxy for the multiple tasks that would be considered in a full MAML deployment. We will then train a simple neural network model on the task and then use the result of our meta-training to improve the model’s adaptability on a different task. The following diagram provides an illustration of the mechanics of a meta-learning framework, as well as what it might look like when applied to multiple marketing tasks as examples:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_01.png"/></figure>
    <p class="packt_figref">Figure 10.1: Key components of a possible MAML framework in the context of marketing campaigns</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Source code and data</strong>:</p>
      <p class="normal"><a href="https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.10"><span class="url">https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.10</span></a></p>
    </div>
    <p class="normal">Model-agnostic techniques are designed to be broadly applicable across a range of model architectures and tasks. To better understand the mechanics of the MAML approach, we will break down its application into several functions that are simplifications of what would be involved with a full implementation:</p>
    <ol>
      <li class="numberedList" value="1">First, we have a function, <code class="inlineCode">generate_task</code>, that creates simulated marketing tasks with its own set of coefficients representing campaign data, which, in this case, is represented as a quadratic relationship with noise. The randomly generated coefficients for each task dictate how input data (such as email campaign length, budget, or reach) affect the outcome (such as engagement or conversions). Then the <code class="inlineCode">task</code> function computes the campaign’s success metrics based on the input and the coefficients. Note that we provide seed values so that your output should be consistent with what’s shown here, but your results may still vary due to randomness from parallel <a id="_idIndexMarker821"/>processing <a id="_idIndexMarker822"/>or GPU usage:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dense
<span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> Adam
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
np.random.seed(<span class="hljs-number">123</span>)
tf.random.set_seed(<span class="hljs-number">123</span>)
<span class="hljs-keyword">def</span> <span class="hljs-title">generate_task</span>():
    coefficients = np.random.randn(<span class="hljs-number">3</span>) 
    <span class="hljs-keyword">def</span> <span class="hljs-title">task</span>(<span class="hljs-params">x</span>):
        <span class="hljs-keyword">return</span> coefficients[<span class="hljs-number">0</span>] * x**<span class="hljs-number">2</span> + coefficients[<span class="hljs-number">1</span>] * x + coefficients[<span class="hljs-number">2</span>] + np.random.randn(*x.shape) * <span class="hljs-number">0.1</span>
    <span class="hljs-keyword">return</span> task, coefficients
</code></pre>
      </li>
      <li class="numberedList">Next, we have a function, <code class="inlineCode">train_model_on_task</code>, that trains the model on one of the tasks generated by the previous function by performing short bursts of training on the task and using the <code class="inlineCode">Adam</code> optimizer to update the model’s weights. Then TensorFlow <code class="inlineCode">GradientTape</code> is used for automatic differentiation, calculating the gradients needed to minimize the loss, which measures how well the model’s predictions match the actual outcomes of the campaign:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">train_model_on_task</span>(<span class="hljs-params">model, task, steps=</span><span class="hljs-number">50</span><span class="hljs-params">, learning_rate=</span><span class="hljs-number">0.01</span>):
    optimizer = Adam(learning_rate)
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(steps):
        x = np.random.uniform(-<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, (<span class="hljs-number">50</span>, <span class="hljs-number">1</span>))
        y = task(x)
        <span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape:
            predictions = model(x, training=<span class="hljs-literal">True</span>)
            loss = tf.reduce_mean((predictions - y) ** <span class="hljs-number">2</span>)
        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(<span class="hljs-built_in">zip</span>(gradients, model.trainable_variables))
</code></pre>
      </li>
      <li class="numberedList">Then we have the <code class="inlineCode">meta_train_model</code> function, which is at the heart of meta-learning. This handles the meta-training process by optimizing the model’s ability to quickly adapt to new tasks after minimal exposure. In practice, the model is first trained on a task, and then it is evaluated on new data from the same task. </li>
    </ol>
    <p class="normal-one">The loss calculated from this evaluation guides adjustment of the model’s initial parameters so that just a few updates lead to significant improvements on new tasks. Note that in a full implementation, we<a id="_idIndexMarker823"/> would<a id="_idIndexMarker824"/> likely use a <code class="inlineCode">reset_weights</code> argument so that after each task the model’s weights are reset to their state before the task-specific training and a <code class="inlineCode">meta_optimizer</code> that updates the model’s initial parameters based on the task performance. This ensures that the model does not overfit to a particular task and retains its ability to generalize across tasks:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">meta_train_model</span>(<span class="hljs-params">base_model, meta_steps=</span><span class="hljs-number">50</span><span class="hljs-params">,                      meta_learning_rate=</span><span class="hljs-number">0.1</span>):
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(meta_steps):
        task, _ = generate_task()
        train_model_on_task(base_model, task, learning_rate=<span class="hljs-number">0.1</span>)
</code></pre>
    <ol>
      <li class="numberedList" value="4">To illustrate this simplified example in action, we can first initialize a very simple neural network with two layers to apply our meta-training function. Here, there is first a dense layer with 10 neurons and a sigmoid activation and then a final dense layer with just one neuron to capture the model’s prediction for the success of a marketing campaign based on the input feature:
        <pre class="programlisting code-one"><code class="hljs-code">model = Sequential([
    Dense(
        <span class="hljs-number">10</span>,
        activation=<span class="hljs-string">'sigmoid'</span>,
        kernel_initializer=<span class="hljs-string">'random_normal'</span>,
        input_shape=(<span class="hljs-number">1</span>,)
    ),
    Dense(<span class="hljs-number">1</span>)])
model.summary()
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This gives us the following summary:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_02.png"/></figure>
    <p class="packt_figref">Figure 10.2: Simple neural network model architecture</p>
    <ol>
      <li class="numberedList" value="5">Let’s now<a id="_idIndexMarker825"/> generate a<a id="_idIndexMarker826"/> proxy for a complex task using your quadratic function and plot the model’s performance on this task before training:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_predictions</span>(<span class="hljs-params">model, task, title</span>):
    x = np.linspace(-<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">100</span>).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)
    y_true = task(x)
    y_pred = model.predict(x)
    plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>))
    plt.scatter(x, y_true, color=<span class="hljs-string">'blue'</span>, label=<span class="hljs-string">'True Values'</span>)
    plt.scatter(x, y_pred, color=<span class="hljs-string">'red'</span>, label=<span class="hljs-string">'Predictions'</span>)
    plt.title(title)
    plt.xlabel(<span class="hljs-string">"Input Feature"</span>)
    plt.ylabel(<span class="hljs-string">"Output Value"</span>)
    plt.legend()
    plt.show()
complex_task, _ = generate_task()
plot_predictions(model, complex_task, <span class="hljs-string">"</span><span class="hljs-string">Model Performance Before Meta-training on Task"</span>)
</code></pre>
      </li>
    </ol>
    <p class="normal-one">The following plot shows the performance of the model before undergoing meta-training. As we can see, the model is initially unable to accurately predict the true values, indicating the need for further training and optimization:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_03.png"/></figure>
    <p class="packt_figref">Figure 10.3: Model performance before meta-training on the task</p>
    <ol>
      <li class="numberedList" value="6">Now we can <a id="_idIndexMarker827"/>perform <a id="_idIndexMarker828"/>meta-training using our algorithm and then plot the model’s performance again on the same task after meta-training:
        <pre class="programlisting code-one"><code class="hljs-code">meta_train_model(model)
plot_predictions(model, complex_task, <span class="hljs-string">"After Meta-training on Task"</span>)
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This yields the following plot:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_04.png"/></figure>
    <p class="packt_figref">Figure 10.4: Model performance after meta-training on the task</p>
    <p class="normal">As shown in <em class="italic">Figures 10.3</em> and <em class="italic">10.4</em>, the model initially fails to grasp any quadratic relationship in the data. After meta-training, however, the predictions improve. While this is a simplified<a id="_idIndexMarker829"/> implementation including <a id="_idIndexMarker830"/>only a simple task, this implementation framework gives a baseline for the mechanics of MAML as a tool for preparing your model for FSL.</p>
    <h2 class="heading-2" id="_idParaDest-223">Overcoming challenges in FSL</h2>
    <p class="normal">FSL aims to make the <a id="_idIndexMarker831"/>most out of minimal data, but this can come with inherent challenges such as overfitting and poor generalization. <strong class="keyWord">Overfitting</strong> occurs <a id="_idIndexMarker832"/>when a model, trained on a very small dataset, learns the noise and irrelevant details to the extent that it negatively impacts the performance on new data. To mitigate this, regularization techniques such as L2 regularization and dropout can be used to simplify the model complexity of neural networks, helping prevent the model from learning overly complex patterns that do not generalize well.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Regularization techniques to prevent overfitting</strong></p>
      <p class="normal">Two common regularization techniques in neural networks are:</p>
      <ul>
        <li class="bulletList">L2 regularization (weight decay) adds a penalty to the loss function based on the squared magnitude of the model’s weights. This discourages large weights, leading to simpler models that generalize better.</li>
      </ul>
      <p class="normal">Learn more here, including how to compare learning curves to evaluate the impact of regularization: <a href="https://developers.google.com/machine-learning/crash-course/overfitting/regularization"><span class="url">https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization</span></a>.</p>
      <ul>
        <li class="bulletList">Dropout randomly deactivates (“drops out”) neurons during training to prevent the model from becoming too reliant on specific pathways.</li>
      </ul>
      <p class="normal">Learn more in the seminal paper <em class="italic">Dropout: a simple way to prevent neural networks from overfitting</em> by Srivastava et al.</p>
    </div>
    <p class="normal">For instance, we could add these types of regularization while building a neural network model suitable for a regression task. As an illustration, the model is designed with a moderately complex<a id="_idIndexMarker833"/> architecture and includes several layers with both types of regularization:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dropout
<span class="hljs-keyword">from</span> tensorflow.keras.regularizers <span class="hljs-keyword">import</span> l2
<span class="hljs-keyword">def</span> <span class="hljs-title">build_regularized_model</span>(<span class="hljs-params">input_shape</span>):
    model = Sequential([
        Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>, input_shape=input_shape,
              kernel_regularizer=l2(<span class="hljs-number">0.001</span>)),
        Dropout(<span class="hljs-number">0.3</span>), 
        Dense(<span class="hljs-number">32</span>, activation=<span class="hljs-string">'relu'</span>, kernel_regularizer=l2(<span class="hljs-number">0.001</span>)), 
        Dropout(<span class="hljs-number">0.3</span>), 
        Dense(<span class="hljs-number">16</span>, activation=<span class="hljs-string">'</span><span class="hljs-string">relu'</span>, kernel_regularizer=l2(<span class="hljs-number">0.001</span>)),
        Dropout(<span class="hljs-number">0.3</span>),
        Dense(<span class="hljs-number">1</span>, activation=<span class="hljs-string">'linear'</span>) 
    ])
    model.<span class="hljs-built_in">compile</span>(optimizer=Adam(learning_rate=<span class="hljs-number">0.001</span>),
                  loss=<span class="hljs-string">'mean_squared_error'</span>)
    <span class="hljs-keyword">return</span> model
input_shape = (<span class="hljs-number">10</span>,)
model = build_regularized_model(input_shape)
model.summary()
</code></pre>
    <p class="normal">This yields the following summary:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_05.png"/></figure>
    <p class="packt_figref">Figure 10.5. Model architecture summary</p>
    <p class="normal">The model embeds L2 regularization within its dense layers to curb the weight size and encourage simpler models. A dropout of 0.3 is also applied after each dense layer, reducing overfitting by deactivating random neuron outputs during training. This regularization pattern is applied across the hidden layers to promote the model’s ability to generalize. The<a id="_idIndexMarker834"/> following figure provides a visualization of how dropout randomly deactivates neurons during training:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_06.png"/></figure>
    <p class="packt_figref">Figure 10.6: Dropout neural net model. Left: A standard neural net with two hidden layers. Right: An example of a thinned net produced by applying dropout to the network on the left. Crossed units have been dropped. (source: https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)</p>
    <p class="normal">As alluded to earlier, <strong class="keyWord">generalization</strong> is another <a id="_idIndexMarker835"/>critical challenge. In the field of image processing, data augmentation techniques like image rotation, cropping, or color adjustment are often employed to artificially enhance the dataset’s size and variability, helping the model learn more general features that perform better on new tasks. In NLP applications, data augmentation techniques such as those presented in <em class="chapterRef">Chapter 5</em> can be employed, along with others such as synonym replacement, in order to increase robustness and aid in better generalization across different contexts.</p>
    <p class="normal">A significant challenge in FSL is also the difficulty of achieving robust performance with limited training data. Depending on the complexity of the pattern being learned, models may require larger datasets to generalize well and therefore struggle to learn useful patterns without it, leading to poor performance on new tasks. Transfer learning can be a powerful, complementary strategy to address this challenge. By starting with a model pre-trained on a large and diverse dataset, you can leverage the learned features and fine-tune the model on your specific FSL task. This approach enables rapid adaptation to new tasks with minimal data while retaining a broad knowledge base, complementing FSL by providing a rich initial set of features that need only slight adjustments rather than learning from<a id="_idIndexMarker836"/> scratch. This powerful approach has its limitations and challenges as well; however, these are topics we will discuss in the following section.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Optimizing FSL techniques</strong></p>
      <p class="normal">Key strategies<a id="_idIndexMarker837"/> for enhancing the efficacy of FSL models:</p>
      <ul>
        <li class="bulletList"><strong class="keyWord">Overfitting prevention</strong>: Implement regularization techniques to help the model focus on simpler, more general patterns, rather than memorizing specific noise in the training data.</li>
        <li class="bulletList"><strong class="keyWord">Enhancing generalization</strong>: Employ data augmentation to expand the training dataset. For text, approaches like paraphrasing or injecting synonyms help the model learn language variations.</li>
        <li class="bulletList"><strong class="keyWord">Leveraging transfer learning</strong>: Utilize a model pre-trained on a comprehensive dataset and then fine-tune it for your specific FSL task.</li>
      </ul>
    </div>
    <h1 class="heading-1" id="_idParaDest-224">Navigating transfer learning</h1>
    <p class="normal">Transfer learning<a id="_idIndexMarker838"/> can enhance how marketing professionals leverage AI by enabling the more effective use of pre-trained models on new tasks with only minor adjustments. While FSL uses a set of examples from the new task for quick adaptation, transfer learning focuses on repurposing an existing model without needing additional examples from the new domain. </p>
    <p class="normal">This approach capitalizes on the knowledge that models gain from large-scale data in previous tasks, applying it to enhance marketing efforts in completely different areas without the overhead of retraining the model from scratch. Put differently, FSL improves model adaptability using very limited data examples, whereas transfer learning excels in environments where the relationship between past and current tasks is strong but the availability of large enough labeled datasets for training a base model for the new task is difficult or costly to acquire.</p>
    <p class="normal">An additional advantage of transfer learning over FSL can come from a cost perspective. For example, when using paid API services for state-of-the-art GenAI models, pricing can be related to the input size used to generate the response. In the context of NLP applications, this is often captured by the token count. When fine-tuning via transfer learning, the base model only needs to be adjusted once. This means that the token count paid for during the fine-tuning phase does not recur with every usage of the model, as opposed to FSL, which may require the same relevant examples to be fed in each time.</p>
    <p class="normal">With transfer learning, the initial cost of fine-tuning the model can be offset by the lower costs for each subsequent inference, as no additional examples need to be fed into the model. Transfer learning therefore becomes cost-effective when the number of inferences after<a id="_idIndexMarker839"/> fine-tuning exceeds a certain threshold, making it cheaper in the long run compared to FSL.</p>
    <p class="normal">As an example, here is <a id="_idIndexMarker840"/>a breakdown to illustrate the potential cost differences<a id="_idIndexMarker841"/> between FSL and transfer learning:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">FSL API costs</strong>:<ul>
          <li class="bulletList level-2"><strong class="keyWord">Base cost</strong>: Cost for tokens used in the prompt (Cost per token × Number of tokens in prompt)</li>
          <li class="bulletList level-2"><strong class="keyWord">Additional cost per example</strong>: Cost per token × Number of tokens per example</li>
        </ul>
      </li>
      <li class="bulletList"><strong class="keyWord">Transfer learning API costs</strong>:<ul>
          <li class="bulletList level-2"><strong class="keyWord">Initial fine-tuning cost</strong>: One-time cost for adjusting the pre-trained model using a larger set of example data</li>
          <li class="bulletList level-2"><strong class="keyWord">Cost per inference</strong>: Cost for each inference using the fine-tuned model</li>
        </ul>
      </li>
    </ul>
    <div class="note">
      <p class="normal"><strong class="keyWord">When to use transfer learning over FSL</strong></p>
      <p class="normal">Compared to FSL, transfer learning can be more advantageous under the following circumstances:</p>
      <ul>
        <li class="bulletList"><strong class="keyWord">High frequency of usage</strong>: The more frequently the model is used, the quicker the initial fine-tuning cost is amortized.</li>
        <li class="bulletList"><strong class="keyWord">Stable task requirements</strong>: New tasks must be similar enough for the fine-tuned model to perform well without further adjustment.</li>
        <li class="bulletList"><strong class="keyWord">Complex pattern adaption</strong>: While requiring more extensive data, it can adapt deeper model layers to learn more complex patterns.</li>
      </ul>
    </div>
    <h2 class="heading-2" id="_idParaDest-225">The mechanics of transfer learning</h2>
    <p class="normal">At a high level, transfer<a id="_idIndexMarker842"/> learning and its fine-tuning processes are built upon similar foundations established by techniques like ZSL and FSL. Both ZSL and FSL are designed to apply pre-existing knowledge to new tasks. However, they differ primarily in the approach to adaptation. ZSL hypothesizes about <em class="italic">unseen tasks</em> based on learned abstract concepts without any specific examples, whereas FSL uses a <em class="italic">handful of examples</em> to guide the adaptation. Transfer learning extends these concepts by utilizing a base of extensively trained models that can be specifically fine-tuned to a new task, providing a practical balance between the broad generalization of ZSL and the rapid adaptation characteristic of FSL. Transfer learning is often the preferred approach when a robust, pre-trained model exists and there are examples from a highly related domain, but a lack of examples specifically related to the new task. </p>
    <p class="normal">At a more technical level, fine-tuning in transfer learning involves subtle yet significant adjustments to the model’s parameters that are already well-trained on large, diverse datasets. This fine-tuning adapts the learned features to the specifics of a new, related task, often involving adjustments to the deeper, more discriminative layers of the model. Such modifications enable the model to maintain its generalization capabilities while optimizing for performance on specific tasks within the new domain. This is different from FSL, where fine-tuning aims to quickly adapt the model using very few examples by making minimal adjustments, often only to the model’s final layers or via prompt engineering where there can be no adjustments to the trainable parameters.</p>
    <p class="normal">The following<a id="_idIndexMarker843"/> figure illustrates the differences between ZSL, FSL, and transfer learning:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_07.png"/></figure>
    <p class="packt_figref">Figure 10.7: Key differences between typical ZSL, FSL, and transfer learning implementations and their mechanics</p>
    <h2 class="heading-2" id="_idParaDest-226">Transfer learning using Keras</h2>
    <p class="normal">In this section, in<a id="_idIndexMarker844"/> order to provide variety beyond applications <a id="_idIndexMarker845"/>just in the field of NLP, we will present a framework for how transfer learning can be implemented in an image classification task. This example will present a framework for how you can adapt a pre-trained image recognition model to a new marketing-relevant challenge of your choice, such as identifying desired product features.</p>
    <p class="normal">The first step in the transfer learning process involves finding a pre-trained model that has been extensively trained on a large and diverse dataset. Here, we will use the VGG16 model, known for its robust performance in image recognition. VGG16 is a convolutional neural network that achieves this high performance through training on the ImageNet dataset using over a million images in order to classify them into a thousand image categories, as detailed by Simonyan and Zisserman in their 2014 paper, <em class="italic">Very deep convolutional networks for large-scale image recognition</em>.</p>
    <p class="normal">First, we’ll summarize the full architecture of this model using <code class="inlineCode">model.summary</code> to give us a <a id="_idIndexMarker846"/>better <a id="_idIndexMarker847"/>understanding of its layers and components:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> keras.applications.vgg16 <span class="hljs-keyword">import</span> VGG16
base_model = VGG16()
base_model.summary()
</code></pre>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_08.png"/></figure>
    <p class="packt_figref">Figure 10.8: Model architecture summary</p>
    <p class="normal">As shown here, the VGG16 architecture is a deep neural network consisting of multiple layers designed to <a id="_idIndexMarker848"/>process <a id="_idIndexMarker849"/>and transform the image into a form that is increasingly abstract and useful for classification tasks. Here’s a simple breakdown based on the preceding summary:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Input layer</strong>: This accepts images of size 224 x 224 pixels, which is a standard dimension for many image processing tasks. Each image has three color channels (Red, Green, and Blue), which explains the <code class="inlineCode">3</code> in the shape given in <em class="italic">Figure 10.8</em>. The <code class="inlineCode">None</code> given in each layer at the start is effectively a placeholder for the batch size, allowing for any number of images to be processed.</li>
      <li class="bulletList"><strong class="keyWord">Convolutional layers (Conv2D)</strong>: These perform the core of the work in the network. VGG16 has multiple convolutional layers stacked on top of each other, each with a set number of filters that detect different features in the image at various levels of granularity. For example, the first convolutional layer might detect edges, while deeper layers might identify more complex patterns like textures or specific objects. The progression in the number of filters from 64 to 512 reflects an increase in the complexity of features being detected in the image as it moves through the network.</li>
      <li class="bulletList"><strong class="keyWord">Max pooling layers (MaxPooling2D)</strong>: These are interspersed with the convolutional layers and serve to reduce the spatial dimensions (width and height) of the input for the next convolutional layer. For instance, a pooling layer following a 224 x 224 convolutional layer output reduces it to 112 x 112, thus reducing the computation required and helping in the detection of dominant features that are invariant to small shifts and rotations in the input image.</li>
      <li class="bulletList"><strong class="keyWord">Fully connected layers (Dense)</strong>: Near the end of the network, the flattened output from<a id="_idIndexMarker850"/> the <a id="_idIndexMarker851"/>convolutional layers is fed into these densely connected layers. These are used to combine all features from the prior convolutional layers to eventually classify the image into one of the 1,000 categories.</li>
      <li class="bulletList"><strong class="keyWord">Output layer (predictions)</strong>: The final layer outputs the probabilities of the image belonging to each of the 1,000 classes trained in the ImageNet dataset. The class with the highest probability is taken as the prediction of the model.</li>
    </ul>
    <p class="normal">The following is a visualization of this summary taken from a medical research article by Yang et al. (<a href="https://www.nature.com/articles/s41598-021-99015-3"><span class="url">https://www.nature.com/articles/s41598-021-99015-3</span></a>):</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_09.png"/></figure>
    <p class="packt_figref">Figure 10.9: Visualization of the architecture of the VGG16 deep neural network</p>
    <p class="normal">Let us now adapt this model for transfer learning:</p>
    <ol>
      <li class="numberedList" value="1">We will load the model into memory again, but this time with the option <code class="inlineCode">include_top=False</code> in order to truncate the model after the last convolution layer. This will move the top layers responsible for classification into predefined categories and allow the model to serve as a feature extractor, which means it outputs a <a id="_idIndexMarker852"/>complex<a id="_idIndexMarker853"/> feature map that represents the input image’s key characteristics but doesn’t output a specific category prediction:
        <pre class="programlisting code-one"><code class="hljs-code">base_model = VGG16(weights=<span class="hljs-string">'imagenet'</span>, include_top=<span class="hljs-literal">False</span>, input_shape=(<span class="hljs-number">224</span>, <span class="hljs-number">224</span>, <span class="hljs-number">3</span>))
</code></pre>
      </li>
      <li class="numberedList">We can then adapt this feature-rich model to our new task of product classification by adding our own classification layers that will be trained on top of the feature extractor:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers, models
model = models.Sequential()
model.add(base_model)
model.add(layers.Flatten()) 
model.add(layers.Dense(<span class="hljs-number">256</span>, activation=<span class="hljs-string">'relu'</span>)) 
model.add(layers.Dense(<span class="hljs-number">1</span>, activation=<span class="hljs-string">'sigmoid'</span>))
</code></pre>
      </li>
      <li class="numberedList">Finally, the model can be fine-tuned for transfer learning using new, task-specific data. This involves setting the pre-trained base model layers to non-trainable, thereby freezing the weights of the pre-trained layers, which is generally advised to avoid having the initial phase of training forget the majority of the<a id="_idIndexMarker854"/> base<a id="_idIndexMarker855"/> model’s initial feature extraction weights:
        <pre class="programlisting code-one"><code class="hljs-code">base_model.trainable = <span class="hljs-literal">False</span>
model.<span class="hljs-built_in">compile</span>(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
</code></pre>
        <div class="note">
          <p class="normal"><strong class="keyWord">Self-guided exercise: Fine-tuning VGG16 on your data</strong></p>
          <p class="normal">To apply transfer learning using the VGG16 model to classify images of product features, follow these steps:</p>
          <ul>
            <li class="bulletList"><strong class="keyWord">Collect images</strong>: Gather images of products with features your company aims to classify. Sources can include online catalogs, social media, or direct captures of physical inventory.</li>
            <li class="bulletList"><strong class="keyWord">Prepare the data</strong>: Resize images to 224 x 224 pixels to match the VGG16 input size and normalize pixel values to range <code class="inlineCode">[0, 1]</code>.</li>
            <li class="bulletList"><strong class="keyWord">Train the model</strong>: Use the compiled model and fit your images (<code class="inlineCode">new_data</code>) and their binary labels <code class="inlineCode">[0, 1]</code>, for instance using:
              <pre class="programlisting code"><code class="hljs-code">   model.fit(new_data, labels, epochs=<span class="hljs-number">5</span>, batch_size=<span class="hljs-number">32</span>)
</code></pre>
            </li>
            <li class="bulletList"><strong class="keyWord">Evaluate and fine-tune</strong>: Based on performance, consider adjusting your learning rate or gradually unfreezing layers in the base VGG16 model</li>
          </ul>
        </div>
      </li>
    </ol>
    <h2 class="heading-2" id="_idParaDest-227">Transfer learning using API services</h2>
    <p class="normal">Transfer learning<a id="_idIndexMarker856"/> through API services offers a practical <a id="_idIndexMarker857"/>solution for marketing professionals who wish to utilize cutting-edge AI without the complexities of a local implementation. Some of the practical benefits of using an available API service for transfer learning are the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Access to advanced models</strong>: Continuous updates and optimizations of API-accessible models ensure the use of cutting-edge technology that is more advanced than what may be publicly available.</li>
      <li class="bulletList"><strong class="keyWord">Computational efficiency</strong>: Offloading the computational demands to cloud-based services removes the need for sophisticated hardware that may be inaccessible for individuals or small businesses.</li>
      <li class="bulletList"><strong class="keyWord">Simplified parameter management</strong>: This refers to the automatic handling of learning rates, gradient adjustments, and other complex training parameters that can affect model performance.</li>
    </ul>
    <p class="normal">To apply transfer learning effectively, it’s crucial that the fine-tuning dataset mirrors the unique characteristics of your brand. This could include customer feedback or vetted marketing copy and product descriptions. If a proprietary dataset is unavailable, publicly accessible data such as reviews or social media posts about similar products or services could be used. The key is to compile this data into a single file, typically in CSV format, in a location that is accessible to the API. Each entry then needs to be clearly labeled according to<a id="_idIndexMarker858"/> its <a id="_idIndexMarker859"/>expected label or output.</p>
    <p class="normal">The following is an example input in CSV format that gives the model a deeper understanding of what sustainability means in the context of our specific brand, setting the stage for what will be discussed in the hands-on example in the next section:</p>
    <pre class="programlisting code"><code class="hljs-code">text,label
<span class="hljs-string">"Our new line of kitchenware not only uses recycled materials but also ensures fair labor practices are upheld."</span>,positive
<span class="hljs-string">"While our products are designed to be eco-friendly, we are also committed to improving our supply chain to support local communities."</span>,positive
<span class="hljs-string">"Our brand continues to strive for environmental sustainability, though we have not yet addressed labor conditions in our factories."</span>,negative
<span class="hljs-string">"We ensure that all our materials are ethically sourced and provide support to the local economies where we operate."</span>,positive
<span class="hljs-string">"Despite using recycled materials, our company has been criticized for poor working conditions in our overseas manufacturing plants."</span>,negative
</code></pre>
    <p class="normal">Now, we can initiate the model fine-tuning using OpenAI’s API with the GPT-4 model, replacing <code class="inlineCode">openai.api_key</code> with your actual key and <code class="inlineCode">path/to/your/dataset.csv</code> with a path to the dataset’s location. Before executing this code, remember to consult the latest OpenAI API documentation (<a href="https://beta.openai.com/docs/"><span class="url">https://beta.openai.com/docs/</span></a>) for any updates or changes in<a id="_idIndexMarker860"/> the<a id="_idIndexMarker861"/> API usage:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> openai
openai.api_key = <span class="hljs-string">'XXX'</span> <span class="hljs-comment">#your API key here</span>
response = openai.File.create(
    file=<span class="hljs-built_in">open</span>(<span class="hljs-string">"path/to/your/dataset.csv"</span>, <span class="hljs-string">"rb"</span>),
    purpose=<span class="hljs-string">'fine-tune'</span>)
file_id = response[<span class="hljs-string">'id'</span>]
fine_tune_response = openai.FineTune.create(training_file=file_id,
    model=<span class="hljs-string">"gpt-4"</span>,
    n_epochs=<span class="hljs-number">5</span>)
</code></pre>
    <h2 class="heading-2" id="_idParaDest-228">Overcoming challenges in transfer learning</h2>
    <p class="normal">While transfer learning can<a id="_idIndexMarker862"/> be a powerful approach for fine-tuning pre-trained models to better perform better on new tasks, it is not without its challenges and limitations. The following are a couple of key challenges to consider when applying transfer learning:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Model drift</strong>: In the context of transfer learning, model drift refers to the gradual decline in a model’s accuracy as the data it was fine-tuned on becomes less representative of the current environment or trends.</li>
    </ul>
    <p class="normal-one">For example, imagine using a model pre-trained on marketing data from 2019 to predict consumer preferences for 2024. Initially, the model may perform well after being fine-tuned via transfer learning with more recent 2020 data. However, as consumer behavior shifts due to reasons such as new social media platforms like TikTok gaining in popularity or significant changes in economic conditions, the model may start recommending outdated messaging strategies.</p>
    <p class="normal-one">To address model drift, one needs to continuously update the model with recent data from the target domain and monitor its performance closely. This can be achieved by continuous learning techniques that allow the model to adjust dynamically as new data comes in. Further resources on continuous learning are given in the info box in this section.</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Domain mismatch</strong>: Domain mismatch in transfer learning occurs when the source domain (where the model was initially trained) and the target domain (where the model is fine-tuned) differ significantly. In transfer learning, this means the pre-trained model’s knowledge may not generalize well to the new domain, leading to poor performance.</li>
    </ul>
    <p class="normal-one">As an example, consider a model pre-trained on English-language customer reviews from an e-commerce platform, which is then fine-tuned to analyze reviews in Japanese for a local market. Even after fine-tuning, the model may struggle to capture cultural nuances and linguistic differences, leading to incorrect sentiment analysis. This may be because the pre-trained model’s reliance on patterns learned from English data makes it less effective when applied to Japanese reviews where the expressions and cultural references are different.</p>
    <p class="normal-one">To address this, a more appropriate approach would be to fine-tune the model with a carefully curated dataset of Japanese customer reviews that specifically captures the specific linguistic and cultural nuances of the local market.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Staying ahead of model drift</strong></p>
      <p class="normal">To maintain the accuracy of your transfer learning models, especially as consumer behavior evolves, continuous learning is key.</p>
      <p class="normal">Continuous learning is often implemented within the practices of MLOps. Learn more about MLOps principles and best practices at <a href="https://cloud.google.com/architecture/ai-ml"><span class="url">https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning</span></a>.</p>
    </div>
    <p class="normal">Having introduced the<a id="_idIndexMarker863"/> fundamentals and techniques behind how FSL and transfer learning can adapt pre-trained models to better address new marketing tasks, we will now demonstrate the importance of FSL through a hands-on marketing example.</p>
    <h1 class="heading-1" id="_idParaDest-229">Applying FSL to improve brand consistency</h1>
    <p class="normal">In our previous <a id="_idIndexMarker864"/>exploration of ZSL in <em class="chapterRef">Chapter 9</em>, we demonstrated how a pre-trained model like GPT-4 could generate marketing copy for an e-commerce brand launching eco-friendly products. This ZSL approach, while powerful, primarily relied on the model’s ability to infer context and content from generalized pre-training using prompts emphasizing terms like <em class="italic">sustainable</em> and <em class="italic">eco-friendly</em>.</p>
    <p class="normal">As the examples in this section will show, while ZSL provides a solid foundation for generating brand-relevant content, it often lacks the precision required for capturing the deeper, more nuanced aspects of a brand’s ethos. This is particularly true for brands whose identity is heavily tied to specific practices or principles that may not be well represented in the generalized training <a id="_idIndexMarker865"/>of the <strong class="keyWord">large language model</strong> (<strong class="keyWord">LLM</strong>).</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Steps for effective FSL in marketing campaigns</strong></p>
      <ol>
        <li class="numberedList" value="1"><strong class="keyWord">Prompt refinement and execution</strong>: Begin with a basic prompt like one that would be used for ZSL, but now add a few examples of desired outputs or contexts that reflect the brand’s unique aspects.</li>
        <li class="numberedList"><strong class="keyWord">Output analysis</strong>: Evaluate the content to ensure it maintains the necessary brand consistency. Note deviations from these expectations as they provide insights into areas needing further examples.</li>
        <li class="numberedList"><strong class="keyWord">Iterative refinement</strong>: Based on the feedback and performance of the initial outputs, refine the examples and prompts iteratively, continuing until you achieve your desired marketing KPIs (see <em class="chapterRef">Chapter 2</em>).</li>
      </ol>
    </div>
    <p class="normal">Continuing our <a id="_idIndexMarker866"/>scenario from the section on <em class="italic">Zero-shot learning for marketing copy</em> in <em class="chapterRef">Chapter 9</em>, we revisit our journey with the sustainability-focused e-commerce brand that we introduced earlier. Now, in response to evolving market trends and corporate directives, the company known for its eco-friendly kitchenware is undergoing a rebranding to align with the growing consumer demand for social responsibility. Recent insights reveal that consumers are increasingly interested in supporting brands that not only offer sustainable products but also demonstrate a tangible commitment to fair labor practices and positive community impact. This shift is particularly pronounced among affluent younger consumers who value ethical production and are willing to pay a premium for products that make a real difference in the lives of workers and communities. Furthermore, this demographic wants their products not just to have eco-friendly packaging but for them to be deemed “zero waste.”</p>
    <p class="normal">Let’s demonstrate how GPT-4 can effectively capture our newly defined sustainability campaign goals by enhancing output content through prompt engineering. This includes the subtle clarifications around sustainability mentioned earlier:</p>
    <ul>
      <li class="bulletList">A commitment to fair labor practices</li>
      <li class="bulletList">Zero waste packaging</li>
      <li class="bulletList">Active community engagement</li>
    </ul>
    <p class="normal">We will exemplify this through a case study aimed at boosting an email marketing campaign. This involves iterative refinement of prompts, closely tied to monitoring key performance<a id="_idIndexMarker867"/> indicators previously discussed in <em class="chapterRef">Chapter 2</em>, to ensure alignment with our rebranded marketing objectives.</p>
    <h2 class="heading-2" id="_idParaDest-230">Benchmarking with ZSL and FSL</h2>
    <p class="normal">Before integrating FSL <a id="_idIndexMarker868"/>into our email marketing <a id="_idIndexMarker869"/>campaign, it’s important to benchmark the effectiveness of ZSL at capturing the refined brand strategy for FSL is introduced. Here, we will compare a baseline response generated using ZSL that’s devoid of specific examples that align with our rebranded sustainability focus. We’ll define a function to execute the API completion and then illustrate how ZSL performs without the nuanced context of our updated campaign goals:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
client = OpenAI(api_key = <span class="hljs-string">'XXX'</span> ) <span class="hljs-comment">#your API key here</span>
base_prompt = <span class="hljs-string">"</span><span class="hljs-string">Write a product description for an eco-friendly kitchenware product focusing on brand ethics."</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">generate_chat_completion</span>(<span class="hljs-params">client, prompt, max_tokens=</span><span class="hljs-number">150</span><span class="hljs-params">, n=</span><span class="hljs-number">1</span><span class="hljs-params">, temperature=</span><span class="hljs-number">0.7</span><span class="hljs-params">, advanced_usage=</span><span class="hljs-literal">False</span>):
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> advanced_usage:
        messages = [{<span class="hljs-string">"role"</span>: <span class="hljs-string">"</span><span class="hljs-string">user"</span>, <span class="hljs-string">"content"</span>: prompt}]
    <span class="hljs-keyword">else</span>:
        messages = prompt
    completion = client.chat.completions.create(
        model=<span class="hljs-string">"gpt-4"</span>,
        messages=messages,
        max_tokens=max_tokens,
        n=n,
        temperature=temperature)
    <span class="hljs-keyword">return</span> completion.choices[<span class="hljs-number">0</span>].message.content
zsl_response = generate_chat_completion(client, base_prompt)
<span class="hljs-built_in">print</span>(zsl_response)
</code></pre>
    <p class="normal">This gives us the following response:</p>
    <pre class="programlisting con"><code class="hljs-con">Product Name: EcoPure Bamboo Kitchen Utensil Set
Enrich your cooking experience with our EcoPure Bamboo Kitchen Utensil Set. This set, which includes a spatula, slotted spoon, mixing spoon, and fork, is not just an ordinary kitchen tool set but a reflection of our commitment to sustainable living and ethical product creation.
Each piece in this set is made from 100% organic bamboo, a renewable and biodegradable resource, offering an environmentally friendly alternative to plastic.
</code></pre>
    <p class="normal">As you can see, while the response is clear, it is too generic and lacks the specificity and context needed to meet the specific goals of our rebranding initiative.</p>
    <p class="normal">To see the value FSL can provide, here, we revisit the exact same base prompt as earlier, but also include <a id="_idIndexMarker870"/>context<a id="_idIndexMarker871"/> specific to our updated campaign goals via FSL:</p>
    <pre class="programlisting code"><code class="hljs-code">fsl_prompts = [
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"</span><span class="hljs-string">system"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Describe a product using sustainable materials that supports fair labor practices."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Our latest kitchenware range not only uses biodegradable materials but is also produced in factories ensuring fair wages and safe working conditions."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"</span><span class="hljs-string">Write about a kitchenware product that exemplifies zero waste in packaging."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Each item in our new line of cookware comes in completely recyclable packaging, designed to leave no environmental footprint."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Explain how a purchase supports community engagement projects."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"</span><span class="hljs-string">user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"With every purchase, a portion of the proceeds goes towards community gardens, supporting urban greening projects."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: base_prompt}]
fsl_response = generate_chat_completion(client, fsl_prompts, max_tokens=<span class="hljs-number">150</span>, temperature=<span class="hljs-number">0.7</span>, advanced_usage=<span class="hljs-literal">True</span>)
<span class="hljs-built_in">print</span>(fsl_response)
</code></pre>
    <p class="normal">This produces the following output:</p>
    <pre class="programlisting con"><code class="hljs-con">Introducing our new line of eco-friendly kitchenware, designed with the <span class="code-highlight"><strong class="hljs-con-slc">utmost respect for our planet and its inhabitants</strong></span>. Each piece in this range is crafted from sustainable, biodegradable materials, making it a guilt-free addition to your kitchen.
<span class="code-highlight"><strong class="hljs-con-slc">We believe in the power of ethical production and fair labor</strong><strong class="hljs-con-slc">factories that ensure fair wages, safe working conditions, and equal opportunities for all workers</strong></span>, which is why all our products are sourced from .
But our commitment doesn't stop there. <span class="code-highlight"><strong class="hljs-con-slc">For every purchase, we contribute towards community development projects</strong></span>, particularly urban greening initiatives, to make our cities more livable.
</code></pre>
    <p class="normal">In the preceding text, the aspects of the LLM-generated content that organically relate to our specific goals—environmental sustainability, fair labor practices, and community engagement—are highlighted for clarity. This comparison with ZSL underscores the capability of FSL to <a id="_idIndexMarker872"/>produce <a id="_idIndexMarker873"/>content that is more tailored and relevant to the strategic nuances of our rebrand by leveraging the initial contextual examples.</p>
    <h2 class="heading-2" id="_idParaDest-231">Developing an email marketing campaign</h2>
    <p class="normal">Now, let’s explore the <a id="_idIndexMarker874"/>application of FSL in enhancing the personalization and relevance of email marketing campaigns, significantly boosting both customer engagement and conversion rates. The following is a concise guide on how to utilize FSL to optimize email campaigns effectively:</p>
    <ol>
      <li class="numberedList" value="1"><strong class="keyWord">Initial email creation</strong>: Generate the initial batch of emails using FSL, specifically focusing on your core marketing goals—in this case, sustainability and ethical practices.</li>
      <li class="numberedList"><strong class="keyWord">Collect initial metrics and responses</strong>: Analyze the initial reactions from customers to understand what aspects of the content resonate the most. This analysis is crucial in identifying successful elements and areas that may require additional refinement.</li>
      <li class="numberedList"><strong class="keyWord">Iterative refinement</strong>: Refine the content of the emails based on the engagement metrics and feedback received from customers.</li>
      <li class="numberedList"><strong class="keyWord">Continued feedback integration</strong>: Continuously integrate new insights to keep the email marketing campaign dynamically aligned with evolving customer preferences and market trends.</li>
    </ol>
    <p class="normal">Now let’s examine what these steps entail.</p>
    <h3 class="heading-3" id="_idParaDest-232">Step 1: Initial email creation</h3>
    <p class="normal">The first step in employing FSL in<a id="_idIndexMarker875"/> an email marketing campaign is to clearly define the campaign’s objectives. For our eco-friendly e-commerce brand, the objective might be to launch a new line of eco-friendly kitchenware that aligns with the rebrand goals. Let’s consider our objective for this scenario to be the following:</p>
    <pre class="programlisting code"><code class="hljs-code">Introducing a new line of sustainable kitchenware that embodies the brand's commitment to zero waste, ethical manufacturing practices, and community engagement.
</code></pre>
    <p class="normal">With the campaign’s objective clearly defined, the next step involves creating prompts that instruct the AI on the content that’s appropriate for the email message.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Structuring the initial email for your marketing campaign</strong></p>
      <p class="normal">The following general structure is helpful in creating an effective initial message for your email marketing campaign that increases engagement and conversion with your audience:</p>
      <ul>
        <li class="bulletList"><strong class="keyWord">Introduction</strong>: Greet the customer and introduce the new product line enthusiastically.</li>
        <li class="bulletList"><strong class="keyWord">Body</strong>: Provide detailed information about the core aspects of the product – in this case, the sustainability and ethical manufacturing aspects.</li>
        <li class="bulletList"><strong class="keyWord">Call to action</strong>: Include a call to action that encourages the recipient to take specific steps such as making a purchase or visiting a website.</li>
        <li class="bulletList"><strong class="keyWord">Closing</strong>: Conclude with a warm closing that reinforces the brand’s commitment to the core aspects of the product.</li>
      </ul>
    </div>
    <p class="normal">We’ll define a starting prompt for the model, which will be used to generate the initial batch of emails. Similar to the earlier product description example, each element of the <code class="inlineCode">fsl_prompts</code> is designed to progressively build a narrative around the brand’s commitment to sustainability, ethical practices, and community involvement, as required by the corporate rebrand, in the following way:</p>
    <ul>
      <li class="bulletList">The first pair of prompts ensures the content appropriately emphasizes the eco-friendly and zero-waste aspect of the kitchenware</li>
      <li class="bulletList">The second set of prompts addresses the context expected when discussing the ethical labor practices involved in the production process</li>
      <li class="bulletList">The final two prompts tie the product to community engagement efforts, linking purchases to initiatives that are important to socially responsible consumers</li>
    </ul>
    <p class="normal">To ensure that the generated content aligns with our campaign goals, we’ll also adjust our base prompt to be more specific to an email campaign and increase the <code class="inlineCode">max_tokens</code> to reflect the longer <a id="_idIndexMarker876"/>content:</p>
    <pre class="programlisting code"><code class="hljs-code">base_prompt = <span class="hljs-string">"Compose a short email to introduce our latest line of eco-friendly kitchenware. The email should be engaging, informative, and conclude with a strong call to action."</span>
fsl_prompts = [
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"</span><span class="hljs-string">content"</span>: <span class="hljs-string">"Make sure to highlight the eco-friendly and zero waste aspects of the kitchenware."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Our kitchenware is designed with the planet in mind, featuring products made entirely from recycled materials and ensuring zero waste in our packaging."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Include information about the fair labor practices in the manufacturing process."</span>},
    {<span class="hljs-string">"</span><span class="hljs-string">role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"We are committed to ethical production practices. All our products are manufactured under fair labor conditions, ensuring all workers are paid fairly and work in safe environments."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Mention how purchasing these products supports community engagement projects."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"</span><span class="hljs-string">content"</span>: <span class="hljs-string">"Every purchase supports community initiatives, including urban greening projects and community gardens that help local environments thrive."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: base_prompt}]
fsl_completion = client.chat.completions.create(
    model=<span class="hljs-string">"gpt-4"</span>,
    messages=fsl_prompts,
    max_tokens=<span class="hljs-number">300</span>,
    n=<span class="hljs-number">1</span>,
    temperature=<span class="hljs-number">0.7</span>
)
<span class="hljs-built_in">print</span>(fsl_completion.choices[<span class="hljs-number">0</span>].message.content)
</code></pre>
    <p class="normal">This produces the following email content:</p>
    <pre class="programlisting code"><code class="hljs-code">Subject: Discover Our New Eco-Friendly Kitchenware - Upgrade Your Kitchen, Save the Planet!
Hello,
We are thrilled to announce the arrival of our latest line of eco-friendly kitchenware, designed with both style and sustainability in mind.
Our new collection is a testament to our commitment to protecting our planet. Each piece is crafted from 100% recycled materials, ensuring that your cooking experience is as kind to the Earth as it is to your culinary creations.
But we don't stop at just the products. We've committed to zero waste in our packaging, meaning when you unbox your new kitchenware, you can do so guilt-free.
We believe in ethical production and are proud to say that all our products are made under fair labor conditions. Every worker involved in creating our kitchenware is paid fairly and operates in a safe and healthy environment.
Moreover, when you purchase from us, you're also giving back to the community. A portion of each sale goes towards local community initiatives, including urban greening projects and community gardens. This means that with every purchase, you're helping local environments to flourish.
We invite you to explore our new line of eco-friendly kitchenware and make your kitchen a beacon of sustainability. Let's cook up a storm, with a side of environmental consciousness!
Click here [insert hyperlink] to begin your sustainable cooking journey with us.
Best,
[Your Name]
</code></pre>
    <h3 class="heading-3" id="_idParaDest-233">Step 2: Collect and analyze initial metrics and responses</h3>
    <p class="normal">Following the deployment <a id="_idIndexMarker877"/>of our email campaign with the newly created content, it is crucial to assess its effectiveness using KPIs. For this evaluation, we assume we already have representative data from the first seven days post-launch that will allow us to examine the metrics of open rate, click-through rate, conversion rate, and unsubscribe rate. This analysis helps us identify areas for improvement by visualizing these KPIs over time.</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
df_initial = pd.read_csv(<span class="hljs-string">'initial_launch_data.csv'</span>)
<span class="hljs-keyword">def</span> <span class="hljs-title">plot_campaign_kpis</span>(<span class="hljs-params">df, title=</span><span class="hljs-string">'Email Campaign KPIs'</span>):
    plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))
    plt.plot(df[<span class="hljs-string">'Date'</span>], df[<span class="hljs-string">'Open Rate (%)'</span>], label=<span class="hljs-string">'Open Rate (%)'</span>, marker=<span class="hljs-string">'o'</span>)
    plt.plot(df[<span class="hljs-string">'Date'</span>], df[<span class="hljs-string">'Click-Through Rate (%)'</span>], label=<span class="hljs-string">'Click-Through Rate (%)'</span>, marker=<span class="hljs-string">'o'</span>)
    plt.plot(df[<span class="hljs-string">'</span><span class="hljs-string">Date'</span>], df[<span class="hljs-string">'Conversion Rate (%)'</span>], label=<span class="hljs-string">'Conversion Rate (%)'</span>, marker=<span class="hljs-string">'o'</span>)
    plt.plot(df[<span class="hljs-string">'Date'</span>], df[<span class="hljs-string">'Unsubscribe Rate (%)'</span>], label=<span class="hljs-string">'Unsubscribe Rate (%)'</span>, marker=<span class="hljs-string">'o'</span>)
    plt.xlabel(<span class="hljs-string">'Date'</span>)
    plt.ylabel(<span class="hljs-string">'Percentage'</span>)
    plt.title(title)
    plt.legend()
    plt.grid(<span class="hljs-literal">True</span>)
    plt.show()
plot_campaign_kpis(df_initial, <span class="hljs-string">'Email Campaign KPIs First Week after Launch'</span>)
</code></pre>
    <p class="normal">In the following graph, we can observe the trends in open rates, click-through rates, conversion rates, and unsubscribe rates over the first week following the campaign launch. This allows us to <a id="_idIndexMarker878"/>quickly identify patterns, which can be critical for diagnosing issues with the campaign’s content or delivery:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_10.png"/></figure>
    <p class="packt_figref">Figure 10.10: Email campaign KPIs during the first week after launch</p>
    <div class="packt_tip">
      <p class="normal"><strong class="keyWord">Benchmarking your email campaign performance</strong></p>
      <p class="normal">Evaluating the<a id="_idIndexMarker879"/> performance of your marketing campaign metrics can be tricky, especially without industry benchmarks as a reference. To quickly assess whether your KPIs are on target, start by comparing them to established benchmarks.</p>
      <p class="normal">Here is a recent comparison of email marketing benchmarks: <a href="https://www.webfx.com/blog/marketing/email-marketing-benchmarks/"><span class="url">https://www.webfx.com/blog/marketing/email-marketing-benchmarks/</span></a>.</p>
    </div>
    <p class="normal">We can also<a id="_idIndexMarker880"/> calculate and review the average performance across these metrics:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(<span class="hljs-string">f"Average Open Rate: </span><span class="hljs-subst">{df_initial[</span><span class="hljs-string">'Open Rate (%)'</span><span class="hljs-subst">].mean():</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string">%"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Average Click-Through Rate: </span><span class="hljs-subst">{df_initial[</span><span class="hljs-string">'Click-Through Rate (%)'</span><span class="hljs-subst">].mean():</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string">%"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Average Conversion Rate: </span><span class="hljs-subst">{df_initial[</span><span class="hljs-string">'Conversion Rate (%)'</span><span class="hljs-subst">].mean():</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string">%"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Average Unsubscribe Rate: </span><span class="hljs-subst">{df_initial[</span><span class="hljs-string">'Unsubscribe Rate (%)'</span><span class="hljs-subst">].mean():</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string">%"</span>)
</code></pre>
    <p class="normal">This yields the following:</p>
    <pre class="programlisting con"><code class="hljs-con">Average Open Rate: 13.07%
Average Click-Through Rate: 2.43%
Average Conversion Rate: 1.21%
Average Unsubscribe Rate: 1.61%
</code></pre>
    <p class="normal">Based on these KPIs, the following are some observations and possible explanations that we may consider addressing in our next iteration of the email campaign:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Low open rates</strong>: This may suggest that the email subject lines are not sufficiently engaging.</li>
      <li class="bulletList"><strong class="keyWord">Click-through rates</strong>: Some recipients view the emails but do not click through at expected rates, possibly due to less compelling content or offers.</li>
      <li class="bulletList"><strong class="keyWord">Modest conversion rates</strong>: This indicates a need for stronger calls to action or improvements in the effectiveness of landing pages.</li>
      <li class="bulletList"><strong class="keyWord">Rising unsubscribe rate</strong>: This could point to issues with the frequency or relevance of the content.</li>
    </ul>
    <p class="normal">In addition to these<a id="_idIndexMarker881"/> KPIs, assume we’ve collected feedback from email recipients who responded directly to this email with their questions and concerns. We can also gather information, for example, by employing sentiment analysis techniques discussed in <em class="chapterRef">Chapter 5</em>, allowing us to determine the core topics and sentiments from product reviews and social media posts from customers who read our emails. Here’s an overview of the positive feedback that we will assume to have received:</p>
    <ul>
      <li class="bulletList">Appreciation for <strong class="keyWord">sustainable practices</strong>: “I love that your kitchenware is made from recycled materials.”</li>
      <li class="bulletList">Approval of <strong class="keyWord">ethical manufacturing</strong>: “It’s reassuring to see a brand commit to fair wages and safe working conditions.”</li>
      <li class="bulletList">Enthusiasm for the <strong class="keyWord">product range</strong>: “The stainless steel cookware looks fantastic!”</li>
    </ul>
    <p class="normal">The following are the highlights of the negative feedback:</p>
    <ul>
      <li class="bulletList">Desire for more <strong class="keyWord">product variety</strong>: “I wish that you advertised more color options for the product lines.”</li>
      <li class="bulletList">Questions about <strong class="keyWord">product care</strong>: “I’m concerned about how I can care for these products to ensure they last longer.”</li>
      <li class="bulletList">Concerns over <strong class="keyWord">price points</strong>: “The products are great, but they’re a bit pricey compared to non-eco-friendly alternatives.”</li>
    </ul>
    <p class="normal">While the positive comments validate our campaign’s core messages, the criticisms and questions provide actionable insights for our future email messaging. Using this feedback, in the next section, we will hone in on how the negative critiques can be exploited to refine our email marketing strategies and improve our KPIs.</p>
    <h3 class="heading-3" id="_idParaDest-234">Step 3: Iterative refinement</h3>
    <p class="normal">After reviewing the<a id="_idIndexMarker882"/> initial metrics and customer feedback from the previous sections, it’s clear that while some aspects of the campaign resonate well, there are key areas needing improvement. The next step is to refine our FSL prompts based on the initial metrics, address the specific criticisms from customer feedback, better meet customer expectations, and enhance the overall effectiveness of the campaign. The following are the new elements of the prompt, with commentary included after each element of the prompt, highlighting their value to our task:</p>
    <pre class="programlisting code"><code class="hljs-code">fsl_prompts = [
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Compose a short email to introduce our latest line of eco-friendly kitchenware. Highlight our zero waste and ethical manufacturing processes in terms of the labor force, and emphasize the practical benefits these practices offer to the consumer. The email should be engaging, informative, and conclude with a strong call to action. Importantly, the subject line should be as engaging as possible."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Discover our new line of eco-friendly kitchenware! Designed with sustainability at heart, each piece not only supports zero waste but is ethically made, ensuring fair labor practices and substantial benefits to the environment."</span>},
</code></pre>
    <p class="normal">This prompt sets the tone for the email, capturing the key elements from our previous FSL attempt but also emphasizing the importance of an engaging subject line in direct response to the low open rate observed in the initial KPI metrics.</p>
    <pre class="programlisting code"><code class="hljs-code">    {<span class="hljs-string">"</span><span class="hljs-string">role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Mention the product variety and colors."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Now available in a range of vibrant colors, our kitchenware allows you to personalize your kitchen while maintaining a commitment to sustainability."</span>},
</code></pre>
    <p class="normal">This response caters to feedback desiring more variety. It emphasizes the range of colors available, aiming to attract customers looking to personalize their purchases.</p>
    <pre class="programlisting code"><code class="hljs-code">    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"</span><span class="hljs-string">system"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Provide care instructions."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Caring for your eco-friendly kitchenware is easy. Here are some simple tips to ensure your items last longer, enhancing their sustainability."</span>},
</code></pre>
    <p class="normal">Addressing customer concerns about maintenance, this prompt reassures customers that the products are not only sustainable but also easy to care for, enhancing their appeal by ensuring <a id="_idIndexMarker883"/>longevity.</p>
    <pre class="programlisting code"><code class="hljs-code">    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"</span><span class="hljs-string">content"</span>: <span class="hljs-string">"Address concerns about pricing."</span>},
    {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Invest in quality and sustainability. While initially more expensive, our kitchenware offers long-term savings and a positive impact on the planet."</span>}]
</code></pre>
    <p class="normal">This prompt directly tackles the issue of price sensitivity noted in the feedback. It reframes the cost as an investment in quality and sustainability, arguing for long-term value and environmental impact.</p>
    <pre class="programlisting code"><code class="hljs-code">fsl_response = generate_chat_completion(client, fsl_prompts, max_tokens=<span class="hljs-number">500</span>, temperature=<span class="hljs-number">0.7</span>, advanced_usage=<span class="hljs-literal">True</span>)
<span class="hljs-built_in">print</span>(fsl_response)
</code></pre>
    <p class="normal">After executing the API recall, we get the following result:</p>
    <pre class="programlisting code"><code class="hljs-code">Subject: Revolutionize Your Kitchen With Our New Eco-Friendly Line!
Dear [Customer],
We're thrilled to introduce our latest line of eco-friendly kitchenware! Designed with both style and sustainability in mind, our new collection showcases a commitment to zero waste and ethical manufacturing processes.
Our kitchenware is crafted using environmentally friendly materials and methods, minimizing waste and harm to our planet. Plus, we're proud to assure you that all products are produced under fair labor conditions, promoting a more equitable and sustainable global workforce.
Available in a variety of shapes, sizes, and vibrant colors, our kitchenware allows you to personalize your kitchen while maintaining a steadfast commitment to sustainability. From our durable cutlery to our stylish serving bowls, each item in our collection is a testament to our dedication to quality and environmental responsibility.
Caring for your new eco-friendly kitchenware is a breeze - just a gentle handwash with mild soap and they're good as new. And remember, every eco-friendly choice you make contributes to a healthier, more sustainable planet.
While our items may seem initially more expensive, consider them an investment. They are designed to endure, offering long-term savings and a positive impact on the environment. Plus, you'll gain a sense of satisfaction knowing you're using items that are kind to our Earth and its workers.
Ready to make the switch to a more sustainable kitchen? Visit our website today to explore our new collection. Together, we can make a difference in our homes and our world.
</code></pre>
    <p class="normal">After deploying these <a id="_idIndexMarker884"/>updates emails on April 7, assume we collect the next seven days of KPI data and observe the following updated trends:</p>
    <pre class="programlisting code"><code class="hljs-code">df_improved = pd.read_csv(<span class="hljs-string">'improved_data.csv'</span>)
plot_campaign_kpis(df_improved, <span class="hljs-string">'Improved Email Campaign KPIs After FSL Refinements'</span>)
</code></pre>
    <p class="normal">This gives us the following plot, where we observe significant changes in the KPIs after FSL refinements:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_10_11.png"/></figure>
    <p class="packt_figref">Figure 10.11: Email campaign KPIs after campaign changes and improvements were made in response to customer feedback</p>
    <p class="normal">Based on this, we<a id="_idIndexMarker885"/> have the following average KPIs:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(<span class="hljs-string">f"Average Open Rate: </span><span class="hljs-subst">{df_improved[</span><span class="hljs-string">'Open Rate (%)'</span><span class="hljs-subst">].mean():</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string">%"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Average Click-Through Rate: </span><span class="hljs-subst">{df_improved[</span><span class="hljs-string">'Click-Through Rate (%)'</span><span class="hljs-subst">].mean():</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string">%"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Average Conversion Rate: </span><span class="hljs-subst">{df_improved[</span><span class="hljs-string">'Conversion Rate (%)'</span><span class="hljs-subst">].mean():</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string">%"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Average Unsubscribe Rate: </span><span class="hljs-subst">{df_improved[</span><span class="hljs-string">'Unsubscribe Rate (%)'</span><span class="hljs-subst">].mean():</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string">%"</span>)
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">Average Open Rate: 21.00%
Average Click-Through Rate: 5.50%
Average Conversion Rate: 3.50%
Average Unsubscribe Rate: 0.59%
</code></pre>
    <p class="normal">By comparing these metrics to the previous ones, we see significant improvements across all areas. While attributing the exact origins of these improvements is not possible without techniques such as A/B testing (<em class="italic">Chapter 6</em>) or causal inference (<em class="italic">Chapter 3</em>), one can still<a id="_idIndexMarker886"/> speculate what may be behind these improved KPIs:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Open rate</strong> improved significantly, which may reflect the more engaging subject lines, including “Revolutionize your Kitchen…”</li>
      <li class="bulletList"><strong class="keyWord">Click-through rate</strong> saw an increase, which may be attributed to the inclusion of requested features like product variety and detailed care instructions, which increased customer engagement</li>
      <li class="bulletList"><strong class="keyWord">Conversion rate</strong> increased, indicating that the email content was not only more engaging but also more effective at convincing customers of the value and relevance of the products, especially after addressing price concerns</li>
      <li class="bulletList"><strong class="keyWord">Unsubscribe rate</strong> decreased, reflecting higher content satisfaction</li>
    </ul>
    <h3 class="heading-3" id="_idParaDest-235">Step 4: Continued feedback integration</h3>
    <p class="normal">The final step in utilizing FSL for email marketing campaigns is to establish a robust system for continuous feedback integration. This approach ensures that the campaign remains dynamic and responsive to the evolving needs and preferences of customers, as well as broader market trends. By integrating continuous feedback, the campaign not only maintains relevance but also strengthens customer engagement and promotes brand loyalty over time.</p>
    <p class="normal">Effective feedback integration requires mechanisms that allow customers to share their thoughts and experiences easily. This includes embedding quick survey links directly in emails, enabling direct email responses, and engaging with customers through social media interactions related to the campaign. These channels facilitate the flow of information from customers back to marketers, providing valuable insights that can be used to refine and improve the campaign continuously.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Example feedback collection strategies</strong></p>
      <p class="normal">The following are additional ways to collect direct customer feedback:</p>
      <ul>
        <li class="bulletList"><strong class="keyWord">Live chat feedback</strong>: Implement live chat on your website to allow real-time interactions and immediate feedback.</li>
        <li class="bulletList"><strong class="keyWord">Interactive content</strong>: Use quizzes and polls in your emails or on digital platforms to make feedback collection engaging.</li>
        <li class="bulletList"><strong class="keyWord">Feedback QR codes</strong>: QR codes on products or ads can link to feedback forms so customers can easily respond on their devices.</li>
      </ul>
    </div>
    <p class="normal">To effectively analyze and utilize ongoing feedback, setting up a real-time feedback dashboard can be immensely beneficial. This dashboard can serve as a central hub for monitoring and analyzing feedback alongside standard marketing KPIs, providing a comprehensive view of campaign performance. To build such a dashboard, consider using software solutions like Tableau, Microsoft Power BI, or Google Data Studio, which offer powerful tools and intuitive interfaces for creating interactive and real-time data visualizations.</p>
    <p class="normal">The following are the steps for creating your own feedback dashboard:</p>
    <ol>
      <li class="numberedList" value="1"><strong class="keyWord">Select a dashboard tool</strong>: Choose a platform that best fits your technical capabilities and budget. Tableau, Microsoft Power BI, and Google Data Studio are popular choices due to their robust features and scalability.</li>
      <li class="numberedList"><strong class="keyWord">Integrate data sources</strong>: Connect the dashboard tool to the data sources that gather your marketing KPIs and feedback. This may include email campaign management tools, social media analytics, and customer feedback systems.</li>
      <li class="numberedList"><strong class="keyWord">Design the dashboard</strong>: Create visualizations that clearly display the key metrics you need to track. Customize the dashboard to highlight trends, spikes, and dips in campaign performance.</li>
      <li class="numberedList"><strong class="keyWord">Schedule regular reviews</strong>: Set up regular intervals, bi-weekly or monthly, for example, to review the dashboard insights. Use these sessions to assess the effectiveness of recent changes and to plan further strategic adjustments based on the data insights.<div class="note">
          <p class="normal"><strong class="keyWord">Keeping your emails out of the spam folder</strong></p>
          <p class="normal">To maximize the effectiveness of your email campaigns, it’s essential to prevent your messages from landing in the spam folder. Here are three key strategies for achieving this:</p>
          <ul>
            <li class="bulletList"><strong class="keyWord">Set up email authentication</strong>: Implement standards like SPF, DKIM, and DMARC to authenticate your emails. This helps establish trust with email providers to reduce the risk of your emails being marked as spam.</li>
            <li class="bulletList"><strong class="keyWord">Maintain list hygiene</strong>: Regularly clean your email list by removing inactive subscribers and ensuring that all recipients have opted in to receive your emails. This not only boosts engagement but also helps protect your sender reputation.</li>
            <li class="bulletList"><strong class="keyWord">Optimize email content</strong>: Other optimization strategies include personalizing your emails using FSL, limiting the number of links, and maintaining a<a id="_idIndexMarker887"/> balanced image-to-text ratio.</li>
          </ul>
        </div>
      </li>
    </ol>
    <h1 class="heading-1" id="_idParaDest-236">Summary</h1>
    <p class="normal">This chapter explored the potential of FSL and its promise for refining AI-driven marketing strategies to enhance brand presence. Building on the principles introduced through ZSL, we explored how FSL leverages a limited dataset to enable rapid adaptation of AI models to new tasks. This is crucial in the fast-paced marketing domain, where aligning quickly with evolving consumer preferences and market trends can have a significant impact on a brand’s relevance and engagement.</p>
    <p class="normal">While FSL focuses on quick adaptability using minimal examples, transfer learning complements this by applying pre-trained models fine-tuned for specific tasks, thereby minimizing the need for extensive retraining. The chapter emphasized practical strategies combining these methodologies to optimize your marketing efforts. Through approaches like the MAML approach, we demonstrated how you can use meta-learning frameworks for marketing.</p>
    <p class="normal">As we proceed, the next chapter will introduce the concept of <strong class="keyWord">retrieval-augmented generation </strong> (<strong class="keyWord">RAG</strong>). We will explore how RAG can dynamically produce content that reflects the latest available data by integrating generative models with advanced information retrieval techniques. This approach not only increases the relevance of the content generated but also enhances precision in consumer targeting, making your marketing efforts significantly more effective. The upcoming discussion will cover the technical setup of a knowledge retrieval system and practical applications of RAG in marketing, through which we aim to provide you with robust tools for writing precisely targeted marketing content that resonates with your current and potential customers.</p>
    <h1 class="heading-1">Join our book’s Discord space</h1>
    <p class="normal">Join our Discord community to meet like-minded people and learn alongside more than 5000 members at:</p>
    <p class="normal"><a href="https://packt.link/genai"><span class="url">https://packt.link/genai</span></a></p>
    <p class="normal"><img alt="" src="../Images/QR_Code12856128601808671.png"/></p>
  </div>
</body></html>