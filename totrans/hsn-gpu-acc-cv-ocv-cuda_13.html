<html><head></head><body><div><div><h1 class="header-title">Assessments</h1>
                
            
            
                


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 1</h1>
                
            
            
                
<ol>
<li>The three options to increase the performance are as follows:
<ul>
<li>Having faster clock speed</li>
<li>More work per clock cycle by a single processor</li>
<li>Many small processors that can work in parallel. This option is used by GPU to improve performance.</li>
</ul>
</li>
<li>True</li>
<li>CPUs are designed to improve latency and GPUs are designed to improve Throughput.</li>
<li>The car will take 4 hours to reach the destination but it can only accommodate 5 persons, while the bus that can accommodate  40 persons takes 6 hours to reach the destination. The bus can transport 6.66 persons per hour, while the car can transport 1.2 persons per hour. Thus, car has better latency, and bus has better throughput.  </li>
<li>Image is nothing but a two dimensional array. Most of the computer vision applications involve processing of these two-dimensional arrays. It involves similar operations on a large amount of data, which can be efficiently performed by GPUs. So GPUs and CUDA are very useful in computer vision applications.</li>
<li>False</li>
<li><kbd>printf</kbd> statement is executed on the host</li>
</ol>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 2</h1>
                
            
            
                
<ol>
<li>CUDA program to subtract two numbers by passing parameters as value is as follows:</li>
</ol>
<pre style="padding-left: 60px">include &lt;iostream&gt;<br/>#include &lt;cuda.h&gt;<br/>#include &lt;cuda_runtime.h&gt;<br/>__global__ void gpuSub(int d_a, int d_b, int *d_c) <br/>{<br/> *d_c = d_a - d_b;<br/>}<br/>int main(void) <br/>{<br/>  int h_c;<br/>  int *d_c;<br/>  cudaMalloc((void**)&amp;d_c, sizeof(int));<br/> gpuSub &lt;&lt; &lt;1, 1 &gt;&gt; &gt; (4, 1, d_c);<br/> cudaMemcpy(&amp;h_c, d_c, sizeof(int), cudaMemcpyDeviceToHost);<br/> printf("4-1 = %d\n", h_c);<br/> cudaFree(d_c);<br/> return 0;<br/>}<br/><br/><br/></pre>
<ol start="2">
<li>CUDA program to multiply two numbers by passing parameters as reference is as follows:</li>
</ol>
<pre style="padding-left: 60px">#include &lt;iostream&gt;<br/>#include &lt;cuda.h&gt;<br/>#include &lt;cuda_runtime.h&gt;<br/> __global__ void gpuMul(int *d_a, int *d_b, int *d_c) <br/>{<br/> *d_c = *d_a * *d_b;<br/>}<br/>int main(void) <br/>{<br/> int h_a,h_b, h_c;<br/> int *d_a,*d_b,*d_c;<br/> h_a = 1;<br/> h_b = 4;<br/> cudaMalloc((void**)&amp;d_a, sizeof(int));<br/> cudaMalloc((void**)&amp;d_b, sizeof(int));<br/> cudaMalloc((void**)&amp;d_c, sizeof(int));<br/> cudaMemcpy(d_a, &amp;h_a, sizeof(int), cudaMemcpyHostToDevice);<br/> cudaMemcpy(d_b, &amp;h_b, sizeof(int), cudaMemcpyHostToDevice);<br/> gpuMul &lt;&lt; &lt;1, 1 &gt;&gt; &gt; (d_a, d_b, d_c);<br/> cudaMemcpy(&amp;h_c, d_c, sizeof(int), cudaMemcpyDeviceToHost);<br/> printf("Passing Parameter by Reference Output: %d + %d = %d\n", h_a, h_b, h_c);<br/> cudaFree(d_a);<br/> cudaFree(d_b);<br/> cudaFree(d_c);<br/> return 0;<br/> }</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<ol start="3">
<li>Three ways to launch 5000 threads for <kbd>gpuMul</kbd> kernel as are follows:</li>
</ol>
<pre style="padding-left: 60px">1. gpuMul &lt;&lt; &lt;25, 200 &gt;&gt; &gt; (d_a, d_b, d_c);<br/>2. gpuMul &lt;&lt; &lt;50, 100 &gt;&gt; &gt; (d_a, d_b, d_c);<br/>3. gpuMul &lt;&lt; &lt;10, 500 &gt;&gt; &gt; (d_a, d_b, d_c);</pre>
<ol start="4">
<li>False</li>
<li>The program to find GPU Devices with version 5.0 or greater is as follows</li>
</ol>
<pre style="padding-left: 60px">int main(void) <br/>{ <br/>  int device; <br/>  cudaDeviceProp device_property; <br/>  cudaGetDevice(&amp;device); <br/>  printf("ID of device: %d\n", device); <br/>  memset(&amp;device_property, 0, sizeof(cudaDeviceProp)); <br/>  device_property.major = 5; <br/>  device_property.minor = 0; <br/>  cudaChooseDevice(&amp;device, &amp;device_property); <br/>  printf("ID of device which supports double precision is: %d\n", device);                                                                         <br/>  cudaSetDevice(device); <br/>} </pre>
<p class="mce-root"/>
<ol start="6">
<li>CUDA program to find Cube of Number is as follows:</li>
</ol>
<pre style="padding-left: 60px">#include "stdio.h"<br/>#include&lt;iostream&gt;<br/>#include &lt;cuda.h&gt;<br/>#include &lt;cuda_runtime.h&gt;<br/>#define N 50<br/>__global__ void gpuCube(float *d_in, float *d_out) <br/>{<br/>     //Getting thread index for current kernel<br/>     int tid = threadIdx.x; // handle the data at this index<br/>     float temp = d_in[tid];<br/>     d_out[tid] = temp*temp*temp;<br/> }<br/>int main(void) <br/>{<br/>     float h_in[N], h_out[N];<br/>     float *d_in, *d_out;<br/>     cudaMalloc((void**)&amp;d_in, N * sizeof(float));<br/>     cudaMalloc((void**)&amp;d_out, N * sizeof(float));<br/>      for (int i = 0; i &lt; N; i++) <br/>    {<br/>         h_in[i] = i;<br/>     }<br/>   cudaMemcpy(d_in, h_in, N * sizeof(float), cudaMemcpyHostToDevice);<br/>   gpuSquare &lt;&lt; &lt;1, N &gt;&gt; &gt;(d_in, d_out);<br/>  cudaMemcpy(h_out, d_out, N * sizeof(float), cudaMemcpyDeviceToHost);<br/>    printf("Cube of Number on GPU \n");<br/>     for (int i = 0; i &lt; N; i++) <br/>     {<br/>         printf("The cube of %f is %f\n", h_in[i], h_out[i]);<br/>     }<br/>     cudaFree(d_in);<br/>     cudaFree(d_out);<br/>     return 0;<br/> }</pre>
<ol start="7">
<li>Communication pattern for a particular application is given as shown here:
<ol>
<li>Image Processing - stencil</li>
<li> Moving Average - gather</li>
<li>Sorting Array in ascending order - Scatter</li>
<li> Finding cube of numbers in Array - Map</li>
</ol>
</li>
</ol>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 3</h1>
                
            
            
                
<ol>
<li>The best method to choose the number of threads and number of blocks is as follows:</li>
</ol>
<pre style="padding-left: 60px">gpuAdd &lt;&lt; &lt;512, 512 &gt;&gt; &gt;(d_a, d_b, d_c);</pre>
<p style="padding-left: 60px">There is a limit to the number of threads that can be launched per block which is 512 or 1024 for the latest processors. The same way there is a limit to the number of blocks per grid. So if there are a large number of threads then it is better to launch kernel by a small number of blocks and threads as described.</p>
<ol start="2">
<li>Following is the CUDA program to find the cube of 50000 number:</li>
</ol>
<pre style="padding-left: 60px">#include "stdio.h"<br/>#include&lt;iostream&gt;<br/>#include &lt;cuda.h&gt;<br/>#include &lt;cuda_runtime.h&gt;<br/>#define N 50000<br/>__global__ void gpuCube(float *d_in, float *d_out) <br/>{<br/>      int tid = threadIdx.x + blockIdx.x * blockDim.x; <br/>while (tid &lt; N)<br/>{<br/>    float temp = d_in[tid];<br/>    d_out[tid] = temp*temp*temp;<br/>    tid += blockDim.x * gridDim.x;<br/> }<br/>}<br/>int main(void) <br/>{<br/>     float h_in[N], h_out[N];<br/>     float *d_in, *d_out;<br/>     cudaMalloc((void**)&amp;d_in, N * sizeof(float));<br/>     cudaMalloc((void**)&amp;d_out, N * sizeof(float));<br/>      for (int i = 0; i &lt; N; i++) <br/>    {<br/>         h_in[i] = i;<br/>     }<br/>   cudaMemcpy(d_in, h_in, N * sizeof(float), cudaMemcpyHostToDevice);<br/>   gpuSquare &lt;&lt; &lt;512, 512 &gt;&gt; &gt;(d_in, d_out);<br/>  cudaMemcpy(h_out, d_out, N * sizeof(float), cudaMemcpyDeviceToHost);<br/>    printf("Cube of Number on GPU \n");<br/>     for (int i = 0; i &lt; N; i++) <br/>     {<br/>         printf("The cube of %f is %f\n", h_in[i], h_out[i]);<br/>     }<br/>     cudaFree(d_in);<br/>     cudaFree(d_out);<br/>     return 0;<br/> }</pre>
<ol start="3">
<li>True, because it only needs to access local memory, which is a faster memory.</li>
<li>When variables of the kernel do not fit in register files, they uses local memory. This is called as register spilling. Because some of the data is not in the registers, it will need more time to fetch it from memory. This will take more time, and hence the performance of the program will be affected.</li>
<li>No, because all the threads are running in parallel. So data might be read before it has been written, and thus it might not give the desired output.</li>
<li>True. In atomic operations, all the other threads have to wait when one thread is accessing a particular memory location. This will incur time overhead when many threads are accessing the same memory locations. So, atomic operations will increase the execution time of the CUDA program.</li>
<li>Stencil communication pattern is ideal for texture memory.</li>
</ol>
<p> </p>
<ol start="8">
<li>When <kbd>__syncthreads</kbd> directive is used inside an <kbd>if</kbd> statement, then for threads that have this condition, <kbd>false</kbd> will never reach this point and <kbd>__syncthreads</kbd> will continuously wait for all the threads to reach this point. Thus, the program will never be terminated.</li>
</ol>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 4</h1>
                
            
            
                
<ol>
<li>CPU timers will include time overhead of thread latency in OS and scheduling in OS, among many other factors. The time measured using CPU will also depend on the availability of high precision CPU timer. The host is frequently performing asynchronous computation while GPU kernel is running, and hence CPU timers may not give correct time for kernel executions.</li>
<li>Open Nvidia Visual profiler from <kbd>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\libnvvp</kbd>. Then, go to -&gt; New Session and Select <kbd>.exe</kbd> file for matrix multiplication example. You can visualize the performance of your code.</li>
<li>Divide by zero, incorrect variable types or sizes, nonexistent variables, subscripts out of range etc are examples of semantic errors.</li>
<li>An example of thread divergence can be given as follows:</li>
</ol>
<pre style="padding-left: 60px">__global__ void gpuCube(float *d_in, float *d_out) <br/>{<br/>     int tid = threadIdx.x; <br/>if(tid%2 == 0)<br/>{<br/>     float temp = d_in[tid];<br/>     d_out[tid] = temp*temp*temp;<br/> }<br/>else<br/>{<br/>    float temp = d_in[tid];<br/>    d_out[tid] = temp*temp*temp;<br/>}<br/>}</pre>
<p style="padding-left: 60px">In the code, odd and even number of threads are performing different operations, and hence they will take different amount of time for completion. After <kbd>if</kbd> statement, these threads will again merge. This will incur time overhead because fast threads have to wait for slow threads. This will slow down the performance of the code.</p>
<p class="mce-root"/>
<ol start="5">
<li> <kbd>cudaHostAlloc</kbd> function should be used with proper care because this memory is not swapped out of disk; your system may run out of memory. It may affect the performance of other applications running on the system. </li>
<li>The order of operation is important in CUDA stream operations as we want to overlap memory copy operations with kernel execution operations. So, operation queues should be made in such a way that these operations can overlap with each other, or else using CUDA stream won't help the performance of the program.</li>
<li>For 1024 x 1024 image, number of threads should be 32x32 (if your system supports 1024 threads per block), and the number of blocks should be 32 x 32, which can be determined by image size divided by number of threads per block.</li>
</ol>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 5</h1>
                
            
            
                
<ol>
<li> There is a difference between image processing and computer vision fields. Image processing is concerned with improving the visual quality of images by modifying pixel values, whereas computer vision is concerned with extracting important information from the images. So, in image processing, both input and output are images, while in computer vision, input is an image but the output is the information extracted from that image.</li>
<li>The OpenCV library has an interface in C, C++, Java, and Python languages and it can be used in all operating systems like Windows, Linux, Mac, and Android without modifying the single line of code. This library can also take advantage of multi-core processing. It can take advantage of OpenGL and CUDA for parallel processing. As OpenCV is lightweight, it can be used on embedded platforms like Raspberry Pi as well. This makes it ideal for deploying computer vision applications on embedded systems in real life scenarios.</li>
<li>The command to initialize image with red color is as follows:</li>
</ol>
<pre style="padding-left: 60px"> Mat img3(1960,1960, CV_64FC3, Scalar(0,0,255) )</pre>
<ol start="4">
<li>The program to capture video from webcam and store it on disk is as follows:</li>
</ol>
<pre style="padding-left: 60px">#include &lt;opencv2/opencv.hpp&gt;<br/>#include &lt;iostream&gt;<br/><br/>using namespace cv;<br/>using namespace std;<br/><br/>int main(int argc, char* argv[])<br/>{<br/>   VideoCapture cap(0); <br/>   if (cap.isOpened() == false) <br/>   {<br/>     cout &lt;&lt; "Cannot open Webcam" &lt;&lt; endl;<br/>     return -1;<br/> }<br/>  Size frame_size(640, 640);<br/>  int frames_per_second = 30;<br/><br/>  VideoWriter v_writer("images/video.avi", VideoWriter::fourcc('M', 'J', 'P', 'G'), frames_per_second, frame_size, true); <br/>  cout&lt;&lt;"Press Q to Quit" &lt;&lt;endl;<br/>  String win_name = "Webcam Video";<br/>  namedWindow(win_name); //create a window<br/>   while (true)<br/>   {<br/>     Mat frame;<br/>     bool flag = cap.read(frame); // read a new frame from video <br/>     imshow(win_name, frame);<br/>     v_writer.write(frame);<br/>  if (waitKey(1) == 'q')<br/>  {<br/>     v_writer.release(); <br/>     break;<br/>  }<br/> }<br/>return 0;<br/>}</pre>
<ol start="5">
<li>BGR color format is used by OpenCV to read and display an Image.</li>
<li>Program to capture video from a webcam and convert it to gray scale is as follows:</li>
</ol>
<pre style="padding-left: 60px">#include &lt;opencv2/opencv.hpp&gt;<br/>#include &lt;iostream&gt;<br/><br/>using namespace cv;<br/>using namespace std;<br/><br/>int main(int argc, char* argv[])<br/>{<br/>   VideoCapture cap(0); <br/> if (cap.isOpened() == false) <br/> {<br/>    cout &lt;&lt; "Cannot open Webcam" &lt;&lt; endl;<br/>    return -1;<br/> }<br/> cout&lt;&lt;"Press Q to Quit" &lt;&lt;endl;<br/> String win_name = "Webcam Video";<br/> namedWindow(win_name); //create a window<br/> while (true)<br/> {<br/>    Mat frame;<br/>    bool flag = cap.read(frame); // read a new frame from video <br/>    cvtColor(frame, frame,cv::COLOR_BGR2GRAY);<br/>    imshow(win_name, frame);<br/>  if (waitKey(1) == 'q')<br/>  {<br/>      break;<br/>  }<br/> }<br/>return 0;<br/>}</pre>
<ol start="7">
<li>OpenCV program to measure the performance of add and subtract operation is as follows:</li>
</ol>
<pre style="padding-left: 60px">#include &lt;iostream&gt;<br/>#include "opencv2/opencv.hpp"<br/><br/>int main (int argc, char* argv[])<br/>{<br/>    //Read Two Images <br/>    cv::Mat h_img1 = cv::imread("images/cameraman.tif");<br/>    cv::Mat h_img2 = cv::imread("images/circles.png");<br/>    //Create Memory for storing Images on device<br/>    cv::cuda::GpuMat d_result1,d_result2,d_img1, d_img2;<br/>    cv::Mat h_result1,h_result2;<br/>int64 work_begin = getTickCount(); <br/>    //Upload Images to device     <br/>    d_img1.upload(h_img1);<br/>    d_img2.upload(h_img2);<br/><br/>    cv::cuda::add(d_img1,d_img2, d_result1);<br/>    cv::cuda::subtract(d_img1, d_img2,d_result2);<br/>    //Download Result back to host<br/>    d_result1.download(h_result1);<br/>     d_result2.download(h_result2);<br/>    int64 delta = getTickCount() - work_begin;<br/>//Frequency of timer<br/>    double freq = getTickFrequency();<br/>    double work_fps = freq / delta;<br/>    std::cout&lt;&lt;"Performance of Thresholding on CPU: " &lt;&lt;std::endl;<br/>    std::cout &lt;&lt;"Time: " &lt;&lt; (1/work_fps) &lt;&lt;std::endl;   <br/>    cv::waitKey();<br/>    return 0;<br/>}</pre>
<ol start="8">
<li> OpenCV program for bitwise <kbd>AND</kbd> and <kbd>OR</kbd> operations is as follows:</li>
</ol>
<pre style="padding-left: 60px">include &lt;iostream&gt;<br/>#include "opencv2/opencv.hpp"<br/><br/>int main (int argc, char* argv[])<br/>{<br/>    cv::Mat h_img1 = cv::imread("images/cameraman.tif");<br/>    cv::Mat h_img2 = cv::imread("images/circles.png");<br/>    cv::cuda::GpuMat d_result1,d_result2,d_img1, d_img2;<br/>    cv::Mat h_result1,h_result2;<br/>    d_img1.upload(h_img1);<br/>    d_img2.upload(h_img2);<br/><br/>    cv::cuda::bitwise_and(d_img1,d_img2, d_result1);<br/>    cv::cuda::biwise_or(d_img1, d_img2,d_result2);<br/><br/>    d_result1.download(h_result1);<br/>     d_result2.download(h_result2);<br/>cv::imshow("Image1 ", h_img1);<br/>    cv::imshow("Image2 ", h_img2);<br/>    cv::imshow("Result AND operation ", h_result1);<br/>cv::imshow("Result OR operation ", h_result2);<br/>    cv::waitKey();<br/>    return 0;<br/>}</pre>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 6</h1>
                
            
            
                
<ol>
<li>OpenCV function to print pixel intensity at location<kbd>(200,200)</kbd> of any color image on the console is as follows:</li>
</ol>
<pre style="padding-left: 60px">cv::Mat h_img2 = cv::imread("images/autumn.tif",1);<br/>cv::Vec3b intensity1 = h_img1.at&lt;cv::Vec3b&gt;(cv::Point(200, 200));<br/>std::cout&lt;&lt;"Pixel Intensity of color Image at (200,200) is:" &lt;&lt; intensity1 &lt;&lt; std::endl;</pre>
<ol start="2">
<li>OpenCV function to resize an image to <kbd>(300,200)</kbd> pixels using bilinear Interpolation method is as follows:</li>
</ol>
<pre style="padding-left: 60px">cv::cuda::resize(d_img1,d_result1,cv::Size(300, 200), cv::INTER_LINEAR);</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<ol start="3">
<li>OpenCV function to upsample an image by 2 using <kbd>AREA</kbd> interpolation is as follows:</li>
</ol>
<pre style="padding-left: 60px">int width= d_img1.cols;<br/>int height = d_img1.size().height;<br/>cv::cuda::resize(d_img1,d_result2,cv::Size(2*width, 2*height), cv::INTER_AREA); </pre>
<ol start="4">
<li>False. Blurring increases as we increase the size of a filter.</li>
<li>False. The median filter can't remove Gaussian noise. It can remove salt and pepper noise.</li>
<li>The image has to be blurred using an Averaging or Gaussian filter before applying lapacian operator to remove noise sensitivity.</li>
<li>OpenCV function to implement top hat and black hat morphological operation is as follows:</li>
</ol>
<pre style="padding-left: 60px">cv::Mat element = cv::getStructuringElement(cv::MORPH_RECT,cv::Size(5,5)); <br/>  d_img1.upload(h_img1);<br/>  cv::Ptr&lt;cv::cuda::Filter&gt; filtert,filterb;<br/>  filtert = cv::cuda::createMorphologyFilter(cv::MORPH_TOPHAT,CV_8UC1,element);<br/>  filtert-&gt;apply(d_img1, d_resulte);<br/>  filterb = cv::cuda::createMorphologyFilter(cv::MORPH_BLACKHAT,CV_8UC1,element);<br/>  filterb-&gt;apply(d_img1, d_resultd);</pre>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 7</h1>
                
            
            
                
<ol>
<li>OpenCV code to detect objects with yellow color from a video is as follows: Note that the boilerplate code is not repeated here.</li>
</ol>
<pre style="padding-left: 60px">cuda::cvtColor(d_frame, d_frame_hsv, COLOR_BGR2HSV);<br/><br/>//Split HSV 3 channels<br/>cuda::split(d_frame_hsv, d_frame_shsv);<br/><br/>//Threshold HSV channels for Yellow color<br/>cuda::threshold(d_frame_shsv[0], d_thresc[0], 20, 30, THRESH_BINARY);<br/>cuda::threshold(d_frame_shsv[1], d_thresc[1], 100, 255, THRESH_BINARY);<br/>cuda::threshold(d_frame_shsv[2], d_thresc[2], 100, 255, THRESH_BINARY);<br/><br/>//Bitwise AND the channels<br/>cv::cuda::bitwise_and(d_thresc[0], d_thresc[1],d_intermediate);<br/>cv::cuda::bitwise_and(d_intermediate, d_thresc[2], d_result);<br/>d_result.download(h_result);<br/>imshow("Thresholded Image", h_result); <br/>imshow("Original", frame);</pre>
<ol start="2">
<li>When the color of an object is the same as the color of background, then color based object detection will fail. If there is a change in illumination, even then it can fail.</li>
<li>The first step of canny edge detection algorithm is Gaussian blurring, which removes the noise present in the image. After that, the gradient is computed. Thus, the edges detected will be less affected by noise here, than other edge detection algorithms seen earlier.</li>
<li>When the image is affected by Gaussian or salt-pepper noise, then the result of the Hough transform is very poor. To improve the result image must be filtered by Gaussian and Median filter, as a preprocessing step.</li>
<li> When the intensity threshold for computing FAST keypoints is low, then more keypoints will pass the segment test and will be categorized as key-points. As this threshold is increased, the number of key-points detected will gradually decrease.</li>
<li>The larger value of hessian threshold in SURF will result in fewer but more salient interest points and a smaller value will result in more numerous but less salient points.</li>
<li>When the scale factor of Haar cascade is increased from 1.01 to 1.05, then image size will be reduced by a larger factor at every scale. Thus, fewer images need to be processed per frame, which reduces computation time; however, this may fail to detect some of the objects.</li>
<li><kbd>MoG</kbd> is faster and less noisy compared to <kbd>GMG</kbd> algorithm for background subtraction. The morphological operation like opening and closing can be applied to the output of GMG to reduce the noise present.</li>
</ol>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 8</h1>
                
            
            
                
<ol start="1">
<li>Jetson TX1 offers performance in terms of Tera floating point operations per second, which is far better than Raspberry Pi. So Jetson TX1 can be used in computationally intensive applications like computer vision and deep learning for deployment in real time.</li>
</ol>
<p> </p>
<ol start="2">
<li>Jetson TX1 development board supports up to six 2-lane or three 4-lane cameras. It has one 5 megapixel camera attached to it.</li>
<li>The USB hub has to be used to connect more than two USB peripherals with Jetson TX1. </li>
<li>True</li>
<li>False. Jetson TX1 contains one ARM Cortex A57 quad-core CPU operating at 1.73 GHz.</li>
<li>Though Jetson TX1 comes with pre-flashed Ubuntu, it does not contain any software packages needed for Computer Vision applications. The Jetpack contains Linux of Tegra (L4T) board support packages, TensorRT, which is used for deep learning inference in computer vision applications, latest CUDA toolkit, cuDNN, which is CUDA deep neural network library, Visionworks, which is also used for computer vision and deep learning applications, and OpenCV. So, by installing Jetpack, we can install all software packages needed to build computer vision applications rapidly.</li>
</ol>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 9</h1>
                
            
            
                
<ol>
<li>The global memory for the GPU device on Jetson TX1 is around 4 GB with a GPU clock speed of around 1 GHz. This clock speed is slower than Geforce 940 GPU used earlier in this book. The memory clock speed is only 13 MHz compared to 2.505 GHz on Geforce 940, which makes Jetson TX1 slower. The L2 cache is 256 KB compared to 1 MB on Geforce 940. Most of the other properties are similar to GeForce 940.</li>
<li>True</li>
<li>In the latest Jetpack, OpenCV is not compiled with CUDA support nor does it have GStreamer support, which is needed for accessing the camera from the code. So, it is a good idea to remove OpenCV installation that comes with Jetpack and compile the new version of OpenCV with CUGA and GStreamer support.</li>
<li>False. OpenCV can capture video from both USB and CSI camera connected to Jetson TX1 board.</li>
<li>True. CSI camera is more close to hardware so frames are read quickly than USB camera so it is better to use CSI camera for computationally intensive applications.</li>
<li>Python OpenCV binding is not supported by CUDA acceleration so it is better to use C++ OpenCV binding for a computationally intensive task.</li>
</ol>
<p> </p>
<ol start="7">
<li>No. Jetson TX1 comes preinstalled with python2 and python3 interpreter, while OpenCV is compiled for Jetson TX1; it also installs python binaries so there is no need to install separate python OpenCV bindings.</li>
</ol>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 10</h1>
                
            
            
                
<ol>
<li>Python is Open Source and has a large user community contributing to the language in terms of modules. These modules can be used easily to develop applications in a small time with few lines of code. The syntax of Python language is easy to read and interpret, which makes it easier to learn for a new programmer. It is an interpreted language that allows line by line execution of the code. These are the few advantages of python over C/C++.</li>
<li>The whole code is checked and converted to machine code in compiled type languages, while one statement at a time is translated in an interpreted language. An interpreted language requires less amount of time to analyze the source code, but the overall execution time is slower compared to compile type languages. Interpreted languages do not generate intermediate code as in the case of compiled type languages.</li>
<li>False. Python is an interpreted language, which makes it slower than C/C++.</li>
<li>PyOpenCL can take advantage of any Graphics processing Unit, while PyCUDA requires Nvidia GPU and CUDA toolkit.</li>
<li>True. Python allows C/C++ code in a python script, and hence the computationally complex task can be written in C/C++ for faster processing, and python wrapper can be created for it. PyCUDA can leverage this capability for kernel code.</li>
</ol>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 11</h1>
                
            
            
                
<ol>
<li>C/C++ programming language is used to write kernel function inside <kbd>SourceModule</kbd> class, and this kernel function is compiled by <kbd>nvcc</kbd> (Nvidia C ) Compiler.</li>
<li>The kernel call function is as follows:</li>
</ol>
<pre style="padding-left: 60px">myfirst_kernel(block=(512,512,1),grid=(1024,1014,1))</pre>
<ol start="3">
<li>False. The order of block execution is random in PyCUDA program, and it can't be determined by PyCUDA programmer.</li>
</ol>
<p> </p>
<ol start="4">
<li>The directives from driver class remove the need of separate allocation of memory for the Array, uploading it to the device and downloading the result back to host. All operations are performed simultaneously during a kernel call. This makes the code simpler and easy to read.</li>
<li>The PyCUDA code for adding two to every element in an array is shown below:</li>
</ol>
<pre style="padding-left: 60px">import pycuda.gpuarray as gpuarray<br/>import numpy<br/>import pycuda.driver as drv<br/><br/>start = drv.Event()<br/>end=drv.Event()<br/>start.record()<br/>start.synchronize()<br/>n=10<br/>h_b = numpy.random.randint(1,5,(1,n))<br/>d_b = gpuarray.to_gpu(h_b.astype(numpy.float32))<br/>h_result = (d_b + 2).get()<br/>end.record()<br/>end.synchronize()<br/><br/>print("original array:")<br/>print(h_b)<br/>print("doubled with gpuarray:")<br/>print(h_result)<br/>secs = start.time_till(end)*1e-3<br/>print("Time of adding 2 on GPU with gpuarray")<br/>print("%fs" % (secs))</pre>
<ol start="6">
<li>The use of Python time measuring options for measuring the performance of PyCUDA programs will not give accurate results. It will include time overhead of thread latency in OS and scheduling in OS, among many other factors. The time measured using time class will also depend on the availability of high precision CPU timer. Many a times, host is performing asynchronous computation while GPU kernel is running, and hence CPU timers of Python may not give correct time for kernel executions. We can overcome these drawbacks by using CUDA events.</li>
<li>True</li>
</ol>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Chapter 12</h1>
                
            
            
                
<ol>
<li>False. This line represents a read-modify-write operation that can yield wrong results when multiple threads are trying to increment the same memory location, as in the case of histogram calculation.</li>
</ol>
<ol start="2">
<li> In the case of using shared memory, fewer threads are trying to access 256 memory elements in shared memory, instead of all threads as in the case without shared memory. This will help in reducing time overhead in the atomic operation. </li>
<li>The kernel call function in case of using share memory is as follows:</li>
</ol>
<pre style="padding-left: 60px">atomic_hist(<br/>        drv.Out(h_result), drv.In(h_a), numpy.uint32(SIZE),<br/>        block=(n_threads,1,1), grid=(NUM_BIN,1),shared= 256*4)</pre>
<p>The size of the shared memory should be defined, while calling the kernel. This is specified by using the shared argument in the kernel call function.</p>
<ol start="4">
<li>The histogram is a statistical feature that gives important information regarding the contrast and brightness of an image. If it has a uniform distribution, then the image will have a good contrast. The histogram also conveys the information about the brightness of an image. If the histogram is concentrated on the left-hand side of the plot, then the image will be too dark, and if it is concentrated on the right-hand side, then the image will be too bright.</li>
<li>True. As RGB and BGR color format is same just the order of channels is different. The equation of conversion will still remain the same.</li>
<li> It is simpler to work with single dimensional threads and blocks than multidimensional. It simplifies the indexing mechanism inside the kernel function, and hence it is performed in every example that appears in the chapter. It is not mandatory if we are working with multidimensional threads and blocks.</li>
<li>The <kbd>imshow</kbd> function, used to display an image on the screen, requires an image in unsigned integer format. So all the results computed by kernel function are converted <kbd>uint8</kbd> datatype of <kbd>numpy</kbd> library before displaying on the screen.</li>
</ol>


            

            
        
    </div></div></body></html>