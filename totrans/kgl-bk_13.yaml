- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modeling for NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Natural language processing** (**NLP**) is a field operating at the intersection
    of linguistics, computer science, and AI. Its primary focus is algorithms to process
    and analyze large amounts of natural language data. Over the last few years, it
    has become an increasingly popular topic of Kaggle competitions. While the domain
    itself is very broad and encompasses very popular topics such as chatbots and
    machine translation, in this chapter we will focus on specific subsets that Kaggle
    contests frequently deal with.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sentiment analysis as a simple classification problem is extremely popular
    and discussed all over, so we’ll begin with a somewhat more interesting variation
    on the problem: identifying sentiment-supporting phrases in a tweet. We’ll proceed
    to describe an example solution to the problem of open domain question answering
    and conclude with a section on augmentation for NLP problems, which is a topic
    that receives significantly less attention than its computer vision counterpart.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open domain Q&A
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text augmentation strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Twitter is one of the most popular social media platforms and an important communication
    tool for many, individuals and companies alike.
  prefs: []
  type: TYPE_NORMAL
- en: 'Capturing sentiment in language is particularly important in the latter context:
    a positive tweet can go viral and spread the word, while a particularly negative
    one can be harmful. Since human language is complicated, it is important not to
    just decide on the sentiment, but also to be able to investigate the *how*: which
    words actually led to the sentiment description?'
  prefs: []
  type: TYPE_NORMAL
- en: We will demonstrate an approach to this problem by using data from the *Tweet
    Sentiment Extraction* competition ([https://www.kaggle.com/c/tweet-sentiment-extraction](https://www.kaggle.com/c/tweet-sentiment-extraction)).
    For brevity, we have omitted the imports from the following code, but you can
    find them in the corresponding Notebook in the GitHub repo for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a better feel for the problem, let’s start by looking at the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the first few rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Obraz zawierający stół  Opis wygenerowany automatycznie](img/B17574_11_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: Sample rows from the training data'
  prefs: []
  type: TYPE_NORMAL
- en: The actual tweets are stored in the `text` column. Each of them has an associated
    `sentiment`, along with the **support phrase** stored in the `selected_text` column
    (the part of the tweet that was the basis for the decision on sentiment assignment).
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by defining basic cleanup functions. First, we want to get rid of
    website URLs and non-characters and replace the stars people use in place of swear
    words with a single token, `"swear"`. We use some regular expressions to help
    us do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we remove HTML from the content of the tweets, as well as emojis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we want to be able to remove repeated characters (for example, so we
    have “way” instead of “waaaayyyyy”):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'For convenience, we combine the four functions into a single cleanup function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The last bit of preparation involves writing functions for creating the embeddings
    based on a pre-trained model (the `tokenizer` argument):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a pre-processing function enabling us to work with the entire
    corpus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Using our previously prepared functions, we can clean and prepare the training
    data. The `sentiment` column is our target, and we convert it to dummy variables
    (one-hot encoding) for performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'A necessary next step is **tokenization** of the input texts, as well as conversion
    into sequences (along with padding, to ensure equal lengths across the dataset):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We will create the embeddings for our model using **DistilBERT** and use them
    as-is. DistilBERT is a lightweight version of BERT: the tradeoff is 3% performance
    loss at 40% fewer parameters. We could train the embedding layer and gain performance
    – at the cost of massively increased training time.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the previously defined `fast_encode` function, along with the `fast_tokenizer`
    defined above, to encode the tweets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'With the data prepared, we can construct the model. For the sake of this demonstration,
    we will go with a fairly standard architecture for these applications: a combination
    of LSTM layers, normalized by global pooling and dropout, and a dense layer on
    top. In order to achieve a truly competitive solution, some tweaking of the architecture
    would be needed: a “heavier” model, bigger embeddings, more units in the LSTM
    layers, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'There is no special need to pay attention to a temporal dimension of the data,
    so we are fine with a random split into training and validation, which can be
    achieved inside a call to the `fit` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Below is some sample output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Generating a prediction from the fitted model proceeds in a straightforward
    manner. In order to utilize all the available data, we begin by re-training our
    model on all available data (so no validation):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We refit the model on the entire dataset before generating the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Our next step is to process the test data into the same format we are using
    for training data fed into the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we generate the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The final model shows **0.74** accuracy on the test set. Below we show a sample
    of what the output looks like; as you can see already from these few rows, there
    are some instances where the sentiment is obvious to a human reader, but the model
    fails to capture it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Obraz zawierający stół  Opis wygenerowany automatycznie](img/B17574_11_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Example rows from the predicted results'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have now demonstrated a sample pipeline for solving sentiment attribution
    problems (identifying parts of the text that lead to annotator decisions on sentiment
    classification). There are some improvements that can be made if you want to achieve
    competitive performance, given below in order of likely impact:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Larger embeddings**: This allows us to capture more information already at
    the (processed) input data level'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bigger model**: More units in the LSTM layers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Longer training**: In other words, more epochs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While the improvements listed above will undoubtedly boost the performance
    of the model, the core elements of our pipeline are reusable:'
  prefs: []
  type: TYPE_NORMAL
- en: Data cleaning and pre-processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating text embeddings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorporating recurrent layers and regularization in the target model architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll now move on to a discussion of open domain question answering, a frequent
    problem encountered in NLP competitions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Abhishek_Thakur.png)'
  prefs: []
  type: TYPE_IMG
- en: Abhishek Thakur
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/abhishek](https://www.kaggle.com/abhishek)'
  prefs: []
  type: TYPE_NORMAL
- en: We caught up with Abhishek Thakur, the world’s first quadruple Kaggle Grandmaster.
    He currently works at Hugging Face, where he is building AutoNLP; he also wrote
    pretty much the only book on Kaggle in English (aside from this one!), *Approaching
    (Almost) Any Machine Learning Problem*.
  prefs: []
  type: TYPE_NORMAL
- en: What’s your specialty on Kaggle?
  prefs: []
  type: TYPE_NORMAL
- en: '*None. Every competition is different and there is so much to learn from each
    one of them. If I were to have a specialty, I would win all competitions in that
    domain.*'
  prefs: []
  type: TYPE_NORMAL
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  prefs: []
  type: TYPE_NORMAL
- en: '*The first thing I do is to take a look at the data and try to understand it
    a bit. If I’m late to the competition, I take the help of public EDA kernels.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The first thing I do when approaching a problem on (or off) Kaggle is to build
    a benchmark. Building a benchmark is very important as it provides you with a
    baseline you can compare your future models to. If I’m late to the game, for building
    the baseline, I try not to take the help of public Notebooks. If we do that, we
    think only in a single direction. At least, that’s what I feel.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*When I am done with a benchmark, I try to squeeze as much as possible without
    doing anything complicated like stacking or blending. Then I go over the data
    and models again and try to improve on the baseline, one step at a time.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Day-to-day work sometimes has a lot of similarities. Most of the time there
    is a benchmark and then you have to come up with techniques, features, models
    that beat the benchmark.*'
  prefs: []
  type: TYPE_NORMAL
- en: What was the most interesting competition you entered? Did you have any special
    insights?
  prefs: []
  type: TYPE_NORMAL
- en: '*Every competition is interesting.*'
  prefs: []
  type: TYPE_NORMAL
- en: Has Kaggle helped you in your career?
  prefs: []
  type: TYPE_NORMAL
- en: '*Sure, it has helped. In the last few years, Kaggle has gained a very good
    reputation when it comes to hiring data scientists and machine learning engineers.
    Kaggle rank and experience with many datasets is something that surely helps in
    the industry in one way or another. The more experienced you are with approaching
    different types of problems, the faster you will be able to iterate. And that’s
    something very useful in industries. No one wants to spend several months doing
    something that doesn’t bring any value to the business.*'
  prefs: []
  type: TYPE_NORMAL
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  prefs: []
  type: TYPE_NORMAL
- en: '*Most beginners give up quite easily. It’s very easy to join a Kaggle competition
    and get intimidated by top scorers. If beginners want to succeed on Kaggle, they
    have to have perseverance. In my opinion, perseverance is the key. Many beginners
    also fail to start on their own and stick to public kernels. This makes them think
    like the authors of public kernels. My advice would be to start with competitions
    on your own, look at data, build features, build models, and then dive into kernels
    and discussions to see what others might be doing differently. Then incorporate
    what you have learned into your own solution.*'
  prefs: []
  type: TYPE_NORMAL
- en: Open domain Q&A
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will be looking at the *Google QUEST Q&A Labeling* competition
    ([https://www.kaggle.com/c/google-quest-challenge/overview/description](https://www.kaggle.com/c/google-quest-challenge/overview/description)).
    In this competition, question-answer pairs were evaluated by human raters on a
    diverse set of criteria, such as “question conversational,” “question fact-seeking,”
    or “answer helpful.” The task was to predict a numeric value for each of the target
    columns (corresponding to the criteria); since the labels were aggregated across
    multiple raters, the objective was effectively a multivariate regression output,
    with target columns normalized to the unit range.
  prefs: []
  type: TYPE_NORMAL
- en: Before engaging in modeling with advanced techniques (like transformer-based
    models for NLP), it is frequently a good idea to establish a baseline with simpler
    methods. As with the previous section, we will omit the imports for brevity, but
    you can find them in the Notebook in the GitHub repo.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by defining several helper functions, which can help us extract different
    aspects of the text. First, a function that will output a word count given a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The metric used in the competition was **Spearman correlation** (linear correlation
    computed on ranks: [https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we intend to build a Scikit-learn pipeline, it is useful to define the
    metric as a scorer (the `make_scorer` method is a wrapper in Scikit-learn that
    takes a scoring function – like accuracy or MSE – and returns a callable that
    scores an output of the estimator):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, a small helper function to extract successive chunks of size `n` from
    `l`. This will help us later with generating embeddings for our body of text without
    running into memory problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Part of the feature set we will use is embeddings from pre-trained models. Recall
    that the idea of this section is the construction of a baseline without training
    elaborate models, but this need not prevent us from using existing ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by importing the tokenizer and model, and then we process the corpus
    in chunks, encoding each question/answer into a fixed-size embedding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now proceed to load the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the first few rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Obraz zawierający stół  Opis wygenerowany automatycznie](img/B17574_11_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: Sample rows from the training data'
  prefs: []
  type: TYPE_NORMAL
- en: 'We specify our 30 target columns of interest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: For a discussion of their meaning and interpretation, the reader is referred
    to the competition’s **Data** page, at [https://www.kaggle.com/c/google-quest-challenge/data](https://www.kaggle.com/c/google-quest-challenge/data).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we proceed with **feature engineering**. We start by counting the words
    in the title and body of the question, as well as the answer. This is a simple
    yet surprisingly useful feature in many applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The next feature we create is **lexical diversity**, counting the proportion
    of unique words in a chunk of text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'When dealing with information sourced from online, we can extract potentially
    informative features by examining the components of a website address (where we
    define components as elements of the address separated by dots); we count the
    number of components, and store individual ones as features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Numerous target columns deal with how relevant the answer is for a given question.
    One possible way of quantifying this relationship is evaluating **shared words**
    within a pair of strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Stopwords and punctuation occurrence patterns can tell us something about the
    style and intent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: With the “vintage” features prepared – where our focus is on simple summary
    statistics of the text, without paying heed to semantic structure – we can move
    on to creating **embeddings** for the questions and answers. We could theoretically
    train a separate word2vec-type model on our data (or fine-tune an existing one),
    but for the sake of this presentation we will use a pre-trained model as-is. A
    useful choice is the **Universal Sentence Encoder** from Google ([https://tfhub.dev/google/universal-sentence-encoder/4](https://tfhub.dev/google/universal-sentence-encoder/4)).
    This model is trained on a variety of data sources. It takes as input a piece
    of text in English and outputs a 512-dimensional vector.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The code for turning the text fields into embeddings is presented below: we
    loop through the entries in the training/test sets in batches, embed each batch
    (for memory efficiency reasons), and then append them to the original list.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The final data frames are constructed by stacking each list of batch-level
    embeddings vertically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Given the vector representations for both questions and answers, we can calculate
    the semantic similarity between the fields by using different distance metrics
    on the pairs of vectors. The idea behind trying different metrics is the desire
    to capture diverse types of characteristics; an analogy in the context of classification
    would be to use both accuracy and entropy to get a complete picture of the situation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s gather the distance features in separate columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we can also create **TF-IDF** representations of the text fields; the
    general idea is to create multiple features based on diverse transformations of
    the input text, and then feed them to a relatively simple model.
  prefs: []
  type: TYPE_NORMAL
- en: This way, we can capture the characteristics of the data without the need to
    fit a sophisticated deep learning model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can achieve it by analyzing the text at the word as well as the character
    level. To limit the memory consumption, we put an upper bound on the maximum number
    of both kinds of features (your mileage might vary; with more memory, these limits
    can be upped):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We instantiate character- and word-level vectorizers. The setup of our problem
    lends itself to a convenient usage of the `Pipeline` functionality from Scikit-learn,
    allowing a combination of multiple steps in the model fitting procedure. We begin
    by creating two separate transformers for the title column (word- and character-level):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the same logic (two different pipelined transformers) for the body:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally for the answer column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We wrap up the feature engineering part by processing the numerical features.
    We use simple methods only: missing value imputation to take care of N/A values
    and a power transformer to stabilize the distribution and make it closer to Gaussian
    (which is frequently helpful if you are using a numerical feature inside a neural
    network):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'A useful feature of Pipelines is they can be combined and nested. Next, we
    add functionality to handle categorical variables, and then put it all together
    in a `ColumnTransformer` object to streamline the data pre-processing and feature
    engineering logic. Each part of the input can be handled in its own appropriate
    manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we are ready to use a `Pipeline` object combining pre-processing and
    model fitting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'It is always a good idea to evaluate the performance of your model out of sample:
    a convenient way to go about this is to create **out-of-fold predictions**, which
    we discussed in *Chapter 6*. The procedure involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Split the data into folds. In our case we use `GroupKFold`, since one question
    can have multiple answers (in separate rows of the data frame). In order to prevent
    information leakage, we want to ensure each question only appears in one fold.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each fold, train the model using the data in the other folds, and generate
    the predictions for the fold of choice, as well as the test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Average the predictions on the test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We start with preparing the “storage” matrices in which we will store the predictions.
    `mvalid` will contain the out-of-fold predictions, while `mfull` is a placeholder
    for the predictions on the entire test set, averaged across folds. Since several
    questions contain more than one candidate answer, we stratify our `KFold` split
    on `question_body`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We loop through the folds and build the separate models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the fitting part is done, we can evaluate the performance in accordance
    with the metric specified in the competition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The final score is **0.34**, which is fairly acceptable as a starting point.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have demonstrated how to build descriptive features on a
    body of text. While this is not a winning formula for an NLP competition (the
    score is OK, but not a guarantee for landing in the medal zone), it is a useful
    tool to keep in your toolbox. We close this chapter with a section providing an
    overview of text augmentation techniques.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Shotaro_Ishihara.png)'
  prefs: []
  type: TYPE_IMG
- en: Shotaro Ishihara
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/sishihara](https://www.kaggle.com/sishihara)'
  prefs: []
  type: TYPE_NORMAL
- en: Our second interview of the chapter is with Shotaro Ishihara, aka u++, a Competitions
    and Notebooks Master who was a member of the winning team in the *PetFinder.my
    Adoption Prediction* competition. He is currently a Data Scientist and Researcher
    at a Japanese news media company, and has also published books in Japanese on
    Kaggle, including a translation of Abhishek Thakur’s book. He maintains a weekly
    newsletter in Japanese on Kaggle initiatives ([https://www.getrevue.co/profile/upura](https://www.getrevue.co/profile/upura)).
  prefs: []
  type: TYPE_NORMAL
- en: Where can we find the Kaggle books you’ve written/translated?
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kspub.co.jp/book/detail/5190067.html](https://www.kspub.co.jp/book/detail/5190067.html)
    *is a Kaggle primer for beginners based on the* Titanic *GettingStarted competition.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://book.mynavi.jp/ec/products/detail/id=123641](https://book.mynavi.jp/ec/products/detail/id=123641)
    *is the Japanese translation of Abhishek Thakur’s* Approaching (Almost) Any Machine
    Learning Problem.'
  prefs: []
  type: TYPE_NORMAL
- en: What’s your favorite kind of competition and why? In terms of techniques and
    solving approaches, what is your specialty on Kaggle?
  prefs: []
  type: TYPE_NORMAL
- en: '*In Kaggle, I love joining competitions with tabular or text datasets. These
    types of datasets are familiar to me because they are widely used in news media
    companies. I have a good knowledge of the approaches used to handle these datasets.*'
  prefs: []
  type: TYPE_NORMAL
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  prefs: []
  type: TYPE_NORMAL
- en: '*The first process is the same: thinking about how to tackle the problem through
    exploratory data analysis. Kaggle assumes the use of advanced machine learning,
    but this is not the case in business. In practice, I try to find ways to avoid
    using machine learning. Even when I do use it, I prefer working with classical
    methods such as TF-IDF and linear regression rather than advanced methods such
    as BERT.*'
  prefs: []
  type: TYPE_NORMAL
- en: We are interested in learning more about how to avoid using machine learning
    in real-world problems. Can you give us some examples?
  prefs: []
  type: TYPE_NORMAL
- en: '*When working on automated article summaries at work, we adopt a more straightforward
    extractive approach (*[https://www.jstage.jst.go.jp/article/pjsai/JSAI2021/0/JSAI2021_1D2OS3a03/_article/-char/en](https://www.jstage.jst.go.jp/article/pjsai/JSAI2021/0/JSAI2021_1D2OS3a03/_article/-char/en)*)
    rather than a neural network-based method (*[https://www.jstage.jst.go.jp/article/pjsai/JSAI2021/0/JSAI2021_1D4OS3c02/_article/-char/en](https://www.jstage.jst.go.jp/article/pjsai/JSAI2021/0/JSAI2021_1D4OS3c02/_article/-char/en)*).*'
  prefs: []
  type: TYPE_NORMAL
- en: '*It is difficult to guarantee 100% performance with machine learning, and simple
    methods that are easy for humans to understand and engage with are sometimes preferred.*'
  prefs: []
  type: TYPE_NORMAL
- en: Tell us about a particularly challenging competition you entered, and what insights
    you used to tackle the task.
  prefs: []
  type: TYPE_NORMAL
- en: '*In the* PetFinder.my Adoption Prediction *competition, a multi-modal dataset
    was provided. Many participants tried to explore and use all types of data, and
    the main approach was to extract features from images and texts, concatenate them,
    and train LightGBM. I also employed the same approach. Surprisingly, one of my
    teammates, takuoko (*[https://www.kaggle.com/takuok](https://www.kaggle.com/takuok)*),
    developed a great neural network that handles all datasets end to end. Well-designed
    neural networks have the potential to outperform LightGBM in multi-modal competitions.
    This is a lesson I learned in 2019.*'
  prefs: []
  type: TYPE_NORMAL
- en: Is that lesson still valid today?
  prefs: []
  type: TYPE_NORMAL
- en: '*I think the answer is yes. Compared to 2019, neural networks are getting better
    and better at handling multimodal data.*'
  prefs: []
  type: TYPE_NORMAL
- en: Has Kaggle helped you in your career? If so, how?
  prefs: []
  type: TYPE_NORMAL
- en: '*Yes. Kaggle gave me a lot of experience in data analysis. The machine learning
    knowledge I’ve gained from Kaggle has significantly helped me to work more successfully.
    My achievements in Kaggle and business work were one of the main reasons why I
    received the 30 Under 30 Awards and Grand Prize in 2020 from the International
    News Media Association. Kaggle has also allowed me to get to know a lot of people.
    These relationships have definitely contributed to my career development.*'
  prefs: []
  type: TYPE_NORMAL
- en: How have you built up your portfolio thanks to Kaggle?
  prefs: []
  type: TYPE_NORMAL
- en: '*Learned skills, achieved competition results, and published Notebooks, books,
    newsletters, and so on.*'
  prefs: []
  type: TYPE_NORMAL
- en: How do you promote your publishing?
  prefs: []
  type: TYPE_NORMAL
- en: '*I have various communication channels and I use the appropriate tools for
    promotion. For example, Twitter, personal blogs, and YouTube.*'
  prefs: []
  type: TYPE_NORMAL
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  prefs: []
  type: TYPE_NORMAL
- en: '*The importance of exploratory data analysis. In the field of machine learning,
    there is a concept of the No Free Lunch theorem. We should not only learn algorithms,
    but also learn how to address challenges. The No Free Lunch theorem is a statement
    that there is no universal model that performs well on all problems.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*In machine learning competitions, it is essential to find a model that is
    appropriate to the characteristics of the dataset and the task in order to improve
    your score.*'
  prefs: []
  type: TYPE_NORMAL
- en: What mistakes have you made in competitions in the past?
  prefs: []
  type: TYPE_NORMAL
- en: '*Overfitting to the public leaderboard. In the* LANL Earthquake Prediction
    *competition, I scored pretty well on the public leaderboard and finished the
    competition at the rank of fifth. However, my final ranking was 211*^(st)*, which
    means I believed too much in a limited dataset. Overfitting is a very popular
    concept in machine learning, and I realized the importance of this with pain through
    Kaggle.*'
  prefs: []
  type: TYPE_NORMAL
- en: Do you suggest any particular way to avoid overfitting?
  prefs: []
  type: TYPE_NORMAL
- en: '*It is important to observe carefully how the training and evaluation datasets
    are divided. I try to build a validation set that reproduces this partitioning.*'
  prefs: []
  type: TYPE_NORMAL
- en: Are there any particular tools or libraries that you would recommend using for
    data analysis or machine learning?
  prefs: []
  type: TYPE_NORMAL
- en: '*I love Pandas, which is an essential library for handling tabular datasets.
    I use it for exploratory data analysis by extracting, aggregating, and visualizing.*'
  prefs: []
  type: TYPE_NORMAL
- en: What do you suggest readers do to master Pandas?
  prefs: []
  type: TYPE_NORMAL
- en: '*You can look at some community tutorials. Kaggle also provides some learning
    tutorial courses on Pandas and feature engineering.*'
  prefs: []
  type: TYPE_NORMAL
- en: Do you use other competition platforms? How do they compare to Kaggle?
  prefs: []
  type: TYPE_NORMAL
- en: '*I sometimes use Japanese platforms like Signate, Nishika, etc. (*[https://upura.github.io/projects/data_science_competitions/](https://upura.github.io/projects/data_science_competitions/)*).
    These are obviously inferior to Kaggle in terms of functionality and UX/UX, but
    it’s interesting to see familiar subjects like the Japanese language.*'
  prefs: []
  type: TYPE_NORMAL
- en: Text augmentation strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We discussed augmentation strategies for computer vision problems extensively
    in the previous chapter. By contrast, similar approaches for textual data are
    a less well-explored topic (as evidenced by the fact there is no single package
    like `albumentations`). In this section, we demonstrate some of the possible approaches
    to addressing the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Basic techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As usual, it is informative to examine the basic approaches first, focusing
    on random changes and synonym handling. A systematic study of the basic approaches
    is provided in *Wei* and *Zou* (2019) at [https://arxiv.org/abs/1901.11196](https://arxiv.org/abs/1901.11196).
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin with **synonym replacement**. Replacing certain words with their synonyms
    produces text that is close in meaning to the original, but slightly perturbed
    (see the project page at [https://wordnet.princeton.edu/](https://wordnet.princeton.edu/)
    if you are interested in more details, like where the synonyms are actually coming
    from):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We create a simple wrapper around the workhorse function defined above, specifying
    a chunk of text (a string containing multiple words) and replace at most *n* of
    the words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see how the function works in practice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Not quite what you would call Shakespearean, but it does convey the same message
    while changing the style markedly. We can extend this approach by creating multiple
    new sentences per tweet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, generating variations of a text chunk using synonyms is quite
    straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: Next, **swapping** is a simple and efficient method; we create a modified sentence
    by randomly swapping the order of words in the text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Carefully applied, this can be viewed as a potentially useful form of **regularization**,
    as it disturbs the sequential nature of the data that models like LSTM rely on.
    The first step is to define a function swapping words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we write a wrapper around this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Synonyms and swapping do not affect the length of the sentence we are modifying.
    If in a given application it is useful to modify that attribute, we can remove
    or add words to the sentence.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common way to implement the former is to delete words at random:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'If we can remove, we can also add, of course. Random insertion of words to
    a sentence can be viewed as the NLP equivalent of adding noise or blur to an image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the function in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We can combine all the transformations discussed above into a single function,
    producing four variants of the same sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The augmentation methods discussed above do not exploit the structure of text
    data - to give one example, even analyzing a simple characteristic like “part
    of speech” can help us construct more useful transformations of the original text.
    This is the approach we will now focus on.
  prefs: []
  type: TYPE_NORMAL
- en: nlpaug
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We conclude this section by demonstrating the capabilities provided by the `nlpaug`
    package ([https://github.com/makcedward/nlpaug](https://github.com/makcedward/nlpaug)).
    It aggregates different methods for text augmentation and is designed to be lightweight
    and easy to incorporate into a workflow. We demonstrate some examples of the functionality
    contained therein below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We import the character- and word-level augmenters, which we will use to plug
    in specific methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'What happens when we apply a **simulated typo** to our test sentence? This
    transformation can be parametrized in a number of ways; for a full list of parameters
    and their explanations, the reader is encouraged to examine the official documentation:
    [https://nlpaug.readthedocs.io/en/latest/augmenter/char/keyboard.html](https://nlpaug.readthedocs.io/en/latest/augmenter/char/keyboard.html).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'We can simulate an **OCR error** creeping into our input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'We get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'While useful, character-level transformations have a limited scope when it
    comes to creative changes in the data. Let us examine what possibilities `nlpaug`
    offers when it comes to word-level modifications. Our first example is replacing
    a fixed percentage of words with their antonyms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'We get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '`nlpaug` also offers us a possibility for, for example, replacing synonyms;
    such transformations can also be achieved with the more basic techniques discussed
    above. For completeness’ sake, we demonstrate a small sample below, which uses
    a BERT architecture under the hood:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `nlpaug` offers a broad range of options for modifying your
    textual input to generate augmentations. Which ones should actually be chosen
    is very much context-dependent and the decision requires a little bit of domain
    knowledge, suited to a particular application.
  prefs: []
  type: TYPE_NORMAL
- en: Some places for further exploration would be beginner competitions such as *Natural
    Language Processing with Disaster Tweets* ([https://www.kaggle.com/c/nlp-getting-started](https://www.kaggle.com/c/nlp-getting-started)),
    as well as more intermediate or advanced ones like *Jigsaw Rate Severity of Toxic
    Comments* ([https://www.kaggle.com/c/jigsaw-toxic-severity-rating](https://www.kaggle.com/c/jigsaw-toxic-severity-rating))
    or *Google QUEST Q&A Labeling* ([https://www.kaggle.com/c/google-quest-challenge](https://www.kaggle.com/c/google-quest-challenge)).
    In all of these cases, `nlpaug` has been widely used – including in the winning
    solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed modeling for NLP competitions. We demonstrate
    both vintage and state-of-the-art methods applicable to a diverse range of problems
    appearing in Kaggle competitions. In addition, we touched upon the frequently
    ignored topic of text augmentation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss simulation competitions, a new class of
    contests that has been gaining popularity over the last few years.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/KaggleDiscord](https://packt.link/KaggleDiscord)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code40480600921811704671.png)'
  prefs: []
  type: TYPE_IMG
